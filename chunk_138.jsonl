{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lock_key(key_name,\n             stash,\n             passphrase,\n             backend):\n    \"\"\"Lock a key to prevent it from being deleted, purged or modified\n\n    `KEY_NAME` is the name of the key to lock\n    \"\"\"\n    stash = _get_stash(backend, stash, passphrase)\n\n    try:\n        click.echo('Locking key...')\n        stash.lock(key_name=key_name)\n        click.echo('Key locked successfully')\n    except GhostError as ex:\n        sys.exit(ex)", "response": "Lock a key in a stash"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unlock_key(key_name,\n               stash,\n               passphrase,\n               backend):\n    \"\"\"Unlock a key to allow it to be modified, deleted or purged\n\n    `KEY_NAME` is the name of the key to unlock\n    \"\"\"\n    stash = _get_stash(backend, stash, passphrase)\n\n    try:\n        click.echo('Unlocking key...')\n        stash.unlock(key_name=key_name)\n        click.echo('Key unlocked successfully')\n    except GhostError as ex:\n        sys.exit(ex)", "response": "Unlock a key in a stash"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve a key from the stash", "response": "def get_key(key_name,\n            value_name,\n            jsonify,\n            no_decrypt,\n            stash,\n            passphrase,\n            backend):\n    \"\"\"Retrieve a key from the stash\n\n    \\b\n    `KEY_NAME` is the name of the key to retrieve\n    `VALUE_NAME` is a single value to retrieve e.g. if the value\n     of the key `test` is `a=b,b=c`, `ghost get test a`a will return\n     `b`\n    \"\"\"\n    if value_name and no_decrypt:\n        sys.exit('VALUE_NAME cannot be used in conjuction with --no-decrypt')\n\n    stash = _get_stash(backend, stash, passphrase, quiet=jsonify or value_name)\n\n    try:\n        key = stash.get(key_name=key_name, decrypt=not no_decrypt)\n    except GhostError as ex:\n        sys.exit(ex)\n\n    if not key:\n        sys.exit('Key `{0}` not found'.format(key_name))\n    if value_name:\n        key = key['value'].get(value_name)\n        if not key:\n            sys.exit(\n                'Value name `{0}` could not be found under key `{1}`'.format(\n                    value_name, key_name))\n\n    if jsonify or value_name:\n        click.echo(\n            json.dumps(key, indent=4, sort_keys=False).strip('\"'),\n            nl=True)\n    else:\n        click.echo('Retrieving key...')\n        click.echo('\\n' + _prettify_dict(key))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_key(key_name, stash, passphrase, backend):\n    stash = _get_stash(backend, stash, passphrase)\n\n    for key in key_name:\n        try:\n            click.echo('Deleting key {0}...'.format(key))\n            stash.delete(key_name=key)\n        except GhostError as ex:\n            sys.exit(ex)\n    click.echo('Keys deleted successfully')", "response": "Delete a key from the stash"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_keys(key_name,\n              max_suggestions,\n              cutoff,\n              jsonify,\n              locked,\n              key_type,\n              stash,\n              passphrase,\n              backend):\n    \"\"\"List all keys in the stash\n\n    If `KEY_NAME` is provided, will look for keys containing `KEY_NAME`.\n    If `KEY_NAME` starts with `~`, close matches will be provided according\n    to `max_suggestions` and `cutoff`.\n    \"\"\"\n    stash = _get_stash(backend, stash, passphrase, quiet=jsonify)\n\n    try:\n        keys = stash.list(\n            key_name=key_name,\n            max_suggestions=max_suggestions,\n            cutoff=cutoff,\n            locked_only=locked,\n            key_type=key_type)\n    except GhostError as ex:\n        sys.exit(ex)\n    if jsonify:\n        click.echo(json.dumps(keys, indent=4, sort_keys=True))\n    elif not keys:\n        click.echo('The stash is empty. Go on, put some keys in there...')\n    else:\n        click.echo('Listing all keys...')\n        click.echo(_prettify_list(keys))", "response": "List all keys in the stash."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef purge_stash(force, stash, passphrase, backend):\n    stash = _get_stash(backend, stash, passphrase)\n\n    try:\n        click.echo('Purging stash...')\n        stash.purge(force)\n        # Maybe we should verify that the list is empty\n        # afterwards?\n        click.echo('Purge complete!')\n    except GhostError as ex:\n        sys.exit(ex)", "response": "Purge the stash from all of its keys\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexport all keys to a file", "response": "def export_keys(output_path, stash, passphrase, backend):\n    \"\"\"Export all keys to a file\n    \"\"\"\n    stash = _get_stash(backend, stash, passphrase)\n\n    try:\n        click.echo('Exporting stash to {0}...'.format(output_path))\n        stash.export(output_path=output_path)\n        click.echo('Export complete!')\n    except GhostError as ex:\n        sys.exit(ex)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_keys(key_file, origin_passphrase, stash, passphrase, backend):\n    stash = _get_stash(backend, stash, passphrase)\n\n    click.echo('Importing all keys from {0}...'.format(key_file))\n    stash.load(origin_passphrase, key_file=key_file)\n    click.echo('Import complete!')", "response": "Load all keys from an exported key file to the stash\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmigrate all keys from one stash to another.", "response": "def migrate_stash(source_stash_path,\n                  source_passphrase,\n                  source_backend,\n                  destination_stash_path,\n                  destination_passphrase,\n                  destination_backend):\n    \"\"\"Migrate all keys from a source stash to a destination stash.\n\n    `SOURCE_STASH_PATH` and `DESTINATION_STASH_PATH` are the paths\n    to the stashs you wish to perform the migration on.\n    \"\"\"\n    click.echo('Migrating all keys from {0} to {1}...'.format(\n        source_stash_path, destination_stash_path))\n\n    try:\n        migrate(\n            src_path=source_stash_path,\n            src_passphrase=source_passphrase,\n            src_backend=source_backend,\n            dst_path=destination_stash_path,\n            dst_passphrase=destination_passphrase,\n            dst_backend=destination_backend)\n    except GhostError as ex:\n        sys.exit(ex)\n    click.echo('Migration complete!')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ssh(key_name, no_tunnel, stash, passphrase, backend):\n    # TODO: find_executable or raise\n    def execute(command):\n        try:\n            click.echo('Executing: {0}'.format(' '.join(command)))\n            subprocess.check_call(' '.join(command), shell=True)\n        except subprocess.CalledProcessError:\n            sys.exit(1)\n\n    stash = _get_stash(backend, stash, passphrase)\n    key = stash.get(key_name)\n\n    if key:\n        _assert_is_ssh_type_key(key)\n    else:\n        sys.exit('Key `{0}` not found'.format(key_name))\n\n    conn_info = key['value']\n    ssh_key_path = conn_info.get('ssh_key_path')\n    ssh_key = conn_info.get('ssh_key')\n    proxy_key_path = conn_info.get('proxy_key_path')\n    proxy_key = conn_info.get('proxy_key')\n\n    id_file = _write_tmp(ssh_key) if ssh_key else ssh_key_path\n    conn_info['ssh_key_path'] = id_file\n\n    if conn_info.get('proxy'):\n        proxy_id_file = _write_tmp(proxy_key) if proxy_key else proxy_key_path\n        conn_info['proxy_key_path'] = proxy_id_file\n\n    ssh_command = _build_ssh_command(conn_info, no_tunnel)\n    try:\n        execute(ssh_command)\n    finally:\n        # If they're not equal, that means we've created a temp one which\n        # should be deleted, else, it's a path to an existing key file.\n        if id_file != ssh_key_path:\n            click.echo('Removing temp ssh key file: {0}...'.format(id_file))\n            os.remove(id_file)\n        if conn_info.get('proxy') and proxy_id_file != proxy_key_path:\n            click.echo('Removing temp proxy key file: {0}...'.format(\n                proxy_id_file))\n            os.remove(proxy_id_file)", "response": "Use an ssh type key to connect to a machine via ssh."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding the SSH command to connect to the server.", "response": "def _build_ssh_command(conn_info, no_tunnel=False):\n    \"\"\"\n    # TODO: Document clearly\n    IndetityFile=\"~/.ssh/id_rsa\"\n    ProxyCommand=\"ssh -i ~/.ssh/id_rsa proxy_IP nc HOST_IP HOST_PORT\"\n    \"\"\"\n    command = ['ssh', '-i', conn_info['ssh_key_path'], conn_info['conn']]\n\n    if conn_info.get('tunnel') and not no_tunnel:\n        command.insert(1, conn_info.get('tunnel'))\n        # Tunnel\n        command.insert(1, '-L')\n        # No shell\n        command.insert(1, '-N')\n    if conn_info.get('proxy'):\n        command.extend(_build_proxy_command(conn_info))\n    if conn_info.get('extend'):\n        command.append(conn_info.get('extend'))\n    return command"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef put(self,\n            name,\n            value=None,\n            modify=False,\n            metadata=None,\n            description='',\n            encrypt=True,\n            lock=False,\n            key_type='secret',\n            add=False):\n        \"\"\"Put a key inside the stash\n\n        if key exists and modify true: delete and create\n        if key exists and modify false: fail\n        if key doesn't exist and modify true: fail\n        if key doesn't exist and modify false: create\n\n        `name` is unique and cannot be changed.\n\n        `value` must be provided if the key didn't already exist, otherwise,\n        the previous value will be retained.\n\n        `created_at` will be left unmodified if the key\n        already existed. Otherwise, the current time will be used.\n\n        `modified_at` will be changed to the current time\n        if the field is being modified.\n\n        `metadata` will be updated if provided. If it wasn't\n        provided the field from the existing key will be used and the\n        same goes for the `uid` which will be generated if it didn't\n        previously exist.\n\n        `lock` will lock the key to prevent it from being modified or deleted\n\n        `add` allows to add values to an existing key instead of overwriting.\n\n        Returns the id of the key in the database\n        \"\"\"\n        def assert_key_is_unlocked(existing_key):\n            if existing_key and existing_key.get('lock'):\n                raise GhostError(\n                    'Key `{0}` is locked and therefore cannot be modified. '\n                    'Unlock the key and try again'.format(name))\n\n        def assert_value_provided_for_new_key(value, existing_key):\n            if not value and not existing_key.get('value'):\n                raise GhostError('You must provide a value for new keys')\n\n        self._assert_valid_stash()\n        self._validate_key_schema(value, key_type)\n        if value and encrypt and not isinstance(value, dict):\n            raise GhostError('Value must be of type dict')\n\n        # TODO: This should be refactored. `_handle_existing_key` deletes\n        # the key rather implicitly. It shouldn't do that.\n        # `existing_key` will be an empty dict if it doesn't exist\n        key = self._handle_existing_key(name, modify or add)\n        assert_key_is_unlocked(key)\n        assert_value_provided_for_new_key(value, key)\n\n        new_key = dict(name=name, lock=lock)\n        if value:\n            # TODO: fix edge case in which encrypt is false and yet we might\n            # try to add to an existing key. encrypt=false is only used when\n            # `load`ing into a new stash, but someone might use it directly\n            # from the API.\n            if add:\n                value = self._update_existing_key(key, value)\n            new_key['value'] = self._encrypt(value) if encrypt else value\n        else:\n            new_key['value'] = key.get('value')\n\n        # TODO: Treat a case in which we try to update an existing key\n        # but don't provide a value in which nothing will happen.\n        new_key['description'] = description or key.get('description')\n        new_key['created_at'] = key.get('created_at') or _get_current_time()\n        new_key['modified_at'] = _get_current_time()\n        new_key['metadata'] = metadata or key.get('metadata')\n        new_key['uid'] = key.get('uid') or str(uuid.uuid4())\n        new_key['type'] = key.get('type') or key_type\n\n        key_id = self._storage.put(new_key)\n\n        audit(\n            storage=self._storage.db_path,\n            action='MODIFY' if (modify or add) else 'PUT',\n            message=json.dumps(dict(\n                key_name=new_key['name'],\n                value='HIDDEN',\n                description=new_key['description'],\n                uid=new_key['uid'],\n                metadata=json.dumps(new_key['metadata']),\n                lock=new_key['lock'],\n                type=new_key['type'])))\n\n        return key_id", "response": "Put a key in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, key_name, decrypt=True):\n        self._assert_valid_stash()\n\n        key = self._storage.get(key_name).copy()\n        if not key.get('value'):\n            return None\n        if decrypt:\n            key['value'] = self._decrypt(key['value'])\n\n        audit(\n            storage=self._storage.db_path,\n            action='GET',\n            message=json.dumps(dict(key_name=key_name)))\n\n        return key", "response": "Return a key with its parameters if it was found."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of all keys.", "response": "def list(self,\n             key_name=None,\n             max_suggestions=100,\n             cutoff=0.5,\n             locked_only=False,\n             key_type=None):\n        \"\"\"Return a list of all keys.\n        \"\"\"\n        self._assert_valid_stash()\n\n        key_list = [k for k in self._storage.list()\n                    if k['name'] != 'stored_passphrase' and\n                    (k.get('lock') if locked_only else True)]\n\n        if key_type:\n            # To maintain backward compatibility with keys without a type.\n            # The default key type is secret, in which case we also look for\n            # keys with no (None) types.\n            types = ('secret', None) if key_type == 'secret' else [key_type]\n            key_list = [k for k in key_list if k.get('type') in types]\n\n        key_list = [k['name'] for k in key_list]\n        if key_name:\n            if key_name.startswith('~'):\n                key_list = difflib.get_close_matches(\n                    key_name.lstrip('~'), key_list, max_suggestions, cutoff)\n            else:\n                key_list = [k for k in key_list if key_name in k]\n\n        audit(\n            storage=self._storage.db_path,\n            action='LIST' + ('[LOCKED]' if locked_only else ''),\n            message=json.dumps(dict()))\n\n        return key_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a key from the storage.", "response": "def delete(self, key_name):\n        \"\"\"Delete a key if it exists.\n        \"\"\"\n        self._assert_valid_stash()\n\n        if key_name == 'stored_passphrase':\n            raise GhostError(\n                '`stored_passphrase` is a reserved ghost key name '\n                'which cannot be deleted')\n\n        # TODO: Optimize. We get from the storage twice here for no reason\n        if not self.get(key_name):\n            raise GhostError('Key `{0}` not found'.format(key_name))\n        key = self._storage.get(key_name)\n        if key.get('lock'):\n            raise GhostError(\n                'Key `{0}` is locked and therefore cannot be deleted '\n                'Please unlock the key and try again'.format(key_name))\n\n        deleted = self._storage.delete(key_name)\n\n        audit(\n            storage=self._storage.db_path,\n            action='DELETE',\n            message=json.dumps(dict(key_name=key_name)))\n\n        if not deleted:\n            raise GhostError('Failed to delete {0}'.format(key_name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npurges the stash from all keys", "response": "def purge(self, force=False, key_type=None):\n        \"\"\"Purge the stash from all keys\n        \"\"\"\n        self._assert_valid_stash()\n\n        if not force:\n            raise GhostError(\n                \"The `force` flag must be provided to perform a stash purge. \"\n                \"I mean, you don't really want to just delete everything \"\n                \"without precautionary measures eh?\")\n\n        audit(\n            storage=self._storage.db_path,\n            action='PURGE',\n            message=json.dumps(dict()))\n\n        for key_name in self.list(key_type=key_type):\n            self.delete(key_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef export(self, output_path=None, decrypt=False):\n        self._assert_valid_stash()\n\n        all_keys = []\n        for key in self.list():\n            # We `dict` this as a precaution as tinydb returns\n            # a tinydb.database.Element instead of a dictionary\n            # and well.. I ain't taking no chances\n            all_keys.append(dict(self.get(key, decrypt=decrypt)))\n        if all_keys:\n            if output_path:\n                with open(output_path, 'w') as output_file:\n                    output_file.write(json.dumps(all_keys, indent=4))\n            return all_keys\n        else:\n            raise GhostError('There are no keys to export')", "response": "Export all keys in the stash to a list or a file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(self, origin_passphrase, keys=None, key_file=None):\n        # TODO: Handle keys not dict or key_file not json\n        self._assert_valid_stash()\n\n        # Check if both or none are provided (ahh, the mighty xor)\n        if not (bool(keys) ^ bool(key_file)):\n            raise GhostError(\n                'You must either provide a path to an exported stash file '\n                'or a list of key dicts to import')\n        if key_file:\n            with open(key_file) as stash_file:\n                keys = json.loads(stash_file.read())\n\n        # If the passphrases are the same, there's no reason to decrypt\n        # and re-encrypt. We can simply pass the value.\n        decrypt = origin_passphrase != self.passphrase\n        if decrypt:\n            # TODO: The fact that we need to create a stub stash just to\n            # decrypt means we should probably have some encryptor class.\n            stub = Stash(TinyDBStorage('stub'), origin_passphrase)\n        # TODO: Handle existing keys when loading\n        for key in keys:\n            self.put(\n                name=key['name'],\n                value=stub._decrypt(key['value']) if decrypt else key['value'],\n                metadata=key['metadata'],\n                description=key['description'],\n                lock=key.get('lock'),\n                key_type=key.get('type'),\n                encrypt=decrypt)", "response": "Load the keys from a file or a list of keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nturns a json serializable value into an encrypted hexa string.", "response": "def _encrypt(self, value):\n        \"\"\"Turn a json serializable value into an jsonified, encrypted,\n        hexa string.\n        \"\"\"\n        value = json.dumps(value)\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            encrypted_value = self.cipher.encrypt(value.encode('utf8'))\n        hexified_value = binascii.hexlify(encrypted_value).decode('ascii')\n        return hexified_value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary consisting of the key itself", "response": "def get(self, key_name):\n        \"\"\"Return a dictionary consisting of the key itself\n\n        e.g.\n        {u'created_at': u'2016-10-10 08:31:53',\n         u'description': None,\n         u'metadata': None,\n         u'modified_at': u'2016-10-10 08:31:53',\n         u'name': u'aws',\n         u'uid': u'459f12c0-f341-413e-9d7e-7410f912fb74',\n         u'value': u'the_value'}\n\n        \"\"\"\n        result = self.db.search(Query().name == key_name)\n        if not result:\n            return {}\n        return result[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(self, key_name):\n        self.db.remove(Query().name == key_name)\n        return self.get(key_name) == {}", "response": "Delete the key and return true if the key was deleted otherwise false"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _construct_key(self, values):\n        key = {}\n        for column, value in zip(self.keys.columns, values):\n            key.update({column.name: value})\n        return key", "response": "Construct a key from a list of columns\n        and a tuple of values\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef put(self, key):\n        self._consul_request('PUT', self._key_url(key['name']), json=key)\n        return key['name']", "response": "Put and return the only unique identifier possible"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef put(self, key):\n        self.client.write(self._key_path(key['name']), **key)\n        return self._key_path(key['name'])", "response": "Put and return the only unique identifier possible"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an Elasticsearch index if necessary", "response": "def init(self):\n        \"\"\"Create an Elasticsearch index if necessary\n        \"\"\"\n        # ignore 400 (IndexAlreadyExistsException) when creating an index\n        self.es.indices.create(index=self.params['index'], ignore=400)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init(self):\n        try:\n            self.client.create_bucket(\n                Bucket=self.db_path,\n                CreateBucketConfiguration=self.bucket_configuration)\n        except botocore.exceptions.ClientError as e:\n            # If the bucket already exists\n            if 'BucketAlreadyOwnedByYou' not in str(\n                    e.response['Error']['Code']):\n                raise e", "response": "Create a new bucket."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninserting the key into the database.", "response": "def put(self, key):\n        \"\"\"Insert the key\n        :return: Key name\n        \"\"\"\n        self.client.put_object(\n            Body=json.dumps(key),\n            Bucket=self.db_path,\n            Key=key['name'])\n        return key['name']"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list(self):\n        response = self.client.list_objects_v2(Bucket=self.db_path)\n        if u'Contents' in response:\n            # Filter out everything but the key names\n            keys = [key[u'Key'] for key in response[u'Contents']]\n            keys_list = []\n\n            for key_name in keys:\n                key = self.get(key_name)\n                keys_list.append(key)\n\n            return keys_list\n        return []", "response": "Lists the keys\n        :return: Returns a list of all keys (not just key names, but rather\n        the keys themselves)."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the key itself in a dictionary.", "response": "def get(self, key_name):\n        \"\"\"Gets the key.\n        :return: The key itself in a dictionary\n        \"\"\"\n        try:\n            obj = self.client.get_object(\n                Bucket=self.db_path,\n                Key=key_name)['Body'].read().decode(\"utf-8\")\n\n            return json.loads(obj)\n        except botocore.exceptions.ClientError as e:\n            if 'NoSuchKey' in str(e.response['Error']['Code']):\n                return {}\n            raise e"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes the object with the given key name.", "response": "def delete(self, key_name):\n        \"\"\"Delete the key.\n        :return: True if it was deleted, False otherwise\n        \"\"\"\n        self.client.delete_object(\n            Bucket=self.db_path,\n            Key=key_name)\n\n        return self.get(key_name) == {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_initialized(self):\n        try:\n            return self.client.head_bucket(\n                Bucket=self.db_path)['ResponseMetadata']['HTTPStatusCode'] \\\n                   == 200\n        except botocore.exceptions.ClientError as e:\n            # If a client error is thrown, then check that it was a 404 error.\n            # If it was a 404 error, then the bucket does not exist.\n            if 'NoSuchBucket' in str(e.response['Error']['Code']):\n                return False\n            raise e", "response": "Check if the resource in the database is initialized."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef terminal(port=default_port(), baud='9600'):\n    testargs = ['nodemcu-uploader', port, baud]\n    # TODO: modifying argv is no good\n    sys.argv = testargs\n    # resuse miniterm on main function\n    miniterm.main()", "response": "Launch minterm from pyserial"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __set_baudrate(self, baud):\n        log.info('Changing communication to %s baud', baud)\n        self.__writeln(UART_SETUP.format(baud=baud))\n        # Wait for the string to be sent before switching baud\n        time.sleep(0.1)\n        try:\n            self._port.setBaudrate(baud)\n        except AttributeError:\n            #pySerial 2.7\n            self._port.baudrate = baud", "response": "set baudrate of the serial port"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_timeout(self, timeout):\n        timeout = int(timeout) # will raise on Error\n        self._timeout = timeout == 0 and 999999 or timeout", "response": "Set the timeout for the communication with the device."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __clear_buffers(self):\n        try:\n            self._port.reset_input_buffer()\n            self._port.reset_output_buffer()\n        except AttributeError:\n            #pySerial 2.7\n            self._port.flushInput()\n            self._port.flushOutput()", "response": "Clears the input and output buffers"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __expect(self, exp='> ', timeout=None):\n        timeout_before = self._port.timeout\n        timeout = timeout or self._timeout\n        #do NOT set timeout on Windows\n        if SYSTEM != 'Windows':\n            # Checking for new data every 100us is fast enough\n            if self._port.timeout != MINIMAL_TIMEOUT:\n                self._port.timeout = MINIMAL_TIMEOUT\n\n        end = time.time() + timeout\n\n        # Finish as soon as either exp matches or we run out of time (work like dump, but faster on success)\n        data = ''\n        while not data.endswith(exp) and time.time() <= end:\n            data += self._port.read()\n\n        log.debug('expect returned: `{0}`'.format(data))\n        if time.time() > end:\n            raise CommunicationTimeout('Timeout waiting for data', data)\n\n        if not data.endswith(exp) and len(exp) > 0:\n            raise BadResponseException('Bad response.', exp, data)\n\n        if SYSTEM != 'Windows':\n            self._port.timeout = timeout_before\n\n        return data", "response": "expect a response from nodemcu or timeout"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __write(self, output, binary=False):\n        if not binary:\n            log.debug('write: %s', output)\n        else:\n            log.debug('write binary: %s', hexify(output))\n        self._port.write(output)\n        self._port.flush()", "response": "write data on the nodemcu port."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __exchange(self, output, timeout=None):\n        self.__writeln(output)\n        self._port.flush()\n        return self.__expect(timeout=timeout or self._timeout)", "response": "Write output to the port and wait for response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef close(self):\n        try:\n            if self.baud != self.start_baud:\n                self.__set_baudrate(self.start_baud)\n            self._port.flush()\n            self.__clear_buffers()\n        except serial.serialutil.SerialException:\n            pass\n        log.debug('closing port')\n        self._port.close()", "response": "restores the nodemcu baudrate and then closes the port"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prepare(self):\n        log.info('Preparing esp for transfer.')\n\n        for func in LUA_FUNCTIONS:\n            detected = self.__exchange('print({0})'.format(func))\n            if detected.find('function:') == -1:\n                break\n        else:\n            log.info('Preparation already done. Not adding functions again.')\n            return True\n        functions = RECV_LUA + '\\n' + SEND_LUA\n        data = functions.format(baud=self._port.baudrate)\n        ##change any \\r\\n to just \\n and split on that\n        lines = data.replace('\\r', '').split('\\n')\n\n        #remove some unneccesary spaces to conserve some bytes\n        for line in lines:\n            line = line.strip().replace(', ', ',').replace(' = ', '=')\n\n            if len(line) == 0:\n                continue\n\n            resp = self.__exchange(line)\n            #do some basic test of the result\n            if ('unexpected' in resp) or ('stdin' in resp) or len(resp) > len(functions)+10:\n                log.error('error when preparing \"%s\"', resp)\n                return False\n        return True", "response": "This method uploads the protocol functions nessecary to do binary transfer and returns True if successful False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef download_file(self, filename):\n        res = self.__exchange('send(\"{filename}\")'.format(filename=filename))\n        if ('unexpected' in res) or ('stdin' in res):\n            log.error('Unexpected error downloading file: %s', res)\n            raise Exception('Unexpected error downloading file')\n\n        #tell device we are ready to receive\n        self.__write('C')\n        #we should get a NUL terminated filename to start with\n        sent_filename = self.__expect(NUL).strip()\n        log.info('receiveing ' + sent_filename)\n\n        #ACK to start download\n        self.__write(ACK, True)\n        buf = ''\n\n        data = ''\n        chunk, buf = self.__read_chunk(buf)\n        #read chunks until we get an empty which is the end\n        while chunk != '':\n            self.__write(ACK, True)\n            data = data + chunk\n            chunk, buf = self.__read_chunk(buf)\n        return data", "response": "Download a file from device to local filesystem"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_file(self, filename, destination=''):\n        if not destination:\n            destination = filename\n        log.info('Transferring %s to %s', filename, destination)\n        data = self.download_file(filename)\n\n        # Just in case, the filename may contain folder, so create it if needed.\n        log.info(destination)\n        if not os.path.exists(os.path.dirname(destination)):\n            try:\n                os.makedirs(os.path.dirname(destination))\n            except OSError as e:  # Guard against race condition\n                if e.errno != errno.EEXIST:\n                    raise\n        with open(destination, 'w') as fil:\n            fil.write(data)", "response": "read a file from the device into a local file"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a file to the device using the transfer protocol", "response": "def write_file(self, path, destination='', verify='none'):\n        \"\"\"sends a file to the device using the transfer protocol\"\"\"\n        filename = os.path.basename(path)\n        if not destination:\n            destination = filename\n\n        log.info('Transferring %s as %s', path, destination)\n        self.__writeln(\"recv()\")\n\n        res = self.__expect('C> ')\n        if not res.endswith('C> '):\n            log.error('Error waiting for esp \"%s\"', res)\n            raise CommunicationTimeout('Error waiting for device to start receiving', res)\n\n        log.debug('sending destination filename \"%s\"', destination)\n        self.__write(destination + '\\x00', True)\n        if not self.__got_ack():\n            log.error('did not ack destination filename')\n            raise NoAckException('Device did not ACK destination filename')\n\n        content = from_file(path)\n\n        log.debug('sending %d bytes in %s', len(content), filename)\n        pos = 0\n        chunk_size = 128\n        while pos < len(content):\n            rest = len(content) - pos\n            if rest > chunk_size:\n                rest = chunk_size\n\n            data = content[pos:pos+rest]\n            if not self.__write_chunk(data):\n                resp = self.__expect()\n                log.error('Bad chunk response \"%s\" %s', resp, hexify(resp))\n                raise BadResponseException('Bad chunk response', ACK, resp)\n\n            pos += chunk_size\n\n        log.debug('sending zero block')\n        #zero size block\n        self.__write_chunk('')\n        if verify != 'none':\n            self.verify_file(path, destination, verify)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef verify_file(self, path, destination, verify='none'):\n        content = from_file(path)\n        log.info('Verifying using %s...' % verify)\n        if verify == 'raw':\n\n            data = self.download_file(destination)\n            if content != data:\n                log.error('Raw verification failed.')\n                raise VerificationError('Verification failed.')\n            else:\n                log.info('Verification successful. Contents are identical.')\n        elif verify == 'sha1':\n            #Calculate SHA1 on remote file. Extract just hash from result\n            data = self.__exchange('shafile(\"'+destination+'\")').splitlines()[1]\n            log.info('Remote SHA1: %s', data)\n\n            #Calculate hash of local data\n            filehashhex = hashlib.sha1(content.encode(ENCODING)).hexdigest()\n            log.info('Local SHA1: %s', filehashhex)\n            if data != filehashhex:\n                log.error('SHA1 verification failed.')\n                raise VerificationError('SHA1 Verification failed.')\n            else:\n                log.info('Verification successful. Checksums match')\n\n        elif verify != 'none':\n            raise Exception(verify + ' is not a valid verification method.')", "response": "Tries to verify if path has same checksum as destination."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exec_file(self, path):\n        filename = os.path.basename(path)\n        log.info('Execute %s', filename)\n\n        content = from_file(path).replace('\\r', '').split('\\n')\n\n        res = '> '\n        for line in content:\n            line = line.rstrip('\\n')\n            retlines = (res + self.__exchange(line)).splitlines()\n            # Log all but the last line\n            res = retlines.pop()\n            for lin in retlines:\n                log.info(lin)\n        # last line\n        log.info(res)", "response": "execute the lines in the local file path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn true if ACK is received", "response": "def __got_ack(self):\n        \"\"\"Returns true if ACK is received\"\"\"\n        log.debug('waiting for ack')\n        res = self._port.read(1)\n        log.debug('ack read %s', hexify(res))\n        return res == ACK"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting lines one by one separated by \\ n to device", "response": "def write_lines(self, data):\n        \"\"\"write lines, one by one, separated by \\n to device\"\"\"\n        lines = data.replace('\\r', '').split('\\n')\n        for line in lines:\n            self.__exchange(line)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __write_chunk(self, chunk):\n        log.debug('writing %d bytes chunk', len(chunk))\n        data = BLOCK_START + chr(len(chunk)) + chunk\n        if len(chunk) < 128:\n            padding = 128 - len(chunk)\n            log.debug('pad with %d characters', padding)\n            data = data + (' ' * padding)\n        log.debug(\"packet size %d\", len(data))\n        self.__write(data)\n        self._port.flush()\n        return self.__got_ack()", "response": "formats and sends a chunk of data to the device according\n        to transfer protocol"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a chunk of data from the port.", "response": "def __read_chunk(self, buf):\n        \"\"\"Read a chunk of data\"\"\"\n        log.debug('reading chunk')\n        timeout_before = self._port.timeout\n        if SYSTEM != 'Windows':\n            # Checking for new data every 100us is fast enough\n            if self._port.timeout != MINIMAL_TIMEOUT:\n                self._port.timeout = MINIMAL_TIMEOUT\n\n        end = time.time() + timeout_before\n\n        while len(buf) < 130 and time.time() <= end:\n            buf = buf + self._port.read()\n\n        if buf[0] != BLOCK_START or len(buf) < 130:\n            log.debug('buffer binary: %s ', hexify(buf))\n            raise Exception('Bad blocksize or start byte')\n\n        if SYSTEM != 'Windows':\n            self._port.timeout = timeout_before\n\n        chunk_size = ord(buf[1])\n        data = buf[2:chunk_size+2]\n        buf = buf[130:]\n        return (data, buf)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists files on the device", "response": "def file_list(self):\n        \"\"\"list files on the device\"\"\"\n        log.info('Listing files')\n        res = self.__exchange(LIST_FILES)\n        res = res.split('\\r\\n')\n        # skip first and last lines\n        res = res[1:-1]\n        files = []\n        for line in res:\n            files.append(line.split('\\t'))\n        return files"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef file_do(self, filename):\n        log.info('Executing '+filename)\n        res = self.__exchange('dofile(\"'+filename+'\")')\n        log.info(res)\n        return res", "response": "Execute a file on the device using dofile"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint a file on the device to the console", "response": "def file_print(self, filename):\n        \"\"\"Prints a file on the device to console\"\"\"\n        log.info('Printing ' + filename)\n        res = self.__exchange(PRINT_FILE.format(filename=filename))\n        log.info(res)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef node_heap(self):\n        log.info('Heap')\n        res = self.__exchange('print(node.heap())')\n        log.info(res)\n        return int(res.split('\\r\\n')[1])", "response": "Show device heap size"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompile a file specified by path on the device", "response": "def file_compile(self, path):\n        \"\"\"Compiles a file specified by path on the device\"\"\"\n        log.info('Compile '+path)\n        cmd = 'node.compile(\"%s\")' % path\n        res = self.__exchange(cmd)\n        log.info(res)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef file_remove(self, path):\n        log.info('Remove '+path)\n        cmd = 'file.remove(\"%s\")' % path\n        res = self.__exchange(cmd)\n        log.info(res)\n        return res", "response": "Removes a file on the device"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of sources and destinations from a source file.", "response": "def destination_from_source(sources, use_glob=True):\n    \"\"\"\n    Split each of the sources in the array on ':'\n    First part will be source, second will be destination.\n    Modifies the the original array to contain only sources\n    and returns an array of destinations.\n    \"\"\"\n    destinations = []\n    newsources = []\n    for i in range(0, len(sources)):\n        srcdst = sources[i].split(':')\n        if len(srcdst) == 2:\n            destinations.append(srcdst[1])\n            newsources.append(srcdst[0]) #proper list assignment\n        else:\n            if use_glob:\n                listing = glob.glob(srcdst[0])\n                for filename in listing:\n                    newsources.append(filename)\n                    #always use forward slash at destination\n                    destinations.append(filename.replace('\\\\', '/'))\n            else:\n                newsources.append(srcdst[0])\n                destinations.append(srcdst[0])\n\n    return [newsources, destinations]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting files on target", "response": "def operation_list(uploader):\n    \"\"\"List file on target\"\"\"\n    files = uploader.file_list()\n    for f in files:\n        log.info(\"{file:30s} {size}\".format(file=f[0], size=f[1]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main_func():\n    parser = argparse.ArgumentParser(\n        description='NodeMCU Lua file uploader',\n        prog='nodemcu-uploader'\n        )\n\n    parser.add_argument(\n        '--verbose',\n        help='verbose output',\n        action='store_true',\n        default=False)\n\n    parser.add_argument(\n        '--version',\n        help='prints the version and exists',\n        action='version',\n        version='%(prog)s {version} (serial {serialversion})'.format(version=__version__, serialversion=serialversion)\n    )\n\n    parser.add_argument(\n        '--port', '-p',\n        help='Serial port device',\n        default=Uploader.PORT)\n\n    parser.add_argument(\n        '--baud', '-b',\n        help='Serial port baudrate',\n        type=arg_auto_int,\n        default=Uploader.BAUD)\n\n    parser.add_argument(\n        '--start_baud', '-B',\n        help='Initial Serial port baudrate',\n        type=arg_auto_int,\n        default=Uploader.START_BAUD)\n\n    parser.add_argument(\n        '--timeout', '-t',\n        help='Timeout for operations',\n        type=arg_auto_int,\n        default=Uploader.TIMEOUT)\n\n    parser.add_argument(\n        '--autobaud_time', '-a',\n        help='Duration of the autobaud timer',\n        type=float,\n        default=Uploader.AUTOBAUD_TIME,\n    )\n\n    subparsers = parser.add_subparsers(\n        dest='operation',\n        help='Run nodemcu-uploader {command} -h for additional help')\n\n    backup_parser = subparsers.add_parser(\n        'backup',\n        help='Backup all the files on the nodemcu board')\n    backup_parser.add_argument('path', help='Folder where to store the backup')\n\n\n    upload_parser = subparsers.add_parser(\n        'upload',\n        help='Path to one or more files to be uploaded. Destination name will be the same as the file name.')\n\n    upload_parser.add_argument(\n        'filename',\n        nargs='+',\n        help='Lua file to upload. Use colon to give alternate destination.'\n        )\n\n    upload_parser.add_argument(\n        '--compile', '-c',\n        help='If file should be uploaded as compiled',\n        action='store_true',\n        default=False\n        )\n\n    upload_parser.add_argument(\n        '--verify', '-v',\n        help='To verify the uploaded data.',\n        action='store',\n        nargs='?',\n        choices=['none', 'raw', 'sha1'],\n        default='none'\n        )\n\n    upload_parser.add_argument(\n        '--dofile', '-e',\n        help='If file should be run after upload.',\n        action='store_true',\n        default=False\n        )\n\n    upload_parser.add_argument(\n        '--restart', '-r',\n        help='If esp should be restarted',\n        action='store_true',\n        default=False\n    )\n\n    exec_parser = subparsers.add_parser(\n        'exec',\n        help='Path to one or more files to be executed line by line.')\n\n    exec_parser.add_argument('filename', nargs='+', help='Lua file to execute.')\n\n    download_parser = subparsers.add_parser(\n        'download',\n        help='Path to one or more files to be downloaded. Destination name will be the same as the file name.')\n\n    download_parser.add_argument('filename',\n        nargs='+',\n        help='Lua file to download. Use colon to give alternate destination.')\n\n\n    file_parser = subparsers.add_parser(\n        'file',\n        help='File functions')\n\n    file_parser.add_argument(\n        'cmd',\n        choices=('list', 'do', 'format', 'remove', 'print'),\n        help=\"list=list files, do=dofile given path, format=formate file area, remove=remove given path\")\n\n    file_parser.add_argument('filename', nargs='*', help='path for cmd')\n\n    node_parse = subparsers.add_parser(\n        'node',\n        help='Node functions')\n\n    node_parse.add_argument('ncmd', choices=('heap', 'restart'), help=\"heap=print heap memory, restart=restart nodemcu\")\n\n    subparsers.add_parser(\n        'terminal',\n        help='Run pySerials miniterm'\n    )\n\n    args = parser.parse_args()\n\n    default_level = logging.INFO\n    if args.verbose:\n        default_level = logging.DEBUG\n\n    #formatter = logging.Formatter('%(message)s')\n\n    logging.basicConfig(level=default_level, format='%(message)s')\n\n    if args.operation == 'terminal':\n        #uploader can not claim the port\n        terminal(args.port, str(args.start_baud))\n        return\n\n    # let uploader user the default (short) timeout for establishing connection\n    uploader = Uploader(args.port, args.baud, start_baud=args.start_baud, autobaud_time=args.autobaud_time)\n\n    # and reset the timeout (if we have the uploader&timeout)\n    if args.timeout:\n        uploader.set_timeout(args.timeout)\n\n    if args.operation == 'upload':\n        operation_upload(uploader, args.filename, args.verify, args.compile, args.dofile,\n                         args.restart)\n\n    elif args.operation == 'download':\n        operation_download(uploader, args.filename)\n\n    elif args.operation == 'exec':\n        sources = args.filename\n        for path in sources:\n            uploader.exec_file(path)\n\n    elif args.operation == 'file':\n        operation_file(uploader, args.cmd, args.filename)\n\n    elif args.operation == 'node':\n        if args.ncmd == 'heap':\n            uploader.node_heap()\n        elif args.ncmd == 'restart':\n            uploader.node_restart()\n\n    elif args.operation == 'backup':\n        uploader.backup(args.path)\n\n    #no uploader related commands after this point\n    uploader.close()", "response": "Main function for CLI"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndisplay a GenePattern Python Library content in a notebook without the need to import IPython at the top level.", "response": "def display(content):\n    \"\"\"\n    Display a widget, text or other media in a notebook without the need to import IPython at the top level.\n\n    Also handles wrapping GenePattern Python Library content in widgets.\n    :param content:\n    :return:\n    \"\"\"\n    if isinstance(content, gp.GPServer):\n        IPython.display.display(GPAuthWidget(content))\n    elif isinstance(content, gp.GPTask):\n        IPython.display.display(GPTaskWidget(content))\n    elif isinstance(content, gp.GPJob):\n        IPython.display.display(GPJobWidget(content))\n    else:\n        IPython.display.display(content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register(self, server, username, password):\n\n        # Create the session\n        session = gp.GPServer(server, username, password)\n\n        # Validate username if not empty\n        valid_username = username != \"\" and username is not None\n\n        # Validate that the server is not already registered\n        index = self._get_index(server)\n        new_server = index == -1\n\n        # Add the new session to the list\n        if valid_username and new_server:\n            self.sessions.append(session)\n\n        # Replace old session is one exists\n        if valid_username and not new_server:\n            self.sessions[index] = session\n\n        return session", "response": "Register a new GenePattern server session for the provided username and password. Return the newly created session."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, server):\n\n        # Handle indexes\n        if isinstance(server, int):\n            if server >= len(self.sessions):\n                return None\n            else:\n                return self.sessions[server]\n\n        # Handle server URLs\n        index = self._get_index(server)\n        if index == -1:\n            return None\n        else:\n            return self.sessions[index]", "response": "Returns a registered GPServer object with a matching GenePattern server url or index\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_index(self, server_url):\n        for i in range(len(self.sessions)):\n            session = self.sessions[i]\n            if session.url == server_url:\n                return i\n        return -1", "response": "Returns a registered GPServer object with a matching GenePattern server url"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\naccepting None or \u221e or datetime or numeric for target", "response": "def _accept(self, target):\n\t\t\"Accept None or \u221e or datetime or numeric for target\"\n\t\tif isinstance(target, datetime.timedelta):\n\t\t\ttarget = target.total_seconds()\n\n\t\tif target is None:\n\t\t\t# treat None as infinite target\n\t\t\ttarget = float('Inf')\n\n\t\treturn target"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a numeric timestamp to a timezone - aware datetime.", "response": "def from_timestamp(ts):\n    \"\"\"\n    Convert a numeric timestamp to a timezone-aware datetime.\n\n    A client may override this function to change the default behavior,\n    such as to use local time or timezone-na\u00efve times.\n    \"\"\"\n    return datetime.datetime.utcfromtimestamp(ts).replace(tzinfo=pytz.utc)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstruct a DelayedCommand to come due at time.", "response": "def at_time(cls, at, target):\n        \"\"\"\n        Construct a DelayedCommand to come due at `at`, where `at` may be\n        a datetime or timestamp.\n        \"\"\"\n        at = cls._from_timestamp(at)\n        cmd = cls.from_datetime(at)\n        cmd.delay = at - now()\n        cmd.target = target\n        return cmd"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrely on pytz. localize to ensure new result honors DST.", "response": "def _localize(dt):\n        \"\"\"\n        Rely on pytz.localize to ensure new result honors DST.\n        \"\"\"\n        try:\n            tz = dt.tzinfo\n            return tz.localize(dt.replace(tzinfo=None))\n        except AttributeError:\n            return dt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nschedule a command to run at a specific time each day.", "response": "def daily_at(cls, at, target):\n        \"\"\"\n        Schedule a command to run at a specific time each day.\n        \"\"\"\n        daily = datetime.timedelta(days=1)\n        # convert when to the next datetime matching this time\n        when = datetime.datetime.combine(datetime.date.today(), at)\n        if when < now():\n            when += daily\n        return cls.at_time(cls._localize(when), daily, target)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef strptime(s, fmt, tzinfo=None):\n\tres = time.strptime(s, fmt)\n\treturn datetime.datetime(tzinfo=tzinfo, *res[:6])", "response": "A function to replace strptime in the time module."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef datetime_mod(dt, period, start=None):\n\tif start is None:\n\t\t# use midnight of the same day\n\t\tstart = datetime.datetime.combine(dt.date(), datetime.time())\n\t# calculate the difference between the specified time and the start date.\n\tdelta = dt - start\n\n\t# now aggregate the delta and the period into microseconds\n\t# Use microseconds because that's the highest precision of these time\n\t# pieces.  Also, using microseconds ensures perfect precision (no floating\n\t# point errors).\n\tdef get_time_delta_microseconds(td):\n\t\treturn (td.days * seconds_per_day + td.seconds) * 1000000 + td.microseconds\n\tdelta, period = map(get_time_delta_microseconds, (delta, period))\n\toffset = datetime.timedelta(microseconds=delta % period)\n\t# the result is the original specified time minus the offset\n\tresult = dt - offset\n\treturn result", "response": "This function calculates the time which is the specified date or time truncated to the time delta_per_day + period."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef datetime_round(dt, period, start=None):\n\tresult = datetime_mod(dt, period, start)\n\tif abs(dt - result) >= period // 2:\n\t\tresult += period\n\treturn result", "response": "This function will return the datetime that is within the specified period."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the nearest year to now inferred from a Julian date.", "response": "def get_nearest_year_for_day(day):\n\t\"\"\"\n\tReturns the nearest year to now inferred from a Julian date.\n\t\"\"\"\n\tnow = time.gmtime()\n\tresult = now.tm_year\n\t# if the day is far greater than today, it must be from last year\n\tif day - now.tm_yday > 365 // 2:\n\t\tresult -= 1\n\t# if the day is far less than today, it must be for next year.\n\tif now.tm_yday - day > 365 // 2:\n\t\tresult += 1\n\treturn result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_period_seconds(period):\n\tif isinstance(period, six.string_types):\n\t\ttry:\n\t\t\tname = 'seconds_per_' + period.lower()\n\t\t\tresult = globals()[name]\n\t\texcept KeyError:\n\t\t\tmsg = \"period not in (second, minute, hour, day, month, year)\"\n\t\t\traise ValueError(msg)\n\telif isinstance(period, numbers.Number):\n\t\tresult = period\n\telif isinstance(period, datetime.timedelta):\n\t\tresult = period.days * get_period_seconds('day') + period.seconds\n\telse:\n\t\traise TypeError('period must be a string or integer')\n\treturn result", "response": "get_period_seconds - Get the number of seconds in the specified period"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the format string that can be used for a given time period.", "response": "def get_date_format_string(period):\n\t\"\"\"\n\tFor a given period (e.g. 'month', 'day', or some numeric interval\n\tsuch as 3600 (in secs)), return the format string that can be\n\tused with strftime to format that time to specify the times\n\tacross that interval, but no more detailed.\n\tFor example,\n\n\t>>> get_date_format_string('month')\n\t'%Y-%m'\n\t>>> get_date_format_string(3600)\n\t'%Y-%m-%d %H'\n\t>>> get_date_format_string('hour')\n\t'%Y-%m-%d %H'\n\t>>> get_date_format_string(None)\n\tTraceback (most recent call last):\n\t\t...\n\tTypeError: period must be a string or integer\n\t>>> get_date_format_string('garbage')\n\tTraceback (most recent call last):\n\t\t...\n\tValueError: period not in (second, minute, hour, day, month, year)\n\t\"\"\"\n\t# handle the special case of 'month' which doesn't have\n\t#  a static interval in seconds\n\tif isinstance(period, six.string_types) and period.lower() == 'month':\n\t\treturn '%Y-%m'\n\tfile_period_secs = get_period_seconds(period)\n\tformat_pieces = ('%Y', '-%m-%d', ' %H', '-%M', '-%S')\n\tseconds_per_second = 1\n\tintervals = (\n\t\tseconds_per_year,\n\t\tseconds_per_day,\n\t\tseconds_per_hour,\n\t\tseconds_per_minute,\n\t\tseconds_per_second,\n\t)\n\tmods = list(map(lambda interval: file_period_secs % interval, intervals))\n\tformat_pieces = format_pieces[: mods.index(0) + 1]\n\treturn ''.join(format_pieces)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndividing a timedelta by a float value", "response": "def divide_timedelta_float(td, divisor):\n\t\"\"\"\n\tDivide a timedelta by a float value\n\n\t>>> one_day = datetime.timedelta(days=1)\n\t>>> half_day = datetime.timedelta(days=.5)\n\t>>> divide_timedelta_float(one_day, 2.0) == half_day\n\tTrue\n\t>>> divide_timedelta_float(one_day, 2) == half_day\n\tTrue\n\t\"\"\"\n\t# td is comprised of days, seconds, microseconds\n\tdsm = [getattr(td, attr) for attr in ('days', 'seconds', 'microseconds')]\n\tdsm = map(lambda elem: elem / divisor, dsm)\n\treturn datetime.timedelta(*dsm)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a string representing a span of time and return a datetime. timedelta object.", "response": "def parse_timedelta(str):\n\t\"\"\"\n\tTake a string representing a span of time and parse it to a time delta.\n\tAccepts any string of comma-separated numbers each with a unit indicator.\n\n\t>>> parse_timedelta('1 day')\n\tdatetime.timedelta(days=1)\n\n\t>>> parse_timedelta('1 day, 30 seconds')\n\tdatetime.timedelta(days=1, seconds=30)\n\n\t>>> parse_timedelta('47.32 days, 20 minutes, 15.4 milliseconds')\n\tdatetime.timedelta(days=47, seconds=28848, microseconds=15400)\n\n\tSupports weeks, months, years\n\n\t>>> parse_timedelta('1 week')\n\tdatetime.timedelta(days=7)\n\n\t>>> parse_timedelta('1 year, 1 month')\n\tdatetime.timedelta(days=395, seconds=58685)\n\n\tNote that months and years strict intervals, not aligned\n\tto a calendar:\n\n\t>>> now = datetime.datetime.now()\n\t>>> later = now + parse_timedelta('1 year')\n\t>>> diff = later.replace(year=now.year) - now\n\t>>> diff.seconds\n\t20940\n\t\"\"\"\n\tdeltas = (_parse_timedelta_part(part.strip()) for part in str.split(','))\n\treturn sum(deltas, datetime.timedelta())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef divide_timedelta(td1, td2):\n\ttry:\n\t\treturn td1 / td2\n\texcept TypeError:\n\t\t# Python 3.2 gets division\n\t\t# http://bugs.python.org/issue2706\n\t\treturn td1.total_seconds() / td2.total_seconds()", "response": "Divide two timedelta objects into a single value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef date_range(start=None, stop=None, step=None):\n\tif step is None:\n\t\tstep = datetime.timedelta(days=1)\n\tif start is None:\n\t\tstart = datetime.datetime.now()\n\twhile start < stop:\n\t\tyield start\n\t\tstart += step", "response": "A built - in function range that returns a generator that yields dates from start to stop."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef construct_datetime(cls, *args, **kwargs):\n\t\tif len(args) == 1:\n\t\t\targ = args[0]\n\t\t\tmethod = cls.__get_dt_constructor(\n\t\t\t\ttype(arg).__module__,\n\t\t\t\ttype(arg).__name__,\n\t\t\t)\n\t\t\tresult = method(arg)\n\t\t\ttry:\n\t\t\t\tresult = result.replace(tzinfo=kwargs.pop('tzinfo'))\n\t\t\texcept KeyError:\n\t\t\t\tpass\n\t\t\tif kwargs:\n\t\t\t\tfirst_key = kwargs.keys()[0]\n\t\t\t\ttmpl = (\n\t\t\t\t\t\"{first_key} is an invalid keyword \"\n\t\t\t\t\t\"argument for this function.\"\n\t\t\t\t)\n\t\t\t\traise TypeError(tmpl.format(**locals()))\n\t\telse:\n\t\t\tresult = datetime.datetime(*args, **kwargs)\n\t\treturn result", "response": "Construct a datetime. datetime from a number of different time\n\ttypes found in python and pythonwin"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __common_triplet(input_string, consonants, vowels):\n    output = consonants\n\n    while len(output) < 3:\n        try:\n            output += vowels.pop(0)\n        except IndexError:\n            # If there are less wovels than needed to fill the triplet,\n            # (e.g. for a surname as \"Fo'\" or \"Hu\" or the corean \"Y\")\n            # fill it with 'X';\n            output += 'X'\n\n    return output[:3]", "response": "This function returns the common triplet of the input_string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the list of consonants and vowels from the input_string.", "response": "def __consonants_and_vowels(input_string):\n    \"\"\"__consonants_and_vowels(input_string) -> (string, list)\n\n    Get the consonants as a string and the vowels as a list.\n    \"\"\"\n    input_string = input_string.upper().replace(' ', '')\n\n    consonants = [ char for char in input_string if char in __CONSONANTS ]\n    vowels     = [ char for char in input_string if char in __VOWELS ]\n\n    return \"\".join(consonants), vowels"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the common triplet of the given string.", "response": "def __surname_triplet(input_string):\n    \"\"\"__surname_triplet(input_string) -> string\"\"\"\n    consonants, vowels = __consonants_and_vowels(input_string)\n\n    return __common_triplet(input_string, consonants, vowels)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __name_triplet(input_string):\n    if input_string == '':\n        # highly unlikely: no first name, like for instance some Indian persons\n        # with only one name on the passport\n        # pylint: disable=W0511\n        return 'XXX' \n\n    consonants, vowels = __consonants_and_vowels(input_string)\n    \n    if len(consonants) > 3:\n        return \"%s%s%s\" % (consonants[0], consonants[2], consonants[3])\n\n    return __common_triplet(input_string, consonants, vowels)", "response": "This function returns the name of the current passport based on the input string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef control_code(input_string):\n    assert len(input_string) == 15\n\n    # building conversion tables for even and odd characters positions\n    even_controlcode = {}\n\n    for idx, char in enumerate(string.digits):\n        even_controlcode[char] = idx\n\n    for idx, char in enumerate(string.ascii_uppercase):\n        even_controlcode[char] = idx\n\n    values = [ 1, 0, 5, 7, 9, 13, 15, 17, 19, 21, 2, 4, 18, 20, 11, 3, 6, 8,\n               12, 14, 16, 10, 22, 25, 24, 23 ]\n\n    odd_controlcode = {}\n\n    for idx, char in enumerate(string.digits):\n        odd_controlcode[char] = values[idx]\n\n    for idx, char in enumerate(string.ascii_uppercase):\n        odd_controlcode[char] = values[idx]\n\n    # computing the code\n    code = 0\n    for idx, char in enumerate(input_string):\n        if idx % 2 == 0:\n            code += odd_controlcode[char]\n        else:\n            code += even_controlcode[char]\n    \n    return string.ascii_uppercase[code % 26]", "response": "Computes the control code for the given input_string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build(surname, name, birthday, sex, municipality):\n\n    # RCCMNL\n    output = __surname_triplet(surname) + __name_triplet(name)\n\n    # RCCMNL83\n    output += str(birthday.year)[2:]\n\n    # RCCMNL83S\n    output += MONTHSCODE[birthday.month - 1]\n\n    # RCCMNL83S18\n    output += \"%02d\" % (sex.upper() == 'M' and birthday.day or 40 + birthday.day)\n\n    # RCCMNL83S18D969 \n    output += municipality\n\n    # RCCMNL83S18D969H\n    output += control_code(output)\n\n    assert isvalid(output)\n\n    return output", "response": "Builds the fiscal code for the given person data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_birthday(code):\n    assert isvalid(code)\n\n    day = int(code[9:11])\n    day = day < 32 and day or day - 40\n\n    month = MONTHSCODE.index(code[8]) + 1\n    year = int(code[6:8])\n\n    return \"%02d-%02d-%02d\" % (day, month, year)", "response": "Returns the birthday of the person whose fiscal code is code."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npass in an Overpass query in Overpass QL.", "response": "def get(self, query, responseformat=\"geojson\", verbosity=\"body\", build=True):\n        \"\"\"Pass in an Overpass query in Overpass QL.\"\"\"\n        # Construct full Overpass query\n        if build:\n            full_query = self._construct_ql_query(\n                query, responseformat=responseformat, verbosity=verbosity\n            )\n        else:\n            full_query = query\n\n        if self.debug:\n            logging.getLogger().info(query)\n\n        # Get the response from Overpass\n        r = self._get_from_overpass(full_query)\n        content_type = r.headers.get(\"content-type\")\n\n        if self.debug:\n            print(content_type)\n        if content_type == \"text/csv\":\n            result = []\n            reader = csv.reader(StringIO(r.text), delimiter=\"\\t\")\n            for row in reader:\n                result.append(row)\n            return result\n        elif content_type in (\"text/xml\", \"application/xml\", \"application/osm3s+xml\"):\n            return r.text\n        elif content_type == \"application/json\":\n            response = json.loads(r.text)\n\n        if not build:\n            return response\n\n        # Check for valid answer from Overpass.\n        # A valid answer contains an 'elements' key at the root level.\n        if \"elements\" not in response:\n            raise UnknownOverpassError(\"Received an invalid answer from Overpass.\")\n\n        # If there is a 'remark' key, it spells trouble.\n        overpass_remark = response.get(\"remark\", None)\n        if overpass_remark and overpass_remark.startswith(\"runtime error\"):\n            raise ServerRuntimeError(overpass_remark)\n\n        if responseformat is not \"geojson\":\n            return response\n\n        # construct geojson\n        return self._as_geojson(response[\"elements\"])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(self, text):\n\n        results = list()\n        \n        for oneline in text.split('\\n'):\n            self._tagger.stdin.write(oneline+'\\n')\n            while True:\n                r = self._tagger.stdout.readline()[:-1]\n                if not r:\n                    break\n                results.append(tuple(r.split('\\t')))\n        return results", "response": "Parse the text of a set of items."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_port(context, port):\n    LOG.info(\"create_port for tenant %s\" % context.tenant_id)\n    port_attrs = port[\"port\"]\n\n    admin_only = [\"mac_address\", \"device_owner\", \"bridge\", \"admin_state_up\",\n                  \"use_forbidden_mac_range\", \"network_plugin\",\n                  \"instance_node_id\"]\n    utils.filter_body(context, port_attrs, admin_only=admin_only)\n\n    port_attrs = port[\"port\"]\n    mac_address = utils.pop_param(port_attrs, \"mac_address\", None)\n    use_forbidden_mac_range = utils.pop_param(port_attrs,\n                                              \"use_forbidden_mac_range\", False)\n    segment_id = utils.pop_param(port_attrs, \"segment_id\")\n    fixed_ips = utils.pop_param(port_attrs, \"fixed_ips\")\n\n    if \"device_id\" not in port_attrs:\n        port_attrs['device_id'] = \"\"\n    device_id = port_attrs['device_id']\n\n    # NOTE(morgabra) This should be instance.node from nova, only needed\n    # for ironic_driver.\n    if \"instance_node_id\" not in port_attrs:\n        port_attrs['instance_node_id'] = \"\"\n    instance_node_id = port_attrs['instance_node_id']\n\n    net_id = port_attrs[\"network_id\"]\n\n    port_id = uuidutils.generate_uuid()\n\n    net = db_api.network_find(context=context, limit=None, sorts=['id'],\n                              marker=None, page_reverse=False, fields=None,\n                              id=net_id, scope=db_api.ONE)\n\n    if not net:\n        raise n_exc.NetworkNotFound(net_id=net_id)\n    _raise_if_unauthorized(context, net)\n\n    # NOTE (Perkins): If a device_id is given, try to prevent multiple ports\n    # from being created for a device already attached to the network\n    if device_id:\n        existing_ports = db_api.port_find(context,\n                                          network_id=net_id,\n                                          device_id=device_id,\n                                          scope=db_api.ONE)\n        if existing_ports:\n            raise n_exc.BadRequest(\n                resource=\"port\", msg=\"This device is already connected to the \"\n                \"requested network via another port\")\n\n    # Try to fail early on quotas and save ourselves some db overhead\n    if fixed_ips:\n        quota.QUOTAS.limit_check(context, context.tenant_id,\n                                 fixed_ips_per_port=len(fixed_ips))\n\n    if not STRATEGY.is_provider_network(net_id):\n        # We don't honor segmented networks when they aren't \"shared\"\n        segment_id = None\n        port_count = db_api.port_count_all(context, network_id=[net_id],\n                                           tenant_id=[context.tenant_id])\n        quota.QUOTAS.limit_check(\n            context, context.tenant_id,\n            ports_per_network=port_count + 1)\n    else:\n        if not segment_id:\n            raise q_exc.AmbiguousNetworkId(net_id=net_id)\n\n    network_plugin = utils.pop_param(port_attrs, \"network_plugin\")\n    if not network_plugin:\n        network_plugin = net[\"network_plugin\"]\n    port_attrs[\"network_plugin\"] = network_plugin\n\n    ipam_driver = _get_ipam_driver(net, port=port_attrs)\n    net_driver = _get_net_driver(net, port=port_attrs)\n    # NOTE(morgabra) It's possible that we select a driver different than\n    # the one specified by the network. However, we still might need to use\n    # this for some operations, so we also fetch it and pass it along to\n    # the backend driver we are actually using.\n    base_net_driver = _get_net_driver(net)\n\n    # TODO(anyone): security groups are not currently supported on port create.\n    #               Please see JIRA:NCP-801\n    security_groups = utils.pop_param(port_attrs, \"security_groups\")\n    if security_groups is not None:\n        raise q_exc.SecurityGroupsNotImplemented()\n\n    group_ids, security_groups = _make_security_group_list(context,\n                                                           security_groups)\n    quota.QUOTAS.limit_check(context, context.tenant_id,\n                             security_groups_per_port=len(group_ids))\n    addresses = []\n    backend_port = None\n\n    with utils.CommandManager().execute() as cmd_mgr:\n        @cmd_mgr.do\n        def _allocate_ips(fixed_ips, net, port_id, segment_id, mac,\n                          **kwargs):\n            if fixed_ips:\n                if (STRATEGY.is_provider_network(net_id) and\n                        not context.is_admin):\n                    raise n_exc.NotAuthorized()\n\n                ips, subnets = split_and_validate_requested_subnets(context,\n                                                                    net_id,\n                                                                    segment_id,\n                                                                    fixed_ips)\n                kwargs[\"ip_addresses\"] = ips\n                kwargs[\"subnets\"] = subnets\n\n            ipam_driver.allocate_ip_address(\n                context, addresses, net[\"id\"], port_id,\n                CONF.QUARK.ipam_reuse_after, segment_id=segment_id,\n                mac_address=mac, **kwargs)\n\n        @cmd_mgr.undo\n        def _allocate_ips_undo(addr, **kwargs):\n            LOG.info(\"Rolling back IP addresses...\")\n            if addresses:\n                for address in addresses:\n                    try:\n                        with context.session.begin():\n                            ipam_driver.deallocate_ip_address(context, address,\n                                                              **kwargs)\n                    except Exception:\n                        LOG.exception(\"Couldn't release IP %s\" % address)\n\n        @cmd_mgr.do\n        def _allocate_mac(net, port_id, mac_address,\n                          use_forbidden_mac_range=False,\n                          **kwargs):\n            mac = ipam_driver.allocate_mac_address(\n                context, net[\"id\"], port_id, CONF.QUARK.ipam_reuse_after,\n                mac_address=mac_address,\n                use_forbidden_mac_range=use_forbidden_mac_range, **kwargs)\n            return mac\n\n        @cmd_mgr.undo\n        def _allocate_mac_undo(mac, **kwargs):\n            LOG.info(\"Rolling back MAC address...\")\n            if mac:\n                try:\n                    with context.session.begin():\n                        ipam_driver.deallocate_mac_address(context,\n                                                           mac[\"address\"])\n                except Exception:\n                    LOG.exception(\"Couldn't release MAC %s\" % mac)\n\n        @cmd_mgr.do\n        def _allocate_backend_port(mac, addresses, net, port_id, **kwargs):\n            backend_port = net_driver.create_port(\n                context, net[\"id\"],\n                port_id=port_id,\n                security_groups=group_ids,\n                device_id=device_id,\n                instance_node_id=instance_node_id,\n                mac_address=mac,\n                addresses=addresses,\n                base_net_driver=base_net_driver)\n            _filter_backend_port(backend_port)\n            return backend_port\n\n        @cmd_mgr.undo\n        def _allocate_back_port_undo(backend_port,\n                                     **kwargs):\n            LOG.info(\"Rolling back backend port...\")\n            try:\n                backend_port_uuid = None\n                if backend_port:\n                    backend_port_uuid = backend_port.get(\"uuid\")\n                net_driver.delete_port(context, backend_port_uuid)\n            except Exception:\n                LOG.exception(\n                    \"Couldn't rollback backend port %s\" % backend_port)\n\n        @cmd_mgr.do\n        def _allocate_db_port(port_attrs, backend_port, addresses, mac,\n                              **kwargs):\n            port_attrs[\"network_id\"] = net[\"id\"]\n            port_attrs[\"id\"] = port_id\n            port_attrs[\"security_groups\"] = security_groups\n\n            LOG.info(\"Including extra plugin attrs: %s\" % backend_port)\n            port_attrs.update(backend_port)\n            with context.session.begin():\n                new_port = db_api.port_create(\n                    context, addresses=addresses, mac_address=mac[\"address\"],\n                    backend_key=backend_port[\"uuid\"], **port_attrs)\n\n            return new_port\n\n        @cmd_mgr.undo\n        def _allocate_db_port_undo(new_port,\n                                   **kwargs):\n            LOG.info(\"Rolling back database port...\")\n            if not new_port:\n                return\n            try:\n                with context.session.begin():\n                    db_api.port_delete(context, new_port)\n            except Exception:\n                LOG.exception(\n                    \"Couldn't rollback db port %s\" % backend_port)\n\n        # addresses, mac, backend_port, new_port\n        mac = _allocate_mac(net, port_id, mac_address,\n                            use_forbidden_mac_range=use_forbidden_mac_range)\n        _allocate_ips(fixed_ips, net, port_id, segment_id, mac)\n        backend_port = _allocate_backend_port(mac, addresses, net, port_id)\n        new_port = _allocate_db_port(port_attrs, backend_port, addresses, mac)\n\n    return v._make_port_dict(new_port)", "response": "Create a port which is a connection point of a device."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the values of a port.", "response": "def update_port(context, id, port):\n    \"\"\"Update values of a port.\n\n    : param context: neutron api request context\n    : param id: UUID representing the port to update.\n    : param port: dictionary with keys indicating fields to update.\n        valid keys are those that have a value of True for 'allow_put'\n        as listed in the RESOURCE_ATTRIBUTE_MAP object in\n        neutron/api/v2/attributes.py.\n    \"\"\"\n    LOG.info(\"update_port %s for tenant %s\" % (id, context.tenant_id))\n    port_db = db_api.port_find(context, id=id, scope=db_api.ONE)\n    if not port_db:\n        raise n_exc.PortNotFound(port_id=id)\n\n    port_dict = port[\"port\"]\n    fixed_ips = port_dict.pop(\"fixed_ips\", None)\n\n    admin_only = [\"mac_address\", \"device_owner\", \"bridge\", \"admin_state_up\",\n                  \"device_id\"]\n    always_filter = [\"network_id\", \"backend_key\", \"network_plugin\"]\n    utils.filter_body(context, port_dict, admin_only=admin_only,\n                      always_filter=always_filter)\n\n    # Pre-check the requested fixed_ips before making too many db trips.\n    # Note that this is the only check we need, since this call replaces\n    # the entirety of the IP addresses document if fixed_ips are provided.\n    if fixed_ips:\n        quota.QUOTAS.limit_check(context, context.tenant_id,\n                                 fixed_ips_per_port=len(fixed_ips))\n\n    new_security_groups = utils.pop_param(port_dict, \"security_groups\")\n    if new_security_groups is not None:\n        if (Capabilities.TENANT_NETWORK_SG not in\n                CONF.QUARK.environment_capabilities):\n            if not STRATEGY.is_provider_network(port_db[\"network_id\"]):\n                raise q_exc.TenantNetworkSecurityGroupRulesNotEnabled()\n\n    if new_security_groups is not None and not port_db[\"device_id\"]:\n        raise q_exc.SecurityGroupsRequireDevice()\n\n    group_ids, security_group_mods = _make_security_group_list(\n        context, new_security_groups)\n    quota.QUOTAS.limit_check(context, context.tenant_id,\n                             security_groups_per_port=len(group_ids))\n\n    if fixed_ips is not None:\n        # NOTE(mdietz): we want full control over IPAM since\n        #              we're allocating by subnet instead of\n        #              network.\n        ipam_driver = ipam.IPAM_REGISTRY.get_strategy(\n            ipam.QuarkIpamANY.get_name())\n\n        addresses, subnet_ids = [], []\n        ip_addresses = {}\n\n        for fixed_ip in fixed_ips:\n            subnet_id = fixed_ip.get(\"subnet_id\")\n            ip_address = fixed_ip.get(\"ip_address\")\n            if not (subnet_id or ip_address):\n                raise n_exc.BadRequest(\n                    resource=\"fixed_ips\",\n                    msg=\"subnet_id or ip_address required\")\n\n            if ip_address and not subnet_id:\n                raise n_exc.BadRequest(\n                    resource=\"fixed_ips\",\n                    msg=\"subnet_id required for ip_address allocation\")\n\n            if subnet_id and ip_address:\n                ip_netaddr = None\n                try:\n                    ip_netaddr = netaddr.IPAddress(ip_address).ipv6()\n                except netaddr.AddrFormatError:\n                    raise n_exc.InvalidInput(\n                        error_message=\"Invalid format provided for ip_address\")\n                ip_addresses[ip_netaddr] = subnet_id\n            else:\n                subnet_ids.append(subnet_id)\n\n        port_ips = set([netaddr.IPAddress(int(a[\"address\"]))\n                        for a in port_db[\"ip_addresses\"]])\n        new_ips = set([a for a in ip_addresses.keys()])\n\n        ips_to_allocate = list(new_ips - port_ips)\n        ips_to_deallocate = list(port_ips - new_ips)\n\n        for ip in ips_to_allocate:\n            if ip in ip_addresses:\n                # NOTE: Fix for RM10187 - we were losing the list of IPs if\n                #       more than one IP was to be allocated. Track an\n                #       aggregate list instead, and add it to the running total\n                #       after each allocate\n                allocated = []\n                ipam_driver.allocate_ip_address(\n                    context, allocated, port_db[\"network_id\"],\n                    port_db[\"id\"], reuse_after=None, ip_addresses=[ip],\n                    subnets=[ip_addresses[ip]])\n                addresses.extend(allocated)\n\n        for ip in ips_to_deallocate:\n            ipam_driver.deallocate_ips_by_port(\n                context, port_db, ip_address=ip)\n\n        for subnet_id in subnet_ids:\n            ipam_driver.allocate_ip_address(\n                context, addresses, port_db[\"network_id\"], port_db[\"id\"],\n                reuse_after=CONF.QUARK.ipam_reuse_after,\n                subnets=[subnet_id])\n\n        # Need to return all existing addresses and the new ones\n        if addresses:\n            port_dict[\"addresses\"] = port_db[\"ip_addresses\"]\n            port_dict[\"addresses\"].extend(addresses)\n\n    # NOTE(morgabra) Updating network_plugin on port objects is explicitly\n    # disallowed in the api, so we use whatever exists in the db.\n    net_driver = _get_net_driver(port_db.network, port=port_db)\n    base_net_driver = _get_net_driver(port_db.network)\n\n    # TODO(anyone): What do we want to have happen here if this fails? Is it\n    #               ok to continue to keep the IPs but fail to apply security\n    #               groups? Is there a clean way to have a multi-status? Since\n    #               we're in a beta-y status, I'm going to let this sit for\n    #               a future patch where we have time to solve it well.\n    kwargs = {}\n    if new_security_groups is not None:\n        # TODO(anyone): this is kind of silly (when testing), because it will\n        #               modify the incoming dict. Probably should be a copy or\n        #               something.\n        kwargs[\"security_groups\"] = security_group_mods\n    net_driver.update_port(context, port_id=port_db[\"backend_key\"],\n                           mac_address=port_db[\"mac_address\"],\n                           device_id=port_db[\"device_id\"],\n                           base_net_driver=base_net_driver,\n                           **kwargs)\n\n    port_dict[\"security_groups\"] = security_group_mods\n\n    with context.session.begin():\n        port = db_api.port_update(context, port_db, **port_dict)\n\n    # NOTE(mdietz): fix for issue 112, we wanted the IPs to be in\n    #              allocated_at order, so get a fresh object every time\n    if port_db in context.session:\n        context.session.expunge(port_db)\n    port_db = db_api.port_find(context, id=id, scope=db_api.ONE)\n\n    return v._make_port_dict(port_db)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves a port. : param context: neutron api request context : param id: UUID representing the port to fetch. : param fields: a list of strings that are valid keys in a port dictionary as listed in the RESOURCE_ATTRIBUTE_MAP object in neutron/api/v2/attributes.py. Only these fields will be returned.", "response": "def get_port(context, id, fields=None):\n    \"\"\"Retrieve a port.\n\n    : param context: neutron api request context\n    : param id: UUID representing the port to fetch.\n    : param fields: a list of strings that are valid keys in a\n        port dictionary as listed in the RESOURCE_ATTRIBUTE_MAP\n        object in neutron/api/v2/attributes.py. Only these fields\n        will be returned.\n    \"\"\"\n    LOG.info(\"get_port %s for tenant %s fields %s\" %\n             (id, context.tenant_id, fields))\n    results = db_api.port_find(context, id=id, fields=fields,\n                               scope=db_api.ONE)\n\n    if not results:\n        raise n_exc.PortNotFound(port_id=id)\n\n    return v._make_port_dict(results)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a list of ports for the user in the tenant.", "response": "def get_ports(context, limit=None, sorts=['id'], marker=None,\n              page_reverse=False, filters=None, fields=None):\n    \"\"\"Retrieve a list of ports.\n\n    The contents of the list depends on the identity of the user\n    making the request (as indicated by the context) as well as any\n    filters.\n    : param context: neutron api request context\n    : param filters: a dictionary with keys that are valid keys for\n        a port as listed in the RESOURCE_ATTRIBUTE_MAP object\n        in neutron/api/v2/attributes.py.  Values in this dictionary\n        are an iterable containing values that will be used for an exact\n        match comparison for that value.  Each result returned by this\n        function will have matched one of the values for each key in\n        filters.\n    : param fields: a list of strings that are valid keys in a\n        port dictionary as listed in the RESOURCE_ATTRIBUTE_MAP\n        object in neutron/api/v2/attributes.py. Only these fields\n        will be returned.\n    \"\"\"\n    LOG.info(\"get_ports for tenant %s filters %s fields %s\" %\n             (context.tenant_id, filters, fields))\n    if filters is None:\n        filters = {}\n\n    if \"ip_address\" in filters:\n        if not context.is_admin:\n            raise n_exc.NotAuthorized()\n        ips = []\n        try:\n            ips = [netaddr.IPAddress(ip) for ip in filters.pop(\"ip_address\")]\n        except netaddr.AddrFormatError:\n            raise n_exc.InvalidInput(\n                error_message=\"Invalid format provided for ip_address\")\n        query = db_api.port_find_by_ip_address(context, ip_address=ips,\n                                               scope=db_api.ALL, **filters)\n        ports = []\n        for ip in query:\n            ports.extend(ip.ports)\n    else:\n        ports = db_api.port_find(context, limit, sorts, marker,\n                                 fields=fields, join_security_groups=True,\n                                 **filters)\n    return v._make_ports_list(ports, fields)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_ports_count(context, filters=None):\n    LOG.info(\"get_ports_count for tenant %s filters %s\" %\n             (context.tenant_id, filters))\n    return db_api.port_count_all(context, join_security_groups=True, **filters)", "response": "Return the number of ports in the current context."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_port(context, id):\n    LOG.info(\"delete_port %s for tenant %s\" % (id, context.tenant_id))\n\n    port = db_api.port_find(context, id=id, scope=db_api.ONE)\n    if not port:\n        raise n_exc.PortNotFound(port_id=id)\n\n    if 'device_id' in port:  # false is weird, but ignore that\n        LOG.info(\"delete_port %s for tenant %s has device %s\" %\n                 (id, context.tenant_id, port['device_id']))\n\n    backend_key = port[\"backend_key\"]\n    mac_address = netaddr.EUI(port[\"mac_address\"]).value\n    ipam_driver = _get_ipam_driver(port[\"network\"], port=port)\n    ipam_driver.deallocate_mac_address(context, mac_address)\n    ipam_driver.deallocate_ips_by_port(\n        context, port, ipam_reuse_after=CONF.QUARK.ipam_reuse_after)\n\n    net_driver = _get_net_driver(port[\"network\"], port=port)\n    base_net_driver = _get_net_driver(port[\"network\"])\n    net_driver.delete_port(context, backend_key, device_id=port[\"device_id\"],\n                           mac_address=port[\"mac_address\"],\n                           base_net_driver=base_net_driver)\n\n    with context.session.begin():\n        db_api.port_delete(context, port)", "response": "Delete a port.\n\n    : param context: neutron api request context\n    : param id: UUID representing the port to delete."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nassociate the flip with ports and creates the flip driver with the flip driver.", "response": "def _create_flip(context, flip, port_fixed_ips):\n    \"\"\"Associates the flip with ports and creates it with the flip driver\n\n    :param context: neutron api request context.\n    :param flip: quark.db.models.IPAddress object representing a floating IP\n    :param port_fixed_ips: dictionary of the structure:\n    {\"<id of port>\": {\"port\": <quark.db.models.Port>,\n     \"fixed_ip\": \"<fixed ip address>\"}}\n    :return: None\n    \"\"\"\n    if port_fixed_ips:\n        context.session.begin()\n        try:\n            ports = [val['port'] for val in port_fixed_ips.values()]\n            flip = db_api.port_associate_ip(context, ports, flip,\n                                            port_fixed_ips.keys())\n\n            for port_id in port_fixed_ips:\n                fixed_ip = port_fixed_ips[port_id]['fixed_ip']\n                flip = db_api.floating_ip_associate_fixed_ip(context, flip,\n                                                             fixed_ip)\n\n            flip_driver = registry.DRIVER_REGISTRY.get_driver()\n\n            flip_driver.register_floating_ip(flip, port_fixed_ips)\n            context.session.commit()\n        except Exception:\n            context.session.rollback()\n            raise\n\n    # alexm: Notify from this method for consistency with _delete_flip\n    billing.notify(context, billing.IP_ASSOC, flip)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _update_flip(context, flip_id, ip_type, requested_ports):\n    # This list will hold flips that require notifications.\n    # Using sets to avoid dups, if any.\n    notifications = {\n        billing.IP_ASSOC: set(),\n        billing.IP_DISASSOC: set()\n    }\n\n    context.session.begin()\n    try:\n        flip = db_api.floating_ip_find(context, id=flip_id, scope=db_api.ONE)\n        if not flip:\n            if ip_type == ip_types.SCALING:\n                raise q_exc.ScalingIpNotFound(id=flip_id)\n            raise q_exc.FloatingIpNotFound(id=flip_id)\n        current_ports = flip.ports\n\n        # Determine what ports are being removed, being added, and remain\n        req_port_ids = [request_port.get('port_id')\n                        for request_port in requested_ports]\n        curr_port_ids = [curr_port.id for curr_port in current_ports]\n        added_port_ids = [port_id for port_id in req_port_ids\n                          if port_id and port_id not in curr_port_ids]\n        removed_port_ids = [port_id for port_id in curr_port_ids\n                            if port_id not in req_port_ids]\n        remaining_port_ids = set(curr_port_ids) - set(removed_port_ids)\n\n        # Validations just for floating ip types\n        if (ip_type == ip_types.FLOATING and curr_port_ids and\n                curr_port_ids == req_port_ids):\n            d = dict(flip_id=flip_id, port_id=curr_port_ids[0])\n            raise q_exc.PortAlreadyAssociatedToFloatingIp(**d)\n        if (ip_type == ip_types.FLOATING and\n                not curr_port_ids and not req_port_ids):\n            raise q_exc.FloatingIpUpdateNoPortIdSupplied()\n\n        # Validate that GW IP is not in use on the NW.\n        flip_subnet = v._make_subnet_dict(flip.subnet)\n        for added_port_id in added_port_ids:\n            port = _get_port(context, added_port_id)\n            nw = port.network\n            nw_ports = v._make_ports_list(nw.ports)\n            fixed_ips = [ip.get('ip_address') for p in nw_ports\n                         for ip in p.get('fixed_ips')]\n\n            gw_ip = flip_subnet.get('gateway_ip')\n            if gw_ip in fixed_ips:\n                port_with_gateway_ip = None\n                for port in nw_ports:\n                    for ip in port.get('fixed_ips'):\n                        if gw_ip in ip.get('ip_address'):\n                            port_with_gateway_ip = port\n                            break\n                port_id = port_with_gateway_ip.get('id')\n                network_id = port_with_gateway_ip.get('network_id')\n                raise q_exc.FixedIpAllocatedToGatewayIp(port_id=port_id,\n                                                        network_id=network_id)\n        port_fixed_ips = {}\n\n        # Keep the ports and fixed ips that have not changed\n        for port_id in remaining_port_ids:\n            port = db_api.port_find(context, id=port_id, scope=db_api.ONE)\n            fixed_ip = _get_flip_fixed_ip_by_port_id(flip, port_id)\n            port_fixed_ips[port_id] = {'port': port, 'fixed_ip': fixed_ip}\n\n        # Disassociate the ports and fixed ips from the flip that were\n        # associated to the flip but are not anymore\n        for port_id in removed_port_ids:\n            port = db_api.port_find(context, id=port_id, scope=db_api.ONE)\n            flip = db_api.port_disassociate_ip(context, [port], flip)\n            notifications[billing.IP_DISASSOC].add(flip)\n            fixed_ip = _get_flip_fixed_ip_by_port_id(flip, port_id)\n            if fixed_ip:\n                flip = db_api.floating_ip_disassociate_fixed_ip(\n                    context, flip, fixed_ip)\n\n        # Validate the new ports with the flip and associate the new ports\n        # and fixed ips with the flip\n        for port_id in added_port_ids:\n            port = db_api.port_find(context, id=port_id, scope=db_api.ONE)\n            if not port:\n                raise n_exc.PortNotFound(port_id=port_id)\n            if any(ip for ip in port.ip_addresses\n                   if (ip.get('address_type') == ip_types.FLOATING)):\n                raise q_exc.PortAlreadyContainsFloatingIp(port_id=port_id)\n            if any(ip for ip in port.ip_addresses\n                   if (ip.get('address_type') == ip_types.SCALING)):\n                raise q_exc.PortAlreadyContainsScalingIp(port_id=port_id)\n            fixed_ip = _get_next_available_fixed_ip(port)\n            LOG.info('new fixed ip: %s' % fixed_ip)\n            if not fixed_ip:\n                raise q_exc.NoAvailableFixedIpsForPort(port_id=port_id)\n            port_fixed_ips[port_id] = {'port': port, 'fixed_ip': fixed_ip}\n            flip = db_api.port_associate_ip(context, [port], flip, [port_id])\n            notifications[billing.IP_ASSOC].add(flip)\n            flip = db_api.floating_ip_associate_fixed_ip(context, flip,\n                                                         fixed_ip)\n\n        flip_driver = registry.DRIVER_REGISTRY.get_driver()\n        # If there are not any remaining ports and no new ones are being added,\n        # remove the floating ip from unicorn\n        if not remaining_port_ids and not added_port_ids:\n            flip_driver.remove_floating_ip(flip)\n        # If new ports are being added but there previously was not any ports,\n        # then register a new floating ip with the driver because it is\n        # assumed it does not exist\n        elif added_port_ids and not curr_port_ids:\n            flip_driver.register_floating_ip(flip, port_fixed_ips)\n        else:\n            flip_driver.update_floating_ip(flip, port_fixed_ips)\n        context.session.commit()\n    except Exception:\n        context.session.rollback()\n        raise\n\n    # Send notifications for possible associate/disassociate events\n    for notif_type, flip_set in notifications.iteritems():\n        for flip in flip_set:\n            billing.notify(context, notif_type, flip)\n\n    # NOTE(blogan): ORM does not seem to update the model to the real state\n    # of the database, so I'm doing an explicit refresh for now.\n    context.session.refresh(flip)\n    return flip", "response": "Update a floating IP object in the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nallocating or reallocate a floating IP.", "response": "def create_floatingip(context, content):\n    \"\"\"Allocate or reallocate a floating IP.\n\n    :param context: neutron api request context.\n    :param content: dictionary describing the floating ip, with keys\n        as listed in the RESOURCE_ATTRIBUTE_MAP object in\n        neutron/api/v2/attributes.py.  All keys will be populated.\n\n    :returns: Dictionary containing details for the new floating IP.  If values\n        are declared in the fields parameter, then only those keys will be\n        present.\n    \"\"\"\n    LOG.info('create_floatingip %s for tenant %s and body %s' %\n             (id, context.tenant_id, content))\n    network_id = content.get('floating_network_id')\n    # TODO(blogan): Since the extension logic will reject any requests without\n    # floating_network_id, is this still needed?\n    if not network_id:\n        raise n_exc.BadRequest(resource='floating_ip',\n                               msg='floating_network_id is required.')\n    fixed_ip_address = content.get('fixed_ip_address')\n    ip_address = content.get('floating_ip_address')\n    port_id = content.get('port_id')\n    port = None\n    port_fixed_ip = {}\n\n    network = _get_network(context, network_id)\n    if port_id:\n        port = _get_port(context, port_id)\n        fixed_ip = _get_fixed_ip(context, fixed_ip_address, port)\n        port_fixed_ip = {port.id: {'port': port, 'fixed_ip': fixed_ip}}\n    flip = _allocate_ip(context, network, port, ip_address, ip_types.FLOATING)\n    _create_flip(context, flip, port_fixed_ip)\n    return v._make_floating_ip_dict(flip, port_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating a floating IP.", "response": "def update_floatingip(context, id, content):\n    \"\"\"Update an existing floating IP.\n\n    :param context: neutron api request context.\n    :param id: id of the floating ip\n    :param content: dictionary with keys indicating fields to update.\n        valid keys are those that have a value of True for 'allow_put'\n        as listed in the RESOURCE_ATTRIBUTE_MAP object in\n        neutron/api/v2/attributes.py.\n\n    :returns: Dictionary containing details for the new floating IP.  If values\n        are declared in the fields parameter, then only those keys will be\n        present.\n    \"\"\"\n\n    LOG.info('update_floatingip %s for tenant %s and body %s' %\n             (id, context.tenant_id, content))\n\n    if 'port_id' not in content:\n        raise n_exc.BadRequest(resource='floating_ip',\n                               msg='port_id is required.')\n\n    requested_ports = []\n    if content.get('port_id'):\n        requested_ports = [{'port_id': content.get('port_id')}]\n    flip = _update_flip(context, id, ip_types.FLOATING, requested_ports)\n    return v._make_floating_ip_dict(flip)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_floatingip(context, id):\n\n    LOG.info('delete_floatingip %s for tenant %s' % (id, context.tenant_id))\n\n    _delete_flip(context, id, ip_types.FLOATING)", "response": "deallocate a floating IP."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_floatingip(context, id, fields=None):\n    LOG.info('get_floatingip %s for tenant %s' % (id, context.tenant_id))\n\n    filters = {'address_type': ip_types.FLOATING, '_deallocated': False}\n\n    floating_ip = db_api.floating_ip_find(context, id=id, scope=db_api.ONE,\n                                          **filters)\n\n    if not floating_ip:\n        raise q_exc.FloatingIpNotFound(id=id)\n\n    return v._make_floating_ip_dict(floating_ip)", "response": "Get a floating IP."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_floatingips(context, filters=None, fields=None, sorts=['id'],\n                    limit=None, marker=None, page_reverse=False):\n    \"\"\"Retrieve a list of floating ips.\n\n    :param context: neutron api request context.\n    :param filters: a dictionary with keys that are valid keys for\n        a floating ip as listed in the RESOURCE_ATTRIBUTE_MAP object\n        in neutron/api/v2/attributes.py.  Values in this dictionary\n        are an iterable containing values that will be used for an exact\n        match comparison for that value.  Each result returned by this\n        function will have matched one of the values for each key in\n        filters.\n    :param fields: a list of strings that are valid keys in a\n        floating IP dictionary as listed in the RESOURCE_ATTRIBUTE_MAP\n        object in neutron/api/v2/attributes.py. Only these fields\n        will be returned.\n\n    :returns: List of floating IPs that are accessible to the tenant who\n        submits the request (as indicated by the tenant id of the context)\n        as well as any filters.\n    \"\"\"\n    LOG.info('get_floatingips for tenant %s filters %s fields %s' %\n             (context.tenant_id, filters, fields))\n\n    floating_ips = _get_ips_by_type(context, ip_types.FLOATING,\n                                    filters=filters, fields=fields)\n\n    return [v._make_floating_ip_dict(flip) for flip in floating_ips]", "response": "Retrieve a list of floating IPs for a given tenant."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_floatingips_count(context, filters=None):\n    LOG.info('get_floatingips_count for tenant %s filters %s' %\n             (context.tenant_id, filters))\n\n    if filters is None:\n        filters = {}\n\n    filters['_deallocated'] = False\n    filters['address_type'] = ip_types.FLOATING\n    count = db_api.ip_address_count_all(context, filters)\n\n    LOG.info('Found %s floating ips for tenant %s' % (count,\n                                                      context.tenant_id))\n    return count", "response": "Returns the number of floating IPs in the given context."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_scalingip(context, content):\n    LOG.info('create_scalingip for tenant %s and body %s',\n             context.tenant_id, content)\n    network_id = content.get('scaling_network_id')\n    ip_address = content.get('scaling_ip_address')\n    requested_ports = content.get('ports', [])\n\n    network = _get_network(context, network_id)\n    port_fixed_ips = {}\n    for req_port in requested_ports:\n        port = _get_port(context, req_port['port_id'])\n        fixed_ip = _get_fixed_ip(context, req_port.get('fixed_ip_address'),\n                                 port)\n        port_fixed_ips[port.id] = {\"port\": port, \"fixed_ip\": fixed_ip}\n    scip = _allocate_ip(context, network, None, ip_address, ip_types.SCALING)\n    _create_flip(context, scip, port_fixed_ips)\n    return v._make_scaling_ip_dict(scip)", "response": "Allocate or reallocate a scaling IP."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating an existing scaling IP.", "response": "def update_scalingip(context, id, content):\n    \"\"\"Update an existing scaling IP.\n\n    :param context: neutron api request context.\n    :param id: id of the scaling ip\n    :param content: dictionary with keys indicating fields to update.\n        valid keys are those that have a value of True for 'allow_put'\n        as listed in the RESOURCE_ATTRIBUTE_MAP object in\n        neutron/api/v2/attributes.py.\n\n    :returns: Dictionary containing details for the new scaling IP.  If values\n        are declared in the fields parameter, then only those keys will be\n        present.\n    \"\"\"\n    LOG.info('update_scalingip %s for tenant %s and body %s' %\n             (id, context.tenant_id, content))\n    requested_ports = content.get('ports', [])\n    flip = _update_flip(context, id, ip_types.SCALING, requested_ports)\n    return v._make_scaling_ip_dict(flip)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_scalingip(context, id):\n    LOG.info('delete_scalingip %s for tenant %s' % (id, context.tenant_id))\n    _delete_flip(context, id, ip_types.SCALING)", "response": "Deallocate a scaling IP."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a scaling IP.", "response": "def get_scalingip(context, id, fields=None):\n    \"\"\"Retrieve a scaling IP.\n\n    :param context: neutron api request context.\n    :param id: The UUID of the scaling IP.\n    :param fields: a list of strings that are valid keys in a\n        scaling IP dictionary as listed in the RESOURCE_ATTRIBUTE_MAP\n        object in neutron/api/v2/attributes.py. Only these fields\n        will be returned.\n\n    :returns: Dictionary containing details for the scaling IP.  If values\n        are declared in the fields parameter, then only those keys will be\n        present.\n    \"\"\"\n    LOG.info('get_scalingip %s for tenant %s' % (id, context.tenant_id))\n    filters = {'address_type': ip_types.SCALING, '_deallocated': False}\n    scaling_ip = db_api.floating_ip_find(context, id=id, scope=db_api.ONE,\n                                         **filters)\n    if not scaling_ip:\n        raise q_exc.ScalingIpNotFound(id=id)\n    return v._make_scaling_ip_dict(scaling_ip)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_scalingips(context, filters=None, fields=None, sorts=['id'],\n                   limit=None, marker=None, page_reverse=False):\n    \"\"\"Retrieve a list of scaling ips.\n\n    :param context: neutron api request context.\n    :param filters: a dictionary with keys that are valid keys for\n        a scaling ip as listed in the RESOURCE_ATTRIBUTE_MAP object\n        in neutron/api/v2/attributes.py.  Values in this dictionary\n        are an iterable containing values that will be used for an exact\n        match comparison for that value.  Each result returned by this\n        function will have matched one of the values for each key in\n        filters.\n    :param fields: a list of strings that are valid keys in a\n        scaling IP dictionary as listed in the RESOURCE_ATTRIBUTE_MAP\n        object in neutron/api/v2/attributes.py. Only these fields\n        will be returned.\n\n    :returns: List of scaling IPs that are accessible to the tenant who\n        submits the request (as indicated by the tenant id of the context)\n        as well as any filters.\n    \"\"\"\n    LOG.info('get_scalingips for tenant %s filters %s fields %s' %\n             (context.tenant_id, filters, fields))\n    scaling_ips = _get_ips_by_type(context, ip_types.SCALING,\n                                   filters=filters, fields=fields)\n    return [v._make_scaling_ip_dict(scip) for scip in scaling_ips]", "response": "Get a list of scaling ips for a given tenant."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_ip_address(context, id, ip_address):\n    LOG.info(\"update_ip_address %s for tenant %s\" % (id, context.tenant_id))\n    ports = []\n    if 'ip_address' not in ip_address:\n        raise n_exc.BadRequest(resource=\"ip_addresses\",\n                               msg=\"Invalid request body.\")\n    with context.session.begin():\n        db_address = db_api.ip_address_find(context, id=id, scope=db_api.ONE)\n        if not db_address:\n            raise q_exc.IpAddressNotFound(addr_id=id)\n        iptype = db_address.address_type\n        if iptype == ip_types.FIXED and not CONF.QUARK.ipaddr_allow_fixed_ip:\n            raise n_exc.BadRequest(\n                resource=\"ip_addresses\",\n                msg=\"Fixed ips cannot be updated using this interface.\")\n\n        reset = ip_address['ip_address'].get('reset_allocation_time', False)\n        if reset and db_address['deallocated'] == 1:\n            if context.is_admin:\n                LOG.info(\"IP's deallocated time being manually reset\")\n                db_address['deallocated_at'] = _get_deallocated_override()\n            else:\n                msg = \"Modification of reset_allocation_time requires admin\"\n                raise webob.exc.HTTPForbidden(detail=msg)\n\n        port_ids = ip_address['ip_address'].get('port_ids', None)\n\n        if port_ids is not None and not port_ids:\n            raise n_exc.BadRequest(\n                resource=\"ip_addresses\",\n                msg=\"Cannot be updated with empty port_id list\")\n\n        if iptype == ip_types.SHARED:\n            has_owner = db_address.has_any_shared_owner()\n\n        if port_ids:\n            if iptype == ip_types.FIXED and len(port_ids) > 1:\n                raise n_exc.BadRequest(\n                    resource=\"ip_addresses\",\n                    msg=\"Fixed ips cannot be updated with more than one port.\")\n\n            _raise_if_shared_and_enabled(ip_address, db_address)\n            ports = db_api.port_find(context, tenant_id=context.tenant_id,\n                                     id=port_ids, scope=db_api.ALL)\n            # NOTE(name): could be considered inefficient because we're\n            # converting to a list to check length. Maybe revisit\n            if len(ports) != len(port_ids):\n                raise n_exc.PortNotFound(port_id=port_ids)\n\n            validate_and_fetch_segment(ports, db_address[\"network_id\"])\n            validate_port_ip_quotas(context, db_address.network_id, ports)\n\n            if iptype == ip_types.SHARED and has_owner:\n                for assoc in db_address.associations:\n                    pid = assoc.port_id\n                    if pid not in port_ids and 'none' != assoc.service:\n                        raise q_exc.PortRequiresDisassociation()\n\n            LOG.info(\"Updating IP address, %s, to only be used by the\"\n                     \"following ports:  %s\" % (db_address.address_readable,\n                                               [p.id for p in ports]))\n            new_address = db_api.update_port_associations_for_ip(context,\n                                                                 ports,\n                                                                 db_address)\n        elif iptype == ip_types.SHARED and has_owner:\n            raise q_exc.PortRequiresDisassociation()\n        elif 'deallocated' in ip_address['ip_address']\\\n                and context.is_admin:\n            # Verify no port associations\n            if len(db_address.associations) != 0:\n                exc_msg = (\"IP %s cannot be deallocated or allocated while\"\n                           \" still associated with ports: %s\"\n                           % (db_address['address_readable'],\n                              db_address.associations))\n                raise q_exc.ActionNotAuthorized(msg=exc_msg)\n\n            # NOTE: If an admin, allow a user to set deallocated to false\n            # in order to reserve a deallocated IP. Alternatively, allow them\n            # reverse that choice if a mistake was made.\n            if ip_address['ip_address']['deallocated'] == 'False':\n                db_address['deallocated'] = False\n            else:\n                db_address['deallocated'] = True\n            return v._make_ip_dict(db_address, context.is_admin)\n        else:\n            ipam_driver.deallocate_ip_address(context, db_address)\n            return v._make_ip_dict(db_address, context.is_admin)\n    return v._make_ip_dict(new_address, context.is_admin)", "response": "Update an existing IP address."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes an ip address.", "response": "def delete_ip_address(context, id):\n    \"\"\"Delete an ip address.\n\n    : param context: neutron api request context\n    : param id: UUID representing the ip address to delete.\n    \"\"\"\n    LOG.info(\"delete_ip_address %s for tenant %s\" % (id, context.tenant_id))\n    with context.session.begin():\n        ip_address = db_api.ip_address_find(\n            context, id=id, scope=db_api.ONE)\n        if not ip_address or ip_address.deallocated:\n            raise q_exc.IpAddressNotFound(addr_id=id)\n\n        iptype = ip_address.address_type\n        if iptype == ip_types.FIXED and not CONF.QUARK.ipaddr_allow_fixed_ip:\n            raise n_exc.BadRequest(\n                resource=\"ip_addresses\",\n                msg=\"Fixed ips cannot be updated using this interface.\")\n\n        if ip_address.has_any_shared_owner():\n            raise q_exc.PortRequiresDisassociation()\n\n        db_api.update_port_associations_for_ip(context, [], ip_address)\n\n        ipam_driver.deallocate_ip_address(context, ip_address)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_ports_for_ip_address(context, ip_id, limit=None, sorts=['id'],\n                             marker=None, page_reverse=False, filters=None,\n                             fields=None):\n    \"\"\"Retrieve a list of ports.\n\n    The contents of the list depends on the identity of the user\n    making the request (as indicated by the context) as well as any\n    filters.\n    : param context: neutron api request context\n    : param filters: a dictionary with keys that are valid keys for\n        a port as listed in the RESOURCE_ATTRIBUTE_MAP object\n        in neutron/api/v2/attributes.py.  Values in this dictionary\n        are an iterable containing values that will be used for an exact\n        match comparison for that value.  Each result returned by this\n        function will have matched one of the values for each key in\n        filters.\n    : param fields: a list of strings that are valid keys in a\n        port dictionary as listed in the RESOURCE_ATTRIBUTE_MAP\n        object in neutron/api/v2/attributes.py. Only these fields\n        will be returned.\n    \"\"\"\n    LOG.info(\"get_ports for tenant %s filters %s fields %s\" %\n             (context.tenant_id, filters, fields))\n    addr = db_api.ip_address_find(context, id=ip_id, scope=db_api.ONE)\n    if not addr:\n        raise q_exc.IpAddressNotFound(addr_id=ip_id)\n\n    if filters is None:\n        filters = {}\n\n    filters['ip_address_id'] = [ip_id]\n\n    ports = db_api.port_find(context, limit, sorts, marker,\n                             fields=fields, join_security_groups=True,\n                             **filters)\n    return v._make_ip_ports_list(addr, ports, fields)", "response": "Get a list of ports for the given IP address."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a port for a given IP address.", "response": "def get_port_for_ip_address(context, ip_id, id, fields=None):\n    \"\"\"Retrieve a port.\n\n    : param context: neutron api request context\n    : param id: UUID representing the port to fetch.\n    : param fields: a list of strings that are valid keys in a\n        port dictionary as listed in the RESOURCE_ATTRIBUTE_MAP\n        object in neutron/api/v2/attributes.py. Only these fields\n        will be returned.\n    \"\"\"\n    LOG.info(\"get_port %s for tenant %s fields %s\" %\n             (id, context.tenant_id, fields))\n    addr = db_api.ip_address_find(context, id=ip_id, scope=db_api.ONE)\n    if not addr:\n        raise q_exc.IpAddressNotFound(addr_id=ip_id)\n\n    filters = {'ip_address_id': [ip_id]}\n    results = db_api.port_find(context, id=id, fields=fields,\n                               scope=db_api.ONE, **filters)\n\n    if not results:\n        raise n_exc.PortNotFound(port_id=id)\n\n    return v._make_port_for_ip_dict(addr, results)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_port_for_ip_address(context, ip_id, id, port):\n    LOG.info(\"update_port %s for tenant %s\" % (id, context.tenant_id))\n    sanitize_list = ['service']\n    with context.session.begin():\n        addr = db_api.ip_address_find(context, id=ip_id, scope=db_api.ONE)\n        if not addr:\n            raise q_exc.IpAddressNotFound(addr_id=ip_id)\n        port_db = db_api.port_find(context, id=id, scope=db_api.ONE)\n        if not port_db:\n            raise q_exc.PortNotFound(port_id=id)\n        port_dict = {k: port['port'][k] for k in sanitize_list}\n\n        require_da = False\n        service = port_dict.get('service')\n\n        if require_da and _shared_ip_and_active(addr, except_port=id):\n            raise q_exc.PortRequiresDisassociation()\n        addr.set_service_for_port(port_db, service)\n        context.session.add(addr)\n    return v._make_port_for_ip_dict(addr, port_db)", "response": "Update the values of a port for a given ip."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_isonet_vif(vif):\n    nicira_iface_id = vif.record.get('other_config').get('nicira-iface-id')\n\n    if nicira_iface_id:\n        return True\n\n    return False", "response": "Determine if a vif is on isonet"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef partition_vifs(xapi_client, interfaces, security_group_states):\n    added = []\n    updated = []\n    removed = []\n\n    for vif in interfaces:\n        # Quark should not action on isonet vifs in regions that use FLIP\n        if ('floating_ip' in CONF.QUARK.environment_capabilities and\n                is_isonet_vif(vif)):\n            continue\n\n        vif_has_groups = vif in security_group_states\n        if vif.tagged and vif_has_groups and\\\n                security_group_states[vif][sg_cli.SECURITY_GROUP_ACK]:\n            # Already ack'd these groups and VIF is tagged, reapply.\n            # If it's not tagged, fall through and have it self-heal\n            continue\n\n        if vif.tagged:\n            if vif_has_groups:\n                updated.append(vif)\n            else:\n                removed.append(vif)\n        else:\n            if vif_has_groups:\n                added.append(vif)\n            # if not tagged and no groups, skip\n\n    return added, updated, removed", "response": "Splits the VIFs into three explicit categories and one implicit category and one implicit category and one implicit category."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomparing the groups that were successfully returned from xapi_client. update_interfaces call and returns the list of groups that have not changed since update.", "response": "def get_groups_to_ack(groups_to_ack, init_sg_states, curr_sg_states):\n    \"\"\"Compares initial security group rules with current sg rules.\n\n    Given the groups that were successfully returned from\n        xapi_client.update_interfaces call, compare initial and current\n        security group rules to determine if an update occurred during\n        the window that the xapi_client.update_interfaces was executing.\n        Return a list of vifs whose security group rules have not changed.\n    \"\"\"\n    security_groups_changed = []\n    # Compare current security group rules with initial rules.\n    for vif in groups_to_ack:\n        initial_state = init_sg_states[vif][sg_cli.SECURITY_GROUP_HASH_ATTR]\n        current_state = curr_sg_states[vif][sg_cli.SECURITY_GROUP_HASH_ATTR]\n        bad_match_msg = ('security group rules were changed for vif \"%s\" while'\n                         ' executing xapi_client.update_interfaces.'\n                         ' Will not ack rule.' % vif)\n        # If lists are different lengths, they're automatically different.\n        if len(initial_state) != len(current_state):\n            security_groups_changed.append(vif)\n            LOG.info(bad_match_msg)\n        elif len(initial_state) > 0:\n            # Compare rules in equal length lists.\n            for rule in current_state:\n                if rule not in initial_state:\n                    security_groups_changed.append(vif)\n                    LOG.info(bad_match_msg)\n                    break\n\n    # Only ack groups whose rules have not changed since update. If\n    # rules do not match, do not add them to ret so the change\n    # can be picked up on the next cycle.\n    ret = [group for group in groups_to_ack\n           if group not in security_groups_changed]\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run():\n    groups_client = sg_cli.SecurityGroupsClient()\n    xapi_client = xapi.XapiClient()\n\n    interfaces = set()\n    while True:\n        try:\n            interfaces = xapi_client.get_interfaces()\n        except Exception:\n            LOG.exception(\"Unable to get instances/interfaces from xapi\")\n            _sleep()\n            continue\n\n        try:\n            sg_states = groups_client.get_security_group_states(interfaces)\n            new_sg, updated_sg, removed_sg = partition_vifs(xapi_client,\n                                                            interfaces,\n                                                            sg_states)\n            xapi_client.update_interfaces(new_sg, updated_sg, removed_sg)\n            groups_to_ack = [v for v in new_sg + updated_sg if v.success]\n            # NOTE(quade): This solves a race condition where a security group\n            # rule may have changed between the time the sg_states were called\n            # and when they were officially ack'd. It functions as a compare\n            # and set. This is a fix until we get onto a proper messaging\n            # queue. NCP-2287\n            sg_sts_curr = groups_client.get_security_group_states(interfaces)\n            groups_to_ack = get_groups_to_ack(groups_to_ack, sg_states,\n                                              sg_sts_curr)\n            # This list will contain all the security group rules that do not\n            # match\n            ack_groups(groups_client, groups_to_ack)\n\n        except Exception:\n            LOG.exception(\"Unable to get security groups from registry and \"\n                          \"apply them to xapi\")\n            _sleep()\n            continue\n\n        _sleep()", "response": "Processes the current state of the current state of the current security group and updates them to the final modified list and applies flows to each new security group."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_tenant_quota(context, tenant_id):\n\n        tenant_quotas = context.session.query(Quota)\n        tenant_quotas = tenant_quotas.filter_by(tenant_id=tenant_id)\n        tenant_quotas.delete()", "response": "Delete the quota entries for a given tenant_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates the CIDR for a subnet.", "response": "def _validate_subnet_cidr(context, network_id, new_subnet_cidr):\n    \"\"\"Validate the CIDR for a subnet.\n\n    Verifies the specified CIDR does not overlap with the ones defined\n    for the other subnets specified for this network, or with any other\n    CIDR if overlapping IPs are disabled.\n\n    \"\"\"\n    if neutron_cfg.cfg.CONF.allow_overlapping_ips:\n        return\n\n    try:\n        new_subnet_ipset = netaddr.IPSet([new_subnet_cidr])\n    except TypeError:\n        LOG.exception(\"Invalid or missing cidr: %s\" % new_subnet_cidr)\n        raise n_exc.BadRequest(resource=\"subnet\",\n                               msg=\"Invalid or missing cidr\")\n\n    filters = {\n        'network_id': network_id,\n        'shared': [False]\n    }\n    # Using admin context here, in case we actually share networks later\n    subnet_list = db_api.subnet_find(context=context.elevated(), **filters)\n\n    for subnet in subnet_list:\n        if (netaddr.IPSet([subnet.cidr]) & new_subnet_ipset):\n            # don't give out details of the overlapping subnet\n            err_msg = (_(\"Requested subnet with cidr: %(cidr)s for \"\n                         \"network: %(network_id)s overlaps with another \"\n                         \"subnet\") %\n                       {'cidr': new_subnet_cidr,\n                        'network_id': network_id})\n            LOG.error(_(\"Validation for CIDR: %(new_cidr)s failed - \"\n                        \"overlaps with subnet %(subnet_id)s \"\n                        \"(CIDR: %(cidr)s)\"),\n                      {'new_cidr': new_subnet_cidr,\n                       'subnet_id': subnet.id,\n                       'cidr': subnet.cidr})\n            raise n_exc.InvalidInput(error_message=err_msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a subnet which represents a range of IP addresses.", "response": "def create_subnet(context, subnet):\n    \"\"\"Create a subnet.\n\n    Create a subnet which represents a range of IP addresses\n    that can be allocated to devices\n\n    : param context: neutron api request context\n    : param subnet: dictionary describing the subnet, with keys\n        as listed in the RESOURCE_ATTRIBUTE_MAP object in\n        neutron/api/v2/attributes.py.  All keys will be populated.\n    \"\"\"\n    LOG.info(\"create_subnet for tenant %s\" % context.tenant_id)\n    net_id = subnet[\"subnet\"][\"network_id\"]\n\n    with context.session.begin():\n        net = db_api.network_find(context=context, limit=None, sorts=['id'],\n                                  marker=None, page_reverse=False, fields=None,\n                                  id=net_id, scope=db_api.ONE)\n        if not net:\n            raise n_exc.NetworkNotFound(net_id=net_id)\n\n        sub_attrs = subnet[\"subnet\"]\n\n        always_pop = [\"enable_dhcp\", \"ip_version\", \"first_ip\", \"last_ip\",\n                      \"_cidr\"]\n        admin_only = [\"segment_id\", \"do_not_use\", \"created_at\",\n                      \"next_auto_assign_ip\"]\n        utils.filter_body(context, sub_attrs, admin_only, always_pop)\n\n        _validate_subnet_cidr(context, net_id, sub_attrs[\"cidr\"])\n\n        cidr = netaddr.IPNetwork(sub_attrs[\"cidr\"])\n\n        err_vals = {'cidr': sub_attrs[\"cidr\"], 'network_id': net_id}\n        err = _(\"Requested subnet with cidr: %(cidr)s for \"\n                \"network: %(network_id)s. Prefix is too small, must be a \"\n                \"larger subnet. A prefix less than /%(prefix)s is required.\")\n\n        if cidr.version == 6 and cidr.prefixlen > 64:\n            err_vals[\"prefix\"] = 65\n            err_msg = err % err_vals\n            raise n_exc.InvalidInput(error_message=err_msg)\n        elif cidr.version == 4 and cidr.prefixlen > 30:\n            err_vals[\"prefix\"] = 31\n            err_msg = err % err_vals\n            raise n_exc.InvalidInput(error_message=err_msg)\n        # Enforce subnet quotas\n        net_subnets = get_subnets(context,\n                                  filters=dict(network_id=net_id))\n        if not context.is_admin:\n            v4_count, v6_count = 0, 0\n            for subnet in net_subnets:\n                if netaddr.IPNetwork(subnet['cidr']).version == 6:\n                    v6_count += 1\n                else:\n                    v4_count += 1\n\n            if cidr.version == 6:\n                tenant_quota_v6 = context.session.query(qdv.Quota).filter_by(\n                    tenant_id=context.tenant_id,\n                    resource='v6_subnets_per_network').first()\n                if tenant_quota_v6 != -1:\n                    quota.QUOTAS.limit_check(\n                        context, context.tenant_id,\n                        v6_subnets_per_network=v6_count + 1)\n            else:\n                tenant_quota_v4 = context.session.query(qdv.Quota).filter_by(\n                    tenant_id=context.tenant_id,\n                    resource='v4_subnets_per_network').first()\n                if tenant_quota_v4 != -1:\n                    quota.QUOTAS.limit_check(\n                        context, context.tenant_id,\n                        v4_subnets_per_network=v4_count + 1)\n\n        # See RM981. The default behavior of setting a gateway unless\n        # explicitly asked to not is no longer desirable.\n        gateway_ip = utils.pop_param(sub_attrs, \"gateway_ip\")\n        dns_ips = utils.pop_param(sub_attrs, \"dns_nameservers\", [])\n        host_routes = utils.pop_param(sub_attrs, \"host_routes\", [])\n        allocation_pools = utils.pop_param(sub_attrs, \"allocation_pools\", None)\n\n        sub_attrs[\"network\"] = net\n        new_subnet = db_api.subnet_create(context, **sub_attrs)\n\n        cidrs = []\n        alloc_pools = allocation_pool.AllocationPools(sub_attrs[\"cidr\"],\n                                                      allocation_pools)\n        if isinstance(allocation_pools, list):\n            cidrs = alloc_pools.get_policy_cidrs()\n\n        quota.QUOTAS.limit_check(\n            context,\n            context.tenant_id,\n            alloc_pools_per_subnet=len(alloc_pools))\n\n        ip_policies.ensure_default_policy(cidrs, [new_subnet])\n        new_subnet[\"ip_policy\"] = db_api.ip_policy_create(context,\n                                                          exclude=cidrs)\n\n        quota.QUOTAS.limit_check(context, context.tenant_id,\n                                 routes_per_subnet=len(host_routes))\n\n        default_route = None\n        for route in host_routes:\n            netaddr_route = netaddr.IPNetwork(route[\"destination\"])\n            if netaddr_route.value == routes.DEFAULT_ROUTE.value:\n                if default_route:\n                    raise q_exc.DuplicateRouteConflict(\n                        subnet_id=new_subnet[\"id\"])\n\n                default_route = route\n                gateway_ip = default_route[\"nexthop\"]\n                alloc_pools.validate_gateway_excluded(gateway_ip)\n\n            new_subnet[\"routes\"].append(db_api.route_create(\n                context, cidr=route[\"destination\"], gateway=route[\"nexthop\"]))\n\n        quota.QUOTAS.limit_check(context, context.tenant_id,\n                                 dns_nameservers_per_subnet=len(dns_ips))\n\n        for dns_ip in dns_ips:\n            new_subnet[\"dns_nameservers\"].append(db_api.dns_create(\n                context, ip=netaddr.IPAddress(dns_ip)))\n\n        # if the gateway_ip is IN the cidr for the subnet and NOT excluded by\n        # policies, we should raise a 409 conflict\n        if gateway_ip and default_route is None:\n            alloc_pools.validate_gateway_excluded(gateway_ip)\n            new_subnet[\"routes\"].append(db_api.route_create(\n                context, cidr=str(routes.DEFAULT_ROUTE), gateway=gateway_ip))\n\n    subnet_dict = v._make_subnet_dict(new_subnet)\n    subnet_dict[\"gateway_ip\"] = gateway_ip\n\n    return subnet_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_subnet(context, id, subnet):\n    LOG.info(\"update_subnet %s for tenant %s\" %\n             (id, context.tenant_id))\n\n    with context.session.begin():\n        subnet_db = db_api.subnet_find(context=context, limit=None,\n                                       page_reverse=False, sorts=['id'],\n                                       marker_obj=None, fields=None,\n                                       id=id, scope=db_api.ONE)\n        if not subnet_db:\n            raise n_exc.SubnetNotFound(subnet_id=id)\n\n        s = subnet[\"subnet\"]\n        always_pop = [\"_cidr\", \"cidr\", \"first_ip\", \"last_ip\", \"ip_version\",\n                      \"segment_id\", \"network_id\"]\n        admin_only = [\"do_not_use\", \"created_at\", \"tenant_id\",\n                      \"next_auto_assign_ip\", \"enable_dhcp\"]\n        utils.filter_body(context, s, admin_only, always_pop)\n\n        dns_ips = utils.pop_param(s, \"dns_nameservers\", [])\n        host_routes = utils.pop_param(s, \"host_routes\", [])\n        gateway_ip = utils.pop_param(s, \"gateway_ip\", None)\n        allocation_pools = utils.pop_param(s, \"allocation_pools\", None)\n        if not CONF.QUARK.allow_allocation_pool_update:\n            if allocation_pools:\n                raise n_exc.BadRequest(\n                    resource=\"subnets\",\n                    msg=\"Allocation pools cannot be updated.\")\n\n            if subnet_db[\"ip_policy\"] is not None:\n                ip_policy_cidrs = subnet_db[\"ip_policy\"].get_cidrs_ip_set()\n            else:\n                ip_policy_cidrs = netaddr.IPSet([])\n\n            alloc_pools = allocation_pool.AllocationPools(\n                subnet_db[\"cidr\"],\n                policies=ip_policy_cidrs)\n        else:\n            alloc_pools = allocation_pool.AllocationPools(subnet_db[\"cidr\"],\n                                                          allocation_pools)\n            original_pools = subnet_db.allocation_pools\n            ori_pools = allocation_pool.AllocationPools(subnet_db[\"cidr\"],\n                                                        original_pools)\n            # Check if the pools are growing or shrinking\n            is_growing = _pool_is_growing(ori_pools, alloc_pools)\n            if not CONF.QUARK.allow_allocation_pool_growth and is_growing:\n                raise n_exc.BadRequest(\n                    resource=\"subnets\",\n                    msg=\"Allocation pools may not be updated to be larger \"\n                        \"do to configuration settings\")\n\n        quota.QUOTAS.limit_check(\n            context,\n            context.tenant_id,\n            alloc_pools_per_subnet=len(alloc_pools))\n        if gateway_ip:\n            alloc_pools.validate_gateway_excluded(gateway_ip)\n            default_route = None\n            for route in host_routes:\n                netaddr_route = netaddr.IPNetwork(route[\"destination\"])\n                if netaddr_route.value == routes.DEFAULT_ROUTE.value:\n                    default_route = route\n                    break\n\n            if default_route is None:\n                route_model = db_api.route_find(\n                    context, cidr=str(routes.DEFAULT_ROUTE), subnet_id=id,\n                    scope=db_api.ONE)\n                if route_model:\n                    db_api.route_update(context, route_model,\n                                        gateway=gateway_ip)\n                else:\n                    db_api.route_create(context,\n                                        cidr=str(routes.DEFAULT_ROUTE),\n                                        gateway=gateway_ip, subnet_id=id)\n\n        if dns_ips:\n            subnet_db[\"dns_nameservers\"] = []\n            quota.QUOTAS.limit_check(context, context.tenant_id,\n                                     dns_nameservers_per_subnet=len(dns_ips))\n\n        for dns_ip in dns_ips:\n            subnet_db[\"dns_nameservers\"].append(db_api.dns_create(\n                context,\n                ip=netaddr.IPAddress(dns_ip)))\n\n        if host_routes:\n            subnet_db[\"routes\"] = []\n            quota.QUOTAS.limit_check(context, context.tenant_id,\n                                     routes_per_subnet=len(host_routes))\n\n        for route in host_routes:\n            subnet_db[\"routes\"].append(db_api.route_create(\n                context, cidr=route[\"destination\"], gateway=route[\"nexthop\"]))\n        if CONF.QUARK.allow_allocation_pool_update:\n            if isinstance(allocation_pools, list):\n                cidrs = alloc_pools.get_policy_cidrs()\n                ip_policies.ensure_default_policy(cidrs, [subnet_db])\n                subnet_db[\"ip_policy\"] = db_api.ip_policy_update(\n                    context, subnet_db[\"ip_policy\"], exclude=cidrs)\n                # invalidate the cache\n                db_api.subnet_update_set_alloc_pool_cache(context, subnet_db)\n        subnet = db_api.subnet_update(context, subnet_db, **s)\n    return v._make_subnet_dict(subnet)", "response": "Update the values of a subnet."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_subnet(context, id, fields=None):\n    LOG.info(\"get_subnet %s for tenant %s with fields %s\" %\n             (id, context.tenant_id, fields))\n    subnet = db_api.subnet_find(context=context, limit=None,\n                                page_reverse=False, sorts=['id'],\n                                marker_obj=None, fields=None, id=id,\n                                join_dns=True, join_routes=True,\n                                scope=db_api.ONE)\n    if not subnet:\n        raise n_exc.SubnetNotFound(subnet_id=id)\n\n    cache = subnet.get(\"_allocation_pool_cache\")\n    if not cache:\n        new_cache = subnet.allocation_pools\n        db_api.subnet_update_set_alloc_pool_cache(context, subnet, new_cache)\n    return v._make_subnet_dict(subnet)", "response": "Retrieve a subnet.\n\n    : param context: neutron api request context\n    : param id: UUID representing the subnet to fetch.\n    : param fields: a list of strings that are valid keys in a\n        subnet dictionary as listed in the RESOURCE_ATTRIBUTE_MAP\n        object in neutron/api/v2/attributes.py. Only these fields\n        will be returned."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a list of subnets for the user in the specified context.", "response": "def get_subnets(context, limit=None, page_reverse=False, sorts=['id'],\n                marker=None, filters=None, fields=None):\n    \"\"\"Retrieve a list of subnets.\n\n    The contents of the list depends on the identity of the user\n    making the request (as indicated by the context) as well as any\n    filters.\n    : param context: neutron api request context\n    : param filters: a dictionary with keys that are valid keys for\n        a subnet as listed in the RESOURCE_ATTRIBUTE_MAP object\n        in neutron/api/v2/attributes.py.  Values in this dictiontary\n        are an iterable containing values that will be used for an exact\n        match comparison for that value.  Each result returned by this\n        function will have matched one of the values for each key in\n        filters.\n    : param fields: a list of strings that are valid keys in a\n        subnet dictionary as listed in the RESOURCE_ATTRIBUTE_MAP\n        object in neutron/api/v2/attributes.py. Only these fields\n        will be returned.\n    \"\"\"\n    LOG.info(\"get_subnets for tenant %s with filters %s fields %s\" %\n             (context.tenant_id, filters, fields))\n    filters = filters or {}\n    subnets = db_api.subnet_find(context, limit=limit,\n                                 page_reverse=page_reverse, sorts=sorts,\n                                 marker_obj=marker, join_dns=True,\n                                 join_routes=True, join_pool=True, **filters)\n    for subnet in subnets:\n        cache = subnet.get(\"_allocation_pool_cache\")\n        if not cache:\n            db_api.subnet_update_set_alloc_pool_cache(\n                context, subnet, subnet.allocation_pools)\n    return v._make_subnets_list(subnets, fields=fields)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the number of subnets in the current tenant.", "response": "def get_subnets_count(context, filters=None):\n    \"\"\"Return the number of subnets.\n\n    The result depends on the identity of the user making the request\n    (as indicated by the context) as well as any filters.\n    : param context: neutron api request context\n    : param filters: a dictionary with keys that are valid keys for\n        a network as listed in the RESOURCE_ATTRIBUTE_MAP object\n        in neutron/api/v2/attributes.py.  Values in this dictiontary\n        are an iterable containing values that will be used for an exact\n        match comparison for that value.  Each result returned by this\n        function will have matched one of the values for each key in\n        filters.\n\n    NOTE: this method is optional, as it was not part of the originally\n          defined plugin API.\n    \"\"\"\n    LOG.info(\"get_subnets_count for tenant %s with filters %s\" %\n             (context.tenant_id, filters))\n    return db_api.subnet_count_all(context, **filters)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_subnet(context, id):\n    LOG.info(\"delete_subnet %s for tenant %s\" % (id, context.tenant_id))\n    with context.session.begin():\n        subnet = db_api.subnet_find(context, id=id, scope=db_api.ONE)\n        if not subnet:\n            raise n_exc.SubnetNotFound(subnet_id=id)\n\n        if not context.is_admin:\n            if STRATEGY.is_provider_network(subnet.network_id):\n                if subnet.tenant_id == context.tenant_id:\n                    # A tenant can't delete subnets on provider network\n                    raise n_exc.NotAuthorized(subnet_id=id)\n                else:\n                    # Raise a NotFound here because the foreign tenant\n                    # does not have to know about other tenant's subnet\n                    # existence.\n                    raise n_exc.SubnetNotFound(subnet_id=id)\n\n        _delete_subnet(context, subnet)", "response": "Delete a subnet.\n\n    : param context: neutron api request context\n    : param id: UUID representing the subnet to delete."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _filter_update_security_group_rule(rule):\n    '''Only two fields are allowed for modification:\n\n        external_service and external_service_id\n    '''\n    allowed = ['external_service', 'external_service_id']\n    filtered = {}\n    for k, val in rule.iteritems():\n        if k in allowed:\n            if isinstance(val, basestring) and \\\n               len(val) <= GROUP_NAME_MAX_LENGTH:\n                filtered[k] = val\n    return filtered", "response": "Only two fields are allowed for modification"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _perform_async_update_rule(context, id, db_sg_group, rule_id, action):\n    rpc_reply = None\n    sg_rpc = sg_rpc_api.QuarkSGAsyncProcessClient()\n    ports = db_api.sg_gather_associated_ports(context, db_sg_group)\n    if len(ports) > 0:\n        rpc_reply = sg_rpc.start_update(context, id, rule_id, action)\n        if rpc_reply:\n            job_id = rpc_reply['job_id']\n            job_api.add_job_to_context(context, job_id)\n        else:\n            LOG.error(\"Async update failed. Is the worker running?\")", "response": "Perform an asynchronous update of a security group rule."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_security_group_rule(context, security_group_rule):\n    LOG.info(\"create_security_group for tenant %s\" %\n             (context.tenant_id))\n    with context.session.begin():\n        rule = _validate_security_group_rule(\n            context, security_group_rule[\"security_group_rule\"])\n        rule[\"id\"] = uuidutils.generate_uuid()\n\n        group_id = rule[\"security_group_id\"]\n        group = db_api.security_group_find(context, id=group_id,\n                                           scope=db_api.ONE)\n        if not group:\n            raise sg_ext.SecurityGroupNotFound(id=group_id)\n\n        quota.QUOTAS.limit_check(\n            context, context.tenant_id,\n            security_rules_per_group=len(group.get(\"rules\", [])) + 1)\n\n        new_rule = db_api.security_group_rule_create(context, **rule)\n    if group:\n        _perform_async_update_rule(context, group_id, group, new_rule.id,\n                                   RULE_CREATE)\n    return v._make_security_group_rule_dict(new_rule)", "response": "Creates a rule and updates the ports if enabled."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_security_group_rule(context, id, security_group_rule):\n    '''Updates a rule and updates the ports'''\n    LOG.info(\"update_security_group_rule for tenant %s\" %\n             (context.tenant_id))\n    new_rule = security_group_rule[\"security_group_rule\"]\n    # Only allow updatable fields\n    new_rule = _filter_update_security_group_rule(new_rule)\n\n    with context.session.begin():\n        rule = db_api.security_group_rule_find(context, id=id,\n                                               scope=db_api.ONE)\n        if not rule:\n            raise sg_ext.SecurityGroupRuleNotFound(id=id)\n\n        db_rule = db_api.security_group_rule_update(context, rule, **new_rule)\n\n        group_id = db_rule.group_id\n        group = db_api.security_group_find(context, id=group_id,\n                                           scope=db_api.ONE)\n        if not group:\n            raise sg_ext.SecurityGroupNotFound(id=group_id)\n\n    if group:\n        _perform_async_update_rule(context, group_id, group, rule.id,\n                                   RULE_UPDATE)\n\n    return v._make_security_group_rule_dict(db_rule)", "response": "Updates a rule and updates the ports"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a rule and updates the ports if enabled.", "response": "def delete_security_group_rule(context, id):\n    \"\"\"Deletes a rule and updates the ports (async) if enabled.\"\"\"\n    LOG.info(\"delete_security_group %s for tenant %s\" %\n             (id, context.tenant_id))\n    with context.session.begin():\n        rule = db_api.security_group_rule_find(context, id=id,\n                                               scope=db_api.ONE)\n        if not rule:\n            raise sg_ext.SecurityGroupRuleNotFound(id=id)\n\n        group = db_api.security_group_find(context, id=rule[\"group_id\"],\n                                           scope=db_api.ONE)\n        if not group:\n            raise sg_ext.SecurityGroupNotFound(id=id)\n\n        rule[\"id\"] = id\n        db_api.security_group_rule_delete(context, rule)\n    if group:\n        _perform_async_update_rule(context, group.id, group, id, RULE_DELETE)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_data():\n\n    output = []\n    tables = get_tables()\n    for table in tables:\n        try:\n            columns = get_columns(table)\n        except sa.exc.NoSuchTableError:\n            continue\n\n        for column in columns:\n            if column['name'] == 'tenant_id':\n                output.append((table, column))\n\n    return output", "response": "Returns a list of tuples that is built based on retrieved tables where column with name\n    exists."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_public_net_id(self):\n        for id, net_params in self.strategy.iteritems():\n            if id == CONF.QUARK.public_net_id:\n                return id\n        return None", "response": "Returns the public net id"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _validate_allocation_pools(self):\n        ip_pools = self._alloc_pools\n        subnet_cidr = self._subnet_cidr\n\n        LOG.debug(_(\"Performing IP validity checks on allocation pools\"))\n        ip_sets = []\n        for ip_pool in ip_pools:\n            try:\n                start_ip = netaddr.IPAddress(ip_pool['start'])\n                end_ip = netaddr.IPAddress(ip_pool['end'])\n            except netaddr.AddrFormatError:\n                LOG.info(_(\"Found invalid IP address in pool: \"\n                           \"%(start)s - %(end)s:\"),\n                         {'start': ip_pool['start'],\n                          'end': ip_pool['end']})\n                raise n_exc_ext.InvalidAllocationPool(pool=ip_pool)\n            if (start_ip.version != self._subnet_cidr.version or\n                    end_ip.version != self._subnet_cidr.version):\n                LOG.info(_(\"Specified IP addresses do not match \"\n                           \"the subnet IP version\"))\n                raise n_exc_ext.InvalidAllocationPool(pool=ip_pool)\n            if end_ip < start_ip:\n                LOG.info(_(\"Start IP (%(start)s) is greater than end IP \"\n                           \"(%(end)s)\"),\n                         {'start': ip_pool['start'], 'end': ip_pool['end']})\n                raise n_exc_ext.InvalidAllocationPool(pool=ip_pool)\n            if (start_ip < self._subnet_first_ip or\n                    end_ip > self._subnet_last_ip):\n                LOG.info(_(\"Found pool larger than subnet \"\n                           \"CIDR:%(start)s - %(end)s\"),\n                         {'start': ip_pool['start'],\n                          'end': ip_pool['end']})\n                raise n_exc_ext.OutOfBoundsAllocationPool(\n                    pool=ip_pool,\n                    subnet_cidr=subnet_cidr)\n            # Valid allocation pool\n            # Create an IPSet for it for easily verifying overlaps\n            ip_sets.append(netaddr.IPSet(netaddr.IPRange(\n                ip_pool['start'],\n                ip_pool['end']).cidrs()))\n\n        LOG.debug(_(\"Checking for overlaps among allocation pools \"\n                    \"and gateway ip\"))\n        ip_ranges = ip_pools[:]\n\n        # Use integer cursors as an efficient way for implementing\n        # comparison and avoiding comparing the same pair twice\n        for l_cursor in xrange(len(ip_sets)):\n            for r_cursor in xrange(l_cursor + 1, len(ip_sets)):\n                if ip_sets[l_cursor] & ip_sets[r_cursor]:\n                    l_range = ip_ranges[l_cursor]\n                    r_range = ip_ranges[r_cursor]\n                    LOG.info(_(\"Found overlapping ranges: %(l_range)s and \"\n                               \"%(r_range)s\"),\n                             {'l_range': l_range, 'r_range': r_range})\n                    raise n_exc_ext.OverlappingAllocationPools(\n                        pool_1=l_range,\n                        pool_2=r_range,\n                        subnet_cidr=subnet_cidr)", "response": "Validate the IP allocation pools."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding job to neutron context for use later.", "response": "def add_job_to_context(context, job_id):\n    \"\"\"Adds job to neutron context for use later.\"\"\"\n    db_job = db_api.async_transaction_find(\n        context, id=job_id, scope=db_api.ONE)\n    if not db_job:\n        return\n    context.async_job = {\"job\": v._make_job_dict(db_job)}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_job(context, body):\n    LOG.info(\"create_job for tenant %s\" % context.tenant_id)\n\n    if not context.is_admin:\n        raise n_exc.NotAuthorized()\n    job = body.get('job')\n    if 'parent_id' in job:\n        parent_id = job['parent_id']\n        if not parent_id:\n            raise q_exc.JobNotFound(job_id=parent_id)\n        parent_job = db_api.async_transaction_find(\n            context, id=parent_id, scope=db_api.ONE)\n        if not parent_job:\n            raise q_exc.JobNotFound(job_id=parent_id)\n        tid = parent_id\n        if parent_job.get('transaction_id'):\n            tid = parent_job.get('transaction_id')\n        job['transaction_id'] = tid\n\n    if not job:\n        raise n_exc.BadRequest(resource=\"job\", msg=\"Invalid request body.\")\n    with context.session.begin(subtransactions=True):\n        new_job = db_api.async_transaction_create(context, **job)\n    return v._make_job_dict(new_job)", "response": "Creates a job with support for subjobs."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete an ip address.", "response": "def delete_job(context, id, **filters):\n    \"\"\"Delete an ip address.\n\n    : param context: neutron api request context\n    : param id: UUID representing the ip address to delete.\n    \"\"\"\n    LOG.info(\"delete_ip_address %s for tenant %s\" % (id, context.tenant_id))\n\n    if not context.is_admin:\n        raise n_exc.NotAuthorized()\n    with context.session.begin():\n        job = db_api.async_transaction_find(context, id=id, scope=db_api.ONE,\n                                            **filters)\n        if not job:\n            raise q_exc.JobNotFound(job_id=id)\n        db_api.async_transaction_delete(context, job)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _lswitch_select_open(self, context, switches=None, **kwargs):\n\n        if switches is not None:\n            for res in switches[\"results\"]:\n                count = res[\"_relations\"][\"LogicalSwitchStatus\"][\"lport_count\"]\n                if (self.limits['max_ports_per_switch'] == 0 or\n                        count < self.limits['max_ports_per_switch']):\n                    return res[\"uuid\"]\n        return None", "response": "Selects an open lswitch for a network."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_default_tz_bindings(self, context, switch, network_id):\n        default_tz = CONF.NVP.default_tz\n\n        # If there is no default tz specified it's pointless to try\n        # and add any additional default tz bindings.\n        if not default_tz:\n            LOG.warn(\"additional_default_tz_types specified, \"\n                     \"but no default_tz. Skipping \"\n                     \"_add_default_tz_bindings().\")\n            return\n\n        # This should never be called without a neutron network uuid,\n        # we require it to bind some segment allocations.\n        if not network_id:\n            LOG.warn(\"neutron network_id not specified, skipping \"\n                     \"_add_default_tz_bindings()\")\n            return\n\n        for net_type in CONF.NVP.additional_default_tz_types:\n            if net_type in TZ_BINDINGS:\n                binding = TZ_BINDINGS[net_type]\n                binding.add(context, switch, default_tz, network_id)\n            else:\n                LOG.warn(\"Unknown default tz type %s\" % (net_type))", "response": "Configure any additional default transport zone bindings."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_lswitch_ids_for_network(self, context, network_id):\n        lswitches = self._lswitches_for_network(context, network_id).results()\n        return [s['uuid'] for s in lswitches[\"results\"]]", "response": "Public interface for fetching lswitch ids for a given network."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_floating_ip(self, floating_ip, port_fixed_ips):\n        url = CONF.QUARK.floating_ip_base_url\n        timeout = CONF.QUARK.unicorn_api_timeout_seconds\n        req = self._build_request_body(floating_ip, port_fixed_ips)\n\n        try:\n            LOG.info(\"Calling unicorn to register floating ip: %s %s\"\n                     % (url, req))\n            r = requests.post(url, data=json.dumps(req), timeout=timeout)\n        except Exception as e:\n            LOG.error(\"Unhandled Exception caught when trying to register \"\n                      \"floating ip %s with the unicorn API.  Error: %s\"\n                      % (floating_ip.id, e.message))\n            raise ex.RegisterFloatingIpFailure(id=floating_ip.id)\n\n        if r.status_code != 200 and r.status_code != 201:\n            msg = \"Unexpected status from unicorn API: Status Code %s, \" \\\n                  \"Message: %s\" % (r.status_code, r.json())\n            LOG.error(\"register_floating_ip: %s\" % msg)\n            raise ex.RegisterFloatingIpFailure(id=floating_ip.id)", "response": "Register a floating IP with Unicorn."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving a floating ip from Unicorn.", "response": "def remove_floating_ip(self, floating_ip):\n        \"\"\"Register a floating ip with Unicorn\n\n        :param floating_ip: The quark.db.models.IPAddress to remove\n        :return: None\n        \"\"\"\n        url = \"%s/%s\" % (CONF.QUARK.floating_ip_base_url,\n                         floating_ip.address_readable)\n        timeout = CONF.QUARK.unicorn_api_timeout_seconds\n\n        try:\n            LOG.info(\"Calling unicorn to remove floating ip: %s\" % url)\n            r = requests.delete(url, timeout=timeout)\n        except Exception as e:\n            LOG.error(\"Unhandled Exception caught when trying to un-register \"\n                      \"floating ip %s with the unicorn API.  Error: %s\"\n                      % (floating_ip.id, e.message))\n            raise ex.RemoveFloatingIpFailure(id=floating_ip.id)\n\n        if r.status_code == 404:\n            LOG.warn(\"The floating IP %s does not exist in the unicorn system.\"\n                     % floating_ip.address_readable)\n        elif r.status_code != 204:\n            msg = \"Unexpected status from unicorn API: Status Code %s, \" \\\n                  \"Message: %s\" % (r.status_code, r.json())\n            LOG.error(\"remove_floating_ip: %s\" % msg)\n            raise ex.RemoveFloatingIpFailure(id=floating_ip.id)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _load_worker_plugin_with_module(self, module, version):\n        classes = inspect.getmembers(module, inspect.isclass)\n        loaded = 0\n        for cls_name, cls in classes:\n            if hasattr(cls, 'versions'):\n                if version not in cls.versions:\n                    continue\n            else:\n                continue\n            if issubclass(cls, base_worker.QuarkAsyncPluginBase):\n                LOG.debug(\"Loading plugin %s\" % cls_name)\n                plugin = cls()\n                self.plugins.append(plugin)\n                loaded += 1\n        LOG.debug(\"Found %d possible plugins and loaded %d\" %\n                  (len(classes), loaded))", "response": "Loads all worker plugins that have requsite properties."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _discover_via_entrypoints(self):\n        emgr = extension.ExtensionManager(PLUGIN_EP, invoke_on_load=False)\n        return ((ext.name, ext.plugin) for ext in emgr)", "response": "Looks for modules with amtching entry points."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlaunches configured rpc workers.", "response": "def serve_rpc(self):\n        \"\"\"Launches configured # of workers per loaded plugin.\"\"\"\n        if cfg.CONF.QUARK_ASYNC.rpc_workers < 1:\n            cfg.CONF.set_override('rpc_workers', 1, \"QUARK_ASYNC\")\n\n        try:\n            rpc = service.RpcWorker(self.plugins)\n            launcher = common_service.ProcessLauncher(CONF, wait_interval=1.0)\n            launcher.launch_service(rpc, workers=CONF.QUARK_ASYNC.rpc_workers)\n\n            return launcher\n        except Exception:\n            with excutils.save_and_reraise_exception():\n                LOG.exception(_LE('Unrecoverable error: please check log for '\n                                  'details.'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes eventlet and starts wait for workers to exit.", "response": "def start_api_and_rpc_workers(self):\n        \"\"\"Initializes eventlet and starts wait for workers to exit.\n\n        Spawns the workers returned from serve_rpc\n        \"\"\"\n        pool = eventlet.GreenPool()\n\n        quark_rpc = self.serve_rpc()\n        pool.spawn(quark_rpc.wait)\n\n        pool.waitall()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _chunks(self, iterable, chunk_size):\n        iterator = iter(iterable)\n        chunk = list(itertools.islice(iterator, 0, chunk_size))\n        while chunk:\n            yield chunk\n            chunk = list(itertools.islice(iterator, 0, chunk_size))", "response": "Yields data into chunks with size < = chunk_size."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_collisions(self, new_range, existing_ranges):\n        def _contains(num, r1):\n            return (num >= r1[0] and\n                    num <= r1[1])\n\n        def _is_overlap(r1, r2):\n            return (_contains(r1[0], r2) or\n                    _contains(r1[1], r2) or\n                    _contains(r2[0], r1) or\n                    _contains(r2[1], r1))\n\n        for existing_range in existing_ranges:\n            if _is_overlap(new_range, existing_range):\n                return True\n        return False", "response": "Check for overlapping ranges."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _try_allocate(self, context, segment_id, network_id):\n        LOG.info(\"Attempting to allocate segment for network %s \"\n                 \"segment_id %s segment_type %s\"\n                 % (network_id, segment_id, self.segment_type))\n\n        filter_dict = {\n            \"segment_id\": segment_id,\n            \"segment_type\": self.segment_type,\n            \"do_not_use\": False\n        }\n        available_ranges = db_api.segment_allocation_range_find(\n            context, scope=db_api.ALL, **filter_dict)\n        available_range_ids = [r[\"id\"] for r in available_ranges]\n\n        try:\n            with context.session.begin(subtransactions=True):\n                # Search for any deallocated segment ids for the\n                # given segment.\n                filter_dict = {\n                    \"deallocated\": True,\n                    \"segment_id\": segment_id,\n                    \"segment_type\": self.segment_type,\n                    \"segment_allocation_range_ids\": available_range_ids\n                }\n\n                # NOTE(morgabra) We select 100 deallocated segment ids from\n                # the table here, and then choose 1 randomly. This is to help\n                # alleviate the case where an uncaught exception might leave\n                # an allocation active on a remote service but we do not have\n                # a record of it locally. If we *do* end up choosing a\n                # conflicted id, the caller should simply allocate another one\n                # and mark them all as reserved. If a single object has\n                # multiple reservations on the same segment, they will not be\n                # deallocated, and the operator must resolve the conficts\n                # manually.\n                allocations = db_api.segment_allocation_find(\n                    context, lock_mode=True, **filter_dict).limit(100).all()\n\n                if allocations:\n                    allocation = random.choice(allocations)\n\n                    # Allocate the chosen segment.\n                    update_dict = {\n                        \"deallocated\": False,\n                        \"deallocated_at\": None,\n                        \"network_id\": network_id\n                    }\n                    allocation = db_api.segment_allocation_update(\n                        context, allocation, **update_dict)\n                    LOG.info(\"Allocated segment %s for network %s \"\n                             \"segment_id %s segment_type %s\"\n                             % (allocation[\"id\"], network_id, segment_id,\n                                self.segment_type))\n                    return allocation\n        except Exception:\n            LOG.exception(\"Error in segment reallocation.\")\n\n        LOG.info(\"Cannot find reallocatable segment for network %s \"\n                 \"segment_id %s segment_type %s\"\n                 % (network_id, segment_id, self.segment_type))", "response": "Try to allocate a new segment from the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_locks(context, network_ids, addresses):\n    addresses_no_longer_null_routed = _find_addresses_to_be_unlocked(\n        context, network_ids, addresses)\n    LOG.info(\"Deleting %s lock holders on IPAddress with ids: %s\",\n             len(addresses_no_longer_null_routed),\n             [addr.id for addr in addresses_no_longer_null_routed])\n\n    for address in addresses_no_longer_null_routed:\n        lock_holder = None\n        try:\n            lock_holder = db_api.lock_holder_find(\n                context, lock_id=address.lock_id, name=LOCK_NAME,\n                scope=db_api.ONE)\n            if lock_holder:\n                db_api.lock_holder_delete(context, address, lock_holder)\n        except Exception:\n            LOG.exception(\"Failed to delete lock holder %s\", lock_holder)\n            continue\n    context.session.flush()", "response": "Deletes locks for each IP address that is no longer null - routed."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_locks(context, network_ids, addresses):\n\n    for address in addresses:\n        address_model = None\n        try:\n            address_model = _find_or_create_address(\n                context, network_ids, address)\n            lock_holder = None\n            if address_model.lock_id:\n                lock_holder = db_api.lock_holder_find(\n                    context,\n                    lock_id=address_model.lock_id, name=LOCK_NAME,\n                    scope=db_api.ONE)\n\n            if not lock_holder:\n                LOG.info(\"Creating lock holder on IPAddress %s with id %s\",\n                         address_model.address_readable,\n                         address_model.id)\n                db_api.lock_holder_create(\n                    context, address_model, name=LOCK_NAME, type=\"ip_address\")\n        except Exception:\n            LOG.exception(\"Failed to create lock holder on IPAddress %s\",\n                          address_model)\n            continue\n    context.session.flush()", "response": "Creates locks for each IP address that is null - routed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nselecting the appropriate IPAM strategy for the given network.", "response": "def select_ipam_strategy(self, network_id, network_strategy, **kwargs):\n        \"\"\"Return relevant IPAM strategy name.\n\n        :param network_id: neutron network id.\n        :param network_strategy: default strategy for the network.\n\n        NOTE(morgabra) This feels like a hack but I can't think of a better\n        idea. The root problem is we can now attach ports to networks with\n        a different backend driver/ipam strategy than the network speficies.\n\n        We handle the the backend driver part with allowing network_plugin to\n        be specified for port objects. This works pretty well because nova or\n        whatever knows when we are hooking up an Ironic node so it can pass\n        along that key during port_create().\n\n        IPAM is a little trickier, especially in Ironic's case, because we\n        *must* use a specific IPAM for provider networks. There isn't really\n        much of an option other than involve the backend driver when selecting\n        the IPAM strategy.\n        \"\"\"\n        LOG.info(\"Selecting IPAM strategy for network_id:%s \"\n                 \"network_strategy:%s\" % (network_id, network_strategy))\n\n        net_type = \"tenant\"\n        if STRATEGY.is_provider_network(network_id):\n            net_type = \"provider\"\n\n        strategy = self._ipam_strategies.get(net_type, {})\n        default = strategy.get(\"default\")\n        overrides = strategy.get(\"overrides\", {})\n\n        # If we override a particular strategy explicitly, we use it.\n        if network_strategy in overrides:\n            LOG.info(\"Selected overridden IPAM strategy: %s\"\n                     % (overrides[network_strategy]))\n            return overrides[network_strategy]\n\n        # Otherwise, we are free to use an explicit default.\n        if default:\n            LOG.info(\"Selected default IPAM strategy for tenant \"\n                     \"network: %s\" % (default))\n            return default\n\n        # Fallback to the network-specified IPAM strategy\n        LOG.info(\"Selected network strategy for tenant \"\n                 \"network: %s\" % (network_strategy))\n        return network_strategy"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget extra network information.", "response": "def _get_base_network_info(self, context, network_id, base_net_driver):\n        \"\"\"Return a dict of extra network information.\n\n        :param context: neutron request context.\n        :param network_id: neturon network id.\n        :param net_driver: network driver associated with network_id.\n        :raises IronicException: Any unexpected data fetching failures will\n            be logged and IronicException raised.\n\n        This driver can attach to networks managed by other drivers. We may\n        need some information from these drivers, or otherwise inform\n        downstream about the type of network we are attaching to. We can\n        make these decisions here.\n        \"\"\"\n        driver_name = base_net_driver.get_name()\n        net_info = {\"network_type\": driver_name}\n        LOG.debug('_get_base_network_info: %s %s'\n                  % (driver_name, network_id))\n\n        # If the driver is NVP, we need to look up the lswitch id we should\n        # be attaching to.\n        if driver_name == 'NVP':\n            LOG.debug('looking up lswitch ids for network %s'\n                      % (network_id))\n            lswitch_ids = base_net_driver.get_lswitch_ids_for_network(\n                context, network_id)\n\n            if not lswitch_ids or len(lswitch_ids) > 1:\n                msg = ('lswitch id lookup failed, %s ids found.'\n                       % (len(lswitch_ids)))\n                LOG.error(msg)\n                raise IronicException(msg)\n\n            lswitch_id = lswitch_ids.pop()\n            LOG.info('found lswitch for network %s: %s'\n                     % (network_id, lswitch_id))\n            net_info['lswitch_id'] = lswitch_id\n\n        LOG.debug('_get_base_network_info finished: %s %s %s'\n                  % (driver_name, network_id, net_info))\n        return net_info"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_port(self, context, network_id, port_id, **kwargs):\n        LOG.info(\"create_port %s %s %s\" % (context.tenant_id, network_id,\n                                           port_id))\n\n        # sanity check\n        if not kwargs.get('base_net_driver'):\n            raise IronicException(msg='base_net_driver required.')\n        base_net_driver = kwargs['base_net_driver']\n\n        if not kwargs.get('device_id'):\n            raise IronicException(msg='device_id required.')\n        device_id = kwargs['device_id']\n\n        if not kwargs.get('instance_node_id'):\n            raise IronicException(msg='instance_node_id required.')\n        instance_node_id = kwargs['instance_node_id']\n\n        if not kwargs.get('mac_address'):\n            raise IronicException(msg='mac_address is required.')\n        mac_address = str(netaddr.EUI(kwargs[\"mac_address\"][\"address\"]))\n        mac_address = mac_address.replace('-', ':')\n\n        # TODO(morgabra): Change this when we enable security groups.\n        if kwargs.get('security_groups'):\n            msg = 'ironic driver does not support security group operations.'\n            raise IronicException(msg=msg)\n\n        # unroll the given address models into a fixed_ips list we can\n        # pass downstream\n        fixed_ips = []\n        addresses = kwargs.get('addresses')\n        if not isinstance(addresses, list):\n            addresses = [addresses]\n        for address in addresses:\n            fixed_ips.append(self._make_fixed_ip_dict(context, address))\n\n        body = {\n            \"id\": port_id,\n            \"network_id\": network_id,\n            \"device_id\": device_id,\n            \"device_owner\": kwargs.get('device_owner', ''),\n            \"tenant_id\": context.tenant_id or \"quark\",\n            \"roles\": context.roles,\n            \"mac_address\": mac_address,\n            \"fixed_ips\": fixed_ips,\n            \"switch:hardware_id\": instance_node_id,\n            \"dynamic_network\": not STRATEGY.is_provider_network(network_id)\n        }\n\n        net_info = self._get_base_network_info(\n            context, network_id, base_net_driver)\n        body.update(net_info)\n\n        try:\n            LOG.info(\"creating downstream port: %s\" % (body))\n            port = self._create_port(context, body)\n            LOG.info(\"created downstream port: %s\" % (port))\n            return {\"uuid\": port['port']['id'],\n                    \"vlan_id\": port['port']['vlan_id']}\n        except Exception as e:\n            msg = \"failed to create downstream port. Exception: %s\" % (e)\n            raise IronicException(msg=msg)", "response": "Create a port in a network."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates a port. :param context: neutron api request context. :param port_id: neutron port id. :param kwargs: optional kwargs. :raises IronicException: If the client is unable to update the downstream port for any reason, the exception will be logged and IronicException raised. TODO(morgabra) It does not really make sense in the context of Ironic to allow updating ports. fixed_ips and mac_address are burned in the configdrive on the host, and we otherwise cannot migrate a port between instances. Eventually we will need to support security groups, but for now it's a no-op on port data changes, and we need to rely on the API/Nova to not allow updating data on active ports.", "response": "def update_port(self, context, port_id, **kwargs):\n        \"\"\"Update a port.\n\n        :param context: neutron api request context.\n        :param port_id: neutron port id.\n        :param kwargs: optional kwargs.\n        :raises IronicException: If the client is unable to update the\n            downstream port for any reason, the exception will be logged\n            and IronicException raised.\n\n        TODO(morgabra) It does not really make sense in the context of Ironic\n        to allow updating ports. fixed_ips and mac_address are burned in the\n        configdrive on the host, and we otherwise cannot migrate a port between\n        instances. Eventually we will need to support security groups, but for\n        now it's a no-op on port data changes, and we need to rely on the\n        API/Nova to not allow updating data on active ports.\n        \"\"\"\n        LOG.info(\"update_port %s %s\" % (context.tenant_id, port_id))\n\n        # TODO(morgabra): Change this when we enable security groups.\n        if kwargs.get(\"security_groups\"):\n            msg = 'ironic driver does not support security group operations.'\n            raise IronicException(msg=msg)\n\n        return {\"uuid\": port_id}"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes a port. :param context: neutron api request context. :param port_id: neutron port id. :param kwargs: optional kwargs. :raises IronicException: If the client is unable to delete the downstream port for any reason, the exception will be logged and IronicException raised.", "response": "def delete_port(self, context, port_id, **kwargs):\n        \"\"\"Delete a port.\n\n        :param context: neutron api request context.\n        :param port_id: neutron port id.\n        :param kwargs: optional kwargs.\n        :raises IronicException: If the client is unable to delete the\n            downstream port for any reason, the exception will be logged\n            and IronicException raised.\n        \"\"\"\n        LOG.info(\"delete_port %s %s\" % (context.tenant_id, port_id))\n        try:\n            self._delete_port(context, port_id)\n            LOG.info(\"deleted downstream port: %s\" % (port_id))\n        except Exception:\n            LOG.error(\"failed deleting downstream port, it is now \"\n                      \"orphaned! port_id: %s\" % (port_id))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndiagnoses a port. :param context: neutron api request context. :param port_id: neutron port id. :param kwargs: optional kwargs. :raises IronicException: If the client is unable to fetch the downstream port for any reason, the exception will be logged and IronicException raised.", "response": "def diag_port(self, context, port_id, **kwargs):\n        \"\"\"Diagnose a port.\n\n        :param context: neutron api request context.\n        :param port_id: neutron port id.\n        :param kwargs: optional kwargs.\n        :raises IronicException: If the client is unable to fetch the\n            downstream port for any reason, the exception will be\n            logged and IronicException raised.\n        \"\"\"\n        LOG.info(\"diag_port %s\" % port_id)\n        try:\n            port = self._client.show_port(port_id)\n        except Exception as e:\n            msg = \"failed fetching downstream port: %s\" % (str(e))\n            LOG.exception(msg)\n            raise IronicException(msg=msg)\n        return {\"downstream_port\": port}"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the tag on the given model object.", "response": "def set(self, model, value):\n        \"\"\"Set tag on model object.\"\"\"\n        self.validate(value)\n        self._pop(model)\n        value = self.serialize(value)\n        model.tags.append(value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, model):\n        for tag in model.tags:\n            if self.is_tag(tag):\n                value = self.deserialize(tag)\n                try:\n                    self.validate(value)\n                    return value\n                except TagValidationError:\n                    continue\n        return None", "response": "Get a matching valid tag off the model."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npop all matching tags off the model and return them.", "response": "def _pop(self, model):\n        \"\"\"Pop all matching tags off the model and return them.\"\"\"\n        tags = []\n\n        # collect any exsiting tags with matching prefix\n        for tag in model.tags:\n            if self.is_tag(tag):\n                tags.append(tag)\n\n        # remove collected tags from model\n        if tags:\n            for tag in tags:\n                model.tags.remove(tag)\n\n        return tags"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pop(self, model):\n        tags = self._pop(model)\n        if tags:\n            for tag in tags:\n                value = self.deserialize(tag)\n                try:\n                    self.validate(value)\n                    return value\n                except TagValidationError:\n                    continue", "response": "Pop all matching tags off the port return a valid one."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndoing the given port have this tag?", "response": "def has_tag(self, model):\n        \"\"\"Does the given port have this tag?\"\"\"\n        for tag in model.tags:\n            if self.is_tag(tag):\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates a VLAN ID.", "response": "def validate(self, value):\n        \"\"\"Validates a VLAN ID.\n\n        :param value: The VLAN ID to validate against.\n        :raises TagValidationError: Raised if the VLAN ID is invalid.\n        \"\"\"\n        try:\n            vlan_id_int = int(value)\n            assert vlan_id_int >= self.MIN_VLAN_ID\n            assert vlan_id_int <= self.MAX_VLAN_ID\n        except Exception:\n            msg = (\"Invalid vlan_id. Got '%(vlan_id)s'. \"\n                   \"vlan_id should be an integer between %(min)d and %(max)d \"\n                   \"inclusive.\" % {'vlan_id': value,\n                                   'min': self.MIN_VLAN_ID,\n                                   'max': self.MAX_VLAN_ID})\n            raise TagValidationError(value, msg)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_all(self, model):\n        tags = {}\n        for name, tag in self.tags.items():\n            for mtag in model.tags:\n                if tag.is_tag(mtag):\n                    tags[name] = tag.get(model)\n        return tags", "response": "Get all known tags from a model."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate and set all known tags on a port.", "response": "def set_all(self, model, **tags):\n        \"\"\"Validate and set all known tags on a port.\"\"\"\n        for name, tag in self.tags.items():\n            if name in tags:\n                value = tags.pop(name)\n                if value:\n                    try:\n                        tag.set(model, value)\n                    except TagValidationError as e:\n                        raise n_exc.BadRequest(\n                            resource=\"tags\",\n                            msg=\"%s\" % (e.message))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef serialize_rules(self, rules):\n        # TODO(mdietz): If/when we support other rule types, this comment\n        #               will have to be revised.\n        # Action and direction are static, for now. The implementation may\n        # support 'deny' and 'egress' respectively in the future. We allow\n        # the direction to be set to something else, technically, but current\n        # plugin level call actually raises. It's supported here for unit\n        # test purposes at this time\n        serialized = []\n        for rule in rules:\n            direction = rule[\"direction\"]\n            source = ''\n            destination = ''\n            if rule.get(\"remote_ip_prefix\"):\n                prefix = rule[\"remote_ip_prefix\"]\n                if direction == \"ingress\":\n                    source = self._convert_remote_network(prefix)\n                else:\n                    if (Capabilities.EGRESS not in\n                            CONF.QUARK.environment_capabilities):\n                        raise q_exc.EgressSecurityGroupRulesNotEnabled()\n                    else:\n                        destination = self._convert_remote_network(prefix)\n\n            optional_fields = {}\n\n            # NOTE(mdietz): this will expand as we add more protocols\n            protocol_map = protocols.PROTOCOL_MAP[rule[\"ethertype\"]]\n            if rule[\"protocol\"] == protocol_map[\"icmp\"]:\n                optional_fields[\"icmp type\"] = rule[\"port_range_min\"]\n                optional_fields[\"icmp code\"] = rule[\"port_range_max\"]\n            else:\n                optional_fields[\"port start\"] = rule[\"port_range_min\"]\n                optional_fields[\"port end\"] = rule[\"port_range_max\"]\n\n            payload = {\"ethertype\": rule[\"ethertype\"],\n                       \"protocol\": rule[\"protocol\"],\n                       \"source network\": source,\n                       \"destination network\": destination,\n                       \"action\": \"allow\",\n                       \"direction\": direction}\n            payload.update(optional_fields)\n            serialized.append(payload)\n        return serialized", "response": "Creates a payload for the redis server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef serialize_groups(self, groups):\n        rules = []\n        for group in groups:\n            rules.extend(self.serialize_rules(group.rules))\n        return rules", "response": "Returns a JSON representation of the given set of security groups."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites a series of security group rules to a redis server.", "response": "def apply_rules(self, device_id, mac_address, rules):\n        \"\"\"Writes a series of security group rules to a redis server.\"\"\"\n        LOG.info(\"Applying security group rules for device %s with MAC %s\" %\n                 (device_id, mac_address))\n\n        rule_dict = {SECURITY_GROUP_RULE_KEY: rules}\n        redis_key = self.vif_key(device_id, mac_address)\n        # TODO(mdietz): Pipeline these. Requires some rewriting\n        self.set_field(redis_key, SECURITY_GROUP_HASH_ATTR, rule_dict)\n        self.set_field_raw(redis_key, SECURITY_GROUP_ACK, False)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_security_group_states(self, interfaces):\n        LOG.debug(\"Getting security groups from Redis for {0}\".format(\n            interfaces))\n        interfaces = tuple(interfaces)\n        vif_keys = [self.vif_key(vif.device_id, vif.mac_address)\n                    for vif in interfaces]\n\n        # Retrieve all fields associated with this key, which should be\n        # 'security groups ack' and 'security group rules'.\n        sec_grp_all = self.get_fields_all(vif_keys)\n\n        ret = {}\n        # Associate the vif with the fields in a dictionary\n        for vif, group in zip(interfaces, sec_grp_all):\n            if group:\n                ret[vif] = {SECURITY_GROUP_ACK: None,\n                            SECURITY_GROUP_HASH_ATTR: []}\n                temp_ack = group[SECURITY_GROUP_ACK].lower()\n                temp_rules = group[SECURITY_GROUP_HASH_ATTR]\n                if temp_rules:\n                    temp_rules = json.loads(temp_rules)\n                    ret[vif][SECURITY_GROUP_HASH_ATTR] = temp_rules[\"rules\"]\n                if \"true\" in temp_ack:\n                    ret[vif][SECURITY_GROUP_ACK] = True\n                elif \"false\" in temp_ack:\n                    ret[vif][SECURITY_GROUP_ACK] = False\n                else:\n                    ret.pop(vif, None)\n                    LOG.debug(\"Skipping bad ack value %s\" % temp_ack)\n\n        return ret", "response": "Get the state of the security group for the given interfaces from Redis."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the ack field of the security groups by setting the ack field of the security groups.", "response": "def update_group_states_for_vifs(self, vifs, ack):\n        \"\"\"Updates security groups by setting the ack field\"\"\"\n        vif_keys = [self.vif_key(vif.device_id, vif.mac_address)\n                    for vif in vifs]\n        self.set_fields(vif_keys, SECURITY_GROUP_ACK, ack)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_migrations_offline():\n    context.configure(url=neutron_config.database.connection)\n\n    with context.begin_transaction():\n        context.run_migrations()", "response": "Run migrations in offline mode."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning migrations in online mode.", "response": "def run_migrations_online():\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n\n    \"\"\"\n    engine = create_engine(\n        neutron_config.database.connection,\n        poolclass=pool.NullPool)\n\n    connection = engine.connect()\n    context.configure(\n        connection=connection,\n        target_metadata=target_metadata)\n\n    try:\n        with context.begin_transaction():\n            context.run_migrations()\n    finally:\n        connection.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_payload(ipaddress,\n                  event_type,\n                  event_time=None,\n                  start_time=None,\n                  end_time=None):\n    \"\"\"Method builds a payload out of the passed arguments.\n\n    Parameters:\n        `ipaddress`: the models.IPAddress object\n        `event_type`: USAGE,CREATE,DELETE,SUSPEND,or UNSUSPEND\n        `start_time`: startTime for cloudfeeds\n        `end_time`: endTime for cloudfeeds\n    Returns a dictionary suitable to notify billing.\n    Message types mapping to cloud feeds for references:\n        ip.exists       - USAGE\n        ip.add          - CREATE\n        ip.delete       - DELETE\n        ip.associate    - UP\n        ip.disassociate  - DOWN\n    Refer to: http://rax.io/cf-api for more details.\n    \"\"\"\n    # This is the common part of all message types\n    payload = {\n        'event_type': unicode(event_type),\n        'tenant_id': unicode(ipaddress.used_by_tenant_id),\n        'ip_address': unicode(ipaddress.address_readable),\n        'ip_version': int(ipaddress.version),\n        'ip_type': unicode(ipaddress.address_type),\n        'id': unicode(ipaddress.id)\n    }\n\n    # Depending on the message type add the appropriate fields\n    if event_type == IP_EXISTS:\n        if start_time is None or end_time is None:\n            raise ValueError('IP_BILL: {} start_time/end_time cannot be empty'\n                             .format(event_type))\n        payload.update({\n            'startTime': unicode(convert_timestamp(start_time)),\n            'endTime': unicode(convert_timestamp(end_time))\n        })\n    elif event_type in [IP_ADD, IP_DEL, IP_ASSOC, IP_DISASSOC]:\n        if event_time is None:\n            raise ValueError('IP_BILL: {}: event_time cannot be NULL'\n                             .format(event_type))\n        payload.update({\n            'eventTime': unicode(convert_timestamp(event_time)),\n            'subnet_id': unicode(ipaddress.subnet_id),\n            'network_id': unicode(ipaddress.network_id),\n            'public': True if ipaddress.network_id == PUBLIC_NETWORK_ID\n            else False,\n        })\n    else:\n        raise ValueError('IP_BILL: bad event_type: {}'.format(event_type))\n\n    return payload", "response": "Method builds a payload for the passed IP object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_full_day_ips(query, period_start, period_end):\n    # Filter out only IPv4 that have not been deallocated\n    ip_list = query.\\\n        filter(models.IPAddress.version == 4L).\\\n        filter(models.IPAddress.network_id == PUBLIC_NETWORK_ID).\\\n        filter(models.IPAddress.used_by_tenant_id is not None).\\\n        filter(models.IPAddress.allocated_at != null()).\\\n        filter(models.IPAddress.allocated_at < period_start).\\\n        filter(or_(models.IPAddress._deallocated is False,\n                   models.IPAddress.deallocated_at == null(),\n                   models.IPAddress.deallocated_at >= period_end)).all()\n\n    return ip_list", "response": "Method to build a full day IP list for the case 1 where the IP was allocated before the period start and the IP is still allocated after the period end."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef calc_periods(hour=0, minute=0):\n    # Calculate the time intervals in a usable form\n    period_end = datetime.datetime.utcnow().replace(hour=hour,\n                                                    minute=minute,\n                                                    second=0,\n                                                    microsecond=0)\n    period_start = period_end - datetime.timedelta(days=1)\n\n    # period end should be slightly before the midnight.\n    # hence, we subtract a second\n    # this will force period_end to store something like:\n    # datetime.datetime(2016, 5, 19, 23, 59, 59, 999999)\n    # instead of:\n    # datetime.datetime(2016, 5, 20,  0,  0,  0,      0)\n    period_end -= datetime.timedelta(seconds=1)\n\n    return (period_start, period_end)", "response": "Calculates the start and end time intervals for a given time interval."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates the view for a job while calculating progress.", "response": "def _make_job_dict(job):\n    \"\"\"Creates the view for a job while calculating progress.\n\n    Since a root job does not have a transaction id (TID) it will return its\n    id as the TID.\n    \"\"\"\n    body = {\"id\": job.get('id'),\n            \"action\": job.get('action'),\n            \"completed\": job.get('completed'),\n            \"tenant_id\": job.get('tenant_id'),\n            \"created_at\": job.get('created_at'),\n            \"transaction_id\": job.get('transaction_id'),\n            \"parent_id\": job.get('parent_id', None)}\n    if not body['transaction_id']:\n        body['transaction_id'] = job.get('id')\n    completed = 0\n    for sub in job.subtransactions:\n        if sub.get('completed'):\n            completed += 1\n    pct = 100 if job.get('completed') else 0\n    if len(job.subtransactions) > 0:\n        pct = float(completed) / len(job.subtransactions) * 100.0\n    body['transaction_percent'] = int(pct)\n    body['completed_subtransactions'] = completed\n    body['subtransactions'] = len(job.subtransactions)\n    return body"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_mac_address_range(context, id, fields=None):\n    LOG.info(\"get_mac_address_range %s for tenant %s fields %s\" %\n             (id, context.tenant_id, fields))\n\n    if not context.is_admin:\n        raise n_exc.NotAuthorized()\n\n    mac_address_range = db_api.mac_address_range_find(\n        context, id=id, scope=db_api.ONE)\n\n    if not mac_address_range:\n        raise q_exc.MacAddressRangeNotFound(\n            mac_address_range_id=id)\n    return v._make_mac_range_dict(mac_address_range)", "response": "Get a mac_address_range for a network."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes a mac_address_range. : param context: neutron api request context : param id: UUID representing the mac_address_range to delete.", "response": "def delete_mac_address_range(context, id):\n    \"\"\"Delete a mac_address_range.\n\n    : param context: neutron api request context\n    : param id: UUID representing the mac_address_range to delete.\n    \"\"\"\n    LOG.info(\"delete_mac_address_range %s for tenant %s\" %\n             (id, context.tenant_id))\n    if not context.is_admin:\n        raise n_exc.NotAuthorized()\n\n    with context.session.begin():\n        mar = db_api.mac_address_range_find(context, id=id, scope=db_api.ONE)\n        if not mar:\n            raise q_exc.MacAddressRangeNotFound(\n                mac_address_range_id=id)\n        _delete_mac_address_range(context, mar)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef downgrade():\n    with op.batch_alter_table(t2_name) as batch_op:\n        batch_op.drop_column('do_not_use')\n\n    with op.batch_alter_table(t1_name) as batch_op:\n        batch_op.drop_column('enabled')", "response": "downgrade the tables to the original state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting a segment_allocation_range. : param context: neutron api request context : param id: UUID representing the segment_allocation_range to delete.", "response": "def delete_segment_allocation_range(context, sa_id):\n    \"\"\"Delete a segment_allocation_range.\n\n    : param context: neutron api request context\n    : param id: UUID representing the segment_allocation_range to delete.\n    \"\"\"\n    LOG.info(\"delete_segment_allocation_range %s for tenant %s\" %\n             (sa_id, context.tenant_id))\n    if not context.is_admin:\n        raise n_exc.NotAuthorized()\n\n    with context.session.begin():\n        sa_range = db_api.segment_allocation_range_find(\n            context, id=sa_id, scope=db_api.ONE)\n        if not sa_range:\n            raise q_exc.SegmentAllocationRangeNotFound(\n                segment_allocation_range_id=sa_id)\n        _delete_segment_allocation_range(context, sa_range)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter_factory(global_conf, **local_conf):\n    conf = global_conf.copy()\n    conf.update(local_conf)\n\n    def wrapper(app):\n        return ResponseAsyncIdAdder(app, conf)\n\n    return wrapper", "response": "Returns a WSGI filter app for use with paste. deploy."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the list of all used IPs in the current network.", "response": "def get_used_ips(session, **kwargs):\n    \"\"\"Returns dictionary with keys segment_id and value used IPs count.\n\n    Used IP address count is determined by:\n    - allocated IPs\n    - deallocated IPs whose `deallocated_at` is within the `reuse_after`\n    window compared to the present time, excluding IPs that are accounted for\n    in the current IP policy (because IP policy is mutable and deallocated IPs\n    are not checked nor deleted on IP policy creation, thus deallocated IPs\n    that don't fit the current IP policy can exist in the neutron database).\n    \"\"\"\n    LOG.debug(\"Getting used IPs...\")\n    with session.begin():\n        query = session.query(\n            models.Subnet.segment_id,\n            func.count(models.IPAddress.address))\n        query = query.group_by(models.Subnet.segment_id)\n        query = _filter(query, **kwargs)\n\n        reuse_window = timeutils.utcnow() - datetime.timedelta(\n            seconds=cfg.CONF.QUARK.ipam_reuse_after)\n        # NOTE(asadoughi): This is an outer join instead of a regular join\n        # to include subnets with zero IP addresses in the database.\n        query = query.outerjoin(\n            models.IPAddress,\n            and_(models.Subnet.id == models.IPAddress.subnet_id,\n                 or_(not_(models.IPAddress.lock_id.is_(None)),\n                     models.IPAddress._deallocated.is_(None),\n                     models.IPAddress._deallocated == 0,\n                     models.IPAddress.deallocated_at > reuse_window)))\n\n        query = query.outerjoin(\n            models.IPPolicyCIDR,\n            and_(\n                models.Subnet.ip_policy_id == models.IPPolicyCIDR.ip_policy_id,\n                models.IPAddress.address >= models.IPPolicyCIDR.first_ip,\n                models.IPAddress.address <= models.IPPolicyCIDR.last_ip))\n        # NOTE(asadoughi): (address is allocated) OR\n        # (address is deallocated and not inside subnet's IP policy)\n        query = query.filter(or_(\n            models.IPAddress._deallocated.is_(None),\n            models.IPAddress._deallocated == 0,\n            models.IPPolicyCIDR.id.is_(None)))\n\n        ret = ((segment_id, address_count)\n               for segment_id, address_count in query.all())\n        return dict(ret)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_unused_ips(session, used_ips_counts, **kwargs):\n    LOG.debug(\"Getting unused IPs...\")\n    with session.begin():\n        query = session.query(\n            models.Subnet.segment_id,\n            models.Subnet)\n        query = _filter(query, **kwargs)\n        query = query.group_by(models.Subnet.segment_id, models.Subnet.id)\n\n        ret = defaultdict(int)\n        for segment_id, subnet in query.all():\n            net_size = netaddr.IPNetwork(subnet._cidr).size\n            ip_policy = subnet[\"ip_policy\"] or {\"size\": 0}\n            ret[segment_id] += net_size - ip_policy[\"size\"]\n\n        for segment_id in used_ips_counts:\n            ret[segment_id] -= used_ips_counts[segment_id]\n\n        return ret", "response": "Returns a dictionary with key segment_id and value unused IP address count."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dict of VM OpaqueRef ( str ) -> xapi. VM.", "response": "def get_instances(self, session):\n        \"\"\"Returns a dict of `VM OpaqueRef` (str) -> `xapi.VM`.\"\"\"\n        LOG.debug(\"Getting instances from Xapi\")\n\n        recs = session.xenapi.VM.get_all_records()\n\n        # NOTE(asadoughi): Copied from xen-networking-scripts/utils.py\n        is_inst = lambda r: (r['power_state'].lower() == 'running' and\n                             not r['is_a_template'] and\n                             not r['is_control_domain'] and\n                             ('nova_uuid' in r['other_config'] or\n                              r['name_label'].startswith('instance-')))\n        instances = dict()\n        for vm_ref, rec in recs.iteritems():\n            if not is_inst(rec):\n                continue\n            instances[vm_ref] = VM(ref=vm_ref,\n                                   uuid=rec[\"other_config\"][\"nova_uuid\"],\n                                   vifs=rec[\"VIFs\"],\n                                   dom_id=rec[\"domid\"])\n        return instances"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_interfaces(self):\n        LOG.debug(\"Getting interfaces from Xapi\")\n\n        with self.sessioned() as session:\n            instances = self.get_instances(session)\n            recs = session.xenapi.VIF.get_all_records()\n\n        interfaces = set()\n        for vif_ref, rec in recs.iteritems():\n            vm = instances.get(rec[\"VM\"])\n            if not vm:\n                continue\n            device_id = vm.uuid\n            interfaces.add(VIF(device_id, rec, vif_ref))\n        return interfaces", "response": "Returns a set of VIFs from get_instances return value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the set of security groups on the specified interfaces.", "response": "def update_interfaces(self, added_sg, updated_sg, removed_sg):\n        \"\"\"Handles changes to interfaces' security groups\n\n        Calls refresh_interfaces on argument VIFs. Set security groups on\n        added_sg's VIFs. Unsets security groups on removed_sg's VIFs.\n        \"\"\"\n        if not (added_sg or updated_sg or removed_sg):\n            return\n\n        with self.sessioned() as session:\n            self._set_security_groups(session, added_sg)\n            self._unset_security_groups(session, removed_sg)\n            combined = added_sg + updated_sg + removed_sg\n            self._refresh_interfaces(session, combined)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a network which represents an L2 network segment which can be used to create a set of subnets and ports associated with it.", "response": "def create_network(context, network):\n    \"\"\"Create a network.\n\n    Create a network which represents an L2 network segment which\n    can have a set of subnets and ports associated with it.\n    : param context: neutron api request context\n    : param network: dictionary describing the network, with keys\n        as listed in the RESOURCE_ATTRIBUTE_MAP object in\n        neutron/api/v2/attributes.py.  All keys will be populated.\n    \"\"\"\n    LOG.info(\"create_network for tenant %s\" % context.tenant_id)\n\n    with context.session.begin():\n        net_attrs = network[\"network\"]\n        subs = net_attrs.pop(\"subnets\", [])\n        # Enforce subnet quotas\n        if not context.is_admin:\n            if len(subs) > 0:\n                v4_count, v6_count = 0, 0\n                for s in subs:\n                    version = netaddr.IPNetwork(s['subnet']['cidr']).version\n                    if version == 6:\n                        v6_count += 1\n                    else:\n                        v4_count += 1\n                if v4_count > 0:\n                    tenant_q_v4 = context.session.query(qdv.Quota).filter_by(\n                        tenant_id=context.tenant_id,\n                        resource='v4_subnets_per_network').first()\n                    if tenant_q_v4 != -1:\n                        quota.QUOTAS.limit_check(\n                            context,\n                            context.tenant_id,\n                            v4_subnets_per_network=v4_count)\n                if v6_count > 0:\n                    tenant_q_v6 = context.session.query(qdv.Quota).filter_by(\n                        tenant_id=context.tenant_id,\n                        resource='v6_subnets_per_network').first()\n                    if tenant_q_v6 != -1:\n                        quota.QUOTAS.limit_check(\n                            context,\n                            context.tenant_id,\n                            v6_subnets_per_network=v6_count)\n        # Generate a uuid that we're going to hand to the backend and db\n        net_uuid = utils.pop_param(net_attrs, \"id\", None)\n        net_type = None\n        if net_uuid and context.is_admin:\n            net = db_api.network_find(context=context, limit=None,\n                                      sorts=['id'], marker=None,\n                                      page_reverse=False, id=net_uuid,\n                                      scope=db_api.ONE)\n            net_type = utils.pop_param(net_attrs, \"network_plugin\", None)\n            if net:\n                raise q_exc.NetworkAlreadyExists(id=net_uuid)\n        else:\n            net_uuid = uuidutils.generate_uuid()\n\n        # TODO(mdietz) this will be the first component registry hook, but\n        #             lets make it work first\n        pnet_type, phys_net, seg_id = _adapt_provider_nets(context, network)\n\n        ipam_strategy = utils.pop_param(net_attrs, \"ipam_strategy\", None)\n        if not ipam_strategy or not context.is_admin:\n            ipam_strategy = CONF.QUARK.default_ipam_strategy\n\n        if not ipam.IPAM_REGISTRY.is_valid_strategy(ipam_strategy):\n            raise q_exc.InvalidIpamStrategy(strat=ipam_strategy)\n        net_attrs[\"ipam_strategy\"] = ipam_strategy\n\n        # NOTE(mdietz) I think ideally we would create the providernet\n        # elsewhere as a separate driver step that could be\n        # kept in a plugin and completely removed if desired. We could\n        # have a pre-callback/observer on the netdriver create_network\n        # that gathers any additional parameters from the network dict\n\n        default_net_type = net_type or CONF.QUARK.default_network_type\n        net_driver = registry.DRIVER_REGISTRY.get_driver(default_net_type)\n        net_driver.create_network(context, net_attrs[\"name\"],\n                                  network_id=net_uuid, phys_type=pnet_type,\n                                  phys_net=phys_net, segment_id=seg_id)\n\n        net_attrs[\"id\"] = net_uuid\n        net_attrs[\"tenant_id\"] = context.tenant_id\n        net_attrs[\"network_plugin\"] = default_net_type\n        new_net = db_api.network_create(context, **net_attrs)\n\n        new_subnets = []\n        for sub in subs:\n            sub[\"subnet\"][\"network_id\"] = new_net[\"id\"]\n            sub[\"subnet\"][\"tenant_id\"] = context.tenant_id\n            s = db_api.subnet_create(context, **sub[\"subnet\"])\n            new_subnets.append(s)\n        new_net[\"subnets\"] = new_subnets\n\n        # if not security_groups.get_security_groups(\n        #        context,\n        #        filters={\"id\": security_groups.DEFAULT_SG_UUID}):\n        #    security_groups._create_default_security_group(context)\n    return v._make_network_dict(new_net)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the values of a network.", "response": "def update_network(context, id, network):\n    \"\"\"Update values of a network.\n\n    : param context: neutron api request context\n    : param id: UUID representing the network to update.\n    : param network: dictionary with keys indicating fields to update.\n        valid keys are those that have a value of True for 'allow_put'\n        as listed in the RESOURCE_ATTRIBUTE_MAP object in\n        neutron/api/v2/attributes.py.\n    \"\"\"\n    LOG.info(\"update_network %s for tenant %s\" %\n             (id, context.tenant_id))\n    with context.session.begin():\n        net = db_api.network_find(context, id=id, scope=db_api.ONE)\n        if not net:\n            raise n_exc.NetworkNotFound(net_id=id)\n        net_dict = network[\"network\"]\n        utils.pop_param(net_dict, \"network_plugin\")\n        if not context.is_admin and \"ipam_strategy\" in net_dict:\n            utils.pop_param(net_dict, \"ipam_strategy\")\n        net = db_api.network_update(context, net, **net_dict)\n\n    return v._make_network_dict(net)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves a network. : param context: neutron api request context : param id: UUID representing the network to fetch. : param fields: a list of strings that are valid keys in a network dictionary as listed in the RESOURCE_ATTRIBUTE_MAP object in neutron/api/v2/attributes.py. Only these fields will be returned.", "response": "def get_network(context, id, fields=None):\n    \"\"\"Retrieve a network.\n\n    : param context: neutron api request context\n    : param id: UUID representing the network to fetch.\n    : param fields: a list of strings that are valid keys in a\n        network dictionary as listed in the RESOURCE_ATTRIBUTE_MAP\n        object in neutron/api/v2/attributes.py. Only these fields\n        will be returned.\n    \"\"\"\n    LOG.info(\"get_network %s for tenant %s fields %s\" %\n             (id, context.tenant_id, fields))\n\n    network = db_api.network_find(context=context, limit=None, sorts=['id'],\n                                  marker=None, page_reverse=False,\n                                  id=id, join_subnets=True, scope=db_api.ONE)\n    if not network:\n        raise n_exc.NetworkNotFound(net_id=id)\n    return v._make_network_dict(network, fields=fields)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve a list of networks for the user in the tenant.", "response": "def get_networks(context, limit=None, sorts=['id'], marker=None,\n                 page_reverse=False, filters=None, fields=None):\n    \"\"\"Retrieve a list of networks.\n\n    The contents of the list depends on the identity of the user\n    making the request (as indicated by the context) as well as any\n    filters.\n    : param context: neutron api request context\n    : param filters: a dictionary with keys that are valid keys for\n        a network as listed in the RESOURCE_ATTRIBUTE_MAP object\n        in neutron/api/v2/attributes.py.  Values in this dictiontary\n        are an iterable containing values that will be used for an exact\n        match comparison for that value.  Each result returned by this\n        function will have matched one of the values for each key in\n        filters.\n    : param fields: a list of strings that are valid keys in a\n        network dictionary as listed in the RESOURCE_ATTRIBUTE_MAP\n        object in neutron/api/v2/attributes.py. Only these fields\n        will be returned.\n    \"\"\"\n    LOG.info(\"get_networks for tenant %s with filters %s, fields %s\" %\n             (context.tenant_id, filters, fields))\n    filters = filters or {}\n    nets = db_api.network_find(context, limit, sorts, marker, page_reverse,\n                               join_subnets=True, **filters) or []\n    nets = [v._make_network_dict(net, fields=fields) for net in nets]\n    return nets"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_networks_count(context, filters=None):\n    LOG.info(\"get_networks_count for tenant %s filters %s\" %\n             (context.tenant_id, filters))\n    return db_api.network_count_all(context)", "response": "Return the number of networks in the current tenant."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting a network. : param context: neutron api request context : param id: UUID representing the network to delete.", "response": "def delete_network(context, id):\n    \"\"\"Delete a network.\n\n    : param context: neutron api request context\n    : param id: UUID representing the network to delete.\n    \"\"\"\n    LOG.info(\"delete_network %s for tenant %s\" % (id, context.tenant_id))\n    with context.session.begin():\n        net = db_api.network_find(context=context, limit=None, sorts=['id'],\n                                  marker=None, page_reverse=False, id=id,\n                                  scope=db_api.ONE)\n        if not net:\n            raise n_exc.NetworkNotFound(net_id=id)\n        if not context.is_admin:\n            if STRATEGY.is_provider_network(net.id):\n                raise n_exc.NotAuthorized(net_id=id)\n        if net.ports:\n            raise n_exc.NetworkInUse(net_id=id)\n        net_driver = registry.DRIVER_REGISTRY.get_driver(net[\"network_plugin\"])\n        net_driver.delete_network(context, id)\n        for subnet in net[\"subnets\"]:\n            subnets._delete_subnet(context, subnet)\n        db_api.network_delete(context, net)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_case2(context):\n    query = context.session.query(models.IPAddress)\n    period_start, period_end = billing.calc_periods()\n    ip_list = billing.build_full_day_ips(query, period_start, period_end)\n    import random\n    ind = random.randint(0, len(ip_list) - 1)\n    address = ip_list[ind]\n    address.allocated_at = datetime.datetime.utcnow() -\\\n        datetime.timedelta(days=1)\n    context.session.add(address)\n    context.session.flush()", "response": "This method is a helper method for testing. It will create a case 2 entry in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns the billing report. Optionally sends notifications to billing", "response": "def main(notify, hour, minute):\n    \"\"\"Runs billing report. Optionally sends notifications to billing\"\"\"\n\n    # Read the config file and get the admin context\n    config_opts = ['--config-file', '/etc/neutron/neutron.conf']\n    config.init(config_opts)\n    # Have to load the billing module _after_ config is parsed so\n    # that we get the right network strategy\n    network_strategy.STRATEGY.load()\n    billing.PUBLIC_NETWORK_ID = network_strategy.STRATEGY.get_public_net_id()\n    config.setup_logging()\n    context = neutron_context.get_admin_context()\n\n    # A query to get all IPAddress objects from the db\n    query = context.session.query(models.IPAddress)\n\n    (period_start, period_end) = billing.calc_periods(hour, minute)\n\n    full_day_ips = billing.build_full_day_ips(query,\n                                              period_start,\n                                              period_end)\n    partial_day_ips = billing.build_partial_day_ips(query,\n                                                    period_start,\n                                                    period_end)\n\n    if notify:\n        # '==================== Full Day ============================='\n        for ipaddress in full_day_ips:\n            click.echo('start: {}, end: {}'.format(period_start, period_end))\n            payload = billing.build_payload(ipaddress,\n                                            billing.IP_EXISTS,\n                                            start_time=period_start,\n                                            end_time=period_end)\n            billing.do_notify(context,\n                              billing.IP_EXISTS,\n                              payload)\n        # '==================== Part Day ============================='\n        for ipaddress in partial_day_ips:\n            click.echo('start: {}, end: {}'.format(period_start, period_end))\n            payload = billing.build_payload(ipaddress,\n                                            billing.IP_EXISTS,\n                                            start_time=ipaddress.allocated_at,\n                                            end_time=period_end)\n            billing.do_notify(context,\n                              billing.IP_EXISTS,\n                              payload)\n    else:\n        click.echo('Case 1 ({}):\\n'.format(len(full_day_ips)))\n        for ipaddress in full_day_ips:\n            pp(billing.build_payload(ipaddress,\n                                     billing.IP_EXISTS,\n                                     start_time=period_start,\n                                     end_time=period_end))\n\n        click.echo('\\n===============================================\\n')\n\n        click.echo('Case 2 ({}):\\n'.format(len(partial_day_ips)))\n        for ipaddress in partial_day_ips:\n            pp(billing.build_payload(ipaddress,\n                                     billing.IP_EXISTS,\n                                     start_time=ipaddress.allocated_at,\n                                     end_time=period_end))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconfigures all listeners here", "response": "def start_rpc_listeners(self):\n        \"\"\"Configure all listeners here\"\"\"\n        self._setup_rpc()\n        if not self.endpoints:\n            return []\n        self.conn = n_rpc.create_connection()\n        self.conn.create_consumer(self.topic, self.endpoints,\n                                  fanout=False)\n        return self.conn.consume_in_threads()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef context(self):\n        if not self._context:\n            self._context = context.get_admin_context()\n        return self._context", "response": "Provides an admin context for workers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting the async update process.", "response": "def update_sg(self, context, sg, rule_id, action):\n        \"\"\"Begins the async update process.\"\"\"\n        db_sg = db_api.security_group_find(context, id=sg, scope=db_api.ONE)\n        if not db_sg:\n            return None\n        with context.session.begin():\n            job_body = dict(action=\"%s sg rule %s\" % (action, rule_id),\n                            resource_id=rule_id,\n                            tenant_id=db_sg['tenant_id'])\n            job_body = dict(job=job_body)\n            job = job_api.create_job(context.elevated(), job_body)\n            rpc_client = QuarkSGAsyncProducerClient()\n            try:\n                rpc_client.populate_subtasks(context, sg, job['id'])\n            except om_exc.MessagingTimeout:\n                LOG.error(\"Failed to create subtasks. Rabbit running?\")\n                return None\n        return {\"job_id\": job['id']}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef populate_subtasks(self, context, sg, parent_job_id):\n        db_sg = db_api.security_group_find(context, id=sg, scope=db_api.ONE)\n        if not db_sg:\n            return None\n        ports = db_api.sg_gather_associated_ports(context, db_sg)\n        if len(ports) == 0:\n            return {\"ports\": 0}\n        for port in ports:\n            job_body = dict(action=\"update port %s\" % port['id'],\n                            tenant_id=db_sg['tenant_id'],\n                            resource_id=port['id'],\n                            parent_id=parent_job_id)\n            job_body = dict(job=job_body)\n            job = job_api.create_job(context.elevated(), job_body)\n            rpc_consumer = QuarkSGAsyncConsumerClient()\n            try:\n                rpc_consumer.update_port(context, port['id'], job['id'])\n            except om_exc.MessagingTimeout:\n                # TODO(roaet): Not too sure what can be done here other than\n                # updating the job as a failure?\n                LOG.error(\"Failed to update port. Rabbit running?\")\n        return None", "response": "Populate the list of ports to be updated async."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_ports_for_sg(self, context, portid, jobid):\n        port = db_api.port_find(context, id=portid, scope=db_api.ONE)\n        if not port:\n            LOG.warning(\"Port not found\")\n            return\n        net_driver = port_api._get_net_driver(port.network, port=port)\n        base_net_driver = port_api._get_net_driver(port.network)\n        sg_list = [sg for sg in port.security_groups]\n\n        success = False\n        error = None\n        retries = 3\n        retry_delay = 2\n        for retry in xrange(retries):\n            try:\n                net_driver.update_port(context, port_id=port[\"backend_key\"],\n                                       mac_address=port[\"mac_address\"],\n                                       device_id=port[\"device_id\"],\n                                       base_net_driver=base_net_driver,\n                                       security_groups=sg_list)\n                success = True\n                error = None\n                break\n            except Exception as error:\n                LOG.warning(\"Could not connect to redis, but retrying soon\")\n                time.sleep(retry_delay)\n        status_str = \"\"\n        if not success:\n            status_str = \"Port %s update failed after %d tries. Error: %s\" % (\n                portid, retries, error)\n        update_body = dict(completed=True, status=status_str)\n        update_body = dict(job=update_body)\n        job_api.update_job(context.elevated(), jobid, update_body)", "response": "Updates the ports through redis."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sg_gather_associated_ports(context, group):\n    if not group:\n        return None\n    if not hasattr(group, \"ports\") or len(group.ports) <= 0:\n        return []\n    return group.ports", "response": "Gather all ports associated to security group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate a security group rule.", "response": "def security_group_rule_update(context, rule, **kwargs):\n    '''Updates a security group rule.\n\n    NOTE(alexm) this is non-standard functionality.\n    '''\n    rule.update(kwargs)\n    context.session.add(rule)\n    return rule"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nquerying for segment allocations.", "response": "def segment_allocation_find(context, lock_mode=False, **filters):\n    \"\"\"Query for segment allocations.\"\"\"\n    range_ids = filters.pop(\"segment_allocation_range_ids\", None)\n\n    query = context.session.query(models.SegmentAllocation)\n    if lock_mode:\n        query = query.with_lockmode(\"update\")\n\n    query = query.filter_by(**filters)\n\n    # Optionally filter by given list of range ids\n    if range_ids:\n        query.filter(\n            models.SegmentAllocation.segment_allocation_range_id.in_(\n                range_ids))\n    return query"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a command to Niko Home Control and returns the output of the system.", "response": "def send(self, s):\n        \"\"\"\n        Sends the given command to Niko Home Control and returns the output of\n        the system.\n\n        Aliases: write, put, sendall, send_all\n        \"\"\"\n        self._socket.send(s.encode())\n        return self.read()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef if_(*args):\n    for i in range(0, len(args) - 1, 2):\n        if args[i]:\n            return args[i + 1]\n    if len(args) % 2:\n        return args[-1]\n    else:\n        return None", "response": "Implements the if operator with support for multiple elseif - s."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef soft_equals(a, b):\n    if isinstance(a, str) or isinstance(b, str):\n        return str(a) == str(b)\n    if isinstance(a, bool) or isinstance(b, bool):\n        return bool(a) is bool(b)\n    return a == b", "response": "Implements the '==' operator which does type JS - style coertion."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimplements the == operator.", "response": "def hard_equals(a, b):\n    \"\"\"Implements the '===' operator.\"\"\"\n    if type(a) != type(b):\n        return False\n    return a == b"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimplements the '<' operator with JS - style type coertion.", "response": "def less(a, b, *args):\n    \"\"\"Implements the '<' operator with JS-style type coertion.\"\"\"\n    types = set([type(a), type(b)])\n    if float in types or int in types:\n        try:\n            a, b = float(a), float(b)\n        except TypeError:\n            # NaN\n            return False\n    return a < b and (not args or less(b, *args))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef less_or_equal(a, b, *args):\n    return (\n        less(a, b) or soft_equals(a, b)\n    ) and (not args or less_or_equal(b, *args))", "response": "Implements the '<=' operator with JS - style type coertion."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a string either to int float or a string.", "response": "def to_numeric(arg):\n    \"\"\"\n    Converts a string either to int or to float.\n    This is important, because e.g. {\"!==\": [{\"+\": \"0\"}, 0.0]}\n    \"\"\"\n    if isinstance(arg, str):\n        if '.' in arg:\n            return float(arg)\n        else:\n            return int(arg)\n    return arg"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nimplement the merge operator for merging lists.", "response": "def merge(*args):\n    \"\"\"Implements the 'merge' operator for merging lists.\"\"\"\n    ret = []\n    for arg in args:\n        if isinstance(arg, list) or isinstance(arg, tuple):\n            ret += list(arg)\n        else:\n            ret.append(arg)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting variable value from data dictionary.", "response": "def get_var(data, var_name, not_found=None):\n    \"\"\"Gets variable value from data dictionary.\"\"\"\n    try:\n        for key in str(var_name).split('.'):\n            try:\n                data = data[key]\n            except TypeError:\n                data = data[int(key)]\n    except (KeyError, TypeError, ValueError):\n        return not_found\n    else:\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef missing(data, *args):\n    not_found = object()\n    if args and isinstance(args[0], list):\n        args = args[0]\n    ret = []\n    for arg in args:\n        if get_var(data, arg, not_found) is not_found:\n            ret.append(arg)\n    return ret", "response": "Implements the missing operator for finding missing variables."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimplement the missing_some operator for finding missing variables.", "response": "def missing_some(data, min_required, args):\n    \"\"\"Implements the missing_some operator for finding missing variables.\"\"\"\n    if min_required < 1:\n        return []\n    found = 0\n    not_found = object()\n    ret = []\n    for arg in args:\n        if get_var(data, arg, not_found) is not_found:\n            ret.append(arg)\n        else:\n            found += 1\n            if found >= min_required:\n                return []\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes the json - logic with given data.", "response": "def jsonLogic(tests, data=None):\n    \"\"\"Executes the json-logic with given data.\"\"\"\n    # You've recursed to a primitive, stop!\n    if tests is None or not isinstance(tests, dict):\n        return tests\n\n    data = data or {}\n\n    operator = list(tests.keys())[0]\n    values = tests[operator]\n\n    # Easy syntax for unary operators, like {\"var\": \"x\"} instead of strict\n    # {\"var\": [\"x\"]}\n    if not isinstance(values, list) and not isinstance(values, tuple):\n        values = [values]\n\n    # Recursion!\n    values = [jsonLogic(val, data) for val in values]\n\n    if operator == 'var':\n        return get_var(data, *values)\n    if operator == 'missing':\n        return missing(data, *values)\n    if operator == 'missing_some':\n        return missing_some(data, *values)\n\n    if operator not in operations:\n        raise ValueError(\"Unrecognized operation %s\" % operator)\n\n    return operations[operator](*values)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform an indentation on the current line of text.", "response": "def indent(self):\n        \"\"\"\n        Performs an indentation\n        \"\"\"\n        if not self.tab_always_indent:\n            super(PyIndenterMode, self).indent()\n        else:\n            cursor = self.editor.textCursor()\n            assert isinstance(cursor, QtGui.QTextCursor)\n            if cursor.hasSelection():\n                self.indent_selection(cursor)\n            else:\n                # simply insert indentation at the cursor position\n                tab_len = self.editor.tab_length\n                cursor.beginEditBlock()\n                if self.editor.use_spaces_instead_of_tabs:\n                    cursor.insertText(tab_len * \" \")\n                else:\n                    cursor.insertText('\\t')\n                cursor.endEditBlock()\n                self.editor.setTextCursor(cursor)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming an un - indentation on the current item.", "response": "def unindent(self):\n        \"\"\"\n        Performs an un-indentation\n        \"\"\"\n        if self.tab_always_indent:\n            cursor = self.editor.textCursor()\n            if not cursor.hasSelection():\n                cursor.select(cursor.LineUnderCursor)\n            self.unindent_selection(cursor)\n        else:\n            super(PyIndenterMode, self).unindent()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _handle_indent_between_paren(self, column, line, parent_impl, tc):\n        pre, post = parent_impl\n        next_char = self._get_next_char(tc)\n        prev_char = self._get_prev_char(tc)\n        prev_open = prev_char in ['[', '(', '{']\n        next_close = next_char in [']', ')', '}']\n        (open_line, open_symbol_col), (close_line, close_col) = \\\n            self._get_paren_pos(tc, column)\n        open_line_txt = self._helper.line_text(open_line)\n        open_line_indent = len(open_line_txt) - len(open_line_txt.lstrip())\n        if prev_open:\n            post = (open_line_indent + self.editor.tab_length) * ' '\n        elif next_close and prev_char != ',':\n            post = open_line_indent * ' '\n        elif tc.block().blockNumber() == open_line:\n            post = open_symbol_col * ' '\n\n        # adapt indent if cursor on closing line and next line have same\n        # indent -> PEP8 compliance\n        if close_line and close_col:\n            txt = self._helper.line_text(close_line)\n            bn = tc.block().blockNumber()\n            flg = bn == close_line\n            next_indent = self._helper.line_indent(bn + 1) * ' '\n            if flg and txt.strip().endswith(':') and next_indent == post:\n                # | look at how the previous line ( ``':'):`` ) was\n                # over-indented, this is actually what we are trying to\n                # achieve here\n                post += self.editor.tab_length * ' '\n\n        # breaking string\n        if next_char in ['\"', \"'\"]:\n            tc.movePosition(tc.Left)\n        is_string = self._helper.is_comment_or_string(tc, formats=['string'])\n        if next_char in ['\"', \"'\"]:\n            tc.movePosition(tc.Right)\n        if is_string:\n            trav = QTextCursor(tc)\n            while self._helper.is_comment_or_string(\n                    trav, formats=['string']):\n                trav.movePosition(trav.Left)\n            trav.movePosition(trav.Right)\n            symbol = '%s' % self._get_next_char(trav)\n            pre += symbol\n            post += symbol\n\n        return pre, post", "response": "Handle indentation between parentheses and braces."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _at_block_start(tc, line):\n        if tc.atBlockStart():\n            return True\n        column = tc.columnNumber()\n        indentation = len(line) - len(line.lstrip())\n        return column <= indentation", "response": "Return True if the cursor is at the start of a block."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef detect_encoding(self, path):\n        with open(path, 'rb') as file:\n            source = file.read()\n            # take care of line encodings (not in jedi)\n            source = source.replace(b'\\r', b'')\n            source_str = str(source).replace('\\\\n', '\\n')\n\n        byte_mark = ast.literal_eval(r\"b'\\xef\\xbb\\xbf'\")\n        if source.startswith(byte_mark):\n            # UTF-8 byte-order mark\n            return 'utf-8'\n\n        first_two_lines = re.match(r'(?:[^\\n]*\\n){0,2}', source_str).group(0)\n        possible_encoding = re.search(r\"coding[=:]\\s*([-\\w.]+)\",\n                                      first_two_lines)\n        if possible_encoding:\n            return possible_encoding.group(1)\n        return 'UTF-8'", "response": "Detect encoding of the current language of the current language of the current language."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling when the mode is activated or deactivated", "response": "def on_state_changed(self, state):\n        \"\"\"\n        Called when the mode is activated/deactivated\n        \"\"\"\n        if state:\n            self.action.triggered.connect(self.comment)\n            self.editor.add_action(self.action, sub_menu='Python')\n            if 'pyqt5' in os.environ['QT_API'].lower():\n                self.editor.key_pressed.connect(self.on_key_pressed)\n        else:\n            self.editor.remove_action(self.action, sub_menu='Python')\n            self.action.triggered.disconnect(self.comment)\n            if 'pyqt5' in os.environ['QT_API'].lower():\n                self.editor.key_pressed.disconnect(self.on_key_pressed)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncomment the selected lines or the current lines if there is no selection.", "response": "def comment(self):\n        \"\"\"\n        Comments/Uncomments the selected lines or the current lines if there\n        is no selection.\n        \"\"\"\n        cursor = self.editor.textCursor()\n        # get the indent at which comment should be inserted and whether to\n        # comment or uncomment the selected text\n        indent, comment, nb_lines = self.get_operation()\n        has_selection = cursor.hasSelection()\n        if nb_lines > 1:\n            self._move_cursor_to_selection_start(cursor)\n            cursor.beginEditBlock()\n            for i in range(nb_lines):\n                self.comment_line(indent, cursor, comment)\n                cursor.movePosition(cursor.NextBlock)\n            cursor.endEditBlock()\n        else:\n            # comment a single line\n            cursor.beginEditBlock()\n            self.comment_line(indent, cursor, comment)\n            if not has_selection:\n                # move to the first non-whitespace character of the next line\n                cursor.movePosition(cursor.NextBlock)\n                text = cursor.block().text()\n                indent = len(text) - len(text.lstrip())\n                cursor.movePosition(cursor.Right, cursor.MoveAnchor, indent)\n                cursor.endEditBlock()\n                self.editor.setTextCursor(cursor)\n            else:\n                cursor.endEditBlock()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setPlainText(self, txt, mimetype='text/x-python', encoding='utf-8'):\n        try:\n            self.syntax_highlighter.docstrings[:] = []\n            self.syntax_highlighter.import_statements[:] = []\n        except AttributeError:\n            pass\n        super(PyCodeEditBase, self).setPlainText(txt, mimetype, encoding)", "response": "Extends QCodeEdit. setPlainText to allow user to set plain text without mimetype."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_terminal_colors(self):\n        self.color_scheme = self.create_color_scheme(\n            background=self.syntax_highlighter.color_scheme.background,\n            foreground=self.syntax_highlighter.color_scheme.formats['normal'].foreground().color())", "response": "Update terminal colors based on pygments color scheme colors\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mouseMoveEvent(self, e):\n        super(PyInteractiveConsole, self).mouseMoveEvent(e)\n        cursor = self.cursorForPosition(e.pos())\n        assert isinstance(cursor, QtGui.QTextCursor)\n        p = cursor.positionInBlock()\n        usd = cursor.block().userData()\n        if usd and usd.start_pos_in_block <= p <= usd.end_pos_in_block:\n            if QtWidgets.QApplication.overrideCursor() is None:\n                QtWidgets.QApplication.setOverrideCursor(\n                    QtGui.QCursor(QtCore.Qt.PointingHandCursor))\n        else:\n            if QtWidgets.QApplication.overrideCursor() is not None:\n                QtWidgets.QApplication.restoreOverrideCursor()", "response": "Overrides mouseMoveEvent to display a pointing hand cursor when the mouse cursor is over a file location"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mousePressEvent(self, e):\n        super(PyInteractiveConsole, self).mousePressEvent(e)\n        cursor = self.cursorForPosition(e.pos())\n        p = cursor.positionInBlock()\n        usd = cursor.block().userData()\n        if usd and usd.start_pos_in_block <= p <= usd.end_pos_in_block:\n            if e.button() == QtCore.Qt.LeftButton:\n                self.open_file_requested.emit(usd.filename, usd.line)", "response": "Emits open_file_requested if the press event occured over\n        a file location string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef detect_fold_level(self, prev_block, block):\n        # Python is an indent based language so use indentation for folding\n        # makes sense but we restrict new regions to indentation after a ':',\n        # that way only the real logical blocks are displayed.\n        lvl = super(PythonFoldDetector, self).detect_fold_level(\n            prev_block, block)\n        # cancel false indentation, indentation can only happen if there is\n        # ':' on the previous line\n        prev_lvl = TextBlockHelper.get_fold_lvl(prev_block)\n        if prev_block and lvl > prev_lvl and not (\n                self._strip_comments(prev_block).endswith(':')):\n            lvl = prev_lvl\n        lvl = self._handle_docstrings(block, lvl, prev_block)\n        lvl = self._handle_imports(block, lvl, prev_block)\n        return lvl", "response": "Detects the fold level of the current block."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setup_actions(self):\n        self.actionOpen.triggered.connect(self.on_open)\n        self.actionNew.triggered.connect(self.on_new)\n        self.actionSave.triggered.connect(self.on_save)\n        self.actionSave_as.triggered.connect(self.on_save_as)\n        self.actionQuit.triggered.connect(\n            QtWidgets.QApplication.instance().quit)\n        self.tabWidget.current_changed.connect(self.on_current_tab_changed)\n        self.tabWidget.last_tab_closed.connect(self.on_last_tab_closed)\n        self.actionAbout.triggered.connect(self.on_about)\n        self.actionRun.triggered.connect(self.on_run)\n        self.interactiveConsole.process_finished.connect(\n            self.on_process_finished)\n        self.actionConfigure_run.triggered.connect(self.on_configure_run)", "response": "Connects the slots to signals"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef open_file(self, path, line=None):\n        editor = None\n        if path:\n            interpreter, pyserver, args = self._get_backend_parameters()\n            editor = self.tabWidget.open_document(\n                path, None, interpreter=interpreter, server_script=pyserver,\n                args=args)\n            if editor:\n                self.setup_editor(editor)\n            self.recent_files_manager.open_file(path)\n            self.menu_recents.update_actions()\n        if line is not None:\n            TextHelper(self.tabWidget.current_widget()).goto_line(line)\n        return editor", "response": "Opens a file and adds it to the menu."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_backend_parameters(self):\n        frozen = hasattr(sys, 'frozen')\n        interpreter = Settings().interpreter\n        if frozen:\n            interpreter = None\n        pyserver = server.__file__ if interpreter is not None else 'server.exe'\n        args = []\n        return interpreter, pyserver, args", "response": "Gets the interpreter pyserver and args for the backend."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a new empty code editor to the tab widget", "response": "def on_new(self):\n        \"\"\"\n        Add a new empty code editor to the tab widget\n        \"\"\"\n        interpreter, pyserver, args = self._get_backend_parameters()\n        self.setup_editor(self.tabWidget.create_new_document(\n            extension='.py', interpreter=interpreter, server_script=pyserver,\n            args=args))\n        self.actionRun.setDisabled(True)\n        self.actionConfigure_run.setDisabled(True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nopening file dialog and open the file if the dialog was accepted.", "response": "def on_open(self):\n        \"\"\"\n        Shows an open file dialog and open the file if the dialog was\n        accepted.\n\n        \"\"\"\n        filename, filter = QtWidgets.QFileDialog.getOpenFileName(self, 'Open')\n        if filename:\n            self.open_file(filename)\n        self.actionRun.setEnabled(True)\n        self.actionConfigure_run.setEnabled(True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_save_as(self):\n        path = self.tabWidget.current_widget().file.path\n        path = os.path.dirname(path) if path else ''\n        filename, filter = QtWidgets.QFileDialog.getSaveFileName(\n            self, 'Save', path)\n        if filename:\n            self.tabWidget.save_current(filename)\n            self.recent_files_manager.open_file(filename)\n            self.menu_recents.update_actions()\n            self.actionRun.setEnabled(True)\n            self.actionConfigure_run.setEnabled(True)\n            self._update_status_bar(self.tabWidget.current_widget())", "response": "Save the current editor document as."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup_mnu_panels(self, editor):\n        for panel in editor.panels:\n            if panel.dynamic:\n                continue\n            a = QtWidgets.QAction(self.menuModes)\n            a.setText(panel.name)\n            a.setCheckable(True)\n            a.setChecked(panel.enabled)\n            a.changed.connect(self.on_panel_state_changed)\n            a.panel = weakref.proxy(panel)\n            self.menuPanels.addAction(a)", "response": "Setup the panels menu for the current editor."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_current_tab_changed(self):\n        self.menuEdit.clear()\n        self.menuModes.clear()\n        self.menuPanels.clear()\n        editor = self.tabWidget.current_widget()\n        self.menuEdit.setEnabled(editor is not None)\n        self.menuModes.setEnabled(editor is not None)\n        self.menuPanels.setEnabled(editor is not None)\n        self.actionSave.setEnabled(editor is not None)\n        self.actionSave_as.setEnabled(editor is not None)\n        self.actionConfigure_run.setEnabled(editor is not None)\n        self.actionRun.setEnabled(editor is not None)\n        if editor is not None:\n            self.setup_mnu_edit(editor)\n            self.setup_mnu_modes(editor)\n            self.setup_mnu_panels(editor)\n        self.widgetOutline.set_editor(editor)\n        self._update_status_bar(editor)", "response": "Update action states when the current tab has changed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_run(self):\n        filename = self.tabWidget.current_widget().file.path\n        wd = os.path.dirname(filename)\n        args = Settings().get_run_config_for_file(filename)\n        self.interactiveConsole.start_process(\n            Settings().interpreter, args=[filename] + args, cwd=wd)\n        self.dockWidget.show()\n        self.actionRun.setEnabled(False)\n        self.actionConfigure_run.setEnabled(False)", "response": "Run the current script"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_goto_out_of_doc(self, assignment):\n        editor = self.open_file(assignment.module_path)\n        if editor:\n            TextHelper(editor).goto_line(assignment.line, assignment.column)", "response": "Open a new tab when goto goes out of the current document."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngoes to assignements worker.", "response": "def goto_assignments(request_data):\n    \"\"\"\n    Go to assignements worker.\n    \"\"\"\n    code = request_data['code']\n    line = request_data['line'] + 1\n    column = request_data['column']\n    path = request_data['path']\n    # encoding = request_data['encoding']\n    encoding = 'utf-8'\n    script = jedi.Script(code, line, column, path, encoding)\n    try:\n        definitions = script.goto_assignments()\n    except jedi.NotFoundError:\n        pass\n    else:\n        ret_val = [(d.module_path, d.line - 1 if d.line else None,\n                    d.column, d.full_name)\n                   for d in definitions]\n        return ret_val"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef defined_names(request_data):\n    global _old_definitions\n    ret_val = []\n    path = request_data['path']\n    toplvl_definitions = jedi.names(\n        request_data['code'], path, 'utf-8')\n    for d in toplvl_definitions:\n        definition = _extract_def(d, path)\n        if d.type != 'import':\n            ret_val.append(definition)\n    ret_val = [d.to_dict() for d in ret_val]\n    return ret_val", "response": "Returns the list of defined names for the document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef quick_doc(request_data):\n    code = request_data['code']\n    line = request_data['line'] + 1\n    column = request_data['column']\n    path = request_data['path']\n    # encoding = 'utf-8'\n    encoding = 'utf-8'\n    script = jedi.Script(code, line, column, path, encoding)\n    try:\n        definitions = script.goto_definitions()\n    except jedi.NotFoundError:\n        return []\n    else:\n        ret_val = [d.docstring() for d in definitions]\n        return ret_val", "response": "Worker that returns the documentation of the symbol under cursor."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_pep8(request_data):\n    import pycodestyle\n    from pyqode.python.backend.pep8utils import CustomChecker\n    WARNING = 1\n    code = request_data['code']\n    path = request_data['path']\n    max_line_length = request_data['max_line_length']\n    ignore_rules = request_data['ignore_rules']\n    ignore_rules += ['W291', 'W292', 'W293', 'W391']\n    pycodestyle.MAX_LINE_LENGTH = max_line_length\n    # setup our custom style guide with our custom checker which returns a list\n    # of strings instread of spitting the results at stdout\n    pep8style = pycodestyle.StyleGuide(parse_argv=False, config_file='',\n                                       checker_class=CustomChecker)\n    try:\n        results = pep8style.input_file(path, lines=code.splitlines(True))\n    except Exception:\n        _logger().exception('Failed to run PEP8 analysis with data=%r'\n                            % request_data)\n        return []\n    else:\n        messages = []\n        for line_number, offset, code, text, doc in results:\n            if code in ignore_rules:\n                continue\n            messages.append(('[PEP8] %s: %s' % (code, text), WARNING,\n                             line_number - 1))\n        return messages", "response": "This function runs the PEP8 tool on the current editor text and returns a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the icon resource filename that corresponds to the given typename.", "response": "def icon_from_typename(name, icon_type):\n    \"\"\"\n    Returns the icon resource filename that corresponds to the given typename.\n\n    :param name: name of the completion. Use to make the distinction between\n        public and private completions (using the count of starting '_')\n    :pram typename: the typename reported by jedi\n\n    :returns: The associate icon resource filename or None.\n    \"\"\"\n    ICONS = {\n        'CLASS': ICON_CLASS,\n        'IMPORT': ICON_NAMESPACE,\n        'STATEMENT': ICON_VAR,\n        'FORFLOW': ICON_VAR,\n        'FORSTMT': ICON_VAR,\n        'WITHSTMT': ICON_VAR,\n        'GLOBALSTMT': ICON_VAR,\n        'MODULE': ICON_NAMESPACE,\n        'KEYWORD': ICON_KEYWORD,\n        'PARAM': ICON_VAR,\n        'ARRAY': ICON_VAR,\n        'INSTANCEELEMENT': ICON_VAR,\n        'INSTANCE': ICON_VAR,\n        'PARAM-PRIV': ICON_VAR,\n        'PARAM-PROT': ICON_VAR,\n        'FUNCTION': ICON_FUNC,\n        'DEF': ICON_FUNC,\n        'FUNCTION-PRIV': ICON_FUNC_PRIVATE,\n        'FUNCTION-PROT': ICON_FUNC_PROTECTED\n    }\n    ret_val = None\n    icon_type = icon_type.upper()\n    # jedi 0.8 introduced NamedPart class, which have a string instead of being\n    # one\n    if hasattr(name, \"string\"):\n        name = name.string\n    if icon_type == \"FORFLOW\" or icon_type == \"STATEMENT\":\n        icon_type = \"PARAM\"\n    if icon_type == \"PARAM\" or icon_type == \"FUNCTION\":\n        if name.startswith(\"__\"):\n            icon_type += \"-PRIV\"\n        elif name.startswith(\"_\"):\n            icon_type += \"-PROT\"\n    if icon_type in ICONS:\n        ret_val = ICONS[icon_type]\n    elif icon_type:\n        _logger().warning(\"Unimplemented completion icon_type: %s\", icon_type)\n    return ret_val"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncomplete python code using jedi.", "response": "def complete(code, line, column, path, encoding, prefix):\n        \"\"\"\n        Completes python code using `jedi`_.\n\n        :returns: a list of completion.\n        \"\"\"\n        ret_val = []\n        try:\n            script = jedi.Script(code, line + 1, column, path, encoding)\n            completions = script.completions()\n            print('completions: %r' % completions)\n        except jedi.NotFoundError:\n            completions = []\n        for completion in completions:\n            ret_val.append({\n                'name': completion.name,\n                'icon': icon_from_typename(\n                    completion.name, completion.type),\n                'tooltip': completion.description})\n        return ret_val"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrequesting a go to the assignment.", "response": "def _check_word_cursor(self, tc=None):\n        \"\"\"\n        Request a go to assignment.\n\n        :param tc: Text cursor which contains the text that we must look for\n                   its assignment. Can be None to go to the text that is under\n                   the text cursor.\n        :type tc: QtGui.QTextCursor\n        \"\"\"\n        if not tc:\n            tc = TextHelper(self.editor).word_under_cursor()\n\n        request_data = {\n            'code': self.editor.toPlainText(),\n            'line': tc.blockNumber(),\n            'column': tc.columnNumber(),\n            'path': self.editor.file.path,\n            'encoding': self.editor.file.encoding\n        }\n        try:\n            self.editor.backend.send_request(\n                workers.goto_assignments, request_data,\n                on_receive=self._on_results_available)\n        except NotRunning:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _unique(self, seq):\n        # order preserving\n        checked = []\n        for e in seq:\n            present = False\n            for c in checked:\n                if str(c) == str(e):\n                    present = True\n                    break\n            if not present:\n                checked.append(e)\n        return checked", "response": "Returns a list of unique items in the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate the list of directives.", "response": "def _validateDirectives(self, directiveList, checkFileName):\n\n        if len(directiveList) == 0:\n            raise ParsingException(\"'{file}' does not contain any CHECK directives\".format(file=checkFileName))\n\n        from . import Directives\n        \"\"\"\n            We should enforce for every CHECK-NOT and CHECK-NOT-L directive that the next directive (if it exists) is\n            a CHECK or CHECK-L directive\n        \"\"\"\n        last = len(directiveList) -1\n        supportedDirectives = [ Directives.Check, Directives.CheckLiteral ]\n        for (index,directive) in enumerate(directiveList):\n            if isA(directive, [Directives.CheckNot, Directives.CheckNotLiteral]):\n                if index < last:\n                    after = directiveList[index +1]\n                    if not isA(after, supportedDirectives):\n                        requiredTypes = \" or \".join( [ \"CHECK{suffix}\".format(suffix=d.directiveToken()) for d in supportedDirectives])\n                        raise ParsingException(\"{directive} must have a {requiredTypes} directive after it instead of a {bad}\".format(\n                                                  directive=directive,\n                                                  requiredTypes=requiredTypes,\n                                                  check=Directives.Check.directiveToken(),\n                                                  bad=after)\n                                              )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _substituteCheckPattern(self, inputString, lineNumber, lastLineNumber, checkFileName, isForRegex):\n        assert isinstance(inputString, str)\n        assert isinstance(lineNumber, int)\n        assert isinstance(lastLineNumber, int)\n        assert isinstance(checkFileName, str)\n\n        \"\"\"\n        Do ${LINE}, ${LINE:+N}, and ${LINE:-N} substitutions.\n        To escape prepend with slash\n        \"\"\"\n        sPattern = r'\\$\\{LINE(\\:(?P<sign>\\+|-)(?P<offset>\\d+))?\\}'\n        matcher = re.compile(sPattern)\n        result = \"\"\n        loop = True\n        start = 0\n        end = len(inputString) # Not inclusive\n        while loop:\n            m = matcher.search(inputString, start, end)\n            if not m:\n                # No match so copy verbatim\n                _logger.debug('Result is currently \"{}\"'.format(result))\n                result += inputString[start:end]\n                break # And we're done :)\n            else:\n                prevIndex = max(0, m.start() -1)\n                _logger.debug('Previous character before match is at index {index} \"{char}\"'.format(index=prevIndex, char=inputString[prevIndex]))\n                if inputString[prevIndex] == \"\\\\\":\n                    # User asked to escape\n                    _logger.debug('Substitution is escaped')\n                    _logger.debug('Result is currently \"{}\"'.format(result))\n                    result += inputString[start:prevIndex] # Copy before escaping character\n                    _logger.debug('Result is currently \"{}\"'.format(result))\n                    result += inputString[(prevIndex+1):m.end()] # Copy the ${LINE..} verbatim\n                    start = min(m.end(), end)\n                    _logger.debug('Result is currently \"{}\"'.format(result))\n                    _logger.debug('Next search is {start}:{end} = \"{ss}\"'.format(start=start, end=end, ss=inputString[start:end]))\n                else:\n                    _logger.debug('Result is currently \"{}\"'.format(result))\n                    _logger.debug('Doing subsitution. Found at {begin}:{end} = {ss}'.format(begin=m.start(),end=m.end(), ss=inputString[m.start():m.end()]))\n                    result += inputString[start:m.start()] # Copy before substitution starts\n\n                    if m.groupdict()['sign'] == None:\n                        # No offset just substitute line number\n                        _logger.debug('No offset')\n                        result += str(lineNumber)\n                    else:\n                        offset = 1 if m.groupdict()['sign'] == '+' else -1\n                        offset *= int(m.groupdict()['offset'])\n                        _logger.debug('Offset is {}'.format(offset))\n\n                        requestedLineNumber = lineNumber + offset\n                        _logger.debug('Request line number to print is  {}'.format(requestedLineNumber))\n\n                        if requestedLineNumber <= 0:\n                            raise ParsingException('{file}:{line}:{col} offset gives line number < 1'.format(file=checkFileName, line=lineNumber, col=m.start()))\n                        elif requestedLineNumber > lastLineNumber:\n                            raise ParsingException('{file}:{line}:{col} offset gives line number past the end of file'.format(file=checkFileName, line=lineNumber, col=m.start()))\n\n                        result += str(requestedLineNumber)\n\n                    start = min(m.end(),end)\n                    _logger.debug('Next search is {start}:{end} = \"{ss}\"'.format(start=start, end=end, ss=inputString[start:end]))\n\n        \"\"\"\n        Do simple ${...} substitutions\n        \"\"\"\n\n\n        # Do ${CHECKFILE_NAME} substitution\n        basenameCheckFileName = os.path.basename(checkFileName)\n        assert basenameCheckFileName.count('\\\\') == 0\n        result = self._simpleSubstitution(\"CHECKFILE_NAME\", basenameCheckFileName, result)\n\n        # Do ${CHECKFILE_ABS_PATH} substitution\n        abspathCheckFileName = os.path.abspath(checkFileName)\n        if isForRegex:\n            # Note slash substitution is for Windows paths (e.g. \"c:\\mything\\foo.txt\") which can break regexes if we don't\n            # correctly escape them.\n            abspathCheckFileName = abspathCheckFileName.replace('\\\\', '\\\\\\\\')\n\n        result = self._simpleSubstitution(\"CHECKFILE_ABS_PATH\", abspathCheckFileName, result)\n\n        assert len(result) != 0\n        return result", "response": "Substitute checkPattern in the inputString."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_metafile(bgen_filepath, metafile_filepath, verbose=True):\n    if verbose:\n        verbose = 1\n    else:\n        verbose = 0\n\n    bgen_filepath = make_sure_bytes(bgen_filepath)\n    metafile_filepath = make_sure_bytes(metafile_filepath)\n\n    assert_file_exist(bgen_filepath)\n    assert_file_readable(bgen_filepath)\n\n    if exists(metafile_filepath):\n        raise ValueError(f\"The file {metafile_filepath} already exists.\")\n\n    with bgen_file(bgen_filepath) as bgen:\n        nparts = _estimate_best_npartitions(lib.bgen_nvariants(bgen))\n        metafile = lib.bgen_create_metafile(bgen, metafile_filepath, nparts, verbose)\n        if metafile == ffi.NULL:\n            raise RuntimeError(f\"Error while creating metafile: {metafile_filepath}.\")\n\n        if lib.bgen_close_metafile(metafile) != 0:\n            raise RuntimeError(f\"Error while closing metafile: {metafile_filepath}.\")", "response": "r Create variants metadata file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef match(self, subsetLines, offsetOfSubset, fileName):\n\n        for (offset,l) in enumerate(subsetLines):\n            column = l.find(self.literal)\n            if column != -1:\n                truePosition = offset + offsetOfSubset\n                _logger.debug('Found match on line {}, col {}'.format(str(truePosition+ 1), column))\n                _logger.debug('Line is {}'.format(l))\n                self.matchLocation = CheckFileParser.FileLocation(fileName, truePosition +1)\n                return truePosition\n\n        # No Match found\n        self.failed = True\n        raise DirectiveException(self)", "response": "Match the line with the literal in the line that matches the pattern."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch through lines for match. A match is found.", "response": "def match(self, subsetLines, offsetOfSubset, fileName):\n        \"\"\"\n            Search through lines for match.\n            Raise an Exception if a match\n        \"\"\"\n        for (offset,l) in enumerate(subsetLines):\n            for t in self.regex:\n                m = t.Regex.search(l)\n                if m != None:\n                    truePosition = offset + offsetOfSubset\n                    _logger.debug('Found match on line {}'.format(str(truePosition+ 1)))\n                    _logger.debug('Line is {}'.format(l))\n                    self.failed = True\n                    self.matchLocation = CheckFileParser.FileLocation(fileName, truePosition +1)\n                    raise DirectiveException(self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef isA(instance, typeList):\n    return any(map(lambda iType: isinstance(instance,iType), typeList))", "response": "Return True if instance is an instance of any of the Directive\n        types in typeList."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntouching a file. Taxonomy Credits to <https://stackoverflow. com/a/1160227 >.", "response": "def _touch(fname, mode=0o666, dir_fd=None, **kwargs):\n    \"\"\" Touch a file.\n\n    Credits to <https://stackoverflow.com/a/1160227>.\n    \"\"\"\n    flags = os.O_CREAT | os.O_APPEND\n    with os.fdopen(os.open(fname, flags=flags, mode=mode, dir_fd=dir_fd)) as f:\n        os.utime(\n            f.fileno() if os.utime in os.supports_fd else fname,\n            dir_fd=None if os.supports_fd else dir_fd,\n            **kwargs,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntry to infer the correct library name.", "response": "def find_libname(self, name):\n        \"\"\"Try to infer the correct library name.\"\"\"\n        names = [\"{}.lib\", \"lib{}.lib\", \"{}lib.lib\"]\n        names = [n.format(name) for n in names]\n        dirs = self.get_library_dirs()\n        for d in dirs:\n            for n in names:\n                if exists(join(d, n)):\n                    return n[:-4]\n        msg = \"Could not find the {} library.\".format(name)\n        raise ValueError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef split(self, X, y=None, groups=None):\n        X, y, groups = indexable(X, y, groups)\n        cgrs = [~r for r in X]\n\n        structure_condition = defaultdict(set)\n\n        for structure, condition in zip(cgrs, groups):\n            structure_condition[structure].add(condition)\n\n        train_data = defaultdict(list)\n        test_data = []\n\n        for n, (structure, condition) in enumerate(zip(cgrs, groups)):\n            train_data[condition].append(n)\n            if len(structure_condition[structure]) > 1:\n                test_data.append(n)\n\n        for condition, indexes in train_data.items():\n            test_index = [index for index in indexes if index in test_data]\n            if test_index:\n                train_index = [i for cond, ind in train_data.items() if cond != condition for i in ind]\n                yield array(train_index), array(test_index)", "response": "Generates indices to split data into training and test sets."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef molconvert_chemaxon(data):\n    if isinstance(data, Path):\n        with data.open('rb') as f:\n            data = f.read()\n    elif isinstance(data, StringIO):\n        data = data.read().encode()\n    elif isinstance(data, BytesIO):\n        data = data.read()\n    elif hasattr(data, 'read'):  # check if data is open(filename, mode)\n        data = data.read()\n        if isinstance(data, str):\n            data = data.encode()\n    elif isinstance(data, str):\n        data = data.encode()\n    elif not isinstance(data, bytes):\n        raise ValueError('invalid input')\n\n    try:\n        p = run(['molconvert', '-g', 'mrv'], input=data, stdout=PIPE)\n    except FileNotFoundError as e:\n        raise ConfigurationError from e\n\n    if p.returncode != 0:\n        raise ConfigurationError(p.stderr.decode())\n\n    with BytesIO(p.stdout) as f, MRVread(f) as r:\n        return iter2array(r)", "response": "molconvert wrapper for the chemaxon file atomconvert wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting distance - based AD.", "response": "def fit(self, X, y=None):\n        \"\"\"Fit distance-based AD.\n\n        Parameters\n        ----------\n        X : array-like or sparse matrix, shape (n_samples, n_features)\n            The input samples. Use ``dtype=np.float32`` for maximum\n            efficiency.\n\n        Returns\n        -------\n        self : object\n            Returns self.\n        \"\"\"\n        # Check data\n        X = check_array(X)\n        self.tree = BallTree(X, leaf_size=self.leaf_size, metric=self.metric)\n        dist_train = self.tree.query(X, k=2)[0]\n        if self.threshold == 'auto':\n            self.threshold_value = 0.5 * sqrt(var(dist_train[:, 1])) + mean(dist_train[:, 1])\n        elif self.threshold == 'cv':\n            if y is None:\n                raise ValueError(\"Y must be specified to find the optimal threshold.\")\n            y = check_array(y, accept_sparse='csc', ensure_2d=False, dtype=None)\n            self.threshold_value = 0\n            score = 0\n            Y_pred, Y_true, AD = [], [], []\n            cv = KFold(n_splits=5, random_state=1, shuffle=True)\n            for train_index, test_index in cv.split(X):\n                x_train = safe_indexing(X, train_index)\n                x_test = safe_indexing(X, test_index)\n                y_train = safe_indexing(y, train_index)\n                y_test = safe_indexing(y, test_index)\n                data_test = safe_indexing(dist_train[:, 1], test_index)\n                if self.reg_model is None:\n                    reg_model = RandomForestRegressor(n_estimators=500, random_state=1).fit(x_train, y_train)\n                else:\n                    reg_model = clone(self.reg_model).fit(x_train, y_train)\n                Y_pred.append(reg_model.predict(x_test))\n                Y_true.append(y_test)\n                AD.append(data_test)\n            AD_ = unique(hstack(AD))\n            for z in AD_:\n                AD_new = hstack(AD) <= z\n                if self.score == 'ba_ad':\n                    val = balanced_accuracy_score_with_ad(Y_true=hstack(Y_true), Y_pred=hstack(Y_pred), AD=AD_new)\n                elif self.score == 'rmse_ad':\n                    val = rmse_score_with_ad(Y_true=hstack(Y_true), Y_pred=hstack(Y_pred), AD=AD_new)\n                if val >= score:\n                    score = val\n                    self.threshold_value = z\n        else:\n            self.threshold_value = self.threshold\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef predict_proba(self, X):\n        # Check is fit had been called\n        check_is_fitted(self, ['tree'])\n        # Check data\n        X = check_array(X)\n        return self.tree.query(X)[0].flatten()", "response": "Returns the value of the nearest neighbor from the training set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef predict(self, X):\n        # Check is fit had been called\n        check_is_fitted(self, ['tree'])\n        # Check data\n        X = check_array(X)\n        return self.tree.query(X)[0].flatten() <= self.threshold_value", "response": "Predict if a particular sample is an outlier or not."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting the regression model on the set of classes.", "response": "def fit(self, X, y=None):\n        \"\"\"Learning is to find the inverse matrix for X and calculate the threshold.\n\n        Parameters\n        ----------\n        X : array-like or sparse matrix, shape (n_samples, n_features)\n            The input samples. Use ``dtype=np.float32`` for maximum\n            efficiency.\n        y : array-like, shape = [n_samples] or [n_samples, n_outputs]\n            The target values (real numbers in regression).\n\n        Returns\n        -------\n        self : object\n        \"\"\"\n        # Check that X have correct shape\n        X = check_array(X)\n        self.inverse_influence_matrix = self.__make_inverse_matrix(X)\n        if self.threshold == 'auto':\n            self.threshold_value = 3 * (1 + X.shape[1]) / X.shape[0]\n        elif self.threshold == 'cv':\n            if y is None:\n                raise ValueError(\"Y must be specified to find the optimal threshold.\")\n            y = check_array(y, accept_sparse='csc', ensure_2d=False, dtype=None)\n            self.threshold_value = 0\n            score = 0\n            Y_pred, Y_true, AD = [], [], []\n            cv = KFold(n_splits=5, random_state=1, shuffle=True)\n            for train_index, test_index in cv.split(X):\n                x_train = safe_indexing(X, train_index)\n                x_test = safe_indexing(X, test_index)\n                y_train = safe_indexing(y, train_index)\n                y_test = safe_indexing(y, test_index)\n                if self.reg_model is None:\n                    reg_model = RandomForestRegressor(n_estimators=500, random_state=1).fit(x_train, y_train)\n                else:\n                    reg_model = clone(self.reg_model).fit(x_train, y_train)\n                Y_pred.append(reg_model.predict(x_test))\n                Y_true.append(y_test)\n                ad_model = self.__make_inverse_matrix(x_train)\n                AD.append(self.__find_leverages(x_test, ad_model))\n            AD_ = unique(hstack(AD))\n            for z in AD_:\n                AD_new = hstack(AD) <= z\n                if self.score == 'ba_ad':\n                    val = balanced_accuracy_score_with_ad(Y_true=hstack(Y_true), Y_pred=hstack(Y_pred), AD=AD_new)\n                elif self.score == 'rmse_ad':\n                    val = rmse_score_with_ad(Y_true=hstack(Y_true), Y_pred=hstack(Y_pred), AD=AD_new)\n                if val >= score:\n                    score = val\n                    self.threshold_value = z\n        else:\n            self.threshold_value = self.threshold\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef predict_proba(self, X):\n        # Check is fit had been called\n        check_is_fitted(self, ['inverse_influence_matrix'])\n        # Check that X have correct shape\n        X = check_array(X)\n        return self.__find_leverages(X, self.inverse_influence_matrix)", "response": "Predict the distances for X to the center of the training set."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef predict(self, X):\n        # Check is fit had been called\n        check_is_fitted(self, ['inverse_influence_matrix'])\n        # Check that X have correct shape\n        X = check_array(X)\n        return self.__find_leverages(X, self.inverse_influence_matrix) <= self.threshold_value", "response": "Predicts inside or outside AD for X."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_feature_names(self):\n        return ['temperature', 'pressure'] + [f'solvent.{x}' for x in range(1, self.max_solvents + 1)] + \\\n               [f'solvent_amount.{x}' for x in range(1, self.max_solvents + 1)]", "response": "Get feature names.\n\n        Returns\n        -------\n        feature_names : list of strings\n            Names of the features produced by transform."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfitting the object to the given data.", "response": "def fit(self, X, y=None):\n        \"\"\"Find min and max values of every feature.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            The training input samples.\n        y : Ignored\n            not used, present for API consistency by convention.\n\n        Returns\n        -------\n        self : object\n        \"\"\"\n        # Check that X have correct shape\n        X = check_array(X)\n\n        self._x_min = X.min(axis=0) # axis=0 will find the minimum values \u200b\u200bby columns (for each feature)\n        self._x_max = X.max(axis=0) # axis=0 will find the minimum values \u200b\u200bby columns (for each feature)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef predict(self, X):\n        # Check is fit had been called\n        check_is_fitted(self, ['_x_min', '_x_max'])\n\n        # Input validation\n        X = check_array(X)\n        return ((X - self._x_min).min(axis=1) >= 0) & ((self._x_max - X).min(axis=1) >= 0)", "response": "Predict if a particular sample is an outlier or not."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates indices to split the data into training and test sets.", "response": "def split(self, X, y=None, groups=None):\n        \"\"\"Generate indices to split data into training and test set.\n        Parameters\n        ----------\n        X : array-like, of length n_samples\n            Training data, includes reaction's containers\n        y : array-like, of length n_samples\n            The target variable for supervised learning problems.\n        groups : array-like, with shape (n_samples,)\n            Group labels for the samples used while splitting the dataset into\n            train/test set.\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        X, y, groups = indexable(X, y, groups)\n        cgrs = [~r for r in X]\n\n        condition_structure = defaultdict(set)\n\n        for structure, condition in zip(cgrs, groups):\n            condition_structure[condition].add(structure)\n\n        train_data = defaultdict(list)\n        test_data = []\n\n        for n, (structure, condition) in enumerate(zip(cgrs, groups)):\n            train_data[structure].append(n)\n            if len(condition_structure[condition]) > 1:\n                test_data.append(n)\n\n        if self.n_splits > len(train_data):\n            raise ValueError(\"Cannot have number of splits n_splits=%d greater\"\n                             \" than the number of transformations: %d.\"\n                             % (self.n_splits, len(train_data)))\n\n        structures_weight = sorted(((x, len(y)) for x, y in train_data.items()), key=lambda x: x[1], reverse=True)\n        fold_mean_size = len(cgrs) // self.n_splits\n\n        if structures_weight[0][1] > fold_mean_size:\n            warning('You have transformation that greater fold size')\n\n        for idx in range(self.n_repeats):\n            train_folds = [[] for _ in range(self.n_splits)]\n            for structure, structure_length in structures_weight:\n                if self.shuffle:\n                    check_random_state(self.random_state).shuffle(train_folds)\n                for fold in train_folds[:-1]:\n                    if len(fold) + structure_length <= fold_mean_size:\n                        fold.extend(train_data[structure])\n                        break\n                    else:\n                        roulette_param = (structure_length - fold_mean_size + len(fold)) / structure_length\n                        if random() > roulette_param:\n                            fold.extend(train_data[structure])\n                            break\n                else:\n                    train_folds[-1].extend(train_data[structure])\n\n            test_folds = [[] for _ in range(self.n_splits)]\n            for test, train in zip(test_folds, train_folds):\n                for index in train:\n                    if index in test_data:\n                        test.append(index)\n\n            for i in range(self.n_splits):\n                train_index = []\n                for fold in train_folds[:i]:\n                    train_index.extend(fold)\n                for fold in train_folds[i+1:]:\n                    train_index.extend(fold)\n                test_index = test_folds[i]\n                yield array(train_index), array(test_index)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndoing nothing and return the estimator unchanged", "response": "def fit(self, x, y=None):\n        \"\"\"Do nothing and return the estimator unchanged\n\n        This method is just there to implement the usual API and hence work in pipelines.\n        \"\"\"\n        if self._dtype is not None:\n            iter2array(x, dtype=self._dtype)\n        else:\n            iter2array(x)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef finalize(self):\n        if self.__head_less:\n            warn(f'{self.__class__.__name__} configured to head less mode. finalize unusable')\n        elif not self.__head_generate:\n            warn(f'{self.__class__.__name__} already finalized or fitted')\n        elif not self.__head_dict:\n            raise NotFittedError(f'{self.__class__.__name__} instance is not fitted yet')\n        else:\n            if self.remove_rare_ratio:\n                self.__clean_head(*self.__head_rare)\n                self.__prepare_header()\n                self.__head_rare = None\n            self.__head_generate = False", "response": "finalize partial fitting procedure"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _reset(self):\n        if not self.__head_less:\n            if not self.__head_generate:\n                self.__head_generate = True\n            if self.__head_dict:\n                self.__head_dump = self.__head_dict = None\n            if self.__head_rare is not None:\n                self.__head_rare = None\n\n            self.delete_work_path()", "response": "Reset internal data - dependent state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_feature_names(self):\n        if self.__head_less:\n            raise AttributeError(f'{self.__class__.__name__} instance configured to head less mode')\n        elif not self.__head_dict:\n            raise NotFittedError(f'{self.__class__.__name__} instance is not fitted yet')\n        return list(self.__head_dict.values())", "response": "Get feature names.\n\n        Returns\n        -------\n        feature_names : list of strings\n            Names of the features produced by transform."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fit(self, X):\n        X = iter2array(X, dtype=ReactionContainer)\n        self._train_signatures = {self.__get_signature(x) for x in X}\n        return self", "response": "Fit structure - based AD. The training model memorizes the unique set of reaction signatures."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npredicting reaction for given set of training sets.", "response": "def predict(self, X):\n        \"\"\"Reaction is considered belonging to model\u2019s AD\n        if its reaction signature coincides with ones used in training set.\n\n        Parameters\n        ----------\n        X : after read rdf file\n\n        Returns\n        -------\n        self : array contains True (reaction in AD) and False (reaction residing outside AD).\n        \"\"\"\n        check_is_fitted(self, ['_train_signatures'])\n        X = iter2array(X, dtype=ReactionContainer)\n        return array([self.__get_signature(x) in self._train_signatures for x in X])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse an expression into a list of identifiers and tokens", "response": "def __parser(expression):\n        \"\"\" adopted from Paul McGuire example. http://pyparsing.wikispaces.com/file/view/fourFn.py\n        \"\"\"\n        expr_stack = []\n\n        def push_first(strg, loc, toks):\n            expr_stack.append(toks[0])\n\n        def push_u_minus(strg, loc, toks):\n            if toks and toks[0] == '-':\n                expr_stack.append('unary -')\n\n        point = Literal('.')\n        _e = CaselessLiteral('E')\n        fnumber = Combine(Word('+-' + nums, nums) +\n                          Optional(point + Optional(Word(nums))) +\n                          Optional(_e + Word('+-' + nums, nums)))\n        ident = Word(alphas, alphas + nums + '_$')\n\n        plus = Literal(\"+\")\n        minus = Literal(\"-\")\n        mult = Literal(\"*\")\n        div = Literal(\"/\")\n        lpar = Literal(\"(\").suppress()\n        rpar = Literal(\")\").suppress()\n        addop = plus | minus\n        multop = mult | div\n        expop = Literal(\"^\")\n        _pi = CaselessLiteral(\"PI\")\n        x = CaselessLiteral(\"X\")\n\n        expr = Forward()\n        atom = (Optional(\"-\") + (x | _pi | _e | fnumber | ident + lpar + expr + rpar).setParseAction(push_first) |\n                (lpar + expr.suppress() + rpar)).setParseAction(push_u_minus)\n\n        factor = Forward()\n        factor << atom + ZeroOrMore((expop + factor).setParseAction(push_first))\n\n        term = factor + ZeroOrMore((multop + factor).setParseAction(push_first))\n        expr << term + ZeroOrMore((addop + term).setParseAction(push_first))\n\n        expr.parseString(expression)\n        return expr_stack"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_int(data):\n    if not isinstance(data, int) and not isinstance(data, long):\n        raise TypeError('Input must be integer')\n\n    res = []\n    while data > 0 or not res:\n        for j in range(5):\n            if not j % 2:\n                res += CONSONANTS[(data & 0xf)]\n                data >>= 4\n            else:\n                res += VOWELS[(data & 0x3)]\n                data >>= 2\n        if data > 0:\n            res += '-'\n    res.reverse()\n    return ''.join(res)", "response": "Convert an integer to a string in the format of a sequence of numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_int(data):\n    if not isinstance(data, basestring):\n        raise TypeError('Input must be string')\n\n    res = 0\n    for part in data.split('-'):\n        if len(part) != 5:\n            raise ValueError('Malformed proquint')\n        for j in range(5):\n            try:\n                if not j % 2:\n                    res <<= 4\n                    res |= CONSONANTS.index(part[j])\n                else:\n                    res <<= 2\n                    res |= VOWELS.index(part[j])\n            except ValueError:\n                raise ValueError('Unknown character \\'{!s}\\' in proquint'.format(part[j]))\n    return res", "response": "decode a string into an integer"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget or create a shared key pair for certificate pushing.", "response": "def get_or_create_shared_key(cls, force_new=False):\n        \"\"\"\n        Create a shared public/private key pair for certificate pushing,\n        if the settings allow.\n        \"\"\"\n        if force_new:\n            with transaction.atomic():\n                SharedKey.objects.filter(current=True).update(current=False)\n                key = Key()\n                return SharedKey.objects.create(public_key=key,\n                                                private_key=key,\n                                                current=True)\n        # create a new shared key if one doesn't exist\n        try:\n            return SharedKey.objects.get(current=True)\n        except SharedKey.DoesNotExist:\n            key = Key()\n            return SharedKey.objects.create(public_key=key,\n                                            private_key=key,\n                                            current=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _self_referential_fk(klass_model):\n    for f in klass_model._meta.concrete_fields:\n        if f.related_model:\n            if issubclass(klass_model, f.related_model):\n                return f.attname\n    return None", "response": "Return whether this model has a self ref FK and the name for the field."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_or_create_current_instance(cls):\n\n        # on Android, platform.platform() barfs, so we handle that safely here\n        try:\n            plat = platform.platform()\n        except:\n            plat = \"Unknown (Android?)\"\n\n        kwargs = {\n            \"platform\": plat,\n            \"hostname\": platform.node(),\n            \"sysversion\": sys.version,\n            \"database\": DatabaseIDModel.get_or_create_current_database_id(),\n            \"db_path\": os.path.abspath(settings.DATABASES['default']['NAME']),\n            \"system_id\": os.environ.get(\"MORANGO_SYSTEM_ID\", \"\"),\n        }\n\n        # try to get the MAC address, but exclude it if it was a fake (random) address\n        mac = uuid.getnode()\n        if (mac >> 40) % 2 == 0:  # 8th bit (of 48 bits, from left) is 1 if MAC is fake\n            hashable_identifier = \"{}:{}\".format(kwargs['database'].id, mac)\n            kwargs[\"node_id\"] = hashlib.sha1(hashable_identifier.encode('utf-8')).hexdigest()[:20]\n        else:\n            kwargs[\"node_id\"] = \"\"\n\n        # do within transaction so we only ever have 1 current instance ID\n        with transaction.atomic():\n            InstanceIDModel.objects.filter(current=True).update(current=False)\n            obj, created = InstanceIDModel.objects.get_or_create(**kwargs)\n            obj.current = True\n            obj.save()\n\n        return obj, created", "response": "Get the instance model corresponding to the current system or create a new one if it does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef serialize(self):\n        # NOTE: code adapted from https://github.com/django/django/blob/master/django/forms/models.py#L75\n        opts = self._meta\n\n        data = {}\n        for f in opts.concrete_fields:\n            if f.attname in self.morango_fields_not_to_serialize:\n                continue\n            if f.attname in self._morango_internal_fields_not_to_serialize:\n                continue\n            # case if model is morango mptt\n            if f.attname in getattr(self, '_internal_mptt_fields_not_to_serialize', '_internal_fields_not_to_serialize'):\n                continue\n            if hasattr(f, 'value_from_object_json_compatible'):\n                data[f.attname] = f.value_from_object_json_compatible(self)\n            else:\n                data[f.attname] = f.value_from_object(self)\n        return data", "response": "Returns a dict of all concrete fields of the SyncableModel subclass except for those specifically blacklisted are returned in a dict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef deserialize(cls, dict_model):\n        kwargs = {}\n        for f in cls._meta.concrete_fields:\n            if f.attname in dict_model:\n                kwargs[f.attname] = dict_model[f.attname]\n        return cls(**kwargs)", "response": "Returns an unsaved class object based on the valid properties passed in."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_default(self):\n        if self.has_default():\n            if callable(self.default):\n                default = self.default()\n                if isinstance(default, uuid.UUID):\n                    return default.hex\n                return default\n            if isinstance(self.default, uuid.UUID):\n                return self.default.hex\n            return self.default\n        return None", "response": "Returns the default value for this field."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_to_deleted_models(sender, instance=None, *args, **kwargs):\n    if issubclass(sender, SyncableModel):\n        instance._update_deleted_models()", "response": "Add a model to the list of deleted models."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking a request to the specified URL and returns the response as json object.", "response": "def make_request(self, url, method='get', headers=None, data=None,\n                     callback=None, errors=STRICT, verify=False, timeout=None, **params):\n        \"\"\"\n        Reusable method for performing requests.\n        :param url - URL to request\n        :param method - request method, default is 'get'\n        :param headers - request headers\n        :param data - post data\n        :param callback - callback to be applied to response,\n                          default callback will parse response as json object.\n        :param errors - specifies communication errors handling mode, possible\n                        values are:\n                         * strict (default) - throw an error as soon as one\n                            occurred\n                         * graceful - ignore certain errors, e.g. EmptyResponse\n                         * ignore - ignore all errors and return a result in\n                                    any case.\n                                    NOTE that it DOES NOT mean that no\n                                    exceptions can be\n                                    raised from this method, it mostly ignores\n                                    communication\n                                    related errors.\n                         * None or empty string equals to default\n        :param verify - whether or not to verify SSL cert, default to False\n        :param timeout - the timeout of the request in second, default to None\n        :param params - additional query parameters for request\n        \"\"\"\n        error_modes = (STRICT, GRACEFUL, IGNORE)\n        error_mode = errors or GRACEFUL\n        if error_mode.lower() not in error_modes:\n            raise ValueError(\n                'Possible values for errors argument are: %s'\n                % ','.join(error_modes))\n\n        if callback is None:\n            callback = self._default_resp_callback\n\n        request = getattr(requests, method.lower())\n        log.debug('* Request URL: %s' % url)\n        log.debug('* Request method: %s' % method)\n        log.debug('* Request query params: %s' % params)\n        log.debug('* Request headers: %s' % headers)\n        log.debug('* Request timeout: %s' % timeout)\n\n        r = request(\n            url, headers=headers, data=data, verify=verify, timeout=timeout, params=params)\n\n        log.debug('* r.url: %s' % r.url)\n\n        try:\n            r.raise_for_status()\n            return callback(r)\n        except Exception as e:\n            return self._with_error_handling(r, e,\n                                             error_mode, self.response_format)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef poll(self, url, initial_delay=2, delay=1, tries=20, errors=STRICT, is_complete_callback=None, **params):\n        time.sleep(initial_delay)\n        poll_response = None\n\n        if is_complete_callback == None:\n            is_complete_callback = self._default_poll_callback\n\n        for n in range(tries):\n            poll_response = self.make_request(url, headers=self._headers(),\n                                              errors=errors, **params)\n\n            if is_complete_callback(poll_response):\n                return poll_response\n            else:\n                time.sleep(delay)\n\n        if STRICT == errors:\n            raise ExceededRetries(\n                \"Failed to poll within {0} tries.\".format(tries))\n        else:\n            return poll_response", "response": "Poll the URL url and return the response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck the condition in poll response to determine if it is complete and no subsequent poll requests should be done.", "response": "def _default_poll_callback(self, poll_resp):\n        \"\"\"\n        Checks the condition in poll response to determine if it is complete\n        and no subsequent poll requests should be done.\n        \"\"\"\n        if poll_resp.parsed is None:\n            return False\n        success_list = ['UpdatesComplete', True, 'COMPLETE']\n        status = None\n        if self.response_format == 'xml':\n            status = poll_resp.parsed.find('./Status').text\n        elif self.response_format == 'json':\n            status = poll_resp.parsed.get(\n                'Status', poll_resp.parsed.get('status'))\n        if status is None:\n            raise RuntimeError('Unable to get poll response status.')\n        return status in success_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _fsic_queuing_calc(fsic1, fsic2):\n    return {instance: fsic2.get(instance, 0) for instance, counter in six.iteritems(fsic1) if fsic2.get(instance, 0) < counter}", "response": "Calculate the lower counter between two fsics."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _serialize_into_store(profile, filter=None):\n    # ensure that we write and retrieve the counter in one go for consistency\n    current_id = InstanceIDModel.get_current_instance_and_increment_counter()\n\n    with transaction.atomic():\n        # create Q objects for filtering by prefixes\n        prefix_condition = None\n        if filter:\n            prefix_condition = functools.reduce(lambda x, y: x | y, [Q(_morango_partition__startswith=prefix) for prefix in filter])\n\n        # filter through all models with the dirty bit turned on\n        syncable_dict = _profile_models[profile]\n        for (_, klass_model) in six.iteritems(syncable_dict):\n            new_store_records = []\n            new_rmc_records = []\n            klass_queryset = klass_model.objects.filter(_morango_dirty_bit=True)\n            if prefix_condition:\n                klass_queryset = klass_queryset.filter(prefix_condition)\n            store_records_dict = Store.objects.in_bulk(id_list=klass_queryset.values_list('id', flat=True))\n            for app_model in klass_queryset:\n                try:\n                    store_model = store_records_dict[app_model.id]\n\n                    # if store record dirty and app record dirty, append store serialized to conflicting data\n                    if store_model.dirty_bit:\n                        store_model.conflicting_serialized_data = store_model.serialized + \"\\n\" + store_model.conflicting_serialized_data\n                        store_model.dirty_bit = False\n\n                    # set new serialized data on this store model\n                    ser_dict = json.loads(store_model.serialized)\n                    ser_dict.update(app_model.serialize())\n                    store_model.serialized = DjangoJSONEncoder().encode(ser_dict)\n\n                    # create or update instance and counter on the record max counter for this store model\n                    RecordMaxCounter.objects.update_or_create(defaults={'counter': current_id.counter},\n                                                              instance_id=current_id.id,\n                                                              store_model_id=store_model.id)\n\n                    # update last saved bys for this store model\n                    store_model.last_saved_instance = current_id.id\n                    store_model.last_saved_counter = current_id.counter\n                    # update deleted flags in case it was previously deleted\n                    store_model.deleted = False\n                    store_model.hard_deleted = False\n\n                    # update this model\n                    store_model.save()\n\n                except KeyError:\n                    kwargs = {\n                        'id': app_model.id,\n                        'serialized': DjangoJSONEncoder().encode(app_model.serialize()),\n                        'last_saved_instance': current_id.id,\n                        'last_saved_counter': current_id.counter,\n                        'model_name': app_model.morango_model_name,\n                        'profile': app_model.morango_profile,\n                        'partition': app_model._morango_partition,\n                        'source_id': app_model._morango_source_id,\n                    }\n                    # check if model has FK pointing to it and add the value to a field on the store\n                    self_ref_fk = _self_referential_fk(klass_model)\n                    if self_ref_fk:\n                        self_ref_fk_value = getattr(app_model, self_ref_fk)\n                        kwargs.update({'_self_ref_fk': self_ref_fk_value or ''})\n                    # create store model and record max counter for the app model\n                    new_store_records.append(Store(**kwargs))\n                    new_rmc_records.append(RecordMaxCounter(store_model_id=app_model.id, instance_id=current_id.id, counter=current_id.counter))\n\n            # bulk create store and rmc records for this class\n            Store.objects.bulk_create(new_store_records)\n            RecordMaxCounter.objects.bulk_create(new_rmc_records)\n\n            # set dirty bit to false for all instances of this model\n            klass_queryset.update(update_dirty_bit_to=False)\n\n        # get list of ids of deleted models\n        deleted_ids = DeletedModels.objects.filter(profile=profile).values_list('id', flat=True)\n        # update last_saved_bys and deleted flag of all deleted store model instances\n        deleted_store_records = Store.objects.filter(id__in=deleted_ids)\n        deleted_store_records.update(dirty_bit=False, deleted=True, last_saved_instance=current_id.id, last_saved_counter=current_id.counter)\n        # update rmcs counters for deleted models that have our instance id\n        RecordMaxCounter.objects.filter(instance_id=current_id.id, store_model_id__in=deleted_ids).update(counter=current_id.counter)\n        # get a list of deleted model ids that don't have an rmc for our instance id\n        new_rmc_ids = deleted_store_records.exclude(recordmaxcounter__instance_id=current_id.id).values_list(\"id\", flat=True)\n        # bulk create these new rmcs\n        RecordMaxCounter.objects.bulk_create([RecordMaxCounter(store_model_id=r_id, instance_id=current_id.id, counter=current_id.counter) for r_id in new_rmc_ids])\n        # clear deleted models table for this profile\n        DeletedModels.objects.filter(profile=profile).delete()\n\n        # handle logic for hard deletion models\n        hard_deleted_ids = HardDeletedModels.objects.filter(profile=profile).values_list('id', flat=True)\n        hard_deleted_store_records = Store.objects.filter(id__in=hard_deleted_ids)\n        hard_deleted_store_records.update(hard_deleted=True, serialized='{}', conflicting_serialized_data='')\n        HardDeletedModels.objects.filter(profile=profile).delete()\n\n        # update our own database max counters after serialization\n        if not filter:\n            DatabaseMaxCounter.objects.update_or_create(instance_id=current_id.id, partition=\"\", defaults={'counter': current_id.counter})\n        else:\n            for f in filter:\n                DatabaseMaxCounter.objects.update_or_create(instance_id=current_id.id, partition=f, defaults={'counter': current_id.counter})", "response": "Takes data from app layer and serializes the models into the store."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _deserialize_from_store(profile):\n    # we first serialize to avoid deserialization merge conflicts\n    _serialize_into_store(profile)\n\n    fk_cache = {}\n    with transaction.atomic():\n        syncable_dict = _profile_models[profile]\n        excluded_list = []\n        # iterate through classes which are in foreign key dependency order\n        for model_name, klass_model in six.iteritems(syncable_dict):\n            # handle cases where a class has a single FK reference to itself\n            self_ref_fk = _self_referential_fk(klass_model)\n            query = Q(model_name=klass_model.morango_model_name)\n            for klass in klass_model.morango_model_dependencies:\n                query |= Q(model_name=klass.morango_model_name)\n            if self_ref_fk:\n                clean_parents = Store.objects.filter(dirty_bit=False, profile=profile).filter(query).char_ids_list()\n                dirty_children = Store.objects.filter(dirty_bit=True, profile=profile) \\\n                                              .filter(Q(_self_ref_fk__in=clean_parents) | Q(_self_ref_fk='')).filter(query)\n\n                # keep iterating until size of dirty_children is 0\n                while len(dirty_children) > 0:\n                    for store_model in dirty_children:\n                        try:\n                            app_model = store_model._deserialize_store_model(fk_cache)\n                            if app_model:\n                                with mute_signals(signals.pre_save, signals.post_save):\n                                    app_model.save(update_dirty_bit_to=False)\n                            # we update a store model after we have deserialized it to be able to mark it as a clean parent\n                            store_model.dirty_bit = False\n                            store_model.save(update_fields=['dirty_bit'])\n                        except exceptions.ValidationError:\n                            # if the app model did not validate, we leave the store dirty bit set\n                            excluded_list.append(store_model.id)\n\n                    # update lists with new clean parents and dirty children\n                    clean_parents = Store.objects.filter(dirty_bit=False, profile=profile).filter(query).char_ids_list()\n                    dirty_children = Store.objects.filter(dirty_bit=True, profile=profile, _self_ref_fk__in=clean_parents).filter(query)\n            else:\n                # array for holding db values from the fields of each model for this class\n                db_values = []\n                fields = klass_model._meta.fields\n                for store_model in Store.objects.filter(model_name=model_name, profile=profile, dirty_bit=True):\n                    try:\n                        app_model = store_model._deserialize_store_model(fk_cache)\n                        # if the model was not deleted add its field values to the list\n                        if app_model:\n                            for f in fields:\n                                value = getattr(app_model, f.attname)\n                                db_value = f.get_db_prep_value(value, connection)\n                                db_values.append(db_value)\n                    except exceptions.ValidationError:\n                        # if the app model did not validate, we leave the store dirty bit set\n                        excluded_list.append(store_model.id)\n\n                if db_values:\n                    # number of rows to update\n                    num_of_rows = len(db_values) // len(fields)\n                    # create '%s' placeholders for a single row\n                    placeholder_tuple = tuple(['%s' for _ in range(len(fields))])\n                    # create list of the '%s' tuple placeholders based on number of rows to update\n                    placeholder_list = [str(placeholder_tuple) for _ in range(num_of_rows)]\n                    with connection.cursor() as cursor:\n                        DBBackend._bulk_insert_into_app_models(cursor, klass_model._meta.db_table, fields, db_values, placeholder_list)\n\n        # clear dirty bit for all store models for this profile except for models that did not validate\n        Store.objects.exclude(id__in=excluded_list).filter(profile=profile, dirty_bit=True).update(dirty_bit=False)", "response": "Deserializes data from the store into the application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nqueue all data into the buffer.", "response": "def _queue_into_buffer(transfersession):\n    \"\"\"\n    Takes a chunk of data from the store to be put into the buffer to be sent to another morango instance.\n    \"\"\"\n    last_saved_by_conditions = []\n    filter_prefixes = Filter(transfersession.filter)\n    server_fsic = json.loads(transfersession.server_fsic)\n    client_fsic = json.loads(transfersession.client_fsic)\n\n    if transfersession.push:\n        fsics = _fsic_queuing_calc(client_fsic, server_fsic)\n    else:\n        fsics = _fsic_queuing_calc(server_fsic, client_fsic)\n\n    # if fsics are identical or receiving end has newer data, then there is nothing to queue\n    if not fsics:\n        return\n\n    # create condition for all push FSICs where instance_ids are equal, but internal counters are higher than FSICs counters\n    for instance, counter in six.iteritems(fsics):\n        last_saved_by_conditions += [\"(last_saved_instance = '{0}' AND last_saved_counter > {1})\".format(instance, counter)]\n    if fsics:\n        last_saved_by_conditions = [_join_with_logical_operator(last_saved_by_conditions, 'OR')]\n\n    partition_conditions = []\n    # create condition for filtering by partitions\n    for prefix in filter_prefixes:\n        partition_conditions += [\"partition LIKE '{}%'\".format(prefix)]\n    if filter_prefixes:\n        partition_conditions = [_join_with_logical_operator(partition_conditions, 'OR')]\n\n    # combine conditions\n    fsic_and_partition_conditions = _join_with_logical_operator(last_saved_by_conditions + partition_conditions, 'AND')\n\n    # filter by profile\n    where_condition = _join_with_logical_operator([fsic_and_partition_conditions, \"profile = '{}'\".format(transfersession.sync_session.profile)], 'AND')\n\n    # execute raw sql to take all records that match condition, to be put into buffer for transfer\n    with connection.cursor() as cursor:\n        queue_buffer = \"\"\"INSERT INTO {outgoing_buffer}\n                        (model_uuid, serialized, deleted, last_saved_instance, last_saved_counter, hard_deleted,\n                         model_name, profile, partition, source_id, conflicting_serialized_data, transfer_session_id, _self_ref_fk)\n                        SELECT id, serialized, deleted, last_saved_instance, last_saved_counter, hard_deleted, model_name, profile, partition, source_id, conflicting_serialized_data, '{transfer_session_id}', _self_ref_fk\n                        FROM {store} WHERE {condition}\"\"\".format(outgoing_buffer=Buffer._meta.db_table,\n                                                                 transfer_session_id=transfersession.id,\n                                                                 condition=where_condition,\n                                                                 store=Store._meta.db_table)\n        cursor.execute(queue_buffer)\n        # take all record max counters that are foreign keyed onto store models, which were queued into the buffer\n        queue_rmc_buffer = \"\"\"INSERT INTO {outgoing_rmcb}\n                            (instance_id, counter, transfer_session_id, model_uuid)\n                            SELECT instance_id, counter, '{transfer_session_id}', store_model_id\n                            FROM {record_max_counter} AS rmc\n                            INNER JOIN {outgoing_buffer} AS buffer ON rmc.store_model_id = buffer.model_uuid\n                            WHERE buffer.transfer_session_id = '{transfer_session_id}'\n                            \"\"\".format(outgoing_rmcb=RecordMaxCounterBuffer._meta.db_table,\n                                       transfer_session_id=transfersession.id,\n                                       record_max_counter=RecordMaxCounter._meta.db_table,\n                                       outgoing_buffer=Buffer._meta.db_table)\n        cursor.execute(queue_rmc_buffer)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes data from the buffers and merges into the store and record max counters.", "response": "def _dequeue_into_store(transfersession):\n    \"\"\"\n    Takes data from the buffers and merges into the store and record max counters.\n    \"\"\"\n    with connection.cursor() as cursor:\n        DBBackend._dequeuing_delete_rmcb_records(cursor, transfersession.id)\n        DBBackend._dequeuing_delete_buffered_records(cursor, transfersession.id)\n        current_id = InstanceIDModel.get_current_instance_and_increment_counter()\n        DBBackend._dequeuing_merge_conflict_buffer(cursor, current_id, transfersession.id)\n        DBBackend._dequeuing_merge_conflict_rmcb(cursor, transfersession.id)\n        DBBackend._dequeuing_update_rmcs_last_saved_by(cursor, current_id, transfersession.id)\n        DBBackend._dequeuing_delete_mc_rmcb(cursor, transfersession.id)\n        DBBackend._dequeuing_delete_mc_buffer(cursor, transfersession.id)\n        DBBackend._dequeuing_insert_remaining_buffer(cursor, transfersession.id)\n        DBBackend._dequeuing_insert_remaining_rmcb(cursor, transfersession.id)\n        DBBackend._dequeuing_delete_remaining_rmcb(cursor, transfersession.id)\n        DBBackend._dequeuing_delete_remaining_buffer(cursor, transfersession.id)\n    if getattr(settings, 'MORANGO_DESERIALIZE_AFTER_DEQUEUING', True):\n        _deserialize_from_store(transfersession.sync_session.profile)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef max_parameter_substitution():\n    if os.path.isfile(SQLITE_VARIABLE_FILE_CACHE):\n        return\n    conn = sqlite3.connect(':memory:')\n    low = 1\n    high = 1000  # hard limit for SQLITE_MAX_VARIABLE_NUMBER <http://www.sqlite.org/limits.html>\n    conn.execute('CREATE TABLE T1 (id C1)')\n    while low < high - 1:\n        guess = (low + high) // 2\n        try:\n            statement = 'select * from T1 where id in (%s)' % ','.join(['?' for _ in range(guess)])\n            values = [i for i in range(guess)]\n            conn.execute(statement, values)\n        except sqlite3.DatabaseError as ex:\n            if 'too many SQL variables' in str(ex):\n                high = guess\n            else:\n                raise\n        else:\n            low = guess\n    conn.close()\n    with open(SQLITE_VARIABLE_FILE_CACHE, 'w') as file:\n        file.write(str(low))", "response": "SQLite has a limit on the maximum number of variables allowed for parameter substitution. This limit is usually 999 but we can t use the max number of variables allowed for parameter substitution."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nauthenticate the userargs and password against Django s auth backends.", "response": "def authenticate_credentials(self, userargs, password, request=None):\n        \"\"\"\n        Authenticate the userargs and password against Django auth backends.\n        The \"userargs\" string may be just the username, or a querystring-encoded set of params.\n        \"\"\"\n\n        credentials = {\n            'password': password\n        }\n\n        if \"=\" not in userargs:\n            # if it doesn't seem to be in querystring format, just use it as the username\n            credentials[get_user_model().USERNAME_FIELD] = userargs\n        else:\n            # parse out the user args from querystring format into the credentials dict\n            for arg in userargs.split(\"&\"):\n                key, val = arg.split(\"=\")\n                credentials[key] = val\n\n        # authenticate the user via Django's auth backends\n        user = authenticate(**credentials)\n\n        if user is None:\n            raise exceptions.AuthenticationFailed('Invalid credentials.')\n\n        if not user.is_active:\n            raise exceptions.AuthenticationFailed('User inactive or deleted.')\n\n        return (user, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _multiple_self_ref_fk_check(class_model):\n    self_fk = []\n    for f in class_model._meta.concrete_fields:\n        if f.related_model in self_fk:\n            return True\n        if f.related_model == class_model:\n            self_fk.append(class_model)\n    return False", "response": "Check whether a class has more than one FK reference to itself."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_syncable_models():\n\n    import django.apps\n    from morango.models import SyncableModel\n    from morango.manager import SyncableModelManager\n    from morango.query import SyncableModelQuerySet\n\n    model_list = []\n    for model_class in django.apps.apps.get_models():\n        # several validation checks to assert models will be syncing correctly\n        if issubclass(model_class, SyncableModel):\n            name = model_class.__name__\n            if _multiple_self_ref_fk_check(model_class):\n                raise InvalidMorangoModelConfiguration(\"Syncing models with more than 1 self referential ForeignKey is not supported.\")\n            try:\n                from mptt import models\n                from morango.utils.morango_mptt import MorangoMPTTModel, MorangoMPTTTreeManager, MorangoTreeQuerySet\n                # mptt syncable model checks\n                if issubclass(model_class, models.MPTTModel):\n                    if not issubclass(model_class, MorangoMPTTModel):\n                        raise InvalidMorangoModelConfiguration(\"{} that inherits from MPTTModel, should instead inherit from MorangoMPTTModel.\".format(name))\n                    if not isinstance(model_class.objects, MorangoMPTTTreeManager):\n                        raise InvalidMPTTManager(\"Manager for {} must inherit from MorangoMPTTTreeManager.\".format(name))\n                    if not isinstance(model_class.objects.none(), MorangoTreeQuerySet):\n                        raise InvalidMPTTQuerySet(\"Queryset for {} model must inherit from MorangoTreeQuerySet.\".format(name))\n            except ImportError:\n                pass\n            # syncable model checks\n            if not isinstance(model_class.objects, SyncableModelManager):\n                raise InvalidSyncableManager(\"Manager for {} must inherit from SyncableModelManager.\".format(name))\n            if not isinstance(model_class.objects.none(), SyncableModelQuerySet):\n                raise InvalidSyncableQueryset(\"Queryset for {} model must inherit from SyncableModelQuerySet.\".format(name))\n            if model_class._meta.many_to_many:\n                raise UnsupportedFieldType(\"{} model with a ManyToManyField is not supported in morango.\")\n            if not hasattr(model_class, 'morango_model_name'):\n                raise InvalidMorangoModelConfiguration(\"{} model must define a morango_model_name attribute\".format(name))\n            if not hasattr(model_class, 'morango_profile'):\n                raise InvalidMorangoModelConfiguration(\"{} model must define a morango_profile attribute\".format(name))\n\n            # create empty list to hold model classes for profile if not yet created\n            profile = model_class.morango_profile\n            _profile_models[profile] = _profile_models.get(profile, [])\n\n            # don't sync models where morango_model_name is None\n            if model_class.morango_model_name is not None:\n                _insert_model_into_profile_dict(model_class, profile)\n\n    # for each profile, create a dict mapping from morango model names to model class\n    for profile, model_list in iteritems(_profile_models):\n        syncable_models_dict = OrderedDict()\n        for model_class in model_list:\n            syncable_models_dict[model_class.morango_model_name] = model_class\n        _profile_models[profile] = syncable_models_dict", "response": "Add syncable models to the internal list of models."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbulk insert into app - models.", "response": "def _bulk_insert_into_app_models(self, cursor, app_model, fields, db_values, placeholder_list):\n        \"\"\"\n        Example query:\n        `REPLACE INTO model (F1,F2,F3) VALUES (%s, %s, %s), (%s, %s, %s), (%s, %s, %s)`\n        where values=[1,2,3,4,5,6,7,8,9]\n        \"\"\"\n        # calculate and create equal sized chunks of data to insert incrementally\n        num_of_rows_able_to_insert = self.SQLITE_MAX_VARIABLE_NUMBER // len(fields)\n        num_of_values_able_to_insert = num_of_rows_able_to_insert * len(fields)\n        value_chunks = [db_values[x:x + num_of_values_able_to_insert] for x in range(0, len(db_values), num_of_values_able_to_insert)]\n        placeholder_chunks = [placeholder_list[x: x + num_of_rows_able_to_insert] for x in range(0, len(placeholder_list), num_of_rows_able_to_insert)]\n        # insert data chunks\n        fields = str(tuple(str(f.attname) for f in fields)).replace(\"'\", '')\n        for values, params in zip(value_chunks, placeholder_chunks):\n            placeholder_str = ', '.join(params).replace(\"'\", '')\n            insert = \"\"\"REPLACE INTO {app_model} {fields}\n                        VALUES {placeholder_str}\n            \"\"\".format(app_model=app_model, fields=fields, placeholder_str=placeholder_str)\n            # use DB-APIs parameter substitution (2nd parameter expects a sequence)\n            cursor.execute(insert, values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fuzzyfinder(input, collection, accessor=lambda x: x, sort_results=True):\n    suggestions = []\n    input = str(input) if not isinstance(input, str) else input\n    pat = '.*?'.join(map(re.escape, input))\n    pat = '(?=({0}))'.format(pat)   # lookahead regex to manage overlapping matches\n    regex = re.compile(pat, re.IGNORECASE)\n    for item in collection:\n        r = list(regex.finditer(accessor(item)))\n        if r:\n            best = min(r, key=lambda x: len(x.group(1)))   # find shortest match\n            suggestions.append((len(best.group(1)), best.start(), accessor(item), item))\n\n    if sort_results:\n        return (z[-1] for z in sorted(suggestions))\n    else:\n        return (z[-1] for z in sorted(suggestions, key=lambda x: x[:2]))", "response": "Returns a generator that yields a list of fuzzy matches for the input string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_access_token(self, valid_in_hours=1, data=None):\n        data = data or {}\n        token = AccessToken(\n            token=self.generate(),\n            expires_at=expires_at(hours=valid_in_hours),\n            data=data)\n        return token", "response": "Creates an access token."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstore an OWS service in mongodb.", "response": "def save_service(self, service, overwrite=True):\n        \"\"\"\n        Stores an OWS service in mongodb.\n        \"\"\"\n        name = namesgenerator.get_sane_name(service.name)\n        if not name:\n            name = namesgenerator.get_random_name()\n            if self.collection.count_documents({'name': name}) > 0:\n                name = namesgenerator.get_random_name(retry=True)\n        # check if service is already registered\n        if self.collection.count_documents({'name': name}) > 0:\n            if overwrite:\n                self.collection.delete_one({'name': name})\n            else:\n                raise Exception(\"service name already registered.\")\n        self.collection.insert_one(Service(\n            name=name,\n            url=baseurl(service.url),\n            type=service.type,\n            purl=service.purl,\n            public=service.public,\n            auth=service.auth,\n            verify=service.verify))\n        return self.fetch_by_name(name=name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist all services in mongodb storage.", "response": "def list_services(self):\n        \"\"\"\n        Lists all services in mongodb storage.\n        \"\"\"\n        my_services = []\n        for service in self.collection.find().sort('name', pymongo.ASCENDING):\n            my_services.append(Service(service))\n        return my_services"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch_by_name(self, name):\n        service = self.collection.find_one({'name': name})\n        if not service:\n            raise ServiceNotFound\n        return Service(service)", "response": "Gets a service by its name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fetch_by_url(self, url):\n        service = self.collection.find_one({'url': url})\n        if not service:\n            raise ServiceNotFound\n        return Service(service)", "response": "Gets a service by url."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new object that is a proxy of the current object.", "response": "def owsproxy(request):\n    \"\"\"\n    TODO: use ows exceptions\n    \"\"\"\n    try:\n        service_name = request.matchdict.get('service_name')\n        extra_path = request.matchdict.get('extra_path')\n        store = servicestore_factory(request.registry)\n        service = store.fetch_by_name(service_name)\n    except Exception as err:\n        # TODO: Store impl should raise appropriate exception like not authorized\n        return OWSAccessFailed(\"Could not find service {0} : {1}.\".format(service_name, err.message))\n    else:\n        return _send_request(request, service, extra_path, request_params=request.query_string)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef owsproxy_delegate(request):\n    twitcher_url = request.registry.settings.get('twitcher.url')\n    protected_path = request.registry.settings.get('twitcher.ows_proxy_protected_path', '/ows')\n    url = twitcher_url + protected_path + '/proxy'\n    if request.matchdict.get('service_name'):\n        url += '/' + request.matchdict.get('service_name')\n        if request.matchdict.get('access_token'):\n            url += '/' + request.matchdict.get('service_name')\n    url += '?' + urlparse.urlencode(request.params)\n    LOGGER.debug(\"delegate to owsproxy: %s\", url)\n    # forward request to target (without Host Header)\n    # h = dict(request.headers)\n    # h.pop(\"Host\", h)\n    resp = requests.request(method=request.method.upper(), url=url, data=request.body,\n                            headers=request.headers, verify=False)\n    return Response(resp.content, status=resp.status_code, headers=resp.headers)", "response": "Delegates owsproxy request to external twitcher service."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ows_security_tween_factory(handler, registry):\n\n    security = owssecurity_factory(registry)\n\n    def ows_security_tween(request):\n        try:\n            security.check_request(request)\n            return handler(request)\n        except OWSException as err:\n            logger.exception(\"security check failed.\")\n            return err\n        except Exception as err:\n            logger.exception(\"unknown error\")\n            return OWSNoApplicableCode(\"{}\".format(err))\n\n    return ows_security_tween", "response": "A tween factory which produces a tween which raises an exception\n            if access to OWS service is not allowed."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main(global_config, **settings):\n    from pyramid.config import Configurator\n\n    config = Configurator(settings=settings)\n\n    # include twitcher components\n    config.include('twitcher.config')\n    config.include('twitcher.frontpage')\n    config.include('twitcher.rpcinterface')\n    config.include('twitcher.owsproxy')\n\n    # tweens/middleware\n    # TODO: maybe add tween for exception handling or use unknown_failure view\n    config.include('twitcher.tweens')\n\n    config.scan()\n\n    return config.make_wsgi_app()", "response": "This function returns a Pyramid WSGI application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving a token from the cache.", "response": "def revoke_token(self, token):\n        \"\"\"\n        Implementation of :meth:`twitcher.api.ITokenManager.revoke_token`.\n        \"\"\"\n        try:\n            self.store.delete_token(token)\n        except Exception:\n            LOGGER.exception('Failed to remove token.')\n            return False\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef revoke_all_tokens(self):\n        try:\n            self.store.clear_tokens()\n        except Exception:\n            LOGGER.exception('Failed to remove tokens.')\n            return False\n        else:\n            return True", "response": "Removes all tokens from the store."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_service(self, url, data=None, overwrite=True):\n        data = data or {}\n\n        args = dict(data)\n        args['url'] = url\n        service = Service(**args)\n        service = self.store.save_service(service, overwrite=overwrite)\n        return service.params", "response": "Implementation of twitcher. api. IRegistry. register_service."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unregister_service(self, name):\n        try:\n            self.store.delete_service(name=name)\n        except Exception:\n            LOGGER.exception('unregister failed')\n            return False\n        else:\n            return True", "response": "Unregisters a service from the registry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clear_services(self):\n        try:\n            self.store.clear_services()\n        except Exception:\n            LOGGER.error('Clear services failed.')\n            return False\n        else:\n            return True", "response": "Clear the services of the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nincludes the XML - RPC interface in a Pyramid application.", "response": "def includeme(config):\n    \"\"\" The callable makes it possible to include rpcinterface\n    in a Pyramid application.\n\n    Calling ``config.include(twitcher.rpcinterface)`` will result in this\n    callable being called.\n\n    Arguments:\n\n    * ``config``: the ``pyramid.config.Configurator`` object.\n    \"\"\"\n    settings = config.registry.settings\n\n    if asbool(settings.get('twitcher.rpcinterface', True)):\n        LOGGER.debug('Twitcher XML-RPC Interface enabled.')\n\n        # include twitcher config\n        config.include('twitcher.config')\n\n        # using basic auth\n        config.include('twitcher.basicauth')\n\n        # pyramid xml-rpc\n        # http://docs.pylonsproject.org/projects/pyramid-rpc/en/latest/xmlrpc.html\n        config.include('pyramid_rpc.xmlrpc')\n        config.include('twitcher.db')\n        config.add_xmlrpc_endpoint('api', '/RPC2')\n\n        # register xmlrpc methods\n        config.add_xmlrpc_method(RPCInterface, attr='generate_token', endpoint='api', method='generate_token')\n        config.add_xmlrpc_method(RPCInterface, attr='revoke_token', endpoint='api', method='revoke_token')\n        config.add_xmlrpc_method(RPCInterface, attr='revoke_all_tokens', endpoint='api', method='revoke_all_tokens')\n        config.add_xmlrpc_method(RPCInterface, attr='register_service', endpoint='api', method='register_service')\n        config.add_xmlrpc_method(RPCInterface, attr='unregister_service', endpoint='api', method='unregister_service')\n        config.add_xmlrpc_method(RPCInterface, attr='get_service_by_name', endpoint='api', method='get_service_by_name')\n        config.add_xmlrpc_method(RPCInterface, attr='get_service_by_url', endpoint='api', method='get_service_by_url')\n        config.add_xmlrpc_method(RPCInterface, attr='clear_services', endpoint='api', method='clear_services')\n        config.add_xmlrpc_method(RPCInterface, attr='list_services', endpoint='api', method='list_services')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_service(self, service, overwrite=True):\n        name = namesgenerator.get_sane_name(service.name)\n        if not name:\n            name = namesgenerator.get_random_name()\n            if name in self.name_index:\n                name = namesgenerator.get_random_name(retry=True)\n        # check if service is already registered\n        if name in self.name_index:\n            if overwrite:\n                self._delete(name=name)\n            else:\n                raise Exception(\"service name already registered.\")\n        self._insert(Service(\n            name=name,\n            url=baseurl(service.url),\n            type=service.type,\n            purl=service.purl,\n            public=service.public,\n            auth=service.auth,\n            verify=service.verify))\n        return self.fetch_by_name(name=name)", "response": "Save an OWS service in database."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists all services in memory storage.", "response": "def list_services(self):\n        \"\"\"\n        Lists all services in memory storage.\n        \"\"\"\n        my_services = []\n        for service in self.name_index.values():\n            my_services.append(Service(service))\n        return my_services"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfetch a service by its name.", "response": "def fetch_by_name(self, name):\n        \"\"\"\n        Get service for given ``name`` from memory storage.\n        \"\"\"\n        service = self.name_index.get(name)\n        if not service:\n            raise ServiceNotFound\n        return Service(service)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving a new private key and certificate request and returns the certificate.", "response": "def _retrieve_certificate(self, access_token, timeout=3):\n        \"\"\"\n        Generates a new private key and certificate request, submits the request to be\n        signed by the SLCS CA and returns the certificate.\n        \"\"\"\n        logger.debug(\"Retrieve certificate with token.\")\n\n        # Generate a new key pair\n        key_pair = crypto.PKey()\n        key_pair.generate_key(crypto.TYPE_RSA, 2048)\n        private_key = crypto.dump_privatekey(crypto.FILETYPE_PEM, key_pair).decode(\"utf-8\")\n\n        # Generate a certificate request using that key-pair\n        cert_request = crypto.X509Req()\n\n        # Create public key object\n        cert_request.set_pubkey(key_pair)\n\n        # Add the public key to the request\n        cert_request.sign(key_pair, 'md5')\n        der_cert_req = crypto.dump_certificate_request(crypto.FILETYPE_ASN1, cert_request)\n\n        encoded_cert_req = base64.b64encode(der_cert_req)\n\n        # Build the OAuth session object\n        token = {'access_token': access_token, 'token_type': 'Bearer'}\n        client = OAuth2Session(token=token)\n\n        response = client.post(\n            self.certificate_url,\n            data={'certificate_request': encoded_cert_req},\n            verify=False,\n            timeout=timeout,\n        )\n\n        if response.ok:\n            content = \"{} {}\".format(response.text, private_key)\n            with open(self.esgf_credentials, 'w') as fh:\n                fh.write(content)\n            logger.debug('Fetched certificate successfully.')\n        else:\n            msg = \"Could not get certificate: {} {}\".format(response.status_code, response.reason)\n            raise Exception(msg)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tokenstore_factory(registry, database=None):\n    database = database or 'mongodb'\n    if database == 'mongodb':\n        db = _mongodb(registry)\n        store = MongodbTokenStore(db.tokens)\n    else:\n        store = MemoryTokenStore()\n    return store", "response": "Returns an instance of TokenStore with the interface of twitcher. store. AccessTokenStore."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef servicestore_factory(registry, database=None):\n    database = database or 'mongodb'\n    if database == 'mongodb':\n        db = _mongodb(registry)\n        store = MongodbServiceStore(collection=db.services)\n    else:\n        store = MemoryServiceStore()\n    return store", "response": "Returns an instance of the service store."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a random name from the list of adjectives and birds in this package formatted as adjective_surname. For example loving_sugarbird3.", "response": "def get_random_name(retry=False):\n    \"\"\"\n    generates a random name from the list of adjectives and birds in this package\n    formatted as \"adjective_surname\". For example 'loving_sugarbird'. If retry is non-zero, a random\n    integer between 0 and 100 will be added to the end of the name, e.g `loving_sugarbird3`\n    \"\"\"\n    name = \"%s_%s\" % (left[random.randint(0, len(left) - 1)], right[random.randint(0, len(right) - 1)])\n    if retry is True:\n        name = \"%s%d\" % (name, random.randint(0, 100))\n    return name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget parameter in GET request.", "response": "def _get_param(self, param, allowed_values=None, optional=False):\n        \"\"\"Get parameter in GET request.\"\"\"\n        request_params = self._request_params()\n        if param in request_params:\n            value = request_params[param].lower()\n            if allowed_values is not None:\n                if value in allowed_values:\n                    self.params[param] = value\n                else:\n                    raise OWSInvalidParameterValue(\"%s %s is not supported\" % (param, value), value=param)\n        elif optional:\n            self.params[param] = None\n        else:\n            raise OWSMissingParameterValue('Parameter \"%s\" is missing' % param, value=param)\n        return self.params[param]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding requested version in GET request.", "response": "def _get_version(self):\n        \"\"\"Find requested version in GET request.\"\"\"\n        version = self._get_param(param=\"version\", allowed_values=allowed_versions[self.params['service']],\n                                  optional=True)\n        if version is None and self._get_request_type() != \"getcapabilities\":\n            raise OWSMissingParameterValue('Parameter \"version\" is missing', value=\"version\")\n        else:\n            return version"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_service(self):\n        if \"service\" in self.document.attrib:\n            value = self.document.attrib[\"service\"].lower()\n            if value in allowed_service_types:\n                self.params[\"service\"] = value\n            else:\n                raise OWSInvalidParameterValue(\"Service %s is not supported\" % value, value=\"service\")\n        else:\n            raise OWSMissingParameterValue('Parameter \"service\" is missing', value=\"service\")\n        return self.params[\"service\"]", "response": "Check mandatory service name parameter in POST request."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_request_type(self):\n        value = self.document.tag.lower()\n        if value in allowed_request_types[self.params['service']]:\n            self.params[\"request\"] = value\n        else:\n            raise OWSInvalidParameterValue(\"Request type %s is not supported\" % value, value=\"request\")\n        return self.params[\"request\"]", "response": "Find requested request type in POST request."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_version(self):\n        if \"version\" in self.document.attrib:\n            value = self.document.attrib[\"version\"].lower()\n            if value in allowed_versions[self.params['service']]:\n                self.params[\"version\"] = value\n            else:\n                raise OWSInvalidParameterValue(\"Version %s is not supported\" % value, value=\"version\")\n        elif self._get_request_type() == \"getcapabilities\":\n            self.params[\"version\"] = None\n        else:\n            raise OWSMissingParameterValue('Parameter \"version\" is missing', value=\"version\")\n        return self.params[\"version\"]", "response": "Find requested version in POST request."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprovides a timzeone - aware object for a given datetime and timezone name", "response": "def localize_datetime(dt, tz_name='UTC'):\n    \"\"\"Provide a timzeone-aware object for a given datetime and timezone name\n    \"\"\"\n    tz_aware_dt = dt\n    if dt.tzinfo is None:\n        utc = pytz.timezone('UTC')\n        aware = utc.localize(dt)\n        timezone = pytz.timezone(tz_name)\n        tz_aware_dt = aware.astimezone(timezone)\n    else:\n        logger.warn('tzinfo already set')\n    return tz_aware_dt"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning base url of given url", "response": "def baseurl(url):\n    \"\"\"\n    return baseurl of given url\n    \"\"\"\n    parsed_url = urlparse.urlparse(url)\n    if not parsed_url.netloc or parsed_url.scheme not in (\"http\", \"https\"):\n        raise ValueError('bad url')\n    service_url = \"%s://%s%s\" % (parsed_url.scheme, parsed_url.netloc, parsed_url.path.strip())\n    return service_url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nverify ssl service certificate.", "response": "def verify(self):\n        \"\"\"Verify ssl service certificate.\"\"\"\n        value = self.get('verify', 'true')\n        if isinstance(value, bool):\n            verify = value\n        elif value.lower() == 'true':\n            verify = True\n        elif value.lower() == 'false':\n            verify = False\n        else:\n            verify = value\n        return verify"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tag(self, label, message=None):\n        notify.warning('Unsupported SCM: Make sure you apply the \"{}\" tag after commit!{}'.format(\n            label, ' [message={}]'.format(message) if message else '',\n        ))", "response": "Tag the current workdir state with the given label."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a PEP - 440 dev version appendix to the main version number.", "response": "def pep440_dev_version(self, verbose=False, non_local=False):\n        \"\"\"Return a PEP-440 dev version appendix to the main version number.\"\"\"\n        # Always return a timestamp\n        pep440 = '.dev{:%Y%m%d%H%M}'.format(datetime.now())\n\n        if not non_local:\n            build_number = os.environ.get('BUILD_NUMBER', 'n/a')\n            if build_number.isdigit():\n                pep440 += '+ci.{}'.format(build_number)\n                if verbose:\n                    notify.info(\"Adding CI build ID #{} to version\".format(build_number))\n\n        return pep440"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls setup. py egg_info and return the parsed meta - data.", "response": "def get_egg_info(cfg, verbose=False):\n    \"\"\"Call 'setup egg_info' and return the parsed meta-data.\"\"\"\n    result = Bunch()\n    setup_py = cfg.rootjoin('setup.py')\n    if not os.path.exists(setup_py):\n        return result\n\n    egg_info = shell.capture(\"python {} egg_info\".format(setup_py), echo=True if verbose else None)\n    for info_line in egg_info.splitlines():\n        if info_line.endswith('PKG-INFO'):\n            pkg_info_file = info_line.split(None, 1)[1]\n            result['__file__'] = pkg_info_file\n            with io.open(pkg_info_file, encoding='utf-8') as handle:\n                lastkey = None\n                for line in handle:\n                    if line.lstrip() != line:\n                        assert lastkey, \"Bad continuation in PKG-INFO file '{}': {}\".format(pkg_info_file, line)\n                        result[lastkey] += '\\n' + line\n                    else:\n                        lastkey, value = line.split(':', 1)\n                        lastkey = lastkey.strip().lower().replace('-', '_')\n                        value = value.strip()\n                        if lastkey in result:\n                            try:\n                                result[lastkey].append(value)\n                            except AttributeError:\n                                result[lastkey] = [result[lastkey], value]\n                        else:\n                            result[lastkey] = value\n\n    for multikey in PKG_INFO_MULTIKEYS:\n        if not isinstance(result.get(multikey, []), list):\n            result[multikey] = [result[multikey]]\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbumps a development version.", "response": "def bump(ctx, verbose=False, pypi=False):\n    \"\"\"Bump a development version.\"\"\"\n    cfg = config.load()\n    scm = scm_provider(cfg.project_root, commit=False, ctx=ctx)\n\n    # Check for uncommitted changes\n    if not scm.workdir_is_clean():\n        notify.warning(\"You have uncommitted changes, will create a time-stamped version!\")\n\n    pep440 = scm.pep440_dev_version(verbose=verbose, non_local=pypi)\n\n    # Rewrite 'setup.cfg'  TODO: refactor to helper, see also release-prep\n    # with util.rewrite_file(cfg.rootjoin('setup.cfg')) as lines:\n    #     ...\n    setup_cfg = cfg.rootjoin('setup.cfg')\n    if not pep440:\n        notify.info(\"Working directory contains a release version!\")\n    elif os.path.exists(setup_cfg):\n        with io.open(setup_cfg, encoding='utf-8') as handle:\n            data = handle.readlines()\n        changed = False\n        for i, line in enumerate(data):\n            if re.match(r\"#? *tag_build *= *.*\", line):\n                verb, _ = data[i].split('=', 1)\n                data[i] = '{}= {}\\n'.format(verb, pep440)\n                changed = True\n\n        if changed:\n            notify.info(\"Rewriting 'setup.cfg'...\")\n            with io.open(setup_cfg, 'w', encoding='utf-8') as handle:\n                handle.write(''.join(data))\n        else:\n            notify.warning(\"No 'tag_build' setting found in 'setup.cfg'!\")\n    else:\n        notify.warning(\"Cannot rewrite 'setup.cfg', none found!\")\n\n    if os.path.exists(setup_cfg):\n        # Update metadata and print version\n        egg_info = shell.capture(\"python setup.py egg_info\", echo=True if verbose else None)\n        for line in egg_info.splitlines():\n            if line.endswith('PKG-INFO'):\n                pkg_info_file = line.split(None, 1)[1]\n                with io.open(pkg_info_file, encoding='utf-8') as handle:\n                    notify.info('\\n'.join(i for i in handle.readlines() if i.startswith('Version:')).strip())\n        ctx.run(\"python setup.py -q develop\", echo=True if verbose else None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npackage the project with PEX.", "response": "def pex(ctx, pyrun='', upload=False, opts=''):\n    \"\"\"Package the project with PEX.\"\"\"\n    cfg = config.load()\n\n    # Build and check release\n    ctx.run(\": invoke clean --all build test check\")\n\n    # Get full version\n    pkg_info = get_egg_info(cfg)\n    # from pprint import pprint; pprint(dict(pkg_info))\n    version = pkg_info.version if pkg_info else cfg.project.version\n\n    # Build a PEX for each console entry-point\n    pex_files = []\n    # from pprint import pprint; pprint(cfg.project.entry_points)\n    for script in cfg.project.entry_points['console_scripts']:\n        script, entry_point = script.split('=', 1)\n        script, entry_point = script.strip(), entry_point.strip()\n        pex_file = cfg.rootjoin('bin', '{}-{}.pex'.format(script, version))\n        cmd = ['pex', '-r', cfg.rootjoin('requirements.txt'), cfg.project_root, '-c', script, '-o', pex_file]\n        if opts:\n            cmd.append(opts)\n        ctx.run(' '.join(cmd))\n\n        # Warn about non-portable stuff\n        non_universal = set()\n        with closing(zipfile.ZipFile(pex_file, mode=\"r\")) as pex_contents:\n            for pex_name in pex_contents.namelist():  # pylint: disable=no-member\n                if pex_name.endswith('WHEEL') and '-py2.py3-none-any.whl' not in pex_name:\n                    non_universal.add(pex_name.split('.whl')[0].split('/')[-1])\n        if non_universal:\n            notify.warning(\"Non-universal or native wheels in PEX '{}':\\n    {}\"\n                           .format(pex_file.replace(os.getcwd(), '.'), '\\n    '.join(sorted(non_universal))))\n            envs = [i.split('-')[-3:] for i in non_universal]\n            envs = {i[0]: i[1:] for i in envs}\n            if len(envs) > 1:\n                envs = {k: v for k, v in envs.items() if not k.startswith('py')}\n            env_id = []\n            for k, v in sorted(envs.items()):\n                env_id.append(k)\n                env_id.extend(v)\n            env_id = '-'.join(env_id)\n        else:\n            env_id = 'py2.py3-none-any'\n\n        new_pex_file = pex_file.replace('.pex', '-{}.pex'.format(env_id))\n        notify.info(\"Renamed PEX to '{}'\".format(os.path.basename(new_pex_file)))\n        os.rename(pex_file, new_pex_file)\n        pex_file = new_pex_file\n        pex_files.append(pex_file)\n\n    if not pex_files:\n        notify.warning(\"No entry points found in project configuration!\")\n    else:\n        if pyrun:\n            if any(pyrun.startswith(i) for i in ('http://', 'https://', 'file://')):\n                pyrun_url = pyrun\n            else:\n                pyrun_cfg = dict(ctx.rituals.pyrun)\n                pyrun_cfg.update(parse_qsl(pyrun.replace(os.pathsep, '&')))\n                pyrun_url = (pyrun_cfg['base_url'] + '/' +\n                             pyrun_cfg['archive']).format(**pyrun_cfg)\n\n            notify.info(\"Getting PyRun from '{}'...\".format(pyrun_url))\n            with url_as_file(pyrun_url, ext='tgz') as pyrun_tarball:\n                pyrun_tar = tarfile.TarFile.gzopen(pyrun_tarball)\n                for pex_file in pex_files[:]:\n                    pyrun_exe = pyrun_tar.extractfile('./bin/pyrun')\n                    with open(pex_file, 'rb') as pex_handle:\n                        pyrun_pex_file = '{}{}-installer.sh'.format(\n                            pex_file[:-4], pyrun_url.rsplit('/egenix')[-1][:-4])\n                        with open(pyrun_pex_file, 'wb') as pyrun_pex:\n                            pyrun_pex.write(INSTALLER_BASH.replace('00000', '{:<5d}'.format(len(INSTALLER_BASH) + 1)))\n                            shutil.copyfileobj(pyrun_exe, pyrun_pex)\n                            shutil.copyfileobj(pex_handle, pyrun_pex)\n                        shutil.copystat(pex_file, pyrun_pex_file)\n                        notify.info(\"Wrote PEX installer to '{}'\".format(pretty_path(pyrun_pex_file)))\n                        pex_files.append(pyrun_pex_file)\n\n        if upload:\n            base_url = ctx.rituals.release.upload.base_url.rstrip('/')\n            if not base_url:\n                notify.failure(\"No base URL provided for uploading!\")\n\n            for pex_file in pex_files:\n                url = base_url + '/' + ctx.rituals.release.upload.path.lstrip('/').format(\n                    name=cfg.project.name, version=cfg.project.version, filename=os.path.basename(pex_file))\n                notify.info(\"Uploading to '{}'...\".format(url))\n                with io.open(pex_file, 'rb') as handle:\n                    reply = requests.put(url, data=handle.read())\n                    if reply.status_code in range(200, 300):\n                        notify.info(\"{status_code} {reason}\".format(**vars(reply)))\n                    else:\n                        notify.warning(\"{status_code} {reason}\".format(**vars(reply)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprepare for a release.", "response": "def prep(ctx, commit=True):\n    \"\"\"Prepare for a release.\"\"\"\n    cfg = config.load()\n    scm = scm_provider(cfg.project_root, commit=commit, ctx=ctx)\n\n    # Check for uncommitted changes\n    if not scm.workdir_is_clean():\n        notify.failure(\"You have uncommitted changes, please commit or stash them!\")\n\n    # TODO Check that changelog entry carries the current date\n\n    # Rewrite 'setup.cfg'\n    setup_cfg = cfg.rootjoin('setup.cfg')\n    if os.path.exists(setup_cfg):\n        with io.open(setup_cfg, encoding='utf-8') as handle:\n            data = handle.readlines()\n        changed = False\n        for i, line in enumerate(data):\n            if any(line.startswith(i) for i in ('tag_build', 'tag_date')):\n                data[i] = '#' + data[i]\n                changed = True\n        if changed and commit:\n            notify.info(\"Rewriting 'setup.cfg'...\")\n            with io.open(setup_cfg, 'w', encoding='utf-8') as handle:\n                handle.write(''.join(data))\n            scm.add_file('setup.cfg')\n        elif changed:\n            notify.warning(\"WOULD rewrite 'setup.cfg', but --no-commit was passed\")\n    else:\n        notify.warning(\"Cannot rewrite 'setup.cfg', none found!\")\n\n    # Update metadata and command stubs\n    ctx.run('python setup.py -q develop -U')\n\n    # Build a clean dist and check version number\n    version = capture('python setup.py --version')\n    ctx.run('invoke clean --all build --docs release.dist')\n    for distfile in os.listdir('dist'):\n        trailer = distfile.split('-' + version)[1]\n        trailer, _ = os.path.splitext(trailer)\n        if trailer and trailer[0] not in '.-':\n            notify.failure(\"The version found in 'dist' seems to be\"\n                           \" a pre-release one! [{}{}]\".format(version, trailer))\n\n    # Commit changes and tag the release\n    scm.commit(ctx.rituals.release.commit.message.format(version=version))\n    scm.tag(ctx.rituals.release.tag.name.format(version=version),\n            ctx.rituals.release.tag.message.format(version=version))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming source code checks via pylint.", "response": "def pylint(ctx, skip_tests=False, skip_root=False, reports=False):\n    \"\"\"Perform source code checks via pylint.\"\"\"\n    cfg = config.load()\n    add_dir2pypath(cfg.project_root)\n    if not os.path.exists(cfg.testjoin('__init__.py')):\n        add_dir2pypath(cfg.testjoin())\n\n    namelist = set()\n    for package in cfg.project.get('packages', []):\n        if '.' not in package:\n            namelist.add(cfg.srcjoin(package))\n    for module in cfg.project.get('py_modules', []):\n        namelist.add(module + '.py')\n\n    if not skip_tests:\n        test_py = antglob.FileSet(cfg.testdir, '**/*.py')\n        test_py = [cfg.testjoin(i) for i in test_py]\n        if test_py:\n            namelist |= set(test_py)\n\n    if not skip_root:\n        root_py = antglob.FileSet('.', '*.py')\n        if root_py:\n            namelist |= set(root_py)\n\n    namelist = set([i[len(os.getcwd())+1:] if i.startswith(os.getcwd() + os.sep) else i for i in namelist])\n    cmd = 'pylint'\n    cmd += ' \"{}\"'.format('\" \"'.join(sorted(namelist)))\n    cmd += ' --reports={0}'.format('y' if reports else 'n')\n    for cfgfile in ('.pylintrc', 'pylint.rc', 'pylint.cfg', 'project.d/pylint.cfg'):\n        if os.path.exists(cfgfile):\n            cmd += ' --rcfile={0}'.format(cfgfile)\n            break\n    try:\n        shell.run(cmd, report_error=False, runner=ctx.run)\n        notify.info(\"OK - No problems found by pylint.\")\n    except exceptions.Failure as exc:\n        # Check bit flags within pylint return code\n        if exc.result.return_code & 32:\n            # Usage error (internal error in this code)\n            notify.error(\"Usage error, bad arguments in {}?!\".format(repr(cmd)))\n            raise\n        else:\n            bits = {\n                1: \"fatal\",\n                2: \"error\",\n                4: \"warning\",\n                8: \"refactor\",\n                16: \"convention\",\n            }\n            notify.warning(\"Some messages of type {} issued by pylint.\".format(\n                \", \".join([text for bit, text in bits.items() if exc.result.return_code & bit])\n            ))\n            if exc.result.return_code & 3:\n                notify.error(\"Exiting due to fatal / error message.\")\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck for uncommitted changes return True if everything is clean.", "response": "def workdir_is_clean(self, quiet=False):\n        \"\"\" Check for uncommitted changes, return `True` if everything is clean.\n\n            Inspired by http://stackoverflow.com/questions/3878624/.\n        \"\"\"\n        # Update the index\n        self.run('git update-index -q --ignore-submodules --refresh', **RUN_KWARGS)\n        unchanged = True\n\n        # Disallow unstaged changes in the working tree\n        try:\n            self.run('git diff-files --quiet --ignore-submodules --', report_error=False, **RUN_KWARGS)\n        except exceptions.Failure:\n            unchanged = False\n            if not quiet:\n                notify.warning('You have unstaged changes!')\n                self.run('git diff-files --name-status -r --ignore-submodules -- >&2', **RUN_KWARGS)\n\n        # Disallow uncommitted changes in the index\n        try:\n            self.run('git diff-index --cached --quiet HEAD --ignore-submodules --', report_error=False, **RUN_KWARGS)\n        except exceptions.Failure:\n            unchanged = False\n            if not quiet:\n                notify.warning('Your index contains uncommitted changes!')\n                self.run('git diff-index --cached --name-status -r --ignore-submodules HEAD -- >&2', **RUN_KWARGS)\n\n        return unchanged"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntag the current workdir state with the given label.", "response": "def tag(self, label, message=None):\n        \"\"\"Tag the current workdir state.\"\"\"\n        options = ' -m \"{}\" -a'.format(message) if message else ''\n        self.run_elective('git tag{} \"{}\"'.format(options, label))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a PEP - 440 dev version appendix to the main version number.", "response": "def pep440_dev_version(self, verbose=False, non_local=False):\n        \"\"\" Return a PEP-440 dev version appendix to the main version number.\n\n            Result is ``None`` if the workdir is in a release-ready state\n            (i.e. clean and properly tagged).\n        \"\"\"\n        version = capture(\"python setup.py --version\", echo=verbose)\n        if verbose:\n            notify.info(\"setuptools version = '{}'\".format(version))\n\n        now = '{:%Y%m%d!%H%M}'.format(datetime.now())\n        tag = capture(\"git describe --long --tags --dirty='!{}'\".format(now), echo=verbose)\n        if verbose:\n            notify.info(\"git describe = '{}'\".format(tag))\n        try:\n            tag, date, time = tag.split('!')\n        except ValueError:\n            date = time = ''\n        tag, commits, short_hash = tag.rsplit('-', 3)\n        label = tag\n        if re.match(r\"v[0-9]+(\\.[0-9]+)*\", label):\n            label = label[1:]\n\n        # Make a PEP-440 version appendix, the format is:\n        # [N!]N(.N)*[{a|b|rc}N][.postN][.devN][+<local version label>]\n        if commits == '0' and label == version:\n            pep440 = None\n        else:\n            local_part = [\n                re.sub(r\"[^a-zA-Z0-9]+\", '.', label).strip('.'),  # reduce to alphanum and dots\n                short_hash,\n                date + ('T' + time if time else ''),\n            ]\n            build_number = os.environ.get('BUILD_NUMBER', 'n/a')\n            if build_number.isdigit():\n                local_part.extend(['ci', build_number])\n                if verbose:\n                    notify.info(\"Adding CI build ID #{} to version\".format(build_number))\n\n            local_part = [i for i in local_part if i]\n            pep440 = '.dev{}+{}'.format(commits, '.'.join(local_part).strip('.'))\n            if non_local:\n                pep440, _ = pep440.split('+', 1)\n\n        return pep440"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping Jenkins project metadata for Jenkins Description Setter Plugin.", "response": "def description(_dummy_ctx, markdown=False):\n    \"\"\"Dump project metadata for Jenkins Description Setter Plugin.\"\"\"\n    cfg = config.load()\n    markup = 'md' if markdown else 'html'\n    description_file = cfg.rootjoin(\"build/project.{}\".format(markup))\n    notify.banner(\"Creating {} file for Jenkins...\".format(description_file))\n\n    long_description = cfg.project.long_description\n    long_description = long_description.replace('\\n\\n', '</p>\\n<p>')\n    long_description = re.sub(r'(\\W)``([^`]+)``(\\W)', r'\\1<tt>\\2</tt>\\3', long_description)\n\n    text = DESCRIPTION_TEMPLATES[markup].format(\n        keywords=', '.join(cfg.project.keywords),\n        classifiers='\\n'.join(cfg.project.classifiers),\n        classifiers_indented='    ' + '\\n    '.join(cfg.project.classifiers),\n        packages=', '.join(cfg.project.packages),\n        long_description_html='<p>{}</p>'.format(long_description),\n        ##data='\\n'.join([\"%s=%r\" % i for i in cfg.project.iteritems()]),\n        **cfg)\n    with io.open(description_file, 'w', encoding='utf-8') as handle:\n        handle.write(text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef capture(cmd, **kw):\n    kw = kw.copy()\n    kw['hide'] = 'out'\n    if not kw.get('echo', False):\n        kw['echo'] = False\n    ignore_failures = kw.pop('ignore_failures', False)\n    try:\n        return invoke_run(cmd, **kw).stdout.strip()\n    except exceptions.Failure as exc:\n        if not ignore_failures:\n            notify.error(\"Command `{}` failed with RC={}!\".format(cmd, exc.result.return_code,))\n            raise", "response": "Run a command and return its stripped captured output."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(cmd, **kw):\n    kw = kw.copy()\n    kw.setdefault('warn', False)  # make extra sure errors don't get silenced\n\n    report_error = kw.pop('report_error', True)\n    runner = kw.pop('runner', invoke_run)\n\n    try:\n        return runner(cmd, **kw)\n    except exceptions.Failure as exc:\n        sys.stdout.flush()\n        sys.stderr.flush()\n        if report_error:\n            notify.error(\"Command `{}` failed with RC={}!\".format(cmd, exc.result.return_code,))\n        raise\n    finally:\n        sys.stdout.flush()\n        sys.stderr.flush()", "response": "Run a command and flush its output."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef auto_detect(workdir):\n    # Any additions here also need a change to `SCM_PROVIDERS`!\n    if os.path.isdir(os.path.join(workdir, '.git')) and os.path.isfile(os.path.join(workdir, '.git', 'HEAD')):\n        return 'git'\n\n    return 'unknown'", "response": "Detects the SCM used in the given directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef provider(workdir, commit=True, **kwargs):\n    return SCM_PROVIDER[auto_detect(workdir)](workdir, commit=commit, **kwargs)", "response": "Factory for the correct SCM provider in workdir."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexiting with error code and message.", "response": "def fail(message, exitcode=1):\n    \"\"\"Exit with error code and message.\"\"\"\n    sys.stderr.write('ERROR: {}\\n'.format(message))\n    sys.stderr.flush()\n    sys.exit(exitcode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_pypi_auth(configfile='~/.pypirc'):\n    pypi_cfg = ConfigParser()\n    if pypi_cfg.read(os.path.expanduser(configfile)):\n        try:\n            user = pypi_cfg.get('pypi', 'username')\n            pwd = pypi_cfg.get('pypi', 'password')\n            return user, pwd\n        except ConfigError:\n            notify.warning(\"No PyPI credentials in '{}',\"\n                           \" will fall back to '~/.netrc'...\".format(configfile))\n    return None", "response": "Read auth from pypi config file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncontrols a running Sphinx autobuild process.", "response": "def watchdogctl(ctx, kill=False, verbose=True):\n    \"\"\"Control / check a running Sphinx autobuild process.\"\"\"\n    tries = 40 if kill else 0\n    cmd = 'lsof -i TCP:{} -s TCP:LISTEN -S -Fp 2>/dev/null'.format(ctx.rituals.docs.watchdog.port)\n\n    pidno = 0\n    pidinfo = capture(cmd, ignore_failures=True)\n    while pidinfo:\n        pidline = next(filter(None, [re.match(r'^p(\\d+)$', x) for x in pidinfo.splitlines()]))\n        if not pidline:\n            raise ValueError(\"Standard lsof output expected (got {!r})\".format(pidinfo))\n        pidno = int(pidline.group(1), 10)\n        if verbose:\n            ctx.run(\"ps uw {}\".format(pidno), echo=False)\n            verbose = False\n\n        tries -= 1\n        if tries <= 0:\n            break\n        else:\n            try:\n                os.kill(pidno, 0)\n            #except ProcessLookupError:  # XXX Python3 only\n            #    break\n            except OSError as exc:  # Python2 has no ProcessLookupError\n                if exc.errno == 3:\n                    break\n                raise\n            else:\n                notify.info(\"Killing PID {}\".format(pidno))\n                ctx.run(\"kill {}\".format(pidno), echo=False)\n                time.sleep(.25)\n\n        pid = capture(cmd, ignore_failures=True)\n\n    return pidno"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef confluence(ctx, no_publish=False, clean=False, opts=''):\n    cfg = config.load()\n\n    if clean:\n        ctx.run(\"invoke clean --docs\")\n\n    cmd = ['sphinx-build', '-b', 'confluence']\n    cmd.extend(['-E', '-a'])  # force a full rebuild\n    if opts:\n        cmd.append(opts)\n    cmd.extend(['.', ctx.rituals.docs.build + '_cf'])\n    if no_publish:\n        cmd.extend(['-Dconfluence_publish=False'])\n\n    # Build docs\n    notify.info(\"Starting Sphinx build...\")\n    with pushd(ctx.rituals.docs.sources):\n        ctx.run(' '.join(cmd), pty=True)", "response": "Build Sphinx docs and publish to Confluence."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuploads a ZIP of built docs to the current directory.", "response": "def upload(ctx, browse=False, target=None, release='latest'):\n    \"\"\"Upload a ZIP of built docs (by default to PyPI, else a WebDAV URL).\"\"\"\n    cfg = config.load()\n    uploader = DocsUploader(ctx, cfg, target)\n\n    html_dir = os.path.join(ctx.rituals.docs.sources, ctx.rituals.docs.build)\n    if not os.path.isdir(html_dir):\n        notify.failure(\"No HTML docs dir found at '{}'!\".format(html_dir))\n\n    url = uploader.upload(html_dir, release)\n    notify.info(\"Uploaded docs to '{url}'!\".format(url=url or 'N/A'))\n    if url and browse:  # Open in browser?\n        webbrowser.open_new_tab(url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprovides a zipped stream of the docs tree.", "response": "def _zipped(self, docs_base):\n        \"\"\" Provide a zipped stream of the docs tree.\"\"\"\n        with pushd(docs_base):\n            with tempfile.NamedTemporaryFile(prefix='pythonhosted-', delete=False) as ziphandle:\n                pass\n            zip_name = shutil.make_archive(ziphandle.name, 'zip')\n\n        notify.info(\"Uploading {:.1f} MiB from '{}' to '{}'...\"\n                    .format(os.path.getsize(zip_name) / 1024.0, zip_name, self.target))\n        with io.open(zip_name, 'rb') as zipread:\n            try:\n                yield zipread\n            finally:\n                os.remove(ziphandle.name)\n                os.remove(ziphandle.name + '.zip')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _to_webdav(self, docs_base, release):\n        try:\n            git_path = subprocess.check_output('git remote get-url origin 2>/dev/null', shell=True)\n        except subprocess.CalledProcessError:\n            git_path = ''\n        else:\n            git_path = git_path.decode('ascii').strip()\n            git_path = git_path.replace('http://', '').replace('https://', '').replace('ssh://', '')\n            git_path = re.search(r'[^:/]+?[:/](.+)', git_path)\n            git_path = git_path.group(1).replace('.git', '') if git_path else ''\n        url = None\n        with self._zipped(docs_base) as handle:\n            url_ns = dict(name=self.cfg.project.name, version=release, git_path=git_path)\n            reply = requests.put(self.params['url'].format(**url_ns),\n                                 data=handle.read(), headers={'Accept': 'application/json'})\n            if reply.status_code in range(200, 300):\n                notify.info(\"{status_code} {reason}\".format(**vars(reply)))\n                try:\n                    data = reply.json()\n                except ValueError as exc:\n                    notify.warning(\"Didn't get a JSON response! ({})\".format(exc))\n                else:\n                    if 'downloadUri' in data:  # Artifactory\n                        url = data['downloadUri'] + '!/index.html'\n            elif reply.status_code == 301:\n                url = reply.headers['location']\n            else:\n                data = self.cfg.copy()\n                data.update(self.params)\n                data.update(vars(reply))\n                notify.error(\"{status_code} {reason} for PUT to {url}\".format(**data))\n\n        if not url:\n            notify.warning(\"Couldn't get URL from upload response!\")\n        return url", "response": "Upload to WebDAV store."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef upload(self, docs_base, release):\n        return getattr(self, '_to_' + self.target)(docs_base, release)", "response": "Upload docs in docs_base to the target of this uploader."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search_file_upwards(name, base=None):\n    base = base or os.getcwd()\n    while base != os.path.dirname(base):\n        if os.path.exists(os.path.join(base, name)):\n            return base\n        base = os.path.dirname(base)\n\n    return None", "response": "Search for a file named name from cwd or given directory to root."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd given directory to PYTHONPATH.", "response": "def add_dir2pypath(path):\n    \"\"\"Add given directory to PYTHONPATH, e.g. for pylint.\"\"\"\n    py_path = os.environ.get('PYTHONPATH', '')\n    if path not in py_path.split(os.pathsep):\n        py_path = ''.join([path, os.pathsep if py_path else '', py_path])\n        os.environ['PYTHONPATH'] = py_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pushd(path):\n    saved = os.getcwd()\n    os.chdir(path)\n    try:\n        yield saved\n    finally:\n        os.chdir(saved)", "response": "A context that enters a given directory and restores the old state on exit."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun a command or just echo it depending on commit.", "response": "def run_elective(self, cmd, *args, **kwargs):\n        \"\"\"Run a command, or just echo it, depending on `commit`.\"\"\"\n        if self._commit:\n            return self.run(cmd, *args, **kwargs)\n        else:\n            notify.warning(\"WOULD RUN: {}\".format(cmd))\n            kwargs = kwargs.copy()\n            kwargs['echo'] = False\n            return self.run('true', *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef banner(msg):\n    if ECHO:\n        _flush()\n        sys.stderr.write(\"\\033[1;7;32;40m{}\\033[0m\\n\".format(msg))\n        sys.stderr.flush()", "response": "Emit a banner just like Invoke s run."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef info(msg):\n    _flush()\n    sys.stdout.write(msg + '\\n')\n    sys.stdout.flush()", "response": "Emit a normal message."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nemit a warning message.", "response": "def warning(msg):\n    \"\"\"Emit a warning message.\"\"\"\n    _flush()\n    sys.stderr.write(\"\\033[1;7;33;40mWARNING: {}\\033[0m\\n\".format(msg))\n    sys.stderr.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef error(msg):\n    _flush()\n    sys.stderr.write(\"\\033[1;37;41mERROR: {}\\033[0m\\n\".format(msg))\n    sys.stderr.flush()", "response": "Emit an error message to stderr."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget currently used devpi base URL.", "response": "def get_devpi_url(ctx):\n    \"\"\"Get currently used 'devpi' base URL.\"\"\"\n    cmd = 'devpi use --urls'\n    lines = ctx.run(cmd, hide='out', echo=False).stdout.splitlines()\n    for line in lines:\n        try:\n            line, base_url = line.split(':', 1)\n        except ValueError:\n            notify.warning('Ignoring \"{}\"!'.format(line))\n        else:\n            if line.split()[-1].strip() == 'simpleindex':\n                return base_url.split('\\x1b')[0].strip().rstrip('/')\n\n    raise LookupError(\"Cannot find simpleindex URL in '{}' output:\\n    {}\".format(\n        cmd, '\\n    '.join(lines),\n    ))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetermine location of tasks. py.", "response": "def get_project_root():\n    \"\"\" Determine location of `tasks.py`.\"\"\"\n    try:\n        tasks_py = sys.modules['tasks']\n    except KeyError:\n        return None\n    else:\n        return os.path.abspath(os.path.dirname(tasks_py.__file__))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load():\n    cfg = Bunch(DEFAULTS)\n    # TODO: override with contents of [rituals] section in setup.cfg\n\n    cfg.project_root = get_project_root()\n    if not cfg.project_root:\n        raise RuntimeError(\"No tasks module is imported, cannot determine project root\")\n\n    cfg.rootjoin = lambda *names: os.path.join(cfg.project_root, *names)\n    cfg.srcjoin = lambda *names: cfg.rootjoin(cfg.srcdir, *names)\n    cfg.testjoin = lambda *names: cfg.rootjoin(cfg.testdir, *names)\n    cfg.cwd = os.getcwd()\n    os.chdir(cfg.project_root)\n\n    # this assumes an importable setup.py\n    # TODO: maybe call \"python setup.py egg_info\" for metadata\n    if cfg.project_root not in sys.path:\n        sys.path.append(cfg.project_root)\n    try:\n        from setup import project # pylint: disable=no-name-in-module\n    except ImportError:\n        from setup import setup_args as project # pylint: disable=no-name-in-module\n    cfg.project = Bunch(project)\n\n    return cfg", "response": "Load and return a Bunch containing all the configuration values for the current project root."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a glob part to regex syntax.", "response": "def glob2re(part):\n    \"\"\"Convert a path part to regex syntax.\"\"\"\n    return \"[^/]*\".join(\n        re.escape(bit).replace(r'\\[\\^', '[^').replace(r'\\[', '[').replace(r'\\]', ']')\n        for bit in part.split(\"*\")\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_glob(pattern):\n    if not pattern:\n        return\n\n    bits = pattern.split(\"/\")\n    dirs, filename = bits[:-1], bits[-1]\n\n    for dirname in dirs:\n        if dirname == \"**\":\n            yield  \"(|.+/)\"\n        else:\n            yield glob2re(dirname) + \"/\"\n\n    yield glob2re(filename)", "response": "Generate parts of regex transformed from glob pattern."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert the given glob spec to a compiled regex.", "response": "def compile_glob(spec):\n    \"\"\"Convert the given glob `spec` to a compiled regex.\"\"\"\n    parsed = \"\".join(parse_glob(spec))\n    regex = \"^{0}$\".format(parsed)\n    return re.compile(regex)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking patterns in order last match that includes or excludes path wins. Return None on undecided.", "response": "def included(self, path, is_dir=False):\n        \"\"\"Check patterns in order, last match that includes or excludes `path` wins. Return `None` on undecided.\"\"\"\n        inclusive = None\n        for pattern in self.patterns:\n            if pattern.is_dir == is_dir and pattern.matches(path):\n                inclusive = pattern.inclusive\n\n        #print('+++' if inclusive else '---', path, pattern)\n        return inclusive"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef walk(self, **kwargs):\n        lead = ''\n        if 'with_root' in kwargs and kwargs.pop('with_root'):\n            lead = self.root.rstrip(os.sep) + os.sep\n\n        for base, dirs, files in os.walk(self.root, **kwargs):\n            prefix = base[len(self.root):].lstrip(os.sep)\n            bits = prefix.split(os.sep) if prefix else []\n\n            for dirname in dirs[:]:\n                path = '/'.join(bits + [dirname])\n                inclusive = self.included(path, is_dir=True)\n                if inclusive:\n                    yield lead + path + '/'\n                elif inclusive is False:\n                    dirs.remove(dirname)\n\n            for filename in files:\n                path = '/'.join(bits + [filename])\n                if self.included(path):\n                    yield lead + path", "response": "Like os. walk but generating paths relative to the root."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build(ctx, dput='', opts=''):\n    # Get package metadata\n    with io.open('debian/changelog', encoding='utf-8') as changes:\n        metadata = re.match(r'^([^ ]+) \\(([^)]+)\\) ([^;]+); urgency=(.+)$', changes.readline().rstrip())\n        if not metadata:\n            notify.failure('Badly formatted top entry in changelog')\n        name, version, _, _ = metadata.groups()\n\n    # Build package\n    ctx.run('dpkg-buildpackage {} {}'.format(ctx.rituals.deb.build.opts, opts))\n\n    # Move created artifacts into \"dist\"\n    if not os.path.exists('dist'):\n        os.makedirs('dist')\n    artifact_pattern = '{}?{}*'.format(name, re.sub(r'[^-_.a-zA-Z0-9]', '?', version))\n    changes_files = []\n    for debfile in glob.glob('../' + artifact_pattern):\n        shutil.move(debfile, 'dist')\n        if debfile.endswith('.changes'):\n            changes_files.append(os.path.join('dist', os.path.basename(debfile)))\n    ctx.run('ls -l dist/{}'.format(artifact_pattern))\n\n    if dput:\n        ctx.run('dput {} {}'.format(dput, ' '.join(changes_files)))", "response": "Build a DEB package."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncleans up the project files.", "response": "def clean(_dummy_ctx, docs=False, backups=False, bytecode=False, dist=False, # pylint: disable=redefined-outer-name\n        all=False, venv=False, tox=False, extra=''): # pylint: disable=redefined-builtin\n    \"\"\"Perform house-keeping.\"\"\"\n    cfg = config.load()\n    notify.banner(\"Cleaning up project files\")\n\n    # Add patterns based on given parameters\n    venv_dirs = ['bin', 'include', 'lib', 'share', 'local', '.venv']\n    patterns = ['build/', 'pip-selfcheck.json']\n    excludes = ['.git/', '.hg/', '.svn/', 'debian/*/']\n    if docs or all:\n        patterns.extend(['docs/_build/', 'doc/_build/'])\n    if dist or all:\n        patterns.append('dist/')\n    if backups or all:\n        patterns.extend(['**/*~'])\n    if bytecode or all:\n        patterns.extend([\n            '**/*.py[co]', '**/__pycache__/', '*.egg-info/',\n            cfg.srcjoin('*.egg-info/')[len(cfg.project_root)+1:],\n        ])\n    if venv:\n        patterns.extend([i + '/' for i in venv_dirs])\n    if tox:\n        patterns.append('.tox/')\n    else:\n        excludes.append('.tox/')\n    if extra:\n        patterns.extend(shlex.split(extra))\n\n    # Build fileset\n    patterns = [antglob.includes(i) for i in patterns] + [antglob.excludes(i) for i in excludes]\n    if not venv:\n        # Do not scan venv dirs when not cleaning them\n        patterns.extend([antglob.excludes(i + '/') for i in venv_dirs])\n    fileset = antglob.FileSet(cfg.project_root, patterns)\n\n    # Iterate over matches and remove them\n    for name in fileset:\n        notify.info('rm {0}'.format(name))\n        if name.endswith('/'):\n            shutil.rmtree(os.path.join(cfg.project_root, name))\n        else:\n            os.unlink(os.path.join(cfg.project_root, name))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef freeze(ctx, local=False):\n    cmd = 'pip --disable-pip-version-check freeze{}'.format(' --local' if local else '')\n    frozen = ctx.run(cmd, hide='out').stdout.replace('\\x1b', '#')\n    with io.open('frozen-requirements.txt', 'w', encoding='ascii') as out:\n        out.write(\"# Requirements frozen by 'pip freeze' on {}\\n\".format(isodate()))\n        out.write(frozen)\n    notify.info(\"Frozen {} requirements.\".format(len(frozen.splitlines()),))", "response": "Freeze currently installed requirements."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef isodate(datestamp=None, microseconds=False):\n    datestamp = datestamp or datetime.datetime.now()\n    if not microseconds:\n        usecs = datetime.timedelta(microseconds=datestamp.microsecond)\n        datestamp = datestamp - usecs\n    return datestamp.isoformat(b' ' if PY2 else u' ')", "response": "Return current or given time formatted according to ISO - 8601."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwindowing allow application paths to be registered in the registry.", "response": "def _get_registered_executable(exe_name):\n    \"\"\"Windows allow application paths to be registered in the registry.\"\"\"\n    registered = None\n    if sys.platform.startswith('win'):\n        if os.path.splitext(exe_name)[1].lower() != '.exe':\n            exe_name += '.exe'\n        import _winreg # pylint: disable=import-error\n        try:\n            key = \"SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\App Paths\\\\\" + exe_name\n            value = _winreg.QueryValue(_winreg.HKEY_LOCAL_MACHINE, key)\n            registered = (value, \"from HKLM\\\\\"+key)\n        except _winreg.error:\n            pass\n        if registered and not os.path.exists(registered[0]):\n            registered = None\n    return registered"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nculling inappropriate matches. Possible reasons: - a duplicate of a previous match - not a disk file - not executable (non-Windows) If 'potential' is approved it is returned and added to 'matches'. Otherwise, None is returned.", "response": "def _cull(potential, matches, verbose=0):\n    \"\"\"Cull inappropriate matches. Possible reasons:\n        - a duplicate of a previous match\n        - not a disk file\n        - not executable (non-Windows)\n    If 'potential' is approved it is returned and added to 'matches'.\n    Otherwise, None is returned.\n    \"\"\"\n    for match in matches: # don't yield duplicates\n        if _samefile(potential[0], match[0]):\n            if verbose:\n                sys.stderr.write(\"duplicate: %s (%s)\\n\" % potential)\n            return None\n\n    if not stat.S_ISREG(os.stat(potential[0]).st_mode):\n        if verbose:\n            sys.stderr.write(\"not a regular file: %s (%s)\\n\" % potential)\n    elif not os.access(potential[0], os.X_OK):\n        if verbose:\n            sys.stderr.write(\"no executable access: %s (%s)\\n\" % potential)\n    else:\n        matches.append(potential)\n        return potential\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a generator of full paths to the given command.", "response": "def whichgen(command, path=None, verbose=0, exts=None): # pylint: disable=too-many-branches, too-many-statements\n    \"\"\"Return a generator of full paths to the given command.\n\n    \"command\" is a the name of the executable to search for.\n    \"path\" is an optional alternate path list to search. The default it\n        to use the PATH environment variable.\n    \"verbose\", if true, will cause a 2-tuple to be returned for each\n        match. The second element is a textual description of where the\n        match was found.\n    \"exts\" optionally allows one to specify a list of extensions to use\n        instead of the standard list for this system. This can\n        effectively be used as an optimization to, for example, avoid\n        stat's of \"foo.vbs\" when searching for \"foo\" and you know it is\n        not a VisualBasic script but \".vbs\" is on PATHEXT. This option\n        is only supported on Windows.\n\n    This method returns a generator which yields either full paths to\n    the given command or, if verbose, tuples of the form (<path to\n    command>, <where path found>).\n    \"\"\"\n    matches = []\n    if path is None:\n        using_given_path = 0\n        path = os.environ.get(\"PATH\", \"\").split(os.pathsep)\n        if sys.platform.startswith(\"win\"):\n            path.insert(0, os.curdir)  # implied by Windows shell\n    else:\n        using_given_path = 1\n\n    # Windows has the concept of a list of extensions (PATHEXT env var).\n    if sys.platform.startswith(\"win\"):\n        if exts is None:\n            exts = os.environ.get(\"PATHEXT\", \"\").split(os.pathsep)\n            # If '.exe' is not in exts then obviously this is Win9x and\n            # or a bogus PATHEXT, then use a reasonable default.\n            for ext in exts:\n                if ext.lower() == \".exe\":\n                    break\n            else:\n                exts = ['.COM', '.EXE', '.BAT']\n        elif not isinstance(exts, list):\n            raise TypeError(\"'exts' argument must be a list or None\")\n    else:\n        if exts is not None:\n            raise WhichError(\"'exts' argument is not supported on platform '%s'\" % sys.platform)\n        exts = []\n\n    # File name cannot have path separators because PATH lookup does not\n    # work that way.\n    if os.sep in command or os.altsep and os.altsep in command:\n        pass\n    else:\n        for i, dir_name in enumerate(path):\n            # On windows the dir_name *could* be quoted, drop the quotes\n            if sys.platform.startswith(\"win\") and len(dir_name) >= 2 and dir_name[0] == '\"' and dir_name[-1] == '\"':\n                dir_name = dir_name[1:-1]\n            for ext in ['']+exts:\n                abs_name = os.path.abspath(os.path.normpath(os.path.join(dir_name, command+ext)))\n                if os.path.isfile(abs_name):\n                    if using_given_path:\n                        from_where = \"from given path element %d\" % i\n                    elif not sys.platform.startswith(\"win\"):\n                        from_where = \"from PATH element %d\" % i\n                    elif i == 0:\n                        from_where = \"from current directory\"\n                    else:\n                        from_where = \"from PATH element %d\" % (i-1)\n                    match = _cull((abs_name, from_where), matches, verbose)\n                    if match:\n                        if verbose:\n                            yield match\n                        else:\n                            yield match[0]\n        match = _get_registered_executable(command)\n        if match is not None:\n            match = _cull(match, matches, verbose)\n            if match:\n                if verbose:\n                    yield match\n                else:\n                    yield match[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef which(command, path=None, verbose=0, exts=None):\n    matched = whichgen(command, path, verbose, exts)\n    try:\n        match = next(matched)\n    except StopIteration:\n        raise WhichError(\"Could not find '%s' on the path.\" % command)\n    else:\n        return match", "response": "Return the full path to the first match of the given command on the path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef step(self, key, chain):\n\n        if chain == \"sending\":\n            self.__previous_sending_chain_length = self.sending_chain_length\n\n            self.__sending_chain = self.__SendingChain(key)\n\n        if chain == \"receiving\":\n            self.__receiving_chain = self.__ReceivingChain(key)", "response": "Perform a rachted step of the recovery process."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decryptMessage(self, ciphertext, header, ad = None):\n\n        if ad == None:\n            ad = self.__ad\n\n        # Try to decrypt the message using a previously saved message key\n        plaintext = self.__decryptSavedMessage(ciphertext, header, ad)\n        if plaintext:\n            return plaintext\n\n        # Check, whether the public key will trigger a dh ratchet step\n        if self.triggersStep(header.dh_pub):\n            # Save missed message keys for the current receiving chain\n            self.__saveMessageKeys(header.pn)\n\n            # Perform the step\n            self.step(header.dh_pub)\n\n        # Save missed message keys for the current receiving chain\n        self.__saveMessageKeys(header.n)\n\n        # Finally decrypt the message and return the plaintext\n        return self.__decrypt(\n            ciphertext,\n            self.__skr.nextDecryptionKey(),\n            header,\n            ad\n        )", "response": "Decrypt a message using this double ratchet session."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encryptMessage(self, message, ad = None):\n\n        if ad == None:\n            ad = self.__ad\n\n        # Prepare the header for this message\n        header = Header(\n            self.pub,\n            self.__skr.sending_chain_length,\n            self.__skr.previous_sending_chain_length\n        )\n\n        # Encrypt the message\n        ciphertext = self.__aead.encrypt(\n            message,\n            self.__skr.nextEncryptionKey(),\n            self._makeAD(header, ad)\n        )\n\n        return {\n            \"header\"     : header,\n            \"ciphertext\" : ciphertext\n        }", "response": "Encrypt a message using this double ratchet session."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms a rachted step of the recovery process.", "response": "def step(self, other_pub):\n        \"\"\"\n        Perform a rachted step, calculating a new shared secret from the public key and\n        deriving new chain keys from this secret.\n\n        New Diffie-Hellman calculations are only performed if the public key is different\n        from the previous one.\n\n        :param other_pub: A bytes-like object encoding the public key of the other\n            Diffie-Hellman ratchet to synchronize with.\n        \"\"\"\n\n        if self.triggersStep(other_pub):\n            self.__wrapOtherPub(other_pub)\n            self.__newRootKey(\"receiving\")\n\n            self.__newRatchetKey()\n\n            self.__newRootKey(\"sending\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef next(self, data):\n\n        self.__length += 1\n\n        result = self.__kdf.calculate(self.__key, data, 64)\n        self.__key = result[:32]\n        return result[32:]", "response": "Derive a new set of internal and output data from given input data and the current key and the data passed to the key derivation function."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a image file such as a png bitmap of jpeg file and convert it to a knitting pattern file.", "response": "def convert_image_to_knitting_pattern(path, colors=(\"white\", \"black\")):\n    \"\"\"Load a image file such as a png bitmap of jpeg file and convert it\n    to a :ref:`knitting pattern file <FileFormatSpecification>`.\n\n    :param list colors: a list of strings that should be used as\n      :ref:`colors <png-color>`.\n    :param str path: ignore this. It is fulfilled by the loeder.\n\n    Example:\n\n    .. code:: python\n\n        convert_image_to_knitting_pattern().path(\"image.png\").path(\"image.json\")\n    \"\"\"\n    image = PIL.Image.open(path)\n    pattern_id = os.path.splitext(os.path.basename(path))[0]\n    rows = []\n    connections = []\n    pattern_set = {\n        \"version\": \"0.1\",\n        \"type\": \"knitting pattern\",\n        \"comment\": {\n            \"source\": path\n        },\n        \"patterns\": [\n            {\n                \"name\": pattern_id,\n                \"id\": pattern_id,\n                \"rows\": rows,\n                \"connections\": connections\n            }\n        ]}\n    bbox = image.getbbox()\n    if not bbox:\n        return pattern_set\n    white = image.getpixel((0, 0))\n    min_x, min_y, max_x, max_y = bbox\n    last_row_y = None\n    for y in reversed(range(min_y, max_y)):\n        instructions = []\n        row = {\"id\": y, \"instructions\": instructions}\n        rows.append(row)\n        for x in range(min_x, max_x):\n            if image.getpixel((x, y)) == white:\n                color = colors[0]\n            else:\n                color = colors[1]\n            instruction = {\"color\": color}\n            instructions.append(instruction)\n        if last_row_y is not None:\n            connections.append({\"from\": {\"id\": last_row_y}, \"to\": {\"id\": y}})\n        last_row_y = y\n    return pattern_set"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconnecting this mesh to another one.", "response": "def connect_to(self, other_mesh):\n        \"\"\"Create a connection to an other mesh.\n\n        .. warning:: Both meshes need to be disconnected and one needs to be\n          a consumed and the other a produced mesh. You can check if a\n          connection is possible using :meth:`can_connect_to`.\n\n        .. seealso:: :meth:`is_consumed`, :meth:`is_produced`,\n          :meth:`can_connect_to`\n        \"\"\"\n        other_mesh.disconnect()\n        self.disconnect()\n        self._connect_to(other_mesh)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a loader for a knitting pattern set.", "response": "def new_knitting_pattern_set_loader(specification=DefaultSpecification()):\n    \"\"\"Create a loader for a knitting pattern set.\n\n    :param specification: a :class:`specification\n      <knittingpattern.ParsingSpecification.ParsingSpecification>`\n      for the knitting pattern set, default\n      :class:`DefaultSpecification`\n    \"\"\"\n    parser = specification.new_parser(specification)\n    loader = specification.new_loader(parser.knitting_pattern_set)\n    return loader"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwalk the knitting pattern in a right - to - left fashion.", "response": "def walk(knitting_pattern):\n    \"\"\"Walk the knitting pattern in a right-to-left fashion.\n\n    :return: an iterable to walk the rows\n    :rtype: list\n    :param knittingpattern.KnittingPattern.KnittingPattern knitting_pattern: a\n      knitting pattern to take the rows from\n    \"\"\"\n    rows_before = {}  # key consumes from values\n    free_rows = []\n    walk = []\n    for row in knitting_pattern.rows:\n        rows_before_ = row.rows_before[:]\n        if rows_before_:\n            rows_before[row] = rows_before_\n        else:\n            free_rows.append(row)\n    assert free_rows\n    while free_rows:\n        # print(\"free rows:\", free_rows)\n        row = free_rows.pop(0)\n        walk.append(row)\n        assert row not in rows_before\n        for freed_row in reversed(row.rows_after):\n            todo = rows_before[freed_row]\n            # print(\"  freed:\", freed_row, todo)\n            todo.remove(row)\n            if not todo:\n                del rows_before[freed_row]\n                free_rows.insert(0, freed_row)\n    assert not rows_before, \"everything is walked\"\n    return walk"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef knitting_pattern(self, specification=None):\n        from ..ParsingSpecification import new_knitting_pattern_set_loader\n        if specification is None:\n            loader = new_knitting_pattern_set_loader()\n        else:\n            loader = new_knitting_pattern_set_loader(specification)\n        return loader.object(self.object())", "response": "loads a : class : knitting pattern\n        <knittingpattern. KnittingPattern > from the dumped\n        content\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the dump as a string", "response": "def string(self):\n        \"\"\":return: the dump as a string\"\"\"\n        if self.__text_is_expected:\n            return self._string()\n        else:\n            return self._bytes().decode(self.__encoding)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _string(self):\n        file = StringIO()\n        self.__dump_to_file(file)\n        file.seek(0)\n        return file.read()", "response": "return the string from a : class : io. StringIO"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bytes(self):\n        if self.__text_is_expected:\n            return self.string().encode(self.__encoding)\n        else:\n            return self._bytes()", "response": "return the dump as bytes"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _bytes(self):\n        file = BytesIO()\n        self.__dump_to_file(file)\n        file.seek(0)\n        return file.read()", "response": "return a bytes object from a : class : io. BytesIO"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef file(self, file=None):\n        if file is None:\n            file = StringIO()\n        self._file(file)\n        return file", "response": "Saves the dump in text mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndumps the content to a file.", "response": "def _file(self, file):\n        \"\"\"Dump the content to a `file`.\n        \"\"\"\n        if not self.__text_is_expected:\n            file = BytesWrapper(file, self.__encoding)\n        self.__dump_to_file(file)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _binary_file(self, file):\n        if self.__text_is_expected:\n            file = TextWrapper(file, self.__encoding)\n        self.__dump_to_file(file)", "response": "Dump the ocntent into the file in binary mode."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the dump in a file named path.", "response": "def _path(self, path):\n        \"\"\"Saves the dump in a file named `path`.\"\"\"\n        mode, encoding = self._mode_and_encoding_for_open()\n        with open(path, mode, encoding=encoding) as file:\n            self.__dump_to_file(file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _temporary_file(self, delete):\n        file = NamedTemporaryFile(\"w+\", delete=delete,\n                                  encoding=self.__encoding)\n        self._file(file)\n        return file", "response": "Returns a temporary file where the content is dumped to."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef temporary_path(self, extension=\"\"):\n        path = NamedTemporaryFile(delete=False, suffix=extension).name\n        self.path(path)\n        return path", "response": "Saves the dump in a temporary file and returns its path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _binary_temporary_file(self, delete):\n        file = NamedTemporaryFile(\"wb+\", delete=delete)\n        self._binary_file(file)\n        return file", "response": "Returns a binary temporary file where the content is dumped to."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _convert_to_image_color(self, color):\n        rgb = self._convert_color_to_rrggbb(color)\n        return self._convert_rrggbb_to_image_color(rgb)", "response": "Converts a color that can be used by the image"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the pixel but convert the color before.", "response": "def _set_pixel_and_convert_color(self, x, y, color):\n        \"\"\"set the pixel but convert the color before.\"\"\"\n        if color is None:\n            return\n        color = self._convert_color_to_rrggbb(color)\n        self._set_pixel(x, y, color)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the color of the pixel.", "response": "def _set_pixel(self, x, y, color):\n        \"\"\"set the color of the pixel.\n\n        :param color: must be a valid color in the form of \"#RRGGBB\".\n          If you need to convert color, use `_set_pixel_and_convert_color()`.\n        \"\"\"\n        if not self.is_in_bounds(x, y):\n            return\n        rgb = self._convert_rrggbb_to_image_color(color)\n        x -= self._min_x\n        y -= self._min_y\n        self._image.putpixel((x, y), rgb)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_pixel(self, x, y, color):\n        self._set_pixel_and_convert_color(x, y, color)", "response": "set the pixel at x y to color"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if x y is inside the bounds of the base image.", "response": "def is_in_bounds(self, x, y):\n        \"\"\"\n        :return: whether ``(x, y)`` is inside the :ref:`bounds\n          <png-builder-bounds>`\n        :rtype: bool\n        \"\"\"\n        lower = self._min_x <= x and self._min_y <= y\n        upper = self._max_x > x and self._max_y > y\n        return lower and upper"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the pixel at the position of the color_in_grid to its color.", "response": "def set_color_in_grid(self, color_in_grid):\n        \"\"\"Set the pixel at the position of the :paramref:`color_in_grid`\n        to its color.\n\n        :param color_in_grid: must have the following attributes:\n\n          - ``color`` is the :ref:`color <png-color>` to set the pixel to\n          - ``x`` is the x position of the pixel\n          - ``y`` is the y position of the pixel\n\n        .. seealso:: :meth:`set_pixel`, :meth:`set_colors_in_grid`\n        \"\"\"\n        self._set_pixel_and_convert_color(\n            color_in_grid.x, color_in_grid.y, color_in_grid.color)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the id that identifies the instruction in this cache.", "response": "def get_instruction_id(self, instruction_or_id):\n        \"\"\"The id that identifies the instruction in this cache.\n\n        :param instruction_or_id: an :class:`instruction\n          <knittingpattern.Instruction.Instruction>` or an instruction id\n        :return: a :func:`hashable <hash>` object\n        :rtype: tuple\n        \"\"\"\n        if isinstance(instruction_or_id, tuple):\n            return _InstructionId(instruction_or_id)\n        return _InstructionId(instruction_or_id.type,\n                              instruction_or_id.hex_color)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the SVG for an instruction.", "response": "def to_svg(self, instruction_or_id,\n               i_promise_not_to_change_the_result=False):\n        \"\"\"Return the SVG for an instruction.\n\n        :param instruction_or_id: either an\n          :class:`~knittingpattern.Instruction.Instruction` or an id\n          returned by :meth:`get_instruction_id`\n        :param bool i_promise_not_to_change_the_result:\n\n          - :obj:`False`: the result is copied, you can alter it.\n          - :obj:`True`: the result is directly from the cache. If you change\n            the result, other calls of this function get the changed result.\n\n        :return: an SVGDumper\n        :rtype: knittingpattern.Dumper.SVGDumper\n        \"\"\"\n        return self._new_svg_dumper(lambda: self.instruction_to_svg_dict(\n            instruction_or_id, not i_promise_not_to_change_the_result))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the SVG dict for the SVGBuilder.", "response": "def instruction_to_svg_dict(self, instruction_or_id, copy_result=True):\n        \"\"\"Return the SVG dict for the SVGBuilder.\n\n        :param instruction_or_id: the instruction or id, see\n          :meth:`get_instruction_id`\n        :param bool copy_result: whether to copy the result\n        :rtype: dict\n\n        The result is cached.\n        \"\"\"\n        instruction_id = self.get_instruction_id(instruction_or_id)\n        if instruction_id in self._cache:\n            result = self._cache[instruction_id]\n        else:\n            result = self._instruction_to_svg_dict(instruction_id)\n            self._cache[instruction_id] = result\n        if copy_result:\n            result = deepcopy(result)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls when there is a change in the instructions.", "response": "def _instructions_changed(self, change):\n        \"\"\"Call when there is a change in the instructions.\"\"\"\n        if change.adds():\n            for index, instruction in change.items():\n                if isinstance(instruction, dict):\n                    in_row = self._parser.instruction_in_row(self, instruction)\n                    self.instructions[index] = in_row\n                else:\n                    instruction.transfer_to_row(self)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef last_consumed_mesh(self):\n        for instruction in reversed(self.instructions):\n            if instruction.consumes_meshes():\n                return instruction.last_consumed_mesh\n        raise IndexError(\"{} consumes no meshes\".format(self))", "response": "The last consumed mesh."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef first_produced_mesh(self):\n        for instruction in self.instructions:\n            if instruction.produces_meshes():\n                return instruction.first_produced_mesh\n        raise IndexError(\"{} produces no meshes\".format(self))", "response": "The first produced mesh."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef first_consumed_mesh(self):\n        for instruction in self.instructions:\n            if instruction.consumes_meshes():\n                return instruction.first_consumed_mesh\n        raise IndexError(\"{} consumes no meshes\".format(self))", "response": "The first consumed mesh."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rows_before(self):\n        rows_before = []\n        for mesh in self.consumed_meshes:\n            if mesh.is_produced():\n                row = mesh.producing_row\n                if rows_before not in rows_before:\n                    rows_before.append(row)\n        return rows_before", "response": "The rows that produce the row\n          instructions before this row."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef at(self, index):\n        keys = list(self._items.keys())\n        key = keys[index]\n        return self[key]", "response": "Get the object at an index."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload all files from a folder recursively.", "response": "def folder(self, folder):\n        \"\"\"Load all files from a folder recursively.\n\n        Depending on :meth:`chooses_path` some paths may not be loaded.\n        Every loaded path is processed and returned part of the returned list.\n\n        :param str folder: the folder to load the files from\n        :rtype: list\n        :return: a list of the results of the processing steps of the loaded\n          files\n        \"\"\"\n        result = []\n        for root, _, files in os.walk(folder):\n            for file in files:\n                path = os.path.join(root, file)\n                if self._chooses_path(path):\n                    result.append(self.path(path))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the absolute path for the folder relative to the module_location.", "response": "def _relative_to_absolute(self, module_location, folder):\n        \"\"\":return: the absolute path for the `folder` relative to\n        the module_location.\n        :rtype: str\n        \"\"\"\n        if os.path.isfile(module_location):\n            path = os.path.dirname(module_location)\n        elif os.path.isdir(module_location):\n            path = module_location\n        else:\n            module_folder = os.path.dirname(module_location)\n            if module_folder:\n                path = module_folder\n            else:\n                __import__(module_location)\n                module = sys.modules[module_location]\n                path = os.path.dirname(module.__file__)\n        absolute_path = os.path.join(path, folder)\n        return absolute_path"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload a folder located relative to a module and return the processed result.", "response": "def relative_folder(self, module, folder):\n        \"\"\"Load a folder located relative to a module and return the processed\n        result.\n\n        :param str module: can be\n\n          - a path to a folder\n          - a path to a file\n          - a module name\n\n        :param str folder: the path of a folder relative to :paramref:`module`\n        :return: a list of the results of the processing\n        :rtype: list\n\n        Depending on :meth:`chooses_path` some paths may not be loaded.\n        Every loaded path is processed and returned part of the returned list.\n        You can use :meth:`choose_paths` to find out which paths are chosen to\n        load.\n        \"\"\"\n        folder = self._relative_to_absolute(module, folder)\n        return self.folder(folder)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef relative_file(self, module, file):\n        path = self._relative_to_absolute(module, file)\n        return self.path(path)", "response": "Load a file relative to a module."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef example(self, relative_path):\n        example_path = os.path.join(\"examples\", relative_path)\n        return self.relative_file(__file__, example_path)", "response": "Load an example from the knitting pattern examples."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef url(self, url, encoding=\"UTF-8\"):\n        import urllib.request\n        with urllib.request.urlopen(url) as file:\n            webpage_content = file.read()\n        webpage_content = webpage_content.decode(encoding)\n        return self.string(webpage_content)", "response": "load and process the content behind a url"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef string(self, string):\n        object_ = json.loads(string)\n        return self.object(object_)", "response": "Load an object from a string and return the processed JSON content\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the value behind key in the specification.", "response": "def get(self, key, default=None):\n        \"\"\"\n        :return: the value behind :paramref:`key` in the specification.\n          If no value was found, :paramref:`default` is returned.\n        :param key: a :ref:`specification key <prototype-key>`\n        \"\"\"\n        for base in self.__specification:\n            if key in base:\n                return base[key]\n        return default"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndump a knitting pattern to a file.", "response": "def _dump_knitting_pattern(self, file):\n        \"\"\"dump a knitting pattern to a file.\"\"\"\n        knitting_pattern_set = self.__on_dump()\n        knitting_pattern = knitting_pattern_set.patterns.at(0)\n        layout = GridLayout(knitting_pattern)\n        builder = AYABPNGBuilder(*layout.bounding_box)\n        builder.set_colors_in_grid(layout.walk_instructions())\n        builder.write_to_file(file)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating an iterable that contains each element once.", "response": "def unique(iterables):\n    \"\"\"Create an iterable from the iterables that contains each element once.\n\n    :return: an iterable over the iterables. Each element of the result\n      appeared only once in the result. They are ordered by the first\n      occurrence in the iterables.\n    \"\"\"\n    included_elements = set()\n\n    def included(element):\n        result = element in included_elements\n        included_elements.add(element)\n        return result\n    return [element for elements in iterables for element in elements\n            if not included(element)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngo through the layout and build the SVG.", "response": "def build_SVG_dict(self):\n        \"\"\"Go through the layout and build the SVG.\n\n        :return: an xml dict that can be exported using a\n          :class:`~knittingpattern.Dumper.XMLDumper`\n        :rtype: dict\n        \"\"\"\n        zoom = self._zoom\n        layout = self._layout\n        builder = self._builder\n        bbox = list(map(lambda f: f * zoom, layout.bounding_box))\n        builder.bounding_box = bbox\n        flip_x = bbox[2] + bbox[0] * 2\n        flip_y = bbox[3] + bbox[1] * 2\n        instructions = list(layout.walk_instructions(\n            lambda i: (flip_x - (i.x + i.width) * zoom,\n                       flip_y - (i.y + i.height) * zoom,\n                       i.instruction)))\n        instructions.sort(key=lambda x_y_i: x_y_i[2].render_z)\n        for x, y, instruction in instructions:\n            render_z = instruction.render_z\n            z_id = (\"\" if not render_z else \"-{}\".format(render_z))\n            layer_id = \"row-{}{}\".format(instruction.row.id, z_id)\n            def_id = self._register_instruction_in_defs(instruction)\n            scale = self._symbol_id_to_scale[def_id]\n            group = {\n                \"@class\": \"instruction\",\n                \"@id\": \"instruction-{}\".format(instruction.id),\n                \"@transform\": \"translate({},{}),scale({})\".format(\n                    x, y, scale)\n            }\n            builder.place_svg_use(def_id, layer_id, group)\n        builder.insert_defs(self._instruction_type_color_to_symbol.values())\n        return builder.get_svg_dict()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a definition for the specified instruction.", "response": "def _register_instruction_in_defs(self, instruction):\n        \"\"\"Create a definition for the instruction.\n\n        :return: the id of a symbol in the defs for the specified\n          :paramref:`instruction`\n        :rtype: str\n\n        If no symbol yet exists in the defs for the :paramref:`instruction` a\n        symbol is created and saved using :meth:`_make_symbol`.\n        \"\"\"\n        type_ = instruction.type\n        color_ = instruction.color\n        instruction_to_svg_dict = \\\n            self._instruction_to_svg.instruction_to_svg_dict\n        instruction_id = \"{}:{}\".format(type_, color_)\n        defs_id = instruction_id + \":defs\"\n        if instruction_id not in self._instruction_type_color_to_symbol:\n            svg_dict = instruction_to_svg_dict(instruction)\n            self._compute_scale(instruction_id, svg_dict)\n            symbol = self._make_definition(svg_dict, instruction_id)\n            self._instruction_type_color_to_symbol[defs_id] = \\\n                symbol[DEFINITION_HOLDER].pop(\"defs\", {})\n            self._instruction_type_color_to_symbol[instruction_id] = symbol\n        return instruction_id"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a symbol out of the supplied SVG dictionary.", "response": "def _make_definition(self, svg_dict, instruction_id):\n        \"\"\"Create a symbol out of the supplied :paramref:`svg_dict`.\n\n        :param dict svg_dict: dictionary containing the SVG for the\n          instruction currently processed\n        :param str instruction_id: id that will be assigned to the symbol\n        \"\"\"\n        instruction_def = svg_dict[\"svg\"]\n        blacklisted_elements = [\"sodipodi:namedview\", \"metadata\"]\n        whitelisted_attributes = [\"@sodipodi:docname\"]\n        symbol = OrderedDict({\"@id\": instruction_id})\n        for content, value in instruction_def.items():\n            if content.startswith('@'):\n                if content in whitelisted_attributes:\n                    symbol[content] = value\n            elif content not in blacklisted_elements:\n                symbol[content] = value\n        return {DEFINITION_HOLDER: symbol}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _compute_scale(self, instruction_id, svg_dict):\n        bbox = list(map(float, svg_dict[\"svg\"][\"@viewBox\"].split()))\n        scale = self._zoom / (bbox[3] - bbox[1])\n        self._symbol_id_to_scale[instruction_id] = scale", "response": "Compute the scale of an instruction svg."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_svg(self, zoom):\n        def on_dump():\n            \"\"\"Dump the knitting pattern to the file.\n\n            :return: the SVG XML structure as dictionary.\n            \"\"\"\n            knitting_pattern = self.patterns.at(0)\n            layout = GridLayout(knitting_pattern)\n            instruction_to_svg = default_instruction_svg_cache()\n            builder = SVGBuilder()\n            kp_to_svg = KnittingPatternToSVG(knitting_pattern, layout,\n                                             instruction_to_svg, builder, zoom)\n            return kp_to_svg.build_SVG_dict()\n        return XMLDumper(on_dump)", "response": "Create an SVG from the knitting pattern set."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_new_pattern(self, id_, name=None):\n        if name is None:\n            name = id_\n        pattern = self._parser.new_pattern(id_, name)\n        self._patterns.append(pattern)\n        return pattern", "response": "Add a new pattern to the set."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_svg(self, converter=None):\n        if converter is None:\n            from knittingpattern.convert.InstructionSVGCache import \\\n                default_svg_cache\n            converter = default_svg_cache()\n        return converter.to_svg(self)", "response": "Return a SVGDumper for this instruction."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transfer_to_row(self, new_row):\n        if new_row != self._row:\n            index = self.get_index_in_row()\n            if index is not None:\n                self._row.instructions.pop(index)\n            self._row = new_row", "response": "Transfer this instruction to a new row."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_index_in_row(self):\n        expected_index = self._cached_index_in_row\n        instructions = self._row.instructions\n        if expected_index is not None and \\\n                0 <= expected_index < len(instructions) and \\\n                instructions[expected_index] is self:\n            return expected_index\n        for index, instruction_in_row in enumerate(instructions):\n            if instruction_in_row is self:\n                self._cached_index_in_row = index\n                return index\n        return None", "response": "Returns the index of the instruction in the row or None if the instruction is not in the row."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef next_instruction_in_row(self):\n        index = self.index_in_row + 1\n        if index >= len(self.row_instructions):\n            return None\n        return self.row_instructions[index]", "response": "The next instruction in the row."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the index of the first produced mesh in the row that consumes it.", "response": "def index_of_first_produced_mesh_in_row(self):\n        \"\"\"Index of the first produced mesh in the row that consumes it.\n\n        :return: an index of the first produced mesh of rows produced meshes\n        :rtype: int\n\n        .. note:: If the instruction :meth:`produces meshes\n          <Instruction.produces_meshes>`, this is the index of the first\n          mesh the instruction produces in all the meshes of the row.\n          If the instruction does not produce meshes, the index of the mesh is\n          returned as if the instruction had produced a mesh.\n\n        .. code::\n\n            if instruction.produces_meshes():\n                index = instruction.index_of_first_produced_mesh_in_row\n\n        \"\"\"\n        index = 0\n        for instruction in self.row_instructions:\n            if instruction is self:\n                break\n            index += instruction.number_of_produced_meshes\n        else:\n            self._raise_not_found_error()\n        return index"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef index_of_first_consumed_mesh_in_row(self):\n        index = 0\n        for instruction in self.row_instructions:\n            if instruction is self:\n                break\n            index += instruction.number_of_consumed_meshes\n        else:\n            self._raise_not_found_error()\n        return index", "response": "The index of the first consumed mesh in this instruction in its row."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _start(self):\n        self._instruction_library = self._spec.new_default_instructions()\n        self._as_instruction = self._instruction_library.as_instruction\n        self._id_cache = {}\n        self._pattern_set = None\n        self._inheritance_todos = []\n        self._instruction_todos = []", "response": "Initialize the parsing process."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef knitting_pattern_set(self, values):\n        self._start()\n        pattern_collection = self._new_pattern_collection()\n        self._fill_pattern_collection(pattern_collection, values)\n        self._create_pattern_set(pattern_collection, values)\n        return self._pattern_set", "response": "Parse a knitting pattern set."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _finish_inheritance(self):\n        while self._inheritance_todos:\n            prototype, parent_id = self._inheritance_todos.pop()\n            parent = self._id_cache[parent_id]\n            prototype.inherit_from(parent)", "response": "Finish those who still need to inherit."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfinish those who still need to inherit.", "response": "def _finish_instructions(self):\n        \"\"\"Finish those who still need to inherit.\"\"\"\n        while self._instruction_todos:\n            row = self._instruction_todos.pop()\n            instructions = row.get(INSTRUCTIONS, [])\n            row.instructions.extend(instructions)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfilling a pattern collection.", "response": "def _fill_pattern_collection(self, pattern_collection, values):\n        \"\"\"Fill a pattern collection.\"\"\"\n        pattern = values.get(PATTERNS, [])\n        for pattern_to_parse in pattern:\n            parsed_pattern = self._pattern(pattern_to_parse)\n            pattern_collection.append(parsed_pattern)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef instruction_in_row(self, row, specification):\n        whole_instruction_ = self._as_instruction(specification)\n        return self._spec.new_instruction_in_row(row, whole_instruction_)", "response": "Parse an instruction.\n        from the row."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new knitting pattern.", "response": "def new_pattern(self, id_, name, rows=None):\n        \"\"\"Create a new knitting pattern.\n\n        If rows is :obj:`None` it is replaced with the\n        :meth:`new_row_collection`.\n        \"\"\"\n        if rows is None:\n            rows = self.new_row_collection()\n        return self._spec.new_pattern(id_, name, rows, self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _rows(self, spec):\n        rows = self.new_row_collection()\n        for row in spec:\n            rows.append(self._row(row))\n        return rows", "response": "Parse a collection of rows."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _connect_rows(self, connections):\n        for connection in connections:\n            from_row_id = self._to_id(connection[FROM][ID])\n            from_row = self._id_cache[from_row_id]\n            from_row_start_index = connection[FROM].get(START, DEFAULT_START)\n            from_row_number_of_possible_meshes = \\\n                from_row.number_of_produced_meshes - from_row_start_index\n            to_row_id = self._to_id(connection[TO][ID])\n            to_row = self._id_cache[to_row_id]\n            to_row_start_index = connection[TO].get(START, DEFAULT_START)\n            to_row_number_of_possible_meshes = \\\n                to_row.number_of_consumed_meshes - to_row_start_index\n            meshes = min(from_row_number_of_possible_meshes,\n                         to_row_number_of_possible_meshes)\n            # TODO: test all kinds of connections\n            number_of_meshes = connection.get(MESHES, meshes)\n            from_row_stop_index = from_row_start_index + number_of_meshes\n            to_row_stop_index = to_row_start_index + number_of_meshes\n            assert 0 <= from_row_start_index <= from_row_stop_index\n            produced_meshes = from_row.produced_meshes[\n                from_row_start_index:from_row_stop_index]\n            assert 0 <= to_row_start_index <= to_row_stop_index\n            consumed_meshes = to_row.consumed_meshes[\n                to_row_start_index:to_row_stop_index]\n            assert len(produced_meshes) == len(consumed_meshes)\n            mesh_pairs = zip(produced_meshes, consumed_meshes)\n            for produced_mesh, consumed_mesh in mesh_pairs:\n                produced_mesh.connect_to(consumed_mesh)", "response": "Connect the parsed rows."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_type(self, values):\n        if TYPE not in values:\n            self._error(\"No pattern type given but should be \"\n                        \"\\\"{}\\\"\".format(KNITTING_PATTERN_TYPE))\n        type_ = values[TYPE]\n        if type_ != KNITTING_PATTERN_TYPE:\n            self._error(\"Wrong pattern type. Type is \\\"{}\\\" \"\n                        \"but should be \\\"{}\\\"\"\n                        \"\".format(type_, KNITTING_PATTERN_TYPE))\n        return type_", "response": "Returns the type of a knitting pattern set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_pattern_set(self, pattern, values):\n        type_ = self._get_type(values)\n        version = self._get_version(values)\n        comment = values.get(COMMENT)\n        self._pattern_set = self._spec.new_pattern_set(\n            type_, version, pattern, self, comment\n        )", "response": "Create a new pattern set."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_row(self, id_):\n        row = self._parser.new_row(id_)\n        self._rows.append(row)\n        return row", "response": "Add a new row to the pattern."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, bytes_):\n        string = bytes_.decode(self._encoding)\n        self._file.write(string)", "response": "Write bytes to the file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite a string to the file.", "response": "def write(self, string):\n        \"\"\"Write a string to the file.\"\"\"\n        bytes_ = string.encode(self._encoding)\n        self._file.write(bytes_)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nplaces the SVG content at x y in the layer with the id layer_id.", "response": "def place(self, x, y, svg, layer_id):\n        \"\"\"Place the :paramref:`svg` content at ``(x, y)`` position\n        in the SVG, in a layer with the id :paramref:`layer_id`.\n\n        :param float x: the x position of the svg\n        :param float y: the y position of the svg\n        :param str svg: the SVG to place at ``(x, y)``\n        :param str layer_id: the id of the layer that this\n          :paramref:`svg` should be placed inside\n\n        \"\"\"\n        content = xmltodict.parse(svg)\n        self.place_svg_dict(x, y, content, layer_id)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef place_svg_dict(self, x, y, svg_dict, layer_id, group=None):\n        if group is None:\n            group = {}\n        group_ = {\n            \"@transform\": \"translate({},{})\".format(x, y),\n            \"g\": list(svg_dict.values())\n        }\n        group_.update(group)\n        layer = self._get_layer(layer_id)\n        layer[\"g\"].append(group_)", "response": "Same as place but with a dictionary as svg_dict."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_layer(self, layer_id):\n        if layer_id not in self._layer_id_to_layer:\n            self._svg.setdefault(\"g\", [])\n            layer = {\n                \"g\": [],\n                \"@inkscape:label\": layer_id,\n                \"@id\": layer_id,\n                \"@inkscape:groupmode\": \"layer\",\n                \"@class\": \"row\"\n            }\n            self._layer_id_to_layer[layer_id] = layer\n            self._svg[\"g\"].append(layer)\n        return self._layer_id_to_layer[layer_id]", "response": "Returns the layer with the given id. If the layer with the given id does not exist it is created."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insert_defs(self, defs):\n        if self._svg[\"defs\"] is None:\n            self._svg[\"defs\"] = {}\n        for def_ in defs:\n            for key, value in def_.items():\n                if key.startswith(\"@\"):\n                    continue\n                if key not in self._svg[\"defs\"]:\n                    self._svg[\"defs\"][key] = []\n                if not isinstance(value, list):\n                    value = [value]\n                self._svg[\"defs\"][key].extend(value)", "response": "Adds the defs to the SVG structure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the current SVG to the file - like object.", "response": "def write_to_file(self, file):\n        \"\"\"Writes the current SVG to the :paramref:`file`.\n\n        :param file: a file-like object\n        \"\"\"\n        xmltodict.unparse(self._structure, file, pretty=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _width(self):\n        layout = self._instruction.get(GRID_LAYOUT)\n        if layout is not None:\n            width = layout.get(WIDTH)\n            if width is not None:\n                return width\n        return self._instruction.number_of_consumed_meshes", "response": "For self. width return the number of consumed meshes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexpand the row into the list of items to be processed.", "response": "def _expand(self, row, consumed_position, passed):\n        \"\"\"Add the arguments `(args, kw)` to `_walk` to the todo list.\"\"\"\n        self._todo.append((row, consumed_position, passed))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _step(self, row, position, passed):\n        if row in passed or not self._row_should_be_placed(row, position):\n            return\n        self._place_row(row, position)\n        passed = [row] + passed\n        # print(\"{}{} at\\t{} {}\".format(\"  \" * len(passed), row, position,\n        #                               passed))\n        for i, produced_mesh in enumerate(row.produced_meshes):\n            self._expand_produced_mesh(produced_mesh, i, position, passed)\n        for i, consumed_mesh in enumerate(row.consumed_meshes):\n            self._expand_consumed_mesh(consumed_mesh, i, position, passed)", "response": "Walk through the knitting pattern by expanding an row."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexpands the consumed meshes", "response": "def _expand_consumed_mesh(self, mesh, mesh_index, row_position, passed):\n        \"\"\"expand the consumed meshes\"\"\"\n        if not mesh.is_produced():\n            return\n        row = mesh.producing_row\n        position = Point(\n            row_position.x + mesh.index_in_producing_row - mesh_index,\n            row_position.y - INSTRUCTION_HEIGHT\n        )\n        self._expand(row, position, passed)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexpands the produced meshes", "response": "def _expand_produced_mesh(self, mesh, mesh_index, row_position, passed):\n        \"\"\"expand the produced meshes\"\"\"\n        if not mesh.is_consumed():\n            return\n        row = mesh.consuming_row\n        position = Point(\n            row_position.x - mesh.index_in_consuming_row + mesh_index,\n            row_position.y + INSTRUCTION_HEIGHT\n        )\n        self._expand(row, position, passed)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning whether or not this instruction should be placed at the given row.", "response": "def _row_should_be_placed(self, row, position):\n        \"\"\":return: whether to place this instruction\"\"\"\n        placed_row = self._rows_in_grid.get(row)\n        return placed_row is None or placed_row.y < position.y"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nplaces the instruction on a grid", "response": "def _place_row(self, row, position):\n        \"\"\"place the instruction on a grid\"\"\"\n        self._rows_in_grid[row] = RowInGrid(row, position)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwalking through all the instructions that are _todo.", "response": "def _walk(self):\n        \"\"\"Loop through all the instructions that are `_todo`.\"\"\"\n        while self._todo:\n            args = self._todo.pop(0)\n            self._step(*args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an InstructionInGrid object for the instruction", "response": "def instruction_in_grid(self, instruction):\n        \"\"\"Returns an `InstructionInGrid` object for the `instruction`\"\"\"\n        row_position = self._rows_in_grid[instruction.row].xy\n        x = instruction.index_of_first_consumed_mesh_in_row\n        position = Point(row_position.x + x, row_position.y)\n        return InstructionInGrid(instruction, position)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if this connection is visible if it is longer than 0.", "response": "def is_visible(self):\n        \"\"\":return: is this connection is visible\n        :rtype: bool\n\n        A connection is visible if it is longer that 0.\"\"\"\n        if self._start.y + 1 < self._stop.y:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\niterating over instructions. :return: an iterator over :class:`instructions in grid <InstructionInGrid>` :param mapping: funcion to map the result .. code:: python for pos, c in layout.walk_instructions(lambda i: (i.xy, i.color)): print(\"color {} at {}\".format(c, pos))", "response": "def walk_instructions(self, mapping=identity):\n        \"\"\"Iterate over instructions.\n\n        :return: an iterator over :class:`instructions in grid\n          <InstructionInGrid>`\n        :param mapping: funcion to map the result\n\n        .. code:: python\n\n            for pos, c in layout.walk_instructions(lambda i: (i.xy, i.color)):\n                print(\"color {} at {}\".format(c, pos))\n\n        \"\"\"\n        instructions = chain(*self.walk_rows(lambda row: row.instructions))\n        return map(mapping, instructions)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef walk_rows(self, mapping=identity):\n        row_in_grid = self._walk.row_in_grid\n        return map(lambda row: mapping(row_in_grid(row)), self._rows)", "response": "Iterate over rows.\n\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef walk_connections(self, mapping=identity):\n        for start in self.walk_instructions():\n            for stop_instruction in start.instruction.consuming_instructions:\n                if stop_instruction is None:\n                    continue\n                stop = self._walk.instruction_in_grid(stop_instruction)\n                connection = Connection(start, stop)\n                if connection.is_visible():\n                    # print(\"connection:\",\n                    #      connection.start.instruction,\n                    #      connection.stop.instruction)\n                    yield mapping(connection)", "response": "Iterate over connections between instructions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing the :paramref:`path`. :param str path: the path to load an svg from", "response": "def _process_loaded_object(self, path):\n        \"\"\"process the :paramref:`path`.\n\n        :param str path: the path to load an svg from\n        \"\"\"\n        file_name = os.path.basename(path)\n        name = os.path.splitext(file_name)[0]\n        with open(path) as file:\n            string = file.read()\n            self._instruction_type_to_file_content[name] = string"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef instruction_to_svg_dict(self, instruction):\n        instruction_type = instruction.type\n        if instruction_type in self._instruction_type_to_file_content:\n            svg = self._instruction_type_to_file_content[instruction_type]\n            return self._set_fills_in_color_layer(svg, instruction.hex_color)\n        return self.default_instruction_to_svg_dict(instruction)", "response": "Converts an instruction to an xml - dictionary with the same content as\n         ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_fills_in_color_layer(self, svg_string, color):\n        structure = xmltodict.parse(svg_string)\n        if color is None:\n            return structure\n        layers = structure[\"svg\"][\"g\"]\n        if not isinstance(layers, list):\n            layers = [layers]\n        for layer in layers:\n            if not isinstance(layer, dict):\n                continue\n            if layer.get(\"@inkscape:label\") == \"color\" and \\\n                    layer.get(\"@inkscape:groupmode\") == \"layer\":\n                for key, elements in layer.items():\n                    if key.startswith(\"@\") or key.startswith(\"#\"):\n                        continue\n                    if not isinstance(elements, list):\n                        elements = [elements]\n                    for element in elements:\n                        style = element.get(\"@style\", None)\n                        if style:\n                            style = style.split(\";\")\n                            processed_style = []\n                            for style_element in style:\n                                if style_element.startswith(\"fill:\"):\n                                    style_element = \"fill:\" + color\n                                processed_style.append(style_element)\n                            style = \";\".join(processed_style)\n                            element[\"@style\"] = style\n        return structure", "response": "replaces fill colors in color layer with color"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef default_instruction_to_svg(self, instruction):\n        svg_dict = self.default_instruction_to_svg_dict(instruction)\n        return xmltodict.unparse(svg_dict)", "response": "As a method to get the default svg for an instruction."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an xml - dictionary with the same content as the default. svg file.", "response": "def default_instruction_to_svg_dict(self, instruction):\n        \"\"\"Returns an xml-dictionary with the same content as\n        :meth:`default_instruction_to_svg`\n\n        If no file ``default.svg`` was loaded, an empty svg-dict is returned.\n        \"\"\"\n        instruction_type = instruction.type\n        default_type = \"default\"\n        rep_str = \"{instruction.type}\"\n        if default_type not in self._instruction_type_to_file_content:\n            return {\"svg\": \"\"}\n        default_svg = self._instruction_type_to_file_content[default_type]\n        default_svg = default_svg.replace(rep_str, instruction_type)\n        colored_svg = self._set_fills_in_color_layer(default_svg,\n                                                     instruction.hex_color)\n        return colored_svg"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping to the file", "response": "def _dump_to_file(self, file):\n        \"\"\"dump to the file\"\"\"\n        xmltodict.unparse(self.object(), file, pretty=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an instruction specification", "response": "def add_instruction(self, specification):\n        \"\"\"Add an instruction specification\n\n        :param specification: a specification with a key\n          :data:`knittingpattern.Instruction.TYPE`\n\n        .. seealso:: :meth:`as_instruction`\n        \"\"\"\n        instruction = self.as_instruction(specification)\n        self._type_to_instruction[instruction.type] = instruction"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef as_instruction(self, specification):\n        instruction = self._instruction_class(specification)\n        type_ = instruction.type\n        if type_ in self._type_to_instruction:\n            instruction.inherit_from(self._type_to_instruction[type_])\n        return instruction", "response": "Convert the specification into an instruction."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the log - determinant of the object.", "response": "def logdet(self):\n        \"\"\"\n        Log of \uff5cK\uff5c.\n\n        Returns\n        -------\n        float\n            Log-determinant of K.\n        \"\"\"\n        from numpy.linalg import slogdet\n\n        K = self.value()\n\n        sign, logdet = slogdet(K)\n        if sign != 1.0:\n            msg = \"The estimated determinant of K is not positive: \"\n            msg += f\" ({sign}, {logdet}).\"\n            raise RuntimeError(msg)\n\n        return logdet"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the value of the COvariance matrix.", "response": "def value(self):\n        \"\"\"\n        Covariance matrix.\n\n        Returns\n        -------\n        K : ndarray\n            Matrix K = LL\u1d40 + \u03f5I, for a very small positive number \u03f5.\n        \"\"\"\n        K = dot(self.L, self.L.T)\n        return K + self._epsilon * eye(K.shape[0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gradient(self):\n        L = self.L\n        self._grad_Lu[:] = 0\n\n        for i in range(len(self._tril1[0])):\n            row = self._tril1[0][i]\n            col = self._tril1[1][i]\n            self._grad_Lu[row, :, i] = L[:, col]\n            self._grad_Lu[:, row, i] += L[:, col]\n\n        m = len(self._tril1[0])\n        for i in range(len(self._diag[0])):\n            row = self._diag[0][i]\n            col = self._diag[1][i]\n            self._grad_Lu[row, :, m + i] = L[row, col] * L[:, col]\n            self._grad_Lu[:, row, m + i] += L[row, col] * L[:, col]\n\n        return {\"Lu\": self._grad_Lu}", "response": "Returns the gradient of the log likelihood matrix over the lower triangular part of L."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Ge(self):\n\n        from scipy.linalg import svd\n        from numpy_sugar.linalg import ddot\n\n        U, S, _ = svd(self._G, full_matrices=False, check_finite=False)\n        if U.shape[1] < self._G.shape[1]:\n            return ddot(U, S)\n        return self._G", "response": "Returns the result of US from the SVD decomposition G = USV\u1d40."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlistening to parameters change.", "response": "def listen(self, func):\n        \"\"\"\n        Listen to parameters change.\n\n        Parameters\n        ----------\n        func : callable\n            Function to be called when a parameter changes.\n        \"\"\"\n        self._C0.listen(func)\n        self._C1.listen(func)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nproviding Lh and D.", "response": "def _LhD(self):\n        \"\"\"\n        Implements L\u2095 and D.\n\n        Returns\n        -------\n        Lh : ndarray\n            U\u2095\u1d40 S\u2081\u207b\u00bd U\u2081\u1d40.\n        D : ndarray\n            (S\u2095 \u2297 S\u2093 + I\u2095\u2093)\u207b\u00b9.\n        \"\"\"\n        from numpy_sugar.linalg import ddot\n\n        self._init_svd()\n        if self._cache[\"LhD\"] is not None:\n            return self._cache[\"LhD\"]\n        S1, U1 = self.C1.eigh()\n        U1S1 = ddot(U1, 1 / sqrt(S1))\n        Sh, Uh = eigh(U1S1.T @ self.C0.value() @ U1S1)\n        self._cache[\"LhD\"] = {\n            \"Lh\": (U1S1 @ Uh).T,\n            \"D\": 1 / (kron(Sh, self._Sx) + 1),\n            \"De\": 1 / (kron(Sh, self._Sxe) + 1),\n        }\n        return self._cache[\"LhD\"]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the value of the object as a numpy array.", "response": "def value(self):\n        \"\"\"\n        Covariance matrix K = C\u2080 \u2297 GG\u1d40 + C\u2081 \u2297 I.\n\n        Returns\n        -------\n        K : ndarray\n            C\u2080 \u2297 GG\u1d40 + C\u2081 \u2297 I.\n        \"\"\"\n        C0 = self._C0.value()\n        C1 = self._C1.value()\n        return kron(C0, self._GG) + kron(C1, self._I)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the gradient of the logarithm of the logarithm of the current logarithm of the given vector.", "response": "def gradient_dot(self, v):\n        \"\"\"\n        Implements \u2202K\u22c5v.\n\n        Parameters\n        ----------\n        v : array_like\n            Vector from \u2202K\u22c5v.\n\n        Returns\n        -------\n        C0.Lu : ndarray\n            \u2202K\u22c5v, where the gradient is taken over the C\u2080 parameters.\n        C1.Lu : ndarray\n            \u2202K\u22c5v, where the gradient is taken over the C\u2081 parameters.\n        \"\"\"\n        self._init_svd()\n        V = unvec(v, (self.G.shape[0], -1) + v.shape[1:])\n        r = {}\n\n        C = self._C0.gradient()[\"Lu\"]\n        r[\"C0.Lu\"] = tensordot(V.T @ self.G @ self.G.T, C, axes=([-2], [0]))\n        r[\"C0.Lu\"] = r[\"C0.Lu\"].reshape(V.shape[2:] + (-1,) + (C.shape[-1],), order=\"F\")\n\n        C = self._C1.gradient()[\"Lu\"]\n        r[\"C1.Lu\"] = tensordot(V.T, C, axes=([-2], [0]))\n        r[\"C1.Lu\"] = r[\"C1.Lu\"].reshape(V.shape[2:] + (-1,) + (C.shape[-1],), order=\"F\")\n\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the solution x to the product K.", "response": "def solve(self, v):\n        \"\"\"\n        Implements the product K\u207b\u00b9\u22c5v.\n\n        Parameters\n        ----------\n        v : array_like\n            Array to be multiplied.\n\n        Returns\n        -------\n        x : ndarray\n            Solution x to the equation K\u22c5x = y.\n        \"\"\"\n        from numpy_sugar.linalg import ddot\n\n        self._init_svd()\n        L = kron(self.Lh, self.Lx)\n        return L.T @ ddot(self.D, L @ v, left=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef logdet(self):\n        self._init_svd()\n        return -log(self._De).sum() + self.G.shape[0] * self.C1.logdet()", "response": "Returns the log - determinant of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef logdet_gradient(self):\n        from numpy_sugar.linalg import dotd\n\n        self._init_svd()\n\n        dC0 = self._C0.gradient()[\"Lu\"]\n        grad_C0 = zeros_like(self._C0.Lu)\n        for i in range(self._C0.Lu.shape[0]):\n            t = kron(dotd(self.Lh, dC0[..., i] @ self.Lh.T), self._diag_LxGGLxe)\n            grad_C0[i] = (self._De * t).sum()\n\n        dC1 = self._C1.gradient()[\"Lu\"]\n        grad_C1 = zeros_like(self._C1.Lu)\n        p = self._Sxe.shape[0]\n        np = self._G.shape[0] - p\n        for i in range(self._C1.Lu.shape[0]):\n            t = (dotd(self.Lh, dC1[..., i] @ self.Lh.T) * np).sum()\n            t1 = kron(dotd(self.Lh, dC1[..., i] @ self.Lh.T), eye(p))\n            t += (self._De * t1).sum()\n            grad_C1[i] = t\n\n        return {\"C0.Lu\": grad_C0, \"C1.Lu\": grad_C1}", "response": "Calculates the log - derivative of the log - derivative of the current state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nimplementing L ( \u2202K ) L\u1d40v.", "response": "def LdKL_dot(self, v, v1=None):\n        \"\"\"\n        Implements L(\u2202K)L\u1d40v.\n\n        The array v can have one or two dimensions and the first dimension has to have\n        size n\u22c5p.\n\n        Let vec(V) = v. We have\n\n            L(\u2202K)L\u1d40\u22c5v = ((L\u2095\u2202C\u2080L\u2095\u1d40) \u2297 (L\u2093GG\u1d40L\u2093\u1d40))vec(V) = vec(L\u2093GG\u1d40L\u2093\u1d40VL\u2095\u2202C\u2080L\u2095\u1d40),\n\n        when the derivative is over the parameters of C\u2080. Similarly,\n\n            L(\u2202K)L\u1d40v = ((L\u2095\u2202C\u2081L\u2095\u1d40) \u2297 (L\u2093L\u2093\u1d40))vec(V) = vec(L\u2093L\u2093\u1d40VL\u2095\u2202C\u2081L\u2095\u1d40),\n\n        over the parameters of C\u2081.\n        \"\"\"\n        self._init_svd()\n\n        def dot(a, b):\n            r = tensordot(a, b, axes=([1], [0]))\n            if a.ndim > b.ndim:\n                return r.transpose([0, 2, 1])\n            return r\n\n        Lh = self.Lh\n        V = unvec(v, (self.Lx.shape[0], -1) + v.shape[1:])\n        LdKL_dot = {\n            \"C0.Lu\": empty((v.shape[0],) + v.shape[1:] + (self._C0.Lu.shape[0],)),\n            \"C1.Lu\": empty((v.shape[0],) + v.shape[1:] + (self._C1.Lu.shape[0],)),\n        }\n\n        dC0 = self._C0.gradient()[\"Lu\"]\n        for i in range(self._C0.Lu.shape[0]):\n            t = dot(self._LxG, dot(self._LxG.T, dot(V, Lh @ dC0[..., i] @ Lh.T)))\n            LdKL_dot[\"C0.Lu\"][..., i] = t.reshape((-1,) + t.shape[2:], order=\"F\")\n\n        dC1 = self._C1.gradient()[\"Lu\"]\n        for i in range(self._C1.Lu.shape[0]):\n            t = dot(V, Lh @ dC1[..., i] @ Lh.T)\n            LdKL_dot[\"C1.Lu\"][..., i] = t.reshape((-1,) + t.shape[2:], order=\"F\")\n\n        return LdKL_dot"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rsolve(A, y):\n    from numpy_sugar.linalg import rsolve as _rsolve\n\n    try:\n        beta = _rsolve(A, y)\n    except LinAlgError:\n        msg = \"Could not converge to solve Ax=y.\"\n        msg += \" Setting x to zero.\"\n        warnings.warn(msg, RuntimeWarning)\n        beta = zeros(A.shape[0])\n\n    return beta", "response": "Robust solve Ax = y.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndrawing random samples from a multivariate normal distribution.", "response": "def multivariate_normal(random, mean, cov):\n    \"\"\"\n    Draw random samples from a multivariate normal distribution.\n\n    Parameters\n    ----------\n    random : np.random.RandomState instance\n        Random state.\n    mean : array_like\n        Mean of the n-dimensional distribution.\n    cov : array_like\n        Covariance matrix of the distribution. It must be symmetric and\n        positive-definite for proper sampling.\n\n    Returns\n    -------\n    out : ndarray\n        The drawn sample.\n    \"\"\"\n    from numpy.linalg import cholesky\n\n    L = cholesky(cov)\n    return L @ random.randn(L.shape[0]) + mean"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the gradient of the covariance function derivatives.", "response": "def gradient(self):\n        \"\"\"\n        Sum of covariance function derivatives.\n\n        Returns\n        -------\n        dict\n            \u2202K\u2080 + \u2202K\u2081 + \u22ef\n        \"\"\"\n        grad = {}\n        for i, f in enumerate(self._covariances):\n            for varname, g in f.gradient().items():\n                grad[f\"{self._name}[{i}].{varname}\"] = g\n        return grad"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the value of the COvariance matrix.", "response": "def value(self):\n        \"\"\"\n        Covariance matrix.\n\n        Returns\n        -------\n        K : ndarray\n            s\u22c5XX\u1d40.\n        \"\"\"\n        X = self.X\n        return self.scale * (X @ X.T)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bernoulli_sample(\n    offset,\n    G,\n    heritability=0.5,\n    causal_variants=None,\n    causal_variance=0,\n    random_state=None,\n):\n    r\"\"\"Bernoulli likelihood sampling.\n\n    Sample according to\n\n    .. math::\n\n        \\mathbf y \\sim \\prod_{i=1}^n\n        \\text{Bernoulli}(\\mu_i = \\text{logit}(z_i))\n        \\mathcal N(~ o \\mathbf 1 + \\mathbf a^\\intercal \\boldsymbol\\alpha;\n        ~ (h^2 - v_c)\\mathrm G^\\intercal\\mathrm G +\n        (1-h^2-v_c)\\mathrm I ~)\n\n    using the canonical Logit link function to define the conditional Bernoulli\n    mean :math:`\\mu_i`.\n\n    The causal :math:`\\mathbf a` covariates and the corresponding effect-sizes\n    are randomly draw according to the following idea. The ``causal_variants``,\n    if given, are first mean-zero and std-one normalized and then having\n    its elements divided by the squared-root the the number of variances::\n\n        causal_variants = _stdnorm(causal_variants, axis=0)\n        causal_variants /= sqrt(causal_variants.shape[1])\n\n    The causal effect-sizes :math:`\\boldsymbol\\alpha` are draw from\n    :math:`\\{-1, +1\\}` and subsequently normalized for mean-zero and std-one\"\"\n\n    Parameters\n    ----------\n    random_state : random_state\n        Set the initial random state.\n\n    Example\n    -------\n\n    .. doctest::\n\n        >>> from glimix_core.random import bernoulli_sample\n        >>> from numpy.random import RandomState\n        >>> offset = 5\n        >>> G = [[1, -1], [2, 1]]\n        >>> bernoulli_sample(offset, G, random_state=RandomState(0))\n        array([1., 1.])\n    \"\"\"\n    link = LogitLink()\n    mean, cov = _mean_cov(\n        offset, G, heritability, causal_variants, causal_variance, random_state\n    )\n    lik = BernoulliProdLik(link)\n    sampler = GGPSampler(lik, mean, cov)\n\n    return sampler.sample(random_state)", "response": "r Bernoulli likelihood sampling."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmaximise the marginal likelihood.", "response": "def fit(self, verbose=True, factr=1e5, pgtol=1e-7):\n        r\"\"\"Maximise the marginal likelihood.\n\n        Parameters\n        ----------\n        verbose : bool\n            ``True`` for progress output; ``False`` otherwise.\n            Defaults to ``True``.\n        factr : float, optional\n            The iteration stops when\n            ``(f^k - f^{k+1})/max{|f^k|,|f^{k+1}|,1} <= factr * eps``, where ``eps`` is\n            the machine precision.\n        pgtol : float, optional\n            The iteration will stop when ``max{|proj g_i | i = 1, ..., n} <= pgtol``\n            where ``pg_i`` is the i-th component of the projected gradient.\n\n        Notes\n        -----\n        Please, refer to :func:`scipy.optimize.fmin_l_bfgs_b` for further information\n        about ``factr`` and ``pgtol``.\n        \"\"\"\n        self._maximize(verbose=verbose, factr=factr, pgtol=pgtol)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef covariance(self):\n        from numpy_sugar.linalg import ddot, sum2diag\n\n        Q0 = self._QS[0][0]\n        S0 = self._QS[1]\n        return sum2diag(dot(ddot(Q0, self.v0 * S0), Q0.T), self.v1)", "response": "rCovariance of the prior."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmaximise the marginal likelihood.", "response": "def fit(self, verbose=True, factr=1e5, pgtol=1e-7):\n        r\"\"\"Maximise the marginal likelihood.\n\n        Parameters\n        ----------\n        verbose : bool\n            ``True`` for progress output; ``False`` otherwise.\n            Defaults to ``True``.\n        factr : float, optional\n            The iteration stops when\n            ``(f^k - f^{k+1})/max{|f^k|,|f^{k+1}|,1} <= factr * eps``, where ``eps`` is\n            the machine precision.\n        pgtol : float, optional\n            The iteration will stop when ``max{|proj g_i | i = 1, ..., n} <= pgtol``\n            where ``pg_i`` is the i-th component of the projected gradient.\n\n        Notes\n        -----\n        Please, refer to :func:`scipy.optimize.fmin_l_bfgs_b` for further information\n        about ``factr`` and ``pgtol``.\n        \"\"\"\n        self._verbose = verbose\n        self._maximize(verbose=verbose, factr=factr, pgtol=pgtol)\n        self._verbose = False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _bstar_set(beta, alpha, yTBy, yTBX, yTBM, XTBX, XTBM, MTBM):\n    from numpy_sugar import epsilon\n\n    r = yTBy\n    r -= 2 * add.reduce([i @ beta for i in yTBX])\n    r -= 2 * add.reduce([i @ alpha for i in yTBM])\n    r += add.reduce([beta.T @ i @ beta for i in XTBX])\n    r += 2 * add.reduce([beta.T @ i @ alpha for i in XTBM])\n    r += add.reduce([alpha.T @ i @ alpha for i in MTBM])\n    return clip(r, epsilon.tiny, inf)", "response": "Compute the bstar set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef null_lml(self):\n        n = self._nsamples\n        scale = self.null_scale\n        return (self._static_lml() - n * log(scale)) / 2", "response": "Returns the log of the null hypothesis."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the null beta matrix.", "response": "def null_beta(self):\n        \"\"\"\n        Optimal \ud835\udf37 according to the marginal likelihood.\n\n        It is compute by solving the equation ::\n\n            (X\u1d40BX)\ud835\udf37 = X\u1d40B\ud835\udc32.\n\n        Returns\n        -------\n        beta : ndarray\n            Optimal \ud835\udf37.\n        \"\"\"\n        ETBE = self._ETBE\n        yTBX = self._yTBX\n\n        A = sum(i.XTBX for i in ETBE)\n        b = sum(yTBX)\n        return rsolve(A, b)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef null_beta_covariance(self):\n        A = sum(i @ j.T for (i, j) in zip(self._XTQDi, self._XTQ))\n        return self.null_scale * pinv(A)", "response": "Covariance of the optimal \ud835\udf37 according to the marginal likelihood."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the null scale of the log likelihood.", "response": "def null_scale(self):\n        \"\"\"\n        Optimal s according to the marginal likelihood.\n\n        The optimal s is given by ::\n\n            s = n\u207b\u00b9\ud835\udc32\u1d40B(\ud835\udc32 - X\ud835\udf37),\n\n        where \ud835\udf37 is optimal.\n\n        Returns\n        -------\n        scale : float\n            Optimal scale.\n        \"\"\"\n        n = self._nsamples\n        beta = self.null_beta\n        sqrdot = self._yTBy - dot(sum(self._yTBX), beta)\n        return sqrdot / n"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fast_scan(self, M, verbose=True):\n        from tqdm import tqdm\n\n        if M.ndim != 2:\n            raise ValueError(\"`M` array must be bidimensional.\")\n        p = M.shape[1]\n\n        lmls = empty(p)\n        effsizes0 = empty((p, self._XTQ[0].shape[0]))\n        effsizes0_se = empty((p, self._XTQ[0].shape[0]))\n        effsizes1 = empty(p)\n        effsizes1_se = empty(p)\n        scales = empty(p)\n\n        if verbose:\n            nchunks = min(p, 30)\n        else:\n            nchunks = min(p, 1)\n\n        chunk_size = (p + nchunks - 1) // nchunks\n\n        for i in tqdm(range(nchunks), desc=\"Scanning\", disable=not verbose):\n            start = i * chunk_size\n            stop = min(start + chunk_size, M.shape[1])\n\n            r = self._fast_scan_chunk(M[:, start:stop])\n\n            lmls[start:stop] = r[\"lml\"]\n            effsizes0[start:stop, :] = r[\"effsizes0\"]\n            effsizes0_se[start:stop, :] = r[\"effsizes0_se\"]\n            effsizes1[start:stop] = r[\"effsizes1\"]\n            effsizes1_se[start:stop] = r[\"effsizes1_se\"]\n            scales[start:stop] = r[\"scale\"]\n\n        return {\n            \"lml\": lmls,\n            \"effsizes0\": effsizes0,\n            \"effsizes0_se\": effsizes0_se,\n            \"effsizes1\": effsizes1,\n            \"effsizes1_se\": effsizes1_se,\n            \"scale\": scales,\n        }", "response": "Fast scan for single - marker marginal likelihoods."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef scan(self, M):\n        from numpy_sugar.linalg import ddot\n        from numpy_sugar import is_all_finite\n\n        M = asarray(M, float)\n\n        if M.shape[1] == 0:\n            return {\n                \"lml\": self.null_lml(),\n                \"effsizes0\": self.null_beta,\n                \"effsizes0_se\": self.null_beta_se,\n                \"effsizes1\": empty((0)),\n                \"effsizes1_se\": empty((0)),\n                \"scale\": self.null_scale,\n            }\n\n        if not is_all_finite(M):\n            raise ValueError(\"M parameter has non-finite elements.\")\n\n        MTQ = [dot(M.T, Q) for Q in self._QS[0] if Q.size > 0]\n        yTBM = [dot(i, j.T) for (i, j) in zip(self._yTQDi, MTQ)]\n        XTBM = [dot(i, j.T) for (i, j) in zip(self._XTQDi, MTQ)]\n        D = self._D\n        MTBM = [ddot(i, 1 / j) @ i.T for i, j in zip(MTQ, D) if j.min() > 0]\n\n        return self._multicovariate_set(yTBM, XTBM, MTBM)", "response": "Scans the multicovariate set for a set of fixed - effect sizes and scale of the candidate set."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the log of the null hypothesis.", "response": "def null_lml(self):\n        \"\"\"\n        Log of the marginal likelihood for the null hypothesis.\n\n        It is implemented as ::\n\n            2\u00b7log(p(Y)) = -n\u00b7p\u00b7log(2\ud835\udf0bs) - log\uff5cK\uff5c - n\u00b7p,\n\n        for which s and \ud835\udea9 are optimal.\n\n        Returns\n        -------\n        lml : float\n            Log of the marginal likelihood.\n        \"\"\"\n        np = self._nsamples * self._ntraits\n        scale = self.null_scale\n        return self._static_lml() / 2 - np * safe_log(scale) / 2 - np / 2"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef null_scale(self):\n        np = self._nsamples * self._ntraits\n        b = vec(self.null_beta)\n        mKiy = b.T @ self._MKiy\n        sqrtdot = self._yKiy - mKiy\n        scale = sqrtdot / np\n        return scale", "response": "Returns the null scale of the logarithmic logarithm."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scan(self, A1, X1):\n        from numpy import empty\n        from numpy.linalg import multi_dot\n        from numpy_sugar import epsilon, is_all_finite\n        from scipy.linalg import cho_solve\n\n        A1 = asarray(A1, float)\n        X1 = asarray(X1, float)\n\n        if not is_all_finite(A1):\n            raise ValueError(\"A1 parameter has non-finite elements.\")\n\n        if not is_all_finite(X1):\n            raise ValueError(\"X1 parameter has non-finite elements.\")\n\n        if A1.shape[1] == 0:\n            beta_se = sqrt(self.null_beta_covariance.diagonal())\n            return {\n                \"lml\": self.null_lml(),\n                \"effsizes0\": unvec(self.null_beta, (self._ncovariates, -1)),\n                \"effsizes0_se\": unvec(beta_se, (self._ncovariates, -1)),\n                \"effsizes1\": empty((0,)),\n                \"effsizes1_se\": empty((0,)),\n                \"scale\": self.null_scale,\n            }\n\n        X1X1 = X1.T @ X1\n        XX1 = self._X.T @ X1\n        AWA1 = self._WA.T @ A1\n        A1W = A1.T @ self._W\n        GX1 = self._G.T @ X1\n\n        MRiM1 = kron(AWA1, XX1)\n        M1RiM1 = kron(A1W @ A1, X1X1)\n\n        M1Riy = vec(multi_dot([X1.T, self._Y, A1W.T]))\n        XRiM1 = kron(self._WL0.T @ A1, GX1)\n        ZiXRiM1 = cho_solve(self._Lz, XRiM1)\n\n        MRiXZiXRiM1 = self._XRiM.T @ ZiXRiM1\n        M1RiXZiXRiM1 = XRiM1.T @ ZiXRiM1\n        M1RiXZiXRiy = XRiM1.T @ self._ZiXRiy\n\n        T0 = [[self._MRiM, MRiM1], [MRiM1.T, M1RiM1]]\n        T1 = [[self._MRiXZiXRiM, MRiXZiXRiM1], [MRiXZiXRiM1.T, M1RiXZiXRiM1]]\n        T2 = [self._MRiy, M1Riy]\n        T3 = [self._MRiXZiXRiy, M1RiXZiXRiy]\n\n        MKiM = block(T0) - block(T1)\n        MKiy = block(T2) - block(T3)\n        beta = rsolve(MKiM, MKiy)\n\n        mKiy = beta.T @ MKiy\n        cp = self._ntraits * self._ncovariates\n        effsizes0 = unvec(beta[:cp], (self._ncovariates, self._ntraits))\n        effsizes1 = unvec(beta[cp:], (X1.shape[1], A1.shape[1]))\n\n        np = self._nsamples * self._ntraits\n        sqrtdot = self._yKiy - mKiy\n        scale = clip(sqrtdot / np, epsilon.tiny, inf)\n        lml = self._static_lml() / 2 - np * safe_log(scale) / 2 - np / 2\n\n        effsizes_se = sqrt(clip(scale * pinv(MKiM).diagonal(), epsilon.tiny, inf))\n        effsizes0_se = unvec(effsizes_se[:cp], (self._ncovariates, self._ntraits))\n        effsizes1_se = unvec(effsizes_se[cp:], (X1.shape[1], A1.shape[1]))\n\n        return {\n            \"lml\": lml,\n            \"effsizes0\": effsizes0,\n            \"effsizes1\": effsizes1,\n            \"scale\": scale,\n            \"effsizes0_se\": effsizes0_se,\n            \"effsizes1_se\": effsizes1_se,\n        }", "response": "This function scans the array A1 and X1 for the covariates and returns a dictionary of the values for the covariates."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_fast_scanner(self):\n        terms = self._terms\n        return KronFastScanner(self._Y, self._mean.A, self._mean.X, self._cov.Ge, terms)", "response": "Returns a new instance of the class designed to perform very fast association scan."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlog of the marginal likelihood.", "response": "def lml(self):\n        \"\"\"\n        Log of the marginal likelihood.\n\n        Let \ud835\udc32 = vec(Y), M = A\u2297X, and H = M\u1d40K\u207b\u00b9M. The restricted log of the marginal\n        likelihood is given by [R07]_::\n\n            2\u22c5log(p(\ud835\udc32)) = -(n\u22c5p - c\u22c5p) log(2\u03c0) + log(\uff5cM\u1d40M\uff5c) - log(\uff5cK\uff5c) - log(\uff5cH\uff5c)\n                - (\ud835\udc32-\ud835\udc26)\u1d40 K\u207b\u00b9 (\ud835\udc32-\ud835\udc26),\n\n        where \ud835\udc26 = M\ud835\udec3 for \ud835\udec3 = H\u207b\u00b9M\u1d40K\u207b\u00b9\ud835\udc32.\n\n        For implementation purpose, let X = (L\u2080 \u2297 G) and R = (L\u2081 \u2297 I)(L\u2081 \u2297 I)\u1d40.\n        The covariance can be written as::\n\n            K = XX\u1d40 + R.\n\n        From the Woodbury matrix identity, we have\n\n            \ud835\udc32\u1d40K\u207b\u00b9\ud835\udc32 = \ud835\udc32\u1d40R\u207b\u00b9\ud835\udc32 - \ud835\udc32\u1d40R\u207b\u00b9XZ\u207b\u00b9X\u1d40R\u207b\u00b9\ud835\udc32,\n\n        where Z = I + X\u1d40R\u207b\u00b9X. Note that R\u207b\u00b9 = (U\u2081S\u2081\u207b\u00b9U\u2081\u1d40) \u2297 I and ::\n\n            X\u1d40R\u207b\u00b9\ud835\udc32 = (L\u2080\u1d40W \u2297 G\u1d40)\ud835\udc32 = vec(G\u1d40YWL\u2080),\n\n        where W = U\u2081S\u2081\u207b\u00b9U\u2081\u1d40. The term G\u1d40Y can be calculated only once and it will form a\n        r\u00d7p matrix. We similarly have ::\n\n            X\u1d40R\u207b\u00b9M = (L\u2080\u1d40WA) \u2297 (G\u1d40X),\n\n        for which G\u1d40X is pre-computed.\n\n        The log-determinant of the covariance matrix is given by\n\n            log(\uff5cK\uff5c) = log(\uff5cZ\uff5c) - log(\uff5cR\u207b\u00b9\uff5c) = log(\uff5cZ\uff5c) - 2\u00b7n\u00b7log(\uff5cU\u2081S\u2081\u207b\u00bd\uff5c).\n\n        The log of the marginal likelihood can be rewritten as::\n\n            2\u22c5log(p(\ud835\udc32)) = -(n\u22c5p - c\u22c5p) log(2\u03c0) + log(\uff5cM\u1d40M\uff5c)\n            - log(\uff5cZ\uff5c) + 2\u00b7n\u00b7log(\uff5cU\u2081S\u2081\u207b\u00bd\uff5c)\n            - log(\uff5cM\u1d40R\u207b\u00b9M - M\u1d40R\u207b\u00b9XZ\u207b\u00b9X\u1d40R\u207b\u00b9M\uff5c)\n            - \ud835\udc32\u1d40R\u207b\u00b9\ud835\udc32 + (\ud835\udc32\u1d40R\u207b\u00b9X)Z\u207b\u00b9(X\u1d40R\u207b\u00b9\ud835\udc32)\n            - \ud835\udc26\u1d40R\u207b\u00b9\ud835\udc26 + (\ud835\udc26\u1d40R\u207b\u00b9X)Z\u207b\u00b9(X\u1d40R\u207b\u00b9\ud835\udc26)\n            + 2\ud835\udc32\u1d40R\u207b\u00b9\ud835\udc26 - 2(\ud835\udc32\u1d40R\u207b\u00b9X)Z\u207b\u00b9(X\u1d40R\u207b\u00b9\ud835\udc26).\n\n        Returns\n        -------\n        lml : float\n            Log of the marginal likelihood.\n\n        References\n        ----------\n        .. [R07] LaMotte, L. R. (2007). A direct derivation of the REML likelihood\n           function. Statistical Papers, 48(2), 321-327.\n        \"\"\"\n        terms = self._terms\n        yKiy = terms[\"yKiy\"]\n        mKiy = terms[\"mKiy\"]\n        mKim = terms[\"mKim\"]\n\n        lml = -self._df * log2pi + self._logdet_MM - self._logdetK\n        lml -= self._logdetH\n        lml += -yKiy - mKim + 2 * mKiy\n\n        return lml / 2"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gradient(self):\n        self._update_approx()\n\n        g = self._ep.lml_derivatives(self._X)\n        ed = exp(-self.logitdelta)\n        es = exp(self.logscale)\n\n        grad = dict()\n        grad[\"logitdelta\"] = g[\"delta\"] * (ed / (1 + ed)) / (1 + ed)\n        grad[\"logscale\"] = g[\"scale\"] * es\n        grad[\"beta\"] = g[\"mean\"]\n\n        return grad", "response": "Gradient of the log of the marginal likelihood."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gradient(self):\n        L = self.L\n        n = self.L.shape[0]\n        grad = {\"Lu\": zeros((n, n, n * self._L.shape[1]))}\n        for ii in range(self._L.shape[0] * self._L.shape[1]):\n            row = ii // self._L.shape[1]\n            col = ii % self._L.shape[1]\n            grad[\"Lu\"][row, :, ii] = L[:, col]\n            grad[\"Lu\"][:, row, ii] += L[:, col]\n\n        return grad", "response": "Gradient of the log likelihood matrix."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef beta(self):\n        from numpy_sugar.linalg import rsolve\n\n        return rsolve(self._X[\"VT\"], rsolve(self._X[\"tX\"], self.mean()))", "response": "Calculates the beta of the current state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nestimating the covariance matrix of the optimal beta.", "response": "def beta_covariance(self):\n        \"\"\"\n        Estimates the covariance-matrix of the optimal beta.\n\n        Returns\n        -------\n        beta-covariance : ndarray\n            (X\u1d40(s((1-\ud835\udeff)K + \ud835\udeffI))\u207b\u00b9X)\u207b\u00b9.\n\n        References\n        ----------\n        .. Rencher, A. C., & Schaalje, G. B. (2008). Linear models in statistics. John\n           Wiley & Sons.\n        \"\"\"\n        from numpy_sugar.linalg import ddot\n\n        tX = self._X[\"tX\"]\n        Q = concatenate(self._QS[0], axis=1)\n        S0 = self._QS[1]\n        D = self.v0 * S0 + self.v1\n        D = D.tolist() + [self.v1] * (len(self._y) - len(D))\n        D = asarray(D)\n        A = inv(tX.T @ (Q @ ddot(1 / D, Q.T @ tX)))\n        VT = self._X[\"VT\"]\n        H = lstsq(VT, A, rcond=None)[0]\n        return lstsq(VT, H.T, rcond=None)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndisabling parameter optimization. Parameters ---------- param : str Possible values are ``\"delta\"``, ``\"beta\"``, and ``\"scale\"``.", "response": "def fix(self, param):\n        \"\"\"\n        Disable parameter optimization.\n\n        Parameters\n        ----------\n        param : str\n            Possible values are ``\"delta\"``, ``\"beta\"``, and ``\"scale\"``.\n        \"\"\"\n        if param == \"delta\":\n            super()._fix(\"logistic\")\n        else:\n            self._fix[param] = True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nenable parameter optimization. Parameters ---------- param : str Possible values are ``\"delta\"``, ``\"beta\"``, and ``\"scale\"``.", "response": "def unfix(self, param):\n        \"\"\"\n        Enable parameter optimization.\n\n        Parameters\n        ----------\n        param : str\n            Possible values are ``\"delta\"``, ``\"beta\"``, and ``\"scale\"``.\n        \"\"\"\n        if param == \"delta\":\n            self._unfix(\"logistic\")\n        else:\n            self._fix[param] = False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fit(self, verbose=True):\n        if not self._isfixed(\"logistic\"):\n            self._maximize_scalar(desc=\"LMM\", rtol=1e-6, atol=1e-6, verbose=verbose)\n\n        if not self._fix[\"beta\"]:\n            self._update_beta()\n\n        if not self._fix[\"scale\"]:\n            self._update_scale()", "response": "Fit the marginal likelihood to the logistic distribution."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_fast_scanner(self):\n        v0 = self.v0\n        v1 = self.v1\n        QS = (self._QS[0], v0 * self._QS[1])\n        return FastScanner(self._y, self.X, QS, v1)", "response": "Returns a new instance of the class designed to perform very fast association scan."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the value of the object.", "response": "def value(self):\n        \"\"\"\n        Internal use only.\n        \"\"\"\n        if not self._fix[\"beta\"]:\n            self._update_beta()\n\n        if not self._fix[\"scale\"]:\n            self._update_scale()\n\n        return self.lml()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the log of the marginal likelihood.", "response": "def lml(self):\n        \"\"\"\n        Log of the marginal likelihood.\n\n        Returns\n        -------\n        lml : float\n            Log of the marginal likelihood.\n\n        Notes\n        -----\n        The log of the marginal likelihood is given by ::\n\n            2\u22c5log(p(\ud835\udc32)) = -n\u22c5log(2\u03c0) - n\u22c5log(s) - log|D| - (Q\u1d40\ud835\udc32)\u1d40s\u207b\u00b9D\u207b\u00b9(Q\u1d40\ud835\udc32)\n                        + (Q\u1d40\ud835\udc32)\u1d40s\u207b\u00b9D\u207b\u00b9(Q\u1d40X\ud835\udf37)/2 - (Q\u1d40X\ud835\udf37)\u1d40s\u207b\u00b9D\u207b\u00b9(Q\u1d40X\ud835\udf37).\n\n        By using the optimal \ud835\udf37, the log of the marginal likelihood can be rewritten\n        as::\n\n            2\u22c5log(p(\ud835\udc32)) = -n\u22c5log(2\u03c0) - n\u22c5log(s) - log|D| + (Q\u1d40\ud835\udc32)\u1d40s\u207b\u00b9D\u207b\u00b9Q\u1d40(X\ud835\udf37-\ud835\udc32).\n\n\n        In the extreme case where \ud835\udf37 is such that \ud835\udc32 = X\ud835\udf37, the maximum is attained as\n        s\u21920.\n\n        For optimals \ud835\udf37 and s, the log of the marginal likelihood can be further\n        simplified to ::\n\n            2\u22c5log(p(\ud835\udc32; \ud835\udf37, s)) = -n\u22c5log(2\u03c0) - n\u22c5log s - log|D| - n.\n        \"\"\"\n        reml = (self._logdetXX() - self._logdetH()) / 2\n        if self._optimal[\"scale\"]:\n            lml = self._lml_optimal_scale()\n        else:\n            lml = self._lml_arbitrary_scale()\n        return lml + reml"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the delta of the logistic value between K and I.", "response": "def delta(self):\n        \"\"\"\n        Variance ratio between ``K`` and ``I``.\n        \"\"\"\n\n        v = float(self._logistic.value)\n\n        if v > 0.0:\n            v = 1 / (1 + exp(-v))\n        else:\n            v = exp(v)\n            v = v / (v + 1.0)\n\n        return min(max(v, epsilon.tiny), 1 - epsilon.tiny)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the log determinant of X\u1d40X.", "response": "def _logdetXX(self):\n        \"\"\"\n        log(\uff5cX\u1d40X\uff5c).\n        \"\"\"\n        if not self._restricted:\n            return 0.0\n\n        ldet = slogdet(self._X[\"tX\"].T @ self._X[\"tX\"])\n        if ldet[0] != 1.0:\n            raise ValueError(\"The determinant of X\u1d40X should be positive.\")\n        return ldet[1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _logdetH(self):\n        if not self._restricted:\n            return 0.0\n        ldet = slogdet(sum(self._XTQDiQTX) / self.scale)\n        if ldet[0] != 1.0:\n            raise ValueError(\"The determinant of H should be positive.\")\n        return ldet[1]", "response": "Return the log - determinant of the current user s income."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _lml_optimal_scale(self):\n        assert self._optimal[\"scale\"]\n\n        n = len(self._y)\n        lml = -self._df * log2pi - self._df - n * log(self.scale)\n        lml -= sum(npsum(log(D)) for D in self._D)\n        return lml / 2", "response": "Implementation for unrestricted LML :: _optimal_scale Returns ------- float DMatrix of the marginal likelihood for optimal scale."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _lml_arbitrary_scale(self):\n        s = self.scale\n        D = self._D\n        n = len(self._y)\n        lml = -self._df * log2pi - n * log(s)\n        lml -= sum(npsum(log(d)) for d in D)\n        d = (mTQ - yTQ for (mTQ, yTQ) in zip(self._mTQ, self._yTQ))\n        lml -= sum((i / j) @ i for (i, j) in zip(d, D)) / s\n\n        return lml / 2", "response": "Calculates the log of the marginal likelihood for arbitrary scale."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _df(self):\n        if not self._restricted:\n            return self.nsamples\n        return self.nsamples - self._X[\"tX\"].shape[1]", "response": "Returns the number of samples in the freezing table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_fast_scanner(self):\n        from numpy_sugar.linalg import ddot, economic_qs, sum2diag\n\n        y = self.eta / self.tau\n\n        if self._QS is None:\n            K = eye(y.shape[0]) / self.tau\n        else:\n            Q0 = self._QS[0][0]\n            S0 = self._QS[1]\n            K = dot(ddot(Q0, self.v0 * S0), Q0.T)\n            K = sum2diag(K, 1 / self.tau)\n\n        return FastScanner(y, self._X, economic_qs(K), self.v1)", "response": "rReturn a FastScanner for the current\n        delta."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the value of the log of the marginal likelihood.", "response": "def value(self):\n        r\"\"\"Log of the marginal likelihood.\n\n        Formally,\n\n        .. math::\n\n            - \\frac{n}{2}\\log{2\\pi} - \\frac{1}{2} \\log{\\left|\n                v_0 \\mathrm K + v_1 \\mathrm I + \\tilde{\\Sigma} \\right|}\n                    - \\frac{1}{2}\n                    \\left(\\tilde{\\boldsymbol\\mu} -\n                    \\mathrm X\\boldsymbol\\beta\\right)^{\\intercal}\n                    \\left( v_0 \\mathrm K + v_1 \\mathrm I +\n                    \\tilde{\\Sigma} \\right)^{-1}\n                    \\left(\\tilde{\\boldsymbol\\mu} -\n                    \\mathrm X\\boldsymbol\\beta\\right)\n\n        Returns\n        -------\n        float\n            :math:`\\log{p(\\tilde{\\boldsymbol\\mu})}`\n        \"\"\"\n        from numpy_sugar.linalg import ddot, sum2diag\n\n        if self._cache[\"value\"] is not None:\n            return self._cache[\"value\"]\n\n        scale = exp(self.logscale)\n        delta = 1 / (1 + exp(-self.logitdelta))\n\n        v0 = scale * (1 - delta)\n        v1 = scale * delta\n\n        mu = self.eta / self.tau\n        n = len(mu)\n        if self._QS is None:\n            K = zeros((n, n))\n        else:\n            Q0 = self._QS[0][0]\n            S0 = self._QS[1]\n            K = dot(ddot(Q0, S0), Q0.T)\n\n        A = sum2diag(sum2diag(v0 * K, v1), 1 / self.tau)\n        m = mu - self.mean()\n\n        v = -n * log(2 * pi)\n        v -= slogdet(A)[1]\n        v -= dot(m, solve(A, m))\n\n        self._cache[\"value\"] = v / 2\n\n        return self._cache[\"value\"]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _initialize(self):\n        if self._mean is None or self._cov is None:\n            return\n\n        Q = self._cov[\"QS\"][0][0]\n        S = self._cov[\"QS\"][1]\n\n        if S.size > 0:\n            self.tau[:] = 1 / npsum((Q * sqrt(S)) ** 2, axis=1)\n        else:\n            self.tau[:] = 0.0\n        self.eta[:] = self._mean\n        self.eta[:] *= self.tau", "response": "r Initializes the mean and covariance of the posterior."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_engine_session(connection, echo=False, autoflush=None, autocommit=None, expire_on_commit=None,\n                         scopefunc=None):\n    \"\"\"Build an engine and a session.\n\n    :param str connection: An RFC-1738 database connection string\n    :param bool echo: Turn on echoing SQL\n    :param Optional[bool] autoflush: Defaults to True if not specified in kwargs or configuration.\n    :param Optional[bool] autocommit: Defaults to False if not specified in kwargs or configuration.\n    :param Optional[bool] expire_on_commit: Defaults to False if not specified in kwargs or configuration.\n    :param scopefunc: Scoped function to pass to :func:`sqlalchemy.orm.scoped_session`\n    :rtype: tuple[Engine,Session]\n\n    From the Flask-SQLAlchemy documentation:\n\n    An extra key ``'scopefunc'`` can be set on the ``options`` dict to\n    specify a custom scope function.  If it's not provided, Flask's app\n    context stack identity is used. This will ensure that sessions are\n    created and removed with the request/response cycle, and should be fine\n    in most cases.\n    \"\"\"\n    if connection is None:\n        raise ValueError('can not build engine when connection is None')\n\n    engine = create_engine(connection, echo=echo)\n\n    autoflush = autoflush if autoflush is not None else False\n    autocommit = autocommit if autocommit is not None else False\n    expire_on_commit = expire_on_commit if expire_on_commit is not None else True\n\n    log.debug('auto flush: %s, auto commit: %s, expire on commmit: %s', autoflush, autocommit, expire_on_commit)\n\n    #: A SQLAlchemy session maker\n    session_maker = sessionmaker(\n        bind=engine,\n        autoflush=autoflush,\n        autocommit=autocommit,\n        expire_on_commit=expire_on_commit,\n    )\n\n    #: A SQLAlchemy session object\n    session = scoped_session(\n        session_maker,\n        scopefunc=scopefunc\n    )\n\n    return engine, session", "response": "Build an engine and a SQLAlchemy session."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a default connection string.", "response": "def _get_connection(cls, connection: Optional[str] = None) -> str:\n        \"\"\"Get a default connection string.\n\n        Wraps :func:`bio2bel.utils.get_connection` and passing this class's :data:`module_name` to it.\n        \"\"\"\n        return get_connection(cls.module_name, connection=connection)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates an instance of the SMTP class based on the settings passed in.", "response": "def setup_smtp_factory(**settings):\n    \"\"\" expects a dictionary with 'mail.' keys to create an appropriate smtplib.SMTP instance\"\"\"\n    return CustomSMTP(\n        host=settings.get('mail.host', 'localhost'),\n        port=int(settings.get('mail.port', 25)),\n        user=settings.get('mail.user'),\n        password=settings.get('mail.password'),\n        timeout=float(settings.get('mail.timeout', 60)),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sendMultiPart(smtp, gpg_context, sender, recipients, subject, text, attachments):\n    sent = 0\n    for to in recipients:\n        if not to.startswith('<'):\n            uid = '<%s>' % to\n        else:\n            uid = to\n\n        if not checkRecipient(gpg_context, uid):\n            continue\n\n        msg = MIMEMultipart()\n\n        msg['From'] = sender\n        msg['To'] = to\n        msg['Subject'] = subject\n        msg[\"Date\"] = formatdate(localtime=True)\n        msg.preamble = u'This is an email in encrypted multipart format.'\n\n        attach = MIMEText(str(gpg_context.encrypt(text.encode('utf-8'), uid, always_trust=True)))\n        attach.set_charset('UTF-8')\n        msg.attach(attach)\n\n        for attachment in attachments:\n            with open(attachment, 'rb') as fp:\n                attach = MIMEBase('application', 'octet-stream')\n                attach.set_payload(str(gpg_context.encrypt_file(fp, uid, always_trust=True)))\n            attach.add_header('Content-Disposition', 'attachment', filename=basename('%s.pgp' % attachment))\n            msg.attach(attach)\n\n        # TODO: need to catch exception?\n        # yes :-) we need to adjust the status accordingly (>500 so it will be destroyed)\n        smtp.begin()\n        smtp.sendmail(sender, to, msg.as_string())\n        smtp.quit()\n        sent += 1\n\n    return sent", "response": "a helper method that composes and sends an email with attachments"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconnects and optionally authenticates a connection.", "response": "def begin(self):\n        \"\"\" connects and optionally authenticates a connection.\"\"\"\n        self.connect(self.host, self.port)\n        if self.user:\n            self.starttls()\n            self.login(self.user, self.password)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a function that downloads the data for you or uses a cached version at the given path.", "response": "def make_downloader(url: str, path: str) -> Callable[[bool], str]:  # noqa: D202\n    \"\"\"Make a function that downloads the data for you, or uses a cached version at the given path.\n\n    :param url: The URL of some data\n    :param path: The path of the cached data, or where data is cached if it does not already exist\n    :return: A function that downloads the data and returns the path of the data\n    \"\"\"\n\n    def download_data(force_download: bool = False) -> str:\n        \"\"\"Download the data.\n\n        :param force_download: If true, overwrites a previously cached file\n        \"\"\"\n        if os.path.exists(path) and not force_download:\n            log.info('using cached data at %s', path)\n        else:\n            log.info('downloading %s to %s', url, path)\n            urlretrieve(url, path)\n\n        return path\n\n    return download_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_df_getter(data_url: str, data_path: str, **kwargs) -> Callable[[Optional[str], bool, bool], pd.DataFrame]:\n    download_function = make_downloader(data_url, data_path)\n\n    def get_df(url: Optional[str] = None, cache: bool = True, force_download: bool = False) -> pd.DataFrame:\n        \"\"\"Get the data as a pandas DataFrame.\n\n        :param url: The URL (or file path) to download.\n        :param cache: If true, the data is downloaded to the file system, else it is loaded from the internet\n        :param force_download: If true, overwrites a previously cached file\n        \"\"\"\n        if url is None and cache:\n            url = download_function(force_download=force_download)\n\n        return pd.read_csv(\n            url or data_url,\n            **kwargs\n        )\n\n    return get_df", "response": "Build a function that returns a pandas DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate(self, **kwargs):\n        '''\n        Generate a :term:`URI` based on parameters passed.\n\n        :param id: The id of the concept or collection.\n        :param type: What we're generating a :term:`URI` for: `concept`\n            or `collection`.\n        :rtype: string\n        '''\n        if kwargs['type'] not in ['concept', 'collection']:\n            raise ValueError('Type %s is invalid' % kwargs['type'])\n        return (\n            self.pattern % (self.vocabulary_id, kwargs['type'], kwargs['id'])\n        ).lower()", "response": "Generate a : term : URI based on the passed parameters."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef has_address(start: int, data_length: int) -> bool:\n    return bool(0x01 & start) or (start == 0x82 and data_length == 16)", "response": "Determines if the packet has an address encoded into it."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decode_timestamp(data: str) -> datetime.datetime:\n    year = 2000 + int(data[0:2])\n    month = int(data[2:4])\n    day = int(data[4:6])\n    hour = int(data[6:8])\n    minute = int(data[8:10])\n    second = int(data[10:12])\n    if minute == 60:\n        minute = 0\n        hour += 1\n\n    return datetime.datetime(year=year, month=month, day=day, hour=hour,\n                             minute=minute, second=second)", "response": "Decode timestamp using bespoke decoder."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_application(connection: Optional[str] = None) -> Flask:\n    app = Flask(__name__)\n\n    flask_bootstrap.Bootstrap(app)\n    Admin(app)\n\n    connection = connection or DEFAULT_CACHE_CONNECTION\n    engine, session = build_engine_session(connection)\n\n    for name, add_admin in add_admins.items():\n        url = '/{}'.format(name)\n        add_admin(app, session, url=url, endpoint=name, name=name)\n        log.debug('added %s - %s to %s', name, add_admin, url)\n\n    app.register_blueprint(ui)\n\n    return app", "response": "Create a Flask application."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a provider with the specified id or uri.", "response": "def register_provider(self, provider):\n        '''\n        Register a :class:`skosprovider.providers.VocabularyProvider`.\n\n        :param skosprovider.providers.VocabularyProvider provider: The provider\n            to register.\n        :raises RegistryException: A provider with this id or uri has already \n            been registered.\n        '''\n        if provider.get_vocabulary_id() in self.providers:\n            raise RegistryException(\n                'A provider with this id has already been registered.'\n            )\n        self.providers[provider.get_vocabulary_id()] = provider\n        if provider.concept_scheme.uri in self.concept_scheme_uri_map:\n            raise RegistryException(\n                'A provider with URI %s has already been registered.' % provider.concept_scheme.uri\n            )\n        self.concept_scheme_uri_map[provider.concept_scheme.uri] = provider.get_vocabulary_id()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_provider(self, id):\n        '''\n        Remove the provider with the given id or :term:`URI`.\n\n        :param str id: The identifier for the provider.\n        :returns: A :class:`skosprovider.providers.VocabularyProvider` or\n            `False` if the id is unknown.\n        '''\n        if id in self.providers:\n            p = self.providers.get(id, False)\n            del self.providers[id]\n            del self.concept_scheme_uri_map[p.concept_scheme.uri]\n            return p\n        elif id in self.concept_scheme_uri_map:\n            id = self.concept_scheme_uri_map[id]\n            return self.remove_provider(id)\n        else:\n            return False", "response": "Removes the provider with the given id or URI."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a provider by id or uri.", "response": "def get_provider(self, id):\n        '''\n        Get a provider by id or :term:`uri`.\n\n        :param str id: The identifier for the provider. This can either be the\n            id with which it was registered or the :term:`uri` of the conceptscheme\n            that the provider services.\n        :returns: A :class:`skosprovider.providers.VocabularyProvider`\n            or `False` if the id or uri is unknown.\n        '''\n        if id in self.providers:\n            return self.providers.get(id, False)\n        elif is_uri(id) and id in self.concept_scheme_uri_map:\n            return self.providers.get(self.concept_scheme_uri_map[id], False)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_providers(self, **kwargs):\n        '''Get all providers registered.\n\n        If keyword `ids` is present, get only the providers with these ids.\n\n        If keys `subject` is present, get only the providers that have this subject.\n\n        .. code-block:: python\n\n           # Get all providers with subject 'biology'\n           registry.get_providers(subject='biology')\n\n           # Get all providers with id 1 or 2\n           registry.get_providers(ids=[1,2])\n\n           # Get all providers with id 1 or 2 and subject 'biology'\n           registry.get_providers(ids=[1,2], subject='biology']\n\n        :param list ids: Only return providers with one of the Ids or :term:`URIs <uri>`.\n        :param str subject: Only return providers with this subject.\n        :returns: A list of :class:`providers <skosprovider.providers.VocabularyProvider>`\n        '''\n        if 'ids' in kwargs:\n            ids = [self.concept_scheme_uri_map.get(id, id) for id in kwargs['ids']]\n            providers = [\n                self.providers[k] for k in self.providers.keys() if k in ids\n            ]\n        else:\n            providers = list(self.providers.values())\n        if 'subject' in kwargs:\n            providers = [p for p in providers if kwargs['subject'] in p.metadata['subject']]\n        return providers", "response": "Get all providers registered."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find(self, query, **kwargs):\n        '''Launch a query across all or a selection of providers.\n\n        .. code-block:: python\n\n            # Find anything that has a label of church in any provider.\n            registry.find({'label': 'church'})\n\n            # Find anything that has a label of church with the BUILDINGS provider.\n            # Attention, this syntax was deprecated in version 0.3.0\n            registry.find({'label': 'church'}, providers=['BUILDINGS'])\n\n            # Find anything that has a label of church with the BUILDINGS provider.\n            registry.find({'label': 'church'}, providers={'ids': ['BUILDINGS']})\n\n            # Find anything that has a label of church with a provider\n            # marked with the subject 'architecture'.\n            registry.find({'label': 'church'}, providers={'subject': 'architecture'})\n\n            # Find anything that has a label of church in any provider.\n            # If possible, display the results with a Dutch label.\n            registry.find({'label': 'church'}, language='nl')\n\n        :param dict query: The query parameters that will be passed on to each\n            :meth:`~skosprovider.providers.VocabularyProvider.find` method of\n            the selected.\n            :class:`providers <skosprovider.providers.VocabularyProvider>`.\n        :param dict providers: Optional. If present, it should be a dictionary.\n            This dictionary can contain any of the keyword arguments available\n            to the :meth:`get_providers` method. The query will then only\n            be passed to the providers confirming to these arguments.\n        :param string language: Optional. If present, it should be a\n            :term:`language-tag`. This language-tag is passed on to the\n            underlying providers and used when selecting the label to display\n            for each concept.\n        :returns: a list of :class:`dict`.\n            Each dict has two keys: id and concepts.\n        '''\n        if 'providers' not in kwargs:\n            providers = self.get_providers()\n        else:\n            pargs = kwargs['providers']\n            if isinstance(pargs, list):\n                providers = self.get_providers(ids=pargs)\n            else:\n                providers = self.get_providers(**pargs)\n        kwarguments = {}\n        if 'language' in kwargs:\n            kwarguments['language'] = kwargs['language']\n        return [{'id': p.get_vocabulary_id(), 'concepts': p.find(query, **kwarguments)}\n                for p in providers]", "response": "Launch a query across all or a selection of providers."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_all(self, **kwargs):\n        '''Get all concepts from all providers.\n\n        .. code-block:: python\n\n            # get all concepts in all providers.\n            registry.get_all()\n\n            # get all concepts in all providers.\n            # If possible, display the results with a Dutch label.\n            registry.get_all(language='nl')\n\n        :param string language: Optional. If present, it should be a\n            :term:`language-tag`. This language-tag is passed on to the\n            underlying providers and used when selecting the label to display\n            for each concept.\n\n        :returns: a list of :class:`dict`.\n            Each dict has two keys: id and concepts.\n        '''\n        kwarguments = {}\n        if 'language' in kwargs:\n            kwarguments['language'] = kwargs['language']\n        return [{'id': p.get_vocabulary_id(), 'concepts': p.get_all(**kwarguments)}\n                for p in self.providers.values()]", "response": "Get all concepts from all providers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a concept or collection by its uri. Returns a single concept or collection if one exists with this uri Returns False otherwise.", "response": "def get_by_uri(self, uri):\n        '''Get a concept or collection by its uri.\n\n        Returns a single concept or collection if one exists with this uri.\n        Returns False otherwise.\n\n        :param string uri: The uri to find a concept or collection for.\n        :raises ValueError: The uri is invalid.\n        :rtype: :class:`skosprovider.skos.Concept` or\n            :class:`skosprovider.skos.Collection`\n        '''\n        if not is_uri(uri):\n            raise ValueError('%s is not a valid URI.' % uri)\n        # Check if there's a provider that's more likely to have the URI\n        csuris = [csuri for csuri in self.concept_scheme_uri_map.keys() if uri.startswith(csuri)]\n        for csuri in csuris:\n            c = self.get_provider(csuri).get_by_uri(uri)\n            if c:\n                return c\n        # Check all providers\n        for p in self.providers.values():\n            c = p.get_by_uri(uri)\n            if c:\n                return c\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_module(self, fullname, path=None):\n        if not fullname.startswith(self._group_with_dot):\n            return\n        end_name = fullname[len(self._group_with_dot):]\n        for entry_point in iter_entry_points(group=self.group, name=None):\n            if entry_point.name == end_name:\n                return self", "response": "Find a module if its name starts with self. group and is registered."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload a module if its name starts with self. group and is registered.", "response": "def load_module(self, fullname):\n        \"\"\"Load a module if its name starts with :code:`self.group` and is registered.\"\"\"\n        if fullname in sys.modules:\n            return sys.modules[fullname]\n        end_name = fullname[len(self._group_with_dot):]\n        for entry_point in iter_entry_points(group=self.group, name=end_name):\n            mod = entry_point.load()\n            sys.modules[fullname] = mod\n            return mod"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef upload_theme():\n    get_vars()\n    with fab.settings():\n        local_theme_path = path.abspath(\n            path.join(fab.env['config_base'],\n                fab.env.instance.config['local_theme_path']))\n        rsync(\n            '-av',\n            '--delete',\n            '%s/' % local_theme_path,\n            '{{host_string}}:{themes_dir}/{ploy_theme_name}'.format(**AV)\n        )\n        briefkasten_ctl('restart')", "response": "Upload and or update the theme with the current git state"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef upload_pgp_keys():\n    get_vars()\n    upload_target = '/tmp/pgp_pubkeys.tmp'\n    with fab.settings(fab.hide('running')):\n        fab.run('rm -rf %s' % upload_target)\n        fab.run('mkdir %s' % upload_target)\n        local_key_path = path.join(fab.env['config_base'], fab.env.instance.config['local_pgpkey_path'])\n        remote_key_path = '/var/briefkasten/pgp_pubkeys/'.format(**AV)\n        rsync('-av', local_key_path, '{host_string}:%s' % upload_target)\n        fab.run('chown -R %s %s' % (AV['appuser'], remote_key_path))\n        fab.run('chmod 700 %s' % remote_key_path)\n        with fab.shell_env(GNUPGHOME=remote_key_path):\n            fab.sudo('''gpg --import %s/*.*''' % upload_target,\n                user=AV['appuser'], shell_escape=False)\n        fab.run('rm -rf %s' % upload_target)", "response": "Upload and update the PGP keys for editors"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild the backend and upload it to the remote server at the given index", "response": "def upload_backend(index='dev', user=None):\n    \"\"\"\n    Build the backend and upload it to the remote server at the given index\n    \"\"\"\n    get_vars()\n    use_devpi(index=index)\n    with fab.lcd('../application'):\n        fab.local('make upload')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the backend from the given index at the given version on the target host.", "response": "def update_backend(use_pypi=False, index='dev', build=True, user=None, version=None):\n    \"\"\"\n    Install the backend from the given devpi index at the given version on the target host and restart the service.\n\n    If version is None, it defaults to the latest version\n\n    Optionally, build and upload the application first from local sources. This requires a\n    full backend development environment on the machine running this command (pyramid etc.)\n    \"\"\"\n    get_vars()\n    if value_asbool(build):\n        upload_backend(index=index, user=user)\n    with fab.cd('{apphome}'.format(**AV)):\n        if value_asbool(use_pypi):\n            command = 'bin/pip install --upgrade briefkasten'\n        else:\n            command = 'bin/pip install --upgrade --pre -i {ploy_default_publish_devpi}/briefkasten/{index}/+simple/ briefkasten'.format(\n                index=index,\n                user=user,\n                **AV)\n        if version:\n            command = '%s==%s' % (command, version)\n        fab.sudo(command)\n\n    briefkasten_ctl('restart')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a sorted version of a list of concepts. Will leave the original list unsorted.", "response": "def _sort(self, concepts, sort=None, language='any', reverse=False):\n        '''\n        Returns a sorted version of a list of concepts. Will leave the original\n        list unsorted.\n\n        :param list concepts: A list of concepts and collections.\n        :param string sort: What to sort on: `id`, `label` or `sortlabel`\n        :param string language: Language to use when sorting on `label` or\n            `sortlabel`.\n        :param boolean reverse: Reverse the sort order?\n        :rtype: list\n        '''\n        sorted = copy.copy(concepts)\n        if sort:\n            sorted.sort(key=methodcaller('_sortkey', sort, language), reverse=reverse)\n        return sorted"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _include_in_find(self, c, query):\n        '''\n        :param c: A :class:`skosprovider.skos.Concept` or\n            :class:`skosprovider.skos.Collection`.\n        :param query: A dict that can be used to express a query.\n        :rtype: boolean\n        '''\n        include = True\n        if include and 'type' in query:\n            include = query['type'] == c.type\n        if include and 'label' in query:\n            def finder(l, query):\n                if not self.case_insensitive:\n                    return l.label.find(query['label'])\n                else:\n                    return l.label.upper().find(query['label'].upper())\n            include = any([finder(l, query) >= 0 for l in c.labels])\n        if include and 'collection' in query:\n            coll = self.get_by_id(query['collection']['id'])\n            if not coll or not isinstance(coll, Collection):\n                raise ValueError(\n                    'You are searching for items in an unexisting collection.'\n                )\n            if 'depth' in query['collection'] and query['collection']['depth'] == 'all':\n                members = self.expand(coll.id)\n            else:\n                members = coll.members\n            include = any([True for id in members if str(id) == str(c.id)]) \n        return include", "response": "Returns True if the item in the given collection is included in the find query."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_find_dict(self, c, **kwargs):\n        '''\n        Return a dict that can be used in the return list of the :meth:`find`\n        method.\n\n        :param c: A :class:`skosprovider.skos.Concept` or\n            :class:`skosprovider.skos.Collection`.\n        :rtype: dict\n        '''\n        language = self._get_language(**kwargs)\n        return {\n            'id': c.id,\n            'uri': c.uri,\n            'type': c.type,\n            'label': None if c.label() is None else c.label(language).label\n        }", "response": "Return a dict that can be used in the return list of the : meth : find method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def update(self) -> None:\n        _LOGGER.debug(\"Requesting state update from server (S00, S14)\")\n        await asyncio.gather(\n            # List unsealed Zones\n            self.send_command('S00'),\n            # Arming status update\n            self.send_command('S14'),\n        )", "response": "Update the state of the current system."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def _update_loop(self) -> None:\n        await asyncio.sleep(self._update_interval)\n        while not self._closed:\n            await self.update()\n            await asyncio.sleep(self._update_interval)", "response": "Schedule a state update to keep the connection alive"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_cli_to_bel_namespace(main: click.Group) -> click.Group:  # noqa: D202\n\n    @main.command()\n    @click.option('-u', '--update', is_flag=True)\n    @click.pass_obj\n    def upload(manager: BELNamespaceManagerMixin, update):\n        \"\"\"Upload names/identifiers to terminology store.\"\"\"\n        namespace = manager.upload_bel_namespace(update=update)\n        click.echo(f'uploaded [{namespace.id}] {namespace.keyword}')\n\n    return main", "response": "Add a command to main function that uploads BEL Namespaces to terminology store."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a clear_bel_namespace command to main.", "response": "def add_cli_clear_bel_namespace(main: click.Group) -> click.Group:  # noqa: D202\n    \"\"\"Add a ``clear_bel_namespace`` command to main :mod:`click` function.\"\"\"\n\n    @main.command()\n    @click.pass_obj\n    def drop(manager: BELNamespaceManagerMixin):\n        \"\"\"Clear names/identifiers to terminology store.\"\"\"\n        namespace = manager.drop_bel_namespace()\n\n        if namespace:\n            click.echo(f'namespace {namespace} was cleared')\n\n    return main"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a write_bel_namespace command to main.", "response": "def add_cli_write_bel_namespace(main: click.Group) -> click.Group:  # noqa: D202\n    \"\"\"Add a ``write_bel_namespace`` command to main :mod:`click` function.\"\"\"\n\n    @main.command()\n    @click.option('-d', '--directory', type=click.Path(file_okay=False, dir_okay=True), default=os.getcwd(),\n                  help='output directory')\n    @click.pass_obj\n    def write(manager: BELNamespaceManagerMixin, directory: str):\n        \"\"\"Write a BEL namespace names/identifiers to terminology store.\"\"\"\n        manager.write_directory(directory)\n\n    return main"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a write_bel_annotation command to main.", "response": "def add_cli_write_bel_annotation(main: click.Group) -> click.Group:  # noqa: D202\n    \"\"\"Add a ``write_bel_annotation`` command to main :mod:`click` function.\"\"\"\n\n    @main.command()\n    @click.option('-d', '--directory', type=click.Path(file_okay=False, dir_okay=True), default=os.getcwd(),\n                  help='output directory')\n    @click.pass_obj\n    def write(manager: BELNamespaceManagerMixin, directory: str):\n        \"\"\"Write a BEL annotation.\"\"\"\n        with open(os.path.join(directory, manager.identifiers_namespace), 'w') as file:\n            manager.write_bel_annotation(file)\n\n    return main"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an iterator over the models that are converted to the namespace.", "response": "def _iterate_namespace_models(self, **kwargs) -> Iterable:\n        \"\"\"Return an iterator over the models to be converted to the namespace.\"\"\"\n        return tqdm(\n            self._get_query(self.namespace_model),\n            total=self._count_model(self.namespace_model),\n            **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_default_namespace(self) -> Optional[Namespace]:\n        return self._get_query(Namespace).filter(Namespace.url == self._get_namespace_url()).one_or_none()", "response": "Get the default BEL namespace if it exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a PyBEL generalized namespace entries to a set.", "response": "def _get_old_entry_identifiers(namespace: Namespace) -> Set[NamespaceEntry]:\n        \"\"\"Convert a PyBEL generalized namespace entries to a set.\n\n        Default to using the identifier, but can be overridden to use the name instead.\n\n        >>> {term.identifier for term in namespace.entries}\n        \"\"\"\n        return {term.identifier for term in namespace.entries}"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates an already - created namespace.", "response": "def _update_namespace(self, namespace: Namespace) -> None:\n        \"\"\"Update an already-created namespace.\n\n        Note: Only call this if namespace won't be none!\n        \"\"\"\n        old_entry_identifiers = self._get_old_entry_identifiers(namespace)\n        new_count = 0\n        skip_count = 0\n\n        for model in self._iterate_namespace_models():\n            if self._get_identifier(model) in old_entry_identifiers:\n                continue\n\n            entry = self._create_namespace_entry_from_model(model, namespace=namespace)\n            if entry is None or entry.name is None:\n                skip_count += 1\n                continue\n\n            new_count += 1\n            self.session.add(entry)\n\n        t = time.time()\n        log.info('got %d new entries. skipped %d entries missing names. committing models', new_count, skip_count)\n        self.session.commit()\n        log.info('committed models in %.2f seconds', time.time() - t)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds this manager s namespace to the graph.", "response": "def add_namespace_to_graph(self, graph: BELGraph) -> Namespace:\n        \"\"\"Add this manager's namespace to the graph.\"\"\"\n        namespace = self.upload_bel_namespace()\n        graph.namespace_url[namespace.keyword] = namespace.url\n\n        # Add this manager as an annotation, too\n        self._add_annotation_to_graph(graph)\n\n        return namespace"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _add_annotation_to_graph(self, graph: BELGraph) -> None:\n        if 'bio2bel' not in graph.annotation_list:\n            graph.annotation_list['bio2bel'] = set()\n\n        graph.annotation_list['bio2bel'].add(self.module_name)", "response": "Add this manager as an annotation to the graph."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupload the BEL namespace to the PyBEL database.", "response": "def upload_bel_namespace(self, update: bool = False) -> Namespace:\n        \"\"\"Upload the namespace to the PyBEL database.\n\n        :param update: Should the namespace be updated first?\n        \"\"\"\n        if not self.is_populated():\n            self.populate()\n\n        namespace = self._get_default_namespace()\n\n        if namespace is None:\n            log.info('making namespace for %s', self._get_namespace_name())\n            return self._make_namespace()\n\n        if update:\n            self._update_namespace(namespace)\n\n        return namespace"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves the default namespace if it exists.", "response": "def drop_bel_namespace(self) -> Optional[Namespace]:\n        \"\"\"Remove the default namespace if it exists.\"\"\"\n        namespace = self._get_default_namespace()\n\n        if namespace is not None:\n            for entry in tqdm(namespace.entries, desc=f'deleting entries in {self._get_namespace_name()}'):\n                self.session.delete(entry)\n            self.session.delete(namespace)\n\n            log.info('committing deletions')\n            self.session.commit()\n            return namespace"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite as a BEL namespace file.", "response": "def write_bel_namespace(self, file: TextIO, use_names: bool = False) -> None:\n        \"\"\"Write as a BEL namespace file.\"\"\"\n        if not self.is_populated():\n            self.populate()\n\n        if use_names and not self.has_names:\n            raise ValueError\n\n        values = (\n            self._get_namespace_name_to_encoding(desc='writing names')\n            if use_names else\n            self._get_namespace_identifier_to_encoding(desc='writing identifiers')\n        )\n\n        write_namespace(\n            namespace_name=self._get_namespace_name(),\n            namespace_keyword=self._get_namespace_keyword(),\n            namespace_query_url=self.identifiers_url,\n            values=values,\n            file=file,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_bel_annotation(self, file: TextIO) -> None:\n        if not self.is_populated():\n            self.populate()\n\n        values = self._get_namespace_name_to_encoding(desc='writing names')\n\n        write_annotation(\n            keyword=self._get_namespace_keyword(),\n            citation_name=self._get_namespace_name(),\n            description='',\n            values=values,\n            file=file,\n        )", "response": "Write as a BEL annotation file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites a BEL namespace mapping file.", "response": "def write_bel_namespace_mappings(self, file: TextIO, **kwargs) -> None:\n        \"\"\"Write a BEL namespace mapping file.\"\"\"\n        json.dump(self._get_namespace_identifier_to_name(**kwargs), file, indent=2, sort_keys=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite a BEL namespace for identifiers names name hash and mappings to the given directory.", "response": "def write_directory(self, directory: str) -> bool:\n        \"\"\"Write a BEL namespace for identifiers, names, name hash, and mappings to the given directory.\"\"\"\n        current_md5_hash = self.get_namespace_hash()\n        md5_hash_path = os.path.join(directory, f'{self.module_name}.belns.md5')\n\n        if not os.path.exists(md5_hash_path):\n            old_md5_hash = None\n        else:\n            with open(md5_hash_path) as file:\n                old_md5_hash = file.read().strip()\n\n        if old_md5_hash == current_md5_hash:\n            return False\n\n        with open(os.path.join(directory, f'{self.module_name}.belns'), 'w') as file:\n            self.write_bel_namespace(file, use_names=False)\n\n        with open(md5_hash_path, 'w') as file:\n            print(current_md5_hash, file=file)\n\n        if self.has_names:\n            with open(os.path.join(directory, f'{self.module_name}-names.belns'), 'w') as file:\n                self.write_bel_namespace(file, use_names=True)\n\n            with open(os.path.join(directory, f'{self.module_name}.belns.mapping'), 'w') as file:\n                self.write_bel_namespace_mappings(file, desc='writing mapping')\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the namespace hash.", "response": "def get_namespace_hash(self, hash_fn=hashlib.md5) -> str:\n        \"\"\"Get the namespace hash.\n\n        Defaults to MD5.\n        \"\"\"\n        m = hash_fn()\n\n        if self.has_names:\n            items = self._get_namespace_name_to_encoding(desc='getting hash').items()\n        else:\n            items = self._get_namespace_identifier_to_encoding(desc='getting hash').items()\n\n        for name, encoding in items:\n            m.update(f'{name}:{encoding}'.encode('utf8'))\n        return m.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_cli(cls) -> click.Group:\n        main = super().get_cli()\n\n        if cls.is_namespace:\n            @main.group()\n            def belns():\n                \"\"\"Manage BEL namespace.\"\"\"\n\n            cls._cli_add_to_bel_namespace(belns)\n            cls._cli_add_clear_bel_namespace(belns)\n            cls._cli_add_write_bel_namespace(belns)\n\n        if cls.is_annotation:\n            @main.group()\n            def belanno():\n                \"\"\"Manage BEL annotation.\"\"\"\n\n            cls._cli_add_write_bel_annotation(belanno)\n\n        return main", "response": "Get a click. Group that adds BEL namespace commands."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_long_description():\n    with codecs.open(os.path.join(HERE, 'README.rst'), encoding='utf-8') as f:\n        long_description = f.read()\n    return long_description", "response": "Get the long_description from the README. rst file. Assume UTF - 8 encoding."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dropbox_post_factory(request):\n    try:\n        max_age = int(request.registry.settings.get('post_token_max_age_seconds'))\n    except Exception:\n        max_age = 300\n\n    try:\n        drop_id = parse_post_token(\n            token=request.matchdict['token'],\n            secret=request.registry.settings['post_secret'],\n            max_age=max_age)\n    except SignatureExpired:\n        raise HTTPGone('dropbox expired')\n    except Exception:  # don't be too specific on the reason for the error\n        raise HTTPNotFound('no such dropbox')\n    dropbox = request.registry.settings['dropbox_container'].get_dropbox(drop_id)\n    if dropbox.status_int >= 20:\n        raise HTTPGone('dropbox already in processing, no longer accepts data')\n    return dropbox", "response": "receives a UUID via the request and returns either a fresh or existing dropbox\n    for it"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexpect the id of an existing dropbox and returns its instance", "response": "def dropbox_factory(request):\n    \"\"\" expects the id of an existing dropbox and returns its instance\"\"\"\n    try:\n        return request.registry.settings['dropbox_container'].get_dropbox(request.matchdict['drop_id'])\n    except KeyError:\n        raise HTTPNotFound('no such dropbox')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_equal(a, b):\n    if len(a) != len(b):\n        return False\n\n    result = 0\n    for x, y in zip(a, b):\n        result |= ord(x) ^ ord(y)\n    return result == 0", "response": "a constant time comparison implementation taken from Codahale s RFC 2965"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_cli(cls) -> click.Group:\n        group_help = 'Default connection at {}\\n\\nusing Bio2BEL v{}'.format(cls._get_connection(), get_version())\n\n        @click.group(help=group_help)\n        @click.option('-c', '--connection', default=cls._get_connection(),\n                      help='Defaults to {}'.format(cls._get_connection()))\n        @click.pass_context\n        def main(ctx, connection):\n            \"\"\"Bio2BEL CLI.\"\"\"\n            logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n            logging.getLogger('bio2bel.utils').setLevel(logging.WARNING)\n            ctx.obj = cls(connection=connection)\n\n        return main", "response": "Build a click CLI main function."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npreserves the file ending but replace the name with a random token", "response": "def sanitize_filename(filename):\n    \"\"\"preserve the file ending, but replace the name with a random token \"\"\"\n    # TODO: fix broken splitext (it reveals everything of the filename after the first `.` - doh!)\n    token = generate_drop_id()\n    name, extension = splitext(filename)\n    if extension:\n        return '%s%s' % (token, extension)\n    else:\n        return token"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls the external cleanser scripts to purge the meta data and then send the contents of the dropbox via email.", "response": "def process(self):\n        \"\"\" Calls the external cleanser scripts to (optionally) purge the meta data and then\n            send the contents of the dropbox via email.\n        \"\"\"\n\n        if self.num_attachments > 0:\n            self.status = u'100 processor running'\n            fs_dirty_archive = self._create_backup()\n            # calling _process_attachments has the side-effect of updating `send_attachments`\n            self._process_attachments()\n            if self.status_int < 500 and not self.send_attachments:\n                    self._create_archive()\n\n        if self.status_int >= 500 and self.status_int < 600:\n            # cleansing failed\n            # if configured, we need to move the uncleansed archive to\n            # the appropriate folder and notify the editors\n            if 'dropbox_dirty_archive_url_format' in self.settings:\n                # create_archive\n                shutil.move(\n                    fs_dirty_archive,\n                    '%s/%s.zip.pgp' % (self.container.fs_archive_dirty, self.drop_id))\n                # update status\n                # it's now considered 'successful-ish' again\n                self.status = '490 cleanser failure but notify success'\n\n        if self.status_int == 800:\n            # at least one attachment was not supported\n            # if configured, we need to move the uncleansed archive to\n            # the appropriate folder and notify the editors\n            if 'dropbox_dirty_archive_url_format' in self.settings:\n                # create_archive\n                shutil.move(\n                    fs_dirty_archive,\n                    '%s/%s.zip.pgp' % (self.container.fs_archive_dirty, self.drop_id))\n\n        if self.status_int < 500 or self.status_int == 800:\n            try:\n                if self._notify_editors() > 0:\n                    if self.status_int < 500:\n                        self.status = '900 success'\n                else:\n                    self.status = '605 smtp failure'\n            except Exception:\n                import traceback\n                tb = traceback.format_exc()\n                self.status = '610 smtp error (%s)' % tb\n\n        self.cleanup()\n        return self.status"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cleanup(self):\n        try:\n            remove(join(self.fs_path, u'message'))\n            remove(join(self.fs_path, 'dirty.zip.pgp'))\n        except OSError:\n            pass\n        shutil.rmtree(join(self.fs_path, u'clean'), ignore_errors=True)\n        shutil.rmtree(join(self.fs_path, u'attach'), ignore_errors=True)", "response": "Removes all data except the status file and clean the directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a zip file from the drop and encrypts it to the editors.", "response": "def _create_encrypted_zip(self, source='dirty', fs_target_dir=None):\n        \"\"\" creates a zip file from the drop and encrypts it to the editors.\n        the encrypted archive is created inside fs_target_dir\"\"\"\n        backup_recipients = [r for r in self.editors if checkRecipient(self.gpg_context, r)]\n\n        # this will be handled by watchdog, no need to send for each drop\n        if not backup_recipients:\n            self.status = u'500 no valid keys at all'\n            return self.status\n\n        # calculate paths\n        fs_backup = join(self.fs_path, '%s.zip' % source)\n        if fs_target_dir is None:\n            fs_backup_pgp = join(self.fs_path, '%s.zip.pgp' % source)\n        else:\n            fs_backup_pgp = join(fs_target_dir, '%s.zip.pgp' % self.drop_id)\n        fs_source = dict(\n            dirty=self.fs_dirty_attachments,\n            clean=self.fs_cleansed_attachments\n        )\n\n        # create archive\n        with ZipFile(fs_backup, 'w', ZIP_STORED) as backup:\n            if exists(join(self.fs_path, 'message')):\n                backup.write(join(self.fs_path, 'message'), arcname='message')\n            for fs_attachment in fs_source[source]:\n                backup.write(fs_attachment, arcname=split(fs_attachment)[-1])\n\n        # encrypt archive\n        with open(fs_backup, \"rb\") as backup:\n            self.gpg_context.encrypt_file(\n                backup,\n                backup_recipients,\n                always_trust=True,\n                output=fs_backup_pgp\n            )\n\n        # cleanup\n        remove(fs_backup)\n        return fs_backup_pgp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _create_archive(self):\n        self.status = u'270 creating final encrypted backup of cleansed attachments'\n        return self._create_encrypted_zip(source='clean', fs_target_dir=self.container.fs_archive_cleansed)", "response": "Creates an encrypted archive of the dropbox inside of the drop directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the number of bytes that the cleansed attachments take up on disk", "response": "def size_attachments(self):\n        \"\"\"returns the number of bytes that the cleansed attachments take up on disk\"\"\"\n        total_size = 0\n        for attachment in self.fs_cleansed_attachments:\n                total_size += stat(attachment).st_size\n        return total_size"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replies(self):\n        fs_reply_path = join(self.fs_replies_path, 'message_001.txt')\n        if exists(fs_reply_path):\n            return [load(open(fs_reply_path, 'r'))]\n        else:\n            return []", "response": "returns a list of strings"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef message(self):\n        try:\n            with open(join(self.fs_path, u'message')) as message_file:\n                return u''.join([line.decode('utf-8') for line in message_file.readlines()])\n        except IOError:\n            return u''", "response": "returns the user submitted text"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of absolute paths to the attachments that have been changed", "response": "def fs_dirty_attachments(self):\n        \"\"\" returns a list of absolute paths to the attachements\"\"\"\n        if exists(self.fs_attachment_container):\n            return [join(self.fs_attachment_container, attachment)\n                    for attachment in listdir(self.fs_attachment_container)]\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of absolute paths to the cleansed attachments", "response": "def fs_cleansed_attachments(self):\n        \"\"\" returns a list of absolute paths to the cleansed attachements\"\"\"\n        if exists(self.fs_cleansed_attachment_container):\n            return [join(self.fs_cleansed_attachment_container, attachment)\n                    for attachment in listdir(self.fs_cleansed_attachment_container)]\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndestroys all cleanser slaves and rollback snapshots as well as the initial master snapshot", "response": "def reset_cleansers(confirm=True):\n    \"\"\"destroys all cleanser slaves and their rollback snapshots, as well as the initial master\n    snapshot - this allows re-running the jailhost deployment to recreate fresh cleansers.\"\"\"\n\n    if value_asbool(confirm) and not yesno(\"\"\"\\nObacht!\n            This will destroy any existing and or currently running cleanser jails.\n            Are you sure that you want to continue?\"\"\"):\n        exit(\"Glad I asked...\")\n\n    get_vars()\n\n    cleanser_count = AV['ploy_cleanser_count']\n    # make sure no workers interfere:\n    fab.run('ezjail-admin stop worker')\n    # stop and nuke the cleanser slaves\n    for cleanser_index in range(cleanser_count):\n        cindex = '{:02d}'.format(cleanser_index + 1)\n        fab.run('ezjail-admin stop cleanser_{cindex}'.format(cindex=cindex))\n        with fab.warn_only():\n            fab.run('zfs destroy tank/jails/cleanser_{cindex}@jdispatch_rollback'.format(cindex=cindex))\n            fab.run('ezjail-admin delete -fw cleanser_{cindex}'.format(cindex=cindex))\n            fab.run('umount -f /usr/jails/cleanser_{cindex}'.format(cindex=cindex))\n            fab.run('rm -rf /usr/jails/cleanser_{cindex}'.format(cindex=cindex))\n\n    with fab.warn_only():\n        # remove master snapshot\n        fab.run('zfs destroy -R tank/jails/cleanser@clonesource')\n\n        # restart worker and cleanser to prepare for subsequent ansible configuration runs\n        fab.run('ezjail-admin start worker')\n        fab.run('ezjail-admin stop cleanser')\n        fab.run('ezjail-admin start cleanser')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reset_jails(confirm=True, keep_cleanser_master=True):\n    if value_asbool(confirm) and not yesno(\"\"\"\\nObacht!\n            This will destroy all existing and or currently running jails on the host.\n            Are you sure that you want to continue?\"\"\"):\n        exit(\"Glad I asked...\")\n\n    reset_cleansers(confirm=False)\n\n    jails = ['appserver', 'webserver', 'worker']\n    if not value_asbool(keep_cleanser_master):\n        jails.append('cleanser')\n\n    with fab.warn_only():\n        for jail in jails:\n            fab.run('ezjail-admin delete -fw {jail}'.format(jail=jail))\n        # remove authorized keys for no longer existing key (they are regenerated for each new worker)\n        fab.run('rm /usr/jails/cleanser/usr/home/cleanser/.ssh/authorized_keys')", "response": "Stops deletes and re - creates all jails."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dict_dumper(provider):\n    '''\n    Dump a provider to a format that can be passed to a\n    :class:`skosprovider.providers.DictionaryProvider`.\n\n    :param skosprovider.providers.VocabularyProvider provider: The provider\n        that wil be turned into a `dict`.\n    :rtype: A list of dicts.\n\n    .. versionadded:: 0.2.0\n    '''\n    ret = []\n    for stuff in provider.get_all():\n        c = provider.get_by_id(stuff['id'])\n        labels = [l.__dict__ for l in c.labels]\n        notes = [n.__dict__ for n in c.notes]\n        sources = [s.__dict__ for s in c.sources]\n        if isinstance(c, Concept):\n            ret.append({\n                'id': c.id,\n                'uri': c.uri,\n                'type': c.type,\n                'labels': labels,\n                'notes': notes,\n                'sources': sources,\n                'narrower': c.narrower,\n                'broader': c.broader,\n                'related': c.related,\n                'member_of': c.member_of,\n                'subordinate_arrays': c.subordinate_arrays,\n                'matches': c.matches\n            })\n        elif isinstance(c, Collection):\n            ret.append({\n                'id': c.id,\n                'uri': c.uri,\n                'type': c.type,\n                'labels': labels,\n                'notes': notes,\n                'sources': sources,\n                'members': c.members,\n                'member_of': c.member_of,\n                'superordinates': c.superordinates\n            })\n    return ret", "response": "Dumps a provider to a list of dicts."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_cli_flask(main: click.Group) -> click.Group:  # noqa: D202\n\n    @main.command()\n    @click.option('-v', '--debug', is_flag=True)\n    @click.option('-p', '--port')\n    @click.option('-h', '--host')\n    @click.option('-k', '--secret-key', default=os.urandom(8))\n    @click.pass_obj\n    def web(manager, debug, port, host, secret_key):\n        \"\"\"Run the web app.\"\"\"\n        if not manager.is_populated():\n            click.echo('{} has not yet been populated'.format(manager.module_name))\n            sys.exit(0)\n\n        app = manager.get_flask_admin_app(url='/', secret_key=secret_key)\n        app.run(debug=debug, host=host, port=port)\n\n    return main", "response": "Add a web comand main."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a Flask Admin interface to an application.", "response": "def _add_admin(self, app, **kwargs):\n        \"\"\"Add a Flask Admin interface to an application.\n\n        :param flask.Flask app: A Flask application\n        :param kwargs: Keyword arguments are passed through to :class:`flask_admin.Admin`\n        :rtype: flask_admin.Admin\n        \"\"\"\n        from flask_admin import Admin\n        from flask_admin.contrib.sqla import ModelView\n\n        admin = Admin(app, **kwargs)\n\n        for flask_admin_model in self.flask_admin_models:\n            if isinstance(flask_admin_model, tuple):  # assume its a 2 tuple\n                if len(flask_admin_model) != 2:\n                    raise TypeError\n\n                model, view = flask_admin_model\n                admin.add_view(view(model, self.session))\n\n            else:\n                admin.add_view(ModelView(flask_admin_model, self.session))\n\n        return admin"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_flask_admin_app(self, url: Optional[str] = None, secret_key: Optional[str] = None):\n        from flask import Flask\n\n        app = Flask(__name__)\n\n        if secret_key:\n            app.secret_key = secret_key\n\n        self._add_admin(app, url=(url or '/'))\n        return app", "response": "Create a Flask application."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a click. Group to use as a command line interface.", "response": "def get_cli(cls) -> click.Group:\n        \"\"\"Add  a :mod:`click` main function to use as a command line interface.\"\"\"\n        main = super().get_cli()\n\n        cls._cli_add_flask(main)\n\n        return main"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle a system status event.", "response": "def _handle_system_status_event(self, event: SystemStatusEvent) -> None:\n        \"\"\"\n        DISARMED -> ARMED_AWAY -> EXIT_DELAY_START -> EXIT_DELAY_END\n         (trip): -> ALARM -> OUTPUT_ON -> ALARM_RESTORE\n            (disarm): -> DISARMED -> OUTPUT_OFF\n         (disarm): -> DISARMED\n         (disarm before EXIT_DELAY_END): -> DISARMED -> EXIT_DELAY_END\n\n        TODO(NW): Check ALARM_RESTORE state transition to move back into ARMED_AWAY state\n        \"\"\"\n        if event.type == SystemStatusEvent.EventType.UNSEALED:\n            return self._update_zone(event.zone, True)\n        elif event.type == SystemStatusEvent.EventType.SEALED:\n            return self._update_zone(event.zone, False)\n        elif event.type == SystemStatusEvent.EventType.ALARM:\n            return self._update_arming_state(ArmingState.TRIGGERED)\n        elif event.type == SystemStatusEvent.EventType.ALARM_RESTORE:\n            if self.arming_state != ArmingState.DISARMED:\n                return self._update_arming_state(ArmingState.ARMED)\n        elif event.type == SystemStatusEvent.EventType.ENTRY_DELAY_START:\n            return self._update_arming_state(ArmingState.ENTRY_DELAY)\n        elif event.type == SystemStatusEvent.EventType.ENTRY_DELAY_END:\n            pass\n        elif event.type == SystemStatusEvent.EventType.EXIT_DELAY_START:\n            return self._update_arming_state(ArmingState.EXIT_DELAY)\n        elif event.type == SystemStatusEvent.EventType.EXIT_DELAY_END:\n            # Exit delay finished - if we were in the process of arming update\n            # state to armed\n            if self.arming_state == ArmingState.EXIT_DELAY:\n                return self._update_arming_state(ArmingState.ARMED)\n        elif event.type in Alarm.ARM_EVENTS:\n            return self._update_arming_state(ArmingState.ARMING)\n        elif event.type == SystemStatusEvent.EventType.DISARMED:\n            return self._update_arming_state(ArmingState.DISARMED)\n        elif event.type == SystemStatusEvent.EventType.ARMING_DELAYED:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dropbox_form(request):\n    from briefkasten import generate_post_token\n    token = generate_post_token(secret=request.registry.settings['post_secret'])\n    return dict(\n        action=request.route_url('dropbox_form_submit', token=token),\n        fileupload_url=request.route_url('dropbox_fileupload', token=token),\n        **defaults(request))", "response": "Generates a dropbox uid and renders the submission form with a signed version of that id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dropbox_fileupload(dropbox, request):\n    attachment = request.POST['attachment']\n    attached = dropbox.add_attachment(attachment)\n    return dict(\n        files=[dict(\n            name=attached,\n            type=attachment.type,\n        )]\n    )", "response": "accepts a single file upload and adds it to the dropbox as attachment"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling the form submission redirects to the dropbox s status page", "response": "def dropbox_submission(dropbox, request):\n    \"\"\" handles the form submission, redirects to the dropbox's status page.\"\"\"\n    try:\n        data = dropbox_schema.deserialize(request.POST)\n    except Exception:\n        return HTTPFound(location=request.route_url('dropbox_form'))\n\n    # set the message\n    dropbox.message = data.get('message')\n\n    # recognize submission from watchdog\n    if 'testing_secret' in dropbox.settings:\n        dropbox.from_watchdog = is_equal(\n            unicode(dropbox.settings['test_submission_secret']),\n            data.pop('testing_secret', u''))\n\n    # a non-js client might have uploaded an attachment via the form's fileupload field:\n    if data.get('upload') is not None:\n        dropbox.add_attachment(data['upload'])\n\n    # now we can call the process method\n    dropbox.submit()\n    drop_url = request.route_url('dropbox_view', drop_id=dropbox.drop_id)\n    print(\"Created dropbox %s\" % drop_url)\n    return HTTPFound(location=drop_url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a function that downloads and parses a GO OBO file and returns a MultiDiGraph.", "response": "def make_obo_getter(data_url: str,\n                    data_path: str,\n                    *,\n                    preparsed_path: Optional[str] = None,\n                    ) -> Callable[[Optional[str], bool, bool], MultiDiGraph]:\n    \"\"\"Build a function that handles downloading OBO data and parsing it into a NetworkX object.\n\n    :param data_url: The URL of the data\n    :param data_path: The path where the data should get stored\n    :param preparsed_path: The optional path to cache a pre-parsed json version\n    \"\"\"\n    download_function = make_downloader(data_url, data_path)\n\n    def get_obo(url: Optional[str] = None, cache: bool = True, force_download: bool = False) -> MultiDiGraph:\n        \"\"\"Download and parse a GO obo file with :mod:`obonet` into a MultiDiGraph.\n\n        :param url: The URL (or file path) to download.\n        :param cache: If true, the data is downloaded to the file system, else it is loaded from the internet\n        :param force_download: If true, overwrites a previously cached file\n        \"\"\"\n        if preparsed_path is not None and os.path.exists(preparsed_path):\n            return read_gpickle(preparsed_path)\n\n        if url is None and cache:\n            url = download_function(force_download=force_download)\n\n        result = obonet.read_obo(url)\n\n        if preparsed_path is not None:\n            write_gpickle(result, preparsed_path)\n\n        return result\n\n    return get_obo"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef belns(keyword: str, file: TextIO, encoding: Optional[str], use_names: bool):\n    directory = get_data_dir(keyword)\n    obo_url = f'http://purl.obolibrary.org/obo/{keyword}.obo'\n    obo_path = os.path.join(directory, f'{keyword}.obo')\n    obo_cache_path = os.path.join(directory, f'{keyword}.obo.pickle')\n\n    obo_getter = make_obo_getter(obo_url, obo_path, preparsed_path=obo_cache_path)\n    graph = obo_getter()\n    convert_obo_graph_to_belns(\n        graph,\n        file=file,\n        encoding=encoding,\n        use_names=use_names,\n    )", "response": "Write as a BEL namespace."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef belanno(keyword: str, file: TextIO):\n    directory = get_data_dir(keyword)\n    obo_url = f'http://purl.obolibrary.org/obo/{keyword}.obo'\n    obo_path = os.path.join(directory, f'{keyword}.obo')\n    obo_cache_path = os.path.join(directory, f'{keyword}.obo.pickle')\n\n    obo_getter = make_obo_getter(obo_url, obo_path, preparsed_path=obo_cache_path)\n    graph = obo_getter()\n    convert_obo_graph_to_belanno(\n        graph,\n        file=file,\n    )", "response": "Write as a BEL annotation."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhelp store an action.", "response": "def _store_helper(model: Action, session: Optional[Session] = None) -> None:\n    \"\"\"Help store an action.\"\"\"\n    if session is None:\n        session = _make_session()\n\n    session.add(model)\n    session.commit()\n    session.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates the tables for Bio2BEL.", "response": "def create_all(engine, checkfirst=True):\n    \"\"\"Create the tables for Bio2BEL.\"\"\"\n    Base.metadata.create_all(bind=engine, checkfirst=checkfirst)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef store_populate(cls, resource: str, session: Optional[Session] = None) -> 'Action':\n        action = cls.make_populate(resource)\n        _store_helper(action, session=session)\n        return action", "response": "Store a populate event."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef store_populate_failed(cls, resource: str, session: Optional[Session] = None) -> 'Action':\n        action = cls.make_populate_failed(resource)\n        _store_helper(action, session=session)\n        return action", "response": "Store a populate failed event."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef store_drop(cls, resource: str, session: Optional[Session] = None) -> 'Action':\n        action = cls.make_drop(resource)\n        _store_helper(action, session=session)\n        return action", "response": "Store a drop event."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nensures the appropriate Bio2BEL data directory exists for the given module.", "response": "def get_data_dir(module_name: str) -> str:\n    \"\"\"Ensure the appropriate Bio2BEL data directory exists for the given module, then returns the file path.\n\n    :param module_name: The name of the module. Ex: 'chembl'\n    :return: The module's data directory\n    \"\"\"\n    module_name = module_name.lower()\n    data_dir = os.path.join(BIO2BEL_DIR, module_name)\n    os.makedirs(data_dir, exist_ok=True)\n    return data_dir"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild a module configuration class.", "response": "def get_module_config_cls(module_name: str) -> Type[_AbstractModuleConfig]:  # noqa: D202\n    \"\"\"Build a module configuration class.\"\"\"\n\n    class ModuleConfig(_AbstractModuleConfig):\n        NAME = f'bio2bel:{module_name}'\n        FILES = DEFAULT_CONFIG_PATHS + [\n            os.path.join(DEFAULT_CONFIG_DIRECTORY, module_name, 'config.ini')\n        ]\n\n    return ModuleConfig"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_connection(module_name: str, connection: Optional[str] = None) -> str:\n    # 1. Use given connection\n    if connection is not None:\n        return connection\n\n    module_name = module_name.lower()\n    module_config_cls = get_module_config_cls(module_name)\n    module_config = module_config_cls.load()\n\n    return module_config.connection or config.connection", "response": "Returns the SQLAlchemy connection string for the given module."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting all Bio2BEL modules.", "response": "def get_modules() -> Mapping:\n    \"\"\"Get all Bio2BEL modules.\"\"\"\n    modules = {}\n\n    for entry_point in iter_entry_points(group='bio2bel', name=None):\n        entry = entry_point.name\n\n        try:\n            modules[entry] = entry_point.load()\n        except VersionConflict as exc:\n            log.warning('Version conflict in %s: %s', entry, exc)\n            continue\n        except UnknownExtra as exc:\n            log.warning('Unknown extra in %s: %s', entry, exc)\n            continue\n        except ImportError as exc:\n            log.exception('Issue with importing module %s: %s', entry, exc)\n            continue\n\n    return modules"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear_cache(module_name: str, keep_database: bool = True) -> None:\n    data_dir = get_data_dir(module_name)\n    if not os.path.exists(data_dir):\n        return\n    for name in os.listdir(data_dir):\n        if name in {'config.ini', 'cfg.ini'}:\n            continue\n        if name == 'cache.db' and keep_database:\n            continue\n        path = os.path.join(data_dir, name)\n        if os.path.isdir(path):\n            shutil.rmtree(path)\n        else:\n            os.remove(path)\n\n        os.rmdir(data_dir)", "response": "Clear all downloaded files and database files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a populate command to main click function.", "response": "def add_cli_populate(main: click.Group) -> click.Group:  # noqa: D202\n    \"\"\"Add a ``populate`` command to main :mod:`click` function.\"\"\"\n\n    @main.command()\n    @click.option('--reset', is_flag=True, help='Nuke database first')\n    @click.option('--force', is_flag=True, help='Force overwrite if already populated')\n    @click.pass_obj\n    def populate(manager: AbstractManager, reset, force):\n        \"\"\"Populate the database.\"\"\"\n        if reset:\n            click.echo('Deleting the previous instance of the database')\n            manager.drop_all()\n            click.echo('Creating new models')\n            manager.create_all()\n\n        if manager.is_populated() and not force:\n            click.echo('Database already populated. Use --force to overwrite')\n            sys.exit(0)\n\n        manager.populate()\n\n    return main"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a drop command to main click function.", "response": "def add_cli_drop(main: click.Group) -> click.Group:  # noqa: D202\n    \"\"\"Add a ``drop`` command to main :mod:`click` function.\"\"\"\n\n    @main.command()\n    @click.confirmation_option(prompt='Are you sure you want to drop the db?')\n    @click.pass_obj\n    def drop(manager):\n        \"\"\"Drop the database.\"\"\"\n        manager.drop_all()\n\n    return main"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_cli_cache(main: click.Group) -> click.Group:  # noqa: D202\n\n    @main.group()\n    def cache():\n        \"\"\"Manage cached data.\"\"\"\n\n    @cache.command()\n    @click.pass_obj\n    def locate(manager):\n        \"\"\"Print the location of the data directory.\"\"\"\n        data_dir = get_data_dir(manager.module_name)\n        click.echo(data_dir)\n\n    @cache.command()\n    @click.pass_obj\n    def ls(manager):\n        \"\"\"List files in the cache.\"\"\"\n        data_dir = get_data_dir(manager.module_name)\n\n        for path in os.listdir(data_dir):\n            click.echo(path)\n\n    @cache.command()\n    @click.pass_obj\n    def clear(manager):\n        \"\"\"Clear all files from the cache.\"\"\"\n        clear_cache(manager.module_name)\n\n    return main", "response": "Add several commands to main click function for handling the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_cli_summarize(main: click.Group) -> click.Group:  # noqa: D202\n\n    @main.command()\n    @click.pass_obj\n    def summarize(manager: AbstractManager):\n        \"\"\"Summarize the contents of the database.\"\"\"\n        if not manager.is_populated():\n            click.secho(f'{manager.module_name} has not been populated', fg='red')\n            sys.exit(1)\n\n        for name, count in sorted(manager.summarize().items()):\n            click.echo(f'{name.capitalize()}: {count}')\n\n    return main", "response": "Add a summarize command to main."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_all(self, check_first: bool = True):\n        self._metadata.create_all(self.engine, checkfirst=check_first)", "response": "Create the empty database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndropping all tables from the database.", "response": "def drop_all(self, check_first: bool = True):\n        \"\"\"Drop all tables from the database.\n\n        :param bool check_first: Defaults to True, only issue DROPs for tables confirmed to be\n          present in the target database. Defers to :meth:`sqlalchemy.sql.schema.MetaData.drop_all`\n        \"\"\"\n        self._metadata.drop_all(self.engine, checkfirst=check_first)\n        self._store_drop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_cli(cls) -> click.Group:\n        main = super().get_cli()\n\n        cls._cli_add_populate(main)\n        cls._cli_add_drop(main)\n        cls._cli_add_cache(main)\n        cls._cli_add_summarize(main)\n\n        return main", "response": "Get the click. Group to use as a command line interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef label(labels=[], language='any', sortLabel=False):\n    '''\n    Provide a label for a list of labels.\n\n    The items in the list of labels are assumed to be either instances of\n    :class:`Label`, or dicts with at least the key `label` in them. These will\n    be passed to the :func:`dict_to_label` function.\n\n    This method tries to find a label by looking if there's\n    a pref label for the specified language. If there's no pref label,\n    it looks for an alt label. It disregards hidden labels.\n\n    While matching languages, preference will be given to exact matches. But,\n    if no exact match is present, an inexact match will be attempted. This might\n    be because a label in language `nl-BE` is being requested, but only `nl` or\n    even `nl-NL` is present. Similarly, when requesting `nl`, a label with\n    language `nl-NL` or even `nl-Latn-NL` will also be considered,\n    providing no label is present that has an exact match with the\n    requested language.\n\n    If language 'any' was specified, all labels will be considered,\n    regardless of language.\n\n    To find a label without a specified language, pass `None` as language.\n\n    If a language or None was specified, and no label could be found, this\n    method will automatically try to find a label in some other language.\n\n    Finally, if no label could be found, None is returned.\n\n    :param string language: The preferred language to receive the label in. This\n        should be a valid IANA language tag.\n    :param boolean sortLabel: Should sortLabels be considered or not? If True,\n        sortLabels will be preferred over prefLabels. Bear in mind that these\n        are still language dependent. So, it's possible to have a different\n        sortLabel per language.\n    :rtype: A :class:`Label` or `None` if no label could be found.\n    '''\n    if not labels:\n        return None\n    if not language:\n        language = 'und'\n    labels = [dict_to_label(l) for l in labels]\n    l = False\n    if sortLabel:\n        l = find_best_label_for_type(labels, language, 'sortLabel')\n    if not l:\n        l = find_best_label_for_type(labels, language, 'prefLabel')\n    if not l:\n        l = find_best_label_for_type(labels, language, 'altLabel')\n    if l:\n        return l\n    else:\n        return label(labels, 'any', sortLabel) if language != 'any' else None", "response": "Returns a new IANA label for a list of labels."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_best_label_for_type(labels, language, labeltype):\n    '''\n    Find the best label for a certain labeltype.\n\n    :param list labels: A list of :class:`Label`.\n    :param str language: An IANA language string, eg. `nl` or `nl-BE`.\n    :param str labeltype: Type of label to look for, eg. `prefLabel`.\n    '''\n    typelabels = [l for l in labels if l.type == labeltype]\n    if not typelabels:\n        return False\n    if language == 'any':\n        return typelabels[0]\n    exact = filter_labels_by_language(typelabels, language)\n    if exact:\n        return exact[0]\n    inexact = filter_labels_by_language(typelabels, language, True)\n    if inexact:\n        return inexact[0]\n    return False", "response": "Find the best label for a certain labeltype."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfilters a list of labels leaving only labels of a certain language.", "response": "def filter_labels_by_language(labels, language, broader=False):\n    '''\n    Filter a list of labels, leaving only labels of a certain language.\n\n    :param list labels: A list of :class:`Label`.\n    :param str language: An IANA language string, eg. `nl` or `nl-BE`.\n    :param boolean broader: When true, will also match `nl-BE` when filtering\n        on `nl`. When false, only exact matches are considered.\n    '''\n    if language == 'any':\n        return labels\n    if broader:\n        language = tags.tag(language).language.format\n        return [l for l in labels if tags.tag(l.language).language.format == language]\n    else:\n        language = tags.tag(language).format\n        return [l for l in labels if tags.tag(l.language).format == language]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntransforming a dict with keys label type and language into a .", "response": "def dict_to_label(dict):\n    '''\n    Transform a dict with keys `label`, `type` and `language` into a\n    :class:`Label`.\n\n    Only the `label` key is mandatory. If `type` is not present, it will\n    default to `prefLabel`. If `language` is not present, it will default\n    to `und`.\n\n    If the argument passed is not a dict, this method just\n    returns the argument.\n    '''\n    try:\n        return Label(\n            dict['label'],\n            dict.get('type', 'prefLabel'),\n            dict.get('language', 'und')\n        )\n    except (KeyError, AttributeError, TypeError):\n        return dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntransforming a dict with keys note type language and markup into a", "response": "def dict_to_note(dict):\n    '''\n    Transform a dict with keys `note`, `type` and `language` into a\n    :class:`Note`.\n\n    Only the `note` key is mandatory. If `type` is not present, it will\n    default to `note`. If `language` is not present, it will default to `und`.\n    If `markup` is not present it will default to `None`.\n\n    If the argument passed is already a :class:`Note`, this method just returns\n    the argument.\n    '''\n    if isinstance(dict, Note):\n        return dict\n    return Note(\n        dict['note'],\n        dict.get('type', 'note'),\n        dict.get('language', 'und'),\n        dict.get('markup')\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntransforming a dict with key citation into a Source.", "response": "def dict_to_source(dict):\n    '''\n    Transform a dict with key 'citation' into a :class:`Source`.\n\n    If the argument passed is already a :class:`Source`, this method just\n    returns the argument.\n    '''\n\n    if isinstance(dict, Source):\n        return dict\n    return Source(\n        dict['citation'],\n        dict.get('markup')\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a single sortkey for this conceptscheme.", "response": "def _sortkey(self, key='uri', language='any'):\n        '''\n        Provide a single sortkey for this conceptscheme.\n\n        :param string key: Either `uri`, `label` or `sortlabel`.\n        :param string language: The preferred language to receive the label in\n            if key is `label` or `sortlabel`. This should be a valid IANA language tag.\n        :rtype: :class:`str`\n        '''\n        if key == 'uri':\n            return self.uri\n        else:\n            l = label(self.labels, language, key == 'sortlabel')\n            return l.label.lower() if l else ''"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates over instantiated managers.", "response": "def _iterate_managers(connection, skip):\n    \"\"\"Iterate over instantiated managers.\"\"\"\n    for idx, name, manager_cls in _iterate_manage_classes(skip):\n        if name in skip:\n            continue\n\n        try:\n            manager = manager_cls(connection=connection)\n        except TypeError as e:\n            click.secho(f'Could not instantiate {name}: {e}', fg='red')\n        else:\n            yield idx, name, manager"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef summarize(connection, skip):\n    for idx, name, manager in _iterate_managers(connection, skip):\n        click.secho(name, fg='cyan', bold=True)\n        if not manager.is_populated():\n            click.echo('\ud83d\udc4e unpopulated')\n            continue\n\n        if isinstance(manager, BELNamespaceManagerMixin):\n            click.secho(f'Terms: {manager._count_model(manager.namespace_model)}', fg='green')\n\n        if isinstance(manager, BELManagerMixin):\n            try:\n                click.secho(f'Relations: {manager.count_relations()}', fg='green')\n            except TypeError as e:\n                click.secho(str(e), fg='red')\n        for field_name, count in sorted(manager.summarize().items()):\n            click.echo(\n                click.style('=> ', fg='white', bold=True) + f\"{field_name.replace('_', ' ').capitalize()}: {count}\"\n            )", "response": "Summarize all available resources."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sheet(connection, skip, file: TextIO):\n    from tabulate import tabulate\n    header = ['', 'Name', 'Description', 'Terms', 'Relations']\n    rows = []\n\n    for i, (idx, name, manager) in enumerate(_iterate_managers(connection, skip), start=1):\n        try:\n            if not manager.is_populated():\n                continue\n        except AttributeError:\n            click.secho(f'{name} does not implement is_populated', fg='red')\n            continue\n\n        terms, relations = None, None\n        if isinstance(manager, BELNamespaceManagerMixin):\n            terms = manager._count_model(manager.namespace_model)\n\n        if isinstance(manager, BELManagerMixin):\n            try:\n                relations = manager.count_relations()\n            except TypeError as e:\n                relations = str(e)\n\n        rows.append((i, name, manager.__doc__.split('\\n')[0].strip().strip('.'), terms, relations))\n\n    print(tabulate(\n        rows,\n        headers=header,\n        # tablefmt=\"fancy_grid\",\n    ))", "response": "Generate a summary sheet."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write(connection, skip, directory, force):\n    os.makedirs(directory, exist_ok=True)\n    from .manager.namespace_manager import BELNamespaceManagerMixin\n    for idx, name, manager in _iterate_managers(connection, skip):\n        if not (isinstance(manager, AbstractManager) and isinstance(manager, BELNamespaceManagerMixin)):\n            continue\n        click.secho(name, fg='cyan', bold=True)\n        if force:\n            try:\n                click.echo(f'dropping')\n                manager.drop_all()\n                click.echo('clearing cache')\n                clear_cache(name)\n                click.echo('populating')\n                manager.populate()\n            except Exception:\n                click.secho(f'{name} failed', fg='red')\n                continue\n\n        try:\n            r = manager.write_directory(directory)\n        except TypeError as e:\n            click.secho(f'error with {name}: {e}'.rstrip(), fg='red')\n        else:\n            if not r:\n                click.echo('no update')", "response": "Write a BEL namespace names to terminology store."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(connection, skip, directory, force):\n    os.makedirs(directory, exist_ok=True)\n    from .manager.bel_manager import BELManagerMixin\n    import pybel\n    for idx, name, manager in _iterate_managers(connection, skip):\n        if not isinstance(manager, BELManagerMixin):\n            continue\n        click.secho(name, fg='cyan', bold=True)\n        path = os.path.join(directory, f'{name}.bel.pickle')\n        if os.path.exists(path) and not force:\n            click.echo('\ud83d\udc4d already exported')\n            continue\n\n        if not manager.is_populated():\n            click.echo('\ud83d\udc4e unpopulated')\n        else:\n            graph = manager.to_bel()\n            pybel.to_pickle(graph, path)\n            pybel.to_json_path(graph, os.path.join(directory, f'{name}.bel.json'))", "response": "Write all BEL objects in a directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef web(connection, host, port):\n    from bio2bel.web.application import create_application\n    app = create_application(connection=connection)\n    app.run(host=host, port=port)", "response": "Run a combine web interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_cli_to_bel(main: click.Group) -> click.Group:  # noqa: D202\n\n    @main.command()\n    @click.option('-o', '--output', type=click.File('w'), default=sys.stdout)\n    @click.option('-f', '--fmt', default='bel', show_default=True, help='BEL export format')\n    @click.pass_obj\n    def write(manager: BELManagerMixin, output: TextIO, fmt: str):\n        \"\"\"Write as BEL Script.\"\"\"\n        graph = manager.to_bel()\n        graph.serialize(file=output, fmt=fmt)\n        click.echo(graph.summary_str())\n\n    return main", "response": "Add several command to main click function related to export to BEL."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds several commands to main click function related to export to BEL Commons.", "response": "def add_cli_upload_bel(main: click.Group) -> click.Group:  # noqa: D202\n    \"\"\"Add several command to main :mod:`click` function related to export to BEL.\"\"\"\n\n    @main.command()\n    @host_option\n    @click.pass_obj\n    def upload(manager: BELManagerMixin, host: str):\n        \"\"\"Upload BEL to BEL Commons.\"\"\"\n        graph = manager.to_bel()\n        pybel.to_web(graph, host=host, public=True)\n\n    return main"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncounting the number of BEL relations generated.", "response": "def count_relations(self) -> int:\n        \"\"\"Count the number of BEL relations generated.\"\"\"\n        if self.edge_model is ...:\n            raise Bio2BELMissingEdgeModelError('edge_edge model is undefined/count_bel_relations is not overridden')\n        elif isinstance(self.edge_model, list):\n            return sum(self._count_model(m) for m in self.edge_model)\n        else:\n            return self._count_model(self.edge_model)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_indra_statements(self, *args, **kwargs):\n        graph = self.to_bel(*args, **kwargs)\n        return to_indra_statements(graph)", "response": "Dump this object as INDRA statements."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_cli(cls) -> click.Group:\n        main = super().get_cli()\n\n        @main.group()\n        def bel():\n            \"\"\"Manage BEL.\"\"\"\n\n        cls._cli_add_to_bel(bel)\n        cls._cli_add_upload_bel(bel)\n\n        return main", "response": "Get a click. Group that adds added BEL commands to the BEL."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _convert_coordinatelist(input_obj):\n    cdl = pgmagick.CoordinateList()\n    for obj in input_obj:\n        cdl.append(pgmagick.Coordinate(obj[0], obj[1]))\n    return cdl", "response": "convert from list or tuple object to pgmagick. CoordinateList"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts from list or tuple object to pgmagick. VPathList", "response": "def _convert_vpathlist(input_obj):\n    \"\"\"convert from 'list' or 'tuple' object to pgmagick.VPathList.\n\n    :type input_obj: list or tuple\n    \"\"\"\n    vpl = pgmagick.VPathList()\n    for obj in input_obj:\n        # FIXME\n        obj = pgmagick.PathMovetoAbs(pgmagick.Coordinate(obj[0], obj[1]))\n        vpl.append(obj)\n    return vpl"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_exif_info(self):\n        _dict = {}\n        for tag in _EXIF_TAGS:\n            ret = self.img.attribute(\"EXIF:%s\" % tag)\n            if ret and ret != 'unknown':\n                _dict[tag] = ret\n        return _dict", "response": "return exif - tag dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndraw a Bezier curve.", "response": "def bezier(self, points):\n        \"\"\"Draw a Bezier-curve.\n\n        :param points: ex.) ((5, 5), (6, 6), (7, 7))\n        :type points: list\n        \"\"\"\n        coordinates = pgmagick.CoordinateList()\n        for point in points:\n            x, y = float(point[0]), float(point[1])\n            coordinates.append(pgmagick.Coordinate(x, y))\n        self.drawer.append(pgmagick.DrawableBezier(coordinates))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a color to the drawing", "response": "def color(self, x, y, paint_method):\n        \"\"\"\n        :param paint_method: 'point' or 'replace' or 'floodfill' or\n                             'filltoborder' or 'reset'\n        :type paint_method: str or pgmagick.PaintMethod\n        \"\"\"\n        paint_method = _convert_paintmethod(paint_method)\n        color = pgmagick.DrawableColor(x, y, paint_method)\n        self.drawer.append(color)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd an ellipse to the drawable", "response": "def ellipse(self, org_x, org_y, radius_x, radius_y, arc_start, arc_end):\n        \"\"\"\n        :param org_x: origination x axis\n        :param org_y: origination y axis\n        :param radius_x: radius x axis\n        :param radius_y: radius y axis\n        :param arc_start: arc start angle\n        :param arc_end: arc end angle\n        \"\"\"\n        ellipse = pgmagick.DrawableEllipse(float(org_x), float(org_y),\n                                           float(radius_x), float(radius_y),\n                                           float(arc_start), float(arc_end))\n        self.drawer.append(ellipse)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an opacity to the drawable", "response": "def fill_opacity(self, opacity):\n        \"\"\"\n        :param opacity: 0.0 ~ 1.0\n        \"\"\"\n        opacity = pgmagick.DrawableFillOpacity(float(opacity))\n        self.drawer.append(opacity)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef matte(self, x, y, paint_method):\n        paint_method = _convert_paintmethod(paint_method)\n        self.drawer.append(pgmagick.DrawableMatte(x, y, paint_method))", "response": "add a new darker drawable to the list of available drawers"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nscale Draw Object :param x: 0.0 ~ 1.0 :param y: 0.0 ~ 1.0", "response": "def scaling(self, x, y):\n        \"\"\"Scaling Draw Object\n\n        :param x: 0.0 ~ 1.0\n        :param y: 0.0 ~ 1.0\n        \"\"\"\n        self.drawer.append(pgmagick.DrawableScaling(float(x), float(y)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstrokes antialias on the current node", "response": "def stroke_antialias(self, flag=True):\n        \"\"\"stroke antialias\n\n        :param flag: True or False. (default is True)\n        :type flag: bool\n        \"\"\"\n        antialias = pgmagick.DrawableStrokeAntialias(flag)\n        self.drawer.append(antialias)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stroke_linecap(self, linecap):\n        linecap = getattr(pgmagick.LineCap, \"%sCap\" % linecap.title())\n        linecap = pgmagick.DrawableStrokeLineCap(linecap)\n        self.drawer.append(linecap)", "response": "set to stroke linecap. linecap is defined as a string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting to stroke linejoin. linejoin can be undefined miter round bevel", "response": "def stroke_linejoin(self, linejoin):\n        \"\"\"set to stroke linejoin.\n\n        :param linejoin: 'undefined', 'miter', 'round', 'bevel'\n        :type linejoin: str\n        \"\"\"\n        linejoin = getattr(pgmagick.LineJoin, \"%sJoin\" % linejoin.title())\n        linejoin = pgmagick.DrawableStrokeLineJoin(linejoin)\n        self.drawer.append(linejoin)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef text_antialias(self, flag=True):\n        antialias = pgmagick.DrawableTextAntialias(flag)\n        self.drawer.append(antialias)", "response": "text antialias is a wrapper around pgmagick. DrawableTextAntialias"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef text_decoration(self, decoration):\n        if decoration.lower() == 'linethrough':\n            d = pgmagick.DecorationType.LineThroughDecoration\n        else:\n            decoration_type_string = \"%sDecoration\" % decoration.title()\n            d = getattr(pgmagick.DecorationType, \"%s\" % decoration_type_string)\n        decoration = pgmagick.DrawableTextDecoration(d)\n        self.drawer.append(decoration)", "response": "text decoration\n            is no underline overline linethrough is no"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_version_from_pc(search_dirs, target):\n    for dirname in search_dirs:\n        for root, dirs, files in os.walk(dirname):\n            for f in files:\n                if f == target:\n                    file_path = os.path.join(root, target)\n                    _tmp = _grep(\"Version: \", file_path)\n                    version = _tmp.split()[1]\n                    print(\"Found version %s in file %s\" % (version, file_path))\n                    return version", "response": "get version from pc file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning whether given library version supports given API version.", "response": "def library_supports_api(library_version, api_version, different_major_breaks_support=True):\n    \"\"\"\n    Returns whether api_version is supported by given library version.\n    E. g.  library_version (1,3,21) returns True for api_version (1,3,21), (1,3,19), (1,3,'x'), (1,2,'x'), (1, 'x')\n           False for (1,3,24), (1,4,'x'), (2,'x')\n\n    different_major_breaks_support - if enabled and library and api major versions are different always return False\n           ex) with library_version (2,0,0) and for api_version(1,3,24) returns False if enabled, True if disabled\n    \"\"\"\n    assert isinstance(library_version, (tuple, list))  # won't work with e.g. generators\n    assert len(library_version) == 3\n    sequence_type = type(library_version)  # assure we will compare same types\n    api_version = sequence_type(0 if num == 'x' else num for num in api_version)\n    if different_major_breaks_support and library_version[0] != api_version[0]:\n        return False\n    assert len(api_version) <= 3     # otherwise following comparision won't work as intended, e.g. (2, 0, 0) > (2, 0, 0, 0)\n    return library_version >= api_version"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of accepting roles.", "response": "def get_roles_request(request):\n    \"\"\"Returns a list of accepting roles.\"\"\"\n    uuid_ = request.matchdict['uuid']\n    user_id = request.matchdict.get('uid')\n\n    args = [uuid_]\n    if user_id is not None:\n        fmt_conditional = \"AND user_id = %s\"\n        args.append(user_id)\n    else:\n        fmt_conditional = \"\"\n\n    with db_connect() as db_conn:\n        with db_conn.cursor() as cursor:\n            cursor.execute(\"\"\"\\\nSELECT row_to_json(combined_rows) FROM (\nSELECT uuid, user_id AS uid, role_type AS role, accepted AS has_accepted\nFROM role_acceptances AS la\nWHERE uuid = %s {}\nORDER BY user_id ASC, role_type ASC\n) as combined_rows\"\"\".format(fmt_conditional), args)\n            acceptances = [r[0] for r in cursor.fetchall()]\n\n            if not acceptances:\n                if user_id is not None:\n                    raise httpexceptions.HTTPNotFound()\n                else:\n                    cursor.execute(\"\"\"\\\nSELECT TRUE FROM document_controls WHERE uuid = %s\"\"\", (uuid_,))\n                    try:\n                        cursor.fetchone()[0]\n                    except TypeError:  # NoneType\n                        raise httpexceptions.HTTPNotFound()\n\n    resp_value = acceptances\n    if user_id is not None:\n        resp_value = acceptances[0]\n    return resp_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_roles_request(request):\n    uuid_ = request.matchdict['uuid']\n\n    posted_roles = request.json\n    with db_connect() as db_conn:\n        with db_conn.cursor() as cursor:\n            remove_role_requests(cursor, uuid_, posted_roles)\n\n    resp = request.response\n    resp.status_int = 200\n    return resp", "response": "Submission to remove a role acceptance request."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the ACL for the given content identified by uuid.", "response": "def get_acl(request):\n    \"\"\"Returns the ACL for the given content identified by ``uuid``.\"\"\"\n    uuid_ = request.matchdict['uuid']\n\n    with db_connect() as db_conn:\n        with db_conn.cursor() as cursor:\n            cursor.execute(\"\"\"\\\nSELECT TRUE FROM document_controls WHERE uuid = %s\"\"\", (uuid_,))\n            try:\n                # Check that it exists\n                cursor.fetchone()[0]\n            except TypeError:\n                raise httpexceptions.HTTPNotFound()\n            cursor.execute(\"\"\"\\\nSELECT row_to_json(combined_rows) FROM (\nSELECT uuid, user_id AS uid, permission\nFROM document_acl AS acl\nWHERE uuid = %s\nORDER BY user_id ASC, permission ASC\n) as combined_rows\"\"\", (uuid_,))\n            acl = [r[0] for r in cursor.fetchall()]\n\n    return acl"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef post_acl_request(request):\n    uuid_ = request.matchdict['uuid']\n\n    posted = request.json\n    permissions = [(x['uid'], x['permission'],) for x in posted]\n    with db_connect() as db_conn:\n        with db_conn.cursor() as cursor:\n            cursor.execute(\"\"\"\\\nSELECT TRUE FROM document_controls WHERE uuid = %s::UUID\"\"\", (uuid_,))\n            try:\n                # Check that it exists\n                cursor.fetchone()[0]\n            except TypeError:\n                if request.has_permission('publish.create-identifier'):\n                    cursor.execute(\"\"\"\\\nINSERT INTO document_controls (uuid) VALUES (%s)\"\"\", (uuid_,))\n                else:\n                    raise httpexceptions.HTTPNotFound()\n            upsert_acl(cursor, uuid_, permissions)\n\n    resp = request.response\n    resp.status_int = 202\n    return resp", "response": "Submission to create an ACL."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_acl_request(request):\n    uuid_ = request.matchdict['uuid']\n\n    posted = request.json\n    permissions = [(x['uid'], x['permission'],) for x in posted]\n    with db_connect() as db_conn:\n        with db_conn.cursor() as cursor:\n            remove_acl(cursor, uuid_, permissions)\n\n    resp = request.response\n    resp.status_int = 200\n    return resp", "response": "Submission to remove an ACL."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef processor():  # pragma: no cover\n    registry = get_current_registry()\n    settings = registry.settings\n    connection_string = settings[CONNECTION_STRING]\n    channels = _get_channels(settings)\n\n    # Code adapted from\n    # http://initd.org/psycopg/docs/advanced.html#asynchronous-notifications\n    with psycopg2.connect(connection_string) as conn:\n        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n\n        with conn.cursor() as cursor:\n            for channel in channels:\n                cursor.execute('LISTEN {}'.format(channel))\n                logger.debug('Waiting for notifications on channel \"{}\"'\n                             .format(channel))\n\n        registry.notify(ChannelProcessingStartUpEvent())\n\n        rlist = [conn]  # wait until ready for reading\n        wlist = []  # wait until ready for writing\n        xlist = []  # wait for an \"exceptional condition\"\n        timeout = 5\n\n        while True:\n            if select.select(rlist, wlist, xlist, timeout) != ([], [], []):\n                conn.poll()\n                while conn.notifies:\n                    notif = conn.notifies.pop(0)\n                    logger.debug('Got NOTIFY: pid={} channel={} payload={}'\n                                 .format(notif.pid, notif.channel,\n                                         notif.payload))\n                    event = create_pg_notify_event(notif)\n                    try:\n                        registry.notify(event)\n                    except Exception:\n                        logger.exception('Logging an uncaught exception')", "response": "This function is used to run the asynchronous notifications on the configured channels."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a dbapi cursor lookup all the api keys and their information.", "response": "def lookup_api_key_info():\n    \"\"\"Given a dbapi cursor, lookup all the api keys and their information.\"\"\"\n    info = {}\n    with db_connect() as conn:\n        with conn.cursor() as cursor:\n            cursor.execute(ALL_KEY_INFO_SQL_STMT)\n            for row in cursor.fetchall():\n                id, key, name, groups = row\n                user_id = \"api_key:{}\".format(id)\n                info[key] = dict(id=id, user_id=user_id,\n                                 name=name, groups=groups)\n    return info"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef includeme(config):\n    api_key_authn_policy = APIKeyAuthenticationPolicy()\n    config.include('openstax_accounts')\n    openstax_authn_policy = config.registry.getUtility(\n        IOpenstaxAccountsAuthenticationPolicy)\n\n    # Set up api & user authentication policies.\n    policies = [api_key_authn_policy, openstax_authn_policy]\n    authn_policy = MultiAuthenticationPolicy(policies)\n    config.set_authentication_policy(authn_policy)\n\n    # Set up the authorization policy.\n    authz_policy = ACLAuthorizationPolicy()\n    config.set_authorization_policy(authz_policy)", "response": "Configuration include fuction for this module"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef expandvars_dict(settings):\n    return dict(\n        (key, os.path.expandvars(value))\n        for key, value in settings.iteritems()\n    )", "response": "Expands all environment variables in a settings dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize the Sentry service with the current app s Sentry_DSN.", "response": "def initialize_sentry_integration():  # pragma: no cover\n    \"\"\"\\\n    Used to optionally initialize the Sentry service with this app.\n    See https://docs.sentry.io/platforms/python/pyramid/\n\n    \"\"\"\n    # This function is not under coverage because it is boilerplate\n    # from the Sentry documentation.\n    try:\n        import sentry_sdk\n        from sentry_sdk.integrations.pyramid import PyramidIntegration\n        from sentry_sdk.integrations.celery import CeleryIntegration\n    except ImportError:\n        warnings.warn(\n            \"Sentry is not configured because the Sentry SDK \"\n            \"(sentry_sdk package) is not installed\",\n            UserWarning,\n        )\n        return  # bail out early\n\n    try:\n        dsn = os.environ['SENTRY_DSN']\n    except KeyError:\n        warnings.warn(\n            \"Sentry is not configured because SENTRY_DSN \"\n            \"was not supplied.\",\n            UserWarning,\n        )\n    else:\n        sentry_sdk.init(\n            dsn=dsn,\n            integrations=[PyramidIntegration(), CeleryIntegration()],\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef task(**kwargs):\n\n    def wrapper(wrapped):\n\n        def callback(scanner, name, obj):\n            celery_app = scanner.config.registry.celery_app\n            celery_app.task(**kwargs)(obj)\n\n        venusian.attach(wrapped, callback)\n        return wrapped\n\n    return wrapper", "response": "A function task decorator used in place of celery_app. task."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _make_celery_app(config):\n    # Tack the pyramid config on the celery app for later use.\n    config.registry.celery_app.conf['pyramid_config'] = config\n    return config.registry.celery_app", "response": "This function creates a celery app that is used to run pyramid tasks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing post - publication events coming out of the database.", "response": "def post_publication_processing(event, cursor):\n    \"\"\"Process post-publication events coming out of the database.\"\"\"\n    module_ident, ident_hash = event.module_ident, event.ident_hash\n\n    celery_app = get_current_registry().celery_app\n\n    # Check baking is not already queued.\n    cursor.execute('SELECT result_id::text '\n                   'FROM document_baking_result_associations '\n                   'WHERE module_ident = %s', (module_ident,))\n    for result in cursor.fetchall():\n        state = celery_app.AsyncResult(result[0]).state\n        if state in ('QUEUED', 'STARTED', 'RETRY'):\n            logger.debug('Already queued module_ident={} ident_hash={}'.format(\n                module_ident, ident_hash))\n            return\n\n    logger.debug('Queued for processing module_ident={} ident_hash={}'.format(\n        module_ident, ident_hash))\n    recipe_ids = _get_recipe_ids(module_ident, cursor)\n    update_module_state(cursor, module_ident, 'processing', recipe_ids[0])\n    # Commit the state change before preceding.\n    cursor.connection.commit()\n\n    # Start of task\n    # FIXME Looking up the task isn't the most clear usage here.\n    task_name = 'cnxpublishing.subscribers.baking_processor'\n    baking_processor = celery_app.tasks[task_name]\n    result = baking_processor.delay(module_ident, ident_hash)\n    baking_processor.backend.store_result(result.id, None, 'QUEUED')\n\n    # Save the mapping between a celery task and this event.\n    track_baking_proc_state(result, module_ident, cursor)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_archive_uri(uri):\n    parsed = urlparse(uri)\n    path = parsed.path.rstrip('/').split('/')\n    ident_hash = path[-1]\n    ident_hash = unquote(ident_hash)\n    return ident_hash", "response": "Given an archive URI parse to a split ident - hash."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef declare_api_routes(config):\n    add_route = config.add_route\n    add_route('get-content', '/contents/{ident_hash}')\n    add_route('get-resource', '/resources/{hash}')\n\n    # User actions API\n    add_route('license-request', '/contents/{uuid}/licensors')\n    add_route('roles-request', '/contents/{uuid}/roles')\n    add_route('acl-request', '/contents/{uuid}/permissions')\n\n    # Publishing API\n    add_route('publications', '/publications')\n    add_route('get-publication', '/publications/{id}')\n    add_route('publication-license-acceptance',\n              '/publications/{id}/license-acceptances/{uid}')\n    add_route('publication-role-acceptance',\n              '/publications/{id}/role-acceptances/{uid}')\n    # TODO (8-May-12017) Remove because the term collate is being phased out.\n    add_route('collate-content', '/contents/{ident_hash}/collate-content')\n    add_route('bake-content', '/contents/{ident_hash}/baked')\n\n    # Moderation routes\n    add_route('moderation', '/moderations')\n    add_route('moderate', '/moderations/{id}')\n    add_route('moderation-rss', '/feeds/moderations.rss')\n\n    # API Key routes\n    add_route('api-keys', '/api-keys')\n    add_route('api-key', '/api-keys/{id}')", "response": "Declare the routes for the API."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef declare_browsable_routes(config):\n    # This makes our routes slashed, which is good browser behavior.\n    config.add_notfound_view(default_exceptionresponse_view,\n                             append_slash=True)\n\n    add_route = config.add_route\n    add_route('admin-index', '/a/')\n    add_route('admin-moderation', '/a/moderation/')\n    add_route('admin-api-keys', '/a/api-keys/')\n    add_route('admin-add-site-messages', '/a/site-messages/',\n              request_method='GET')\n    add_route('admin-add-site-messages-POST', '/a/site-messages/',\n              request_method='POST')\n    add_route('admin-delete-site-messages', '/a/site-messages/',\n              request_method='DELETE')\n    add_route('admin-edit-site-message', '/a/site-messages/{id}/',\n              request_method='GET')\n    add_route('admin-edit-site-message-POST', '/a/site-messages/{id}/',\n              request_method='POST')\n\n    add_route('admin-content-status', '/a/content-status/')\n    add_route('admin-content-status-single', '/a/content-status/{uuid}')\n\n    add_route('admin-print-style', '/a/print-style/')\n    add_route('admin-print-style-single', '/a/print-style/{style}')", "response": "Declare the routes that can be browsed by users."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _formatter_callback_factory():  # pragma: no cover\n    includes = []\n    exercise_url_template = '{baseUrl}/api/exercises?q={field}:\"{{itemCode}}\"'\n    settings = get_current_registry().settings\n    exercise_base_url = settings.get('embeddables.exercise.base_url', None)\n    exercise_matches = [match.split(',', 1) for match in aslist(\n        settings.get('embeddables.exercise.match', ''), flatten=False)]\n    exercise_token = settings.get('embeddables.exercise.token', None)\n    mathml_url = settings.get('mathmlcloud.url', None)\n    memcache_servers = settings.get('memcache_servers')\n    if memcache_servers:\n        memcache_servers = memcache_servers.split()\n    else:\n        memcache_servers = None\n\n    if exercise_base_url and exercise_matches:\n        mc_client = None\n        if memcache_servers:\n            mc_client = memcache.Client(memcache_servers, debug=0)\n        for (exercise_match, exercise_field) in exercise_matches:\n            template = exercise_url_template.format(\n                baseUrl=exercise_base_url, field=exercise_field)\n            includes.append(exercise_callback_factory(exercise_match,\n                                                      template,\n                                                      mc_client,\n                                                      exercise_token,\n                                                      mathml_url))\n    return includes", "response": "Returns a list of includes to be given to cnxepub. collation. collate."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbake the contents and persist those changes alongside the published content.", "response": "def bake(binder, recipe_id, publisher, message, cursor):\n    \"\"\"Given a `Binder` as `binder`, bake the contents and\n    persist those changes alongside the published content.\n\n    \"\"\"\n    recipe = _get_recipe(recipe_id, cursor)\n    includes = _formatter_callback_factory()\n    binder = collate_models(binder, ruleset=recipe, includes=includes)\n\n    def flatten_filter(model):\n        return (isinstance(model, cnxepub.CompositeDocument) or\n                (isinstance(model, cnxepub.Binder) and\n                 model.metadata.get('type') == 'composite-chapter'))\n\n    def only_documents_filter(model):\n        return isinstance(model, cnxepub.Document) \\\n            and not isinstance(model, cnxepub.CompositeDocument)\n\n    for doc in cnxepub.flatten_to(binder, flatten_filter):\n        publish_composite_model(cursor, doc, binder, publisher, message)\n\n    for doc in cnxepub.flatten_to(binder, only_documents_filter):\n        publish_collated_document(cursor, doc, binder)\n\n    tree = cnxepub.model_to_tree(binder)\n    publish_collated_tree(cursor, tree)\n\n    return []"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef volcano(differential_dfs, title='Axial Volcano Plot', scripts_mode=\"CDN\", data_mode=\"directory\",\n            organism=\"human\", q_value_column_name=\"q\", log2FC_column_name=\"logFC\",\n            output_dir=\".\", filename=\"volcano.html\", version=this_version):\n    \"\"\"\n    Arguments:\n        differential_dfs (dict or pandas.DataFrame): python dict of names to pandas dataframes, or a single dataframe, indexed by gene symbols which must have columns named log2FC and qval.\n        title (str): The title of the plot (to be embedded in the html).\n        scripts_mode (str): Choose from [`\"CDN\"`, `\"directory\"`, `\"inline\"`]:\n\n            - `\"CDN\"` compiles a single HTML page with links to scripts hosted on a CDN,\n\n            - `\"directory\"` compiles a directory with all scripts locally cached,\n\n            - `\"inline\"` compiles a single HTML file with all scripts/styles inlined.\n\n        data_mode (str): Choose from [\"directory\", \"inline\"]:\n\n            - \"directory\" compiles a directory with all data locally cached,\n\n            - \"inline\" compiles a single HTML file with all data inlined.\n\n        organism (str): `\"human\"` or `\"mouse\"`\n        q_value_column_name (str):\n        log2FC_column_name (str):\n        output_dir (str): the directory in which to output the file\n        filename (str): the filename of the output file\n        version (str): the version of the javascripts to use.\n            Leave the default to pin the version, or choose \"latest\" to get updates,\n            or choose part of the version string to get minor updates.\n    Returns:\n        Path: The filepath which the html was outputted to.\n    \"\"\"\n\n    output_dir = Path(output_dir)\n    output_dir.mkdir(exist_ok=True, parents=True)\n\n    # Data   =======================\n\n    if isinstance(differential_dfs, pd.DataFrame):\n        differential_dfs = {'differential': differential_dfs}\n\n    for name, df in differential_dfs.items():\n        df = df[[q_value_column_name, log2FC_column_name]]\n        df.columns = ['q', 'logFC']\n        df = df.round(2)\n        # TODO drop all zero rows\n        _verify_differential_df(df)\n\n        del differential_dfs[name]\n        differential_dfs[_sanitize(name)] = df\n\n    names_and_differentials = f\"var names_and_differentials = { '{'+ ','.join([_quote(name)+': '+df.to_json(orient='index') for name, df in differential_dfs.items()]) +'}' };\"\n\n    data_block = _data_block(data_mode, [('names_and_differentials', names_and_differentials)], output_dir, include_gene_sets=False, organism=organism)\n\n    # Scripts =======================\n\n    scripts = third_party_scripts + [CDN_url(version)+\"js/util.js\", CDN_url(version)+\"js/GOrilla.js\", CDN_url(version)+\"js/volcano.js\"]\n\n    scripts_block = _scripts_block(scripts, scripts_mode, output_dir)\n\n\n    html = templateEnv.get_template('volcano.html.j2').render(title=title, scripts_block=scripts_block+'\\n'+data_block, organism=\"HOMO_SAPIENS\")\n\n    (output_dir / filename).write_text(html)\n\n\n    return (output_dir / filename).resolve()", "response": "Generate a new volcano file from a differential plot."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a heatmap from a dataframe indexed by genes and sample attributes.", "response": "def heatmap(genes_by_samples_matrix, sample_attributes, title='Axial Heatmap', scripts_mode=\"CDN\", data_mode=\"directory\",\n            organism=\"human\", separate_zscore_by=[\"system\"],\n            output_dir=\".\", filename=\"heatmap.html\", version=this_version):\n    \"\"\"\n    Arguments:\n        genes_by_samples_matrix (pandas.DataFrame): dataframe indexed by genes, columns are samples\n        sample_attributes (pandas.DataFrame): dataframe indexed by samples, columns are sample attributes (e.g. classes)\n        title (str): The title of the plot (to be embedded in the html).\n        scripts_mode (str): Choose from [`\"CDN\"`, `\"directory\"`, `\"inline\"`]:\n\n            - `\"CDN\"` compiles a single HTML page with links to scripts hosted on a CDN,\n\n            - `\"directory\"` compiles a directory with all scripts locally cached,\n\n            - `\"inline\"` compiles a single HTML file with all scripts/styles inlined.\n\n        data_mode (str): Choose from [\"directory\", \"inline\"]:\n\n            - \"directory\" compiles a directory with all data locally cached,\n\n            - \"inline\" compiles a single HTML file with all data inlined.\n\n        organism (str): `\"human\"` or `\"mouse\"`\n        separate_zscore_by (list):\n        output_dir (str): the directory in which to output the file\n        filename (str): the filename of the output file\n        version (str): the version of the javascripts to use.\n            Leave the default to pin the version, or choose \"latest\" to get updates,\n            or choose part of the version string to get minor updates.\n    Returns:\n        Path: The filepath which the html was outputted to.\n    \"\"\"\n\n\n    output_dir = Path(output_dir)\n    output_dir.mkdir(exist_ok=True, parents=True)\n\n    # Data   =======================\n\n    _verify_sample_by_genes_matrix(genes_by_samples_matrix)\n    _verify_sample_attributes(genes_by_samples_matrix, sample_attributes)\n    genes_by_samples_matrix = genes_by_samples_matrix.round(2)\n    # TODO drop all zero rows\n\n    matrix = f\"var matrix = {genes_by_samples_matrix.to_json(orient='columns')};\"\n    classes = f\"var classes = {sample_attributes.to_json(orient='index')};\"\n\n    data_block = _data_block(data_mode, [('matrix', matrix), ('classes', classes)], output_dir, organism=organism)\n\n    # Scripts =======================\n\n    scripts = third_party_scripts + [CDN_url(version)+\"js/util.js\", CDN_url(version)+\"js/reorder.js\", CDN_url(version)+\"js/heatmap.js\"]\n\n    scripts_block = _scripts_block(scripts, scripts_mode, output_dir)\n\n\n    html = templateEnv.get_template('heatmap.html.j2').render(title=title, scripts_block=scripts_block+'\\n'+data_block, separate_zscore_by=separate_zscore_by)\n\n    (output_dir / filename).write_text(html)\n\n\n    return (output_dir / filename).resolve()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef graph(networkx_graph, title='Axial Graph Visualization', scripts_mode=\"CDN\", data_mode=\"directory\",\n          output_dir=\".\", filename=\"graph.html\", version=this_version):\n    \"\"\"\n    Arguments:\n        networkx_graph (networkx.Graph): any instance of networkx.Graph\n        title (str): The title of the plot (to be embedded in the html).\n        scripts_mode (str): Choose from [`\"CDN\"`, `\"directory\"`, `\"inline\"`]:\n\n            - `\"CDN\"` compiles a single HTML page with links to scripts hosted on a CDN,\n\n            - `\"directory\"` compiles a directory with all scripts locally cached,\n\n            - `\"inline\"` compiles a single HTML file with all scripts/styles inlined.\n\n        data_mode (str): Choose from [\"directory\", \"inline\"]:\n\n            - \"directory\" compiles a directory with all data locally cached,\n\n            - \"inline\" compiles a single HTML file with all data inlined.\n\n        output_dir (str): the directory in which to output the file\n        filename (str): the filename of the output file\n        version (str): the version of the javascripts to use.\n            Leave the default to pin the version, or choose \"latest\" to get updates,\n            or choose part of the version string to get minor updates.\n    Returns:\n        Path: The filepath which the html was outputted to.\n    \"\"\"\n\n    output_dir = Path(output_dir)\n    output_dir.mkdir(exist_ok=True, parents=True)\n\n    # Scripts =======================\n\n    scripts = third_party_scripts + [CDN_url(version)+\"js/cola.min.js\", CDN_url(version)+\"js/graph.js\"]\n\n    scripts_block = _scripts_block(scripts, scripts_mode, output_dir)\n\n    # Data    =======================\n\n    graph_json = nx_json.node_link_data(networkx_graph)\n\n    for node in graph_json['nodes']:\n        for attr, val in node.items():\n            if isinstance(val, numbers.Number):\n                node[attr] = round(val, 2)\n    for link in graph_json['links']:\n        for attr, val in link.items():\n            if isinstance(val, numbers.Number):\n                link[attr] = round(val, 2)\n\n    graph_json = f\"var graph = {json.dumps(graph_json)};\"\n\n    data_block = _data_block(data_mode, [('graph', graph_json)], output_dir)\n\n    html = templateEnv.get_template('graph.html.j2').render(title=title, scripts_block=scripts_block+'\\n'+data_block, nodes=networkx_graph.nodes())\n\n    (output_dir / filename).write_text(html)\n\n    return (output_dir / filename).resolve()", "response": "A function that generates the HTML for a single page of a graph."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef db_connect(connection_string=None, **kwargs):\n    if connection_string is None:\n        connection_string = get_current_registry().settings[CONNECTION_STRING]\n    db_conn = psycopg2.connect(connection_string, **kwargs)\n    try:\n        with db_conn:\n            yield db_conn\n    finally:\n        db_conn.close()", "response": "Function to supply a database connection object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef with_db_cursor(func):\n\n    @functools.wraps(func)\n    def wrapped(*args, **kwargs):\n        if 'cursor' in kwargs or func.func_code.co_argcount == len(args):\n            return func(*args, **kwargs)\n        with db_connect() as db_connection:\n            with db_connection.cursor() as cursor:\n                kwargs['cursor'] = cursor\n                return func(*args, **kwargs)\n\n    return wrapped", "response": "Decorator that supplies a cursor to the function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _role_type_to_db_type(type_):\n    with db_connect() as db_conn:\n        with db_conn.cursor() as cursor:\n            cursor.execute(\"\"\"\\\nWITH unnested_role_types AS (\n  SELECT unnest(enum_range(NULL::role_types)) as role_type\n  ORDER BY role_type ASC)\nSELECT array_agg(role_type)::text[] FROM unnested_role_types\"\"\")\n            db_types = cursor.fetchone()[0]\n    return dict(zip(cnxepub.ATTRIBUTED_ROLE_KEYS, db_types))[type_]", "response": "Translates a role type to a database compatible\n    value for role_types."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a model s metadata iterate over the roles.", "response": "def _dissect_roles(metadata):\n    \"\"\"Given a model's ``metadata``, iterate over the roles.\n    Return values are the role identifier and role type as a tuple.\n    \"\"\"\n    for role_key in cnxepub.ATTRIBUTED_ROLE_KEYS:\n        for user in metadata.get(role_key, []):\n            if user['type'] != 'cnx-id':\n                raise ValueError(\"Archive only accepts Connexions users.\")\n            uid = parse_user_uri(user['id'])\n            yield uid, role_key\n    raise StopIteration()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates or insert records for pending license acceptors.", "response": "def upsert_pending_licensors(cursor, document_id):\n    \"\"\"Update or insert records for pending license acceptors.\"\"\"\n    cursor.execute(\"\"\"\\\nSELECT \"uuid\", \"metadata\"\nFROM pending_documents\nWHERE id = %s\"\"\", (document_id,))\n    uuid_, metadata = cursor.fetchone()\n    acceptors = set([uid for uid, type_ in _dissect_roles(metadata)])\n\n    # Acquire a list of existing acceptors.\n    cursor.execute(\"\"\"\\\nSELECT \"user_id\", \"accepted\"\nFROM license_acceptances\nWHERE uuid = %s\"\"\", (uuid_,))\n    existing_acceptors_mapping = dict(cursor.fetchall())\n\n    # Who's not in the existing list?\n    existing_acceptors = set(existing_acceptors_mapping.keys())\n    new_acceptors = acceptors.difference(existing_acceptors)\n\n    # Insert the new licensor acceptors.\n    for acceptor in new_acceptors:\n        cursor.execute(\"\"\"\\\nINSERT INTO license_acceptances\n  (\"uuid\", \"user_id\", \"accepted\")\nVALUES (%s, %s, NULL)\"\"\", (uuid_, acceptor,))\n\n    # Has everyone already accepted?\n    cursor.execute(\"\"\"\\\nSELECT user_id\nFROM license_acceptances\nWHERE\n  uuid = %s\n  AND\n  (accepted is UNKNOWN OR accepted is FALSE)\"\"\", (uuid_,))\n    defectors = set(cursor.fetchall())\n\n    if not defectors:\n        # Update the pending document license acceptance state.\n        cursor.execute(\"\"\"\\\nupdate pending_documents set license_accepted = 't'\nwhere id = %s\"\"\", (document_id,))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate or insert records for pending document role acceptance.", "response": "def upsert_pending_roles(cursor, document_id):\n    \"\"\"Update or insert records for pending document role acceptance.\"\"\"\n    cursor.execute(\"\"\"\\\nSELECT \"uuid\", \"metadata\"\nFROM pending_documents\nWHERE id = %s\"\"\", (document_id,))\n    uuid_, metadata = cursor.fetchone()\n\n    acceptors = set([(uid, _role_type_to_db_type(type_),)\n                     for uid, type_ in _dissect_roles(metadata)])\n\n    # Upsert the user info.\n    upsert_users(cursor, [x[0] for x in acceptors])\n\n    # Acquire a list of existing acceptors.\n    cursor.execute(\"\"\"\\\nSELECT user_id, role_type\nFROM role_acceptances\nWHERE uuid = %s\"\"\", (uuid_,))\n    existing_roles = set([(r, t,) for r, t in cursor.fetchall()])\n\n    # Who's not in the existing list?\n    existing_acceptors = existing_roles\n    new_acceptors = acceptors.difference(existing_acceptors)\n\n    # Insert the new role acceptors.\n    for acceptor, type_ in new_acceptors:\n        cursor.execute(\"\"\"\\\nINSERT INTO role_acceptances\n  (\"uuid\", \"user_id\", \"role_type\", \"accepted\")\n        VALUES (%s, %s, %s, DEFAULT)\"\"\", (uuid_, acceptor, type_))\n\n    # Has everyone already accepted?\n    cursor.execute(\"\"\"\\\nSELECT user_id\nFROM role_acceptances\nWHERE\n  uuid = %s\n  AND\n  (accepted is UNKNOWN OR accepted is FALSE)\"\"\", (uuid_,))\n    defectors = set(cursor.fetchall())\n\n    if not defectors:\n        # Update the pending document license acceptance state.\n        cursor.execute(\"\"\"\\\nupdate pending_documents set roles_accepted = 't'\nwhere id = %s\"\"\", (document_id,))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef obtain_licenses():\n    with db_connect() as db_conn:\n        with db_conn.cursor() as cursor:\n            cursor.execute(\"\"\"\\\nSELECT combined_row.url, row_to_json(combined_row) FROM (\n  SELECT \"code\", \"version\", \"name\", \"url\", \"is_valid_for_publication\"\n  FROM licenses) AS combined_row\"\"\")\n            licenses = {r[0]: r[1] for r in cursor.fetchall()}\n    return licenses", "response": "Obtain the licenses in a dictionary form keyed by url."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _validate_license(model):\n    license_mapping = obtain_licenses()\n    try:\n        license_url = model.metadata['license_url']\n    except KeyError:\n        raise exceptions.MissingRequiredMetadata('license_url')\n    try:\n        license = license_mapping[license_url]\n    except KeyError:\n        raise exceptions.InvalidLicense(license_url)\n    if not license['is_valid_for_publication']:\n        raise exceptions.InvalidLicense(license_url)", "response": "Given the model check the license is one valid for publication."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates that all the metadata roles in the given model have valid information in them.", "response": "def _validate_roles(model):\n    \"\"\"Given the model, check that all the metadata role values\n    have valid information in them and any required metadata fields\n    contain values.\n    \"\"\"\n    required_roles = (ATTRIBUTED_ROLE_KEYS[0], ATTRIBUTED_ROLE_KEYS[4],)\n    for role_key in ATTRIBUTED_ROLE_KEYS:\n        try:\n            roles = model.metadata[role_key]\n        except KeyError:\n            if role_key in required_roles:\n                raise exceptions.MissingRequiredMetadata(role_key)\n        else:\n            if role_key in required_roles and len(roles) == 0:\n                raise exceptions.MissingRequiredMetadata(role_key)\n        for role in roles:\n            if role.get('type') != 'cnx-id':\n                raise exceptions.InvalidRole(role_key, role)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating that the derived_from_uri is correctly set.", "response": "def _validate_derived_from(cursor, model):\n    \"\"\"Given a database cursor and model, check the derived-from\n    value accurately points to content in the archive.\n    The value can be nothing or must point to existing content.\n    \"\"\"\n    derived_from_uri = model.metadata.get('derived_from_uri')\n    if derived_from_uri is None:\n        return  # bail out early\n\n    # Can we parse the value?\n    try:\n        ident_hash = parse_archive_uri(derived_from_uri)\n        uuid_, version = split_ident_hash(ident_hash, split_version=True)\n    except (ValueError, IdentHashSyntaxError, IdentHashShortId) as exc:\n        raise exceptions.InvalidMetadata('derived_from_uri', derived_from_uri,\n                                         original_exception=exc)\n    # Is the ident-hash a valid pointer?\n    args = [uuid_]\n    table = 'modules'\n    version_condition = ''\n    if version != (None, None,):\n        args.extend(version)\n        table = 'modules'\n        version_condition = \" AND major_version = %s\" \\\n                            \" AND minor_version {} %s\" \\\n                            .format(version[1] is None and 'is' or '=')\n    cursor.execute(\"\"\"SELECT 't' FROM {} WHERE uuid::text = %s{}\"\"\"\n                   .format(table, version_condition), args)\n    try:\n        _exists = cursor.fetchone()[0]  # noqa\n    except TypeError:  # None type\n        raise exceptions.InvalidMetadata('derived_from_uri', derived_from_uri)\n\n    # Assign the derived_from value so that we don't have to split it again.\n    model.metadata['derived_from'] = ident_hash"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck the subjects against the subject vocabulary.", "response": "def _validate_subjects(cursor, model):\n    \"\"\"Give a database cursor and model, check the subjects against\n    the subject vocabulary.\n    \"\"\"\n    subject_vocab = [term[0] for term in acquire_subject_vocabulary(cursor)]\n    subjects = model.metadata.get('subjects', [])\n    invalid_subjects = [s for s in subjects if s not in subject_vocab]\n    if invalid_subjects:\n        raise exceptions.InvalidMetadata('subjects', invalid_subjects)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating the model using a series of checks on bits of the data.", "response": "def validate_model(cursor, model):\n    \"\"\"Validates the model using a series of checks on bits of the data.\"\"\"\n    # Check the license is one valid for publication.\n    _validate_license(model)\n    _validate_roles(model)\n\n    # Other required metadata includes: title, summary\n    required_metadata = ('title', 'summary',)\n    for metadata_key in required_metadata:\n        if model.metadata.get(metadata_key) in [None, '', []]:\n            raise exceptions.MissingRequiredMetadata(metadata_key)\n\n    # Ensure that derived-from values are either None\n    # or point at a live record in the archive.\n    _validate_derived_from(cursor, model)\n\n    # FIXME Valid language code?\n\n    # Are the given 'subjects'\n    _validate_subjects(cursor, model)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the given publisher of this publication is allowed to publish the content given by uuid.", "response": "def is_publication_permissible(cursor, publication_id, uuid_):\n    \"\"\"Check the given publisher of this publication given\n    by ``publication_id`` is allowed to publish the content given\n    by ``uuid``.\n    \"\"\"\n    # Check the publishing user has permission to publish\n    cursor.execute(\"\"\"\\\nSELECT 't'::boolean\nFROM\n  pending_documents AS pd\n  NATURAL JOIN document_acl AS acl\n  JOIN publications AS p ON (pd.publication_id = p.id)\nWHERE\n  p.id = %s\n  AND\n  pd.uuid = %s\n  AND\n  p.publisher = acl.user_id\n  AND\n  acl.permission = 'publish'\"\"\", (publication_id, uuid_,))\n    try:\n        is_allowed = cursor.fetchone()[0]\n    except TypeError:\n        is_allowed = False\n    return is_allowed"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_pending_model(cursor, publication_id, model):\n    # FIXME Too much happening here...\n    assert isinstance(model, (cnxepub.Document, cnxepub.Binder,)), type(model)\n    uri = model.get_uri('cnx-archive')\n\n    if uri is not None:\n        ident_hash = parse_archive_uri(uri)\n        id, version = split_ident_hash(ident_hash, split_version=True)\n        cursor.execute(\"\"\"\\\nSELECT major_version + 1 as next_version\nFROM latest_modules\nWHERE uuid = %s\nUNION ALL\nSELECT 1 as next_version\nORDER BY next_version DESC\nLIMIT 1\n\"\"\", (id,))\n        next_major_version = cursor.fetchone()[0]\n        if isinstance(model, cnxepub.Document):\n            version = (next_major_version, None,)\n        else:  # ...assume it's a binder.\n            version = (next_major_version, 1,)\n    else:\n        cursor.execute(\"\"\"\\\nWITH\ncontrol_insert AS (\n  INSERT INTO document_controls (uuid) VALUES (DEFAULT) RETURNING uuid),\nacl_insert AS (\n  INSERT INTO document_acl (uuid, user_id, permission)\n  VALUES ((SELECT uuid FROM control_insert),\n          (SELECT publisher FROM publications WHERE id = %s),\n          'publish'::permission_type))\nSELECT uuid FROM control_insert\"\"\", (publication_id,))\n        id = cursor.fetchone()[0]\n        if isinstance(model, cnxepub.Document):\n            version = (1, None,)\n        else:  # ...assume it's a binder.\n            version = (1, 1,)\n\n    type_ = _get_type_name(model)\n    model.id = str(id)\n    model.metadata['version'] = '.'.join([str(v) for v in version if v])\n    args = [publication_id, id, version[0], version[1], type_,\n            json.dumps(model.metadata)]\n    cursor.execute(\"\"\"\\\nINSERT INTO \"pending_documents\"\n  (\"publication_id\", \"uuid\", \"major_version\", \"minor_version\", \"type\",\n    \"license_accepted\", \"roles_accepted\", \"metadata\")\nVALUES (%s, %s, %s, %s, %s, 'f', 'f', %s)\nRETURNING \"id\", \"uuid\", module_version(\"major_version\", \"minor_version\")\n\"\"\", args)\n    pending_id, uuid_, version = cursor.fetchone()\n    pending_ident_hash = join_ident_hash(uuid_, version)\n\n    # Assign the new ident-hash to the document for later use.\n    request = get_current_request()\n    path = request.route_path('get-content', ident_hash=pending_ident_hash)\n    model.set_uri('cnx-archive', path)\n\n    # Check if the publication is allowed for the publishing user.\n    if not is_publication_permissible(cursor, publication_id, id):\n        # Set the failure but continue the operation of inserting\n        # the pending document.\n        exc = exceptions.NotAllowed(id)\n        exc.publication_id = publication_id\n        exc.pending_document_id = pending_id\n        exc.pending_ident_hash = pending_ident_hash\n        set_publication_failure(cursor, exc)\n\n    try:\n        validate_model(cursor, model)\n    except exceptions.PublicationException as exc:\n        exc_info = sys.exc_info()\n        exc.publication_id = publication_id\n        exc.pending_document_id = pending_id\n        exc.pending_ident_hash = pending_ident_hash\n        try:\n            set_publication_failure(cursor, exc)\n        except BaseException:\n            import traceback\n            print(\"Critical data error. Immediate attention is \"\n                  \"required. On publication at '{}'.\"\n                  .format(publication_id),\n                  file=sys.stderr)\n            # Print the critical exception.\n            traceback.print_exc()\n            # Raise the previous exception, so we know the original cause.\n            raise exc_info[0], exc_info[1], exc_info[2]\n    else:\n        upsert_pending_licensors(cursor, pending_id)\n        upsert_pending_roles(cursor, pending_id)\n        notify_users(cursor, pending_id)\n    return pending_ident_hash", "response": "Adds a pending model that is awaiting publication\n    to the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_pending_model_content(cursor, publication_id, model):\n    cursor.execute(\"\"\"\\\n        SELECT id, ident_hash(uuid, major_version, minor_version)\n        FROM pending_documents\n        WHERE publication_id = %s AND uuid = %s\"\"\",\n                   (publication_id, model.id,))\n    document_info = cursor.fetchone()\n\n    def attach_info_to_exception(exc):\n        \"\"\"Small cached function to grab the pending document id\n        and hash to attach to the exception, which is useful when\n        reading the json data on a response.\n        \"\"\"\n        exc.publication_id = publication_id\n        exc.pending_document_id, exc.pending_ident_hash = document_info\n\n    def mark_invalid_reference(reference):\n        \"\"\"Set the publication to failure and attach invalid reference\n        to the publication.\n        \"\"\"\n        exc = exceptions.InvalidReference(reference)\n        attach_info_to_exception(exc)\n        set_publication_failure(cursor, exc)\n\n    for resource in getattr(model, 'resources', []):\n        add_pending_resource(cursor, resource, document=model)\n\n    if isinstance(model, cnxepub.Document):\n        for reference in model.references:\n            if reference.is_bound:\n                reference.bind(reference.bound_model, '/resources/{}')\n            elif reference.remote_type == cnxepub.INTERNAL_REFERENCE_TYPE:\n                if reference.uri.startswith('#'):\n                    pass\n                elif reference.uri.startswith('/contents'):\n                    ident_hash = parse_archive_uri(reference.uri)\n                    try:\n                        doc_pointer = lookup_document_pointer(\n                            ident_hash, cursor)\n                    except DocumentLookupError:\n                        mark_invalid_reference(reference)\n                    else:\n                        reference.bind(doc_pointer, \"/contents/{}\")\n                else:\n                    mark_invalid_reference(reference)\n            # else, it's a remote or cnx.org reference ...Do nothing.\n\n        args = (psycopg2.Binary(model.content.encode('utf-8')),\n                publication_id, model.id,)\n        stmt = \"\"\"\\\n            UPDATE \"pending_documents\"\n            SET (\"content\") = (%s)\n            WHERE \"publication_id\" = %s AND \"uuid\" = %s\"\"\"\n    else:\n        metadata = model.metadata.copy()\n        # All document pointers in the tree are valid?\n        document_pointers = [m for m in cnxepub.flatten_model(model)\n                             if isinstance(m, cnxepub.DocumentPointer)]\n        document_pointer_ident_hashes = [\n            (split_ident_hash(dp.ident_hash)[0],\n             split_ident_hash(dp.ident_hash, split_version=True)[1][0],\n             split_ident_hash(dp.ident_hash, split_version=True)[1][1],)\n            #  split_ident_hash(dp.ident_hash, split_version=True)[1][0],)\n            for dp in document_pointers]\n        document_pointer_ident_hashes = zip(*document_pointer_ident_hashes)\n\n        if document_pointers:\n            uuids, major_vers, minor_vers = document_pointer_ident_hashes\n            cursor.execute(\"\"\"\\\nSELECT dp.uuid, module_version(dp.maj_ver, dp.min_ver) AS version,\n       dp.uuid = m.uuid AS exists,\n       m.portal_type = 'Module' AS is_document\nFROM (SELECT unnest(%s::uuid[]), unnest(%s::integer[]), unnest(%s::integer[]))\\\n         AS dp(uuid, maj_ver, min_ver)\n     LEFT JOIN modules AS m ON dp.uuid = m.uuid AND \\\n         (dp.maj_ver = m.major_version OR dp.maj_ver is null)\"\"\",\n                           (list(uuids), list(major_vers), list(minor_vers),))\n            valid_pointer_results = cursor.fetchall()\n            for result_row in valid_pointer_results:\n                uuid, version, exists, is_document = result_row\n                if not (exists and is_document):\n                    dp = [dp for dp in document_pointers\n                          if dp.ident_hash == join_ident_hash(uuid, version)\n                          ][0]\n                    exc = exceptions.InvalidDocumentPointer(\n                        dp, exists=exists, is_document=is_document)\n                    attach_info_to_exception(exc)\n                    set_publication_failure(cursor, exc)\n\n        # Insert the tree into the metadata.\n        metadata['_tree'] = cnxepub.model_to_tree(model)\n        args = (json.dumps(metadata),\n                None,  # TODO Render the HTML tree at ``model.content``.\n                publication_id, model.id,)\n        # Must pave over metadata because postgresql lacks built-in\n        # json update functions.\n        stmt = \"\"\"\\\n            UPDATE \"pending_documents\"\n            SET (\"metadata\", \"content\") = (%s, %s)\n            WHERE \"publication_id\" = %s AND \"uuid\" = %s\"\"\"\n    cursor.execute(stmt, args)", "response": "Adds the pending model s content to the pending model s content."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_publication_failure(cursor, exc):\n    publication_id = exc.publication_id\n    if publication_id is None:\n        raise ValueError(\"Exception must have a ``publication_id`` value.\")\n    cursor.execute(\"\"\"\\\nSELECT \"state_messages\"\nFROM publications\nWHERE id = %s\"\"\", (publication_id,))\n    state_messages = cursor.fetchone()[0]\n    if state_messages is None:\n        state_messages = []\n    entry = exc.__dict__\n    entry['message'] = exc.message\n    state_messages.append(entry)\n    state_messages = json.dumps(state_messages)\n    cursor.execute(\"\"\"\\\nUPDATE publications SET (\"state\", \"state_messages\") = (%s, %s)\nWHERE id = %s\"\"\", ('Failed/Error', state_messages, publication_id,))", "response": "Sets the publication as failed and append the failure message to the publication record."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a publication entry and makes each item a pending document.", "response": "def add_publication(cursor, epub, epub_file, is_pre_publication=False):\n    \"\"\"Adds a publication entry and makes each item\n    a pending document.\n    \"\"\"\n    publisher = epub[0].metadata['publisher']\n    publish_message = epub[0].metadata['publication_message']\n    epub_binary = psycopg2.Binary(epub_file.read())\n    args = (publisher, publish_message, epub_binary, is_pre_publication,)\n    cursor.execute(\"\"\"\\\nINSERT INTO publications\n  (\"publisher\", \"publication_message\", \"epub\", \"is_pre_publication\")\nVALUES (%s, %s, %s, %s)\nRETURNING id\n\"\"\", args)\n    publication_id = cursor.fetchone()[0]\n    insert_mapping = {}\n\n    models = set([])\n    for package in epub:\n        binder = cnxepub.adapt_package(package)\n        if binder in models:\n            continue\n        for document in cnxepub.flatten_to_documents(binder):\n            if document not in models:\n                ident_hash = add_pending_model(\n                    cursor, publication_id, document)\n                insert_mapping[document.id] = ident_hash\n                models.add(document)\n        # The binding object could be translucent/see-through,\n        # (case for a binder that only contains loose-documents).\n        # Otherwise we should also publish the the binder.\n        if not binder.is_translucent:\n            ident_hash = add_pending_model(cursor, publication_id, binder)\n            insert_mapping[binder.id] = ident_hash\n            models.add(binder)\n    for model in models:\n        # Now that all models have been given an identifier\n        # we can write the content to the database.\n        try:\n            add_pending_model_content(cursor, publication_id, model)\n        except ResourceFileExceededLimitError as e:\n            e.publication_id = publication_id\n            set_publication_failure(cursor, e)\n    return publication_id, insert_mapping"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_pending_document_license_state(cursor, document_id):\n    cursor.execute(\"\"\"\\\nSELECT BOOL_AND(accepted IS TRUE)\nFROM\n  pending_documents AS pd,\n  license_acceptances AS la\nWHERE\n  pd.id = %s\n  AND\n  pd.uuid = la.uuid\"\"\",\n                   (document_id,))\n    try:\n        is_accepted = cursor.fetchone()[0]\n    except TypeError:\n        # There are no licenses associated with this document.\n        is_accepted = True\n    return is_accepted", "response": "Check the aggregate state on the pending document."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_pending_document_role_state(cursor, document_id):\n    cursor.execute(\"\"\"\\\nSELECT BOOL_AND(accepted IS TRUE)\nFROM\n  role_acceptances AS ra,\n  pending_documents as pd\nWHERE\n  pd.id = %s\n  AND\n  pd.uuid = ra.uuid\"\"\",\n                   (document_id,))\n    try:\n        is_accepted = cursor.fetchone()[0]\n    except TypeError:\n        # There are no roles to accept\n        is_accepted = True\n    return is_accepted", "response": "Check the aggregate state on the pending document."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the state of the pending document.", "response": "def _update_pending_document_state(cursor, document_id, is_license_accepted,\n                                   are_roles_accepted):\n    \"\"\"Update the state of the document's state values.\"\"\"\n    args = (bool(is_license_accepted), bool(are_roles_accepted),\n            document_id,)\n    cursor.execute(\"\"\"\\\nUPDATE pending_documents\nSET (license_accepted, roles_accepted) = (%s, %s)\nWHERE id = %s\"\"\",\n                   args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck to see if the publication contains any revised models.", "response": "def is_revision_publication(publication_id, cursor):\n    \"\"\"Checks to see if the publication contains any revised models.\n    Revised in this context means that it is a new version of an\n    existing piece of content.\n    \"\"\"\n    cursor.execute(\"\"\"\\\nSELECT 't'::boolean FROM modules\nWHERE uuid IN (SELECT uuid\n               FROM pending_documents\n               WHERE publication_id = %s)\nLIMIT 1\"\"\", (publication_id,))\n    try:\n        cursor.fetchone()[0]\n    except TypeError:  # NoneType\n        has_revision_models = False\n    else:\n        has_revision_models = True\n    return has_revision_models"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninvokes to update and acquire its current state. This is used to update the publication to archive.", "response": "def poke_publication_state(publication_id, cursor):\n    \"\"\"Invoked to poke at the publication to update and acquire its current\n    state. This is used to persist the publication to archive.\n    \"\"\"\n    cursor.execute(\"\"\"\\\nSELECT \"state\", \"state_messages\", \"is_pre_publication\", \"publisher\"\nFROM publications\nWHERE id = %s\"\"\", (publication_id,))\n    row = cursor.fetchone()\n    current_state, messages, is_pre_publication, publisher = row\n\n    if current_state in END_N_INTERIM_STATES:\n        # Bailout early, because the publication is either in progress\n        # or has been completed.\n        return current_state, messages\n\n    # Check for acceptance...\n    cursor.execute(\"\"\"\\\nSELECT\n  pd.id, license_accepted, roles_accepted\nFROM publications AS p JOIN pending_documents AS pd ON p.id = pd.publication_id\nWHERE p.id = %s\n\"\"\", (publication_id,))\n    pending_document_states = cursor.fetchall()\n    publication_state_mapping = {}\n    for document_state in pending_document_states:\n        id, is_license_accepted, are_roles_accepted = document_state\n        publication_state_mapping[id] = [is_license_accepted,\n                                         are_roles_accepted]\n        has_changed_state = False\n        if is_license_accepted and are_roles_accepted:\n            continue\n        if not is_license_accepted:\n            accepted = _check_pending_document_license_state(\n                cursor, id)\n            if accepted != is_license_accepted:\n                has_changed_state = True\n                is_license_accepted = accepted\n                publication_state_mapping[id][0] = accepted\n        if not are_roles_accepted:\n            accepted = _check_pending_document_role_state(\n                cursor, id)\n            if accepted != are_roles_accepted:\n                has_changed_state = True\n                are_roles_accepted = accepted\n                publication_state_mapping[id][1] = accepted\n        if has_changed_state:\n            _update_pending_document_state(cursor, id,\n                                           is_license_accepted,\n                                           are_roles_accepted)\n\n    # Are all the documents ready for publication?\n    state_lump = set([l and r for l, r in publication_state_mapping.values()])\n    is_publish_ready = not (False in state_lump) and not (None in state_lump)\n    change_state = \"Done/Success\"\n    if not is_publish_ready:\n        change_state = \"Waiting for acceptance\"\n\n    # Does this publication need moderation? (ignore on pre-publication)\n    # TODO Is this a revision publication? If so, it doesn't matter who the\n    #      user is, because they have been vetted by the previous publisher.\n    #      This has loopholes...\n    if not is_pre_publication and is_publish_ready:\n        # Has this publisher been moderated before?\n        cursor.execute(\"\"\"\\\nSELECT is_moderated\nFROM users AS u LEFT JOIN publications AS p ON (u.username = p.publisher)\nWHERE p.id = %s\"\"\",\n                       (publication_id,))\n        try:\n            is_publisher_moderated = cursor.fetchone()[0]\n        except TypeError:\n            is_publisher_moderated = False\n\n        # Are any of these documents a revision? Thus vetting of\n        #   the publisher was done by a vetted peer.\n        if not is_publisher_moderated \\\n           and not is_revision_publication(publication_id, cursor):\n            # Hold up! This publish needs moderation.\n            change_state = \"Waiting for moderation\"\n            is_publish_ready = False\n\n    # Publish the pending documents.\n    if is_publish_ready:\n        change_state = \"Done/Success\"\n        if not is_pre_publication:\n            publication_state = publish_pending(cursor, publication_id)\n        else:\n            cursor.execute(\"\"\"\\\nUPDATE publications\nSET state = %s\nWHERE id = %s\nRETURNING state, state_messages\"\"\", (change_state, publication_id,))\n            publication_state, messages = cursor.fetchone()\n    else:\n        # `change_state` set prior to this...\n        cursor.execute(\"\"\"\\\nUPDATE publications\nSET state = %s\nWHERE id = %s\nRETURNING state, state_messages\"\"\", (change_state, publication_id,))\n        publication_state, messages = cursor.fetchone()\n\n    return publication_state, messages"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks the publication s current state.", "response": "def check_publication_state(publication_id):\n    \"\"\"Check the publication's current state.\"\"\"\n    with db_connect() as db_conn:\n        with db_conn.cursor() as cursor:\n            cursor.execute(\"\"\"\\\nSELECT \"state\", \"state_messages\"\nFROM publications\nWHERE id = %s\"\"\", (publication_id,))\n            publication_state, publication_messages = cursor.fetchone()\n    return publication_state, publication_messages"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a tree parse to a set of models", "response": "def _node_to_model(tree_or_item, metadata=None, parent=None,\n                   lucent_id=cnxepub.TRANSLUCENT_BINDER_ID):\n    \"\"\"Given a tree, parse to a set of models\"\"\"\n    if 'contents' in tree_or_item:\n        # It is a binder.\n        tree = tree_or_item\n        binder = cnxepub.TranslucentBinder(metadata=tree)\n        for item in tree['contents']:\n            node = _node_to_model(item, parent=binder,\n                                  lucent_id=lucent_id)\n            if node.metadata['title'] != item['title']:\n                binder.set_title_for_node(node, item['title'])\n        result = binder\n    else:\n        # It is an item pointing at a document.\n        item = tree_or_item\n        result = cnxepub.DocumentPointer(item['id'], metadata=item)\n    if parent is not None:\n        parent.append(result)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _reassemble_binder(id, tree, metadata):\n    binder = cnxepub.Binder(id, metadata=metadata)\n    for item in tree['contents']:\n        node = _node_to_model(item, parent=binder)\n        if node.metadata['title'] != item['title']:\n            binder.set_title_for_node(node, item['title'])\n    return binder", "response": "Reassemble a Binder object coming out of the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite the pending documents to the *Connexions Archive*.", "response": "def publish_pending(cursor, publication_id):\n    \"\"\"Given a publication id as ``publication_id``,\n    write the documents to the *Connexions Archive*.\n    \"\"\"\n    cursor.execute(\"\"\"\\\nWITH state_update AS (\n  UPDATE publications SET state = 'Publishing' WHERE id = %s\n)\nSELECT publisher, publication_message\nFROM publications\nWHERE id = %s\"\"\",\n                   (publication_id, publication_id,))\n    publisher, message = cursor.fetchone()\n    cursor.connection.commit()\n\n    all_models = []\n\n    from .publish import publish_model\n    # Commit documents one at a time...\n    type_ = cnxepub.Document.__name__\n    cursor.execute(\"\"\"\\\nSELECT id, uuid, major_version, minor_version, metadata, content\nFROM pending_documents\nWHERE type = %s AND publication_id = %s\"\"\", (type_, publication_id,))\n    for row in cursor.fetchall():\n        # FIXME Oof, this is hideous!\n        id, major_version, minor_version = row[1:4]\n        id = str(id)\n        version = '.'.join([str(x)\n                            for x in (major_version, minor_version,)\n                            if x is not None])\n        metadata, content = row[-2:]\n        content = content[:]\n        metadata['version'] = version\n\n        document = cnxepub.Document(id, content, metadata)\n        for ref in document.references:\n            if ref.uri.startswith('/resources/'):\n                hash = ref.uri[len('/resources/'):]\n                cursor.execute(\"\"\"\\\nSELECT data, media_type\nFROM pending_resources\nWHERE hash = %s\"\"\", (hash,))\n                data, media_type = cursor.fetchone()\n                document.resources.append(cnxepub.Resource(\n                    hash, io.BytesIO(data[:]), media_type, filename=hash))\n\n        _ident_hash = publish_model(cursor, document, publisher, message)  # noqa\n        all_models.append(document)\n\n    # And now the binders, one at a time...\n    type_ = cnxepub.Binder.__name__\n    cursor.execute(\"\"\"\\\nSELECT id, uuid, major_version, minor_version, metadata, content\nFROM pending_documents\nWHERE type = %s AND publication_id = %s\"\"\", (type_, publication_id,))\n    for row in cursor.fetchall():\n        id, major_version, minor_version, metadata = row[1:5]\n        tree = metadata['_tree']\n        binder = _reassemble_binder(str(id), tree, metadata)\n        # Add the resources\n        cursor.execute(\"\"\"\\\nSELECT hash, data, media_type, filename\nFROM pending_resources r\nJOIN pending_resource_associations a ON a.resource_id = r.id\nJOIN pending_documents d ON a.document_id = d.id\nWHERE ident_hash(uuid, major_version, minor_version) = %s\"\"\",\n                       (binder.ident_hash,))\n        binder.resources = [\n            cnxepub.Resource(r_hash,\n                             io.BytesIO(r_data[:]),\n                             r_media_type,\n                             filename=r_filename)\n            for (r_hash, r_data, r_media_type, r_filename)\n            in cursor.fetchall()]\n        _ident_hash = publish_model(cursor, binder, publisher, message)  # noqa\n        all_models.append(binder)\n\n    # Republish binders containing shared documents.\n    from .publish import republish_binders\n    _republished_ident_hashes = republish_binders(cursor, all_models)  # noqa\n\n    # Lastly, update the publication status.\n    cursor.execute(\"\"\"\\\nUPDATE publications\nSET state = 'Done/Success'\nWHERE id = %s\nRETURNING state\"\"\", (publication_id,))\n    state = cursor.fetchone()[0]\n    return state"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\naccepts or deny the document license for the publication_id and user_id.", "response": "def accept_publication_license(cursor, publication_id, user_id,\n                               document_ids, is_accepted=False):\n    \"\"\"Accept or deny  the document license for the publication\n    (``publication_id``) and user (at ``user_id``)\n    for the documents (listed by id as ``document_ids``).\n    \"\"\"\n    cursor.execute(\"\"\"\\\nUPDATE license_acceptances AS la\nSET accepted = %s\nFROM pending_documents AS pd\nWHERE\n  pd.publication_id = %s\n  AND\n  la.user_id = %s\n  AND\n  pd.uuid = ANY(%s::UUID[])\n  AND\n  pd.uuid = la.uuid\"\"\",\n                   (is_accepted, publication_id, user_id, document_ids,))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\naccept or deny the document role attribution for the publication_id and user_id.", "response": "def accept_publication_role(cursor, publication_id, user_id,\n                            document_ids, is_accepted=False):\n    \"\"\"Accept or deny  the document role attribution for the publication\n    (``publication_id``) and user (at ``user_id``)\n    for the documents (listed by id as ``document_ids``).\n    \"\"\"\n    cursor.execute(\"\"\"\\\nUPDATE role_acceptances AS ra\nSET accepted = %s\nFROM pending_documents AS pd\nWHERE\n  pd.publication_id = %s\n  AND\n  ra.user_id = %s\n  AND\n  pd.uuid = ANY(%s::UUID[])\n  AND\n  pd.uuid = ra.uuid\"\"\",\n                   (is_accepted, publication_id, user_id, document_ids,))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef upsert_license_requests(cursor, uuid_, roles):\n    if not isinstance(roles, (list, set, tuple,)):\n        raise TypeError(\"``roles`` is an invalid type: {}\".format(type(roles)))\n\n    acceptors = set([x['uid'] for x in roles])\n\n    # Acquire a list of existing acceptors.\n    cursor.execute(\"\"\"\\\nSELECT user_id, accepted FROM license_acceptances WHERE uuid = %s\"\"\",\n                   (uuid_,))\n    existing_acceptors = cursor.fetchall()\n\n    # Who's not in the existing list?\n    new_acceptors = acceptors.difference([x[0] for x in existing_acceptors])\n\n    # Insert the new licensor acceptors.\n    if new_acceptors:\n        args = []\n        values_fmt = []\n        for uid in new_acceptors:\n            has_accepted = [x.get('has_accepted', None)\n                            for x in roles\n                            if uid == x['uid']][0]\n            args.extend([uuid_, uid, has_accepted])\n            values_fmt.append(\"(%s, %s, %s)\")\n        values_fmt = ', '.join(values_fmt)\n        cursor.execute(\"\"\"\\\nINSERT INTO license_acceptances (uuid, user_id, accepted)\nVALUES {}\"\"\".format(values_fmt), args)\n\n    # Update any existing license acceptors\n    acceptors = set([\n        (x['uid'], x.get('has_accepted', None),)\n        for x in roles\n        # Prevent updating newly inserted records.\n        if (x['uid'], x.get('has_accepted', None),) not in new_acceptors\n    ])\n    existing_acceptors = set([\n        x for x in existing_acceptors\n        # Prevent updating newly inserted records.\n        if x[0] not in new_acceptors\n    ])\n    tobe_updated_acceptors = acceptors.difference(existing_acceptors)\n\n    for uid, has_accepted in tobe_updated_acceptors:\n        cursor.execute(\"\"\"\\\nUPDATE license_acceptances SET accepted = %s\nWHERE uuid = %s AND user_id = %s\"\"\", (has_accepted, uuid_, uid,))", "response": "Insert or update license requests for a given uuid and list of roles."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a uuid and list of uids remove the identified users s license acceptance entries.", "response": "def remove_license_requests(cursor, uuid_, uids):\n    \"\"\"Given a ``uuid`` and list of ``uids`` (user identifiers)\n    remove the identified users' license acceptance entries.\n    \"\"\"\n    if not isinstance(uids, (list, set, tuple,)):\n        raise TypeError(\"``uids`` is an invalid type: {}\".format(type(uids)))\n\n    acceptors = list(set(uids))\n\n    # Remove the the entries.\n    cursor.execute(\"\"\"\\\nDELETE FROM license_acceptances\nWHERE uuid = %s AND user_id = ANY(%s::text[])\"\"\", (uuid_, acceptors,))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninserts or update a list of role requests.", "response": "def upsert_role_requests(cursor, uuid_, roles):\n    \"\"\"Given a ``uuid`` and list of dicts containing the ``uid`` and\n    ``role`` for creating a role acceptance entry. The ``roles`` dict\n    can optionally contain a ``has_accepted`` value, which will default\n    to true.\n    \"\"\"\n    if not isinstance(roles, (list, set, tuple,)):\n        raise TypeError(\"``roles`` is an invalid type: {}\"\n                        .format(type(roles)))\n\n    acceptors = set([(x['uid'], x['role'],) for x in roles])\n\n    # Acquire a list of existing acceptors.\n    cursor.execute(\"\"\"\\\nSELECT user_id, role_type, accepted\nFROM role_acceptances\nWHERE uuid = %s\"\"\", (uuid_,))\n    existing_roles = cursor.fetchall()\n\n    # Who's not in the existing list?\n    existing_acceptors = set([(r, t,) for r, t, _ in existing_roles])\n    new_acceptors = acceptors.difference(existing_acceptors)\n\n    # Insert the new role acceptors.\n    for acceptor, type_ in new_acceptors:\n        has_accepted = [x.get('has_accepted', None)\n                        for x in roles\n                        if acceptor == x['uid'] and type_ == x['role']][0]\n        cursor.execute(\"\"\"\\\nINSERT INTO role_acceptances (\"uuid\", \"user_id\", \"role_type\", \"accepted\")\nVALUES (%s, %s, %s, %s)\"\"\", (uuid_, acceptor, type_, has_accepted,))\n\n    # Update any existing license acceptors\n    acceptors = set([\n        (x['uid'], x['role'], x.get('has_accepted', None),)\n        for x in roles\n        # Prevent updating newly inserted records.\n        if (x['uid'], x.get('has_accepted', None),) not in new_acceptors\n    ])\n    existing_acceptors = set([\n        x for x in existing_roles\n        # Prevent updating newly inserted records.\n        if (x[0], x[1],) not in new_acceptors\n    ])\n    tobe_updated_acceptors = acceptors.difference(existing_acceptors)\n\n    for uid, type_, has_accepted in tobe_updated_acceptors:\n        cursor.execute(\"\"\"\\\nUPDATE role_acceptances SET accepted = %s\nWHERE uuid = %s AND user_id = %s AND role_type = %s\"\"\",\n                       (has_accepted, uuid_, uid, type_,))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving the role requests for the given user identifiers and role.", "response": "def remove_role_requests(cursor, uuid_, roles):\n    \"\"\"Given a ``uuid`` and list of dicts containing the ``uid``\n    (user identifiers) and ``role`` for removal of the identified\n    users' role acceptance entries.\n    \"\"\"\n    if not isinstance(roles, (list, set, tuple,)):\n        raise TypeError(\"``roles`` is an invalid type: {}\".format(type(roles)))\n\n    acceptors = set([(x['uid'], x['role'],) for x in roles])\n\n    # Remove the the entries.\n    for uid, role_type in acceptors:\n        cursor.execute(\"\"\"\\\nDELETE FROM role_acceptances\nWHERE uuid = %s AND user_id = %s AND role_type = %s\"\"\",\n                       (uuid_, uid, role_type,))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upsert_acl(cursor, uuid_, permissions):\n    if not isinstance(permissions, (list, set, tuple,)):\n        raise TypeError(\"``permissions`` is an invalid type: {}\"\n                        .format(type(permissions)))\n\n    permissions = set(permissions)\n\n    # Acquire the existin ACL.\n    cursor.execute(\"\"\"\\\nSELECT user_id, permission\nFROM document_acl\nWHERE uuid = %s\"\"\", (uuid_,))\n    existing = set([(r, t,) for r, t in cursor.fetchall()])\n\n    # Who's not in the existing list?\n    new_entries = permissions.difference(existing)\n\n    # Insert the new permissions.\n    for uid, permission in new_entries:\n        cursor.execute(\"\"\"\\\nINSERT INTO document_acl\n  (\"uuid\", \"user_id\", \"permission\")\nVALUES (%s, %s, %s)\"\"\", (uuid_, uid, permission))", "response": "Given a uuid and a set of permissions given as a\n    tuple of uid and permission upsert them into the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a uuid and a set of permissions remove these entries from the database.", "response": "def remove_acl(cursor, uuid_, permissions):\n    \"\"\"Given a ``uuid`` and a set of permissions given as a tuple\n    of ``uid`` and ``permission``, remove these entries from the database.\n    \"\"\"\n    if not isinstance(permissions, (list, set, tuple,)):\n        raise TypeError(\"``permissions`` is an invalid type: {}\"\n                        .format(type(permissions)))\n\n    permissions = set(permissions)\n\n    # Remove the the entries.\n    for uid, permission in permissions:\n        cursor.execute(\"\"\"\\\nDELETE FROM document_acl\nWHERE uuid = %s AND user_id = %s AND permission = %s\"\"\",\n                       (uuid_, uid, permission,))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef upsert_users(cursor, user_ids):\n    accounts = get_current_registry().getUtility(IOpenstaxAccounts)\n\n    def lookup_profile(username):\n        profile = accounts.get_profile_by_username(username)\n        # See structure documentation at:\n        #   https://<accounts-instance>/api/docs/v1/users/index\n        if profile is None:\n            raise UserFetchError(username)\n\n        opt_attrs = ('first_name', 'last_name', 'full_name',\n                     'title', 'suffix',)\n        for attr in opt_attrs:\n            profile.setdefault(attr, None)\n        return profile\n\n    _upsert_users(cursor, user_ids, lookup_profile)\n    _upsert_persons(cursor, user_ids, lookup_profile)", "response": "Given a set of user identifiers and a cursor that returns a new user record in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef notify_users(cursor, document_id):\n    return\n\n    registry = get_current_registry()\n    accounts = registry.getUtility(IOpenstaxAccounts)\n    cursor.execute(\"\"\"\\\nSELECT la.user_id\nFROM license_acceptances AS la\nWHERE\n  la.uuid = (SELECT uuid FROM pending_documents WHERE id = %s)\n  AND la.notified IS NULL AND (NOT la.accepted or la.accepted IS UNKNOWN)\n\"\"\", (document_id,))\n    licensors = [x[0] for x in cursor.fetchall()]\n\n    cursor.execute(\"\"\"\\\nSELECT user_id, array_agg(role_type)::text[]\nFROM role_acceptances AS ra\nWHERE\n  ra.uuid = (SELECT uuid FROM pending_documents WHERE id = %s)\n  AND ra.notified IS NULL AND (NOT ra.accepted or ra.accepted IS UNKNOWN)\nGROUP BY user_id\n\"\"\", (document_id,))\n    roles = {u: r for u, r in cursor.fetchall()}\n\n    needs_notified = set(licensors + roles.keys())\n\n    for user_id in needs_notified:\n        data = {\n            'user_id': user_id,\n            'full_name': None,  # TODO\n            'licensor': user_id in licensors,\n            'roles': roles.get(user_id, []),\n        }\n        message = NOTIFICATION_TEMPLATE.render(**data)\n        accounts.send_message(user_id, NOFIFICATION_SUBJECT, message)\n\n    cursor.execute(\"\"\"\\\nUPDATE license_acceptances SET notified = CURRENT_TIMESTAMP\nWHERE\n  uuid = (SELECT uuid FROM pending_documents WHERE id = %s)\n  AND user_id = ANY (%s)\"\"\", (document_id, licensors,))\n    # FIXME overwrites notified for all roles types a user might have.\n    cursor.execute(\"\"\"\\\nUPDATE role_acceptances SET notified = CURRENT_TIMESTAMP\nWHERE\n  uuid = (SELECT uuid FROM pending_documents WHERE id = %s)\n  AND user_id = ANY (%s)\"\"\", (document_id, roles.keys(),))", "response": "Notify all users about their role and license acceptance for a piece of content associated with the given document_id."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_post_publications_state(cursor, module_ident, state_name,\n                                state_message=''):  # pragma: no cover\n    \"\"\"This sets the post-publication state in the database.\"\"\"\n    cursor.execute(\"\"\"\\\nINSERT INTO post_publications\n  (module_ident, state, state_message)\n  VALUES (%s, %s, %s)\"\"\", (module_ident, state_name, state_message))", "response": "This function sets the post - publication state in the database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_moderation(request):\n    with db_connect() as db_conn:\n        with db_conn.cursor() as cursor:\n            cursor.execute(\"\"\"\\\nSELECT row_to_json(combined_rows) FROM (\n  SELECT id, created, publisher, publication_message,\n         (select array_agg(row_to_json(pd))\n          from pending_documents as pd\n          where pd.publication_id = p.id) AS models\n  FROM publications AS p\n  WHERE state = 'Waiting for moderation') AS combined_rows\"\"\")\n            moderations = [x[0] for x in cursor.fetchall()]\n\n    return moderations", "response": "Return the list of publications that need moderation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef includeme(config):\n    settings = config.registry.settings\n    session_factory = SignedCookieSessionFactory(settings['session_key'])\n    config.set_session_factory(session_factory)", "response": "Configures the session manager"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef admin_print_styles(request):\n    styles = []\n    # This fetches all recipes that have been used to successfully bake a\n    # current book plus all default recipes that have not yet been used\n    # as well as \"bad\" books that are not \"current\" state, but would otherwise\n    # be the latest/current for that book\n    with db_connect(cursor_factory=DictCursor) as db_conn:\n        with db_conn.cursor() as cursor:\n            cursor.execute(\"\"\"\\\n                WITH latest AS (SELECT print_style, recipe,\n                    count(*), count(nullif(stateid, 1)) as bad\n                FROM modules m\n                WHERE portal_type = 'Collection'\n                      AND recipe IS NOT NULL\n                      AND (\n                          baked IS NOT NULL OR (\n                              baked IS NULL AND stateid not in (1,8)\n                              )\n                          )\n                      AND ARRAY [major_version, minor_version] = (\n                          SELECT max(ARRAY[major_version,minor_version]) FROM\n                              modules where m.uuid= uuid)\n\n                GROUP BY print_style, recipe\n                ),\n                defaults AS (SELECT print_style, fileid AS recipe\n                FROM default_print_style_recipes d\n                WHERE not exists (SELECT 1\n                                  FROM latest WHERE latest.recipe = d.fileid)\n                )\n                SELECT coalesce(ps.print_style, '(custom)') as print_style,\n                       ps.title, coalesce(ps.recipe_type, 'web') as type,\n                       ps.revised, ps.tag, ps.commit_id, la.count, la.bad\n                FROM latest la LEFT JOIN print_style_recipes ps ON\n                                    la.print_style = ps.print_style AND\n                                    la.recipe = ps.fileid\n                UNION ALL\n                SELECT ps.print_style, ps.title, ps.recipe_type,\n                       ps.revised, ps.tag, ps.commit_id, 0 AS count, 0 AS bad\n                FROM defaults de JOIN print_style_recipes ps ON\n                                    de.print_style = ps.print_style AND\n                                    de.recipe = ps.fileid\n\n            ORDER BY revised desc NULLS LAST, print_style\n\n                \"\"\")\n            for row in cursor.fetchall():\n                styles.append({\n                    'print_style': row['print_style'],\n                    'title': row['title'],\n                    'type': row['type'],\n                    'revised': row['revised'],\n                    'tag': row['tag'],\n                    'commit_id': row['commit_id'],\n                    'number': row['count'],\n                    'bad': row['bad'],\n                    'link': request.route_path('admin-print-style-single',\n                                               style=row['print_style'])\n                })\n    return {'styles': styles}", "response": "Returns a dictionary of all unique print_styles and their latest tag revision and recipe_type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all books with any version of the given print style.", "response": "def admin_print_styles_single(request):\n    \"\"\" Returns all books with any version of the given print style.\n\n    Returns the print_style, recipe type, num books using the print_style,\n    along with a dictionary of the book, author, revision date, recipe,\n    tag of the print_style, and a link to the content.\n    \"\"\"\n    style = request.matchdict['style']\n    # do db search to get file id and other info on the print_style\n    with db_connect(cursor_factory=DictCursor) as db_conn:\n        with db_conn.cursor() as cursor:\n\n            if style != '(custom)':\n                cursor.execute(\"\"\"\n                    SELECT fileid, recipe_type, title\n                    FROM default_print_style_recipes\n                    WHERE print_style=%s\n                    \"\"\", vars=(style,))\n                info = cursor.fetchall()\n                if len(info) < 1:\n                    current_recipe = None\n                    recipe_type = None\n                    status = None\n\n                else:\n                    current_recipe = info[0]['fileid']\n                    recipe_type = info[0]['recipe_type']\n                    status = 'current'\n\n                cursor.execute(\"\"\"\\\n                    SELECT name, authors, lm.revised, lm.recipe, psr.tag,\n                        f.sha1 as hash, psr.commit_id, uuid,\n                        ident_hash(uuid, major_version, minor_version)\n                    FROM modules as lm\n                    LEFT JOIN print_style_recipes as psr\n                    ON (psr.print_style = lm.print_style and\n                        psr.fileid = lm.recipe)\n                    LEFT JOIN files f ON psr.fileid = f.fileid\n                    WHERE lm.print_style=%s\n                    AND portal_type='Collection'\n                    AND ARRAY [major_version, minor_version] = (\n                        SELECT max(ARRAY[major_version,minor_version])\n                        FROM modules WHERE lm.uuid = uuid)\n\n                    ORDER BY psr.tag DESC;\n                    \"\"\", vars=(style,))\n            else:\n                current_recipe = '(custom)'\n                recipe_type = '(custom)'\n                cursor.execute(\"\"\"\\\n                    SELECT name, authors, lm.revised, lm.recipe, NULL as tag,\n                        f.sha1 as hash, NULL as commit_id, uuid,\n                        ident_hash(uuid, major_version, minor_version)\n                    FROM modules as lm\n                    JOIN files f ON lm.recipe = f.fileid\n                    WHERE portal_type='Collection'\n                    AND NOT EXISTS (\n                        SELECT 1 from print_style_recipes psr\n                        WHERE psr.fileid = lm.recipe)\n                    AND ARRAY [major_version, minor_version] = (\n                        SELECT max(ARRAY[major_version,minor_version])\n                        FROM modules WHERE lm.uuid = uuid)\n                    ORDER BY uuid, recipe, revised DESC;\n                    \"\"\", vars=(style,))\n                status = '(custom)'\n\n            collections = []\n            for row in cursor.fetchall():\n                recipe = row['recipe']\n                if (status != '(custom)' and\n                        current_recipe is not None and\n                        recipe != current_recipe):\n                    status = 'stale'\n                collections.append({\n                    'title': row['name'].decode('utf-8'),\n                    'authors': row['authors'],\n                    'revised': row['revised'],\n                    'recipe': row['hash'],\n                    'recipe_link': request.route_path('get-resource',\n                                                      hash=row['hash']),\n                    'tag': row['tag'],\n                    'ident_hash': row['ident_hash'],\n                    'link': request.route_path('get-content',\n                                               ident_hash=row['ident_hash']),\n                    'status': status,\n                    'status_link': request.route_path(\n                        'admin-content-status-single', uuid=row['uuid']),\n\n                })\n    return {'number': len(collections),\n            'collections': collections,\n            'print_style': style,\n            'recipe_type': recipe_type}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the list of API keys.", "response": "def get_api_keys(request):\n    \"\"\"Return the list of API keys.\"\"\"\n    with db_connect() as db_conn:\n        with db_conn.cursor() as cursor:\n            cursor.execute(\"\"\"\\\nSELECT row_to_json(combined_rows) FROM (\n  SELECT id, key, name, groups FROM api_keys\n) AS combined_rows\"\"\")\n            api_keys = [x[0] for x in cursor.fetchall()]\n\n    return api_keys"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_baking_statuses_sql(get_request):\n    args = {}\n    sort = get_request.get('sort', 'bpsa.created DESC')\n    if (len(sort.split(\" \")) != 2 or\n            sort.split(\" \")[0] not in SORTS_DICT.keys() or\n            sort.split(\" \")[1] not in ARROW_MATCH.keys()):\n        raise httpexceptions.HTTPBadRequest(\n            'invalid sort: {}'.format(sort))\n    if sort == \"STATE ASC\" or sort == \"STATE DESC\":\n        sort = 'bpsa.created DESC'\n    uuid_filter = get_request.get('uuid', '').strip()\n    author_filter = get_request.get('author', '').strip()\n    latest_filter = get_request.get('latest', False)\n\n    sql_filters = \"WHERE\"\n    if latest_filter:\n        sql_filters += \"\"\" ARRAY [m.major_version, m.minor_version] = (\n         SELECT max(ARRAY[major_version,minor_version]) FROM\n                   modules where m.uuid= uuid) AND \"\"\"\n    if uuid_filter != '':\n        args['uuid'] = uuid_filter\n        sql_filters += \" m.uuid=%(uuid)s AND \"\n    if author_filter != '':\n        author_filter = author_filter.decode('utf-8')\n        sql_filters += \" %(author)s=ANY(m.authors) \"\n        args[\"author\"] = author_filter\n\n    if sql_filters.endswith(\"AND \"):\n        sql_filters = sql_filters[:-4]\n    if sql_filters == \"WHERE\":\n        sql_filters = \"\"\n\n    # FIXME  celery AsyncResult API is soooo sloow that this page takes\n    # 2 min. or more to load on production.  As an workaround, this code\n    # accesses the celery_taskmeta table directly. Need to remove that access\n    # once we track enough state info ourselves. Want to track when queued,\n    # started, ended, etc. for future monitoring of baking system performance\n    # as well.\n    # The 'limit 1' subselect is to ensure the \"oldest identical version\"\n    # for recipes released as part of cnx-recipes (avoids one line per\n    # identical recipe file in different releases, for a single baking job)\n\n    statement = \"\"\"\n                       SELECT m.name, m.authors, m.uuid,\n                       module_version(m.major_version,m.minor_version)\n                          as current_version,\n                       m.print_style,\n                       CASE WHEN f.sha1 IS NOT NULL\n                       THEN coalesce(dps.print_style,'(custom)')\n                       ELSE dps.print_style\n                       END AS recipe_name,\n                       (select tag from print_style_recipes\n                            where print_style = m.print_style\n                                and fileid = m.recipe\n                                order by revised asc limit 1) as recipe_tag,\n                       coalesce(dps.fileid, m.recipe) as latest_recipe_id,\n                       m.recipe as recipe_id,\n                       f.sha1 as recipe,\n                       m.module_ident,\n                       ident_hash(m.uuid, m.major_version, m.minor_version),\n                       bpsa.created, ctm.traceback,\n                       CASE WHEN ctm.status = 'SUCCESS'\n                           AND ms.statename = 'fallback'\n                       THEN 'FALLBACK'\n                       ELSE ctm.status\n                       END as state\n                FROM document_baking_result_associations AS bpsa\n                INNER JOIN modules AS m USING (module_ident)\n                INNER JOIN modulestates as ms USING (stateid)\n                LEFT JOIN celery_taskmeta AS ctm\n                    ON bpsa.result_id = ctm.task_id::uuid\n                LEFT JOIN default_print_style_recipes as dps\n                    ON dps.print_style = m.print_style\n                LEFT JOIN latest_modules as lm\n                    ON lm.uuid=m.uuid\n                LEFT JOIN files f on m.recipe = f.fileid\n                {}\n                ORDER BY {};\n                \"\"\".format(sql_filters, sort)\n    args.update({'sort': sort})\n    return statement, args", "response": "Returns a SQL query that returns the list of baking statuses for the current project."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef admin_content_status(request):\n    statement, sql_args = get_baking_statuses_sql(request.GET)\n\n    states = []\n    status_filters = request.params.getall('status_filter') or []\n    state_icons = dict(STATE_ICONS)\n    with db_connect(cursor_factory=DictCursor) as db_conn:\n        with db_conn.cursor() as cursor:\n            cursor.execute(statement, vars=sql_args)\n            for row in cursor.fetchall():\n                message = ''\n                state = row['state'] or 'PENDING'\n                if status_filters and state not in status_filters:\n                    continue\n                if state == 'FAILURE':  # pragma: no cover\n                    if row['traceback'] is not None:\n                        message = row['traceback'].split(\"\\n\")[-2]\n                latest_recipe = row['latest_recipe_id']\n                current_recipe = row['recipe_id']\n                if (current_recipe is not None and\n                        current_recipe != latest_recipe):\n                    state += ' stale_recipe'\n                state_icon = state\n                if state[:7] == \"SUCCESS\" and len(state) > 7:\n                    state_icon = 'unknown'\n                states.append({\n                    'title': row['name'].decode('utf-8'),\n                    'authors': format_authors(row['authors']),\n                    'uuid': row['uuid'],\n                    'print_style': row['print_style'],\n                    'print_style_link': request.route_path(\n                        'admin-print-style-single', style=row['print_style']),\n                    'recipe': row['recipe'],\n                    'recipe_name': row['recipe_name'],\n                    'recipe_tag': row['recipe_tag'],\n                    'recipe_link': request.route_path(\n                        'get-resource', hash=row['recipe']),\n                    'created': row['created'],\n                    'state': state,\n                    'state_message': message,\n                    'state_icon': state_icons.get(\n                        state_icon, DEFAULT_ICON),\n                    'status_link': request.route_path(\n                        'admin-content-status-single', uuid=row['uuid']),\n                    'content_link': request.route_path(\n                        'get-content', ident_hash=row['ident_hash'])\n                })\n    sort = request.params.get('sort', 'bpsa.created DESC')\n    sort_match = SORTS_DICT[sort.split(' ')[0]]\n    sort_arrow = ARROW_MATCH[sort.split(' ')[1]]\n    if sort == \"STATE ASC\":\n        states.sort(key=lambda x: x['state'])\n    if sort == \"STATE DESC\":\n        states.sort(key=lambda x: x['state'], reverse=True)\n\n    num_entries = request.params.get('number', 100) or 100\n    page = request.params.get('page', 1) or 1\n    try:\n        page = int(page)\n        num_entries = int(num_entries)\n        start_entry = (page - 1) * num_entries\n    except ValueError:\n        raise httpexceptions.HTTPBadRequest(\n            'invalid page({}) or entries per page({})'.\n            format(page, num_entries))\n    total_entries = len(states)\n    states = states[start_entry: start_entry + num_entries]\n\n    returns = sql_args\n    returns.update({'start_entry': start_entry,\n                    'num_entries': num_entries,\n                    'page': page,\n                    'total_entries': total_entries,\n                    'states': states,\n                    'sort_' + sort_match: sort_arrow,\n                    'sort': sort,\n                    'domain': request.host,\n                    'latest_only': request.GET.get('latest', False),\n                    'STATE_ICONS': STATE_ICONS,\n                    'status_filters': status_filters or [\n                        i[0] for i in STATE_ICONS]})\n    return returns", "response": "Returns a dictionary with the states and info of baking books and the filters from the GET request to pre - populate the form."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef admin_content_status_single(request):\n    uuid = request.matchdict['uuid']\n    try:\n        UUID(uuid)\n    except ValueError:\n        raise httpexceptions.HTTPBadRequest(\n            '{} is not a valid uuid'.format(uuid))\n\n    statement, sql_args = get_baking_statuses_sql({'uuid': uuid})\n    with db_connect(cursor_factory=DictCursor) as db_conn:\n        with db_conn.cursor() as cursor:\n            cursor.execute(statement, sql_args)\n            modules = cursor.fetchall()\n            if len(modules) == 0:\n                raise httpexceptions.HTTPBadRequest(\n                    '{} is not a book'.format(uuid))\n\n            states = []\n            collection_info = modules[0]\n\n            for row in modules:\n                message = ''\n                state = row['state'] or 'PENDING'\n                if state == 'FAILURE':  # pragma: no cover\n                    if row['traceback'] is not None:\n                        message = row['traceback']\n                latest_recipe = row['latest_recipe_id']\n                current_recipe = row['recipe_id']\n                if (latest_recipe is not None and\n                        current_recipe != latest_recipe):\n                    state += ' stale_recipe'\n                states.append({\n                    'version': row['current_version'],\n                    'recipe': row['recipe'],\n                    'created': str(row['created']),\n                    'state': state,\n                    'state_message': message,\n                })\n\n    return {'uuid': str(collection_info['uuid']),\n            'title': collection_info['name'].decode('utf-8'),\n            'authors': format_authors(collection_info['authors']),\n            'print_style': collection_info['print_style'],\n            'current_recipe': collection_info['recipe_id'],\n            'current_ident': collection_info['module_ident'],\n            'current_state': states[0]['state'],\n            'states': states}", "response": "Returns a dictionary with all the past baking statuses of a single book."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef admin_content_status_single_POST(request):\n    args = admin_content_status_single(request)\n    title = args['title']\n    if args['current_state'] == 'SUCCESS':\n        args['response'] = title + ' is not stale, no need to bake'\n        return args\n\n    with db_connect() as db_conn:\n        with db_conn.cursor() as cursor:\n            cursor.execute(\"SELECT stateid FROM modules WHERE module_ident=%s\",\n                           vars=(args['current_ident'],))\n            data = cursor.fetchall()\n            if len(data) == 0:\n                raise httpexceptions.HTTPBadRequest(\n                    'invalid module_ident: {}'.format(args['current_ident']))\n            if data[0][0] == 5 or data[0][0] == 6:\n                args['response'] = title + ' is already baking/set to bake'\n                return args\n\n            cursor.execute(\"\"\"UPDATE modules SET stateid=5\n                           WHERE module_ident=%s\"\"\",\n                           vars=(args['current_ident'],))\n\n            args['response'] = title + \" set to bake!\"\n\n    return args", "response": "Retetriggers baking for a given book."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninsert the optional roles for the given module.", "response": "def _insert_optional_roles(cursor, model, ident):\n    \"\"\"Inserts the optional roles if values for the optional roles\n    exist.\n    \"\"\"\n    optional_roles = [\n        # (<metadata-attr>, <db-role-id>,),\n        ('translators', 4,),\n        ('editors', 5,),\n    ]\n    for attr, role_id in optional_roles:\n        roles = model.metadata.get(attr)\n        if not roles:\n            # Bail out, no roles for this type.\n            continue\n        usernames = [parse_user_uri(x['id']) for x in roles]\n        cursor.execute(\"\"\"\\\nINSERT INTO moduleoptionalroles (module_ident, roleid, personids)\nVALUES (%s, %s, %s)\"\"\", (ident, role_id, usernames,))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninsert a module with the given metadata.", "response": "def _insert_metadata(cursor, model, publisher, message):\n    \"\"\"Insert a module with the given ``metadata``.\"\"\"\n    params = model.metadata.copy()\n    params['publisher'] = publisher\n    params['publication_message'] = message\n    params['_portal_type'] = _model_to_portaltype(model)\n\n    params['summary'] = str(cnxepub.DocumentSummaryFormatter(model))\n\n    # Transform person structs to id lists for database array entry.\n    for person_field in ATTRIBUTED_ROLE_KEYS:\n        params[person_field] = [parse_user_uri(x['id'])\n                                for x in params.get(person_field, [])]\n    params['parent_ident_hash'] = parse_parent_ident_hash(model)\n\n    # Assign the id and version if one is known.\n    if model.ident_hash is not None:\n        uuid, version = split_ident_hash(model.ident_hash,\n                                         split_version=True)\n        params['_uuid'] = uuid\n        params['_major_version'], params['_minor_version'] = version\n        # Lookup legacy ``moduleid``.\n        cursor.execute(\"SELECT moduleid FROM latest_modules WHERE uuid = %s\",\n                       (uuid,))\n        # There is the chance that a uuid and version have been set,\n        #   but a previous publication does not exist. Therefore the\n        #   moduleid will not be found. This happens on a pre-publication.\n        try:\n            moduleid = cursor.fetchone()[0]\n        except TypeError:  # NoneType\n            moduleid = None\n        params['_moduleid'] = moduleid\n\n        # Verify that uuid is reserved in document_contols. If not, add it.\n        cursor.execute(\"SELECT * from document_controls where uuid = %s\",\n                       (uuid,))\n        try:\n            cursor.fetchone()[0]\n        except TypeError:  # NoneType\n            cursor.execute(\"INSERT INTO document_controls (uuid) VALUES (%s)\",\n                           (uuid,))\n\n        created = model.metadata.get('created', None)\n        # Format the statement to accept the identifiers.\n        stmt = MODULE_INSERTION_TEMPLATE.format(**{\n            '__uuid__': \"%(_uuid)s::uuid\",\n            '__major_version__': \"%(_major_version)s\",\n            '__minor_version__': \"%(_minor_version)s\",\n            '__moduleid__': moduleid is None and \"DEFAULT\" or \"%(_moduleid)s\",\n            '__created__': created is None and \"DEFAULT\" or \"%(created)s\",\n        })\n    else:\n        created = model.metadata.get('created', None)\n        # Format the statement for defaults.\n        stmt = MODULE_INSERTION_TEMPLATE.format(**{\n            '__uuid__': \"DEFAULT\",\n            '__major_version__': \"DEFAULT\",\n            '__minor_version__': \"DEFAULT\",\n            '__moduleid__': \"DEFAULT\",\n            '__created__': created is None and \"DEFAULT\" or \"%(created)s\",\n        })\n\n    # Insert the metadata\n    cursor.execute(stmt, params)\n    module_ident, ident_hash = cursor.fetchone()\n    # Insert optional roles\n    _insert_optional_roles(cursor, model, module_ident)\n\n    return module_ident, ident_hash"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_file_sha1(file):\n    bits = file.read()\n    file.seek(0)\n    h = hashlib.new('sha1', bits).hexdigest()\n    return h", "response": "Return the SHA1 hash of the given a file - like object as file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninsert the file and media_type into the files table.", "response": "def _insert_file(cursor, file, media_type):\n    \"\"\"Upsert the ``file`` and ``media_type`` into the files table.\n    Returns the ``fileid`` and ``sha1`` of the upserted file.\n\n    \"\"\"\n    resource_hash = _get_file_sha1(file)\n    cursor.execute(\"SELECT fileid FROM files WHERE sha1 = %s\",\n                   (resource_hash,))\n    try:\n        fileid = cursor.fetchone()[0]\n    except (IndexError, TypeError):\n        cursor.execute(\"INSERT INTO files (file, media_type) \"\n                       \"VALUES (%s, %s)\"\n                       \"RETURNING fileid\",\n                       (psycopg2.Binary(file.read()), media_type,))\n        fileid = cursor.fetchone()[0]\n    return fileid, resource_hash"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninsert a resource into the modules_files table. This will create a new file entry and associates an existing one.", "response": "def _insert_resource_file(cursor, module_ident, resource):\n    \"\"\"Insert a resource into the modules_files table. This will\n    create a new file entry or associates an existing one.\n    \"\"\"\n    with resource.open() as file:\n        fileid, _ = _insert_file(cursor, file, resource.media_type)\n\n    # Is this file legitimately used twice within the same content?\n    cursor.execute(\"\"\"\\\nselect\n  (fileid = %s) as is_same_file\nfrom module_files\nwhere module_ident = %s and filename = %s\"\"\",\n                   (fileid, module_ident, resource.filename,))\n    try:\n        is_same_file = cursor.fetchone()[0]\n    except TypeError:  # NoneType\n        is_same_file = None\n    if is_same_file:\n        # All is good, bail out.\n        return\n    elif is_same_file is not None:  # pragma: no cover\n        # This means the file is not the same, but a filename\n        #   conflict exists.\n        # FFF At this time, it is impossible to get to this logic.\n        raise Exception(\"filename conflict\")\n\n    args = (module_ident, fileid, resource.filename,)\n    cursor.execute(\"\"\"\\\nINSERT INTO module_files (module_ident, fileid, filename)\nVALUES (%s, %s, %s)\"\"\", args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _insert_tree(cursor, tree, parent_id=None, index=0, is_collated=False):\n    if isinstance(tree, dict):\n        if tree['id'] == 'subcol':\n            document_id = None\n            title = tree['title']\n        else:\n            cursor.execute(\"\"\"\\\n            SELECT module_ident, name\n            FROM modules\n            WHERE ident_hash(uuid,major_version,minor_version) = %s\n            \"\"\", (tree['id'],))\n            try:\n                document_id, document_title = cursor.fetchone()\n            except TypeError:  # NoneType\n                raise ValueError(\"Missing published document for '{}'.\"\n                                 .format(tree['id']))\n            if tree.get('title', None):\n                title = tree['title']\n            else:\n                title = document_title\n        # TODO We haven't settled on a flag (name or value)\n        #      to pin the node to a specific version.\n        is_latest = True\n        cursor.execute(TREE_NODE_INSERT,\n                       dict(document_id=document_id, parent_id=parent_id,\n                            title=title, child_order=index,\n                            is_latest=is_latest, is_collated=is_collated))\n        node_id = cursor.fetchone()[0]\n        if 'contents' in tree:\n            _insert_tree(cursor, tree['contents'], parent_id=node_id,\n                         is_collated=is_collated)\n    elif isinstance(tree, list):\n        for tree_node in tree:\n            _insert_tree(cursor, tree_node, parent_id=parent_id,\n                         index=tree.index(tree_node), is_collated=is_collated)", "response": "Inserts a binder tree into the archive."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npublishes the given model and returns its ident_hash.", "response": "def publish_model(cursor, model, publisher, message):\n    \"\"\"Publishes the ``model`` and return its ident_hash.\"\"\"\n    publishers = publisher\n    if isinstance(publishers, list) and len(publishers) > 1:\n        raise ValueError(\"Only one publisher is allowed. '{}' \"\n                         \"were given: {}\"\n                         .format(len(publishers), publishers))\n    module_ident, ident_hash = _insert_metadata(cursor, model,\n                                                publisher, message)\n\n    for resource in getattr(model, 'resources', []):\n        _insert_resource_file(cursor, module_ident, resource)\n\n    if isinstance(model, Document):\n        html = bytes(cnxepub.DocumentContentFormatter(model))\n        sha1 = hashlib.new('sha1', html).hexdigest()\n        cursor.execute(\"SELECT fileid FROM files WHERE sha1 = %s\", (sha1,))\n        try:\n            fileid = cursor.fetchone()[0]\n        except TypeError:\n            file_args = {\n                'media_type': 'text/html',\n                'data': psycopg2.Binary(html),\n            }\n            cursor.execute(\"\"\"\\\n            insert into files (file, media_type)\n            VALUES (%(data)s, %(media_type)s)\n            returning fileid\"\"\", file_args)\n            fileid = cursor.fetchone()[0]\n        args = {\n            'module_ident': module_ident,\n            'filename': 'index.cnxml.html',\n            'fileid': fileid,\n        }\n        cursor.execute(\"\"\"\\\n        INSERT INTO module_files\n          (module_ident, fileid, filename)\n        VALUES\n          (%(module_ident)s, %(fileid)s, %(filename)s)\"\"\", args)\n\n    elif isinstance(model, Binder):\n        tree = cnxepub.model_to_tree(model)\n        tree = _insert_tree(cursor, tree)\n    return ident_hash"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npublishing the model and returns its ident_hash.", "response": "def publish_composite_model(cursor, model, parent_model, publisher, message):\n    \"\"\"Publishes the ``model`` and return its ident_hash.\"\"\"\n    if not (isinstance(model, CompositeDocument) or\n            (isinstance(model, Binder) and\n                model.metadata.get('type') == 'composite-chapter')):\n        raise ValueError(\"This function only publishes Composite\"\n                         \"objects. '{}' was given.\".format(type(model)))\n    if issequence(publisher) and len(publisher) > 1:\n        raise ValueError(\"Only one publisher is allowed. '{}' \"\n                         \"were given: {}\"\n                         .format(len(publisher), publisher))\n    module_ident, ident_hash = _insert_metadata(cursor, model,\n                                                publisher, message)\n\n    model.id, model.metadata['version'] = split_ident_hash(ident_hash)\n    model.set_uri('cnx-archive', ident_hash)\n\n    for resource in model.resources:\n        _insert_resource_file(cursor, module_ident, resource)\n\n    if isinstance(model, CompositeDocument):\n        html = bytes(cnxepub.DocumentContentFormatter(model))\n        fileid, _ = _insert_file(cursor, io.BytesIO(html), 'text/html')\n        file_arg = {\n            'module_ident': module_ident,\n            'parent_ident_hash': parent_model.ident_hash,\n            'fileid': fileid,\n        }\n        cursor.execute(\"\"\"\\\n        INSERT INTO collated_file_associations\n          (context, item, fileid)\n        VALUES\n          ((SELECT module_ident FROM modules\n            WHERE ident_hash(uuid, major_version, minor_version)\n           = %(parent_ident_hash)s),\n            %(module_ident)s, %(fileid)s)\"\"\", file_arg)\n\n    return ident_hash"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npublishing a given module s collated content in the context of the parent_model.", "response": "def publish_collated_document(cursor, model, parent_model):\n    \"\"\"Publish a given `module`'s collated content in the context of\n    the `parent_model`. Note, the model's content is expected to already\n    have the collated content. This will just persist that content to\n    the archive.\n\n    \"\"\"\n    html = bytes(cnxepub.DocumentContentFormatter(model))\n    sha1 = hashlib.new('sha1', html).hexdigest()\n    cursor.execute(\"SELECT fileid FROM files WHERE sha1 = %s\", (sha1,))\n    try:\n        fileid = cursor.fetchone()[0]\n    except TypeError:\n        file_args = {\n            'media_type': 'text/html',\n            'data': psycopg2.Binary(html),\n        }\n        cursor.execute(\"\"\"\\\n        INSERT INTO files (file, media_type)\n        VALUES (%(data)s, %(media_type)s)\n        RETURNING fileid\"\"\", file_args)\n        fileid = cursor.fetchone()[0]\n    args = {\n        'module_ident_hash': model.ident_hash,\n        'parent_ident_hash': parent_model.ident_hash,\n        'fileid': fileid,\n    }\n    stmt = \"\"\"\\\nINSERT INTO collated_file_associations (context, item, fileid)\nVALUES\n  ((SELECT module_ident FROM modules\n    WHERE ident_hash(uuid, major_version, minor_version)\n   = %(parent_ident_hash)s),\n   (SELECT module_ident FROM modules\n    WHERE ident_hash(uuid, major_version, minor_version)\n   = %(module_ident_hash)s),\n   %(fileid)s)\"\"\"\n    cursor.execute(stmt, args)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npublishing a given collated tree.", "response": "def publish_collated_tree(cursor, tree):\n    \"\"\"Publish a given collated `tree` (containing newly added\n    `CompositeDocument` objects and number inforation)\n    alongside the original tree.\n\n    \"\"\"\n    tree = _insert_tree(cursor, tree, is_collated=True)\n    return tree"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrepublish the Binders that share Documents in the publication context.", "response": "def republish_binders(cursor, models):\n    \"\"\"Republish the Binders that share Documents in the publication context.\n    This needs to be given all the models in the publication context.\"\"\"\n    documents = set([])\n    binders = set([])\n    history_mapping = {}  # <previous-ident-hash>: <current-ident-hash>\n    if not isinstance(models, (list, tuple, set,)):\n        raise TypeError(\"``models`` Must be a sequence of model objects.\"\n                        \"We were given: {}\".format(models))\n    for model in models:\n        if isinstance(model, (cnxepub.Binder,)):\n            binders.add(split_ident_hash(model.ident_hash)[0])\n            for doc in cnxepub.flatten_to_documents(model):\n                documents.add(split_ident_hash(doc.ident_hash))\n        else:\n            documents.add(split_ident_hash(model.ident_hash))\n\n    to_be_republished = []\n    # What binders are these documents a part of?\n    for (uuid, version) in documents:\n        ident_hash = join_ident_hash(uuid, version)\n        previous_ident_hash = get_previous_publication(cursor, ident_hash)\n        if previous_ident_hash is None:\n            # Has no prior existence.\n            continue\n        else:\n            history_mapping[previous_ident_hash] = ident_hash\n        cursor.execute(\"\"\"\\\nWITH RECURSIVE t(nodeid, parent_id, documentid, path) AS (\n  SELECT tr.nodeid, tr.parent_id, tr.documentid, ARRAY[tr.nodeid]\n  FROM trees tr\n  WHERE tr.documentid = (\n    SELECT module_ident FROM modules\n    WHERE ident_hash(uuid, major_version, minor_version) = %s)\nUNION ALL\n  SELECT c.nodeid, c.parent_id, c.documentid, path || ARRAY[c.nodeid]\n  FROM trees c JOIN t ON (c.nodeid = t.parent_id)\n  WHERE not c.nodeid = ANY(t.path)\n)\nSELECT ident_hash(uuid, major_version, minor_version)\nFROM t JOIN latest_modules m ON (t.documentid = m.module_ident)\nWHERE t.parent_id IS NULL\n\"\"\",\n                       (previous_ident_hash,))\n        to_be_republished.extend([split_ident_hash(x[0])\n                                  for x in cursor.fetchall()])\n    to_be_republished = set(to_be_republished)\n\n    republished_ident_hashes = []\n    # Republish the Collections set.\n    for (uuid, version) in to_be_republished:\n        if uuid in binders:\n            # This binder is already in the publication context,\n            # don't try to publish it again.\n            continue\n        ident_hash = join_ident_hash(uuid, version)\n        bumped_version = bump_version(cursor, uuid, is_minor_bump=True)\n        republished_ident_hash = republish_collection(cursor, ident_hash,\n                                                      version=bumped_version)\n        # Set the identifier history.\n        history_mapping[ident_hash] = republished_ident_hash\n        rebuild_collection_tree(cursor, ident_hash, history_mapping)\n        republished_ident_hashes.append(republished_ident_hash)\n\n    return republished_ident_hashes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_previous_publication(cursor, ident_hash):\n    cursor.execute(\"\"\"\\\nWITH contextual_module AS (\n  SELECT uuid, module_ident\n  FROM modules\n  WHERE ident_hash(uuid, major_version, minor_version) = %s)\nSELECT ident_hash(m.uuid, m.major_version, m.minor_version)\nFROM modules AS m JOIN contextual_module AS context ON (m.uuid = context.uuid)\nWHERE\n  m.module_ident < context.module_ident\nORDER BY revised DESC\nLIMIT 1\"\"\", (ident_hash,))\n    try:\n        previous_ident_hash = cursor.fetchone()[0]\n    except TypeError:  # NoneType\n        previous_ident_hash = None\n    return previous_ident_hash", "response": "Get the previous publication of the given ident - hash."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbump to the next available version of the given content identified by uuid.", "response": "def bump_version(cursor, uuid, is_minor_bump=False):\n    \"\"\"Bump to the next version of the given content identified\n    by ``uuid``. Returns the next available version as a version tuple,\n    containing major and minor version.\n    If ``is_minor_bump`` is ``True`` the version will minor bump. That is\n    1.2 becomes 1.3 in the case of Collections. And 2 becomes 3 for\n    Modules regardless of this option.\n    \"\"\"\n    cursor.execute(\"\"\"\\\nSELECT portal_type, major_version, minor_version\nFROM latest_modules\nWHERE uuid = %s::uuid\"\"\", (uuid,))\n    type_, major_version, minor_version = cursor.fetchone()\n    incr = 1\n    if type_ == 'Collection' and is_minor_bump:\n        minor_version = minor_version + incr\n    else:\n        major_version = major_version + incr\n    return (major_version, minor_version,)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef republish_collection(cursor, ident_hash, version):\n    if not isinstance(version, (list, tuple,)):\n        split_version = version.split('.')\n        if len(split_version) == 1:\n            split_version.append(None)\n        version = tuple(split_version)\n    major_version, minor_version = version\n\n    cursor.execute(\"\"\"\\\nWITH previous AS (\n  SELECT module_ident\n  FROM modules\n  WHERE ident_hash(uuid, major_version, minor_version) = %s),\ninserted AS (\n  INSERT INTO modules\n    (uuid, major_version, minor_version, revised,\n     portal_type, moduleid,\n     name, created, language,\n     submitter, submitlog,\n     abstractid, licenseid, parent, parentauthors,\n     authors, maintainers, licensors,\n     google_analytics, buylink,\n     stateid, doctype)\n  SELECT\n    uuid, %s, %s, CURRENT_TIMESTAMP,\n    portal_type, moduleid,\n    name, created, language,\n    submitter, submitlog,\n    abstractid, licenseid, parent, parentauthors,\n    authors, maintainers, licensors,\n    google_analytics, buylink,\n    stateid, doctype\n  FROM modules AS m JOIN previous AS p ON (m.module_ident = p.module_ident)\n  RETURNING\n    ident_hash(uuid, major_version, minor_version) AS ident_hash,\n    module_ident),\nkeywords AS (\n  INSERT INTO modulekeywords (module_ident, keywordid)\n  SELECT i.module_ident, keywordid\n  FROM modulekeywords AS mk, inserted AS i, previous AS p\n  WHERE mk.module_ident = p.module_ident),\ntags AS (\n  INSERT INTO moduletags (module_ident, tagid)\n  SELECT i.module_ident, tagid\n  FROM moduletags AS mt, inserted AS i, previous AS p\n  WHERE mt.module_ident = p.module_ident)\nSELECT ident_hash FROM inserted\"\"\",\n                   (ident_hash, major_version, minor_version,))\n    repub_ident_hash = cursor.fetchone()[0]\n    return repub_ident_hash", "response": "Republish the collection identified as ident_hash with the given version."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rebuild_collection_tree(cursor, ident_hash, history_map):\n    collection_tree_sql = \"\"\"\\\nWITH RECURSIVE t(nodeid, parent_id, documentid, title, childorder, latest,\n                 ident_hash, path) AS (\n  SELECT\n    tr.nodeid, tr.parent_id, tr.documentid,\n    tr.title, tr.childorder, tr.latest,\n    (SELECT ident_hash(uuid, major_version, minor_version)\n     FROM modules\n     WHERE module_ident = tr.documentid) AS ident_hash,\n    ARRAY[tr.nodeid]\n  FROM trees AS tr\n  WHERE tr.documentid = (\n    SELECT module_ident\n    FROM modules\n    WHERE ident_hash(uuid, major_version, minor_version) = %s)\n    AND tr.is_collated = FALSE\nUNION ALL\n  SELECT\n    c.nodeid, c.parent_id, c.documentid, c.title, c.childorder, c.latest,\n    (SELECT ident_hash(uuid, major_version, minor_version)\n     FROM modules\n     WHERE module_ident = c.documentid) AS ident_hash,\n    path || ARRAY[c.nodeid]\n  FROM trees AS c JOIN t ON (c.parent_id = t.nodeid)\n  WHERE not c.nodeid = ANY(t.path) AND c.is_collated = FALSE\n)\nSELECT row_to_json(row) FROM (SELECT * FROM t) AS row\"\"\"\n\n    tree_insert_sql = \"\"\"\\\nINSERT INTO trees\n  (nodeid, parent_id,\n   documentid,\n   title, childorder, latest)\nVALUES\n  (DEFAULT, %(parent_id)s,\n   (SELECT module_ident\n    FROM modules\n    WHERE ident_hash(uuid, major_version, minor_version) = \\\n          %(ident_hash)s),\n   %(title)s, %(childorder)s, %(latest)s)\nRETURNING nodeid\"\"\"\n\n    def get_tree():\n        cursor.execute(collection_tree_sql, (ident_hash,))\n        for row in cursor.fetchall():\n            yield row[0]\n\n    def insert(fields):\n        cursor.execute(tree_insert_sql, fields)\n        results = cursor.fetchone()[0]\n        return results\n\n    tree = {}  # {<current-nodeid>: {<row-data>...}, ...}\n    children = {}  # {<nodeid>: [<child-nodeid>, ...], <child-nodeid>: [...]}\n    for node in get_tree():\n        tree[node['nodeid']] = node\n        children.setdefault(node['parent_id'], [])\n        children[node['parent_id']].append(node['nodeid'])\n\n    def build_tree(nodeid, parent_id):\n        data = tree[nodeid]\n        data['parent_id'] = parent_id\n        if history_map.get(data['ident_hash']) is not None \\\n           and (data['latest'] or parent_id is None):\n            data['ident_hash'] = history_map[data['ident_hash']]\n        new_nodeid = insert(data)\n        for child_nodeid in children.get(nodeid, []):\n            build_tree(child_nodeid, new_nodeid)\n\n    root_node = children[None][0]\n    build_tree(root_node, None)", "response": "Rebuild the tree based on the old tree and the new tree based on the new tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npublishes a new resource.", "response": "def publish(request):\n    \"\"\"Accept a publication request at form value 'epub'\"\"\"\n    if 'epub' not in request.POST:\n        raise httpexceptions.HTTPBadRequest(\"Missing EPUB in POST body.\")\n\n    is_pre_publication = asbool(request.POST.get('pre-publication'))\n    epub_upload = request.POST['epub'].file\n    try:\n        epub = cnxepub.EPUB.from_file(epub_upload)\n    except:  # noqa: E722\n        raise httpexceptions.HTTPBadRequest('Format not recognized.')\n\n    # Make a publication entry in the database for status checking\n    # the publication. This also creates publication entries for all\n    # of the content in the EPUB.\n    with db_connect() as db_conn:\n        with db_conn.cursor() as cursor:\n            epub_upload.seek(0)\n            publication_id, publications = add_publication(\n                cursor, epub, epub_upload, is_pre_publication)\n\n    # Poke at the publication & lookup its state.\n    state, messages = poke_publication_state(publication_id)\n\n    response_data = {\n        'publication': publication_id,\n        'mapping': publications,\n        'state': state,\n        'messages': messages,\n    }\n    return response_data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_accept_license(request):\n    publication_id = request.matchdict['id']\n    user_id = request.matchdict['uid']\n\n    # FIXME Is this an active publication?\n    # TODO Verify the accepting user is the one making the request.\n\n    # For each pending document, accept the license.\n    with db_connect() as db_conn:\n        with db_conn.cursor() as cursor:\n            cursor.execute(\"\"\"\nSELECT row_to_json(combined_rows) FROM (\nSELECT\n  pd.uuid AS id,\n  ident_hash(pd.uuid, pd.major_version, pd.minor_version) \\\n    AS ident_hash,\n  accepted AS is_accepted\nFROM\n  pending_documents AS pd\n  NATURAL JOIN license_acceptances AS la\nWHERE pd.publication_id = %s AND user_id = %s\n) as combined_rows;\"\"\",\n                           (publication_id, user_id))\n            user_documents = [r[0] for r in cursor.fetchall()]\n\n    return {'publication_id': publication_id,\n            'user_id': user_id,\n            'documents': user_documents,\n            }", "response": "This returns the JSON data for a user to view the license(s) that have been accepted for a publication."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nallowing the user to accept the license for a specific publication.", "response": "def post_accept_license(request):\n    \"\"\"Allows the user (at ``uid``) to accept the license(s) for\n    a publication (at ``id``).\n    \"\"\"\n    publication_id = request.matchdict['id']\n    uid = request.matchdict['uid']\n\n    # TODO Verify the accepting user is the one making the request.\n    #      They could be authenticated but not be the license acceptor.\n\n    post_data = request.json\n    accepted = []\n    denied = []\n    try:\n        documents = post_data['documents']\n        for doc_acceptance in documents:\n            if doc_acceptance['is_accepted'] is None:\n                continue\n            elif doc_acceptance['is_accepted']:\n                accepted.append(doc_acceptance['id'])\n            else:\n                denied.append(doc_acceptance['id'])\n    except KeyError:\n        raise httpexceptions.BadRequest(\"Posted data is invalid.\")\n\n    # For each pending document, accept/deny the license.\n    with db_connect() as db_conn:\n        with db_conn.cursor() as cursor:\n            accept_publication_license(cursor, publication_id, uid,\n                                       accepted, True)\n            accept_publication_license(cursor, publication_id, uid,\n                                       denied, False)\n\n    location = request.route_url('publication-license-acceptance',\n                                 id=publication_id, uid=uid)\n    # Poke publication to change state.\n    poke_publication_state(publication_id)\n    return httpexceptions.HTTPFound(location=location)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninvoking the baking process - trigger post - publication", "response": "def bake_content(request):\n    \"\"\"Invoke the baking process - trigger post-publication\"\"\"\n    ident_hash = request.matchdict['ident_hash']\n    try:\n        id, version = split_ident_hash(ident_hash)\n    except IdentHashError:\n        raise httpexceptions.HTTPNotFound()\n\n    if not version:\n        raise httpexceptions.HTTPBadRequest('must specify the version')\n\n    with db_connect() as db_conn:\n        with db_conn.cursor() as cursor:\n            cursor.execute(\"\"\"\\\nSELECT bool(portal_type = 'Collection'), stateid, module_ident\nFROM modules\nWHERE ident_hash(uuid, major_version, minor_version) = %s\n\"\"\", (ident_hash,))\n            try:\n                is_binder, stateid, module_ident = cursor.fetchone()\n            except TypeError:\n                raise httpexceptions.HTTPNotFound()\n            if not is_binder:\n                raise httpexceptions.HTTPBadRequest(\n                    '{} is not a book'.format(ident_hash))\n\n            if stateid == 5:\n                cursor.execute(\"\"\"\\\nSELECT pg_notify('post_publication',\n'{\"module_ident\": '||%s||',\n  \"ident_hash\": \"'||%s||'\",\n  \"timestamp\": \"'||CURRENT_TIMESTAMP||'\"}')\n\"\"\", (module_ident, ident_hash))\n            else:\n                cursor.execute(\"\"\"\\\nUPDATE modules SET stateid = 5\nWHERE ident_hash(uuid, major_version, minor_version) = %s\n\"\"\", (ident_hash,))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef includeme(config):\n    global cache_manager\n    settings = config.registry.settings\n    cache_manager = CacheManager(**parse_cache_config_options(settings))", "response": "Configures the caching manager"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a Postgres Notification Event object from a Notify object.", "response": "def create_pg_notify_event(notif):\n    \"\"\"A factory for creating a Postgres Notification Event\n    (an object inheriting from `cnxpublishing.events.PGNotifyEvent`)\n    given `notif`, a `psycopg2.extensions.Notify` object.\n\n    \"\"\"\n    # TODO Lookup registered events via getAllUtilitiesRegisteredFor\n    #      for class mapping.\n    if notif.channel not in _CHANNEL_MAPPER:\n        cls = _CHANNEL_MAPPER[None]\n    else:\n        cls = _CHANNEL_MAPPER[notif.channel]\n    return cls(notif)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef map(self, from_obj, to_type, ignore_case=False, allow_none=False, excluded=None):\r\n        if (from_obj is None) and allow_none:\r\n            return None\r\n        else:\r\n            # one of the tests is explicitly checking for an attribute error on __dict__ if it's not set\r\n            from_obj.__dict__\r\n\r\n        inst = to_type()\r\n        key_from = from_obj.__class__.__name__\r\n        key_to = to_type.__name__\r\n\r\n        def not_private(s):\r\n            return not s.startswith('_')\r\n\r\n        def not_excluded(s):\r\n            return not (excluded and s in excluded)\r\n\r\n        from_obj_attributes = getmembers(from_obj, lambda a: not isroutine(a))\r\n        from_obj_dict = {k: v for k, v in from_obj_attributes\r\n                         if not_private(k) and not_excluded(k)}\r\n\r\n        to_obj_attributes = getmembers(inst, lambda a: not isroutine(a))\r\n        to_obj_dict = {k: v for k, v in to_obj_attributes if not_private(k)}\r\n\r\n        if ignore_case:\r\n            from_props = CaseDict(from_obj_dict)\r\n            to_props = CaseDict(to_obj_dict)\r\n        else:\r\n            from_props = from_obj_dict\r\n            to_props = to_obj_dict\r\n\r\n        for prop in to_props:\r\n            if self.mappings is not None \\\r\n                    and key_from in self.mappings \\\r\n                    and key_to in self.mappings[key_from]:\r\n                if prop in self.mappings[key_from][key_to]:\r\n                    # take mapping function\r\n                    try:\r\n                        fnc = self.mappings[key_from][key_to][prop]\r\n                        if fnc is not None:\r\n                            setattr(inst, prop, fnc(from_obj))\r\n                            # none suppress mapping\r\n                    except Exception:\r\n                        raise ObjectMapperException(\"Invalid mapping function while setting property {0}.{1}\".\r\n                                                    format(inst.__class__.__name__, prop))\r\n\r\n                else:\r\n                    # try find property with the same name in the source\r\n                    if prop in from_props:\r\n                        setattr(inst, prop, from_props[prop])\r\n                        # case when target attribute is not mapped (can be extended)\r\n            else:\r\n                raise ObjectMapperException(\"No mapping defined for {0} -> {1}\".format(key_from, key_to))\r\n\r\n        return inst", "response": "Method for creating a new object from one object to another."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, key, default=_sentinel):\n        tup = self._data.get(key.lower())\n        if tup is not None:\n            return tup[1]\n        elif default is not _sentinel:\n            return default\n        else:\n            return None", "response": "Gets the value of the key from the key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pop(self, key, default=_sentinel):\n        if default is not _sentinel:\n            tup = self._data.pop(key.lower(), default)\n        else:\n            tup = self._data.pop(key.lower())\n        if tup is not default:\n            return tup[1]\n        else:\n            return default", "response": "Removes the specified key and returns the corresponding value. If default is not given KeyError is raised."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reversals(series, left=False, right=False):\n    series = iter(series)\n\n    x_last, x = next(series), next(series)\n    d_last = (x - x_last)\n\n    if left:\n        yield x_last\n    for x_next in series:\n        if x_next == x:\n            continue\n        d_next = x_next - x\n        if d_last * d_next < 0:\n            yield x\n        x_last, x = x, x_next\n        d_last = d_next\n    if right:\n        yield x_next", "response": "Iterate over the series of reversal points."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_cycles(series, left=False, right=False):\n    points = deque()\n\n    for x in reversals(series, left=left, right=right):\n        points.append(x)\n        while len(points) >= 3:\n            # Form ranges X and Y from the three most recent points\n            X = abs(points[-2] - points[-1])\n            Y = abs(points[-3] - points[-2])\n\n            if X < Y:\n                # Read the next point\n                break\n            elif len(points) == 3:\n                # Y contains the starting point\n                # Count Y as one-half cycle and discard the first point\n                yield points[0], points[1], 0.5\n                points.popleft()\n            else:\n                # Count Y as one cycle and discard the peak and the valley of Y\n                yield points[-3], points[-2], 1.0\n                last = points.pop()\n                points.pop()\n                points.pop()\n                points.append(last)\n    else:\n        # Count the remaining ranges as one-half cycles\n        while len(points) > 1:\n            yield points[0], points[1], 0.5\n            points.popleft()", "response": "Iterate cycles in the series."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncounts the number of cycles in a series.", "response": "def count_cycles(series, ndigits=None, left=False, right=False):\n    \"\"\"Count cycles in the series.\n\n    Parameters\n    ----------\n    series : iterable sequence of numbers\n    ndigits : int, optional\n        Round cycle magnitudes to the given number of digits before counting.\n    left: bool, optional\n        If True, treat the first point in the series as a reversal.\n    right: bool, optional\n        If True, treat the last point in the series as a reversal.\n\n    Returns\n    -------\n    A sorted list containing pairs of cycle magnitude and count.\n    One-half cycles are counted as 0.5, so the returned counts may not be\n    whole numbers.\n    \"\"\"\n    counts = defaultdict(float)\n    round_ = _get_round_function(ndigits)\n\n    for low, high, mult in extract_cycles(series, left=left, right=right):\n        delta = round_(abs(high - low))\n        counts[delta] += mult\n    return sorted(counts.items())"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a FST that renders a given node.", "response": "def render(node, strict=False):\n    \"\"\"Recipe to render a given FST node.\n\n    The FST is composed of branch nodes which are either lists or dicts\n    and of leaf nodes which are strings. Branch nodes can have other\n    list, dict or leaf nodes as childs.\n\n    To render a string, simply output it. To render a list, render each\n    of its elements in order. To render a dict, you must follow the\n    node's entry in the nodes_rendering_order dictionary and its\n    dependents constraints.\n\n    This function hides all this algorithmic complexity by returning\n    a structured rendering recipe, whatever the type of node. But even\n    better, you should subclass the RenderWalker which simplifies\n    drastically working with the rendered FST.\n\n    The recipe is a list of steps, each step correspond to a child and is actually a 3-uple composed of the following fields:\n\n    - `key_type` is a string determining the type of the child in the second field (`item`) of the tuple. It can be one of:\n\n      - 'constant': the child is a string\n      - 'node': the child is a dict\n      - 'key': the child is an element of a dict\n      - 'list': the child is a list\n      - 'formatting': the child is a list specialized in formatting\n\n    - `item` is the child itself: either a string, a dict or a list.\n    - `render_key` gives the key used to access this child from the parent node. It's a string if the node is a dict or a number if its a list.\n\n    Please note that \"bool\" `key_types` are never rendered, that's why\n    they are not shown here.\n    \"\"\"\n    if isinstance(node, list):\n        return render_list(node)\n\n    elif isinstance(node, dict):\n        return render_node(node, strict=strict)\n\n    else:\n        raise NotImplementedError(\"You tried to render a %s. Only list and dicts can be rendered.\" % node.__class__.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the FST node located at the given path", "response": "def path_to_node(tree, path):\n    \"\"\"FST node located at the given path\"\"\"\n    if path is None:\n        return None\n\n    node = tree\n\n    for key in path:\n        node = child_by_key(node, key)\n\n    return node"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef before_constant(self, constant, key):\n        newlines_split = split_on_newlines(constant)\n\n        for c in newlines_split:\n            if is_newline(c):\n                self.current.advance_line()\n                # if target line is passed\n                if self.current.line > self.target.line:\n                    return self.STOP\n\n            else:\n                advance_by = len(c)\n                if self.is_on_targetted_node(advance_by):\n                    self.found_path = deepcopy(self.current_path)\n                    return self.STOP\n                self.current.advance_columns(advance_by)", "response": "Determine if we re on the targetted node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the prefix for a given multicodec name.", "response": "def get_prefix(multicodec):\n    \"\"\"\n    Returns prefix for a given multicodec\n\n    :param str multicodec: multicodec codec name\n    :return: the prefix for the given multicodec\n    :rtype: byte\n    :raises ValueError: if an invalid multicodec name is provided\n    \"\"\"\n    try:\n        prefix = varint.encode(NAME_TABLE[multicodec])\n    except KeyError:\n        raise ValueError('{} multicodec is not supported.'.format(multicodec))\n    return prefix"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_prefix(multicodec, bytes_):\n    prefix = get_prefix(multicodec)\n    return b''.join([prefix, bytes_])", "response": "Adds multicodec prefix to the given bytes input\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove prefix from a prefixed data bytes", "response": "def remove_prefix(bytes_):\n    \"\"\"\n    Removes prefix from a prefixed data\n\n    :param bytes bytes_: multicodec prefixed data bytes\n    :return: prefix removed data bytes\n    :rtype: bytes\n    \"\"\"\n    prefix_int = extract_prefix(bytes_)\n    prefix = varint.encode(prefix_int)\n    return bytes_[len(prefix):]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_codec(bytes_):\n    prefix = extract_prefix(bytes_)\n    try:\n        return CODE_TABLE[prefix]\n    except KeyError:\n        raise ValueError('Prefix {} not present in the lookup table'.format(prefix))", "response": "Gets the codec used for prefix the multicodec prefixed data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef capture(\n    target_url,\n    user_agent=\"archiveis (https://github.com/pastpages/archiveis)\",\n    proxies={}\n):\n    \"\"\"\n    Archives the provided URL using archive.is\n\n    Returns the URL where the capture is stored.\n    \"\"\"\n    # Put together the URL that will save our request\n    domain = \"http://archive.vn\"\n    save_url = urljoin(domain, \"/submit/\")\n\n    # Configure the request headers\n    headers = {\n        'User-Agent': user_agent,\n        \"host\": \"archive.vn\",\n    }\n\n    # Request a unique identifier for our activity\n    logger.debug(\"Requesting {}\".format(domain + \"/\"))\n    get_kwargs = dict(\n        timeout=120,\n        allow_redirects=True,\n        headers=headers,\n    )\n    if proxies:\n        get_kwargs['proxies'] = proxies\n    response = requests.get(domain + \"/\", **get_kwargs)\n    response.raise_for_status()\n\n    # It will need to be parsed from the homepage response headers\n    html = str(response.content)\n    try:\n        unique_id = html.split('name=\"submitid', 1)[1].split('value=\"', 1)[1].split('\"', 1)[0]\n        logger.debug(\"Unique identifier: {}\".format(unique_id))\n    except IndexError:\n        logger.warn(\"Unable to extract unique identifier from archive.is. Submitting without it.\")\n        unique_id = None\n\n    # Send the capture request to archive.is with the unique id included\n    data = {\n        \"url\": target_url,\n        \"anyway\": 1,\n    }\n    if unique_id:\n        data.update({\"submitid\": unique_id})\n\n    post_kwargs = dict(\n        timeout=120,\n        allow_redirects=True,\n        headers=headers,\n        data=data\n    )\n    if proxies:\n        post_kwargs['proxies'] = proxies\n\n    logger.debug(\"Requesting {}\".format(save_url))\n    response = requests.post(save_url, **post_kwargs)\n    response.raise_for_status()\n\n    # There are a couple ways the header can come back\n    if 'Refresh' in response.headers:\n        memento = str(response.headers['Refresh']).split(';url=')[1]\n        logger.debug(\"Memento from Refresh header: {}\".format(memento))\n        return memento\n    if 'Location' in response.headers:\n        memento = response.headers['Location']\n        logger.debug(\"Memento from Location header: {}\".format(memento))\n        return memento\n    logger.debug(\"Memento not found in response headers. Inspecting history.\")\n    for i, r in enumerate(response.history):\n        logger.debug(\"Inspecting history request #{}\".format(i))\n        logger.debug(r.headers)\n        if 'Location' in r.headers:\n            memento = r.headers['Location']\n            logger.debug(\"Memento from the Location header of {} history response: {}\".format(i+1, memento))\n            return memento\n    # If there's nothing at this point, throw an error\n    logger.error(\"No memento returned by archive.is\")\n    logger.error(\"Status code: {}\".format(response.status_code))\n    logger.error(response.headers)\n    logger.error(response.text)\n    raise Exception(\"No memento returned by archive.is\")", "response": "Create a new object of the correct type for the given target_url."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\narchiving the provided URL using archive.is.", "response": "def cli(url, user_agent):\n    \"\"\"\n    Archives the provided URL using archive.is.\n    \"\"\"\n    kwargs = {}\n    if user_agent:\n        kwargs['user_agent'] = user_agent\n    archive_url = capture(url, **kwargs)\n    click.echo(archive_url)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the logo for a channel.", "response": "def get_channel_image(self, channel, img_size=300, skip_cache=False):\n        \"\"\"Get the logo for a channel\"\"\"\n        from bs4 import BeautifulSoup\n        from wikipedia.exceptions import PageError\n        import re\n        import wikipedia\n        wikipedia.set_lang('fr')\n\n        if not channel:\n            _LOGGER.error('Channel is not set. Could not retrieve image.')\n            return\n\n        # Check if the image is in cache\n        if channel in self._cache_channel_img and not skip_cache:\n            img = self._cache_channel_img[channel]\n            _LOGGER.debug('Cache hit: %s -> %s', channel, img)\n            return img\n\n        channel_info = self.get_channel_info(channel)\n        query = channel_info['wiki_page']\n        if not query:\n            _LOGGER.debug('Wiki page is not set for channel %s', channel)\n            return\n        _LOGGER.debug('Query: %s', query)\n        # If there is a max image size defined use it.\n        if 'max_img_size' in channel_info:\n            if img_size > channel_info['max_img_size']:\n                _LOGGER.info(\n                    'Requested image size is bigger than the max, '\n                    'setting it to %s', channel_info['max_img_size']\n                )\n                img_size = channel_info['max_img_size']\n        try:\n            page = wikipedia.page(query)\n            _LOGGER.debug('Wikipedia article title: %s', page.title)\n            soup = BeautifulSoup(page.html(), 'html.parser')\n            images = soup.find_all('img')\n            img_src = None\n            for i in images:\n                if i['alt'].startswith('Image illustrative'):\n                    img_src = re.sub(r'\\d+px', '{}px'.format(img_size),\n                                     i['src'])\n            img = 'https:{}'.format(img_src) if img_src else None\n            # Cache result\n            self._cache_channel_img[channel] = img\n            return img\n        except PageError:\n            _LOGGER.error('Could not fetch channel image for %s', channel)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npress a key from the cache.", "response": "def press_key(self, key, mode=0):\n        '''\n        modes:\n            0 -> simple press\n            1 -> long press\n            2 -> release after long press\n        '''\n        if isinstance(key, str):\n            assert key in KEYS, 'No such key: {}'.format(key)\n            key = KEYS[key]\n        _LOGGER.info('Press key %s', self.__get_key_name(key))\n        return self.rq('01', OrderedDict([('key', key), ('mode', mode)]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef forwards(self, orm):\n        \"Write your forwards methods here.\"\n        # Note: Remember to use orm['appname.ModelName'] rather than \"from appname.models...\"\n        for translation in orm['people.PersonTranslation'].objects.all():\n            if translation.language in ['en', 'de']:\n                translation.roman_first_name = translation.first_name\n                translation.roman_last_name = translation.last_name\n            else:\n                translation.non_roman_first_name = translation.first_name\n                translation.non_roman_last_name = translation.last_name\n            translation.save()", "response": "Write your forwards methods here."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite your forwards methods here.", "response": "def forwards(self, orm):\n        \"Write your forwards methods here.\"\n        for translation in orm['people.PersonTranslation'].objects.all():\n            translation.person.roman_first_name = translation.roman_first_name\n            translation.person.roman_last_name = translation.roman_last_name\n            translation.person.non_roman_first_name = translation.non_roman_first_name\n            translation.person.non_roman_last_name = translation.non_roman_last_name\n            translation.person.save()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a block node.", "response": "def parse(self, scope):\n        \"\"\"Parse block node.\n        args:\n            scope (Scope): Current scope\n        raises:\n            SyntaxError\n        returns:\n            self\n        \"\"\"\n        if not self.parsed:\n            scope.push()\n            self.name, inner = self.tokens\n            scope.current = self.name\n            scope.real.append(self.name)\n            if not self.name.parsed:\n                self.name.parse(scope)\n            if not inner:\n                inner = []\n            inner = list(utility.flatten([p.parse(scope) for p in inner if p]))\n            self.parsed = []\n            self.inner = []\n            if not hasattr(self, \"inner_media_queries\"):\n                self.inner_media_queries = []\n            for p in inner:\n                if p is not None:\n                    if isinstance(p, Block):\n                        if (len(scope) == 2 and p.tokens[1] is not None):\n                            p_is_mediaquery = p.name.tokens[0] == '@media'\n                            # Inner block @media ... { ... } is a nested media\n                            # query. But double-nested media queries have to be\n                            # removed and marked as well. While parsing \".foo\",\n                            # both nested \"@media print\" and double-nested\n                            # \"@media all\" will be handled as we have to\n                            # re-arrange the scope and block layout quite a bit:\n                            #\n                            #   .foo {\n                            #       @media print {\n                            #           color: blue;\n                            #           @media screen { font-size: 12em; }\n                            #       }\n                            #   }\n                            #\n                            # Expected result:\n                            #\n                            #   @media print {\n                            #       .foo { color: blue; }\n                            #   }\n                            #   @media print and screen {\n                            #       .foo { font-size: 12 em; }\n                            #   }\n                            append_list = []\n                            reparse_p = False\n                            for child in p.tokens[1]:\n                                if isinstance(child, Block) and child.name.raw(\n                                ).startswith(\"@media\"):\n                                    # Remove child from the nested media query, it will be re-added to\n                                    # the parent with 'merged' media query (see above example).\n                                    p.tokens[1].remove(child)\n                                    if p_is_mediaquery:  # Media query inside a & block\n                                        # Double-nested media query found. We remove it from 'p' and add\n                                        # it to this block with a new 'name'.\n                                        reparse_p = True\n                                        part_a = p.name.tokens[2:][0][0][0]\n                                        part_b = child.name.tokens[2:][0][0]\n                                        new_ident_tokens = [\n                                            '@media', ' ', [\n                                                part_a, (' ', 'and', ' '),\n                                                part_b\n                                            ]\n                                        ]\n                                        # Parse child again with new @media $BLA {} part\n                                        child.tokens[0] = Identifier(\n                                            new_ident_tokens)\n                                        child.parsed = None\n                                        child = child.parse(scope)\n                                    else:\n                                        child.block_name = p.name\n                                    append_list.append(child)\n                                if reparse_p:\n                                    p.parsed = None\n                                    p = p.parse(scope)\n                            if not p_is_mediaquery and not append_list:\n                                self.inner.append(p)\n                            else:\n                                append_list.insert(\n                                    0, p\n                                )  # This media query should occur before it's children\n                                for media_query in append_list:\n                                    self.inner_media_queries.append(\n                                        media_query)\n                            # NOTE(saschpe): The code is not recursive but we hope that people\n                            # wont use triple-nested media queries.\n                        else:\n                            self.inner.append(p)\n                    else:\n                        self.parsed.append(p)\n            if self.inner_media_queries:\n                # Nested media queries, we have to remove self from scope and\n                # push all nested @media ... {} blocks.\n                scope.remove_block(self, index=-2)\n                for mb in self.inner_media_queries:\n                    # New inner block with current name and media block contents\n                    if hasattr(mb, 'block_name'):\n                        cb_name = mb.block_name\n                    else:\n                        cb_name = self.tokens[0]\n                    cb = Block([cb_name, mb.tokens[1]]).parse(scope)\n                    # Replace inner block contents with new block\n                    new_mb = Block([mb.tokens[0], [cb]]).parse(scope)\n                    self.inner.append(new_mb)\n                    scope.add_block(new_mb)\n            scope.real.pop()\n            scope.pop()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fmt(self, fills):\n        f = \"%(identifier)s%(ws)s{%(nl)s%(proplist)s}%(eb)s\"\n        out = []\n        name = self.name.fmt(fills)\n        if self.parsed and any(\n                p for p in self.parsed\n                if str(type(p)) != \"<class 'lesscpy.plib.variable.Variable'>\"):\n            fills.update({\n                'identifier':\n                name,\n                'proplist':\n                ''.join([p.fmt(fills) for p in self.parsed if p]),\n            })\n            out.append(f % fills)\n        if hasattr(self, 'inner'):\n            if self.name.subparse and len(self.inner) > 0:  # @media\n                inner = ''.join([p.fmt(fills) for p in self.inner])\n                inner = inner.replace(fills['nl'],\n                                      fills['nl'] + fills['tab']).rstrip(\n                                          fills['tab'])\n                if not fills['nl']:\n                    inner = inner.strip()\n                fills.update({\n                    'identifier': name,\n                    'proplist': fills['tab'] + inner\n                })\n                out.append(f % fills)\n            else:\n                out.append(''.join([p.fmt(fills) for p in self.inner]))\n        return ''.join(out)", "response": "Format a single block of CSS"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy(self):\n        name, inner = self.tokens\n        if inner:\n            inner = [u.copy() if u else u for u in inner]\n        if name:\n            name = name.copy()\n        return Block([name, inner], 0)", "response": "Return a full copy of self\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy_inner(self, scope):\n        if self.tokens[1]:\n            tokens = [u.copy() if u else u for u in self.tokens[1]]\n            out = [p for p in tokens if p]\n            utility.rename(out, scope, Block)\n            return out\n        return None", "response": "Copy the inner block contents."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the node s tokens and return a new instance of the node class.", "response": "def parse(self, scope):\n        \"\"\"Parse node\n        args:\n            scope (Scope): current scope\n        raises:\n            SyntaxError\n        returns:\n            self\n        \"\"\"\n        self.parsed = list(utility.flatten(self.tokens))\n        if self.parsed[0] == '@import':\n            if len(self.parsed) > 4:\n                # Media @import\n                self.parsed.insert(3, ' ')\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse function. We parse the tokens and return the mixed version of the tokens.", "response": "def parse(self, scope, error=False, depth=0):\n        \"\"\" Parse function. We search for mixins\n        first within current scope then fallback\n        to global scope. The special scope.deferred\n        is used when local scope mixins are called\n        within parent mixins.\n        If nothing is found we fallback to block-mixin\n        as lessc.js allows calls to blocks and mixins to\n        be inter-changable.\n        clx: This method is a HACK that stems from\n        poor design elsewhere. I will fix it\n        when I have more time.\n        args:\n            scope (Scope): Current scope\n        returns:\n            mixed\n        \"\"\"\n        res = False\n        ident, args = self.tokens\n        ident.parse(scope)\n        mixins = scope.mixins(ident.raw())\n\n        if not mixins:\n            ident.parse(None)\n            mixins = scope.mixins(ident.raw())\n\n        if depth > 64:\n            raise SyntaxError('NameError `%s`' % ident.raw(True))\n\n        if not mixins:\n            if scope.deferred:\n                store = [t for t in scope.deferred.parsed[-1]]\n                i = 0\n                while scope.deferred.parsed[-1]:\n                    scope.current = scope.deferred\n                    ident.parse(scope)\n                    mixins = scope.mixins(ident.raw())\n                    scope.current = None\n                    if mixins or i > 64:\n                        break\n                    scope.deferred.parsed[-1].pop()\n                    i += 1\n                scope.deferred.parsed[-1] = store\n\n        if not mixins:\n            # Fallback to blocks\n            block = scope.blocks(ident.raw())\n            if not block:\n                ident.parse(None)\n                block = scope.blocks(ident.raw())\n            if block:\n                scope.current = scope.real[-1] if scope.real else None\n                res = block.copy_inner(scope)\n                scope.current = None\n\n        if mixins:\n            for mixin in mixins:\n                scope.current = scope.real[-1] if scope.real else None\n                res = mixin.call(scope, args)\n                if res:\n                    # Add variables to scope to support\n                    # closures\n                    [scope.add_variable(v) for v in mixin.vars]\n                    scope.deferred = ident\n                    break\n\n        if res:\n            store = [t for t in scope.deferred.parsed[-1]\n                     ] if scope.deferred else False\n            tmp_res = []\n            for p in res:\n                if p:\n                    if isinstance(p, Deferred):\n                        tmp_res.append(p.parse(scope, depth=depth + 1))\n                    else:\n                        tmp_res.append(p.parse(scope))\n            res = tmp_res\n            #res = [p.parse(scope, depth=depth+1) for p in res if p]\n            while (any(t for t in res if isinstance(t, Deferred))):\n                res = [p.parse(scope) for p in res if p]\n            if store:\n                scope.deferred.parsed[-1] = store\n\n        if error and not res:\n            raise SyntaxError('NameError `%s`' % ident.raw(True))\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncompiling all. less files in a directory and write them to outpath.", "response": "def ldirectory(inpath, outpath, args, scope):\n    \"\"\"Compile all *.less files in directory\n    Args:\n        inpath (str): Path to compile\n        outpath (str): Output directory\n        args (object): Argparse Object\n        scope (Scope): Scope object or None\n    \"\"\"\n    yacctab = 'yacctab' if args.debug else None\n    if not outpath:\n        sys.exit(\"Compile directory option needs -o ...\")\n    else:\n        if not os.path.isdir(outpath):\n            if args.verbose:\n                print(\"Creating '%s'\" % outpath, file=sys.stderr)\n            if not args.dry_run:\n                os.mkdir(outpath)\n    less = glob.glob(os.path.join(inpath, '*.less'))\n    f = formatter.Formatter(args)\n    for lf in less:\n        outf = os.path.splitext(os.path.basename(lf))\n        minx = '.min' if args.min_ending else ''\n        outf = \"%s/%s%s.css\" % (outpath, outf[0], minx)\n        if not args.force and os.path.exists(outf):\n            recompile = os.path.getmtime(outf) < os.path.getmtime(lf)\n        else:\n            recompile = True\n        if recompile:\n            print('%s -> %s' % (lf, outf))\n            p = parser.LessParser(\n                yacc_debug=(args.debug),\n                lex_optimize=True,\n                yacc_optimize=(not args.debug),\n                scope=scope,\n                tabfile=yacctab,\n                verbose=args.verbose)\n            p.parse(filename=lf, debuglevel=0)\n            css = f.format(p)\n            if not args.dry_run:\n                with open(outf, 'w') as outfile:\n                    outfile.write(css)\n        elif args.verbose:\n            print('skipping %s, not modified' % lf, file=sys.stderr)\n        sys.stdout.flush()\n    if args.recurse:\n        [\n            ldirectory(\n                os.path.join(inpath, name), os.path.join(outpath, name), args,\n                scope) for name in os.listdir(inpath)\n            if os.path.isdir(os.path.join(inpath, name))\n            and not name.startswith('.') and not name == outpath\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(self, scope):\n        self.keyframe, = [\n            e[0] if isinstance(e, tuple) else e for e in self.tokens\n            if str(e).strip()\n        ]\n        self.subparse = False\n        return self", "response": "Parse the keyframe from the current scope."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef t_mediaquery_t_semicolon(self, t):\n        r';'\n        # This can happen only as part of a CSS import statement. The\n        # \"mediaquery\" state is reused there. Ordinary media queries always\n        # end at '{', i.e. when a block is opened.\n        t.lexer.pop_state()  # state mediaquery\n        # We have to pop the 'import' state here because we already ate the\n        # t_semicolon and won't trigger t_import_t_semicolon.\n        t.lexer.pop_state()  # state import\n        return t", "response": "Parse the next token and return the next token after the semicolon."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef t_css_string(self, t):\n        r'\"[^\"@]*\"|\\'[^\\'@]*\\''\n        t.lexer.lineno += t.value.count('\\n')\n        return t", "response": "Tokenizer for CSS string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef t_istringapostrophe_css_string(self, t):\n        r'[^\\'@]+'\n        t.lexer.lineno += t.value.count('\\n')\n        return t", "response": "Tokenizer for string apostrophe css"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef file(self, filename):\n        with open(filename) as f:\n            self.lexer.input(f.read())\n        return self", "response": "Reads a file and parses it into the Lex file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads lexer with content from file which can be a path or a file object.", "response": "def input(self, file):\n        \"\"\"\n        Load lexer with content from `file` which can be a path or a file\n        like object.\n        \"\"\"\n        if isinstance(file, string_types):\n            with open(file) as f:\n                self.lexer.input(f.read())\n        else:\n            self.lexer.input(file.read())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef token(self):\n        if self.next_:\n            t = self.next_\n            self.next_ = None\n            return t\n        while True:\n            t = self.lexer.token()\n            if not t:\n                return t\n            if t.type == 't_ws' and (\n                    self.pretok or\n                (self.last and self.last.type not in self.significant_ws)):\n                continue\n            self.pretok = False\n            if t.type == 't_bclose' and self.last and self.last.type not in ['t_bopen', 't_bclose'] and self.last.type != 't_semicolon' \\\n                    and not (hasattr(t, 'lexer') and (t.lexer.lexstate == 'escapequotes' or t.lexer.lexstate == 'escapeapostrophe')):\n                self.next_ = t\n                tok = lex.LexToken()\n                tok.type = 't_semicolon'\n                tok.value = ';'\n                tok.lineno = t.lineno\n                tok.lexpos = t.lexpos\n                self.last = tok\n                self.lexer.in_property_decl = False\n                return tok\n            self.last = t\n            break\n        return t", "response": "Returns the next token in the language."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse(self, scope):\n        names = []\n        name = []\n        self._subp = ('@media', '@keyframes', '@-moz-keyframes',\n                      '@-webkit-keyframes', '@-ms-keyframes')\n        if self.tokens and hasattr(self.tokens, 'parse'):\n            self.tokens = list(\n                utility.flatten([\n                    id.split() + [',']\n                    for id in self.tokens.parse(scope).split(',')\n                ]))\n            self.tokens.pop()\n        if self.tokens and any(hasattr(t, 'parse') for t in self.tokens):\n            tmp_tokens = []\n            for t in self.tokens:\n                if hasattr(t, 'parse'):\n                    tmp_tokens.append(t.parse(scope))\n                else:\n                    tmp_tokens.append(t)\n            self.tokens = list(utility.flatten(tmp_tokens))\n        if self.tokens and self.tokens[0] in self._subp:\n            name = list(utility.flatten(self.tokens))\n            self.subparse = True\n        else:\n            self.subparse = False\n            for n in utility.flatten(self.tokens):\n                if n == '*':\n                    name.append('* ')\n                elif n in '>+~':\n                    if name and name[-1] == ' ':\n                        name.pop()\n                    name.append('?%s?' % n)\n                elif n == ',':\n                    names.append(name)\n                    name = []\n                else:\n                    name.append(n)\n        names.append(name)\n        parsed = self.root(scope, names) if scope else names\n\n        # Interpolated selectors need another step, we have to replace variables. Avoid reserved words though\n        #\n        # Example:  '.@{var}'       results in [['.', '@{var}']]\n        # But:      '@media print'  results in [['@media', ' ', 'print']]\n        #\n        def replace_variables(tokens, scope):\n            return [\n                scope.swap(t)\n                if (utility.is_variable(t) and not t in reserved.tokens) else t\n                for t in tokens\n            ]\n\n        parsed = [\n            list(utility.flatten(replace_variables(part, scope)))\n            for part in parsed\n        ]\n\n        self.parsed = [[\n            i for i, j in utility.pairwise(part)\n            if i != ' ' or (j and '?' not in j)\n        ] for part in parsed]\n        return self", "response": "Parse node. Block identifiers are stored as\n        strings with spaces replaced with ?\n        args:\n            scope (Scope): Current scope\n        raises:\n            SyntaxError\n        returns:\n            self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef root(self, scope, names):\n        parent = scope.scopename\n        if parent:\n            parent = parent[-1]\n            if parent.parsed:\n                parsed_names = []\n                for name in names:\n                    ampersand_count = name.count('&')\n                    if ampersand_count:\n                        filtered_parts = []\n                        for part in parent.parsed:\n                            if part and part[0] not in self._subp:\n                                filtered_parts.append(part)\n                        permutations = list(\n                            utility.permutations_with_replacement(\n                                filtered_parts, ampersand_count))\n                        for permutation in permutations:\n                            parsed = []\n                            for name_part in name:\n                                if name_part == \"&\":\n                                    parent_part = permutation.pop(0)\n                                    if parsed and parsed[-1].endswith(']'):\n                                        parsed.extend(' ')\n                                    if parent_part[-1] == ' ':\n                                        parent_part.pop()\n                                    parsed.extend(parent_part)\n                                else:\n                                    parsed.append(name_part)\n                            parsed_names.append(parsed)\n                    else:\n                        # NOTE(saschpe): Maybe this code can be expressed with permutations too?\n                        for part in parent.parsed:\n                            if part and part[0] not in self._subp:\n                                parsed = []\n                                if name[0] == \"@media\":\n                                    parsed.extend(name)\n                                else:\n                                    parsed.extend(part)\n                                    if part[-1] != ' ':\n                                        parsed.append(' ')\n                                    parsed.extend(name)\n                                parsed_names.append(parsed)\n                            else:\n                                parsed_names.append(name)\n                return parsed_names\n        return names", "response": "Find the root of identifier from a list of names."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef copy(self):\n        tokens = ([t for t in self.tokens]\n                  if isinstance(self.tokens, list) else self.tokens)\n        return Identifier(tokens, 0)", "response": "Return a copy of self\n           Identifier"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats identifier args: fills (dict): replacements returns: str (CSS)", "response": "def fmt(self, fills):\n        \"\"\"Format identifier\n        args:\n            fills (dict): replacements\n        returns:\n            str (CSS)\n        \"\"\"\n        name = ',$$'.join(''.join(p).strip() for p in self.parsed)\n        name = re.sub('\\?(.)\\?', '%(ws)s\\\\1%(ws)s', name) % fills\n        return name.replace('$$', fills['nl']).replace('  ', ' ')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a block element to the log", "response": "def add_block(self, block):\n        \"\"\"Add block element to scope\n        Args:\n            block (Block): Block object\n        \"\"\"\n        self[-1]['__blocks__'].append(block)\n        self[-1]['__names__'].append(block.raw())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_block(self, block, index=\"-1\"):\n        self[index][\"__blocks__\"].remove(block)\n        self[index][\"__names__\"].remove(block.raw())", "response": "Removes a block element from the scope\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a mixin to the scope of the log.", "response": "def add_mixin(self, mixin):\n        \"\"\"Add mixin to scope\n        Args:\n            mixin (Mixin): Mixin object\n        \"\"\"\n        raw = mixin.tokens[0][0].raw()\n        if raw in self._mixins:\n            self._mixins[raw].append(mixin)\n        else:\n            self._mixins[raw] = [mixin]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches for variable by name. Searches scope top down and returns Variable object OR False", "response": "def variables(self, name):\n        \"\"\"Search for variable by name. Searches scope top down\n        Args:\n            name (string): Search term\n        Returns:\n            Variable object OR False\n        \"\"\"\n        if isinstance(name, tuple):\n            name = name[0]\n        if name.startswith('@{'):\n            name = '@' + name[2:-1]\n        i = len(self)\n        while i >= 0:\n            i -= 1\n            if name in self[i]['__variables__']:\n                return self[i]['__variables__'][name]\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches mixins for name.", "response": "def mixins(self, name):\n        \"\"\" Search mixins for name.\n        Allow '>' to be ignored. '.a .b()' == '.a > .b()'\n        Args:\n            name (string): Search term\n        Returns:\n            Mixin object list OR False\n        \"\"\"\n        m = self._smixins(name)\n        if m:\n            return m\n        return self._smixins(name.replace('?>?', ' '))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch for defined blocks recursively.", "response": "def blocks(self, name):\n        \"\"\"\n        Search for defined blocks recursively.\n        Allow '>' to be ignored. '.a .b' == '.a > .b'\n        Args:\n            name (string): Search term\n        Returns:\n            Block object OR False\n        \"\"\"\n        b = self._blocks(name)\n        if b:\n            return b\n        return self._blocks(name.replace('?>?', ' '))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _blocks(self, name):\n        i = len(self)\n        while i >= 0:\n            i -= 1\n            if name in self[i]['__names__']:\n                for b in self[i]['__blocks__']:\n                    r = b.raw()\n                    if r and r == name:\n                        return b\n            else:\n                for b in self[i]['__blocks__']:\n                    r = b.raw()\n                    if r and name.startswith(r):\n                        b = utility.blocksearch(b, name)\n                        if b:\n                            return b\n        return False", "response": "Search for blocks by name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the internal state of the object.", "response": "def update(self, scope, at=0):\n        \"\"\"Update scope. Add another scope to this one.\n        Args:\n            scope (Scope): Scope object\n        Kwargs:\n            at (int): Level to update\n        \"\"\"\n        if hasattr(scope, '_mixins') and not at:\n            self._mixins.update(scope._mixins)\n        self[at]['__variables__'].update(scope[at]['__variables__'])\n        self[at]['__blocks__'].extend(scope[at]['__blocks__'])\n        self[at]['__names__'].extend(scope[at]['__names__'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nswapping variable name for variable value", "response": "def swap(self, name):\n        \"\"\" Swap variable name for variable value\n        Args:\n            name (str): Variable name\n        Returns:\n            Variable value (Mixed)\n        \"\"\"\n        if name.startswith('@@'):\n            var = self.variables(name[1:])\n            if var is False:\n                raise SyntaxError('Unknown variable %s' % name)\n            name = '@' + utility.destring(var.value[0])\n            var = self.variables(name)\n            if var is False:\n                raise SyntaxError('Unknown variable %s' % name)\n        elif name.startswith('@{'):\n            var = self.variables('@' + name[2:-1])\n            if var is False:\n                raise SyntaxError('Unknown escaped variable %s' % name)\n            if isinstance(var.value[0], string_types):\n                var.value[0] = utility.destring(var.value[0])\n        else:\n            var = self.variables(name)\n            if var is False:\n                raise SyntaxError('Unknown variable %s' % name)\n        return var.value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing tokenslist flattening and parsing it", "response": "def process(self, tokens, scope):\n        \"\"\" Process tokenslist, flattening and parsing it\n        args:\n            tokens (list): tokenlist\n            scope (Scope): Current scope\n        returns:\n            list\n        \"\"\"\n        while True:\n            tokens = list(utility.flatten(tokens))\n            done = True\n            if any(t for t in tokens if hasattr(t, 'parse')):\n                tokens = [\n                    t.parse(scope) if hasattr(t, 'parse') else t\n                    for t in tokens\n                ]\n                done = False\n            if any(\n                    t for t in tokens\n                    if (utility.is_variable(t)) or str(type(t)) ==\n                    \"<class 'lesscpy.plib.variable.Variable'>\"):\n                tokens = self.replace_variables(tokens, scope)\n                done = False\n            if done:\n                break\n        return tokens"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreplace variables in tokenlist tokens with variables in scope.", "response": "def replace_variables(self, tokens, scope):\n        \"\"\" Replace variables in tokenlist\n        args:\n            tokens (list): tokenlist\n            scope (Scope): Current scope\n        returns:\n            list\n        \"\"\"\n        list = []\n        for t in tokens:\n            if utility.is_variable(t):\n                list.append(scope.swap(t))\n            elif str(type(t)) == \"<class 'lesscpy.plib.variable.Variable'>\":\n                list.append(scope.swap(t.name))\n            else:\n                list.append(t)\n        return list"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(self, scope):\n        if not self.parsed:\n            if len(self.tokens) > 2:\n                property, style, _ = self.tokens\n                self.important = True\n            else:\n                property, style = self.tokens\n                self.important = False\n            self.property = ''.join(property)\n            self.parsed = []\n            if style:\n                style = self.preprocess(style)\n                self.parsed = self.process(style, scope)\n        return self", "response": "Parse node - level properties and style."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef preprocess(self, style):\n        if self.property == 'font':\n            style = [\n                ''.join(u.expression()) if hasattr(u, 'expression') else u\n                for u in style\n            ]\n        else:\n            style = [(u, ' ') if hasattr(u, 'expression') else u\n                     for u in style]\n        return style", "response": "Hackish preprocessing from font shorthand tags."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nformat node with fills", "response": "def fmt(self, fills):\n        \"\"\" Format node\n        args:\n            fills (dict): replacements\n        returns:\n            str\n        \"\"\"\n        f = \"%(tab)s%(property)s:%(ws)s%(style)s%(important)s;%(nl)s\"\n        imp = ' !important' if self.important else ''\n        if fills['nl']:\n            self.parsed = [\n                ',%s' % fills['ws'] if p == ',' else p for p in self.parsed\n            ]\n        style = ''.join([\n            p.fmt(fills) if hasattr(p, 'fmt') else str(p) for p in self.parsed\n        ])\n        # IE cannot handle no space after url()\n        style = re.sub(\"(url\\([^\\)]*\\))([^\\s,])\", \"\\\\1 \\\\2\", style)\n        fills.update({\n            'property': self.property,\n            'style': style.strip(),\n            'important': imp\n        })\n        return f % fills"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse node args and scope.", "response": "def parse(self, scope):\n        \"\"\"Parse node\n        args:\n            scope (Scope): current scope\n        raises:\n            SyntaxError\n        returns:\n            self\n        \"\"\"\n        self.name, args, self.guards = self.tokens[0]\n        self.args = [a for a in utility.flatten(args) if a]\n        self.body = Block([None, self.tokens[1]], 0)\n        self.vars = list(\n            utility.flatten([\n                list(v.values()) for v in [s['__variables__'] for s in scope]\n            ]))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the arguments to mixin.", "response": "def parse_args(self, args, scope):\n        \"\"\"Parse arguments to mixin. Add them to scope\n        as variables. Sets upp special variable @arguments\n        as well.\n        args:\n            args (list): arguments\n            scope (Scope): current scope\n        raises:\n            SyntaxError\n        \"\"\"\n        arguments = list(zip(args,\n                             [' '] * len(args))) if args and args[0] else None\n        zl = itertools.zip_longest if sys.version_info[\n            0] == 3 else itertools.izip_longest\n        if self.args:\n            parsed = [\n                v if hasattr(v, 'parse') else v for v in copy.copy(self.args)\n            ]\n            args = args if isinstance(args, list) else [args]\n            vars = [\n                self._parse_arg(var, arg, scope)\n                for arg, var in zl([a for a in args], parsed)\n            ]\n            for var in vars:\n                if var:\n                    var.parse(scope)\n            if not arguments:\n                arguments = [v.value for v in vars if v]\n        if not arguments:\n            arguments = ''\n        Variable(['@arguments', None, arguments]).parse(scope)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_arg(self, var, arg, scope):\n        if isinstance(var, Variable):\n            # kwarg\n            if arg:\n                if utility.is_variable(arg[0]):\n                    tmp = scope.variables(arg[0])\n                    if not tmp:\n                        return None\n                    val = tmp.value\n                else:\n                    val = arg\n                var = Variable(var.tokens[:-1] + [val])\n        else:\n            # arg\n            if utility.is_variable(var):\n                if arg is None:\n                    raise SyntaxError('Missing argument to mixin')\n                elif utility.is_variable(arg[0]):\n                    tmp = scope.variables(arg[0])\n                    if not tmp:\n                        return None\n                    val = tmp.value\n                else:\n                    val = arg\n                var = Variable([var, None, val])\n            else:\n                return None\n        return var", "response": "Parse a single argument to mixin.\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_guards(self, scope):\n        if self.guards:\n            cor = True if ',' in self.guards else False\n            for g in self.guards:\n                if isinstance(g, list):\n                    res = (g[0].parse(scope)\n                           if len(g) == 1 else Expression(g).parse(scope))\n                    if cor:\n                        if res:\n                            return True\n                    elif not res:\n                        return False\n        return True", "response": "Parse guards on mixin."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef call(self, scope, args=[]):\n        ret = False\n        if args:\n            args = [[\n                a.parse(scope) if isinstance(a, Expression) else a for a in arg\n            ] if arg else arg for arg in args]\n        try:\n            self.parse_args(args, scope)\n        except SyntaxError:\n            pass\n        else:\n            if self.parse_guards(scope):\n                body = self.body.copy()\n                ret = body.tokens[1]\n                if ret:\n                    utility.rename(ret, scope, Block)\n        return ret", "response": "Parses a copy of the mixins body\n            in the current scope and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(self, scope):\n        self.name, _, self.value = self.tokens\n        if isinstance(self.name, tuple):\n            if len(self.name) > 1:\n                self.name, pad = self.name\n                self.value.append(pad)\n            else:\n                self.name = self.name[0]\n        scope.add_variable(self)\n        return self", "response": "Parse function\n        args : Scope object containing the related attributes. Returns self."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse(self, scope):\n        name = ''.join(self.tokens[0])\n        parsed = self.process(self.tokens[1:], scope)\n\n        if name == '%(':\n            name = 'sformat'\n        elif name in ('~', 'e'):\n            name = 'escape'\n        color = Color.Color()\n        args = [\n            t for t in parsed\n            if not isinstance(t, string_types) or t not in '(),'\n        ]\n        if hasattr(self, name):\n            try:\n                return getattr(self, name)(*args)\n            except ValueError:\n                pass\n\n        if hasattr(color, name):\n            try:\n                result = getattr(color, name)(*args)\n                try:\n                    return result + ' '\n                except TypeError:\n                    return result\n            except ValueError:\n                pass\n        return name + ''.join([p for p in parsed])", "response": "Parse a node within scope."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sformat(self, string, *args):\n        format = string\n        items = []\n        m = re.findall('(%[asdA])', format)\n        if m and not args:\n            raise SyntaxError('Not enough arguments...')\n        i = 0\n        for n in m:\n            v = {\n                '%A': urlquote,\n                '%s': utility.destring,\n            }.get(n, str)(args[i])\n            items.append(v)\n            i += 1\n        format = format.replace('%A', '%s')\n        format = format.replace('%d', '%s')\n        return format % tuple(items)", "response": "String format.\n        args:\n            string (str): string to format\n            args (list): format options\n        returns:\n            str"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nam number args: string (str): match returns: bool", "response": "def isnumber(self, string, *args):\n        \"\"\"Is number\n        args:\n            string (str): match\n        returns:\n            bool\n        \"\"\"\n        try:\n            n, u = utility.analyze_number(string)\n        except SyntaxError:\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nis url args: string (str): match returns: bool", "response": "def isurl(self, string, *args):\n        \"\"\"Is url\n        args:\n            string (str): match\n        returns:\n            bool\n        \"\"\"\n        arg = utility.destring(string)\n        regex = re.compile(\n            r'^(?:http|ftp)s?://'  # http:// or https://\n            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+'\n            r'(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|'  # domain...\n            # localhost...\n            r'localhost|'\n            r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})'  # ...or ip\n            # optional port\n            r'(?::\\d+)?'\n            r'(?:/?|[/?]\\S+)$',\n            re.IGNORECASE)\n        return regex.match(arg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef isstring(self, string, *args):\n        regex = re.compile(r'\\'[^\\']*\\'|\"[^\"]*\"')\n        return regex.match(string)", "response": "Is string containing a valid tag"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef increment(self, value, *args):\n        n, u = utility.analyze_number(value)\n        return utility.with_unit(n + 1, u)", "response": "Increment function for a log entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding integers to a set of integers.", "response": "def add(self, *args):\n        \"\"\" Add integers\n        args:\n            args (list): target\n        returns:\n            str\n        \"\"\"\n        if (len(args) <= 1):\n            return 0\n        return sum([int(v) for v in args])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the number of the log entry in the specified unit.", "response": "def round(self, value, *args):\n        \"\"\" Round number\n        args:\n            value (str): target\n        returns:\n            str\n        \"\"\"\n        n, u = utility.analyze_number(value)\n        return utility.with_unit(\n            int(utility.away_from_zero_round(float(n))), u)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ceil(self, value, *args):\n        n, u = utility.analyze_number(value)\n        return utility.with_unit(int(math.ceil(n)), u)", "response": "ceil - Calculates the ceiling of a number in a set of units"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the value in a percentage.", "response": "def percentage(self, value, *args):\n        \"\"\" Return percentage value\n        args:\n            value (str): target\n        returns:\n            str\n        \"\"\"\n        n, u = utility.analyze_number(value)\n        n = int(n * 100.0)\n        u = '%'\n        return utility.with_unit(n, u)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess color expression returns string", "response": "def process(self, expression):\n        \"\"\" Process color expression\n        args:\n            expression (tuple): color expression\n        returns:\n            str\n        \"\"\"\n        a, o, b = expression\n        c1 = self._hextorgb(a)\n        c2 = self._hextorgb(b)\n        r = ['#']\n        for i in range(3):\n            v = self.operate(c1[i], c2[i], o)\n            if v > 0xff:\n                v = 0xff\n            if v < 0:\n                v = 0\n            r.append(\"%02x\" % int(v))\n        return ''.join(r)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndoing a operation on colors", "response": "def operate(self, left, right, operation):\n        \"\"\" Do operation on colors\n        args:\n            left (str): left side\n            right (str): right side\n            operation (str): Operation\n        returns:\n            str\n        \"\"\"\n        operation = {\n            '+': operator.add,\n            '-': operator.sub,\n            '*': operator.mul,\n            '/': operator.truediv\n        }.get(operation)\n        return operation(left, right)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntranslates rgb to color string", "response": "def rgb(self, *args):\n        \"\"\" Translate rgb(...) to color string\n        raises:\n            ValueError\n        returns:\n            str\n        \"\"\"\n        if len(args) == 4:\n            args = args[:3]\n        if len(args) == 3:\n            try:\n                return self._rgbatohex(list(map(int, args)))\n            except ValueError:\n                if all((a for a in args\n                        if a[-1] == '%' and 100 >= int(a[:-1]) >= 0)):\n                    return self._rgbatohex(\n                        [int(a[:-1]) * 255 / 100.0 for a in args])\n        raise ValueError('Illegal color values')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rgba(self, *args):\n        if len(args) == 4:\n            try:\n                falpha = float(list(args)[3])\n                if falpha > 1:\n                    args = args[:3]\n                if falpha == 0:\n                    values = self._rgbatohex_raw(list(map(int, args)))\n                    return \"rgba(%s)\" % ','.join([str(a) for a in values])\n                return self._rgbatohex(list(map(int, args)))\n            except ValueError:\n                if all((a for a in args\n                        if a[-1] == '%' and 100 >= int(a[:-1]) >= 0)):\n                    alpha = list(args)[3]\n                    if alpha[-1] == '%' and float(alpha[:-1]) == 0:\n                        values = self._rgbatohex_raw(\n                            [int(a[:-1]) * 255 / 100.0 for a in args])\n                        return \"rgba(%s)\" % ','.join([str(a) for a in values])\n                    return self._rgbatohex(\n                        [int(a[:-1]) * 255 / 100.0 for a in args])\n        raise ValueError('Illegal color values')", "response": "Translate rgba to color string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef argb(self, *args):\n        if len(args) == 1 and type(args[0]) is str:\n            match = re.match(r'rgba\\((.*)\\)', args[0])\n            if match:\n                # NOTE(saschpe): Evil hack to cope with rgba(.., .., .., 0.5) passed through untransformed\n                rgb = re.sub(r'\\s+', '', match.group(1)).split(',')\n            else:\n                rgb = list(self._hextorgb(args[0]))\n        else:\n            rgb = list(args)\n        if len(rgb) == 3:\n            return self._rgbatohex([255] + list(map(int, rgb)))\n        elif len(rgb) == 4:\n            rgb = [rgb.pop()] + rgb  # Move Alpha to front\n            try:\n                fval = float(list(rgb)[0])\n                if fval > 1:\n                    rgb = [255] + rgb[1:]  # Clip invalid integer/float values\n                elif 1 >= fval >= 0:\n                    rgb = [\n                        fval * 256\n                    ] + rgb[1:]  # Convert 0-1 to 0-255 range for _rgbatohex\n                else:\n                    rgb = [0] + rgb[1:]  # Clip lower bound\n                return self._rgbatohex(list(map(int, rgb)))\n            except ValueError:\n                if all((a for a in rgb\n                        if a[-1] == '%' and 100 >= int(a[:-1]) >= 0)):\n                    return self._rgbatohex(\n                        [int(a[:-1]) * 255 / 100.0 for a in rgb])\n        raise ValueError('Illegal color values')", "response": "Translate argb to color string"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntranslating hsl to color string raises ValueError ValueError", "response": "def hsl(self, *args):\n        \"\"\" Translate hsl(...) to color string\n        raises:\n            ValueError\n        returns:\n            str\n        \"\"\"\n        if len(args) == 4:\n            return self.hsla(*args)\n        elif len(args) == 3:\n            h, s, l = args\n            rgb = colorsys.hls_to_rgb(\n                int(h) / 360.0, utility.pc_or_float(l), utility.pc_or_float(s))\n            color = (utility.convergent_round(c * 255) for c in rgb)\n            return self._rgbatohex(color)\n        raise ValueError('Illegal color values')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hsla(self, *args):\n        if len(args) == 4:\n            h, s, l, a = args\n            rgb = colorsys.hls_to_rgb(\n                int(h) / 360.0, utility.pc_or_float(l), utility.pc_or_float(s))\n            color = [float(utility.convergent_round(c * 255)) for c in rgb]\n            color.append(utility.pc_or_float(a))\n            return \"rgba(%s,%s,%s,%s)\" % tuple(color)\n        raise ValueError('Illegal color values')", "response": "Translate hsla to color string raises ValueError ValueError"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the hue value of a color in a nutl.", "response": "def hue(self, color, *args):\n        \"\"\" Return the hue value of a color\n        args:\n            color (str): color\n        raises:\n            ValueError\n        returns:\n            float\n        \"\"\"\n        if color:\n            h, l, s = self._hextohls(color)\n            return utility.convergent_round(h * 360.0, 3)\n        raise ValueError('Illegal color values')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the saturation value of a color in a nutime.", "response": "def saturation(self, color, *args):\n        \"\"\" Return the saturation value of a color\n        args:\n            color (str): color\n        raises:\n            ValueError\n        returns:\n            float\n        \"\"\"\n        if color:\n            h, l, s = self._hextohls(color)\n            return s * 100.0\n        raise ValueError('Illegal color values')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlightens a color args: color (str): color diff (str): percentage returns: str", "response": "def lighten(self, color, diff, *args):\n        \"\"\" Lighten a color\n        args:\n            color (str): color\n            diff (str): percentage\n        returns:\n            str\n        \"\"\"\n        if color and diff:\n            return self._ophsl(color, diff, 1, operator.add)\n        raise ValueError('Illegal color values')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndarkening a color args: color (str): color diff (str): percentage returns: str", "response": "def darken(self, color, diff, *args):\n        \"\"\" Darken a color\n        args:\n            color (str): color\n            diff (str): percentage\n        returns:\n            str\n        \"\"\"\n        if color and diff:\n            return self._ophsl(color, diff, 1, operator.sub)\n        raise ValueError('Illegal color values')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nspins color by degree.", "response": "def spin(self, color, degree, *args):\n        \"\"\" Spin color by degree. (Increase / decrease hue)\n        args:\n            color (str): color\n            degree (str): percentage\n        raises:\n            ValueError\n        returns:\n            str\n        \"\"\"\n        if color and degree:\n            if isinstance(degree, string_types):\n                degree = float(degree.strip('%'))\n            h, l, s = self._hextohls(color)\n            h = ((h * 360.0) + degree) % 360.0\n            h = 360.0 + h if h < 0 else h\n            rgb = colorsys.hls_to_rgb(h / 360.0, l, s)\n            color = (utility.convergent_round(c * 255) for c in rgb)\n            return self._rgbatohex(color)\n        raise ValueError('Illegal color values')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat CSS Hex color code.", "response": "def fmt(self, color):\n        \"\"\" Format CSS Hex color code.\n        uppercase becomes lowercase, 3 digit codes expand to 6 digit.\n        args:\n            color (str): color\n        raises:\n            ValueError\n        returns:\n            str\n        \"\"\"\n        if utility.is_color(color):\n            color = color.lower().strip('#')\n            if len(color) in [3, 4]:\n                color = ''.join([c * 2 for c in color])\n            return '#%s' % color\n        raise ValueError('Cannot format non-color')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nflattening a list of items into a single element", "response": "def flatten(lst):\n    \"\"\"Flatten list.\n    Args:\n        lst (list): List to flatten\n    Returns:\n        generator\n    \"\"\"\n    for elm in lst:\n        if isinstance(elm, collections.Iterable) and not isinstance(\n                elm, string_types):\n            for sub in flatten(elm):\n                yield sub\n        else:\n            yield elm"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pairwise(lst):\n    if not lst:\n        return\n    length = len(lst)\n    for i in range(length - 1):\n        yield lst[i], lst[i + 1]\n    yield lst[-1], None", "response": "Yields items i and i + 1 in lst. e. g. item i and item i + 1 in lst. e. g. item i and item i + 1 in lst. e. g. item i and item i + 1 in lst. e. g. item i + 1 is None is returned."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrename all sub - blocks moved under another block.", "response": "def rename(blocks, scope, stype):\n    \"\"\" Rename all sub-blocks moved under another\n        block. (mixins)\n    Args:\n        lst (list): block list\n        scope (object): Scope object\n    \"\"\"\n    for p in blocks:\n        if isinstance(p, stype):\n            p.tokens[0].parse(scope)\n            if p.tokens[1]:\n                scope.push()\n                scope.current = p.tokens[0]\n                rename(p.tokens[1], scope, stype)\n                scope.pop()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef blocksearch(block, name):\n    if hasattr(block, 'tokens'):\n        for b in block.tokens[1]:\n            b = (b if hasattr(b, 'raw') and b.raw() == name else blocksearch(\n                b, name))\n            if b:\n                return b\n    return False", "response": "Recursive search for name in block"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreverses guard expression. not (@a > 5) -> (@a =< 5) Args: lst (list): Expression returns: list", "response": "def reverse_guard(lst):\n    \"\"\" Reverse guard expression. not\n        (@a > 5) ->  (@a =< 5)\n    Args:\n        lst (list): Expression\n    returns:\n        list\n    \"\"\"\n    rev = {'<': '>=', '>': '=<', '>=': '<', '=<': '>'}\n    return [rev[l] if l in rev else l for l in lst]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef debug_print(lst, lvl=0):\n    pad = ''.join(['\\t.'] * lvl)\n    t = type(lst)\n    if t is list:\n        for p in lst:\n            debug_print(p, lvl)\n    elif hasattr(lst, 'tokens'):\n        print(pad, t)\n        debug_print(list(flatten(lst.tokens)), lvl + 1)", "response": "Print scope tree with nesting level lvl."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef analyze_number(var, err=''):\n    n, u = split_unit(var)\n    if not isinstance(var, string_types):\n        return (var, u)\n    if is_color(var):\n        return (var, 'color')\n    if is_int(n):\n        n = int(n)\n    elif is_float(n):\n        n = float(n)\n    else:\n        raise SyntaxError('%s \u00b4%s\u00b4' % (err, var))\n    return (n, u)", "response": "Analyse number for type and split from unit\n    1px -> ( q px )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn number with unit", "response": "def with_unit(number, unit=None):\n    \"\"\" Return number with unit\n    args:\n        number (mixed): Number\n        unit (str): Unit\n    returns:\n        str\n    \"\"\"\n    if isinstance(number, tuple):\n        number, unit = number\n    if number == 0:\n        return '0'\n    if unit:\n        number = str(number)\n        if number.startswith('.'):\n            number = '0' + number\n        return \"%s%s\" % (number, unit)\n    return number if isinstance(number, string_types) else str(number)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nam string CSS color", "response": "def is_color(value):\n    \"\"\" Is string CSS color\n    args:\n        value (str): string\n    returns:\n        bool\n    \"\"\"\n    if not value or not isinstance(value, string_types):\n        return False\n    if value[0] == '#' and len(value) in [4, 5, 7, 9]:\n        try:\n            int(value[1:], 16)\n            return True\n        except ValueError:\n            pass\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_variable(value):\n    if isinstance(value, string_types):\n        return (value.startswith('@') or value.startswith('-@'))\n    elif isinstance(value, tuple):\n        value = ''.join(value)\n        return (value.startswith('@') or value.startswith('-@'))\n    return False", "response": "Check if string is LESS variable"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nam value float args: value (str): string returns: bool", "response": "def is_float(value):\n    \"\"\" Is value float\n    args:\n        value (str): string\n    returns:\n        bool\n    \"\"\"\n    if not is_int(value):\n        try:\n            float(str(value))\n            return True\n        except (ValueError, TypeError):\n            pass\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsplitting a number from its unit 1px -> q px", "response": "def split_unit(value):\n    \"\"\" Split a number from its unit\n        1px -> (q, 'px')\n    Args:\n        value (str): input\n    returns:\n        tuple\n    \"\"\"\n    r = re.search('^(\\-?[\\d\\.]+)(.*)$', str(value))\n    return r.groups() if r else ('', '')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrounds half - way away from zero.", "response": "def away_from_zero_round(value, ndigits=0):\n    \"\"\"Round half-way away from zero.\n\n    Python2's round() method.\n    \"\"\"\n    if sys.version_info[0] >= 3:\n        p = 10**ndigits\n        return float(math.floor((value * p) + math.copysign(0.5, value))) / p\n    else:\n        return round(value, ndigits)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pc_or_float(s):\n    if isinstance(s, string_types) and '%' in s:\n        return float(s.strip('%')) / 100.0\n    return float(s)", "response": "Utility function to process strings that contain either percentiles or floats"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef permutations_with_replacement(iterable, r=None):\n    pool = tuple(iterable)\n    n = len(pool)\n    r = n if r is None else r\n    for indices in itertools.product(range(n), repeat=r):\n        yield list(pool[i] for i in indices)", "response": "Returns successive r length permutations of elements in the iterable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a node name and return the node name.", "response": "def parse(self, scope):\n        \"\"\" Parse Node\n        args:\n            scope (Scope): Scope object\n        raises:\n            SyntaxError\n        returns:\n            str\n        \"\"\"\n        assert (len(self.tokens) == 3)\n        expr = self.process(self.tokens, scope)\n        A, O, B = [\n            e[0] if isinstance(e, tuple) else e for e in expr\n            if str(e).strip()\n        ]\n        try:\n            a, ua = utility.analyze_number(A, 'Illegal element in expression')\n            b, ub = utility.analyze_number(B, 'Illegal element in expression')\n        except SyntaxError:\n            return ' '.join([str(A), str(O), str(B)])\n        if (a is False or b is False):\n            return ' '.join([str(A), str(O), str(B)])\n        if ua == 'color' or ub == 'color':\n            return color.Color().process((A, O, B))\n        if a == 0 and O == '/':\n            # NOTE(saschpe): The ugliest but valid CSS since sliced bread: 'font: 0/1 a;'\n            return ''.join([str(A), str(O), str(B), ' '])\n        out = self.operate(a, b, O)\n        if isinstance(out, bool):\n            return out\n        return self.with_units(out, ua, ub)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn value with unit.", "response": "def with_units(self, val, ua, ub):\n        \"\"\"Return value with unit.\n        args:\n            val (mixed): result\n            ua (str): 1st unit\n            ub (str): 2nd unit\n        raises:\n            SyntaxError\n        returns:\n            str\n        \"\"\"\n        if not val:\n            return str(val)\n        if ua or ub:\n            if ua and ub:\n                if ua == ub:\n                    return str(val) + ua\n                else:\n                    # Nodejs version does not seem to mind mismatched\n                    # units within expressions. So we choose the first\n                    # as they do\n                    # raise SyntaxError(\"Error in expression %s != %s\" % (ua, ub))\n                    return str(val) + ua\n            elif ua:\n                return str(val) + ua\n            elif ub:\n                return str(val) + ub\n        return repr(val)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef operate(self, vala, valb, oper):\n        operation = {\n            '+': operator.add,\n            '-': operator.sub,\n            '*': operator.mul,\n            '/': operator.truediv,\n            '=': operator.eq,\n            '>': operator.gt,\n            '<': operator.lt,\n            '>=': operator.ge,\n            '=<': operator.le,\n        }.get(oper)\n        if operation is None:\n            raise SyntaxError(\"Unknown operation %s\" % oper)\n        ret = operation(vala, valb)\n        if oper in '+-*/' and int(ret) == ret:\n            ret = int(ret)\n        return ret", "response": "Perform an operation on the key - value pair."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a file into a set of unique identifiers.", "response": "def parse(self, filename=None, file=None, debuglevel=0):\n        \"\"\" Parse file.\n        kwargs:\n            filename (str): File to parse\n            debuglevel (int): Parser debuglevel\n        \"\"\"\n        self.scope.push()\n\n        if not file:\n            # We use a path.\n            file = filename\n        else:\n            # We use a stream and try to extract the name from the stream.\n            if hasattr(file, 'name'):\n                if filename is not None:\n                    raise AssertionError(\n                        'names of file and filename are in conflict')\n                filename = file.name\n            else:\n                filename = '(stream)'\n\n        self.target = filename\n        if self.verbose and not self.fail_with_exc:\n            print('Compiling target: %s' % filename, file=sys.stderr)\n        self.result = self.parser.parse(file, lexer=self.lex, debug=debuglevel)\n\n        self.post_parse()\n        self.register.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef post_parse(self):\n        if self.result:\n            out = []\n            for pu in self.result:\n                try:\n                    out.append(pu.parse(self.scope))\n                except SyntaxError as e:\n                    self.handle_error(e, 0)\n            self.result = list(utility.flatten(out))", "response": "Post parse cycle. nodejs version allows calls to mixins\n        not yet defined or known to the parser. We defer all calls\n        to mixins until after first cycle when all names are known."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_unit_list(self, p):\n        if isinstance(p[1], list):\n            if len(p) >= 3:\n                if isinstance(p[2], list):\n                    p[1].extend(p[2])\n                else:\n                    p[1].append(p[2])\n        else:\n            p[1] = [p[1]]\n        p[0] = p[1]", "response": "unit_list - list of all units"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_statement_namespace(self, p):\n        p[0] = Statement(list(p)[1:], p.lineno(1))\n        p[0].parse(None)", "response": "Parse a statement in the form of a namespace."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_block(self, p):\n        p[0] = Block(list(p)[1:-1], p.lineno(3))\n        self.scope.pop()\n        self.scope.add_block(p[0])", "response": "block_decl               : block_open declaration_list brace_close"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreplaces block with new one.", "response": "def p_block_replace(self, p):\n        \"\"\" block_decl               : identifier t_semicolon\n        \"\"\"\n        m = p[1].parse(None)\n        block = self.scope.blocks(m.raw())\n        if block:\n            p[0] = block.copy_inner(self.scope)\n        else:\n            # fallback to mixin. Allow calls to mixins without parens\n            p[0] = Deferred(p[1], None, p.lineno(2))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_font_face_open(self, p):\n        p[0] = Identifier([p[1], p[2]]).parse(self.scope)", "response": "P font face open section"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p_open_mixin(self, p):\n        p[1].parse(self.scope)\n        self.scope.current = p[1]\n        p[0] = [p[1], p[3]]\n        if len(p) > 6:\n            p[0].append(p[5])\n        else:\n            p[0].append(None)", "response": "open_mixin - Handles the mixin - level open - mixin command."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_mixin_guard_cond_list_aux(self, p):\n        p[1].append(p[2])\n        p[1].append(p[3])\n        p[0] = p[1]", "response": "A mixin guard condition list auxiliary function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef p_call_mixin(self, p):\n        p[1].parse(None)\n        p[0] = Deferred(p[1], p[3], p.lineno(4))", "response": "\\ x1b [ 1mNAME \\ x1b [ 0m mixin - Augment the mixin with a Deferred object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef p_declaration_list(self, p):\n        if len(p) > 2:\n            p[1].extend(p[2])\n        p[0] = p[1]", "response": "A function to add the declaration_list to the given parameter list."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_variable_decl(self, p):\n        p[0] = Variable(list(p)[1:-1], p.lineno(4))\n        p[0].parse(self.scope)", "response": "variable_decl            : variable t_colon style_list t_semicolon"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the property declaration.", "response": "def p_property_decl(self, p):\n        \"\"\" property_decl           : prop_open style_list t_semicolon\n                                    | prop_open style_list css_important t_semicolon\n                                    | prop_open empty t_semicolon\n        \"\"\"\n        l = len(p)\n        p[0] = Property(list(p)[1:-1], p.lineno(l - 1))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_identifier_list_aux(self, p):\n        p[1].extend([p[2]])\n        p[1].extend(p[3])\n        p[0] = p[1]", "response": "A version of the identifier_list_aux method."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_identifier_group_op(self, p):\n        p[1].extend([p[2]])\n        if len(p) > 3:\n            p[1].extend(p[3])\n        p[0] = p[1]", "response": "A function to handle the identifier_group operation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_ident_parts_aux(self, p):\n        if isinstance(p[2], list):\n            p[1].extend(p[2])\n        else:\n            p[1].append(p[2])\n        p[0] = p[1]", "response": "A version of p_ident_parts_aux that adds the new version to the list of the set of available ident_parts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef p_ident_parts(self, p):\n        if not isinstance(p[1], list):\n            p[1] = [p[1]]\n        p[0] = p[1]", "response": "A helper function to set the ident_parts               property in a dict."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_media_query_value(self, p):\n        if utility.is_variable(p[1]):\n            var = self.scope.variables(''.join(p[1]))\n            if var:\n                value = var.value[0]\n                if hasattr(value, 'parse'):\n                    p[1] = value.parse(self.scope)\n                else:\n                    p[1] = value\n        if isinstance(p[1], Expression):\n            p[0] = p[1].parse(self.scope)\n        else:\n            p[0] = p[1]", "response": "media_query_value           : number\n                                        | variable\n                                        | word\n                                        | color\n                                        | expression"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef p_color(self, p):\n        try:\n            p[0] = Color().fmt(p[1])\n            if len(p) > 2:\n                p[0] = [p[0], p[2]]\n        except ValueError:\n            self.handle_error('Illegal color value `%s`' % p[1], p.lineno(1),\n                              'W')\n            p[0] = p[1]", "response": "color                   : css_color\n                                    | css_color t_ws"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef p_error(self, t):\n        if t:\n            error_msg = \"E: %s line: %d, Syntax Error, token: `%s`, `%s`\" % \\\n                      (self.target, t.lineno, t.type, t.value)\n            self.register.register(error_msg)\n        while True:\n            t = self.lex.token()\n            if not t or t.value == '}':\n                if len(self.scope) > 1:\n                    self.scope.pop()\n                break\n        self.parser.restart()\n        return t", "response": "Internal error handler for the internal error handler."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_error(self, e, line, t='E'):\n        self.register.register(\"%s: line: %d: %s\\n\" % (t, line, e))", "response": "Custom error handler for the\n            class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing node s tokens and return a list of parsed tokens.", "response": "def parse(self, scope):\n        \"\"\"Parse node\n        args:\n            scope (Scope): current scope\n        raises:\n            SyntaxError\n        returns:\n            parsed\n        \"\"\"\n        if not self.parsed:\n            self.parsed = ''.join(self.process(self.tokens, scope))\n        return self.parsed"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef NextPage(gh):\n    header = dict(gh.getheaders())\n    if 'Link' in header:\n        parts = header['Link'].split(',')\n        for part in parts:\n            subparts = part.split(';')\n            sub = subparts[1].split('=')\n            if sub[0].strip() == 'rel':\n                if sub[1] == '\"next\"':\n                    page = int(\n                        re.match(\n                            r'.*page=(\\d+).*', subparts[0],\n                            re.IGNORECASE | re.DOTALL | re.UNICODE\n                        ).groups()[0]\n                    )\n                    return page\n    return 0", "response": "Checks if a GitHub call returned multiple pages of data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch GitHub token from git config and last CHANGELOG_GITHUB_TOKEN env variable.", "response": "def fetch_github_token(self):\n        \"\"\"\n        Fetch GitHub token. First try to use variable provided\n        by --token option, otherwise try to fetch it from git config\n        and last CHANGELOG_GITHUB_TOKEN env variable.\n\n        :returns: Nothing\n        \"\"\"\n\n        if not self.options.token:\n            try:\n                for v in GH_CFG_VARS:\n                    cmd = ['git', 'config', '--get', '{0}'.format(v)]\n                    self.options.token = subprocess.Popen(\n                        cmd, stdout=subprocess.PIPE).communicate()[0].strip()\n                    if self.options.token:\n                        break\n            except (subprocess.CalledProcessError, WindowsError):\n                pass\n        if not self.options.token:\n            self.options.token = os.environ.get(CHANGELOG_GITHUB_TOKEN)\n        if not self.options.token:\n            print(NO_TOKEN_PROVIDED)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfetches all tags for a repository from Github.", "response": "def get_all_tags(self):\n        \"\"\"\n        Fetch all tags for repository from Github.\n\n        :return: tags in repository\n        :rtype: list\n        \"\"\"\n\n        verbose = self.options.verbose\n        gh = self.github\n        user = self.options.user\n        repo = self.options.project\n        if verbose:\n            print(\"Fetching tags...\")\n\n        tags = []\n        page = 1\n        while page > 0:\n            if verbose > 2:\n                print(\".\", end=\"\")\n            rc, data = gh.repos[user][repo].tags.get(\n                page=page, per_page=PER_PAGE_NUMBER)\n            if rc == 200:\n                tags.extend(data)\n            else:\n                self.raise_GitHubError(rc, data, gh.getheaders())\n            page = NextPage(gh)\n        if verbose > 2:\n            print(\".\")\n\n        if len(tags) == 0:\n            if not self.options.quiet:\n                print(\"Warning: Can't find any tags in repo. Make sure, that \"\n                      \"you push tags to remote repo via 'git push --tags'\")\n                exit()\n        if verbose > 1:\n            print(\"Found {} tag(s)\".format(len(tags)))\n        return tags"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fetch_closed_issues_and_pr(self):\n\n        verbose = self.options.verbose\n        gh = self.github\n        user = self.options.user\n        repo = self.options.project\n        if verbose:\n            print(\"Fetching closed issues and pull requests...\")\n\n        data = []\n        issues = []\n        data = []\n        page = 1\n        while page > 0:\n            if verbose > 2:\n                print(\".\", end=\"\")\n            rc, data = gh.repos[user][repo].issues.get(\n                page=page, per_page=PER_PAGE_NUMBER,\n                state='closed', filter='all'\n            )\n            if rc == 200:\n                issues.extend(data)\n            else:\n                self.raise_GitHubError(rc, data, gh.getheaders())\n            if len(issues) >= self.options.max_issues:\n                break\n            page = NextPage(gh)\n        self.first_issue = data[-1] if len(data) > 0 else []\n        if verbose > 2:\n            print(\".\")\n\n        # separate arrays of issues and pull requests:\n        prs = []\n        iss = []\n        for i in issues:\n            if \"pull_request\" in i:\n                prs.append(i)\n            else:\n                iss.append(i)\n        if verbose > 1:\n            print(\"\\treceived {} issues and  {} pull requests.\".format(\n                len(iss), len(prs))\n            )\n        return iss, prs", "response": "This method fetches all closed issues and pull requests and pure issues and pure issues."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfetches all closed pull requests. We need them to detect merged_at", "response": "def fetch_closed_pull_requests(self):\n        \"\"\"\n        Fetch all pull requests. We need them to detect \"merged_at\" parameter\n\n        :rtype: list\n        :return: all pull requests\n        \"\"\"\n\n        pull_requests = []\n        verbose = self.options.verbose\n        gh = self.github\n        user = self.options.user\n        repo = self.options.project\n        if verbose:\n            print(\"Fetching closed pull requests...\")\n        page = 1\n        while page > 0:\n            if verbose > 2:\n                print(\".\", end=\"\")\n\n            if self.options.release_branch:\n                rc, data = gh.repos[user][repo].pulls.get(\n                    page=page, per_page=PER_PAGE_NUMBER, state='closed',\n                    base=self.options.release_branch\n                )\n            else:\n                rc, data = gh.repos[user][repo].pulls.get(\n                    page=page, per_page=PER_PAGE_NUMBER, state='closed',\n                )\n\n            if rc == 200:\n                pull_requests.extend(data)\n            else:\n                self.raise_GitHubError(rc, data, gh.getheaders())\n            page = NextPage(gh)\n        if verbose > 2:\n            print(\".\")\n        if verbose > 1:\n            print(\"\\tfetched {} closed pull requests.\".format(\n                len(pull_requests))\n            )\n        return pull_requests"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fetch_repo_creation_date(self):\n        gh = self.github\n        user = self.options.user\n        repo = self.options.project\n        rc, data = gh.repos[user][repo].get()\n        if rc == 200:\n            return REPO_CREATED_TAG_NAME, data[\"created_at\"]\n        else:\n            self.raise_GitHubError(rc, data, gh.getheaders())\n        return None, None", "response": "Fetch the creation date of the repository from GitHub."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfetch events for all issues and add them to self. events", "response": "def fetch_events_async(self, issues, tag_name):\n        \"\"\"\n        Fetch events for all issues and add them to self.events\n\n        :param list issues: all issues\n        :param str tag_name: name of the tag to fetch events for\n        :returns: Nothing\n        \"\"\"\n\n        if not issues:\n            return issues\n\n        max_simultaneous_requests = self.options.max_simultaneous_requests\n        verbose = self.options.verbose\n        gh = self.github\n        user = self.options.user\n        repo = self.options.project\n        self.events_cnt = 0\n        if verbose:\n            print(\"fetching events for {} {}... \".format(\n                len(issues), tag_name)\n            )\n\n        def worker(issue):\n            page = 1\n            issue['events'] = []\n            while page > 0:\n                rc, data = gh.repos[user][repo].issues[\n                    issue['number']].events.get(\n                    page=page, per_page=PER_PAGE_NUMBER)\n                if rc == 200:\n                    issue['events'].extend(data)\n                    self.events_cnt += len(data)\n                else:\n                    self.raise_GitHubError(rc, data, gh.getheaders())\n                page = NextPage(gh)\n\n        threads = []\n        cnt = len(issues)\n        for i in range(0, (cnt // max_simultaneous_requests) + 1):\n            for j in range(max_simultaneous_requests):\n                idx = i * max_simultaneous_requests + j\n                if idx == cnt:\n                    break\n                t = threading.Thread(target=worker, args=(issues[idx],))\n                threads.append(t)\n                t.start()\n                if verbose > 2:\n                    print(\".\", end=\"\")\n                    if not idx % PER_PAGE_NUMBER:\n                        print(\"\")\n            for t in threads:\n                t.join()\n        if verbose > 2:\n            print(\".\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch time of specified tag from repository.", "response": "def fetch_date_of_tag(self, tag):\n        \"\"\"\n        Fetch time for tag from repository.\n\n        :param dict tag: dictionary with tag information\n        :rtype: str\n        :return: time of specified tag as ISO date string\n        \"\"\"\n\n        if self.options.verbose > 1:\n            print(\"\\tFetching date for tag {}\".format(tag[\"name\"]))\n        gh = self.github\n        user = self.options.user\n        repo = self.options.project\n\n        rc, data = gh.repos[user][repo].git.commits[\n            tag[\"commit\"][\"sha\"]].get()\n        if rc == 200:\n            return data[\"committer\"][\"date\"]\n        self.raise_GitHubError(rc, data, gh.getheaders())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetch_commit(self, event):\n\n        gh = self.github\n        user = self.options.user\n        repo = self.options.project\n\n        rc, data = gh.repos[user][repo].git.commits[\n            event[\"commit_id\"]].get()\n        if rc == 200:\n            return data\n        self.raise_GitHubError(rc, data, gh.getheaders())", "response": "Fetch the commit data for the specified event."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self):\n        if not self.options.project or not self.options.user:\n            print(\"Project and/or user missing. \"\n                  \"For help run:\\n  pygcgen --help\")\n            return\n\n        if not self.options.quiet:\n            print(\"Generating changelog...\")\n\n        log = None\n        try:\n            log = self.generator.compound_changelog()\n        except ChangelogGeneratorError as err:\n            print(\"\\n\\033[91m\\033[1m{}\\x1b[0m\".format(err.args[0]))\n            exit(1)\n        if not log:\n            if not self.options.quiet:\n                print(\"Empty changelog generated. {} not written.\".format(\n                    self.options.output)\n                )\n            return\n\n        if self.options.no_overwrite:\n            out = checkname(self.options.output)\n        else:\n            out = self.options.output\n\n        with codecs.open(out, \"w\", \"utf-8\") as fh:\n            fh.write(log)\n\n        if not self.options.quiet:\n            print(\"Done!\")\n            print(\"Generated changelog written to {}\".format(out))", "response": "Generate a new entry point for one of the tags in the list of tags."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_heading(heading):\n\n    heading_structures = [\n        r\"^## \\[(?P<version>.+?)\\]\\((?P<url>.+?)\\)( \\((?P<date>.+?)\\))?$\",\n        r\"^## (?P<version>.+?)( \\((?P<date>.+?)\\))?$\",\n        ]\n    captures = {\"version\": None, \"url\": None, \"date\": None}\n\n    for regexp in heading_structures:\n        matches = re.match(regexp, heading)\n        if matches:\n            captures.update(matches.groupdict())\n            break\n    return captures", "response": "Parse a single heading and return a Hash containing version url and date."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse(data):\n\n    sections = re.compile(\"^## .+$\", re.MULTILINE).split(data)\n    headings = re.findall(\"^## .+?$\", data, re.MULTILINE)\n    sections.pop(0)\n    parsed = []\n\n    def func(h, s):\n        p = parse_heading(h)\n        p[\"content\"] = s\n        parsed.append(p)\n\n    list(map(func, headings, sections))\n    return parsed", "response": "Parse the given ChangeLog data into a list of Hashes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate the signal handler map based on self. signal_map", "response": "def _signal_handler_map(self):\n        \"\"\" Create the signal handler map\n\n        create a dictionary with signal:handler mapping based on\n        self.signal_map\n\n        :return: dict\n        \"\"\"\n        result = {}\n        for signum, handler in self.signal_map.items():\n            result[signum] = self._get_signal_handler(handler)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef open(self):\n        if self.is_open:\n            return\n        try:\n            os.chdir(self.working_directory)\n            if self.chroot_directory:\n                os.chroot(self.chroot_directory)\n            os.setgid(self.gid)\n            os.setuid(self.uid)\n            os.umask(self.umask)\n        except OSError as err:\n            raise DaemonError('Setting up Environment failed: {0}'\n                              .format(err))\n\n        if self.prevent_core:\n            try:\n                resource.setrlimit(resource.RLIMIT_CORE, (0, 0))\n            except Exception as err:\n                raise DaemonError('Could not disable core files: {0}'\n                                  .format(err))\n\n        if self.detach_process:\n            try:\n                if os.fork() > 0:\n                    os._exit(0)\n            except OSError as err:\n                raise DaemonError('First fork failed: {0}'.format(err))\n            os.setsid()\n            try:\n                if os.fork() > 0:\n                    os._exit(0)\n            except OSError as err:\n                raise DaemonError('Second fork failed: {0}'.format(err))\n\n        for (signal_number, handler) in self._signal_handler_map.items():\n            signal.signal(signal_number, handler)\n\n        close_filenos(self._files_preserve)\n\n        redirect_stream(sys.stdin, self.stdin)\n        redirect_stream(sys.stdout, self.stdout)\n        redirect_stream(sys.stderr, self.stderr)\n\n        if self.pidfile:\n            self.pidfile.acquire()\n\n        self._is_open = True", "response": "Open the process and return the unique identifier."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef user_and_project_from_git(self, options, arg0=None, arg1=None):\n        user, project = self.user_project_from_option(options, arg0, arg1)\n        if user and project:\n            return user, project\n\n        try:\n            remote = subprocess.check_output(\n                [\n                    'git', 'config', '--get',\n                    'remote.{0}.url'.format(options.git_remote)\n                ]\n            )\n        except subprocess.CalledProcessError:\n            return None, None\n        except WindowsError:\n            print(\"git binary not found.\")\n            exit(1)\n        else:\n            return self.user_project_from_remote(remote)", "response": "Detects user and project from git."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntry to find user and project name from git remote command MimeType", "response": "def user_project_from_option(options, arg0, arg1):\n        \"\"\"\n        Try to find user and project name from git remote output\n\n        @param [String] output of git remote command\n        @return [Array] user and project\n        \"\"\"\n\n        site = options.github_site\n        if arg0 and not arg1:\n            # this match should parse strings such as\n            #   \"https://github.com/skywinder/Github-Changelog-Generator\"\n            # or\n            #   \"skywinder/Github-Changelog-Generator\"\n            #  to user and project\n            match = re.match(\n                \"(?:.+{site}/)?(.+)/(.+)\".format(site=site),\n                arg0\n            )\n            if not match:\n                print(\"Can't detect user and name from first \"\n                      \"parameter: '{arg0}' -> exit'\".format(arg0=arg0))\n                exit(1)\n            return match.groups()\n        return None, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef user_project_from_remote(remote):\n\n        # try to find repo in format:\n        # origin\tgit@github.com:skywinder/Github-Changelog-Generator.git (fetch)\n        # git@github.com:skywinder/Github-Changelog-Generator.git\n        regex1 = br\".*(?:[:/])(?P<user>(-|\\w|\\.)*)/\" \\\n                 br\"(?P<project>(-|\\w|\\.)*)(\\.git).*\"\n        match = re.match(regex1, remote)\n        if match:\n            return match.group(\"user\"), match.group(\"project\")\n\n        # try to find repo in format:\n        # origin\thttps://github.com/skywinder/ChangelogMerger (fetch)\n        # https://github.com/skywinder/ChangelogMerger\n        regex2 = r\".*/((?:-|\\w|\\.)*)/((?:-|\\w|\\.)*).*\"\n        match = re.match(regex2, remote)\n        if match:\n            return match.group(\"user\"), match.group(\"project\")\n\n        return None, None", "response": "Try to find user and project name from git remote output\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef timestring_to_datetime(timestring):\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UnicodeWarning)\n        result = dateutil_parser(timestring)\n\n    return result", "response": "Convert an ISO formated date and time string to a datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching event for issues and pull requests", "response": "def fetch_events_for_issues_and_pr(self):\n        \"\"\"\n        Fetch event for issues and pull requests\n\n        @return [Array] array of fetched issues\n        \"\"\"\n\n        # Async fetching events:\n        self.fetcher.fetch_events_async(self.issues, \"issues\")\n        self.fetcher.fetch_events_async(self.pull_requests, \"pull requests\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef detect_actual_closed_dates(self, issues, kind):\n\n        if self.options.verbose:\n            print(\"Fetching closed dates for {} {}...\".format(\n                len(issues), kind)\n            )\n        all_issues = copy.deepcopy(issues)\n        for issue in all_issues:\n            if self.options.verbose > 2:\n                print(\".\", end=\"\")\n                if not issues.index(issue) % 30:\n                    print(\"\")\n            self.find_closed_date_by_commit(issue)\n\n            if not issue.get('actual_date', False):\n                if issue.get('closed_at', False):\n                    print(\"Skipping closed non-merged issue: #{0} {1}\".format(\n                        issue[\"number\"], issue[\"title\"]))\n\n                all_issues.remove(issue)\n\n        if self.options.verbose > 2:\n            print(\".\")\n        return all_issues", "response": "Detects correct closed dates for issues that were closed by commits."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_closed_date_by_commit(self, issue):\n\n        if not issue.get('events'):\n            return\n        # if it's PR -> then find \"merged event\", in case\n        # of usual issue -> find closed date\n        compare_string = \"merged\" if 'merged_at' in issue else \"closed\"\n        # reverse! - to find latest closed event. (event goes in date order)\n        # if it were reopened and closed again.\n        issue['events'].reverse()\n        found_date = False\n        for event in issue['events']:\n            if event[\"event\"] == compare_string:\n                self.set_date_from_event(event, issue)\n                found_date = True\n                break\n        if not found_date:\n            # TODO: assert issues, that remain without\n            #       'actual_date' hash for some reason.\n            print(\"\\nWARNING: Issue without 'actual_date':\"\n                  \" #{0} {1}\".format(issue[\"number\"], issue[\"title\"]))", "response": "Find the closed date of a given issue by the commit."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_date_from_event(self, event, issue):\n\n        if not event.get('commit_id', None):\n            issue['actual_date'] = timestring_to_datetime(issue['closed_at'])\n            return\n        try:\n            commit = self.fetcher.fetch_commit(event)\n            issue['actual_date'] = timestring_to_datetime(\n                commit['author']['date']\n            )\n        except ValueError:\n            print(\"WARNING: Can't fetch commit {0}. \"\n                  \"It is probably referenced from another repo.\".\n                  format(event['commit_id']))\n            issue['actual_date'] = timestring_to_datetime(issue['closed_at'])", "response": "Set the actual date from this issue."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nencapsulates characters to make markdown look as expected.", "response": "def encapsulate_string(raw_string):\n        \"\"\"\n        Encapsulate characters to make markdown look as expected.\n\n        :param str raw_string: string to encapsulate\n        :rtype: str\n        :return: encapsulated input string\n        \"\"\"\n\n        raw_string.replace('\\\\', '\\\\\\\\')\n        enc_string = re.sub(\"([<>*_()\\[\\]#])\", r\"\\\\\\1\", raw_string)\n        return enc_string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compound_changelog(self):\n\n        self.fetch_and_filter_tags()\n        tags_sorted = self.sort_tags_by_date(self.filtered_tags)\n        self.filtered_tags = tags_sorted\n        self.fetch_and_filter_issues_and_pr()\n\n        log = str(self.options.frontmatter) \\\n            if self.options.frontmatter else u\"\"\n        log += u\"{0}\\n\\n\".format(self.options.header)\n\n        if self.options.unreleased_only:\n            log += self.generate_unreleased_section()\n        else:\n            log += self.generate_log_for_all_tags()\n\n        try:\n            with open(self.options.base) as fh:\n                log += fh.read()\n        except (TypeError, IOError):\n            pass\n        return log", "response": "Generates a compound change log file for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates formated list of issues for changelog.", "response": "def generate_sub_section(self, issues, prefix):\n        \"\"\"\n        Generate formated list of issues for changelog.\n\n        :param list issues: Issues to put in sub-section.\n        :param str prefix: Title of sub-section.\n        :rtype: str\n        :return: Generated ready-to-add sub-section.\n        \"\"\"\n\n        log = \"\"\n        if issues:\n            if not self.options.simple_list:\n                log += u\"{0}\\n\\n\".format(prefix)\n            for issue in issues:\n                merge_string = self.get_string_for_issue(issue)\n                log += u\"- {0}\\n\".format(merge_string)\n            log += \"\\n\"\n        return log"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a header for a tag section.", "response": "def generate_header(self, newer_tag_name, newer_tag_link,\n                        newer_tag_time,\n                        older_tag_link, project_url):\n        \"\"\"\n        Generate a header for a tag section with specific parameters.\n\n        :param str newer_tag_name: Name (title) of newer tag.\n        :param str newer_tag_link: Tag name of newer tag, used for links.\n                               Could be same as **newer_tag_name** or some\n                               specific value, like `HEAD`.\n        :param datetime newer_tag_time: Date and time when\n                                        newer tag was created.\n        :param str older_tag_link: Tag name of older tag, used for links.\n        :param str project_url: URL for current project.\n        :rtype: str\n        :return: Generated ready-to-add tag section.\n        \"\"\"\n\n        log = \"\"\n        # Generate date string:\n        # noinspection PyUnresolvedReferences\n        time_string = newer_tag_time.strftime(self.options.date_format)\n\n        # Generate tag name and link\n        if self.options.release_url:\n            release_url = self.options.release_url.format(newer_tag_link)\n        else:\n            release_url = u\"{project_url}/tree/{newer_tag_link}\".format(\n                project_url=project_url, newer_tag_link=newer_tag_link)\n\n        if not self.options.unreleased_with_date and \\\n                newer_tag_name == self.options.unreleased_label:\n            log += u\"## [{newer_tag_name}]({release_url})\\n\\n\".format(\n                newer_tag_name=newer_tag_name, release_url=release_url)\n        else:\n            log += u\"## [{newer_tag_name}]({release_url}) \" \\\n                   u\"({time_string})\\n\".format(\n                        newer_tag_name=newer_tag_name,\n                        release_url=release_url,\n                        time_string=time_string\n                   )\n\n        if self.options.compare_link \\\n            and older_tag_link != REPO_CREATED_TAG_NAME:\n            # Generate compare link\n            log += u\"[Full Changelog]\"\n            log += u\"({project_url}/compare/{older_tag_link}\".format(\n                project_url=project_url,\n                older_tag_link=older_tag_link,\n            )\n            log += u\"...{newer_tag_link})\\n\\n\".format(\n                newer_tag_link=newer_tag_link\n            )\n        return log"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates log between two tags.", "response": "def generate_log_between_tags(self, older_tag, newer_tag):\n        \"\"\"\n        Generate log between 2 specified tags.\n\n        :param dict older_tag: All issues before this tag's date will be\n                               excluded. May be special value, if new tag is\n                               the first tag. (Means **older_tag** is when\n                               the repo was created.)\n        :param dict newer_tag: All issues after this tag's date  will be\n                               excluded. May be title of unreleased section.\n        :rtype: str\n        :return: Generated ready-to-add tag section for newer tag.\n        \"\"\"\n\n        filtered_issues, filtered_pull_requests = \\\n            self.filter_issues_for_tags(newer_tag, older_tag)\n\n        older_tag_name = older_tag[\"name\"] if older_tag \\\n            else self.detect_since_tag()\n\n        if not filtered_issues and not filtered_pull_requests:\n            # do not generate an unreleased section if it would be empty\n            return \"\"\n        return self.generate_log_for_tag(\n            filtered_pull_requests, filtered_issues,\n            newer_tag, older_tag_name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying all filters to issues and pull requests.", "response": "def filter_issues_for_tags(self, newer_tag, older_tag):\n        \"\"\"\n        Apply all filters to issues and pull requests.\n\n        :param dict older_tag: All issues before this tag's date will be\n                               excluded. May be special value, if new tag is\n                               the first tag. (Means **older_tag** is when\n                               the repo  was created.)\n        :param dict newer_tag: All issues after this tag's date  will be\n                               excluded. May be title of unreleased section.\n        :rtype: list(dict), list(dict)\n        :return: Filtered issues and pull requests.\n        \"\"\"\n\n        filtered_pull_requests = self.delete_by_time(self.pull_requests,\n                                                     older_tag, newer_tag)\n        filtered_issues = self.delete_by_time(self.issues, older_tag,\n                                              newer_tag)\n\n        newer_tag_name = newer_tag[\"name\"] if newer_tag else None\n\n        if self.options.filter_issues_by_milestone:\n            # delete excess irrelevant issues (according milestones).Issue #22.\n            filtered_issues = self.filter_by_milestone(\n                filtered_issues, newer_tag_name, self.issues\n            )\n            filtered_pull_requests = self.filter_by_milestone(\n                filtered_pull_requests, newer_tag_name, self.pull_requests\n            )\n        return filtered_issues, filtered_pull_requests"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a complete change log for all tags.", "response": "def generate_log_for_all_tags(self):\n        \"\"\"\n        The full cycle of generation for whole project.\n\n        :rtype: str\n        :return: The complete change log for released tags.\n        \"\"\"\n\n        if self.options.verbose:\n            print(\"Generating log...\")\n        self.issues2 = copy.deepcopy(self.issues)\n\n        log1 = \"\"\n        if self.options.with_unreleased:\n            log1 = self.generate_unreleased_section()\n\n        log = \"\"\n        for index in range(len(self.filtered_tags) - 1):\n            log += self.do_generate_log_for_all_tags_part1(log, index)\n\n        if self.options.tag_separator and log1:\n            log = log1 + self.options.tag_separator + log\n        else:\n            log = log1 + log\n\n        if len(self.filtered_tags) != 0:\n            log += self.do_generate_log_for_all_tags_part2(log)\n\n        return log"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates log for unreleased closed issues.", "response": "def generate_unreleased_section(self):\n        \"\"\"\n        Generate log for unreleased closed issues.\n\n        :rtype: str\n        :return: Generated ready-to-add unreleased section.\n        \"\"\"\n        if not self.filtered_tags:\n            return \"\"\n        now = datetime.datetime.utcnow()\n        now = now.replace(tzinfo=dateutil.tz.tzutc())\n        head_tag = {\"name\": self.options.unreleased_label}\n        self.tag_times_dict[head_tag[\"name\"]] = now\n        unreleased_log = self.generate_log_between_tags(\n            self.filtered_tags[0], head_tag)\n        return unreleased_log"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_string_for_issue(self, issue):\n\n        encapsulated_title = self.encapsulate_string(issue['title'])\n        try:\n            title_with_number = u\"{0} [\\\\#{1}]({2})\".format(\n                encapsulated_title, issue[\"number\"], issue[\"html_url\"]\n            )\n        except UnicodeEncodeError:\n            # TODO: why did i add this? Is it needed?\n            title_with_number = \"ERROR ERROR ERROR: #{0} {1}\".format(\n                issue[\"number\"], issue['title']\n            )\n            print(title_with_number, '\\n', issue[\"html_url\"])\n        return self.issue_line_with_user(title_with_number, issue)", "response": "Parse issue and generate single line formatted issue line."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef issue_line_with_user(self, line, issue):\n        if not issue.get(\"pull_request\") or not self.options.author:\n            return line\n\n        if not issue.get(\"user\"):\n            line += u\" (Null user)\"\n        elif self.options.username_as_tag:\n            line += u\" (@{0})\".format(\n                issue[\"user\"][\"login\"]\n            )\n        else:\n            line += u\" ([{0}]({1}))\".format(\n                issue[\"user\"][\"login\"], issue[\"user\"][\"html_url\"]\n            )\n        return line", "response": "Adds author link to the author of the pull request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate log for a tag section.", "response": "def generate_log_for_tag(self,\n                             pull_requests,\n                             issues,\n                             newer_tag,\n                             older_tag_name):\n        \"\"\"\n        Generates log for tag section with header and body.\n\n        :param list(dict) pull_requests: List of PR's in this tag section.\n        :param list(dict) issues: List of issues in this tag section.\n        :param dict newer_tag: Github data of tag for this section.\n        :param str older_tag_name: Older tag, used for the links.\n                                   May be special value, if **newer tag** is\n                                   the first tag. (Means **older_tag** is when\n                                   the repo was created.)\n        :rtype: str\n        :return: Ready-to-add and parsed tag section.\n        \"\"\"\n\n        newer_tag_link, newer_tag_name, \\\n        newer_tag_time = self.detect_link_tag_time(newer_tag)\n\n        github_site = \"https://github.com\" or self.options.github_endpoint\n        project_url = \"{0}/{1}/{2}\".format(\n            github_site, self.options.user, self.options.project)\n\n        log = self.generate_header(newer_tag_name, newer_tag_link,\n                                   newer_tag_time, older_tag_name, project_url)\n        if self.options.issues:\n            # Generate issues:\n            log += self.issues_to_log(issues, pull_requests)\n        if self.options.include_pull_request:\n            # Generate pull requests:\n            log += self.generate_sub_section(\n                pull_requests, self.options.merge_prefix\n            )\n        return log"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef issues_to_log(self, issues, pull_requests):\n\n        log = \"\"\n        sections_a, issues_a = self.parse_by_sections(\n            issues, pull_requests)\n\n        for section, s_issues in sections_a.items():\n            log += self.generate_sub_section(s_issues, section)\n        log += self.generate_sub_section(issues_a, self.options.issue_prefix)\n        return log", "response": "Generate ready - to - paste log from list of issues and pull requests."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_by_sections(self, issues, pull_requests):\n\n        issues_a = []\n        sections_a = OrderedDict()\n\n        if not self.options.sections:\n            return [sections_a, issues]\n        for key in self.options.sections:\n            sections_a.update({key: []})\n        self.parse_by_sections_for_issues(issues, sections_a, issues_a)\n        self.parse_by_sections_for_pr(pull_requests, sections_a)\n        return [sections_a, issues_a]", "response": "This method sorts the issues and pull_requests by sections."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exclude_issues_by_labels(self, issues):\n        if not self.options.exclude_labels:\n            return copy.deepcopy(issues)\n\n        remove_issues = set()\n        exclude_labels = self.options.exclude_labels\n        include_issues = []\n        for issue in issues:\n            for label in issue[\"labels\"]:\n                if label[\"name\"] in exclude_labels:\n                    remove_issues.add(issue[\"number\"])\n                    break\n        for issue in issues:\n            if issue[\"number\"] not in remove_issues:\n                include_issues.append(issue)\n        return include_issues", "response": "Returns a list of issues that are not in the exclude - labels option."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filter_by_milestone(self, filtered_issues, tag_name, all_issues):\n\n        filtered_issues = self.remove_issues_in_milestones(filtered_issues)\n        if tag_name:\n            # add missed issues (according milestones)\n            issues_to_add = self.find_issues_to_add(all_issues, tag_name)\n            filtered_issues.extend(issues_to_add)\n        return filtered_issues", "response": "Filter issues according to a milestone."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_issues_to_add(all_issues, tag_name):\n\n        filtered = []\n        for issue in all_issues:\n            if issue.get(\"milestone\"):\n                if issue[\"milestone\"][\"title\"] == tag_name:\n                    iss = copy.deepcopy(issue)\n                    filtered.append(iss)\n        return filtered", "response": "Find all issues that should be in that tag according to milestone."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving issues that contain milestones with the same name as a tag.", "response": "def remove_issues_in_milestones(self, filtered_issues):\n        \"\"\"\n        :param list(dict) filtered_issues: Filtered issues.\n        :rtype: list(dict)\n        :return: List with removed issues, that contain milestones with\n                 same name as a tag.\n        \"\"\"\n        for issue in filtered_issues:\n            # leave issues without milestones\n            if issue[\"milestone\"]:\n                # check, that this milestone is in tag list:\n                for tag in self.filtered_tags:\n                    if tag[\"name\"] == issue[\"milestone\"][\"title\"]:\n                        filtered_issues.remove(issue)\n        return filtered_issues"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfilters issues that belong to specified tag range.", "response": "def delete_by_time(self, issues, older_tag, newer_tag):\n        \"\"\"\n        Filter issues that belong to specified tag range.\n\n        :param list(dict) issues: Issues to filter.\n        :param dict older_tag: All issues before this tag's date will be\n                               excluded. May be special value, if **newer_tag**\n                               is the first tag. (Means **older_tag** is when\n                               the repo was created.)\n        :param dict newer_tag: All issues after this tag's date  will be\n                               excluded. May be title of unreleased section.\n        :rtype: list(dict)\n        :return: Filtered issues.\n        \"\"\"\n\n        if not older_tag and not newer_tag:\n            # in case if no tags are specified - return unchanged array\n            return copy.deepcopy(issues)\n\n        newer_tag_time = self.get_time_of_tag(newer_tag)\n        older_tag_time = self.get_time_of_tag(older_tag)\n        filtered = []\n        for issue in issues:\n            if issue.get('actual_date'):\n                rslt = older_tag_time < issue['actual_date'] <= newer_tag_time\n                if rslt:\n                    filtered.append(copy.deepcopy(issue))\n        return filtered"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfiltering issues by labels specified in self. options. include_labels.", "response": "def include_issues_by_labels(self, all_issues):\n        \"\"\"\n        Include issues with labels, specified in self.options.include_labels.\n\n        :param list(dict) all_issues: All issues.\n        :rtype: list(dict)\n        :return: Filtered issues.\n        \"\"\"\n\n        included_by_labels = self.filter_by_include_labels(all_issues)\n        wo_labels = self.filter_wo_labels(all_issues)\n        il = set([f[\"number\"] for f in included_by_labels])\n        wl = set([w[\"number\"] for w in wo_labels])\n        filtered_issues = []\n        for issue in all_issues:\n            if issue[\"number\"] in il or issue[\"number\"] in wl:\n                filtered_issues.append(issue)\n        return filtered_issues"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfilter all issues that don t have labels.", "response": "def filter_wo_labels(self, all_issues):\n        \"\"\"\n        Filter all issues that don't have a label.\n\n        :rtype: list(dict)\n        :return: Issues without labels.\n        \"\"\"\n\n        issues_wo_labels = []\n        if not self.options.add_issues_wo_labels:\n            for issue in all_issues:\n                if not issue['labels']:\n                    issues_wo_labels.append(issue)\n        return issues_wo_labels"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter_by_include_labels(self, issues):\n\n        if not self.options.include_labels:\n            return copy.deepcopy(issues)\n        filtered_issues = []\n        include_labels = set(self.options.include_labels)\n        for issue in issues:\n            labels = [label[\"name\"] for label in issue[\"labels\"]]\n            if include_labels.intersection(labels):\n                filtered_issues.append(issue)\n        return filtered_issues", "response": "Filter issues to include only issues with labels specified in include_labels."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfiltering issues for include and exclude labels.", "response": "def filter_by_labels(self, all_issues, kind):\n        \"\"\"\n        Filter issues for include/exclude labels.\n\n        :param list(dict) all_issues: All issues.\n        :param str kind: Either \"issues\" or \"pull requests\".\n        :rtype: list(dict)\n        :return: Filtered issues.\n        \"\"\"\n\n        filtered_issues = self.include_issues_by_labels(all_issues)\n        filtered = self.exclude_issues_by_labels(filtered_issues)\n        if self.options.verbose > 1:\n            print(\"\\tremaining {}: {}\".format(kind, len(filtered)))\n        return filtered"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fetch_and_filter_tags(self):\n\n        self.all_tags = self.fetcher.get_all_tags()\n        self.filtered_tags = self.get_filtered_tags(self.all_tags)\n        self.fetch_tags_dates()", "response": "Fetch and filter tags and sort them in time order."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sort_tags_by_date(self, tags):\n\n        if self.options.verbose:\n            print(\"Sorting tags...\")\n        tags.sort(key=lambda x: self.get_time_of_tag(x))\n        tags.reverse()\n        return tags", "response": "Sort all tags by date."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the date and time for a tag.", "response": "def get_time_of_tag(self, tag):\n        \"\"\"\n        Get date and time for tag, fetching it if not already cached.\n\n        :param dict tag: Tag to get the datetime for.\n        :rtype: datetime\n        :return: datetime for specified tag.\n        \"\"\"\n\n        if not tag:\n            raise ChangelogGeneratorError(\"tag is nil\")\n\n        name_of_tag = tag[\"name\"]\n        time_for_name = self.tag_times_dict.get(name_of_tag, None)\n        if time_for_name:\n            return time_for_name\n        else:\n            time_string = self.fetcher.fetch_date_of_tag(tag)\n            try:\n                self.tag_times_dict[name_of_tag] = \\\n                    timestring_to_datetime(time_string)\n            except UnicodeWarning:\n                print(\"ERROR ERROR:\", tag)\n                self.tag_times_dict[name_of_tag] = \\\n                    timestring_to_datetime(time_string)\n            return self.tag_times_dict[name_of_tag]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef detect_link_tag_time(self, tag):\n\n        # if tag is nil - set current time\n        newer_tag_time = self.get_time_of_tag(tag) if tag \\\n            else datetime.datetime.now()\n\n        # if it's future release tag - set this value\n        if tag[\"name\"] == self.options.unreleased_label \\\n            and self.options.future_release:\n            newer_tag_name = self.options.future_release\n            newer_tag_link = self.options.future_release\n        elif tag[\"name\"] is not self.options.unreleased_label :\n            # put unreleased label if there is no name for the tag\n            newer_tag_name = tag[\"name\"]\n            newer_tag_link = newer_tag_name\n        else:\n            newer_tag_name = self.options.unreleased_label\n            newer_tag_link = \"HEAD\"\n        return [newer_tag_link, newer_tag_name, newer_tag_time]", "response": "Detect link name and time for specified tag."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrying to detect the newest tag from self. options. base otherwise return a special value indicating the creation of the repo.", "response": "def version_of_first_item(self):\n        \"\"\"\n        Try to detect the newest tag from self.options.base, otherwise\n        return a special value indicating the creation of the repo.\n\n        :rtype: str\n        :return: Tag name to use as 'oldest' tag. May be special value,\n                 indicating the creation of the repo.\n        \"\"\"\n        try:\n            sections = read_changelog(self.options)\n            return sections[0][\"version\"]\n        except(IOError, TypeError):\n            return self.get_temp_tag_for_repo_creation()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the name of the tag that is used for the creation of the repo. If not already cached returns the creation date of the repo and returns the special value indicating the creation of the repo.", "response": "def get_temp_tag_for_repo_creation(self):\n        \"\"\"\n        If not already cached, fetch the creation date of the repo, cache it\n        and return the special value indicating the creation of the repo.\n\n        :rtype: str\n        :return: value indicating the creation\n        \"\"\"\n        tag_date = self.tag_times_dict.get(REPO_CREATED_TAG_NAME, None)\n        if not tag_date:\n            tag_name, tag_date = self.fetcher.fetch_repo_creation_date()\n            self.tag_times_dict[tag_name] = timestring_to_datetime(tag_date)\n        return REPO_CREATED_TAG_NAME"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_filtered_tags(self, all_tags):\n\n        filtered_tags = self.filter_since_tag(all_tags)\n        if self.options.between_tags:\n            filtered_tags = self.filter_between_tags(filtered_tags)\n        if self.options.due_tag:\n            filtered_tags = self.filter_due_tag(filtered_tags)\n        return self.filter_excluded_tags(filtered_tags)", "response": "Return tags after filtering tags in lists provided by the user - supplied option between - tags & -- exclude - tags\n        option."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfilter tags according since_tag option.", "response": "def filter_since_tag(self, all_tags):\n        \"\"\"\n        Filter tags according since_tag option.\n\n        :param list(dict) all_tags: All tags.\n        :rtype: list(dict)\n        :return: Filtered tags.\n        \"\"\"\n\n        tag = self.detect_since_tag()\n        if not tag or tag == REPO_CREATED_TAG_NAME:\n            return copy.deepcopy(all_tags)\n\n        filtered_tags = []\n        tag_names = [t[\"name\"] for t in all_tags]\n        try:\n            idx = tag_names.index(tag)\n        except ValueError:\n            self.warn_if_tag_not_found(tag, \"since-tag\")\n            return copy.deepcopy(all_tags)\n\n        since_tag = all_tags[idx]\n        since_date = self.get_time_of_tag(since_tag)\n        for t in all_tags:\n            tag_date = self.get_time_of_tag(t)\n            if since_date <= tag_date:\n                filtered_tags.append(t)\n        return filtered_tags"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfiltering tags according due_tag option.", "response": "def filter_due_tag(self, all_tags):\n        \"\"\"\n        Filter tags according due_tag option.\n\n        :param list(dict) all_tags: Pre-filtered tags.\n        :rtype: list(dict)\n        :return: Filtered tags.\n        \"\"\"\n\n        filtered_tags = []\n        tag = self.options.due_tag\n        tag_names = [t[\"name\"] for t in all_tags]\n        try:\n            idx = tag_names.index(tag)\n        except ValueError:\n            self.warn_if_tag_not_found(tag, \"due-tag\")\n            return copy.deepcopy(all_tags)\n\n        due_tag = all_tags[idx]\n        due_date = self.get_time_of_tag(due_tag)\n        for t in all_tags:\n            tag_date = self.get_time_of_tag(t)\n            if tag_date <= due_date:\n                filtered_tags.append(t)\n        return filtered_tags"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfilter tags according between_tags option.", "response": "def filter_between_tags(self, all_tags):\n        \"\"\"\n        Filter tags according between_tags option.\n\n        :param list(dict) all_tags: Pre-filtered tags.\n        :rtype: list(dict)\n        :return: Filtered tags.\n        \"\"\"\n\n        tag_names = [t[\"name\"] for t in all_tags]\n        between_tags = []\n        for tag in self.options.between_tags:\n            try:\n                idx = tag_names.index(tag)\n            except ValueError:\n                raise ChangelogGeneratorError(\n                    \"ERROR: can't find tag {0}, specified with \"\n                    \"--between-tags option.\".format(tag))\n            between_tags.append(all_tags[idx])\n\n        between_tags = self.sort_tags_by_date(between_tags)\n\n        if len(between_tags) == 1:\n            # if option --between-tags was only 1 tag given, duplicate it\n            # to generate the changelog only for that one tag.\n            between_tags.append(between_tags[0])\n\n        older = self.get_time_of_tag(between_tags[1])\n        newer = self.get_time_of_tag(between_tags[0])\n\n        for tag in all_tags:\n            if older < self.get_time_of_tag(tag) < newer:\n                between_tags.append(tag)\n        if older == newer:\n            between_tags.pop(0)\n        return between_tags"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfiltering tags according exclude_tags and exclude_tags_regex option.", "response": "def filter_excluded_tags(self, all_tags):\n        \"\"\"\n        Filter tags according exclude_tags and exclude_tags_regex option.\n\n        :param list(dict) all_tags: Pre-filtered tags.\n        :rtype: list(dict)\n        :return: Filtered tags.\n        \"\"\"\n        filtered_tags = copy.deepcopy(all_tags)\n        if self.options.exclude_tags:\n            filtered_tags = self.apply_exclude_tags(filtered_tags)\n        if self.options.exclude_tags_regex:\n            filtered_tags = self.apply_exclude_tags_regex(filtered_tags)\n        return filtered_tags"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfilter tags according exclude_tags_regex option.", "response": "def apply_exclude_tags_regex(self, all_tags):\n        \"\"\"\n        Filter tags according exclude_tags_regex option.\n\n        :param list(dict) all_tags: Pre-filtered tags.\n        :rtype: list(dict)\n        :return: Filtered tags.\n        \"\"\"\n        filtered = []\n        for tag in all_tags:\n            if not re.match(self.options.exclude_tags_regex, tag[\"name\"]):\n                filtered.append(tag)\n        if len(all_tags) == len(filtered):\n            self.warn_if_nonmatching_regex()\n        return filtered"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef apply_exclude_tags(self, all_tags):\n        filtered = copy.deepcopy(all_tags)\n        for tag in all_tags:\n            if tag[\"name\"] not in self.options.exclude_tags:\n                self.warn_if_tag_not_found(tag, \"exclude-tags\")\n            else:\n                filtered.remove(tag)\n        return filtered", "response": "Filter tags according exclude_tags option."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef random_letters(n):\n    return ''.join(random.SystemRandom().choice(string.ascii_letters) for _ in range(n))", "response": "Generate a random string from a - zA - ZA - ZA"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef random_numbers(n):\n    return ''.join(random.SystemRandom().choice(string.digits) for _ in range(n))", "response": "Generate a random string from 0 - 9"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dict_search(d, k, v):\n    for i in range(len(d)):\n        if d[i][k] == v:\n            return i\n    return None", "response": "Search dictionary list by key and value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dict_merge(a, b, k):\n    c = a.copy()\n    for j in range(len(b)):\n        flag = False\n        for i in range(len(c)):\n            if c[i][k] == b[j][k]:\n                c[i] = b[j].copy()\n                flag = True\n        if not flag:\n            c.append(b[j].copy())\n    return c", "response": "Merge two dictionary lists\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dict_sort(d, k):\n    return sorted(d.copy(), key=lambda i: i[k])", "response": "Sort a dictionary list by key"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dict_top(d, k, n, reverse=False):\n    h = list()\n    for i in range(len(d)):\n        heappush(h, (-d[i][k] if reverse else d[i][k], i))\n    r = list()\n    while len(r) < n and len(h) > 0:\n        _, i = heappop(h)\n        r.append(d[i].copy())\n    return r", "response": "Return the top n elements of a dictionary list sorted by key"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dict_flatten(d):\n    if type(d) != dict:\n        return d\n    else:\n        dd = dict()\n        for key, value in d.items():\n            if type(value) == dict:\n                for k, v in value.items():\n                    dd[key + '_' + k] = dict_flatten(v)\n            else:\n                dd[key] = value\n        return dd", "response": "Flatten nested dict keys to underscore - connected keys"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary with the values of a dict with certain type", "response": "def dict_format_type(d, source, formatter, include_list=True):\n    \"\"\"\n    Replace the values of a dict with certain type to other values\n    :param d: the dictionary\n    :param source: the source type, e.g., int\n    :param formatter: the formatter method, e.g., return the string format of an int\n    :param include_list: whether list should be formatted, otherwise list will be considered as source type\n    :return: formatted dictionary\n    \"\"\"\n    if not isinstance(d, dict):\n        if isinstance(d, source):\n            return formatter(d)\n        else:\n            return d\n    else:\n        dd = dict()\n        for key, value in d.items():\n            if include_list and isinstance(value, list):\n                dd[key] = [dict_format_type(i, source, formatter) for i in value]\n            elif isinstance(value, dict):\n                dd[key] = dict_format_type(value, source, formatter)\n            elif isinstance(value, source):\n                dd[key] = formatter(value)\n            else:\n                dd[key] = value\n        return dd"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dict_as_tuple_list(d, as_list=False):\n    dd = list()\n    for k, v in d.items():\n        dd.append([k, v] if as_list else (k, v))\n    return dd", "response": "Format a dictionary to a list of tuples"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tuple_search(t, i, v):\n    for e in t:\n        if e[i] == v:\n            return e\n    return None", "response": "Search the tuple array by index and value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_comment_telemetry(text):\n    parsed = {}\n    match = re.findall(r\"^(.*?)\\|([!-{]{4,14})\\|(.*)$\", text)\n\n    if match and len(match[0][1]) % 2 == 0:\n        text, telemetry, post = match[0]\n        text += post\n\n        temp = [0] * 7\n        for i in range(7):\n            temp[i] = base91.to_decimal(telemetry[i*2:i*2+2])\n\n        parsed.update({\n            'telemetry': {\n                'seq': temp[0],\n                'vals': temp[1:6]\n                }\n            })\n\n        if temp[6] != '':\n            parsed['telemetry'].update({\n                'bits': \"{0:08b}\".format(temp[6] & 0xFF)[::-1]\n                })\n\n    return (text, parsed)", "response": "Parse base91 telemetry found in comment field\n    Returns parsed text and telemetry"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses an APRS packet and returns a dict with decoded data", "response": "def parse(packet):\n    \"\"\"\n    Parses an APRS packet and returns a dict with decoded data\n\n    - All attributes are in metric units\n    \"\"\"\n\n    if not isinstance(packet, string_type_parse):\n        raise TypeError(\"Expected packet to be str/unicode/bytes, got %s\", type(packet))\n\n    if len(packet) == 0:\n        raise ParseError(\"packet is empty\", packet)\n\n    # attempt to detect encoding\n    if isinstance(packet, bytes):\n        packet = _unicode_packet(packet)\n\n    packet = packet.rstrip(\"\\r\\n\")\n    logger.debug(\"Parsing: %s\", packet)\n\n    # split into head and body\n    try:\n        (head, body) = packet.split(':', 1)\n    except:\n        raise ParseError(\"packet has no body\", packet)\n\n    if len(body) == 0:\n        raise ParseError(\"packet body is empty\", packet)\n\n    parsed = {\n        'raw': packet,\n        }\n\n    # parse head\n    try:\n        parsed.update(parse_header(head))\n    except ParseError as msg:\n        raise ParseError(str(msg), packet)\n\n    # parse body\n    packet_type = body[0]\n    body = body[1:]\n\n    if len(body) == 0 and packet_type != '>':\n        raise ParseError(\"packet body is empty after packet type character\", packet)\n\n    # attempt to parse the body\n    try:\n        _try_toparse_body(packet_type, body, parsed)\n\n    # capture ParseErrors and attach the packet\n    except (UnknownFormat, ParseError) as exp:\n        exp.packet = packet\n        raise\n\n    # if we fail all attempts to parse, try beacon packet\n    if 'format' not in parsed:\n        if not re.match(r\"^(AIR.*|ALL.*|AP.*|BEACON|CQ.*|GPS.*|DF.*|DGPS.*|\"\n                        \"DRILL.*|DX.*|ID.*|JAVA.*|MAIL.*|MICE.*|QST.*|QTH.*|\"\n                        \"RTCM.*|SKY.*|SPACE.*|SPC.*|SYM.*|TEL.*|TEST.*|TLM.*|\"\n                        \"WX.*|ZIP.*|UIDIGI)$\", parsed['to']):\n            raise UnknownFormat(\"format is not supported\", packet)\n\n        parsed.update({\n            'format': 'beacon',\n            'text': packet_type + body,\n            })\n\n    logger.debug(\"Parsed ok.\")\n    return parsed"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_decimal(text):\n\n    if not isinstance(text, string_type):\n        raise TypeError(\"expected str or unicode, %s given\" % type(text))\n\n    if findall(r\"[\\x00-\\x20\\x7c-\\xff]\", text):\n        raise ValueError(\"invalid character in sequence\")\n\n    text = text.lstrip('!')\n    decimal = 0\n    length = len(text) - 1\n    for i, char in enumerate(text):\n        decimal += (ord(char) - 33) * (91 ** (length - i))\n\n    return decimal if text != '' else 0", "response": "Takes a base91 char string and returns a decimal number."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_decimal(number, width=1):\n    text = []\n\n    if not isinstance(number, int_type):\n        raise TypeError(\"Expected number to be int, got %s\", type(number))\n    elif not isinstance(width, int_type):\n        raise TypeError(\"Expected width to be int, got %s\", type(number))\n    elif number < 0:\n        raise ValueError(\"Expected number to be positive integer\")\n    elif number > 0:\n        max_n = ceil(log(number) / log(91))\n\n        for n in _range(int(max_n), -1, -1):\n            quotient, number = divmod(number, 91**n)\n            text.append(chr(33 + quotient))\n\n    return \"\".join(text).lstrip('!').rjust(max(1, width), '!')", "response": "Takes a decimal and returns base91 char string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a passcode for a CALLSIGN.", "response": "def passcode(callsign):\n    \"\"\"\n    Takes a CALLSIGN and returns passcode\n    \"\"\"\n    assert isinstance(callsign, str)\n\n    callsign = callsign.split('-')[0].upper()\n\n    code = 0x73e2\n    for i, char in enumerate(callsign):\n        code ^= ord(char) << (8 if not i % 2 else 0)\n\n    return code & 0x7fff"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_header(head):\n    try:\n        (fromcall, path) = head.split('>', 1)\n    except:\n        raise ParseError(\"invalid packet header\")\n\n    if (not 1 <= len(fromcall) <= 9 or\n       not re.findall(r\"^[a-z0-9]{0,9}(\\-[a-z0-9]{1,8})?$\", fromcall, re.I)):\n\n        raise ParseError(\"fromcallsign is invalid\")\n\n    path = path.split(',')\n\n    if len(path[0]) == 0:\n        raise ParseError(\"no tocallsign in header\")\n\n    tocall = path[0]\n    path = path[1:]\n\n    validate_callsign(tocall, \"tocallsign\")\n\n    for digi in path:\n        if not re.findall(r\"^[A-Z0-9\\-]{1,9}\\*?$\", digi, re.I):\n            raise ParseError(\"invalid callsign in path\")\n\n    parsed = {\n        'from': fromcall,\n        'to': tocall,\n        'path': path,\n        }\n\n    viacall = \"\"\n    if len(path) >= 2 and re.match(r\"^q..$\", path[-2]):\n        viacall = path[-1]\n\n    parsed.update({'via': viacall})\n\n    return parsed", "response": "Parses the header part of a packet into a dict containing the keys fromcall tocall path via."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_filter(self, filter_text):\n        self.filter = filter_text\n\n        self.logger.info(\"Setting filter to: %s\", self.filter)\n\n        if self._connected:\n            self._sendall(\"#filter %s\\r\\n\" % self.filter)", "response": "Set a specified aprs - is filter for this connection"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_login(self, callsign, passwd=\"-1\", skip_login=False):\n        self.__dict__.update(locals())", "response": "Set the login for this object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connect(self, blocking=False, retry=30):\n\n        if self._connected:\n            return\n\n        while True:\n            try:\n                self._connect()\n                if not self.skip_login:\n                    self._send_login()\n                break\n            except (LoginError, ConnectionError):\n                if not blocking:\n                    raise\n\n            self.logger.info(\"Retrying connection is %d seconds.\" % retry)\n            time.sleep(retry)", "response": "Initiate connection to APRS server and attempt to login and return the new APRS session identifier."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclosing the socket with the current socket_id.", "response": "def close(self):\n        \"\"\"\n        Closes the socket\n        Called internally when Exceptions are raised\n        \"\"\"\n\n        self._connected = False\n        self.buf = b''\n\n        if self.sock is not None:\n            self.sock.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sendall(self, line):\n        if isinstance(line, APRSPacket):\n            line = str(line)\n        elif not isinstance(line, string_type):\n            raise TypeError(\"Expected line to be str or APRSPacket, got %s\", type(line))\n        if not self._connected:\n            raise ConnectionError(\"not connected\")\n\n        if line == \"\":\n            return\n\n        line = line.rstrip(\"\\r\\n\") + \"\\r\\n\"\n\n        try:\n            self.sock.setblocking(1)\n            self.sock.settimeout(5)\n            self._sendall(line)\n        except socket.error as exp:\n            self.close()\n            raise ConnectionError(str(exp))", "response": "Send a line or multiple lines sperapted by '\\\\ r\\\\ n'"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef consumer(self, callback, blocking=True, immortal=False, raw=False):\n\n        if not self._connected:\n            raise ConnectionError(\"not connected to a server\")\n\n        line = b''\n\n        while True:\n            try:\n                for line in self._socket_readlines(blocking):\n                    if line[0:1] != b'#':\n                        if raw:\n                            callback(line)\n                        else:\n                            callback(self._parse(line))\n                    else:\n                        self.logger.debug(\"Server: %s\", line.decode('utf8'))\n            except ParseError as exp:\n                self.logger.log(11, \"%s\\n    Packet: %s\", exp.message, exp.packet)\n            except UnknownFormat as exp:\n                self.logger.log(9, \"%s\\n    Packet: %s\", exp.message, exp.packet)\n            except LoginError as exp:\n                self.logger.error(\"%s: %s\", exp.__class__.__name__, exp.message)\n            except (KeyboardInterrupt, SystemExit):\n                raise\n            except (ConnectionDrop, ConnectionError):\n                self.close()\n\n                if not immortal:\n                    raise\n                else:\n                    self.connect(blocking=blocking)\n                    continue\n            except GenericError:\n                pass\n            except StopIteration:\n                break\n            except:\n                self.logger.error(\"APRS Packet: %s\", line)\n                raise\n\n            if not blocking:\n                break", "response": "This function is used to consume a single file from the server."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _connect(self):\n\n        self.logger.info(\"Attempting connection to %s:%s\", self.server[0], self.server[1])\n\n        try:\n            self._open_socket()\n\n            peer = self.sock.getpeername()\n\n            self.logger.info(\"Connected to %s\", str(peer))\n\n            # 5 second timeout to receive server banner\n            self.sock.setblocking(1)\n            self.sock.settimeout(5)\n\n            self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)\n\n            banner = self.sock.recv(512)\n            if is_py3:\n                banner = banner.decode('latin-1')\n\n            if banner[0] == \"#\":\n                self.logger.debug(\"Banner: %s\", banner.rstrip())\n            else:\n                raise ConnectionError(\"invalid banner from server\")\n\n        except ConnectionError as e:\n            self.logger.error(str(e))\n            self.close()\n            raise\n        except (socket.error, socket.timeout) as e:\n            self.close()\n\n            self.logger.error(\"Socket error: %s\" % str(e))\n            if str(e) == \"timed out\":\n                raise ConnectionError(\"no banner from server\")\n            else:\n                raise ConnectionError(e)\n\n        self._connected = True", "response": "Connects to the server and returns the ID of the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _send_login(self):\n        login_str = \"user {0} pass {1} vers aprslib {3}{2}\\r\\n\"\n        login_str = login_str.format(\n            self.callsign,\n            self.passwd,\n            (\" filter \" + self.filter) if self.filter != \"\" else \"\",\n            __version__\n            )\n\n        self.logger.info(\"Sending login information\")\n\n        try:\n            self._sendall(login_str)\n            self.sock.settimeout(5)\n            test = self.sock.recv(len(login_str) + 100)\n            if is_py3:\n                test = test.decode('latin-1')\n            test = test.rstrip()\n\n            self.logger.debug(\"Server: %s\", test)\n\n            _, _, callsign, status, _ = test.split(' ', 4)\n\n            if callsign == \"\":\n                raise LoginError(\"Server responded with empty callsign???\")\n            if callsign != self.callsign:\n                raise LoginError(\"Server: %s\" % test)\n            if status != \"verified,\" and self.passwd != \"-1\":\n                raise LoginError(\"Password is incorrect\")\n\n            if self.passwd == \"-1\":\n                self.logger.info(\"Login successful (receive only)\")\n            else:\n                self.logger.info(\"Login successful\")\n\n        except LoginError as e:\n            self.logger.error(str(e))\n            self.close()\n            raise\n        except:\n            self.close()\n            self.logger.error(\"Failed to login\")\n            raise LoginError(\"Failed to login\")", "response": "Sends a login string to the server and returns the ID of the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a UUID to binary blob and reconstruct the value", "response": "def db_value(self, value):\n        \"\"\"\n        Convert UUID to binary blob\n        \"\"\"\n\n        # ensure we have a valid UUID\n        if not isinstance(value, UUID):\n            value = UUID(value)\n\n        # reconstruct for optimal indexing\n        parts = str(value).split(\"-\")\n        reordered = ''.join([parts[2], parts[1], parts[0], parts[3], parts[4]])\n        value = binascii.unhexlify(reordered)\n        return super(OrderedUUIDField, self).db_value(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef python_value(self, value):\n        value = super(OrderedUUIDField, self).python_value(value)\n        u = binascii.b2a_hex(value)\n        value = u[8:16] + u[4:8] + u[0:4] + u[16:22] + u[22:32]\n        return UUID(value.decode())", "response": "Convert binary blob to UUID instance"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef db_value(self, value):\n        value = self.transform_value(value)\n        return self.hhash.encrypt(value, \n            salt_size=self.salt_size, rounds=self.rounds)", "response": "Convert the python value for storage in the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef python_value(self, value):\n        value = coerce_to_bytes(value)\n        obj = HashValue(value)\n        obj.field = self\n        return obj", "response": "Convert the database value to a pythonic value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering model with app", "response": "def register(self, model_cls):\n        \"\"\"Register model(s) with app\"\"\"\n        assert issubclass(model_cls, peewee.Model)\n        assert not hasattr(model_cls._meta, 'database_manager')\n        if model_cls in self:\n            raise RuntimeError(\"Model already registered\")\n        self.append(model_cls)\n        model_cls._meta.database = self.dbm\n        return model_cls"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef disconnect(self):\n        for name, connection in self.items():\n            if not connection.is_closed():\n                connection.close()", "response": "Disconnect from all databases"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_database(self, model):\n        for router in self.routers:\n            r = router.get_database(model)\n            if r is not None:\n                return r\n        return self.get('default')", "response": "Find matching database router"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_cursor_ref(self):\n        fields = self._meta.get_primary_keys()\n        assert fields\n        values = {field.name:self.__data__[field.name] for field in fields}\n        return values", "response": "Returns dict of values to uniquely reference this item"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef paginate_query(self, query, count, offset=None, sort=None):\n        assert isinstance(query, peewee.Query)\n        assert isinstance(count, int)\n        assert isinstance(offset, (str, int, type(None)))\n        assert isinstance(sort, (list, set, tuple, type(None)))\n\n         # ensure our model has a primary key\n        fields = query.model._meta.get_primary_keys()\n        if len(fields) == 0:\n            raise peewee.ProgrammingError(\n                'Cannot apply pagination on model without primary key')\n\n        # ensure our model doesn't use a compound primary key\n        if len(fields) > 1:\n            raise peewee.ProgrammingError(\n                'Cannot apply pagination on model with compound primary key')\n\n        # apply offset\n        if offset is not None:\n            query = query.where(fields[0] >= offset)\n\n        # do we need to apply sorting?\n        order_bys = []\n        if sort:\n            for field, direction in sort:\n                # does this field have a valid sort direction?\n                if not isinstance(direction, str):\n                    raise ValueError(\"Invalid sort direction on field '{}'\".format(field))\n\n                direction = direction.lower().strip()\n                if direction not in ['asc', 'desc']:\n                    raise ValueError(\"Invalid sort direction on field '{}'\".format(field))\n\n                # apply sorting\n                order_by = peewee.SQL(field)\n                order_by = getattr(order_by, direction)()\n                order_bys += [order_by]\n\n        # add primary key ordering after user sorting\n        order_bys += [fields[0].asc()]\n\n        # apply ordering and limits\n        query = query.order_by(*order_bys)\n        query = query.limit(count)\n        return query", "response": "Apply pagination to query\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies user specified filters to query", "response": "def apply_filters(self, query, filters):\n        \"\"\"\n        Apply user specified filters to query\n        \"\"\"\n        assert isinstance(query, peewee.Query)\n        assert isinstance(filters, dict)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list(self, filters, cursor, count):\n        assert isinstance(filters, dict), \"expected filters type 'dict'\"\n        assert isinstance(cursor, dict), \"expected cursor type 'dict'\"\n\n        # start with our base query\n        query = self.get_query()\n        assert isinstance(query, peewee.Query)\n\n        # XXX: convert and apply user specified filters\n        #filters = {field.name: cursor[field.name] for field in fields}\n        #query.where(\n\n        paginator = self.get_paginator()\n        assert isinstance(paginator, Pagination)\n\n        # always include an extra row for next cursor position\n        count += 1\n\n        # apply pagination to query\n        pquery = paginator.filter_query(query, cursor, count)\n        items = [ item for item in pquery ]\n\n        # determine next cursor position\n        next_item = items.pop(1)\n        next_cursor = next_item.to_cursor_ref()\n\n        '''\n        # is this field allowed for sort?\n        if field not in self.sort_fields:\n            raise ValueError(\"Cannot sort on field '{}'\".format(field))\n        '''\n\n        return items, next_cursor", "response": "List items from query\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving items from query", "response": "def retrieve(self, cursor):\n        \"\"\"\n        Retrieve items from query\n        \"\"\"\n        assert isinstance(cursor, dict), \"expected cursor type 'dict'\"\n\n        # look for record in query\n        query = self.get_query()\n        assert isinstance(query, peewee.Query)\n\n        query\n        return query.get(**cursor)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef regenerate_signing_key(self, secret_key=None, region=None,\n                               service=None, date=None):\n        \"\"\"\n        Regenerate the signing key for this instance. Store the new key in\n        signing_key property.\n\n        Take scope elements of the new key from the equivalent properties\n        (region, service, date) of the current AWS4Auth instance. Scope\n        elements can be overridden for the new key by supplying arguments to\n        this function. If overrides are supplied update the current AWS4Auth\n        instance's equivalent properties to match the new values.\n\n        If secret_key is not specified use the value of the secret_key property\n        of the current AWS4Auth instance's signing key. If the existing signing\n        key is not storing its secret key (i.e. store_secret_key was set to\n        False at instantiation) then raise a NoSecretKeyError and do not\n        regenerate the key. In order to regenerate a key which is not storing\n        its secret key, secret_key must be supplied to this function.\n\n        Use the value of the existing key's store_secret_key property when\n        generating the new key. If there is no existing key, then default\n        to setting store_secret_key to True for new key.\n\n        \"\"\"\n        if secret_key is None and (self.signing_key is None or\n                                   self.signing_key.secret_key is None):\n            raise NoSecretKeyError\n\n        secret_key = secret_key or self.signing_key.secret_key\n        region = region or self.region\n        service = service or self.service\n        date = date or self.date\n        if self.signing_key is None:\n            store_secret_key = True\n        else:\n            store_secret_key = self.signing_key.store_secret_key\n\n        self.signing_key = AWS4SigningKey(secret_key, region, service, date,\n                                          store_secret_key)\n\n        self.region = region\n        self.service = service\n        self.date = self.signing_key.date", "response": "Generate a new signing key for this instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_request_date(cls, req):\n        date = None\n        for header in ['x-amz-date', 'date']:\n            if header not in req.headers:\n                continue\n            try:\n                date_str = cls.parse_date(req.headers[header])\n            except DateFormatError:\n                continue\n            try:\n                date = datetime.datetime.strptime(date_str, '%Y-%m-%d').date()\n            except ValueError:\n                continue\n            else:\n                break\n\n        return date", "response": "Try to pull a date from the request by looking first at the x - amz - date header and then the date header."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a date string and return an ISO ISO object.", "response": "def parse_date(date_str):\n        \"\"\"\n        Check if date_str is in a recognised format and return an ISO\n        yyyy-mm-dd format version if so. Raise DateFormatError if not.\n\n        Recognised formats are:\n        * RFC 7231 (e.g. Mon, 09 Sep 2011 23:36:00 GMT)\n        * RFC 850 (e.g. Sunday, 06-Nov-94 08:49:37 GMT)\n        * C time (e.g. Wed Dec 4 00:00:00 2002)\n        * Amz-Date format (e.g. 20090325T010101Z)\n        * ISO 8601 / RFC 3339 (e.g. 2009-03-25T10:11:12.13-01:00)\n\n        date_str -- Str containing a date and optional time\n\n        \"\"\"\n        months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug',\n                  'sep', 'oct', 'nov', 'dec']\n        formats = {\n            # RFC 7231, e.g. 'Mon, 09 Sep 2011 23:36:00 GMT'\n            r'^(?:\\w{3}, )?(\\d{2}) (\\w{3}) (\\d{4})\\D.*$':\n                lambda m: '{}-{:02d}-{}'.format(\n                                          m.group(3),\n                                          months.index(m.group(2).lower())+1,\n                                          m.group(1)),\n            # RFC 850 (e.g. Sunday, 06-Nov-94 08:49:37 GMT)\n            # assumes current century\n            r'^\\w+day, (\\d{2})-(\\w{3})-(\\d{2})\\D.*$':\n                lambda m: '{}{}-{:02d}-{}'.format(\n                                            str(datetime.date.today().year)[:2],\n                                            m.group(3),\n                                            months.index(m.group(2).lower())+1,\n                                            m.group(1)),\n            # C time, e.g. 'Wed Dec 4 00:00:00 2002'\n            r'^\\w{3} (\\w{3}) (\\d{1,2}) \\d{2}:\\d{2}:\\d{2} (\\d{4})$':\n                lambda m: '{}-{:02d}-{:02d}'.format(\n                                              m.group(3),\n                                              months.index(m.group(1).lower())+1,\n                                              int(m.group(2))),\n            # x-amz-date format dates, e.g. 20100325T010101Z\n            r'^(\\d{4})(\\d{2})(\\d{2})T\\d{6}Z$':\n                lambda m: '{}-{}-{}'.format(*m.groups()),\n            # ISO 8601 / RFC 3339, e.g. '2009-03-25T10:11:12.13-01:00'\n            r'^(\\d{4}-\\d{2}-\\d{2})(?:[Tt].*)?$':\n                lambda m: m.group(1),\n        }\n\n        out_date = None\n        for regex, xform in formats.items():\n            m = re.search(regex, date_str)\n            if m:\n                out_date = xform(m)\n                break\n        if out_date is None:\n            raise DateFormatError\n        else:\n            return out_date"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling a request whose date doesn t match the signing key scope date.", "response": "def handle_date_mismatch(self, req):\n        \"\"\"\n        Handle a request whose date doesn't match the signing key scope date.\n\n        This AWS4Auth class implementation regenerates the signing key. See\n        StrictAWS4Auth class if you would prefer an exception to be raised.\n\n        req -- a requests prepared request object\n\n        \"\"\"\n        req_datetime = self.get_request_date(req)\n        new_key_date = req_datetime.strftime('%Y%m%d')\n        self.regenerate_signing_key(date=new_key_date)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nencoding the body of the request to bytes and update content - type header if required.", "response": "def encode_body(req):\n        \"\"\"\n        Encode body of request to bytes and update content-type if required.\n\n        If the body of req is Unicode then encode to the charset found in\n        content-type header if present, otherwise UTF-8, or ASCII if\n        content-type is application/x-www-form-urlencoded. If encoding to UTF-8\n        then add charset to content-type. Modifies req directly, does not\n        return a modified copy.\n\n        req -- Requests PreparedRequest object\n\n        \"\"\"\n        if isinstance(req.body, text_type):\n            split = req.headers.get('content-type', 'text/plain').split(';')\n            if len(split) == 2:\n                ct, cs = split\n                cs = cs.split('=')[1]\n                req.body = req.body.encode(cs)\n            else:\n                ct = split[0]\n                if (ct == 'application/x-www-form-urlencoded' or\n                        'x-amz-' in ct):\n                    req.body = req.body.encode()\n                else:\n                    req.body = req.body.encode('utf-8')\n                    req.headers['content-type'] = ct + '; charset=utf-8'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the AWS authentication Canonical Request string.", "response": "def get_canonical_request(self, req, cano_headers, signed_headers):\n        \"\"\"\n        Create the AWS authentication Canonical Request string.\n\n        req            -- Requests PreparedRequest object. Should already\n                          include an x-amz-content-sha256 header\n        cano_headers   -- Canonical Headers section of Canonical Request, as\n                          returned by get_canonical_headers()\n        signed_headers -- Signed Headers, as returned by\n                          get_canonical_headers()\n\n        \"\"\"\n        url = urlparse(req.url)\n        path = self.amz_cano_path(url.path)\n        # AWS handles \"extreme\" querystrings differently to urlparse\n        # (see post-vanilla-query-nonunreserved test in aws_testsuite)\n        split = req.url.split('?', 1)\n        qs = split[1] if len(split) == 2 else ''\n        qs = self.amz_cano_querystring(qs)\n        payload_hash = req.headers['x-amz-content-sha256']\n        req_parts = [req.method.upper(), path, qs, cano_headers,\n                     signed_headers, payload_hash]\n        cano_req = '\\n'.join(req_parts)\n        return cano_req"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate the canonical headers section of the Canonical Request and the signed headers.", "response": "def get_canonical_headers(cls, req, include=None):\n        \"\"\"\n        Generate the Canonical Headers section of the Canonical Request.\n\n        Return the Canonical Headers and the Signed Headers strs as a tuple\n        (canonical_headers, signed_headers).\n\n        req     -- Requests PreparedRequest object\n        include -- List of headers to include in the canonical and signed\n                   headers. It's primarily included to allow testing against\n                   specific examples from Amazon. If omitted or None it\n                   includes host, content-type and any header starting 'x-amz-'\n                   except for x-amz-client context, which appears to break\n                   mobile analytics auth if included. Except for the\n                   x-amz-client-context exclusion these defaults are per the\n                   AWS documentation.\n\n        \"\"\"\n        if include is None:\n            include = cls.default_include_headers\n        include = [x.lower() for x in include]\n        headers = req.headers.copy()\n        # Temporarily include the host header - AWS requires it to be included\n        # in the signed headers, but Requests doesn't include it in a\n        # PreparedRequest\n        if 'host' not in headers:\n            headers['host'] = urlparse(req.url).netloc.split(':')[0]\n        # Aggregate for upper/lowercase header name collisions in header names,\n        # AMZ requires values of colliding headers be concatenated into a\n        # single header with lowercase name.  Although this is not possible with\n        # Requests, since it uses a case-insensitive dict to hold headers, this\n        # is here just in case you duck type with a regular dict\n        cano_headers_dict = {}\n        for hdr, val in headers.items():\n            hdr = hdr.strip().lower()\n            val = cls.amz_norm_whitespace(val).strip()\n            if (hdr in include or '*' in include or\n                    ('x-amz-*' in include and hdr.startswith('x-amz-') and not\n                    hdr == 'x-amz-client-context')):\n                vals = cano_headers_dict.setdefault(hdr, [])\n                vals.append(val)\n        # Flatten cano_headers dict to string and generate signed_headers\n        cano_headers = ''\n        signed_headers_list = []\n        for hdr in sorted(cano_headers_dict):\n            vals = cano_headers_dict[hdr]\n            val = ','.join(sorted(vals))\n            cano_headers += '{}:{}\\n'.format(hdr, val)\n            signed_headers_list.append(hdr)\n        signed_headers = ';'.join(signed_headers_list)\n        return (cano_headers, signed_headers)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates the AWS4 auth string to sign for the request.", "response": "def get_sig_string(req, cano_req, scope):\n        \"\"\"\n        Generate the AWS4 auth string to sign for the request.\n\n        req      -- Requests PreparedRequest object. This should already\n                    include an x-amz-date header.\n        cano_req -- The Canonical Request, as returned by\n                    get_canonical_request()\n\n        \"\"\"\n        amz_date = req.headers['x-amz-date']\n        hsh = hashlib.sha256(cano_req.encode())\n        sig_items = ['AWS4-HMAC-SHA256', amz_date, scope, hsh.hexdigest()]\n        sig_string = '\\n'.join(sig_items)\n        return sig_string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate the canonical path as per AWS4 auth requirements.", "response": "def amz_cano_path(self, path):\n        \"\"\"\n        Generate the canonical path as per AWS4 auth requirements.\n\n        Not documented anywhere, determined from aws4_testsuite examples,\n        problem reports and testing against the live services.\n\n        path -- request path\n\n        \"\"\"\n        safe_chars = '/~'\n        qs = ''\n        fixed_path = path\n        if '?' in fixed_path:\n            fixed_path, qs = fixed_path.split('?', 1)\n        fixed_path = posixpath.normpath(fixed_path)\n        fixed_path = re.sub('/+', '/', fixed_path)\n        if path.endswith('/') and not fixed_path.endswith('/'):\n            fixed_path += '/'\n        full_path = fixed_path\n        # If Python 2, switch to working entirely in str as quote() has problems\n        # with Unicode\n        if PY2:\n            full_path = full_path.encode('utf-8')\n            safe_chars = safe_chars.encode('utf-8')\n            qs = qs.encode('utf-8')\n        # S3 seems to require unquoting first. 'host' service is used in\n        # amz_testsuite tests\n        if self.service in ['s3', 'host']:\n            full_path = unquote(full_path)\n        full_path = quote(full_path, safe=safe_chars)\n        if qs:\n            qm = b'?' if PY2 else '?'\n            full_path = qm.join((full_path, qs))\n        if PY2:\n            full_path = unicode(full_path)\n        return full_path"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing and format a query string as per AWS4 auth requirements.", "response": "def amz_cano_querystring(qs):\n        \"\"\"\n        Parse and format querystring as per AWS4 auth requirements.\n\n        Perform percent quoting as needed.\n\n        qs -- querystring\n\n        \"\"\"\n        safe_qs_amz_chars = '&=+'\n        safe_qs_unresvd = '-_.~'\n        # If Python 2, switch to working entirely in str\n        # as quote() has problems with Unicode\n        if PY2:\n            qs = qs.encode('utf-8')\n            safe_qs_amz_chars = safe_qs_amz_chars.encode()\n            safe_qs_unresvd = safe_qs_unresvd.encode()\n        qs = unquote(qs)\n        space = b' ' if PY2 else ' '\n        qs = qs.split(space)[0]\n        qs = quote(qs, safe=safe_qs_amz_chars)\n        qs_items = {}\n        for name, vals in parse_qs(qs, keep_blank_values=True).items():\n            name = quote(name, safe=safe_qs_unresvd)\n            vals = [quote(val, safe=safe_qs_unresvd) for val in vals]\n            qs_items[name] = vals\n        qs_strings = []\n        for name, vals in qs_items.items():\n            for val in vals:\n                qs_strings.append('='.join([name, val]))\n        qs = '&'.join(sorted(qs_strings))\n        if PY2:\n            qs = unicode(qs)\n        return qs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating the signing key string as bytes.", "response": "def generate_key(cls, secret_key, region, service, date,\n                     intermediates=False):\n        \"\"\"\n        Generate the signing key string as bytes.\n\n        If intermediate is set to True, returns a 4-tuple containing the key\n        and the intermediate keys:\n\n        ( signing_key, date_key, region_key, service_key )\n\n        The intermediate keys can be used for testing against examples from\n        Amazon.\n\n        \"\"\"\n        init_key = ('AWS4' + secret_key).encode('utf-8')\n        date_key = cls.sign_sha256(init_key, date)\n        region_key = cls.sign_sha256(date_key, region)\n        service_key = cls.sign_sha256(region_key, service)\n        key = cls.sign_sha256(service_key, 'aws4_request')\n        if intermediates:\n            return (key, date_key, region_key, service_key)\n        else:\n            return key"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sign_sha256(key, msg):\n        if isinstance(msg, text_type):\n            msg = msg.encode('utf-8')\n        return hmac.new(key, msg, hashlib.sha256).digest()", "response": "Generate a SHA256 HMAC of the message msg."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a datetime object into a valid STIX timestamp string.", "response": "def _format_datetime(dttm):\n    \"\"\"Convert a datetime object into a valid STIX timestamp string.\n\n    1. Convert to timezone-aware\n    2. Convert to UTC\n    3. Format in ISO format\n    4. Ensure correct precision\n       a. Add subsecond value if non-zero and precision not defined\n    5. Add \"Z\"\n\n    \"\"\"\n\n    if dttm.tzinfo is None or dttm.tzinfo.utcoffset(dttm) is None:\n        # dttm is timezone-naive; assume UTC\n        zoned = pytz.utc.localize(dttm)\n    else:\n        zoned = dttm.astimezone(pytz.utc)\n    ts = zoned.strftime(\"%Y-%m-%dT%H:%M:%S\")\n    ms = zoned.strftime(\"%f\")\n    precision = getattr(dttm, \"precision\", None)\n    if precision == \"second\":\n        pass  # Already precise to the second\n    elif precision == \"millisecond\":\n        ts = ts + \".\" + ms[:3]\n    elif zoned.microsecond > 0:\n        ts = ts + \".\" + ms.rstrip(\"0\")\n    return ts + \"Z\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _ensure_datetime_to_string(maybe_dttm):\n    if isinstance(maybe_dttm, datetime.datetime):\n        maybe_dttm = _format_datetime(maybe_dttm)\n    return maybe_dttm", "response": "Ensure that maybe_dttm is a datetime instance and return a STIX - compliant\n    string representation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting API keyword args to a mapping of URL query parameters.", "response": "def _filter_kwargs_to_query_params(filter_kwargs):\n    \"\"\"\n    Convert API keyword args to a mapping of URL query parameters.  Except for\n    \"added_after\", all keywords are mapped to match filters, i.e. to a query\n    parameter of the form \"match[<kwarg>]\".  \"added_after\" is left alone, since\n    it's a special filter, as defined in the spec.\n\n    Each value can be a single value or iterable of values.  \"version\" and\n    \"added_after\" get special treatment, since they are timestamp-valued:\n    datetime.datetime instances are supported and automatically converted to\n    STIX-compliant strings.  Other than that, all values must be strings.  None\n    values, empty lists, etc are silently ignored.\n\n    Args:\n        filter_kwargs: The filter information, as a mapping.\n\n    Returns:\n        query_params (dict): The query parameter map, mapping strings to\n            strings.\n\n    \"\"\"\n    query_params = {}\n    for kwarg, arglist in six.iteritems(filter_kwargs):\n        # If user passes an empty list, None, etc, silently skip?\n        if not arglist:\n            continue\n\n        # force iterability, for the sake of code uniformity\n        if not hasattr(arglist, \"__iter__\") or \\\n                isinstance(arglist, six.string_types):\n            arglist = arglist,\n\n        if kwarg == \"version\":\n            query_params[\"match[version]\"] = \",\".join(\n                _ensure_datetime_to_string(val) for val in arglist\n            )\n\n        elif kwarg == \"added_after\":\n            if len(arglist) > 1:\n                raise InvalidArgumentsError(\"No more than one value for filter\"\n                                            \" 'added_after' may be given\")\n\n            query_params[\"added_after\"] = \",\".join(\n                _ensure_datetime_to_string(val) for val in arglist\n            )\n\n        else:\n            query_params[\"match[\" + kwarg + \"]\"] = \",\".join(arglist)\n\n    return query_params"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a response to a JSON object.", "response": "def _to_json(resp):\n    \"\"\"\n    Factors out some JSON parse code with error handling, to hopefully improve\n    error messages.\n\n    :param resp: A \"requests\" library response\n    :return: Parsed JSON.\n    :raises: InvalidJSONError If JSON parsing failed.\n    \"\"\"\n    try:\n        return resp.json()\n    except ValueError as e:\n        # Maybe better to report the original request URL?\n        six.raise_from(InvalidJSONError(\n            \"Invalid JSON was received from \" + resp.request.url\n        ), e)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the status information of the current resource", "response": "def refresh(self, accept=MEDIA_TYPE_TAXII_V20):\n        \"\"\"Updates Status information\"\"\"\n        response = self.__raw = self._conn.get(self.url,\n                                               headers={\"Accept\": accept})\n        self._populate_fields(**response)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wait_until_final(self, poll_interval=1, timeout=60):\n        start_time = time.time()\n        elapsed = 0\n        while (self.status != \"complete\" and\n                (timeout <= 0 or elapsed < timeout)):\n            time.sleep(poll_interval)\n            self.refresh()\n            elapsed = time.time() - start_time", "response": "This function will wait until the status service is complete."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates the status information. Raises errors for required properties. Raises errors for required properties.", "response": "def _validate_status(self):\n        \"\"\"Validates Status information. Raises errors for required\n        properties.\"\"\"\n        if not self.id:\n            msg = \"No 'id' in Status for request '{}'\"\n            raise ValidationError(msg.format(self.url))\n\n        if not self.status:\n            msg = \"No 'status' in Status for request '{}'\"\n            raise ValidationError(msg.format(self.url))\n\n        if self.total_count is None:\n            msg = \"No 'total_count' in Status for request '{}'\"\n            raise ValidationError(msg.format(self.url))\n\n        if self.success_count is None:\n            msg = \"No 'success_count' in Status for request '{}'\"\n            raise ValidationError(msg.format(self.url))\n\n        if self.failure_count is None:\n            msg = \"No 'failure_count' in Status for request '{}'\"\n            raise ValidationError(msg.format(self.url))\n\n        if self.pending_count is None:\n            msg = \"No 'pending_count' in Status for request '{}'\"\n            raise ValidationError(msg.format(self.url))\n\n        if len(self.successes) != self.success_count:\n            msg = \"Found successes={}, but success_count={} in status '{}'\"\n            raise ValidationError(msg.format(self.successes,\n                                             self.success_count,\n                                             self.id))\n\n        if len(self.pendings) != self.pending_count:\n            msg = \"Found pendings={}, but pending_count={} in status '{}'\"\n            raise ValidationError(msg.format(self.pendings,\n                                             self.pending_count,\n                                             self.id))\n\n        if len(self.failures) != self.failure_count:\n            msg = \"Found failures={}, but failure_count={} in status '{}'\"\n            raise ValidationError(msg.format(self.failures,\n                                             self.failure_count,\n                                             self.id))\n\n        if (self.success_count + self.pending_count + self.failure_count !=\n                self.total_count):\n            msg = (\"(success_count={} + pending_count={} + \"\n                   \"failure_count={}) != total_count={} in status '{}'\")\n            raise ValidationError(msg.format(self.success_count,\n                                             self.pending_count,\n                                             self.failure_count,\n                                             self.total_count,\n                                             self.id))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _validate_collection(self):\n        if not self._id:\n            msg = \"No 'id' in Collection for request '{}'\"\n            raise ValidationError(msg.format(self.url))\n\n        if not self._title:\n            msg = \"No 'title' in Collection for request '{}'\"\n            raise ValidationError(msg.format(self.url))\n\n        if self._can_read is None:\n            msg = \"No 'can_read' in Collection for request '{}'\"\n            raise ValidationError(msg.format(self.url))\n\n        if self._can_write is None:\n            msg = \"No 'can_write' in Collection for request '{}'\"\n            raise ValidationError(msg.format(self.url))\n\n        if self._id not in self.url:\n            msg = \"The collection '{}' does not match the url for queries '{}'\"\n            raise ValidationError(msg.format(self._id, self.url))", "response": "Validates the collection information. Raises errors for required\n            properties."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimplement the Get Objects endpoint ( section 5. 3. 1", "response": "def get_objects(self, accept=MEDIA_TYPE_STIX_V20, **filter_kwargs):\n        \"\"\"Implement the ``Get Objects`` endpoint (section 5.3)\"\"\"\n        self._verify_can_read()\n        query_params = _filter_kwargs_to_query_params(filter_kwargs)\n        return self._conn.get(self.objects_url, headers={\"Accept\": accept},\n                              params=query_params)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_object(self, obj_id, version=None, accept=MEDIA_TYPE_STIX_V20):\n        self._verify_can_read()\n        url = self.objects_url + str(obj_id) + \"/\"\n        query_params = None\n        if version:\n            query_params = _filter_kwargs_to_query_params({\"version\": version})\n        return self._conn.get(url, headers={\"Accept\": accept},\n                              params=query_params)", "response": "Implement the Get an Object endpoint ( section 5. 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nimplement the Add Objects endpoint.", "response": "def add_objects(self, bundle, wait_for_completion=True, poll_interval=1,\n                    timeout=60, accept=MEDIA_TYPE_TAXII_V20,\n                    content_type=MEDIA_TYPE_STIX_V20):\n        \"\"\"Implement the ``Add Objects`` endpoint (section 5.4)\n\n        Add objects to the collection.  This may be performed either\n        synchronously or asynchronously.  To add asynchronously, set\n        wait_for_completion to False.  If False, the latter two args are\n        unused.  If the caller wishes to monitor the status of the addition,\n        it may do so in its own way.  To add synchronously, set\n        wait_for_completion to True, and optionally set the poll and timeout\n        intervals.  After initiating the addition, the caller will block,\n        and the TAXII \"status\" service will be polled until the timeout\n        expires, or the operation completes.\n\n        Args:\n            bundle: A STIX bundle with the objects to add (string, dict, binary)\n            wait_for_completion (bool): Whether to wait for the add operation\n                to complete before returning\n            poll_interval (int): If waiting for completion, how often to poll\n                the status service (seconds)\n            timeout (int): If waiting for completion, how long to poll until\n                giving up (seconds).  Use <= 0 to wait forever\n            accept (str): media type to include in the ``Accept:`` header.\n            content_type (str): media type to include in the ``Content-Type:``\n                header.\n\n        Returns:\n            If ``wait_for_completion`` is False, a Status object corresponding\n            to the initial status data returned from the service, is returned.\n            The status may not yet be complete at this point.\n\n            If ``wait_for_completion`` is True, a Status object corresponding\n            to the completed operation is returned if it didn't time out;\n            otherwise a Status object corresponding to the most recent data\n            obtained before the timeout, is returned.\n\n        \"\"\"\n        self._verify_can_write()\n\n        headers = {\n            \"Accept\": accept,\n            \"Content-Type\": content_type,\n        }\n\n        if isinstance(bundle, dict):\n            json_text = json.dumps(bundle, ensure_ascii=False)\n            data = json_text.encode(\"utf-8\")\n\n        elif isinstance(bundle, six.text_type):\n            data = bundle.encode(\"utf-8\")\n\n        elif isinstance(bundle, six.binary_type):\n            data = bundle\n\n        else:\n            raise TypeError(\"Don't know how to handle type '{}'\".format(\n                type(bundle).__name__))\n\n        status_json = self._conn.post(self.objects_url, headers=headers,\n                                      data=data)\n\n        status_url = urlparse.urljoin(\n            self.url,\n            \"../../status/{}\".format(status_json[\"id\"])\n        )\n\n        status = Status(url=status_url, conn=self._conn,\n                        status_info=status_json)\n\n        if not wait_for_completion or status.status == \"complete\":\n            return status\n\n        status.wait_until_final(poll_interval, timeout)\n\n        return status"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_manifest(self, accept=MEDIA_TYPE_TAXII_V20, **filter_kwargs):\n        self._verify_can_read()\n        query_params = _filter_kwargs_to_query_params(filter_kwargs)\n        return self._conn.get(self.url + \"manifest/\",\n                              headers={\"Accept\": accept},\n                              params=query_params)", "response": "Implement the Get Object Manifests endpoint ( section 5. 6. 1. 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _validate_api_root(self):\n        if not self._title:\n            msg = \"No 'title' in API Root for request '{}'\"\n            raise ValidationError(msg.format(self.url))\n\n        if not self._versions:\n            msg = \"No 'versions' in API Root for request '{}'\"\n            raise ValidationError(msg.format(self.url))\n\n        if self._max_content_length is None:\n            msg = \"No 'max_content_length' in API Root for request '{}'\"\n            raise ValidationError(msg.format(self.url))", "response": "Validates API Root information. Raises errors for required\n        properties."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the API Root s information and list of Collections", "response": "def refresh(self, accept=MEDIA_TYPE_TAXII_V20):\n        \"\"\"Update the API Root's information and list of Collections\"\"\"\n        self.refresh_information(accept)\n        self.refresh_collections(accept)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef refresh_information(self, accept=MEDIA_TYPE_TAXII_V20):\n        response = self.__raw = self._conn.get(self.url,\n                                               headers={\"Accept\": accept})\n        self._populate_fields(**response)\n        self._loaded_information = True", "response": "Refreshes the properties of this object based on the response from the Get API Root Information endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef refresh_collections(self, accept=MEDIA_TYPE_TAXII_V20):\n        url = self.url + \"collections/\"\n        response = self._conn.get(url, headers={\"Accept\": accept})\n\n        self._collections = []\n        for item in response.get(\"collections\", []):  # optional\n            collection_url = url + item[\"id\"] + \"/\"\n            collection = Collection(collection_url, conn=self._conn,\n                                    collection_info=item)\n            self._collections.append(collection)\n\n        self._loaded_collections = True", "response": "Updates the list of Collections contained by this API Root."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates server information. Raises errors for required properties.", "response": "def _validate_server(self):\n        \"\"\"Validates server information. Raises errors for required properties.\n        \"\"\"\n        if not self._title:\n            msg = \"No 'title' in Server Discovery for request '{}'\"\n            raise ValidationError(msg.format(self.url))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the Server information and API Roots", "response": "def refresh(self):\n        \"\"\"Update the Server information and list of API Roots\"\"\"\n        response = self.__raw = self._conn.get(self.url)\n        self._populate_fields(**response)\n        self._loaded = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks that the server is returning a valid Content - Type.", "response": "def valid_content_type(self, content_type, accept):\n        \"\"\"Check that the server is returning a valid Content-Type\n\n        Args:\n            content_type (str): ``Content-Type:`` header value\n            accept (str): media type to include in the ``Accept:`` header.\n\n        \"\"\"\n        accept_tokens = accept.replace(' ', '').split(';')\n        content_type_tokens = content_type.replace(' ', '').split(';')\n\n        return (\n            all(elem in content_type_tokens for elem in accept_tokens) and\n            (content_type_tokens[0] == 'application/vnd.oasis.taxii+json' or\n             content_type_tokens[0] == 'application/vnd.oasis.stix+json')\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform an HTTP GET request.", "response": "def get(self, url, headers=None, params=None):\n        \"\"\"Perform an HTTP GET, using the saved requests.Session and auth info.\n        If \"Accept\" isn't one of the given headers, a default TAXII mime type is\n        used.  Regardless, the response type is checked against the accept\n        header value, and an exception is raised if they don't match.\n\n        Args:\n            url (str): URL to retrieve\n            headers (dict): Any other headers to be added to the request.\n            params: dictionary or bytes to be sent in the query string for the\n                request. (optional)\n\n        \"\"\"\n\n        merged_headers = self._merge_headers(headers)\n\n        if \"Accept\" not in merged_headers:\n            merged_headers[\"Accept\"] = MEDIA_TYPE_TAXII_V20\n        accept = merged_headers[\"Accept\"]\n\n        resp = self.session.get(url, headers=merged_headers, params=params)\n\n        resp.raise_for_status()\n\n        content_type = resp.headers[\"Content-Type\"]\n\n        if not self.valid_content_type(content_type=content_type, accept=accept):\n            msg = \"Unexpected Response. Got Content-Type: '{}' for Accept: '{}'\"\n            raise TAXIIServiceException(msg.format(content_type, accept))\n\n        return _to_json(resp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a JSON POST request to the given URL.", "response": "def post(self, url, headers=None, params=None, **kwargs):\n        \"\"\"Send a JSON POST request with the given request headers, additional\n        URL query parameters, and the given JSON in the request body.  The\n        extra query parameters are merged with any which already exist in the\n        URL.  The 'json' and 'data' parameters may not both be given.\n\n        Args:\n            url (str): URL to retrieve\n            headers (dict): Any other headers to be added to the request.\n            params: dictionary or bytes to be sent in the query string for the\n                request. (optional)\n            json: json to send in the body of the Request.  This must be a\n                JSON-serializable object. (optional)\n            data: raw request body data.  May be a dictionary, list of tuples,\n                bytes, or file-like object to send in the body of the Request.\n                (optional)\n        \"\"\"\n\n        if len(kwargs) > 1:\n            raise InvalidArgumentsError(\"Too many extra args ({} > 1)\".format(\n                len(kwargs)))\n\n        if kwargs:\n            kwarg = next(iter(kwargs))\n            if kwarg not in (\"json\", \"data\"):\n                raise InvalidArgumentsError(\"Invalid kwarg: \" + kwarg)\n\n        resp = self.session.post(url, headers=headers, params=params, **kwargs)\n        resp.raise_for_status()\n        return _to_json(resp)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmerge headers from different sources together.", "response": "def _merge_headers(self, call_specific_headers):\n        \"\"\"\n        Merge headers from different sources together.  Headers passed to the\n        post/get methods have highest priority, then headers associated with\n        the connection object itself have next priority.\n\n        :param call_specific_headers: A header dict from the get/post call, or\n            None (the default for those methods).\n        :return: A key-case-insensitive MutableMapping object which contains\n            the merged headers.  (This doesn't actually return a dict.)\n        \"\"\"\n\n        # A case-insensitive mapping is necessary here so that there is\n        # predictable behavior.  If a plain dict were used, you'd get keys in\n        # the merged dict which differ only in case.  The requests library\n        # would merge them internally, and it would be unpredictable which key\n        # is chosen for the final set of headers.  Another possible approach\n        # would be to upper/lower-case everything, but this seemed easier.  On\n        # the other hand, I don't know if CaseInsensitiveDict is public API...?\n\n        # First establish defaults\n        merged_headers = requests.structures.CaseInsensitiveDict({\n            \"User-Agent\": self.user_agent\n        })\n\n        # Then overlay with specifics from post/get methods\n        if call_specific_headers:\n            merged_headers.update(call_specific_headers)\n\n        # Special \"User-Agent\" header check, to ensure one is always sent.\n        # The call-specific overlay could have null'd out that header.\n        if not merged_headers.get(\"User-Agent\"):\n            merged_headers[\"User-Agent\"] = self.user_agent\n\n        return merged_headers"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the amount of memory available for use in a list of items.", "response": "def total_memory():\n    \"\"\" Returns the the amount of memory available for use.\n\n        The memory is obtained from MemTotal entry in /proc/meminfo.\n        \n        Notes\n        =====\n        This function is not very useful and not very portable. \n\n    \"\"\"\n    with file('/proc/meminfo', 'r') as f:\n        for line in f:\n            words = line.split()\n        if words[0].upper() == 'MEMTOTAL:':\n            return int(words[1]) * 1024\n    raise IOError('MemTotal unknown')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cpu_count():\n    num = os.getenv(\"OMP_NUM_THREADS\")\n    if num is None:\n        num = os.getenv(\"PBS_NUM_PPN\")\n    try:\n        return int(num)\n    except:\n        return multiprocessing.cpu_count()", "response": "Returns the default number of slave processes to be spawned."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef empty_like(array, dtype=None):\n    array = numpy.asarray(array)\n    if dtype is None: \n        dtype = array.dtype\n    return anonymousmemmap(array.shape, dtype)", "response": "Create an anonymous shared memory array from the shape of array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef full_like(array, value, dtype=None):\n    shared = empty_like(array, dtype)\n    shared[:] = value\n    return shared", "response": "Create a shared memory array filled with value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef full(shape, value, dtype='f8'):\n    shared = empty(shape, dtype)\n    shared[:] = value\n    return shared", "response": "Create a shared memory array of given shape and type filled with value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncopy an array to the shared memory.", "response": "def copy(a):\n    \"\"\" Copy an array to the shared memory. \n\n        Notes\n        -----\n        copy is not always necessary because the private memory is always copy-on-write.\n\n        Use :code:`a = copy(a)` to immediately dereference the old 'a' on private memory\n    \"\"\"\n    shared = anonymousmemmap(a.shape, dtype=a.dtype)\n    shared[:] = a[:]\n    return shared"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, Q):\n        while self.Errors.empty():\n            try:\n                return Q.get(timeout=1)\n            except queue.Empty:\n                # check if the process group is dead\n                if not self.is_alive():\n                    # todo : can be graceful, in which\n                    # case the last item shall have been\n                    # flushed to Q.\n                    try:\n                        return Q.get(timeout=0)\n                    except queue.Empty:\n                        raise StopProcessGroup\n                else:\n                    continue\n        else:\n            raise StopProcessGroup", "response": "Protected get. Get an item from Q."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwaiting and join the child process.", "response": "def wait(self):\n        \"\"\" Wait and join the child process. \n            The return value of the function call is returned.\n            If any exception occurred it is wrapped and raised.\n        \"\"\"\n        e, r = self.result.get()\n        self.slave.join()\n        self.slave = None\n        self.result = None\n        if isinstance(e, Exception):\n            raise SlaveException(e, r)\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef map(self, func, sequence, reduce=None, star=False, minlength=0):\n        def realreduce(r):\n            if reduce:\n                if isinstance(r, tuple):\n                    return reduce(*r)\n                else:\n                    return reduce(r)\n            return r\n\n        def realfunc(i):\n            if star: return func(*i)\n            else: return func(i)\n\n        if len(sequence) <= 0 or self.np == 0 or get_debug():\n            # Do this in serial\n            self.local = lambda : None\n            self.local.rank = 0\n\n            rt = [realreduce(realfunc(i)) for i in sequence]\n\n            self.local = None\n            return rt\n\n        # never use more than len(sequence) processes\n        np = min([self.np, len(sequence)])\n\n        Q = self.backend.QueueFactory(64)\n        R = self.backend.QueueFactory(64)\n        self.ordered.reset()\n\n        pg = ProcessGroup(main=self._main, np=np,\n                backend=self.backend,\n                args=(Q, R, sequence, realfunc))\n\n        pg.start()\n\n        L = []\n        N = []\n        def feeder(pg, Q, N):\n            #   will fail silently if any error occurs.\n            j = 0\n            try:\n                for i, work in enumerate(sequence):\n                    if not hasattr(sequence, '__getitem__'):\n                        pg.put(Q, (i, work))\n                    else:\n                        pg.put(Q, (i, ))\n                    j = j + 1\n                N.append(j)\n\n                for i in range(np):\n                    pg.put(Q, None)\n            except StopProcessGroup:\n                return\n            finally:\n                pass\n        feeder = threading.Thread(None, feeder, args=(pg, Q, N))\n        feeder.start() \n\n        # we run fetcher on main thread to catch exceptions\n        # raised by reduce \n        count = 0\n        try:\n            while True:\n                try:\n                    capsule = pg.get(R)\n                except queue.Empty:\n                    continue\n                except StopProcessGroup:\n                    raise pg.get_exception()\n                capsule = capsule[0], realreduce(capsule[1])\n                heapq.heappush(L, capsule)\n                count = count + 1\n                if len(N) > 0 and count == N[0]: \n                    # if finished feeding see if all\n                    # results have been obtained\n                    break\n            rt = []\n#            R.close()\n#            R.join_thread()\n            while len(L) > 0:\n                rt.append(heapq.heappop(L)[1])\n            pg.join()\n            feeder.join()\n            assert N[0] == len(rt)\n            return rt\n        except BaseException as e:\n            pg.killall()\n            pg.join()\n            feeder.join()\n            raise", "response": "Map a function over a sequence of items and return the reduced result."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef savetxt2(fname, X, delimiter=' ', newline='\\n', comment_character='#',\n        header='', save_dtype=False, fmt={}):\n\n    \"\"\" format of table header:\n\n        # ID [type]:name(index) .... * number of items\n\n        user's header is not prefixed by comment_character\n\n        name of nested dtype elements are split by .\n    \"\"\"\n    prefixfmt = {}\n    for key in fmt:\n            prefixfmt[key] = fmt[key]\n\n    olddtype = X.dtype\n    newdtype = flatten_dtype(numpy.dtype([('', (X.dtype, X.shape[1:]))]))\n    X = X.view(dtype=newdtype)\n    dtype = X.dtype\n    X = numpy.atleast_1d(X.squeeze())\n    header2 = _mkheader(dtype)\n    fmtstr = _mkfmtstr(dtype, prefixfmt, delimiter, _default_fmt)\n    if hasattr(fname, 'write'):\n        fh = fname\n        cleanup = lambda : None\n    else:\n        fh = file(fname, 'w+')\n        cleanup = lambda : fh.close()\n    try:\n        fh.write (header)\n        if header[:-1] != newline:\n            fh.write(newline)\n        fh.write (comment_character)\n        fh.write ('!')\n        fh.write (header2)\n        fh.write (delimiter)\n        fh.write ('*%d' % len(X))\n        fh.write(newline)\n        if save_dtype:\n            fh.write (comment_character)\n            fh.write ('?')\n            fh.write (base64.b64encode(pickle.dumps(olddtype)))\n            fh.write (newline)\n        for row in X:\n            fh.write(fmtstr % tuple(row))\n            fh.write(newline)\n\n        if hasattr(fh, 'flush'):\n            fh.flush()\n    finally:\n        cleanup()", "response": "Save a numpy array to a file in 2 - line format."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef loadtxt2(fname, dtype=None, delimiter=' ', newline='\\n', comment_character='#',\n        skiplines=0):\n    \"\"\" Known issues delimiter and newline is not respected. \n        string quotation with space is broken.\n    \"\"\"\n    dtypert = [None, None, None]\n    def preparedtype(dtype):\n        dtypert[0] = dtype\n        flatten = flatten_dtype(dtype)\n        dtypert[1] = flatten\n        dtypert[2] = numpy.dtype([('a', (numpy.int8,\n            flatten.itemsize))])\n        buf = numpy.empty((), dtype=dtypert[1])\n        converters = [_default_conv[flatten[name].char] for name in flatten.names]\n        return buf, converters, flatten.names\n\n    def fileiter(fh):\n        converters = []\n        buf = None\n\n        if dtype is not None:\n            buf, converters, names = preparedtype(dtype)\n            yield None\n\n        for lineno, line in enumerate(fh):\n            if lineno < skiplines: continue\n            if line[0] in comment_character:\n                if buf is None and line[1] == '?':\n                    ddtype = pickle.loads(base64.b64decode(line[2:]))\n                    buf, converters, names = preparedtype(ddtype)\n                    yield None\n                continue\n            for word, c, name in zip(line.split(), converters, names):\n                buf[name] = c(word)\n            buf2 = buf.copy().view(dtype=dtypert[2])\n            yield buf2\n\n    if isinstance(fname, basestring):\n        fh = file(fh, 'r')\n        cleanup = lambda : fh.close()\n    else:\n        fh = iter(fname)\n        cleanup = lambda : None\n    try:\n        i = fileiter(fh)\n        i.next()\n        return numpy.fromiter(i, dtype=dtypert[2]).view(dtype=dtypert[0]) \n    finally:\n        cleanup()", "response": "Load a text file into a list of objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nunpack a structured data - type into a list of nested numpy. ndarrays.", "response": "def flatten_dtype(dtype, _next=None):\n    \"\"\" Unpack a structured data-type.  \"\"\"\n    types = []\n    if _next is None: \n        _next = [0, '']\n        primary = True\n    else:\n        primary = False\n\n    prefix = _next[1]\n\n    if dtype.names is None:\n        for i in numpy.ndindex(dtype.shape):\n            if dtype.base == dtype:\n                types.append(('%s%s' % (prefix, simplerepr(i)), dtype))\n                _next[0] += 1\n            else:\n                _next[1] = '%s%s' % (prefix, simplerepr(i))\n                types.extend(flatten_dtype(dtype.base, _next))\n    else:\n        for field in dtype.names:\n            typ_fields = dtype.fields[field]\n            if len(prefix) > 0:\n                _next[1] = prefix + '.' + field\n            else:\n                _next[1] = '' + field\n            flat_dt = flatten_dtype(typ_fields[0], _next)\n            types.extend(flat_dt)\n\n    _next[1] = prefix\n    if primary:\n        return numpy.dtype(types)\n    else:\n        return types"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nkilling all slaves and reap the monitor", "response": "def kill_all(self):\n        \"\"\"kill all slaves and reap the monitor \"\"\"\n        for pid in self.children:\n            try:\n                os.kill(pid, signal.SIGTRAP)\n            except OSError:\n                continue\n        self.join()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef forloop(self, range, ordered=False, schedule=('static', 1)):\n\n        if isinstance(schedule, tuple):\n            schedule, chunk = schedule\n        else:\n            chunk = None\n        if schedule == 'static':\n            return self._StaticForLoop(range, ordered, chunk)\n        elif schedule == 'dynamic':\n            return self._DynamicForLoop(range, ordered, chunk, guided=False)\n        elif schedule == 'guided':\n            return self._DynamicForLoop(range, ordered, chunk, guided=True)\n        else:\n            raise \"schedule unknown\"", "response": "forloop for the given time range"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nensures the master exit from Barrier", "response": "def abort(self):\n        \"\"\" ensure the master exit from Barrier \"\"\"\n        self.mutex.release()\n        self.turnstile.release()\n        self.mutex.release()\n        self.turnstile2.release()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread at most n array items move the cursor.", "response": "def read(self, n):\n        \"\"\" return at most n array items, move the cursor. \n        \"\"\"\n        while len(self.pool) < n:\n            self.cur = self.files.next()\n            self.pool = numpy.append(self.pool,\n                    self.fetch(self.cur), axis=0)\n\n        rt = self.pool[:n]\n        if n == len(self.pool):\n            self.pool = self.fetch(None)\n        else:\n            self.pool = self.pool[n:]\n        return rt"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef call(self, args, axis=0, out=None, chunksize=1024 * 1024, **kwargs):\n        if self.altreduce is not None:\n            ret = [None]\n        else:\n            if out is None :\n                if self.outdtype is not None:\n                    dtype = self.outdtype\n                else:\n                    try:\n                        dtype = numpy.result_type(*[args[i] for i in self.ins] * 2)\n                    except:\n                        dtype = None\n                out = sharedmem.empty(\n                        numpy.broadcast(*[args[i] for i in self.ins] * 2).shape,\n                        dtype=dtype)\n        if axis != 0:\n            for i in self.ins:\n                args[i] = numpy.rollaxis(args[i], axis)\n            out = numpy.rollaxis(out, axis)\n        size = numpy.max([len(args[i]) for i in self.ins])\n        with sharedmem.MapReduce() as pool:\n            def work(i):\n                sl = slice(i, i+chunksize)\n                myargs = args[:]\n                for j in self.ins:\n                    try: \n                        tmp = myargs[j][sl]\n                        a, b, c = sl.indices(len(args[j]))\n                        myargs[j] = tmp\n                    except Exception as e:\n                        print tmp\n                        print j, e\n                        pass\n                if b == a: return None\n                rt = self.ufunc(*myargs, **kwargs)\n                if self.altreduce is not None:\n                    return rt\n                else:\n                    out[sl] = rt\n            def reduce(rt):\n                if self.altreduce is None:\n                    return\n                if ret[0] is None:\n                    ret[0] = rt\n                elif rt is not None:\n                    ret[0] = self.altreduce(ret[0], rt)\n\n            pool.map(work, range(0, size, chunksize), reduce=reduce)\n\n        if self.altreduce is None:\n            if axis != 0:\n                out = numpy.rollaxis(out, 0, axis + 1)\n            return out                \n        else:\n            return ret[0]", "response": "Call the ufunc with the given arguments and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef adapt(cls, source, template):\n    if not isinstance(template, packarray):\n      raise TypeError('template must be a packarray')\n    return cls(source, template.start, template.end)", "response": "adapt source to a packarray according to the layout of template"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparallels argsort for a set of integers", "response": "def argsort(data, out=None, chunksize=None, \n        baseargsort=None, \n        argmerge=None, np=None):\n    \"\"\"\n     parallel argsort, like numpy.argsort\n\n     use sizeof(intp) * len(data) as scratch space\n\n     use baseargsort for serial sort \n         ind = baseargsort(data)\n\n     use argmerge to merge\n         def argmerge(data, A, B, out):\n             ensure data[out] is sorted\n             and out[:] = A join B\n\n     TODO: shall try to use the inplace merge mentioned in \n            http://keithschwarz.com/interesting/code/?dir=inplace-merge.\n    \"\"\"\n    if baseargsort is None:\n        baseargsort = lambda x:x.argsort()\n\n    if argmerge is None:\n        argmerge = default_argmerge\n\n    if chunksize is None:\n        chunksize = 1024 * 1024 * 16\n\n    if out is None:\n        arg1 = numpy.empty(len(data), dtype='intp')\n        out = arg1\n    else:\n        assert out.dtype == numpy.dtype('intp')\n        assert len(out) == len(data)\n        arg1 = out\n\n    if np is None:\n        np = sharedmem.cpu_count()\n\n    if np <= 1 or len(data) < chunksize: \n        out[:] = baseargsort(data)\n        return out\n\n    CHK = [slice(i, i + chunksize) for i in range(0, len(data), chunksize)]\n    DUMMY = slice(len(data), len(data))\n    if len(CHK) % 2: CHK.append(DUMMY)\n    with sharedmem.TPool() as pool:\n        def work(i):\n            C = CHK[i]\n            start, stop, step = C.indices(len(data))\n            arg1[C] = baseargsort(data[C])\n            arg1[C] += start\n        pool.map(work, range(len(CHK)))\n  \n    arg2 = numpy.empty_like(arg1)\n  \n    flip = 0\n    while len(CHK) > 1:\n        with sharedmem.TPool() as pool:\n            def work(i):\n                C1 = CHK[i]\n                C2 = CHK[i+1]\n                start1, stop1, step1 = C1.indices(len(data))\n                start2, stop2, step2 = C2.indices(len(data))\n        #        print 'argmerge', start1, stop1, start2, stop2\n                assert start2 == stop1\n                argmerge(data, arg1[C1], arg1[C2], arg2[start1:stop2])\n                return slice(start1, stop2)\n            CHK = pool.map(work, range(0, len(CHK), 2))\n            arg1, arg2 = arg2, arg1\n            flip = flip + 1\n        if len(CHK) == 1: break\n        if len(CHK) % 2: CHK.append(DUMMY)\n    if flip % 2 != 0:\n        # only even flips out ends up pointing to arg2 and needs to be\n        # copied\n        out[:] = arg1\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a random day of week name.", "response": "def day_of_week(abbr=False):\n    \"\"\"Return a random (abbreviated if `abbr`) day of week name.\"\"\"\n    if abbr:\n        return random.choice(DAYS_ABBR)\n    else:\n        return random.choice(DAYS)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a random month name or month number if numerical.", "response": "def month(abbr=False, numerical=False):\n    \"\"\"Return a random (abbreviated if `abbr`) month name or month number if\n    `numerical`.\n    \"\"\"\n    if numerical:\n        return random.randint(1, 12)\n    else:\n        if abbr:\n            return random.choice(MONTHS_ABBR)\n        else:\n            return random.choice(MONTHS)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef year(past=False, min_delta=0, max_delta=20):\n    return dt.date.today().year + _delta(past, min_delta, max_delta)", "response": "Return a random year."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a random dt. date object. Delta args are days.", "response": "def date(past=False, min_delta=0, max_delta=20):\n    \"\"\"Return a random `dt.date` object. Delta args are days.\"\"\"\n    timedelta = dt.timedelta(days=_delta(past, min_delta, max_delta))\n    return dt.date.today() + timedelta"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a dictionary file and return its contents as an array of strings.", "response": "def get_dictionary(dict_name):\n    \"\"\"\n    Load a dictionary file ``dict_name`` (if it's not cached) and return its\n    contents as an array of strings.\n    \"\"\"\n    global dictionaries_cache\n\n    if dict_name not in dictionaries_cache:\n        try:\n            dictionary_file = codecs.open(\n                join(DICTIONARIES_PATH, dict_name), 'r', 'utf-8'\n            )\n        except IOError:\n            None\n        else:\n            dictionaries_cache[dict_name] = dictionary_file.readlines()\n            dictionary_file.close()\n\n    return dictionaries_cache[dict_name]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a check digit of the given credit card number.", "response": "def check_digit(num):\n    \"\"\"Return a check digit of the given credit card number.\n\n    Check digit calculated using Luhn algorithm (\"modulus 10\")\n    See: http://www.darkcoding.net/credit-card/luhn-formula/\n    \"\"\"\n    sum = 0\n\n    # drop last digit, then reverse the number\n    digits = str(num)[:-1][::-1]\n\n    for i, n in enumerate(digits):\n        # select all digits at odd positions starting from 1\n        if (i + 1) % 2 != 0:\n            digit = int(n) * 2\n            if digit > 9:\n                sum += (digit - 9)\n            else:\n                sum += digit\n        else:\n            sum += int(n)\n\n    return ((divmod(sum, 10)[0] + 1) * 10 - sum) % 10"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a random credit card number.", "response": "def number(type=None, length=None, prefixes=None):\n    \"\"\"\n    Return a random credit card number.\n\n    :param type: credit card type. Defaults to a random selection.\n    :param length: length of the credit card number.\n                   Defaults to the length for the selected card type.\n    :param prefixes: allowed prefixes for the card number.\n                     Defaults to prefixes for the selected card type.\n    :return: credit card randomly generated number (int)\n    \"\"\"\n    # select credit card type\n    if type and type in CARDS:\n        card = type\n    else:\n        card = random.choice(list(CARDS.keys()))\n\n    # select a credit card number's prefix\n    if not prefixes:\n        prefixes = CARDS[card]['prefixes']\n    prefix = random.choice(prefixes)\n\n    # select length of the credit card number, if it's not set\n    if not length:\n        length = CARDS[card]['length']\n\n    # generate all digits but the last one\n    result = str(prefix)\n\n    for d in range(length - len(str(prefix))):\n        result += str(basic.number())\n\n    last_digit = check_digit(int(result))\n\n    return int(result[:-1] + str(last_digit))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a random street number.", "response": "def street_number():\n    \"\"\"Return a random street number.\"\"\"\n    length = int(random.choice(string.digits[1:6]))\n    return ''.join(random.sample(string.digits, length))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a random ZIP code either in a##### or a##### -#### format.", "response": "def zip_code():\n    \"\"\"Return a random ZIP code, either in `#####` or `#####-####` format.\"\"\"\n    format = '#####'\n    if random.random() >= 0.5:\n        format = '#####-####'\n\n    result = ''\n    for item in format:\n        if item == '#':\n            result += str(random.randint(0, 9))\n        else:\n            result += item\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a random phone number in the specified format.", "response": "def phone():\n    \"\"\"Return a random phone number in `#-(###)###-####` format.\"\"\"\n    format = '#-(###)###-####'\n\n    result = ''\n    for item in format:\n        if item == '#':\n            result += str(random.randint(0, 9))\n        else:\n            result += item\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a random job title.", "response": "def job_title():\n    \"\"\"Return a random job title.\"\"\"\n    result = random.choice(get_dictionary('job_titles')).strip()\n    result = result.replace('#{N}', job_title_suffix())\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a random email text.", "response": "def body(quantity=2, separator='\\n\\n', wrap_start='', wrap_end='',\n         html=False, sentences_quantity=3, as_list=False):\n    \"\"\"Return a random email text.\"\"\"\n    return lorem_ipsum.paragraphs(quantity=quantity, separator=separator,\n                                  wrap_start=wrap_start, wrap_end=wrap_end,\n                                  html=html,\n                                  sentences_quantity=sentences_quantity,\n                                  as_list=as_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef money(min=0, max=10):\n    value = random.choice(range(min * 100, max * 100))\n    return \"%1.2f\" % (float(value) / 100)", "response": "Return a str of decimal with two digits after a decimal mark."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef title(words_quantity=4):\n    result = words(quantity=words_quantity)\n    result += random.choice('?.!')\n    return result.capitalize()", "response": "Return a random sentence to be used as e - mail subject."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a random paragraph.", "response": "def paragraph(separator='\\n\\n', wrap_start='', wrap_end='',\n              html=False, sentences_quantity=3):\n    \"\"\"Return a random paragraph.\"\"\"\n    return paragraphs(quantity=1, separator=separator, wrap_start=wrap_start,\n                      wrap_end=wrap_end, html=html,\n                      sentences_quantity=sentences_quantity)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _to_lower_alpha_only(s):\n    s = re.sub(r'\\n', ' ',  s.lower())\n    return re.sub(r'[^a-z\\s]', '', s)", "response": "Return a lowercased string with non alphabetic chars removed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef text(what=\"sentence\", *args, **kwargs):\n\n    if what == \"character\":\n        return character(*args, **kwargs)\n    elif what == \"characters\":\n        return characters(*args, **kwargs)\n    elif what == \"word\":\n        return word(*args, **kwargs)\n    elif what == \"words\":\n        return words(*args, **kwargs)\n    elif what == \"sentence\":\n        return sentence(*args, **kwargs)\n    elif what == \"sentences\":\n        return sentences(*args, **kwargs)\n    elif what == \"paragraph\":\n        return paragraph(*args, **kwargs)\n    elif what == \"paragraphs\":\n        return paragraphs(*args, **kwargs)\n    elif what == \"title\":\n        return title(*args, **kwargs)\n    else:\n        raise NameError('No such method')", "response": "An aggregator for all above defined public methods."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a random user name.", "response": "def user_name(with_num=False):\n    \"\"\"Return a random user name.\n\n    Basically it's lowercased result of\n    :py:func:`~forgery_py.forgery.name.first_name()` with a number appended\n    if `with_num`.\n    \"\"\"\n    result = first_name()\n    if with_num:\n        result += str(random.randint(63, 94))\n\n    return result.lower()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef domain_name():\n    result = random.choice(get_dictionary('company_names')).strip()\n    result += '.' + top_level_domain()\n\n    return result.lower()", "response": "Return a random domain name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef email_address(user=None):\n    if not user:\n        user = user_name()\n    else:\n        user = user.strip().replace(' ', '_').lower()\n\n    return user + '@' + domain_name()", "response": "Return a random e - mail address in a hopefully imaginary domain."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef account_number():\n    account = [random.randint(1, 9) for _ in range(20)]\n    return \"\".join(map(str, account))", "response": "Return a random bank account number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bik():\n    return '04' + \\\n           ''.join([str(random.randint(1, 9)) for _ in range(5)]) + \\\n           str(random.randint(0, 49) + 50)", "response": "Return a random bank identification number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef legal_inn():\n    mask = [2, 4, 10, 3, 5, 9, 4, 6, 8]\n    inn = [random.randint(1, 9) for _ in range(10)]\n    weighted = [v * mask[i] for i, v in enumerate(inn[:-1])]\n    inn[9] = sum(weighted) % 11 % 10\n    return \"\".join(map(str, inn))", "response": "Return a random taxation ID number for a company."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a random government registration ID for a company.", "response": "def legal_ogrn():\n    \"\"\"Return a random government registration ID for a company.\"\"\"\n    ogrn = \"\".join(map(str, [random.randint(1, 9) for _ in range(12)]))\n    ogrn += str((int(ogrn) % 11 % 10))\n    return ogrn"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef person_inn():\n    mask11 = [7, 2, 4, 10, 3, 5, 9, 4, 6, 8]\n    mask12 = [3, 7, 2, 4, 10, 3, 5, 9, 4, 6, 8]\n    inn = [random.randint(1, 9) for _ in range(12)]\n\n    # get the 11th digit of the INN\n    weighted11 = [v * mask11[i] for i, v in enumerate(inn[:-2])]\n    inn[10] = sum(weighted11) % 11 % 10\n\n    # get the 12th digit of the INN\n    weighted12 = [v * mask12[i] for i, v in enumerate(inn[:-1])]\n    inn[11] = sum(weighted12) % 11 % 10\n\n    return \"\".join(map(str, inn))", "response": "Return a random taxation ID number for a natural person."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning SHA1 hexdigest of a password optionally salted with a string.", "response": "def encrypt(password='password', salt=None):\n    \"\"\"\n    Return SHA1 hexdigest of a password (optionally salted with a string).\n\n\n    \"\"\"\n    if not salt:\n        salt = str(datetime.utcnow())\n\n    try:\n        #  available for python 2.7.8 and python 3.4+\n        dk = hashlib.pbkdf2_hmac('sha1', password.encode(), salt.encode(), 100000)\n        hexdigest = binascii.hexlify(dk).decode('utf-8')\n    except AttributeError:\n        # see https://pymotw.com/2/hashlib/\n        # see https://docs.python.org/release/2.5/lib/module-hashlib.html\n        dk = hashlib.sha1()\n        dk.update(password.encode() + salt.encode())\n        hexdigest = dk.hexdigest()\n    return hexdigest"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a random string for use as a password.", "response": "def password(at_least=6, at_most=12, lowercase=True,\n             uppercase=True, digits=True, spaces=False, punctuation=False):\n    \"\"\"Return a random string for use as a password.\"\"\"\n    return text(at_least=at_least, at_most=at_most, lowercase=lowercase,\n                uppercase=uppercase, digits=digits, spaces=spaces,\n                punctuation=punctuation)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef forwards(self, orm):\n        \"Write your forwards methods here.\"\n        # Note: Don't use \"from appname.models import ModelName\". \n        # Use orm.ModelName to refer to models in this application,\n        # and orm['appname.ModelName'] for models in other applications.\n        print(\"Updating: JednostkaAdministracyjna\")\n        ja_akt_stan=orm.JednostkaAdministracyjna.objects.all().aggregate(Max('stan_na'))['stan_na__max']\n        orm.JednostkaAdministracyjna.objects.filter(stan_na__exact=ja_akt_stan).update(aktywny=True)\n        orm.JednostkaAdministracyjna.objects.exclude(stan_na__exact=ja_akt_stan).update(aktywny=False)\n\n        print(\"Updating: Miejscowosc\")\n        m_akt_stan=orm.Miejscowosc.objects.all().aggregate(Max('stan_na'))['stan_na__max']\n        orm.Miejscowosc.objects.filter(stan_na__exact=m_akt_stan).update(aktywny=True)\n        orm.Miejscowosc.objects.exclude(stan_na__exact=m_akt_stan).update(aktywny=False)\n\n        print(\"Updating: RodzajMiejsowosci\")\n        rm_akt_stan=orm.RodzajMiejsowosci.objects.all().aggregate(Max('stan_na'))['stan_na__max']\n        orm.RodzajMiejsowosci.objects.filter(stan_na__exact=rm_akt_stan).update(aktywny=True)\n        orm.RodzajMiejsowosci.objects.exclude(stan_na__exact=rm_akt_stan).update(aktywny=False)\n\n        print(\"Updating: Ulica\")\n        u_akt_stan=orm.Ulica.objects.all().aggregate(Max('stan_na'))['stan_na__max']\n        orm.Ulica.objects.filter(stan_na__exact=u_akt_stan).update(aktywny=True)\n        orm.Ulica.objects.exclude(stan_na__exact=u_akt_stan).update(aktywny=False)", "response": "Write your forwards methods here."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef forwards(self, orm):\n        \"Write your forwards methods here.\"\n        # Note: Don't use \"from appname.models import ModelName\". \n        # Use orm.ModelName to refer to models in this application,\n        # and orm['appname.ModelName'] for models in other applications.\n        LEN_TYPE = {\n            7: 'GMI',\n            4: 'POW',\n            2: 'WOJ',\n        }\n        for ja in orm.JednostkaAdministracyjna.objects.all():\n            ja.typ = LEN_TYPE[len(ja.id)]\n            ja.save()", "response": "Write your forwards methods here."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef case(*, to, **kwargs):\n\n    if len(kwargs) != 1:\n        raise ValueError(\"expect exactly one source string argument\")\n\n    [(typ, string)] = kwargs.items()\n\n    types = {'pascal', 'camel', 'snake', 'constant'}\n    if typ not in types:\n        raise ValueError(f\"source string keyword must be one of {types}\")\n    if to not in types:\n        raise ValueError(f\"\\\"to\\\" argument must be one of {types}\")\n\n    def pascal_iter(string):\n        yield from (m.group(0) for m in re.finditer(r'[A-Z][a-z0-9]*|[a-z0-9]+', string))\n\n    def snake_iter(string):\n        yield from (m.group(2) for m in re.finditer(r'(^|_)([A-Za-z0-9]+)', string))\n\n    inputs = {\n        'pascal': pascal_iter,\n        'camel': pascal_iter,\n        'snake': snake_iter,\n        'constant': snake_iter,\n    }\n\n    def out_fun(sep, case=None, case_fst=None):\n        if case is None:\n            case = lambda x: x\n        if case_fst is None:\n            case_fst = case\n        return lambda tokens: sep.join(case_fst(token) if i == 0 else case(token) for i, token in enumerate(tokens))\n\n    outputs = {\n        'pascal': out_fun('', str.capitalize),\n        'camel': out_fun('', str.capitalize, str.lower),\n        'snake': out_fun('_', str.lower),\n        'constant': out_fun('_', str.upper),\n    }\n\n    tokens = inputs[typ](string)\n    return outputs[to](tokens)", "response": "Converts an identifier from one case type to another."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_stream(schema, stream, *, buffer_size=io.DEFAULT_BUFFER_SIZE):\n    reader = _lancaster.Reader(schema)\n    buf = stream.read(buffer_size)\n    remainder = b''\n    while len(buf) > 0:\n        values, n = reader.read_seq(buf)\n        yield from values\n        remainder = buf[n:]\n        buf = stream.read(buffer_size)\n        if len(buf) > 0 and len(remainder) > 0:\n            ba = bytearray()\n            ba.extend(remainder)\n            ba.extend(buf)\n            buf = memoryview(ba).tobytes()\n    if len(remainder) > 0:\n        raise EOFError('{} bytes remaining but could not continue reading '\n                       'from stream'.format(len(remainder)))", "response": "Using a schema deserialize a stream of consecutive Avro values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_user_defined_metric_classes(config_obj, metric_classes):\n  user_defined_metric_list = config_obj.get('GLOBAL', 'user_defined_metrics').split()\n  for udm_string in user_defined_metric_list:\n    try:\n      metric_name, metric_class_name, metric_file = udm_string.split(':')\n    except ValueError:\n      logger.error('Bad user defined metric specified')\n      continue\n    module_name = os.path.splitext(os.path.basename(metric_file))[0]\n    try:\n      new_module = imp.load_source(module_name, metric_file)\n      new_class = getattr(new_module, metric_class_name)\n      if metric_name in metric_classes.keys():\n        logger.warn('Overriding pre-defined metric class definition for ', metric_name)\n      metric_classes[metric_name] = new_class\n    except ImportError:\n      logger.error('Something wrong with importing a user defined metric class. Skipping metric: ', metric_name)\n      continue", "response": "Parse the user defined metric class information\n Parse the user defined metric class information\n "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if a given string is in the correct URL format or not", "response": "def is_valid_url(url):\n  \"\"\"\n  Check if a given string is in the correct URL format or not\n\n  :param str url:\n  :return: True or False\n  \"\"\"\n  regex = re.compile(r'^(?:http|ftp)s?://'\n                     r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|'\n                     r'localhost|'\n                     r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})'\n                     r'(?::\\d+)?'\n                     r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n  if regex.match(url):\n    logger.info(\"URL given as config\")\n    return True\n  else:\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef download_file(url):\n  try:\n    (local_file, headers) = urllib.urlretrieve(url)\n  except:\n    sys.exit(\"ERROR: Problem downloading config file. Please check the URL (\" + url + \"). Exiting...\")\n  return local_file", "response": "Download a file pointed to by url to a temp file on local disk"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking the validity of metric_name in config", "response": "def is_valid_metric_name(metric_name):\n  \"\"\"\n  check the validity of metric_name in config; the metric_name will be used for creation of sub-dir, so only contains: alphabet, digits , '.', '-' and '_'\n  :param str metric_name: metric_name\n  :return: True if valid\n  \"\"\"\n  reg = re.compile('^[a-zA-Z0-9\\.\\-\\_]+$')\n  if reg.match(metric_name) and not metric_name.startswith('.'):\n    return True\n  else:\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_run_time_period(run_steps):\n  init_ts_start = get_standardized_timestamp('now', None)\n  ts_start = init_ts_start\n  ts_end = '0'\n  for run_step in run_steps:\n    if run_step.ts_start and run_step.ts_end:\n      if run_step.ts_start < ts_start:\n        ts_start = run_step.ts_start\n      if run_step.ts_end > ts_end:\n        ts_end = run_step.ts_end\n  if ts_end == '0':\n    ts_end = None\n  if ts_start == init_ts_start:\n    ts_start = None\n  logger.info('get_run_time_period range returned ' + str(ts_start) + ' to ' + str(ts_end))\n  return ts_start, ts_end", "response": "This method finds the time range which covers all the Run_Steps\n \u00bb and \u00bb runs."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts rule strings from a section Returns a tuple of the rule strings and kwargs", "response": "def get_rule_strings(config_obj, section):\n  \"\"\"\n  Extract rule strings from a section\n  :param config_obj: ConfigParser object\n  :param section: Section name\n  :return: the rule strings\n  \"\"\"\n  rule_strings = {}\n  kwargs = dict(config_obj.items(section))\n  for key in kwargs.keys():\n    if key.endswith('.sla'):\n      rule_strings[key.replace('.sla', '')] = kwargs[key]\n      del kwargs[key]\n  return rule_strings, kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts SLA rules from diff config file.", "response": "def extract_diff_sla_from_config_file(obj, options_file):\n  \"\"\"\n  Helper function to parse diff config file, which contains SLA rules for diff comparisons\n  \"\"\"\n  rule_strings = {}\n  config_obj = ConfigParser.ConfigParser()\n  config_obj.optionxform = str\n  config_obj.read(options_file)\n  for section in config_obj.sections():\n    rule_strings, kwargs = get_rule_strings(config_obj, section)\n    for (key, val) in rule_strings.iteritems():\n      set_sla(obj, section, key, val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_basic_metric_options(config_obj, section):\n  infile = {}\n  aggr_hosts = None\n  aggr_metrics = None\n  ts_start = None\n  ts_end = None\n  precision = None\n  hostname = \"localhost\"\n  rule_strings = {}\n  important_sub_metrics = None\n  anomaly_detection_metrics = None\n\n  try:\n    if config_obj.has_option(section, 'important_sub_metrics'):\n      important_sub_metrics = config_obj.get(section, 'important_sub_metrics').split()\n      config_obj.remove_option(section, 'important_sub_metrics')\n\n    if config_obj.has_option(section, 'hostname'):\n      hostname = config_obj.get(section, 'hostname')\n      config_obj.remove_option(section, 'hostname')\n\n    # 'infile' is not mandatory for aggregate metrics\n    if config_obj.has_option(section, 'infile'):\n      infile = config_obj.get(section, 'infile').split()\n      config_obj.remove_option(section, 'infile')\n\n    label = sanitize_string_section_name(section)\n    if config_obj.has_option(section, 'ts_start'):\n      ts_start = get_standardized_timestamp(config_obj.get(section, 'ts_start'), None)\n      config_obj.remove_option(section, 'ts_start')\n    if config_obj.has_option(section, 'ts_end'):\n      ts_end = get_standardized_timestamp(config_obj.get(section, 'ts_end'), None)\n      config_obj.remove_option(section, 'ts_end')\n    if config_obj.has_option(section, 'precision'):\n      precision = config_obj.get(section, 'precision')\n      config_obj.remove_option(section, 'precision')\n    # support aggregate metrics, which take aggr_hosts and aggr_metrics\n    if config_obj.has_option(section, 'aggr_hosts'):\n      aggr_hosts = config_obj.get(section, 'aggr_hosts')\n      config_obj.remove_option(section, 'aggr_hosts')\n    if config_obj.has_option(section, 'aggr_metrics'):\n      aggr_metrics = config_obj.get(section, 'aggr_metrics')\n      config_obj.remove_option(section, 'aggr_metrics')\n    if config_obj.has_option(section, 'anomaly_detection_metrics'):\n      anomaly_detection_metrics = config_obj.get(section, 'anomaly_detection_metrics').split()\n      config_obj.remove_option(section, 'anomaly_detection_metrics')\n    rule_strings, other_options = get_rule_strings(config_obj, section)\n  except ConfigParser.NoOptionError:\n    logger.exception(\"Exiting.... some mandatory options are missing from the config file in section: \" + section)\n    sys.exit()\n\n  return (hostname, infile, aggr_hosts, aggr_metrics, label, ts_start, ts_end, precision, aggr_metrics, other_options,\n         rule_strings, important_sub_metrics, anomaly_detection_metrics)", "response": "Parse the basic options from the config_obj section of the config_obj."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a metric section and create a Metric object.", "response": "def parse_metric_section(config_obj, section, metric_classes, metrics, aggregate_metric_classes, outdir_default, resource_path):\n  \"\"\"\n  Parse a metric section and create a Metric object\n  :param config_obj: ConfigParser object\n  :param section: Section name\n  :param metric_classes: List of valid metric types\n  :param metrics: List of all regular metric objects (used by aggregate metric)\n  :param aggregate_metric_classes: List of all valid aggregate metric types\n  :param outdir_default: Default output directory\n  :param resource_path: Default resource directory\n  :return: An initialized Metric object\n  \"\"\"\n  (hostname, infile, aggr_hosts, aggr_metrics, label, ts_start, ts_end, precision, aggr_metrics, other_options,\n   rule_strings, important_sub_metrics, anomaly_detection_metrics) = parse_basic_metric_options(config_obj, section)\n\n  # TODO: Make user specify metric_type in config and not infer from section\n  metric_type = section.split('-')[0]\n  if metric_type in aggregate_metric_classes:\n    new_metric = initialize_aggregate_metric(section, aggr_hosts, aggr_metrics, metrics, outdir_default, resource_path, label, ts_start, ts_end, rule_strings,\n                                             important_sub_metrics, anomaly_detection_metrics, other_options)\n  else:\n    new_metric = initialize_metric(section, infile, hostname, aggr_metrics, outdir_default, resource_path, label, ts_start, ts_end, rule_strings,\n                                   important_sub_metrics, anomaly_detection_metrics, other_options)\n  if config_obj.has_option(section, 'ignore') and config_obj.getint(section, 'ignore') == 1:\n    new_metric.ignore = True\n  if config_obj.has_option(section, 'calc_metrics'):\n    new_metric.calc_metrics = config_obj.get(section, 'calc_metrics')\n  new_metric.precision = precision\n  return new_metric"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_global_section(config_obj, section):\n  ts_start = None\n  ts_end = None\n  if config_obj.has_option(section, 'ts_start'):\n    ts_start = get_standardized_timestamp(config_obj.get(section, 'ts_start'), None)\n    config_obj.remove_option(section, 'ts_start')\n  if config_obj.has_option(section, 'ts_end'):\n    ts_end = get_standardized_timestamp(config_obj.get(section, 'ts_end'), None)\n    config_obj.remove_option(section, 'ts_end')\n  return ts_start, ts_end", "response": "Parse GLOBAL section in the config file to return start and end times"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a RUN - STEP section in the config file to return a Run_Step object.", "response": "def parse_run_step_section(config_obj, section):\n  \"\"\"\n  Parse a RUN-STEP section in the config to return a Run_Step object\n  :param config_obj: ConfigParser objection\n  :param section: Section name\n  :return: an initialized Run_Step object\n  \"\"\"\n  kill_after_seconds = None\n  try:\n    run_cmd = config_obj.get(section, 'run_cmd')\n    run_rank = int(config_obj.get(section, 'run_rank'))\n  except ConfigParser.NoOptionError:\n    logger.exception(\"Exiting.... some mandatory options are missing from the config file in section: \" + section)\n    sys.exit()\n  except ValueError:\n    logger.error(\"Bad run_rank %s specified in section %s, should be integer. Exiting.\", config_obj.get(section, 'run_rank'), section)\n    sys.exit()\n  if config_obj.has_option(section, 'run_type'):\n    run_type = config_obj.get(section, 'run_type')\n  else:\n    run_type = CONSTANTS.RUN_TYPE_WORKLOAD\n  if config_obj.has_option(section, 'run_order'):\n    run_order = config_obj.get(section, 'run_order')\n  else:\n    run_order = CONSTANTS.PRE_ANALYSIS_RUN\n  if config_obj.has_option(section, 'call_type'):\n    call_type = config_obj.get(section, 'call_type')\n  else:\n    call_type = 'local'\n  if config_obj.has_option(section, 'kill_after_seconds'):\n    try:\n      kill_after_seconds = int(config_obj.get(section, 'kill_after_seconds'))\n    except ValueError:\n      logger.error(\"Bad kill_after_seconds %s specified in section %s, should be integer.\", config_obj.get(section, 'kill_after_seconds'), section)\n\n  if call_type == 'local':\n    run_step_obj = Local_Cmd(run_type, run_cmd, call_type, run_order, run_rank, kill_after_seconds=kill_after_seconds)\n  else:\n    logger.error('Unsupported RUN_STEP supplied, call_type should be local')\n    run_step_obj = None\n  return run_step_obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the GRAPH section of the config file and returns a list of options extracted from it", "response": "def parse_graph_section(config_obj, section, outdir_default, indir_default):\n  \"\"\"\n  Parse the GRAPH section of the config to extract useful values\n  :param config_obj: ConfigParser object\n  :param section: Section name\n  :param outdir_default: Default output directory passed in args\n  :param indir_default: Default input directory passed in args\n  :return: List of options extracted from the GRAPH section\n  \"\"\"\n  graph_timezone = None\n  graphing_library = CONSTANTS.DEFAULT_GRAPHING_LIBRARY\n  crossplots = []\n\n  if config_obj.has_option(section, 'graphing_library'):\n    graphing_library = config_obj.get(section, 'graphing_library')\n  if config_obj.has_option(section, 'graphs'):\n    graphs_string = config_obj.get(section, 'graphs')\n    crossplots = graphs_string.split()\n    # Supporting both outdir and output_dir\n  if config_obj.has_option(section, 'outdir'):\n    outdir_default = config_obj.get(section, 'outdir')\n  if config_obj.has_option(section, 'output_dir'):\n    outdir_default = config_obj.get(section, 'output_dir')\n  if config_obj.has_option(section, 'input_dir'):\n    indir_default = config_obj.get(section, 'input_dir')\n  if config_obj.has_option(section, 'graph_timezone'):\n    graph_timezone = config_obj.get(section, 'graph_timezone')\n    if graph_timezone not in (\"UTC\", \"PST\", \"PDT\"):\n      logger.warn('Unsupported timezone ' + graph_timezone + ' specified in option graph_timezone. Will use UTC instead')\n      graph_timezone = \"UTC\"\n  return graphing_library, crossplots, outdir_default, indir_default, graph_timezone"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calculate_stats(data_list, stats_to_calculate=['mean', 'std'], percentiles_to_calculate=[]):\n  stats_to_numpy_method_map = {\n      'mean': numpy.mean,\n      'avg': numpy.mean,\n      'std': numpy.std,\n      'standard_deviation': numpy.std,\n      'median': numpy.median,\n      'min': numpy.amin,\n      'max': numpy.amax\n  }\n  calculated_stats = {}\n  calculated_percentiles = {}\n  if len(data_list) == 0:\n    return calculated_stats, calculated_percentiles\n  for stat in stats_to_calculate:\n    if stat in stats_to_numpy_method_map.keys():\n      calculated_stats[stat] = stats_to_numpy_method_map[stat](data_list)\n    else:\n      logger.error(\"Unsupported stat : \" + str(stat))\n  for percentile in percentiles_to_calculate:\n    if isinstance(percentile, float) or isinstance(percentile, int):\n      calculated_percentiles[percentile] = numpy.percentile(data_list, percentile)\n    else:\n      logger.error(\"Unsupported percentile requested (should be int or float): \" + str(percentile))\n  return calculated_stats, calculated_percentiles", "response": "Calculate statistics for given data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_valid_file(filename):\n  if os.path.exists(filename):\n    if not os.path.getsize(filename):\n      logger.warning('%s : file is empty.', filename)\n      return False\n  else:\n    logger.warning('%s : file does not exist.', filename)\n    return False\n  return True", "response": "Check if the file exists and is not empty."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetecting the format of a timestamp string", "response": "def detect_timestamp_format(timestamp):\n  \"\"\"\n  Given an input timestamp string, determine what format is it likely in.\n\n  :param string timestamp: the timestamp string for which we need to determine format\n  :return: best guess timestamp format\n  \"\"\"\n  time_formats = {\n      'epoch': re.compile(r'^[0-9]{10}$'),\n      'epoch_ms': re.compile(r'^[0-9]{13}$'),\n      'epoch_fraction': re.compile(r'^[0-9]{10}\\.[0-9]{3,9}$'),\n      '%Y-%m-%d %H:%M:%S': re.compile(r'^[0-9]{4}-[0-1][0-9]-[0-3][0-9] [0-2][0-9]:[0-5][0-9]:[0-5][0-9]$'),\n      '%Y-%m-%dT%H:%M:%S': re.compile(r'^[0-9]{4}-[0-1][0-9]-[0-3][0-9]T[0-2][0-9]:[0-5][0-9]:[0-5][0-9]$'),\n      '%Y-%m-%d_%H:%M:%S': re.compile(r'^[0-9]{4}-[0-1][0-9]-[0-3][0-9]_[0-2][0-9]:[0-5][0-9]:[0-5][0-9]$'),\n      '%Y-%m-%d %H:%M:%S.%f': re.compile(r'^[0-9]{4}-[0-1][0-9]-[0-3][0-9] [0-2][0-9]:[0-5][0-9]:[0-5][0-9].[0-9]+$'),\n      '%Y-%m-%dT%H:%M:%S.%f': re.compile(r'^[0-9]{4}-[0-1][0-9]-[0-3][0-9]T[0-2][0-9]:[0-5][0-9]:[0-5][0-9].[0-9]+$'),\n      '%Y-%m-%d_%H:%M:%S.%f': re.compile(r'^[0-9]{4}-[0-1][0-9]-[0-3][0-9]_[0-2][0-9]:[0-5][0-9]:[0-5][0-9].[0-9]+$'),\n      '%Y%m%d %H:%M:%S': re.compile(r'^[0-9]{4}[0-1][0-9][0-3][0-9] [0-2][0-9]:[0-5][0-9]:[0-5][0-9]$'),\n      '%Y%m%dT%H:%M:%S': re.compile(r'^[0-9]{4}[0-1][0-9][0-3][0-9]T[0-2][0-9]:[0-5][0-9]:[0-5][0-9]$'),\n      '%Y%m%d_%H:%M:%S': re.compile(r'^[0-9]{4}[0-1][0-9][0-3][0-9]_[0-2][0-9]:[0-5][0-9]:[0-5][0-9]$'),\n      '%Y%m%d %H:%M:%S.%f': re.compile(r'^[0-9]{4}[0-1][0-9][0-3][0-9] [0-2][0-9]:[0-5][0-9]:[0-5][0-9].[0-9]+$'),\n      '%Y%m%dT%H:%M:%S.%f': re.compile(r'^[0-9]{4}[0-1][0-9][0-3][0-9]T[0-2][0-9]:[0-5][0-9]:[0-5][0-9].[0-9]+$'),\n      '%Y%m%d_%H:%M:%S.%f': re.compile(r'^[0-9]{4}[0-1][0-9][0-3][0-9]_[0-2][0-9]:[0-5][0-9]:[0-5][0-9].[0-9]+$'),\n      '%H:%M:%S': re.compile(r'^[0-2][0-9]:[0-5][0-9]:[0-5][0-9]$'),\n      '%H:%M:%S.%f': re.compile(r'^[0-2][0-9]:[0-5][0-9]:[0-5][0-9].[0-9]+$'),\n      '%Y-%m-%dT%H:%M:%S.%f%z': re.compile(r'^[0-9]{4}-[0-1][0-9]-[0-3][0-9]T[0-2][0-9]:[0-5][0-9]:[0-5][0-9].[0-9]+[+-][0-9]{4}$')\n  }\n  for time_format in time_formats:\n    if re.match(time_formats[time_format], timestamp):\n      return time_format\n  return 'unknown'"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a timestamp string return a time stamp in the epoch ms format.", "response": "def get_standardized_timestamp(timestamp, ts_format):\n  \"\"\"\n  Given a timestamp string, return a time stamp in the epoch ms format. If no date is present in\n  timestamp then today's date will be added as a prefix before conversion to epoch ms\n  \"\"\"\n  if not timestamp:\n    return None\n  if timestamp == 'now':\n    timestamp = str(datetime.datetime.now())\n  if not ts_format:\n    ts_format = detect_timestamp_format(timestamp)\n  try:\n    if ts_format == 'unknown':\n      logger.error('Unable to determine timestamp format for : %s', timestamp)\n      return -1\n    elif ts_format == 'epoch':\n      ts = int(timestamp) * 1000\n    elif ts_format == 'epoch_ms':\n      ts = timestamp\n    elif ts_format == 'epoch_fraction':\n      ts = int(timestamp[:10]) * 1000 + int(timestamp[11:])\n    elif ts_format in ('%H:%M:%S', '%H:%M:%S.%f'):\n      date_today = str(datetime.date.today())\n      dt_obj = datetime.datetime.strptime(date_today + ' ' + timestamp, '%Y-%m-%d ' + ts_format)\n      ts = calendar.timegm(dt_obj.utctimetuple()) * 1000 + dt_obj.microsecond / 1000\n    else:\n      dt_obj = datetime.datetime.strptime(timestamp, ts_format)\n      ts = calendar.timegm(dt_obj.utctimetuple()) * 1000 + dt_obj.microsecond / 1000\n  except ValueError:\n    return -1\n  return str(ts)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_sla(obj, metric, sub_metric, rules):\n  if not hasattr(obj, 'sla_map'):\n    return False\n  rules_list = rules.split()\n  for rule in rules_list:\n    if '<' in rule:\n      stat, threshold = rule.split('<')\n      sla = SLA(metric, sub_metric, stat, threshold, 'lt')\n    elif '>' in rule:\n      stat, threshold = rule.split('>')\n      sla = SLA(metric, sub_metric, stat, threshold, 'gt')\n    else:\n      if hasattr(obj, 'logger'):\n        obj.logger.error('Unsupported SLA type defined : ' + rule)\n      sla = None\n    obj.sla_map[metric][sub_metric][stat] = sla\n    if hasattr(obj, 'sla_list'):\n      obj.sla_list.append(sla)  # TODO : remove this once report has grading done in the metric tables\n  return True", "response": "Set the SLA for a metric and sub_metric in a report."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if all SLAs pass and save the SLA results in a file athorian", "response": "def check_slas(metric):\n  \"\"\"\n  Check if all SLAs pass\n  :return: 0 (if all SLAs pass) or the number of SLAs failures\n  \"\"\"\n  if not hasattr(metric, 'sla_map'):\n    return\n  for metric_label in metric.sla_map.keys():\n    for sub_metric in metric.sla_map[metric_label].keys():\n      for stat_name in metric.sla_map[metric_label][sub_metric].keys():\n        sla = metric.sla_map[metric_label][sub_metric][stat_name]\n        if stat_name[0] == 'p' and hasattr(metric, 'calculated_percentiles'):\n          if sub_metric in metric.calculated_percentiles.keys():\n            percentile_num = int(stat_name[1:])\n            if isinstance(percentile_num, float) or isinstance(percentile_num, int):\n              if percentile_num in metric.calculated_percentiles[sub_metric].keys():\n                if not sla.check_sla_passed(metric.calculated_percentiles[sub_metric][percentile_num]):\n                  logger.info(\"Failed SLA for \" + sub_metric)\n                  metric.status = CONSTANTS.SLA_FAILED\n        if sub_metric in metric.calculated_stats.keys() and hasattr(metric, 'calculated_stats'):\n          if stat_name in metric.calculated_stats[sub_metric].keys():\n            if not sla.check_sla_passed(metric.calculated_stats[sub_metric][stat_name]):\n              logger.info(\"Failed SLA for \" + sub_metric)\n              metric.status = CONSTANTS.SLA_FAILED\n  # Save SLA results in a file\n  if len(metric.sla_map.keys()) > 0 and hasattr(metric, 'get_sla_csv'):\n    sla_csv_file = metric.get_sla_csv()\n    with open(sla_csv_file, 'w') as FH:\n      for metric_label in metric.sla_map.keys():\n        for sub_metric in metric.sla_map[metric_label].keys():\n          for stat, sla in metric.sla_map[metric_label][sub_metric].items():\n            FH.write('%s\\n' % (sla.get_csv_repr()))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef init_logging(logger, log_file, log_level):\n  with open(log_file, 'w'):\n    pass\n  numeric_level = getattr(logging, log_level.upper(), None) if log_level else logging.INFO\n  if not isinstance(numeric_level, int):\n    raise ValueError('Invalid log level: %s' % log_level)\n  logger.setLevel(logging.DEBUG)\n  fh = logging.FileHandler(log_file)\n  fh.setLevel(logging.DEBUG)\n  ch = logging.StreamHandler()\n  ch.setLevel(numeric_level)\n  formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n  fh.setFormatter(formatter)\n  ch.setFormatter(formatter)\n  logger.addHandler(fh)\n  logger.addHandler(ch)\n  return CONSTANTS.OK", "response": "Initialize the naarad logger."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes list of valid arguments accepted by Naarad CLI parameters", "response": "def get_argument_parser():\n  \"\"\"\n  Initialize list of valid arguments accepted by Naarad CLI\n  :return: arg_parser: argeparse.ArgumentParser object initialized with naarad CLI parameters\n  \"\"\"\n  arg_parser = argparse.ArgumentParser()\n  arg_parser.add_argument('-c', '--config', help=\"file with specifications for each metric and graphs\")\n  arg_parser.add_argument('--start', help=\"Start time in the format of HH:MM:SS or YYYY-mm-dd_HH:MM:SS\")\n  arg_parser.add_argument('--end', help=\"End time in the format of HH:MM:SS or YYYY-mm-dd_HH:MM:SS\")\n  arg_parser.add_argument('-i', '--input_dir', help=\"input directory used to construct full path name of the metric infile\")\n  arg_parser.add_argument('-o', '--output_dir', help=\"output directory where the plots and Report.html will be generated\")\n  arg_parser.add_argument('-V', '--variables', action=\"append\",\n                          help=\"User defined variables (in form key=value) for substitution in the config file. \"\n                               \"Config should have the variable names in format %%(key)s\")\n  arg_parser.add_argument('-s', '--show_config', help=\"Print config associated with the provided template name\", action=\"store_true\")\n  arg_parser.add_argument('-l', '--log', help=\"log level\")\n  arg_parser.add_argument('-d', '--diff', nargs=2,\n                          help=\"Specify the location of two naarad reports to diff separated by a space. Can be local or http(s) \"\n                               \"locations. The first report is used as a baseline.\", metavar=(\"report-1\", \"report-2\"))\n  arg_parser.add_argument('-n', '--no_plots',\n                          help=\"Don't generate plot images. Useful when you only want SLA calculations. Note that on-demand charts can \"\n                               \"still be generated through client-charting.\", action=\"store_true\")\n  arg_parser.add_argument('-e', '--exit_code', help=\"optional argument to enable exit_code for naarad\", action=\"store_true\")\n  # TODO(Ritesh) : Print a list of all templates supported with descriptions\n  # arg_parser.add_argument('-l', '--list_templates', help=\"List all template configs\", action=\"store_true\")\n  return arg_parser"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_variables(args):\n  variables_dict = {}\n  if args.variables:\n    for var in args.variables:\n      words = var.split('=')\n      variables_dict[words[0]] = words[1]\n  return variables_dict", "response": "Return a dictionary of variables specified at CLI\n"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_arguments(args):\n  if args.diff:\n    if not args.output_dir:\n      logger.error('No Output location specified')\n      print_usage()\n      sys.exit(0)\n  # elif not (args.config and args.output_dir):\n  elif not args.output_dir:\n    print_usage()\n    sys.exit(0)", "response": "Validate that the necessary arguments for normal or diff analysis are specified."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef initialize_metric(section, infile_list, hostname, aggr_metrics, output_directory, resource_path, label, ts_start, ts_end, rule_strings,\n                      important_sub_metrics, anomaly_detection_metrics, other_options):\n  \"\"\"\n  Initialize appropriate metric based on type of metric.\n  :param: section: config section name or auto discovered metric type\n  :param: infile_list: list of input log files for the metric\n  :param: hostname: hostname associated with the logs origin\n  :param: output_directory: report location\n  :param: resource_path: resource path for report\n  :param: label: label for config section or auto discovered metric type\n  :param: ts_start: start time for analysis\n  :param: ts_end: end time for analysis\n  :param: rule_strings: list of slas\n  :param: important_sub_metrics: list of important sub metrics\n  :param: anomaly_detection_metrics: list of metrics to use for anomaly detection.\n  :param: other_options: kwargs\n  :return: metric object\n  \"\"\"\n  metric = None\n  metric_type = section.split('-')[0]\n  if metric_type in metric_classes:\n    if 'SAR' in metric_type:\n      metric = metric_classes['SAR'](section, infile_list, hostname, aggr_metrics, output_directory, resource_path, label, ts_start, ts_end,\n                                     rule_strings, important_sub_metrics, anomaly_detection_metrics, **other_options)\n    else:\n      metric = metric_classes[metric_type](section, infile_list, hostname, aggr_metrics, output_directory, resource_path, label, ts_start, ts_end,\n                                           rule_strings, important_sub_metrics, anomaly_detection_metrics, **other_options)\n  else:\n    metric = Metric(section, infile_list, hostname, aggr_metrics, output_directory, resource_path, label, ts_start, ts_end, rule_strings,\n                    important_sub_metrics, anomaly_detection_metrics, **other_options)\n  return metric", "response": "Initialize appropriate metric based on type of metric."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef initialize_aggregate_metric(section, aggr_hosts, aggr_metrics, metrics, outdir_default, resource_path, label, ts_start, ts_end, rule_strings,\n                                important_sub_metrics, anomaly_detection_metrics, other_options):\n  \"\"\"\n  Initialize aggregate metric\n  :param: section: config section name\n  :param: aggr_hosts: list of hostnames to aggregate\n  :param: aggr_metrics: list of metrics to aggregate\n  :param: metrics: list of metric objects associated with the current naarad analysis\n  :param: outdir_default: report location\n  :param: resource_path: resource path for report\n  :param: label: label for config section\n  :param: ts_start: start time for analysis\n  :param: ts_end: end time for analysis\n  :param: rule_strings: list of slas\n  :param: important_sub_metrics: list of important sub metrics\n  :param: other_options: kwargs\n  :return: metric object\n  \"\"\"\n  metric = None\n  metric_type = section.split('-')[0]\n  metric = aggregate_metric_classes[metric_type](section, aggr_hosts, aggr_metrics, metrics, outdir_default, resource_path, label, ts_start, ts_end,\n                                                 rule_strings, important_sub_metrics, anomaly_detection_metrics, **other_options)\n  return metric", "response": "Initialize aggregate metric object based on the config section name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsingle metric graphing function", "response": "def graph_csv(output_directory, resource_path, csv_file, plot_title, output_filename, y_label=None, precision=None, graph_height=\"600\", graph_width=\"1500\"):\n  \"\"\" Single metric graphing function \"\"\"\n  if not os.path.getsize(csv_file):\n    return False, \"\"\n  y_label = y_label or plot_title\n  div_id = str(random.random())\n  div_string = \"<div id=\\\"%s\\\" style=\\\"width:%spx; height:%spx;\\\"></div>\" % (div_id, graph_width, graph_height)\n  script_string = \"\"\"<script type=\\\"text/javascript\\\">\n        g2 = new Dygraph(\n          document.getElementById(\\\"\"\"\" + div_id + \"\"\"\"),\n            \\\"\"\"\" + resource_path + '/' + os.path.basename(csv_file) + \"\"\"\",\n            {\n                        xValueFormatter: Dygraph.dateString_,\n                        xValueParser: function(x) {\n                                        var date_components = x.split(\" \");\n                                        var supported_format = date_components[0] + 'T' + date_components[1];\n                                        if(date_components[1].indexOf(\".\") == -1)\n                                        {\n                                          supported_format += \".0\";\n                                        }\n                                        return Date.parse(supported_format);\n                                        },\n                        xTicker: Dygraph.dateTicker,\n                        xlabel: \"Time\",\n                        ylabel: \\\"\"\"\" + y_label + \"\"\"\",\n                        title: \\\"\"\"\" + plot_title + \"\"\"\",\n                        labels: [\"Time\",\\\"\"\"\" + y_label + \"\"\"\"]\n            }          // options\n        );\n        </script>\"\"\"\n\n  with open(os.path.join(output_directory, output_filename + '.div'), 'w') as div_file:\n    div_file.write(div_string + script_string)\n  # TODO(ritesh): Also generate PNGs if someone needs them separately\n  return True, os.path.join(output_directory, output_filename + '.div')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\naggregating the count of data over time", "response": "def aggregate_count_over_time(self, metric_store, line_data, transaction_list, aggregate_timestamp):\n    \"\"\"\n    Organize and store the count of data from the log line into the metric store by metric type, transaction, timestamp\n\n    :param dict metric_store: The metric store used to store all the parsed jmeter log data\n    :param dict line_data: dict with the extracted k:v from the log line\n    :param list transaction_list: list of transaction to be used for storing the metrics from given line\n    :param string aggregate_timestamp: timestamp used for storing the raw data. This accounts for aggregation time period\n    :return: None\n    \"\"\"\n    for transaction in transaction_list:\n      if line_data.get('s') == 'true':\n        all_qps = metric_store['qps']\n      else:\n        all_qps = metric_store['eqps']\n      qps = all_qps[transaction]\n      if aggregate_timestamp in qps:\n        qps[aggregate_timestamp] += 1\n      else:\n        qps[aggregate_timestamp] = 1\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef aggregate_values_over_time(self, metric_store, line_data, transaction_list, metric_list, aggregate_timestamp):\n    for metric in metric_list:\n      for transaction in transaction_list:\n        metric_data = reduce(defaultdict.__getitem__, [metric, transaction, aggregate_timestamp], metric_store)\n        metric_data.append(float(line_data.get(metric)))\n    return None", "response": "Aggregate the values of the log line into the metric store by the given timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate the time series for the various metrics averaged over the aggregation period being used for plots", "response": "def average_values_for_plot(self, metric_store, data, averaging_factor):\n    \"\"\"\n    Create the time series for the various metrics, averaged over the aggregation period being used for plots\n\n    :param dict metric_store: The metric store used to store all the parsed jmeter log data\n    :param dict data: Dict with all the metric data to be output to csv\n    :param float averaging_factor: averaging factor to be used for calculating the average per second metrics\n    :return: None\n    \"\"\"\n    for metric, transaction_store in metric_store.items():\n      for transaction, time_store in transaction_store.items():\n        for time_stamp, metric_data in sorted(time_store.items()):\n          if metric in ['t', 'by']:\n            data[self.get_csv(transaction, metric)].append(','.join([str(time_stamp), str(sum(map(float, metric_data)) / float(len(metric_data)))]))\n            if metric == 'by':\n              metric_store['thr'][transaction][time_stamp] = sum(map(float, metric_data)) / float(averaging_factor * 1024 * 1024 / 8.0)\n              data[self.get_csv(transaction, 'thr')].append(','.join([str(time_stamp), str(metric_store['thr'][transaction][time_stamp])]))\n          elif metric in ['qps', 'eqps']:\n            data[self.get_csv(transaction, metric)].append(','.join([str(time_stamp), str(metric_data / float(averaging_factor))]))\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calculate_key_stats(self, metric_store):\n    stats_to_calculate = ['mean', 'std', 'median', 'min', 'max']  # TODO: get input from user\n    percentiles_to_calculate = range(5, 101, 5)  # TODO: get input from user\n    percentiles_to_calculate.append(99)\n    for transaction in metric_store['t'].keys():\n      transaction_key = transaction + '.' + 'ResponseTime'\n      # For ResponseTime and ResponseSize, each timestamp has a list of values associated with it.\n      # Using heapq.merge to merge all the lists into a single list to be passed to numpy.\n      self.calculated_stats[transaction_key], self.calculated_percentiles[transaction_key] = \\\n          naarad.utils.calculate_stats(list(heapq.merge(*metric_store['t'][transaction].values())),\n                                   stats_to_calculate, percentiles_to_calculate)\n      self.update_summary_stats(transaction_key)\n      transaction_key = transaction + '.' + 'qps'\n      if len(metric_store['qps'][transaction].values()) > 0:\n        self.calculated_stats[transaction_key], self.calculated_percentiles[transaction_key] = \\\n            naarad.utils.calculate_stats(metric_store['qps'][transaction].values(),\n                                         stats_to_calculate, percentiles_to_calculate)\n        self.update_summary_stats(transaction_key)\n      transaction_key = transaction + '.' + 'ResponseSize'\n      self.calculated_stats[transaction_key], self.calculated_percentiles[transaction_key] = \\\n          naarad.utils.calculate_stats(list(heapq.merge(*metric_store['by'][transaction].values())),\n                                       stats_to_calculate, percentiles_to_calculate)\n      self.update_summary_stats(transaction_key)\n      if 'eqps' in metric_store.keys() and transaction in metric_store['eqps'].keys():\n        transaction_key = transaction + '.' + 'ErrorsPerSecond'\n        self.calculated_stats[transaction_key], self.calculated_percentiles[transaction_key] = \\\n            naarad.utils.calculate_stats(metric_store['eqps'][transaction].values(),\n                                         stats_to_calculate, percentiles_to_calculate)\n        self.update_summary_stats(transaction + '.' + 'ErrorsPerSecond')\n      transaction_key = transaction + '.' + 'DataThroughput'\n      self.calculated_stats[transaction_key], self.calculated_percentiles[transaction_key] = \\\n          naarad.utils.calculate_stats(metric_store['thr'][transaction].values(),\n                                       stats_to_calculate, percentiles_to_calculate)\n      self.update_summary_stats(transaction_key)\n    return None", "response": "Calculate key statistics for given data and store in the class variables calculated_stats and calculated_percentiles"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse(self):\n    file_status = True\n    for infile in self.infile_list:\n      file_status = file_status and naarad.utils.is_valid_file(infile)\n      if not file_status:\n        return False\n\n    status = self.parse_xml_jtl(self.aggregation_granularity)\n    gc.collect()\n    return status", "response": "Parse the Jmeter file and calculate key stats"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_xml_jtl(self, granularity):\n    data = defaultdict(list)\n    processed_data = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n    for input_file in self.infile_list:\n      logger.info('Processing : %s', input_file)\n      timestamp_format = None\n      tree = ElementTree.parse(input_file)\n      samples = tree.findall('./httpSample') + tree.findall('./sample')\n      for sample in samples:\n        if not timestamp_format or timestamp_format == 'unknown':\n          timestamp_format = naarad.utils.detect_timestamp_format(sample.get('ts'))\n        if timestamp_format == 'unknown':\n          continue\n        ts = naarad.utils.get_standardized_timestamp(sample.get('ts'), timestamp_format)\n        if ts == -1:\n          continue\n        ts = naarad.utils.reconcile_timezones(ts, self.timezone, self.graph_timezone)\n        aggregate_timestamp, averaging_factor = self.get_aggregation_timestamp(ts, granularity)\n        self.aggregate_count_over_time(processed_data, sample, [self._sanitize_label(sample.get('lb')), 'Overall_Summary'], aggregate_timestamp)\n        self.aggregate_values_over_time(processed_data, sample, [self._sanitize_label(sample.get('lb')), 'Overall_Summary'], ['t', 'by'], aggregate_timestamp)\n        logger.info('Finished parsing : %s', input_file)\n    logger.info('Processing metrics for output to csv')\n    self.average_values_for_plot(processed_data, data, averaging_factor)\n    logger.info('Writing time series csv')\n    for csv in data.keys():\n      self.csv_files.append(csv)\n      with open(csv, 'w') as csvf:\n        csvf.write('\\n'.join(sorted(data[csv])))\n    logger.info('Processing raw data for stats')\n    self.calculate_key_stats(processed_data)\n    return True", "response": "Parse the Jmeter workload output in XML format and extract overall and per transaction data and key statistics"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef put_values_into_data(self, values):\n    for col, value in values.items():\n      if col in self.column_csv_map:\n        out_csv = self.column_csv_map[col]\n      else:\n        out_csv = self.get_csv(col)   # column_csv_map[] is assigned in get_csv()\n        self.data[out_csv] = []\n      self.data[out_csv].append(self.ts + \",\" + value)", "response": "Take the col in values append value into self. data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing the top line of the log file", "response": "def process_top_line(self, words):\n    \"\"\"\n    Process the line starting with \"top\"\n    Example log:   top - 00:00:02 up 32 days,  7:08, 19 users,  load average: 0.00, 0.00, 0.00\n    \"\"\"\n    self.ts_time = words[2]\n    self.ts = self.ts_date + ' ' + self.ts_time\n    self.ts = ts = naarad.utils.get_standardized_timestamp(self.ts, None)\n\n    if self.ts_out_of_range(self.ts):\n      self.ts_valid_lines = False\n    else:\n      self.ts_valid_lines = True\n    up_days = int(words[4])\n    up_hour_minute = words[6].split(':')  # E.g. '4:02,'\n    up_minutes = int(up_hour_minute[0]) * 60 + int(up_hour_minute[1].split(',')[0])\n    uptime_minute = up_days * 24 * 60 + up_minutes  # Converting days to minutes\n\n    values = {}\n    values['uptime_minute'] = str(uptime_minute)\n    values['num_users'] = words[7]\n    values['load_aver_1_minute'] = words[11][:-1]\n    values['load_aver_5_minute'] = words[12][:-1]\n    values['load_aver_15_minute'] = words[13]\n    self.put_values_into_data(values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses the line starting with Tasks", "response": "def process_tasks_line(self, words):\n    \"\"\"\n    Process the line starting with \"Tasks:\"\n    Example log:   Tasks: 446 total,   1 running, 442 sleeping,   2 stopped,   1 zombie\n    \"\"\"\n    words = words[1:]\n    length = len(words) / 2  # The number of pairs\n    values = {}\n    for offset in range(length):\n      k = words[2 * offset + 1].strip(',')\n      v = words[2 * offset]\n      values['tasks_' + k] = v\n    self.put_values_into_data(values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_cpu_line(self, words):\n\n    values = {}\n    for word in words[1:]:\n      val, key = word.split('%')\n      values['cpu_' + key.strip(',')] = val\n    self.put_values_into_data(values)", "response": "Process the line starting with Cpu ( s"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a size such as 2343M to G", "response": "def convert_to_G(self, word):\n    \"\"\"\n    Given a size such as '2333M', return the converted value in G\n    \"\"\"\n    value = 0.0\n    if word[-1] == 'G' or word[-1] == 'g':\n      value = float(word[:-1])\n    elif word[-1] == 'M' or word[-1] == 'm':\n      value = float(word[:-1]) / 1000.0\n    elif word[-1] == 'K' or word[-1] == 'k':\n      value = float(word[:-1]) / 1000.0 / 1000.0\n    else:  # No unit\n      value = float(word) / 1000.0 / 1000.0 / 1000.0\n    return str(value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_swap_line(self, words):\n    words = words[1:]\n    length = len(words) / 2  # The number of pairs\n    values = {}\n    for offset in range(length):\n      k = words[2 * offset + 1].strip(',')\n      v = self.convert_to_G(words[2 * offset])\n      values['swap_' + k] = v\n    self.put_values_into_data(values)", "response": "Process the line starting with Swap"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses individual command line.", "response": "def process_individual_command(self, words):\n    \"\"\"\n    process the individual lines like this:\n    #PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND\n    29303 root      20   0 35300 2580 1664 R  3.9  0.0   0:00.02 top\n    11 root      RT   0     0    0    0 S  1.9  0.0   0:18.87 migration/2\n    3702 root      20   0 34884 4192 1692 S  1.9  0.0  31:40.47 cf-serverd\n    It does not record all processes due to memory concern; rather only records interested processes (based on user input of PID and COMMAND)\n    \"\"\"\n    pid_index = self.process_headers.index('PID')\n    proces_index = self.process_headers.index('COMMAND')\n\n    pid = words[pid_index]\n    process = words[proces_index]\n    if pid in self.PID or process in self.COMMAND:\n      process_name = process.split('/')[0]\n\n      values = {}\n      for word_col in self.process_headers:\n        word_index = self.process_headers.index(word_col)\n        if word_col in ['VIRT', 'RES', 'SHR']:  # These values need to convert to 'G'\n          values[process_name + '_' + pid + '_' + word_col] = self.convert_to_G(words[word_index])\n        elif word_col in ['PR', 'NI', '%CPU', '%MEM']:  # These values will be assigned later or ignored\n          values[process_name + '_' + pid + '_' + word_col.strip('%')] = words[word_index]\n\n        uptime_index = self.process_headers.index('TIME+')\n        uptime = words[uptime_index].split(':')\n        uptime_sec = float(uptime[0]) * 60 + float(uptime[1])\n        values[process_name + '_' + pid + '_' + 'TIME'] = str(uptime_sec)\n      self.put_values_into_data(values)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(self):\n\n    for infile in self.infile_list:\n      logger.info('Processing : %s', infile)\n      status = True\n      file_status = naarad.utils.is_valid_file(infile)\n      if not file_status:\n        return False\n\n      with open(infile) as fh:\n        for line in fh:\n          words = line.split()\n          if not words:\n            continue\n\n          # Pattern matches line of '2014-02-03'\n          if re.match('^\\d\\d\\d\\d-\\d\\d-\\d\\d$', line):\n            self.ts_date = words[0]\n            continue\n\n          prefix_word = words[0].strip()\n          if prefix_word == 'top':\n            self.process_top_line(words)\n            self.saw_pid = False  # Turn off the processing of individual process line\n          elif self.ts_valid_lines:\n            if prefix_word == 'Tasks:':\n              self.process_tasks_line(words)\n            elif prefix_word == 'Cpu(s):':\n              self.process_cpu_line(words)\n            elif prefix_word == 'Mem:':\n              self.process_mem_line(words)\n            elif prefix_word == 'Swap:':\n              self.process_swap_line(words)\n            elif prefix_word == 'PID':\n              self.saw_pid = True  # Turn on the processing of individual process line\n              self.process_headers = words\n            else:  # Each individual process line\n              if self.saw_pid and len(words) >= len(self.process_headers):  # Only valid process lines\n                self.process_individual_command(words)\n\n    # Putting data in csv files;\n    for out_csv in self.data.keys():    # All sub_metrics\n      self.csv_files.append(out_csv)\n      with open(out_csv, 'w') as fh:\n        fh.write('\\n'.join(self.data[out_csv]))\n\n    gc.collect()\n    return status", "response": "Parse the top output file and return the status of the metric"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbase function which takes a single url download it to outdir and return the local full path name of the downloaded file.", "response": "def handle_single_url(url, outdir, outfile=None):\n  \"\"\"\n  Base function which takes a single url, download it to outdir/outfile\n  :param str url: a full/absolute url, e.g. http://www.cnn.com/log.zip\n  :param str outdir: the absolute local directory. e.g. /home/user1/tmp/\n  :param str outfile: (optional) filename stored in local directory. If outfile is not given, extract the filename from url\n  :return: the local full path name of downloaded url\n  \"\"\"\n  if not url or type(url) != str \\\n     or not outdir or type(outdir) != str:\n      logger.error('passed in parameters %s %s are incorrect.' % (url, outdir))\n      return\n\n  if not naarad.utils.is_valid_url(url):\n    logger.error(\"passed in url %s is incorrect.\" % url)\n    return\n\n  if not outfile:\n    segs = url.split('/')\n    outfile = segs[-1]\n    outfile = urllib2.quote(outfile)\n\n  output_file = os.path.join(outdir, outfile)\n  if os.path.exists(output_file):\n    logger.warn(\"the %s already exists!\" % outfile)\n\n  with open(output_file, \"w\") as fh:\n    try:\n      response = urllib2.urlopen(url)\n      fh.write(response.read())\n    except urllib2.HTTPError:\n      logger.error(\"got HTTPError when retrieving %s\" % url)\n      return\n    except urllib2.URLError:\n      logger.error(\"got URLError when retrieving %s\" % url)\n      return\n\n  return output_file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread response of specified url into memory and return to caller.", "response": "def stream_url(url):\n  \"\"\"\n  Read response of specified url into memory and return to caller. No persistence to disk.\n  :return: response content if accessing the URL succeeds, False otherwise\n  \"\"\"\n  try:\n    response = urllib2.urlopen(url)\n    response_content = response.read()\n    return response_content\n  except (urllib2.URLError, urllib2.HTTPError) as e:\n    logger.error('Unable to access requested URL: %s', url)\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a list of urls from a seeding url", "response": "def get_urls_from_seed(url):\n  \"\"\"\n  get a list of urls from a seeding url, return a list of urls\n\n  :param str url: a full/absolute url, e.g. http://www.cnn.com/logs/\n  :return: a list of full/absolute urls.\n  \"\"\"\n\n  if not url or type(url) != str or not naarad.utils.is_valid_url(url):\n    logger.error(\"get_urls_from_seed() does not have valid seeding url.\")\n    return\n\n  # Extract the host info of \"http://host:port/\" in case of href urls are elative urls (e.g., /path/gc.log)\n  # Then join (host info and relative urls) to form the complete urls\n  base_index = url.find('/', len(\"https://\"))   # get the first \"/\" after http://\" or \"https://\"; handling both cases.\n  base_url = url[:base_index]      # base_url = \"http://host:port\" or https://host:port\" or http://host\" (where no port is given)\n\n  # Extract the \"href\" denoted urls\n  urls = []\n  try:\n    response = urllib2.urlopen(url)\n    hp = HTMLLinkExtractor()\n    hp.feed(response.read())\n    urls = hp.links\n    hp.close()\n  except urllib2.HTTPError:\n    logger.error(\"Got HTTPError when opening the url of %s\" % url)\n    return urls\n\n  # Check whether the url is relative or complete\n  for i in range(len(urls)):\n    if not urls[i].startswith(\"http://\") and not urls[i].startswith(\"https://\"):    # a relative url ?\n      urls[i] = base_url + urls[i]\n\n  return urls"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef download_url_single(inputs, outdir, outfile=None):\n\n  if not inputs or type(inputs) != str or not outdir or type(outdir) != str:\n    logging.error(\"The call parameters are invalid.\")\n    return\n  else:\n    if not os.path.exists(outdir):\n      os.makedirs(outdir)\n\n  output_file = handle_single_url(inputs, outdir, outfile)\n  return output_file", "response": "Downloads a single http url to a local file\n"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndownload http ( s ) urls from a seed url and stores them in a local file.", "response": "def download_url_regex(inputs, outdir, regex=\".*\"):\n  \"\"\"\n  Downloads http(s) urls to a local files\n  :param str inputs: Required, the seed url\n  :param str outdir: Required. the local directory to put the downloadedfiles.\n  :param str regex: Optional, a regex string. If not given, then all urls will be valid\n  :return: A list of local full path names (downloaded from inputs)\n  \"\"\"\n  if not inputs or type(inputs) != str \\\n     or not outdir or type(outdir) != str:\n    logging.error(\"The call parameters are invalid.\")\n    return\n  else:\n    if not os.path.exists(outdir):\n      os.makedirs(outdir)\n\n  output_files = []\n  files = get_urls_from_seed(inputs)\n  for f in files:\n    if re.compile(regex).match(f):\n      output_file = handle_single_url(f, outdir)\n      output_files.append(output_file)\n\n  return output_files"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads data from a csv file into a dictionary.", "response": "def read_csv(csv_name):\n  \"\"\"\n  Read data from a csv file into a dictionary.\n  :param str csv_name: path to a csv file.\n  :return dict: a dictionary represents the data in file.\n  \"\"\"\n  data = {}\n  if not isinstance(csv_name, (str, unicode)):\n    raise exceptions.InvalidDataFormat('luminol.utils: csv_name has to be a string!')\n  with open(csv_name, 'r') as csv_data:\n    reader = csv.reader(csv_data, delimiter=',', quotechar='|')\n    for row in reader:\n      try:\n        key = to_epoch(row[0])\n        value = float(row[1])\n        data[key] = value\n      except ValueError:\n        pass\n  return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the command and infer time period for analysis phase.", "response": "def run(self):\n    \"\"\"\n    Run the command, infer time period to be used in metric analysis phase.\n    :return: None\n    \"\"\"\n    cmd_args = shlex.split(self.run_cmd)\n    logger.info('Local command RUN-STEP starting with rank %d', self.run_rank)\n    logger.info('Running subprocess command with following args: ' + str(cmd_args))\n\n    # TODO: Add try catch blocks. Kill process on CTRL-C\n    # Infer time period for analysis. Assume same timezone between client and servers.\n    self.ts_start = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n    try:\n      self.process = subprocess.Popen(cmd_args, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, bufsize=1)\n      if self.kill_after_seconds:\n        self.timer = Timer(self.kill_after_seconds, self.kill)\n        self.timer.start()\n      # Using 2nd method here to stream output:\n      # http://stackoverflow.com/questions/2715847/python-read-streaming-input-from-subprocess-communicate\n      for line in iter(self.process.stdout.readline, b''):\n        logger.info(line.strip())\n      self.process.communicate()\n    except KeyboardInterrupt:\n      logger.warning('Handling keyboard interrupt (Ctrl-C)')\n      self.kill()\n    if self.timer:\n      self.timer.cancel()\n    self.ts_end = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n    logger.info('subprocess finished')\n    logger.info('run_step started at ' + self.ts_start + ' and ended at ' + self.ts_end)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nkilling the run_step process.", "response": "def kill(self):\n    \"\"\"\n    If run_step needs to be killed, this method will be called\n    :return: None\n    \"\"\"\n    try:\n      logger.info('Trying to terminating run_step...')\n      self.process.terminate()\n      time_waited_seconds = 0\n      while self.process.poll() is None and time_waited_seconds < CONSTANTS.SECONDS_TO_KILL_AFTER_SIGTERM:\n        time.sleep(0.5)\n        time_waited_seconds += 0.5\n      if self.process.poll() is None:\n        self.process.kill()\n        logger.warning('Waited %d seconds for run_step to terminate. Killing now....', CONSTANTS.SECONDS_TO_KILL_AFTER_SIGTERM)\n    except OSError, e:\n      logger.error('Error while trying to kill the subprocess: %s', e)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy_local_includes(self):\n    resource_folder = self.get_resources_location()\n    for stylesheet in self.stylesheet_includes:\n      if ('http' not in stylesheet) and naarad.utils.is_valid_file(os.path.join(resource_folder, stylesheet)):\n        shutil.copy(os.path.join(resource_folder, stylesheet), self.resource_directory)\n\n    for javascript in self.javascript_includes:\n      if ('http' not in javascript) and naarad.utils.is_valid_file(os.path.join(resource_folder, javascript)):\n        shutil.copy(os.path.join(resource_folder, javascript), self.resource_directory)\n\n    return None", "response": "Copy local css and javascript includes from naarad resources to the report / resources directory"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_client_charting_page(self, data_sources):\n    if not os.path.exists(self.resource_directory):\n      os.makedirs(self.resource_directory)\n    self.copy_local_includes()\n    template_loader = FileSystemLoader(self.get_resources_location())\n    template_environment = Environment(loader=template_loader)\n    client_html = template_environment.get_template(CONSTANTS.TEMPLATE_HEADER).render(custom_stylesheet_includes=CONSTANTS.STYLESHEET_INCLUDES,\n                                                                                      custom_javascript_includes=CONSTANTS.JAVASCRIPT_INCLUDES,\n                                                                                      resource_path=self.resource_path,\n                                                                                      report_title='naarad diff report') + '\\n'\n    client_html += template_environment.get_template(CONSTANTS.TEMPLATE_DIFF_CLIENT_CHARTING).render(data_series=data_sources,\n                                                                                                     resource_path=self.resource_path) + '\\n'\n    client_html += template_environment.get_template(CONSTANTS.TEMPLATE_FOOTER).render()\n    return client_html", "response": "Generate the client charting page for the diff report."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_diff_html(self):\n    if not os.path.exists(self.resource_directory):\n      os.makedirs(self.resource_directory)\n    self.copy_local_includes()\n    div_html = ''\n    for plot_div in sorted(self.plot_files):\n      with open(plot_div, 'r') as div_file:\n        div_html += '\\n' + div_file.read()\n    template_loader = FileSystemLoader(self.get_resources_location())\n    template_environment = Environment(loader=template_loader)\n    template_environment.filters['sanitize_string'] = naarad.utils.sanitize_string\n    diff_html = template_environment.get_template(CONSTANTS.TEMPLATE_HEADER).render(custom_stylesheet_includes=CONSTANTS.STYLESHEET_INCLUDES,\n                                                                                    custom_javascript_includes=CONSTANTS.JAVASCRIPT_INCLUDES,\n                                                                                    resource_path=self.resource_path,\n                                                                                    report_title='naarad diff report') + '\\n'\n    diff_html += template_environment.get_template(CONSTANTS.TEMPLATE_DIFF_PAGE).render(diff_data=self.diff_data, plot_div_content=div_html,\n                                                                                        reports=self.reports, sla_failure_list=self.sla_failure_list,\n                                                                                        sla_map=self.sla_map) + '\\n'\n    diff_html += template_environment.get_template(CONSTANTS.TEMPLATE_FOOTER).render()\n    return diff_html", "response": "Generate the summary diff report html from template\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef discover(self, metafile):\n    for report in self.reports:\n      if report.remote_location == 'local':\n        if naarad.utils.is_valid_file(os.path.join(os.path.join(report.location, self.resource_path), metafile)):\n          with open(os.path.join(os.path.join(report.location, self.resource_path), metafile), 'r') as meta_file:\n            if metafile == CONSTANTS.STATS_CSV_LIST_FILE:\n              report.stats = meta_file.readlines()[0].split(',')\n            elif metafile == CONSTANTS.PLOTS_CSV_LIST_FILE:\n              report.datasource = meta_file.readlines()[0].split(',')\n            elif metafile == CONSTANTS.CDF_PLOTS_CSV_LIST_FILE:\n              report.cdf_datasource = meta_file.readlines()[0].split(',')\n        else:\n            report.status = 'NO_SUMMARY_STATS'\n            self.status = 'ERROR'\n            logger.error('Unable to access summary stats file for report :%s', report.label)\n            return False\n      else:\n        stats_url = report.remote_location + '/' + self.resource_path + '/' + metafile\n        meta_file_data = naarad.httpdownload.stream_url(stats_url)\n\n        if meta_file_data:\n          if metafile == CONSTANTS.STATS_CSV_LIST_FILE:\n            report.stats = meta_file_data.split(',')\n          elif metafile == CONSTANTS.PLOTS_CSV_LIST_FILE:\n            report.datasource = meta_file_data.split(',')\n          elif metafile == CONSTANTS.CDF_PLOTS_CSV_LIST_FILE:\n            report.cdf_datasource = meta_file_data.split(',')\n        else:\n          report.status = 'NO_SUMMARY_STATS'\n          self.status = 'ERROR'\n          logger.error('No summary stats available for report :%s', report.label)\n          return False\n    return True", "response": "Discover what summary stats time series and CDF csv exist for the reports that need to be diffed."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef collect_datasources(self):\n    report_count = 0\n    if self.status != 'OK':\n      return False\n    diff_datasource = sorted(set(self.reports[0].datasource) & set(self.reports[1].datasource))\n    if diff_datasource:\n      self.reports[0].datasource = diff_datasource\n      self.reports[1].datasource = diff_datasource\n    else:\n      self.status = 'NO_COMMON_STATS'\n      logger.error('No common metrics were found between the two reports')\n      return False\n    for report in self.reports:\n      report.label = report_count\n      report_count += 1\n      report.local_location = os.path.join(self.resource_directory, str(report.label))\n      try:\n        os.makedirs(report.local_location)\n      except OSError as exeption:\n        if exeption.errno != errno.EEXIST:\n          raise\n      if report.remote_location != 'local':\n        naarad.httpdownload.download_url_list(map(lambda x: report.remote_location + '/' + self.resource_path + '/' + x + '.csv', report.datasource),\n                                              report.local_location)\n      else:\n        for filename in report.datasource:\n          try:\n            shutil.copy(os.path.join(os.path.join(report.location, self.resource_path), filename + '.csv'), report.local_location)\n          except IOError as exeption:\n            continue\n    return True", "response": "Collect the common metrics from both the diffed reports and download them to the diff report resources directory\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates CDF diff plots of the submetrics", "response": "def plot_diff(self, graphing_library='matplotlib'):\n    \"\"\"\n    Generate CDF diff plots of the submetrics\n    \"\"\"\n    diff_datasource = sorted(set(self.reports[0].datasource) & set(self.reports[1].datasource))\n    graphed = False\n    for submetric in diff_datasource:\n      baseline_csv = naarad.utils.get_default_csv(self.reports[0].local_location, (submetric + '.percentiles'))\n      current_csv = naarad.utils.get_default_csv(self.reports[1].local_location, (submetric + '.percentiles'))\n      if (not (naarad.utils.is_valid_file(baseline_csv) & naarad.utils.is_valid_file(current_csv))):\n        continue\n      baseline_plot = PD(input_csv=baseline_csv, csv_column=1, series_name=submetric, y_label=submetric, precision=None, graph_height=600, graph_width=1200,\n                         graph_type='line', plot_label='baseline', x_label='Percentiles')\n      current_plot = PD(input_csv=current_csv, csv_column=1, series_name=submetric, y_label=submetric, precision=None, graph_height=600, graph_width=1200,\n                        graph_type='line', plot_label='current', x_label='Percentiles')\n      graphed, div_file = Diff.graphing_modules[graphing_library].graph_data_on_the_same_graph([baseline_plot, current_plot],\n                                                                                               os.path.join(self.output_directory, self.resource_path),\n                                                                                               self.resource_path, (submetric + '.diff'))\n      if graphed:\n        self.plot_files.append(div_file)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_sla(self, sla, diff_metric):\n    try:\n      if sla.display is '%':\n        diff_val = float(diff_metric['percent_diff'])\n      else:\n        diff_val = float(diff_metric['absolute_diff'])\n    except ValueError:\n      return False\n    if not (sla.check_sla_passed(diff_val)):\n      self.sla_failures += 1\n      self.sla_failure_list.append(DiffSLAFailure(sla, diff_metric))\n    return True", "response": "Check whether the SLA has passed or failed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a diff report from the reports specified.", "response": "def generate(self):\n    \"\"\"\n    Generate a diff report from the reports specified.\n    :return: True/False : return status of whether the diff report generation succeeded.\n    \"\"\"\n    if (self.discover(CONSTANTS.STATS_CSV_LIST_FILE) and self.discover(CONSTANTS.PLOTS_CSV_LIST_FILE) and self.discover(CONSTANTS.CDF_PLOTS_CSV_LIST_FILE) and\n       self.collect() and self.collect_datasources() and self.collect_cdf_datasources()):\n      for stats in self.reports[0].stats:\n        metric_label = stats.replace('.stats.csv', '')\n        stats_0 = os.path.join(self.reports[0].local_location, stats)\n        stats_1 = os.path.join(self.reports[1].local_location, stats)\n        report0_stats = {}\n        report1_stats = {}\n        if naarad.utils.is_valid_file(stats_0) and naarad.utils.is_valid_file(stats_1):\n          report0 = csv.DictReader(open(stats_0))\n          for row in report0:\n            report0_stats[row[CONSTANTS.SUBMETRIC_HEADER]] = row\n          report0_stats['__headers__'] = report0._fieldnames\n          report1 = csv.DictReader(open(stats_1))\n          for row in report1:\n            report1_stats[row[CONSTANTS.SUBMETRIC_HEADER]] = row\n          report1_stats['__headers__'] = report1._fieldnames\n          common_stats = sorted(set(report0_stats['__headers__']) & set(report1_stats['__headers__']))\n          common_submetrics = sorted(set(report0_stats.keys()) & set(report1_stats.keys()))\n          for submetric in common_submetrics:\n            if submetric != '__headers__':\n              for stat in common_stats:\n                if stat != CONSTANTS.SUBMETRIC_HEADER:\n                  diff_metric = reduce(defaultdict.__getitem__, [stats.split('.')[0], submetric, stat], self.diff_data)\n                  diff_metric[0] = float(report0_stats[submetric][stat])\n                  diff_metric[1] = float(report1_stats[submetric][stat])\n                  diff_metric['absolute_diff'] = naarad.utils.normalize_float_for_display(diff_metric[1] - diff_metric[0])\n                  if diff_metric[0] == 0:\n                    if diff_metric['absolute_diff'] == '0.0':\n                      diff_metric['percent_diff'] = 0.0\n                    else:\n                      diff_metric['percent_diff'] = 'N/A'\n                  else:\n                    diff_metric['percent_diff'] = naarad.utils.normalize_float_for_display((diff_metric[1] - diff_metric[0]) * 100 / diff_metric[0])\n                  # check whether there is a SLA failure\n                  if ((metric_label in self.sla_map.keys()) and (submetric in self.sla_map[metric_label].keys()) and\n                     (stat in self.sla_map[metric_label][submetric].keys())):\n                    self.check_sla(self.sla_map[metric_label][submetric][stat], diff_metric)\n    else:\n      return False\n    self.plot_diff()\n    diff_html = ''\n    if self.diff_data:\n      diff_html = self.generate_diff_html()\n      client_html = self.generate_client_charting_page(self.reports[0].datasource)\n    if diff_html != '':\n      with open(os.path.join(self.output_directory, CONSTANTS.DIFF_REPORT_FILE), 'w') as diff_file:\n        diff_file.write(diff_html)\n      with open(os.path.join(self.output_directory, CONSTANTS.CLIENT_CHARTING_FILE), 'w') as client_file:\n        client_file.write(client_html)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a timestamp from the raw epoch time based on the granularity preferences passed in.", "response": "def get_aggregation_timestamp(self, timestamp, granularity='second'):\n    \"\"\"\n    Return a timestamp from the raw epoch time based on the granularity preferences passed in.\n\n    :param string timestamp: timestamp from the log line\n    :param string granularity: aggregation granularity used for plots.\n    :return: string aggregate_timestamp: timestamp used for metrics aggregation in all functions\n    \"\"\"\n    if granularity is None or granularity.lower() == 'none':\n      return int(timestamp), 1\n    elif granularity == 'hour':\n      return (int(timestamp) / (3600 * 1000)) * 3600 * 1000, 3600\n    elif granularity == 'minute':\n      return (int(timestamp) / (60 * 1000)) * 60 * 1000, 60\n    else:\n      return (int(timestamp) / 1000) * 1000, 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\naggregating the count of data over time.", "response": "def aggregate_count_over_time(self, metric_store, groupby_name, aggregate_timestamp):\n    \"\"\"\n    Organize and store the count of data from the log line into the metric store by columnm, group name, timestamp\n\n    :param dict metric_store: The metric store used to store all the parsed the log data\n    :param string groupby_name: the group name that the log line belongs to\n    :param string aggregate_timestamp: timestamp used for storing the raw data. This accounts for aggregation time period\n    :return: None\n    \"\"\"\n    all_qps = metric_store['qps']\n    qps = all_qps[groupby_name]\n    if aggregate_timestamp in qps:\n      qps[aggregate_timestamp] += 1\n    else:\n      qps[aggregate_timestamp] = 1\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef aggregate_values_over_time(self, metric_store, data, groupby_name, column_name, aggregate_timestamp):\n    # To add overall_summary one\n    if self.groupby:\n      metric_data = reduce(defaultdict.__getitem__, [column_name, 'Overall_summary', aggregate_timestamp], metric_store)\n      metric_data.append(float(data))\n    metric_data = reduce(defaultdict.__getitem__, [column_name, groupby_name, aggregate_timestamp], metric_store)\n    metric_data.append(float(data))\n    return None", "response": "Aggregate the values of a column over a given time."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef average_values_for_plot(self, metric_store, data, averaging_factor):\n    for column, groups_store in metric_store.items():\n      for group, time_store in groups_store.items():\n        for time_stamp, column_data in sorted(time_store.items()):\n          if column in ['qps']:\n            if self.groupby:\n              data[self.get_csv(column, group)].append(','.join([str(time_stamp), str(column_data / float(averaging_factor))]))\n            else:\n              data[self.get_csv(column)].append(','.join([str(time_stamp), str(column_data / float(averaging_factor))]))\n          else:\n            if self.groupby:\n              data[self.get_csv(column, group)].append(','.join([str(time_stamp), str(sum(map(float, column_data)) / float(len(column_data)))]))\n            else:\n              data[self.get_csv(column)].append(','.join([str(time_stamp), str(sum(map(float, column_data)) / float(len(column_data)))]))\n    return None", "response": "Create the time series for the various metrics averaged over the aggregation period being used for plots\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef calc_key_stats(self, metric_store):\n    stats_to_calculate = ['mean', 'std', 'min', 'max']  # TODO: get input from user\n    percentiles_to_calculate = range(0, 100, 1)  # TODO: get input from user\n    for column, groups_store in metric_store.items():\n      for group, time_store in groups_store.items():\n        data = metric_store[column][group].values()\n        if self.groupby:\n          column_name = group + '.' + column\n        else:\n          column_name = column\n        if column.startswith('qps'):\n          self.calculated_stats[column_name], self.calculated_percentiles[column_name] = naarad.utils.calculate_stats(data, stats_to_calculate, percentiles_to_calculate)\n        else:\n          self.calculated_stats[column_name], self.calculated_percentiles[column_name] = naarad.utils.calculate_stats(list(heapq.merge(*data)), stats_to_calculate,\n                                                                                                            percentiles_to_calculate)\n        self.update_summary_stats(column_name)", "response": "Calculate stats such as percentile and mean\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calculate_stats(self):\n    metric_type = self.metric_type.split('-')[0]\n    if metric_type in naarad.naarad_imports.metric_classes or metric_type in naarad.naarad_imports.aggregate_metric_classes:\n      self.calculate_other_metric_stats()\n    else:\n      self.calculate_base_metric_stats()", "response": "Calculate stats with different function depending on the metric type"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplots time series for all sub - metrics.", "response": "def plot_timeseries(self, graphing_library='matplotlib'):\n    \"\"\"\n    plot timeseries for sub-metrics\n    \"\"\"\n    if self.groupby:\n      plot_data = {}\n      # plot time series data for submetrics\n      for out_csv in sorted(self.csv_files, reverse=True):\n        csv_filename = os.path.basename(out_csv)\n        transaction_name = \".\".join(csv_filename.split('.')[1:-1])\n        if transaction_name in self.anomalies.keys():\n          highlight_regions = self.anomalies[transaction_name]\n        else:\n          highlight_regions = None\n        # The last element is .csv, don't need that in the name of the chart\n        column = csv_filename.split('.')[-2]\n        transaction_name = ' '.join(csv_filename.split('.')[1:-2])\n        plot = PD(input_csv=out_csv, csv_column=1, series_name=transaction_name + '.' + column,\n                  y_label=column + ' (' + self.sub_metric_description[column] + ')', precision=None, graph_height=500, graph_width=1200, graph_type='line',\n                  highlight_regions=highlight_regions)\n        if transaction_name in plot_data:\n          plot_data[transaction_name].append(plot)\n        else:\n          plot_data[transaction_name] = [plot]\n      for transaction in plot_data:\n        graphed, div_file = Metric.graphing_modules[graphing_library].graph_data(plot_data[transaction], self.resource_directory, self.resource_path,\n                                                                                 self.label + '.' + transaction)\n        if graphed:\n          self.plot_files.append(div_file)\n    else:\n      graphed = False\n      for out_csv in self.csv_files:\n        csv_filename = os.path.basename(out_csv)\n        transaction_name = \".\".join(csv_filename.split('.')[1:-1])\n        if transaction_name in self.anomalies.keys():\n          highlight_regions = self.anomalies[transaction_name]\n        else:\n          highlight_regions = None\n        # The last element is .csv, don't need that in the name of the chart\n        column = self.csv_column_map[out_csv]\n        column = naarad.utils.sanitize_string(column)\n        graph_title = '.'.join(csv_filename.split('.')[0:-1])\n        if self.sub_metric_description and column in self.sub_metric_description.keys():\n          graph_title += ' (' + self.sub_metric_description[column] + ')'\n        if self.sub_metric_unit and column in self.sub_metric_unit.keys():\n          plot_data = [PD(input_csv=out_csv, csv_column=1, series_name=graph_title, y_label=column + ' (' + self.sub_metric_unit[column] + ')',\n                          precision=None, graph_height=600, graph_width=1200, graph_type='line', highlight_regions=highlight_regions)]\n        else:\n          plot_data = [PD(input_csv=out_csv, csv_column=1, series_name=graph_title, y_label=column, precision=None, graph_height=600, graph_width=1200,\n                          graph_type='line', highlight_regions=highlight_regions)]\n        graphed, div_file = Metric.graphing_modules[graphing_library].graph_data(plot_data, self.resource_directory, self.resource_path, graph_title)\n        if graphed:\n          self.plot_files.append(div_file)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks whether the given sub metric is in the important_sub_metrics list", "response": "def check_important_sub_metrics(self, sub_metric):\n    \"\"\"\n    check whether the given sub metric is in important_sub_metrics list\n    \"\"\"\n    if not self.important_sub_metrics:\n      return False\n    if sub_metric in self.important_sub_metrics:\n      return True\n    items = sub_metric.split('.')\n    if items[-1] in self.important_sub_metrics:\n      return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot CDF for important sub-metrics", "response": "def plot_cdf(self, graphing_library='matplotlib'):\n    \"\"\"\n    plot CDF for important sub-metrics\n    \"\"\"\n    graphed = False\n    for percentile_csv in self.percentiles_files:\n      csv_filename = os.path.basename(percentile_csv)\n      # The last element is .csv, don't need that in the name of the chart\n      column = self.csv_column_map[percentile_csv.replace(\".percentiles.\", \".\")]\n      if not self.check_important_sub_metrics(column):\n        continue\n      column = naarad.utils.sanitize_string(column)\n      graph_title = '.'.join(csv_filename.split('.')[0:-1])\n      if self.sub_metric_description and column in self.sub_metric_description.keys():\n        graph_title += ' (' + self.sub_metric_description[column] + ')'\n      if self.sub_metric_unit and column in self.sub_metric_unit.keys():\n        plot_data = [PD(input_csv=percentile_csv, csv_column=1, series_name=graph_title, x_label='Percentiles',\n                        y_label=column + ' (' + self.sub_metric_unit[column] + ')', precision=None, graph_height=600, graph_width=1200, graph_type='line')]\n      else:\n        plot_data = [PD(input_csv=percentile_csv, csv_column=1, series_name=graph_title, x_label='Percentiles', y_label=column, precision=None,\n                        graph_height=600, graph_width=1200, graph_type='line')]\n      graphed, div_file = Metric.graphing_modules[graphing_library].graph_data_on_the_same_graph(plot_data, self.resource_directory,\n                                                                                                 self.resource_path, graph_title)\n      if graphed:\n        self.plot_files.append(div_file)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a graph for this metric", "response": "def graph(self, graphing_library='matplotlib'):\n    \"\"\"\n    graph generates two types of graphs\n    'time': generate a time-series plot for all submetrics (the x-axis is a time series)\n    'cdf': generate a CDF plot for important submetrics (the x-axis shows percentiles)\n    \"\"\"\n    logger.info('Using graphing_library {lib} for metric {name}'.format(lib=graphing_library, name=self.label))\n    self.plot_cdf(graphing_library)\n    self.plot_timeseries(graphing_library)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef detect_anomaly(self):\n    if not self.anomaly_detection_metrics or len(self.anomaly_detection_metrics) <= 0:\n      return\n    for submetric in self.anomaly_detection_metrics:\n      csv_file = self.get_csv(submetric)\n      if naarad.utils.is_valid_file(csv_file):\n        detector = anomaly_detector.AnomalyDetector(csv_file)\n        anomalies = detector.get_anomalies()\n        if len(anomalies) <= 0:\n          return\n        self.anomalies[submetric] = anomalies\n        anomaly_csv_file = os.path.join(self.resource_directory, self.label + '.' + submetric + '.anomalies.csv')\n        with open(anomaly_csv_file, 'w') as FH:\n          for anomaly in anomalies:\n            FH.write(\",\".join([str(anomaly.anomaly_score), str(anomaly.start_timestamp), str(anomaly.end_timestamp), str(anomaly.exact_timestamp)]))\n            FH.write('\\n')", "response": "Detect anomalies in the timeseries data for the specified submetrics."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_tuple(self, fields):\n    v1 = ''\n    v2 = ''\n    if len(fields) > 0:\n      v1 = fields[0]\n    if len(fields) > 1:\n      v2 = fields[1]\n    return v1, v2", "response": "returns a tuple with default values of '';"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _extract_input_connections(self):\n    for con in self.connections:\n      ends = con.strip().split('<->')  # [host1:port1->host2]\n      ends = filter(None, ends)  # Remove '' elements\n      if len(ends) == 0:\n        continue\n      if len(ends) > 0:\n        host1, port1 = self._get_tuple(ends[0].split(':'))\n      host2 = ''\n      port2 = ''\n      if len(ends) > 1:\n        host2, port2 = self._get_tuple(ends[1].split(':'))\n      self.input_connections.append((host1, port1, host2, port2))", "response": "Given a user input of interested connections extract the info and output a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _extract_input_processes(self):\n    for proc in self.processes:\n      ends = proc.split('/')\n      pid, name = self._get_tuple(ends)\n      self.input_processes.append((pid, name))", "response": "Given user input of interested processes extract the info and output a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine whether host and port matches current connection.", "response": "def _match_host_port(self, host, port, cur_host, cur_port):\n    \"\"\"\n    Determine whether user-specified (host,port) matches current (cur_host, cur_port)\n    :param host,port: The user input of (host,port)\n    :param cur_host, cur_port: The current connection\n    :return: True or Not\n    \"\"\"\n    # if host is '', true;  if not '', it should prefix-match cur_host\n    host_match = False\n    if not host:\n      host_match = True\n    elif cur_host.startswith(host):  # allow for partial match\n      host_match = True\n\n    # if port is '', true;  if not '', it should exactly match cur_port\n    port_match = False\n    if not port:\n      port_match = True\n    elif port == cur_port:\n      port_match = True\n\n    return host_match and port_match"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _match_processes(self, pid, name, cur_process):\n    cur_pid, cur_name = self._get_tuple(cur_process.split('/'))\n\n    pid_match = False\n    if not pid:\n      pid_match = True\n    elif pid == cur_pid:\n      pid_match = True\n\n    name_match = False\n    if not name:\n      name_match = True\n    elif name == cur_name:\n      name_match = True\n\n    return pid_match and name_match", "response": "Determines whether the user - specified pid and name of the processes are in the current process."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck whether the connection is of interest or not.", "response": "def _check_connection(self, local_end, remote_end, process):\n    \"\"\"\n    Check whether the connection is of interest or not\n    :param local_end: Local connection end point, e.g., 'host1:port1'\n    :param remote_end: Remote connection end point, e.g., 'host2:port2'\n    :param process: Current connection 's process info, e.g., '1234/firefox'\n    :return: a tuple of (local_end, remote_end, True/False); e.g. ('host1_23232', 'host2_2222', True)\n    \"\"\"\n    # check tcp end points\n    cur_host1, cur_port1 = self._get_tuple(local_end.split(':'))\n    cur_host2, cur_port2 = self._get_tuple(remote_end.split(':'))\n\n    # check whether the connection is interested or not by checking user input\n    host_port_is_interested = False\n    for (host1, port1, host2, port2) in self.input_connections:\n      if self._match_host_port(host1, port1, cur_host1, cur_port1) and self._match_host_port(host2, port2, cur_host2, cur_port2):\n        host_port_is_interested = True\n        break\n      if self._match_host_port(host1, port1, cur_host2, cur_port2) and self._match_host_port(host2, port2, cur_host1, cur_port1):\n        host_port_is_interested = True\n        break\n\n    # check whether the connection is interested or not by checking process names given in the config\n    process_is_interested = False\n    for pid, name in self.input_processes:\n      if self._match_processes(pid, name, process):\n        process_is_interested = True\n        break\n\n    return cur_host1 + '_' + cur_port1, cur_host2 + '_' + cur_port2, host_port_is_interested and process_is_interested"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding the data point to the dictionary of data", "response": "def _add_data_line(self, data, col, value, ts):\n    \"\"\"\n    Append the data point to the dictionary of \"data\"\n    :param data: The dictionary containing all data\n    :param col: The sub-metric name e.g. 'host1_port1.host2_port2.SendQ'\n    :param value: integer\n    :param ts: timestamp\n    :return: None\n    \"\"\"\n    if col in self.column_csv_map:\n      out_csv = self.column_csv_map[col]\n    else:\n      out_csv = self.get_csv(col)   # column_csv_map[] is assigned in get_csv()\n      data[out_csv] = []\n    data[out_csv].append(ts + \",\" + value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the netstat output file and return the status of the metric parse", "response": "def parse(self):\n    \"\"\"\n    Parse the netstat output file\n    :return: status of the metric parse\n    \"\"\"\n    # sample netstat output: 2014-04-02 15:44:02.86612\ttcp     9600      0 host1.localdomain.com.:21567 remote.remotedomain.com:51168 ESTABLISH pid/process\n    data = {}  # stores the data of each sub-metric\n    for infile in self.infile_list:\n      logger.info('Processing : %s', infile)\n      timestamp_format = None\n      with open(infile) as fh:\n        for line in fh:\n          if 'ESTABLISHED' not in line:\n            continue\n          words = line.split()\n          if len(words) < 8 or words[2] != 'tcp':\n            continue\n          ts = words[0] + \" \" + words[1]\n          if not timestamp_format or timestamp_format == 'unknown':\n            timestamp_format = naarad.utils.detect_timestamp_format(ts)\n          if timestamp_format == 'unknown':\n            continue\n          ts = naarad.utils.get_standardized_timestamp(ts, timestamp_format)\n          if self.ts_out_of_range(ts):\n            continue\n          # filtering based on user input; (local socket, remote socket, pid/process)\n          local_end, remote_end, interested = self._check_connection(words[5], words[6], words[8])\n          if interested:\n            self._add_data_line(data, local_end + '.' + remote_end + '.RecvQ', words[3], ts)\n            self._add_data_line(data, local_end + '.' + remote_end + '.SendQ', words[4], ts)\n    # post processing, putting data in csv files;\n    for csv in data.keys():\n      self.csv_files.append(csv)\n      with open(csv, 'w') as fh:\n        fh.write('\\n'.join(sorted(data[csv])))\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_csv(self, cpu, device=None):\n    cpu = naarad.utils.sanitize_string(cpu)\n    if device is None:\n      outcsv = os.path.join(self.resource_directory, \"{0}.{1}.csv\".format(self.label, cpu))\n      self.csv_column_map[outcsv] = cpu\n    else:\n      device = naarad.utils.sanitize_string(device)\n      outcsv = os.path.join(self.resource_directory, \"{0}.{1}.{2}.csv\".format(self.label, cpu, device))\n      self.csv_column_map[outcsv] = cpu + '.' + device\n    return outcsv", "response": "Returns the CSV file related to the given metric."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_header(self, infile):\n    cpus = []\n    for line in infile:  # Pre-processing - Try to find header\n      if not self.is_header_line(line):\n        continue\n      # Verifying correctness of the header\n      cpu_header = line.split()\n      for cpu_h in cpu_header[2:]:\n        if not cpu_h.startswith('CPU'):\n          cpus = []  # Bad header so reset to nothing\n          break\n        else:\n          cpus.append(cpu_h)\n      if len(cpus) > 0:  # We found the header\n        break\n    return cpus", "response": "Parses the file and tries to find the header line."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the input files and returns a new set of data structures.", "response": "def parse(self):\n    \"\"\"\n    Processes the files for each IRQ and each CPU in terms of the differences.\n    Also produces accumulated interrupt count differences for each set of Ethernet IRQs.\n    Generally Ethernet has 8 TxRx IRQs thus all are combined so that one can see the overall interrupts being generated by the NIC.\n\n    Simplified Interrupt File Format: (See examples for example log)\n\n                                        CPU0   CPU1\n      2014-10-29 00:27:42.15161    59:    29      2    IR-IO-APIC-edge    timer\n      2014-10-29 00:27:42.15161    60:  2123      0    IR-PCI-MSI-edge    eth0\n\n                                        CPU0   CPU1\n      2014-10-29 00:27:42.15161    59:    29      2    IR-IO-APIC-edge    timer\n      2014-10-29 00:27:42.15161    60:  2123      0    IR-PCI-MSI-edge    eth0\n\n    :returns: True or False whether parsing was successful or not.\n    \"\"\"\n    if not os.path.isdir(self.outdir):\n      os.makedirs(self.outdir)\n    if not os.path.isdir(self.resource_directory):\n      os.makedirs(self.resource_directory)\n\n    data = {}\n    for input_file in self.infile_list:\n      logger.info('Processing : %s', input_file)\n      timestamp_format = None\n      with open(input_file, 'r') as infile:\n        # Get the header for this file\n        cpus = self.find_header(infile)\n        if len(cpus) == 0:  # Make sure we have header otherwise go to next file\n          logger.error(\"Header not found for file: %s\", input_file)\n          continue\n\n        # Parse the actual file after header\n        prev_data = None    # Stores the previous interval's log data\n        curr_data = {}      # Stores the current interval's log data\n        eth_data = {}\n        for line in infile:\n          if self.is_header_line(line):  # New section so save old and aggregate ETH\n            prev_data = curr_data\n            curr_data = {}\n            # New section so store the collected Ethernet data\n            # Example Aggregate metric: PROCINTERRUPTS.AGGREGATE.eth0\n            for eth in eth_data:\n              outcsv = self.get_csv('AGGREGATE', eth)\n              if outcsv not in data:\n                data[outcsv] = []\n              data[outcsv].append(ts + ',' + str(eth_data[eth]))\n            eth_data = {}\n            continue\n\n          words = line.split()\n          if len(words) <= 4:  # Does not have any CPU data so skip\n            continue\n\n          # Process timestamp or determine timestamp\n          ts = words[0] + \" \" + words[1]\n          if not timestamp_format or timestamp_format == 'unknown':\n            timestamp_format = naarad.utils.detect_timestamp_format(ts)\n          if timestamp_format == 'unknown':\n            continue\n          ts = naarad.utils.get_standardized_timestamp(ts, timestamp_format)\n          if self.ts_out_of_range(ts):  # See if time is in range\n            continue\n\n          # Process data lines\n          # Note that some IRQs such as ERR and MIS do not have device nor ascii name\n          device = words[2].strip(':')  # Get IRQ Number/Name\n          if re.match(\"\\d+\", device):\n            # Devices with digits need ASCII name if exists\n            if (4 + len(cpus)) < len(words):\n              device = words[4 + len(cpus)] + \"-IRQ\" + device\n            else:\n              device = \"IRQ\" + device\n          else:\n            # For devices with IRQ # that aren't digits then has description\n            device = \"-\".join(words[(3 + len(cpus)):]) + \"-IRQ\" + device\n\n          # Deal with each column worth of data\n          for (cpu, datum) in zip(cpus, words[3:]):\n            if self.CPUS and cpu not in self.CPUS:  # Skip if config defines which CPUs to look at\n              continue\n            outcsv = self.get_csv(cpu, device)\n            curr_data[outcsv] = int(datum)\n            if outcsv in data:\n              datum = int(datum) - prev_data[outcsv]  # prev_data exists since outcsv exists in data\n            else:\n              data[outcsv] = []\n              datum = 0  # First data point is set to 0\n            # Store data point\n            data[outcsv].append(ts + ',' + str(datum))\n\n            # Deal with accumulating aggregate data for Ethernet\n            m = re.search(\"(?P<eth>eth\\d)\", device)\n            if m:\n              eth = m.group('eth')\n              if eth not in eth_data:\n                eth_data[eth] = 0\n              eth_data[eth] += datum\n\n    # Post processing, putting data in csv files\n    for csv in data.keys():\n      self.csv_files.append(csv)\n      with open(csv, 'w') as csvf:\n        csvf.write('\\n'.join(sorted(data[csv])))\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the vmstat file and return the status of the metric parse", "response": "def parse(self):\n    \"\"\"\n    Parse the vmstat file\n    :return: status of the metric parse\n    \"\"\"\n    file_status = True\n    for input_file in self.infile_list:\n      file_status = file_status and naarad.utils.is_valid_file(input_file)\n      if not file_status:\n        return False\n    status = True\n    data = {}  # stores the data of each column\n    for input_file in self.infile_list:\n      logger.info('Processing : %s', input_file)\n      timestamp_format = None\n      with open(input_file) as fh:\n        for line in fh:\n          words = line.split()        # [0] is day; [1] is seconds; [2] is field name:; [3] is value  [4] is unit\n          if len(words) < 3:\n            continue\n          ts = words[0] + \" \" + words[1]\n          if not timestamp_format or timestamp_format == 'unknown':\n            timestamp_format = naarad.utils.detect_timestamp_format(ts)\n          if timestamp_format == 'unknown':\n            continue\n          ts = naarad.utils.get_standardized_timestamp(ts, timestamp_format)\n          if self.ts_out_of_range(ts):\n            continue\n          col = words[2].strip(':')\n          # only process sub_metrics specified in config.\n          if self.sub_metrics and col not in self.sub_metrics:\n            continue\n          # add unit to metric description; most of the metrics have 'KB'; a few others do not have unit, they are in number of pages\n          if len(words) > 4 and words[4]:\n            unit = words[4]\n          else:\n            unit = 'pages'\n          self.sub_metric_unit[col] = unit\n          # stores the values in data[] before finally writing out\n          if col in self.column_csv_map:\n            out_csv = self.column_csv_map[col]\n          else:\n            out_csv = self.get_csv(col)   # column_csv_map[] is assigned in get_csv()\n            data[out_csv] = []\n          data[out_csv].append(ts + \",\" + words[3])\n    # post processing, putting data in csv files;\n    for csv in data.keys():\n      self.csv_files.append(csv)\n      with open(csv, 'w') as fh:\n        fh.write('\\n'.join(sorted(data[csv])))\n    return status"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_innotop_mode_m(self):\n    with open(self.infile, 'r') as infh:\n      # Pre processing to figure out different headers\n      max_row_quot = 0\n      valrow = -1\n      thisrowcolumns = {}\n      data = {}\n      last_ts = None\n      while True:\n        # 2012-05-11T00:00:02 master_host slave_sql_running  time_behind_master  slave_catchup_rate  slave_open_temp_tables  relay_log_pos   last_error\n        line1 = infh.readline()\n        words = line1.split()\n        # Skip next line\n        infh.readline()\n        is_header = True\n        for word in words:\n          if naarad.utils.is_number(word):\n            last_ts = words[0].strip().replace('T', ' ')\n            is_header = False\n            break  # from this loop\n        if len(words) > 2 and is_header:\n          thisrowcolumns[max_row_quot] = words[2:]\n          for column in thisrowcolumns[max_row_quot]:\n            data[column] = []\n          max_row_quot += 1\n        else:\n          break\n          # from pre-processing. All headers accounted for\n\n      # Real Processing\n      if not last_ts:\n        logger.warn(\"last_ts not set, looks like there is no data in file %s\", self.infile)\n        return True\n      infh.seek(0)\n      is_bad_line = False\n      outfilehandlers = {}\n      for line in infh:\n        l = line.strip().split(' ', 1)\n        # Blank line\n        if len(l) <= 1:\n          continue\n        ts = l[0].strip().replace('T', ' ')\n        if ts != last_ts:\n          last_ts = ts\n          valrow = -1\n        nameval = l[1].strip().split('\\t', 1)\n        try:\n          words = nameval[1].split('\\t')\n        except IndexError:\n          logger.warn(\"Bad line: %s\", line)\n          continue\n        valrow += 1\n        command = nameval[0]\n        if command not in outfilehandlers:\n          outfilehandlers[command] = {}\n        quot = valrow % max_row_quot\n        columns = thisrowcolumns[quot]\n        for i in range(len(words)):\n          if len(words) > len(columns):\n            logger.warn(\"Mismatched number of columns: %s\", line)\n            logger.warn(\"%d %d\", len(words), len(columns))\n            break\n          if words[i] in columns:\n            logger.warn(\"Skipping line: %s\", line)\n            valrow -= 1\n            break\n          if self.options and columns[i] not in self.options:\n            continue\n          if columns[i] not in outfilehandlers[command]:\n            outfilehandlers[command][columns[i]] = open(self.get_csv_C(command, columns[i]), 'w')\n            self.csv_files.append(self.get_csv_C(command, columns[i]))\n          ts = naarad.utils.reconcile_timezones(ts, self.timezone, self.graph_timezone)\n          outfilehandlers[command][columns[i]].write(ts + ',')\n          outfilehandlers[command][columns[i]].write(words[i])\n          outfilehandlers[command][columns[i]].write('\\n')\n      for command in outfilehandlers:\n        for column in outfilehandlers[command]:\n          outfilehandlers[command][column].close()\n    return True", "response": "Special parsing method for Innotop Replication Status results ( innotop mode M"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhighlight a region on the matplotlib plot between start and end x - co -ordinates.", "response": "def highlight_region(plt, start_x, end_x):\n  \"\"\"\n  Highlight a region on the chart between the specified start and end x-co-ordinates.\n  param pyplot plt: matplotlibk pyplot which contains the charts to be highlighted\n  param string start_x : epoch time millis\n  param string end_x : epoch time millis\n  \"\"\"\n  start_x = convert_to_mdate(start_x)\n  end_x = convert_to_mdate(end_x)\n  plt.axvspan(start_x, end_x, color=CONSTANTS.HIGHLIGHT_COLOR, alpha=CONSTANTS.HIGHLIGHT_ALPHA)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef graph_data_on_the_same_graph(list_of_plots, output_directory, resource_path, output_filename):\n  maximum_yvalue = -float('inf')\n  minimum_yvalue = float('inf')\n  plots = curate_plot_list(list_of_plots)\n  plot_count = len(plots)\n  if plot_count == 0:\n    return False, None\n  graph_height, graph_width, graph_title = get_graph_metadata(plots)\n  current_plot_count = 0\n  fig, axis = plt.subplots()\n  fig.set_size_inches(graph_width, graph_height)\n  if plot_count < 2:\n    fig.subplots_adjust(left=CONSTANTS.SUBPLOT_LEFT_OFFSET, bottom=CONSTANTS.SUBPLOT_BOTTOM_OFFSET, right=CONSTANTS.SUBPLOT_RIGHT_OFFSET)\n  else:\n    fig.subplots_adjust(left=CONSTANTS.SUBPLOT_LEFT_OFFSET, bottom=CONSTANTS.SUBPLOT_BOTTOM_OFFSET,\n                        right=CONSTANTS.SUBPLOT_RIGHT_OFFSET - CONSTANTS.Y_AXIS_OFFSET * (plot_count - 2))\n  # Generate each plot on the graph\n  for plot in plots:\n    current_plot_count += 1\n    logger.info('Processing: ' + plot.input_csv + ' [ ' + output_filename + ' ]')\n    xval, yval = numpy.loadtxt(plot.input_csv, unpack=True, delimiter=',')\n    axis.plot(xval, yval, linestyle='-', marker=None, color=get_current_color(current_plot_count), label=plot.plot_label)\n    axis.legend()\n    maximum_yvalue = max(maximum_yvalue, numpy.amax(yval) * (1.0 + CONSTANTS.ZOOM_FACTOR * current_plot_count))\n    minimum_yvalue = min(minimum_yvalue, numpy.amin(yval) * (1.0 - CONSTANTS.ZOOM_FACTOR * current_plot_count))\n  # Set properties of the plots\n  axis.yaxis.set_ticks_position('left')\n  axis.set_xlabel(plots[0].x_label)\n  axis.set_ylabel(plots[0].y_label, fontsize=CONSTANTS.Y_LABEL_FONTSIZE)\n  axis.set_ylim([minimum_yvalue, maximum_yvalue])\n  axis.yaxis.grid(True)\n  axis.xaxis.grid(True)\n  axis.set_title(graph_title)\n  plot_file_name = os.path.join(output_directory, output_filename + \".png\")\n  fig.savefig(plot_file_name)\n  plt.close()\n  # Create html fragment to be used for creation of the report\n  with open(os.path.join(output_directory, output_filename + '.div'), 'w') as div_file:\n    div_file.write('<a name=\"' + os.path.basename(plot_file_name).replace(\".png\", \"\").replace(\".diff\", \"\") + '\"></a><div class=\"col-md-12\"><img src=\"' +\n                   resource_path + '/' + os.path.basename(plot_file_name) + '\" id=\"' + os.path.basename(plot_file_name) +\n                   '\" width=\"100%\" height=\"auto\"/></div><div class=\"col-md-12\"><p align=center>' + os.path.basename(plot_file_name) + '<br/></p></div>')\n  return True, os.path.join(output_directory, output_filename + '.div')", "response": "This function will plot a list of plots on the same graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute anomaly scores for the time series.", "response": "def _set_scores(self):\n    \"\"\"\n    Compute anomaly scores for the time series.\n    \"\"\"\n    anom_scores = {}\n    self._compute_derivatives()\n    derivatives_ema = utils.compute_ema(self.smoothing_factor, self.derivatives)\n    for i, (timestamp, value) in enumerate(self.time_series_items):\n      anom_scores[timestamp] = abs(self.derivatives[i] - derivatives_ema[i])\n    stdev = numpy.std(anom_scores.values())\n    if stdev:\n        for timestamp in anom_scores.keys():\n          anom_scores[timestamp] /= stdev\n    self.anom_scores = TimeSeries(self._denoise_scores(anom_scores))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_metric_name(self, metric_name):\n    for metric_type in self.supported_sar_types:\n      if metric_type in metric_name:\n        return metric_type\n    logger.error('Section [%s] does not contain a valid metric type, using type: \"SAR-generic\". Naarad works better '\n                 'if it knows the metric type. Valid SAR metric names are: %s', metric_name, self.supported_sar_types)\n    return 'SAR-generic'", "response": "Method to extract the SAR metric name from the given section name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _find_allowed_shift(self, timestamps):\n    init_ts = timestamps[0]\n    residual_timestamps = map(lambda ts: ts - init_ts, timestamps)\n    n = len(residual_timestamps)\n    return self._find_first_bigger(residual_timestamps, self.max_shift_milliseconds, 0, n)", "response": "Find the maximum allowed shift steps based on max_shift_milliseconds."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _find_first_bigger(self, timestamps, target, lower_bound, upper_bound):\n    while lower_bound < upper_bound:\n      pos = lower_bound + (upper_bound - lower_bound) / 2\n      if timestamps[pos] > target:\n        upper_bound = pos\n      else:\n        lower_bound = pos + 1\n    return pos", "response": "This function searches for the first element in timestamps whose value is bigger than target."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_analysis(self, config):\n    self._default_test_id += 1\n    self._analyses[self._default_test_id] = _Analysis(ts_start=None, config=config, test_id=self._default_test_id)", "response": "Create Analysis and save in Naarad from config\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize an analysis object and set ts_start for the analysis represented by test_id", "response": "def signal_start(self, config, test_id=None, **kwargs):\n    \"\"\"\n    Initialize an analysis object and set ts_start for the analysis represented by test_id\n    :param test_id: integer that represents the analysis\n    :param config: config can be a ConfigParser.ConfigParser object or a string specifying local or http(s) location\n     for config\n    :return: test_id\n    \"\"\"\n    if not test_id:\n      self._default_test_id += 1\n      test_id = self._default_test_id\n    self._analyses[test_id] = _Analysis(naarad.utils.get_standardized_timestamp('now', None), config,\n                                      test_id=test_id)\n    if kwargs:\n      if 'description' in kwargs.keys():\n        self._analyses[test_id].description = kwargs['description']\n      if 'input_directory' in kwargs.keys():\n        self._analyses[test_id].input_directory = kwargs['input_directory']\n      if 'output_directory' in kwargs.keys():\n        self._analyses[test_id].output_directory = kwargs['output_directory']\n    return test_id"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef signal_stop(self, test_id=None):\n    if test_id is None:\n      test_id = self._default_test_id\n    if self._analyses[test_id].ts_end:\n      return CONSTANTS.OK\n    self._analyses[test_id].ts_end = naarad.utils.get_standardized_timestamp('now', None)\n    return CONSTANTS.OK", "response": "Signal that the analysis is stopped."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of test_ids for which naarad analysis failed", "response": "def get_failed_analyses(self):\n    \"\"\"\n    Returns a list of test_id for which naarad analysis failed\n    :return: list of test_ids\n    \"\"\"\n    failed_analyses = []\n    for test_id in self._analyses.keys():\n      if self._analyses[test_id].status != CONSTANTS.OK:\n        failed_analyses.append(test_id)\n    return failed_analyses"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the sla data for each metric in the metrics list", "response": "def _set_sla_data(self, test_id, metrics):\n    \"\"\"\n    Get sla data from each metric and set it in the _Analysis object specified by test_id to make it available\n    for retrieval\n    :return: currently always returns CONSTANTS.OK. Maybe enhanced in future to return additional status\n    \"\"\"\n    for metric in metrics:\n      self._analyses[test_id].sla_data[metric.label] = metric.sla_map\n    return CONSTANTS.OK"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the summary stats data for each metric in the metrics list", "response": "def _set_stats_data(self, test_id, metrics):\n    \"\"\"\n    Get summary stats data from each metric and set it in the _Analysis object specified by test_id to make it available\n    for retrieval\n    :return: currently always returns CONSTANTS.OK. Maybe enhanced in future to return additional status\n    \"\"\"\n    for metric in metrics:\n      self._analyses[test_id].stats_data[metric.label] = metric.summary_stats\n    return CONSTANTS.OK"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_output_directories(self, analysis):\n    try:\n      os.makedirs(analysis.output_directory)\n    except OSError as exception:\n      if exception.errno != errno.EEXIST:\n        raise\n    try:\n      resource_directory = os.path.join(analysis.output_directory, analysis.resource_path)\n      os.makedirs(resource_directory)\n    except OSError as exception:\n      if exception.errno != errno.EEXIST:\n        raise", "response": "Create the necessary output and resource directories for the specified analysis."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute any pre run steps in the config.", "response": "def _run_pre(self, analysis, run_steps):\n    \"\"\"\n    If Naarad is run in CLI mode, execute any pre run steps specified in the config. ts_start/ts_end are set based on\n    workload run steps if any.\n    :param: analysis: The analysis object being processed\n    :param: run_steps: list of post run steps\n    \"\"\"\n    workload_run_steps = []\n    for run_step in sorted(run_steps, key=lambda step: step.run_rank):\n      run_step.run()\n      if run_step.run_type == CONSTANTS.RUN_TYPE_WORKLOAD:\n        workload_run_steps.append(run_step)\n    # Get analysis time period from workload run steps\n    if len(workload_run_steps) > 0:\n      analysis.ts_start, analysis.ts_end = naarad.utils.get_run_time_period(workload_run_steps)\n    return CONSTANTS.OK"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes any post run steps specified in the config", "response": "def _run_post(self, run_steps):\n    \"\"\"\n    If Naarad is run in CLI mode, execute any post run steps specified in the config\n    :param: run_steps: list of post run steps\n    \"\"\"\n    for run_step in sorted(run_steps, key=lambda step: step.run_rank):\n      run_step.run()\n    return CONSTANTS.OK"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _process_args(self, analysis, args):\n    if args.exit_code:\n      self.return_exit_code = args.exit_code\n    if args.no_plots:\n      self.skip_plots = args.no_plots\n    if args.start:\n      analysis.ts_start = naarad.utils.get_standardized_timestamp(args.start, None)\n    if args.end:\n      analysis.ts_end = naarad.utils.get_standardized_timestamp(args.end, None)\n    if args.variables:\n      analysis.variables = naarad.utils.get_variables(args)\n    return CONSTANTS.OK", "response": "Process the command line arguments received by Naarad and update the analysis object with the values received by the analysis."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns all the analyses in the log files and save the results in the output_directory.", "response": "def analyze(self, input_directory, output_directory, **kwargs):\n    \"\"\"\n    Run all the analysis saved in self._analyses, sorted by test_id.\n    This is useful when Naarad() is used by other programs and multiple analyses are run\n    In naarad CLI mode, len(_analyses) == 1\n    :param: input_directory: location of log files\n    :param: output_directory: root directory for analysis output\n    :param: **kwargs: Optional keyword args\n    :return: int: status code.\n    \"\"\"\n    is_api_call = True\n    if len(self._analyses) == 0:\n      if 'config' not in kwargs.keys():\n        return CONSTANTS.ERROR\n      self.create_analysis(kwargs['config'])\n    if 'args' in kwargs:\n      self._process_args(self._analyses[0], kwargs['args'])\n      is_api_call = False\n    error_count = 0\n    self._input_directory = input_directory\n    self._output_directory = output_directory\n    for test_id in sorted(self._analyses.keys()):\n      # Setup\n      if not self._analyses[test_id].input_directory:\n        self._analyses[test_id].input_directory = input_directory\n      if not self._analyses[test_id].output_directory:\n        if len(self._analyses) > 1:\n          self._analyses[test_id].output_directory = os.path.join(output_directory, str(test_id))\n        else:\n          self._analyses[test_id].output_directory = output_directory\n      if('config' in kwargs.keys()) and (not self._analyses[test_id].config):\n        self._analyses[test_id].config = kwargs['config']\n      self._create_output_directories(self._analyses[test_id])\n      # Actually run analysis\n      self._analyses[test_id].status = self.run(self._analyses[test_id], is_api_call, **kwargs)\n      if self._analyses[test_id].status != CONSTANTS.OK:\n        error_count += 1\n    if len(self._analyses) == 1:\n      return self._analyses[0].status\n    elif error_count > 0:\n      return CONSTANTS.ERROR\n    else:\n      return CONSTANTS.OK"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the analysis object.", "response": "def run(self, analysis, is_api_call, **kwargs):\n    \"\"\"\n    :param analysis: Run naarad analysis for the specified analysis object\n    :param **kwargs: Additional keyword args can be passed in here for future enhancements\n    :return:\n    \"\"\"\n    threads = []\n    crossplots = []\n    report_args = {}\n    metrics = defaultdict()\n    run_steps = defaultdict(list)\n    discovery_mode = False\n    graph_timezone = None\n    graphing_library = None\n\n    if isinstance(analysis.config, str):\n      if not naarad.utils.is_valid_file(analysis.config):\n        return CONSTANTS.INVALID_CONFIG\n      config_object = ConfigParser.ConfigParser(analysis.variables)\n      config_object.optionxform = str\n      config_object.read(analysis.config)\n    elif isinstance(analysis.config, ConfigParser.ConfigParser):\n      config_object = analysis.config\n    else:\n      if is_api_call:\n        return CONSTANTS.INVALID_CONFIG\n      else:\n        metrics['metrics'] = naarad.utils.discover_by_name(analysis.input_directory, analysis.output_directory)\n        if len(metrics['metrics']) == 0:\n          logger.warning('Unable to auto detect metrics in the specified input directory: %s', analysis.input_directory)\n          return CONSTANTS.ERROR\n        else:\n          discovery_mode = True\n          metrics['aggregate_metrics'] = []\n    if not discovery_mode:\n      metrics, run_steps, crossplots, report_args, graph_timezone, graphing_library = self._process_naarad_config(config_object, analysis)\n\n    if graphing_library is None:\n      graphing_library = CONSTANTS.DEFAULT_GRAPHING_LIBRARY\n    # If graphing libraries are not installed, skip static images\n    if graphing_library not in self.available_graphing_modules.keys():\n      logger.error(\"Naarad cannot import graphing library %s on your system. Will not generate static charts\", graphing_library)\n      self.skip_plots = True\n\n    if not is_api_call:\n      self._run_pre(analysis, run_steps['pre'])\n    for metric in metrics['metrics']:\n      if analysis.ts_start:\n        metric.ts_start = analysis.ts_start\n      if analysis.ts_end:\n        metric.ts_end = analysis.ts_end\n      thread = threading.Thread(target=naarad.utils.parse_and_plot_single_metrics,\n                                args=(metric, graph_timezone, analysis.output_directory, analysis.input_directory, graphing_library, self.skip_plots))\n      thread.start()\n      threads.append(thread)\n    for t in threads:\n      t.join()\n    for metric in metrics['aggregate_metrics']:\n      thread = threading.Thread(target=naarad.utils.parse_and_plot_single_metrics,\n                                args=(metric, graph_timezone, analysis.output_directory, analysis.input_directory, graphing_library, self.skip_plots))\n      thread.start()\n      threads.append(thread)\n    for t in threads:\n      t.join()\n    self._set_sla_data(analysis.test_id, metrics['metrics'] + metrics['aggregate_metrics'])\n    self._set_stats_data(analysis.test_id, metrics['metrics'] + metrics['aggregate_metrics'])\n    if len(crossplots) > 0 and not self.skip_plots:\n      correlated_plots = naarad.utils.nway_plotting(crossplots, metrics['metrics'] + metrics['aggregate_metrics'],\n                                                    os.path.join(analysis.output_directory, analysis.resource_path),\n                                                    analysis.resource_path, graphing_library)\n    else:\n      correlated_plots = []\n    rpt = reporting_modules['report'](None, analysis.output_directory, os.path.join(analysis.output_directory, analysis.resource_path), analysis.resource_path,\n                                      metrics['metrics'] + metrics['aggregate_metrics'], correlated_plots=correlated_plots, **report_args)\n    rpt.generate()\n    if not is_api_call:\n      self._run_post(run_steps['post'])\n\n    if self.return_exit_code:\n      for metric in metrics['metrics'] + metrics['aggregate_metrics']:\n        if metric.status == CONSTANTS.SLA_FAILED:\n          return CONSTANTS.SLA_FAILURE\n\n    return CONSTANTS.OK"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef diff(self, test_id_1, test_id_2, config=None, **kwargs):\n    output_directory = os.path.join(self._output_directory, 'diff_' + str(test_id_1) + '_' + str(test_id_2))\n    if kwargs:\n      if 'output_directory' in kwargs.keys():\n        output_directory = kwargs['output_directory']\n    diff_report = Diff([NaaradReport(self._analyses[test_id_1].output_directory, None),\n                        NaaradReport(self._analyses[test_id_2].output_directory, None)],\n                       'diff', output_directory, os.path.join(output_directory, self._resource_path),\n                       self._resource_path)\n    if config:\n      naarad.utils.extract_diff_sla_from_config_file(diff_report, config)\n    diff_report.generate()\n    if diff_report.sla_failures > 0:\n      return CONSTANTS.SLA_FAILURE\n    if diff_report.status != 'OK':\n      return CONSTANTS.ERROR\n    return CONSTANTS.OK", "response": "Creates a diff report using test_id_1 and test_id_2 as a baseline\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a diff report using report1 and report2 as a baseline", "response": "def diff_reports_by_location(self, report1_location, report2_location, output_directory, config=None, **kwargs):\n    \"\"\"\n    Create a diff report using report1 as a baseline\n    :param: report1_location: report to be used as baseline\n    :param: report2_location: report to compare against baseline\n    :param: config file for diff (optional)\n    :param: **kwargs: keyword arguments\n    \"\"\"\n\n    if kwargs:\n      if 'output_directory' in kwargs.keys():\n        output_directory = kwargs['output_directory']\n    diff_report = Diff([NaaradReport(report1_location, None), NaaradReport(report2_location, None)], 'diff',\n                       output_directory, os.path.join(output_directory, self._resource_path), self._resource_path)\n    if config:\n      naarad.utils.extract_diff_sla_from_config_file(diff_report, config)\n    diff_report.generate()\n    if diff_report.sla_failures > 0:\n      return CONSTANTS.SLA_FAILURE\n    if diff_report.status != 'OK':\n      return CONSTANTS.ERROR\n    return CONSTANTS.OK"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _process_naarad_config(self, config, analysis):\n    graph_timezone = None\n    output_directory = analysis.output_directory\n    resource_path = analysis.resource_path\n    run_steps = defaultdict(list)\n    metrics = defaultdict(list)\n    indir_default = ''\n    crossplots = []\n    report_args = {}\n    graphing_library = None\n    ts_start, ts_end = None, None\n\n    if config.has_section('GLOBAL'):\n      ts_start, ts_end = naarad.utils.parse_global_section(config, 'GLOBAL')\n      if config.has_option('GLOBAL', 'user_defined_metrics'):\n        naarad.utils.parse_user_defined_metric_classes(config, metric_classes)\n      config.remove_section('GLOBAL')\n\n    if config.has_section('REPORT'):\n      report_args = naarad.utils.parse_report_section(config, 'REPORT')\n      config.remove_section('REPORT')\n\n    for section in config.sections():\n      # GRAPH section is optional\n      if section == 'GRAPH':\n        graphing_library, crossplots, outdir_default, indir_default, graph_timezone = \\\n            naarad.utils.parse_graph_section(config, section, output_directory, indir_default)\n      elif section.startswith('RUN-STEP'):\n        run_step = naarad.utils.parse_run_step_section(config, section)\n        if not run_step:\n          logger.error('Ignoring section %s, could not parse it correctly', section)\n          continue\n        if run_step.run_order == CONSTANTS.PRE_ANALYSIS_RUN:\n          run_steps['pre'].append(run_step)\n        # DURING_ANALYSIS_RUN not supported yet\n        elif run_step.run_order == CONSTANTS.DURING_ANALYSIS_RUN:\n          run_steps['in'].append(run_step)\n        elif run_step.run_order == CONSTANTS.POST_ANALYSIS_RUN:\n          run_steps['post'].append(run_step)\n        else:\n          logger.error('Unknown RUN-STEP run_order specified')\n      else:\n        # section name is used to create sub-directories, so enforce it.\n        if not naarad.utils.is_valid_metric_name(section):\n          logger.critical('Section name %s is invalid! Only letters, digits, dot(.), dash(-), underscore(_) are allowed'\n                          % section)\n          return CONSTANTS.CRITICAL_FAILURE\n        if section == 'SAR-*':\n          hostname, infile, label, ts_start, ts_end, precision, kwargs, rule_strings = \\\n              naarad.utils.parse_basic_metric_options(config, section)\n          sar_metrics = naarad.utils.get_all_sar_objects(metrics, infile, hostname, output_directory, label, ts_start,\n                                                         ts_end, None)\n          for sar_metric in sar_metrics:\n            if sar_metric.ts_start is None and (sar_metric.ts_end is None or sar_metric.ts_end > ts_start):\n              sar_metric.ts_start = ts_start\n            if sar_metric.ts_end is None and (sar_metric.ts_start is None or ts_end > sar_metric.ts_start):\n              sar_metric.ts_end = ts_end\n          metrics['metrics'].extend(sar_metrics)\n        else:\n          new_metric = naarad.utils.parse_metric_section(config, section, metric_classes, metrics['metrics'],\n                                                         aggregate_metric_classes, output_directory, resource_path)\n          if new_metric.ts_start is None and (new_metric.ts_end is None or new_metric.ts_end > ts_start):\n            new_metric.ts_start = ts_start\n          if new_metric.ts_end is None and (new_metric.ts_start is None or ts_end > new_metric.ts_start):\n            new_metric.ts_end = ts_end\n          metric_type = section.split('-')[0]\n          if metric_type in aggregate_metric_classes:\n            metrics['aggregate_metrics'].append(new_metric)\n          else:\n            metrics['metrics'].append(new_metric)\n    return metrics, run_steps, crossplots, report_args, graph_timezone, graphing_library", "response": "Processes the config file associated with a particular analysis and returns metrics run_steps and crossplots."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the vmstat file and return the status of the metric parse", "response": "def parse(self):\n    \"\"\"\n    Parse the vmstat file\n    :return: status of the metric parse\n    \"\"\"\n    file_status = True\n    for input_file in self.infile_list:\n      file_status = file_status and naarad.utils.is_valid_file(input_file)\n      if not file_status:\n        return False\n\n    status = True\n    cur_zone = None\n    cur_submetric = None\n    cur_value = None\n    data = {}  # stores the data of each column\n    for input_file in self.infile_list:\n      logger.info('Processing : %s', input_file)\n      timestamp_format = None\n      with open(input_file) as fh:\n        for line in fh:\n          words = line.replace(',', ' ').split()           # [0] is day; [1] is seconds; [2...] is field names:;\n          if len(words) < 3:\n            continue\n          ts = words[0] + \" \" + words[1]\n          if not timestamp_format or timestamp_format == 'unknown':\n            timestamp_format = naarad.utils.detect_timestamp_format(ts)\n          if timestamp_format == 'unknown':\n            continue\n          ts = naarad.utils.get_standardized_timestamp(ts, timestamp_format)\n          if self.ts_out_of_range(ts):\n            continue\n          if words[2] == 'Node':  # Node 0 zone      DMA\n            cols = words[2:]\n            cur_zone = '.'.join(cols)\n            continue\n          elif words[2] == 'pages':  # pages free     3936\n            cur_submetric = words[2] + '.' + words[3]  # pages.free\n            cur_value = words[4]\n          elif words[2] in self.processed_sub_metrics:\n            cur_submetric = 'pages' + '.' + words[2]  # pages.min\n            cur_value = words[3]\n          elif words[2] in self.skipped_sub_metrics:\n            continue\n          else:   # other useful submetrics\n            cur_submetric = words[2]\n            cur_value = words[3]\n          col = cur_zone + '.' + cur_submetric  # prefix with 'Node.0.zone.DMA.\n          # only process zones specified in config\n          if cur_zone and self.zones and cur_zone not in self.zones:\n            continue\n          self.sub_metric_unit[col] = 'pages'  # The unit of the sub metric. For /proc/zoneinfo, they are all in pages\n          # only process sub_metrics specified in config.\n          if self.sub_metrics and cur_submetric and cur_submetric not in self.sub_metrics:\n            continue\n          if col in self.column_csv_map:\n            out_csv = self.column_csv_map[col]\n          else:\n            out_csv = self.get_csv(col)   # column_csv_map[] is assigned in get_csv()\n            data[out_csv] = []\n          data[out_csv].append(ts + \",\" + cur_value)\n    # post processing, putting data in csv files;\n    for csv in data.keys():\n      self.csv_files.append(csv)\n      with open(csv, 'w') as fh:\n        fh.write('\\n'.join(sorted(data[csv])))\n    return status"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef collect(self):\n\n    for aggr_metric in self.aggr_metrics:   # e.g., SAR-device.sda.await:count,sum,avg\n      functions_aggr = []\n      fields = aggr_metric.split(\":\")\n      cur_metric_type = fields[0].split(\".\")[0]  # e.g. SAR-device\n\n      if len(fields) > 1:  # The user has to specify the aggregate functions (i.e., :raw,count,sum,avg)\n        func_user = ''.join(fields[1].split())\n        functions_aggr.extend(func_user.split(\",\"))\n      else:  # no user input of aggregate functions\n        return True\n\n      cur_column = '.'.join(fields[0].split('.')[1:])    # e.g. sda.await or all.percent-sys\n\n      # Store data points of various aggregation functions\n      aggr_data = {}\n      aggr_data['raw'] = []   # Store all the raw values\n      aggr_data['sum'] = defaultdict(float)   # Store the sum values for each timestamp\n      aggr_data['count'] = defaultdict(int)  # Store the count of each timestamp (i.e. qps)\n\n      for metric in self.metrics:   # Loop the list to find from all metrics to merge\n        if metric.hostname in self.aggr_hosts and \\\n           cur_column in metric.csv_column_map.values():\n          file_csv = metric.get_csv(cur_column)\n          timestamp_format = None\n          with open(file_csv) as fh:\n            for line in fh:\n              aggr_data['raw'].append(line.rstrip())\n              words = line.split(\",\")\n              ts = words[0].split('.')[0]   # In case of sub-seconds; we only want the value of seconds;\n              if not timestamp_format or timestamp_format == 'unknown':\n                timestamp_format = naarad.utils.detect_timestamp_format(ts)\n              if timestamp_format == 'unknown':\n                continue\n              ts = naarad.utils.get_standardized_timestamp(ts, timestamp_format)\n              aggr_data['sum'][ts] += float(words[1])\n              aggr_data['count'][ts] += 1\n      # \"raw\" csv file\n      if 'raw' in functions_aggr:\n        out_csv = self.get_csv(cur_column, 'raw')\n        self.csv_files.append(out_csv)\n        with open(out_csv, 'w') as fh:\n          fh.write(\"\\n\".join(sorted(aggr_data['raw'])))\n\n      # \"sum\"  csv file\n      if 'sum' in functions_aggr:\n        out_csv = self.get_csv(cur_column, 'sum')\n        self.csv_files.append(out_csv)\n        with open(out_csv, 'w') as fh:\n          for (k, v) in sorted(aggr_data['sum'].items()):\n            fh.write(k + \",\" + str(v) + '\\n')\n\n      # \"avg\" csv file\n      if 'avg' in functions_aggr:\n        out_csv = self.get_csv(cur_column, 'avg')\n        self.csv_files.append(out_csv)\n        with open(out_csv, 'w') as fh:\n          for (k, v) in sorted(aggr_data['sum'].items()):\n            fh.write(k + \",\" + str(v / aggr_data['count'][k]) + '\\n')\n\n      # \"count\" csv file (qps)\n      if 'count' in functions_aggr:\n        out_csv = self.get_csv(cur_column, 'count')\n        self.csv_files.append(out_csv)\n        with open(out_csv, 'w') as fh:\n          for (k, v) in sorted(aggr_data['count'].items()):\n            fh.write(k + \",\" + str(v) + '\\n')\n\n      gc.collect()\n    return True", "response": "Collect the metrics from the given hosts and update the corresponding properties such as csv_column_map."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_times(self, native):\n    start_time = 0\n    end_time = 0\n    launch_time = 0\n    nus_update_time = 0\n\n    for item in native:\n      if item[CONSTANTS.LIA_TIMING_NAME] == CONSTANTS.LIA_APP_ON_CREATE and item[CONSTANTS.LIA_START] is not None:\n        start_time = item[CONSTANTS.LIA_START][CONSTANTS.LIA_LONG]\n      if item[CONSTANTS.LIA_TIMING_NAME] == CONSTANTS.LIA_NUS_UPDATE:\n        if item[CONSTANTS.LIA_TIMING_VALUE] is not None:\n          nus_update_time = item[CONSTANTS.LIA_TIMING_VALUE][CONSTANTS.LIA_LONG]\n        if item[CONSTANTS.LIA_START] is not None:\n          end_time = item[CONSTANTS.LIA_START][CONSTANTS.LIA_LONG]\n\n    if start_time == 0 or end_time == 0:\n      time_stamp = 0\n      launch_time = 0\n    else:\n      time_stamp = start_time\n      launch_time = end_time - start_time\n    return (time_stamp, launch_time, nus_update_time)", "response": "get start time stamp launch time duration and nus update time duration from JSON object native"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform the Oct2Py speed analysis.", "response": "def run(self):\r\n        \"\"\"Perform the Oct2Py speed analysis.\r\n\r\n        Uses timeit to test the raw execution of an Octave command,\r\n        Then tests progressively larger array passing.\r\n\r\n        \"\"\"\r\n        print('Oct2Py speed test')\r\n        print('*' * 20)\r\n        time.sleep(1)\r\n\r\n        print('Raw speed: ')\r\n        avg = timeit.timeit(self.raw_speed, number=10) / 10\r\n        print('    {0:0.01f} usec per loop'.format(avg * 1e6))\r\n        sides = [1, 10, 100, 1000]\r\n        runs = [10, 10, 10, 5]\r\n        for (side, nruns) in zip(sides, runs):\r\n            self.array = np.reshape(np.arange(side ** 2), (-1))\r\n            print('Put {0}x{1}: '.format(side, side))\r\n            avg = timeit.timeit(self.large_array_put, number=nruns) / nruns\r\n            print('    {0:0.01f} msec'.format(avg * 1e3))\r\n\r\n            print('Get {0}x{1}: '.format(side, side))\r\n            avg = timeit.timeit(self.large_array_get, number=nruns) / nruns\r\n            print('    {0:0.01f} msec'.format(avg * 1e3))\r\n\r\n        self.octave.exit()\r\n        print('*' * 20)\r\n        print('Test complete!')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquitting this octave session and cleans up.", "response": "def exit(self):\r\n        \"\"\"Quits this octave session and cleans up.\r\n        \"\"\"\r\n        if self._engine:\r\n            self._engine.repl.terminate()\r\n        self._engine = None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npush a variable or variable to the Octave session.", "response": "def push(self, name, var, timeout=None, verbose=True):\r\n        \"\"\"\r\n        Put a variable or variables into the Octave session.\r\n\r\n        Parameters\r\n        ----------\r\n        name : str or list\r\n            Name of the variable(s).\r\n        var : object or list\r\n            The value(s) to pass.\r\n        timeout : float\r\n            Time to wait for response from Octave (per line).\r\n        **kwargs: Deprecated kwargs, ignored.\r\n\r\n        Examples\r\n        --------\r\n        >>> from oct2py import octave\r\n        >>> y = [1, 2]\r\n        >>> octave.push('y', y)\r\n        >>> octave.pull('y')\r\n        array([[ 1.,  2.]])\r\n        >>> octave.push(['x', 'y'], ['spam', [1, 2, 3, 4]])\r\n        >>> octave.pull(['x', 'y'])  # doctest: +SKIP\r\n        [u'spam', array([[1, 2, 3, 4]])]\r\n\r\n        Notes\r\n        -----\r\n        Integer type arguments will be converted to floating point\r\n        unless `convert_to_float=False`.\r\n\r\n        \"\"\"\r\n        if isinstance(name, (str, unicode)):\r\n            name = [name]\r\n            var = [var]\r\n\r\n        for (n, v) in zip(name, var):\r\n            self.feval('assignin', 'base', n, v, nout=0, timeout=timeout,\r\n                       verbose=verbose)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pull(self, var, timeout=None, verbose=True):\r\n        if isinstance(var, (str, unicode)):\r\n            var = [var]\r\n        outputs = []\r\n        for name in var:\r\n            exist = self._exist(name)\r\n            if exist == 1:\r\n                outputs.append(self.feval('evalin', 'base', name,\r\n                                          timeout=timeout, verbose=verbose))\r\n            else:\r\n                outputs.append(self.get_pointer(name, timeout=timeout))\r\n\r\n        if len(outputs) == 1:\r\n            return outputs[0]\r\n        return outputs", "response": "Retrieves a value or values from Octave."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_pointer(self, name, timeout=None):\r\n        exist = self._exist(name)\r\n        isobject = self._isobject(name, exist)\r\n\r\n        if exist == 0:\r\n            raise Oct2PyError('\"%s\" is undefined' % name)\r\n\r\n        elif exist == 1:\r\n            return _make_variable_ptr_instance(self, name)\r\n\r\n        elif isobject:\r\n            return self._get_user_class(name)\r\n\r\n        elif exist in [2, 3, 5]:\r\n            return self._get_function_ptr(name)\r\n\r\n        raise Oct2PyError('Unknown type for object \"%s\"' % name)", "response": "Get a pointer to a named object in the Octave workspace."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_figures(self, plot_dir, remove=False):\r\n        figures = self._engine.extract_figures(plot_dir, remove)\r\n        return figures", "response": "Extract the figures in the directory to IPython display objects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef feval(self, func_path, *func_args, **kwargs):\r\n        if not self._engine:\r\n            raise Oct2PyError('Session is not open')\r\n\r\n        nout = kwargs.get('nout', None)\r\n        if nout is None:\r\n            nout = 1\r\n\r\n        plot_dir = kwargs.get('plot_dir')\r\n        settings = dict(backend='inline' if plot_dir else self.backend,\r\n                        format=kwargs.get('plot_format'),\r\n                        name=kwargs.get('plot_name'),\r\n                        width=kwargs.get('plot_width'),\r\n                        height=kwargs.get('plot_height'),\r\n                        resolution=kwargs.get('plot_res'))\r\n        self._engine.plot_settings = settings\r\n\r\n        dname = osp.dirname(func_path)\r\n        fname = osp.basename(func_path)\r\n        func_name, ext = osp.splitext(fname)\r\n        if ext and not ext == '.m':\r\n            raise TypeError('Need to give path to .m file')\r\n\r\n        if func_name == 'clear':\r\n            raise Oct2PyError('Cannot use `clear` command directly, use' +\r\n                              ' eval(\"clear(var1, var2)\")')\r\n\r\n        stream_handler = kwargs.get('stream_handler')\r\n        verbose = kwargs.get('verbose', True)\r\n        store_as = kwargs.get('store_as', '')\r\n        timeout = kwargs.get('timeout', self.timeout)\r\n        if not stream_handler:\r\n            stream_handler = self.logger.info if verbose else self.logger.debug\r\n\r\n        return self._feval(func_name, func_args, dname=dname, nout=nout,\r\n                          timeout=timeout, stream_handler=stream_handler,\r\n                          store_as=store_as, plot_dir=plot_dir)", "response": "Run a function in Octave and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nevaluate an Octave command or commands and return the result.", "response": "def eval(self, cmds, verbose=True, timeout=None, stream_handler=None,\r\n             temp_dir=None, plot_dir=None, plot_name='plot', plot_format='svg',\r\n             plot_width=None, plot_height=None, plot_res=None,\r\n             nout=0, **kwargs):\r\n        \"\"\"\r\n        Evaluate an Octave command or commands.\r\n\r\n        Parameters\r\n        ----------\r\n        cmds : str or list\r\n            Commands(s) to pass to Octave.\r\n        verbose : bool, optional\r\n             Log Octave output at INFO level.  If False, log at DEBUG level.\r\n        stream_handler: callable, optional\r\n            A function that is called for each line of output from the\r\n            evaluation.\r\n        timeout : float, optional\r\n            Time to wait for response from Octave (per line).  If not given,\r\n            the instance `timeout` is used.\r\n        nout : int, optional.\r\n            The desired number of returned values, defaults to 0.  If nout\r\n            is 0, the `ans` will be returned as the return value.\r\n        temp_dir: str, optional\r\n            If specified, the session's MAT files will be created in the\r\n            directory, otherwise a the instance `temp_dir` is used.\r\n            a shared memory (tmpfs) path.\r\n        plot_dir: str, optional\r\n            If specificed, save the session's plot figures to the plot\r\n            directory instead of displaying the plot window.\r\n        plot_name : str, optional\r\n            Saved plots will start with `plot_name` and\r\n            end with \"_%%.xxx' where %% is the plot number and\r\n            xxx is the `plot_format`.\r\n        plot_format: str, optional\r\n            The format in which to save the plot (PNG by default).\r\n        plot_width: int, optional\r\n            The plot with in pixels.\r\n        plot_height: int, optional\r\n            The plot height in pixels.\r\n        plot_res: int, optional\r\n            The plot resolution in pixels per inch.\r\n        **kwargs Deprectated kwargs.\r\n\r\n        Examples\r\n        --------\r\n        >>> from oct2py import octave\r\n        >>> octave.eval('disp(\"hello\")') # doctest: +SKIP\r\n        hello\r\n        >>> x = octave.eval('round(quad(@sin, 0, pi/2));')\r\n        >>> x\r\n        1.0\r\n\r\n        >>> a = octave.eval('disp(\"hello\");1;')  # doctest: +SKIP\r\n        hello\r\n        >>> a = octave.eval('disp(\"hello\");1;', verbose=False)\r\n        >>> a\r\n        1.0\r\n\r\n        >>> from oct2py import octave\r\n        >>> lines = []\r\n        >>> octave.eval('for i = 1:3; disp(i);end', \\\r\n                        stream_handler=lines.append)\r\n        >>> lines  # doctest: +SKIP\r\n        [' 1', ' 2', ' 3']\r\n\r\n        Returns\r\n        -------\r\n        out : object\r\n            Octave \"ans\" variable, or None.\r\n\r\n        Notes\r\n        -----\r\n        The deprecated `log` kwarg will temporarily set the `logger` level to\r\n        `WARN`.  Using the `logger` settings directly is preferred.\r\n        The deprecated `return_both` kwarg will still work, but the preferred\r\n        method is to use the `stream_handler`.  If `stream_handler` is given,\r\n        the `return_both` kwarg will be honored but will give an empty string\r\n        as the reponse.\r\n\r\n        Raises\r\n        ------\r\n        Oct2PyError\r\n            If the command(s) fail.\r\n        \"\"\"\r\n        if isinstance(cmds, (str, unicode)):\r\n            cmds = [cmds]\r\n\r\n        prev_temp_dir = self.temp_dir\r\n        self.temp_dir = temp_dir or self.temp_dir\r\n        prev_log_level = self.logger.level\r\n\r\n        if kwargs.get('log') is False:\r\n            self.logger.setLevel(logging.WARN)\r\n\r\n        for name in ['log', 'return_both']:\r\n            if name not in kwargs:\r\n                continue\r\n            msg = 'Using deprecated `%s` kwarg, see docs on `Oct2Py.eval()`'\r\n            warnings.warn(msg % name, stacklevel=2)\r\n\r\n        return_both = kwargs.pop('return_both', False)\r\n        lines = []\r\n        if return_both and not stream_handler:\r\n            stream_handler = lines.append\r\n\r\n        ans = None\r\n        for cmd in cmds:\r\n            resp = self.feval('evalin', 'base', cmd,\r\n                              nout=nout, timeout=timeout,\r\n                              stream_handler=stream_handler,\r\n                              verbose=verbose, plot_dir=plot_dir,\r\n                              plot_name=plot_name, plot_format=plot_format,\r\n                              plot_width=plot_width, plot_height=plot_height,\r\n                              plot_res=plot_res)\r\n            if resp is not None:\r\n                ans = resp\r\n\r\n        self.temp_dir = prev_temp_dir\r\n        self.logger.setLevel(prev_log_level)\r\n\r\n        if return_both:\r\n            return '\\n'.join(lines), ans\r\n        return ans"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef restart(self):\r\n        if self._engine:\r\n            self._engine.repl.terminate()\r\n\r\n        executable = self._executable\r\n        if executable:\r\n            os.environ['OCTAVE_EXECUTABLE'] = executable\r\n        if 'OCTAVE_EXECUTABLE' not in os.environ and 'OCTAVE' in os.environ:\r\n            os.environ['OCTAVE_EXECUTABLE'] = os.environ['OCTAVE']\r\n\r\n        self._engine = OctaveEngine(stdin_handler=self._handle_stdin,\r\n                                    logger=self.logger)\r\n\r\n        # Add local Octave scripts.\r\n        self._engine.eval('addpath(\"%s\");' % HERE.replace(osp.sep, '/'))", "response": "Restart an Octave session in a clean state"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _feval(self, func_name, func_args=(), dname='', nout=0,\r\n              timeout=None, stream_handler=None, store_as='', plot_dir=None):\r\n        \"\"\"Run the given function with the given args.\r\n        \"\"\"\r\n        engine = self._engine\r\n        if engine is None:\r\n            raise Oct2PyError('Session is closed')\r\n\r\n        # Set up our mat file paths.\r\n        out_file = osp.join(self.temp_dir, 'writer.mat')\r\n        out_file = out_file.replace(osp.sep, '/')\r\n        in_file = osp.join(self.temp_dir, 'reader.mat')\r\n        in_file = in_file.replace(osp.sep, '/')\r\n\r\n        func_args = list(func_args)\r\n        ref_indices = []\r\n        for (i, value) in enumerate(func_args):\r\n            if isinstance(value, OctavePtr):\r\n                ref_indices.append(i + 1)\r\n                func_args[i] = value.address\r\n        ref_indices = np.array(ref_indices)\r\n\r\n        # Save the request data to the output file.\r\n        req = dict(func_name=func_name, func_args=tuple(func_args),\r\n                   dname=dname or '', nout=nout,\r\n                   store_as=store_as or '',\r\n                   ref_indices=ref_indices)\r\n\r\n        write_file(req, out_file, oned_as=self._oned_as,\r\n                   convert_to_float=self.convert_to_float)\r\n\r\n        # Set up the engine and evaluate the `_pyeval()` function.\r\n        engine.stream_handler = stream_handler or self.logger.info\r\n        if timeout is None:\r\n            timeout = self.timeout\r\n\r\n        try:\r\n            engine.eval('_pyeval(\"%s\", \"%s\");' % (out_file, in_file),\r\n                        timeout=timeout)\r\n        except KeyboardInterrupt as e:\r\n            stream_handler(engine.repl.interrupt())\r\n            raise\r\n        except TIMEOUT:\r\n            stream_handler(engine.repl.interrupt())\r\n            raise Oct2PyError('Timed out, interrupting')\r\n        except EOF:\r\n            stream_handler(engine.repl.child.before)\r\n            self.restart()\r\n            raise Oct2PyError('Session died, restarting')\r\n\r\n        # Read in the output.\r\n        resp = read_file(in_file, self)\r\n        if resp['err']:\r\n            msg = self._parse_error(resp['err'])\r\n            raise Oct2PyError(msg)\r\n\r\n        result = resp['result'].ravel().tolist()\r\n        if isinstance(result, list) and len(result) == 1:\r\n            result = result[0]\r\n\r\n        # Check for sentinel value.\r\n        if (isinstance(result, Cell) and\r\n                result.size == 1 and\r\n                isinstance(result[0], string_types) and\r\n                result[0] == '__no_value__'):\r\n            result = None\r\n\r\n        if plot_dir:\r\n            self._engine.make_figures(plot_dir)\r\n\r\n        return result", "response": "Run the given function with the given args."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_error(self, err):\r\n        self.logger.debug(err)\r\n        stack = err.get('stack', [])\r\n        if not err['message'].startswith('parse error:'):\r\n            err['message'] = 'error: ' + err['message']\r\n        errmsg = 'Octave evaluation error:\\n%s' % err['message']\r\n\r\n        if not isinstance(stack, StructArray):\r\n            return errmsg\r\n\r\n        errmsg += '\\nerror: called from:'\r\n        for item in stack[:-1]:\r\n            errmsg += '\\n    %(name)s at line %(line)d' % item\r\n            try:\r\n                errmsg += ', column %(column)d' % item\r\n            except Exception:\r\n                pass\r\n        return errmsg", "response": "Create a traceback for an Octave evaluation error."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the documentation of a named function.", "response": "def _get_doc(self, name):\r\n        \"\"\"\r\n        Get the documentation of an Octave procedure or object.\r\n\r\n        Parameters\r\n        ----------\r\n        name : str\r\n            Function name to search for.\r\n\r\n        Returns\r\n        -------\r\n        out : str\r\n          Documentation string.\r\n\r\n        Raises\r\n        ------\r\n        Oct2PyError\r\n           If the procedure or object function has a syntax error.\r\n\r\n        \"\"\"\r\n        doc = 'No documentation for %s' % name\r\n\r\n        engine = self._engine\r\n\r\n        doc = engine.eval('help(\"%s\")' % name, silent=True)\r\n\r\n        if 'syntax error:' in doc.lower():\r\n            raise Oct2PyError(doc)\r\n\r\n        if 'error:' in doc.lower():\r\n            doc = engine.eval('type(\"%s\")' % name, silent=True)\r\n            doc = '\\n'.join(doc.splitlines()[:3])\r\n\r\n        default = self.feval.__doc__\r\n        default = '        ' + default[default.find('func_args:'):]\r\n        default = '\\n'.join([line[8:] for line in default.splitlines()])\r\n\r\n        doc = '\\n'.join(doc.splitlines())\r\n        doc = '\\n' + doc + '\\n\\nParameters\\n----------\\n' + default\r\n        doc += '\\n**kwargs - Deprecated keyword arguments\\n\\n'\r\n        doc += 'Notes\\n-----\\n'\r\n        doc += 'Keyword arguments to dynamic functions are deprecated.\\n'\r\n        doc += 'The `plot_*` kwargs will be ignored, but the rest will\\n'\r\n        doc += 'used as key - value pairs as in version 3.x.\\n'\r\n        doc += 'Use `set_plot_settings()` for plot settings, and use\\n'\r\n        doc += '`func_args` directly for key - value pairs.'\r\n        return doc"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _exist(self, name):\r\n        cmd = 'exist(\"%s\")' % name\r\n        resp = self._engine.eval(cmd, silent=True).strip()\r\n        exist = int(resp.split()[-1])\r\n        if exist == 0:\r\n            msg = 'Value \"%s\" does not exist in Octave workspace'\r\n            raise Oct2PyError(msg % name)\r\n        return exist", "response": "Test whether a name exists and return the name code."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntests whether the name is an object.", "response": "def _isobject(self, name, exist):\r\n        \"\"\"Test whether the name is an object.\"\"\"\r\n        if exist in [2, 5]:\r\n            return False\r\n        cmd = 'isobject(%s)' % name\r\n        resp = self._engine.eval(cmd, silent=True).strip()\r\n        return resp == 'ans =  1'"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets or create a function pointer of the given name.", "response": "def _get_function_ptr(self, name):\r\n        \"\"\"Get or create a function pointer of the given name.\"\"\"\r\n        func = _make_function_ptr_instance\r\n        self._function_ptrs.setdefault(name, func(self, name))\r\n        return self._function_ptrs[name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets or create a user class of the given type.", "response": "def _get_user_class(self, name):\r\n        \"\"\"Get or create a user class of the given type.\"\"\"\r\n        self._user_classes.setdefault(name, _make_user_class(self, name))\r\n        return self._user_classes[name]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _cleanup(self):\r\n        self.exit()\r\n        workspace = osp.join(os.getcwd(), 'octave-workspace')\r\n        if osp.exists(workspace):\r\n            os.remove(workspace)", "response": "Clean up resources used by the session."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nplaying a demo script showing most of the oct2py api features. Parameters ========== delay : float Time between each command in seconds.", "response": "def demo(delay=1, interactive=True):\r\n    \"\"\"\r\n    Play a demo script showing most of the oct2py api features.\r\n\r\n    Parameters\r\n    ==========\r\n    delay : float\r\n        Time between each command in seconds.\r\n\r\n    \"\"\"\r\n    script = \"\"\"\r\n    #########################\r\n    # Oct2Py demo\r\n    #########################\r\n    import numpy as np\r\n    from oct2py import Oct2Py\r\n    oc = Oct2Py()\r\n    # basic commands\r\n    print(oc.abs(-1))\r\n    print(oc.upper('xyz'))\r\n    # plotting\r\n    oc.plot([1,2,3],'-o', 'linewidth', 2)\r\n    raw_input('Press Enter to continue...')\r\n    oc.close()\r\n    xx = np.arange(-2*np.pi, 2*np.pi, 0.2)\r\n    oc.surf(np.subtract.outer(np.sin(xx), np.cos(xx)))\r\n    raw_input('Press Enter to continue...')\r\n    oc.close()\r\n    # getting help\r\n    help(oc.svd)\r\n    # single vs. multiple return values\r\n    print(oc.svd(np.array([[1,2], [1,3]])))\r\n    U, S, V = oc.svd([[1,2], [1,3]], nout=3)\r\n    print(U, S, V)\r\n    # low level constructs\r\n    oc.eval(\"y=ones(3,3)\")\r\n    print(oc.pull(\"y\"))\r\n    oc.eval(\"x=zeros(3,3)\", verbose=True)\r\n    t = oc.eval('rand(1, 2)', verbose=True)\r\n    y = np.zeros((3,3))\r\n    oc.push('y', y)\r\n    print(oc.pull('y'))\r\n    from oct2py import Struct\r\n    y = Struct()\r\n    y.b = 'spam'\r\n    y.c.d = 'eggs'\r\n    print(y.c['d'])\r\n    print(y)\r\n    #########################\r\n    # Demo Complete!\r\n    #########################\r\n    \"\"\"\r\n    if not PY2:\r\n        script = script.replace('raw_input', 'input')\r\n\r\n    for line in script.strip().split('\\n'):\r\n        line = line.strip()\r\n        if not 'input(' in line:\r\n            time.sleep(delay)\r\n            print(\">>> {0}\".format(line))\r\n            time.sleep(delay)\r\n        if not interactive:\r\n            if 'plot' in line or 'surf' in line or 'input(' in line:\r\n                line = 'print()'\r\n        exec(line)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef kill_octave():\r\n    import os\r\n    if os.name == 'nt':\r\n        os.system('taskkill /im octave /f')\r\n    else:\r\n        os.system('killall -9 octave')\r\n        os.system('killall -9 octave-cli')\r\n    octave.restart()", "response": "Kill all Octave instances."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting a number of threads and verify each has a unique Octave session. Parameters ========== nthreads : int Number of threads to use. Raises ====== Oct2PyError If the thread does not sucessfully demonstrate independence.", "response": "def thread_check(nthreads=3):\r\n    \"\"\"\r\n    Start a number of threads and verify each has a unique Octave session.\r\n\r\n    Parameters\r\n    ==========\r\n    nthreads : int\r\n        Number of threads to use.\r\n\r\n    Raises\r\n    ======\r\n    Oct2PyError\r\n        If the thread does not sucessfully demonstrate independence.\r\n\r\n    \"\"\"\r\n    print(\"Starting {0} threads at {1}\".format(nthreads,\r\n                                               datetime.datetime.now()))\r\n    threads = []\r\n    for i in range(nthreads):\r\n        thread = ThreadClass()\r\n        thread.setDaemon(True)\r\n        thread.start()\r\n        threads.append(thread)\r\n    for thread in threads:\r\n        thread.join()\r\n    print('All threads closed at {0}'.format(datetime.datetime.now()))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self):\r\n        octave = Oct2Py()\r\n        # write the same variable name in each thread and read it back\r\n        octave.push('name', self.getName())\r\n        name = octave.pull('name')\r\n        now = datetime.datetime.now()\r\n        print(\"{0} got '{1}' at {2}\".format(self.getName(), name, now))\r\n        octave.exit()\r\n        try:\r\n            assert self.getName() == name\r\n        except AssertionError:  # pragma: no cover\r\n            raise Oct2PyError('Thread collision detected')\r\n        return", "response": "Create a unique instance of Octave and verify namespace uniqueness."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_file(path, session=None):\r\n    try:\r\n        data = loadmat(path, struct_as_record=True)\r\n    except UnicodeDecodeError as e:\r\n        raise Oct2PyError(str(e))\r\n    out = dict()\r\n    for (key, value) in data.items():\r\n        out[key] = _extract(value, session)\r\n    return out", "response": "Read the data from the given file path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_file(obj, path, oned_as='row', convert_to_float=True):\r\n    data = _encode(obj, convert_to_float)\r\n    try:\r\n        # scipy.io.savemat is not thread-save.\r\n        # See https://github.com/scipy/scipy/issues/7260\r\n        with _WRITE_LOCK:\r\n            savemat(path, data, appendmat=False, oned_as=oned_as,\r\n                    long_field_names=True)\r\n    except KeyError:  # pragma: no cover\r\n        raise Exception('could not save mat file')", "response": "Save a Python object to an Octave file on the given path."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert the Octave values to values suitable for Python.", "response": "def _extract(data, session=None):\r\n    \"\"\"Convert the Octave values to values suitable for Python.\r\n    \"\"\"\r\n    # Extract each item of a list.\r\n    if isinstance(data, list):\r\n        return [_extract(d, session) for d in data]\r\n\r\n    # Ignore leaf objects.\r\n    if not isinstance(data, np.ndarray):\r\n        return data\r\n\r\n    # Extract user defined classes.\r\n    if isinstance(data, MatlabObject):\r\n        cls = session._get_user_class(data.classname)\r\n        return cls.from_value(data)\r\n\r\n    # Extract struct data.\r\n    if data.dtype.names:\r\n        # Singular struct\r\n        if data.size == 1:\r\n            return _create_struct(data, session)\r\n        # Struct array\r\n        return StructArray(data, session)\r\n\r\n    # Extract cells.\r\n    if data.dtype.kind == 'O':\r\n        return Cell(data, session)\r\n\r\n    # Compress singleton values.\r\n    if data.size == 1:\r\n        return data.item()\r\n\r\n    # Compress empty values.\r\n    if data.size == 0:\r\n        if data.dtype.kind in 'US':\r\n            return ''\r\n        return []\r\n\r\n    # Return standard array.\r\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a struct from session data.", "response": "def _create_struct(data, session):\r\n    \"\"\"Create a struct from session data.\r\n    \"\"\"\r\n    out = Struct()\r\n    for name in data.dtype.names:\r\n        item = data[name]\r\n        # Extract values that are cells (they are doubly wrapped).\r\n        if isinstance(item, np.ndarray) and item.dtype.kind == 'O':\r\n            item = item.squeeze().tolist()\r\n        out[name] = _extract(item, session)\r\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting the Python values to values suitable to send to Octave.", "response": "def _encode(data, convert_to_float):\r\n    \"\"\"Convert the Python values to values suitable to send to Octave.\r\n    \"\"\"\r\n    ctf = convert_to_float\r\n\r\n    # Handle variable pointer.\r\n    if isinstance(data, (OctaveVariablePtr)):\r\n        return _encode(data.value, ctf)\r\n\r\n    # Handle a user defined object.\r\n    if isinstance(data, OctaveUserClass):\r\n        return _encode(OctaveUserClass.to_value(data), ctf)\r\n\r\n    # Handle a function pointer.\r\n    if isinstance(data, (OctaveFunctionPtr, MatlabFunction)):\r\n        raise Oct2PyError('Cannot write Octave functions')\r\n\r\n    # Handle matlab objects.\r\n    if isinstance(data, MatlabObject):\r\n        view = data.view(np.ndarray)\r\n        out = MatlabObject(data, data.classname)\r\n        for name in out.dtype.names:\r\n            out[name] = _encode(view[name], ctf)\r\n        return out\r\n\r\n    # Handle pandas series and dataframes\r\n    if isinstance(data, (DataFrame, Series)):\r\n        return _encode(data.values, ctf)\r\n\r\n    # Extract and encode values from dict-like objects.\r\n    if isinstance(data, dict):\r\n        out = dict()\r\n        for (key, value) in data.items():\r\n            out[key] = _encode(value, ctf)\r\n        return out\r\n\r\n    # Send None as nan.\r\n    if data is None:\r\n        return np.NaN\r\n\r\n    # Sets are treated like lists.\r\n    if isinstance(data, set):\r\n        return _encode(list(data), ctf)\r\n\r\n    # Lists can be interpreted as numeric arrays or cell arrays.\r\n    if isinstance(data, list):\r\n        if _is_simple_numeric(data):\r\n            return _encode(np.array(data), ctf)\r\n        return _encode(tuple(data), ctf)\r\n\r\n    # Tuples are handled as cells.\r\n    if isinstance(data, tuple):\r\n        obj = np.empty(len(data), dtype=object)\r\n        for (i, item) in enumerate(data):\r\n            obj[i] = _encode(item, ctf)\r\n        return obj\r\n\r\n    # Sparse data must be floating type.\r\n    if isinstance(data, spmatrix):\r\n        return data.astype(np.float64)\r\n\r\n    # Return other data types unchanged.\r\n    if not isinstance(data, np.ndarray):\r\n        return data\r\n\r\n    # Extract and encode data from object-like arrays.\r\n    if data.dtype.kind in 'OV':\r\n        out = np.empty(data.size, dtype=data.dtype)\r\n        for (i, item) in enumerate(data.ravel()):\r\n            if data.dtype.names:\r\n                for name in data.dtype.names:\r\n                    out[i][name] = _encode(item[name], ctf)\r\n            else:\r\n                out[i] = _encode(item, ctf)\r\n        return out.reshape(data.shape)\r\n\r\n    # Complex 128 is the highest supported by savemat.\r\n    if data.dtype.name == 'complex256':\r\n        return data.astype(np.complex128)\r\n\r\n    # Convert to float if applicable.\r\n    if ctf and data.dtype.kind in 'ui':\r\n        return data.astype(np.float64)\r\n\r\n    # Return standard array.\r\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntests if a list contains simple numeric data.", "response": "def _is_simple_numeric(data):\r\n    \"\"\"Test if a list contains simple numeric data.\"\"\"\r\n    for item in data:\r\n        if isinstance(item, set):\r\n            item = list(item)\r\n        if isinstance(item, list):\r\n            if not _is_simple_numeric(item):\r\n                return False\r\n        elif not isinstance(item, (int, float, complex)):\r\n            return False\r\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_log(name=None):\r\n    if name is None:\r\n        name = 'oct2py'\r\n    else:\r\n        name = 'oct2py.' + name\r\n\r\n    log = logging.getLogger(name)\r\n    log.setLevel(logging.INFO)\r\n    return log", "response": "Returns a console logger."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _make_user_class(session, name):\n    attrs = session.eval('fieldnames(%s);' % name, nout=1).ravel().tolist()\n    methods = session.eval('methods(%s);' % name, nout=1).ravel().tolist()\n    ref = weakref.ref(session)\n\n    doc = _DocDescriptor(ref, name)\n    values = dict(__doc__=doc, _name=name, _ref=ref, _attrs=attrs,\n                  __module__='oct2py.dynamic')\n\n    for method in methods:\n        doc = _MethodDocDescriptor(ref, name, method)\n        cls_name = '%s_%s' % (name, method)\n        method_values = dict(__doc__=doc)\n        method_cls = type(str(cls_name),\n                          (OctaveUserClassMethod,), method_values)\n        values[method] = method_cls(ref, method, name)\n\n    for attr in attrs:\n        values[attr] = OctaveUserClassAttr(ref, attr, attr)\n\n    return type(str(name), (OctaveUserClass,), values)", "response": "Make an Octave class for a given class name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_value(cls, value):\n        instance = OctaveUserClass.__new__(cls)\n        instance._address = '%s_%s' % (instance._name, id(instance))\n        instance._ref().push(instance._address, value)\n        return instance", "response": "This is how an instance is created when we read a MatlabObject from a MAT file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting an OctaveUserClass instance to a value to send to Octave.", "response": "def to_value(cls, instance):\n        \"\"\"Convert to a value to send to Octave.\"\"\"\n        if not isinstance(instance, OctaveUserClass) or not instance._attrs:\n            return dict()\n        # Bootstrap a MatlabObject from scipy.io\n        # From https://github.com/scipy/scipy/blob/93a0ea9e5d4aba1f661b6bb0e18f9c2d1fce436a/scipy/io/matlab/mio5.py#L435-L443\n        # and https://github.com/scipy/scipy/blob/93a0ea9e5d4aba1f661b6bb0e18f9c2d1fce436a/scipy/io/matlab/mio5_params.py#L224\n        dtype = []\n        values = []\n        for attr in instance._attrs:\n            dtype.append((str(attr), object))\n            values.append(getattr(instance, attr))\n        struct = np.array([tuple(values)], dtype)\n        return MatlabObject(struct, instance._name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a pointer to the private object.", "response": "def to_pointer(cls, instance):\n        \"\"\"Get a pointer to the private object.\n        \"\"\"\n        return OctavePtr(instance._ref, instance._name, instance._address)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef document_func_view(serializer_class=None,\n                       response_serializer_class=None,\n                       filter_backends=None,\n                       permission_classes=None,\n                       authentication_classes=None,\n                       doc_format_args=list(),\n                       doc_format_kwargs=dict()):\n    \"\"\"\n    Decorator to make functional view documentable via drf-autodocs\n    \"\"\"\n    def decorator(func):\n        if serializer_class:\n            func.cls.serializer_class = func.view_class.serializer_class = serializer_class\n        if response_serializer_class:\n            func.cls.response_serializer_class = func.view_class.response_serializer_class = response_serializer_class\n        if filter_backends:\n            func.cls.filter_backends = func.view_class.filter_backends = filter_backends\n        if permission_classes:\n            func.cls.permission_classes = func.view_class.permission_classes = permission_classes\n        if authentication_classes:\n            func.cls.authentication_classes = func.view_class.authentication_classes = authentication_classes\n        if doc_format_args or doc_format_kwargs:\n            func.cls.__doc__ = func.view_class.__doc__ = getdoc(func).format(*doc_format_args, **doc_format_kwargs)\n        return func\n\n    return decorator", "response": "Decorator to make functional view documentable via drf - autodocs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if file is a valid RAR file.", "response": "def is_rarfile(filename):\n    \"\"\"Return true if file is a valid RAR file.\"\"\"\n    mode = constants.RAR_OM_LIST_INCSPLIT\n    archive = unrarlib.RAROpenArchiveDataEx(filename, mode=mode)\n    try:\n        handle = unrarlib.RAROpenArchiveEx(ctypes.byref(archive))\n    except unrarlib.UnrarException:\n        return False\n    unrarlib.RARCloseArchive(handle)\n    return (archive.OpenResult == constants.SUCCESS)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_header(self, handle):\n        header_data = unrarlib.RARHeaderDataEx()\n        try:\n            res = unrarlib.RARReadHeaderEx(handle, ctypes.byref(header_data))\n            rarinfo = RarInfo(header=header_data)\n        except unrarlib.ArchiveEnd:\n            return None\n        except unrarlib.MissingPassword:\n            raise RuntimeError(\"Archive is encrypted, password required\")\n        except unrarlib.BadPassword:\n            raise RuntimeError(\"Bad password for Archive\")\n        except unrarlib.UnrarException as e:\n            raise BadRarFile(str(e))\n\n        return rarinfo", "response": "Read the current member header into a RarInfo object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _process_current(self, handle, op, dest_path=None, dest_name=None):\n        unrarlib.RARProcessFileW(handle, op, dest_path, dest_name)", "response": "Process current member with op operation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload archive members metadata.", "response": "def _load_metadata(self, handle):\n        \"\"\"Load archive members metadata.\"\"\"\n        rarinfo = self._read_header(handle)\n        while rarinfo:\n            self.filelist.append(rarinfo)\n            self.NameToInfo[rarinfo.filename] = rarinfo\n            self._process_current(handle, constants.RAR_SKIP)\n            rarinfo = self._read_header(handle)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _open(self, archive):\n        try:\n            handle = unrarlib.RAROpenArchiveEx(ctypes.byref(archive))\n        except unrarlib.UnrarException:\n            raise BadRarFile(\"Invalid RAR file.\")\n        return handle", "response": "Open RAR archive file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef open(self, member, pwd=None):\n        if isinstance(member, RarInfo):\n            member = member.filename\n\n        archive = unrarlib.RAROpenArchiveDataEx(\n            self.filename, mode=constants.RAR_OM_EXTRACT)\n        handle = self._open(archive)\n\n        password = pwd or self.pwd\n        if password is not None:\n            unrarlib.RARSetPassword(handle, b(password))\n\n        # based on BrutuZ (https://github.com/matiasb/python-unrar/pull/4)\n        # and Cubixmeister work\n        data = _ReadIntoMemory()\n        c_callback = unrarlib.UNRARCALLBACK(data._callback)\n        unrarlib.RARSetCallback(handle, c_callback, 0)\n\n        try:\n            rarinfo = self._read_header(handle)\n            while rarinfo is not None:\n                if rarinfo.filename == member:\n                    self._process_current(handle, constants.RAR_TEST)\n                    break\n                else:\n                    self._process_current(handle, constants.RAR_SKIP)\n                rarinfo = self._read_header(handle)\n\n            if rarinfo is None:\n                data = None\n\n        except unrarlib.MissingPassword:\n            raise RuntimeError(\"File is encrypted, password required\")\n        except unrarlib.BadPassword:\n            raise RuntimeError(\"Bad password for File\")\n        except unrarlib.BadDataError:\n            if password is not None:\n                raise RuntimeError(\"File CRC error or incorrect password\")\n            else:\n                raise RuntimeError(\"File CRC error\")\n        except unrarlib.UnrarException as e:\n            raise BadRarFile(\"Bad RAR archive data: %s\" % str(e))\n        finally:\n            self._close(handle)\n\n        if data is None:\n            raise KeyError('There is no item named %r in the archive' % member)\n\n        # return file-like object\n        return data.get_bytes()", "response": "Open an archive and return a file - like object for the specified member."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef namelist(self):\n        names = []\n        for member in self.filelist:\n            names.append(member.filename)\n        return names", "response": "Return a list of file names in the archive."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the instance of RarInfo given name.", "response": "def getinfo(self, name):\n        \"\"\"Return the instance of RarInfo given 'name'.\"\"\"\n        rarinfo = self.NameToInfo.get(name)\n        if rarinfo is None:\n            raise KeyError('There is no item named %r in the archive' % name)\n        return rarinfo"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints a table of contents for the RAR file.", "response": "def printdir(self):\n        \"\"\"Print a table of contents for the RAR file.\"\"\"\n        print(\"%-46s %19s %12s\" % (\"File Name\", \"Modified    \", \"Size\"))\n        for rarinfo in self.filelist:\n            date = \"%d-%02d-%02d %02d:%02d:%02d\" % rarinfo.date_time[:6]\n            print(\"%-46s %s %12d\" % (\n                rarinfo.filename, date, rarinfo.file_size))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract(self, member, path=None, pwd=None):\n        if isinstance(member, RarInfo):\n            member = member.filename\n\n        if path is None:\n            path = os.getcwd()\n\n        self._extract_members([member], path, pwd)\n        return os.path.join(path, member)", "response": "Extract a member from the archive to the current working directory pwd is the pwd of the member."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extractall(self, path=None, members=None, pwd=None):\n        if members is None:\n            members = self.namelist()\n        self._extract_members(members, path, pwd)", "response": "Extract all members from the archive to the current working\n           directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _extract_members(self, members, targetpath, pwd):\n        archive = unrarlib.RAROpenArchiveDataEx(\n            self.filename, mode=constants.RAR_OM_EXTRACT)\n        handle = self._open(archive)\n\n        password = pwd or self.pwd\n        if password is not None:\n            unrarlib.RARSetPassword(handle, b(password))\n\n        try:\n            rarinfo = self._read_header(handle)\n            while rarinfo is not None:\n                if rarinfo.filename in members:\n                    self._process_current(\n                        handle, constants.RAR_EXTRACT, targetpath)\n                else:\n                    self._process_current(handle, constants.RAR_SKIP)\n                rarinfo = self._read_header(handle)\n        except unrarlib.MissingPassword:\n            raise RuntimeError(\"File is encrypted, password required\")\n        except unrarlib.BadPassword:\n            raise RuntimeError(\"Bad password for File\")\n        except unrarlib.BadDataError:\n            raise RuntimeError(\"File CRC Error\")\n        except unrarlib.UnrarException as e:\n            raise BadRarFile(\"Bad RAR archive data: %s\" % str(e))\n        finally:\n            self._close(handle)", "response": "Extracts the RarInfo objects members from the RAR archive at targetpath."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dostime_to_timetuple(dostime):\n    dostime = dostime >> 16\n    dostime = dostime & 0xffff\n    day = dostime & 0x1f\n    month = (dostime >> 5) & 0xf\n    year = 1980 + (dostime >> 9)\n    second = 2 * (dostime & 0x1f)\n    minute = (dostime >> 5) & 0x3f\n    hour = dostime >> 11\n    return (year, month, day, hour, minute, second)", "response": "Convert a RAR archive member DOS time to a Python time tuple."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _c_func(func, restype, argtypes, errcheck=None):\n    func.restype = restype\n    func.argtypes = argtypes\n    if errcheck is not None:\n        func.errcheck = errcheck\n    return func", "response": "Wrap c function setting prototype."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _load_savefile_header(file_h):\n    try:\n        raw_savefile_header = file_h.read(24)\n    except UnicodeDecodeError:\n        print(\"\\nMake sure the input file is opened in read binary, 'rb'\\n\")\n        raise InvalidEncoding(\"Could not read file; it might not be opened in binary mode.\")\n\n    # in case the capture file is not the same endianness as ours, we have to\n    # use the correct byte order for the file header\n    if raw_savefile_header[:4] in [struct.pack(\">I\", _MAGIC_NUMBER),\n                                   struct.pack(\">I\", _MAGIC_NUMBER_NS)]:\n        byte_order = b'big'\n        unpacked = struct.unpack('>IhhIIII', raw_savefile_header)\n    elif raw_savefile_header[:4] in [struct.pack(\"<I\", _MAGIC_NUMBER),\n                                     struct.pack(\"<I\", _MAGIC_NUMBER_NS)]:\n        byte_order = b'little'\n        unpacked = struct.unpack('<IhhIIII', raw_savefile_header)\n    else:\n        raise UnknownMagicNumber(\"No supported Magic Number found\")\n\n    (magic, major, minor, tz_off, ts_acc, snaplen, ll_type) = unpacked\n    header = __pcap_header__(magic, major, minor, tz_off, ts_acc, snaplen,\n                             ll_type, ctypes.c_char_p(byte_order),\n                             magic == _MAGIC_NUMBER_NS)\n    if not __validate_header__(header):\n        raise InvalidHeader(\"Invalid Header\")\n    else:\n        return header", "response": "Load and validate the header of a pcap file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a savefile as a pcap_savefile instance.", "response": "def load_savefile(input_file, layers=0, verbose=False, lazy=False):\n    \"\"\"\n    Parse a savefile as a pcap_savefile instance. Returns the savefile\n    on success and None on failure. Verbose mode prints additional information\n    about the file's processing. layers defines how many layers to descend and\n    decode the packet. input_file should be a Python file object.\n    \"\"\"\n    global VERBOSE\n    old_verbose = VERBOSE\n    VERBOSE = verbose\n\n    __TRACE__('[+] attempting to load {:s}', (input_file.name,))\n\n    header = _load_savefile_header(input_file)\n    if __validate_header__(header):\n        __TRACE__('[+] found valid header')\n        if lazy:\n            packets = _generate_packets(input_file, header, layers)\n            __TRACE__('[+] created packet generator')\n        else:\n            packets = _load_packets(input_file, header, layers)\n            __TRACE__('[+] loaded {:d} packets', (len(packets),))\n        sfile = pcap_savefile(header, packets)\n        __TRACE__('[+] finished loading savefile.')\n    else:\n        __TRACE__('[!] invalid savefile')\n        sfile = None\n\n    VERBOSE = old_verbose\n    return sfile"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread packets from the capture file.", "response": "def _load_packets(file_h, header, layers=0):\n    \"\"\"\n    Read packets from the capture file. Expects the file handle to point to\n    the location immediately after the header (24 bytes).\n    \"\"\"\n    pkts = []\n\n    hdrp = ctypes.pointer(header)\n    while True:\n        pkt = _read_a_packet(file_h, hdrp, layers)\n        if pkt:\n            pkts.append(pkt)\n        else:\n            break\n\n    return pkts"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _generate_packets(file_h, header, layers=0):\n    hdrp = ctypes.pointer(header)\n    while True:\n        pkt = _read_a_packet(file_h, hdrp, layers)\n        if pkt:\n            yield pkt\n        else:\n            break", "response": "Generator that yields packets from the capture file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _read_a_packet(file_h, hdrp, layers=0):\n    raw_packet_header = file_h.read(16)\n    if not raw_packet_header or len(raw_packet_header) != 16:\n        return None\n\n    # in case the capture file is not the same endianness as ours, we have to\n    # use the correct byte order for the packet header\n    if hdrp[0].byteorder == 'big':\n        packet_header = struct.unpack('>IIII', raw_packet_header)\n    else:\n        packet_header = struct.unpack('<IIII', raw_packet_header)\n    (timestamp, timestamp_us, capture_len, packet_len) = packet_header\n    raw_packet_data = file_h.read(capture_len)\n\n    if not raw_packet_data or len(raw_packet_data) != capture_len:\n        return None\n\n    if layers > 0:\n        layers -= 1\n        raw_packet = linklayer.clookup(hdrp[0].ll_type)(raw_packet_data,\n                                                        layers=layers)\n    else:\n        raw_packet = raw_packet_data\n\n    packet = pcap_packet(hdrp, timestamp, timestamp_us, capture_len,\n                         packet_len, raw_packet)\n    return packet", "response": "Reads a packet from the capture file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a raw IPv4 address return it in dotted quad notation.", "response": "def parse_ipv4(address):\n    \"\"\"\n    Given a raw IPv4 address (i.e. as an unsigned integer), return it in\n    dotted quad notation.\n    \"\"\"\n    raw = struct.pack('I', address)\n    octets = struct.unpack('BBBB', raw)[::-1]\n    ipv4 = b'.'.join([('%d' % o).encode('ascii') for o in bytearray(octets)])\n    return ipv4"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove the IP packet layer yielding the transport layer.", "response": "def strip_ip(packet):\n    \"\"\"\n    Remove the IP packet layer, yielding the transport layer.\n    \"\"\"\n    if not isinstance(packet, IP):\n        packet = IP(packet)\n    payload = packet.payload\n\n    return payload"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef strip_ethernet(packet):\n    if not isinstance(packet, Ethernet):\n        packet = Ethernet(packet)\n    payload = packet.payload\n\n    return payload", "response": "Strip the Ethernet frame from a packet."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_network(self, layers=1):\n        if layers:\n            ctor = payload_type(self.type)[0]\n            if ctor:\n                ctor = ctor\n                payload = self.payload\n                self.payload = ctor(payload, layers - 1)\n            else:\n                # if no type is found, do not touch the packet.\n                pass", "response": "Load the network packet into the internal memory."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls wifi packet discriminator and constructor.", "response": "def WIFI(frame, no_rtap=False):\n    \"\"\"calls wifi packet discriminator and constructor.\n    :frame: ctypes.Structure\n    :no_rtap: Bool\n    :return: packet object in success\n    :return: int\n        -1 on known error\n    :return: int\n        -2 on unknown error\n    \"\"\"\n    pack = None\n    try:\n        pack = WiHelper.get_wifi_packet(frame, no_rtap)\n    except Exception as e:\n        logging.exception(e)\n    return pack"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndiscriminate Wi - Fi packet and creates packet object.", "response": "def get_wifi_packet(frame, no_rtap=False):\n        \"\"\"Discriminates Wi-Fi packet and creates\n        packet object.\n        :frame: ctypes.Structure\n        :no_rtap: Bool\n        :return: obj\n            Wi-Fi packet\n        \"\"\"\n        _, packet = WiHelper._strip_rtap(frame)\n        frame_control = struct.unpack('BB', packet[:2])\n        cat = (frame_control[0] >> 2) & 0b0011\n        s_type = frame_control[0] >> 4\n\n        if cat not in _CATEGORIES_.keys():\n            logging.warning(\"unknown category: %d\" % (cat))\n            return Unknown(frame, no_rtap)\n\n        if s_type not in _SUBTYPES_[cat].keys():\n            logging.warning(\"unknown subtype %d in %s category\" % (s_type, _CATEGORIES_[cat]))\n            return Unknown(frame, no_rtap)\n\n        if cat == 0:\n            if s_type == 4:\n                return ProbeReq(frame, no_rtap)\n            elif s_type == 5:\n                return ProbeResp(frame, no_rtap)\n            elif s_type == 8:\n                return Beacon(frame, no_rtap)\n            else:\n                return Management(frame, no_rtap)\n        elif cat == 1:\n            if s_type == 11:\n                return RTS(frame, no_rtap)\n            elif s_type == 12:\n                return CTS(frame, no_rtap)\n            elif s_type == 9:\n                return BACK(frame, no_rtap)\n            else:\n                return Control(frame, no_rtap)\n        elif cat == 2:\n            if s_type == 8:\n                return QosData(frame, no_rtap, parse_amsdu=True)\n            else:\n                return Data(frame, no_rtap)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _strip_rtap(frame):\n        rtap_len = WiHelper.__get_rtap_len(frame)\n        rtap = frame[:rtap_len]\n        packet = frame[rtap_len:]\n        return rtap, packet", "response": "strip injected radiotap header."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstrip the present bit from the given payload and return a namedtuple containing the fields that are present in the radiotap meta - data.", "response": "def strip_present(payload):\n        \"\"\"strip(4 byte) radiotap.present. Those are flags that\n        identify existence of incoming radiotap meta-data.\n        :idx: int\n        :return: str\n        :return: namedtuple\n        \"\"\"\n        present = collections.namedtuple(\n            'present', ['tsft', 'flags', 'rate', 'channel', 'fhss',\n                        'dbm_antsignal', 'dbm_antnoise', 'lock_quality',\n                        'tx_attenuation', 'db_tx_attenuation', 'dbm_tx_power',\n                        'antenna', 'db_antsignal', 'db_antnoise', 'rxflags',\n                        'txflags', 'rts_retries', 'data_retries', 'xchannel',\n                        'mcs', 'ampdu', 'vht', 'rtap_ns', 'ven_ns', 'ext'])\n\n        val = struct.unpack('<L', payload)[0]\n        bits = format(val, '032b')[::-1]\n        present.tsft = int(bits[0])               # timer synchronization function\n        present.flags = int(bits[1])              # flags\n        present.rate = int(bits[2])               # rate\n        present.channel = int(bits[3])            # channel\n        present.fhss = int(bits[4])               # frequency hoping spread spectrum\n        present.dbm_antsignal = int(bits[5])      # dbm antenna signal\n        present.dbm_antnoise = int(bits[6])       # dbm antenna noinse\n        present.lock_quality = int(bits[7])       # quality of barker code lock\n        present.tx_attenuation = int(bits[8])     # transmitter attenuation\n        present.db_tx_attenuation = int(bits[9])  # decibel transmit attenuation\n        present.dbm_tx_power = int(bits[10])      # dbm transmit power\n        present.antenna = int(bits[11])           # antenna\n        present.db_antsignal = int(bits[12])      # db antenna signal\n        present.db_antnoise = int(bits[13])       # db antenna noise\n        present.rxflags = int(bits[14])           # receiver flags\n        present.txflags = int(bits[15])           # transmitter flags\n        present.rts_retries = int(bits[16])       # rts(request to send) retries\n        present.data_retries = int(bits[17])      # data retries\n        present.xchannel = int(bits[18])          # xchannel\n        present.mcs = int(bits[19])               # modulation and coding scheme\n        present.ampdu = int(bits[20])             # aggregated mac protocol data unit\n        present.vht = int(bits[21])               # very high throughput\n        present.rtap_ns = int(bits[29])           # radiotap namespace\n        present.ven_ns = int(bits[30])            # vendor namespace\n        present.ext = int(bits[31])               # extension\n\n        return present, bits"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef strip_tsft(self, idx):\n        idx = Radiotap.align(idx, 8)\n        mactime, = struct.unpack_from('<Q', self._rtap, idx)\n        return idx + 8, mactime", "response": "strips 8 byte from the radiotap. mactime\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef strip_flags(self, idx):\n        flags = collections.namedtuple(\n            'flags', ['cfp', 'preamble', 'wep', 'fragmentation', 'fcs',\n                      'datapad', 'badfcs', 'shortgi'])\n        val, = struct.unpack_from('<B', self._rtap, idx)\n        bits = format(val, '08b')[::-1]\n        flags.cfp = int(bits[0])\n        flags.preamble = int(bits[1])\n        flags.wep = int(bits[2])\n        flags.fragmentation = int(bits[3])\n        flags.fcs = int(bits[4])\n        flags.datapad = int(bits[5])\n        flags.badfcs = int(bits[6])\n        flags.shortgi = int(bits[7])\n        return idx + 1, flags", "response": "strips 1 byte from the internal flags field of the current radiotap."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstrip rate of the Mbps at the given index", "response": "def strip_rate(self, idx):\n        \"\"\"strip(1 byte) radiotap.datarate\n        note that, unit of this field is originally 0.5 Mbps\n        :idx: int\n        :return: int\n            idx\n        :return: double\n            rate in terms of Mbps\n        \"\"\"\n        val, = struct.unpack_from('<B', self._rtap, idx)\n        rate_unit = float(1) / 2    # Mbps\n        return idx + 1, rate_unit * val"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef strip_chan(self, idx):\n        chan = collections.namedtuple(\n            'chan', ['freq', 'turbo', 'cck', 'ofdm', 'two_g', 'five_g',\n                     'passive', 'dynamic', 'gfsk', 'gsm', 'static_turbo',\n                     'half_rate', 'quarter_rate'])\n\n        idx = Radiotap.align(idx, 2)\n        freq, flags, = struct.unpack_from('<HH', self._rtap, idx)\n        chan.freq = freq\n\n        bits = format(flags, '016b')[::-1]\n        chan.turbo = int(bits[4])\n        chan.cck = int(bits[5])\n        chan.ofdm = int(bits[6])\n        chan.two_g = int(bits[7])\n        chan.five_g = int(bits[8])\n        chan.passive = int(bits[9])\n        chan.dynamic = int(bits[10])\n        chan.gfsk = int(bits[11])\n        chan.gsm = int(bits[12])\n        chan.static_turbo = int(bits[13])\n        chan.half_rate = int(bits[14])\n        chan.quarter_rate = int(bits[15])\n        return idx + 4, chan", "response": "strips 2 byte channels from the internal data structure"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef strip_fhss(self, idx):\n        fhss = collections.namedtuple('fhss', ['hopset', 'pattern'])\n        fhss.hopset, fhss.pattern, = struct.unpack_from('<bb', self._rtap, idx)\n        return idx + 2, fhss", "response": "strip the FHSS from the internal structure"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef strip_dbm_antsignal(self, idx):\n        dbm_antsignal, = struct.unpack_from('<b', self._rtap, idx)\n        return idx + 1, dbm_antsignal", "response": "strips the dbm. ant_signal from the internal structure"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstripping dbm_antnoise from the internal structure", "response": "def strip_dbm_antnoise(self, idx):\n        \"\"\"strip(1 byte) radiotap.dbm_antnoise\n        :idx: int\n        :return: int\n            idx\n        :return: int\n        \"\"\"\n        dbm_antnoise, = struct.unpack_from('<b', self._rtap, idx)\n        return idx + 1, dbm_antnoise"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstripping lock quality from the internal table", "response": "def strip_lock_quality(self, idx):\n        \"\"\"strip(2 byte) lock quality\n        :idx: int\n        :return: int\n            idx\n        :return: int\n        \"\"\"\n        idx = Radiotap.align(idx, 2)\n        lock_quality, = struct.unpack_from('<H', self._rtap, idx)\n        return idx + 2, lock_quality"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef strip_tx_attenuation(self, idx):\n        idx = Radiotap.align(idx, 2)\n        tx_attenuation, = struct.unpack_from('<H', self._rtap, idx)\n        return idx + 2, tx_attenuation", "response": "strip tx_attenuation - strips the first byte from the internal array and returns the index and the last byte"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef strip_db_tx_attenuation(self, idx):\n        idx = Radiotap.align(idx, 2)\n        db_tx_attenuation, = struct.unpack_from('<H', self._rtap, idx)\n        return idx + 2, db_tx_attenuation", "response": "strip db_tx_attenuation - strips db_tx_attenuation - return the index and db_tx_attenuation - 2 byte"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef strip_dbm_tx_power(self, idx):\n        idx = Radiotap.align(idx, 1)\n        dbm_tx_power, = struct.unpack_from('<b', self._rtap, idx)\n        return idx + 1, dbm_tx_power", "response": "strip 1 byte from the internal table of DBM tx power"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstrip 1 byte radiotap. antenna idx", "response": "def strip_antenna(self, idx):\n        \"\"\"strip(1 byte) radiotap.antenna\n        :return: int\n            idx\n        :return: int\n        \"\"\"\n        antenna, = struct.unpack_from('<B', self._rtap, idx)\n        return idx + 1, antenna"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef strip_db_antsignal(self, idx):\n        db_antsignal, = struct.unpack_from('<B', self._rtap, idx)\n        return idx + 1, db_antsignal", "response": "strip 1 byte from radiotap. db_antsignal\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef strip_db_antnoise(self, idx):\n        db_antnoise, = struct.unpack_from('<B', self._rtap, idx)\n        return idx + 1, db_antnoise", "response": "strip 1 byte from radiotap. db_antnoise\n            idx"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef strip_rx_flags(self, idx):\n        rx_flags = collections.namedtuple('rx_flags', ['reserved', 'badplcp'])\n\n        idx = Radiotap.align(idx, 2)\n        flags, = struct.unpack_from('<H', self._rtap, idx)\n        flag_bits = format(flags, '08b')[::-1]\n        rx_flags.reserved = int(flag_bits[0])\n        rx_flags.badplcp = int(flag_bits[1])\n        return idx + 2, rx_flags", "response": "strips the rx flags from the internal structure"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef strip_tx_flags(self, idx):\n        idx = Radiotap.align(idx, 2)\n        tx_flags, = struct.unpack_from('<B', self._rtap, idx)\n        return idx + 1, tx_flags", "response": "strip tx_flags - strips tx_flags from the internal structure"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstrip 1 byte from the rts_retries structure and returns the index and the remaining rts_retries bytes.", "response": "def strip_rts_retries(self, idx):\n        \"\"\"strip(1 byte) rts_retries\n        :idx: int\n        :return: int\n            idx\n        :return: int\n        \"\"\"\n        rts_retries, = struct.unpack_from('<B', self._rtap, idx)\n        return idx + 1, rts_retries"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstrip 1 byte from the data_retries field of the record", "response": "def strip_data_retries(self, idx):\n        \"\"\"strip(1 byte) data_retries\n        :idx: int\n        :return: int\n            idx\n        :return: int\n        \"\"\"\n        data_retries, = struct.unpack_from('<B', self._rtap, idx)\n        return idx + 1, data_retries"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef strip_xchannel(self, idx):\n        xchannel = collections.namedtuple(\n            'xchannel', ['flags', 'freq', 'channel', 'max_power'])\n\n        flags = collections.namedtuple(\n            'flags', ['turbo', 'cck', 'ofdm', 'two_g', 'five_g', 'passive',\n                      'dynamic', 'gfsk', 'gsm', 'sturbo', 'hafl', 'quarter',\n                      'ht_20', 'ht_40u', 'ht_40d'])\n\n        idx = Radiotap.align(idx, 2)\n        flag_val, freq, channel, max_power = struct.unpack_from('<lHBB', self._rtap, idx)\n\n        xchannel.freq = freq\n        xchannel.channel = channel\n        xchannel.max_power = max_power\n\n        bits = format(flag_val, '032b')[::-1]\n        flags.turbo = int(bits[4])\n        flags.cck = int(bits[5])\n        flags.ofdm = int(bits[6])\n        flags.two_g = int(bits[7])\n        flags.five_g = int(bits[8])\n        flags.passive = int(bits[9])\n        flags.dynamic = int(bits[10])\n        flags.gfsk = int(bits[11])\n        flags.gsm = int(bits[12])\n        flags.sturbo = int(bits[13])\n        flags.half = int(bits[14])\n        flags.quarter = int(bits[15])\n        flags.ht_20 = int(bits[16])\n        flags.ht_40u = int(bits[17])\n        flags.ht_40d = int(bits[18])\n        xchannel.flags = flags\n\n        return idx + 8, xchannel", "response": "Strip the X - Channel information from the current instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstripping 8 byte ampdu from the internal structure", "response": "def strip_ampdu(self, idx):\n        \"\"\"strip(8 byte) radiotap.ampdu\n        :idx: int\n        :return: int\n            idx\n        :return: collections.namedtuple\n        \"\"\"\n        ampdu = collections.namedtuple(\n            'ampdu', ['reference', 'crc_val', 'reservered', 'flags'])\n        flags = collections.namedtuple(\n            'flags', ['report_zerolen', 'is_zerolen', 'lastknown', 'last',\n                      'delim_crc_error'])\n\n        idx = Radiotap.align(idx, 4)\n        refnum, flag_vals, crc_val, reserved = struct.unpack_from('<LHBB', self._rtap, idx)\n        ampdu.flags = flags\n        ampdu.reference = refnum\n        ampdu.crc_val = crc_val\n        ampdu.reserved = reserved\n\n        bits = format(flag_vals, '032b')[::-1]\n        ampdu.flags.report_zerolen = int(bits[0])\n        ampdu.flags.is_zerolen = int(bits[1])\n        ampdu.flags.lastknown = int(bits[2])\n        ampdu.flags.last = int(bits[3])\n        ampdu.flags.delim_crc_error = int(bits[4])\n        return idx + 8, ampdu"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef strip_vht(self, idx):\n        vht = collections.namedtuple(\n            'vht', ['known_bits', 'have_stbc', 'have_txop_ps', 'have_gi',\n                    'have_sgi_nsym_da', 'have_ldpc_extra', 'have_beamformed',\n                    'have_bw', 'have_gid', 'have_paid', 'stbc', 'txop_ps', 'gi',\n                    'sgi_nysm_da', 'ldpc_extra', 'group_id', 'partial_id',\n                    'beamformed', 'user_0', 'user_1', 'user_2', 'user_3'])\n        user = collections.namedtuple('user', ['nss', 'mcs', 'coding'])\n\n        idx = Radiotap.align(idx, 2)\n        known, flags, bw = struct.unpack_from('<HBB', self._rtap, idx)\n        mcs_nss_0, mcs_nss_1, mcs_nss_2, mcs_nss_3 = struct.unpack_from('<BBBB', self._rtap, idx + 4)\n        coding, group_id, partial_id = struct.unpack_from('<BBH', self._rtap, idx + 8)\n\n        known_bits = format(known, '032b')[::-1]\n        vht.known_bits = known_bits\n        vht.have_stbc = int(known_bits[0])         # Space Time Block Coding\n        vht.have_txop_ps = int(known_bits[1])      # TXOP_PS_NOT_ALLOWD\n        vht.have_gi = int(known_bits[2])           # Short/Long Guard Interval\n        vht.have_sgi_nsym_da = int(known_bits[3])  # Short Guard Interval Nsym Disambiguation\n        vht.have_ldpc_extra = int(known_bits[4])   # LDPC(Low Density Parity Check)\n        vht.have_beamformed = int(known_bits[5])   # Beamformed\n        vht.have_bw = int(known_bits[6])           # Bandwidth\n        vht.have_gid = int(known_bits[7])          # Group ID\n        vht.have_paid = int(known_bits[8])         # Partial AID\n\n        flag_bits = format(flags, '032b')[::-1]\n        vht.flag_bits = flag_bits\n        vht.stbc = int(flag_bits[0])\n        vht.txop_ps = int(flag_bits[1])\n        vht.gi = int(flag_bits[2])\n        vht.sgi_nysm_da = int(flag_bits[3])\n        vht.ldpc_extra = int(flag_bits[4])\n        vht.beamformed = int(flag_bits[5])\n        vht.group_id = group_id\n        vht.partial_id = partial_id\n\n        vht.bw = bw\n        vht.user_0 = user(None, None, None)\n        vht.user_1 = user(None, None, None)\n        vht.user_2 = user(None, None, None)\n        vht.user_3 = user(None, None, None)\n        for (i, mcs_nss) in enumerate([mcs_nss_0, mcs_nss_1, mcs_nss_2, mcs_nss_3]):\n            if mcs_nss:\n                nss = mcs_nss & 0xf0 >> 4\n                mcs = (mcs_nss & 0xf0) >> 4\n                coding = (coding & 2**i) >> i\n                if i == 0:\n                    vht.user_0 = user(nss, mcs, coding)\n                elif i == 1:\n                    vht.user_1 = user(nss, mcs, coding)\n                elif i == 2:\n                    vht.user_2 = user(nss, mcs, coding)\n                elif i == 3:\n                    vht.user_3 = user(nss, mcs, coding)\n\n        return idx + 12, vht", "response": "strips the vht entry from the internal buffer and returns the index in the internal buffer."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_protocol(self):\n        if self.present.mcs:\n            return '.11n'\n\n        if self.present.vht:\n            return '.11ac'\n\n        if self.present.channel and hasattr(self, 'chan'):\n            if self.chan.five_g:\n                if self.chan.ofdm:\n                    return '.11a'\n            elif self.chan.two_g:\n                if self.chan.cck:\n                    return '.11b'\n                elif self.chan.ofdm or self.chan.dynamic:\n                    return '.11g'\n        return 'None'", "response": "extract 802. 11 protocol from radiotap. channel. flags\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_shark_field(self, fields):\n        keys, exist, out = None, {}, None\n\n        if isinstance(fields, str):\n            fields = [fields]\n        elif not isinstance(fields, list):\n            logging.error('invalid input type')\n            return None\n\n        out = dict.fromkeys(fields)\n\n        if hasattr(self, '_shark_'):\n            exist.update(self._shark_)\n\n        if hasattr(self, '_s_shark_'):\n            exist.update(self._s_shark_)\n\n        if hasattr(self.radiotap, '_r_shark_'):\n            exist.update(self.radiotap._r_shark_)\n\n        keys = exist.keys()\n\n        for elem in fields:\n            if elem in keys:\n                obj_field, tmp = exist[elem], None\n                try:\n                    tmp = operator.attrgetter(obj_field)(self)\n                except AttributeError:\n                    tmp = None\n                if not tmp:\n                    try:\n                        tmp = operator.attrgetter(obj_field)(self.radiotap)\n                    except AttributeError:\n                        tmp = None\n                out[elem] = tmp\n        return out", "response": "get parameters via wireshark syntax."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_mac_addr(mac_addr):\n        mac_addr = bytearray(mac_addr)\n        mac = b':'.join([('%02x' % o).encode('ascii') for o in mac_addr])\n        return mac", "response": "converts bytes to mac addr format\n            11 : 22 : 33. aa. cc. cz"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef strip_mac_addrs(self):\n        qos_idx, seq_idx = 0, 0\n        sa, ta, ra, da, bssid = None, None, None, None, None\n\n        if self.to_ds == 1 and self.from_ds == 1:\n            (ra, ta, da) = struct.unpack('!6s6s6s', self._packet[4:22])\n            sa = struct.unpack('!6s', self._packet[24:30])[0]\n            qos_idx = 30\n            seq_idx = 22\n        elif self.to_ds == 0 and self.from_ds == 1:\n            (ra, ta, sa) = struct.unpack('!6s6s6s', self._packet[4:22])\n            qos_idx = 24\n            seq_idx = 22\n        elif self.to_ds == 1 and self.from_ds == 0:\n            (ra, ta, da) = struct.unpack('!6s6s6s', self._packet[4:22])\n            qos_idx = 24\n            seq_idx = 22\n        elif self.to_ds == 0 and self.from_ds == 0:\n            (ra, ta, bssid) = struct.unpack('!6s6s6s', self._packet[4:22])\n            qos_idx = 24\n            seq_idx = 22\n\n        if ta is not None:\n            ta = Wifi.get_mac_addr(ta)\n        if ra is not None:\n            ra = Wifi.get_mac_addr(ra)\n        if sa is not None:\n            sa = Wifi.get_mac_addr(sa)\n        if da is not None:\n            da = Wifi.get_mac_addr(da)\n        if bssid is not None:\n            bssid = Wifi.get_mac_addr(bssid)\n\n        return seq_idx, qos_idx, sa, ta, ra, da, bssid", "response": "strips the MAC addresses from the packet and returns the corresponding entry in the sequence control structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef strip_seq_cntrl(self, idx):\n        seq_cntrl = struct.unpack('H', self._packet[idx:idx + 2])[0]\n        seq_num = seq_cntrl >> 4\n        frag_num = seq_cntrl & 0x000f\n        return seq_num, frag_num", "response": "strips the seq and fram number information."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef strip_qos_cntrl(self, idx, prot_type):\n        qos_cntrl, = struct.unpack('H', self._packet[idx:idx + 2])\n        qos_cntrl_bits = format(qos_cntrl, '016b')[::-1]\n        qos_pri = qos_cntrl & 0x000f\n        qos_bit = int(qos_cntrl_bits[5])\n        qos_ack = int(qos_cntrl_bits[6:8], 2)\n        amsdupresent = 0\n        if prot_type == '.11ac':\n            amsdupresent = int(qos_cntrl_bits[7])\n        return 2, qos_pri, qos_bit, qos_ack, amsdupresent", "response": "strips the QoS control packet from the packet and returns the tuple."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef strip_ccmp(self, idx):\n        ccmp_extiv = None\n        if len(self._packet[idx:]) >= 8:\n            raw_bytes = self._packet[idx:idx + 8]\n            ccmp_extiv, = struct.unpack_from('Q', raw_bytes, 0)\n        return 8, ccmp_extiv", "response": "strips the CCMP extended initialization vector from the packet at the given index"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstrip a single mac servis data unit from the packet at the given index", "response": "def strip_msdu(self, idx):\n        \"\"\"strip single mac servis data unit(msdu)\n        see -> https://mrncciew.com/2014/11/01/cwap-802-11-data-frame-aggregation/\n        :idx: int\n        :return: dict\n            msdu\n        :return: int\n            number of processed bytes\n        \"\"\"\n        # length of msdu payload has to be multiple of 4,\n        # this guaranteed with padding\n        padding = 0\n        len_payload = 0\n        msdu = {\n            'llc': {},\n            'wlan.da': None,\n            'wlan.sa': None,\n            'payload': None,\n            'length': 0\n        }\n\n        (da_mac, sa_mac) = struct.unpack('!6s6s', self._packet[idx:idx + 12])\n        msdu['wlan.da'] = Wifi.get_mac_addr(da_mac)\n        msdu['wlan.sa'] = Wifi.get_mac_addr(sa_mac)\n        idx += 12\n        msdu['length'] = struct.unpack('!H', self._packet[idx:idx + 2])[0]\n        idx += 2\n        offset, msdu['llc'] = self.strip_llc(idx)\n        idx += offset\n        len_payload = msdu['length'] - offset\n        msdu['payload'] = self._packet[idx:idx + len_payload]\n        padding = 4 - (len_payload % 4)\n        return msdu, msdu['length'] + padding + 12"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef strip_llc(self, idx):\n        llc = {}\n        snap = 170\n        llc_dsap = struct.unpack('B', self._packet[idx:idx + 1])[0]\n        llc['dsap.dsap'] = llc_dsap >> 1\n        llc['dsap.ig'] = llc_dsap & 0b01\n        idx += 1\n        llc_ssap = struct.unpack('B', self._packet[idx:idx + 1])[0]\n        llc['ssap.sap'] = llc_ssap >> 1\n        llc['ssap.cr'] = llc_ssap & 0b01\n        idx += 1\n        if llc_dsap == snap and llc_ssap == snap:\n            llc_control = struct.unpack('B', self._packet[idx:idx + 1])[0]\n            llc['control.u_modifier_cmd'] = llc_control >> 2\n            llc['control.ftype'] = llc_control & 0x03\n            idx += 1\n            llc['organization_code'] = self._packet[idx:idx + 3]\n            idx += 3\n            llc['type'] = self._packet[idx:idx + 2]\n            return 8, llc\n        else:\n            return 4, llc", "response": "strips the 4 or 8 byte logical link control headers from the packet at the given index and returns the number of processed bytes and the object that is returned."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_tagged_params(raw_tagged_params):\n        fcs_len = 4  # wlan.fcs (4 bytes)\n        idx = 0\n        tagged_params = []\n        while idx < len(raw_tagged_params) - fcs_len:\n            tag_num, tag_len = struct.unpack('BB', raw_tagged_params[idx:idx + 2])\n            idx += 2\n            if len(raw_tagged_params) >= idx + tag_len:\n                param = {}\n                param['number'], param['length'] = tag_num, tag_len\n                payload = raw_tagged_params[idx:idx + tag_len]\n                if tag_num in MNGMT_TAGS:\n                    param['name'] = MNGMT_TAGS[tag_num]\n                    if MNGMT_TAGS[tag_num] == 'TAG_VENDOR_SPECIFIC_IE':\n                        param['payload'] = Management.parse_vendor_ie(payload)\n                    else:\n                        param['payload'] = payload\n                else:\n                    param['name'] = None\n                tagged_params.append(param)\n                idx += tag_len\n            else:\n                logging.warning('out tag length header points out of boundary')\n                log_msg = 'index: {p_idx}, pack_len: {p_len}'\n                log_msg = log_msg.format(p_idx=idx + tag_len,\n                                         p_len=len(raw_tagged_params))\n                logging.warning(log_msg)\n                return 1, tagged_params\n        return 0, tagged_params", "response": "parse tagged information elements wlan_mgt. tag\n        which has generic type - length - value structure\n        type - length - value structure\n        length - value structure\nosity - length of structure\nosity - payload of payload of payload of tag"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_fixed_capabils(payload):\n        if len(payload) != 2:\n            return None\n        capabils = {}\n        fix_cap = struct.unpack('H', payload)[0]\n        cap_bits = format(fix_cap, '016b')[::-1]\n        capabils['ess'] = int(cap_bits[0])             # Extended Service Set\n        capabils['ibss'] = int(cap_bits[1])            # Independent Basic Service Set\n        capabils['priv'] = int(cap_bits[4])            # Privacy\n        capabils['short_preamble'] = int(cap_bits[5])  # Short Preamble\n        capabils['pbcc'] = int(cap_bits[6])            # Packet Binary Convolutional Code\n        capabils['chan_agility'] = int(cap_bits[7])    # Channel Agility\n        capabils['spec_man'] = int(cap_bits[8])        # Spectrum Management\n        capabils['short_slot'] = int(cap_bits[10])     # Short Slot Time\n        capabils['apsd'] = int(cap_bits[11])           # Automatic Power Save Delivery\n        capabils['radio_meas'] = int(cap_bits[12])     # Radio Measurement\n        capabils['dss_ofdm'] = int(cap_bits[13])       # Direct Spread Spectrum\n        capabils['del_back'] = int(cap_bits[14])       # Delayed Block Acknowledgement\n        capabils['imm_back'] = int(cap_bits[15])       # Immediate Block Acknowledgement\n        return capabils", "response": "Returns dict of fixed capabilities from wlan_mgt. fixed. capabilities\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing vendor specific information element oui -> organizationally unique identifier", "response": "def parse_vendor_ie(payload):\n        \"\"\"parse vendor specific information element\n        oui -> organizationally unique identifier\n        first 3 bytes of mac addresses\n        see:https://www.wireshark.org/tools/oui-lookup.html\n        strip wlan_mgt.tag.oui(3 bytes),\n        wlan_mgt.tag.vendor.oui.type(1 byte)\n        wlan_mgt.tag.vendor.data (varies)\n        :payload: ctypes.structure\n        :return: dict\n            {'oui':00-11-22, 'oui_type':1, 'oui_data':ctypes.structure}\n        \"\"\"\n        output = {}\n        oui = struct.unpack('BBB', payload[0:3])\n        oui = b'-'.join([('%02x' % o).encode('ascii') for o in oui])\n        oui_type = struct.unpack('B', payload[3:4])[0]\n        oui_data = payload[4:]\n        output['oui'] = oui.upper()\n        output['oui_type'] = oui_type\n        output['oui_data'] = oui_data\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstrip the fixed parameters from the payload and returns the timestamp interval and capabils", "response": "def strip_fixed_params(payload):\n        \"\"\"strip(12 byte) wlan_mgt.fixed.all\n        :payload: ctypes.structure\n        :return: int\n            timestamp\n        :return: int\n            beacon interval\n        :return: dict\n            capabilities\n        \"\"\"\n        if len(payload) != 12:\n            return None, None, None\n        idx = 0\n        timestamp = Management.get_timestamp(payload[idx:idx + 8])\n        idx += 8\n        interval = Management.get_interval(payload[idx:idx + 2])\n        idx += 2\n        capabils = Management.get_fixed_capabils(payload[idx:idx + 2])\n        return timestamp, interval, capabils"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_valid_mac_oui(mac_block):\n        if len(mac_block) != 8:\n            return 0\n        if ':' in mac_block:\n            if len(mac_block.split(':')) != 3:\n                return 0\n        elif '-' in mac_block:\n            if len(mac_block.split('-')) != 3:\n                return 0\n        return 1", "response": "checks whether the given mac block is in format of\n        00 - 11 - 22 or 00 - 11 - 22 or 00 - 11 - 22 or 00 - 11 - 22."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_fixed_capabils(self, capabils):\n        self.ess = capabils['ess']\n        self.ibss = capabils['ibss']\n        self.priv = capabils['priv']\n        self.short_preamble = capabils['short_preamble']\n        self.pbcc = capabils['pbcc']\n        self.chan_agility = capabils['chan_agility']\n        self.spec_man = capabils['spec_man']\n        self.short_slot = capabils['short_slot']\n        self.apsd = capabils['apsd']\n        self.radio_meas = capabils['radio_meas']\n        self.dss_ofdm = capabils['dss_ofdm']\n        self.del_back = capabils['del_back']\n        self.imm_back = capabils['imm_back']", "response": "set keys of capabils into fields of object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_vendor_ies(self, mac_block=None, oui_type=None):\n        vendor_ies = []\n        if mac_block is not None:\n            if Management.is_valid_mac_oui(mac_block):\n                mac_block = mac_block.upper()\n                if ':' in mac_block:\n                    mac_block.replace(':', '-')\n            else:\n                logging.warning(\"invalid oui macblock\")\n                return None\n\n        for elem in self.tagged_params:\n            tag_num = elem['number']\n            if MNGMT_TAGS[tag_num] == 'TAG_VENDOR_SPECIFIC_IE':\n                if mac_block is None:\n                    vendor_ies.append(elem)\n                elif elem['payload']['oui'] == mac_block.encode('ascii'):\n                    if oui_type is None:\n                        vendor_ies.append(elem)\n                    elif elem['payload']['oui_type'] == oui_type:\n                        vendor_ies.append(elem)\n        return vendor_ies", "response": "get vendor information elements querying the tag"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_shark_field(self, fields):\n        out = super(BACK, self).get_shark_field(fields)\n        out.update({'acked_seqs': self.acked_seqs,\n                    'bitmap_str': self.bitmap_str})\n        return out", "response": "Returns a dictionary of the shark fields for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstrip the cntrl from the payload and returns the ackpolicy and multitid", "response": "def strip_cntrl(payload):\n        \"\"\"strip(2 byte) wlan.ba.control\n        :payload: ctypes.structure\n        :return: int\n            multitid (tid: traffic indicator)\n        :return: int\n            ackpolicy\n        \"\"\"\n        cntrl = struct.unpack('H', payload)[0]\n        cntrl_bits = format(cntrl, '016b')[::-1]\n        ackpolicy = int(cntrl_bits[0])\n        multitid = int(cntrl_bits[1])\n        return ackpolicy, multitid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef strip_ssc(payload):\n        ssc = struct.unpack('H', payload)[0]\n        ssc_seq = ssc >> 4\n        ssc_frag = ssc & 0x000f\n        return ssc_seq, ssc_frag", "response": "strips the SSC from the given payload and returns the sequence and fragment number of the SSC."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstrip 8 byte bitmap", "response": "def strip_bitmap_str(payload):\n        \"\"\"strip(8 byte) wlan.ba.bm\n        :payload: ctypes.structure\n        :return: str\n            bitmap\n        \"\"\"\n        bitmap = struct.unpack('BBBBBBBB', payload)\n        bitmap_str = ''\n        for elem in bitmap:\n            bitmap_str += format(elem, '08b')[::-1]\n        return bitmap_str"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract acknowledged sequences from bitmap and starting sequence number.", "response": "def extract_acked_seqs(bitmap, ssc_seq):\n        \"\"\"extracts acknowledged sequences from bitmap and\n        starting sequence number.\n        :bitmap: str\n        :ssc_seq: int\n        :return: int[]\n            acknowledged sequence numbers\n        \"\"\"\n        acked_seqs = []\n        for idx, val in enumerate(bitmap):\n            if int(val) == 1:\n                seq = (ssc_seq + idx) % 4096\n                acked_seqs.append(seq)\n        return acked_seqs"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a request and gets a response from the Plivo REST API", "response": "def request(self, path, method=None, data={}):\n        \"\"\"sends a request and gets a response from the Plivo REST API\n\n        path: the URL (relative to the endpoint URL, after the /v1\n        method: the HTTP method to use, defaults to POST\n        data: for POST or PUT, a dict of data to send\n\n        returns Plivo response in XML or raises an exception on error\n        \"\"\"\n        if not path:\n            raise ValueError('Invalid path parameter')\n        if method and method not in ['GET', 'POST', 'DELETE', 'PUT']:\n            raise NotImplementedError(\n                'HTTP %s method not implemented' % method)\n\n        if path[0] == '/':\n            uri = self.url + path\n        else:\n            uri = self.url + '/' + path\n\n        if APPENGINE:\n            return json.loads(self._appengine_fetch(uri, data, method))\n        return json.loads(self._urllib2_fetch(uri, data, method))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrests Reload Plivo Config helper", "response": "def reload_config(self, call_params):\n        \"\"\"REST Reload Plivo Config helper\n        \"\"\"\n        path = '/' + self.api_version + '/ReloadConfig/'\n        method = 'POST'\n        return self.request(path, method, call_params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nresting Reload Plivo Cache Config helper", "response": "def reload_cache_config(self, call_params):\n        \"\"\"REST Reload Plivo Cache Config helper\n        \"\"\"\n        path = '/' + self.api_version + '/ReloadCacheConfig/'\n        method = 'POST'\n        return self.request(path, method, call_params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrest Group Call Helper", "response": "def group_call(self, call_params):\n        \"\"\"REST GroupCalls Helper\n        \"\"\"\n        path = '/' + self.api_version + '/GroupCall/'\n        method = 'POST'\n        return self.request(path, method, call_params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrests Transfer Live Call Helper", "response": "def transfer_call(self, call_params):\n        \"\"\"REST Transfer Live Call Helper\n        \"\"\"\n        path = '/' + self.api_version + '/TransferCall/'\n        method = 'POST'\n        return self.request(path, method, call_params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrests Hangup All Live Calls Helper", "response": "def hangup_all_calls(self):\n        \"\"\"REST Hangup All Live Calls Helper\n        \"\"\"\n        path = '/' + self.api_version + '/HangupAllCalls/'\n        method = 'POST'\n        return self.request(path, method)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hangup_call(self, call_params):\n        path = '/' + self.api_version + '/HangupCall/'\n        method = 'POST'\n        return self.request(path, method, call_params)", "response": "Hangup a live call"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrests Schedule Hangup Helper", "response": "def schedule_hangup(self, call_params):\n        \"\"\"REST Schedule Hangup Helper\n        \"\"\"\n        path = '/' + self.api_version + '/ScheduleHangup/'\n        method = 'POST'\n        return self.request(path, method, call_params)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cancel_scheduled_hangup(self, call_params):\n        path = '/' + self.api_version + '/CancelScheduledHangup/'\n        method = 'POST'\n        return self.request(path, method, call_params)", "response": "This method cancels a scheduled hangup"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nresting Conference Mute helper", "response": "def conference_mute(self, call_params):\n        \"\"\"REST Conference Mute helper\n        \"\"\"\n        path = '/' + self.api_version + '/ConferenceMute/'\n        method = 'POST'\n        return self.request(path, method, call_params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef play(self, call_params):\n        path = '/' + self.api_version + '/Play/'\n        method = 'POST'\n        return self.request(path, method, call_params)", "response": "REST Play something on a Call Helper\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef play_stop(self, call_params):\n        path = '/' + self.api_version + '/PlayStop/'\n        method = 'POST'\n        return self.request(path, method, call_params)", "response": "REST PlayStop on a Call Helper\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrests Schedule playing something on a call Helper", "response": "def schedule_play(self, call_params):\n        \"\"\"REST Schedule playing something on a call Helper\n        \"\"\"\n        path = '/' + self.api_version + '/SchedulePlay/'\n        method = 'POST'\n        return self.request(path, method, call_params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cancel_scheduled_play(self, call_params):\n        path = '/' + self.api_version + '/CancelScheduledPlay/'\n        method = 'POST'\n        return self.request(path, method, call_params)", "response": "This method cancels a scheduled play"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrests Add soundtouch audio effects to a Call", "response": "def sound_touch(self, call_params):\n        \"\"\"REST Add soundtouch audio effects to a Call\n        \"\"\"\n        path = '/' + self.api_version + '/SoundTouch/'\n        method = 'POST'\n        return self.request(path, method, call_params)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrest Remove soundtouch audio effects on a Call", "response": "def sound_touch_stop(self, call_params):\n        \"\"\"REST Remove soundtouch audio effects on a Call\n        \"\"\"\n        path = '/' + self.api_version + '/SoundTouchStop/'\n        method = 'POST'\n        return self.request(path, method, call_params)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrest Send digits to a Call", "response": "def send_digits(self, call_params):\n        \"\"\"REST Send digits to a Call\n        \"\"\"\n        path = '/' + self.api_version + '/SendDigits/'\n        method = 'POST'\n        return self.request(path, method, call_params)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef conference_unmute(self, call_params):\n        path = '/' + self.api_version + '/ConferenceUnmute/'\n        method = 'POST'\n        return self.request(path, method, call_params)", "response": "REST Conference Unmute helper"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef conference_kick(self, call_params):\n        path = '/' + self.api_version + '/ConferenceKick/'\n        method = 'POST'\n        return self.request(path, method, call_params)", "response": "REST Conference Kick helper"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrests Conference Hangup helper", "response": "def conference_hangup(self, call_params):\n        \"\"\"REST Conference Hangup helper\n        \"\"\"\n        path = '/' + self.api_version + '/ConferenceHangup/'\n        method = 'POST'\n        return self.request(path, method, call_params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrest Conference Deaf helper", "response": "def conference_deaf(self, call_params):\n        \"\"\"REST Conference Deaf helper\n        \"\"\"\n        path = '/' + self.api_version + '/ConferenceDeaf/'\n        method = 'POST'\n        return self.request(path, method, call_params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrests Conference Undeaf helper", "response": "def conference_undeaf(self, call_params):\n        \"\"\"REST Conference Undeaf helper\n        \"\"\"\n        path = '/' + self.api_version + '/ConferenceUndeaf/'\n        method = 'POST'\n        return self.request(path, method, call_params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef conference_record_start(self, call_params):\n        path = '/' + self.api_version + '/ConferenceRecordStart/'\n        method = 'POST'\n        return self.request(path, method, call_params)", "response": "REST Conference Record Start"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef conference_record_stop(self, call_params):\n        path = '/' + self.api_version + '/ConferenceRecordStop/'\n        method = 'POST'\n        return self.request(path, method, call_params)", "response": "This method stops a conference record for a specific set of attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef conference_play(self, call_params):\n        path = '/' + self.api_version + '/ConferencePlay/'\n        method = 'POST'\n        return self.request(path, method, call_params)", "response": "REST Conference Play helper"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresting Conference Speak helper", "response": "def conference_speak(self, call_params):\n        \"\"\"REST Conference Speak helper\n        \"\"\"\n        path = '/' + self.api_version + '/ConferenceSpeak/'\n        method = 'POST'\n        return self.request(path, method, call_params)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef conference_list(self, call_params):\n        path = '/' + self.api_version + '/ConferenceList/'\n        method = 'POST'\n        return self.request(path, method, call_params)", "response": "REST Conference List Helper\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresting Conference List Members Helper", "response": "def conference_list_members(self, call_params):\n        \"\"\"REST Conference List Members Helper\n        \"\"\"\n        path = '/' + self.api_version + '/ConferenceListMembers/'\n        method = 'POST'\n        return self.request(path, method, call_params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _xml(self, root):\n        element = root.createElement(self.name)\n\n        # Add attributes\n        keys = self.attrs.keys()\n        keys.sort()\n        for a in keys:\n            element.setAttribute(a, self.attrs[a])\n\n        if self.body:\n            text = root.createTextNode(self.body)\n            element.appendChild(text)\n\n        for c in self.elements:\n            element.appendChild(c._xml(root))\n\n        return element", "response": "Return an XML element representing this element."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate a request from plivo", "response": "def validateRequest(self, uri, postVars, expectedSignature):\n        \"\"\"validate a request from plivo\n\n        uri: the full URI that Plivo requested on your server\n        postVars: post vars that Plivo sent with the request\n        expectedSignature: signature in HTTP X-Plivo-Signature header\n\n        returns true if the request passes validation, false if not\n        \"\"\"\n\n        # append the POST variables sorted by key to the uri\n        s = uri\n        for k, v in sorted(postVars.items()):\n            s += k + v\n\n        # compute signature and compare signatures\n        return (base64.encodestring(hmac.new(self.auth_token, s, sha1).digest()).\\\n            strip() == expectedSignature)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_node(self,label):\n      '''Return a node with label. Create node if label is new'''\n      try:\n          n = self._nodes[label]\n      except KeyError:\n          n = Node()\n          n['label'] = label\n          self._nodes[label]=n\n      return n", "response": "Return a node with label. Create node if it does not exist."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd an edge between nodes n1 and n2.", "response": "def add_edge(self, n1_label, n2_label,directed=False):\n      \"\"\"\n      Get or create edges using get_or_create_node\n      \"\"\"\n      n1 = self.add_node(n1_label)\n      n2 = self.add_node(n2_label)\n      e = Edge(n1, n2, directed)\n      self._edges.append(e)\n      return e"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a DOM into a Graph object.", "response": "def parse_dom(dom):\n        \"\"\"Parse dom into a Graph.\n\n        :param dom: dom as returned by minidom.parse or minidom.parseString\n        :return: A Graph representation\n        \"\"\"\n        root = dom.getElementsByTagName(\"graphml\")[0]\n        graph = root.getElementsByTagName(\"graph\")[0]\n        name = graph.getAttribute('id')\n\n        g = Graph(name)\n\n        # # Get attributes\n        # attributes = []\n        # for attr in root.getElementsByTagName(\"key\"):\n        #     attributes.append(attr)\n\n        # Get nodes\n        for node in graph.getElementsByTagName(\"node\"):\n            n = g.add_node(id=node.getAttribute('id'))\n\n            for attr in node.getElementsByTagName(\"data\"):\n                if attr.firstChild:\n                    n[attr.getAttribute(\"key\")] = attr.firstChild.data\n                else:\n                    n[attr.getAttribute(\"key\")] = \"\"\n\n        # Get edges\n        for edge in graph.getElementsByTagName(\"edge\"):\n            source = edge.getAttribute('source')\n            dest = edge.getAttribute('target')\n\n            # source/target attributes refer to IDs: http://graphml.graphdrawing.org/xmlns/1.1/graphml-structure.xsd\n            e = g.add_edge_by_id(source, dest)\n\n            for attr in edge.getElementsByTagName(\"data\"):\n                if attr.firstChild:\n                    e[attr.getAttribute(\"key\")] = attr.firstChild.data\n                else:\n                    e[attr.getAttribute(\"key\")] = \"\"\n\n        return g"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_string(self, string):\n        dom = minidom.parseString(string)\n        return self.parse_dom(dom)", "response": "Parse a string into a Graph.\n        object"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the other node that is in the tree", "response": "def node(self, node):\n        \"\"\"\n        Return the other node\n        \"\"\"\n\n        if node == self.node1:\n            return self.node2\n        elif node == self.node2:\n            return self.node1\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef consume(self, **kwargs):\n        kwargs.setdefault('block', True)\n        try:\n            while True:\n                msg = self.get(**kwargs)\n                if msg is None:\n                    break\n                yield msg\n        except KeyboardInterrupt:\n            print; return", "response": "Return a generator that yields whenever a message is waiting in the the\n            queue. Will block if a KeyboardInterrupt is raised."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a message from the queue.", "response": "def get(self, block=False, timeout=None):\n        \"\"\"Return a message from the queue. Example:\n    \n        >>> queue.get()\n        'my message'\n        >>> queue.get()\n        'another message'\n        \n        :param block: whether or not to wait until a msg is available in\n            the queue before returning; ``False`` by default\n        :param timeout: when using :attr:`block`, if no msg is available\n            for :attr:`timeout` in seconds, give up and return ``None``\n        \"\"\"\n        if block:\n            if timeout is None:\n                timeout = 0\n            msg = self.__redis.blpop(self.key, timeout=timeout)\n            if msg is not None:\n                msg = msg[1]\n        else:\n            msg = self.__redis.lpop(self.key)\n        if msg is not None and self.serializer is not None:\n            msg = self.serializer.loads(msg)\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nput one or more messages onto the queue.", "response": "def put(self, *msgs):\n        \"\"\"Put one or more messages onto the queue. Example:\n        \n        >>> queue.put(\"my message\")\n        >>> queue.put(\"another message\")\n        \n        To put messages onto the queue in bulk, which can be significantly\n        faster if you have a large number of messages:\n        \n        >>> queue.put(\"my message\", \"another message\", \"third message\")\n        \"\"\"\n        if self.serializer is not None:\n            msgs = map(self.serializer.dumps, msgs)\n        self.__redis.rpush(self.key, *msgs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef worker(self, *args, **kwargs):\n        def decorator(worker):\n            @wraps(worker)\n            def wrapper(*args):\n                for msg in self.consume(**kwargs):\n                    worker(*args + (msg,))\n            return wrapper\n        if args:\n            return decorator(*args)\n        return decorator", "response": "Decorator for using a function as a queue worker."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_bytes(self, previous: bytes):\n        # First, validate the lengths.\n        if len(self.conditions) != len(self.body):\n            raise exc.CompileError(\"Conditions and body length mismatch!\")\n\n        bc = b\"\"\n\n        prev_len = len(previous)\n\n        # Loop over the conditions and bodies\n        for condition, body in zip(self.conditions, self.body):\n            # Generate the conditional data.\n            cond_bytecode = condition.to_bytecode(previous)\n            bc += cond_bytecode\n            # Complex calculation. First, generate the bytecode for all tokens in the body. Then\n            # we calculate the len() of that. We create a POP_JUMP_IF_FALSE operation that jumps\n            # to the instructions after the body code + 3 for the pop call. This is done for all\n            # chained IF calls, as if it was an elif call. Else calls are not possible to be\n            # auto-generated, but it is possible to emulate them using an elif call that checks\n            # for the opposite of the above IF.\n\n            # Call the _compile_func method from compiler to compile the body.\n            body_bc = compiler.compile_bytecode(body)\n\n            bdyl = len(body_bc)\n            # Add together the lengths.\n            gen_len = prev_len + len(cond_bytecode) + bdyl + 1\n            # Generate the POP_JUMP_IF_FALSE instruction\n            bc += generate_simple_call(tokens.POP_JUMP_IF_FALSE, gen_len)\n            # Add the body_bc\n            bc += body_bc\n\n            # Update previous_len\n            prev_len = len(previous) + len(bc)\n\n        return bc", "response": "Generate the Complex Code ahead. Comments have been added in as needed."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_bytes_35(self, previous: bytes):\n\n        # Calculations ahead.\n        bc = b\"\"\n\n        # Calculate the length of the iterator.\n        it_bc = util.generate_bytecode_from_obb(self.iterator, previous)\n        bc += it_bc\n\n        # Push a get_iter on.\n        bc += util.generate_bytecode_from_obb(tokens.GET_ITER, b\"\")\n        prev_len = len(previous) + len(bc)\n        # Calculate the bytecode for the body.\n        body_bc = b\"\"\n        for op in self._body:\n            # Add padding bytes to the bytecode to allow if blocks to work.\n            padded_bc = previous\n            # Add padding for SETUP_LOOP\n            padded_bc += b\"\\x00\\x00\\x00\"\n            padded_bc += bc\n            # Add padding for FOR_ITER\n            padded_bc += b\"\\x00\\x00\\x00\"\n            # Add previous body\n            padded_bc += body_bc\n            body_bc += util.generate_bytecode_from_obb(op, padded_bc)\n\n        # Add a JUMP_ABSOLUTE\n        body_bc += util.generate_simple_call(tokens.JUMP_ABSOLUTE, prev_len + 3)\n\n        # Add a POP_TOP\n        body_bc += util.generate_bytecode_from_obb(tokens.POP_BLOCK, b\"\")\n\n        # Calculate the right lengths.\n        # Add a FOR_ITER, using len(body_bc)\n        body_bc = util.generate_simple_call(tokens.FOR_ITER, len(body_bc) - 1) + body_bc\n        # Add the SETUP_LOOP call\n        bc = util.generate_simple_call(tokens.SETUP_LOOP, prev_len + len(body_bc) - 6) + bc + body_bc\n\n        return bc", "response": "A to - bytes version of the internal method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_bytes_36(self, previous: bytes):\n        # Calculations ahead.\n        bc = b\"\"\n\n        # Calculate the length of the iterator.\n        it_bc = util.generate_bytecode_from_obb(self.iterator, previous)\n        bc += it_bc\n\n        bc += util.ensure_instruction(tokens.GET_ITER)", "response": "A to - bytes specific to Python 3. 6 and above."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns the correct validator for given objects. Assumes all same type.", "response": "def validate_content(*objs):\n    \"\"\"Runs the correct validator for given `obj`ects. Assumes all same type\"\"\"\n    from .main import Collection, Module\n    validator = {\n        Collection: cnxml.validate_collxml,\n        Module: cnxml.validate_cnxml,\n    }[type(objs[0])]\n    return validator(*[obj.file for obj in objs])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_litezip(struct):\n    msgs = []\n\n    def _fmt_err(err):\n        return (Path(err.filename), \"{}:{} -- {}: {}\".format(*(err[1:])))\n\n    obj_by_type = {}\n    for obj in struct:\n        if not is_valid_identifier(obj.id):\n            msg = (obj.file.parent,\n                   \"{} is not a valid identifier\".format(obj.id),)\n            logger.info(\"{}: {}\".format(*msg))\n            msgs.append(msg)\n        obj_by_type.setdefault(type(obj), []).append(obj)\n\n    for obtype in obj_by_type:\n        content_msgs = list([_fmt_err(err) for err in\n                             validate_content(*obj_by_type[obtype])])\n        for msg in content_msgs:\n            logger.info(\"{}: {}\".format(*msg))\n        msgs.extend(content_msgs)\n    return msgs", "response": "Validate the given litezip as struct.\n    Returns a list of validation messages."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nensure that an instruction is Python 3. 6 + compatible.", "response": "def ensure_instruction(instruction: int) -> bytes:\n    \"\"\"\n    Wraps an instruction to be Python 3.6+ compatible. This does nothing on Python 3.5 and below.\n\n    This is most useful for operating on bare, single-width instructions such as\n    ``RETURN_FUNCTION`` in a version portable way.\n\n    :param instruction: The instruction integer to use.\n    :return: A safe bytes object, if applicable.\n    \"\"\"\n    if PY36:\n        return instruction.to_bytes(2, byteorder=\"little\")\n    else:\n        return instruction.to_bytes(1, byteorder=\"little\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a simple call for the current node.", "response": "def generate_simple_call(opcode: int, index: int):\n    \"\"\"\n    Generates a simple call, with an index for something.\n\n    :param opcode: The opcode to generate.\n    :param index: The index to use as an argument.\n    :return:\n    \"\"\"\n    bs = b\"\"\n    # add the opcode\n    bs += opcode.to_bytes(1, byteorder=\"little\")\n    # Add the index\n    if isinstance(index, int):\n        if PY36:\n            bs += index.to_bytes(1, byteorder=\"little\")\n        else:\n            bs += index.to_bytes(2, byteorder=\"little\")\n    else:\n        bs += index\n    return bs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_bytecode_from_obb(obb: object, previous: bytes) -> bytes:\n    # Generates bytecode from a specified object, be it a validator or an int or bytes even.\n    if isinstance(obb, pyte.superclasses._PyteOp):\n        return obb.to_bytes(previous)\n    elif isinstance(obb, (pyte.superclasses._PyteAugmentedComparator,\n                          pyte.superclasses._PyteAugmentedValidator._FakeMathematicalOP)):\n        return obb.to_bytes(previous)\n    elif isinstance(obb, pyte.superclasses._PyteAugmentedValidator):\n        obb.validate()\n        return obb.to_load()\n    elif isinstance(obb, int):\n        return obb.to_bytes((obb.bit_length() + 7) // 8, byteorder=\"little\") or b''\n    elif isinstance(obb, bytes):\n        return obb\n    else:\n        raise TypeError(\"`{}` was not a valid bytecode-encodable item\".format(obb))", "response": "Generates a bytecode from an object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_const_info(const_index, const_list):\n    argval = const_index\n    if const_list is not None:\n        try:\n            argval = const_list[const_index]\n        except IndexError:\n            raise ValidationError(\"Consts value out of range: {}\".format(const_index)) from None\n    return argval, repr(argval)", "response": "Helper to get optional details about a constant in a resource tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd arguments described in the usage string to the argument parser.", "response": "def add_to_parser(parser, usage, ignore_existing=False):\n    \"\"\"\n    Add arguments described in the usage string to the\n    parser. View more details at the <create_parser> docs\n\n    Args:\n        parser (ArgumentParser): parser to add arguments to\n        usage (str): Usage string in the format described above\n        ignore_existing (bool): Ignore any arguments that have already been defined\n    \"\"\"\n    usage = '\\n' + usage\n    first_line = [i for i in usage.split('\\n') if i][0]\n    indent = ' ' * (len(first_line) - len(first_line.lstrip(' ')))\n    usage = usage.replace('\\n' + indent, '\\n')\n    usage = usage.replace('\\n...', '')\n\n    defaults = {}\n    description, *descriptors = usage.split('\\n:')\n    description = description.replace('\\n', ' ').strip()\n    if description and (not parser.description or not ignore_existing):\n        parser.description = description\n    for descriptor in descriptors:\n        try:\n            options, *info = descriptor.split('\\n')\n            info = ' '.join(i for i in info if i).replace('    ', '')\n            if options.count(' ') == 1:\n                if options[0] == '-':\n                    short, long = options.split(' ')\n                    var_name = long.strip('-').replace('-', '_')\n                    parser.add_argument(short, long, dest=var_name, action='store_true', help=info)\n                    defaults[var_name] = False\n                else:\n                    short, typ = options.split(' ')\n                    parser.add_argument(short, type=types[typ], help=info)\n            else:\n                short, long, typ, default = options.split(' ')\n                info = info.rstrip() + '. Default: ' + default\n                default = '' if default == '-' else default\n                parser.add_argument(short, long, type=types[typ], default=default, help=info)\n        except ArgumentError:\n            if not ignore_existing:\n                raise\n        except Exception as e:\n            print(e.__class__.__name__ + ': ' + str(e))\n            print('While parsing:')\n            print(descriptor)\n            raise ValueError('Failed to create parser from usage string')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a byte string containing the bytecode of the given list of Pyte objects.", "response": "def compile_bytecode(code: list) -> bytes:\n    \"\"\"\n    Compiles Pyte objects into a bytecode list.\n\n    :param code: A list of objects to compile.\n    :return: The computed bytecode.\n    \"\"\"\n    bc = b\"\"\n    for i, op in enumerate(code):\n        try:\n            # Get the bytecode.\n            if isinstance(op, _PyteOp) or isinstance(op, _PyteAugmentedComparator):\n                bc_op = op.to_bytes(bc)\n            elif isinstance(op, int):\n                bc_op = op.to_bytes(1, byteorder=\"little\")\n            elif isinstance(op, bytes):\n                bc_op = op\n            else:\n                raise CompileError(\"Could not compile code of type {}\".format(type(op)))\n            bc += bc_op\n        except Exception as e:\n            print(\"Fatal compiliation error on operator {i} ({op}).\".format(i=i, op=op))\n            raise e\n\n    return bc"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsimulates the actions of the stack.", "response": "def _simulate_stack(code: list) -> int:\n    \"\"\"\n    Simulates the actions of the stack, to check safety.\n\n    This returns the maximum needed stack.\n    \"\"\"\n\n    max_stack = 0\n    curr_stack = 0\n\n    def _check_stack(ins):\n        if curr_stack < 0:\n            raise CompileError(\"Stack turned negative on instruction: {}\".format(ins))\n        if curr_stack > max_stack:\n            return curr_stack\n\n    # Iterate over the bytecode.\n    for instruction in code:\n        assert isinstance(instruction, dis.Instruction)\n        if instruction.arg is not None:\n            try:\n                effect = dis.stack_effect(instruction.opcode, instruction.arg)\n            except ValueError as e:\n                raise CompileError(\"Invalid opcode `{}` when compiling\"\n                                   .format(instruction.opcode)) from e\n        else:\n            try:\n                effect = dis.stack_effect(instruction.opcode)\n            except ValueError as e:\n                raise CompileError(\"Invalid opcode `{}` when compiling\"\n                                   .format(instruction.opcode)) from e\n        curr_stack += effect\n        # Re-check the stack.\n        _should_new_stack = _check_stack(instruction)\n        if _should_new_stack:\n            max_stack = _should_new_stack\n\n    return max_stack"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compile(code: list, consts: list, names: list, varnames: list,\n            func_name: str = \"<unknown, compiled>\",\n            arg_count: int = 0, kwarg_defaults: Tuple[Any] = (), use_safety_wrapper: bool = True):\n    \"\"\"\n    Compiles a set of bytecode instructions into a working function, using Python's bytecode\n    compiler.\n\n    :param code: A list of bytecode instructions.\n    :param consts: A list of constants to compile into the function.\n    :param names: A list of names to compile into the function.\n    :param varnames: A list of ``varnames`` to compile into the function.\n    :param func_name: The name of the function to use.\n    :param arg_count: The number of arguments this function takes. Must be ``<= len(varnames)``.\n    :param kwarg_defaults: A tuple of defaults for kwargs.\n    :param use_safety_wrapper: Use the safety wrapper? This hijacks SystemError to print better \\\n        stack traces.\n    \"\"\"\n    varnames = tuple(varnames)\n    consts = tuple(consts)\n    names = tuple(names)\n\n    # Flatten the code list.\n    code = util.flatten(code)\n\n    if arg_count > len(varnames):\n        raise CompileError(\"arg_count > len(varnames)\")\n\n    if len(kwarg_defaults) > len(varnames):\n        raise CompileError(\"len(kwarg_defaults) > len(varnames)\")\n\n    # Compile it.\n    bc = compile_bytecode(code)\n\n    dis.dis(bc)\n\n    # Check for a final RETURN_VALUE.\n    if PY36:\n        # TODO: Add Python 3.6 check\n        pass\n    else:\n        if bc[-1] != tokens.RETURN_VALUE:\n            raise CompileError(\n                \"No default RETURN_VALUE. Add a `pyte.tokens.RETURN_VALUE` to the end of your \"\n                \"bytecode if you don't need one.\")\n\n    # Set default flags\n    flags = 1 | 2 | 64\n\n    frame_data = inspect.stack()[1]\n\n    if sys.version_info[0:2] > (3, 3):\n        # Validate the stack.\n        stack_size = _simulate_stack(dis._get_instructions_bytes(\n            bc, constants=consts, names=names, varnames=varnames)\n        )\n    else:\n        warnings.warn(\"Cannot check stack for safety.\")\n        stack_size = 99\n\n    # Generate optimization warnings.\n    _optimize_warn_pass(dis._get_instructions_bytes(bc, constants=consts, names=names, varnames=varnames))\n\n    obb = types.CodeType(\n        arg_count,  # Varnames - used for arguments.\n        0,  # Kwargs are not supported yet\n        len(varnames),  # co_nlocals -> Non-argument local variables\n        stack_size,  # Auto-calculated\n        flags,  # 67 is default for a normal function.\n        bc,  # co_code - use the bytecode we generated.\n        consts,  # co_consts\n        names,  # co_names, used for global calls.\n        varnames,  # arguments\n        frame_data[1],  # use <unknown, compiled>\n        func_name,  # co_name\n        frame_data[2],  # co_firstlineno, ignore this.\n        b'',  # https://svn.python.org/projects/python/trunk/Objects/lnotab_notes.txt\n        (),  # freevars - no idea what this does\n        ()  # cellvars - used for nested functions - we don't use these.\n    )\n    # Update globals\n    f_globals = frame_data[0].f_globals\n\n    # Create a function type.\n    f = types.FunctionType(obb, f_globals)\n    f.__name__ = func_name\n    f.__defaults__ = kwarg_defaults\n\n    if use_safety_wrapper:\n        def __safety_wrapper(*args, **kwargs):\n            try:\n                return f(*args, **kwargs)\n            except SystemError as e:\n                if 'opcode' not in ' '.join(e.args):\n                    # Re-raise any non opcode related errors.\n                    raise\n                msg = \"Bytecode exception!\" \\\n                      \"\\nFunction {} returned an invalid opcode.\" \\\n                      \"\\nFunction dissection:\\n\\n\".format(f.__name__)\n                # dis sucks and always prints to stdout\n                # so we capture it\n                file = io.StringIO()\n                with contextlib.redirect_stdout(file):\n                    dis.dis(f)\n                msg += file.getvalue()\n                raise SystemError(msg) from e\n\n        returned_func = __safety_wrapper\n        returned_func.wrapped = f\n    else:\n        returned_func = f\n\n    # return the func\n    return returned_func", "response": "Compiles a list of bytecode instructions into a working function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving the parsed xml to an ElementTree parse the id from the content.", "response": "def _parse_document_id(elm_tree):\n    \"\"\"Given the parsed xml to an `ElementTree`,\n    parse the id from the content.\n\n    \"\"\"\n    xpath = '//md:content-id/text()'\n    return [x for x in elm_tree.xpath(xpath, namespaces=COLLECTION_NSMAP)][0]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _find_resources(directory, excludes=[]):\n    return sorted([r for r in directory.glob('*')\n                   if True not in [e(r) for e in excludes]])", "response": "Find all the resource paths in the directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the file structure given the path to a module directory.", "response": "def parse_module(path, excludes=None):\n    \"\"\"Parse the file structure to a data structure given the path to\n    a module directory.\n\n    \"\"\"\n    file = path / MODULE_FILENAME\n\n    if not file.exists():\n        raise MissingFile(file)\n    id = _parse_document_id(etree.parse(file.open()))\n\n    excludes = excludes or []\n    excludes.extend([\n        lambda filepath: filepath.name == MODULE_FILENAME,\n    ])\n\n    resources_paths = _find_resources(path, excludes=excludes)\n    resources = tuple(_resource_from_path(res) for res in resources_paths)\n\n    return Module(id, file, resources)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_collection(path, excludes=None):\n    file = path / COLLECTION_FILENAME\n    if not file.exists():\n        raise MissingFile(file)\n    id = _parse_document_id(etree.parse(file.open()))\n\n    excludes = excludes or []\n    excludes.extend([\n        lambda filepath: filepath.name == COLLECTION_FILENAME,\n        lambda filepath: filepath.is_dir(),\n    ])\n    resources_paths = _find_resources(path, excludes=excludes)\n    resources = tuple(_resource_from_path(res) for res in resources_paths)\n\n    return Collection(id, file, resources)", "response": "Parse a file structure given the path to\n    a collection directory."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a litezip file structure given the path to the litezip directory.", "response": "def parse_litezip(path):\n    \"\"\"Parse a litezip file structure to a data structure given the path\n    to the litezip directory.\n\n    \"\"\"\n    struct = [parse_collection(path)]\n    struct.extend([parse_module(x) for x in path.iterdir()\n                   if x.is_dir() and x.name.startswith('m')])\n    return tuple(sorted(struct))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_completezip(path):\n    for filepath in path.glob('**/index_auto_generated.cnxml'):\n        filepath.rename(filepath.parent / 'index.cnxml')\n        logger.debug('removed {}'.format(filepath))\n    for filepath in path.glob('**/index.cnxml.html'):\n        filepath.unlink()\n    return parse_litezip(path)", "response": "Converts a completezip file structure to a litezip file structure."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a sequence of Instructions in a bytecode string.", "response": "def _get_instructions_bytes(code, varnames=None, names=None, constants=None,\n                            cells=None, linestarts=None, line_offset=0):\n    \"\"\"Iterate over the instructions in a bytecode string.\n\n    Generates a sequence of Instruction namedtuples giving the details of each\n    opcode.  Additional information about the code's runtime environment\n    (e.g. variable names, constants) can be specified using optional\n    arguments.\n\n    \"\"\"\n    labels = dis.findlabels(code)\n    extended_arg = 0\n    starts_line = None\n    free = None\n    # enumerate() is not an option, since we sometimes process\n    # multiple elements on a single pass through the loop\n    n = len(code)\n    i = 0\n    while i < n:\n        op = code[i]\n        offset = i\n        if linestarts is not None:\n            starts_line = linestarts.get(i, None)\n            if starts_line is not None:\n                starts_line += line_offset\n        is_jump_target = i in labels\n        i = i + 1\n        arg = None\n        argval = None\n        argrepr = ''\n        if op >= dis.HAVE_ARGUMENT:\n            arg = code[i] + code[i + 1] * 256 + extended_arg\n            extended_arg = 0\n            i = i + 2\n            if op == dis.EXTENDED_ARG:\n                extended_arg = arg * 65536\n            # Set argval to the dereferenced value of the argument when\n            #  availabe, and argrepr to the string representation of argval.\n            #    _disassemble_bytes needs the string repr of the\n            #    raw name index for LOAD_GLOBAL, LOAD_CONST, etc.\n            argval = arg\n            if op in dis.hasconst:\n                argval, argrepr = dis._get_const_info(arg, constants)\n            elif op in dis.hasname:\n                argval, argrepr = dis._get_name_info(arg, names)\n            elif op in dis.hasjrel:\n                argval = i + arg\n                argrepr = \"to \" + repr(argval)\n            elif op in dis.haslocal:\n                argval, argrepr = dis._get_name_info(arg, varnames)\n            elif op in dis.hascompare:\n                argval = dis.cmp_op[arg]\n                argrepr = argval\n            elif op in dis.hasfree:\n                argval, argrepr = dis._get_name_info(arg, cells)\n            elif op in dis.hasnargs:\n                argrepr = \"%d positional, %d keyword pair\" % (code[i - 2], code[i - 1])\n        yield dis.Instruction(dis.opname[op], op,\n                              arg, argval, argrepr,\n                              offset, starts_line, is_jump_target)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _disassemble(self, lineno_width=3, mark_as_current=False):\n        fields = []\n        # Column: Source code line number\n        if lineno_width:\n            if self.starts_line is not None:\n                lineno_fmt = \"%%%dd\" % lineno_width\n                fields.append(lineno_fmt % self.starts_line)\n            else:\n                fields.append(' ' * lineno_width)\n        # Column: Current instruction indicator\n        if mark_as_current:\n            fields.append('-->')\n        else:\n            fields.append('   ')\n        # Column: Jump target marker\n        if self.is_jump_target:\n            fields.append('>>')\n        else:\n            fields.append('  ')\n        # Column: Instruction offset from start of code sequence\n        fields.append(repr(self.offset).rjust(4))\n        # Column: Opcode name\n        fields.append(self.opname.ljust(20))\n        # Column: Opcode argument\n        if self.arg is not None:\n            fields.append(repr(self.arg).rjust(5))\n            # Column: Opcode argument details\n            if self.argrepr:\n                fields.append('(' + self.argrepr + ')')\n        return ' '.join(fields).rstrip()", "response": "Format instruction details for inclusion in disassembly output\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the intersection of two lists. Assumes the lists are sorted by start positions.", "response": "def intersection(l1, l2):\n    '''Returns intersection of two lists.  Assumes the lists are sorted by start positions'''\n    if len(l1) == 0 or len(l2) == 0:\n        return []\n\n    out = []\n    l2_pos = 0\n\n    for l in l1:\n        while l2_pos < len(l2) and l2[l2_pos].end < l.start:\n            l2_pos += 1\n\n        if l2_pos == len(l2):\n            break\n\n        while l2_pos < len(l2) and l.intersects(l2[l2_pos]):\n            out.append(l.intersection(l2[l2_pos]))\n            l2_pos += 1\n\n        l2_pos = max(0, l2_pos - 1)\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merge_overlapping_in_list(l):\n    '''Sorts list, merges any overlapping intervals, and also adjacent intervals. e.g.\n       [0,1], [1,2] would be merge to [0,.2].'''\n    i = 0\n    l.sort()\n\n    while i < len(l) - 1:\n        u = l[i].union(l[i+1])\n        if u is not None:\n            l[i] = u\n            l.pop(i+1)\n        else:\n            i += 1", "response": "Sorts list merges any overlapping intervals and also adjacent intervals. e. g. A list of all entries in the list are merged to [ 0 1 2 )."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_contained_in_list(l):\n    '''Sorts list in place, then removes any intervals that are completely\n       contained inside another interval'''\n    i = 0\n    l.sort()\n\n    while i < len(l) - 1:\n       if l[i+1].contains(l[i]):\n           l.pop(i)\n       elif l[i].contains(l[i+1]):\n           l.pop(i+1)\n       else:\n           i += 1", "response": "Sorts list in place then removes any intervals that are completely\n       contained inside another interval"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the distance from the point to the interval. Zero if the point lies inside the interval.", "response": "def distance_to_point(self, p):\n        '''Returns the distance from the point to the interval. Zero if the point lies inside the interval.'''\n        if self.start <= p <= self.end:\n            return 0\n        else:\n            return min(abs(self.start - p), abs(self.end - p))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef intersects(self, i):\n        '''Returns true iff this interval intersects the interval i'''\n        return self.start <= i.end and i.start <= self.end", "response": "Returns true iff this interval intersects the interval i"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning true iff this interval contains the interval i", "response": "def contains(self, i):\n        '''Returns true iff this interval contains the interval i'''\n        return self.start <= i.start and i.end <= self.end"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef union(self, i):\n        '''If intervals intersect, returns their union, otherwise returns None'''\n        if self.intersects(i) or self.end + 1 == i.start or i.end + 1 == self.start:\n            return Interval(min(self.start, i.start), max(self.end, i.end))\n        else:\n            return None", "response": "Returns the union of two intervals."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef union_fill_gap(self, i):\n        '''Like union, but ignores whether the two intervals intersect or not'''\n        return Interval(min(self.start, i.start), max(self.end, i.end))", "response": "Like union but ignores whether the two intervals intersect or not"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef intersection(self, i):\n        '''If intervals intersect, returns their intersection, otherwise returns None'''\n        if self.intersects(i):\n            return Interval(max(self.start, i.start), min(self.end, i.end))\n        else:\n            return None", "response": "Returns the intersection of two sets or None if there is no intersection."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a FASTA or FASTQ file and returns a dictionary of all the sequence IDs that are available in memory.", "response": "def file_reader(fname, read_quals=False):\n    '''Iterates over a FASTA or FASTQ file, yielding the next sequence in the file until there are no more sequences'''\n    f = utils.open_file_read(fname)\n    line = f.readline()\n    phylip_regex = re.compile('^\\s*[0-9]+\\s+[0-9]+$')\n    gbk_regex = re.compile('^LOCUS\\s+\\S')\n\n    if line.startswith('>'):\n        seq = Fasta()\n        previous_lines[f] = line\n    elif line.startswith('##gff-version 3'):\n        seq = Fasta()\n        # if a GFF file, need to skip past all the annotation\n        # and get to the fasta sequences at the end of the file\n        while not line.startswith('>'):\n            line = f.readline()\n            if not line:\n                utils.close(f)\n                raise Error('No sequences found in GFF file \"' + fname + '\"')\n\n        seq = Fasta()\n        previous_lines[f] = line\n    elif line.startswith('ID   ') and line[5] != ' ':\n        seq = Embl()\n        previous_lines[f] = line\n    elif gbk_regex.search(line):\n        seq = Embl()\n        previous_lines[f] = line\n    elif line.startswith('@'):\n        seq = Fastq()\n        previous_lines[f] = line\n    elif phylip_regex.search(line):\n        # phylip format could be interleaved or not, need to look at next\n        # couple of lines to figure that out. Don't expect these files to\n        # be too huge, so just store all the sequences in memory\n        number_of_seqs, bases_per_seq = line.strip().split()\n        number_of_seqs = int(number_of_seqs)\n        bases_per_seq = int(bases_per_seq)\n        got_blank_line = False\n\n        first_line = line\n        seq_lines = []\n        while 1:\n            line = f.readline()\n            if line == '':\n                break\n            elif line == '\\n':\n                got_blank_line = True\n            else:\n                seq_lines.append(line.rstrip())\n        utils.close(f)\n\n        if len(seq_lines) == 1 or len(seq_lines) == number_of_seqs:\n            sequential = True\n        elif seq_lines[0][10] != ' ' and seq_lines[1][10] == ' ':\n            sequential = True\n        else:\n            sequential = False\n\n        # if the 11th char of second sequence line is a space,  then the file is sequential, e.g.:\n        # GAGCCCGGGC AATACAGGGT AT\n        # as opposed to:\n        # Salmo gairAAGCCTTGGC AGTGCAGGGT\n        if sequential:\n            current_id = None\n            current_seq = ''\n            for line in seq_lines:\n                if len(current_seq) == bases_per_seq or len(current_seq) == 0:\n                    if current_id is not None:\n                        yield Fasta(current_id, current_seq.replace('-', ''))\n                    current_seq = ''\n                    current_id, new_bases = line[0:10].rstrip(), line.rstrip()[10:]\n                else:\n                    new_bases = line.rstrip()\n\n                current_seq += new_bases.replace(' ','')\n\n            yield Fasta(current_id, current_seq.replace('-', ''))\n        else:\n            # seaview files start all seqs at pos >=12. Other files start\n            # their sequence at the start of the line\n            if seq_lines[number_of_seqs + 1][0] == ' ':\n                first_gap_pos = seq_lines[0].find(' ')\n                end_of_gap = first_gap_pos\n                while seq_lines[0][end_of_gap] == ' ':\n                    end_of_gap += 1\n                first_seq_base = end_of_gap\n            else:\n                first_seq_base = 10\n\n            seqs = []\n            for i in range(number_of_seqs):\n                name, bases = seq_lines[i][0:first_seq_base].rstrip(), seq_lines[i][first_seq_base:]\n                seqs.append(Fasta(name, bases))\n\n            for i in range(number_of_seqs, len(seq_lines)):\n                seqs[i%number_of_seqs].seq += seq_lines[i]\n\n            for fa in seqs:\n                fa.seq = fa.seq.replace(' ','').replace('-','')\n                yield fa\n\n        return\n    elif line == '':\n        utils.close(f)\n        return\n    else:\n        utils.close(f)\n        raise Error('Error determining file type from file \"' + fname + '\". First line is:\\n' + line.rstrip())\n\n    try:\n        while seq.get_next_from_file(f, read_quals):\n            yield seq\n    finally:\n        utils.close(f)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef subseq(self, start, end):\n        '''Returns Fasta object with the same name, of the bases from start to end, but not including end'''\n        return Fasta(self.id, self.seq[start:end])", "response": "Returns a Fasta object with the same name of the bases from start to end"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the prefix and suffix of a capillary read e. g. xxxxx. p1k or xxxxx. q1k Returns a tuple ( prefix suffix )", "response": "def split_capillary_id(self):\n        '''Gets the prefix and suffix of an name of a capillary read, e.g. xxxxx.p1k or xxxx.q1k. Returns a tuple (prefix, suffx)'''\n        try:\n            a = self.id.rsplit('.', 1)\n            if a[1].startswith('p'):\n                dir = 'fwd'\n            elif a[1].startswith('q'):\n                dir = 'rev'\n            else:\n                dir = 'unk'\n\n            return {'prefix': a[0], 'dir': dir, 'suffix':a[1]}\n        except:\n            raise Error('Error in split_capillary_id() on ID', self.id)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef expand_nucleotides(self):\n        '''Assumes sequence is nucleotides. Returns list of all combinations of redundant nucleotides. e.g. R is A or G, so CRT would have combinations CAT and CGT'''\n        s = list(self.seq)\n        for i in range(len(s)):\n            if s[i] in redundant_nts:\n                s[i] = ''.join(redundant_nts[s[i]])\n\n        seqs = []\n        for x in itertools.product(*s):\n            seqs.append(Fasta(self.id + '.' + str(len(seqs) + 1), ''.join(x)))\n        return seqs", "response": "Assumes sequence is nucleotides. Returns list of all combinations of redundant nucleotides. e. g. R is A or G so CRT would have combinations CAT and CGT."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef strip_illumina_suffix(self):\n        '''Removes any trailing /1 or /2 off the end of the name'''\n        if self.id.endswith('/1') or self.id.endswith('/2'):\n            self.id = self.id[:-2]", "response": "Removes any trailing illumina suffix off the end of the name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn true if the sequence is all Ns", "response": "def is_all_Ns(self, start=0, end=None):\n        '''Returns true if the sequence is all Ns (upper or lower case)'''\n        if end is not None:\n            if start > end:\n                raise Error('Error in is_all_Ns. Start coord must be <= end coord')\n            end += 1\n        else:\n            end = len(self)\n\n        if len(self) == 0:\n            return False\n        else:\n            return re.search('[^Nn]', self.seq[start:end]) is None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_insertions(self, skip=10, window=1, test=False):\n        '''Adds a random base within window bases around every skip bases. e.g. skip=10, window=1 means a random base added somwhere in theintervals [9,11], [19,21] ... '''\n        assert 2 * window < skip\n        new_seq = list(self.seq)\n        for i in range(len(self) - skip, 0, -skip):\n            pos = random.randrange(i - window, i + window + 1)\n            base = random.choice(['A', 'C', 'G', 'T'])\n            if test:\n                base = 'N'\n            new_seq.insert(pos, base)\n\n        self.seq = ''.join(new_seq)", "response": "Adds a random base within window bases around every skip bases. e. g. a random base added somwhere in the intervals [ 9 11 19 21..."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replace_bases(self, old, new):\n        '''Replaces all occurrences of 'old' with 'new' '''\n        self.seq = self.seq.replace(old, new)", "response": "Replaces all occurrences of old with new"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replace_interval(self, start, end, new):\n        '''Replaces the sequence from start to end with the sequence \"new\"'''\n        if start > end or start > len(self) - 1 or end > len(self) - 1:\n            raise Error('Error replacing bases ' + str(start) + '-' + str(end) + ' in sequence ' + self.id)\n\n        self.seq = self.seq[0:start] + new + self.seq[end + 1:]", "response": "Replaces the sequence from start to end with the sequence new"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds the positions of all gaps in the sequence that are at least min_length long. Returns a list of Intervals. Coords are zero - based", "response": "def gaps(self, min_length = 1):\n        '''Finds the positions of all gaps in the sequence that are at least min_length long. Returns a list of Intervals. Coords are zero-based'''\n        gaps = []\n        regex = re.compile('N+', re.IGNORECASE)\n        for m in regex.finditer(self.seq):\n             if m.span()[1] - m.span()[0] + 1 >= min_length:\n                 gaps.append(intervals.Interval(m.span()[0], m.span()[1] - 1))\n        return gaps"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the coordinates of contigs i. e. everything that s not a gap ( N or n. Returns a list of Intervals. Coords are zero - based.", "response": "def contig_coords(self):\n        '''Finds coords of contigs, i.e. everything that's not a gap (N or n). Returns a list of Intervals. Coords are zero-based'''\n        # contigs are the opposite of gaps, so work out the coords from the gap coords\n        gaps = self.gaps()\n\n        if len(gaps) == 0:\n            return [intervals.Interval(0, len(self) - 1)]\n\n        coords = [0]\n        for g in gaps:\n            if g.start == 0:\n                coords = [g.end + 1]\n            else:\n                coords += [g.start - 1, g.end + 1]\n\n        if coords[-1] < len(self):\n            coords.append(len(self) - 1)\n\n        return [intervals.Interval(coords[i], coords[i+1]) for i in range(0, len(coords)-1,2)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of ORFs that the sequence has starting on the given frame.", "response": "def orfs(self, frame=0, revcomp=False):\n        '''Returns a list of ORFs that the sequence has, starting on the given\n           frame. Each returned ORF is an interval.Interval object.\n           If revomp=True, then finds the ORFs of the reverse complement\n           of the sequence.'''\n        assert frame in [0,1,2]\n        if revcomp:\n            self.revcomp()\n\n        aa_seq = self.translate(frame=frame).seq.rstrip('X')\n        if revcomp:\n            self.revcomp()\n\n        orfs = _orfs_from_aa_seq(aa_seq)\n        for i in range(len(orfs)):\n            if revcomp:\n                start = len(self) - (orfs[i].end * 3 + 3) - frame\n                end = len(self) - (orfs[i].start * 3) - 1 - frame\n            else:\n                start = orfs[i].start * 3 + frame\n                end = orfs[i].end * 3 + 2 + frame\n\n            orfs[i] = intervals.Interval(start, end)\n\n        return orfs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_complete_orf(self):\n        '''Returns true iff length is >= 6, is a multiple of 3, and there is exactly one stop codon in the sequence and it is at the end'''\n        if len(self) %3 != 0 or len(self) < 6:\n            return False\n\n        orfs = self.orfs()\n        complete_orf = intervals.Interval(0, len(self) - 1)\n        for orf in orfs:\n            if orf == complete_orf:\n                return True\n        return False", "response": "Returns true iff length is > = 6 and there is exactly one stop codon in the sequence and it is at the end."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef looks_like_gene(self):\n        '''Returns true iff: length >=6, length is a multiple of 3, first codon is start, last codon is a stop and has no other stop codons'''\n        return self.is_complete_orf() \\\n          and len(self) >= 6 \\\n          and len(self) %3 == 0 \\\n          and self.seq[0:3].upper() in genetic_codes.starts[genetic_code]", "response": "Returns true iff the sequence looks like a gene"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntrying to make into a gene sequence. Returns a tuple ( new sequence strand frame ). Returns None.", "response": "def make_into_gene(self):\n        '''Tries to make into a gene sequence. Tries all three reading frames and both strands. Returns a tuple (new sequence, strand, frame) if it was successful. Otherwise returns None.'''\n        for reverse in [True, False]:\n            for frame in range(3):\n                new_seq = copy.copy(self)\n                if reverse:\n                    new_seq.revcomp()\n                new_seq.seq = new_seq[frame:]\n                if len(new_seq) % 3:\n                    new_seq.seq = new_seq.seq[:-(len(new_seq) % 3)]\n\n                new_aa_seq = new_seq.translate()\n                if len(new_aa_seq) >= 2 and new_seq[0:3] in genetic_codes.starts[genetic_code] and new_aa_seq[-1] == '*' and '*' not in new_aa_seq[:-1]:\n                    strand = '-' if reverse else '+'\n                    return new_seq, strand, frame\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove first start/'end bases off the start of the sequence", "response": "def trim(self, start, end):\n        '''Removes first 'start'/'end' bases off the start/end of the sequence'''\n        self.seq = self.seq[start:len(self.seq) - end]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a Fastq object.", "response": "def to_Fastq(self, qual_scores):\n        '''Returns a Fastq object. qual_scores expected to be a list of numbers, like you would get in a .qual file'''\n        if len(self) != len(qual_scores):\n            raise Error('Error making Fastq from Fasta, lengths differ.', self.id)\n        return Fastq(self.id, self.seq, ''.join([chr(max(0, min(x, 93)) + 33) for x in qual_scores]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef translate(self, frame=0):\n        '''Returns a Fasta sequence, translated into amino acids. Starts translating from 'frame', where frame expected to be 0,1 or 2'''\n        return Fasta(self.id, ''.join([genetic_codes.codes[genetic_code].get(self.seq[x:x+3].upper(), 'X') for x in range(frame, len(self)-1-frame, 3)]))", "response": "Returns a Fasta sequence translated into amino acids. Starts translating from frame where frame expected to be 0 1 or 2"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the GC content for the sequence.", "response": "def gc_content(self, as_decimal=True):\n        \"\"\"Returns the GC content for the sequence.\n        Notes:\n            This method ignores N when calculating the length of the sequence.\n            It does not, however ignore other ambiguous bases. It also only\n            includes the ambiguous base S (G or C). In this sense the method is\n            conservative with its calculation.\n\n        Args:\n            as_decimal (bool): Return the result as a decimal. Setting to False\n            will return as a percentage. i.e for the sequence GCAT it will\n            return 0.5 by default and 50.00 if set to False.\n\n        Returns:\n            float: GC content calculated as the number of G, C, and S divided\n            by the number of (non-N) bases (length).\n\n        \"\"\"\n        gc_total = 0.0\n        num_bases = 0.0\n        n_tuple = tuple('nN')\n        accepted_bases = tuple('cCgGsS')\n\n        # counter sums all unique characters in sequence. Case insensitive.\n        for base, count in Counter(self.seq).items():\n\n            # dont count N in the number of bases\n            if base not in n_tuple:\n                num_bases += count\n\n                if base in accepted_bases:  # S is a G or C\n                    gc_total += count\n\n        gc_content = gc_total / num_bases\n\n        if not as_decimal:  # return as percentage\n            gc_content *= 100\n\n        return gc_content"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef subseq(self, start, end):\n        '''Returns Fastq object with the same name, of the bases from start to end, but not including end'''\n        return Fastq(self.id, self.seq[start:end], self.qual[start:end])", "response": "Returns a new Fastq object with the same name of the bases from start to end"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trim(self, start, end):\n        '''Removes first 'start'/'end' bases off the start/end of the sequence'''\n        super().trim(start, end)\n        self.qual = self.qual[start:len(self.qual) - end]", "response": "Removes first start/'end bases off the start of the sequence"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef trim_Ns(self):\n        '''Removes any leading or trailing N or n characters from the sequence'''\n        # get index of first base that is not an N\n        i = 0\n        while i < len(self) and self.seq[i] in 'nN':\n            i += 1\n\n        # strip off start of sequence and quality\n        self.seq = self.seq[i:]\n        self.qual = self.qual[i:]\n\n        # strip the ends\n        self.seq = self.seq.rstrip('Nn')\n        self.qual = self.qual[:len(self.seq)]", "response": "Removes any leading or trailing N or n characters from the sequence"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreplacing the sequence from start to end with the sequence new", "response": "def replace_interval(self, start, end, new, qual_string):\n        '''Replaces the sequence from start to end with the sequence \"new\"'''\n        if len(new) != len(qual_string):\n            raise Error('Length of new seq and qual string in replace_interval() must be equal. Cannot continue')\n        super().replace_interval(start, end, new)\n        self.qual = self.qual[0:start] + qual_string + self.qual[end + 1:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a Fasta sequence translated into amino acids. Starts translating from frame where frame expected to be 0 1 2", "response": "def translate(self):\n        '''Returns a Fasta sequence, translated into amino acids. Starts translating from 'frame', where frame expected to be 0,1 or 2'''\n        fa = super().translate()\n        return Fastq(fa.id, fa.seq, 'I'*len(fa.seq))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef acgtn_only(infile, outfile):\n    '''Replace every non-acgtn (case insensitve) character with an N'''\n    f = utils.open_file_write(outfile)\n    for seq in sequences.file_reader(infile):\n        seq.replace_non_acgt()\n        print(seq, file=f)\n    utils.close(f)", "response": "Replace every non - acgtn character with an N"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a CAF file to fastq.", "response": "def caf_to_fastq(infile, outfile, min_length=0, trim=False):\n    '''Convert a CAF file to fastq. Reads shorter than min_length are not output. If clipping information is in the CAF file (with a line Clipping QUAL ...) and trim=True, then trim the reads'''\n    caf_reader = caf.file_reader(infile)\n    fout = utils.open_file_write(outfile)\n\n    for c in caf_reader:\n        if trim:\n            if c.clip_start is not None and c.clip_end is not None:\n                c.seq.seq = c.seq.seq[c.clip_start:c.clip_end + 1]\n                c.seq.qual = c.seq.qual[c.clip_start:c.clip_end + 1]\n            else:\n                print('Warning: no clipping info for sequence', c.id, file=sys.stderr)\n\n\n        if len(c.seq) >= min_length:\n            print(c.seq, file=fout)\n\n    utils.close(fout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef count_sequences(infile):\n    '''Returns the number of sequences in a file'''\n    seq_reader = sequences.file_reader(infile)\n    n = 0\n    for seq in seq_reader:\n        n += 1\n    return n", "response": "Returns the number of sequences in a file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef interleave(infile_1, infile_2, outfile, suffix1=None, suffix2=None):\n    '''Makes interleaved file from two sequence files. If used, will append suffix1 onto end\n    of every sequence name in infile_1, unless it already ends with suffix1. Similar for sufffix2.'''\n    seq_reader_1 = sequences.file_reader(infile_1)\n    seq_reader_2 = sequences.file_reader(infile_2)\n    f_out = utils.open_file_write(outfile)\n\n    for seq_1 in seq_reader_1:\n        try:\n            seq_2 = next(seq_reader_2)\n        except:\n            utils.close(f_out)\n            raise Error('Error getting mate for sequence', seq_1.id, ' ... cannot continue')\n\n        if suffix1 is not None and not seq_1.id.endswith(suffix1):\n            seq_1.id += suffix1\n        if suffix2 is not None and not seq_2.id.endswith(suffix2):\n            seq_2.id += suffix2\n\n        print(seq_1, file=f_out)\n        print(seq_2, file=f_out)\n\n    try:\n        seq_2 = next(seq_reader_2)\n    except:\n        seq_2 = None\n\n    if seq_2 is not None:\n        utils.close(f_out)\n        raise Error('Error getting mate for sequence', seq_2.id, ' ... cannot continue')\n\n    utils.close(f_out)", "response": "Makes an interleaved file from two sequence files. If used will append suffix1 onto end\n    of every sequence name in infile_1 unless it already ends with suffix2. Similar for sufffix2."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes a multi fasta file of random sequences all the same length", "response": "def make_random_contigs(contigs, length, outfile, name_by_letters=False, prefix='', seed=None, first_number=1):\n    '''Makes a multi fasta file of random sequences, all the same length'''\n    random.seed(a=seed)\n    fout = utils.open_file_write(outfile)\n    letters = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n    letters_index = 0\n\n    for i in range(contigs):\n        if name_by_letters:\n            name = letters[letters_index]\n            letters_index += 1\n            if letters_index == len(letters):\n                letters_index = 0\n        else:\n            name = str(i + first_number)\n\n        fa = sequences.Fasta(prefix + name, ''.join([random.choice('ACGT') for x in range(length)]))\n        print(fa, file=fout)\n\n    utils.close(fout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the mean length of the sequences in the input file. By default uses all sequences. By default uses all sequences.", "response": "def mean_length(infile, limit=None):\n    '''Returns the mean length of the sequences in the input file. By default uses all sequences. To limit to the first N sequences, use limit=N'''\n    total = 0\n    count = 0\n    seq_reader = sequences.file_reader(infile)\n    for seq in seq_reader:\n        total += len(seq)\n        count += 1\n        if limit is not None and count >= limit:\n            break\n\n    assert count > 0\n    return total / count"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake a multi fasta file and writes a new file that contains just one sequence with the original sequences catted together preserving their order", "response": "def merge_to_one_seq(infile, outfile, seqname='union'):\n    '''Takes a multi fasta or fastq file and writes a new file that contains just one sequence, with the original sequences catted together, preserving their order'''\n    seq_reader = sequences.file_reader(infile)\n    seqs = []\n\n    for seq in seq_reader:\n        seqs.append(copy.copy(seq))\n\n    new_seq = ''.join([seq.seq for seq in seqs])\n\n    if type(seqs[0]) == sequences.Fastq:\n        new_qual = ''.join([seq.qual for seq in seqs])\n        seqs[:] = []\n        merged = sequences.Fastq(seqname, new_seq, new_qual)\n    else:\n        merged = sequences.Fasta(seqname, new_seq)\n        seqs[:] = []\n\n    f = utils.open_file_write(outfile)\n    print(merged, file=f)\n    utils.close(f)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking a file of contigs from scaffolds by splitting at every N. contig.", "response": "def scaffolds_to_contigs(infile, outfile, number_contigs=False):\n    '''Makes a file of contigs from scaffolds by splitting at every N.\n       Use number_contigs=True to add .1, .2, etc onto end of each\n       contig, instead of default to append coordinates.'''\n    seq_reader = sequences.file_reader(infile)\n    fout = utils.open_file_write(outfile)\n\n    for seq in seq_reader:\n        contigs = seq.contig_coords()\n        counter = 1\n        for contig in contigs:\n            if number_contigs:\n                name = seq.id + '.' + str(counter)\n                counter += 1\n            else:\n                name = '.'.join([seq.id, str(contig.start + 1), str(contig.end + 1)])\n            print(sequences.Fasta(name, seq[contig.start:contig.end+1]), file=fout)\n\n    utils.close(fout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sort_by_size(infile, outfile, smallest_first=False):\n    '''Sorts input sequence file by biggest sequence first, writes sorted output file. Set smallest_first=True to have smallest first'''\n    seqs = {}\n    file_to_dict(infile, seqs)\n    seqs = list(seqs.values())\n    seqs.sort(key=lambda x: len(x), reverse=not smallest_first)\n    fout = utils.open_file_write(outfile)\n    for seq in seqs:\n        print(seq, file=fout)\n    utils.close(fout)", "response": "Sorts input sequence file by biggest sequence first writes sorted output file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsort input sequence file by sort - d - k1 1 writes sorted output file.", "response": "def sort_by_name(infile, outfile):\n    '''Sorts input sequence file by sort -d -k1,1, writes sorted output file.'''\n    seqs = {}\n    file_to_dict(infile, seqs)\n    #seqs = list(seqs.values())\n    #seqs.sort()\n    fout = utils.open_file_write(outfile)\n    for name in sorted(seqs):\n        print(seqs[name], file=fout)\n    utils.close(fout)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_fastg(infile, outfile, circular=None):\n    '''Writes a FASTG file in SPAdes format from input file. Currently only whether or not a sequence is circular is supported. Put circular=set of ids, or circular=filename to make those sequences circular in the output. Puts coverage=1 on all contigs'''\n    if circular is None:\n        to_circularise = set()\n    elif type(circular) is not set:\n        f = utils.open_file_read(circular)\n        to_circularise = set([x.rstrip() for x in f.readlines()])\n        utils.close(f)\n    else:\n        to_circularise = circular\n\n    seq_reader = sequences.file_reader(infile)\n    fout = utils.open_file_write(outfile)\n    nodes = 1\n\n    for seq in seq_reader:\n        new_id = '_'.join([\n            'NODE', str(nodes),\n            'length', str(len(seq)),\n            'cov', '1',\n            'ID', seq.id\n        ])\n\n        if seq.id in to_circularise:\n            seq.id = new_id + ':' + new_id + ';'\n            print(seq, file=fout)\n            seq.revcomp()\n            seq.id = new_id + \"':\" + new_id + \"';\"\n            print(seq, file=fout)\n        else:\n            seq.id = new_id + ';'\n            print(seq, file=fout)\n            seq.revcomp()\n            seq.id = new_id + \"';\"\n            print(seq, file=fout)\n\n        nodes += 1\n\n    utils.close(fout)", "response": "Writes a FASTG file in SPAdes format from input file. Currently only supports circular sequences."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary of positions of the start of each sequence in the file as sgi is a dictionary of name = > length of each sequence in the file.", "response": "def length_offsets_from_fai(fai_file):\n    '''Returns a dictionary of positions of the start of each sequence, as\n       if all the sequences were catted into one sequence.\n       eg if file has three sequences, seq1 10bp, seq2 30bp, seq3 20bp, then\n       the output would be: {'seq1': 0, 'seq2': 10, 'seq3': 40}'''\n    positions = {}\n    total_length = 0\n    f = utils.open_file_read(fai_file)\n\n    for line in f:\n        try:\n            (name, length) = line.rstrip().split()[:2]\n            length = int(length)\n        except:\n            raise Error('Error reading the following line of fai file ' + fai_file + '\\n' + line)\n\n        positions[name] = total_length\n        total_length += length\n\n    utils.close(f)\n    return positions"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef split_by_base_count(infile, outfiles_prefix, max_bases, max_seqs=None):\n    '''Splits a fasta/q file into separate files, file size determined by number of bases.\n\n    Puts <= max_bases in each split file The exception is a single sequence >=max_bases\n    is put in its own file.  This does not split sequences.\n    '''\n    seq_reader = sequences.file_reader(infile)\n    base_count = 0\n    file_count = 1\n    seq_count = 0\n    fout = None\n    if max_seqs is None:\n        max_seqs = float('inf')\n\n    for seq in seq_reader:\n        if base_count == 0:\n            fout = utils.open_file_write(outfiles_prefix + '.' + str(file_count))\n            file_count += 1\n\n        if base_count + len(seq) > max_bases or seq_count >= max_seqs:\n            if base_count == 0:\n                print(seq, file=fout)\n                utils.close(fout)\n            else:\n                utils.close(fout)\n                fout = utils.open_file_write(outfiles_prefix + '.' + str(file_count))\n                print(seq, file=fout)\n                base_count = len(seq)\n                file_count += 1\n                seq_count = 1\n        else:\n            base_count += len(seq)\n            seq_count += 1\n            print(seq, file=fout)\n\n    utils.close(fout)", "response": "Splits a fasta file into separate files file size determined by number of bases."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef split_by_fixed_size(infile, outfiles_prefix, chunk_size, tolerance, skip_if_all_Ns=False):\n    '''Splits  fasta/q file into separate files, with up to (chunk_size + tolerance) bases in each file'''\n    file_count = 1\n    coords = []\n    small_sequences = []  # sequences shorter than chunk_size\n    seq_reader = sequences.file_reader(infile)\n    f_coords = utils.open_file_write(outfiles_prefix + '.coords')\n\n    for seq in seq_reader:\n        if skip_if_all_Ns and seq.is_all_Ns():\n             continue\n        if len(seq) < chunk_size:\n            small_sequences.append(copy.copy(seq))\n        elif len(seq) <= chunk_size + tolerance:\n            f = utils.open_file_write(outfiles_prefix + '.' + str(file_count))\n            print(seq, file=f)\n            utils.close(f)\n            file_count += 1\n        else:\n            # make list of chunk coords\n            chunks = [(x,x+chunk_size) for x in range(0, len(seq), chunk_size)]\n            if chunks[-1][1] - 1 > len(seq):\n                chunks[-1] = (chunks[-1][0], len(seq))\n            if len(chunks) > 1 and (chunks[-1][1] - chunks[-1][0]) <= tolerance:\n                chunks[-2] = (chunks[-2][0], chunks[-1][1])\n                chunks.pop()\n\n            # write one output file per chunk\n            offset = 0\n            for chunk in chunks:\n                if not(skip_if_all_Ns and seq.is_all_Ns(start=chunk[0], end=chunk[1]-1)):\n                    f = utils.open_file_write(outfiles_prefix + '.' + str(file_count))\n                    chunk_id = seq.id + ':' + str(chunk[0]+1) + '-' + str(chunk[1])\n                    print(sequences.Fasta(chunk_id, seq[chunk[0]:chunk[1]]), file=f)\n                    print(chunk_id, seq.id, offset, sep='\\t', file=f_coords)\n                    utils.close(f)\n                    file_count += 1\n\n                offset += chunk[1] - chunk[0]\n\n    # write files of small sequences\n    if len(small_sequences):\n        f = utils.open_file_write(outfiles_prefix + '.' + str(file_count))\n        file_count += 1\n        base_count = 0\n        for seq in small_sequences:\n            if base_count > 0 and base_count + len(seq) > chunk_size + tolerance:\n                utils.close(f)\n                f = utils.open_file_write(outfiles_prefix + '.' + str(file_count))\n                file_count += 1\n                base_count = 0\n\n            print(seq, file=f)\n            base_count += len(seq)\n\n        utils.close(f)", "response": "Splits a fasta file into separate files with up to chunk_size bases in each file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef split_by_fixed_size_onefile(infile, outfile, chunk_size, tolerance, skip_if_all_Ns=False):\n    '''Splits each sequence in infile into chunks of fixed size, last chunk can be up to\n       (chunk_size + tolerance) in length'''\n    seq_reader = sequences.file_reader(infile)\n    f_out = utils.open_file_write(outfile)\n    for seq in seq_reader:\n        for i in range(0, len(seq), chunk_size):\n            if i + chunk_size + tolerance >= len(seq):\n                end = len(seq)\n            else:\n                end = i + chunk_size\n\n            subseq = seq.subseq(i, end)\n            if not (skip_if_all_Ns and subseq.is_all_Ns()):\n                subseq.id += '.' + str(i+1) + '_' + str(end)\n                print(subseq, file=f_out)\n\n            if end == len(seq):\n                break\n\n    utils.close(f_out)", "response": "Splits each sequence in infile into chunks of fixed size and writes the result to outfile."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning dictionary of length stats from an fai file. Keys are longest shortest mean total_length N50 number", "response": "def stats_from_fai(infile):\n    '''Returns dictionary of length stats from an fai file. Keys are: longest, shortest, mean, total_length, N50, number'''\n    f = utils.open_file_read(infile)\n    try:\n        lengths = sorted([int(line.split('\\t')[1]) for line in f], reverse=True)\n    except:\n        raise Error('Error getting lengths from fai file ' + infile)\n    utils.close(f)\n\n    stats = {}\n    if len(lengths) > 0:\n        stats['longest'] = max(lengths)\n        stats['shortest'] = min(lengths)\n        stats['total_length'] = sum(lengths)\n        stats['mean'] = stats['total_length'] / len(lengths)\n        stats['number'] = len(lengths)\n\n        cumulative_length = 0\n        for length in lengths:\n            cumulative_length += length\n            if cumulative_length >= 0.5 * stats['total_length']:\n                stats['N50'] = length\n                break\n    else:\n        stats = {x: 0 for x in ('longest', 'shortest', 'mean', 'N50', 'total_length', 'number')}\n\n    return stats"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting input sequence file into a Boulder - IO format as used by primer3", "response": "def to_boulderio(infile, outfile):\n    '''Converts input sequence file into a \"Boulder-IO format\", as used by primer3'''\n    seq_reader = sequences.file_reader(infile)\n    f_out = utils.open_file_write(outfile)\n\n    for sequence in seq_reader:\n        print(\"SEQUENCE_ID=\" + sequence.id, file=f_out)\n        print(\"SEQUENCE_TEMPLATE=\" + sequence.seq, file=f_out)\n        print(\"=\", file=f_out)\n\n    utils.close(f_out)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef salted_hmac(key_salt, value, secret=None):\n    if secret is None:\n        secret = settings.SECRET_KEY\n\n    key_salt = force_bytes(key_salt)\n    secret = force_bytes(secret)\n\n    # We need to generate a derived key from our base key.  We can do this by\n    # passing the key_salt and our base key through a pseudo-random function and\n    # SHA1 works nicely.\n    digest = hashes.Hash(\n        settings.CRYPTOGRAPHY_DIGEST, backend=settings.CRYPTOGRAPHY_BACKEND)\n    digest.update(key_salt + secret)\n    key = digest.finalize()\n\n    # If len(key_salt + secret) > sha_constructor().block_size, the above\n    # line is redundant and could be replaced by key = key_salt + secret, since\n    # the hmac module does the same thing for keys longer than the block size.\n    # However, we need to ensure that we *always* do this.\n    h = HMAC(\n        key,\n        settings.CRYPTOGRAPHY_DIGEST,\n        backend=settings.CRYPTOGRAPHY_BACKEND)\n    h.update(force_bytes(value))\n    return h", "response": "Returns the HMAC - HASH of value using a different key generated from key_salt and secret."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nderive a key from a password and salt.", "response": "def pbkdf2(password, salt, iterations, dklen=0, digest=None):\n    \"\"\"\n    Implements PBKDF2 with the same API as Django's existing\n    implementation, using cryptography.\n\n    :type password: any\n    :type salt: any\n    :type iterations: int\n    :type dklen: int\n    :type digest: cryptography.hazmat.primitives.hashes.HashAlgorithm\n    \"\"\"\n    if digest is None:\n        digest = settings.CRYPTOGRAPHY_DIGEST\n    if not dklen:\n        dklen = digest.digest_size\n    password = force_bytes(password)\n    salt = force_bytes(salt)\n    kdf = PBKDF2HMAC(\n        algorithm=digest,\n        length=dklen,\n        salt=salt,\n        iterations=iterations,\n        backend=settings.CRYPTOGRAPHY_BACKEND)\n    return kdf.derive(password)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encrypt(self, data):\n        data = force_bytes(data)\n        iv = os.urandom(16)\n        return self._encrypt_from_parts(data, iv)", "response": "encrypt data with the key"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nencrypts the data and return the ciphertext.", "response": "def _encrypt_from_parts(self, data, iv):\n        \"\"\"\n        :type data: bytes\n        :type iv: bytes\n        :rtype: any\n        \"\"\"\n        padder = padding.PKCS7(algorithms.AES.block_size).padder()\n        padded_data = padder.update(data) + padder.finalize()\n        encryptor = Cipher(\n            algorithms.AES(self._encryption_key), modes.CBC(iv),\n            self._backend).encryptor()\n        ciphertext = encryptor.update(padded_data) + encryptor.finalize()\n\n        return self._signer.sign(iv + ciphertext)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decrypt(self, data, ttl=None):\n        data = self._signer.unsign(data, ttl)\n\n        iv = data[:16]\n        ciphertext = data[16:]\n        decryptor = Cipher(\n            algorithms.AES(self._encryption_key), modes.CBC(iv),\n            self._backend).decryptor()\n        plaintext_padded = decryptor.update(ciphertext)\n        try:\n            plaintext_padded += decryptor.finalize()\n        except ValueError:\n            raise InvalidToken\n\n        # Remove padding\n        unpadder = padding.PKCS7(algorithms.AES.block_size).unpadder()\n        unpadded = unpadder.update(plaintext_padded)\n        try:\n            unpadded += unpadder.finalize()\n        except ValueError:\n            raise InvalidToken\n        return unpadded", "response": ":type data: bytes\n        :type ttl: int\n        :rtype: bytes"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_encrypted_field(base_class):\n    assert not isinstance(base_class, models.Field)\n    field_name = 'Encrypted' + base_class.__name__\n    if base_class not in FIELD_CACHE:\n        FIELD_CACHE[base_class] = type(field_name,\n                                       (EncryptedMixin, base_class), {\n                                           'base_class': base_class,\n                                       })\n    return FIELD_CACHE[base_class]", "response": "A get or create method for encrypted fields."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef encrypt(base_field, key=None, ttl=None):\n    if not isinstance(base_field, models.Field):\n        assert key is None\n        assert ttl is None\n        return get_encrypted_field(base_field)\n\n    name, path, args, kwargs = base_field.deconstruct()\n    kwargs.update({'key': key, 'ttl': ttl})\n    return get_encrypted_field(base_field.__class__)(*args, **kwargs)", "response": "A decorator for creating encrypted model fields."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npickling data is serialized as base64", "response": "def value_to_string(self, obj):\n        \"\"\"Pickled data is serialized as base64\"\"\"\n        value = self.value_from_object(obj)\n        return b64encode(self._dump(value)).decode('ascii')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nserializes the object to a base64 - encoded JSON string.", "response": "def dumps(obj,\n          key=None,\n          salt='django.core.signing',\n          serializer=JSONSerializer,\n          compress=False):\n    \"\"\"\n    Returns URL-safe, sha1 signed base64 compressed JSON string. If key is\n    None, settings.SECRET_KEY is used instead.\n\n    If compress is True (not the default) checks if compressing using zlib can\n    save some space. Prepends a '.' to signify compression. This is included\n    in the signature, to protect against zip bombs.\n\n    Salt can be used to namespace the hash, so that a signed string is\n    only valid for a given namespace. Leaving this at the default\n    value or re-using a salt value across different parts of your\n    application without good cause is a security risk.\n\n    The serializer is expected to return a bytestring.\n    \"\"\"\n    data = serializer().dumps(obj)\n\n    # Flag for if it's been compressed or not\n    is_compressed = False\n\n    if compress:\n        # Avoid zlib dependency unless compress is being used\n        compressed = zlib.compress(data)\n        if len(compressed) < (len(data) - 1):\n            data = compressed\n            is_compressed = True\n    base64d = b64_encode(data)\n    if is_compressed:\n        base64d = b'.' + base64d\n    return TimestampSigner(key, salt=salt).sign(base64d)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef signature(self, value):\n        h = HMAC(self.key, self.digest, backend=settings.CRYPTOGRAPHY_BACKEND)\n        h.update(force_bytes(value))\n        return h", "response": "Returns the signature of the value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving original value and check it wasn't signed more than max_age seconds ago. :type signed_value: bytes :type ttl: int | datetime.timedelta", "response": "def unsign(self, signed_value, ttl=None):\n        \"\"\"\n        Retrieve original value and check it wasn't signed more\n        than max_age seconds ago.\n\n        :type signed_value: bytes\n        :type ttl: int | datetime.timedelta\n        \"\"\"\n        h_size, d_size = struct.calcsize('>cQ'), self.digest.digest_size\n        fmt = '>cQ%ds%ds' % (len(signed_value) - h_size - d_size, d_size)\n        try:\n            version, timestamp, value, sig = struct.unpack(fmt, signed_value)\n        except struct.error:\n            raise BadSignature('Signature is not valid')\n        if version != self.version:\n            raise BadSignature('Signature version not supported')\n        if ttl is not None:\n            if isinstance(ttl, datetime.timedelta):\n                ttl = ttl.total_seconds()\n            # Check timestamp is not older than ttl\n            age = abs(time.time() - timestamp)\n            if age > ttl + _MAX_CLOCK_SKEW:\n                raise SignatureExpired('Signature age %s > %s seconds' % (age,\n                                                                          ttl))\n        try:\n            self.signature(signed_value[:-d_size]).verify(sig)\n        except InvalidSignature:\n            raise BadSignature(\n                'Signature \"%s\" does not match' % binascii.b2a_base64(sig))\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a PEP 386 - compliant version number from VERSION.", "response": "def get_version(version=None):\n    \"\"\"\n    Returns a PEP 386-compliant version number from VERSION.\n    \"\"\"\n    version = get_complete_version(version)\n\n    # Now build the two parts of the version number:\n    # main = X.Y[.Z]\n    # sub = .devN - for pre-alpha releases\n    #     | {a|b|c}N - for alpha, beta and rc releases\n\n    main = get_main_version(version)\n\n    sub = ''\n    if version[3] == 'alpha' and version[4] == 0:\n        git_changeset = get_git_changeset()\n        if git_changeset:\n            sub = '.dev%s' % git_changeset\n\n    elif version[3] != 'final':\n        mapping = {'alpha': 'a', 'beta': 'b', 'rc': 'c'}\n        sub = mapping[version[3]] + str(version[4])\n\n    return str(main + sub)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_complete_version(version=None):\n    if version is None:\n        from django_cryptography import VERSION as version\n    else:\n        assert len(version) == 5\n        assert version[3] in ('alpha', 'beta', 'rc', 'final')\n\n    return version", "response": "Returns a tuple of django_cryptography version."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef enumeration(*args):\n\n    assert len(args) > 0, 'at least one argument is required'\n    if len(args) == 1:\n        # assume the first argument defines the membership\n        members = args[0]\n    else:\n        # assume the arguments are the members\n        members = args\n    def checker(value):\n        if value not in members:\n            raise ValueError(value)\n    return checker", "response": "Return a value checker which raises a value error if the value is not in the enumeration of values."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef match_pattern(regex):\n\n    prog = re.compile(regex)\n    def checker(v):\n        result = prog.match(v)\n        if result is None:\n            raise ValueError(v)\n    return checker", "response": "Returns a value checker which checks that the value does\n    match the supplied regular expression."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search_pattern(regex):\n\n    prog = re.compile(regex)\n    def checker(v):\n        result = prog.search(v)\n        if result is None:\n            raise ValueError(v)\n    return checker", "response": "Returns a value checker which checks the supplied regular expression against the internal regex."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef number_range_inclusive(min, max, type=float):\n\n    def checker(v):\n        if type(v) < min or type(v) > max:\n            raise ValueError(v)\n    return checker", "response": "Returns a function which checks that the supplied value is inclusive."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a function which raises a ValueError if the supplied value is not a number range.", "response": "def number_range_exclusive(min, max, type=float):\n    \"\"\"\n    Return a value check function which raises a ValueError if the supplied\n    value when cast as `type` is less than or equal to `min` or greater than\n    or equal to `max`.\n\n    \"\"\"\n\n    def checker(v):\n        if type(v) <= min or type(v) >= max:\n            raise ValueError(v)\n    return checker"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a value checker that checks if the supplied value is inclusive.", "response": "def datetime_range_inclusive(min, max, format):\n    \"\"\"\n    Return a value check function which raises a ValueError if the supplied\n    value when converted to a datetime using the supplied `format` string is\n    less than `min` or greater than `max`.\n\n    \"\"\"\n\n    dmin = datetime.strptime(min, format)\n    dmax = datetime.strptime(max, format)\n    def checker(v):\n        dv = datetime.strptime(v, format)\n        if dv < dmin or dv > dmax:\n            raise ValueError(v)\n    return checker"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite a list of problems as restructured text to a file.", "response": "def write_problems(problems, file, summarize=False, limit=0):\n    \"\"\"\n    Write problems as restructured text to a file (or stdout/stderr).\n\n    \"\"\"\n    w = file.write # convenience variable\n    w(\"\"\"\n=================\nValidation Report\n=================\n\"\"\")\n    counts = dict() # store problem counts per problem code\n    total = 0\n    for i, p in enumerate(problems):\n        if limit and i >= limit:\n            break # bail out\n        if total == 0 and not summarize:\n            w(\"\"\"\nProblems\n========\n\"\"\")\n        total += 1\n        code = p['code']\n        if code in counts:\n            counts[code] += 1\n        else:\n            counts[code] = 1\n        if not summarize:\n            ptitle = '\\n%s - %s\\n' % (p['code'], p['message'])\n            w(ptitle)\n            underline = ''\n            for i in range(len(ptitle.strip())):\n                underline += '-'\n            underline += '\\n'\n            w(underline)\n            for k in sorted(p.viewkeys() - set(['code', 'message', 'context'])):\n                w(':%s: %s\\n' % (k, p[k]))\n            if 'context' in p:\n                c = p['context']\n                for k in sorted(c.viewkeys()):\n                    w(':%s: %s\\n' % (k, c[k]))\n\n    w(\"\"\"\nSummary\n=======\n\nFound %s%s problem%s in total.\n\n\"\"\" % ('at least ' if limit else '', total, 's' if total != 1 else ''))\n    for code in sorted(counts.viewkeys()):\n        w(':%s: %s\\n' % (code, counts[code]))\n    return total"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a header check to the list of header checks that can be performed for the current locale.", "response": "def add_header_check(self,\n                         code=HEADER_CHECK_FAILED,\n                         message=MESSAGES[HEADER_CHECK_FAILED]):\n        \"\"\"\n        Add a header check, i.e., check whether the header record is consistent\n        with the expected field names.\n\n        Arguments\n        ---------\n\n        `code` - problem code to report if the header record is not valid,\n        defaults to `HEADER_CHECK_FAILED`\n\n        `message` - problem message to report if a value is not valid\n\n        \"\"\"\n\n        t = code, message\n        self._header_checks.append(t)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_record_length_check(self,\n                         code=RECORD_LENGTH_CHECK_FAILED,\n                         message=MESSAGES[RECORD_LENGTH_CHECK_FAILED],\n                         modulus=1):\n        \"\"\"\n        Add a record length check, i.e., check whether the length of a record is\n        consistent with the number of expected fields.\n\n        Arguments\n        ---------\n\n        `code` - problem code to report if a record is not valid, defaults to\n        `RECORD_LENGTH_CHECK_FAILED`\n\n        `message` - problem message to report if a record is not valid\n\n        `modulus` - apply the check to every nth record, defaults to 1 (check\n        every record)\n\n        \"\"\"\n\n        t = code, message, modulus\n        self._record_length_checks.append(t)", "response": "Add a record length check to the list of record lengths checks that are consistent with the number of expected fields."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_value_check(self, field_name, value_check,\n                        code=VALUE_CHECK_FAILED,\n                        message=MESSAGES[VALUE_CHECK_FAILED],\n                        modulus=1):\n        \"\"\"\n        Add a value check function for the specified field.\n\n        Arguments\n        ---------\n\n        `field_name` - the name of the field to attach the value check function\n        to\n\n        `value_check` - a function that accepts a single argument (a value) and\n        raises a `ValueError` if the value is not valid\n\n        `code` - problem code to report if a value is not valid, defaults to\n        `VALUE_CHECK_FAILED`\n\n        `message` - problem message to report if a value is not valid\n\n        `modulus` - apply the check to every nth record, defaults to 1 (check\n        every record)\n\n        \"\"\"\n\n        # guard conditions\n        assert field_name in self._field_names, 'unexpected field name: %s' % field_name\n        assert callable(value_check), 'value check must be a callable function'\n\n        t = field_name, value_check, code, message, modulus\n        self._value_checks.append(t)", "response": "Adds a value check function to the entry in the internal value check list for the specified field."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_value_predicate(self, field_name, value_predicate,\n                        code=VALUE_PREDICATE_FALSE,\n                        message=MESSAGES[VALUE_PREDICATE_FALSE],\n                        modulus=1):\n        \"\"\"\n        Add a value predicate function for the specified field.\n\n        N.B., everything you can do with value predicates can also be done with\n        value check functions, whether you use one or the other is a matter of\n        style.\n\n        Arguments\n        ---------\n\n        `field_name` - the name of the field to attach the value predicate\n        function to\n\n        `value_predicate` - a function that accepts a single argument (a value)\n        and returns False if the value is not valid\n\n        `code` - problem code to report if a value is not valid, defaults to\n        `VALUE_PREDICATE_FALSE`\n\n        `message` - problem message to report if a value is not valid\n\n        `modulus` - apply the check to every nth record, defaults to 1 (check\n        every record)\n\n        \"\"\"\n\n        assert field_name in self._field_names, 'unexpected field name: %s' % field_name\n        assert callable(value_predicate), 'value predicate must be a callable function'\n\n        t = field_name, value_predicate, code, message, modulus\n        self._value_predicates.append(t)", "response": "Adds a value predicate function to the entry set."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a record check function to the internal list of record checks.", "response": "def add_record_check(self, record_check, modulus=1):\n        \"\"\"\n        Add a record check function.\n\n        Arguments\n        ---------\n\n        `record_check` - a function that accepts a single argument (a record as\n        a dictionary of values indexed by field name) and raises a\n        `RecordError` if the record is not valid\n\n        `modulus` - apply the check to every nth record, defaults to 1 (check\n        every record)\n\n        \"\"\"\n\n        assert callable(record_check), 'record check must be a callable function'\n\n        t = record_check, modulus\n        self._record_checks.append(t)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a record predicate function to the list of record checks that occur for this entry.", "response": "def add_record_predicate(self, record_predicate,\n                        code=RECORD_PREDICATE_FALSE,\n                        message=MESSAGES[RECORD_PREDICATE_FALSE],\n                        modulus=1):\n        \"\"\"\n        Add a record predicate function.\n\n        N.B., everything you can do with record predicates can also be done with\n        record check functions, whether you use one or the other is a matter of\n        style.\n\n        Arguments\n        ---------\n\n        `record_predicate` - a function that accepts a single argument (a record\n        as a dictionary of values indexed by field name) and returns False if\n        the value is not valid\n\n        `code` - problem code to report if a record is not valid, defaults to\n        `RECORD_PREDICATE_FALSE`\n\n        `message` - problem message to report if a record is not valid\n\n        `modulus` - apply the check to every nth record, defaults to 1 (check\n        every record)\n\n        \"\"\"\n\n        assert callable(record_predicate), 'record predicate must be a callable function'\n\n        t = record_predicate, code, message, modulus\n        self._record_predicates.append(t)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a unique check on a single column or combination of columns.", "response": "def add_unique_check(self, key,\n                        code=UNIQUE_CHECK_FAILED,\n                        message=MESSAGES[UNIQUE_CHECK_FAILED]):\n        \"\"\"\n        Add a unique check on a single column or combination of columns.\n\n        Arguments\n        ---------\n\n        `key` - a single field name (string) specifying a field in which all\n        values are expected to be unique, or a sequence of field names (tuple\n        or list of strings) specifying a compound key\n\n        `code` - problem code to report if a record is not valid, defaults to\n        `UNIQUE_CHECK_FAILED`\n\n        `message` - problem message to report if a record is not valid\n\n        \"\"\"\n\n        if isinstance(key, basestring):\n            assert key in self._field_names, 'unexpected field name: %s' % key\n        else:\n            for f in key:\n                assert f in self._field_names, 'unexpected field name: %s' % key\n        t = key, code, message\n        self._unique_checks.append(t)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating data and return a list of validation problems found.", "response": "def validate(self, data,\n                 expect_header_row=True,\n                 ignore_lines=0,\n                 summarize=False,\n                 limit=0,\n                 context=None,\n                 report_unexpected_exceptions=True):\n        \"\"\"\n        Validate `data` and return a list of validation problems found.\n\n        Arguments\n        ---------\n\n        `data` - any source of row-oriented data, e.g., as provided by a\n        `csv.reader`, or a list of lists of strings, or ...\n\n        `expect_header_row` - does the data contain a header row (i.e., the\n        first record is a list of field names)? Defaults to True.\n\n        `ignore_lines` - ignore n lines (rows) at the beginning of the data\n\n        `summarize` - only report problem codes, no other details\n\n        `limit` - report at most n problems\n\n        `context` - a dictionary of any additional information to be added to\n        any problems found - useful if problems are being aggregated from\n        multiple validators\n\n        `report_unexpected_exceptions` - value check function, value predicates,\n        record check functions, record predicates, and other user-supplied\n        validation functions may raise unexpected exceptions. If this argument\n        is true, any unexpected exceptions will be reported as validation\n        problems; if False, unexpected exceptions will be handled silently.\n\n        \"\"\"\n\n        problems = list()\n        problem_generator = self.ivalidate(data, expect_header_row,\n                                           ignore_lines, summarize, context,\n                                           report_unexpected_exceptions)\n        for i, p in enumerate(problem_generator):\n            if not limit or i < limit:\n                problems.append(p)\n        return problems"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate data and return an iterator over problems found.", "response": "def ivalidate(self, data,\n                 expect_header_row=True,\n                 ignore_lines=0,\n                 summarize=False,\n                 context=None,\n                 report_unexpected_exceptions=True):\n        \"\"\"\n        Validate `data` and return a iterator over problems found.\n\n        Use this function rather than validate() if you expect a large number\n        of problems.\n\n        Arguments\n        ---------\n\n        `data` - any source of row-oriented data, e.g., as provided by a\n        `csv.reader`, or a list of lists of strings, or ...\n\n        `expect_header_row` - does the data contain a header row (i.e., the\n        first record is a list of field names)? Defaults to True.\n\n        `ignore_lines` - ignore n lines (rows) at the beginning of the data\n\n        `summarize` - only report problem codes, no other details\n\n        `context` - a dictionary of any additional information to be added to\n        any problems found - useful if problems are being aggregated from\n        multiple validators\n\n        `report_unexpected_exceptions` - value check function, value predicates,\n        record check functions, record predicates, and other user-supplied\n        validation functions may raise unexpected exceptions. If this argument\n        is true, any unexpected exceptions will be reported as validation\n        problems; if False, unexpected exceptions will be handled silently.\n\n        \"\"\"\n\n        unique_sets = self._init_unique_sets() # used for unique checks\n        for i, r in enumerate(data):\n            if expect_header_row and i == ignore_lines:\n                # r is the header row\n                for p in self._apply_header_checks(i, r, summarize, context):\n                    yield p\n            elif i >= ignore_lines:\n                # r is a data row\n                skip = False\n                for p in self._apply_skips(i, r, summarize,\n                                                  report_unexpected_exceptions,\n                                                  context):\n                    if p is True:\n                        skip = True\n                    else:\n                        yield p\n                if not skip:\n                    for p in self._apply_each_methods(i, r, summarize,\n                                                      report_unexpected_exceptions,\n                                                      context):\n                        yield p # may yield a problem if an exception is raised\n                    for p in self._apply_value_checks(i, r, summarize,\n                                                      report_unexpected_exceptions,\n                                                      context):\n                        yield p\n                    for p in self._apply_record_length_checks(i, r, summarize,\n                                                              context):\n                        yield p\n                    for p in self._apply_value_predicates(i, r, summarize,\n                                                          report_unexpected_exceptions,\n                                                          context):\n                        yield p\n                    for p in self._apply_record_checks(i, r, summarize,\n                                                           report_unexpected_exceptions,\n                                                           context):\n                        yield p\n                    for p in self._apply_record_predicates(i, r, summarize,\n                                                           report_unexpected_exceptions,\n                                                           context):\n                        yield p\n                    for p in self._apply_unique_checks(i, r, unique_sets, summarize):\n                        yield p\n                    for p in self._apply_check_methods(i, r, summarize,\n                                                       report_unexpected_exceptions,\n                                                       context):\n                        yield p\n                    for p in self._apply_assert_methods(i, r, summarize,\n                                                        report_unexpected_exceptions,\n                                                        context):\n                        yield p\n        for p in self._apply_finally_assert_methods(summarize,\n                                                    report_unexpected_exceptions,\n                                                    context):\n            yield p"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialise sets used for uniqueness checking.", "response": "def _init_unique_sets(self):\n        \"\"\"Initialise sets used for uniqueness checking.\"\"\"\n\n        ks = dict()\n        for t in self._unique_checks:\n            key = t[0]\n            ks[key] = set() # empty set\n        return ks"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding the values from the value checks for the given record i.", "response": "def _apply_value_checks(self, i, r,\n                            summarize=False,\n                            report_unexpected_exceptions=True,\n                            context=None):\n        \"\"\"Apply value check functions on the given record `r`.\"\"\"\n\n        for field_name, check, code, message, modulus in self._value_checks:\n            if i % modulus == 0: # support sampling\n                fi = self._field_names.index(field_name)\n                if fi < len(r): # only apply checks if there is a value\n                    value = r[fi]\n                    try:\n                        check(value)\n                    except ValueError:\n                        p = {'code': code}\n                        if not summarize:\n                            p['message'] = message\n                            p['row'] = i + 1\n                            p['column'] = fi + 1\n                            p['field'] = field_name\n                            p['value'] = value\n                            p['record'] = r\n                            if context is not None: p['context'] = context\n                        yield p\n                    except Exception as e:\n                        if report_unexpected_exceptions:\n                            p = {'code': UNEXPECTED_EXCEPTION}\n                            if not summarize:\n                                p['message'] = MESSAGES[UNEXPECTED_EXCEPTION] % (e.__class__.__name__, e)\n                                p['row'] = i + 1\n                                p['column'] = fi + 1\n                                p['field'] = field_name\n                                p['value'] = value\n                                p['record'] = r\n                                p['exception'] = e\n                                p['function'] = '%s: %s' % (check.__name__,\n                                                            check.__doc__)\n                                if context is not None: p['context'] = context\n                            yield p"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _apply_header_checks(self, i, r, summarize=False, context=None):\n\n        for code, message in self._header_checks:\n            if tuple(r) != self._field_names:\n                p = {'code': code}\n                if not summarize:\n                    p['message'] = message\n                    p['row'] = i + 1\n                    p['record'] = tuple(r)\n                    p['missing'] = set(self._field_names) - set(r)\n                    p['unexpected'] = set(r) - set(self._field_names)\n                    if context is not None: p['context'] = context\n                yield p", "response": "Yields a list of dicts that are passed to the header checks on the given record r."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying record length checks on the given record r.", "response": "def _apply_record_length_checks(self, i, r, summarize=False, context=None):\n        \"\"\"Apply record length checks on the given record `r`.\"\"\"\n\n        for code, message, modulus in self._record_length_checks:\n            if i % modulus == 0: # support sampling\n                if len(r) != len(self._field_names):\n                    p = {'code': code}\n                    if not summarize:\n                        p['message'] = message\n                        p['row'] = i + 1\n                        p['record'] = r\n                        p['length'] = len(r)\n                        if context is not None: p['context'] = context\n                    yield p"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _apply_value_predicates(self, i, r,\n                                summarize=False,\n                                report_unexpected_exceptions=True,\n                                context=None):\n        \"\"\"Apply value predicates on the given record `r`.\"\"\"\n\n        for field_name, predicate, code, message, modulus in self._value_predicates:\n            if i % modulus == 0: # support sampling\n                fi = self._field_names.index(field_name)\n                if fi < len(r): # only apply predicate if there is a value\n                    value = r[fi]\n                    try:\n                        valid = predicate(value)\n                        if not valid:\n                            p = {'code': code}\n                            if not summarize:\n                                p['message'] = message\n                                p['row'] = i + 1\n                                p['column'] = fi + 1\n                                p['field'] = field_name\n                                p['value'] = value\n                                p['record'] = r\n                                if context is not None: p['context'] = context\n                            yield p\n                    except Exception as e:\n                        if report_unexpected_exceptions:\n                            p = {'code': UNEXPECTED_EXCEPTION}\n                            if not summarize:\n                                p['message'] = MESSAGES[UNEXPECTED_EXCEPTION] % (e.__class__.__name__, e)\n                                p['row'] = i + 1\n                                p['column'] = fi + 1\n                                p['field'] = field_name\n                                p['value'] = value\n                                p['record'] = r\n                                p['exception'] = e\n                                p['function'] = '%s: %s' % (predicate.__name__,\n                                                            predicate.__doc__)\n                                if context is not None: p['context'] = context\n                            yield p", "response": "Apply value predicates on the given record i."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _apply_record_checks(self, i, r,\n                                 summarize=False,\n                                 report_unexpected_exceptions=True,\n                                 context=None):\n        \"\"\"Apply record checks on `r`.\"\"\"\n\n        for check, modulus in self._record_checks:\n            if i % modulus == 0: # support sampling\n                rdict = self._as_dict(r)\n                try:\n                    check(rdict)\n                except RecordError as e:\n                    code = e.code if e.code is not None else RECORD_CHECK_FAILED\n                    p = {'code': code}\n                    if not summarize:\n                        message = e.message if e.message is not None else MESSAGES[RECORD_CHECK_FAILED]\n                        p['message'] = message\n                        p['row'] = i + 1\n                        p['record'] = r\n                        if context is not None: p['context'] = context\n                        if e.details is not None: p['details'] = e.details\n                    yield p\n                except Exception as e:\n                    if report_unexpected_exceptions:\n                        p = {'code': UNEXPECTED_EXCEPTION}\n                        if not summarize:\n                            p['message'] = MESSAGES[UNEXPECTED_EXCEPTION] % (e.__class__.__name__, e)\n                            p['row'] = i + 1\n                            p['record'] = r\n                            p['exception'] = e\n                            p['function'] = '%s: %s' % (check.__name__,\n                                                        check.__doc__)\n                            if context is not None: p['context'] = context\n                        yield p", "response": "Yields a list of record checks that can be performed on r."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\napply record predicates on r.", "response": "def _apply_record_predicates(self, i, r,\n                                 summarize=False,\n                                 report_unexpected_exceptions=True,\n                                 context=None):\n        \"\"\"Apply record predicates on `r`.\"\"\"\n\n        for predicate, code, message, modulus in self._record_predicates:\n            if i % modulus == 0: # support sampling\n                rdict = self._as_dict(r)\n                try:\n                    valid = predicate(rdict)\n                    if not valid:\n                        p = {'code': code}\n                        if not summarize:\n                            p['message'] = message\n                            p['row'] = i + 1\n                            p['record'] = r\n                            if context is not None: p['context'] = context\n                        yield p\n                except Exception as e:\n                    if report_unexpected_exceptions:\n                        p = {'code': UNEXPECTED_EXCEPTION}\n                        if not summarize:\n                            p['message'] = MESSAGES[UNEXPECTED_EXCEPTION] % (e.__class__.__name__, e)\n                            p['row'] = i + 1\n                            p['record'] = r\n                            p['exception'] = e\n                            p['function'] = '%s: %s' % (predicate.__name__,\n                                                        predicate.__doc__)\n                            if context is not None: p['context'] = context\n                        yield p"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nyielding unique checks on r.", "response": "def _apply_unique_checks(self, i, r, unique_sets,\n                             summarize=False,\n                             context=None):\n        \"\"\"Apply unique checks on `r`.\"\"\"\n\n        for key, code, message in self._unique_checks:\n            value = None\n            values = unique_sets[key]\n            if isinstance(key, basestring): # assume key is a field name\n                fi = self._field_names.index(key)\n                if fi >= len(r):\n                    continue\n                value = r[fi]\n            else: # assume key is a list or tuple, i.e., compound key\n                value = []\n                for f in key:\n                    fi = self._field_names.index(f)\n                    if fi >= len(r):\n                        break\n                    value.append(r[fi])\n                value = tuple(value) # enable hashing\n            if value in values:\n                p = {'code': code}\n                if not summarize:\n                    p['message'] = message\n                    p['row'] = i + 1\n                    p['record'] = r\n                    p['key'] = key\n                    p['value'] = value\n                    if context is not None: p['context'] = context\n                yield p\n            values.add(value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _apply_each_methods(self, i, r,\n                            summarize=False,\n                            report_unexpected_exceptions=True,\n                            context=None):\n        \"\"\"Invoke 'each' methods on `r`.\"\"\"\n\n        for a in dir(self):\n            if a.startswith('each'):\n                rdict = self._as_dict(r)\n                f = getattr(self, a)\n                try:\n                    f(rdict)\n                except Exception as e:\n                    if report_unexpected_exceptions:\n                        p = {'code': UNEXPECTED_EXCEPTION}\n                        if not summarize:\n                            p['message'] = MESSAGES[UNEXPECTED_EXCEPTION] % (e.__class__.__name__, e)\n                            p['row'] = i + 1\n                            p['record'] = r\n                            p['exception'] = e\n                            p['function'] = '%s: %s' % (f.__name__,\n                                                        f.__doc__)\n                            if context is not None: p['context'] = context\n                        yield p", "response": "Invoke each method on r."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields a generator of the values of the assert methods on r.", "response": "def _apply_assert_methods(self, i, r,\n                              summarize=False,\n                              report_unexpected_exceptions=True,\n                              context=None):\n        \"\"\"Apply 'assert' methods on `r`.\"\"\"\n\n        for a in dir(self):\n            if a.startswith('assert'):\n                rdict = self._as_dict(r)\n                f = getattr(self, a)\n                try:\n                    f(rdict)\n                except AssertionError as e:\n                    code = ASSERT_CHECK_FAILED\n                    message = MESSAGES[ASSERT_CHECK_FAILED]\n                    if len(e.args) > 0:\n                        custom = e.args[0]\n                        if isinstance(custom, (list, tuple)):\n                            if len(custom) > 0:\n                                code = custom[0]\n                            if len(custom) > 1:\n                                message = custom[1]\n                        else:\n                            code = custom\n                    p = {'code': code}\n                    if not summarize:\n                        p['message'] = message\n                        p['row'] = i + 1\n                        p['record'] = r\n                        if context is not None: p['context'] = context\n                    yield p\n                except Exception as e:\n                    if report_unexpected_exceptions:\n                        p = {'code': UNEXPECTED_EXCEPTION}\n                        if not summarize:\n                            p['message'] = MESSAGES[UNEXPECTED_EXCEPTION] % (e.__class__.__name__, e)\n                            p['row'] = i + 1\n                            p['record'] = r\n                            p['exception'] = e\n                            p['function'] = '%s: %s' % (f.__name__,\n                                                        f.__doc__)\n                            if context is not None: p['context'] = context\n                        yield p"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _apply_check_methods(self, i, r,\n                              summarize=False,\n                              report_unexpected_exceptions=True,\n                              context=None):\n        \"\"\"Apply 'check' methods on `r`.\"\"\"\n\n        for a in dir(self):\n            if a.startswith('check'):\n                rdict = self._as_dict(r)\n                f = getattr(self, a)\n                try:\n                    f(rdict)\n                except RecordError as e:\n                    code = e.code if e.code is not None else RECORD_CHECK_FAILED\n                    p = {'code': code}\n                    if not summarize:\n                        message = e.message if e.message is not None else MESSAGES[RECORD_CHECK_FAILED]\n                        p['message'] = message\n                        p['row'] = i + 1\n                        p['record'] = r\n                        if context is not None: p['context'] = context\n                        if e.details is not None: p['details'] = e.details\n                    yield p\n                except Exception as e:\n                    if report_unexpected_exceptions:\n                        p = {'code': UNEXPECTED_EXCEPTION}\n                        if not summarize:\n                            p['message'] = MESSAGES[UNEXPECTED_EXCEPTION] % (e.__class__.__name__, e)\n                            p['row'] = i + 1\n                            p['record'] = r\n                            p['exception'] = e\n                            p['function'] = '%s: %s' % (f.__name__,\n                                                        f.__doc__)\n                            if context is not None: p['context'] = context\n                        yield p", "response": "Yields a list of dict with the details of all check methods on r."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _apply_skips(self, i, r,\n                     summarize=False,\n                     report_unexpected_exceptions=True,\n                     context=None):\n        \"\"\"Apply skip functions on `r`.\"\"\"\n\n        for skip in self._skips:\n            try:\n                result = skip(r)\n                if result is True:\n                    yield True\n            except Exception as e:\n                if report_unexpected_exceptions:\n                    p = {'code': UNEXPECTED_EXCEPTION}\n                    if not summarize:\n                        p['message'] = MESSAGES[UNEXPECTED_EXCEPTION] % (e.__class__.__name__, e)\n                        p['row'] = i + 1\n                        p['record'] = r\n                        p['exception'] = e\n                        p['function'] = '%s: %s' % (skip.__name__,\n                                                    skip.__doc__)\n                        if context is not None: p['context'] = context\n                    yield p", "response": "Yields the result of applying the skip functions on r."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the record to a dictionary using field names as keys.", "response": "def _as_dict(self, r):\n        \"\"\"Convert the record to a dictionary using field names as keys.\"\"\"\n\n        d = dict()\n        for i, f in enumerate(self._field_names):\n            d[f] = r[i] if i < len(r) else None\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating an example CSV validator for patient demographic data.", "response": "def create_validator():\n    \"\"\"Create an example CSV validator for patient demographic data.\"\"\"\n\n    field_names = (\n                   'study_id', \n                   'patient_id', \n                   'gender', \n                   'age_years', \n                   'age_months',\n                   'date_inclusion'\n                   )\n    validator = CSVValidator(field_names)\n    \n    # basic header and record length checks\n    validator.add_header_check('EX1', 'bad header')\n    validator.add_record_length_check('EX2', 'unexpected record length')\n    \n    # some simple value checks\n    validator.add_value_check('study_id', int, \n                              'EX3', 'study id must be an integer')\n    validator.add_value_check('patient_id', int, \n                              'EX4', 'patient id must be an integer')\n    validator.add_value_check('gender', enumeration('M', 'F'), \n                              'EX5', 'invalid gender')\n    validator.add_value_check('age_years', number_range_inclusive(0, 120, int), \n                              'EX6', 'invalid age in years')\n    validator.add_value_check('date_inclusion', datetime_string('%Y-%m-%d'),\n                              'EX7', 'invalid date')\n    \n    # a more complicated record check\n    def check_age_variables(r):\n        age_years = int(r['age_years'])\n        age_months = int(r['age_months'])\n        valid = (age_months >= age_years * 12 and \n                 age_months % age_years < 12)\n        if not valid:\n            raise RecordError('EX8', 'invalid age variables')\n    validator.add_record_check(check_age_variables)\n    \n    return validator"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_tables(app, docname, source):\n    import markdown\n    md = markdown.Markdown(extensions=['markdown.extensions.tables'])\n    table_processor = markdown.extensions.tables.TableProcessor(md.parser)\n\n    raw_markdown = source[0]\n    blocks = re.split(r'\\n{2,}', raw_markdown)\n\n    for i, block in enumerate(blocks):\n        if table_processor.test(None, block):\n            html = md.convert(block)\n            styled = html.replace('<table>', '<table border=\"1\" class=\"docutils\">', 1)  # apply styling\n            blocks[i] = styled\n\n    # re-assemble into markdown-with-tables-replaced\n    # must replace element 0 for changes to persist\n    source[0] = '\\n\\n'.join(blocks)", "response": "Convert markdown tables to html"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npacks given values v1 v2... into given bytearray buf starting at bit offset offset.", "response": "def pack_into(fmt, buf, offset, *args, **kwargs):\n    \"\"\"Pack given values v1, v2, ... into given bytearray `buf`, starting\n    at given bit offset `offset`. Pack according to given format\n    string `fmt`. Give `fill_padding` as ``False`` to leave padding\n    bits in `buf` unmodified.\n\n    \"\"\"\n\n    return CompiledFormat(fmt).pack_into(buf,\n                                         offset,\n                                         *args,\n                                         **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pack_into_dict(fmt, names, buf, offset, data, **kwargs):\n\n    return CompiledFormatDict(fmt, names).pack_into(buf,\n                                                    offset,\n                                                    data,\n                                                    **kwargs)", "response": "Packs data into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef byteswap(fmt, data, offset=0):\n\n    data = BytesIO(data)\n    data.seek(offset)\n    data_swapped = BytesIO()\n\n    for f in fmt:\n        swapped = data.read(int(f))[::-1]\n        data_swapped.write(swapped)\n\n    return data_swapped.getvalue()", "response": "Swap bytes in data according to fmt starting at byte offset and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pack(self, *args):\n\n        # Sanity check of the number of arguments.\n        if len(args) < self._number_of_arguments:\n            raise Error(\n                \"pack expected {} item(s) for packing (got {})\".format(\n                    self._number_of_arguments,\n                    len(args)))\n\n        return self.pack_any(args)", "response": "Packs the given items into a new set of items."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pack_into(self, buf, offset, *args, **kwargs):\n\n        # Sanity check of the number of arguments.\n        if len(args) < self._number_of_arguments:\n            raise Error(\n                \"pack expected {} item(s) for packing (got {})\".format(\n                    self._number_of_arguments,\n                    len(args)))\n\n        self.pack_into_any(buf, offset, args, **kwargs)", "response": "Pack the items into the buffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unpack_from(self, data, offset=0):\n\n        return tuple([v[1] for v in self.unpack_from_any(data, offset)])", "response": "Unpack the bitstring from the given data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npacks the data dictionary into a single object.", "response": "def pack(self, data):\n        \"\"\"See :func:`~bitstruct.pack_dict()`.\n\n        \"\"\"\n\n        try:\n            return self.pack_any(data)\n        except KeyError as e:\n            raise Error('{} not found in data dictionary'.format(str(e)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npack the data into the buffer.", "response": "def pack_into(self, buf, offset, data, **kwargs):\n        \"\"\"See :func:`~bitstruct.pack_into_dict()`.\n\n        \"\"\"\n\n        try:\n            self.pack_into_any(buf, offset, data, **kwargs)\n        except KeyError as e:\n            raise Error('{} not found in data dictionary'.format(str(e)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unpack_from(self, data, offset=0):\n\n        return {info.name: v for info, v in self.unpack_from_any(data, offset)}", "response": "Unpacks the set of fields from the given data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cli(ctx, version):\n\n    # If no subcommand was given and the version flag is true, shows\n    # Bottery version\n    if not ctx.invoked_subcommand and version:\n        click.echo(bottery.__version__)\n        ctx.exit()\n\n    # If no subcommand but neither the version flag, shows help message\n    elif not ctx.invoked_subcommand:\n        click.echo(ctx.get_help())\n        ctx.exit()", "response": "Bottery version and help message"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_message(self, data):\n        '''\n        Return a Message instance according to the data received from\n        Telegram API.\n        https://core.telegram.org/bots/api#update\n        '''\n        message_data = data.get('message') or data.get('edited_message')\n\n        if not message_data:\n            return None\n\n        edited = 'edited_message' in data\n        return Message(\n            id=message_data['message_id'],\n            platform=self.platform,\n            text=message_data.get('text', ''),\n            user=TelegramUser(message_data['from']),\n            chat=TelegramChat(message_data['chat']),\n            timestamp=message_data['date'],\n            raw=data,\n            edited=edited,\n        )", "response": "Build a Message instance according to the data received from Telegram API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_chat_id(self, message):\n        '''\n        Telegram chat type can be either \"private\", \"group\", \"supergroup\" or\n        \"channel\".\n        Return user ID if it is of type \"private\", chat ID otherwise.\n        '''\n        if message.chat.type == 'private':\n            return message.user.id\n\n        return message.chat.id", "response": "Return Telegram chat ID if it is of type private otherwise return chat ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a Message instance according to the data received from Facebook Messenger API.", "response": "def build_message(self, data):\n        '''\n        Return a Message instance according to the data received from\n        Facebook Messenger API.\n        '''\n        if not data:\n            return None\n\n        return Message(\n            id=data['message']['mid'],\n            platform=self.platform,\n            text=data['message']['text'],\n            user=data['sender']['id'],\n            timestamp=data['timestamp'],\n            raw=data,\n            chat=None,  # TODO: Refactor build_messages and Message class\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget response from the view with async syntax.", "response": "async def _get_response(self, message):\n        \"\"\"\n        Get response running the view with await syntax if it is a\n        coroutine function, otherwise just run it the normal way.\n        \"\"\"\n\n        view = self.discovery_view(message)\n        if not view:\n            return\n\n        if inspect.iscoroutinefunction(view):\n            response = await view(message)\n        else:\n            response = view(message)\n\n        return self.prepare_response(response, message)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching for a registered view according to the new message.", "response": "def discovery_view(self, message):\n        \"\"\"\n        Use the new message to search for a registered view according\n        to its pattern.\n        \"\"\"\n        for handler in self.registered_handlers:\n            if handler.check(message):\n                return handler.view\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing a new message and send it to the client.", "response": "async def message_handler(self, data):\n        \"\"\"\n        For each new message, build its platform specific message\n        object and get a response.\n        \"\"\"\n\n        message = self.build_message(data)\n        if not message:\n            logger.error(\n                '[%s] Unable to build Message with data, data=%s, error',\n                self.engine_name,\n                data\n            )\n            return\n\n        logger.info('[%s] New message from %s: %s', self.engine_name,\n                    message.user, message.text)\n\n        response = await self.get_response(message)\n        if response:\n            await self.send_response(response)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nunpacking a byte string to the given format.", "response": "def unpack(endian, fmt, data):\n    \"\"\"Unpack a byte string to the given format. If the byte string\n    contains more bytes than required for the given format, the function\n    returns a tuple of values.\n    \"\"\"\n    if fmt == 's':\n        # read data as an array of chars\n        val = struct.unpack(''.join([endian, str(len(data)), 's']),\n                            data)[0]\n    else:\n        # read a number of values\n        num = len(data) // struct.calcsize(fmt)\n        val = struct.unpack(''.join([endian, str(num), fmt]), data)\n        if len(val) == 1:\n            val = val[0]\n    return val"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_file_header(fd, endian):\n    fields = [\n        ('description', 's', 116),\n        ('subsystem_offset', 's', 8),\n        ('version', 'H', 2),\n        ('endian_test', 's', 2)\n    ]\n    hdict = {}\n    for name, fmt, num_bytes in fields:\n        data = fd.read(num_bytes)\n        hdict[name] = unpack(endian, fmt, data)\n    hdict['description'] = hdict['description'].strip()\n    v_major = hdict['version'] >> 8\n    v_minor = hdict['version'] & 0xFF\n    hdict['__version__'] = '%d.%d' % (v_major, v_minor)\n    return hdict", "response": "Read mat 5 file header of the file fd."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_element_tag(fd, endian):\n    data = fd.read(8)\n    mtpn = unpack(endian, 'I', data[:4])\n    # The most significant two bytes of mtpn will always be 0,\n    # if they are not, this must be SDE format\n    num_bytes = mtpn >> 16\n    if num_bytes > 0:\n        # small data element format\n        mtpn = mtpn & 0xFFFF\n        if num_bytes > 4:\n            raise ParseError('Error parsing Small Data Element (SDE) '\n                             'formatted data')\n        data = data[4:4 + num_bytes]\n    else:\n        # regular element\n        num_bytes = unpack(endian, 'I', data[4:])\n        data = None\n    return (mtpn, num_bytes, data)", "response": "Read data element tag."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_elements(fd, endian, mtps, is_name=False):\n    mtpn, num_bytes, data = read_element_tag(fd, endian)\n    if mtps and mtpn not in [etypes[mtp]['n'] for mtp in mtps]:\n        raise ParseError('Got type {}, expected {}'.format(\n            mtpn, ' / '.join('{} ({})'.format(\n                etypes[mtp]['n'], mtp) for mtp in mtps)))\n    if not data:\n        # full format, read data\n        data = fd.read(num_bytes)\n        # Seek to next 64-bit boundary\n        mod8 = num_bytes % 8\n        if mod8:\n            fd.seek(8 - mod8, 1)\n\n    # parse data and return values\n    if is_name:\n        # names are stored as miINT8 bytes\n        fmt = 's'\n        val = [unpack(endian, fmt, s)\n               for s in data.split(b'\\0') if s]\n        if len(val) == 0:\n            val = ''\n        elif len(val) == 1:\n            val = asstr(val[0])\n        else:\n            val = [asstr(s) for s in val]\n    else:\n        fmt = etypes[inv_etypes[mtpn]]['fmt']\n        val = unpack(endian, fmt, data)\n    return val", "response": "Read elements from the file and return them as a list of possible matrix data types."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_header(fd, endian):\n    flag_class, nzmax = read_elements(fd, endian, ['miUINT32'])\n    header = {\n        'mclass': flag_class & 0x0FF,\n        'is_logical': (flag_class >> 9 & 1) == 1,\n        'is_global': (flag_class >> 10 & 1) == 1,\n        'is_complex': (flag_class >> 11 & 1) == 1,\n        'nzmax': nzmax\n    }\n    header['dims'] = read_elements(fd, endian, ['miINT32'])\n    header['n_dims'] = len(header['dims'])\n    if header['n_dims'] != 2:\n        raise ParseError('Only matrices with dimension 2 are supported.')\n    header['name'] = read_elements(fd, endian, ['miINT8'], is_name=True)\n    return header", "response": "Read and return the matrix header."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_var_header(fd, endian):\n    mtpn, num_bytes = unpack(endian, 'II', fd.read(8))\n    next_pos = fd.tell() + num_bytes\n\n    if mtpn == etypes['miCOMPRESSED']['n']:\n        # read compressed data\n        data = fd.read(num_bytes)\n        dcor = zlib.decompressobj()\n        # from here, read of the decompressed data\n        fd_var = BytesIO(dcor.decompress(data))\n        del data\n        fd = fd_var\n        # Check the stream is not so broken as to leave cruft behind\n        if dcor.flush() != b'':\n            raise ParseError('Error in compressed data.')\n        # read full tag from the uncompressed data\n        mtpn, num_bytes = unpack(endian, 'II', fd.read(8))\n\n    if mtpn != etypes['miMATRIX']['n']:\n        raise ParseError('Expecting miMATRIX type number {}, '\n                         'got {}'.format(etypes['miMATRIX']['n'], mtpn))\n    # read the header\n    header = read_header(fd, endian)\n    return header, next_pos, fd", "response": "Read the var header of the next tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_numeric_array(fd, endian, header, data_etypes):\n    if header['is_complex']:\n        raise ParseError('Complex arrays are not supported')\n    # read array data (stored as column-major)\n    data = read_elements(fd, endian, data_etypes)\n    if not isinstance(data, Sequence):\n        # not an array, just a value\n        return data\n    # transform column major data continous array to\n    # a row major array of nested lists\n    rowcount = header['dims'][0]\n    colcount = header['dims'][1]\n    array = [list(data[c * rowcount + r] for c in range(colcount))\n             for r in range(rowcount)]\n    # pack and return the array\n    return squeeze(array)", "response": "Read a numeric matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a cell array.", "response": "def read_cell_array(fd, endian, header):\n    \"\"\"Read a cell array.\n    Returns an array with rows of the cell array.\n    \"\"\"\n    array = [list() for i in range(header['dims'][0])]\n    for row in range(header['dims'][0]):\n        for col in range(header['dims'][1]):\n            # read the matrix header and array\n            vheader, next_pos, fd_var = read_var_header(fd, endian)\n            varray = read_var_array(fd_var, endian, vheader)\n            array[row].append(varray)\n            # move on to next field\n            fd.seek(next_pos)\n    # pack and return the array\n    if header['dims'][0] == 1:\n        return squeeze(array[0])\n    return squeeze(array)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading a struct array.", "response": "def read_struct_array(fd, endian, header):\n    \"\"\"Read a struct array.\n    Returns a dict with fields of the struct array.\n    \"\"\"\n    # read field name length (unused, as strings are null terminated)\n    field_name_length = read_elements(fd, endian, ['miINT32'])\n    if field_name_length > 32:\n        raise ParseError('Unexpected field name length: {}'.format(\n                         field_name_length))\n\n    # read field names\n    fields = read_elements(fd, endian, ['miINT8'], is_name=True)\n    if isinstance(fields, basestring):\n        fields = [fields]\n\n    # read rows and columns of each field\n    empty = lambda: [list() for i in range(header['dims'][0])]\n    array = {}\n    for row in range(header['dims'][0]):\n        for col in range(header['dims'][1]):\n            for field in fields:\n                # read the matrix header and array\n                vheader, next_pos, fd_var = read_var_header(fd, endian)\n                data = read_var_array(fd_var, endian, vheader)\n                if field not in array:\n                    array[field] = empty()\n                array[field][row].append(data)\n                # move on to next field\n                fd.seek(next_pos)\n    # pack the nested arrays\n    for field in fields:\n        rows = array[field]\n        for i in range(header['dims'][0]):\n            rows[i] = squeeze(rows[i])\n        array[field] = squeeze(array[field])\n    return array"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread a variable array of any supported type.", "response": "def read_var_array(fd, endian, header):\n    \"\"\"Read variable array (of any supported type).\"\"\"\n    mc = inv_mclasses[header['mclass']]\n\n    if mc in numeric_class_etypes:\n        return read_numeric_array(\n            fd, endian, header,\n            set(compressed_numeric).union([numeric_class_etypes[mc]])\n        )\n    elif mc == 'mxSPARSE_CLASS':\n        raise ParseError('Sparse matrices not supported')\n    elif mc == 'mxCHAR_CLASS':\n        return read_char_array(fd, endian, header)\n    elif mc == 'mxCELL_CLASS':\n        return read_cell_array(fd, endian, header)\n    elif mc == 'mxSTRUCT_CLASS':\n        return read_struct_array(fd, endian, header)\n    elif mc == 'mxOBJECT_CLASS':\n        raise ParseError('Object classes not supported')\n    elif mc == 'mxFUNCTION_CLASS':\n        raise ParseError('Function classes not supported')\n    elif mc == 'mxOPAQUE_CLASS':\n        raise ParseError('Anonymous function classes not supported')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef eof(fd):\n    b = fd.read(1)\n    end = len(b) == 0\n    if not end:\n        curpos = fd.tell()\n        fd.seek(curpos - 1)\n    return end", "response": "Determine if end - of - file is reached for file fd."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef loadmat(filename, meta=False):\n\n    if isinstance(filename, basestring):\n        fd = open(filename, 'rb')\n    else:\n        fd = filename\n\n    # Check mat file format is version 5\n    # For 5 format we need to read an integer in the header.\n    # Bytes 124 through 128 contain a version integer and an\n    # endian test string\n    fd.seek(124)\n    tst_str = fd.read(4)\n    little_endian = (tst_str[2:4] == b'IM')\n    endian = ''\n    if (sys.byteorder == 'little' and little_endian) or \\\n       (sys.byteorder == 'big' and not little_endian):\n        # no byte swapping same endian\n        pass\n    elif sys.byteorder == 'little':\n        # byte swapping\n        endian = '>'\n    else:\n        # byte swapping\n        endian = '<'\n    maj_ind = int(little_endian)\n    # major version number\n    maj_val = ord(tst_str[maj_ind]) if ispy2 else tst_str[maj_ind]\n    if maj_val != 1:\n        raise ParseError('Can only read from Matlab level 5 MAT-files')\n    # the minor version number (unused value)\n    # min_val = ord(tst_str[1 - maj_ind]) if ispy2 else tst_str[1 - maj_ind]\n\n    mdict = {}\n    if meta:\n        # read the file header\n        fd.seek(0)\n        mdict['__header__'] = read_file_header(fd, endian)\n        mdict['__globals__'] = []\n\n    # read data elements\n    while not eof(fd):\n        hdr, next_position, fd_var = read_var_header(fd, endian)\n        name = hdr['name']\n        if name in mdict:\n            raise ParseError('Duplicate variable name \"{}\" in mat file.'\n                             .format(name))\n\n        # read the matrix\n        mdict[name] = read_var_array(fd_var, endian, hdr)\n        if meta and hdr['is_global']:\n            mdict['__globals__'].append(name)\n\n        # move on to next entry in file\n        fd.seek(next_position)\n\n    fd.close()\n    return mdict", "response": "Load data from Matlab MAT - file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite data elements to the file.", "response": "def write_elements(fd, mtp, data, is_name=False):\n    \"\"\"Write data element tag and data.\n\n    The tag contains the array type and the number of\n    bytes the array data will occupy when written to file.\n\n    If data occupies 4 bytes or less, it is written immediately\n    as a Small Data Element (SDE).\n    \"\"\"\n    fmt = etypes[mtp]['fmt']\n    if isinstance(data, Sequence):\n        if fmt == 's' or is_name:\n            if isinstance(data, bytes):\n                if is_name and len(data) > 31:\n                    raise ValueError(\n                        'Name \"{}\" is too long (max. 31 '\n                        'characters allowed)'.format(data))\n                fmt = '{}s'.format(len(data))\n                data = (data,)\n            else:\n                fmt = ''.join('{}s'.format(len(s)) for s in data)\n        else:\n            l = len(data)\n            if l == 0:\n                # empty array\n                fmt = ''\n            if l > 1:\n                # more than one element to be written\n                fmt = '{}{}'.format(l, fmt)\n    else:\n        data = (data,)\n    num_bytes = struct.calcsize(fmt)\n    if num_bytes <= 4:\n        # write SDE\n        if num_bytes < 4:\n            # add pad bytes\n            fmt += '{}x'.format(4 - num_bytes)\n        fd.write(struct.pack('hh' + fmt, etypes[mtp]['n'],\n                 *chain([num_bytes], data)))\n        return\n    # write tag: element type and number of bytes\n    fd.write(struct.pack('b3xI', etypes[mtp]['n'], num_bytes))\n    # add pad bytes to fmt, if needed\n    mod8 = num_bytes % 8\n    if mod8:\n        fmt += '{}x'.format(8 - mod8)\n    # write data\n    fd.write(struct.pack(fmt, *data))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite variable data to file", "response": "def write_var_data(fd, data):\n    \"\"\"Write variable data to file\"\"\"\n    # write array data elements (size info)\n    fd.write(struct.pack('b3xI', etypes['miMATRIX']['n'], len(data)))\n\n    # write the data\n    fd.write(data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite compressed variable data to file", "response": "def write_compressed_var_array(fd, array, name):\n    \"\"\"Write compressed variable data to file\"\"\"\n    bd = BytesIO()\n\n    write_var_array(bd, array, name)\n\n    data = zlib.compress(bd.getvalue())\n    bd.close()\n\n    # write array data elements (size info)\n    fd.write(struct.pack('b3xI', etypes['miCOMPRESSED']['n'], len(data)))\n\n    # write the compressed data\n    fd.write(data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_numeric_array(fd, header, array):\n    # make a memory file for writing array data\n    bd = BytesIO()\n\n    # write matrix header to memory file\n    write_var_header(bd, header)\n\n    if not isinstance(array, basestring) and header['dims'][0] > 1:\n        # list array data in column major order\n        array = list(chain.from_iterable(izip(*array)))\n\n    # write matrix data to memory file\n    write_elements(bd, header['mtp'], array)\n\n    # write the variable to disk file\n    data = bd.getvalue()\n    bd.close()\n    write_var_data(fd, data)", "response": "Write the numeric array to disk"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites a variable array of any supported type.", "response": "def write_var_array(fd, array, name=''):\n    \"\"\"Write variable array (of any supported type)\"\"\"\n    header, array = guess_header(array, name)\n    mc = header['mclass']\n    if mc in numeric_class_etypes:\n        return write_numeric_array(fd, header, array)\n    elif mc == 'mxCHAR_CLASS':\n        return write_char_array(fd, header, array)\n    elif mc == 'mxCELL_CLASS':\n        return write_cell_array(fd, header, array)\n    elif mc == 'mxSTRUCT_CLASS':\n        return write_struct_array(fd, header, array)\n    else:\n        raise ValueError('Unknown mclass {}'.format(mc))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if test is True for all array elements.", "response": "def isarray(array, test, dim=2):\n    \"\"\"Returns True if test is True for all array elements.\n    Otherwise, returns False.\n    \"\"\"\n    if dim > 1:\n        return all(isarray(array[i], test, dim - 1)\n                   for i in range(len(array)))\n    return all(test(i) for i in array)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nguessing the array header information.", "response": "def guess_header(array, name=''):\n    \"\"\"Guess the array header information.\n    Returns a header dict, with class, data type, and size information.\n    \"\"\"\n    header = {}\n\n    if isinstance(array, Sequence) and len(array) == 1:\n        # sequence with only one element, squeeze the array\n        array = array[0]\n\n    if isinstance(array, basestring):\n        header.update({\n            'mclass': 'mxCHAR_CLASS', 'mtp': 'miUTF8',\n            'dims': (1 if len(array) > 0 else 0, len(array))})\n\n    elif isinstance(array, Sequence) and len(array) == 0:\n        # empty (int) array\n        header.update({\n            'mclass': 'mxINT32_CLASS', 'mtp': 'miINT32', 'dims': (0, 0)})\n\n    elif isinstance(array, Mapping):\n        # test if cells (values) of all fields are of equal type and\n        # have equal length\n        field_types = [type(j) for j in array.values()]\n        field_lengths = [1 if isinstance(j, (basestring, int, float))\n                         else len(j) for j in array.values()]\n        if len(field_lengths) == 1:\n            equal_lengths = True\n            equal_types = True\n        else:\n            equal_lengths = not any(diff(field_lengths))\n            equal_types = all([field_types[0] == f for f in field_types])\n\n        # if of unqeual lengths or unequal types, then treat each value\n        # as a cell in a 1x1 struct\n        header.update({\n            'mclass': 'mxSTRUCT_CLASS',\n            'dims': (\n                1,\n                field_lengths[0] if equal_lengths and equal_types else 1)}\n            )\n\n    elif isinstance(array, int):\n        header.update({\n            'mclass': 'mxINT32_CLASS', 'mtp': 'miINT32', 'dims': (1, 1)})\n\n    elif isinstance(array, float):\n        header.update({\n            'mclass': 'mxDOUBLE_CLASS', 'mtp': 'miDOUBLE', 'dims': (1, 1)})\n\n    elif isinstance(array, Sequence):\n\n        if isarray(array, lambda i: isinstance(i, int), 1):\n            # 1D int array\n            header.update({\n                'mclass': 'mxINT32_CLASS', 'mtp': 'miINT32',\n                'dims': (1, len(array))})\n\n        elif isarray(array, lambda i: isinstance(i, (int, float)), 1):\n            # 1D double array\n            header.update({\n                'mclass': 'mxDOUBLE_CLASS', 'mtp': 'miDOUBLE',\n                'dims': (1, len(array))})\n\n        elif (isarray(array, lambda i: isinstance(i, Sequence), 1) and\n                any(diff(len(s) for s in array))):\n            # sequence of unequal length, assume cell array\n            header.update({\n                'mclass': 'mxCELL_CLASS',\n                'dims': (1, len(array))\n            })\n\n        elif isarray(array, lambda i: isinstance(i, basestring), 1):\n            # char array\n            header.update({\n                'mclass': 'mxCHAR_CLASS', 'mtp': 'miUTF8',\n                'dims': (len(array), len(array[0]))})\n\n        elif isarray(array, lambda i: isinstance(i, Sequence), 1):\n            # 2D array\n\n            if any(diff(len(j) for j in array)):\n                # rows are of unequal length, make it a cell array\n                header.update({\n                    'mclass': 'mxCELL_CLASS',\n                    'dims': (len(array), len(array[0]))})\n\n            elif isarray(array, lambda i: isinstance(i, int)):\n                # 2D int array\n                header.update({\n                    'mclass': 'mxINT32_CLASS', 'mtp': 'miINT32',\n                    'dims': (len(array), len(array[0]))})\n\n            elif isarray(array, lambda i: isinstance(i, (int, float))):\n                # 2D double array\n                header.update({\n                    'mclass': 'mxDOUBLE_CLASS',\n                    'mtp': 'miDOUBLE',\n                    'dims': (len(array), len(array[0]))})\n\n        elif isarray(array, lambda i: isinstance(\n                i, (int, float, basestring, Sequence, Mapping))):\n            # mixed contents, make it a cell array\n            header.update({\n                'mclass': 'mxCELL_CLASS',\n                'dims': (1, len(array))})\n\n    if not header:\n        raise ValueError(\n            'Only dicts, two dimensional numeric, '\n            'and char arrays are currently supported')\n    header['name'] = name\n    return header, array"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves data to MAT - file.", "response": "def savemat(filename, data):\n    \"\"\"Save data to MAT-file:\n\n    savemat(filename, data)\n\n    The filename argument is either a string with the filename, or\n    a file like object.\n\n    The parameter ``data`` shall be a dict with the variables.\n\n    A ``ValueError`` exception is raised if data has invalid format, or if the\n    data structure cannot be mapped to a known MAT array type.\n    \"\"\"\n\n    if not isinstance(data, Mapping):\n        raise ValueError('Data should be a dict of variable arrays')\n\n    if isinstance(filename, basestring):\n        fd = open(filename, 'wb')\n    else:\n        fd = filename\n\n    write_file_header(fd)\n\n    # write variables\n    for name, array in data.items():\n        write_compressed_var_array(fd, array, name)\n\n    fd.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _execute(self, command, data=None, unpack=True):\n        if not data:\n            data = {}\n        if self.session_id is not None:\n            data.setdefault('session_id', self.session_id)\n        data = self._wrap_el(data)\n        res = self.remote_invoker.execute(command, data)\n        ret = WebDriverResult.from_object(res)\n        ret.raise_for_status()\n        ret.value = self._unwrap_el(ret.value)\n        if not unpack:\n            return ret\n        return ret.value", "response": "Private method to execute command."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _unwrap_el(self, value):\n        if isinstance(value, dict) and 'ELEMENT' in value:\n            element_id = value.get('ELEMENT')\n            return WebElement(element_id, self)\n        elif isinstance(value, list) and not isinstance(value, str):\n            return [self._unwrap_el(item) for item in value]\n        else:\n            return value", "response": "Convert the value field in the json response to WebElement Object\n           "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert WebElement Object to dict", "response": "def _wrap_el(self, value):\n        \"\"\"Convert WebElement Object to {'Element': 1234}\n\n        Args:\n            value(str|list|dict): The local value.\n\n        Returns:\n            The wrapped value.\n        \"\"\"\n        if isinstance(value, dict):\n            return {k: self._wrap_el(v) for k, v in value.items()}\n        elif isinstance(value, WebElement):\n            return {'ELEMENT': value.element_id}\n        elif isinstance(value, list) and not isinstance(value, str):\n            return [self._wrap_el(item) for item in value]\n        else:\n            return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new session by desiredCapabilities Support : Android iOS Web Web", "response": "def init(self):\n        \"\"\"Create Session by desiredCapabilities\n\n        Support:\n            Android iOS Web(WebView)\n\n        Returns:\n            WebDriver Object.\n        \"\"\"\n        resp = self._execute(Command.NEW_SESSION, {\n            'desiredCapabilities': self.desired_capabilities\n        }, False)\n        resp.raise_for_status()\n        self.session_id = str(resp.session_id)\n        self.capabilities = resp.value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nswitch focus to the given window.", "response": "def switch_to_window(self, window_name):\n        \"\"\"Switch to the given window.\n\n        Support:\n            Web(WebView)\n\n        Args:\n            window_name(str): The window to change focus to.\n\n        Returns:\n            WebDriver Object.\n        \"\"\"\n        data = {\n            'name': window_name\n        }\n        self._execute(Command.SWITCH_TO_WINDOW, data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_window_size(self, width, height, window_handle='current'):\n        self._execute(Command.SET_WINDOW_SIZE, {\n            'width': int(width),\n            'height': int(height),\n            'window_handle': window_handle})", "response": "Sets the width and height of the current window."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_window_position(self, x, y, window_handle='current'):\n        self._execute(Command.SET_WINDOW_POSITION, {\n            'x': int(x),\n            'y': int(y),\n            'window_handle': window_handle})", "response": "Sets the x y position of the current window."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndeprecate use element. touch move toX toY duration in seconds.", "response": "def move_to(self, element, x=0, y=0):\n        \"\"\"Deprecated use element.touch('drag', { toX, toY, duration(s) }) instead.\n            Move the mouse by an offset of the specificed element.\n\n        Support:\n            Android\n\n        Args:\n            element(WebElement): WebElement Object.\n            x(float): X offset to move to, relative to the\n                      top-left corner of the element.\n            y(float): Y offset to move to, relative to the\n                      top-left corner of the element.\n\n        Returns:\n            WebDriver object.\n        \"\"\"\n        self._execute(Command.MOVE_TO, {\n            'element': element.element_id,\n            'x': x,\n            'y': y\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef flick(self, element, x, y, speed):\n        self._execute(Command.FLICK, {\n            'element': element.element_id,\n            'x': x,\n            'y': y,\n            'speed': speed\n        })", "response": "Flick an element on the touch screen using finger motion events."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nswitches focus to the specified frame.", "response": "def switch_to_frame(self, frame_reference=None):\n        \"\"\"Switches focus to the specified frame, by index, name, or webelement.\n\n        Support:\n            Web(WebView)\n\n        Args:\n            frame_reference(None|int|WebElement):\n                The identifier of the frame to switch to.\n                None means to set to the default context.\n                An integer representing the index.\n                A webelement means that is an (i)frame to switch to.\n                Otherwise throw an error.\n\n        Returns:\n            WebDriver Object.\n        \"\"\"\n        if frame_reference is not None and type(frame_reference) not in [int, WebElement]:\n            raise TypeError('Type of frame_reference must be None or int or WebElement')\n        self._execute(Command.SWITCH_TO_FRAME,\n            {'id': frame_reference})"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute JavaScript Synchronously in current context.", "response": "def execute_script(self, script, *args):\n        \"\"\"Execute JavaScript Synchronously in current context.\n\n        Support:\n            Web(WebView)\n\n        Args:\n            script: The JavaScript to execute.\n            *args: Arguments for your JavaScript.\n\n        Returns:\n            Returns the return value of the function.\n        \"\"\"\n        return self._execute(Command.EXECUTE_SCRIPT, {\n            'script': script,\n            'args': list(args)})"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute_async_script(self, script, *args):\n        return self._execute(Command.EXECUTE_ASYNC_SCRIPT, {\n            'script': script,\n            'args': list(args)})", "response": "Execute JavaScript Asynchronously in current context."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset a cookie. Support: Web(WebView) Args: cookie_dict: A dictionary contain keys: \"name\", \"value\", [\"path\"], [\"domain\"], [\"secure\"], [\"httpOnly\"], [\"expiry\"]. Returns: WebElement Object.", "response": "def add_cookie(self, cookie_dict):\n        \"\"\"Set a cookie.\n\n        Support:\n            Web(WebView)\n\n        Args:\n            cookie_dict: A dictionary contain keys: \"name\", \"value\",\n                [\"path\"], [\"domain\"], [\"secure\"], [\"httpOnly\"], [\"expiry\"].\n\n        Returns:\n            WebElement Object.\n        \"\"\"\n        if not isinstance(cookie_dict, dict):\n            raise TypeError('Type of the cookie must be a dict.')\n        if not cookie_dict.get(\n            'name', None\n        ) or not cookie_dict.get(\n            'value', None):\n            raise KeyError('Missing required keys, \\'name\\' and \\'value\\' must be provided.')\n        self._execute(Command.ADD_COOKIE, {'cookie': cookie_dict})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_screenshot(self, filename, quietly = False):\n        imgData = self.take_screenshot()\n        try:\n            with open(filename, \"wb\") as f:\n                f.write(b64decode(imgData.encode('ascii')))\n        except IOError as err:\n            if not quietly:\n                raise err", "response": "Save the screenshot to a local file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding an element in the current context.", "response": "def element(self, using, value):\n        \"\"\"Find an element in the current context.\n\n        Support:\n            Android iOS Web(WebView)\n\n        Args:\n            using(str): The element location strategy.\n            value(str): The value of the location strategy.\n\n        Returns:\n            WebElement Object.\n\n        Raises:\n            WebDriverException.\n        \"\"\"\n        return self._execute(Command.FIND_ELEMENT, {\n            'using': using,\n            'value': value\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef element_if_exists(self, using, value):\n        try:\n            self._execute(Command.FIND_ELEMENT, {\n                'using': using,\n                'value': value\n            })\n            return True\n        except:\n            return False", "response": "Check if an element in the current context exists."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if an element exists and return None if it does not exist.", "response": "def element_or_none(self, using, value):\n        \"\"\"Check if an element in the current context.\n\n        Support:\n            Android iOS Web(WebView)\n\n        Args:\n            using(str): The element location strategy.\n            value(str): The value of the location strategy.\n\n        Returns:\n            Return Element if the element does exists and return None otherwise.\n\n        Raises:\n            WebDriverException.\n        \"\"\"\n        try:\n            return self._execute(Command.FIND_ELEMENT, {\n                'using': using,\n                'value': value\n            })\n        except:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef elements(self, using, value):\n        return self._execute(Command.FIND_ELEMENTS, {\n            'using': using,\n            'value': value\n        })", "response": "Find elements in the current context."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwaiting for the driver till satisfy the condition AttributeNames", "response": "def wait_for(\n        self, timeout=10000, interval=1000,\n        asserter=lambda x: x):\n        \"\"\"Wait for driver till satisfy the given condition\n\n        Support:\n            Android iOS Web(WebView)\n\n        Args:\n            timeout(int): How long we should be retrying stuff.\n            interval(int): How long between retries.\n            asserter(callable): The asserter func to determine the result.\n\n        Returns:\n            Return the driver.\n\n        Raises:\n            WebDriverException.\n        \"\"\"\n        if not callable(asserter):\n            raise TypeError('Asserter must be callable.')\n        @retry(\n            retry_on_exception=lambda ex: isinstance(ex, WebDriverException),\n            stop_max_delay=timeout,\n            wait_fixed=interval\n        )\n        def _wait_for(driver):\n            asserter(driver)\n            return driver\n\n        return _wait_for(self)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wait_for_element(\n        self, using, value, timeout=10000,\n        interval=1000, asserter=is_displayed):\n        \"\"\"Wait for element till satisfy the given condition\n\n        Support:\n            Android iOS Web(WebView)\n\n        Args:\n            using(str): The element location strategy.\n            value(str): The value of the location strategy.\n            timeout(int): How long we should be retrying stuff.\n            interval(int): How long between retries.\n            asserter(callable): The asserter func to determine the result.\n\n        Returns:\n            Return the Element.\n\n        Raises:\n            WebDriverException.\n        \"\"\"\n        if not callable(asserter):\n            raise TypeError('Asserter must be callable.')\n        @retry(\n            retry_on_exception=lambda ex: isinstance(ex, WebDriverException),\n            stop_max_delay=timeout,\n            wait_fixed=interval\n        )\n        def _wait_for_element(ctx, using, value):\n            el = ctx.element(using, value)\n            asserter(el)\n            return el\n\n        return _wait_for_element(self, using, value)", "response": "Wait for an element till satisfy the condition using."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wait_for_elements(\n        self, using, value, timeout=10000,\n        interval=1000, asserter=is_displayed):\n        \"\"\"Wait for elements till satisfy the given condition\n\n        Support:\n            Android iOS Web(WebView)\n\n        Args:\n            using(str): The element location strategy.\n            value(str): The value of the location strategy.\n            timeout(int): How long we should be retrying stuff.\n            interval(int): How long between retries.\n            asserter(callable): The asserter func to determine the result.\n\n        Returns:\n            Return the list of Element if any of them satisfy the condition.\n\n        Raises:\n            WebDriverException.\n        \"\"\"\n        if not callable(asserter):\n            raise TypeError('Asserter must be callable.')\n        @retry(\n            retry_on_exception=lambda ex: isinstance(ex, WebDriverException),\n            stop_max_delay=timeout,\n            wait_fixed=interval\n        )\n        def _wait_for_elements(ctx, using, value):\n            els = ctx.elements(using, value)\n            if not len(els):\n                raise WebDriverException('no such element')\n            else:\n                el = els[0]\n                asserter(el)\n                return els\n\n        return _wait_for_elements(self, using, value)", "response": "Wait for elements till satisfy the condition."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_object(cls, obj):\n        return cls(\n            obj.get('sessionId', None),\n            obj.get('status', 0),\n            obj.get('value', None)\n        )", "response": "The factory method to create WebDriverResult from a JSON object returned by server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nraising WebDriverException if returned status is not zero.", "response": "def raise_for_status(self):\n        \"\"\"Raise WebDriverException if returned status is not zero.\"\"\"\n        if not self.status:\n            return\n\n        error = find_exception_by_code(self.status)\n        message = None\n        screen = None\n        stacktrace = None\n\n        if isinstance(self.value, str):\n            message = self.value\n        elif isinstance(self.value, dict):\n            message = self.value.get('message', None)\n            screen = self.value.get('screen', None)\n            stacktrace = self.value.get('stacktrace', None)\n\n        raise WebDriverException(error, message, screen, stacktrace)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding element_by alias and extension methods (if_exists or or_none.", "response": "def add_element_extension_method(Klass):\n    \"\"\"Add element_by alias and extension' methods(if_exists/or_none).\"\"\"\n    def add_element_method(Klass, using):\n        locator = using.name.lower()\n        find_element_name = \"element_by_\" + locator\n        find_element_if_exists_name = \"element_by_\" + locator + \"_if_exists\"\n        find_element_or_none_name = \"element_by_\" + locator + \"_or_none\"\n        wait_for_element_name = \"wait_for_element_by_\" + locator\n\n        find_elements_name = \"elements_by_\" + locator\n        wait_for_elements_name = \"wait_for_elements_by_\" + locator\n\n        def find_element(self, value):\n            return self.element(using.value, value)\n\n        find_element.__name__ = find_element_name\n        find_element.__doc__ = (\n            \"Set parameter 'using' to '{0}'.\\n\".format(using.value) +\n            \"See more in \\'element\\' method.\"\n        )\n\n        def find_element_if_exists(self, value):\n            return self.element_if_exists(using.value, value)\n\n        find_element_if_exists.__name__ = find_element_if_exists_name\n        find_element_if_exists.__doc__ = (\n            \"Set parameter 'using' to '{0}'.\\n\".format(using.value) +\n            \"See more in \\'element_if_exists\\' method.\"\n        )\n\n        def find_element_or_none(self, value):\n            return self.element_or_none(using.value, value)\n\n        find_element_or_none.__name__ = find_element_or_none_name\n        find_element_or_none.__doc__ = (\n            \"Set parameter 'using' to '{0}'.\\n\".format(using.value) +\n            \"See more in \\'element_or_none\\' method.\"\n        )\n\n        def wait_for_element_by(self, *args, **kwargs):\n            return self.wait_for_element(using.value, *args, **kwargs)\n\n        wait_for_element_by.__name__ = wait_for_element_name\n        wait_for_element_by.__doc__ = (\n            \"Set parameter 'using' to '{0}'.\\n\".format(using.value) +\n            \"See more in \\'wait_for_element\\' method.\"\n        )\n\n        def find_elements(self, value):\n            return self.elements(using.value, value)\n\n        find_elements.__name__ = find_elements_name\n        find_elements.__doc__ = (\n            \"Set parameter 'using' to '{0}'.\\n\".format(using.value) +\n            \"See more in \\'elements\\' method.\"\n        )\n\n        def wait_for_elements_available(self, *args, **kwargs):\n            return self.wait_for_elements(using.value, *args, **kwargs)\n\n        wait_for_elements_available.__name__ = wait_for_elements_name\n        wait_for_elements_available.__doc__ = (\n            \"Set parameter 'using' to '{0}'.\\n\".format(using.value) +\n            \"See more in \\'wait_for_elements\\' method.\"\n        )\n\n        setattr(Klass, find_element_name, find_element)\n        setattr(Klass, find_element_if_exists_name, find_element_if_exists)\n        setattr(Klass, find_element_or_none_name, find_element_or_none)\n        setattr(Klass, wait_for_element_name, wait_for_element_by)\n        setattr(Klass, find_elements_name, find_elements)\n        setattr(Klass, wait_for_elements_name, wait_for_elements_available)\n\n    for locator in iter(Locator):\n        add_element_method(Klass, locator)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts value to a list of key strokes", "response": "def value_to_key_strokes(value):\n    \"\"\"Convert value to a list of key strokes\n    >>> value_to_key_strokes(123)\n    ['123']\n    >>> value_to_key_strokes('123')\n    ['123']\n    >>> value_to_key_strokes([1, 2, 3])\n    ['123']\n    >>> value_to_key_strokes(['1', '2', '3'])\n    ['123']\n\n    Args:\n        value(int|str|list)\n\n    Returns:\n        A list of string.\n    \"\"\"\n    result = ''\n    if isinstance(value, Integral):\n        value = str(value)\n\n    for v in value:\n        if isinstance(v, Keys):\n            result += v.value\n        elif isinstance(v, Integral):\n            result += str(v)\n        else:\n            result += v\n    return [result]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef value_to_single_key_strokes(value):\n    result = []\n    if isinstance(value, Integral):\n        value = str(value)\n\n    for v in value:\n        if isinstance(v, Keys):\n            result.append(v.value)\n        elif isinstance(v, Integral):\n            result.append(str(v))\n        else:\n            result.append(v)\n    return result", "response": "Convert value to a list of key strokes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nimplementing the check_unused_args in superclass.", "response": "def check_unused_args(self, used_args, args, kwargs):\n        \"\"\"Implement the check_unused_args in superclass.\"\"\"\n        for k, v in kwargs.items():\n            if k in used_args:\n                self._used_kwargs.update({k: v})\n            else:\n                self._unused_kwargs.update({k: v})"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nclearing used and unused dicts before each formatting.", "response": "def vformat(self, format_string, args, kwargs):\n        \"\"\"Clear used and unused dicts before each formatting.\"\"\"\n        self._used_kwargs = {}\n        self._unused_kwargs = {}\n        return super(MemorizeFormatter, self).vformat(format_string, args, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nformat a string by a map", "response": "def format_map(self, format_string, mapping):\n        \"\"\"format a string by a map\n\n        Args:\n            format_string(str): A format string\n            mapping(dict): A map to format the string\n\n        Returns:\n            A formatted string.\n\n        Raises:\n            KeyError: if key is not provided by the given map.\n        \"\"\"\n        return self.vformat(format_string, args=None, kwargs=mapping)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_exception_by_code(code):\n    errorName = None\n    for error in WebDriverError:\n        if error.value.code == code:\n            errorName = error\n            break\n    return errorName", "response": "Find error name by error code."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef execute(self, command, data={}):\n        method, uri = command\n        try:\n            path = self._formatter.format_map(uri, data)\n            body = self._formatter.get_unused_kwargs()\n            url = \"{0}{1}\".format(self._url, path)\n            return self._request(method, url, body)\n        except KeyError as err:\n            LOGGER.debug(\n                'Endpoint {0} is missing argument {1}'.format(uri, err))\n            raise", "response": "Execute a command on the remote server and return the json body."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _execute(self, command, data=None, unpack=True):\n        if not data:\n            data = {}\n        data.setdefault('element_id', self.element_id)\n        return self._driver._execute(command, data, unpack)", "response": "Private method to execute command with data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef element(self, using, value):\n        return self._execute(Command.FIND_CHILD_ELEMENT, {\n            'using': using,\n            'value': value\n        })", "response": "Find an element in the current element."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef element_or_none(self, using, value):\n        try:\n            return self._execute(Command.FIND_CHILD_ELEMENT, {\n                'using': using,\n                'value': value\n            })\n        except:\n            return None", "response": "Check if an element in the current element or return None if it does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef elements(self, using, value):\n        return self._execute(Command.FIND_CHILD_ELEMENTS, {\n            'using': using,\n            'value': value\n        })", "response": "Find elements in the current element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndeprecate use element. touch move to", "response": "def move_to(self, x=0, y=0):\n        \"\"\"Deprecated use element.touch('drag', { toX, toY, duration(s) }) instead.\n            Move the mouse by an offset of the specificed element.\n\n        Support:\n            Android\n\n        Args:\n            x(float): X offset to move to, relative to the\n                      top-left corner of the element.\n            y(float): Y offset to move to, relative to the\n                      top-left corner of the element.\n\n        Returns:\n            WebElement object.\n        \"\"\"\n        self._driver.move_to(self, x, y)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nflicks on the touch screen using finger motion events.", "response": "def flick(self, x, y, speed):\n        \"\"\"Deprecated use touch('drag', { fromX, fromY, toX, toY, duration(s) }) instead.\n            Flick on the touch screen using finger motion events.\n            This flickcommand starts at a particulat screen location.\n\n        Support:\n            iOS\n\n        Args:\n            x(float}: The x offset in pixels to flick by.\n            y(float): The y offset in pixels to flick by.\n            speed(float) The speed in pixels per seconds.\n\n        Returns:\n            WebElement object.\n        \"\"\"\n        self._driver.flick(self, x, y, speed)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef touch(self, name, args=None):\n        if isinstance(name, list) and not isinstance(name, str):\n            for obj in name:\n                obj['element'] = self.element_id\n            actions = name\n        elif isinstance(name, str):\n            if not args:\n                args = {}\n            args['type'] = name\n            args['element'] = self.element_id\n            actions = [args]\n        else:\n            raise TypeError('Invalid parameters.')\n        self._driver._execute(Command.PERFORM_ACTIONS, {\n            'actions': actions\n        })", "response": "Applies touch actions on devices. Such as tap doubleTap press pinch rotate drag."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nassert whether the target is displayed.", "response": "def is_displayed(target):\n    \"\"\"Assert whether the target is displayed\n\n    Args:\n        target(WebElement): WebElement Object.\n\n    Returns:\n        Return True if the element is displayed or return False otherwise.\n    \"\"\"\n    is_displayed = getattr(target, 'is_displayed', None)\n    if not is_displayed or not callable(is_displayed):\n        raise TypeError('Target has no attribute \\'is_displayed\\' or not callable')\n    if not is_displayed():\n        raise WebDriverException('element not visible')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nplugs in to Virtual USB Bus", "response": "def PlugIn(self):\n        \"\"\"Take next available controller id and plug in to Virtual USB Bus\"\"\"\n        ids = self.available_ids()\n        if len(ids) == 0:\n            raise MaxInputsReachedError('Max Inputs Reached')\n\n        self.id = ids[0]\n\n        _xinput.PlugIn(self.id)\n        while self.id in self.available_ids():\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nunplug the controller from Virtual USB Bus and free up ID.", "response": "def UnPlug(self, force=False):\n        \"\"\"Unplug controller from Virtual USB Bus and free up ID\"\"\"\n        if force:\n            _xinput.UnPlugForce(c_uint(self.id))\n        else:\n            _xinput.UnPlug(c_uint(self.id))\n        while self.id not in self.available_ids():\n            if self.id == 0:\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset a value on the controller.", "response": "def set_value(self, control, value=None):\n        \"\"\"Set a value on the controller\n    If percent is True all controls will accept a value between -1.0 and 1.0\n\n    If not then:\n        Triggers are 0 to 255\n        Axis are -32768 to 32767\n\n    Control List:\n        AxisLx          , Left Stick X-Axis\n        AxisLy          , Left Stick Y-Axis\n        AxisRx          , Right Stick X-Axis\n        AxisRy          , Right Stick Y-Axis\n        BtnBack         , Menu/Back Button\n        BtnStart        , Start Button\n        BtnA            , A Button\n        BtnB            , B Button\n        BtnX            , X Button\n        BtnY            , Y Button\n        BtnThumbL       , Left Thumbstick Click\n        BtnThumbR       , Right Thumbstick Click\n        BtnShoulderL    , Left Shoulder Button\n        BtnShoulderR    , Right Shoulder Button\n        Dpad            , Set Dpad Value (0 = Off, Use DPAD_### Constants)\n        TriggerL        , Left Trigger\n        TriggerR        , Right Trigger\n\n    \"\"\"\n        func = getattr(_xinput, 'Set' + control)\n\n        if 'Axis' in control:\n            target_type = c_short\n\n            if self.percent:\n                target_value = int(32767 * value)\n            else:\n                target_value = value\n        elif 'Btn' in control:\n            target_type = c_bool\n            target_value = bool(value)\n        elif 'Trigger' in control:\n            target_type = c_byte\n\n            if self.percent:\n                target_value = int(255 * value)\n            else:\n                target_value = value\n        elif 'Dpad' in control:\n            target_type = c_int\n            target_value = int(value)\n\n        func(c_uint(self.id), target_type(target_value))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntest the functionality of the rController object", "response": "def main():\n    \"\"\"Test the functionality of the rController object\"\"\"\n    import time\n\n    print('Testing controller in position 1:')\n    print('Running 3 x 3 seconds tests')\n\n    # Initialise Controller\n    con = rController(1)\n\n    # Loop printing controller state and buttons held\n    for i in range(3):\n        print('Waiting...')\n        time.sleep(2.5)\n        print('State: ', con.gamepad)\n        print('Buttons: ', con.buttons)\n        time.sleep(0.5)\n\n    print('Done!')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gamepad(self):\n        state = _xinput_state()\n        _xinput.XInputGetState(self.ControllerID - 1, pointer(state))\n        self.dwPacketNumber = state.dwPacketNumber\n\n        return state.XINPUT_GAMEPAD", "response": "Returns the current gamepad state."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of buttons currently pressed", "response": "def buttons(self):\n        \"\"\"Returns a list of buttons currently pressed\"\"\"\n        return [name for name, value in rController._buttons.items()\n                if self.gamepad.wButtons & value == value]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndecoding a 7 - bit ASCII header value into its actual value.", "response": "def maybe_decode_header(header):\n    \"\"\"\n    Decodes an encoded 7-bit ASCII header value into it's actual value.\n    \"\"\"\n    value, encoding = decode_header(header)[0]\n    if encoding:\n        return value.decode(encoding)\n    else:\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nimporting all available previews classes.", "response": "def autodiscover():\n    \"\"\"\n    Imports all available previews classes.\n    \"\"\"\n    from django.conf import settings\n    for application in settings.INSTALLED_APPS:\n        module = import_module(application)\n\n        if module_has_submodule(module, 'emails'):\n            emails = import_module('%s.emails' % application)\n            try:\n                import_module('%s.emails.previews' % application)\n            except ImportError:\n                # Only raise the exception if this module contains previews and\n                # there was a problem importing them. (An emails module that\n                # does not contain previews is not an error.)\n                if module_has_submodule(emails, 'previews'):\n                    raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters a new preview with the index.", "response": "def register(self, cls):\n        \"\"\"\n        Adds a preview to the index.\n        \"\"\"\n        preview = cls(site=self)\n        logger.debug('Registering %r with %r', preview, self)\n        index = self.__previews.setdefault(preview.module, {})\n        index[cls.__name__] = preview"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a detail view for the given module and preview.", "response": "def detail_view(self, request, module, preview):\n        \"\"\"\n        Looks up a preview in the index, returning a detail view response.\n        \"\"\"\n        try:\n            preview = self.__previews[module][preview]\n        except KeyError:\n            raise Http404  # The provided module/preview does not exist in the index.\n        return preview.detail_view(request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the URL to access this preview.", "response": "def url(self):\n        \"\"\"\n        The URL to access this preview.\n        \"\"\"\n        return reverse('%s:detail' % URL_NAMESPACE, kwargs={\n            'module': self.module,\n            'preview': type(self).__name__,\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrender the message view to a response.", "response": "def detail_view(self, request):\n        \"\"\"\n        Renders the message view to a response.\n        \"\"\"\n        context = {\n            'preview': self,\n        }\n\n        kwargs = {}\n        if self.form_class:\n            if request.GET:\n                form = self.form_class(data=request.GET)\n            else:\n                form = self.form_class()\n\n            context['form'] = form\n            if not form.is_bound or not form.is_valid():\n                return render(request, 'mailviews/previews/detail.html', context)\n\n            kwargs.update(form.get_message_view_kwargs())\n\n        message_view = self.get_message_view(request, **kwargs)\n\n        message = message_view.render_to_message()\n        raw = message.message()\n        headers = OrderedDict((header, maybe_decode_header(raw[header])) for header in self.headers)\n\n        context.update({\n            'message': message,\n            'subject': message.subject,\n            'body': message.body,\n            'headers': headers,\n            'raw': raw.as_string(),\n        })\n\n        alternatives = getattr(message, 'alternatives', [])\n        try:\n            html = next(alternative[0] for alternative in alternatives\n                if alternative[1] == 'text/html')\n            context.update({\n                'html': html,\n                'escaped_html': b64encode(html.encode('utf-8')),\n            })\n        except StopIteration:\n            pass\n\n        return render(request, self.template_name, context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef split_docstring(value):\n    docstring = textwrap.dedent(getattr(value, '__doc__', ''))\n    if not docstring:\n        return None\n\n    pieces = docstring.strip().split('\\n\\n', 1)\n    try:\n        body = pieces[1]\n    except IndexError:\n        body = None\n\n    return Docstring(pieces[0], body)", "response": "Splits the docstring of the given value into its summary and body."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering and returns an unsent message with the provided context.", "response": "def render_to_message(self, extra_context=None, **kwargs):\n        \"\"\"\n        Renders and returns an unsent message with the provided context.\n\n        Any extra keyword arguments passed will be passed through as keyword\n        arguments to the message constructor.\n\n        :param extra_context: Any additional context to use when rendering the\n            templated content.\n        :type extra_context: :class:`dict`\n        :returns: A message instance.\n        :rtype: :attr:`.message_class`\n        \"\"\"\n        if extra_context is None:\n            extra_context = {}\n\n        # Ensure our custom headers are added to the underlying message class.\n        kwargs.setdefault('headers', {}).update(self.headers)\n\n        context = self.get_context_data(**extra_context)\n        return self.message_class(\n            subject=self.render_subject(context),\n            body=self.render_body(context),\n            **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrender and sends an email message.", "response": "def send(self, extra_context=None, **kwargs):\n        \"\"\"\n        Renders and sends an email message.\n\n        All keyword arguments other than ``extra_context`` are passed through\n        as keyword arguments when constructing a new :attr:`message_class`\n        instance for this message.\n\n        This method exists primarily for convenience, and the proper\n        rendering of your message should not depend on the behavior of this\n        method. To alter how a message is created, override\n        :meth:``render_to_message`` instead, since that should always be\n        called, even if a message is not sent.\n\n        :param extra_context: Any additional context data that will be used\n            when rendering this message.\n        :type extra_context: :class:`dict`\n        \"\"\"\n        message = self.render_to_message(extra_context=extra_context, **kwargs)\n        return message.send()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render_subject(self, context):\n        rendered = self.subject_template.render(unescape(context))\n        return rendered.strip()", "response": "Renders the subject for the given context."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrender and returns an unsent message with the given context.", "response": "def render_to_message(self, extra_context=None, *args, **kwargs):\n        \"\"\"\n        Renders and returns an unsent message with the given context.\n\n        Any extra keyword arguments passed will be passed through as keyword\n        arguments to the message constructor.\n\n        :param extra_context: Any additional context to use when rendering\n            templated content.\n        :type extra_context: :class:`dict`\n        :returns: A message instance.\n        :rtype: :attr:`.message_class`\n        \"\"\"\n        message = super(TemplatedHTMLEmailMessageView, self)\\\n            .render_to_message(extra_context, *args, **kwargs)\n\n        if extra_context is None:\n            extra_context = {}\n\n        context = self.get_context_data(**extra_context)\n        content = self.render_html_body(context)\n        message.attach_alternative(content, mimetype='text/html')\n        return message"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef timestamp(_, dt):\n    'get microseconds since 2000-01-01 00:00'\n    # see http://stackoverflow.com/questions/2956886/\n    dt = util.to_utc(dt)\n    unix_timestamp = calendar.timegm(dt.timetuple())\n    # timetuple doesn't maintain microseconds\n    # see http://stackoverflow.com/a/14369386/519015\n    val = ((unix_timestamp - psql_epoch) * 1000000) + dt.microsecond\n    return ('iq', (8, val))", "response": "get microseconds since 2000 - 01 - 01 00 : 00"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a string that represents a numeric value in the ISO - 8601 format.", "response": "def numeric(_, n):\n    \"\"\"\n    NBASE = 1000\n    ndigits = total number of base-NBASE digits\n    weight = base-NBASE weight of first digit\n    sign = 0x0000 if positive, 0x4000 if negative, 0xC000 if nan\n    dscale = decimal digits after decimal place\n    \"\"\"\n    try:\n        nt = n.as_tuple()\n    except AttributeError:\n        raise TypeError('numeric field requires Decimal value (got %r)' % n)\n    digits = []\n    if isinstance(nt.exponent, str):\n        # NaN, Inf, -Inf\n        ndigits = 0\n        weight = 0\n        sign = 0xC000\n        dscale = 0\n    else:\n        decdigits = list(reversed(nt.digits + (nt.exponent % 4) * (0,)))\n        weight = 0\n        while decdigits:\n            if any(decdigits[:4]):\n                break\n            weight += 1\n            del decdigits[:4]\n        while decdigits:\n            digits.insert(0, ndig(decdigits[:4]))\n            del decdigits[:4]\n        ndigits = len(digits)\n        weight += nt.exponent // 4 + ndigits - 1\n        sign = nt.sign * 0x4000\n        dscale = -min(0, nt.exponent)\n    data = [ndigits, weight, sign, dscale] + digits\n    return ('ihhHH%dH' % ndigits, [2 * len(data)] + data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_default_subparser(self, name, args=None):\n    subparser_found = False\n    for arg in sys.argv[1:]:\n        if arg in ['-h', '--help']:  # global help if no subparser\n            break\n    else:\n        for x in self._subparsers._actions:\n            if not isinstance(x, argparse._SubParsersAction):\n                continue\n            for sp_name in x._name_parser_map.keys():\n                if sp_name in sys.argv[1:]:\n                    subparser_found = True\n        if not subparser_found:\n            # insert default in first position, this implies no\n            # global options without a sub_parsers specified\n            if args is None:\n                sys.argv.insert(1, name)\n            else:\n                args.insert(0, name)", "response": "set the default subparser for this command line"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a record to JSON - encode through redis.", "response": "def format(self, record):\n        \"\"\"\n        JSON-encode a record for serializing through redis.\n\n        Convert date to iso format, and stringify any exceptions.\n        \"\"\"\n        data = record._raw.copy()\n\n        # serialize the datetime date as utc string\n        data['time'] = data['time'].isoformat()\n\n        # stringify exception data\n        if data.get('traceback'):\n            data['traceback'] = self.formatException(data['traceback'])\n\n        return json.dumps(data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npublish a record to redis logging channel", "response": "def emit(self, record):\n        \"\"\"\n        Publish record to redis logging channel\n        \"\"\"\n        try:\n            self.redis_client.publish(self.channel, self.format(record))\n        except redis.RedisError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef emit(self, record):\n        try:\n            if self.max_messages:\n                p = self.redis_client.pipeline()\n                p.rpush(self.key, self.format(record))\n                p.ltrim(self.key, -self.max_messages, -1)\n                p.execute()\n            else:\n                self.redis_client.rpush(self.key, self.format(record))\n        except redis.RedisError:\n            pass", "response": "Publish a record to the redis logging list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef require_template_debug(f):\n    def _(*args, **kwargs):\n        TEMPLATE_DEBUG = getattr(settings, 'TEMPLATE_DEBUG', False)\n        return f(*args, **kwargs) if TEMPLATE_DEBUG else ''\n    return _", "response": "Decorator that ensures that the TEMPLATE_DEBUG setting is set to True."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndisplays the details of the variable attributes in the terminal.", "response": "def _display_details(var_data):\n    \"\"\"\n    Given a dictionary of variable attribute data from get_details display the\n    data in the terminal.\n    \"\"\"\n    meta_keys = (key for key in list(var_data.keys())\n                 if key.startswith('META_'))\n    for key in meta_keys:\n        display_key = key[5:].capitalize()\n        pprint('{0}: {1}'.format(display_key, var_data.pop(key)))\n    pprint(var_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_trace(context):\n    try:\n        import ipdb as pdb\n    except ImportError:\n        import pdb\n        print(\"For best results, pip install ipdb.\")\n    print(\"Variables that are available in the current context:\")\n    render = lambda s: template.Template(s).render(context)\n    availables = get_variables(context)\n    pprint(availables)\n    print('Type `availables` to show this list.')\n    print('Type <variable_name> to access one.')\n    print('Use render(\"template string\") to test template rendering')\n    # Cram context variables into the local scope\n    for var in availables:\n        locals()[var] = context[var]\n    pdb.set_trace()\n    return ''", "response": "Start a pdb set_trace inside of the template with the given context. Uses ipdb if available."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts a pydevd settrace on the next page", "response": "def pydevd(context):\n    \"\"\"\n    Start a pydev settrace\n    \"\"\"\n    global pdevd_not_available\n    if pdevd_not_available:\n        return ''\n    try:\n        import pydevd\n    except ImportError:\n        pdevd_not_available = True\n        return ''\n    render = lambda s: template.Template(s).render(context)\n    availables = get_variables(context)\n    for var in availables:\n        locals()[var] = context[var]\n    #catch the case where no client is listening\n    try:\n        pydevd.settrace()\n    except socket.error:\n        pdevd_not_available = True\n    return ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _flatten(iterable):\n    for i in iterable:\n        if isinstance(i, Iterable) and not isinstance(i, string_types):\n            for sub_i in _flatten(i):\n                yield sub_i\n        else:\n            yield i", "response": "Given an iterable with nested iterables generate a flat iterable"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a variable in the context obtain the attributes and callables and their values where possible and add them in the var_data dictionary.", "response": "def get_details(var):\n    \"\"\"\n    Given a variable inside the context, obtain the attributes/callables,\n    their values where possible, and the module name and class name if possible\n    \"\"\"\n    var_data = {}\n    # Obtain module and class details if available and add them in\n    module = getattr(var, '__module__', '')\n    kls = getattr(getattr(var, '__class__', ''), '__name__', '')\n    if module:\n        var_data['META_module_name'] = module\n    if kls:\n        var_data['META_class_name'] = kls\n    for attr in get_attributes(var):\n        value = _get_detail_value(var, attr)\n        if value is not None:\n            var_data[attr] = value\n    return var_data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_detail_value(var, attr):\n    value = getattr(var, attr)\n    # Rename common Django class names\n    kls = getattr(getattr(value, '__class__', ''), '__name__', '')\n    if kls in ('ManyRelatedManager', 'RelatedManager', 'EmptyManager'):\n        return kls\n    if callable(value):\n        return 'routine'\n    return value", "response": "Returns the value of a variable and one of its attributes that are available inside of\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a varaible return the list of attributes that are available inside the template", "response": "def get_attributes(var):\n    \"\"\"\n    Given a varaible, return the list of attributes that are available inside\n    of a template\n    \"\"\"\n    is_valid = partial(is_valid_in_template, var)\n    return list(filter(is_valid, dir(var)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a variable and an attribute returns True or False accordingly", "response": "def is_valid_in_template(var, attr):\n    \"\"\"\n    Given a variable and one of its attributes, determine if the attribute is\n    accessible inside of a Django template and return True or False accordingly\n    \"\"\"\n    # Remove private variables or methods\n    if attr.startswith('_'):\n        return False\n    # Remove any attributes that raise an acception when read\n    try:\n        value = getattr(var, attr)\n    except:\n        return False\n    if isroutine(value):\n        # Remove any routines that are flagged with 'alters_data'\n        if getattr(value, 'alters_data', False):\n            return False\n        else:\n            # Remove any routines that require arguments\n            try:\n                argspec = getargspec(value)\n                num_args = len(argspec.args) if argspec.args else 0\n                num_defaults = len(argspec.defaults) if argspec.defaults else 0\n                if num_args - num_defaults > 1:\n                    return False\n            except TypeError:\n                # C extension callables are routines, but getargspec fails with\n                # a TypeError when these are passed.\n                pass\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nincrementing version number string version.", "response": "def version_bump(self, version, type=\"bug\"):\n        \"\"\"\n        Increment version number string 'version'.\n        \n        Type can be one of: major, minor, or bug \n        \"\"\"\n        parsed_version = LooseVersion(version).version\n        total_components = max(3, len(parsed_version))\n        \n        bits = []\n        for bit in parsed_version:\n            try:\n                bit = int(bit)\n            except ValueError:\n                continue\n            \n            bits.append(bit)\n        \n        indexes = {\n            \"major\": 0,\n            \"minor\": 1,\n            \"bug\": 2,\n        }\n        \n        bits += [0] * (3 - len(bits)) # pad to 3 digits\n        \n        # Increment the version\n        bits[indexes[type]] += 1\n        \n        # Set the subsequent digits to 0\n        for i in range(indexes[type] + 1, 3):\n            bits[i] = 0\n        \n        return \".\".join(map(str, bits))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef determine_paths(self, package_name=None, create_package_dir=False, dry_run=False):\n        \n        # Give preference to the environment variable here as it will not \n        # derefrence sym links\n        self.project_dir = Path(os.getenv('PWD') or os.getcwd())\n        \n        # Try and work out the project name\n        distribution = self.get_distribution()\n        if distribution:\n            # Get name from setup.py\n            self.project_name = distribution.get_name()\n        else:\n            # ...failing that, use the current directory name\n            self.project_name = self.project_dir.name\n        \n        # Descend into the 'src' directory to find the package \n        # if necessary\n        if os.path.isdir(self.project_dir / \"src\"):\n            package_search_dir = self.project_dir / \"src\"\n        else:\n            package_search_dir = self.project_dir\n\n        created_package_dir = False\n        if not package_name:\n            # Lets try and work out the package_name from the project_name\n            package_name = self.project_name.replace(\"-\", \"_\")\n            \n            # Now do some fuzzy matching\n            def get_matches(name):\n                possibles = [n for n in os.listdir(package_search_dir) if os.path.isdir(package_search_dir / n)]\n                return difflib.get_close_matches(name, possibles, n=1, cutoff=0.8)\n            \n            close = get_matches(package_name)\n            \n            # If no matches, try removing the first part of the package name\n            # (e.g. django-guardian becomes guardian)\n            if not close and \"_\" in package_name:\n                short_package_name = \"_\".join(package_name.split(\"_\")[1:])\n                close = get_matches(short_package_name)\n            \n            if not close:\n                if create_package_dir:\n                    package_dir = package_search_dir / package_name\n                    # Gets set to true even during dry run\n                    created_package_dir = True\n                    if not dry_run:\n                        print(\"Creating package directory at %s\" % package_dir)\n                        os.mkdir(package_dir)\n                    else:\n                        print(\"Would have created package directory at %s\" % package_dir)\n                else:\n                    raise CommandError(\"Could not guess the package name. Specify it using --name.\")\n            else:\n                package_name = close[0]\n        \n        self.package_name = package_name\n        self.package_dir = package_search_dir / package_name\n\n        if not os.path.exists(self.package_dir) and not created_package_dir:\n            raise CommandError(\"Package directory did not exist at %s. Perhaps specify it using --name\" % self.package_dir)", "response": "Determine paths automatically and a little intelligently."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_integrity(sakefile, settings):\n    sprint = settings[\"sprint\"]\n    error = settings[\"error\"]\n    sprint(\"Call to check_integrity issued\", level=\"verbose\")\n    if not sakefile:\n        error(\"Sakefile is empty\")\n        return False\n    # checking for duplicate targets\n    if len(sakefile.keys()) != len(set(sakefile.keys())):\n        error(\"Sakefile contains duplicate targets\")\n        return False\n    for target in sakefile:\n        if target == \"all\":\n            if not check_target_integrity(target, sakefile[\"all\"], all=True):\n                error(\"Failed to accept target 'all'\")\n                return False\n            continue\n        if \"formula\" not in sakefile[target]:\n            if not check_target_integrity(target, sakefile[target],\n                                          meta=True):\n                errmes = \"Failed to accept meta-target '{}'\".format(target)\n                error(errmes)\n                return False\n            for atom_target in sakefile[target]:\n                if atom_target == \"help\":\n                    continue\n                if not check_target_integrity(atom_target,\n                                              sakefile[target][atom_target],\n                                              parent=target):\n                    errmes = \"Failed to accept target '{}'\\n\".format(\n                                                                atom_target)\n                    error(errmes)\n                    return False\n            continue\n        if not check_target_integrity(target, sakefile[target]):\n            errmes = \"Failed to accept target '{}'\\n\".format(target)\n            error(errmes)\n            return False\n    return True", "response": "Checks the format of the Sakefile to ensure it conforms to the specification of the current language."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks the integrity of a specific target.", "response": "def check_target_integrity(key, values, meta=False, all=False, parent=None):\n    \"\"\"\n    Checks the integrity of a specific target. Gets called\n    multiple times from check_integrity()\n\n    Args:\n        The target name\n        The dictionary values of that target\n        A boolean representing whether it is a meta-target\n        A boolean representing whether it is the \"all\" target\n        A string representing name of parent (default None)\n\n    Returns:\n        True is the target is conformant\n        False if not\n    \"\"\"\n\n    # logic to audit \"all\" target\n    if all:\n        if not values:\n            print(\"Warning: target 'all' is empty\")\n        # will check if it has unrecognized target later\n        return True\n\n    errmes = \"target '{}' is not allowed to be missing a help message\\n\"\n\n    # logic to audit a meta-target\n    if meta:\n        # check if help is missing\n        if \"help\" not in values:\n            sys.stderr.write(errmes.format(key))\n            return False\n        # checking if empty\n        if len(values.keys()) == 1:\n            sys.stderr.write(\"Meta-target '{}' is empty\\n\".format(key))\n            return False\n        return True\n\n    # logic to audit any other target\n    expected_fields = [\"dependencies\", \"help\", \"output\", \"formula\"]\n    expected_fields = set(expected_fields)\n    try:\n        our_keys_set = set(values.keys())\n    except:\n        sys.stderr.write(\"Error processing target '{}'\\n\".format(key))\n        sys.stderr.write(\"Are you sure '{}' is a meta-target?\\n\".format(\n                                                                     parent))\n        sys.stderr.write(\"If it's not, it's missing a formula\\n\")\n        return False\n    ignored_fields = set([field for field in our_keys_set\\\n                          if field.strip().startswith(\"(ignore)\")])\n    difference = our_keys_set - expected_fields - ignored_fields\n    if difference:\n        print(\"The following fields were not recognized and will be ignored\")\n        for item in difference:\n            print(\"  - \" + item)\n    if \"help\" not in values:\n        sys.stderr.write(errmes.format(key))\n        return False\n    # can't be missing formula either\n    if \"formula\" not in values:\n        sys.stderr.write(\"Target '{}' is missing formula\\n\".format(key))\n        return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if the current version of sake is in the from_store.", "response": "def check_shastore_version(from_store, settings):\n    \"\"\"\n    This function gives us the option to emit errors or warnings\n    after sake upgrades\n    \"\"\"\n    sprint = settings[\"sprint\"]\n    error = settings[\"error\"]\n\n    sprint(\"checking .shastore version for potential incompatibilities\",\n           level=\"verbose\")\n    if not from_store or 'sake version' not in from_store:\n        errmes = [\"Since you've used this project last, a new version of \",\n                  \"sake was installed that introduced backwards incompatible\",\n                  \" changes. Run 'sake clean', and rebuild before continuing\\n\"]\n        errmes = \" \".join(errmes)\n        error(errmes)\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn sha1 hash of the file supplied as an argument", "response": "def get_sha(a_file, settings=None):\n    \"\"\"\n    Returns sha1 hash of the file supplied as an argument\n    \"\"\"\n    if settings:\n        error = settings[\"error\"]\n    else:\n        error = ERROR_FN\n    try:\n        BLOCKSIZE = 65536\n        hasher = hashlib.sha1()\n        with io.open(a_file, \"rb\") as fh:\n            buf = fh.read(BLOCKSIZE)\n            while len(buf) > 0:\n                hasher.update(buf)\n                buf = fh.read(BLOCKSIZE)\n        the_hash = hasher.hexdigest()\n    except IOError:\n        errmes = \"File '{}' could not be read! Exiting!\".format(a_file)\n        error(errmes)\n        sys.exit(1)\n    except:\n        errmes = \"Unspecified error returning sha1 hash. Exiting!\"\n        error(errmes)\n        sys.exit(1)\n    return the_hash"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_shas_to_shastore(sha_dict):\n    if sys.version_info[0] < 3:\n        fn_open = open\n    else:\n        fn_open = io.open\n    with fn_open(\".shastore\", \"w\") as fh:\n        fh.write(\"---\\n\")\n        fh.write('sake version: {}\\n'.format(constants.VERSION))\n        if sha_dict:\n            fh.write(yaml.dump(sha_dict))\n        fh.write(\"...\")", "response": "Writes a sha1 dictionary stored in memory to\nAttributeNames the. shastore file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef take_shas_of_all_files(G, settings):\n    global ERROR_FN\n    sprint = settings[\"sprint\"]\n    error = settings[\"error\"]\n    ERROR_FN = error\n    sha_dict = {}\n    all_files = []\n    for target in G.nodes(data=True):\n        sprint(\"About to take shas of files in target '{}'\".format(target[0]),\n               level=\"verbose\")\n        if 'dependencies' in target[1]:\n            sprint(\"It has dependencies\", level=\"verbose\")\n            deplist = []\n            for dep in target[1]['dependencies']:\n                glist = glob.glob(dep)\n                if glist:\n                    for oneglob in glist:\n                        deplist.append(oneglob)\n                else:\n                    deplist.append(dep)\n            target[1]['dependencies'] = list(deplist)\n            for dep in target[1]['dependencies']:\n                sprint(\"  - {}\".format(dep), level=\"verbose\")\n                all_files.append(dep)\n        if 'output' in target[1]:\n            sprint(\"It has outputs\", level=\"verbose\")\n            for out in acts.get_all_outputs(target[1]):\n                sprint(\"  - {}\".format(out), level=\"verbose\")\n                all_files.append(out)\n    if len(all_files):\n        sha_dict['files'] = {}\n        # check if files exist and de-dupe\n        extant_files = []\n        for item in all_files:\n            if item not in extant_files and os.path.isfile(item):\n                extant_files.append(item)\n        pool = Pool()\n        results = pool.map(get_sha, extant_files)\n        pool.close()\n        pool.join()\n        for fn, sha in zip(extant_files, results):\n            sha_dict['files'][fn] = {'sha': sha}\n        return sha_dict\n    sprint(\"No dependencies\", level=\"verbose\")", "response": "Takes sha1 hash of all dependencies and outputs of all targets and returns a dictionary where the keys are the filenames and the values are the sha1 hash of the files and the values are the sha1 hash of the files and the values are the sha1 hash of the files and the sha1 hash of the files."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef needs_to_run(G, target, in_mem_shas, from_store, settings):\n    force = settings[\"force\"]\n    sprint = settings[\"sprint\"]\n\n    if(force):\n        sprint(\"Target rebuild is being forced so {} needs to run\".format(target),\n               level=\"verbose\")\n        return True\n    node_dict = get_the_node_dict(G, target)\n    if 'output' in node_dict:\n        for output in acts.get_all_outputs(node_dict):\n            if not os.path.isfile(output):\n                outstr = \"Output file '{}' is missing so it needs to run\"\n                sprint(outstr.format(output), level=\"verbose\")\n                return True\n    if 'dependencies' not in node_dict:\n        # if it has no dependencies, it always needs to run\n        sprint(\"Target {} has no dependencies and needs to run\".format(target),\n               level=\"verbose\")\n        return True\n    for dep in node_dict['dependencies']:\n        # because the shas are updated after all targets build,\n        # its possible that the dependency's sha doesn't exist\n        # in the current \"in_mem\" dictionary. If this is the case,\n        # then the target needs to run\n        if ('files' in in_mem_shas and dep not in in_mem_shas['files'] or\n            'files' not in in_mem_shas):\n            outstr = \"Dep '{}' doesn't exist in memory so it needs to run\"\n            sprint(outstr.format(dep), level=\"verbose\")\n            return True\n        now_sha = in_mem_shas['files'][dep]['sha']\n        if ('files' in from_store and dep not in from_store['files'] or\n            'files' not in from_store):\n            outst = \"Dep '{}' doesn't exist in shastore so it needs to run\"\n            sprint(outst.format(dep), level=\"verbose\")\n            return True\n        old_sha = from_store['files'][dep]['sha']\n        if now_sha != old_sha:\n            outstr = \"There's a mismatch for dep {} so it needs to run\"\n            sprint(outstr.format(dep), level=\"verbose\")\n            return True\n    sprint(\"Target '{}' doesn't need to run\".format(target), level=\"verbose\")\n    return False", "response": "Determines if a target needs to be run based on the current state of the target."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_commands(commands, settings):\n    sprint = settings[\"sprint\"]\n    quiet = settings[\"quiet\"]\n    error = settings[\"error\"]\n    enhanced_errors = True\n    the_shell = None\n    if settings[\"no_enhanced_errors\"]:\n        enhanced_errors = False\n    if \"shell\" in settings:\n        the_shell = settings[\"shell\"]\n    windows_p = sys.platform == \"win32\"\n\n    STDOUT = None\n    STDERR = None\n    if quiet:\n        STDOUT = PIPE\n        STDERR = PIPE\n\n    commands = commands.rstrip()\n    sprint(\"About to run commands '{}'\".format(commands), level=\"verbose\")\n    if not quiet:\n        sprint(commands)\n\n    if the_shell:\n        tmp = shlex.split(the_shell)\n        the_shell = tmp[0]\n        tmp = tmp[1:]\n        if enhanced_errors and not windows_p:\n            tmp.append(\"-e\")\n        tmp.append(commands)\n        commands = tmp\n    else:\n        if enhanced_errors and not windows_p:\n            commands = [\"-e\", commands]\n\n    p = Popen(commands, shell=True, stdout=STDOUT, stderr=STDERR,\n              executable=the_shell)\n    out, err = p.communicate()\n    if p.returncode:\n        if quiet:\n            error(err.decode(locale.getpreferredencoding()))\n        error(\"Command failed to run\")\n        sys.exit(1)", "response": "Runs the commands supplied as an argument\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrap function that sends to commands in a target s formula to run_commands", "response": "def run_the_target(G, target, settings):\n    \"\"\"\n    Wrapper function that sends to commands in a target's 'formula'\n    to run_commands()\n\n    Args:\n        The graph we are going to build\n        The target to run\n        The settings dictionary\n    \"\"\"\n    sprint = settings[\"sprint\"]\n    sprint(\"Running target {}\".format(target))\n    the_formula = get_the_node_dict(G, target)[\"formula\"]\n    run_commands(the_formula, settings)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of nodes that are the direct ancestors of all of the nodes given as an argument.", "response": "def get_direct_ancestors(G, list_of_nodes):\n    \"\"\"\n    Returns a list of nodes that are the parents\n    from all of the nodes given as an argument.\n    This is for use in the parallel topo sort\n    \"\"\"\n    parents = []\n    for item in list_of_nodes:\n        anc = G.predecessors(item)\n        for one in anc:\n            parents.append(one)\n    return parents"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of all sinks in a topo - sort graph.", "response": "def get_sinks(G):\n    \"\"\"\n    A sink is a node with no children.\n    This means that this is the end of the line,\n    and it should be run last in topo sort. This\n    returns a list of all sinks in a graph\n    \"\"\"\n    sinks = []\n    for node in G:\n        if not len(list(G.successors(node))):\n            sinks.append(node)\n    return sinks"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of lists representing all the nodes that have no dependency relationship between any nodes in a layer.", "response": "def get_levels(G):\n    \"\"\"\n    For the parallel topo sort to work, the targets have\n    to be executed in layers such that there is no\n    dependency relationship between any nodes in a layer.\n    What is returned is a list of lists representing all\n    the layers, or levels\n    \"\"\"\n    levels = []\n    ends = get_sinks(G)\n    levels.append(ends)\n    while get_direct_ancestors(G, ends):\n        ends = get_direct_ancestors(G, ends)\n        levels.append(ends)\n    levels.reverse()\n    return levels"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving redundant entries from the list of levels.", "response": "def remove_redundancies(levels):\n    \"\"\"\n    There are repeats in the output from get_levels(). We\n    want only the earliest occurrence (after it's reversed)\n    \"\"\"\n    seen = []\n    final = []\n    for line in levels:\n        new_line = []\n        for item in line:\n            if item not in seen:\n                seen.append(item)\n                new_line.append(item)\n        final.append(new_line)\n    return final"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parallel_run_these(G, list_of_targets, in_mem_shas, from_store,\n                       settings, dont_update_shas_of):\n    \"\"\"\n    The parallel equivalent of \"run_this_target()\"\n    It receives a list of targets to execute in parallel.\n    Unlike \"run_this_target()\" it has to update the shas\n    (in memory and in the store) within the function.\n    This is because one of the targets may fail but many can\n    succeed, and those outputs need to be updated\n\n    Args:\n        G\n        A graph\n        A list of targets that we need to build in parallel\n        The dictionary containing the in-memory sha store\n        The dictionary containing the contents of the .shastore file\n        The settings dictionary\n        A list of outputs to not update shas of\n    \"\"\"\n    verbose = settings[\"verbose\"]\n    quiet = settings[\"quiet\"]\n    error = settings[\"error\"]\n    sprint = settings[\"sprint\"]\n\n    if len(list_of_targets) == 1:\n        target = list_of_targets[0]\n        sprint(\"Going to run target '{}' serially\".format(target),\n               level=\"verbose\")\n        run_the_target(G, target, settings)\n        node_dict = get_the_node_dict(G, target)\n        if \"output\" in node_dict:\n            for output in acts.get_all_outputs(node_dict):\n                if output not in dont_update_shas_of:\n                    in_mem_shas['files'][output] = {\"sha\": get_sha(output,\n                                                                   settings)}\n                    in_mem_shas[output] = get_sha(output, settings)\n                    write_shas_to_shastore(in_mem_shas)\n        if \"dependencies\" in node_dict:\n            for dep in acts.get_all_dependencies(node_dict):\n                if dep not in dont_update_shas_of:\n                    in_mem_shas['files'][dep] = {\"sha\": get_sha(dep, settings)}\n                    write_shas_to_shastore(in_mem_shas)\n        return True\n    a_failure_occurred = False\n    out = \"Going to run these targets '{}' in parallel\"\n    sprint(out.format(\", \".join(list_of_targets)))\n    info = [(target, get_the_node_dict(G, target))\n              for target in list_of_targets]\n    commands = [item[1]['formula'].rstrip() for item in info]\n    if not quiet:\n        procs = [Popen(command, shell=True) for command in commands]\n    else:\n        procs = [Popen(command, shell=True, stdout=PIPE, stderr=PIPE)\n                   for command in commands]\n    for index, process in enumerate(procs):\n        if process.wait():\n            error(\"Target '{}' failed!\".format(info[index][0]))\n            a_failure_occurred = True\n        else:\n            if \"output\" in info[index][1]:\n                for output in acts.get_all_outputs(info[index][1]):\n                    if output not in dont_update_shas_of:\n                        in_mem_shas['files'][output] = {\"sha\": get_sha(output,\n                                                                       settings)}\n                        write_shas_to_shastore(in_mem_shas)\n            if \"dependencies\" in info[index][1]:\n                for dep in acts.get_all_dependencies(info[index][1]):\n                    if dep not in dont_update_shas_of:\n                        in_mem_shas['files'][dep] = {\"sha\": get_sha(dep, settings)}\n                        write_shas_to_shastore(in_mem_shas)\n    if a_failure_occurred:\n        error(\"A command failed to run\")\n        sys.exit(1)\n    return True", "response": "This function runs the target in parallel and updates the in - memory shas of the nodes in the store."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmerging the files in from_store and in_mem_shas with the shas in in_mem_shas.", "response": "def merge_from_store_and_in_mems(from_store, in_mem_shas, dont_update_shas_of):\n    \"\"\"\n    If we don't merge the shas from the sha store and if we build a\n    subgraph, the .shastore will only contain the shas of the files\n    from the subgraph and the rest of the graph will have to be\n    rebuilt\n    \"\"\"\n    if not from_store:\n        for item in dont_update_shas_of:\n            if item in in_mem_shas['files']:\n                del in_mem_shas['files'][item]\n        return in_mem_shas\n    for key in from_store['files']:\n        if key not in in_mem_shas['files'] and key not in dont_update_shas_of:\n            in_mem_shas['files'][key] = from_store['files'][key]\n    for item in dont_update_shas_of:\n        if item in in_mem_shas['files']:\n            del in_mem_shas['files'][item]\n    return in_mem_shas"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_this_graph(G, settings, dont_update_shas_of=None):\n    verbose = settings[\"verbose\"]\n    quiet = settings[\"quiet\"]\n    force = settings[\"force\"]\n    recon = settings[\"recon\"]\n    parallel = settings[\"parallel\"]\n    error = settings[\"error\"]\n    sprint = settings[\"sprint\"]\n\n    if not dont_update_shas_of:\n        dont_update_shas_of = []\n    sprint(\"Checking that graph is directed acyclic\", level=\"verbose\")\n    if not nx.is_directed_acyclic_graph(G):\n        errmes = \"Dependency resolution is impossible; \"\n        errmes += \"graph is not directed and acyclic\"\n        errmes += \"\\nCheck the Sakefile\\n\"\n        error(errmes)\n        sys.exit(1)\n    sprint(\"Dependency resolution is possible\", level=\"verbose\")\n    in_mem_shas = take_shas_of_all_files(G, settings)\n    from_store = {}\n    if not os.path.isfile(\".shastore\"):\n        write_shas_to_shastore(in_mem_shas)\n        in_mem_shas = {}\n        in_mem_shas['files'] = {}\n    with io.open(\".shastore\", \"r\") as fh:\n        shas_on_disk = fh.read()\n    from_store = yaml.load(shas_on_disk)\n    check_shastore_version(from_store, settings)\n    if not from_store:\n        write_shas_to_shastore(in_mem_shas)\n        in_mem_shas = {}\n        in_mem_shas['files'] = {}\n        with io.open(\".shastore\", \"r\") as fh:\n            shas_on_disk = fh.read()\n        from_store = yaml.load(shas_on_disk)\n    # parallel\n    if parallel:\n        for line in parallel_sort(G):\n            line = sorted(line)\n            out = \"Checking if targets '{}' need to be run\"\n            sprint(out.format(\", \".join(line)), level=\"verbose\")\n            to_build = []\n            for item in line:\n                if needs_to_run(G, item, in_mem_shas, from_store, settings):\n                    to_build.append(item)\n            if to_build:\n                if recon:\n                    if len(to_build) == 1:\n                        out = \"Would run target '{}'\"\n                        sprint(out.format(to_build[0]))\n                    else:\n                        out = \"Would run targets '{}' in parallel\"\n                        sprint(out.format(\", \".join(to_build)))\n                    continue\n                parallel_run_these(G, to_build, in_mem_shas, from_store,\n                                   settings, dont_update_shas_of)\n    # not parallel\n    else:\n        # still have to use parallel_sort to make\n        # build order deterministic (by sorting targets)\n        targets = []\n        for line in parallel_sort(G):\n            for item in sorted(line):\n                targets.append(item)\n        for target in targets:\n            outstr = \"Checking if target '{}' needs to be run\"\n            sprint(outstr.format(target), level=\"verbose\")\n            if needs_to_run(G, target, in_mem_shas, from_store, settings):\n                if recon:\n                    sprint(\"Would run target: {}\".format(target))\n                    continue\n                run_the_target(G, target, settings)\n                node_dict = get_the_node_dict(G, target)\n                if \"output\" in node_dict:\n                    for output in acts.get_all_outputs(node_dict):\n                        if output not in dont_update_shas_of:\n                            in_mem_shas['files'][output] = {\"sha\": get_sha(output,\n                                                                           settings)}\n                            write_shas_to_shastore(in_mem_shas)\n                if \"dependencies\" in node_dict:\n                    for dep in acts.get_all_dependencies(node_dict):\n                        if dep not in dont_update_shas_of:\n                            in_mem_shas['files'][dep] = {\"sha\": get_sha(dep,\n                                                                        settings)}\n                            write_shas_to_shastore(in_mem_shas)\n\n    if recon:\n        return 0\n    in_mem_shas = take_shas_of_all_files(G, settings)\n    if in_mem_shas:\n        in_mem_shas = merge_from_store_and_in_mems(from_store, in_mem_shas,\n                                                   dont_update_shas_of)\n        write_shas_to_shastore(in_mem_shas)\n    sprint(\"Done\", color=True)\n    return 0", "response": "This function builds the tree from a graph G."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the print functions that can be used to print the current language.", "response": "def get_print_functions(settings):\n    \"\"\"\n    This returns the appropriate print functions\n    in a tuple\n    The print function are:\n        - sprint - for standard printing\n        - warn - for warnings\n        - error - for errors\n    This will all be the same if color is False.\n\n    The returned print functions will contain an optional parameter\n    that specifies the output level (verbose or not). If not verbose,\n    the print function will ignore the message.\n    \"\"\"\n    verbose = settings[\"verbose\"]\n    # the regular print doesn't use color by default\n    # (even if color is True)\n    def sprint(message, level=None, color=False):\n        if level==\"verbose\" and not verbose:\n            return\n        # for colors\n        prepend = \"\"\n        postfix = \"\"\n        if settings[\"color\"] and color:\n            prepend = \"\\033[92m\"\n            postfix = \"\\033[0m\"\n        print(\"{}{}{}\".format(prepend, message, postfix))\n        sys.stdout.flush()\n    def warn(message, level=None, color=True):\n        if level==\"verbose\" and not verbose:\n            return\n        # for colors\n        prepend = \"\"\n        postfix = \"\"\n        if settings[\"color\"] and color:\n            prepend = \"\\033[93m\"\n            postfix = \"\\033[0m\"\n        print(\"{}{}{}\".format(prepend, message, postfix))\n        sys.stdout.flush()\n    def error(message, level=None, color=True):\n        # this condition does really make any sense but w/e\n        if level==\"verbose\" and not verbose:\n            return\n        # for colors\n        prepend = \"\"\n        postfix = \"\"\n        if settings[\"color\"] and color:\n            prepend = \"\\033[91m\"\n            postfix = \"\\033[0m\"\n        print(\"{}{}{}\".format(prepend, message, postfix), file=sys.stderr)\n        sys.stderr.flush()\n    return sprint, warn, error"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_standard_sakefile(settings):\n    error = settings[\"error\"]\n    if settings[\"customsake\"]:\n        custom = settings[\"customsake\"]\n        if not os.path.isfile(custom):\n            error(\"Specified sakefile '{}' doesn't exist\", custom)\n            sys.exit(1)\n        return custom\n    # no custom specified, going over defaults in order\n    for name in [\"Sakefile\", \"Sakefile.yaml\", \"Sakefile.yml\"]:\n        if os.path.isfile(name):\n            return name\n    error(\"Error: there is no Sakefile to read\")\n    sys.exit(1)", "response": "Returns the filename of the appropriate sakefile"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean_path(a_path, force_os=None, force_start=None):\n    if not force_start:\n        force_start = os.curdir\n    if force_os == \"windows\":\n        import ntpath\n        return ntpath.relpath(ntpath.normpath(a_path),\n                             start=force_start)\n    if force_os == \"posix\":\n        import posixpath\n        return posixpath.relpath(posixpath.normpath(a_path),\n                                start=force_start)\n    return os.path.relpath(os.path.normpath(a_path),\n                          start=force_start)", "response": "This function is used to normalize the path of an output or\n    dependency and provide the path in relative form."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a prettily formatted help string for the current language of the current language.", "response": "def get_help(sakefile):\n    \"\"\"\n    Returns the prettily formatted help strings (for printing)\n\n    Args:\n        A dictionary that is the parsed Sakefile (from sake.py)\n\n    NOTE:\n        the list sorting in this function is required for this\n        function to be deterministic\n    \"\"\"\n    full_string = \"You can 'sake' one of the following...\\n\\n\"\n    errmes = \"target '{}' is not allowed to not have help message\\n\"\n    outerlines = []\n    for target in sakefile:\n        if target == \"all\":\n            # this doesn't have a help message\n            continue\n        middle_lines = []\n        if \"formula\" not in sakefile[target]:\n            # this means it's a meta-target\n            innerstr = \"{}:\\n  - {}\\n\\n\".format(escp(target),\n                                                sakefile[target][\"help\"])\n            inner = []\n            for atom_target in sakefile[target]:\n                if atom_target == \"help\":\n                    continue\n                inner.append(\"    {}:\\n      -  {}\\n\\n\".format(escp(atom_target),\n                                                               sakefile[target][atom_target][\"help\"]))\n            if inner:\n                innerstr += '\\n'.join(sorted(inner))\n            middle_lines.append(innerstr)\n        else:\n            middle_lines.append(\"{}:\\n  - {}\\n\\n\".format(escp(target),\n                                                         sakefile[target][\"help\"]))\n        if middle_lines:\n            outerlines.append('\\n'.join(sorted(middle_lines)))\n\n    if outerlines:\n        full_string += '\\n'.join(sorted(outerlines))\n    what_clean_does = \"remove all targets' outputs and start from scratch\"\n    full_string += \"\\nclean:\\n  -  {}\\n\\n\".format(what_clean_does)\n    what_visual_does = \"output visual representation of project's dependencies\"\n    full_string += \"visual:\\n  -  {}\\n\".format(what_visual_does)\n    full_string = re.sub(\"\\n{3,}\", \"\\n\\n\", full_string)\n    return full_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_for_dep_in_outputs(dep, verbose, G):\n    if verbose:\n        print(\"checking dep {}\".format(dep))\n    ret_list = []\n    for node in G.nodes(data=True):\n        if \"output\" not in node[1]:\n            continue\n        for out in node[1]['output']:\n            if fnmatch.fnmatch(out, dep):\n                ret_list.append(node[0])\n                break\n    return ret_list", "response": "Function to help construct_graph() identify dependencies in outputs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_ties(G):\n    # we are going to make a dictionary whose keys are every dependency\n    # and whose values are a list of all targets that use that dependency.\n    # after making the dictionary, values whose length is above one will\n    # be called \"ties\"\n    ties = []\n    dep_dict = {}\n    for node in G.nodes(data=True):\n        if 'dependencies' in node[1]:\n            for item in node[1]['dependencies']:\n                if item not in dep_dict:\n                    dep_dict[item] = []\n                dep_dict[item].append(node[0])\n    for item in dep_dict:\n        if len(list(set(dep_dict[item]))) > 1:\n            ties.append(list(set(dep_dict[item])))\n    return ties", "response": "Returns a list of all ties that are used by the dependency tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs a NetworkX graph from a dictionary of sakefile.", "response": "def construct_graph(sakefile, settings):\n    \"\"\"\n    Takes the sakefile dictionary and builds a NetworkX graph\n\n    Args:\n        A dictionary that is the parsed Sakefile (from sake.py)\n        The settings dictionary\n\n    Returns:\n        A NetworkX graph\n    \"\"\"\n    verbose = settings[\"verbose\"]\n    sprint = settings[\"sprint\"]\n    G = nx.DiGraph()\n    sprint(\"Going to construct Graph\", level=\"verbose\")\n    for target in sakefile:\n        if target == \"all\":\n            # we don't want this node\n            continue\n        if \"formula\" not in sakefile[target]:\n            # that means this is a meta target\n            for atomtarget in sakefile[target]:\n                if atomtarget == \"help\":\n                    continue\n                sprint(\"Adding '{}'\".format(atomtarget), level=\"verbose\")\n                data_dict = sakefile[target][atomtarget]\n                data_dict[\"parent\"] = target\n                G.add_node(atomtarget, **data_dict)\n        else:\n            sprint(\"Adding '{}'\".format(target), level=\"verbose\")\n            G.add_node(target, **sakefile[target])\n    sprint(\"Nodes are built\\nBuilding connections\", level=\"verbose\")\n    for node in G.nodes(data=True):\n        sprint(\"checking node {} for dependencies\".format(node[0]),\n               level=\"verbose\")\n        # normalize all paths in output\n        for k, v in node[1].items():\n            if v is None: node[1][k] = []\n        if \"output\" in node[1]:\n            for index, out in enumerate(node[1]['output']):\n                node[1]['output'][index] = clean_path(node[1]['output'][index])\n        if \"dependencies\" not in node[1]:\n            continue\n        sprint(\"it has dependencies\", level=\"verbose\")\n        connects = []\n        # normalize all paths in dependencies\n        for index, dep in enumerate(node[1]['dependencies']):\n            dep = os.path.normpath(dep)\n            shrt = \"dependencies\"\n            node[1]['dependencies'][index] = clean_path(node[1][shrt][index])\n    for node in G.nodes(data=True):\n        connects = []\n        if \"dependencies\" not in node[1]:\n            continue\n        for dep in node[1]['dependencies']:\n            matches = check_for_dep_in_outputs(dep, verbose, G)\n            if not matches:\n                continue\n            for match in matches:\n                sprint(\"Appending {} to matches\".format(match), level=\"verbose\")\n                connects.append(match)\n        if connects:\n            for connect in connects:\n                G.add_edge(connect, node[0])\n    return G"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_all_outputs(node_dict):\n    outlist = []\n    for item in node_dict['output']:\n        glist = glob.glob(item)\n        if glist:\n            for oneglob in glist:\n                outlist.append(oneglob)\n        else:\n            outlist.append(item)\n    return outlist", "response": "This function takes a node dictionary and returns a list of all outputs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of all the dependencies of a node.", "response": "def get_all_dependencies(node_dict):\n    \"\"\"\n    ...............................\n    \"\"\"\n    deplist = []\n    for item in node_dict['dependencies']:\n        glist = glob.glob(item)\n        if glist:\n            for oneglob in glist:\n                deplist.append(oneglob)\n        else:\n            deplist.append(item)\n    return deplist"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clean_all(G, settings):\n    quiet = settings[\"quiet\"]\n    recon = settings[\"recon\"]\n    sprint = settings[\"sprint\"]\n    error = settings[\"error\"]\n    all_outputs = []\n    for node in G.nodes(data=True):\n        if \"output\" in node[1]:\n            for item in get_all_outputs(node[1]):\n                all_outputs.append(item)\n    all_outputs.append(\".shastore\")\n    retcode = 0\n    for item in sorted(all_outputs):\n        if os.path.isfile(item):\n            if recon:\n                sprint(\"Would remove file: {}\".format(item))\n                continue\n            sprint(\"Attempting to remove file '{}'\", level=\"verbose\")\n            try:\n                os.remove(item)\n                sprint(\"Removed file\", level=\"verbose\")\n            except:\n                errmes = \"Error: file '{}' failed to be removed\"\n                error(errmes.format(item))\n                retcode = 1\n    if not retcode and not recon:\n        sprint(\"All clean\", color=True)\n    return retcode", "response": "Removes all the output files from all targets in the graph."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_dot_file(G, filename):\n    with io.open(filename, \"w\") as fh:\n        fh.write(\"strict digraph DependencyDiagram {\\n\")\n        edge_list = G.edges()\n        node_list = set(G.nodes())\n        if edge_list:\n            for edge in sorted(edge_list):\n                source, targ = edge\n                node_list = node_list - set(source)\n                node_list = node_list - set(targ)\n                line = '\"{}\" -> \"{}\";\\n'\n                fh.write(line.format(source, targ))\n        # draw nodes with no links\n        if node_list:\n            for node in sorted(node_list):\n                line = '\"{}\"\\n'.format(node)\n                fh.write(line)\n        fh.write(\"}\")", "response": "Writes the graph G in dot file format for graphviz visualization."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef visualize(G, settings, filename=\"dependencies\", no_graphviz=False):\n    error = settings[\"error\"]\n    if no_graphviz:\n        write_dot_file(G, filename)\n        return 0\n    write_dot_file(G, \"tempdot\")\n    renderer = \"svg\"\n    if re.search(\"\\.jpg$\", filename, re.IGNORECASE):\n        renderer = \"jpg\"\n    elif re.search(\"\\.jpeg$\", filename, re.IGNORECASE):\n        renderer = \"jpg\"\n    elif re.search(\"\\.svg$\", filename, re.IGNORECASE):\n        renderer = \"svg\"\n    elif re.search(\"\\.png$\", filename, re.IGNORECASE):\n        renderer = \"png\"\n    elif re.search(\"\\.gif$\", filename, re.IGNORECASE):\n        renderer = \"gif\"\n    elif re.search(\"\\.ps$\", filename, re.IGNORECASE):\n        renderer = \"ps\"\n    elif re.search(\"\\.pdf$\", filename, re.IGNORECASE):\n        renderer = \"pdf\"\n    else:\n        renderer = \"svg\"\n        filename += \".svg\"\n    command = \"dot -T{} tempdot -o {}\".format(renderer, filename)\n    p = Popen(command, shell=True)\n    p.communicate()\n    if p.returncode:\n        errmes = \"Either graphviz is not installed, or its not on PATH\"\n        os.remove(\"tempdot\")\n        error(errmes)\n        sys.exit(1)\n    os.remove(\"tempdot\")\n    return 0", "response": "Visualize a NetworkX DiGraph into a graphviz dot file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npreparing transcriptiondata from the transcription sources.", "response": "def _make_package(args):  # pragma: no cover\n    \"\"\"Prepare transcriptiondata from the transcription sources.\"\"\"\n    from lingpy.sequence.sound_classes import token2class\n    from lingpy.data import Model\n\n    columns = ['LATEX', 'FEATURES', 'SOUND', 'IMAGE', 'COUNT', 'NOTE']\n    bipa = TranscriptionSystem('bipa')\n    for src, rows in args.repos.iter_sources(type='td'):\n        args.log.info('TranscriptionData {0} ...'.format(src['NAME']))\n        uritemplate = URITemplate(src['URITEMPLATE']) if src['URITEMPLATE'] else None\n        out = [['BIPA_GRAPHEME', 'CLTS_NAME', 'GENERATED', 'EXPLICIT',\n                'GRAPHEME', 'URL'] + columns]\n        graphemes = set()\n        for row in rows:\n            if row['GRAPHEME'] in graphemes:\n                args.log.warn('skipping duplicate grapheme: {0}'.format(row['GRAPHEME']))\n                continue\n            graphemes.add(row['GRAPHEME'])\n            if not row['BIPA']:\n                bipa_sound = bipa[row['GRAPHEME']]\n                explicit = ''\n            else:\n                bipa_sound = bipa[row['BIPA']]\n                explicit = '+'\n            generated = '+' if bipa_sound.generated else ''\n            if is_valid_sound(bipa_sound, bipa):\n                bipa_grapheme = bipa_sound.s\n                bipa_name = bipa_sound.name\n            else:\n                bipa_grapheme, bipa_name = '<NA>', '<NA>'\n            url = uritemplate.expand(**row) if uritemplate else row.get('URL', '')\n            out.append(\n                [bipa_grapheme, bipa_name, generated, explicit, row['GRAPHEME'],\n                 url] + [\n                    row.get(c, '') for c in columns])\n        found = len([o for o in out if o[0] != '<NA>'])\n        args.log.info('... {0} of {1} graphemes found ({2:.0f}%)'.format(\n            found, len(out), found / len(out) * 100))\n        with UnicodeWriter(\n            pkg_path('transcriptiondata', '{0}.tsv'.format(src['NAME'])), delimiter='\\t'\n        ) as writer:\n            writer.writerows(out)\n\n    count = 0\n    with UnicodeWriter(pkg_path('soundclasses', 'lingpy.tsv'), delimiter='\\t') as writer:\n        writer.writerow(['CLTS_NAME', 'BIPA_GRAPHEME'] + SOUNDCLASS_SYSTEMS)\n        for grapheme, sound in sorted(bipa.sounds.items()):\n            if not sound.alias:\n                writer.writerow(\n                    [sound.name, grapheme] + [token2class(\n                        grapheme, Model(cls)) for cls in SOUNDCLASS_SYSTEMS])\n                count += 1\n    args.log.info('SoundClasses: {0} written to file.'.format(count))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks the consistency of a given transcription system conversino", "response": "def is_valid_sound(sound, ts):\n    \"\"\"Check the consistency of a given transcription system conversino\"\"\"\n    if isinstance(sound, (Marker, UnknownSound)):\n        return False\n    s1 = ts[sound.name]\n    s2 = ts[sound.s]\n    return s1.name == s2.name and s1.s == s2.s"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resolve_sound(self, sound):\n        sound = sound if isinstance(sound, Sound) else self.system[sound]\n        if sound.name in self.data:\n            return '//'.join([x['grapheme'] for x in self.data[sound.name]])\n        raise KeyError(\":td:resolve_sound: No sound could be found.\")", "response": "Function tries to identify a sound in the data and returns the grapheme of that sound."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _norm(self, string):\n        nstring = norm(string)\n        if \"/\" in string:\n            s, t = string.split('/')\n            nstring = t\n        return self.normalize(nstring)", "response": "Extended normalization : normalize by list of norm - characers split\n            by character \"/\"."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nnormalizing the string according to normalization list", "response": "def normalize(self, string):\n        \"\"\"Normalize the string according to normalization list\"\"\"\n        return ''.join([self._normalize.get(x, x) for x in nfd(string)])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a sound from its name", "response": "def _from_name(self, string):\n        \"\"\"Parse a sound from its name\"\"\"\n        components = string.split(' ')\n        if frozenset(components) in self.features:\n            return self.features[frozenset(components)]\n        rest, sound_class = components[:-1], components[-1]\n        if sound_class in ['diphthong', 'cluster']:\n            if string.startswith('from ') and 'to ' in string:\n                extension = {'diphthong': 'vowel', 'cluster': 'consonant'}[sound_class]\n                string_ = ' '.join(string.split(' ')[1:-1])\n                from_, to_ = string_.split(' to ')\n                v1, v2 = frozenset(from_.split(' ') + [extension]), frozenset(\n                    to_.split(' ') + [extension])\n                if v1 in self.features and v2 in self.features:\n                    s1, s2 = (self.features[v1], self.features[v2])\n                    if sound_class == 'diphthong':\n                        return Diphthong.from_sounds(s1 + s2, s1, s2, self)  # noqa: F405\n                    else:\n                        return Cluster.from_sounds(s1 + s2, s1, s2, self)  # noqa: F405\n                else:\n                    # try to generate the sounds if they are not there\n                    s1, s2 = self._from_name(from_ + ' ' + extension), self._from_name(\n                        to_ + ' ' + extension)\n                    if not (isinstance(\n                        s1, UnknownSound) or isinstance(s2, UnknownSound)):  # noqa: F405\n                        if sound_class == 'diphthong':\n                            return Diphthong.from_sounds(  # noqa: F405\n                                s1 + s2, s1, s2, self)\n                        return Cluster.from_sounds(s1 + s2, s1, s2, self)  # noqa: F405\n                    raise ValueError('components could not be found in system')\n            else:\n                raise ValueError('name string is erroneously encoded')\n\n        if sound_class not in self.sound_classes:\n            raise ValueError('no sound class specified')\n\n        args = {self._feature_values.get(comp, '?'): comp for comp in rest}\n        if '?' in args:\n            raise ValueError('string contains unknown features')\n        args['grapheme'] = ''\n        args['ts'] = self\n        sound = self.sound_classes[sound_class](**args)\n        if sound.featureset not in self.features:\n            sound.generated = True\n            return sound\n        return self.features[sound.featureset]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a string and return its features.", "response": "def _parse(self, string):\n        \"\"\"Parse a string and return its features.\n\n        :param string: A one-symbol string in NFD\n\n        Notes\n        -----\n        Strategy is rather simple: we determine the base part of a string and\n        then search left and right of this part for the additional features as\n        expressed by the diacritics. Fails if a segment has more than one basic\n        part.\n        \"\"\"\n        nstring = self._norm(string)\n\n        # check whether sound is in self.sounds\n        if nstring in self.sounds:\n            sound = self.sounds[nstring]\n            sound.normalized = nstring != string\n            sound.source = string\n            return sound\n\n        match = list(self._regex.finditer(nstring))\n        # if the match has length 2, we assume that we have two sounds, so we split\n        # the sound and pass it on for separate evaluation (recursive function)\n        if len(match) == 2:\n            sound1 = self._parse(nstring[:match[1].start()])\n            sound2 = self._parse(nstring[match[1].start():])\n            # if we have ANY unknown sound, we mark the whole sound as unknown, if\n            # we have two known sounds of the same type (vowel or consonant), we\n            # either construct a diphthong or a cluster\n            if 'unknownsound' not in (sound1.type, sound2.type) and \\\n                    sound1.type == sound2.type:\n                # diphthong creation\n                if sound1.type == 'vowel':\n                    return Diphthong.from_sounds(  # noqa: F405\n                        string, sound1, sound2, self)\n                elif sound1.type == 'consonant' and \\\n                        sound1.manner in ('stop', 'implosive', 'click', 'nasal') and \\\n                        sound2.manner in ('stop', 'implosive', 'affricate', 'fricative'):\n                    return Cluster.from_sounds(  # noqa: F405\n                        string, sound1, sound2, self)\n            return UnknownSound(grapheme=nstring, source=string, ts=self)  # noqa: F405\n\n        if len(match) != 1:\n            # Either no match or more than one; both is considered an error.\n            return UnknownSound(grapheme=nstring, source=string, ts=self)  # noqa: F405\n\n        pre, mid, post = nstring.partition(nstring[match[0].start():match[0].end()])\n        base_sound = self.sounds[mid]\n        if isinstance(base_sound, Marker):  # noqa: F405\n            assert pre or post\n            return UnknownSound(grapheme=nstring, source=string, ts=self)  # noqa: F405\n\n        # A base sound with diacritics or a custom symbol.\n        features = attr.asdict(base_sound)\n        features.update(\n            source=string,\n            generated=True,\n            normalized=nstring != string,\n            base=base_sound.grapheme)\n\n        # we construct two versions: the \"normal\" version and the version where\n        # we search for aliases and normalize them (as our features system for\n        # diacritics may well define aliases\n        grapheme, sound = '', ''\n        for dia in [p + EMPTY for p in pre]:\n            feature = self.diacritics[base_sound.type].get(dia, {})\n            if not feature:\n                return UnknownSound(  # noqa: F405\n                    grapheme=nstring, source=string, ts=self)\n            features[self._feature_values[feature]] = feature\n            # we add the unaliased version to the grapheme\n            grapheme += dia[0]\n            # we add the corrected version (if this is needed) to the sound\n            sound += self.features[base_sound.type][feature][0]\n        # add the base sound\n        grapheme += base_sound.grapheme\n        sound += base_sound.s\n        for dia in [EMPTY + p for p in post]:\n            feature = self.diacritics[base_sound.type].get(dia, {})\n            # we are strict: if we don't know the feature, it's an unknown\n            # sound\n            if not feature:\n                return UnknownSound(  # noqa: F405\n                    grapheme=nstring, source=string, ts=self)\n            features[self._feature_values[feature]] = feature\n            grapheme += dia[1]\n            sound += self.features[base_sound.type][feature][1]\n\n        features['grapheme'] = sound\n        new_sound = self.sound_classes[base_sound.type](**features)\n        # check whether grapheme differs from re-generated sound\n        if text_type(new_sound) != sound:\n            new_sound.alias = True\n        if grapheme != sound:\n            new_sound.alias = True\n            new_sound.grapheme = grapheme\n        return new_sound"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction tries to identify a sound in the data and returns the next approximate sound class.", "response": "def resolve_sound(self, sound):\n        \"\"\"Function tries to identify a sound in the data.\n\n        Notes\n        -----\n        The function tries to resolve sounds to take a sound with less complex\n        features in order to yield the next approximate sound class, if the\n        transcription data are sound classes.\n        \"\"\"\n        sound = sound if isinstance(sound, Symbol) else self.system[sound]\n        if sound.name in self.data:\n            return self.data[sound.name]['grapheme']\n        if not sound.type == 'unknownsound':\n            if sound.type in ['diphthong', 'cluster']:\n                return self.resolve_sound(sound.from_sound)\n            name = [\n                s for s in sound.name.split(' ') if\n                self.system._feature_values.get(s, '') not in\n                ['laminality', 'ejection', 'tone']]\n            while len(name) >= 4:\n                sound = self.system.get(' '.join(name))\n                if sound and sound.name in self.data:\n                    return self.resolve_sound(sound)\n                name.pop(0)\n        raise KeyError(\":sc:resolve_sound: No sound could be found.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ipfn_np(self, m, aggregates, dimensions, weight_col='total'):\n        steps = len(aggregates)\n        dim = len(m.shape)\n        product_elem = []\n        tables = [m]\n        # TODO: do we need to persist all these dataframe? Or maybe we just need to persist the table_update and table_current\n        # and then update the table_current to the table_update to the latest we have. And create an empty zero dataframe for table_update (Evelyn)\n        for inc in range(steps - 1):\n            tables.append(np.array(np.zeros(m.shape)))\n        original = copy.copy(m)\n\n        # Calculate the new weights for each dimension\n        for inc in range(steps):\n            if inc == (steps - 1):\n                table_update = m\n                table_current = tables[inc]\n            else:\n                table_update = tables[inc + 1]\n                table_current = tables[inc]\n            for dimension in dimensions[inc]:\n                product_elem.append(range(m.shape[dimension]))\n            for item in product(*product_elem):\n                idx = self.index_axis_elem(dim, dimensions[inc], item)\n                table_current_slice = table_current[idx]\n                mijk = table_current_slice.sum()\n                # TODO: Directly put it as xijk = aggregates[inc][item] (Evelyn)\n                xijk = aggregates[inc]\n                xijk = xijk[item]\n                if mijk == 0:\n                    # table_current_slice += 1e-5\n                    # TODO: Basically, this part would remain 0 as always right? Cause if the sum of the slice is zero, then we only have zeros in this slice.\n                    # TODO: you could put it as table_update[idx] = table_current_slice (since multiplication on zero is still zero)\n                    table_update[idx] = table_current_slice\n                else:\n                    # TODO: when inc == steps - 1, this part is also directly updating the dataframe m (Evelyn)\n                    # If we are not going to persist every table generated, we could still keep this part to directly update dataframe m\n                    table_update[idx] = table_current_slice * 1.0 * xijk / mijk\n                # For debug purposes\n                # if np.isnan(table_update).any():\n                #     print(idx)\n                #     sys.exit(0)\n            product_elem = []\n\n        # Check the convergence rate for each dimension\n        max_conv = 0\n        for inc in range(steps):\n            # TODO: this part already generated before, we could somehow persist it. But it's not important (Evelyn)\n            for dimension in dimensions[inc]:\n                product_elem.append(range(m.shape[dimension]))\n            for item in product(*product_elem):\n                idx = self.index_axis_elem(dim, dimensions[inc], item)\n                ori_ijk = aggregates[inc][item]\n                m_slice = m[idx]\n                m_ijk = m_slice.sum()\n                # print('Current vs original', abs(m_ijk/ori_ijk - 1))\n                if abs(m_ijk / ori_ijk - 1) > max_conv:\n                    max_conv = abs(m_ijk / ori_ijk - 1)\n\n            product_elem = []\n\n        return m, max_conv", "response": "Runs the ipfn method from a matrix m and returns a numpy array with the result of the ipfn method."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns the ipfn method from a dataframe df and returns a dictionary of the unique entries.", "response": "def ipfn_df(self, df, aggregates, dimensions, weight_col='total'):\n        \"\"\"\n        Runs the ipfn method from a dataframe df, aggregates/marginals and the dimension(s) preserved.\n        For example:\n        from ipfn import ipfn\n        import pandas as pd\n        age = [30, 30, 30, 30, 40, 40, 40, 40, 50, 50, 50, 50]\n        distance = [10,20,30,40,10,20,30,40,10,20,30,40]\n        m = [8., 4., 6., 7., 3., 6., 5., 2., 9., 11., 3., 1.]\n        df = pd.DataFrame()\n        df['age'] = age\n        df['distance'] = distance\n        df['total'] = m\n\n        xip = df.groupby('age')['total'].sum()\n        xip.loc[30] = 20\n        xip.loc[40] = 18\n        xip.loc[50] = 22\n        xpj = df.groupby('distance')['total'].sum()\n        xpj.loc[10] = 18\n        xpj.loc[20] = 16\n        xpj.loc[30] = 12\n        xpj.loc[40] = 14\n        dimensions = [['age'], ['distance']]\n        aggregates = [xip, xpj]\n\n        IPF = ipfn(df, aggregates, dimensions)\n        df = IPF.iteration()\n\n        print(df)\n        print(df.groupby('age')['total'].sum(), xip)\"\"\"\n\n        steps = len(aggregates)\n        tables = [df]\n        for inc in range(steps - 1):\n            tables.append(df.copy())\n        original = df.copy()\n\n        # Calculate the new weights for each dimension\n        inc = 0\n        for features in dimensions:\n            if inc == (steps - 1):\n                table_update = df\n                table_current = tables[inc]\n            else:\n                table_update = tables[inc + 1]\n                table_current = tables[inc]\n\n            tmp = table_current.groupby(features)[weight_col].sum()\n            xijk = aggregates[inc]\n\n            feat_l = []\n            for feature in features:\n                feat_l.append(np.unique(table_current[feature]))\n            table_update.set_index(features, inplace=True)\n            table_current.set_index(features, inplace=True)\n\n            for feature in product(*feat_l):\n                den = tmp.loc[feature]\n                # calculate new weight for this iteration\n                if den == 0:\n                    table_update.loc[feature, weight_col] =\\\n                        table_current.loc[feature, weight_col] *\\\n                        xijk.loc[feature]\n                else:\n                    table_update.loc[feature, weight_col] = \\\n                        table_current.loc[feature, weight_col].astype(float) * \\\n                        xijk.loc[feature] / den\n\n            table_update.reset_index(inplace=True)\n            table_current.reset_index(inplace=True)\n            inc += 1\n            feat_l = []\n\n        # Calculate the max convergence rate\n        max_conv = 0\n        inc = 0\n        for features in dimensions:\n            tmp = df.groupby(features)[weight_col].sum()\n            ori_ijk = aggregates[inc]\n            temp_conv = max(abs(tmp / ori_ijk - 1))\n            if temp_conv > max_conv:\n                max_conv = temp_conv\n            inc += 1\n\n        return df, max_conv"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders link as HTML output tag <a.", "response": "def render(self, obj):\n        \"\"\" Render link as HTML output tag <a>.\n        \"\"\"\n        self.obj = obj\n        attrs = ' '.join([\n            '%s=\"%s\"' % (attr_name, attr.resolve(obj))\n            if isinstance(attr, Accessor)\n            else '%s=\"%s\"' % (attr_name, attr)\n            for attr_name, attr in self.attrs.items()\n        ])\n        return mark_safe(u'<a %s>%s</a>' % (attrs, self.text))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresolving the object described by the accessor by traversing the attributes of the given context.", "response": "def resolve(self, context, quiet=True):\r\n        \"\"\"\r\n        Return an object described by the accessor by traversing the attributes\r\n        of context.\r\n\r\n        \"\"\"\r\n        try:\r\n            obj = context\r\n            for level in self.levels:\r\n                if isinstance(obj, dict):\r\n                    obj = obj[level]\r\n                elif isinstance(obj, list) or isinstance(obj, tuple):\r\n                    obj = obj[int(level)]\r\n                else:\r\n                    if callable(getattr(obj, level)):\r\n                        try:\r\n                            obj = getattr(obj, level)()\r\n                        except KeyError:\r\n                            obj = getattr(obj, level)\r\n                    else:\r\n                        # for model field that has choice set\r\n                        # use get_xxx_display to access\r\n                        display = 'get_%s_display' % level\r\n                        obj = getattr(obj, display)() if hasattr(obj, display) else getattr(obj, level)\r\n                if not obj:\r\n                    break\r\n            return obj\r\n        except Exception as e:\r\n            if quiet:\r\n                return ''\r\n            else:\r\n                raise e"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of all the header rows in order of the entries in the table.", "response": "def header_rows(self):\n        \"\"\"\n        [ [header1], [header3, header4] ]\n        \"\"\"\n        # TO BE FIX: refactor\n        header_rows = []\n        headers = [col.header for col in self.columns]\n        for header in headers:\n            if len(header_rows) <= header.row_order:\n                header_rows.append([])\n            header_rows[header.row_order].append(header)\n        return header_rows"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting context data for datatable server - side response.", "response": "def get_context_data(self, **kwargs):\n        \"\"\"\n        Get context data for datatable server-side response.\n        See http://www.datatables.net/usage/server-side\n        \"\"\"\n        sEcho = self.query_data[\"sEcho\"]\n\n        context = super(BaseListView, self).get_context_data(**kwargs)\n        queryset = context[\"object_list\"]\n        if queryset is not None:\n            total_length = self.get_queryset_length(queryset)\n            queryset = self.filter_queryset(queryset)\n            display_length = self.get_queryset_length(queryset)\n\n            queryset = self.sort_queryset(queryset)\n            queryset = self.paging_queryset(queryset)\n            values_list = self.convert_queryset_to_values_list(queryset)\n            context = {\n                \"sEcho\": sEcho,\n                \"iTotalRecords\": total_length,\n                \"iTotalDisplayRecords\": display_length,\n                \"aaData\": values_list,\n            }\n        else:\n            context = {\n                \"sEcho\": sEcho,\n                \"iTotalRecords\": 0,\n                \"iTotalDisplayRecords\": 0,\n                \"aaData\": [],\n            }\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_days_span(self, month_index):\n        is_first_month = month_index == 0\n        is_last_month = month_index == self.__len__() - 1\n\n        y = int(self.start_date.year + (self.start_date.month + month_index) / 13)\n        m = int((self.start_date.month + month_index) % 12 or 12)\n        total = calendar.monthrange(y, m)[1]\n\n        if is_first_month and is_last_month:\n            return (self.end_date - self.start_date).days + 1\n        else:\n            if is_first_month:\n                return total - self.start_date.day + 1\n            elif is_last_month:\n                return self.end_date.day\n            else:\n                return total", "response": "Calculate how many days the month spans."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates an IEEE 754 float from an array of 4 bytes", "response": "def _calculate_float(self, byte_array):\n        \"\"\"Returns an IEEE 754 float from an array of 4 bytes\n\n        :param byte_array: Expects an array of 4 bytes\n\n        :type byte_array: array\n\n        :rtype: float\n        \"\"\"\n        if len(byte_array) != 4:\n            return None\n\n        return struct.unpack('f', struct.pack('4B', *byte_array))[0]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _calculate_period(self, vals):\n        ''' calculate the sampling period in seconds '''\n        if len(vals) < 4:\n            return None\n\n        if self.firmware['major'] < 16:\n            return ((vals[3] << 24) | (vals[2] << 16) | (vals[1] << 8) | vals[0]) / 12e6\n        else:\n            return self._calculate_float(vals)", "response": "calculate the sampling period in seconds"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wait(self, **kwargs):\n\n        if not callable(self.on):\n            raise UserWarning('Your device does not support the self.on function, try without wait')\n\n        if not callable(self.histogram):\n            raise UserWarning('Your device does not support the self.histogram function, try without wait')\n\n        self.on()\n        while True:\n            try:\n                if self.histogram() is None:\n                    raise UserWarning('Could not load histogram, perhaps the device is not yet connected')\n\n            except UserWarning as e:\n                sleep(kwargs.get('check', 200) / 1000.)\n\n        return self", "response": "Wait for the OPC to prepare itself for data transmission."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef calculate_bin_boundary(self, bb):\n\n        return min(enumerate(OPC_LOOKUP), key = lambda x: abs(x[1] - bb))[0]", "response": "Calculates the adc value that corresponds to a specific bin boundary diameter in microns."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the information string for the OPC .", "response": "def read_info_string(self):\n        \"\"\"Reads the information string for the OPC\n\n        :rtype: string\n\n        :Example:\n\n        >>> alpha.read_info_string()\n        'OPC-N2 FirmwareVer=OPC-018.2....................BD'\n        \"\"\"\n        infostring = []\n\n        # Send the command byte and sleep for 9 ms\n        self.cnxn.xfer([0x3F])\n        sleep(9e-3)\n\n        # Read the info string by sending 60 empty bytes\n        for i in range(60):\n            resp = self.cnxn.xfer([0x00])[0]\n            infostring.append(chr(resp))\n\n        sleep(0.1)\n\n        return ''.join(infostring)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking the connection between the Raspberry Pi and the OPC protocol.", "response": "def ping(self):\n        \"\"\"Checks the connection between the Raspberry Pi and the OPC\n\n        :rtype: Boolean\n        \"\"\"\n        b = self.cnxn.xfer([0xCF])[0]           # send the command byte\n\n        sleep(0.1)\n\n        return True if b == 0xF3 else False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on(self):\n        b1 = self.cnxn.xfer([0x03])[0]          # send the command byte\n        sleep(9e-3)                             # sleep for 9 ms\n        b2, b3 = self.cnxn.xfer([0x00, 0x01])   # send the following byte\n        sleep(0.1)\n\n        return True if b1 == 0xF3 and b2 == 0x03 else False", "response": "Turn ON the OPC"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef off(self):\n        b1 = self.cnxn.xfer([0x03])[0]          # send the command byte\n        sleep(9e-3)                             # sleep for 9 ms\n        b2 = self.cnxn.xfer([0x01])[0]          # send the following two bytes\n        sleep(0.1)\n\n        return True if b1 == 0xF3 and b2 == 0x03 else False", "response": "Turn OFF the OPC"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the configuration variables and returns them as a dictionary.", "response": "def config(self):\n        \"\"\"Read the configuration variables and returns them as a dictionary\n\n        :rtype: dictionary\n\n        :Example:\n\n        >>> alpha.config()\n        {\n            'BPD 13': 1.6499,\n            'BPD 12': 1.6499,\n            'BPD 11': 1.6499,\n            'BPD 10': 1.6499,\n            'BPD 15': 1.6499,\n            'BPD 14': 1.6499,\n            'BSVW 15': 1.0,\n            ...\n        }\n        \"\"\"\n        config  = []\n        data    = {}\n\n        # Send the command byte and sleep for 10 ms\n        self.cnxn.xfer([0x3C])\n        sleep(10e-3)\n\n        # Read the config variables by sending 256 empty bytes\n        for i in range(256):\n            resp = self.cnxn.xfer([0x00])[0]\n            config.append(resp)\n\n        # Add the bin bounds to the dictionary of data [bytes 0-29]\n        for i in range(0, 15):\n            data[\"Bin Boundary {0}\".format(i)] = self._16bit_unsigned(config[2*i], config[2*i + 1])\n\n        # Add the Bin Particle Volumes (BPV) [bytes 32-95]\n        for i in range(0, 16):\n            data[\"BPV {0}\".format(i)] = self._calculate_float(config[4*i + 32:4*i + 36])\n\n        # Add the Bin Particle Densities (BPD) [bytes 96-159]\n        for i in range(0, 16):\n            data[\"BPD {0}\".format(i)] = self._calculate_float(config[4*i + 96:4*i + 100])\n\n        # Add the Bin Sample Volume Weight (BSVW) [bytes 160-223]\n        for i in range(0, 16):\n            data[\"BSVW {0}\".format(i)] = self._calculate_float(config[4*i + 160: 4*i + 164])\n\n        # Add the Gain Scaling Coefficient (GSC) and sample flow rate (SFR)\n        data[\"GSC\"] = self._calculate_float(config[224:228])\n        data[\"SFR\"] = self._calculate_float(config[228:232])\n\n        # Add laser dac (LDAC) and Fan dac (FanDAC)\n        data[\"LaserDAC\"]    = config[232]\n        data[\"FanDAC\"]      = config[233]\n\n        # If past firmware 15, add other things\n        if self.firmware['major'] > 15.:\n            data['TOF_SFR'] = config[234]\n\n        sleep(0.1)\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the second set of configuration variables and return as a dictionary.", "response": "def config2(self):\n        \"\"\"Read the second set of configuration variables and return as a dictionary.\n\n        **NOTE: This method is supported by firmware v18+.**\n\n        :rtype: dictionary\n\n        :Example:\n\n        >>> a.config2()\n        {\n            'AMFanOnIdle': 0,\n            'AMIdleIntervalCount': 0,\n            'AMMaxDataArraysInFile': 61798,\n            'AMSamplingInterval': 1,\n            'AMOnlySavePMData': 0,\n            'AMLaserOnIdle': 0\n        }\n        \"\"\"\n        config  = []\n        data    = {}\n\n        # Send the command byte and sleep for 10 ms\n        self.cnxn.xfer([0x3D])\n        sleep(10e-3)\n\n        # Read the config variables by sending 256 empty bytes\n        for i in range(9):\n            resp = self.cnxn.xfer([0x00])[0]\n            config.append(resp)\n\n        data[\"AMSamplingInterval\"]      = self._16bit_unsigned(config[0], config[1])\n        data[\"AMIdleIntervalCount\"]     = self._16bit_unsigned(config[2], config[3])\n        data['AMFanOnIdle']             = config[4]\n        data['AMLaserOnIdle']           = config[5]\n        data['AMMaxDataArraysInFile']   = self._16bit_unsigned(config[6], config[7])\n        data['AMOnlySavePMData']        = config[8]\n\n        sleep(0.1)\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef histogram(self, number_concentration=True):\n        resp = []\n        data = {}\n\n        # Send the command byte\n        self.cnxn.xfer([0x30])\n\n        # Wait 10 ms\n        sleep(10e-3)\n\n        # read the histogram\n        for i in range(62):\n            r = self.cnxn.xfer([0x00])[0]\n            resp.append(r)\n\n        # convert to real things and store in dictionary!\n        data['Bin 0']           = self._16bit_unsigned(resp[0], resp[1])\n        data['Bin 1']           = self._16bit_unsigned(resp[2], resp[3])\n        data['Bin 2']           = self._16bit_unsigned(resp[4], resp[5])\n        data['Bin 3']           = self._16bit_unsigned(resp[6], resp[7])\n        data['Bin 4']           = self._16bit_unsigned(resp[8], resp[9])\n        data['Bin 5']           = self._16bit_unsigned(resp[10], resp[11])\n        data['Bin 6']           = self._16bit_unsigned(resp[12], resp[13])\n        data['Bin 7']           = self._16bit_unsigned(resp[14], resp[15])\n        data['Bin 8']           = self._16bit_unsigned(resp[16], resp[17])\n        data['Bin 9']           = self._16bit_unsigned(resp[18], resp[19])\n        data['Bin 10']          = self._16bit_unsigned(resp[20], resp[21])\n        data['Bin 11']          = self._16bit_unsigned(resp[22], resp[23])\n        data['Bin 12']          = self._16bit_unsigned(resp[24], resp[25])\n        data['Bin 13']          = self._16bit_unsigned(resp[26], resp[27])\n        data['Bin 14']          = self._16bit_unsigned(resp[28], resp[29])\n        data['Bin 15']          = self._16bit_unsigned(resp[30], resp[31])\n        data['Bin1 MToF']       = self._calculate_mtof(resp[32])\n        data['Bin3 MToF']       = self._calculate_mtof(resp[33])\n        data['Bin5 MToF']       = self._calculate_mtof(resp[34])\n        data['Bin7 MToF']       = self._calculate_mtof(resp[35])\n\n        # Bins associated with firmware versions 14 and 15(?)\n        if self.firmware['version'] < 16.:\n            data['Temperature']     = self._calculate_temp(resp[36:40])\n            data['Pressure']        = self._calculate_pressure(resp[40:44])\n            data['Sampling Period'] = self._calculate_period(resp[44:48])\n            data['Checksum']        = self._16bit_unsigned(resp[48], resp[49])\n            data['PM1']             = self._calculate_float(resp[50:54])\n            data['PM2.5']           = self._calculate_float(resp[54:58])\n            data['PM10']            = self._calculate_float(resp[58:])\n\n        else:\n            data['SFR']             = self._calculate_float(resp[36:40])\n\n            # Alright, we don't know whether it is temp or pressure since it switches..\n            tmp = self._calculate_pressure(resp[40:44])\n            if tmp > 98000:\n                data['Temperature'] = None\n                data['Pressure']    = tmp\n            else:\n                tmp = self._calculate_temp(resp[40:44])\n                if tmp < 500:\n                    data['Temperature'] = tmp\n                    data['Pressure']    = None\n                else:\n                    data['Temperature'] = None\n                    data['Pressure']    = None\n\n            data['Sampling Period'] = self._calculate_float(resp[44:48])\n            data['Checksum']        = self._16bit_unsigned(resp[48], resp[49])\n            data['PM1']             = self._calculate_float(resp[50:54])\n            data['PM2.5']           = self._calculate_float(resp[54:58])\n            data['PM10']            = self._calculate_float(resp[58:])\n\n        # Calculate the sum of the histogram bins\n        histogram_sum = data['Bin 0'] + data['Bin 1'] + data['Bin 2']   + \\\n                data['Bin 3'] + data['Bin 4'] + data['Bin 5'] + data['Bin 6']   + \\\n                data['Bin 7'] + data['Bin 8'] + data['Bin 9'] + data['Bin 10']  + \\\n                data['Bin 11'] + data['Bin 12'] + data['Bin 13'] + data['Bin 14'] + \\\n                data['Bin 15']\n\n        # Check that checksum and the least significant bits of the sum of histogram bins\n        # are equivilant\n        if (histogram_sum & 0x0000FFFF) != data['Checksum']:\n            logger.warning(\"Data transfer was incomplete\")\n            return None\n\n        # If histogram is true, convert histogram values to number concentration\n        if number_concentration is True:\n            _conv_ = data['SFR'] * data['Sampling Period'] # Divider in units of ml (cc)\n\n            data['Bin 0']   = data['Bin 0'] / _conv_\n            data['Bin 1']   = data['Bin 1'] / _conv_\n            data['Bin 2']   = data['Bin 2'] / _conv_\n            data['Bin 3']   = data['Bin 3'] / _conv_\n            data['Bin 4']   = data['Bin 4'] / _conv_\n            data['Bin 5']   = data['Bin 5'] / _conv_\n            data['Bin 6']   = data['Bin 6'] / _conv_\n            data['Bin 7']   = data['Bin 7'] / _conv_\n            data['Bin 8']   = data['Bin 8'] / _conv_\n            data['Bin 9']   = data['Bin 9'] / _conv_\n            data['Bin 10']  = data['Bin 10'] / _conv_\n            data['Bin 11']  = data['Bin 11'] / _conv_\n            data['Bin 12']  = data['Bin 12'] / _conv_\n            data['Bin 13']  = data['Bin 13'] / _conv_\n            data['Bin 14']  = data['Bin 14'] / _conv_\n            data['Bin 15']  = data['Bin 15'] / _conv_\n\n        sleep(0.1)\n\n        return data", "response": "Read and reset the histogram. As of v1. 3. 0 histogram values are reported in number concentration by default."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_config_variables(self):\n        command = 0x43\n        byte_list = [0x3F, 0x3C, 0x3F, 0x3C, 0x43]\n        success = [0xF3, 0x43, 0x3F, 0x3C, 0x3F, 0x3C]\n        resp = []\n\n        # Send the command byte and then wait for 10 ms\n        r = self.cnxn.xfer([command])[0]\n        sleep(10e-3)\n\n        # append the response of the command byte to the List\n        resp.append(r)\n\n        # Send the rest of the config bytes\n        for each in byte_list:\n            r = self.cnxn.xfer([each])[0]\n            resp.append(r)\n\n        sleep(0.1)\n\n        return True if resp == success else False", "response": "This method saves the configuration variables in non - volatile memory. This method is used in conjuction with write_config_variables."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_fan_power(self, power):\n        # Check to make sure the value is a single byte\n        if power > 255:\n            raise ValueError(\"The fan power should be a single byte (0-255).\")\n\n        # Send the command byte and wait 10 ms\n        a = self.cnxn.xfer([0x42])[0]\n        sleep(10e-3)\n\n        # Send the next two bytes\n        b = self.cnxn.xfer([0x00])[0]\n        c = self.cnxn.xfer([power])[0]\n\n        sleep(0.1)\n\n        return True if a == 0xF3 and b == 0x42 and c == 0x00 else False", "response": "Set the fan power."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef toggle_laser(self, state):\n\n        # Send the command byte and wait 10 ms\n        a = self.cnxn.xfer([0x03])[0]\n\n        sleep(10e-3)\n\n        # If state is true, turn the laser ON, else OFF\n        if state:\n            b = self.cnxn.xfer([0x02])[0]\n        else:\n            b = self.cnxn.xfer([0x03])[0]\n\n        sleep(0.1)\n\n        return True if a == 0xF3 and b == 0x03 else False", "response": "Toggle the power state of the laser."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the status of the digital potential. Firmware v18 + only.", "response": "def read_pot_status(self):\n        \"\"\"Read the status of the digital pot. Firmware v18+ only.\n        The return value is a dictionary containing the following as\n        unsigned 8-bit integers: FanON, LaserON, FanDACVal, LaserDACVal.\n\n        :rtype: dict\n\n        :Example:\n\n        >>> alpha.read_pot_status()\n        {\n            'LaserDACVal': 230,\n            'FanDACVal': 255,\n            'FanON': 0,\n            'LaserON': 0\n        }\n        \"\"\"\n        # Send the command byte and wait 10 ms\n        a = self.cnxn.xfer([0x13])[0]\n\n        sleep(10e-3)\n\n        # Build an array of the results\n        res = []\n        for i in range(4):\n            res.append(self.cnxn.xfer([0x00])[0])\n\n        sleep(0.1)\n\n        return {\n            'FanON':        res[0],\n            'LaserON':      res[1],\n            'FanDACVal':    res[2],\n            'LaserDACVal':  res[3]\n            }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the Serial Number string. This method is only available on OPC - N2 123456789.", "response": "def sn(self):\n        \"\"\"Read the Serial Number string. This method is only available on OPC-N2\n        firmware versions 18+.\n\n        :rtype: string\n\n        :Example:\n\n        >>> alpha.sn()\n        'OPC-N2 123456789'\n        \"\"\"\n        string = []\n\n        # Send the command byte and sleep for 9 ms\n        self.cnxn.xfer([0x10])\n        sleep(9e-3)\n\n        # Read the info string by sending 60 empty bytes\n        for i in range(60):\n            resp = self.cnxn.xfer([0x00])[0]\n            string.append(chr(resp))\n\n        sleep(0.1)\n\n        return ''.join(string)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the firmware version of the OPC - N2. Firmware v18 + only.", "response": "def read_firmware(self):\n        \"\"\"Read the firmware version of the OPC-N2. Firmware v18+ only.\n\n        :rtype: dict\n\n        :Example:\n\n        >>> alpha.read_firmware()\n        {\n            'major': 18,\n            'minor': 2,\n            'version': 18.2\n        }\n        \"\"\"\n        # Send the command byte and sleep for 9 ms\n        self.cnxn.xfer([0x12])\n        sleep(10e-3)\n\n        self.firmware['major'] = self.cnxn.xfer([0x00])[0]\n        self.firmware['minor'] = self.cnxn.xfer([0x00])[0]\n\n        # Build the firmware version\n        self.firmware['version'] = float('{}.{}'.format(self.firmware['major'], self.firmware['minor']))\n\n        sleep(0.1)\n\n        return self.firmware"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the PM data and reset the histogram!", "response": "def pm(self):\n        \"\"\"Read the PM data and reset the histogram\n\n        **NOTE: This method is supported by firmware v18+.**\n\n        :rtype: dictionary\n\n        :Example:\n\n        >>> alpha.pm()\n        {\n            'PM1': 0.12,\n            'PM2.5': 0.24,\n            'PM10': 1.42\n        }\n        \"\"\"\n\n        resp = []\n        data = {}\n\n        # Send the command byte\n        self.cnxn.xfer([0x32])\n\n        # Wait 10 ms\n        sleep(10e-3)\n\n        # read the histogram\n        for i in range(12):\n            r = self.cnxn.xfer([0x00])[0]\n            resp.append(r)\n\n        # convert to real things and store in dictionary!\n        data['PM1']     = self._calculate_float(resp[0:4])\n        data['PM2.5']   = self._calculate_float(resp[4:8])\n        data['PM10']    = self._calculate_float(resp[8:])\n\n        sleep(0.1)\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on(self):\n        b1 = self.cnxn.xfer([0x0C])[0]          # send the command byte\n        sleep(9e-3)                             # sleep for 9 ms\n\n        return True if b1 == 0xF3 else False", "response": "Turn ON the OPC"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef off(self):\n        b1 = self.cnxn.xfer([0x03])[0]          # send the command byte\n        sleep(9e-3)                             # sleep for 9 ms\n\n        return True if b1 == 0xF3 else False", "response": "Turn OFF the OPC"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_gsc_sfr(self):\n        config  = []\n        data    = {}\n\n        # Send the command byte and sleep for 10 ms\n        self.cnxn.xfer([0x33])\n        sleep(10e-3)\n\n        # Read the config variables by sending 256 empty bytes\n        for i in range(8):\n            resp = self.cnxn.xfer([0x00])[0]\n            config.append(resp)\n\n        data[\"GSC\"] = self._calculate_float(config[0:4])\n        data[\"SFR\"] = self._calculate_float(config[4:])\n\n        return data", "response": "Reads the gain - scaling coefficient and sample flow rate."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_bin_boundaries(self):\n        config  = []\n        data    = {}\n\n        # Send the command byte and sleep for 10 ms\n        self.cnxn.xfer([0x33])\n        sleep(10e-3)\n\n        # Read the config variables by sending 256 empty bytes\n        for i in range(30):\n            resp = self.cnxn.xfer([0x00])[0]\n            config.append(resp)\n\n        # Add the bin bounds to the dictionary of data [bytes 0-29]\n        for i in range(0, 14):\n            data[\"Bin Boundary {0}\".format(i)] = self._16bit_unsigned(config[2*i], config[2*i + 1])\n\n        return data", "response": "Reads the 17 bin boundaries from the CXN and returns the dictionary with the bin boundaries."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the bin particle density.", "response": "def read_bin_particle_density(self):\n        \"\"\"Read the bin particle density\n\n        :returns: float\n        \"\"\"\n        config = []\n\n        # Send the command byte and sleep for 10 ms\n        self.cnxn.xfer([0x33])\n        sleep(10e-3)\n\n        # Read the config variables by sending 256 empty bytes\n        for i in range(4):\n            resp = self.cnxn.xfer([0x00])[0]\n            config.append(resp)\n\n        bpd = self._calculate_float(config)\n\n        return bpd"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads and reset the histogram.", "response": "def read_histogram(self):\n        \"\"\"Read and reset the histogram. The expected return is a dictionary\n        containing the counts per bin, MToF for bins 1, 3, 5, and 7, temperature,\n        pressure, the sampling period, the checksum, PM1, PM2.5, and PM10.\n\n        **NOTE:** The sampling period for the OPCN1 seems to be incorrect.\n\n        :returns: dictionary\n        \"\"\"\n        resp = []\n        data = {}\n\n        # command byte\n        command = 0x30\n\n        # Send the command byte\n        self.cnxn.xfer([command])\n\n        # Wait 10 ms\n        sleep(10e-3)\n\n        # read the histogram\n        for i in range(62):\n            r = self.cnxn.xfer([0x00])[0]\n            resp.append(r)\n\n        # convert to real things and store in dictionary!\n        data['Bin 0']           = self._16bit_unsigned(resp[0], resp[1])\n        data['Bin 1']           = self._16bit_unsigned(resp[2], resp[3])\n        data['Bin 2']           = self._16bit_unsigned(resp[4], resp[5])\n        data['Bin 3']           = self._16bit_unsigned(resp[6], resp[7])\n        data['Bin 4']           = self._16bit_unsigned(resp[8], resp[9])\n        data['Bin 5']           = self._16bit_unsigned(resp[10], resp[11])\n        data['Bin 6']           = self._16bit_unsigned(resp[12], resp[13])\n        data['Bin 7']           = self._16bit_unsigned(resp[14], resp[15])\n        data['Bin 8']           = self._16bit_unsigned(resp[16], resp[17])\n        data['Bin 9']           = self._16bit_unsigned(resp[18], resp[19])\n        data['Bin 10']          = self._16bit_unsigned(resp[20], resp[21])\n        data['Bin 11']          = self._16bit_unsigned(resp[22], resp[23])\n        data['Bin 12']          = self._16bit_unsigned(resp[24], resp[25])\n        data['Bin 13']          = self._16bit_unsigned(resp[26], resp[27])\n        data['Bin 14']          = self._16bit_unsigned(resp[28], resp[29])\n        data['Bin 15']          = self._16bit_unsigned(resp[30], resp[31])\n        data['Bin1 MToF']       = self._calculate_mtof(resp[32])\n        data['Bin3 MToF']       = self._calculate_mtof(resp[33])\n        data['Bin5 MToF']       = self._calculate_mtof(resp[34])\n        data['Bin7 MToF']       = self._calculate_mtof(resp[35])\n        data['Temperature']     = self._calculate_temp(resp[36:40])\n        data['Pressure']        = self._calculate_pressure(resp[40:44])\n        data['Sampling Period'] = self._calculate_period(resp[44:48])\n        data['Checksum']        = self._16bit_unsigned(resp[48], resp[49])\n        data['PM1']             = self._calculate_float(resp[50:54])\n        data['PM2.5']           = self._calculate_float(resp[54:58])\n        data['PM10']            = self._calculate_float(resp[58:])\n\n        # Calculate the sum of the histogram bins\n        histogram_sum = data['Bin 0'] + data['Bin 1'] + data['Bin 2']   + \\\n                data['Bin 3'] + data['Bin 4'] + data['Bin 5'] + data['Bin 6']   + \\\n                data['Bin 7'] + data['Bin 8'] + data['Bin 9'] + data['Bin 10']  + \\\n                data['Bin 11'] + data['Bin 12'] + data['Bin 13'] + data['Bin 14'] + \\\n                data['Bin 15']\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start(self):\n\n        self.receiver = self.Receiver(\n            self.read,\n            self.write,\n            self.send_lock,\n            self.senders,\n            self.frames_received,\n            callback=self.receive_callback,\n            fcs_nack=self.fcs_nack,\n        )\n\n        self.receiver.start()", "response": "Starts HDLC controller s threads."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stop(self):\n\n        if self.receiver != None:\n            self.receiver.join()\n\n        for s in self.senders.values():\n            s.join()", "response": "Stops HDLC controller s threads."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send(self, data):\n\n        while len(self.senders) >= self.window:\n            pass\n\n        self.senders[self.new_seq_no] = self.Sender(\n            self.write,\n            self.send_lock,\n            data,\n            self.new_seq_no,\n            timeout=self.sending_timeout,\n            callback=self.send_callback,\n        )\n\n        self.senders[self.new_seq_no].start()\n        self.new_seq_no = (self.new_seq_no + 1) % HDLController.MAX_SEQ_NO", "response": "This method sends a new data frame to the HDL controller."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cmp(self, other):\n        if isinstance(other, Range):\n            # other has tz, I dont, so replace the tz\n            start = self.start.replace(tzinfo=other.start.tz) if other.start.tz and self.start.tz is None else self.start\n            end = self.end.replace(tzinfo=other.end.tz) if other.end.tz and self.end.tz is None else self.end\n\n            if start == other.start and end == other.end:\n                return 0 \n            elif start < other.start:\n                return -1\n            else:\n                return 1\n\n        elif isinstance(other, Date):\n            if other.tz and self.start.tz is None:\n                return 0 if other == self.start.replace(tzinfo=other.tz) else -1 if other > self.start.replace(tzinfo=other.start.tz) else 1\n            return 0 if other == self.start else -1 if other > self.start else 1\n        else:\n            return self.cmp(Range(other, tz=self.start.tz))", "response": "Compare two sets of date objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncut this object from_start to the number requestd returns new instance of Range", "response": "def cut(self, by, from_start=True):\n        \"\"\" Cuts this object from_start to the number requestd\n        returns new instance\n        \"\"\"\n        s, e = copy(self.start), copy(self.end)\n        if from_start:\n            e = s + by\n        else:\n            s = e - by\n        return Range(s, e)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new instance of self with the next time.", "response": "def next(self, times=1):\n        \"\"\"Returns a new instance of self\n        times is not supported yet.\n        \"\"\"\n        return Range(copy(self.end),\n                     self.end + self.elapse, tz=self.start.tz)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new instance of self with the previous entry in the time zone.", "response": "def prev(self, times=1):\n        \"\"\"Returns a new instance of self\n        times is not supported yet.\n        \"\"\"\n        return Range(self.start - self.elapse,\n                     copy(self.start), tz=self.start.tz)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nnoting returns a new Date obj", "response": "def replace(self, **k):\n        \"\"\"Note returns a new Date obj\"\"\"\n        if self.date != 'infinity':\n            return Date(self.date.replace(**k))\n        else:\n            return Date('infinity')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadjusts the time from kwargs to timedelta Returns a new copy of self", "response": "def adjust(self, to):\n        '''\n        Adjusts the time from kwargs to timedelta\n        **Will change this object**\n\n        return new copy of self\n        '''\n        if self.date == 'infinity':\n            return\n        new = copy(self)\n        if type(to) in (str, unicode):\n            to = to.lower()\n            res = TIMESTRING_RE.search(to)\n            if res:\n                rgroup = res.groupdict()\n                if (rgroup.get('delta') or rgroup.get('delta_2')):\n                    i = int(text2num(rgroup.get('num', 'one'))) * (-1 if to.startswith('-') else 1)\n                    delta = (rgroup.get('delta') or rgroup.get('delta_2')).lower()\n                    if delta.startswith('y'):\n                        try:\n                            new.date = new.date.replace(year=(new.date.year + i))\n                        except ValueError:\n                            # day is out of range for month\n                            new.date = new.date + timedelta(days=(365 * i))\n                    elif delta.startswith('month'):\n                        if (new.date.month + i) > 12:\n                            new.date = new.date.replace(month=(i - (i / 12)),\n                                                        year=(new.date.year + 1 + (i / 12)))\n                        elif (new.date.month + i) < 1:\n                            new.date = new.date.replace(month=12, year=(new.date.year - 1))\n                        else:\n                            new.date = new.date.replace(month=(new.date.month + i))\n                    elif delta.startswith('q'):\n                        # NP\n                        pass\n                    elif delta.startswith('w'):\n                        new.date = new.date + timedelta(days=(7 * i))\n                    elif delta.startswith('s'):\n                        new.date = new.date + timedelta(seconds=i)\n                    else:\n                        new.date = new.date + timedelta(**{('days' if delta.startswith('d') else 'hours' if delta.startswith('h') else 'minutes' if delta.startswith('m') else 'seconds'): i})\n                    return new\n        else:\n            new.date = new.date + timedelta(seconds=int(to))\n            return new\n\n        raise TimestringInvalid('Invalid addition request')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind all the timestrings within a block of text.", "response": "def findall(text):\n    \"\"\"Find all the timestrings within a block of text.\n\n    >>> timestring.findall(\"once upon a time, about 3 weeks ago, there was a boy whom was born on august 15th at 7:20 am. epic.\")\n    [\n     ('3 weeks ago,', <timestring.Date 2014-02-09 00:00:00 4483019280>),\n     ('august 15th at 7:20 am', <timestring.Date 2014-08-15 07:20:00 4483019344>)\n    ]\n    \"\"\"\n    results = TIMESTRING_RE.findall(text)\n    dates = []\n    for date in results:\n        if re.compile('((next|last)\\s(\\d+|couple(\\sof))\\s(weeks|months|quarters|years))|(between|from)', re.I).match(date[0]):\n            dates.append((date[0].strip(), Range(date[0])))\n        else:\n            dates.append((date[0].strip(), Date(date[0])))\n    return dates"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef authenticate(self, request):\n        try:\n            oauth_request = oauth_provider.utils.get_oauth_request(request)\n        except oauth.Error as err:\n            raise exceptions.AuthenticationFailed(err.message)\n\n        if not oauth_request:\n            return None\n\n        oauth_params = oauth_provider.consts.OAUTH_PARAMETERS_NAMES\n\n        found = any(param for param in oauth_params if param in oauth_request)\n        missing = list(param for param in oauth_params if param not in oauth_request)\n\n        if not found:\n            # OAuth authentication was not attempted.\n            return None\n\n        if missing:\n            # OAuth was attempted but missing parameters.\n            msg = 'Missing parameters: %s' % (', '.join(missing))\n            raise exceptions.AuthenticationFailed(msg)\n\n        if not self.check_nonce(request, oauth_request):\n            msg = 'Nonce check failed'\n            raise exceptions.AuthenticationFailed(msg)\n\n        try:\n            consumer_key = oauth_request.get_parameter('oauth_consumer_key')\n            consumer = oauth_provider_store.get_consumer(request, oauth_request, consumer_key)\n        except oauth_provider.store.InvalidConsumerError:\n            msg = 'Invalid consumer token: %s' % oauth_request.get_parameter('oauth_consumer_key')\n            raise exceptions.AuthenticationFailed(msg)\n\n        if consumer.status != oauth_provider.consts.ACCEPTED:\n            msg = 'Invalid consumer key status: %s' % consumer.get_status_display()\n            raise exceptions.AuthenticationFailed(msg)\n\n        try:\n            token_param = oauth_request.get_parameter('oauth_token')\n            token = oauth_provider_store.get_access_token(request, oauth_request, consumer, token_param)\n        except oauth_provider.store.InvalidTokenError:\n            msg = 'Invalid access token: %s' % oauth_request.get_parameter('oauth_token')\n            raise exceptions.AuthenticationFailed(msg)\n\n        try:\n            self.validate_token(request, consumer, token)\n        except oauth.Error as err:\n            raise exceptions.AuthenticationFailed(err.message)\n\n        user = token.user\n\n        if not user.is_active:\n            msg = 'User inactive or deleted: %s' % user.username\n            raise exceptions.AuthenticationFailed(msg)\n\n        return (token.user, token)", "response": "Authenticate the user with the OAuth request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_token(self, request, consumer, token):\n        oauth_server, oauth_request = oauth_provider.utils.initialize_server_request(request)\n        oauth_server.verify_request(oauth_request, consumer, token)", "response": "Validate the token and raise an OAuth. Error exception if invalid."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_nonce(self, request, oauth_request):\n        oauth_nonce = oauth_request['oauth_nonce']\n        oauth_timestamp = oauth_request['oauth_timestamp']\n        return check_nonce(request, oauth_request, oauth_nonce, oauth_timestamp)", "response": "Checks the nonce of request and return True if valid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nauthenticate the user with the request.", "response": "def authenticate(self, request):\n        \"\"\"\n        Returns two-tuple of (user, token) if authentication succeeds,\n        or None otherwise.\n        \"\"\"\n\n        auth = get_authorization_header(request).split()\n\n        if len(auth) == 1:\n            msg = 'Invalid bearer header. No credentials provided.'\n            raise exceptions.AuthenticationFailed(msg)\n        elif len(auth) > 2:\n            msg = 'Invalid bearer header. Token string should not contain spaces.'\n            raise exceptions.AuthenticationFailed(msg)\n\n        if auth and auth[0].lower() == b'bearer':\n            access_token = auth[1]\n        elif 'access_token' in request.POST:\n            access_token = request.POST['access_token']\n        elif 'access_token' in request.GET and self.allow_query_params_token:\n            access_token = request.GET['access_token']\n        else:\n            return None\n\n        return self.authenticate_credentials(request, access_token)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the signature of the current token", "response": "def getSHA1(self, token, timestamp, nonce, encrypt):\n        \"\"\"\u7528SHA1\u7b97\u6cd5\u751f\u6210\u5b89\u5168\u7b7e\u540d\n        @param token:  \u7968\u636e\n        @param timestamp: \u65f6\u95f4\u6233\n        @param encrypt: \u5bc6\u6587\n        @param nonce: \u968f\u673a\u5b57\u7b26\u4e32\n        @return: \u5b89\u5168\u7b7e\u540d\n        \"\"\"\n        try:\n            sortlist = [token, timestamp, nonce, encrypt]\n            sortlist.sort()\n            sha = hashlib.sha1()\n            sha.update(\"\".join(sortlist))\n            return WXBizMsgCrypt_OK, sha.hexdigest()\n        except Exception:\n            return WXBizMsgCrypt_ComputeSignature_Error, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts the encrypted and touser name from xmltext.", "response": "def extract(self, xmltext):\n        \"\"\"\u63d0\u53d6\u51faxml\u6570\u636e\u5305\u4e2d\u7684\u52a0\u5bc6\u6d88\u606f\n        @param xmltext: \u5f85\u63d0\u53d6\u7684xml\u5b57\u7b26\u4e32\n        @return: \u63d0\u53d6\u51fa\u7684\u52a0\u5bc6\u6d88\u606f\u5b57\u7b26\u4e32\n        \"\"\"\n        try:\n            xml_tree = ET.fromstring(xmltext)\n            encrypt = xml_tree.find(\"Encrypt\")\n            touser_name = xml_tree.find(\"ToUserName\")\n            if touser_name != None:\n                touser_name = touser_name.text\n            return WXBizMsgCrypt_OK, encrypt.text, touser_name\n        except Exception:\n            return WXBizMsgCrypt_ParseXml_Error, None, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef encode(self, text):\n        text_length = len(text)\n        # \u8ba1\u7b97\u9700\u8981\u586b\u5145\u7684\u4f4d\u6570\n        amount_to_pad = self.block_size - (text_length % self.block_size)\n        if amount_to_pad == 0:\n            amount_to_pad = self.block_size\n        # \u83b7\u5f97\u8865\u4f4d\u6240\u7528\u7684\u5b57\u7b26\n        pad = chr(amount_to_pad)\n        return text + pad * amount_to_pad", "response": "Encodes the given text into a base64 - encoded version of the key."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndecodes a string to a unicode object", "response": "def decode(self, decrypted):\n        \"\"\"\u5220\u9664\u89e3\u5bc6\u540e\u660e\u6587\u7684\u8865\u4f4d\u5b57\u7b26\n        @param decrypted: \u89e3\u5bc6\u540e\u7684\u660e\u6587\n        @return: \u5220\u9664\u8865\u4f4d\u5b57\u7b26\u540e\u7684\u660e\u6587\n        \"\"\"\n        pad = ord(decrypted[-1])\n        if pad < 1 or pad > 32:\n            pad = 0\n        return decrypted[:-pad]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nencrypting text with appid", "response": "def encrypt(self, text, appid):\n        \"\"\"\u5bf9\u660e\u6587\u8fdb\u884c\u52a0\u5bc6\n        @param text: \u9700\u8981\u52a0\u5bc6\u7684\u660e\u6587\n        @return: \u52a0\u5bc6\u5f97\u5230\u7684\u5b57\u7b26\u4e32\n        \"\"\"\n        # 16\u4f4d\u968f\u673a\u5b57\u7b26\u4e32\u6dfb\u52a0\u5230\u660e\u6587\u5f00\u5934\n        text = self.get_random_str() + struct.pack(\n            \"I\", socket.htonl(len(text))) + text + appid\n        # \u4f7f\u7528\u81ea\u5b9a\u4e49\u7684\u586b\u5145\u65b9\u5f0f\u5bf9\u660e\u6587\u8fdb\u884c\u8865\u4f4d\u586b\u5145\n        pkcs7 = PKCS7Encoder()\n        text = pkcs7.encode(text)\n        # \u52a0\u5bc6\n        cryptor = AES.new(self.key, self.mode, self.key[:16])\n        try:\n            ciphertext = cryptor.encrypt(text)\n            # \u4f7f\u7528BASE64\u5bf9\u52a0\u5bc6\u540e\u7684\u5b57\u7b26\u4e32\u8fdb\u884c\u7f16\u7801\n            return WXBizMsgCrypt_OK, base64.b64encode(ciphertext)\n        except Exception:\n            return WXBizMsgCrypt_EncryptAES_Error, None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef deliveries(self):\n        key = make_key(\n            event=self.object.event,\n            owner_name=self.object.owner.username,\n            identifier=self.object.identifier\n        )\n        return redis.lrange(key, 0, 20)", "response": "Get the delivery log from Redis"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the possible events from settings. WEBHOOK_EVENTS", "response": "def event_choices(events):\n    \"\"\" Get the possible events from settings \"\"\"\n    if events is None:\n        msg = \"Please add some events in settings.WEBHOOK_EVENTS.\"\n        raise ImproperlyConfigured(msg)\n    try:\n        choices = [(x, x) for x in events]\n    except TypeError:\n        \"\"\" Not a valid iterator, so we raise an exception \"\"\"\n        msg = \"settings.WEBHOOK_EVENTS must be an iterable object.\"\n        raise ImproperlyConfigured(msg)\n    return choices"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nnotifying the user of a new resource.", "response": "def notify(self, message):\n        \"\"\"\n            TODO: Add code to lpush to redis stack\n                    rpop when stack hits size 'X'\n        \"\"\"\n        data = dict(\n                payload=self.payload,\n                attempt=self.attempt,\n                success=self.success,\n                response_message=self.response_content,\n                hash_value=self.hash_value,\n                response_status=self.response.status_code,\n                notification=message,\n                created=timezone.now()\n            )\n        value = json.dumps(data, cls=StandardJSONEncoder)\n        key = make_key(self.event, self.owner.username, self.identifier)\n        redis.lpush(key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send(self, msg):\n        # Create a sliplib Driver\n        slipDriver = sliplib.Driver()\n\n        # Package data in slip format\n        slipData = slipDriver.send(msg)\n\n        # Send data over serial port\n        res = self._serialPort.write(slipData)\n\n        # Return number of bytes transmitted over serial port\n        return res", "response": "Encodes data to slip protocol and then sends it over the serial port."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef receive(self, length):\n\n        # Create a sliplib Driver\n        slipDriver = sliplib.Driver()\n\n        # Receive data from serial port\n        ret = self._serialPort.read(length)\n\n        # Decode data from slip format, stores msgs in sliplib.Driver.messages\n        temp = slipDriver.receive(ret)\n        return iter(temp)", "response": "Reads in data from a serial port and decodes the SLIP packets and returns an iterator of the messages received."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef checkTUN(self):\n        packet = self._TUN._tun.read(self._TUN._tun.mtu)\n        return(packet)", "response": "Checks the TUN adapter for data and returns any that is found."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef monitorTUN(self):\n        packet = self.checkTUN()\n\n        if packet:\n            try:\n                # TODO Do I need to strip off [4:] before sending?\n                ret = self._faraday.send(packet)\n                return ret\n\n            except AttributeError as error:\n                # AttributeError was encounteredthreading.Event()\n                print(\"AttributeError\")", "response": "Monitors the TUN adapter and sends data over serial port."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef checkSerial(self):\n        for item in self.rxSerial(self._TUN._tun.mtu):\n            # print(\"about to send: {0}\".format(item))\n            try:\n                self._TUN._tun.write(item)\n            except pytun.Error as error:\n                print(\"pytun error writing: {0}\".format(item))\n                print(error)", "response": "Check the serial port for data to write to the TUN adapter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrap function for TUN and serial port monitoring Wraps the necessary functions to loop over until self._isRunning threading.Event() is set(). This checks for data on the TUN/serial interfaces and then sends data over the appropriate interface. This function is automatically run when Threading.start() is called on the Monitor class.", "response": "def run(self):\n        \"\"\"\n        Wrapper function for TUN and serial port monitoring\n\n        Wraps the necessary functions to loop over until self._isRunning\n        threading.Event() is set(). This checks for data on the TUN/serial\n        interfaces and then sends data over the appropriate interface. This\n        function is automatically run when Threading.start() is called on the\n        Monitor class.\n        \"\"\"\n        while self.isRunning.is_set():\n            try:\n                try:\n                    # self.checkTUN()\n                    self.monitorTUN()\n\n                except timeout_decorator.TimeoutError as error:\n                    # No data received so just move on\n                    pass\n                self.checkSerial()\n            except KeyboardInterrupt:\n                break"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_formsets(self, request, obj, change, index, is_template):\n        \"Helper function to generate formsets for add/change_view.\"\n        formsets = []\n        inline_instances = []\n        prefixes = defaultdict(int)\n        get_formsets_args = [request]\n        if change:\n            get_formsets_args.append(obj)\n        base_prefix = self.get_formset(request).get_default_prefix()\n        for FormSet, inline in self.get_formsets_with_inlines(\n                *get_formsets_args):\n            prefix = base_prefix + '-' + FormSet.get_default_prefix()\n            if not is_template:\n                prefix += '-%s' % index\n            prefixes[prefix] += 1\n            if prefixes[prefix] != 1 or not prefix:\n                prefix = \"%s-%s\" % (prefix, prefixes[prefix])\n            formset_params = {\n                'instance': obj,\n                'prefix': prefix,\n                'queryset': inline.get_queryset(request),\n            }\n            if request.method == 'POST':\n                formset_params.update({\n                    'data': request.POST,\n                    'files': request.FILES,\n                    'save_as_new': '_saveasnew' in request.POST\n                })\n            formset = FormSet(**formset_params)\n            formset.has_parent = True\n            formsets.append(formset)\n            inline_instances.append(inline)\n        return formsets, inline_instances", "response": "Helper function to generate formsets for add / change_view."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_field_settings(self):\n        field_settings = None\n        if self.field_settings:\n            if isinstance(self.field_settings, six.string_types):\n                profiles = settings.CONFIG.get(self.PROFILE_KEY, {})\n                field_settings = profiles.get(self.field_settings)\n            else:\n                field_settings = self.field_settings\n        return field_settings", "response": "Get the field settings from the global config."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef value_from_datadict(self, *args, **kwargs):\n        value = super(RichTextWidget, self).value_from_datadict(\n            *args, **kwargs)\n        if value is not None:\n            value = self.get_sanitizer()(value)\n        return value", "response": "Pass the submitted value through the sanitizer before returning it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the field sanitizer.", "response": "def get_sanitizer(self):\n        \"\"\"\n        Get the field sanitizer.\n\n        The priority is the first defined in the following order:\n        - A sanitizer provided to the widget.\n        - Profile (field settings) specific sanitizer, if defined in settings.\n        - Global sanitizer defined in settings.\n        - Simple no-op sanitizer which just returns the provided value.\n\n        \"\"\"\n        sanitizer = self.sanitizer\n\n        if not sanitizer:\n            default_sanitizer = settings.CONFIG.get(self.SANITIZER_KEY)\n            field_settings = getattr(self, 'field_settings', None)\n            if isinstance(field_settings, six.string_types):\n                profiles = settings.CONFIG.get(self.SANITIZER_PROFILES_KEY, {})\n                sanitizer = profiles.get(field_settings, default_sanitizer)\n            else:\n                sanitizer = default_sanitizer\n\n        if isinstance(sanitizer, six.string_types):\n            sanitizer = import_string(sanitizer)\n\n        return sanitizer or noop"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef heapreplace_max(heap, item):\n    returnitem = heap[0]    # raises appropriate IndexError if heap is empty\n    heap[0] = item\n    _siftup_max(heap, 0)\n    return returnitem", "response": "Maxheap version of a heappop followed by a heappush."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef heappush_max(heap, item):\n    heap.append(item)\n    _siftdown_max(heap, 0, len(heap) - 1)", "response": "Push item onto heap maintaining the heap invariant."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef heappushpop_max(heap, item):\n    if heap and heap[0] > item:\n        # if item >= heap[0], it will be popped immediately after pushed\n        item, heap[0] = heap[0], item\n        _siftup_max(heap, 0)\n    return item", "response": "Fast version of a heappush followed by a heappop."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_response(expected_responses):\n\n    def internal_decorator(function):\n        @wraps(function)\n        async def wrapper(*args, **kwargs):\n\n            response = await function(*args, **kwargs)\n\n            for expected_response in expected_responses:\n                if response.startswith(expected_response):\n                    return response\n\n            raise QRTCommandException(\n                \"Expected %s but got %s\" % (expected_responses, response)\n            )\n\n        return wrapper\n\n    return internal_decorator", "response": "Decorator to validate responses from QTM"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconnect to a specific couldonite site.", "response": "async def connect(\n    host,\n    port=22223,\n    version=\"1.19\",\n    on_event=None,\n    on_disconnect=None,\n    timeout=5,\n    loop=None,\n) -> QRTConnection:\n    \"\"\"Async function to connect to QTM\n\n    :param host: Address of the computer running QTM.\n    :param port: Port number to connect to, should be the port configured for little endian.\n    :param version: What version of the protocol to use, tested for 1.17 and above but could\n        work with lower versions as well.\n    :param on_disconnect: Function to be called when a disconnect from QTM occurs.\n    :param on_event: Function to be called when there's an event from QTM.\n    :param timeout: The default timeout time for calls to QTM.\n    :param loop: Alternative event loop, will use asyncio default if None.\n\n    :rtype: A :class:`.QRTConnection`\n    \"\"\"\n    loop = loop or asyncio.get_event_loop()\n\n    try:\n        _, protocol = await loop.create_connection(\n            lambda: QTMProtocol(\n                loop=loop, on_event=on_event, on_disconnect=on_disconnect\n            ),\n            host,\n            port,\n        )\n    except (ConnectionRefusedError, TimeoutError, OSError) as exception:\n        LOG.error(exception)\n        return None\n\n    try:\n        await protocol.set_version(version)\n    except QRTCommandException as exception:\n        LOG.error(Exception)\n        return None\n    except TypeError as exception:  # TODO: fix test requiring this (test_connect_set_version)\n        LOG.error(exception)\n        return None\n\n    return QRTConnection(protocol, timeout=timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def qtm_version(self):\n        return await asyncio.wait_for(\n            self._protocol.send_command(\"qtmversion\"), timeout=self._timeout\n        )", "response": "Get the QTM version."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def byte_order(self):\n        return await asyncio.wait_for(\n            self._protocol.send_command(\"byteorder\"), timeout=self._timeout\n        )", "response": "Get the byte order used when communicating with the ISO."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the latest state of QTM.", "response": "async def get_state(self):\n        \"\"\"Get the latest state change of QTM. If the :func:`~qtm.connect` on_event\n        callback was set the callback will be called as well.\n\n        :rtype: A :class:`qtm.QRTEvent`\n        \"\"\"\n        await self._protocol.send_command(\"getstate\", callback=False)\n        return await self._protocol.await_event()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwaiting for an event from QTM.", "response": "async def await_event(self, event=None, timeout=30):\n        \"\"\"Wait for an event from QTM.\n\n        :param event: A :class:`qtm.QRTEvent`\n            to wait for a specific event. Otherwise wait for any event.\n\n        :param timeout: Max time to wait for event.\n\n        :rtype: A :class:`qtm.QRTEvent`\n        \"\"\"\n        return await self._protocol.await_event(event, timeout=timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def get_parameters(self, parameters=None):\n\n        if parameters is None:\n            parameters = [\"all\"]\n        else:\n            for parameter in parameters:\n                if not parameter in [\n                    \"all\",\n                    \"general\",\n                    \"3d\",\n                    \"6d\",\n                    \"analog\",\n                    \"force\",\n                    \"gazevector\",\n                    \"image\",\n                    \"skeleton\",\n                    \"skeleton:global\",\n                ]:\n                    raise QRTCommandException(\"%s is not a valid parameter\" % parameter)\n\n        cmd = \"getparameters %s\" % \" \".join(parameters)\n        return await asyncio.wait_for(\n            self._protocol.send_command(cmd), timeout=self._timeout\n        )", "response": "Get the settings for the requested component of QTM."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def get_current_frame(self, components=None) -> QRTPacket:\n\n        if components is None:\n            components = [\"all\"]\n        else:\n            _validate_components(components)\n\n        cmd = \"getcurrentframe %s\" % \" \".join(components)\n        return await asyncio.wait_for(\n            self._protocol.send_command(cmd), timeout=self._timeout\n        )", "response": "Get the current frame from QTM."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def stream_frames(self, frames=\"allframes\", components=None, on_packet=None):\n\n        if components is None:\n            components = [\"all\"]\n        else:\n            _validate_components(components)\n\n        self._protocol.set_on_packet(on_packet)\n\n        cmd = \"streamframes %s %s\" % (frames, \" \".join(components))\n        return await asyncio.wait_for(\n            self._protocol.send_command(cmd), timeout=self._timeout\n        )", "response": "Stream measured frames from QTM until the connection is closed."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes control of the current user.", "response": "async def take_control(self, password):\n        \"\"\"Take control of QTM.\n\n        :param password: Password as entered in QTM.\n        \"\"\"\n        cmd = \"takecontrol %s\" % password\n        return await asyncio.wait_for(\n            self._protocol.send_command(cmd), timeout=self._timeout\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreleases control of the current user s system.", "response": "async def release_control(self):\n        \"\"\"Release control of QTM.\n        \"\"\"\n\n        cmd = \"releasecontrol\"\n        return await asyncio.wait_for(\n            self._protocol.send_command(cmd), timeout=self._timeout\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting RT from file.", "response": "async def start(self, rtfromfile=False):\n        \"\"\"Start RT from file. You need to be in control of QTM to be able to do this.\n        \"\"\"\n        cmd = \"start\" + (\" rtfromfile\" if rtfromfile else \"\")\n        return await asyncio.wait_for(\n            self._protocol.send_command(cmd), timeout=self._timeout\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads a measurement. :param filename: Path to measurement you want to load.", "response": "async def load(self, filename):\n        \"\"\"Load a measurement.\n\n        :param filename: Path to measurement you want to load.\n        \"\"\"\n        cmd = \"load %s\" % filename\n        return await asyncio.wait_for(\n            self._protocol.send_command(cmd), timeout=self._timeout\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def save(self, filename, overwrite=False):\n        cmd = \"save %s%s\" % (filename, \" overwrite\" if overwrite else \"\")\n        return await asyncio.wait_for(\n            self._protocol.send_command(cmd), timeout=self._timeout\n        )", "response": "Save a measurement.\n\n        :param filename: Filename you wish to save as.\n        :param overwrite: If QTM should overwrite existing measurement."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload a project. :param project_path: Path to project you want to load.", "response": "async def load_project(self, project_path):\n        \"\"\"Load a project.\n\n        :param project_path: Path to project you want to load.\n        \"\"\"\n        cmd = \"loadproject %s\" % project_path\n        return await asyncio.wait_for(\n            self._protocol.send_command(cmd), timeout=self._timeout\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets event in QTM.", "response": "async def set_qtm_event(self, event=None):\n        \"\"\"Set event in QTM.\"\"\"\n        cmd = \"event%s\" % (\"\" if event is None else \" \" + event)\n        return await asyncio.wait_for(\n            self._protocol.send_command(cmd), timeout=self._timeout\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend an XML document to the QTM RT.", "response": "async def send_xml(self, xml):\n        \"\"\"Used to update QTM settings, see QTM RT protocol for more information.\n\n        :param xml: XML document as a str. See QTM RT Documentation for details.\n        \"\"\"\n        return await asyncio.wait_for(\n            self._protocol.send_command(xml, command_type=QRTPacketType.PacketXML),\n            timeout=self._timeout,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef data_received(self, data):\n        self._received_data += data\n        h_size = RTheader.size\n\n        data = self._received_data\n        size, type_ = RTheader.unpack_from(data, 0)\n\n        while len(data) >= size:\n            self._parse_received(data[h_size:size], type_)\n            data = data[size:]\n\n            if len(data) < h_size:\n                break\n\n            size, type_ = RTheader.unpack_from(data, 0)\n\n        self._received_data = data", "response": "Parse the received data from QTM and route accordingly"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a single analog data channel.", "response": "def get_analog_single(\n        self, component_info=None, data=None, component_position=None\n    ):\n        \"\"\"Get a single analog data channel.\"\"\"\n        components = []\n        append_components = components.append\n        for _ in range(component_info.device_count):\n            component_position, device = QRTPacket._get_exact(\n                RTAnalogDeviceSingle, data, component_position\n            )\n\n            RTAnalogDeviceSamples.format = struct.Struct(\n                RTAnalogDeviceSamples.format_str % device.channel_count\n            )\n            component_position, sample = QRTPacket._get_tuple(\n                RTAnalogDeviceSamples, data, component_position\n            )\n            append_components((device, sample))\n        return components"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_force_single(self, component_info=None, data=None, component_position=None):\n        components = []\n        append_components = components.append\n        for _ in range(component_info.plate_count):\n            component_position, plate = QRTPacket._get_exact(\n                RTForcePlateSingle, data, component_position\n            )\n            component_position, force = QRTPacket._get_exact(\n                RTForce, data, component_position\n            )\n            append_components((plate, force))\n        return components", "response": "Get a single force data channel."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_6d_euler(self, component_info=None, data=None, component_position=None):\n        components = []\n        append_components = components.append\n        for _ in range(component_info.body_count):\n            component_position, position = QRTPacket._get_exact(\n                RT6DBodyPosition, data, component_position\n            )\n            component_position, euler = QRTPacket._get_exact(\n                RT6DBodyEuler, data, component_position\n            )\n            append_components((position, euler))\n        return components", "response": "Get 6D data with euler rotations."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_3d_markers_residual(\n        self, component_info=None, data=None, component_position=None\n    ):\n        \"\"\"Get 3D markers with residual.\"\"\"\n        return self._get_3d_markers(\n            RT3DMarkerPositionResidual, component_info, data, component_position\n        )", "response": "Get 3D markers with residual."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting 3D markers without label.", "response": "def get_3d_markers_no_label(\n        self, component_info=None, data=None, component_position=None\n    ):\n        \"\"\"Get 3D markers without label.\"\"\"\n        return self._get_3d_markers(\n            RT3DMarkerPositionNoLabel, component_info, data, component_position\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget 3D markers without label with residual.", "response": "def get_3d_markers_no_label_residual(\n        self, component_info=None, data=None, component_position=None\n    ):\n        \"\"\"Get 3D markers without label with residual.\"\"\"\n        return self._get_3d_markers(\n            RT3DMarkerPositionNoLabelResidual, component_info, data, component_position\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_2d_markers(\n        self, component_info=None, data=None, component_position=None, index=None\n    ):\n        \"\"\"Get 2D markers.\n\n        :param index: Specify which camera to get 2D from, will be returned as\n                      first entry in the returned array.\n        \"\"\"\n        return self._get_2d_markers(\n            data, component_info, component_position, index=index\n        )", "response": "Get 2D markers.\n\n        :param index: Specify which camera to get 2D from, will be returned as\n                      first entry in the returned array."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_2d_markers_linearized(\n        self, component_info=None, data=None, component_position=None, index=None\n    ):\n        \"\"\"Get 2D linearized markers.\n\n        :param index: Specify which camera to get 2D from, will be returned as\n                      first entry in the returned array.\n        \"\"\"\n\n        return self._get_2d_markers(\n            data, component_info, component_position, index=index\n        )", "response": "Get 2D linearized markers."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_skeletons(self, component_info=None, data=None, component_position=None):\n\n        components = []\n        append_components = components.append\n        for _ in range(component_info.skeleton_count):\n            component_position, info = QRTPacket._get_exact(\n                RTSegmentCount, data, component_position\n            )\n\n            segments = []\n            for __ in range(info.segment_count):\n                component_position, segment = QRTPacket._get_exact(\n                    RTSegmentId, data, component_position\n                )\n                component_position, position = QRTPacket._get_exact(\n                    RTSegmentPosition, data, component_position\n                )\n                component_position, rotation = QRTPacket._get_exact(\n                    RTSegmentRotation, data, component_position\n                )\n\n                segments.append((segment.id, position, rotation))\n            append_components(segments)\n        return components", "response": "Get skeletons from the component info and data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def await_event(self, event=None, timeout=None):\n        if self.event_future is not None:\n            raise Exception(\"Can't wait on multiple events!\")\n\n        result = await asyncio.wait_for(self._wait_loop(event), timeout)\n        return result", "response": "Wait for an event or timeout."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_command(\n        self, command, callback=True, command_type=QRTPacketType.PacketCommand\n    ):\n        \"\"\" Sends commands to QTM \"\"\"\n        if self.transport is not None:\n            cmd_length = len(command)\n            LOG.debug(\"S: %s\", command)\n            self.transport.write(\n                struct.pack(\n                    RTCommand % cmd_length,\n                    RTheader.size + cmd_length + 1,\n                    command_type.value,\n                    command.encode(),\n                    b\"\\0\",\n                )\n            )\n\n            future = self.loop.create_future()\n            if callback:\n                self.request_queue.append(future)\n            else:\n                future.set_result(None)\n            return future\n\n        raise QRTCommandException(\"Not connected!\")", "response": "Sends a command to the QTM."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def reboot(ip_address):\n    _, protocol = await asyncio.get_event_loop().create_datagram_endpoint(\n        QRebootProtocol,\n        local_addr=(ip_address, 0),\n        allow_broadcast=True,\n        reuse_address=True,\n    )\n\n    LOG.info(\"Sending reboot on %s\", ip_address)\n    protocol.send_reboot()", "response": "async function to reboot QTM cameras"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_packet(packet):\n    print(\"Framenumber: {}\".format(packet.framenumber))\n    header, markers = packet.get_3d_markers()\n    print(\"Component info: {}\".format(header))\n    for marker in markers:\n        print(\"\\t\", marker)", "response": "Callback function that is called every time a data packet arrives from QTM"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def setup():\n    connection = await qtm.connect(\"127.0.0.1\")\n    if connection is None:\n        return\n\n    await connection.stream_frames(components=[\"3d\"], on_packet=on_packet)", "response": "Setup the connection to the server"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a datagram from QTM and send it to the receiver.", "response": "def datagram_received(self, datagram, address):\n        \"\"\" Parse response from QTM instances \"\"\"\n        size, _ = RTheader.unpack_from(datagram, 0)\n        info, = struct.unpack_from(\"{0}s\".format(size - 3 - 8), datagram, RTheader.size)\n        base_port, = QRTDiscoveryBasePort.unpack_from(datagram, size - 2)\n\n        if self.receiver is not None:\n            self.receiver(QRTDiscoveryResponse(info, address[0], base_port))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_discovery_packet(self):\n        if self.port is None:\n            return\n\n        self.transport.sendto(\n            QRTDiscoveryP1.pack(\n                QRTDiscoveryPacketSize, QRTPacketType.PacketDiscover.value\n            )\n            + QRTDiscoveryP2.pack(self.port),\n            (\"<broadcast>\", 22226),\n        )", "response": "Send discovery packet for QTM to respond to"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def choose_qtm_instance(interface):\n    instances = {}\n    print(\"Available QTM instances:\")\n    async for i, qtm_instance in AsyncEnumerate(qtm.Discover(interface), start=1):\n        instances[i] = qtm_instance\n        print(\"{} - {}\".format(i, qtm_instance.info))\n\n    try:\n\n        choice = int(input(\"Connect to: \"))\n\n        if choice not in instances:\n            raise ValueError\n\n    except ValueError:\n        LOG.error(\"Invalid choice\")\n        return None\n\n    return instances[choice].host", "response": "List running QTM instances asks for input and return chosen QTM"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def package_receiver(queue):\n    LOG.info(\"Entering package_receiver\")\n    while True:\n        packet = await queue.get()\n        if packet is None:\n            break\n\n        LOG.info(\"Framenumber %s\", packet.framenumber)\n        header, cameras = packet.get_2d_markers()\n        LOG.info(\"Component info: %s\", header)\n\n        for i, camera in enumerate(cameras, 1):\n            LOG.info(\"Camera %d\", i)\n            for marker in camera:\n                LOG.info(\"\\t%s\", marker)\n\n    LOG.info(\"Exiting package_receiver\")", "response": "Asynchronous function that processes queue until None is posted in queue"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def setup():\n\n    connection = await qtm.connect(\"127.0.0.1\")\n\n    if connection is None:\n        return -1\n\n    async with qtm.TakeControl(connection, \"password\"):\n\n        state = await connection.get_state()\n        if state != qtm.QRTEvent.EventConnected:\n            await connection.new()\n            try:\n                await connection.await_event(qtm.QRTEvent.EventConnected, timeout=10)\n            except asyncio.TimeoutError:\n                LOG.error(\"Failed to start new measurement\")\n                return -1\n\n        queue = asyncio.Queue()\n\n        receiver_future = asyncio.ensure_future(package_receiver(queue))\n\n        await connection.stream_frames(components=[\"2d\"], on_packet=queue.put_nowait)\n\n        asyncio.ensure_future(shutdown(30, connection, receiver_future, queue))", "response": "main function for the sequence of new items"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_body_index(xml_string):\n    xml = ET.fromstring(xml_string)\n\n    body_to_index = {}\n    for index, body in enumerate(xml.findall(\"*/Body/Name\")):\n        body_to_index[body.text.strip()] = index\n\n    return body_to_index", "response": "Extract a name to index dictionary from 6dof settings xml"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntry to find executable in the directories listed in path.", "response": "def find_executable(executable, path=None):\n    '''Try to find 'executable' in the directories listed in 'path' (a\n    string listing directories separated by 'os.pathsep'; defaults to\n    os.environ['PATH']).'''\n    if path is None:\n        path = os.environ['PATH']\n    paths = path.split(os.pathsep)\n    extlist = ['']\n    if os.name == 'os2':\n        ext = os.path.splitext(executable)\n        # executable files on OS/2 can have an arbitrary extension, but\n        # .exe is automatically appended if no dot is present in the name\n        if not ext:\n            executable = executable + \".exe\"\n    elif sys.platform == 'win32':\n        pathext = os.environ['PATHEXT'].lower().split(os.pathsep)\n        ext = os.path.splitext(executable)\n        if ext not in pathext:\n            extlist = pathext\n    for ext in extlist:\n        execname = executable + ext\n        if os.path.isfile(execname):\n            return execname\n        else:\n            for pth in paths:\n                fil = os.path.join(pth, execname)\n                if os.path.isfile(fil):\n                    return fil\n            break\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn true if substring is in string for files in specified path", "response": "def find_x(path1):\n    '''Return true if substring is in string for files\n    in specified path'''\n    libs = os.listdir(path1)\n    for lib_dir in libs:\n        if \"doublefann\" in lib_dir:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_swig():\n    '''Run SWIG with specified parameters'''\n    print(\"Looking for FANN libs...\")\n    find_fann()\n    print(\"running SWIG...\")\n    swig_bin = find_swig()\n    swig_cmd = [swig_bin, '-c++', '-python', 'fann2/fann2.i']\n    subprocess.Popen(swig_cmd).wait()", "response": "Run SWIG with specified parameters"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(ctx, job):\n\n    def get_experiment():\n        try:\n            response = PolyaxonClient().experiment.get_experiment(user, project_name, _experiment)\n            cache.cache(config_manager=ExperimentManager, response=response)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not load experiment `{}` info.'.format(_experiment))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n\n        get_experiment_details(response)\n\n    def get_experiment_job():\n        try:\n            response = PolyaxonClient().experiment_job.get_job(user,\n                                                               project_name,\n                                                               _experiment,\n                                                               _job)\n            cache.cache(config_manager=ExperimentJobManager, response=response)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not get job `{}`.'.format(_job))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n\n        if response.resources:\n            get_resources(response.resources.to_dict(), header=\"Job resources:\")\n\n        response = Printer.add_status_color(response.to_light_dict(\n            humanize_values=True,\n            exclude_attrs=['uuid', 'definition', 'experiment', 'unique_name', 'resources']\n        ))\n        Printer.print_header(\"Job info:\")\n        dict_tabulate(response)\n\n    user, project_name, _experiment = get_project_experiment_or_local(ctx.obj.get('project'),\n                                                                      ctx.obj.get('experiment'))\n\n    if job:\n        _job = get_experiment_job_or_local(job)\n        get_experiment_job()\n    else:\n        get_experiment()", "response": "Get an entire sequence of items."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(ctx):\n    user, project_name, _experiment = get_project_experiment_or_local(ctx.obj.get('project'),\n                                                                      ctx.obj.get('experiment'))\n    if not click.confirm(\"Are sure you want to delete experiment `{}`\".format(_experiment)):\n        click.echo('Existing without deleting experiment.')\n        sys.exit(1)\n\n    try:\n        response = PolyaxonClient().experiment.delete_experiment(\n            user, project_name, _experiment)\n        # Purge caching\n        ExperimentManager.purge()\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not delete experiment `{}`.'.format(_experiment))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    if response.status_code == 204:\n        Printer.print_success(\"Experiment `{}` was delete successfully\".format(_experiment))", "response": "Delete experiment.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Example:\n\n    \\b\n    ```bash\n    $ polyaxon experiment delete\n    ```"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating an existing resource in the project.", "response": "def update(ctx, name, description, tags):\n    \"\"\"Update experiment.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Examples:\n\n    \\b\n    ```bash\n    $ polyaxon experiment -xp 2 update --description=\"new description for my experiments\"\n    ```\n\n    \\b\n    ```bash\n    $ polyaxon experiment -xp 2 update --tags=\"foo, bar\" --name=\"unique-name\"\n    ```\n    \"\"\"\n    user, project_name, _experiment = get_project_experiment_or_local(ctx.obj.get('project'),\n                                                                      ctx.obj.get('experiment'))\n    update_dict = {}\n\n    if name:\n        update_dict['name'] = name\n\n    if description:\n        update_dict['description'] = description\n\n    tags = validate_tags(tags)\n    if tags:\n        update_dict['tags'] = tags\n\n    if not update_dict:\n        Printer.print_warning('No argument was provided to update the experiment.')\n        sys.exit(0)\n\n    try:\n        response = PolyaxonClient().experiment.update_experiment(\n            user, project_name, _experiment, update_dict)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not update experiment `{}`.'.format(_experiment))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    Printer.print_success(\"Experiment updated.\")\n    get_experiment_details(response)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstopping experiment. Uses [Caching](/references/polyaxon-cli/#caching) Examples: \\b ```bash $ polyaxon experiment stop ``` \\b ```bash $ polyaxon experiment -xp 2 stop ```", "response": "def stop(ctx, yes):\n    \"\"\"Stop experiment.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Examples:\n\n    \\b\n    ```bash\n    $ polyaxon experiment stop\n    ```\n\n    \\b\n    ```bash\n    $ polyaxon experiment -xp 2 stop\n    ```\n    \"\"\"\n    user, project_name, _experiment = get_project_experiment_or_local(ctx.obj.get('project'),\n                                                                      ctx.obj.get('experiment'))\n    if not yes and not click.confirm(\"Are sure you want to stop \"\n                                     \"experiment `{}`\".format(_experiment)):\n        click.echo('Existing without stopping experiment.')\n        sys.exit(0)\n\n    try:\n        PolyaxonClient().experiment.stop(user, project_name, _experiment)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not stop experiment `{}`.'.format(_experiment))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    Printer.print_success(\"Experiment is being stopped.\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrestart the current node.", "response": "def restart(ctx, copy, file, u):  # pylint:disable=redefined-builtin\n    \"\"\"Restart experiment.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Examples:\n\n    \\b\n    ```bash\n    $ polyaxon experiment --experiment=1 restart\n    ```\n    \"\"\"\n    config = None\n    update_code = None\n    if file:\n        config = rhea.read(file)\n\n    # Check if we need to upload\n    if u:\n        ctx.invoke(upload, sync=False)\n        update_code = True\n\n    user, project_name, _experiment = get_project_experiment_or_local(ctx.obj.get('project'),\n                                                                      ctx.obj.get('experiment'))\n    try:\n        if copy:\n            response = PolyaxonClient().experiment.copy(\n                user, project_name, _experiment, config=config, update_code=update_code)\n            Printer.print_success('Experiment was copied with id {}'.format(response.id))\n        else:\n            response = PolyaxonClient().experiment.restart(\n                user, project_name, _experiment, config=config, update_code=update_code)\n            Printer.print_success('Experiment was restarted with id {}'.format(response.id))\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not restart experiment `{}`.'.format(_experiment))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the statuses of the specified experiment or job.", "response": "def statuses(ctx, job, page):\n    \"\"\"Get experiment or experiment job statuses.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Examples getting experiment statuses:\n\n    \\b\n    ```bash\n    $ polyaxon experiment statuses\n    ```\n\n    \\b\n    ```bash\n    $ polyaxon experiment -xp 1 statuses\n    ```\n\n    Examples getting experiment job statuses:\n\n    \\b\n    ```bash\n    $ polyaxon experiment statuses -j 3\n    ```\n\n    \\b\n    ```bash\n    $ polyaxon experiment -xp 1 statuses --job 1\n    ```\n    \"\"\"\n\n    def get_experiment_statuses():\n        try:\n            response = PolyaxonClient().experiment.get_statuses(\n                user, project_name, _experiment, page=page)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could get status for experiment `{}`.'.format(_experiment))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n\n        meta = get_meta_response(response)\n        if meta:\n            Printer.print_header('Statuses for experiment `{}`.'.format(_experiment))\n            Printer.print_header('Navigation:')\n            dict_tabulate(meta)\n        else:\n            Printer.print_header('No statuses found for experiment `{}`.'.format(_experiment))\n\n        objects = list_dicts_to_tabulate(\n            [Printer.add_status_color(o.to_light_dict(humanize_values=True), status_key='status')\n             for o in response['results']])\n        if objects:\n            Printer.print_header(\"Statuses:\")\n            objects.pop('experiment', None)\n            dict_tabulate(objects, is_list_dict=True)\n\n    def get_experiment_job_statuses():\n        try:\n            response = PolyaxonClient().experiment_job.get_statuses(user,\n                                                                    project_name,\n                                                                    _experiment,\n                                                                    _job,\n                                                                    page=page)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not get status for job `{}`.'.format(job))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n\n        meta = get_meta_response(response)\n        if meta:\n            Printer.print_header('Statuses for Job `{}`.'.format(_job))\n            Printer.print_header('Navigation:')\n            dict_tabulate(meta)\n        else:\n            Printer.print_header('No statuses found for job `{}`.'.format(_job))\n\n        objects = list_dicts_to_tabulate(\n            [Printer.add_status_color(o.to_light_dict(humanize_values=True), status_key='status')\n             for o in response['results']])\n        if objects:\n            Printer.print_header(\"Statuses:\")\n            objects.pop('job', None)\n            dict_tabulate(objects, is_list_dict=True)\n\n    page = page or 1\n\n    user, project_name, _experiment = get_project_experiment_or_local(ctx.obj.get('project'),\n                                                                      ctx.obj.get('experiment'))\n\n    if job:\n        _job = get_experiment_job_or_local(job)\n        get_experiment_job_statuses()\n    else:\n        get_experiment_statuses()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resources(ctx, job, gpu):\n\n    def get_experiment_resources():\n        try:\n            message_handler = Printer.gpu_resources if gpu else Printer.resources\n            PolyaxonClient().experiment.resources(\n                user, project_name, _experiment, message_handler=message_handler)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not get resources for experiment `{}`.'.format(_experiment))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n\n    def get_experiment_job_resources():\n        try:\n            message_handler = Printer.gpu_resources if gpu else Printer.resources\n            PolyaxonClient().experiment_job.resources(user,\n                                                      project_name,\n                                                      _experiment,\n                                                      _job,\n                                                      message_handler=message_handler)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not get resources for job `{}`.'.format(_job))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n\n    user, project_name, _experiment = get_project_experiment_or_local(ctx.obj.get('project'),\n                                                                      ctx.obj.get('experiment'))\n\n    if job:\n        _job = get_experiment_job_or_local(job)\n        get_experiment_job_resources()\n    else:\n        get_experiment_resources()", "response": "Get all resources for a specific experiment or job."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget logs for a specific experiment or job.", "response": "def logs(ctx, job, past, follow, hide_time):\n    \"\"\"Get experiment or experiment job logs.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Examples for getting experiment logs:\n\n    \\b\n    ```bash\n    $ polyaxon experiment logs\n    ```\n\n    \\b\n    ```bash\n    $ polyaxon experiment -xp 10 -p mnist logs\n    ```\n\n    Examples for getting experiment job logs:\n\n    \\b\n    ```bash\n    $ polyaxon experiment -xp 1 -j 1 logs\n    ```\n    \"\"\"\n\n    def get_experiment_logs():\n        if past:\n            try:\n                response = PolyaxonClient().experiment.logs(\n                    user, project_name, _experiment, stream=False)\n                get_logs_handler(handle_job_info=True,\n                                 show_timestamp=not hide_time,\n                                 stream=False)(response.content.decode().split('\\n'))\n                print()\n\n                if not follow:\n                    return\n            except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n                if not follow:\n                    Printer.print_error(\n                        'Could not get logs for experiment `{}`.'.format(_experiment))\n                    Printer.print_error(\n                        'Error message `{}`.'.format(e))\n                    sys.exit(1)\n\n        try:\n            PolyaxonClient().experiment.logs(\n                user,\n                project_name,\n                _experiment,\n                message_handler=get_logs_handler(handle_job_info=True,\n                                                 show_timestamp=not hide_time))\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not get logs for experiment `{}`.'.format(_experiment))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n\n    def get_experiment_job_logs():\n        if past:\n            try:\n                response = PolyaxonClient().experiment_job.logs(\n                    user,\n                    project_name,\n                    _experiment,\n                    _job,\n                    stream=False)\n                get_logs_handler(handle_job_info=True,\n                                 show_timestamp=not hide_time,\n                                 stream=False)(response.content.decode().split('\\n'))\n                print()\n\n                if not follow:\n                    return\n            except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n                if not follow:\n                    Printer.print_error(\n                        'Could not get logs for experiment `{}`.'.format(_experiment))\n                    Printer.print_error(\n                        'Error message `{}`.'.format(e))\n                    sys.exit(1)\n\n        try:\n            PolyaxonClient().experiment_job.logs(\n                user,\n                project_name,\n                _experiment,\n                _job,\n                message_handler=get_logs_handler(handle_job_info=True,\n                                                 show_timestamp=not hide_time))\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not get logs for job `{}`.'.format(_job))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n\n    user, project_name, _experiment = get_project_experiment_or_local(ctx.obj.get('project'),\n                                                                      ctx.obj.get('experiment'))\n\n    if job:\n        _job = get_experiment_job_or_local(job)\n        get_experiment_job_logs()\n    else:\n        get_experiment_logs()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef upload(sync=True):  # pylint:disable=assign-to-new-keyword\n    project = ProjectManager.get_config_or_raise()\n    files = IgnoreManager.get_unignored_file_paths()\n    try:\n        with create_tarfile(files, project.name) as file_path:\n            with get_files_in_current_directory('repo', [file_path]) as (files, files_size):\n                try:\n                    PolyaxonClient().project.upload_repo(project.user,\n                                                         project.name,\n                                                         files,\n                                                         files_size,\n                                                         sync=sync)\n                except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n                    Printer.print_error(\n                        'Could not upload code for project `{}`.'.format(project.name))\n                    Printer.print_error('Error message `{}`.'.format(e))\n                    Printer.print_error(\n                        'Check the project exists, '\n                        'and that you have access rights, '\n                        'this could happen as well when uploading large files.'\n                        'If you are running a notebook and mounting the code to the notebook, '\n                        'you should stop it before uploading.')\n                    sys.exit(1)\n                Printer.print_success('Files uploaded.')\n    except Exception as e:\n        Printer.print_error(\"Could not upload the file.\")\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)", "response": "Upload code of the current directory while respecting the. polyaxonignore file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cluster(node):\n    cluster_client = PolyaxonClient().cluster\n    if node:\n        try:\n            node_config = cluster_client.get_node(node)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not load node `{}` info.'.format(node))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n        get_node_info(node_config)\n    else:\n        try:\n            cluster_config = cluster_client.get_cluster()\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not load cluster info.')\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n        get_cluster_info(cluster_config)", "response": "Get cluster and nodes info."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clean_outputs(fn):\n\n    @wraps(fn)\n    def clean_outputs_wrapper(*args, **kwargs):\n        try:\n            return fn(*args, **kwargs)\n        except SystemExit as e:\n            sys.stdout = StringIO()\n            sys.exit(e.code)  # make sure we still exit with the proper code\n        except Exception as e:\n            sys.stdout = StringIO()\n            raise e\n\n    return clean_outputs_wrapper", "response": "Decorator for CLI with Sentry client handling."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(ctx):\n    user, project_name, _job = get_job_or_local(ctx.obj.get('project'), ctx.obj.get('job'))\n    try:\n        response = PolyaxonClient().job.get_job(user, project_name, _job)\n        cache.cache(config_manager=JobManager, response=response)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not get job `{}`.'.format(_job))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    get_job_details(response)", "response": "Get a single job."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(ctx):\n    user, project_name, _job = get_job_or_local(ctx.obj.get('project'), ctx.obj.get('job'))\n    if not click.confirm(\"Are sure you want to delete job `{}`\".format(_job)):\n        click.echo('Existing without deleting job.')\n        sys.exit(1)\n\n    try:\n        response = PolyaxonClient().job.delete_job(\n            user, project_name, _job)\n        # Purge caching\n        JobManager.purge()\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not delete job `{}`.'.format(_job))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    if response.status_code == 204:\n        Printer.print_success(\"Job `{}` was delete successfully\".format(_job))", "response": "Delete job.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Example:\n\n    \\b\n    ```bash\n    $ polyaxon job delete\n    ```"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating job. Uses [Caching](/references/polyaxon-cli/#caching) Example: \\b ```bash $ polyaxon job -j 2 update --description=\"new description for my job\" ```", "response": "def update(ctx, name, description, tags):\n    \"\"\"Update job.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Example:\n\n    \\b\n    ```bash\n    $ polyaxon job -j 2 update --description=\"new description for my job\"\n    ```\n    \"\"\"\n    user, project_name, _job = get_job_or_local(ctx.obj.get('project'), ctx.obj.get('job'))\n    update_dict = {}\n\n    if name:\n        update_dict['name'] = name\n\n    if description:\n        update_dict['description'] = description\n\n    tags = validate_tags(tags)\n    if tags:\n        update_dict['tags'] = tags\n\n    if not update_dict:\n        Printer.print_warning('No argument was provided to update the job.')\n        sys.exit(0)\n\n    try:\n        response = PolyaxonClient().job.update_job(\n            user, project_name, _job, update_dict)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not update job  `{}`.'.format(_job))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    Printer.print_success(\"Job updated.\")\n    get_job_details(response)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop(ctx, yes):\n    user, project_name, _job = get_job_or_local(ctx.obj.get('project'), ctx.obj.get('job'))\n    if not yes and not click.confirm(\"Are sure you want to stop \"\n                                     \"job `{}`\".format(_job)):\n        click.echo('Existing without stopping job.')\n        sys.exit(0)\n\n    try:\n        PolyaxonClient().job.stop(user, project_name, _job)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not stop job `{}`.'.format(_job))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    Printer.print_success(\"Job is being stopped.\")", "response": "Stop a running job."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrestarts the current node.", "response": "def restart(ctx, copy, file, u):  # pylint:disable=redefined-builtin\n    \"\"\"Restart job.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Examples:\n\n    \\b\n    ```bash\n    $ polyaxon job --job=1 restart\n    ```\n    \"\"\"\n    config = None\n    update_code = None\n    if file:\n        config = rhea.read(file)\n\n    # Check if we need to upload\n    if u:\n        ctx.invoke(upload, sync=False)\n        update_code = True\n\n    user, project_name, _job = get_job_or_local(ctx.obj.get('project'), ctx.obj.get('job'))\n    try:\n        if copy:\n            response = PolyaxonClient().job.copy(\n                user, project_name, _job, config=config, update_code=update_code)\n        else:\n            response = PolyaxonClient().job.restart(\n                user, project_name, _job, config=config, update_code=update_code)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not restart job `{}`.'.format(_job))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    get_job_details(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef statuses(ctx, page):\n    user, project_name, _job = get_job_or_local(ctx.obj.get('project'), ctx.obj.get('job'))\n    page = page or 1\n    try:\n        response = PolyaxonClient().job.get_statuses(user, project_name, _job, page=page)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not get status for job `{}`.'.format(_job))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    meta = get_meta_response(response)\n    if meta:\n        Printer.print_header('Statuses for Job `{}`.'.format(_job))\n        Printer.print_header('Navigation:')\n        dict_tabulate(meta)\n    else:\n        Printer.print_header('No statuses found for job `{}`.'.format(_job))\n\n    objects = list_dicts_to_tabulate(\n        [Printer.add_status_color(o.to_light_dict(humanize_values=True), status_key='status')\n         for o in response['results']])\n    if objects:\n        Printer.print_header(\"Statuses:\")\n        objects.pop('job', None)\n        dict_tabulate(objects, is_list_dict=True)", "response": "Get job statuses.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Examples:\n\n    \\b\n    ```bash\n    $ polyaxon job -j 2 statuses\n    ```"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resources(ctx, gpu):\n    user, project_name, _job = get_job_or_local(ctx.obj.get('project'), ctx.obj.get('job'))\n    try:\n        message_handler = Printer.gpu_resources if gpu else Printer.resources\n        PolyaxonClient().job.resources(user,\n                                       project_name,\n                                       _job,\n                                       message_handler=message_handler)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not get resources for job `{}`.'.format(_job))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)", "response": "Get job resources.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Examples:\n\n    \\b\n    ```bash\n    $ polyaxon job -j 2 resources\n    ```\n\n    For GPU resources\n\n    \\b\n    ```bash\n    $ polyaxon job -j 2 resources --gpu\n    ```"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets job logs. Uses [Caching](/references/polyaxon-cli/#caching) Examples: \\b ```bash $ polyaxon job -j 2 logs ``` \\b ```bash $ polyaxon job logs ```", "response": "def logs(ctx, past, follow, hide_time):\n    \"\"\"Get job logs.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Examples:\n\n    \\b\n    ```bash\n    $ polyaxon job -j 2 logs\n    ```\n\n    \\b\n    ```bash\n    $ polyaxon job logs\n    ```\n    \"\"\"\n    user, project_name, _job = get_job_or_local(ctx.obj.get('project'), ctx.obj.get('job'))\n\n    if past:\n        try:\n            response = PolyaxonClient().job.logs(\n                user, project_name, _job, stream=False)\n            get_logs_handler(handle_job_info=False,\n                             show_timestamp=not hide_time,\n                             stream=False)(response.content.decode().split('\\n'))\n            print()\n\n            if not follow:\n                return\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            if not follow:\n                Printer.print_error('Could not get logs for job `{}`.'.format(_job))\n                Printer.print_error('Error message `{}`.'.format(e))\n                sys.exit(1)\n\n    try:\n        PolyaxonClient().job.logs(\n            user,\n            project_name,\n            _job,\n            message_handler=get_logs_handler(handle_job_info=False, show_timestamp=not hide_time))\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not get logs for job `{}`.'.format(_job))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef outputs(ctx):\n    user, project_name, _job = get_job_or_local(ctx.obj.get('project'), ctx.obj.get('job'))\n    try:\n        PolyaxonClient().job.download_outputs(user, project_name, _job)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not download outputs for job `{}`.'.format(_job))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n    Printer.print_success('Files downloaded.')", "response": "Download outputs for a specific job."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pprint(value):\n    click.echo(\n        json.dumps(value,\n                   sort_keys=True,\n                   indent=4,\n                   separators=(',', ': ')))", "response": "Prints as formatted JSON"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef whoami():\n    try:\n        user = PolyaxonClient().auth.get_user()\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not load user info.')\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n    click.echo(\"\\nUsername: {username}, Email: {email}\\n\".format(**user.to_dict()))", "response": "Show current logged Polyaxon user."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncommands for build jobs.", "response": "def build(ctx, project, build):  # pylint:disable=redefined-outer-name\n    \"\"\"Commands for build jobs.\"\"\"\n    ctx.obj = ctx.obj or {}\n    ctx.obj['project'] = project\n    ctx.obj['build'] = build"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a build job.", "response": "def get(ctx):\n    \"\"\"Get build job.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Examples:\n\n    \\b\n    ```bash\n    $ polyaxon build -b 1 get\n    ```\n\n    \\b\n    ```bash\n    $ polyaxon build --build=1 --project=project_name get\n    ```\n    \"\"\"\n    user, project_name, _build = get_build_or_local(ctx.obj.get('project'), ctx.obj.get('build'))\n    try:\n        response = PolyaxonClient().build_job.get_build(user, project_name, _build)\n        cache.cache(config_manager=BuildJobManager, response=response)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not get build job `{}`.'.format(_build))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    get_build_details(response)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a build job.", "response": "def delete(ctx):\n    \"\"\"Delete build job.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Example:\n\n    \\b\n    ```bash\n    $ polyaxon build delete\n    ```\n\n    \\b\n    ```bash\n    $ polyaxon build -b 2 delete\n    ```\n    \"\"\"\n    user, project_name, _build = get_build_or_local(ctx.obj.get('project'), ctx.obj.get('build'))\n    if not click.confirm(\"Are sure you want to delete build job `{}`\".format(_build)):\n        click.echo('Existing without deleting build job.')\n        sys.exit(1)\n\n    try:\n        response = PolyaxonClient().build_job.delete_build(\n            user, project_name, _build)\n        # Purge caching\n        BuildJobManager.purge()\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not delete job `{}`.'.format(_build))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    if response.status_code == 204:\n        Printer.print_success(\"Build job `{}` was deleted successfully\".format(_build))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate build. Uses [Caching](/references/polyaxon-cli/#caching) Example: \\b ```bash $ polyaxon build -b 2 update --description=\"new description for my build\" ```", "response": "def update(ctx, name, description, tags):\n    \"\"\"Update build.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Example:\n\n    \\b\n    ```bash\n    $ polyaxon build -b 2 update --description=\"new description for my build\"\n    ```\n    \"\"\"\n    user, project_name, _build = get_build_or_local(ctx.obj.get('project'), ctx.obj.get('build'))\n    update_dict = {}\n\n    if name:\n        update_dict['name'] = name\n\n    if description:\n        update_dict['description'] = description\n\n    tags = validate_tags(tags)\n    if tags:\n        update_dict['tags'] = tags\n\n    if not update_dict:\n        Printer.print_warning('No argument was provided to update the build.')\n        sys.exit(0)\n\n    try:\n        response = PolyaxonClient().build_job.update_build(\n            user, project_name, _build, update_dict)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not update build `{}`.'.format(_build))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    Printer.print_success(\"Build updated.\")\n    get_build_details(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstops a build job.", "response": "def stop(ctx, yes):\n    \"\"\"Stop build job.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Examples:\n\n    \\b\n    ```bash\n    $ polyaxon build stop\n    ```\n\n    \\b\n    ```bash\n    $ polyaxon build -b 2 stop\n    ```\n    \"\"\"\n    user, project_name, _build = get_build_or_local(ctx.obj.get('project'), ctx.obj.get('build'))\n    if not yes and not click.confirm(\"Are sure you want to stop \"\n                                     \"job `{}`\".format(_build)):\n        click.echo('Existing without stopping build job.')\n        sys.exit(0)\n\n    try:\n        PolyaxonClient().build_job.stop(user, project_name, _build)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not stop build job `{}`.'.format(_build))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    Printer.print_success(\"Build job is being stopped.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbookmark build job. Uses [Caching](/references/polyaxon-cli/#caching) Examples: \\b ```bash $ polyaxon build bookmark ``` \\b ```bash $ polyaxon build -b 2 bookmark ```", "response": "def bookmark(ctx):\n    \"\"\"Bookmark build job.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Examples:\n\n    \\b\n    ```bash\n    $ polyaxon build bookmark\n    ```\n\n    \\b\n    ```bash\n    $ polyaxon build -b 2 bookmark\n    ```\n    \"\"\"\n    user, project_name, _build = get_build_or_local(ctx.obj.get('project'), ctx.obj.get('build'))\n    try:\n        PolyaxonClient().build_job.bookmark(user, project_name, _build)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not bookmark build job `{}`.'.format(_build))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    Printer.print_success(\"Build job bookmarked.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget build job resources.", "response": "def resources(ctx, gpu):\n    \"\"\"Get build job resources.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Examples:\n\n    \\b\n    ```bash\n    $ polyaxon build -b 2 resources\n    ```\n\n    For GPU resources\n\n    \\b\n    ```bash\n    $ polyaxon build -b 2 resources --gpu\n    ```\n    \"\"\"\n    user, project_name, _build = get_build_or_local(ctx.obj.get('project'), ctx.obj.get('build'))\n    try:\n        message_handler = Printer.gpu_resources if gpu else Printer.resources\n        PolyaxonClient().build_job.resources(user,\n                                             project_name,\n                                             _build,\n                                             message_handler=message_handler)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not get resources for build job `{}`.'.format(_build))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init(project, polyaxonfile):\n    user, project_name = get_project_or_local(project)\n    try:\n        project_config = PolyaxonClient().project.get_project(user, project_name)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Make sure you have a project with this name `{}`'.format(project))\n        Printer.print_error(\n            'You can a create new project with this command: '\n            'polyaxon project create '\n            '--name={} [--description=...] [--tags=...]'.format(project_name))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    init_project = False\n    if ProjectManager.is_initialized():\n        local_project = ProjectManager.get_config()\n        click.echo('Warning! This project is already initialized with the following project:')\n        with clint.textui.indent(4):\n            clint.textui.puts('User: {}'.format(local_project.user))\n            clint.textui.puts('Project: {}'.format(local_project.name))\n        if click.confirm('Would you like to override this current config?', default=False):\n            init_project = True\n    else:\n        init_project = True\n\n    if init_project:\n        ProjectManager.purge()\n        ProjectManager.set_config(project_config, init=True)\n        Printer.print_success('Project was initialized')\n    else:\n        Printer.print_header('Project config was not changed.')\n\n    init_ignore = False\n    if IgnoreManager.is_initialized():\n        click.echo('Warning! Found a .polyaxonignore file.')\n        if click.confirm('Would you like to override it?', default=False):\n            init_ignore = True\n    else:\n        init_ignore = True\n\n    if init_ignore:\n        IgnoreManager.init_config()\n        Printer.print_success('New .polyaxonignore file was created.')\n    else:\n        Printer.print_header('.polyaxonignore file was not changed.')\n\n    if polyaxonfile:\n        create_polyaxonfile()", "response": "Initialize a new polyaxonfile specification."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(ctx, project, file, name, tags, description, ttl, u, l):  # pylint:disable=redefined-builtin\n    if not file:\n        file = PolyaxonFile.check_default_path(path='.')\n    if not file:\n        file = ''\n    specification = check_polyaxonfile(file, log=False).specification\n\n    spec_cond = (specification.is_experiment or\n                 specification.is_group or\n                 specification.is_job or\n                 specification.is_build)\n    if not spec_cond:\n        Printer.print_error(\n            'This command expects an experiment, a group, a job, or a build specification,'\n            'received instead a `{}` specification'.format(specification.kind))\n        if specification.is_notebook:\n            click.echo('Please check \"polyaxon notebook --help\" to start a notebook.')\n        elif specification.is_tensorboard:\n            click.echo('Please check: \"polyaxon tensorboard --help\" to start a tensorboard.')\n        sys.exit(1)\n\n    # Check if we need to upload\n    if u:\n        if project:\n            Printer.print_error('Uploading is not supported when switching project context!')\n            click.echo('Please, either omit the `-u` option or `-p` / `--project=` option.')\n            sys.exit(1)\n        ctx.invoke(upload, sync=False)\n\n    user, project_name = get_project_or_local(project)\n    project_client = PolyaxonClient().project\n\n    tags = validate_tags(tags)\n\n    def run_experiment():\n        click.echo('Creating an independent experiment.')\n        experiment = ExperimentConfig(\n            name=name,\n            description=description,\n            tags=tags,\n            config=specification.parsed_data,\n            ttl=ttl)\n        try:\n            response = PolyaxonClient().project.create_experiment(user,\n                                                                  project_name,\n                                                                  experiment)\n            cache.cache(config_manager=ExperimentManager, response=response)\n            Printer.print_success('Experiment `{}` was created'.format(response.id))\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not create experiment.')\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n\n    def run_group():\n        click.echo('Creating an experiment group with the following definition:')\n        experiments_def = specification.experiments_def\n        get_group_experiments_info(**experiments_def)\n        experiment_group = ExperimentGroupConfig(\n            name=name,\n            description=description,\n            tags=tags,\n            content=specification._data)  # pylint:disable=protected-access\n        try:\n            response = project_client.create_experiment_group(user,\n                                                              project_name,\n                                                              experiment_group)\n            cache.cache(config_manager=GroupManager, response=response)\n            Printer.print_success('Experiment group {} was created'.format(response.id))\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not create experiment group.')\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n\n    def run_job():\n        click.echo('Creating a job.')\n        job = JobConfig(\n            name=name,\n            description=description,\n            tags=tags,\n            config=specification.parsed_data,\n            ttl=ttl)\n        try:\n            response = project_client.create_job(user,\n                                                 project_name,\n                                                 job)\n            cache.cache(config_manager=JobManager, response=response)\n            Printer.print_success('Job {} was created'.format(response.id))\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not create job.')\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n\n    def run_build():\n        click.echo('Creating a build.')\n        job = JobConfig(\n            name=name,\n            description=description,\n            tags=tags,\n            config=specification.parsed_data,\n            ttl=ttl)\n        try:\n            response = project_client.create_build(user,\n                                                   project_name,\n                                                   job)\n            cache.cache(config_manager=BuildJobManager, response=response)\n            Printer.print_success('Build {} was created'.format(response.id))\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not create build.')\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n\n    logs = None\n    if specification.is_experiment:\n        run_experiment()\n        logs = experiment_logs\n    elif specification.is_group:\n        run_group()\n    elif specification.is_job:\n        run_job()\n        logs = job_logs\n    elif specification.is_build:\n        run_build()\n        logs = build_logs\n\n    # Check if we need to invoke logs\n    if l and logs:\n        ctx.obj = {'project': '{}/{}'.format(user, project_name)}\n        ctx.invoke(logs)", "response": "Run a single polyaxon file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef projects(ctx, page):\n    user = get_username_or_local(ctx.obj.get('username'))\n\n    page = page or 1\n    try:\n        response = PolyaxonClient().bookmark.projects(username=user, page=page)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error(\n            'Could not get bookmarked projects for user `{}`.'.format(user))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    meta = get_meta_response(response)\n    if meta:\n        Printer.print_header('Bookmarked projects for user `{}`.'.format(user))\n        Printer.print_header('Navigation:')\n        dict_tabulate(meta)\n    else:\n        Printer.print_header('No bookmarked projects found for user `{}`.'.format(user))\n\n    objects = [Printer.add_status_color(o.to_light_dict(humanize_values=True))\n               for o in response['results']]\n    objects = list_dicts_to_tabulate(objects)\n    if objects:\n        Printer.print_header(\"Projects:\")\n        dict_tabulate(objects, is_list_dict=True)", "response": "List bookmarked projects for a user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving trailing spaces unless they are quoted with a backslash.", "response": "def _remove_trailing_spaces(line):\n        \"\"\"Remove trailing spaces unless they are quoted with a backslash.\"\"\"\n        while line.endswith(' ') and not line.endswith('\\\\ '):\n            line = line[:-1]\n        return line.replace('\\\\ ', ' ')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields all matching patterns for path.", "response": "def find_matching(cls, path, patterns):\n        \"\"\"Yield all matching patterns for path.\"\"\"\n        for pattern in patterns:\n            if pattern.match(path):\n                yield pattern"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks whether a path is ignored. For directories include a trailing slash.", "response": "def is_ignored(cls, path, patterns):\n        \"\"\"Check whether a path is ignored. For directories, include a trailing slash.\"\"\"\n        status = None\n        for pattern in cls.find_matching(path, patterns):\n            status = pattern.is_exclude\n        return status"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _matches_patterns(path, patterns):\n        for glob in patterns:\n            try:\n                if PurePath(path).match(glob):\n                    return True\n            except TypeError:\n                pass\n        return False", "response": "Returns a if a path matches any pattern."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a whether a path should be ignored or not.", "response": "def _ignore_path(cls, path, ignore_list=None, white_list=None):\n        \"\"\"Returns a whether a path should be ignored or not.\"\"\"\n        ignore_list = ignore_list or []\n        white_list = white_list or []\n        return (cls._matches_patterns(path, ignore_list) and\n                not cls._matches_patterns(path, white_list))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef group(ctx, project, group):  # pylint:disable=redefined-outer-name\n    ctx.obj = ctx.obj or {}\n    ctx.obj['project'] = project\n    ctx.obj['group'] = group", "response": "Commands for experiment groups."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets an experiment group by uuid.", "response": "def get(ctx):\n    \"\"\"Get experiment group by uuid.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Examples:\n\n    \\b\n    ```bash\n    $ polyaxon group -g 13 get\n    ```\n    \"\"\"\n    user, project_name, _group = get_project_group_or_local(ctx.obj.get('project'),\n                                                            ctx.obj.get('group'))\n    try:\n        response = PolyaxonClient().experiment_group.get_experiment_group(\n            user, project_name, _group)\n        cache.cache(config_manager=GroupManager, response=response)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not get experiment group `{}`.'.format(_group))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    get_group_details(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(ctx):\n    user, project_name, _group = get_project_group_or_local(ctx.obj.get('project'),\n                                                            ctx.obj.get('group'))\n\n    if not click.confirm(\"Are sure you want to delete experiment group `{}`\".format(_group)):\n        click.echo('Existing without deleting experiment group.')\n        sys.exit(0)\n\n    try:\n        response = PolyaxonClient().experiment_group.delete_experiment_group(\n            user, project_name, _group)\n        # Purge caching\n        GroupManager.purge()\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not delete experiment group `{}`.'.format(_group))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    if response.status_code == 204:\n        Printer.print_success(\"Experiment group `{}` was delete successfully\".format(_group))", "response": "Delete an experiment group."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating an existing group.", "response": "def update(ctx, name, description, tags):\n    \"\"\"Update experiment group.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Example:\n\n    \\b\n    ```bash\n    $ polyaxon group -g 2 update --description=\"new description for this group\"\n    ```\n\n    \\b\n    ```bash\n    $ polyaxon update --tags=\"foo, bar\"\n    ```\n    \"\"\"\n    user, project_name, _group = get_project_group_or_local(ctx.obj.get('project'),\n                                                            ctx.obj.get('group'))\n    update_dict = {}\n\n    if name:\n        update_dict['name'] = name\n\n    if description:\n        update_dict['description'] = description\n\n    tags = validate_tags(tags)\n    if tags:\n        update_dict['tags'] = tags\n\n    if not update_dict:\n        Printer.print_warning('No argument was provided to update the experiment group.')\n        sys.exit(0)\n\n    try:\n        response = PolyaxonClient().experiment_group.update_experiment_group(\n            user, project_name, _group, update_dict)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not update experiment group `{}`.'.format(_group))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    Printer.print_success(\"Experiment group updated.\")\n    get_group_details(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stop(ctx, yes, pending):\n    user, project_name, _group = get_project_group_or_local(ctx.obj.get('project'),\n                                                            ctx.obj.get('group'))\n\n    if not yes and not click.confirm(\"Are sure you want to stop experiments \"\n                                     \"in group `{}`\".format(_group)):\n        click.echo('Existing without stopping experiments in group.')\n        sys.exit(0)\n\n    try:\n        PolyaxonClient().experiment_group.stop(user, project_name, _group, pending=pending)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not stop experiments in group `{}`.'.format(_group))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    Printer.print_success(\"Experiments in group are being stopped.\")", "response": "Stop all experiments in the specified group."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bookmark(ctx):\n    user, project_name, _group = get_project_group_or_local(ctx.obj.get('project'),\n                                                            ctx.obj.get('group'))\n\n    try:\n        PolyaxonClient().experiment_group.bookmark(user, project_name, _group)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not bookmark group `{}`.'.format(_group))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    Printer.print_success(\"Experiments group is bookmarked.\")", "response": "Bookmark the current group."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset and get the global configurations.", "response": "def config(list):  # pylint:disable=redefined-builtin\n    \"\"\"Set and get the global configurations.\"\"\"\n    if list:\n        _config = GlobalConfigManager.get_config_or_default()\n        Printer.print_header('Current config:')\n        dict_tabulate(_config.to_dict())"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the global config values by keys.", "response": "def get(keys):\n    \"\"\"Get the global config values by keys.\n\n    Example:\n\n    \\b\n    ```bash\n    $ polyaxon config get host http_port\n    ```\n    \"\"\"\n    _config = GlobalConfigManager.get_config_or_default()\n\n    if not keys:\n        return\n\n    print_values = {}\n    for key in keys:\n        if hasattr(_config, key):\n            print_values[key] = getattr(_config, key)\n        else:\n            click.echo('Key `{}` is not recognised.'.format(key))\n\n    dict_tabulate(print_values, )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set(verbose,  # pylint:disable=redefined-builtin\n        host,\n        http_port,\n        ws_port,\n        use_https,\n        verify_ssl):\n    \"\"\"Set the global config values.\n\n    Example:\n\n    \\b\n    ```bash\n    $ polyaxon config set --hots=localhost http_port=80\n    ```\n    \"\"\"\n    _config = GlobalConfigManager.get_config_or_default()\n\n    if verbose is not None:\n        _config.verbose = verbose\n\n    if host is not None:\n        _config.host = host\n\n    if http_port is not None:\n        _config.http_port = http_port\n\n    if ws_port is not None:\n        _config.ws_port = ws_port\n\n    if use_https is not None:\n        _config.use_https = use_https\n\n    if verify_ssl is False:\n        _config.verify_ssl = verify_ssl\n\n    GlobalConfigManager.set_config(_config)\n    Printer.print_success('Config was updated.')\n    # Reset cli config\n    CliConfigManager.purge()", "response": "Set the global config values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nactivating a user. Example: \\b ```bash $ polyaxon user activate david ```", "response": "def activate(username):\n    \"\"\"Activate a user.\n\n    Example:\n\n    \\b\n    ```bash\n    $ polyaxon user activate david\n    ```\n    \"\"\"\n    try:\n        PolyaxonClient().user.activate_user(username)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not activate user `{}`.'.format(username))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    Printer.print_success(\"User `{}` was activated successfully.\".format(username))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete a user. Example: \\b ```bash $ polyaxon user delete david ```", "response": "def delete(username):\n    \"\"\"Delete a user.\n\n    Example:\n\n    \\b\n    ```bash\n    $ polyaxon user delete david\n    ```\n    \"\"\"\n    try:\n        PolyaxonClient().user.delete_user(username)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not delete user `{}`.'.format(username))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    Printer.print_success(\"User `{}` was deleted successfully.\".format(username))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef teardown(file):  # pylint:disable=redefined-builtin\n    config = read_deployment_config(file)\n    manager = DeployManager(config=config, filepath=file)\n    exception = None\n    try:\n        if click.confirm('Would you like to execute pre-delete hooks?', default=True):\n            manager.teardown(hooks=True)\n        else:\n            manager.teardown(hooks=False)\n    except Exception as e:\n        Printer.print_error('Polyaxon could not teardown the deployment.')\n        exception = e\n\n    if exception:\n        Printer.print_error('Error message `{}`.'.format(exception))", "response": "Teardown a polyaxon deployment given a config file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_tarfile(files, project_name):\n    fd, filename = tempfile.mkstemp(prefix=\"polyaxon_{}\".format(project_name), suffix='.tar.gz')\n    with tarfile.open(filename, \"w:gz\") as tar:\n        for f in files:\n            tar.add(f)\n\n    yield filename\n\n    # clear\n    os.close(fd)\n    os.remove(filename)", "response": "Create a tar file based on the list of files passed"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint the tensorboard url for project group and experiment.", "response": "def url(ctx):\n    \"\"\"Prints the tensorboard url for project/experiment/experiment group.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Examples for project tensorboards:\n\n    \\b\n    ```bash\n    $ polyaxon tensorboard url\n    ```\n\n    \\b\n    ```bash\n    $ polyaxon tensorboard -p mnist url\n    ```\n\n    Examples for experiment tensorboards:\n\n    \\b\n    ```bash\n    $ polyaxon tensorboard -xp 1 url\n    ```\n\n    Examples for experiment group tensorboards:\n\n    \\b\n    ```bash\n    $ polyaxon tensorboard -g 1 url\n    ```\n    \"\"\"\n    user, project_name = get_project_or_local(ctx.obj.get('project'))\n    group = ctx.obj.get('group')\n    experiment = ctx.obj.get('experiment')\n    if experiment:\n        try:\n            response = PolyaxonClient().experiment.get_experiment(\n                username=user,\n                project_name=project_name,\n                experiment_id=experiment)\n            obj = 'experiment {}'.format(experiment)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not get experiment `{}`.'.format(experiment))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n    elif group:\n        try:\n            response = PolyaxonClient().experiment_group.get_experiment_group(\n                username=user,\n                project_name=project_name,\n                group_id=group)\n            obj = 'group `{}`.'.format(group)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not get group `{}`.'.format(group))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n    else:\n        try:\n            response = PolyaxonClient().project.get_project(\n                username=user,\n                project_name=project_name)\n            obj = 'project `{}`.'.format(project_name)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not get project `{}`.'.format(project_name))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n\n    if response.has_tensorboard:\n        click.echo(get_tensorboard_url(user=user,\n                                       project_name=project_name,\n                                       experiment=experiment,\n                                       group=group))\n    else:\n        Printer.print_warning('This `{}` does not have a running tensorboard'.format(obj))\n        click.echo('You can start tensorboard with this command: polyaxon tensorboard start --help')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start(ctx, file):  # pylint:disable=redefined-builtin\n    specification = None\n    job_config = None\n    if file:\n        specification = check_polyaxonfile(file, log=False).specification\n\n    if specification:\n        # pylint:disable=protected-access\n        check_polyaxonfile_kind(specification=specification, kind=specification._TENSORBOARD)\n        job_config = specification.parsed_data\n\n    user, project_name = get_project_or_local(ctx.obj.get('project'))\n    group = ctx.obj.get('group')\n    experiment = ctx.obj.get('experiment')\n    if experiment:\n        try:\n            response = PolyaxonClient().experiment.start_tensorboard(\n                username=user,\n                project_name=project_name,\n                experiment_id=experiment,\n                job_config=job_config)\n            obj = 'experiment `{}`'.format(experiment)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not start tensorboard experiment `{}`.'.format(experiment))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n    elif group:\n        try:\n            response = PolyaxonClient().experiment_group.start_tensorboard(\n                username=user,\n                project_name=project_name,\n                group_id=group,\n                job_config=job_config)\n            obj = 'group `{}`'.format(group)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not start tensorboard group `{}`.'.format(group))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n    else:\n        try:\n            response = PolyaxonClient().project.start_tensorboard(\n                username=user,\n                project_name=project_name,\n                job_config=job_config)\n            obj = 'project `{}`'.format(project_name)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not start tensorboard project `{}`.'.format(project_name))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n\n    if response.status_code == 200:\n        Printer.print_header(\"A tensorboard for this {} is already running on:\".format(obj))\n        click.echo(get_tensorboard_url(user=user,\n                                       project_name=project_name,\n                                       experiment=experiment,\n                                       group=group))\n        sys.exit(0)\n\n    if response.status_code != 201:\n        Printer.print_error('Something went wrong, Tensorboard was not created.')\n        sys.exit(1)\n\n    Printer.print_success('Tensorboard is being deployed for {}'.format(obj))\n    clint.textui.puts(\"It may take some time before you can access tensorboard.\\n\")\n    clint.textui.puts(\"Your tensorboard will be available on:\\n\")\n    with clint.textui.indent(4):\n        clint.textui.puts(get_tensorboard_url(user, project_name, experiment, group))", "response": "Start a tensorboard deployment for project group and resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop(ctx, yes):\n    user, project_name = get_project_or_local(ctx.obj.get('project'))\n    group = ctx.obj.get('group')\n    experiment = ctx.obj.get('experiment')\n\n    if experiment:\n        obj = 'experiment `{}`'.format(experiment)\n    elif group:\n        obj = 'group `{}`'.format(group)\n    else:\n        obj = 'project `{}/{}`'.format(user, project_name)\n\n    if not yes and not click.confirm(\"Are sure you want to stop tensorboard \"\n                                     \"for {}\".format(obj)):\n        click.echo('Existing without stopping tensorboard.')\n        sys.exit(1)\n\n    if experiment:\n        try:\n            PolyaxonClient().experiment.stop_tensorboard(\n                username=user,\n                project_name=project_name,\n                experiment_id=experiment)\n            Printer.print_success('Tensorboard is being deleted')\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not stop tensorboard {}.'.format(obj))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n    elif group:\n        try:\n            PolyaxonClient().experiment_group.stop_tensorboard(\n                username=user,\n                project_name=project_name,\n                group_id=group)\n            Printer.print_success('Tensorboard is being deleted')\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not stop tensorboard {}.'.format(obj))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n    else:\n        try:\n            PolyaxonClient().project.stop_tensorboard(\n                username=user,\n                project_name=project_name)\n            Printer.print_success('Tensorboard is being deleted')\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not stop tensorboard {}.'.format(obj))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)", "response": "Stops the tensorboard for the current project and experiment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_cli_version():\n    if not CliConfigManager.should_check():\n        return\n\n    server_version = get_server_version()\n    current_version = get_current_version()\n    CliConfigManager.reset(current_version=current_version,\n                           min_version=server_version.min_version)\n\n    if LooseVersion(current_version) < LooseVersion(server_version.min_version):\n        click.echo(\"\"\"Your version of CLI ({}) is no longer compatible with server.\"\"\".format(\n            current_version))\n        if click.confirm(\"Do you want to upgrade to \"\n                         \"version {} now?\".format(server_version.latest_version)):\n            pip_upgrade()\n            sys.exit(0)\n        else:\n            clint.textui.puts(\"Your can manually run:\")\n            with clint.textui.indent(4):\n                clint.textui.puts(\"pip install -U polyaxon-cli\")\n            clint.textui.puts(\n                \"to upgrade to the latest version `{}`\".format(server_version.latest_version))\n\n            sys.exit(0)\n    elif LooseVersion(current_version) < LooseVersion(server_version.latest_version):\n        clint.textui.puts(\"New version of CLI ({}) is now available. To upgrade run:\".format(\n            server_version.latest_version\n        ))\n        with clint.textui.indent(4):\n            clint.textui.puts(\"pip install -U polyaxon-cli\")\n    elif LooseVersion(current_version) > LooseVersion(server_version.latest_version):\n        clint.textui.puts(\"You version of CLI ({}) is ahead of the latest version \"\n                          \"supported by Polyaxon Platform ({}) on your cluster, \"\n                          \"and might be incompatible.\".format(current_version,\n                                                              server_version.latest_version))", "response": "Check if the current CLI version satisfies the server requirements"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint the current version of the cli and platform.", "response": "def version(cli, platform):\n    \"\"\"Print the current version of the cli and platform.\"\"\"\n    version_client = PolyaxonClient().version\n    cli = cli or not any([cli, platform])\n    if cli:\n        try:\n            server_version = version_client.get_cli_version()\n        except AuthorizationError:\n            session_expired()\n            sys.exit(1)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not get cli version.')\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n        cli_version = get_version(PROJECT_CLI_NAME)\n        Printer.print_header('Current cli version: {}.'.format(cli_version))\n        Printer.print_header('Supported cli versions:')\n        dict_tabulate(server_version.to_dict())\n\n    if platform:\n        try:\n            platform_version = version_client.get_platform_version()\n        except AuthorizationError:\n            session_expired()\n            sys.exit(1)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not get platform version.')\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n        chart_version = version_client.get_chart_version()\n        Printer.print_header('Current platform version: {}.'.format(chart_version.version))\n        Printer.print_header('Supported platform versions:')\n        dict_tabulate(platform_version.to_dict())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nopens dashboard in browser.", "response": "def dashboard(yes, url):\n    \"\"\"Open dashboard in browser.\"\"\"\n    dashboard_url = \"{}/app\".format(PolyaxonClient().api_config.http_host)\n    if url:\n        click.echo(dashboard_url)\n        sys.exit(0)\n    if not yes:\n        click.confirm('Dashboard page will now open in your browser. Continue?',\n                      abort=True, default=True)\n\n    click.launch(dashboard_url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef grant(username):\n    try:\n        PolyaxonClient().user.grant_superuser(username)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not grant superuser role to user `{}`.'.format(username))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    Printer.print_success(\n        \"Superuser role was granted successfully to user `{}`.\".format(username))", "response": "Grant superuser role to a user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef revoke(username):\n    try:\n        PolyaxonClient().user.revoke_superuser(username)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not revoke superuser role from user `{}`.'.format(username))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    Printer.print_success(\n        \"Superuser role was revoked successfully from user `{}`.\".format(username))", "response": "Revoke superuser role from a user."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints the url for this project.", "response": "def url(ctx):\n    \"\"\"Prints the notebook url for this project.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Example:\n\n    \\b\n    ```bash\n    $ polyaxon notebook url\n    ```\n    \"\"\"\n    user, project_name = get_project_or_local(ctx.obj.get('project'))\n    try:\n        response = PolyaxonClient().project.get_project(user, project_name)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not get project `{}`.'.format(project_name))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    if response.has_notebook:\n        click.echo(get_notebook_url(user, project_name))\n    else:\n        Printer.print_warning(\n            'This project `{}` does not have a running notebook.'.format(project_name))\n        click.echo('You can start a notebook with this command: polyaxon notebook start --help')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts a new notebook for this project.", "response": "def start(ctx, file, u):  # pylint:disable=redefined-builtin\n    \"\"\"Start a notebook deployment for this project.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Example:\n\n    \\b\n    ```bash\n    $ polyaxon notebook start -f file -f file_override ...\n    ```\n\n    Example: upload before running\n\n    \\b\n    ```bash\n    $ polyaxon -p user12/mnist notebook start -f file -u\n    ```\n    \"\"\"\n    specification = None\n    job_config = None\n    if file:\n        specification = check_polyaxonfile(file, log=False).specification\n\n    # Check if we need to upload\n    if u:\n        ctx.invoke(upload, sync=False)\n\n    if specification:\n        # pylint:disable=protected-access\n        check_polyaxonfile_kind(specification=specification, kind=specification._NOTEBOOK)\n        job_config = specification.parsed_data\n    user, project_name = get_project_or_local(ctx.obj.get('project'))\n    try:\n        response = PolyaxonClient().project.start_notebook(user, project_name, job_config)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not start notebook project `{}`.'.format(project_name))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    if response.status_code == 200:\n        Printer.print_header(\"A notebook for this project is already running on:\")\n        click.echo(get_notebook_url(user, project_name))\n        sys.exit(0)\n\n    if response.status_code != 201:\n        Printer.print_error('Something went wrong, Notebook was not created.')\n        sys.exit(1)\n\n    Printer.print_success('Notebook is being deployed for project `{}`'.format(project_name))\n    clint.textui.puts(\"It may take some time before you can access the notebook.\\n\")\n    clint.textui.puts(\"Your notebook will be available on:\\n\")\n    with clint.textui.indent(4):\n        clint.textui.puts(get_notebook_url(user, project_name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstop the notebook deployment for this project.", "response": "def stop(ctx, commit, yes):\n    \"\"\"Stops the notebook deployment for this project if it exists.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n    \"\"\"\n    user, project_name = get_project_or_local(ctx.obj.get('project'))\n\n    if not yes and not click.confirm(\"Are sure you want to stop notebook \"\n                                     \"for project `{}/{}`\".format(user, project_name)):\n        click.echo('Existing without stopping notebook.')\n        sys.exit(1)\n\n    if commit is None:\n        commit = True\n\n    try:\n        PolyaxonClient().project.stop_notebook(user, project_name, commit)\n        Printer.print_success('Notebook is being deleted')\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not stop notebook project `{}`.'.format(project_name))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd platform specific checks", "response": "def check(self):\n        \"\"\"Add platform specific checks\"\"\"\n        if not self.is_valid:\n            raise PolyaxonDeploymentConfigError(\n                'Deployment type `{}` not supported'.format(self.deployment_type))\n        check = False\n        if self.is_kubernetes:\n            check = self.check_for_kubernetes()\n        elif self.is_docker_compose:\n            check = self.check_for_docker_compose()\n        elif self.is_docker:\n            check = self.check_for_docker()\n        elif self.is_heroku:\n            check = self.check_for_heroku()\n        if not check:\n            raise PolyaxonDeploymentConfigError(\n                'Deployment `{}` is not valid'.format(self.deployment_type))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef install(self):\n        if not self.is_valid:\n            raise PolyaxonDeploymentConfigError(\n                'Deployment type `{}` not supported'.format(self.deployment_type))\n\n        if self.is_kubernetes:\n            self.install_on_kubernetes()\n        elif self.is_docker_compose:\n            self.install_on_docker_compose()\n        elif self.is_docker:\n            self.install_on_docker()\n        elif self.is_heroku:\n            self.install_on_heroku()", "response": "Install polyaxon using the current config to the correct platform."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupgrading the specified resource.", "response": "def upgrade(self):\n        \"\"\"Upgrade deployment.\"\"\"\n        if not self.is_valid:\n            raise PolyaxonDeploymentConfigError(\n                'Deployment type `{}` not supported'.format(self.deployment_type))\n\n        if self.is_kubernetes:\n            self.upgrade_on_kubernetes()\n        elif self.is_docker_compose:\n            self.upgrade_on_docker_compose()\n        elif self.is_docker:\n            self.upgrade_on_docker()\n        elif self.is_heroku:\n            self.upgrade_on_heroku()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(ctx, name, description, tags, private, init):\n    try:\n        tags = tags.split(',') if tags else None\n        project_dict = dict(name=name, description=description, is_public=not private, tags=tags)\n        project_config = ProjectConfig.from_dict(project_dict)\n    except ValidationError:\n        Printer.print_error('Project name should contain only alpha numerical, \"-\", and \"_\".')\n        sys.exit(1)\n\n    try:\n        _project = PolyaxonClient().project.create_project(project_config)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not create project `{}`.'.format(name))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    Printer.print_success(\"Project `{}` was created successfully.\".format(_project.name))\n\n    if init:\n        ctx.obj = {}\n        ctx.invoke(init_project, project=name)", "response": "Create a new project."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list(page):  # pylint:disable=redefined-builtin\n    user = AuthConfigManager.get_value('username')\n    if not user:\n        Printer.print_error('Please login first. `polyaxon login --help`')\n\n    page = page or 1\n    try:\n        response = PolyaxonClient().project.list_projects(user, page=page)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not get list of projects.')\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    meta = get_meta_response(response)\n    if meta:\n        Printer.print_header('Projects for current user')\n        Printer.print_header('Navigation:')\n        dict_tabulate(meta)\n    else:\n        Printer.print_header('No projects found for current user')\n\n    objects = list_dicts_to_tabulate(\n        [o.to_light_dict(\n            humanize_values=True,\n            exclude_attrs=['uuid', 'experiment_groups', 'experiments', 'description',\n                           'num_experiments', 'num_independent_experiments',\n                           'num_experiment_groups', 'num_jobs', 'num_builds', 'unique_name'])\n            for o in response['results']])\n    if objects:\n        Printer.print_header(\"Projects:\")\n        dict_tabulate(objects, is_list_dict=True)", "response": "List projects.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(ctx):\n    user, project_name = get_project_or_local(ctx.obj.get('project'))\n\n    try:\n        response = PolyaxonClient().project.get_project(user, project_name)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not get project `{}`.'.format(project_name))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    get_project_details(response)", "response": "Get current project by project_name or user or project_name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(ctx):\n    user, project_name = get_project_or_local(ctx.obj.get('project'))\n\n    if not click.confirm(\"Are sure you want to delete project `{}/{}`\".format(user, project_name)):\n        click.echo('Existing without deleting project.')\n        sys.exit(1)\n\n    try:\n        response = PolyaxonClient().project.delete_project(user, project_name)\n        local_project = ProjectManager.get_config()\n        if local_project and (user, project_name) == (local_project.user, local_project.name):\n            # Purge caching\n            ProjectManager.purge()\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not delete project `{}/{}`.'.format(user, project_name))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    if response.status_code == 204:\n        Printer.print_success(\"Project `{}/{}` was delete successfully\".format(user, project_name))", "response": "Delete project.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating project. Uses [Caching](/references/polyaxon-cli/#caching) Example: \\b ```bash $ polyaxon update foobar --description=\"Image Classification with DL using TensorFlow\" ``` \\b ```bash $ polyaxon update mike1/foobar --description=\"Image Classification with DL using TensorFlow\" ``` \\b ```bash $ polyaxon update --tags=\"foo, bar\" ```", "response": "def update(ctx, name, description, tags, private):\n    \"\"\"Update project.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Example:\n\n    \\b\n    ```bash\n    $ polyaxon update foobar --description=\"Image Classification with DL using TensorFlow\"\n    ```\n\n    \\b\n    ```bash\n    $ polyaxon update mike1/foobar --description=\"Image Classification with DL using TensorFlow\"\n    ```\n\n    \\b\n    ```bash\n    $ polyaxon update --tags=\"foo, bar\"\n    ```\n    \"\"\"\n    user, project_name = get_project_or_local(ctx.obj.get('project'))\n\n    update_dict = {}\n    if name:\n        update_dict['name'] = name\n\n    if description:\n        update_dict['description'] = description\n\n    if private is not None:\n        update_dict['is_public'] = not private\n\n    tags = validate_tags(tags)\n    if tags:\n        update_dict['tags'] = tags\n\n    if not update_dict:\n        Printer.print_warning('No argument was provided to update the project.')\n        sys.exit(1)\n\n    try:\n        response = PolyaxonClient().project.update_project(user, project_name, update_dict)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not update project `{}`.'.format(project_name))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    Printer.print_success(\"Project updated.\")\n    get_project_details(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef groups(ctx, query, sort, page):\n    user, project_name = get_project_or_local(ctx.obj.get('project'))\n\n    page = page or 1\n    try:\n        response = PolyaxonClient().project.list_experiment_groups(username=user,\n                                                                   project_name=project_name,\n                                                                   query=query,\n                                                                   sort=sort,\n                                                                   page=page)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error(\n            'Could not get experiment groups for project `{}`.'.format(project_name))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    meta = get_meta_response(response)\n    if meta:\n        Printer.print_header('Experiment groups for project `{}/{}`.'.format(user, project_name))\n        Printer.print_header('Navigation:')\n        dict_tabulate(meta)\n    else:\n        Printer.print_header('No experiment groups found for project `{}/{}`.'.format(\n            user, project_name))\n\n    objects = [Printer.add_status_color(o.to_light_dict(humanize_values=True))\n               for o in response['results']]\n    objects = list_dicts_to_tabulate(objects)\n    if objects:\n        Printer.print_header(\"Experiment groups:\")\n        objects.pop('project', None)\n        objects.pop('user', None)\n        dict_tabulate(objects, is_list_dict=True)", "response": "List experiment groups for this project."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist all experiments for this project.", "response": "def experiments(ctx, metrics, declarations, independent, group, query, sort, page):\n    \"\"\"List experiments for this project.\n\n    Uses [Caching](/references/polyaxon-cli/#caching)\n\n    Examples:\n\n    Get all experiments:\n\n    \\b\n    ```bash\n    $ polyaxon project experiments\n    ```\n\n    Get all experiments with with status {created or running}, and\n    creation date between 2018-01-01 and 2018-01-02, and declarations activation equal to sigmoid\n    and metric loss less or equal to 0.2\n\n    \\b\n    ```bash\n    $ polyaxon project experiments \\\n      -q \"status:created|running, started_at:2018-01-01..2018-01-02, \\\n          declarations.activation:sigmoid, metric.loss:<=0.2\"\n    ```\n\n    Get all experiments sorted by update date\n\n    \\b\n    ```bash\n    $ polyaxon project experiments -s \"-updated_at\"\n    ```\n    \"\"\"\n    user, project_name = get_project_or_local(ctx.obj.get('project'))\n\n    page = page or 1\n    try:\n        response = PolyaxonClient().project.list_experiments(username=user,\n                                                             project_name=project_name,\n                                                             independent=independent,\n                                                             group=group,\n                                                             metrics=metrics,\n                                                             declarations=declarations,\n                                                             query=query,\n                                                             sort=sort,\n                                                             page=page)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not get experiments for project `{}`.'.format(project_name))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n\n    meta = get_meta_response(response)\n    if meta:\n        Printer.print_header('Experiments for project `{}/{}`.'.format(user, project_name))\n        Printer.print_header('Navigation:')\n        dict_tabulate(meta)\n    else:\n        Printer.print_header('No experiments found for project `{}/{}`.'.format(user, project_name))\n\n    if metrics:\n        objects = get_experiments_with_metrics(response)\n    elif declarations:\n        objects = get_experiments_with_declarations(response)\n    else:\n        objects = [Printer.add_status_color(o.to_light_dict(humanize_values=True))\n                   for o in response['results']]\n    objects = list_dicts_to_tabulate(objects)\n    if objects:\n        Printer.print_header(\"Experiments:\")\n        objects.pop('project_name', None)\n        dict_tabulate(objects, is_list_dict=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef git(ctx, url, private, sync):  # pylint:disable=assign-to-new-keyword\n    user, project_name = get_project_or_local(ctx.obj.get('project'))\n\n    def git_set_url():\n        if private:\n            click.echo('\\nSetting a private git repo \"{}\" on project: {} ...\\n'.format(\n                url, project_name))\n        else:\n            click.echo('\\nSetting a public git repo \"{}\" on project: {} ...\\n'.format(\n                url, project_name))\n\n        try:\n            PolyaxonClient().project.set_repo(user, project_name, url, not private)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not set git repo on project `{}`.'.format(project_name))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n\n        Printer.print_success('Project was successfully initialized with `{}`.'.format(url))\n\n    def git_sync_repo():\n        try:\n            response = PolyaxonClient().project.sync_repo(user, project_name)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not sync git repo on project `{}`.'.format(project_name))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n\n        click.echo(response.status_code)\n        Printer.print_success('Project was successfully synced with latest changes.')\n\n    if url:\n        git_set_url()\n    if sync:\n        git_sync_repo()", "response": "Set or sync git repo on this project."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ci(ctx, enable, disable):  # pylint:disable=assign-to-new-keyword\n    user, project_name = get_project_or_local(ctx.obj.get('project'))\n\n    def enable_ci():\n        try:\n            PolyaxonClient().project.enable_ci(user, project_name)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not enable CI on project `{}`.'.format(project_name))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n\n        Printer.print_success(\n            'Polyaxon CI was successfully enabled on project: `{}`.'.format(project_name))\n\n    def disable_ci():\n        try:\n            PolyaxonClient().project.disable_ci(user, project_name)\n        except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n            Printer.print_error('Could not disable CI on project `{}`.'.format(project_name))\n            Printer.print_error('Error message `{}`.'.format(e))\n            sys.exit(1)\n\n        Printer.print_success(\n            'Polyaxon CI was successfully disabled on project: `{}`.'.format(project_name))\n\n    if enable:\n        enable_ci()\n    if disable:\n        disable_ci()", "response": "Enables or disables the CI on this project."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef download(ctx):\n    user, project_name = get_project_or_local(ctx.obj.get('project'))\n    try:\n        PolyaxonClient().project.download_repo(user, project_name)\n    except (PolyaxonHTTPError, PolyaxonShouldExitError, PolyaxonClientException) as e:\n        Printer.print_error('Could not download code for project `{}`.'.format(project_name))\n        Printer.print_error('Error message `{}`.'.format(e))\n        sys.exit(1)\n    Printer.print_success('Files downloaded.')", "response": "Download code of the current project."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self,file,optstring=\"\",quote=False):\n        classid = str(self.id)\n        if quote: classid = '\"'+classid+'\"'\n        # Only use a *single* space between tokens; both chimera's and pymol's DX parser\n        # does not properly implement the OpenDX specs and produces garbage with multiple\n        # spaces. (Chimera 1.4.1, PyMOL 1.3)\n        file.write('object '+classid+' class '+str(self.name)+' '+\\\n                   optstring+'\\n')", "response": "write the object line ; additional args are packed in string"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef edges(self):\n        return [self.delta[d,d] * numpy.arange(self.shape[d]+1) + self.origin[d]\\\n                - 0.5*self.delta[d,d]     for d in range(self.rank)]", "response": "Edges of the grid cells origin at centre of 0.. 0 grid cell."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite the class array section to a file.", "response": "def write(self, file):\n        \"\"\"Write the *class array* section.\n\n        Parameters\n        ----------\n        file : file\n\n        Raises\n        ------\n        ValueError\n             If the `dxtype` is not a valid type, :exc:`ValueError` is\n             raised.\n\n        \"\"\"\n        if self.type not in self.dx_types:\n            raise ValueError((\"DX type {} is not supported in the DX format. \\n\"\n                              \"Supported valus are: {}\\n\"\n                              \"Use the type=<type> keyword argument.\").format(\n                                  self.type, list(self.dx_types.keys())))\n        typelabel = (self.typequote+self.type+self.typequote)\n        DXclass.write(self,file,\n                      'type {0} rank 0 items {1} data follows'.format(\n                          typelabel, self.array.size))\n        # grid data, serialized as a C array (z fastest varying)\n        # (flat iterator is equivalent to: for x: for y: for z: grid[x,y,z])\n        # VMD's DX reader requires exactly 3 values per line\n        fmt_string = \"{:d}\"\n        if (self.array.dtype.kind == 'f' or self.array.dtype.kind == 'c'):\n            precision = numpy.finfo(self.array.dtype).precision\n            fmt_string = \"{:.\"+\"{:d}\".format(precision)+\"f}\"\n        values_per_line = 3\n        values = self.array.flat\n        while 1:\n            try:\n                for i in range(values_per_line):\n                    file.write(fmt_string.format(next(values)) + \"\\t\")\n                file.write('\\n')\n            except StopIteration:\n                file.write('\\n')\n                break\n        file.write('attribute \"dep\" string \"positions\"\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting the complete dx object to the file.", "response": "def write(self, filename):\n        \"\"\"Write the complete dx object to the file.\n\n        This is the simple OpenDX format which includes the data into\n        the header via the 'object array ... data follows' statement.\n\n        Only simple regular arrays are supported.\n\n        The format should be compatible with VMD's dx reader plugin.\n        \"\"\"\n        # comments (VMD chokes on lines of len > 80, so truncate)\n        maxcol = 80\n        with open(filename,'w') as outfile:\n            for line in self.comments:\n                comment = '# '+str(line)\n                outfile.write(comment[:maxcol]+'\\n')\n            # each individual object\n            for component,object in self.sorted_components():\n                object.write(outfile)\n            # the field object itself\n            DXclass.write(self,outfile,quote=True)\n            for component,object in self.sorted_components():\n                outfile.write('component \"%s\" value %s\\n' % (component,str(object.id)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the classid from file.", "response": "def read(self,file):\n        \"\"\"Read DX field from file.\n\n            dx = OpenDX.field.read(dxfile)\n\n        The classid is discarded and replaced with the one from the file.\n        \"\"\"\n        DXfield = self\n        p = DXParser(file)\n        p.parse(DXfield)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef histogramdd(self):\n        shape = self.components['positions'].shape\n        edges = self.components['positions'].edges()\n        hist = self.components['data'].array.reshape(shape)\n        return (hist,edges)", "response": "Return array data as ( edges grid ) i. e. a numpy nD histogram."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef value(self,ascode=None):\n        if ascode is None:\n            ascode = self.code\n        return self.cast[ascode](self.text)", "response": "Return text cast to the correct type or the selected type"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing the corresponding DXclass from the data.", "response": "def initialize(self):\n        \"\"\"Initialize the corresponding DXclass from the data.\n\n        class = DXInitObject.initialize()\n        \"\"\"\n        return self.DXclasses[self.type](self.id,**self.args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(self,DXfield):\n\n        self.DXfield = DXfield              # OpenDX.field (used by comment parser)\n        self.currentobject = None           # containers for data\n        self.objects = []                   # |\n        self.tokens = []                    # token buffer\n        with open(self.filename,'r') as self.dxfile:\n            self.use_parser('general')      # parse the whole file and populate self.objects\n\n        # assemble field from objects\n        for o in self.objects:\n            if o.type == 'field':\n                # Almost ignore the field object; VMD, for instance,\n                # does not write components. To make this work\n                # seamlessly I have to think harder how to organize\n                # and use the data, eg preping the field object\n                # properly and the initializing. Probably should also\n                # check uniqueness of ids etc.\n                DXfield.id = o.id\n                continue\n            c = o.initialize()\n            self.DXfield.add(c.component,c)\n\n        # free space\n        del self.currentobject, self.objects", "response": "Parse the dx file and construct a DXField object with component classes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __general(self):\n        while 1:                            # main loop\n            try:\n                tok = self.__peek()         # only peek, apply_parser() will consume\n            except DXParserNoTokens:\n                # save previous DXInitObject\n                # (kludge in here as the last level-2 parser usually does not return\n                # via the object parser)\n                if self.currentobject and self.currentobject not in self.objects:\n                    self.objects.append(self.currentobject)\n                return                      # stop parsing and finish\n            # decision branches for all level-1 parsers:\n            # (the only way to get out of the lower level parsers!)\n            if tok.iscode('COMMENT'):\n                self.set_parser('comment')  # switch the state\n            elif tok.iscode('WORD') and tok.equals('object'):\n                self.set_parser('object')   # switch the state\n            elif self.__parser is self.__general:\n                # Either a level-2 parser screwed up or some level-1\n                # construct is not implemented.  (Note: this elif can\n                # be only reached at the beginning or after comments;\n                # later we never formally switch back to __general\n                # (would create inifinite loop)\n                raise DXParseError('Unknown level-1 construct at '+str(tok))\n\n            self.apply_parser()", "response": "Level - 1 parser and main loop."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlevels - 1 parser for comments. pattern", "response": "def __comment(self):\n        \"\"\"Level-1 parser for comments.\n\n        pattern: #.*\n        Append comment (with initial '# ' stripped) to all comments.\n        \"\"\"\n        tok = self.__consume()\n        self.DXfield.add_comment(tok.value())\n        self.set_parser('general')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __object(self):\n        self.__consume()                    # 'object'\n        classid = self.__consume().text\n        word = self.__consume().text\n        if word != \"class\":\n            raise DXParseError(\"reserved word %s should have been 'class'.\" % word)\n        # save previous DXInitObject\n        if self.currentobject:\n            self.objects.append(self.currentobject)\n        # setup new DXInitObject\n        classtype = self.__consume().text\n        self.currentobject = DXInitObject(classtype=classtype,classid=classid)\n\n        self.use_parser(classtype)", "response": "Level-1 parser for objects.\n\n        pattern: 'object' id 'class' type ...\n\n        id ::=   integer|string|'\"'white space string'\"'\n        type ::= string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nleveling - 2 parser for gridpositions.", "response": "def __gridpositions(self):\n        \"\"\"Level-2 parser for gridpositions.\n\n        pattern:\n        object 1 class gridpositions counts 97 93 99\n        origin -46.5 -45.5 -48.5\n        delta 1 0 0\n        delta 0 1 0\n        delta 0 0 1\n        \"\"\"\n        try:\n            tok = self.__consume()\n        except DXParserNoTokens:\n            return\n\n        if tok.equals('counts'):\n            shape = []\n            try:\n                while True:\n                    # raises exception if not an int\n                    self.__peek().value('INTEGER')\n                    tok = self.__consume()\n                    shape.append(tok.value('INTEGER'))\n            except (DXParserNoTokens, ValueError):\n                pass\n            if len(shape) == 0:\n                raise DXParseError('gridpositions: no shape parameters')\n            self.currentobject['shape'] = shape\n        elif tok.equals('origin'):\n            origin = []\n            try:\n                while (self.__peek().iscode('INTEGER') or\n                       self.__peek().iscode('REAL')):\n                    tok = self.__consume()\n                    origin.append(tok.value())\n            except DXParserNoTokens:\n                pass\n            if len(origin) == 0:\n                raise DXParseError('gridpositions: no origin parameters')\n            self.currentobject['origin'] = origin\n        elif tok.equals('delta'):\n            d = []\n            try:\n                while (self.__peek().iscode('INTEGER') or\n                       self.__peek().iscode('REAL')):\n                    tok = self.__consume()\n                    d.append(tok.value())\n            except DXParserNoTokens:\n                pass\n            if len(d) == 0:\n                raise DXParseError('gridpositions: missing delta parameters')\n            try:\n                self.currentobject['delta'].append(d)\n            except KeyError:\n                self.currentobject['delta'] = [d]\n        else:\n            raise DXParseError('gridpositions: '+str(tok)+' not recognized.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlevels - 2 parser for gridconnections.", "response": "def __gridconnections(self):\n        \"\"\"Level-2 parser for gridconnections.\n\n        pattern:\n        object 2 class gridconnections counts 97 93 99\n        \"\"\"\n        try:\n            tok = self.__consume()\n        except DXParserNoTokens:\n            return\n\n        if tok.equals('counts'):\n            shape = []\n            try:\n                while True:\n                    # raises exception if not an int\n                    self.__peek().value('INTEGER')\n                    tok = self.__consume()\n                    shape.append(tok.value('INTEGER'))\n            except (DXParserNoTokens, ValueError):\n                pass\n            if len(shape) == 0:\n                raise DXParseError('gridconnections: no shape parameters')\n            self.currentobject['shape'] = shape\n        else:\n            raise DXParseError('gridconnections: '+str(tok)+' not recognized.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __array(self):\n        try:\n            tok = self.__consume()\n        except DXParserNoTokens:\n            return\n\n        if tok.equals('type'):\n            tok = self.__consume()\n            if not tok.iscode('STRING'):\n                raise DXParseError('array: type was \"%s\", not a string.'%\\\n                                   tok.text)\n            self.currentobject['type'] = tok.value()\n        elif tok.equals('rank'):\n            tok = self.__consume()\n            try:\n                self.currentobject['rank'] = tok.value('INTEGER')\n            except ValueError:\n                raise DXParseError('array: rank was \"%s\", not an integer.'%\\\n                                   tok.text)\n        elif tok.equals('items'):\n            tok = self.__consume()\n            try:\n                self.currentobject['size'] = tok.value('INTEGER')\n            except ValueError:\n                raise DXParseError('array: items was \"%s\", not an integer.'%\\\n                                   tok.text)\n        elif tok.equals('data'):\n            tok = self.__consume()\n            if not tok.iscode('STRING'):\n                raise DXParseError('array: data was \"%s\", not a string.'%\\\n                                   tok.text)\n            if tok.text != 'follows':\n                raise NotImplementedError(\\\n                            'array: Only the \"data follows header\" format is supported.')\n            if not self.currentobject['size']:\n                raise DXParseError(\"array: missing number of items\")\n            # This is the slow part.  Once we get here, we are just\n            # reading in a long list of numbers.  Conversion to floats\n            # will be done later when the numpy array is created.\n\n            # Don't assume anything about whitespace or the number of elements per row\n            self.currentobject['array'] = []\n            while len(self.currentobject['array']) <self.currentobject['size']:\n                 self.currentobject['array'].extend(self.dxfile.readline().strip().split())\n\n            # If you assume that there are three elements per row\n            # (except the last) the following version works and is a little faster.\n            # for i in range(int(numpy.ceil(self.currentobject['size']/3))):\n            #     self.currentobject['array'].append(self.dxfile.readline())\n            # self.currentobject['array'] = ' '.join(self.currentobject['array']).split()\n        elif tok.equals('attribute'):\n            # not used at the moment\n            attribute = self.__consume().value()\n            if not self.__consume().equals('string'):\n                raise DXParseError('array: \"string\" expected.')\n            value = self.__consume().value()\n        else:\n            raise DXParseError('array: '+str(tok)+' not recognized.')", "response": "Level - 2 parser for arrays."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a DX Field object.", "response": "def __field(self):\n        \"\"\"Level-2 parser for a DX field object.\n\n        pattern:\n        object \"site map 1\" class field\n        component \"positions\" value 1\n        component \"connections\" value 2\n        component \"data\" value 3\n        \"\"\"\n        try:\n            tok = self.__consume()\n        except DXParserNoTokens:\n            return\n\n        if tok.equals('component'):\n            component = self.__consume().value()\n            if not self.__consume().equals('value'):\n                raise DXParseError('field: \"value\" expected')\n            classid = self.__consume().value()\n            try:\n                self.currentobject['components'][component] = classid\n            except KeyError:\n                self.currentobject['components'] = {component:classid}\n        else:\n            raise DXParseError('field: '+str(tok)+' not recognized.')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting parsername as the current parser and apply it.", "response": "def use_parser(self,parsername):\n        \"\"\"Set parsername as the current parser and apply it.\"\"\"\n        self.__parser = self.parsers[parsername]\n        self.__parser()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __tokenize(self,string):\n        for m in self.dx_regex.finditer(string.strip()):\n            code = m.lastgroup\n            text = m.group(m.lastgroup)\n            tok = Token(code,text)\n            if not tok.iscode('WHITESPACE'):\n                 self.tokens.append(tok)", "response": "Splits s into tokens and update the token buffer."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __refill_tokenbuffer(self):\n        if len(self.tokens) == 0:\n            self.__tokenize(self.dxfile.readline())", "response": "Add a new tokenized line from the file to the token buffer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npopulating the instance from the plt file filename.", "response": "def read(self, filename):\n        \"\"\"Populate the instance from the plt file *filename*.\"\"\"\n        from struct import calcsize, unpack\n        if not filename is None:\n            self.filename = filename\n        with open(self.filename, 'rb') as plt:\n            h = self.header = self._read_header(plt)\n            nentries = h['nx'] * h['ny'] * h['nz']\n            # quick and dirty... slurp it all in one go\n            datafmt = h['bsaflag']+str(nentries)+self._data_bintype\n            a = numpy.array(unpack(datafmt, plt.read(calcsize(datafmt))))\n        self.header['filename'] = self.filename\n        self.array = a.reshape(h['nz'], h['ny'], h['nx']).transpose()  # unpack plt in reverse!!\n        self.delta = self._delta()\n        self.origin = numpy.array([h['xmin'], h['ymin'], h['zmin']]) + 0.5*numpy.diagonal(self.delta)\n        self.rank = h['rank']"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _read_header(self, pltfile):\n        nheader = struct.calcsize(self._headerfmt)\n        names = [r.key for r in self._header_struct]\n        binheader = pltfile.read(nheader)\n        def decode_header(bsaflag='@'):\n            h = dict(zip(names, struct.unpack(bsaflag+self._headerfmt, binheader)))\n            h['bsaflag'] = bsaflag\n            return h\n        for flag in '@=<>':\n            # try all endinaness and alignment options until we find something that looks sensible\n            header = decode_header(flag)\n            if header['rank'] == 3:\n                break   # only legal value according to spec\n            header = None\n        if header is None:\n            raise TypeError(\"Cannot decode header --- corrupted or wrong format?\")\n        for rec in self._header_struct:\n            if not rec.is_legal_dict(header):\n                warnings.warn(\"Key %s: Illegal value %r\" % (rec.key, header[rec.key]))\n        return header", "response": "Read the header bytes and return a dictionary of the header values."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ndmeshgrid(*arrs):\n    #arrs = tuple(reversed(arrs)) <-- wrong on stackoverflow.com\n    arrs = tuple(arrs)\n    lens = list(map(len, arrs))\n    dim = len(arrs)\n\n    sz = 1\n    for s in lens:\n        sz *= s\n\n    ans = []\n    for i, arr in enumerate(arrs):\n        slc = [1] * dim\n        slc[i] = lens[i]\n        arr2 = numpy.asanyarray(arr).reshape(slc)\n        for j, sz in enumerate(lens):\n            if j != i:\n                arr2 = arr2.repeat(sz, axis=j)\n        ans.append(arr2)\n\n    return tuple(ans)", "response": "Return a meshgrid for N dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resample(self, edges):\n        try:\n            edges = edges.edges  # can also supply another Grid\n        except AttributeError:\n            pass\n        midpoints = self._midpoints(edges)\n        coordinates = ndmeshgrid(*midpoints)\n        # feed a meshgrid to generate all points\n        newgrid = self.interpolated(*coordinates)\n        return self.__class__(newgrid, edges)", "response": "Resample data to a new grid with the given edges."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute and update all derived data for a specific entry.", "response": "def _update(self):\n        \"\"\"compute/update all derived data\n\n        Can be called without harm and is idem-potent.\n\n        Updates these attributes and methods:\n           :attr:`origin`\n              the center of the cell with index 0,0,0\n           :attr:`midpoints`\n              centre coordinate of each grid cell\n           :meth:`interpolated`\n              spline interpolation function that can generated a value for\n              coordinate\n        \"\"\"\n        self.delta = numpy.array(list(\n            map(lambda e: (e[-1] - e[0]) / (len(e) - 1), self.edges)))\n        self.midpoints = self._midpoints(self.edges)\n        self.origin = numpy.array(list(map(lambda m: m[0], self.midpoints)))\n        if self.__interpolated is not None:\n            # only update if we are using it\n            self.__interpolated = self._interpolationFunctionFactory()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef interpolated(self):\n        if self.__interpolated is None:\n            self.__interpolated = self._interpolationFunctionFactory()\n        return self.__interpolated", "response": "A function that returns the interpolated function over the data grid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(self, filename, file_format=None):\n        loader = self._get_loader(filename, file_format=file_format)\n        loader(filename)", "response": "Load a saved ( pickled or dx grid and edges from a file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _load_cpp4(self, filename):\n        ccp4 = CCP4.CCP4()\n        ccp4.read(filename)\n        grid, edges = ccp4.histogramdd()\n        self.__init__(grid=grid, edges=edges, metadata=self.metadata)", "response": "Initializes Grid from a CCP4 file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize a Grid from a OpenDX file.", "response": "def _load_dx(self, filename):\n        \"\"\"Initializes Grid from a OpenDX file.\"\"\"\n        dx = OpenDX.field(0)\n        dx.read(filename)\n        grid, edges = dx.histogramdd()\n        self.__init__(grid=grid, edges=edges, metadata=self.metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _load_plt(self, filename):\n        g = gOpenMol.Plt()\n        g.read(filename)\n        grid, edges = g.histogramdd()\n        self.__init__(grid=grid, edges=edges, metadata=self.metadata)", "response": "Initialize Grid from gOpenMol plt file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexport density to file using the given format.", "response": "def export(self, filename, file_format=None, type=None, typequote='\"'):\n        \"\"\"export density to file using the given format.\n\n        The format can also be deduced from the suffix of the filename\n        though the *format* keyword takes precedence.\n\n        The default format for export() is 'dx'.  Use 'dx' for\n        visualization.\n\n        Implemented formats:\n\n        dx\n            :mod:`OpenDX`\n        pickle\n            pickle (use :meth:`Grid.load` to restore); :meth:`Grid.save`\n            is simpler than ``export(format='python')``.\n\n        Parameters\n        ----------\n\n        filename : str\n            name of the output file\n\n        file_format : {'dx', 'pickle', None} (optional)\n            output file format, the default is \"dx\"\n\n        type : str (optional)\n            for DX, set the output DX array type, e.g., \"double\" or \"float\".\n            By default (``None``), the DX type is determined from the numpy\n            dtype of the array of the grid (and this will typically result in\n            \"double\").\n\n            .. versionadded:: 0.4.0\n\n        typequote : str (optional)\n            For DX, set the character used to quote the type string;\n            by default this is a double-quote character, '\"'.\n            Custom parsers like the one from NAMD-GridForces (backend for MDFF)\n            expect no quotes, and typequote='' may be used to appease them.\n\n            .. versionadded:: 0.5.0\n\n        \"\"\"\n        exporter = self._get_exporter(filename, file_format=file_format)\n        exporter(filename, type=type, typequote=typequote)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexport the grid object to a file.", "response": "def _export_python(self, filename, **kwargs):\n        \"\"\"Pickle the Grid object\n\n        The object is dumped as a dictionary with grid and edges: This\n        is sufficient to recreate the grid object with __init__().\n        \"\"\"\n        data = dict(grid=self.grid, edges=self.edges, metadata=self.metadata)\n        with open(filename, 'wb') as f:\n            cPickle.dump(data, f, cPickle.HIGHEST_PROTOCOL)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexports the density grid to an OpenDX file.", "response": "def _export_dx(self, filename, type=None, typequote='\"', **kwargs):\n        \"\"\"Export the density grid to an OpenDX file.\n\n        The file format is the simplest regular grid array and it is\n        also understood by VMD's and Chimera's DX reader; PyMOL\n        requires the dx `type` to be set to \"double\".\n\n        For the file format see\n        http://opendx.sdsc.edu/docs/html/pages/usrgu068.htm#HDREDF\n\n        \"\"\"\n        root, ext = os.path.splitext(filename)\n        filename = root + '.dx'\n\n        comments = [\n            'OpenDX density file written by gridDataFormats.Grid.export()',\n            'File format: http://opendx.sdsc.edu/docs/html/pages/usrgu068.htm#HDREDF',\n            'Data are embedded in the header and tied to the grid positions.',\n            'Data is written in C array order: In grid[x,y,z] the axis z is fastest',\n            'varying, then y, then finally x, i.e. z is the innermost loop.'\n        ]\n\n        # write metadata in comments section\n        if self.metadata:\n            comments.append('Meta data stored with the python Grid object:')\n        for k in self.metadata:\n            comments.append('   ' + str(k) + ' = ' + str(self.metadata[k]))\n        comments.append(\n            '(Note: the VMD dx-reader chokes on comments below this line)')\n\n        components = dict(\n            positions=OpenDX.gridpositions(1, self.grid.shape, self.origin,\n                                           self.delta),\n            connections=OpenDX.gridconnections(2, self.grid.shape),\n            data=OpenDX.array(3, self.grid, type=type, typequote=typequote),\n        )\n        dx = OpenDX.field('density', components=components, comments=comments)\n        dx.write(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the coordinates of the centers of all grid cells as an an iterator.", "response": "def centers(self):\n        \"\"\"Returns the coordinates of the centers of all grid cells as an\n        iterator.\"\"\"\n        for idx in numpy.ndindex(self.grid.shape):\n            yield self.delta * numpy.array(idx) + self.origin"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_compatible(self, other):\n        if not (numpy.isreal(other) or self == other):\n            raise TypeError(\n                \"The argument can not be arithmetically combined with the grid. \"\n                \"It must be a scalar or a grid with identical edges. \"\n                \"Use Grid.resample(other.edges) to make a new grid that is \"\n                \"compatible with other.\")\n        return True", "response": "Checks if self and other are compatible with the grid."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _interpolationFunctionFactory(self, spline_order=None, cval=None):\n        # for scipy >=0.9: should use scipy.interpolate.griddata\n        # http://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.griddata.html#scipy.interpolate.griddata\n        # (does it work for nD?)\n        import scipy.ndimage\n\n        if spline_order is None:\n            # must be compatible with whatever :func:`scipy.ndimage.spline_filter` takes.\n            spline_order = self.interpolation_spline_order\n        if cval is None:\n            cval = self.interpolation_cval\n\n        data = self.grid\n        if cval is None:\n            cval = data.min()\n        try:\n            # masked arrays, fill with min: should keep spline happy\n            _data = data.filled(cval)\n        except AttributeError:\n            _data = data\n\n        coeffs = scipy.ndimage.spline_filter(_data, order=spline_order)\n        x0 = self.origin\n        dx = self.delta\n\n        def _transform(cnew, c0, dc):\n            return (numpy.atleast_1d(cnew) - c0) / dc\n\n        def interpolatedF(*coordinates):\n            \"\"\"B-spline function over the data grid(x,y,z).\n\n            interpolatedF([x1,x2,...],[y1,y2,...],[z1,z2,...]) -> F[x1,y1,z1],F[x2,y2,z2],...\n\n            Example usage for resampling::\n              >>> XX,YY,ZZ = numpy.mgrid[40:75:0.5, 96:150:0.5, 20:50:0.5]\n              >>> FF = _interpolationFunction(XX,YY,ZZ)\n            \"\"\"\n            _coordinates = numpy.array(\n                [_transform(coordinates[i], x0[i], dx[i]) for i in range(len(\n                    coordinates))])\n            return scipy.ndimage.map_coordinates(coeffs,\n                                                 _coordinates,\n                                                 prefilter=False,\n                                                 mode='nearest',\n                                                 cval=cval)\n        # mode='wrap' would be ideal but is broken: https://github.com/scipy/scipy/issues/1323\n        return interpolatedF", "response": "Returns a function F that interpolates any values on the grid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read(self, filename):\n        if filename is not None:\n            self.filename = filename\n        with open(self.filename, 'rb') as ccp4:\n            h = self.header = self._read_header(ccp4)\n            nentries = h['nc'] * h['nr'] * h['ns']\n            # Quick and dirty... slurp it all in one go.\n            datafmt = h['bsaflag'] + str(nentries) + self._data_bintype\n            a = np.array(struct.unpack(datafmt, ccp4.read(struct.calcsize(datafmt))))\n        self.header['filename'] = self.filename\n        # TODO: Account for the possibility that y-axis is fastest or\n        # slowest index, which unfortunately is possible in CCP4.\n        order = 'C' if h['mapc'] == 'z' else 'F'\n        self.array = a.reshape(h['nc'], h['nr'], h['ns'], order=order)\n        self.delta = self._delta()\n        self.origin = np.zeros(3)\n        self.rank = 3", "response": "Populate the instance from the ccp4 file filename."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _detect_byteorder(ccp4file):\n        bsaflag = None\n        ccp4file.seek(52 * 4)\n        mapbin = ccp4file.read(4)\n        for flag in '@=<>':\n            mapstr = struct.unpack(flag + '4s', mapbin)[0].decode('utf-8')\n            if mapstr.upper() == 'MAP ':\n                bsaflag = flag\n                break  # Only possible value according to spec.\n        else:\n            raise TypeError(\n                \"Cannot decode header --- corrupted or wrong format?\")\n        ccp4file.seek(0)\n        return bsaflag", "response": "Detect the byteorder of stream ccp4file and return format character."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _read_header(self, ccp4file):\n\n        bsaflag = self._detect_byteorder(ccp4file)\n\n        # Parse the top of the header (4-byte words, 1 to 25).\n        nheader = struct.calcsize(self._headerfmt)\n        names = [r.key for r in self._header_struct]\n        bintopheader = ccp4file.read(25 * 4)\n\n        def decode_header(header, bsaflag='@'):\n            h = dict(zip(names, struct.unpack(bsaflag + self._headerfmt,\n                                              header)))\n            h['bsaflag'] = bsaflag\n            return h\n\n        header = decode_header(bintopheader, bsaflag)\n        for rec in self._header_struct:\n            if not rec.is_legal_dict(header):\n                warnings.warn(\n                    \"Key %s: Illegal value %r\" % (rec.key, header[rec.key]))\n\n        # Parse the latter half of the header (4-byte words, 26 to 256).\n        if (header['lskflg']):\n            skewmatrix = np.fromfile(ccp4file, dtype=np.float32, count=9)\n            header['skwmat'] = skewmatrix.reshape((3, 3))\n            header['skwtrn'] = np.fromfile(ccp4file, dtype=np.float32, count=3)\n        else:\n            header['skwmat'] = header['skwtrn'] = None\n            ccp4file.seek(12 * 4, 1)\n        ccp4file.seek(15 * 4, 1)  # Skip future use section.\n        ccp4file.seek(4, 1)  # Skip map text, already used above to verify format.\n        # TODO: Compare file specified endianness to one obtained above.\n        endiancode = struct.unpack(bsaflag + '4b', ccp4file.read(4))\n        header['endianness'] = 'little' if endiancode == (0x44, 0x41, 0, 0\n                                                          ) else 'big'\n        header['arms'] = struct.unpack(bsaflag + 'f', ccp4file.read(4))[0]\n        header['nlabl'] = struct.unpack(bsaflag + 'I', ccp4file.read(4))[0]\n        if header['nlabl']:\n            binlabel = ccp4file.read(80 * header['nlabl'])\n            flag = bsaflag + str(80 * header['nlabl']) + 's'\n            label = struct.unpack(flag, binlabel)[0]\n            header['label'] = label.decode('utf-8').rstrip('\\x00')\n        else:\n            header['label'] = None\n        ccp4file.seek(256 * 4)\n        # TODO: Parse symmetry records, if any.\n        return header", "response": "Read the header bytes and return a tuple of the class ID and the header bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_data(self, **kwargs):\n        limit = int(kwargs.get('limit', 288))\n        end_date = kwargs.get('end_date', False)\n\n        if end_date and isinstance(end_date, datetime.datetime):\n            end_date = self.convert_datetime(end_date)\n\n        if self.mac_address is not None:\n            service_address = 'devices/%s' % self.mac_address\n            self.api_instance.log('SERVICE ADDRESS: %s' % service_address)\n\n            data = dict(limit=limit)\n\n            # If endDate is left blank (not passed in), the most recent results will be returned.\n            if end_date:\n                data.update({'endDate': end_date})\n\n            self.api_instance.log('DATA:')\n            self.api_instance.log(data)\n\n            return self.api_instance.api_call(service_address, **data)", "response": "Get the data for a specific device for a specific end date"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_devices(self):\n        retn = []\n        api_devices = self.api_call('devices')\n\n        self.log('DEVICES:')\n        self.log(api_devices)\n\n        for device in api_devices:\n            retn.append(AmbientWeatherStation(self, device))\n\n        self.log('DEVICE INSTANCE LIST:')\n        self.log(retn)\n\n        return retn", "response": "Get all devices in the system"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_url(self, path, params={}, opts={}):\n\n        if opts:\n            warnings.warn('`opts` has been deprecated. Use `params` instead.',\n                          DeprecationWarning, stacklevel=2)\n        params = params or opts\n        if self._shard_strategy == SHARD_STRATEGY_CRC:\n            crc = zlib.crc32(path.encode('utf-8')) & 0xffffffff\n            index = crc % len(self._domains)  # Deterministically choose domain\n            domain = self._domains[index]\n\n        elif self._shard_strategy == SHARD_STRATEGY_CYCLE:\n            domain = self._domains[self._shard_next_index]\n            self._shard_next_index = (\n                self._shard_next_index + 1) % len(self._domains)\n\n        else:\n            domain = self._domains[0]\n\n        scheme = \"https\" if self._use_https else \"http\"\n\n        url_obj = UrlHelper(\n            domain,\n            path,\n            scheme,\n            sign_key=self._sign_key,\n            include_library_param=self._include_library_param,\n            params=params)\n\n        return str(url_obj)", "response": "Create URL with supplied path and opts parameters dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets a url parameter.", "response": "def set_parameter(self, key, value):\n        \"\"\"\n        Set a url parameter.\n\n        Parameters\n        ----------\n        key : str\n            If key ends with '64', the value provided will be automatically\n            base64 encoded.\n        \"\"\"\n        if value is None or isinstance(value, (int, float, bool)):\n            value = str(value)\n\n        if key.endswith('64'):\n            value = urlsafe_b64encode(value.encode('utf-8'))\n            value = value.replace(b('='), b(''))\n\n        self._parameters[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting subscription manager for real time data.", "response": "async def rt_connect(self, loop):\n        \"\"\"Start subscription manager for real time data.\"\"\"\n        if self.sub_manager is not None:\n            return\n        self.sub_manager = SubscriptionManager(\n            loop, \"token={}\".format(self._access_token), SUB_ENDPOINT\n        )\n        self.sub_manager.start()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def update_info(self, *_):\n        query = gql(\n            \"\"\"\n        {\n          viewer {\n            name\n            homes {\n              subscriptions {\n                status\n              }\n              id\n            }\n          }\n        }\n        \"\"\"\n        )\n\n        res = await self._execute(query)\n        if res is None:\n            return\n        errors = res.get(\"errors\", [])\n        if errors:\n            msg = errors[0].get(\"message\", \"failed to login\")\n            _LOGGER.error(msg)\n            raise InvalidLogin(msg)\n\n        data = res.get(\"data\")\n        if not data:\n            return\n        viewer = data.get(\"viewer\")\n        if not viewer:\n            return\n        self._name = viewer.get(\"name\")\n        homes = viewer.get(\"homes\", [])\n        self._home_ids = []\n        for _home in homes:\n            home_id = _home.get(\"id\")\n            self._all_home_ids += [home_id]\n            subs = _home.get(\"subscriptions\")\n            if subs:\n                status = subs[0].get(\"status\", \"ended\").lower()\n                if not home_id or status != \"running\":\n                    continue\n            self._home_ids += [home_id]", "response": "Update home info async."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn list of Tibber homes.", "response": "def get_homes(self, only_active=True):\n        \"\"\"Return list of Tibber homes.\"\"\"\n        return [self.get_home(home_id) for home_id in self.get_home_ids(only_active)]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def send_notification(self, title, message):\n        query = gql(\n            \"\"\"\n        mutation{\n          sendPushNotification(input: {\n            title: \"%s\",\n            message: \"%s\",\n          }){\n            successful\n            pushedToNumberOfDevices\n          }\n        }\n        \"\"\"\n            % (title, message)\n        )\n\n        res = await self.execute(query)\n        if not res:\n            return False\n        noti = res.get(\"sendPushNotification\", {})\n        successful = noti.get(\"successful\", False)\n        pushed_to_number_of_devices = noti.get(\"pushedToNumberOfDevices\", 0)\n        _LOGGER.debug(\n            \"send_notification: status %s, send to %s devices\",\n            successful,\n            pushed_to_number_of_devices,\n        )\n        return successful", "response": "Send a notification to the specified user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate current price info async.", "response": "async def update_info(self):\n        \"\"\"Update current price info async.\"\"\"\n        query = gql(\n            \"\"\"\n        {\n          viewer {\n            home(id: \"%s\") {\n              appNickname\n              features {\n                  realTimeConsumptionEnabled\n                }\n              currentSubscription {\n                status\n              }\n              address {\n                address1\n                address2\n                address3\n                city\n                postalCode\n                country\n                latitude\n                longitude\n              }\n              meteringPointData {\n                consumptionEan\n                energyTaxType\n                estimatedAnnualConsumption\n                gridCompany\n                productionEan\n                vatType\n              }\n              owner {\n                name\n                isCompany\n                language\n                contactInfo {\n                  email\n                  mobile\n                }\n              }\n              timeZone\n              subscriptions {\n                id\n                status\n                validFrom\n                validTo\n                statusReason\n              }\n             currentSubscription {\n                    priceInfo {\n                      current {\n                        currency\n                      }\n                    }\n                  }\n                }\n              }\n            }\n        \"\"\"\n            % self._home_id\n        )\n        self.info = await self._tibber_control.execute(query)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating current price info.", "response": "def sync_update_current_price_info(self):\n        \"\"\"Update current price info.\"\"\"\n        loop = asyncio.get_event_loop()\n        task = loop.create_task(self.update_current_price_info())\n        loop.run_until_complete(task)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def update_current_price_info(self):\n        query = gql(\n            \"\"\"\n        {\n          viewer {\n            home(id: \"%s\") {\n              currentSubscription {\n                priceInfo {\n                  current {\n                    energy\n                    tax\n                    total\n                    startsAt\n                  }\n                }\n              }\n            }\n          }\n        }\n        \"\"\"\n            % self.home_id\n        )\n        price_info_temp = await self._tibber_control.execute(query)\n        if not price_info_temp:\n            _LOGGER.error(\"Could not find current price info.\")\n            return\n        try:\n            home = price_info_temp[\"viewer\"][\"home\"]\n            current_subscription = home[\"currentSubscription\"]\n            price_info = current_subscription[\"priceInfo\"][\"current\"]\n        except (KeyError, TypeError):\n            _LOGGER.error(\"Could not find current price info.\")\n            return\n        if price_info:\n            self._current_price_info = price_info", "response": "Update the current price info."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating current price info.", "response": "def sync_update_price_info(self):\n        \"\"\"Update current price info.\"\"\"\n        loop = asyncio.get_event_loop()\n        task = loop.create_task(self.update_price_info())\n        loop.run_until_complete(task)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def update_price_info(self):\n        query = gql(\n            \"\"\"\n        {\n          viewer {\n            home(id: \"%s\") {\n              currentSubscription {\n                priceInfo {\n                  current {\n                    energy\n                    tax\n                    total\n                    startsAt\n                    level\n                  }\n                  today {\n                    total\n                    startsAt\n                    level\n                  }\n                  tomorrow {\n                    total\n                    startsAt\n                    level\n                  }\n                }\n              }\n            }\n          }\n        }\n        \"\"\"\n            % self.home_id\n        )\n        price_info_temp = await self._tibber_control.execute(query)\n        if not price_info_temp:\n            _LOGGER.error(\"Could not find price info.\")\n            return\n        self._price_info = {}\n        self._level_info = {}\n        for key in [\"current\", \"today\", \"tomorrow\"]:\n            try:\n                home = price_info_temp[\"viewer\"][\"home\"]\n                current_subscription = home[\"currentSubscription\"]\n                price_info = current_subscription[\"priceInfo\"][key]\n            except (KeyError, TypeError):\n                _LOGGER.error(\"Could not find price info for %s.\", key)\n                continue\n            if key == \"current\":\n                self._current_price_info = price_info\n                continue\n            for data in price_info:\n                self._price_info[data.get(\"startsAt\")] = data.get(\"total\")\n                self._level_info[data.get(\"startsAt\")] = data.get(\"level\")", "response": "Update internal state of price info."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef price_unit(self):\n        currency = self.currency\n        consumption_unit = self.consumption_unit\n        if not currency or not consumption_unit:\n            _LOGGER.error(\"Could not find price_unit.\")\n            return \" \"\n        return currency + \"/\" + consumption_unit", "response": "Return the price unit."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def rt_subscribe(self, loop, async_callback):\n        if self._subscription_id is not None:\n            _LOGGER.error(\"Already subscribed.\")\n            return\n        await self._tibber_control.rt_connect(loop)\n        document = gql(\n            \"\"\"\n            subscription{\n              liveMeasurement(homeId:\"%s\"){\n                timestamp\n                power\n                powerProduction\n                accumulatedProduction\n                accumulatedConsumption\n                accumulatedCost\n                currency\n                minPower\n                averagePower\n                maxPower\n                voltagePhase1\n                voltagePhase2\n                voltagePhase3\n                currentPhase1\n                currentPhase2\n                currentPhase3\n                lastMeterConsumption\n                lastMeterProduction\n            }\n           }\n        \"\"\"\n            % self.home_id\n        )\n        sub_query = print_ast(document)\n\n        self._subscription_id = await self._tibber_control.sub_manager.subscribe(\n            sub_query, async_callback\n        )", "response": "Connect to Tibber and subscribe to RT subscription."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def rt_unsubscribe(self):\n        if self._subscription_id is None:\n            _LOGGER.error(\"Not subscribed.\")\n            return\n        await self._tibber_control.sub_manager.unsubscribe(self._subscription_id)", "response": "Unsubscribe to Tibber rt subscription."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rt_subscription_running(self):\n        return (\n            self._tibber_control.sub_manager is not None\n            and self._tibber_control.sub_manager.is_running\n            and self._subscription_id is not None\n        )", "response": "Is real time subscription running?"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def get_historic_data(self, n_data):\n        query = gql(\n            \"\"\"\n                {\n                  viewer {\n                    home(id: \"%s\") {\n                      consumption(resolution: HOURLY, last: %s) {\n                        nodes {\n                          from\n                          totalCost\n                          consumption\n                        }\n                      }\n                    }\n                  }\n                }\n          \"\"\"\n            % (self.home_id, n_data)\n        )\n        data = await self._tibber_control.execute(query)\n        if not data:\n            _LOGGER.error(\"Could not find current the data.\")\n            return\n        data = data[\"viewer\"][\"home\"][\"consumption\"]\n        if data is None:\n            self._data = []\n            return\n        self._data = data[\"nodes\"]", "response": "Get the historic data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cleanup_none(self):\n        for (prop, default) in self.defaults.items():\n            if getattr(self, prop) == '_None':\n                setattr(self, prop, None)", "response": "Removes the temporary value set for None attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds the execution environment.", "response": "def build_environ(self, sock_file, conn):\n        \"\"\" Build the execution environment. \"\"\"\n        # Grab the request line\n        request = self.read_request_line(sock_file)\n\n        # Copy the Base Environment\n        environ = self.base_environ.copy()\n\n        # Grab the headers\n        for k, v in self.read_headers(sock_file).items():\n            environ[str('HTTP_'+k)] = v\n\n        # Add CGI Variables\n        environ['REQUEST_METHOD'] = request['method']\n        environ['PATH_INFO'] = request['path']\n        environ['SERVER_PROTOCOL'] = request['protocol']\n        environ['SERVER_PORT'] = str(conn.server_port)\n        environ['REMOTE_PORT'] = str(conn.client_port)\n        environ['REMOTE_ADDR'] = str(conn.client_addr)\n        environ['QUERY_STRING'] = request['query_string']\n        if 'HTTP_CONTENT_LENGTH' in environ:\n            environ['CONTENT_LENGTH'] = environ['HTTP_CONTENT_LENGTH']\n        if 'HTTP_CONTENT_TYPE' in environ:\n            environ['CONTENT_TYPE'] = environ['HTTP_CONTENT_TYPE']\n\n        # Save the request method for later\n        self.request_method = environ['REQUEST_METHOD']\n\n        # Add Dynamic WSGI Variables\n        if conn.ssl:\n            environ['wsgi.url_scheme'] = 'https'\n            environ['HTTPS'] = 'on'\n        else:\n            environ['wsgi.url_scheme'] = 'http'\n\n        if environ.get('HTTP_TRANSFER_ENCODING', '') == 'chunked':\n            environ['wsgi.input'] = ChunkedReader(sock_file)\n        else:\n            environ['wsgi.input'] = sock_file\n\n        return environ"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite the data to the output socket.", "response": "def write(self, data, sections=None):\n        \"\"\" Write the data to the output socket. \"\"\"\n\n        if self.error[0]:\n            self.status = self.error[0]\n            data = b(self.error[1])\n\n        if not self.headers_sent:\n            self.send_headers(data, sections)\n\n        if self.request_method != 'HEAD':\n            try:\n                if self.chunked:\n                    self.conn.sendall(b('%x\\r\\n%s\\r\\n' % (len(data), data)))\n                else:\n                    self.conn.sendall(data)\n            except socket.timeout:\n                self.closeConnection = True\n            except socket.error:\n                # But some clients will close the connection before that\n                # resulting in a socket error.\n                self.closeConnection = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start_response(self, status, response_headers, exc_info=None):\n        if exc_info:\n            try:\n                if self.headers_sent:\n                    # Re-raise original exception if headers sent\n                    # because this violates WSGI specification.\n                    raise\n            finally:\n                exc_info = None\n        elif self.header_set:\n            raise AssertionError(\"Headers already set!\")\n\n        if PY3K and not isinstance(status, str):\n            self.status = str(status, 'ISO-8859-1')\n        else:\n            self.status = status\n        # Make sure headers are bytes objects\n        try:\n            self.header_set = Headers(response_headers)\n        except UnicodeDecodeError:\n            self.error = ('500 Internal Server Error',\n                          'HTTP Headers should be bytes')\n            self.err_log.error('Received HTTP Headers from client that contain'\n                               ' invalid characters for Latin-1 encoding.')\n\n        return self.write_warning", "response": "Store the HTTP status and headers to be sent when self. write is called."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_bgp_neighbors(self):\n        def generate_vrf_query(vrf_name):\n            \"\"\"\n            Helper to provide XML-query for the VRF-type we're interested in.\n            \"\"\"\n            if vrf_name == \"global\":\n                rpc_command = '<Get><Operational><BGP><InstanceTable><Instance><Naming>\\\n                <InstanceName>default</InstanceName></Naming><InstanceActive><DefaultVRF>\\\n                <GlobalProcessInfo></GlobalProcessInfo><NeighborTable></NeighborTable></DefaultVRF>\\\n                </InstanceActive></Instance></InstanceTable></BGP></Operational></Get>'\n\n            else:\n                rpc_command = '<Get><Operational><BGP><InstanceTable><Instance><Naming>\\\n                <InstanceName>default</InstanceName></Naming><InstanceActive><VRFTable><VRF>\\\n                <Naming>{vrf_name}</Naming><GlobalProcessInfo></GlobalProcessInfo><NeighborTable>\\\n                </NeighborTable></VRF></VRFTable></InstanceActive></Instance></InstanceTable>\\\n                </BGP></Operational></Get>'.format(vrf_name=vrf_name)\n            return rpc_command\n\n        \"\"\"\n        Initial run to figure out what VRF's are available\n        Decided to get this one from Configured-section\n        because bulk-getting all instance-data to do the same could get ridiculously heavy\n        Assuming we're always interested in the DefaultVRF\n        \"\"\"\n\n        active_vrfs = [\"global\"]\n\n        rpc_command = '<Get><Operational><BGP><ConfigInstanceTable><ConfigInstance><Naming>\\\n        <InstanceName>default</InstanceName></Naming><ConfigInstanceVRFTable>\\\n        </ConfigInstanceVRFTable></ConfigInstance></ConfigInstanceTable></BGP></Operational></Get>'\n\n        result_tree = ETREE.fromstring(self.device.make_rpc_call(rpc_command))\n\n        for node in result_tree.xpath('.//ConfigVRF'):\n            active_vrfs.append(napalm_base.helpers.find_txt(node, 'Naming/VRFName'))\n\n        result = {}\n\n        for vrf in active_vrfs:\n            rpc_command = generate_vrf_query(vrf)\n            result_tree = ETREE.fromstring(self.device.make_rpc_call(rpc_command))\n\n            this_vrf = {}\n            this_vrf['peers'] = {}\n\n            if vrf == \"global\":\n                this_vrf['router_id'] = napalm_base.helpers.convert(\n                    text_type, napalm_base.helpers.find_txt(result_tree,\n                        'Get/Operational/BGP/InstanceTable/Instance/InstanceActive/DefaultVRF\\\n                        /GlobalProcessInfo/VRF/RouterID'))\n            else:\n                this_vrf['router_id'] = napalm_base.helpers.convert(\n                    text_type, napalm_base.helpers.find_txt(result_tree,\n                        'Get/Operational/BGP/InstanceTable/Instance/InstanceActive/VRFTable/VRF\\\n                        /GlobalProcessInfo/VRF/RouterID'))\n\n            neighbors = {}\n\n            for neighbor in result_tree.xpath('.//Neighbor'):\n                this_neighbor = {}\n                this_neighbor['local_as'] = napalm_base.helpers.convert(\n                    int, napalm_base.helpers.find_txt(neighbor, 'LocalAS'))\n                this_neighbor['remote_as'] = napalm_base.helpers.convert(\n                    int, napalm_base.helpers.find_txt(neighbor, 'RemoteAS'))\n                this_neighbor['remote_id'] = napalm_base.helpers.convert(\n                    text_type, napalm_base.helpers.find_txt(neighbor, 'RouterID'))\n\n                if napalm_base.helpers.find_txt(neighbor, 'ConnectionAdminStatus') is \"1\":\n                    this_neighbor['is_enabled'] = True\n                try:\n                    this_neighbor['description'] = napalm_base.helpers.convert(\n                        text_type, napalm_base.helpers.find_txt(neighbor, 'Description'))\n                except AttributeError:\n                    this_neighbor['description'] = u''\n\n                this_neighbor['is_enabled'] = (\n                    napalm_base.helpers.find_txt(neighbor, 'ConnectionAdminStatus') == \"1\")\n\n                if str(napalm_base.helpers.find_txt(neighbor, 'ConnectionAdminStatus')) is \"1\":\n                    this_neighbor['is_enabled'] = True\n                else:\n                    this_neighbor['is_enabled'] = False\n\n                if str(napalm_base.helpers.find_txt(neighbor, 'ConnectionState')) == \"BGP_ST_ESTAB\":\n                    this_neighbor['is_up'] = True\n                    this_neighbor['uptime'] = napalm_base.helpers.convert(\n                        int, napalm_base.helpers.find_txt(neighbor, 'ConnectionEstablishedTime'))\n                else:\n                    this_neighbor['is_up'] = False\n                    this_neighbor['uptime'] = -1\n\n                this_neighbor['address_family'] = {}\n\n                if napalm_base.helpers.find_txt(neighbor,\n                'ConnectionRemoteAddress/AFI') == \"IPv4\":\n                    this_afi = \"ipv4\"\n                elif napalm_base.helpers.find_txt(neighbor,\n                'ConnectionRemoteAddress/AFI') == \"IPv6\":\n                    this_afi = \"ipv6\"\n                else:\n                    this_afi = napalm_base.helpers.find_txt(neighbor, 'ConnectionRemoteAddress/AFI')\n\n                this_neighbor['address_family'][this_afi] = {}\n\n                try:\n                    this_neighbor['address_family'][this_afi][\"received_prefixes\"] = \\\n                        napalm_base.helpers.convert(int,\n                            napalm_base.helpers.find_txt(\n                                neighbor, 'AFData/Entry/PrefixesAccepted'), 0) + \\\n                        napalm_base.helpers.convert(int,\n                            napalm_base.helpers.find_txt(\n                                neighbor, 'AFData/Entry/PrefixesDenied'), 0)\n                    this_neighbor['address_family'][this_afi][\"accepted_prefixes\"] = \\\n                        napalm_base.helpers.convert(int,\n                            napalm_base.helpers.find_txt(\n                                neighbor, 'AFData/Entry/PrefixesAccepted'), 0)\n                    this_neighbor['address_family'][this_afi][\"sent_prefixes\"] = \\\n                        napalm_base.helpers.convert(int,\n                            napalm_base.helpers.find_txt(\n                                neighbor, 'AFData/Entry/PrefixesAdvertised'), 0)\n                except AttributeError:\n                    this_neighbor['address_family'][this_afi][\"received_prefixes\"] = -1\n                    this_neighbor['address_family'][this_afi][\"accepted_prefixes\"] = -1\n                    this_neighbor['address_family'][this_afi][\"sent_prefixes\"] = -1\n\n                neighbor_ip = napalm_base.helpers.ip(\n                    napalm_base.helpers.find_txt(\n                        neighbor, 'Naming/NeighborAddress/IPV4Address') or\n                    napalm_base.helpers.find_txt(\n                        neighbor, 'Naming/NeighborAddress/IPV6Address')\n                )\n\n                neighbors[neighbor_ip] = this_neighbor\n\n            this_vrf['peers'] = neighbors\n            result[vrf] = this_vrf\n\n        return result", "response": "Get all BGP neighbors for this instance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\naggregating a list of prefixes.", "response": "def aggregate(l):\n    \"\"\"Aggregate a `list` of prefixes.\n\n    Keyword arguments:\n    l -- a python list of prefixes\n\n    Example use:\n    >>> aggregate([\"10.0.0.0/8\", \"10.0.0.0/24\"])\n    ['10.0.0.0/8']\n    \"\"\"\n    tree = radix.Radix()\n    for item in l:\n        try:\n            tree.add(item)\n        except (ValueError) as err:\n            raise Exception(\"ERROR: invalid IP prefix: {}\".format(item))\n\n    return aggregate_tree(tree).prefixes()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef aggregate_tree(l_tree):\n\n    def _aggregate_phase1(tree):\n        # phase1 removes any supplied prefixes which are superfluous because\n        # they are already included in another supplied prefix. For example,\n        # 2001:67c:208c:10::/64 would be removed if 2001:67c:208c::/48 was\n        # also supplied.\n        n_tree = radix.Radix()\n        for prefix in tree.prefixes():\n            if tree.search_worst(prefix).prefix == prefix:\n                n_tree.add(prefix)\n        return n_tree\n\n    def _aggregate_phase2(tree):\n        # phase2 identifies adjacent prefixes that can be combined under a\n        # single, shorter-length prefix. For example, 2001:67c:208c::/48 and\n        # 2001:67c:208d::/48 can be combined into the single prefix\n        # 2001:67c:208c::/47.\n        n_tree = radix.Radix()\n        for rnode in tree:\n            p = text(ip_network(text(rnode.prefix)).supernet())\n            r = tree.search_covered(p)\n            if len(r) == 2:\n                if r[0].prefixlen == r[1].prefixlen == rnode.prefixlen:\n                    n_tree.add(p)\n                else:\n                    n_tree.add(rnode.prefix)\n            else:\n                n_tree.add(rnode.prefix)\n        return n_tree\n\n    l_tree = _aggregate_phase1(l_tree)\n\n    if len(l_tree.prefixes()) == 1:\n        return l_tree\n\n    while True:\n        r_tree = _aggregate_phase2(l_tree)\n        if l_tree.prefixes() == r_tree.prefixes():\n            break\n        else:\n            l_tree = r_tree\n            del r_tree\n\n    return l_tree", "response": "Walk a py - radix tree and aggregate it."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _ratio_metric(v1, v2, **_kwargs):\n    return (((v1 - v2) / (v1 + v2)) ** 2) if v1 + v2 != 0 else 0", "response": "Metric for ratio data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the coincidences of a single resource in a single resource.", "response": "def _coincidences(value_counts, value_domain, dtype=np.float64):\n    \"\"\"Coincidence matrix.\n\n    Parameters\n    ----------\n    value_counts : ndarray, with shape (N, V)\n        Number of coders that assigned a certain value to a determined unit, where N is the number of units\n        and V is the value count.\n\n    value_domain : array_like, with shape (V,)\n        Possible values V the units can take.\n        If the level of measurement is not nominal, it must be ordered.\n\n    dtype : data-type\n        Result and computation data-type.\n\n    Returns\n    -------\n    o : ndarray, with shape (V, V)\n        Coincidence matrix.\n    \"\"\"\n    value_counts_matrices = value_counts.reshape(value_counts.shape + (1,))\n    pairable = np.maximum(np.sum(value_counts, axis=1), 2)\n    diagonals = np.tile(np.eye(len(value_domain)), (len(value_counts), 1, 1)) \\\n        * value_counts.reshape((value_counts.shape[0], 1, value_counts.shape[1]))\n    unnormalized_coincidences = value_counts_matrices * value_counts_matrices.transpose((0, 2, 1)) - diagonals\n    return np.sum(np.divide(unnormalized_coincidences, (pairable - 1).reshape((-1, 1, 1)), dtype=dtype), axis=0)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the distances of the different possible values.", "response": "def _distances(value_domain, distance_metric, n_v):\n    \"\"\"Distances of the different possible values.\n\n    Parameters\n    ----------\n    value_domain : array_like, with shape (V,)\n        Possible values V the units can take.\n        If the level of measurement is not nominal, it must be ordered.\n\n    distance_metric : callable\n        Callable that return the distance of two given values.\n\n    n_v : ndarray, with shape (V,)\n        Number of pairable elements for each value.\n\n    Returns\n    -------\n    d : ndarray, with shape (V, V)\n        Distance matrix for each value pair.\n    \"\"\"\n    return np.array([[distance_metric(v1, v2, i1=i1, i2=i2, n_v=n_v)\n                      for i2, v2 in enumerate(value_domain)]\n                     for i1, v1 in enumerate(value_domain)])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _reliability_data_to_value_counts(reliability_data, value_domain):\n    return np.array([[sum(1 for rate in unit if rate == v) for v in value_domain] for unit in reliability_data.T])", "response": "Return the value counts given the reliability data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef alpha(reliability_data=None, value_counts=None, value_domain=None, level_of_measurement='interval',\n          dtype=np.float64):\n    \"\"\"Compute Krippendorff's alpha.\n\n    See https://en.wikipedia.org/wiki/Krippendorff%27s_alpha for more information.\n\n    Parameters\n    ----------\n    reliability_data : array_like, with shape (M, N)\n        Reliability data matrix which has the rate the i coder gave to the j unit, where M is the number of raters\n        and N is the unit count.\n        Missing rates are represented with `np.nan`.\n        If it's provided then `value_counts` must not be provided.\n\n    value_counts : ndarray, with shape (N, V)\n        Number of coders that assigned a certain value to a determined unit, where N is the number of units\n        and V is the value count.\n        If it's provided then `reliability_data` must not be provided.\n\n    value_domain : array_like, with shape (V,)\n        Possible values the units can take.\n        If the level of measurement is not nominal, it must be ordered.\n        If `reliability_data` is provided, then the default value is the ordered list of unique rates that appear.\n        Else, the default value is `list(range(V))`.\n\n    level_of_measurement : string or callable\n        Steven's level of measurement of the variable.\n        It must be one of 'nominal', 'ordinal', 'interval', 'ratio' or a callable.\n\n    dtype : data-type\n        Result and computation data-type.\n\n    Returns\n    -------\n    alpha : `dtype`\n        Scalar value of Krippendorff's alpha of type `dtype`.\n\n    Examples\n    --------\n    >>> reliability_data = [[np.nan, np.nan, np.nan, np.nan, np.nan, 3, 4, 1, 2, 1, 1, 3, 3, np.nan, 3],\n    ...                     [1, np.nan, 2, 1, 3, 3, 4, 3, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan],\n    ...                     [np.nan, np.nan, 2, 1, 3, 4, 4, np.nan, 2, 1, 1, 3, 3, np.nan, 4]]\n    >>> print(round(alpha(reliability_data=reliability_data, level_of_measurement='nominal'), 6))\n    0.691358\n    >>> print(round(alpha(reliability_data=reliability_data, level_of_measurement='interval'), 6))\n    0.810845\n    >>> value_counts = np.array([[1, 0, 0, 0],\n    ...                          [0, 0, 0, 0],\n    ...                          [0, 2, 0, 0],\n    ...                          [2, 0, 0, 0],\n    ...                          [0, 0, 2, 0],\n    ...                          [0, 0, 2, 1],\n    ...                          [0, 0, 0, 3],\n    ...                          [1, 0, 1, 0],\n    ...                          [0, 2, 0, 0],\n    ...                          [2, 0, 0, 0],\n    ...                          [2, 0, 0, 0],\n    ...                          [0, 0, 2, 0],\n    ...                          [0, 0, 2, 0],\n    ...                          [0, 0, 0, 0],\n    ...                          [0, 0, 1, 1]])\n    >>> print(round(alpha(value_counts=value_counts, level_of_measurement='nominal'), 6))\n    0.691358\n    >>> # The following examples were extracted from\n    >>> # https://www.statisticshowto.datasciencecentral.com/wp-content/uploads/2016/07/fulltext.pdf, page 8.\n    >>> reliability_data = [[1, 2, 3, 3, 2, 1, 4, 1, 2, np.nan, np.nan, np.nan],\n    ...                     [1, 2, 3, 3, 2, 2, 4, 1, 2, 5, np.nan, 3.],\n    ...                     [np.nan, 3, 3, 3, 2, 3, 4, 2, 2, 5, 1, np.nan],\n    ...                     [1, 2, 3, 3, 2, 4, 4, 1, 2, 5, 1, np.nan]]\n    >>> print(round(alpha(reliability_data, level_of_measurement='ordinal'), 3))\n    0.815\n    >>> print(round(alpha(reliability_data, level_of_measurement='ratio'), 3))\n    0.797\n    \"\"\"\n    if (reliability_data is None) == (value_counts is None):\n        raise ValueError(\"Either reliability_data or value_counts must be provided, but not both.\")\n\n    # Don't know if it's a list or numpy array. If it's the latter, the truth value is ambiguous. So, ask for None.\n    if value_counts is None:\n        if type(reliability_data) is not np.ndarray:\n            reliability_data = np.array(reliability_data)\n\n        value_domain = value_domain or np.unique(reliability_data[~np.isnan(reliability_data)])\n\n        value_counts = _reliability_data_to_value_counts(reliability_data, value_domain)\n    else:  # elif reliability_data is None\n        if value_domain:\n            assert value_counts.shape[1] == len(value_domain), \\\n                \"The value domain should be equal to the number of columns of value_counts.\"\n        else:\n            value_domain = tuple(range(value_counts.shape[1]))\n\n    distance_metric = _distance_metric(level_of_measurement)\n\n    o = _coincidences(value_counts, value_domain, dtype=dtype)\n    n_v = np.sum(o, axis=0)\n    n = np.sum(n_v)\n    e = _random_coincidences(value_domain, n, n_v)\n    d = _distances(value_domain, distance_metric, n_v)\n    return 1 - np.sum(o * d) / np.sum(e * d)", "response": "Compute the alpha of a set of reliability data for a particular set of coders."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmaps to CDF_Inquire. inquire and returns pysatCDF instance. Not intended for regular direct use by user.", "response": "def inquire(self):\n        \"\"\"Maps to fortran CDF_Inquire.\n\n        Assigns parameters returned by CDF_Inquire\n        to pysatCDF instance. Not intended\n        for regular direct use by user.\n\n        \"\"\"\n\n        name = copy.deepcopy(self.fname)\n        stats = fortran_cdf.inquire(name)\n\n        # break out fortran output into something meaningful\n        status = stats[0]\n        if status == 0:\n            self._num_dims = stats[1]\n            self._dim_sizes = stats[2]\n            self._encoding = stats[3]\n            self._majority = stats[4]\n            self._max_rec = stats[5]\n            self._num_r_vars = stats[6]\n            self._num_z_vars = stats[7]\n            self._num_attrs = stats[8]\n        else:\n            raise IOError(fortran_cdf.statusreporter(status))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_all_z_variable_info(self):\n\n        self.z_variable_info = {}\n        self.z_variable_names_by_num = {}\n\n        # call Fortran that grabs all of the basic stats on all of the\n        # zVariables in one go.\n        info = fortran_cdf.z_var_all_inquire(self.fname, self._num_z_vars,\n                                             len(self.fname))\n        status = info[0]\n        data_types = info[1]\n        num_elems = info[2]\n        rec_varys = info[3]\n        dim_varys = info[4]\n        num_dims = info[5]\n        dim_sizes = info[6]\n        rec_nums = info[7]\n        var_nums = info[8]\n        var_names = info[9]\n\n        if status == 0:\n            for i in np.arange(len(data_types)):\n                out = {}\n                out['data_type'] = data_types[i]\n                out['num_elems'] = num_elems[i]\n                out['rec_vary'] = rec_varys[i]\n                out['dim_varys'] = dim_varys[i]\n                out['num_dims'] = num_dims[i]\n                # only looking at first possible extra dimension\n                out['dim_sizes'] = dim_sizes[i, :1]\n                if out['dim_sizes'][0] == 0:\n                    out['dim_sizes'][0] += 1\n                out['rec_num'] = rec_nums[i]\n                out['var_num'] = var_nums[i]\n                var_name = ''.join(var_names[i].astype('U'))\n                out['var_name'] = var_name.rstrip()\n                self.z_variable_info[out['var_name']] = out\n                self.z_variable_names_by_num[out['var_num']] = var_name\n        else:\n            raise IOError(fortran_cdf.statusreporter(status))", "response": "Reads all CDF z - variable information from the file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_all_variables(self):\n\n        self.data = {}\n        # need to add r variable names\n        file_var_names = self.z_variable_info.keys()\n        # collect variable information for each\n        # organize it neatly for fortran call\n        dim_sizes = []\n        rec_nums = []\n        data_types = []\n        names = []\n        for i, name in enumerate(file_var_names):\n            dim_sizes.extend(self.z_variable_info[name]['dim_sizes'])\n            rec_nums.append(self.z_variable_info[name]['rec_num'])\n            data_types.append(self.z_variable_info[name]['data_type'])\n            names.append(name.ljust(256))\n        dim_sizes = np.array(dim_sizes)\n        rec_nums = np.array(rec_nums)\n        data_types = np.array(data_types)\n        # individually load all variables by each data type\n        self._call_multi_fortran_z(names, data_types, rec_nums, dim_sizes,\n                                   self.cdf_data_types['real4'],\n                                   fortran_cdf.get_multi_z_real4)\n        self._call_multi_fortran_z(names, data_types, rec_nums, dim_sizes,\n                                   self.cdf_data_types['float'],\n                                   fortran_cdf.get_multi_z_real4)\n        self._call_multi_fortran_z(names, data_types, rec_nums, dim_sizes,\n                                   self.cdf_data_types['real8'],\n                                   fortran_cdf.get_multi_z_real8)\n        self._call_multi_fortran_z(names, data_types, rec_nums, dim_sizes,\n                                   self.cdf_data_types['double'],\n                                   fortran_cdf.get_multi_z_real8)\n        self._call_multi_fortran_z(names, data_types, rec_nums, dim_sizes,\n                                   self.cdf_data_types['int4'],\n                                   fortran_cdf.get_multi_z_int4)\n        self._call_multi_fortran_z(names, data_types, rec_nums, dim_sizes,\n                                   self.cdf_data_types['uint4'],\n                                   fortran_cdf.get_multi_z_int4,\n                                   data_offset=2 ** 32)\n        self._call_multi_fortran_z(names, data_types, rec_nums, dim_sizes,\n                                   self.cdf_data_types['int2'],\n                                   fortran_cdf.get_multi_z_int2)\n        self._call_multi_fortran_z(names, data_types, rec_nums, dim_sizes,\n                                   self.cdf_data_types['uint2'],\n                                   fortran_cdf.get_multi_z_int2,\n                                   data_offset=2 ** 16)\n        self._call_multi_fortran_z(names, data_types, rec_nums, dim_sizes,\n                                   self.cdf_data_types['int1'],\n                                   fortran_cdf.get_multi_z_int1)\n        self._call_multi_fortran_z(names, data_types, rec_nums, dim_sizes,\n                                   self.cdf_data_types['uint1'],\n                                   fortran_cdf.get_multi_z_int1,\n                                   data_offset=2 ** 8)\n        self._call_multi_fortran_z(names, data_types, rec_nums, dim_sizes,\n                                   self.cdf_data_types['byte'],\n                                   fortran_cdf.get_multi_z_int1)\n        self._call_multi_fortran_z(names, data_types, rec_nums, dim_sizes,\n                                   self.cdf_data_types['epoch'],\n                                   fortran_cdf.get_multi_z_real8,\n                                   epoch=True)\n        self._call_multi_fortran_z(names, data_types, rec_nums, 2 * dim_sizes,\n                                   self.cdf_data_types['epoch16'],\n                                   fortran_cdf.get_multi_z_epoch16,\n                                   epoch16=True)\n        self._call_multi_fortran_z(names, data_types, rec_nums, dim_sizes,\n                                   self.cdf_data_types['TT2000'],\n                                   fortran_cdf.get_multi_z_tt2000,\n                                   epoch=True)\n        # mark data has been loaded\n        self.data_loaded = True", "response": "Loads all variables from CDF."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _call_multi_fortran_z(self, names, data_types, rec_nums,\n                              dim_sizes, input_type_code, func,\n                              epoch=False, data_offset=None, epoch16=False):\n        \"\"\"Calls fortran functions to load CDF variable data\n\n        Parameters\n        ----------\n        names : list_like\n            list of variables names\n        data_types : list_like\n            list of all loaded data type codes as used by CDF\n        rec_nums : list_like\n            list of record numbers in CDF file. Provided by variable_info\n        dim_sizes :\n            list of dimensions as provided by variable_info.\n        input_type_code : int\n            Specific type code to load\n        func : function\n            Fortran function via python interface that will be used for actual loading.\n        epoch : bool\n            Flag indicating type is epoch. Translates things to datetime standard.\n        data_offset :\n            Offset value to be applied to data. Required for unsigned integers in CDF.\n        epoch16 : bool\n            Flag indicating type is epoch16. Translates things to datetime standard.\n\n        \n        \"\"\"\n\n        # isolate input type code variables from total supplied types\n        idx, = np.where(data_types == input_type_code)\n\n        if len(idx) > 0:\n            # read all data of a given type at once\n            max_rec = rec_nums[idx].max()\n            sub_names = np.array(names)[idx]\n            sub_sizes = dim_sizes[idx]\n            status, data = func(self.fname, sub_names.tolist(),\n                                sub_sizes, sub_sizes.sum(), max_rec, len(sub_names))\n            if status == 0:\n                # account for quirks of CDF data storage for certain types\n                if data_offset is not None:\n                    data = data.astype(int)\n                    idx, idy, = np.where(data < 0)\n                    data[idx, idy] += data_offset\n                if epoch:\n                    # account for difference in seconds between\n                    # CDF epoch and python's epoch, leap year in there\n                    # (datetime(1971,1,2) - \n                    #      datetime(1,1,1)).total_seconds()*1000\n                    data -= 62167219200000\n                    data = data.astype('<M8[ms]')\n                if epoch16:\n                    data[0::2, :] -= 62167219200\n                    data = data[0::2, :] * 1E9 + data[1::2, :] / 1.E3\n                    data = data.astype('datetime64[ns]')\n                    sub_sizes /= 2\n                # all data of a type has been loaded and tweaked as necessary\n                # parse through returned array to break out the individual variables\n                # as appropriate\n                self._process_return_multi_z(data, sub_names, sub_sizes)\n            else:\n                raise IOError(fortran_cdf.statusreporter(status))", "response": "Calls the function func on all of the variables in the CDF file and returns the data in the CDF variable data_types."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing and attach data from fortran_cdf. get_multi_z", "response": "def _process_return_multi_z(self, data, names, dim_sizes):\n        \"\"\"process and attach data from fortran_cdf.get_multi_*\"\"\"\n        # process data\n        d1 = 0\n        d2 = 0\n        for name, dim_size in zip(names, dim_sizes):\n            d2 = d1 + dim_size\n            if dim_size == 1:\n                self.data[name.rstrip()] = data[d1, :]\n            else:\n                self.data[name.rstrip()] = data[d1:d2, :]\n            d1 += dim_size"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _read_all_attribute_info(self):\n\n        num = copy.deepcopy(self._num_attrs)\n        fname = copy.deepcopy(self.fname)\n        out = fortran_cdf.inquire_all_attr(fname, num, len(fname))\n        status = out[0]\n        names = out[1].astype('U')\n        scopes = out[2]\n        max_gentries = out[3]\n        max_rentries = out[4]\n        max_zentries = out[5]\n        attr_nums = out[6]\n\n        global_attrs_info = {}\n        var_attrs_info = {}\n        if status == 0:\n            for name, scope, gentry, rentry, zentry, num in zip(names, scopes, max_gentries,\n                                                                max_rentries, max_zentries,\n                                                                attr_nums):\n                name = ''.join(name)\n                name = name.rstrip()\n                nug = {}\n                nug['scope'] = scope\n                nug['max_gentry'] = gentry\n                nug['max_rentry'] = rentry\n                nug['max_zentry'] = zentry\n                nug['attr_num'] = num\n                flag = (gentry == 0) & (rentry == 0) & (zentry == 0)\n                if not flag:\n                    if scope == 1:\n                        global_attrs_info[name] = nug\n                    elif scope == 2:\n                        var_attrs_info[name] = nug\n\n            self.global_attrs_info = global_attrs_info\n            self.var_attrs_info = var_attrs_info\n        else:\n            raise IOError(fortran_cdf.statusreporter(status))", "response": "Read all attribute properties g r and z attributes from the file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads all CDF z - attribute data from file and store it in self. meta.", "response": "def _read_all_z_attribute_data(self):\n        \"\"\"Read all CDF z-attribute data\"\"\"\n        self.meta = {}\n        # collect attribute info needed to get more info from \n        # fortran routines\n        max_entries = []\n        attr_nums = []\n        names = []\n        attr_names = []\n        names = self.var_attrs_info.keys()\n        num_z_attrs = len(names)\n        exp_attr_nums = []\n        for key in names:\n            max_entries.append(self.var_attrs_info[key]['max_zentry'])\n            attr_nums.append(self.var_attrs_info[key]['attr_num'])\n        attr_nums = np.array(attr_nums)\n        max_entries = np.array(max_entries)\n\n        info = fortran_cdf.z_attr_all_inquire(self.fname, attr_nums,\n                                              num_z_attrs, max_entries, \n                                              self._num_z_vars, len(self.fname))\n\n        status = info[0]\n        data_types = info[1]\n        num_elems = info[2]\n        entry_nums = info[3]\n\n        if status == 0:\n            for i, name in enumerate(names):\n                self.var_attrs_info[name]['data_type'] = data_types[i]\n                self.var_attrs_info[name]['num_elems'] = num_elems[i]\n                self.var_attrs_info[name]['entry_num'] = entry_nums[i]\n                exp_attr_nums.extend([self.var_attrs_info[name]['attr_num']] * len(entry_nums[i]))\n                attr_names.extend([name] * len(entry_nums[i]))\n        else:\n            raise IOError(fortran_cdf.statusreporter(status))\n\n        # all the info is now packed up\n        # need to break it out to make it easier to load via fortran\n        # all of this junk\n        # attribute  id, entry id (zVariable ID), data_type, num_elems\n        # should just need to flatten this stuff\n\n        data_types = data_types.flatten()\n        num_elems = num_elems.flatten()\n        entry_nums = entry_nums.flatten()\n        attr_nums = np.array(exp_attr_nums)\n        # drop everything that isn't valid\n        idx, = np.where(entry_nums > 0)\n\n        data_types = data_types[idx]\n        num_elems = num_elems[idx]\n        entry_nums = entry_nums[idx]\n        attr_nums = attr_nums[idx]\n        attr_names = np.array(attr_names)[idx]\n        # grad corresponding variable name for each attribute\n        var_names = [self.z_variable_names_by_num[i].rstrip() for i in entry_nums]\n\n        # the names that go along with this are already set up\n\n        # in attr_names\n        # chunk by data type, grab largest num_elems\n\n        # get data back, shorten to num_elems, add to structure\n        self._call_multi_fortran_z_attr(attr_names, data_types, num_elems,\n                                        entry_nums, attr_nums, var_names, self.cdf_data_types['real4'],\n                                        fortran_cdf.get_multi_z_attr_real4)\n        self._call_multi_fortran_z_attr(attr_names, data_types, num_elems,\n                                        entry_nums, attr_nums, var_names, self.cdf_data_types['float'],\n                                        fortran_cdf.get_multi_z_attr_real4)\n        self._call_multi_fortran_z_attr(attr_names, data_types, num_elems,\n                                        entry_nums, attr_nums, var_names, self.cdf_data_types['real8'],\n                                        fortran_cdf.get_multi_z_attr_real8)\n        self._call_multi_fortran_z_attr(attr_names, data_types, num_elems,\n                                        entry_nums, attr_nums, var_names, self.cdf_data_types['double'],\n                                        fortran_cdf.get_multi_z_attr_real8)\n        self._call_multi_fortran_z_attr(attr_names, data_types, num_elems,\n                                        entry_nums, attr_nums, var_names, self.cdf_data_types['byte'],\n                                        fortran_cdf.get_multi_z_attr_int1)\n        self._call_multi_fortran_z_attr(attr_names, data_types, num_elems,\n                                        entry_nums, attr_nums, var_names, self.cdf_data_types['int1'],\n                                        fortran_cdf.get_multi_z_attr_int1)\n        self._call_multi_fortran_z_attr(attr_names, data_types, num_elems,\n                                        entry_nums, attr_nums, var_names, self.cdf_data_types['uint1'],\n                                        fortran_cdf.get_multi_z_attr_int1,\n                                        data_offset=256)\n        self._call_multi_fortran_z_attr(attr_names, data_types, num_elems,\n                                        entry_nums, attr_nums, var_names, self.cdf_data_types['int2'],\n                                        fortran_cdf.get_multi_z_attr_int2)\n        self._call_multi_fortran_z_attr(attr_names, data_types, num_elems,\n                                        entry_nums, attr_nums, var_names, self.cdf_data_types['uint2'],\n                                        fortran_cdf.get_multi_z_attr_int2,\n                                        data_offset=65536)\n        self._call_multi_fortran_z_attr(attr_names, data_types, num_elems,\n                                        entry_nums, attr_nums, var_names, self.cdf_data_types['int4'],\n                                        fortran_cdf.get_multi_z_attr_int4)\n        self._call_multi_fortran_z_attr(attr_names, data_types, num_elems,\n                                        entry_nums, attr_nums, var_names, self.cdf_data_types['uint4'],\n                                        fortran_cdf.get_multi_z_attr_int4,\n                                        data_offset=2 ** 32)\n        self._call_multi_fortran_z_attr(attr_names, data_types, num_elems,\n                                        entry_nums, attr_nums, var_names, self.cdf_data_types['char'],\n                                        fortran_cdf.get_multi_z_attr_char)\n        self._call_multi_fortran_z_attr(attr_names, data_types, num_elems,\n                                        entry_nums, attr_nums, var_names, self.cdf_data_types['uchar'],\n                                        fortran_cdf.get_multi_z_attr_char)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _call_multi_fortran_z_attr(self, names, data_types, num_elems,\n                                   entry_nums, attr_nums, var_names,\n                                   input_type_code, func, data_offset=None):\n        \"\"\"Calls Fortran function that reads attribute data.\n        \n        data_offset translates unsigned into signed.\n        If number read in is negative, offset added.\n        \"\"\"\n        # isolate input type code variables\n        idx, = np.where(data_types == input_type_code)\n\n        if len(idx) > 0:\n            # maximimum array dimension\n            max_num = num_elems[idx].max()\n            sub_num_elems = num_elems[idx]\n            sub_names = np.array(names)[idx]\n            sub_var_names = np.array(var_names)[idx]\n            # zVariable numbers, 'entry' number\n            sub_entry_nums = entry_nums[idx]\n            # attribute number\n            sub_attr_nums = attr_nums[idx]\n            status, data = func(self.fname, sub_attr_nums, sub_entry_nums,\n                                len(sub_attr_nums), max_num, len(self.fname))\n            if (status == 0).all():\n                if data_offset is not None:\n                    data = data.astype(int)\n                    idx, idy, = np.where(data < 0)\n                    data[idx, idy] += data_offset\n                self._process_return_multi_z_attr(data, sub_names,\n                                                  sub_var_names, sub_num_elems)\n            else:\n                # raise ValueError('CDF Error code :', status)\n                idx, = np.where(status != 0)\n                # raise first error\n                raise IOError(fortran_cdf.statusreporter(status[idx][0]))", "response": "Calls the function that reads attribute data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _process_return_multi_z_attr(self, data, attr_names, var_names, sub_num_elems):\n        '''process and attach data from fortran_cdf.get_multi_*'''\n        # process data\n\n        for i, (attr_name, var_name, num_e) in enumerate(zip(attr_names, var_names, sub_num_elems)):\n            if var_name not in self.meta.keys():\n                self.meta[var_name] = {}\n            if num_e == 1:\n                self.meta[var_name][attr_name] = data[i, 0]\n            else:\n                if data[i].dtype == '|S1':\n                    self.meta[var_name][attr_name] = ''.join(data[i, 0:num_e].astype('U')).rstrip()\n                else:\n                    self.meta[var_name][attr_name] = data[i, 0:num_e]", "response": "process and attach data from fortran_cdf. get_multi_*'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_pysat(self, flatten_twod=True, units_label='UNITS', name_label='long_name',\n                        fill_label='FILLVAL', plot_label='FieldNam', \n                        min_label='ValidMin', max_label='ValidMax', \n                        notes_label='Var_Notes', desc_label='CatDesc',\n                        axis_label = 'LablAxis'):\n        \"\"\"\n        Exports loaded CDF data into data, meta for pysat module\n        \n        Notes\n        -----\n        The *_labels should be set to the values in the file, if present.\n        Note that once the meta object returned from this function is attached\n        to a pysat.Instrument object then the *_labels on the Instrument\n        are assigned to the newly attached Meta object.\n        \n        The pysat Meta object will use data with labels that match the patterns\n        in *_labels even if the case does not match.\n\n        Parameters\n        ----------\n        flatten_twod : bool (True)\n            If True, then two dimensional data is flattened across \n            columns. Name mangling is used to group data, first column\n            is 'name', last column is 'name_end'. In between numbers are \n            appended 'name_1', 'name_2', etc. All data for a given 2D array\n            may be accessed via, data.ix[:,'item':'item_end']\n            If False, then 2D data is stored as a series of DataFrames, \n            indexed by Epoch. data.ix[0, 'item']\n        units_label : str\n            Identifier within metadata for units. Defults to CDAWab standard.\n        name_label : str\n            Identifier within metadata for variable name. Defults to 'long_name',\n            not normally present within CDAWeb files. If not, will use values\n            from the variable name in the file.\n        fill_label : str\n            Identifier within metadata for Fill Values. Defults to CDAWab standard.\n        plot_label : str\n            Identifier within metadata for variable name used when plotting.\n            Defults to CDAWab standard.\n        min_label : str\n            Identifier within metadata for minimim variable value. \n            Defults to CDAWab standard.\n        max_label : str\n            Identifier within metadata for maximum variable value.\n            Defults to CDAWab standard.\n        notes_label : str\n            Identifier within metadata for notes. Defults to CDAWab standard.\n        desc_label : str\n            Identifier within metadata for a variable description.\n            Defults to CDAWab standard.\n        axis_label : str\n            Identifier within metadata for axis name used when plotting. \n            Defults to CDAWab standard.\n            \n                             \n        Returns\n        -------\n        pandas.DataFrame, pysat.Meta\n            Data and Metadata suitable for attachment to a pysat.Instrument\n            object.\n        \n        \"\"\"\n\n        import string\n        import pysat\n        import pandas\n\n        # copy data\n        cdata = self.data.copy()\n        #\n        # create pysat.Meta object using data above\n        # and utilizing the attribute labels provided by the user\n        meta = pysat.Meta(pysat.DataFrame.from_dict(self.meta, orient='index'),\n                          units_label=units_label, name_label=name_label,\n                          fill_label=fill_label, plot_label=plot_label,\n                          min_label=min_label, max_label=max_label,\n                          notes_label=notes_label, desc_label=desc_label,\n                          axis_label=axis_label)\n                          \n        # account for different possible cases for Epoch, epoch, EPOCH, epOch\n        lower_names = [name.lower() for name in meta.keys()] \n        for name, true_name in zip(lower_names, meta.keys()):\n            if name == 'epoch':\n                meta.data.rename(index={true_name: 'Epoch'}, inplace=True)\n                epoch = cdata.pop(true_name)\n                cdata['Epoch'] = epoch\n\n        # ready to format data, iterate over all of the data names\n        # and put into a pandas DataFrame\n        two_d_data = []\n        drop_list = []\n        for name in cdata.keys():\n            temp = np.shape(cdata[name])\n            # treat 2 dimensional data differently\n            if len(temp) == 2:\n                if not flatten_twod:\n                    # put 2D data into a Frame at each time\n                    # remove data from dict when adding to the DataFrame\n                    frame = pysat.DataFrame(cdata[name].flatten(), columns=[name])\n                    drop_list.append(name)\n\n                    step = temp[0]\n                    new_list = []\n                    new_index = np.arange(step)\n                    for i in np.arange(len(epoch)):\n                        new_list.append(frame.iloc[i*step:(i+1)*step, :])\n                        new_list[-1].index = new_index\n                    #new_frame = pandas.DataFrame.from_records(new_list, index=epoch, columns=[name])\n                    new_frame = pandas.Series(new_list, index=epoch, name=name)\n                    two_d_data.append(new_frame)\n\n                else:\n                    # flatten 2D into series of 1D columns\n                    new_names = [name + '_{i}'.format(i=i) for i in np.arange(temp[0] - 2)]\n                    new_names.append(name + '_end')\n                    new_names.insert(0, name)\n                    # remove data from dict when adding to the DataFrame\n                    drop_list.append(name)\n                    frame = pysat.DataFrame(cdata[name].T,\n                                            index=epoch,\n                                            columns=new_names)\n                    two_d_data.append(frame)\n        for name in drop_list:\n            _ = cdata.pop(name)\n        # all of the data left over is 1D, add as Series\n        data = pysat.DataFrame(cdata, index=epoch)\n        two_d_data.append(data)\n        data = pandas.concat(two_d_data, axis=1)\n        data.drop('Epoch', axis=1, inplace=True)\n        return data, meta", "response": "Converts the CDF data into a pysat. Instrument object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _uptime_linux():\n    # With procfs\n    try:\n        f = open('/proc/uptime', 'r')\n        up = float(f.readline().split()[0])\n        f.close()\n        return up\n    except (IOError, ValueError):\n        pass\n\n    # Without procfs (really?)\n    try:\n        libc = ctypes.CDLL('libc.so')\n    except AttributeError:\n        return None\n    except OSError:\n        # Debian and derivatives do the wrong thing because /usr/lib/libc.so\n        # is a GNU ld script rather than an ELF object. To get around this, we\n        # have to be more specific.\n        # We don't want to use ctypes.util.find_library because that creates a\n        # new process on Linux. We also don't want to try too hard because at\n        # this point we're already pretty sure this isn't Linux.\n        try:\n            libc = ctypes.CDLL('libc.so.6')\n        except OSError:\n            return None\n\n    if not hasattr(libc, 'sysinfo'):\n        # Not Linux.\n        return None\n\n    buf = ctypes.create_string_buffer(128) # 64 suffices on 32-bit, whatever.\n    if libc.sysinfo(buf) < 0:\n        return None\n\n    up = struct.unpack_from('@l', buf.raw)[0]\n    if up < 0:\n        up = None\n    return up", "response": "Returns uptime in seconds or None on Linux."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn uptime in seconds on AmigaOS", "response": "def _uptime_amiga():\n    \"\"\"Returns uptime in seconds or None, on AmigaOS.\"\"\"\n    global __boottime\n    try:\n        __boottime = os.stat('RAM:').st_ctime\n        return time.time() - __boottime\n    except (NameError, OSError):\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns uptime on BeOS or Haiku.", "response": "def _uptime_beos():\n    \"\"\"Returns uptime in seconds on None, on BeOS/Haiku.\"\"\"\n    try:\n        libroot = ctypes.CDLL('libroot.so')\n    except (AttributeError, OSError):\n        return None\n\n    if not hasattr(libroot, 'system_time'):\n        return None\n\n    libroot.system_time.restype = ctypes.c_int64\n    return libroot.system_time() / 1000000."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _uptime_bsd():\n    global __boottime\n    try:\n        libc = ctypes.CDLL('libc.so')\n    except AttributeError:\n        return None\n    except OSError:\n        # OS X; can't use ctypes.util.find_library because that creates\n        # a new process on Linux, which is undesirable.\n        try:\n            libc = ctypes.CDLL('libc.dylib')\n        except OSError:\n            return None\n\n    if not hasattr(libc, 'sysctlbyname'):\n        # Not BSD.\n        return None\n\n    # Determine how much space we need for the response.\n    sz = ctypes.c_uint(0)\n    libc.sysctlbyname('kern.boottime', None, ctypes.byref(sz), None, 0)\n    if sz.value != struct.calcsize('@LL'):\n        # Unexpected, let's give up.\n        return None\n\n    # For real now.\n    buf = ctypes.create_string_buffer(sz.value)\n    libc.sysctlbyname('kern.boottime', buf, ctypes.byref(sz), None, 0)\n    sec, usec = struct.unpack('@LL', buf.raw)\n\n    # OS X disagrees what that second value is.\n    if usec > 1000000:\n        usec = 0.\n\n    __boottime = sec + usec / 1000000.\n    up = time.time() - __boottime\n    if up < 0:\n        up = None\n    return up", "response": "Returns uptime in seconds or None on BSD."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn uptime in seconds or None on MINIX.", "response": "def _uptime_minix():\n    \"\"\"Returns uptime in seconds or None, on MINIX.\"\"\"\n    try:\n        f = open('/proc/uptime', 'r')\n        up = float(f.read())\n        f.close()\n        return up\n    except (IOError, ValueError):\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _uptime_plan9():\n    # Apparently Plan 9 only has Python 2.2, which I'm not prepared to\n    # support. Maybe some Linuxes implement /dev/time, though, someone was\n    # talking about it somewhere.\n    try:\n        # The time file holds one 32-bit number representing the sec-\n        # onds since start of epoch and three 64-bit numbers, repre-\n        # senting nanoseconds since start of epoch, clock ticks, and\n        # clock frequency.\n        #  -- cons(3)\n        f = open('/dev/time', 'r')\n        s, ns, ct, cf = f.read().split()\n        f.close()\n        return float(ct) / float(cf)\n    except (IOError, ValueError):\n        return None", "response": "Returns uptime in seconds or None on Plan 9."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns uptime in seconds or None on Solaris.", "response": "def _uptime_solaris():\n    \"\"\"Returns uptime in seconds or None, on Solaris.\"\"\"\n    global __boottime\n    try:\n        kstat = ctypes.CDLL('libkstat.so')\n    except (AttributeError, OSError):\n        return None\n\n    # kstat doesn't have uptime, but it does have boot time.\n    # Unfortunately, getting at it isn't perfectly straightforward.\n    # First, let's pretend to be kstat.h\n\n    # Constant\n    KSTAT_STRLEN = 31   # According to every kstat.h I could find.\n\n    # Data structures\n    class anon_union(ctypes.Union):\n        # The ``value'' union in kstat_named_t actually has a bunch more\n        # members, but we're only using it for boot_time, so we only need\n        # the padding and the one we're actually using.\n        _fields_ = [('c', ctypes.c_char * 16),\n                    ('time', ctypes.c_int)]\n\n    class kstat_named_t(ctypes.Structure):\n        _fields_ = [('name', ctypes.c_char * KSTAT_STRLEN),\n                    ('data_type', ctypes.c_char),\n                    ('value', anon_union)]\n\n    # Function signatures\n    kstat.kstat_open.restype = ctypes.c_void_p\n    kstat.kstat_lookup.restype = ctypes.c_void_p\n    kstat.kstat_lookup.argtypes = [ctypes.c_void_p,\n                                   ctypes.c_char_p,\n                                   ctypes.c_int,\n                                   ctypes.c_char_p]\n    kstat.kstat_read.restype = ctypes.c_int\n    kstat.kstat_read.argtypes = [ctypes.c_void_p,\n                                 ctypes.c_void_p,\n                                 ctypes.c_void_p]\n    kstat.kstat_data_lookup.restype = ctypes.POINTER(kstat_named_t)\n    kstat.kstat_data_lookup.argtypes = [ctypes.c_void_p,\n                                        ctypes.c_char_p]\n\n    # Now, let's do something useful.\n\n    # Initialise kstat control structure.\n    kc = kstat.kstat_open()\n    if not kc:\n        return None\n\n    # We're looking for unix:0:system_misc:boot_time.\n    ksp = kstat.kstat_lookup(kc, 'unix', 0, 'system_misc')\n    if ksp and kstat.kstat_read(kc, ksp, None) != -1:\n        data = kstat.kstat_data_lookup(ksp, 'boot_time')\n        if data:\n            __boottime = data.contents.value.time\n\n    # Clean-up.\n    kstat.kstat_close(kc)\n\n    if __boottime is not None:\n        return time.time() - __boottime\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _uptime_syllable():\n    global __boottime\n    try:\n        __boottime = os.stat('/dev/pty/mst/pty0').st_mtime\n        return time.time() - __boottime\n    except (NameError, OSError):\n        return None", "response": "Returns uptime in seconds on Syllable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning uptime in seconds on Windows.", "response": "def _uptime_windows():\n    \"\"\"\n    Returns uptime in seconds or None, on Windows. Warning: may return\n    incorrect answers after 49.7 days on versions older than Vista.\n    \"\"\"\n    if hasattr(ctypes, 'windll') and hasattr(ctypes.windll, 'kernel32'):\n        lib = ctypes.windll.kernel32\n    else:\n        try:\n            # Windows CE uses the cdecl calling convention.\n            lib = ctypes.CDLL('coredll.lib')\n        except (AttributeError, OSError):\n            return None\n\n    if hasattr(lib, 'GetTickCount64'):\n        # Vista/Server 2008 or later.\n        lib.GetTickCount64.restype = ctypes.c_uint64\n        return lib.GetTickCount64() / 1000.\n    if hasattr(lib, 'GetTickCount'):\n        # WinCE and Win2k or later; gives wrong answers after 49.7 days.\n        lib.GetTickCount.restype = ctypes.c_uint32\n        return lib.GetTickCount() / 1000.\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning uptime in seconds if even remotely possible or None if not.", "response": "def uptime():\n    \"\"\"Returns uptime in seconds if even remotely possible, or None if not.\"\"\"\n    if __boottime is not None:\n        return time.time() - __boottime\n\n    return {'amiga': _uptime_amiga,\n            'aros12': _uptime_amiga,\n            'beos5': _uptime_beos,\n            'cygwin': _uptime_linux,\n            'darwin': _uptime_osx,\n            'haiku1': _uptime_beos,\n            'linux': _uptime_linux,\n            'linux-armv71': _uptime_linux,\n            'linux2': _uptime_linux,\n            'mac': _uptime_mac,\n            'minix3': _uptime_minix,\n            'riscos': _uptime_riscos,\n            'sunos5': _uptime_solaris,\n            'syllable': _uptime_syllable,\n            'win32': _uptime_windows,\n            'wince': _uptime_windows}.get(sys.platform, _uptime_bsd)() or \\\n           _uptime_bsd() or _uptime_plan9() or _uptime_linux() or \\\n           _uptime_windows() or _uptime_solaris() or _uptime_beos() or \\\n           _uptime_amiga() or _uptime_riscos() or _uptime_posix() or \\\n           _uptime_syllable() or _uptime_mac() or _uptime_osx()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns boot time if remotely possible or None if not.", "response": "def boottime():\n    \"\"\"Returns boot time if remotely possible, or None if not.\"\"\"\n    global __boottime\n\n    if __boottime is None:\n        up = uptime()\n        if up is None:\n            return None\n    if __boottime is None:\n        _boottime_linux()\n\n    if datetime is None:\n        raise RuntimeError('datetime module required.')\n\n    return datetime.fromtimestamp(__boottime or time.time() - up)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _initfile(path, data=\"dict\"):\n    data = {} if data.lower() == \"dict\" else []\n    # The file will need to be created if it doesn't exist\n    if not os.path.exists(path):  # The file doesn't exist\n        # Raise exception if the directory that should contain the file doesn't\n        # exist\n        dirname = os.path.dirname(path)\n        if dirname and not os.path.exists(dirname):\n            raise IOError(\n                (\"Could not initialize empty JSON file in non-existant \"\n                 \"directory '{}'\").format(os.path.dirname(path))\n            )\n        # Write an empty file there\n        with open(path, \"w\") as f:\n            json.dump(data, f)\n        return True\n    elif os.path.getsize(path) == 0:  # The file is empty\n        with open(path, \"w\") as f:\n            json.dump(data, f)\n    else:  # The file exists and contains content\n        return False", "response": "Initialize an empty JSON file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nover-writes the file with new data.", "response": "def data(self, data):\n        \"\"\"Overwrite the file with new data. You probably shouldn't do\n        this yourself, it's easy to screw up your whole file with this.\"\"\"\n        if self.is_caching:\n            self.cache = data\n        else:\n            fcontents = self.file_contents\n            with open(self.path, \"w\") as f:\n                try:\n                    # Write the file. Keep user settings about indentation, etc\n                    indent = self.indent if self.pretty else None\n                    json.dump(data, f, sort_keys=self.sort_keys, indent=indent)\n                except Exception as e:\n                    # Rollback to prevent data loss\n                    f.seek(0)\n                    f.truncate()\n                    f.write(fcontents)\n                    # And re-raise the exception\n                    raise e\n        self._updateType()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _updateType(self):\n        data = self._data()\n        # Change type if needed\n        if isinstance(data, dict) and isinstance(self, ListFile):\n            self.__class__ = DictFile\n        elif isinstance(data, list) and isinstance(self, DictFile):\n            self.__class__ = ListFile", "response": "Make sure that the class behaves like the data structure that it contains a dict and that we don t get a DictFile."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes a new file that starts out with some data. Pass data as a list dict or JSON string.", "response": "def with_data(path, data):\n        \"\"\"Initialize a new file that starts out with some data. Pass data\n        as a list, dict, or JSON string.\n        \"\"\"\n        # De-jsonize data if necessary\n        if isinstance(data, str):\n            data = json.loads(data)\n\n        # Make sure this is really a new file\n        if os.path.exists(path):\n            raise ValueError(\"File exists, not overwriting data. Set the \"\n                             \"'data' attribute on a normally-initialized \"\n                             \"'livejson.File' instance if you really \"\n                             \"want to do this.\")\n        else:\n            f = File(path)\n            f.data = data\n            return f"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_configured(self, project, **kwargs):\n        params = self.get_option\n        return bool(params('server_host', project) and params('server_port', project))", "response": "Check if the plugin is configured."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dict representation of the object.", "response": "def as_dict(self):\n        \"\"\"\n        ping statistics.\n\n        Returns:\n            |dict|:\n\n        Examples:\n            >>> import pingparsing\n            >>> parser = pingparsing.PingParsing()\n            >>> parser.parse(ping_result)\n            >>> parser.as_dict()\n            {\n                \"destination\": \"google.com\",\n                \"packet_transmit\": 60,\n                \"packet_receive\": 60,\n                \"packet_loss_rate\": 0.0,\n                \"packet_loss_count\": 0,\n                \"rtt_min\": 61.425,\n                \"rtt_avg\": 99.731,\n                \"rtt_max\": 212.597,\n                \"rtt_mdev\": 27.566,\n                \"packet_duplicate_rate\": 0.0,\n                \"packet_duplicate_count\": 0\n            }\n        \"\"\"\n\n        return {\n            \"destination\": self.destination,\n            \"packet_transmit\": self.packet_transmit,\n            \"packet_receive\": self.packet_receive,\n            \"packet_loss_count\": self.packet_loss_count,\n            \"packet_loss_rate\": self.packet_loss_rate,\n            \"rtt_min\": self.rtt_min,\n            \"rtt_avg\": self.rtt_avg,\n            \"rtt_max\": self.rtt_max,\n            \"rtt_mdev\": self.rtt_mdev,\n            \"packet_duplicate_count\": self.packet_duplicate_count,\n            \"packet_duplicate_rate\": self.packet_duplicate_rate,\n        }"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a tuple containing the current ping statistics.", "response": "def as_tuple(self):\n        \"\"\"\n        ping statistics.\n\n        Returns:\n            |namedtuple|:\n\n        Examples:\n            >>> import pingparsing\n            >>> parser = pingparsing.PingParsing()\n            >>> parser.parse(ping_result)\n            >>> parser.as_tuple()\n            PingResult(destination='google.com', packet_transmit=60, packet_receive=60, packet_loss_rate=0.0, packet_loss_count=0, rtt_min=61.425, rtt_avg=99.731, rtt_max=212.597, rtt_mdev=27.566, packet_duplicate_rate=0.0, packet_duplicate_count=0)\n        \"\"\"\n\n        from collections import namedtuple\n\n        ping_result = self.as_dict()\n\n        return namedtuple(\"PingStatsTuple\", ping_result.keys())(**ping_result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends ICMP packets. :return: ``ping`` command execution result. :rtype: :py:class:`.PingResult` :raises ValueError: If parameters not valid.", "response": "def ping(self):\n        \"\"\"\n        Sending ICMP packets.\n\n        :return: ``ping`` command execution result.\n        :rtype: :py:class:`.PingResult`\n        :raises ValueError: If parameters not valid.\n        \"\"\"\n\n        self.__validate_ping_param()\n\n        ping_proc = subprocrunner.SubprocessRunner(self.__get_ping_command())\n        ping_proc.run()\n\n        return PingResult(ping_proc.stdout, ping_proc.stderr, ping_proc.returncode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse(self, ping_message):\n\n        try:\n            # accept PingResult instance as an input\n            if typepy.is_not_null_string(ping_message.stdout):\n                ping_message = ping_message.stdout\n        except AttributeError:\n            pass\n\n        logger.debug(\"parsing ping result: {}\".format(ping_message))\n\n        self.__parser = NullPingParser()\n\n        if typepy.is_null_string(ping_message):\n            logger.debug(\"ping_message is empty\")\n            self.__stats = PingStats()\n\n            return self.__stats\n\n        ping_lines = _to_unicode(ping_message).splitlines()\n        parser_class_list = (\n            LinuxPingParser,\n            WindowsPingParser,\n            MacOsPingParser,\n            AlpineLinuxPingParser,\n        )\n\n        for parser_class in parser_class_list:\n            self.__parser = parser_class()\n            try:\n                self.__stats = self.__parser.parse(ping_lines)\n                return self.__stats\n            except ParseError as e:\n                if e.reason != ParseErrorReason.HEADER_NOT_FOUND:\n                    raise e\n            except pp.ParseException:\n                pass\n\n        self.__parser = NullPingParser()\n\n        return self.__stats", "response": "Parse the ping command output."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_confirmation(self):\n        confirmation = EmailConfirmation.objects.create(email=self)\n        confirmation.send()", "response": "Send a verification email for the email address."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_duplicate_notification(self):\n        email_utils.send_email(\n            from_email=settings.DEFAULT_FROM_EMAIL,\n            recipient_list=[self.email],\n            subject=_(\"Registration Attempt\"),\n            template_name=\"rest_email_auth/emails/duplicate-email\",\n        )\n\n        logger.info(\"Sent duplicate email notification to: %s\", self.email)", "response": "Send a duplicate notification about a duplicate signup."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_primary(self):\n        query = EmailAddress.objects.filter(is_primary=True, user=self.user)\n        query = query.exclude(pk=self.pk)\n\n        # The transaction is atomic so there is never a gap where a user\n        # has no primary email address.\n        with transaction.atomic():\n            query.update(is_primary=False)\n\n            self.is_primary = True\n            self.save()\n\n        logger.info(\n            \"Set %s as the primary email address for %s.\",\n            self.email,\n            self.user,\n        )", "response": "Set this email address as the user s primary email address."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmarks the instance s email as verified.", "response": "def confirm(self):\n        \"\"\"\n        Mark the instance's email as verified.\n        \"\"\"\n        self.email.is_verified = True\n        self.email.save()\n\n        signals.email_verified.send(email=self.email, sender=self.__class__)\n\n        logger.info(\"Verified email address: %s\", self.email.email)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_expired(self):\n        expiration_time = self.created_at + datetime.timedelta(days=1)\n\n        return timezone.now() > expiration_time", "response": "Determines if the confirmation has expired."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a verification email to the user.", "response": "def send(self):\n        \"\"\"\n        Send a verification email to the user.\n        \"\"\"\n        context = {\n            \"verification_url\": app_settings.EMAIL_VERIFICATION_URL.format(\n                key=self.key\n            )\n        }\n\n        email_utils.send_email(\n            context=context,\n            from_email=settings.DEFAULT_FROM_EMAIL,\n            recipient_list=[self.email.email],\n            subject=_(\"Please Verify Your Email Address\"),\n            template_name=\"rest_email_auth/emails/verify-email\",\n        )\n\n        logger.info(\n            \"Sent confirmation email to %s for user #%d\",\n            self.email.email,\n            self.email.user.id,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create(cls, model_class, *args, **kwargs):\n        manager = cls._get_manager(model_class)\n\n        return manager.create_user(*args, **kwargs)", "response": "Create a new user instance of the specified type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, validated_data):\n        email_query = models.EmailAddress.objects.filter(\n            email=self.validated_data[\"email\"]\n        )\n\n        if email_query.exists():\n            email = email_query.get()\n\n            email.send_duplicate_notification()\n        else:\n            email = super(EmailSerializer, self).create(validated_data)\n            email.send_confirmation()\n\n            user = validated_data.get(\"user\")\n            query = models.EmailAddress.objects.filter(\n                is_primary=True, user=user\n            )\n\n            if not query.exists():\n                email.set_primary()\n\n        return email", "response": "Create a new email and send a confirmation to it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, instance, validated_data):\n        is_primary = validated_data.pop(\"is_primary\", False)\n\n        instance = super(EmailSerializer, self).update(\n            instance, validated_data\n        )\n\n        if is_primary:\n            instance.set_primary()\n\n        return instance", "response": "Updates the instance with the data provided."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_email(self, email):\n        user, domain = email.rsplit(\"@\", 1)\n        email = \"@\".join([user, domain.lower()])\n\n        if self.instance and email and self.instance.email != email:\n            raise serializers.ValidationError(\n                _(\n                    \"Existing emails may not be edited. Create a new one \"\n                    \"instead.\"\n                )\n            )\n\n        return email", "response": "Validate the provided email address."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_is_primary(self, is_primary):\n        # TODO: Setting 'is_primary' to 'False' should probably not be\n        #       allowed.\n        if is_primary and not (self.instance and self.instance.is_verified):\n            raise serializers.ValidationError(\n                _(\n                    \"Unverified email addresses may not be used as the \"\n                    \"primary address.\"\n                )\n            )\n\n        return is_primary", "response": "Validate the provided is_primary parameter."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate(self, data):\n        user = self._confirmation.email.user\n\n        if (\n            app_settings.EMAIL_VERIFICATION_PASSWORD_REQUIRED\n            and not user.check_password(data[\"password\"])\n        ):\n            raise serializers.ValidationError(\n                _(\"The provided password is invalid.\")\n            )\n\n        # Add email to returned data\n        data[\"email\"] = self._confirmation.email.email\n\n        return data", "response": "Validate the provided data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_key(self, key):\n        try:\n            confirmation = models.EmailConfirmation.objects.select_related(\n                \"email__user\"\n            ).get(key=key)\n        except models.EmailConfirmation.DoesNotExist:\n            raise serializers.ValidationError(\n                _(\"The provided verification key is invalid.\")\n            )\n\n        if confirmation.is_expired:\n            raise serializers.ValidationError(\n                _(\"That verification code has expired.\")\n            )\n\n        # Cache confirmation instance\n        self._confirmation = confirmation\n\n        return key", "response": "Validate the provided confirmation key."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save(self):\n        try:\n            email = models.EmailAddress.objects.get(\n                email=self.validated_data[\"email\"], is_verified=True\n            )\n        except models.EmailAddress.DoesNotExist:\n            return None\n\n        token = models.PasswordResetToken.objects.create(email=email)\n        token.send()\n\n        return token", "response": "Send out a password reset token if the provided data is valid and returns the associated password reset token."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save(self):\n        token = models.PasswordResetToken.objects.get(\n            key=self.validated_data[\"key\"]\n        )\n\n        token.email.user.set_password(self.validated_data[\"password\"])\n        token.email.user.save()\n\n        logger.info(\"Reset password for %s\", token.email.user)\n\n        token.delete()", "response": "Save the user s password if the provided information is valid."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nvalidate the provided reset key.", "response": "def validate_key(self, key):\n        \"\"\"\n        Validate the provided reset key.\n\n        Returns:\n            The validated key.\n\n        Raises:\n            serializers.ValidationError:\n                If the provided key does not exist.\n        \"\"\"\n        if not models.PasswordResetToken.valid_tokens.filter(key=key).exists():\n            raise serializers.ValidationError(\n                _(\"The provided reset token does not exist, or is expired.\")\n            )\n\n        return key"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new user from the data passed to the serializer.", "response": "def create(self, validated_data):\n        \"\"\"\n        Create a new user from the data passed to the serializer.\n\n        If the provided email has not been verified yet, the user is\n        created and a verification email is sent to the address.\n        Otherwise we send a notification to the email address that\n        someone attempted to register with an email that's already been\n        verified.\n\n        Args:\n            validated_data (dict):\n                The data passed to the serializer after it has been\n                validated.\n\n        Returns:\n            A new user created from the provided data.\n        \"\"\"\n        email = validated_data.pop(\"email\")\n        password = validated_data.pop(\"password\")\n\n        # We don't save the user instance yet in case the provided email\n        # address already exists.\n        user = get_user_model()(**validated_data)\n        user.set_password(password)\n\n        # We set an ephemeral email property so that it is included in\n        # the data returned by the serializer.\n        user.email = email\n\n        email_query = models.EmailAddress.objects.filter(email=email)\n\n        if email_query.exists():\n            existing_email = email_query.get()\n            existing_email.send_duplicate_notification()\n        else:\n            user.save()\n\n            email_instance = models.EmailAddress.objects.create(\n                email=email, user=user\n            )\n            email_instance.send_confirmation()\n\n            signals.user_registered.send(sender=self.__class__, user=user)\n\n        return user"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_email(self, email):\n        user, domain = email.rsplit(\"@\", 1)\n\n        return \"@\".join([user, domain.lower()])", "response": "Validate the provided email address."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nre-sending a verification email to the provided address.", "response": "def save(self):\n        \"\"\"\n        Resend a verification email to the provided address.\n\n        If the provided email is already verified no action is taken.\n        \"\"\"\n        try:\n            email = models.EmailAddress.objects.get(\n                email=self.validated_data[\"email\"], is_verified=False\n            )\n\n            logger.debug(\n                \"Resending verification email to %s\",\n                self.validated_data[\"email\"],\n            )\n\n            email.send_confirmation()\n        except models.EmailAddress.DoesNotExist:\n            logger.debug(\n                \"Not resending verification email to %s because the address \"\n                \"doesn't exist in the database.\",\n                self.validated_data[\"email\"],\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new email address.", "response": "def create(self, *args, **kwargs):\n        \"\"\"\n        Create a new email address.\n        \"\"\"\n        is_primary = kwargs.pop(\"is_primary\", False)\n\n        with transaction.atomic():\n            email = super(EmailAddressManager, self).create(*args, **kwargs)\n\n            if is_primary:\n                email.set_primary()\n\n        return email"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_queryset(self):\n        oldest = timezone.now() - app_settings.PASSWORD_RESET_EXPIRATION\n        queryset = super(ValidPasswordResetTokenManager, self).get_queryset()\n\n        return queryset.filter(created_at__gt=oldest)", "response": "Return all expired password reset tokens."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle execution of the command.", "response": "def handle(self, *args, **kwargs):\n        \"\"\"\n        Handle execution of the command.\n        \"\"\"\n        cutoff = timezone.now()\n        cutoff -= app_settings.CONFIRMATION_EXPIRATION\n        cutoff -= app_settings.CONFIRMATION_SAVE_PERIOD\n\n        queryset = models.EmailConfirmation.objects.filter(\n            created_at__lte=cutoff\n        )\n\n        count = queryset.count()\n\n        queryset.delete()\n\n        if count:\n            self.stdout.write(\n                self.style.SUCCESS(\n                    \"Removed {count} old email confirmation(s)\".format(\n                        count=count\n                    )\n                )\n            )\n        else:\n            self.stdout.write(\"No email confirmations to remove.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_user(self, user_id):\n        try:\n            return get_user_model().objects.get(id=user_id)\n        except get_user_model().DoesNotExist:\n            return None", "response": "Get a user by their ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nattempts to authenticate a set of credentials.", "response": "def authenticate(self, request, email=None, password=None, username=None):\n        \"\"\"\n        Attempt to authenticate a set of credentials.\n\n        Args:\n            request:\n                The request associated with the authentication attempt.\n            email:\n                The user's email address.\n            password:\n                The user's password.\n            username:\n                An alias for the ``email`` field. This is provided for\n                compatability with Django's built in authentication\n                views.\n\n        Returns:\n            The user associated with the provided credentials if they\n            are valid. Returns ``None`` otherwise.\n        \"\"\"\n        email = email or username\n\n        try:\n            email_instance = models.EmailAddress.objects.get(\n                is_verified=True, email=email\n            )\n        except models.EmailAddress.DoesNotExist:\n            return None\n\n        user = email_instance.user\n\n        if user.check_password(password):\n            return user\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nauthenticates for the given username and password.", "response": "def authenticate(username, password, service='login', encoding='utf-8',\n                 resetcred=True):\n    \"\"\"Returns True if the given username and password authenticate for the\n    given service.  Returns False otherwise.\n\n    ``username``: the username to authenticate\n\n    ``password``: the password in plain text\n\n    ``service``: the PAM service to authenticate against.\n                 Defaults to 'login'\n\n    The above parameters can be strings or bytes.  If they are strings,\n    they will be encoded using the encoding given by:\n\n    ``encoding``: the encoding to use for the above parameters if they\n                  are given as strings.  Defaults to 'utf-8'\n\n    ``resetcred``: Use the pam_setcred() function to\n                   reinitialize the credentials.\n                   Defaults to 'True'.\n    \"\"\"\n\n    if sys.version_info >= (3,):\n        if isinstance(username, str):\n            username = username.encode(encoding)\n        if isinstance(password, str):\n            password = password.encode(encoding)\n        if isinstance(service, str):\n            service = service.encode(encoding)\n\n    @conv_func\n    def my_conv(n_messages, messages, p_response, app_data):\n        \"\"\"Simple conversation function that responds to any\n        prompt where the echo is off with the supplied password\"\"\"\n        # Create an array of n_messages response objects\n        addr = calloc(n_messages, sizeof(PamResponse))\n        p_response[0] = cast(addr, POINTER(PamResponse))\n        for i in range(n_messages):\n            if messages[i].contents.msg_style == PAM_PROMPT_ECHO_OFF:\n                pw_copy = strdup(password)\n                p_response.contents[i].resp = cast(pw_copy, c_char_p)\n                p_response.contents[i].resp_retcode = 0\n        return 0\n\n    handle = PamHandle()\n    conv = PamConv(my_conv, 0)\n    retval = pam_start(service, username, byref(conv), byref(handle))\n\n    if retval != 0:\n        # TODO: This is not an authentication error, something\n        # has gone wrong starting up PAM\n        return False\n\n    retval = pam_authenticate(handle, 0)\n    auth_success = (retval == 0)\n\n    # Re-initialize credentials (for Kerberos users, etc)\n    # Don't check return code of pam_setcred(), it shouldn't matter\n    # if this fails\n    if auth_success and resetcred:\n        retval = pam_setcred(handle, PAM_REINITIALIZE_CRED)\n\n    pam_end(handle, retval)\n\n    return auth_success"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves the provided data using the class serializer.", "response": "def post(self, request):\n        \"\"\"\n        Save the provided data using the class' serializer.\n\n        Args:\n            request:\n                The request being made.\n\n        Returns:\n            An ``APIResponse`` instance. If the request was successful\n            the response will have a 200 status code and contain the\n            serializer's data. Otherwise a 400 status code and the\n            request's errors will be returned.\n        \"\"\"\n        serializer = self.get_serializer(data=request.data)\n\n        if serializer.is_valid():\n            serializer.save()\n\n            return Response(serializer.data)\n\n        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an HTML tree block describing the given object.", "response": "def get_repr(self, obj, referent=None):\n        \"\"\"Return an HTML tree block describing the given object.\"\"\"\n        objtype = type(obj)\n        typename = str(objtype.__module__) + \".\" + objtype.__name__\n        prettytype = typename.replace(\"__builtin__.\", \"\")\n\n        name = getattr(obj, \"__name__\", \"\")\n        if name:\n            prettytype = \"%s %r\" % (prettytype, name)\n\n        key = \"\"\n        if referent:\n            key = self.get_refkey(obj, referent)\n        url = reverse('dowser_trace_object', args=(\n            typename,\n            id(obj)\n        ))\n        return ('<a class=\"objectid\" href=\"%s\">%s</a> '\n                '<span class=\"typename\">%s</span>%s<br />'\n                '<span class=\"repr\">%s</span>'\n                % (url, id(obj), prettytype, key, get_repr(obj, 100))\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_refkey(self, obj, referent):\n        if isinstance(obj, dict):\n            for k, v in obj.items():\n                if v is referent:\n                    return \" (via its %r key)\" % k\n\n        for k in dir(obj) + ['__dict__']:\n            if getattr(obj, k, None) is referent:\n                return \" (via its %r attribute)\" % k\n        return \"\"", "response": "Return the dict key or attribute name of obj which refers to\n        referent."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwalks the object tree ignoring duplicates and circular refs.", "response": "def walk(self, maxresults=100, maxdepth=None):\n        \"\"\"Walk the object tree, ignoring duplicates and circular refs.\"\"\"\n        log.debug(\"step\")\n        self.seen = {}\n        self.ignore(self, self.__dict__, self.obj, self.seen, self._ignore)\n\n        # Ignore the calling frame, its builtins, globals and locals\n        self.ignore_caller()\n        self.maxdepth = maxdepth\n        count = 0\n        log.debug(\"will iterate results\")\n        for result in self._gen(self.obj):\n            log.debug(\"will yeld\")\n            yield result\n            count += 1\n            if maxresults and count >= maxresults:\n                yield 0, 0, \"==== Max results reached ====\"\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_tree(self, maxresults=100, maxdepth=None):\n        self.ignore_caller()\n        for depth, refid, rep in self.walk(maxresults, maxdepth):\n            print((\"%9d\" % refid), (\" \" * depth * 2), rep)", "response": "Walk the object tree and print each branch."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwalks the object tree and print each branch.", "response": "def print_tree(self, maxresults=100, maxdepth=None):\n        \"\"\"Walk the object tree, pretty-printing each branch.\"\"\"\n        self.ignore_caller()\n        for trail in self.walk(maxresults, maxdepth):\n            print(trail)\n        if self.stops:\n            print(\"%s paths stopped because max depth reached\" % self.stops)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_finders():\n    if hasattr(settings, 'MEDIA_FIXTURES_FILES_FINDERS'):\n        finders = settings.MEDIA_FIXTURES_FILES_FINDERS\n    else:\n        finders = (\n            'django_media_fixtures.finders.AppDirectoriesFinder',\n        )\n\n    for finder_path in finders:\n        yield get_finder(finder_path)", "response": "Yields a generator of all media fixtures finders."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the media fixtures files finder class described by import_path.", "response": "def get_finder(import_path):\n    \"\"\"\n    Imports the media fixtures files finder class described by import_path, where\n    import_path is the full Python path to the class.\n    \"\"\"\n    Finder = import_string(import_path)\n    if not issubclass(Finder, BaseFinder):\n        raise ImproperlyConfigured('Finder \"%s\" is not a subclass of \"%s\"' %\n                                   (Finder, BaseFinder))\n    return Finder()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find(self, path, all=False):\n        matches = []\n        for prefix, root in self.locations:\n            if root not in searched_locations:\n                searched_locations.append(root)\n            matched_path = self.find_location(root, path, prefix)\n            if matched_path:\n                if not all:\n                    return matched_path\n                matches.append(matched_path)\n        return matches", "response": "Find the files in the extra locations that are located at the given path."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds a requested media file in a location returning the absolute path.", "response": "def find_location(self, root, path, prefix=None):\n        \"\"\"\n        Finds a requested media file in a location, returning the found\n        absolute path (or ``None`` if no match).\n        \"\"\"\n        if prefix:\n            prefix = '%s%s' % (prefix, os.sep)\n            if not path.startswith(prefix):\n                return None\n            path = path[len(prefix):]\n        path = safe_join(root, path)\n        if os.path.exists(path):\n            return path"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting all files in all locations.", "response": "def list(self, ignore_patterns):\n        \"\"\"\n        List all files in all locations.\n        \"\"\"\n        for prefix, root in self.locations:\n            storage = self.storages[root]\n            for path in utils.get_files(storage, ignore_patterns):\n                yield path, storage"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list(self, ignore_patterns):\n        for storage in six.itervalues(self.storages):\n            if storage.exists(''):  # check if storage location exists\n                for path in utils.get_files(storage, ignore_patterns):\n                    yield path, storage", "response": "List all files in all app storages."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind the files in the app directories and return the list of matches.", "response": "def find(self, path, all=False):\n        \"\"\"\n        Looks for files in the app directories.\n        \"\"\"\n        matches = []\n        for app in self.apps:\n            app_location = self.storages[app].location\n            if app_location not in searched_locations:\n                searched_locations.append(app_location)\n            match = self.find_in_app(app, path)\n            if match:\n                if not all:\n                    return match\n                matches.append(match)\n        return matches"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_in_app(self, app, path):\n        storage = self.storages.get(app, None)\n        if storage:\n            # only try to find a file if the source dir actually exists\n            if storage.exists(path):\n                matched_path = storage.path(path)\n                if matched_path:\n                    return matched_path", "response": "Find a requested media file in an app s media fixtures locations."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_options(self, **options):\n        self.interactive = options['interactive']\n        self.verbosity = options['verbosity']\n        self.symlink = options['link']\n        self.clear = options['clear']\n        self.dry_run = options['dry_run']\n        ignore_patterns = options['ignore_patterns']\n        if options['use_default_ignore_patterns']:\n            ignore_patterns += ['CVS', '.*', '*~']\n        self.ignore_patterns = list(set(ignore_patterns))\n        self.post_process = options['post_process']", "response": "Set instance variables based on an options dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncollect the media files and store them in a dictionary.", "response": "def collect(self):\n        \"\"\"\n        Perform the bulk of the work of collectmedia.\n\n        Split off from handle() to facilitate testing.\n        \"\"\"\n        if self.symlink and not self.local:\n            raise CommandError(\"Can't symlink to a remote destination.\")\n\n        if self.clear:\n            self.clear_dir('')\n\n        if self.symlink:\n            handler = self.link_file\n        else:\n            handler = self.copy_file\n\n        found_files = OrderedDict()\n        for finder in get_finders():\n            for path, storage in finder.list(self.ignore_patterns):\n                # Prefix the relative path if the source storage contains it\n                if getattr(storage, 'prefix', None):\n                    prefixed_path = os.path.join(storage.prefix, path)\n                else:\n                    prefixed_path = path\n\n                if prefixed_path not in found_files:\n                    found_files[prefixed_path] = (storage, path)\n                    handler(path, prefixed_path, storage)\n\n        # Here we check if the storage backend has a post_process\n        # method and pass it the list of modified files.\n        if self.post_process and hasattr(self.storage, 'post_process'):\n            processor = self.storage.post_process(found_files,\n                                                  dry_run=self.dry_run)\n            for original_path, processed_path, processed in processor:\n                if isinstance(processed, Exception):\n                    self.stderr.write(\"Post-processing '%s' failed!\" % original_path)\n                    # Add a blank line before the traceback, otherwise it's\n                    # too easy to miss the relevant part of the error message.\n                    self.stderr.write(\"\")\n                    raise processed\n                if processed:\n                    self.log(\"Post-processed '%s' as '%s'\" %\n                             (original_path, processed_path), level=1)\n                    self.post_processed_files.append(original_path)\n                else:\n                    self.log(\"Skipped post-processing '%s'\" % original_path)\n\n        return {\n            'modified': self.copied_files + self.symlinked_files,\n            'unmodified': self.unmodified_files,\n            'post_processed': self.post_processed_files,\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes the given relative path using the destination storage backend.", "response": "def clear_dir(self, path):\n        \"\"\"\n        Deletes the given relative path using the destination storage backend.\n        \"\"\"\n        dirs, files = self.storage.listdir(path)\n        for f in files:\n            fpath = os.path.join(path, f)\n            if self.dry_run:\n                self.log(\"Pretending to delete '%s'\" %\n                         smart_text(fpath), level=1)\n            else:\n                self.log(\"Deleting '%s'\" % smart_text(fpath), level=1)\n                self.storage.delete(fpath)\n        for d in dirs:\n            self.clear_dir(os.path.join(path, d))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_file(self, path, prefixed_path, source_storage):\n        if self.storage.exists(prefixed_path):\n            try:\n                # When was the target file modified last time?\n                target_last_modified = \\\n                    self.storage.modified_time(prefixed_path)\n            except (OSError, NotImplementedError, AttributeError):\n                # The storage doesn't support ``modified_time`` or failed\n                pass\n            else:\n                try:\n                    # When was the source file modified last time?\n                    source_last_modified = source_storage.modified_time(path)\n                except (OSError, NotImplementedError, AttributeError):\n                    pass\n                else:\n                    # The full path of the target file\n                    if self.local:\n                        full_path = self.storage.path(prefixed_path)\n                    else:\n                        full_path = None\n                    # Skip the file if the source file is younger\n                    # Avoid sub-second precision (see #14665, #19540)\n                    if (target_last_modified.replace(microsecond=0)\n                            >= source_last_modified.replace(microsecond=0)):\n                        if not ((self.symlink and full_path\n                                 and not os.path.islink(full_path)) or\n                                (not self.symlink and full_path\n                                 and os.path.islink(full_path))):\n                            if prefixed_path not in self.unmodified_files:\n                                self.unmodified_files.append(prefixed_path)\n                            self.log(\"Skipping '%s' (not modified)\" % path)\n                            return False\n            # Then delete the existing file if really needed\n            if self.dry_run:\n                self.log(\"Pretending to delete '%s'\" % path)\n            else:\n                self.log(\"Deleting '%s'\" % path)\n                self.storage.delete(prefixed_path)\n        return True", "response": "Checks if the target file should be deleted if it exists and if it should be deleted if it should be deleted if it already exists and if it should be deleted if it should be deleted if it should be deleted if it already exists and if it should be deleted if it should be deleted if it should be deleted if it already exists."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef link_file(self, path, prefixed_path, source_storage):\n        # Skip this file if it was already copied earlier\n        if prefixed_path in self.symlinked_files:\n            return self.log(\"Skipping '%s' (already linked earlier)\" % path)\n        # Delete the target file if needed or break\n        if not self.delete_file(path, prefixed_path, source_storage):\n            return\n        # The full path of the source file\n        source_path = source_storage.path(path)\n        # Finally link the file\n        if self.dry_run:\n            self.log(\"Pretending to link '%s'\" % source_path, level=1)\n        else:\n            self.log(\"Linking '%s'\" % source_path, level=1)\n            full_path = self.storage.path(prefixed_path)\n            try:\n                os.makedirs(os.path.dirname(full_path))\n            except OSError:\n                pass\n            try:\n                if os.path.lexists(full_path):\n                    os.unlink(full_path)\n                os.symlink(source_path, full_path)\n            except AttributeError:\n                import platform\n                raise CommandError(\"Symlinking is not supported by Python %s.\" %\n                                   platform.python_version())\n            except NotImplementedError:\n                import platform\n                raise CommandError(\"Symlinking is not supported in this \"\n                                   \"platform (%s).\" % platform.platform())\n            except OSError as e:\n                raise CommandError(e)\n        if prefixed_path not in self.symlinked_files:\n            self.symlinked_files.append(prefixed_path)", "response": "Link the file at the given path to the source file at the given prefixed_path."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncopies a file from source_storage to the target storage.", "response": "def copy_file(self, path, prefixed_path, source_storage):\n        \"\"\"\n        Attempt to copy ``path`` with storage\n        \"\"\"\n        # Skip this file if it was already copied earlier\n        if prefixed_path in self.copied_files:\n            return self.log(\"Skipping '%s' (already copied earlier)\" % path)\n        # Delete the target file if needed or break\n        if not self.delete_file(path, prefixed_path, source_storage):\n            return\n        # The full path of the source file\n        source_path = source_storage.path(path)\n        # Finally start copying\n        if self.dry_run:\n            self.log(\"Pretending to copy '%s'\" % source_path, level=1)\n        else:\n            self.log(\"Copying '%s'\" % source_path, level=1)\n            with source_storage.open(path) as source_file:\n                self.storage.save(prefixed_path, source_file)\n        self.copied_files.append(prefixed_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reorderChild(self, parent, newitem):\n        source = self.getItem(parent).childItems\n        target = newitem.childItems\n\n        i = 0\n        while i < len(source):\n\n            if source[i] == target[i]:\n                i += 1\n                continue\n            else:\n                i0 = i\n                j0 = source.index(target[i0])\n                j = j0 + 1\n                while j < len(source):\n                    if source[j] == target[j - j0 + i0]:\n                        j += 1\n                        continue\n                    else:\n                        break\n                self.moveRows(parent, i0, j0, j - j0)\n                i += j - j0", "response": "Reorder a list to match target by moving a sequence at a time."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef moveRows(self, parent, index_to, index_from, length):\n        source = self.getItem(parent).childItems\n\n        self.beginMoveRows(\n            parent, index_from, index_from + length - 1, parent, index_to\n        )\n\n        sublist = [source.pop(index_from) for _ in range(length)]\n\n        for _ in range(length):\n            source.insert(index_to, sublist.pop())\n\n        self.endMoveRows()", "response": "Move a sub sequence in a list\n            parent to index_to."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cur_space(self, name=None):\n        if name is None:\n            return self._impl.model.currentspace.interface\n        else:\n            self._impl.model.currentspace = self._impl.spaces[name]\n            return self.cur_space()", "response": "Set the current space to the space named name and return it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef new_space(self, name=None, bases=None, formula=None, refs=None):\n        space = self._impl.model.currentspace = self._impl.new_space(\n            name=name, bases=get_impls(bases), formula=formula, refs=refs\n        )\n\n        return space.interface", "response": "Create a new child space."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef import_module(self, module=None, recursive=False, **params):\n        if module is None:\n            if \"module_\" in params:\n                warnings.warn(\n                    \"Parameter 'module_' is deprecated. Use 'module' instead.\")\n                module = params.pop(\"module_\")\n            else:\n                raise ValueError(\"no module specified\")\n\n        if \"bases\" in params:\n            params[\"bases\"] = get_impls(params[\"bases\"])\n\n        space = (\n            self._impl.model.currentspace\n        ) = self._impl.new_space_from_module(\n            module, recursive=recursive, **params\n        )\n        return get_interfaces(space)", "response": "Create a child space from a module object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef new_space_from_module(self, module, recursive=False, **params):\n        if \"bases\" in params:\n            params[\"bases\"] = get_impls(params[\"bases\"])\n\n        space = (\n            self._impl.model.currentspace\n        ) = self._impl.new_space_from_module(\n            module, recursive=recursive, **params\n        )\n        return get_interfaces(space)", "response": "Create a new child space from a module object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new child space from an Excel file.", "response": "def new_space_from_excel(\n        self,\n        book,\n        range_,\n        sheet=None,\n        name=None,\n        names_row=None,\n        param_cols=None,\n        space_param_order=None,\n        cells_param_order=None,\n        transpose=False,\n        names_col=None,\n        param_rows=None,\n    ):\n        \"\"\"Create a child space from an Excel range.\n\n        To use this method, ``openpyxl`` package must be installed.\n\n        Args:\n            book (str): Path to an Excel file.\n            range_ (str): Range expression, such as \"A1\", \"$G4:$K10\",\n                or named range \"NamedRange1\".\n            sheet (str): Sheet name (case ignored).\n            name (str, optional): Name of the space. Defaults to ``SpaceN``,\n                where ``N`` is a number determined automatically.\n            names_row (optional): an index number indicating\n                what row contains the names of cells and parameters.\n                Defaults to the top row (0).\n            param_cols (optional): a sequence of index numbers\n                indicating parameter columns.\n                Defaults to only the leftmost column ([0]).\n            names_col (optional): an index number, starting from 0,\n                indicating what column contains additional parameters.\n            param_rows (optional): a sequence of index numbers, starting from\n                0, indicating rows of additional parameters, in case cells are\n                defined in two dimensions.\n            transpose (optional): Defaults to ``False``.\n                If set to ``True``, \"row(s)\" and \"col(s)\" in the parameter\n                names are interpreted inversely, i.e.\n                all indexes passed to \"row(s)\" parameters are interpreted\n                as column indexes,\n                and all indexes passed to \"col(s)\" parameters as row indexes.\n            space_param_order: a sequence to specify space parameters and\n                their orders. The elements of the sequence denote the indexes\n                of ``param_cols`` elements, and optionally the index of\n                ``param_rows`` elements shifted by the length of\n                ``param_cols``. The elements of this parameter and\n                ``cell_param_order`` must not overlap.\n            cell_param_order (optional): a sequence to reorder the parameters.\n                The elements of the sequence denote the indexes of\n                ``param_cols`` elements, and optionally the index of\n                ``param_rows`` elements shifted by the length of\n                ``param_cols``. The elements of this parameter and\n                ``cell_space_order`` must not overlap.\n\n        Returns:\n            The new child space created from the Excel range.\n        \"\"\"\n\n        space = self._impl.new_space_from_excel(\n            book,\n            range_,\n            sheet,\n            name,\n            names_row,\n            param_cols,\n            space_param_order,\n            cells_param_order,\n            transpose,\n            names_col,\n            param_rows,\n        )\n\n        return get_interfaces(space)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef restore_state(self, system):\n\n        for space in self._spaces.values():\n            space.restore_state(system)", "response": "Called after unpickling to restore some attributes manually."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef new_space(\n        self,\n        name=None,\n        bases=None,\n        formula=None,\n        *,\n        refs=None,\n        source=None,\n        is_derived=False,\n        prefix=\"\"\n    ):\n        \"\"\"Create a new child space.\n\n        Args:\n            name (str): Name of the space. If omitted, the space is\n                created automatically.\n            bases: If specified, the new space becomes a derived space of\n                the `base` space.\n            formula: Function whose parameters used to set space parameters.\n            refs: a mapping of refs to be added.\n            arguments: ordered dict of space parameter names to their values.\n            source: A source module from which cell definitions are read.\n            prefix: Prefix to the autogenerated name when name is None.\n        \"\"\"\n        from modelx.core.space import StaticSpaceImpl\n\n        if name is None:\n            name = self.spacenamer.get_next(self.namespace, prefix)\n\n        if name in self.namespace:\n            raise ValueError(\"Name '%s' already exists.\" % name)\n\n        if not prefix and not is_valid_name(name):\n            raise ValueError(\"Invalid name '%s'.\" % name)\n\n        space = self._new_space(\n            name=name,\n            formula=formula,\n            refs=refs,\n            source=source,\n            is_derived=is_derived,\n        )\n        self._set_space(space)\n\n        self.model.spacegraph.add_space(space)\n\n        # Set up direct base spaces and mro\n        if bases is not None:\n            if isinstance(bases, StaticSpaceImpl):\n                bases = [bases]\n\n            space.add_bases(bases)\n\n        return space", "response": "Create a new child space."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a node from arguments and return it", "response": "def get_node(obj, args, kwargs):\n    \"\"\"Create a node from arguments and return it\"\"\"\n\n    if args is None and kwargs is None:\n        return (obj,)\n\n    if kwargs is None:\n        kwargs = {}\n    return obj, _bind_args(obj, args, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef node_get_args(node):\n    obj = node[OBJ]\n    key = node[KEY]\n    boundargs = obj.formula.signature.bind(*key)\n    boundargs.apply_defaults()\n    return boundargs.arguments", "response": "Return an ordered mapping from params to args"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a modelx object from its full name.", "response": "def get_object(name: str):\n    \"\"\"Get a modelx object from its full name.\"\"\"\n    # TODO: Duplicate of system.get_object\n    elms = name.split(\".\")\n    parent = get_models()[elms.pop(0)]\n    while len(elms) > 0:\n        obj = elms.pop(0)\n        parent = getattr(parent, obj)\n\n    return parent"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_node(name: str, args: str):\n    obj = get_object(name)\n    args = ast.literal_eval(args)\n    if not isinstance(args, tuple):\n        args = (args,)\n\n    return obj.node(*args)", "response": "Get node from object name and arg string\n\n    Not Used. Left for future reference purpose."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cur_model(model=None):\n    if model is None:\n        if _system.currentmodel is not None:\n            return _system.currentmodel.interface\n        else:\n            return None\n    else:\n        if isinstance(model, _Model):\n            _system.currentmodel = model._impl\n        else:\n            _system.currentmodel = _system.models[model]\n\n        return _system.currentmodel.interface", "response": "Get and or set the current model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting and / or set the current space of the current model.", "response": "def cur_space(space=None):\n    \"\"\"Get and/or set the current space of the current model.\n\n    If ``name`` is given, the current space of the current model is\n    set to ``name`` and return it.\n    If ``name`` is not given, the current space of the current model\n    is returned.\n    \"\"\"\n    if space is None:\n        if _system.currentmodel is not None:\n            if _system.currentmodel.currentspace is not None:\n                return _system.currentmodel.currentspace.interface\n            else:\n                return None\n        else:\n            return None\n    else:\n        if isinstance(space, _Space):\n            cur_model(space.model)\n            _system.currentmodel.currentspace = space._impl\n        else:\n            _system.currentmodel.currentspace = _system.currentmodel.spaces[\n                space\n            ]\n\n        return cur_space()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhook to override default showwarning.", "response": "def custom_showwarning(\n    message, category, filename=\"\", lineno=-1, file=None, line=None\n):\n    \"\"\"Hook to override default showwarning.\n\n    https://stackoverflow.com/questions/2187269/python-print-only-the-message-on-warnings\n    \"\"\"\n\n    if file is None:\n        file = sys.stderr\n        if file is None:\n            # sys.stderr is None when run with pythonw.exe:\n            # warnings get lost\n            return\n    text = \"%s: %s\\n\" % (category.__name__, message)\n    try:\n        file.write(text)\n    except OSError:\n        # the file (probably stderr) is invalid - this warning gets lost.\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef excepthook(self, except_type, exception, traceback):\n    if except_type is DeepReferenceError:\n        print(exception.msg)\n    else:\n        self.default_excepthook(except_type, exception, traceback)", "response": "Custom exception hook to replace sys. excepthook\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tracemessage(self, maxlen=6):\n        result = \"\"\n        for i, value in enumerate(self):\n            result += \"{0}: {1}\\n\".format(i, get_node_repr(value))\n\n        result = result.strip(\"\\n\")\n        lines = result.split(\"\\n\")\n\n        if maxlen and len(lines) > maxlen:\n            i = int(maxlen / 2)\n            lines = lines[:i] + [\"...\"] + lines[-(maxlen - i) :]\n            result = \"\\n\".join(lines)\n\n        return result", "response": "Returns a string representation of the log entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setup_ipython(self):\n        if self.is_ipysetup:\n            return\n\n        from ipykernel.kernelapp import IPKernelApp\n\n        self.shell = IPKernelApp.instance().shell  # None in PyCharm console\n\n        if not self.shell and is_ipython():\n            self.shell = get_ipython()\n\n        if self.shell:\n            shell_class = type(self.shell)\n            shell_class.default_showtraceback = shell_class.showtraceback\n            shell_class.showtraceback = custom_showtraceback\n            self.is_ipysetup = True\n        else:\n            raise RuntimeError(\"IPython shell not found.\")", "response": "Monkey patch shell s error handler to include the custom showtraceback method of the IPython kernel."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef restore_ipython(self):\n        if not self.is_ipysetup:\n            return\n\n        shell_class = type(self.shell)\n        shell_class.showtraceback = shell_class.default_showtraceback\n        del shell_class.default_showtraceback\n\n        self.is_ipysetup = False", "response": "Restore default IPython showtraceback"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrestores Python settings to the original states", "response": "def restore_python(self):\n        \"\"\"Restore Python settings to the original states\"\"\"\n        orig = self.orig_settings\n        sys.setrecursionlimit(orig[\"sys.recursionlimit\"])\n\n        if \"sys.tracebacklimit\" in orig:\n            sys.tracebacklimit = orig[\"sys.tracebacklimit\"]\n        else:\n            if hasattr(sys, \"tracebacklimit\"):\n                del sys.tracebacklimit\n\n        if \"showwarning\" in orig:\n            warnings.showwarning = orig[\"showwarning\"]\n\n        orig.clear()\n        threading.stack_size()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_object(self, name):\n\n        parts = name.split(\".\")\n\n        model_name = parts.pop(0)\n        return self.models[model_name].get_object(\".\".join(parts))", "response": "Retrieve an object by its absolute name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_modeltree(model=None):\n    if model is None:\n        model = mx.cur_model()\n    treemodel = ModelTreeModel(model._baseattrs)\n    view = QTreeView()\n    view.setModel(treemodel)\n    view.setWindowTitle(\"Model %s\" % model.name)\n    view.setAlternatingRowColors(True)\n    return view", "response": "Alias to : func : get_tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef show_tree(model=None):\n    if model is None:\n        model = mx.cur_model()\n    view = get_modeltree(model)\n    app = QApplication.instance()\n    if not app:\n        raise RuntimeError(\"QApplication does not exist.\")\n    view.show()\n    app.exec_()", "response": "Display the model tree window."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget interfaces from their implementations.", "response": "def get_interfaces(impls):\n    \"\"\"Get interfaces from their implementations.\"\"\"\n    if impls is None:\n        return None\n\n    elif isinstance(impls, OrderMixin):\n        result = OrderedDict()\n        for name in impls.order:\n            result[name] = impls[name].interface\n        return result\n\n    elif isinstance(impls, Mapping):\n        return {name: impls[name].interface for name in impls}\n\n    elif isinstance(impls, Sequence):\n        return [impl.interface for impl in impls]\n\n    else:\n        return impls.interface"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_impls(interfaces):\n    if interfaces is None:\n        return None\n\n    elif isinstance(interfaces, Mapping):\n        return {name: interfaces[name]._impl for name in interfaces}\n\n    elif isinstance(interfaces, Sequence):\n        return [interfaces._impl for interfaces in interfaces]\n\n    else:\n        return interfaces._impl", "response": "Get impls from their interfaces."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating all LazyEvals in self. lzy_evals enough to update all owned LazyEvals.", "response": "def update_lazyevals(self):\n        \"\"\"Update all LazyEvals in self\n\n        self.lzy_evals must be set to LazyEval object(s) enough to\n        update all owned LazyEval objects.\n        \"\"\"\n        if self.lazy_evals is None:\n            return\n        elif isinstance(self.lazy_evals, LazyEval):\n            self.lazy_evals.get_updated()\n        else:\n            for lz in self.lazy_evals:\n                lz.get_updated()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _baseattrs(self):\n\n        result = {\n            \"type\": type(self).__name__,\n            \"id\": id(self),\n            \"name\": self.name,\n            \"fullname\": self.fullname,\n            \"repr\": self._get_repr(),\n        }\n\n        return result", "response": "A dict of members expressed in literals"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _to_attrdict(self, attrs=None):\n        result = self._baseattrs\n\n        for attr in attrs:\n            if hasattr(self, attr):\n                result[attr] = getattr(self, attr)._to_attrdict(attrs)\n\n        return result", "response": "Convert the attribute list to a dictionary of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _update_data(self):\n\n        func = self.owner.formula.func\n        codeobj = func.__code__\n        name = func.__name__  # self.cells.name   # func.__name__\n        namespace_impl = self.owner._namespace_impl.get_updated()\n        namespace = namespace_impl.interfaces\n        selfnode = get_node(self.owner, None, None)\n\n        for name in self.owner.formula.srcnames:\n            if name in namespace_impl and isinstance(\n                namespace_impl[name], ReferenceImpl\n            ):\n                refnode = get_node(namespace_impl[name], None, None)\n                self.owner.model.lexdep.add_path([selfnode, refnode])\n\n        closure = func.__closure__  # None normally.\n        if closure is not None:  # pytest fails without this.\n            closure = create_closure(self.owner.interface)\n\n        self.altfunc = FunctionType(\n            codeobj, namespace, name=name, closure=closure\n        )", "response": "Update altfunc with new data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_args(args, kwargs):\n\n    found = False\n    for arg in args:\n        if isinstance(arg, Cells):\n            found = True\n            break\n\n    if found:\n        args = tuple(\n            arg.value if isinstance(arg, Cells) else arg for arg in args\n        )\n\n    if kwargs is not None:\n        for key, arg in kwargs.items():\n            if isinstance(arg, Cells):\n                kwargs[key] = arg.value\n\n    return args, kwargs", "response": "If args and kwargs contains Cells convert them to their values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef shareable_parameters(cells):\n    result = []\n    for c in cells.values():\n        params = c.formula.parameters\n\n        for i in range(min(len(result), len(params))):\n            if params[i] != result[i]:\n                return None\n\n        for i in range(len(result), len(params)):\n            result.append(params[i])\n\n    return result", "response": "Returns a list of parameters that are shareable among multiple cells."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake a copy of itself and return it.", "response": "def copy(self, space=None, name=None):\n        \"\"\"Make a copy of itself and return it.\"\"\"\n        return Cells(space=space, name=name, formula=self.formula)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a CellNode object for the given arguments.", "response": "def node(self, *args, **kwargs):\n        \"\"\"Return a :class:`CellNode` object for the given arguments.\"\"\"\n        return CellNode(get_node(self._impl, *convert_args(args, kwargs)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _baseattrs(self):\n\n        result = super()._baseattrs\n        result[\"params\"] = \", \".join(self.parameters)\n        return result", "response": "A dict of members expressed in literals"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef value(self):\n        if self.has_value:\n            return self._impl[OBJ].get_value(self._impl[KEY])\n        else:\n            raise ValueError(\"Value not found\")", "response": "Return the value of the cells."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _baseattrs(self):\n\n        result = {\n            \"type\": type(self).__name__,\n            \"obj\": self.cells._baseattrs,\n            \"args\": self.args,\n            \"value\": self.value if self.has_value else None,\n            \"predslen\": len(self.preds),\n            \"succslen\": len(self.succs),\n            \"repr_parent\": self.cells._impl.repr_parent(),\n            \"repr\": self.cells._get_repr(),\n        }\n\n        return result", "response": "A dict of members expressed in literals"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreordering a list to match target by moving a sequence at a time.", "response": "def reorder_list(source, targetorder):\n    \"\"\"Reorder a list to match target by moving a sequence at a time.\n\n    Written for QtAbstractItemModel.moveRows.\n    \"\"\"\n    i = 0\n    while i < len(source):\n\n        if source[i] == targetorder[i]:\n            i += 1\n            continue\n        else:\n            i0 = i\n            j0 = source.index(targetorder[i0])\n            j = j0 + 1\n            while j < len(source):\n                if source[j] == targetorder[j - j0 + i0]:\n                    j += 1\n                    continue\n                else:\n                    break\n            move_elements(source, i0, j0, j - j0)\n            i += j - j0"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmoves a sub sequence in a list", "response": "def move_elements(source, index_to, index_from, length):\n    \"\"\"Move a sub sequence in a list\"\"\"\n\n    sublist = [source.pop(index_from) for _ in range(length)]\n\n    for _ in range(length):\n        source.insert(index_to, sublist.pop())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert column name to index.", "response": "def _get_col_index(name):\n    \"\"\"Convert column name to index.\"\"\"\n\n    index = string.ascii_uppercase.index\n    col = 0\n    for c in name.upper():\n        col = col * 26 + index(c) + 1\n    return col"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_range(book, range_, sheet):\n\n    filename = None\n    if isinstance(book, str):\n        filename = book\n        book = opxl.load_workbook(book, data_only=True)\n    elif isinstance(book, opxl.Workbook):\n        pass\n    else:\n        raise TypeError\n\n    if _is_range_address(range_):\n        sheet_names = [name.upper() for name in book.sheetnames]\n        index = sheet_names.index(sheet.upper())\n        data = book.worksheets[index][range_]\n    else:\n        data = _get_namedrange(book, range_, sheet)\n        if data is None:\n            raise ValueError(\n                \"Named range '%s' not found in %s\" % (range_, filename or book)\n            )\n\n    return data", "response": "Return a range as nested dict of openpyxl cells."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_range(filepath, range_expr, sheet=None, dict_generator=None):\n\n    def default_generator(cells):\n        for row_ind, row in enumerate(cells):\n            for col_ind, cell in enumerate(row):\n                yield (row_ind, col_ind), cell.value\n\n    book = opxl.load_workbook(filepath, data_only=True)\n\n    if _is_range_address(range_expr):\n        sheet_names = [name.upper() for name in book.sheetnames]\n        index = sheet_names.index(sheet.upper())\n        cells = book.worksheets[index][range_expr]\n    else:\n        cells = _get_namedrange(book, range_expr, sheet)\n\n    # In case of a single cell, return its value.\n    if isinstance(cells, opxl.cell.Cell):\n        return cells.value\n\n    if dict_generator is None:\n        dict_generator = default_generator\n\n    gen = dict_generator(cells)\n    return {keyval[0]: keyval[1] for keyval in gen}", "response": "Read values from an Excel file into a nested list containing the values of the specified range."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_namedrange(book, rangename, sheetname=None):\n\n    def cond(namedef):\n\n        if namedef.type.upper() == \"RANGE\":\n            if namedef.name.upper() == rangename.upper():\n\n                if sheetname is None:\n                    if not namedef.localSheetId:\n                        return True\n\n                else:  # sheet local name\n                    sheet_id = [sht.upper() for sht in book.sheetnames].index(\n                        sheetname.upper()\n                    )\n\n                    if namedef.localSheetId == sheet_id:\n                        return True\n\n        return False\n\n    def get_destinations(name_def):\n        \"\"\"Workaround for the bug in DefinedName.destinations\"\"\"\n\n        from openpyxl.formula import Tokenizer\n        from openpyxl.utils.cell import SHEETRANGE_RE\n\n        if name_def.type == \"RANGE\":\n            tok = Tokenizer(\"=\" + name_def.value)\n            for part in tok.items:\n                if part.subtype == \"RANGE\":\n                    m = SHEETRANGE_RE.match(part.value)\n                    if m.group(\"quoted\"):\n                        sheet_name = m.group(\"quoted\")\n                    else:\n                        sheet_name = m.group(\"notquoted\")\n\n                    yield sheet_name, m.group(\"cells\")\n\n    namedef = next(\n        (item for item in book.defined_names.definedName if cond(item)), None\n    )\n\n    if namedef is None:\n        return None\n\n    dests = get_destinations(namedef)\n    xlranges = []\n\n    sheetnames_upper = [name.upper() for name in book.sheetnames]\n\n    for sht, addr in dests:\n        if sheetname:\n            sht = sheetname\n        index = sheetnames_upper.index(sht.upper())\n        xlranges.append(book.worksheets[index][addr])\n\n    if len(xlranges) == 1:\n        return xlranges[0]\n    else:\n        return xlranges", "response": "Get a named range from a workbook."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_mro(self, space):\n        seqs = [self.get_mro(base) for base\n                in self.get_bases(space)] + [list(self.get_bases(space))]\n        res = []\n        while True:\n            non_empty = list(filter(None, seqs))\n\n            if not non_empty:\n                # Nothing left to process, we're done.\n                res.insert(0, space)\n                return res\n\n            for seq in non_empty:  # Find merge candidates among seq heads.\n                candidate = seq[0]\n                not_head = [s for s in non_empty if candidate in s[1:]]\n                if not_head:\n                    # Reject the candidate.\n                    candidate = None\n                else:\n                    break\n\n            if not candidate:\n                raise TypeError(\n                    \"inconsistent hierarchy, no C3 MRO is possible\")\n\n            res.append(candidate)\n\n            for seq in non_empty:\n                # Remove candidate.\n                if seq[0] == candidate:\n                    del seq[0]", "response": "Calculate the Method Resolution Order of bases using the C3 algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new code object by altering some of the attributes of the code object.", "response": "def _alter_code(code, **attrs):\n    \"\"\"Create a new code object by altering some of ``code`` attributes\n\n    Args:\n        code: code objcect\n        attrs: a mapping of names of code object attrs to their values\n    \"\"\"\n\n    PyCode_New = ctypes.pythonapi.PyCode_New\n\n    PyCode_New.argtypes = (\n        ctypes.c_int,\n        ctypes.c_int,\n        ctypes.c_int,\n        ctypes.c_int,\n        ctypes.c_int,\n        ctypes.py_object,\n        ctypes.py_object,\n        ctypes.py_object,\n        ctypes.py_object,\n        ctypes.py_object,\n        ctypes.py_object,\n        ctypes.py_object,\n        ctypes.py_object,\n        ctypes.c_int,\n        ctypes.py_object)\n\n    PyCode_New.restype = ctypes.py_object\n\n    args = [\n        [code.co_argcount, 'co_argcount'],\n        [code.co_kwonlyargcount, 'co_kwonlyargcount'],\n        [code.co_nlocals, 'co_nlocals'],\n        [code.co_stacksize, 'co_stacksize'],\n        [code.co_flags, 'co_flags'],\n        [code.co_code, 'co_code'],\n        [code.co_consts, 'co_consts'],\n        [code.co_names, 'co_names'],\n        [code.co_varnames, 'co_varnames'],\n        [code.co_freevars, 'co_freevars'],\n        [code.co_cellvars, 'co_cellvars'],\n        [code.co_filename, 'co_filename'],\n        [code.co_name, 'co_name'],\n        [code.co_firstlineno, 'co_firstlineno'],\n        [code.co_lnotab, 'co_lnotab']]\n\n    for arg in args:\n        if arg[1] in attrs:\n            arg[0] = attrs[arg[1]]\n\n    return PyCode_New(\n        args[0][0],  # code.co_argcount,\n        args[1][0],  # code.co_kwonlyargcount,\n        args[2][0],  # code.co_nlocals,\n        args[3][0],  # code.co_stacksize,\n        args[4][0],  # code.co_flags,\n        args[5][0],  # code.co_code,\n        args[6][0],  # code.co_consts,\n        args[7][0],  # code.co_names,\n        args[8][0],  # code.co_varnames,\n        args[9][0],  # code.co_freevars,\n        args[10][0],  # code.co_cellvars,\n        args[11][0],  # code.co_filename,\n        args[12][0],  # code.co_name,\n        args[13][0],  # code.co_firstlineno,\n        args[14][0])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new function with modified local variables.", "response": "def alter_freevars(func, globals_=None, **vars):\n    \"\"\"Replace local variables with free variables\n\n    Warnings:\n        This function does not work.\n    \"\"\"\n\n    if globals_ is None:\n        globals_ = func.__globals__\n\n    frees = tuple(vars.keys())\n    oldlocs = func.__code__.co_names\n    newlocs = tuple(name for name in oldlocs if name not in frees)\n\n    code = _alter_code(func.__code__,\n                       co_freevars=frees,\n                       co_names=newlocs,\n                       co_flags=func.__code__.co_flags | inspect.CO_NESTED)\n    closure = _create_closure(*vars.values())\n\n    return FunctionType(code, globals_, closure=closure)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfixes the lamdaline of a source string.", "response": "def fix_lamdaline(source):\n    \"\"\"Remove the last redundant token from lambda expression\n\n    lambda x: return x)\n                      ^\n    Return string without irrelevant tokens\n    returned from inspect.getsource on lamda expr returns\n    \"\"\"\n\n    # Using undocumented generate_tokens due to a tokenize.tokenize bug\n    # See https://bugs.python.org/issue23297\n    strio = io.StringIO(source)\n    gen = tokenize.generate_tokens(strio.readline)\n\n    tkns = []\n    try:\n        for t in gen:\n            tkns.append(t)\n    except tokenize.TokenError:\n        pass\n\n    # Find the position of 'lambda'\n    lambda_pos = [(t.type, t.string) for t in tkns].index(\n        (tokenize.NAME, \"lambda\")\n    )\n\n    # Ignore tokes before 'lambda'\n    tkns = tkns[lambda_pos:]\n\n    # Find the position of th las OP\n    lastop_pos = (\n        len(tkns) - 1 - [t.type for t in tkns[::-1]].index(tokenize.OP)\n    )\n    lastop = tkns[lastop_pos]\n\n    # Remove OP from the line\n    fiedlineno = lastop.start[0]\n    fixedline = lastop.line[: lastop.start[1]] + lastop.line[lastop.end[1] :]\n\n    tkns = tkns[:lastop_pos]\n\n    fixedlines = \"\"\n    last_lineno = 0\n    for t in tkns:\n        if last_lineno == t.start[0]:\n            continue\n        elif t.start[0] == fiedlineno:\n            fixedlines += fixedline\n            last_lineno = t.start[0]\n        else:\n            fixedlines += t.line\n            last_lineno = t.start[0]\n\n    return fixedlines"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding the first FuncDef ast object in source", "response": "def find_funcdef(source):\n    \"\"\"Find the first FuncDef ast object in source\"\"\"\n\n    try:\n        module_node = compile(\n            source, \"<string>\", mode=\"exec\", flags=ast.PyCF_ONLY_AST\n        )\n    except SyntaxError:\n        return find_funcdef(fix_lamdaline(source))\n\n    for node in ast.walk(module_node):\n        if isinstance(node, ast.FunctionDef) or isinstance(node, ast.Lambda):\n            return node\n\n    raise ValueError(\"function definition not found\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_params(source):\n\n    funcdef = find_funcdef(source)\n    params = []\n    for node in ast.walk(funcdef.args):\n        if isinstance(node, ast.arg):\n            if node.arg not in params:\n                params.append(node.arg)\n\n    return params", "response": "Extract parameters from a function definition"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_names(source):\n    if source is None:\n        return None\n\n    source = dedent(source)\n    funcdef = find_funcdef(source)\n    params = extract_params(source)\n    names = []\n\n    if isinstance(funcdef, ast.FunctionDef):\n        stmts = funcdef.body\n    elif isinstance(funcdef, ast.Lambda):\n        stmts = [funcdef.body]\n    else:\n        raise ValueError(\"must not happen\")\n\n    for stmt in stmts:\n        for node in ast.walk(stmt):\n            if isinstance(node, ast.Name):\n                if node.id not in names and node.id not in params:\n                    names.append(node.id)\n\n    return names", "response": "Extract names from a function definition in the source."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntruing if src is a function definition", "response": "def is_funcdef(src):\n    \"\"\"True if src is a function definition\"\"\"\n\n    module_node = ast.parse(dedent(src))\n\n    if len(module_node.body) == 1 and isinstance(\n            module_node.body[0], ast.FunctionDef\n    ):\n        return True\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving decorators from function definition", "response": "def remove_decorator(source: str):\n    \"\"\"Remove decorators from function definition\"\"\"\n    lines = source.splitlines()\n    atok = asttokens.ASTTokens(source, parse=True)\n\n    for node in ast.walk(atok.tree):\n        if isinstance(node, ast.FunctionDef):\n            break\n\n    if node.decorator_list:\n        deco_first = node.decorator_list[0]\n        deco_last = node.decorator_list[-1]\n        line_first = atok.tokens[deco_first.first_token.index - 1].start[0]\n        line_last = atok.tokens[deco_last.last_token.index + 1].start[0]\n\n        lines = lines[:line_first - 1] + lines[line_last:]\n\n    return \"\\n\".join(lines) + \"\\n\""}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replace_funcname(source: str, name: str):\n\n    lines = source.splitlines()\n    atok = asttokens.ASTTokens(source, parse=True)\n\n    for node in ast.walk(atok.tree):\n        if isinstance(node, ast.FunctionDef):\n            break\n\n    i = node.first_token.index\n    for i in range(node.first_token.index, node.last_token.index):\n        if (atok.tokens[i].type == token.NAME\n                and atok.tokens[i].string == \"def\"):\n            break\n\n    lineno, col_begin = atok.tokens[i + 1].start\n    lineno_end, col_end = atok.tokens[i + 1].end\n\n    assert lineno == lineno_end\n\n    lines[lineno-1] = (\n            lines[lineno-1][:col_begin] + name + lines[lineno-1][col_end:]\n    )\n\n    return \"\\n\".join(lines) + \"\\n\"", "response": "Replace function name in source with name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntruing if only one lambda expression is included", "response": "def has_lambda(src):\n    \"\"\"True if only one lambda expression is included\"\"\"\n\n    module_node = ast.parse(dedent(src))\n    lambdaexp = [node for node in ast.walk(module_node)\n                 if isinstance(node, ast.Lambda)]\n\n    return bool(lambdaexp)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreload the source function from the source module.", "response": "def _reload(self, module=None):\n        \"\"\"Reload the source function from the source module.\n\n        **Internal use only**\n        Update the source function of the formula.\n        This method is used to updated the underlying formula\n        when the source code of the module in which the source function\n        is read from is modified.\n\n        If the formula was not created from a module, an error is raised.\n        If ``module_`` is not given, the source module of the formula is\n        reloaded. If ``module_`` is given and matches the source module,\n        then the module_ is used without being reloaded.\n        If ``module_`` is given and does not match the source module of\n        the formula, an error is raised.\n\n        Args:\n            module_: A ``ModuleSource`` object\n\n        Returns:\n            self\n        \"\"\"\n        if self.module is None:\n            raise RuntimeError\n        elif module is None:\n            import importlib\n\n            module = ModuleSource(importlib.reload(module))\n        elif module.name != self.module:\n            raise RuntimeError\n\n        if self.name in module.funcs:\n            func = module.funcs[self.name]\n            self.__init__(func=func)\n        else:\n            self.__init__(func=NULL_FORMULA)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets long description from README. rst", "response": "def get_description():\n    \"\"\"Get long description from README.\"\"\"\n    with open(path.join(here, 'README.rst'), 'r') as f:\n        data = f.read()\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert the cells in the view into a DataFrame object.", "response": "def to_frame(self, *args):\n        \"\"\"Convert the cells in the view into a DataFrame object.\n\n        If ``args`` is not given, this method returns a DataFrame that\n        has an Index or a MultiIndex depending of the number of\n        cells parameters and columns each of which corresponds to each\n        cells included in the view.\n\n        ``args`` can be given to calculate cells values and limit the\n        DataFrame indexes to the given arguments.\n\n        The cells in this view may have different number of parameters,\n        but parameters shared among multiple cells\n        must appear in the same position in all the parameter lists.\n        For example,\n        Having ``foo()``, ``bar(x)`` and ``baz(x, y=1)`` is okay\n        because the shared parameter ``x`` is always the first parameter,\n        but this method does not work if the view has ``quz(x, z=2, y=1)``\n        cells in addition to the first three cells, because ``y`` appears\n        in different positions.\n\n        Args:\n            args(optional): multiple arguments,\n               or an iterator of arguments to the cells.\n        \"\"\"\n        if sys.version_info < (3, 6, 0):\n            from collections import OrderedDict\n\n            impls = OrderedDict()\n            for name, obj in self.items():\n                impls[name] = obj._impl\n        else:\n            impls = get_impls(self)\n\n        return _to_frame_inner(impls, args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef new_cells(self, name=None, formula=None):\n        # Outside formulas only\n        return self._impl.new_cells(name, formula).interface", "response": "Create a new cells in the space."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a cells from a module.", "response": "def import_funcs(self, module):\n        \"\"\"Create a cells from a module.\"\"\"\n        # Outside formulas only\n        newcells = self._impl.new_cells_from_module(module)\n        return get_interfaces(newcells)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates multiple cells from an Excel file.", "response": "def new_cells_from_excel(\n        self,\n        book,\n        range_,\n        sheet=None,\n        names_row=None,\n        param_cols=None,\n        param_order=None,\n        transpose=False,\n        names_col=None,\n        param_rows=None,\n    ):\n        \"\"\"Create multiple cells from an Excel range.\n\n        This method reads values from a range in an Excel file,\n        create cells and populate them with the values in the range.\n        To use this method, ``openpyxl`` package must be installed.\n\n        The Excel file to read data from is specified by ``book``\n        parameters. The ``range_`` can be a range address, such as \"$G4:$K10\",\n        or a named range. In case a range address is given,\n        ``sheet`` must also be given.\n\n        By default, cells data are interpreted as being laid out side-by-side.\n        ``names_row`` is a row index (starting from 0) to specify the\n        row that contains the names of cells and parameters.\n        Cells and parameter names must be contained in a single row.\n        ``param_cols`` accepts a sequence (such as list or tuple) of\n        column indexes (starting from 0) that indicate columns that\n        contain cells arguments.\n\n        **2-dimensional cells definitions**\n\n        The optional ``names_col`` and ``param_rows`` parameters are used,\n        when data for one cells spans more than one column.\n        In such cases, the cells data is 2-dimensional, and\n        there must be parameter row(s) across the columns\n        that contain arguments of the parameters.\n        A sequence of row indexes that indicate parameter rows\n        is passed to ``param_rows``.\n        The names of those parameters must be contained in the\n        same rows as parameter values (arguments), and\n        ``names_col`` is to indicate the column position at which\n        the parameter names are defined.\n\n        **Horizontal arrangement**\n\n        By default, cells data are interpreted as being placed\n        side-by-side, regardless of whether one cells corresponds\n        to a single column or multiple columns.\n        ``transpose`` parameter is used to alter this orientation,\n        and if it is set to ``True``, cells values are\n        interpreted as being placed one above the other.\n        \"row(s)\" and \"col(s)\" in the parameter\n        names are interpreted inversely, i.e.\n        all indexes passed to \"row(s)\" parameters are interpreted\n        as column indexes,\n        and all indexes passed to \"col(s)\" parameters as row indexes.\n\n\n        Args:\n            book (str): Path to an Excel file.\n            range_ (str): Range expression, such as \"A1\", \"$G4:$K10\",\n                or named range \"NamedRange1\".\n            sheet (str): Sheet name (case ignored).\n            names_row (optional): an index number indicating\n                what row contains the names of cells and parameters.\n                Defaults to the top row (0).\n            param_cols (optional): a sequence of index numbers\n                indicating parameter columns.\n                Defaults to only the leftmost column ([0]).\n            names_col (optional): an index number, starting from 0,\n                indicating what column contains additional parameters.\n            param_rows (optional): a sequence of index numbers, starting from\n                0, indicating rows of additional parameters, in case cells are\n                defined in two dimensions.\n            transpose (optional): Defaults to ``False``.\n                If set to ``True``, \"row(s)\" and \"col(s)\" in the parameter\n                names are interpreted inversely, i.e.\n                all indexes passed to \"row(s)\" parameters are interpreted\n                as column indexes,\n                and all indexes passed to \"col(s)\" parameters as row indexes.\n            param_order (optional): a sequence to reorder the parameters.\n                The elements of the sequence are the indexes of ``param_cols``\n                elements, and optionally the index of ``param_rows`` elements\n                shifted by the length of ``param_cols``.\n        \"\"\"\n        return self._impl.new_cells_from_excel(\n            book,\n            range_,\n            sheet,\n            names_row,\n            param_cols,\n            param_order,\n            transpose,\n            names_col,\n            param_rows,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_object(self, name):\n\n        parts = name.split(\".\")\n        child = parts.pop(0)\n\n        if parts:\n            return self.spaces[child].get_object(\".\".join(parts))\n        else:\n            return self._namespace_impl[child]", "response": "Retrieve an object by a dotted name relative to the space."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_dynamic_base(self, bases_):\n        bases = tuple(\n            base.bases[0] if base.is_dynamic() else base for base in bases_\n        )\n\n        if len(bases) == 1:\n            return bases[0]\n\n        elif len(bases) > 1:\n            return self.model.get_dynamic_base(bases)\n\n        else:\n            RuntimeError(\"must not happen\")", "response": "Create or get the base space from a list of spaces\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new dynamic root space.", "response": "def _new_dynspace(\n        self,\n        name=None,\n        bases=None,\n        formula=None,\n        refs=None,\n        arguments=None,\n        source=None,\n    ):\n        \"\"\"Create a new dynamic root space.\"\"\"\n\n        if name is None:\n            name = self.spacenamer.get_next(self.namespace)\n\n        if name in self.namespace:\n            raise ValueError(\"Name '%s' already exists.\" % name)\n\n        if not is_valid_name(name):\n            raise ValueError(\"Invalid name '%s'.\" % name)\n\n        space = RootDynamicSpaceImpl(\n            parent=self,\n            name=name,\n            formula=formula,\n            refs=refs,\n            source=source,\n            arguments=arguments,\n        )\n        space.is_derived = False\n        self._set_space(space)\n\n        if bases:  # i.e. not []\n            dynbase = self._get_dynamic_base(bases)\n            space._dynbase = dynbase\n            dynbase._dynamic_subs.append(space)\n\n        return space"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_dynspace(self, args, kwargs=None):\n\n        node = get_node(self, *convert_args(args, kwargs))\n        key = node[KEY]\n\n        if key in self.param_spaces:\n            return self.param_spaces[key]\n\n        else:\n            last_self = self.system.self\n            self.system.self = self\n\n            try:\n                space_args = self.eval_formula(node)\n\n            finally:\n                self.system.self = last_self\n\n            if space_args is None:\n                space_args = {\"bases\": [self]}  # Default\n            else:\n                if \"bases\" in space_args:\n                    bases = get_impls(space_args[\"bases\"])\n                    if isinstance(bases, StaticSpaceImpl):\n                        space_args[\"bases\"] = [bases]\n                    elif bases is None:\n                        space_args[\"bases\"] = [self]  # Default\n                    else:\n                        space_args[\"bases\"] = bases\n                else:\n                    space_args[\"bases\"] = [self]\n\n            space_args[\"arguments\"] = node_get_args(node)\n            space = self._new_dynspace(**space_args)\n            self.param_spaces[key] = space\n            space.inherit(clear_value=False)\n            return space", "response": "Create a dynamic root space with the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls after unpickling to restore some attributes manually.", "response": "def restore_state(self, system):\n        \"\"\"Called after unpickling to restore some attributes manually.\"\"\"\n        super().restore_state(system)\n        BaseSpaceContainerImpl.restore_state(self, system)\n\n        for cells in self._cells.values():\n            cells.restore_state(system)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef new_cells_from_excel(\n        self,\n        book,\n        range_,\n        sheet=None,\n        names_row=None,\n        param_cols=None,\n        param_order=None,\n        transpose=False,\n        names_col=None,\n        param_rows=None,\n    ):\n        \"\"\"Create multiple cells from an Excel range.\n\n        Args:\n            book (str): Path to an Excel file.\n            range_ (str): Range expression, such as \"A1\", \"$G4:$K10\",\n                or named range \"NamedRange1\".\n            sheet (str): Sheet name (case ignored).\n            names_row: Cells names in a sequence, or an integer number, or\n              a string expression indicating row (or column depending on\n              ```orientation```) to read cells names from.\n            param_cols: a sequence of them\n                indicating parameter columns (or rows depending on ```\n                orientation```)\n            param_order: a sequence of integers representing\n                the order of params and extra_params.\n            transpose: in which direction 'vertical' or 'horizontal'\n            names_col: a string or a list of names of the extra params.\n            param_rows: integer or string expression, or a sequence of them\n                indicating row (or column) to be interpreted as parameters.\n        \"\"\"\n        import modelx.io.excel as xl\n\n        cellstable = xl.CellsTable(\n            book,\n            range_,\n            sheet,\n            names_row,\n            param_cols,\n            param_order,\n            transpose,\n            names_col,\n            param_rows,\n        )\n\n        if cellstable.param_names:\n            sig = \"=None, \".join(cellstable.param_names) + \"=None\"\n        else:\n            sig = \"\"\n\n        blank_func = \"def _blank_func(\" + sig + \"): pass\"\n\n        for cellsdata in cellstable.items():\n            cells = self.new_cells(name=cellsdata.name, formula=blank_func)\n            for args, value in cellsdata.items():\n                cells.set_value(args, value)", "response": "Create multiple cells from an Excel file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_attr(self, name, value):\n        if not is_valid_name(name):\n            raise ValueError(\"Invalid name '%s'\" % name)\n\n        if name in self.namespace:\n            if name in self.refs:\n                if name in self.self_refs:\n                    self.new_ref(name, value)\n                else:\n                    raise KeyError(\"Ref '%s' cannot be changed\" % name)\n\n            elif name in self.cells:\n                if self.cells[name].is_scalar():\n                    self.cells[name].set_value((), value)\n                else:\n                    raise AttributeError(\"Cells '%s' is not a scalar.\" % name)\n            else:\n                raise ValueError\n        else:\n            self.new_ref(name, value)", "response": "Implementation of attribute setting by user script\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef del_attr(self, name):\n        if name in self.namespace:\n            if name in self.cells:\n                self.del_cells(name)\n            elif name in self.spaces:\n                self.del_space(name)\n            elif name in self.refs:\n                self.del_ref(name)\n            else:\n                raise RuntimeError(\"Must not happen\")\n        else:\n            raise KeyError(\"'%s' not found in Space '%s'\" % (name, self.name))", "response": "Implementation of attribute deletion by user script\n        Called by user script\n       . name by user script\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef del_cells(self, name):\n        if name in self.cells:\n            cells = self.cells[name]\n            self.cells.del_item(name)\n            self.inherit()\n            self.model.spacegraph.update_subspaces(self)\n\n        elif name in self.dynamic_spaces:\n            cells = self.dynamic_spaces.pop(name)\n            self.dynamic_spaces.set_update()\n\n        else:\n            raise KeyError(\"Cells '%s' does not exist\" % name)\n\n        NullImpl(cells)", "response": "Implementation of cells deletion\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cellsiter_to_dataframe(cellsiter, args, drop_allna=True):\n    from modelx.core.cells import shareable_parameters\n\n    if len(args):\n        indexes = shareable_parameters(cellsiter)\n    else:\n        indexes = get_all_params(cellsiter.values())\n\n    result = None\n\n    for cells in cellsiter.values():\n        df = cells_to_dataframe(cells, args)\n\n        if drop_allna and df.isnull().all().all():\n            continue  #  Ignore all NA or empty\n\n        if df.index.names != [None]:\n            if isinstance(df.index, pd.MultiIndex):\n                if _pd_ver < (0, 20):\n                    df = _reset_naindex(df)\n\n            df = df.reset_index()\n\n        missing_params = set(indexes) - set(df)\n\n        for params in missing_params:\n            df[params] = np.nan\n\n        if result is None:\n            result = df\n        else:\n            try:\n                result = pd.merge(result, df, how=\"outer\")\n            except MergeError:\n                # When no common column exists, i.e. all cells are scalars.\n                result = pd.concat([result, df], axis=1)\n            except ValueError:\n                # When common columns are not coercible (numeric vs object),\n                # Make the numeric column object type\n                cols = set(result.columns) & set(df.columns)\n                for col in cols:\n\n                    # When only either of them has object dtype\n                    if (\n                        len(\n                            [\n                                str(frame[col].dtype)\n                                for frame in (result, df)\n                                if str(frame[col].dtype) == \"object\"\n                            ]\n                        )\n                        == 1\n                    ):\n\n                        if str(result[col].dtype) == \"object\":\n                            frame = df\n                        else:\n                            frame = result\n                        frame[[col]] = frame[col].astype(\"object\")\n\n                # Try again\n                result = pd.merge(result, df, how=\"outer\")\n\n    if result is None:\n        return pd.DataFrame()\n    else:\n        return result.set_index(indexes) if indexes else result", "response": "Convert multiple cells to a DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a CellImpl into a Series.", "response": "def cells_to_series(cells, args):\n    \"\"\"Convert a CellImpl into a Series.\n\n    `args` must be a sequence of argkeys.\n\n    `args` can be longer or shorter then the number of cell's parameters.\n    If shorter, then defaults are filled if any, else raise error.\n    If longer, then redundant args are ignored.\n    \"\"\"\n\n    paramlen = len(cells.formula.parameters)\n    is_multidx = paramlen > 1\n\n    if len(cells.data) == 0:\n        data = {}\n        indexes = None\n\n    elif paramlen == 0:  # Const Cells\n        data = list(cells.data.values())\n        indexes = [np.nan]\n\n    else:\n\n        if len(args) > 0:\n            defaults = tuple(\n                param.default\n                for param in cells.formula.signature.parameters.values()\n            )\n            updated_args = []\n            for arg in args:\n\n                if len(arg) > paramlen:\n                    arg = arg[:paramlen]\n                elif len(arg) < paramlen:\n                    arg += defaults[len(arg) :]\n\n                updated_args.append(arg)\n\n            items = [\n                (arg, cells.data[arg])\n                for arg in updated_args\n                if arg in cells.data\n            ]\n        else:\n            items = [(key, value) for key, value in cells.data.items()]\n\n        if not is_multidx:  # Peel 1-element tuple\n            items = [(key[0], value) for key, value in items]\n\n        if len(items) == 0:\n            indexes, data = None, {}\n        else:\n            indexes, data = zip(*items)\n            if is_multidx:\n                indexes = pd.MultiIndex.from_tuples(indexes)\n\n    result = pd.Series(data=data, name=cells.name, index=indexes)\n\n    if indexes is not None and any(i is not np.nan for i in indexes):\n        result.index.names = list(cells.formula.parameters)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove all descendants of source.", "response": "def clear_descendants(self, source, clear_source=True):\n        \"\"\"Remove all descendants of(reachable from) `source`.\n\n        Args:\n            source: Node descendants\n            clear_source(bool): Remove origin too if True.\n        Returns:\n            set: The removed nodes.\n        \"\"\"\n        desc = nx.descendants(self, source)\n        if clear_source:\n            desc.add(source)\n        self.remove_nodes_from(desc)\n        return desc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving all nodes with obj and their descendants.", "response": "def clear_obj(self, obj):\n        \"\"\"\"Remove all nodes with `obj` and their descendants.\"\"\"\n        obj_nodes = self.get_nodes_with(obj)\n        removed = set()\n        for node in obj_nodes:\n            if self.has_node(node):\n                removed.update(self.clear_descendants(node))\n        return removed"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns nodes with obj.", "response": "def get_nodes_with(self, obj):\n        \"\"\"Return nodes with `obj`.\"\"\"\n        result = set()\n\n        if nx.__version__[0] == \"1\":\n            nodes = self.nodes_iter()\n        else:\n            nodes = self.nodes\n\n        for node in nodes:\n            if node[OBJ] == obj:\n                result.add(node)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_path(self, nodes, **attr):\n        if nx.__version__[0] == \"1\":\n            return super().add_path(nodes, **attr)\n        else:\n            return nx.add_path(self, nodes, **attr)", "response": "In replacement for deprecated add_path method"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrenaming the model itself", "response": "def rename(self, name):\n        \"\"\"Rename the model itself\"\"\"\n        self._impl.system.rename_model(new_name=name, old_name=self.name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrename the current object.", "response": "def rename(self, name):\n        \"\"\"Rename self. Must be called only by its system.\"\"\"\n        if is_valid_name(name):\n            if name not in self.system.models:\n                self.name = name\n                return True  # Rename success\n            else:  # Model name already exists\n                return False\n        else:\n            raise ValueError(\"Invalid name '%s'.\" % name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nclears values and nodes calculated from source.", "response": "def clear_descendants(self, source, clear_source=True):\n        \"\"\"Clear values and nodes calculated from `source`.\"\"\"\n        removed = self.cellgraph.clear_descendants(source, clear_source)\n        for node in removed:\n            del node[OBJ].data[node[KEY]]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear_obj(self, obj):\n        removed = self.cellgraph.clear_obj(obj)\n        for node in removed:\n            del node[OBJ].data[node[KEY]]", "response": "Clear values and nodes of obj and their dependants."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_object(self, name):\n        parts = name.split(\".\")\n        space = self.spaces[parts.pop(0)]\n        if parts:\n            return space.get_object(\".\".join(parts))\n        else:\n            return space", "response": "Retrieve an object by a dotted name relative to the model."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling after unpickling to restore some attributes manually.", "response": "def restore_state(self, system):\n        \"\"\"Called after unpickling to restore some attributes manually.\"\"\"\n        Impl.restore_state(self, system)\n        BaseSpaceContainerImpl.restore_state(self, system)\n        mapping = {}\n        for node in self.cellgraph:\n            if isinstance(node, tuple):\n                name, key = node\n            else:\n                name, key = node, None\n            cells = self.get_object(name)\n            mapping[node] = get_node(cells, key, None)\n\n        self.cellgraph = nx.relabel_nodes(self.cellgraph, mapping)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates of get a base space for a tuple of bases", "response": "def get_dynamic_base(self, bases: tuple):\n        \"\"\"Create of get a base space for a tuple of bases\"\"\"\n\n        try:\n            return self._dynamic_bases_inverse[bases]\n        except KeyError:\n            name = self._dynamic_base_namer.get_next(self._dynamic_bases)\n            base = self._new_space(name=name)\n            self.spacegraph.add_space(base)\n            self._dynamic_bases[name] = base\n            self._dynamic_bases_inverse[bases] = base\n            base.add_bases(bases)\n            return base"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_mro(self, bases):\n\n        try:\n            self.add_node(\"temp\")\n            for base in bases:\n                nx.DiGraph.add_edge(self, base, \"temp\")\n            result = self.get_mro(\"temp\")[1:]\n\n        finally:\n            self.remove_node(\"temp\")\n\n        return result", "response": "Check if C3 MRO is possible with given bases"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of command names supported by the current user.", "response": "def get_command_names():\n    \"\"\"\n    Returns a list of command names supported\n    \"\"\"\n    ret = []\n    for f in os.listdir(COMMAND_MODULE_PATH):\n        if os.path.isfile(os.path.join(COMMAND_MODULE_PATH, f)) and f.endswith(COMMAND_MODULE_SUFFIX):\n            ret.append(f[:-len(COMMAND_MODULE_SUFFIX)])\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dictionary value for the specified key.", "response": "def get(vals, key, default_val=None):\n    \"\"\"\n    Returns a dictionary value\n    \"\"\"\n    val = vals\n    for part in key.split('.'):\n        if isinstance(val, dict):\n            val = val.get(part, None)\n            if val is None:\n                return default_val\n        else:\n            return default_val\n    return val"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_option_settings(option_settings):\n    ret = []\n    for namespace, params in list(option_settings.items()):\n        for key, value in list(params.items()):\n            ret.append((namespace, key, value))\n    return ret", "response": "Parses option_settings as they are defined in the configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing an environment config into a single dict.", "response": "def parse_env_config(config, env_name):\n    \"\"\"\n    Parses an environment config\n    \"\"\"\n    all_env = get(config, 'app.all_environments', {})\n    env = get(config, 'app.environments.' + str(env_name), {})\n    return merge_dict(all_env, env)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_archive(directory, filename, config={}, ignore_predicate=None, ignored_files=['.git', '.svn']):\n    with zipfile.ZipFile(filename, 'w', compression=zipfile.ZIP_DEFLATED) as zip_file:\n        root_len = len(os.path.abspath(directory))\n\n        # create it\n        out(\"Creating archive: \" + str(filename))\n        for root, dirs, files in os.walk(directory, followlinks=True):\n            archive_root = os.path.abspath(root)[root_len + 1:]\n            for f in files:\n                fullpath = os.path.join(root, f)\n                archive_name = os.path.join(archive_root, f)\n\n                # ignore the file we're creating\n                if filename in fullpath:\n                    continue\n\n                # ignored files\n                if ignored_files is not None:\n                    for name in ignored_files:\n                        if fullpath.endswith(name):\n                            out(\"Skipping: \" + str(name))\n                            continue\n\n                # do predicate\n                if ignore_predicate is not None:\n                    if not ignore_predicate(archive_name):\n                        out(\"Skipping: \" + str(archive_name))\n                        continue\n\n                out(\"Adding: \" + str(archive_name))\n                zip_file.write(fullpath, archive_name, zipfile.ZIP_DEFLATED)\n\n    return filename", "response": "Creates an archive from a directory and returns the filename that was created."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_config_files_to_archive(directory, filename, config={}):\n    with zipfile.ZipFile(filename, 'a') as zip_file:\n        for conf in config:\n            for conf, tree in list(conf.items()):\n                if 'yaml' in tree:\n                    content = yaml.dump(tree['yaml'], default_flow_style=False)\n                else:\n                    content = tree.get('content', '')\n                out(\"Adding file \" + str(conf) + \" to archive \" + str(filename))\n                file_entry = zipfile.ZipInfo(conf)\n                file_entry.external_attr = tree.get('permissions', 0o644) << 16 \n                zip_file.writestr(file_entry, content)\n\n    return filename", "response": "Adds configuration files to an existing archive"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef swap_environment_cnames(self, from_env_name, to_env_name):\n        self.ebs.swap_environment_cnames(source_environment_name=from_env_name,\n                                         destination_environment_name=to_env_name)", "response": "Swaps the environment names of a specific environment."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef upload_archive(self, filename, key, auto_create_bucket=True):\n        try:\n            bucket = self.s3.get_bucket(self.aws.bucket)\n            if ((\n                  self.aws.region != 'us-east-1' and self.aws.region != 'eu-west-1') and bucket.get_location() != self.aws.region) or (\n                  self.aws.region == 'us-east-1' and bucket.get_location() != '') or (\n                  self.aws.region == 'eu-west-1' and bucket.get_location() != 'eu-west-1'):\n                raise Exception(\"Existing bucket doesn't match region\")\n        except S3ResponseError:\n            bucket = self.s3.create_bucket(self.aws.bucket, location=self.aws.region)\n\n        def __report_upload_progress(sent, total):\n            if not sent:\n                sent = 0\n            if not total:\n                total = 0\n            out(\"Uploaded \" + str(sent) + \" bytes of \" + str(total) \\\n                + \" (\" + str(int(float(max(1, sent)) / float(total) * 100)) + \"%)\")\n\n        # upload the new version\n        k = Key(bucket)\n        k.key = self.aws.bucket_path + key\n        k.set_metadata('time', str(time()))\n        k.set_contents_from_filename(filename, cb=__report_upload_progress, num_cb=10)", "response": "Uploads an application archive version to s3"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_application(self, description=None):\n        out(\"Creating application \" + str(self.app_name))\n        self.ebs.create_application(self.app_name, description=description)", "response": "Creates an application and sets the helpers current\n        app_name to the application created by this application."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_application(self):\n        out(\"Deleting application \" + str(self.app_name))\n        self.ebs.delete_application(self.app_name, terminate_env_by_force=True)", "response": "Delete the application from the ebs"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns whether or not the given app_name exists.", "response": "def application_exists(self):\n        \"\"\"\n        Returns whether or not the given app_name exists\n        \"\"\"\n        response = self.ebs.describe_applications(application_names=[self.app_name])\n        return len(response['DescribeApplicationsResponse']['DescribeApplicationsResult']['Applications']) > 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new environment in the cluster.", "response": "def create_environment(self, env_name, version_label=None,\n                           solution_stack_name=None, cname_prefix=None, description=None,\n                           option_settings=None, tier_name='WebServer', tier_type='Standard', tier_version='1.1'):\n        \"\"\"\n        Creates a new environment\n        \"\"\"\n        out(\"Creating environment: \" + str(env_name) + \", tier_name:\" + str(tier_name) + \", tier_type:\" + str(tier_type))\n        self.ebs.create_environment(self.app_name, env_name,\n                                    version_label=version_label,\n                                    solution_stack_name=solution_stack_name,\n                                    cname_prefix=cname_prefix,\n                                    description=description,\n                                    option_settings=option_settings,\n                                    tier_type=tier_type,\n                                    tier_name=tier_name,\n                                    tier_version=tier_version)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef environment_exists(self, env_name):\n        response = self.ebs.describe_environments(application_name=self.app_name, environment_names=[env_name],\n                                                  include_deleted=False)\n        return len(response['DescribeEnvironmentsResponse']['DescribeEnvironmentsResult']['Environments']) > 0 \\\n               and response['DescribeEnvironmentsResponse']['DescribeEnvironmentsResult']['Environments'][0][\n                       'Status'] != 'Terminated'", "response": "Returns whether or not the given environment exists"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_environments(self):\n        response = self.ebs.describe_environments(application_name=self.app_name, include_deleted=False)\n        return response['DescribeEnvironmentsResponse']['DescribeEnvironmentsResult']['Environments']", "response": "Returns the list of environments in the current environment"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate an application version of an environment.", "response": "def update_environment(self, environment_name, description=None, option_settings=[], tier_type=None, tier_name=None,\n                           tier_version='1.0'):\n        \"\"\"\n        Updates an application version\n        \"\"\"\n        out(\"Updating environment: \" + str(environment_name))\n        messages = self.ebs.validate_configuration_settings(self.app_name, option_settings,\n                                                            environment_name=environment_name)\n        messages = messages['ValidateConfigurationSettingsResponse']['ValidateConfigurationSettingsResult']['Messages']\n        ok = True\n        for message in messages:\n            if message['Severity'] == 'error':\n                ok = False\n            out(\"[\" + message['Severity'] + \"] \" + str(environment_name) + \" - '\" \\\n                + message['Namespace'] + \":\" + message['OptionName'] + \"': \" + message['Message'])\n        self.ebs.update_environment(\n            environment_name=environment_name,\n            description=description,\n            option_settings=option_settings,\n            tier_type=tier_type,\n            tier_name=tier_name,\n            tier_version=tier_version)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an environment name for the given cname", "response": "def environment_name_for_cname(self, env_cname):\n        \"\"\"\n        Returns an environment name for the given cname\n        \"\"\"\n        envs = self.get_environments()\n        for env in envs:\n            if env['Status'] != 'Terminated' \\\n                and 'CNAME' in env \\\n                and env['CNAME'] \\\n                and env['CNAME'].lower().startswith(env_cname.lower() + '.'):\n                return env['EnvironmentName']\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeploys a version to an environment", "response": "def deploy_version(self, environment_name, version_label):\n        \"\"\"\n        Deploys a version to an environment\n        \"\"\"\n        out(\"Deploying \" + str(version_label) + \" to \" + str(environment_name))\n        self.ebs.update_environment(environment_name=environment_name, version_label=version_label)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_versions(self):\n        response = self.ebs.describe_application_versions(application_name=self.app_name)\n        return response['DescribeApplicationVersionsResponse']['DescribeApplicationVersionsResult']['ApplicationVersions']", "response": "Returns the available versions of the application"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_application_version(self, version_label, key):\n        out(\"Creating application version \" + str(version_label) + \" for \" + str(key))\n        self.ebs.create_application_version(self.app_name, version_label,\n                                            s3_bucket=self.aws.bucket, s3_key=self.aws.bucket_path+key)", "response": "Creates an application version"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_unused_versions(self, versions_to_keep=10):\n\n        # get versions in use\n        environments = self.ebs.describe_environments(application_name=self.app_name, include_deleted=False)\n        environments = environments['DescribeEnvironmentsResponse']['DescribeEnvironmentsResult']['Environments']\n        versions_in_use = []\n        for env in environments:\n            versions_in_use.append(env['VersionLabel'])\n\n        # get all versions\n        versions = self.ebs.describe_application_versions(application_name=self.app_name)\n        versions = versions['DescribeApplicationVersionsResponse']['DescribeApplicationVersionsResult'][\n            'ApplicationVersions']\n        versions = sorted(versions, reverse=True, key=functools.cmp_to_key(lambda x, y: (x['DateCreated'] > y['DateCreated']) - (x['DateCreated'] < y['DateCreated'])))\n\n        # delete versions in use\n        for version in versions[versions_to_keep:]:\n            if version['VersionLabel'] in versions_in_use:\n                out(\"Not deleting \" + version[\"VersionLabel\"] + \" because it is in use\")\n            else:\n                out(\"Deleting unused version: \" + version[\"VersionLabel\"])\n                self.ebs.delete_application_version(application_name=self.app_name,\n                                                    version_label=version['VersionLabel'])\n                sleep(2)", "response": "Deletes unused versions in the specified list of versions_to_keep."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndescribing the events from the given environment.", "response": "def describe_events(self, environment_name, next_token=None, start_time=None):\n        \"\"\"\n        Describes events from the given environment\n        \"\"\"\n        events = self.ebs.describe_events(\n            application_name=self.app_name,\n            environment_name=environment_name,\n            next_token=next_token,\n            start_time=start_time + 'Z')\n\n        return (events['DescribeEventsResponse']['DescribeEventsResult']['Events'], events['DescribeEventsResponse']['DescribeEventsResult']['NextToken'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwait for an environment to have the given version_label and to be in the green state.", "response": "def wait_for_environments(self, environment_names, health=None, status=None, version_label=None,\n                              include_deleted=True, use_events=True):\n        \"\"\"\n        Waits for an environment to have the given version_label\n        and to be in the green state\n        \"\"\"\n\n        # turn into a list\n        if not isinstance(environment_names, (list, tuple)):\n            environment_names = [environment_names]\n        environment_names = environment_names[:]\n\n        # print some stuff\n        s = \"Waiting for environment(s) \" + (\", \".join(environment_names)) + \" to\"\n        if health is not None:\n            s += \" have health \" + health\n        else:\n            s += \" have any health\"\n        if version_label is not None:\n            s += \" and have version \" + version_label\n        if status is not None:\n            s += \" and have status \" + status\n        out(s)\n\n        started = time()\n        seen_events = list()\n\n        for env_name in environment_names:\n            (events, next_token) = self.describe_events(env_name, start_time=datetime.now().isoformat())\n            for event in events:\n                seen_events.append(event)\n\n        while True:\n            # bail if they're all good\n            if len(environment_names) == 0:\n                break\n\n            # wait\n            sleep(10)\n\n            # # get the env\n            environments = self.ebs.describe_environments(\n                application_name=self.app_name,\n                environment_names=environment_names,\n                include_deleted=include_deleted)\n\n            environments = environments['DescribeEnvironmentsResponse']['DescribeEnvironmentsResult']['Environments']\n            if len(environments) <= 0:\n                raise Exception(\"Couldn't find any environments\")\n\n            # loop through and wait\n            for env in environments[:]:\n                env_name = env['EnvironmentName']\n\n                # the message\n                msg = \"Environment \" + env_name + \" is \" + str(env['Health'])\n                if version_label is not None:\n                    msg = msg + \" and has version \" + str(env['VersionLabel'])\n                if status is not None:\n                    msg = msg + \" and has status \" + str(env['Status'])\n\n                # what we're doing\n                good_to_go = True\n                if health is not None:\n                    good_to_go = good_to_go and str(env['Health']) == health\n                if status is not None:\n                    good_to_go = good_to_go and str(env['Status']) == status\n                if version_label is not None:\n                    good_to_go = good_to_go and str(env['VersionLabel']) == version_label\n\n                # allow a certain number of Red samples before failing\n                if env['Status'] == 'Ready' and env['Health'] == 'Red':\n                    if 'RedCount' not in env:\n                        env['RedCount'] = 0\n\n                    env['RedCount'] += 1\n                    if env['RedCount'] > MAX_RED_SAMPLES:\n                        out('Deploy failed')\n                        raise Exception('Ready and red')\n\n                # log it\n                if good_to_go:\n                    out(msg + \" ... done\")\n                    environment_names.remove(env_name)\n                else:\n                    out(msg + \" ... waiting\")\n\n                # log events\n                (events, next_token) = self.describe_events(env_name, start_time=datetime.now().isoformat())\n                for event in events:\n                    if event not in seen_events:\n                        out(\"[\"+event['Severity']+\"] \"+event['Message'])\n                        seen_events.append(event)\n\n            # check the time\n            elapsed = time() - started\n            if elapsed > self.wait_time_secs:\n                message = \"Wait time for environment(s) {environments} to be {health} expired\".format(\n                    environments=\" and \".join(environment_names), health=(health or \"Green\")\n                )\n                raise Exception(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_arguments(parser):\n    parser.add_argument('-o', '--old-environment', help='Old environment name', required=True)\n    parser.add_argument('-n', '--new-environment', help='New environment name', required=True)", "response": "Adds arguments for the swap urls command\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nswap old and new URLs.", "response": "def execute(helper, config, args):\n    \"\"\"\n    Swaps old and new URLs.\n    If old_environment was active, new_environment will become the active environment\n    \"\"\"\n    old_env_name = args.old_environment\n    new_env_name = args.new_environment\n\n    # swap C-Names\n    out(\"Assuming that {} is the currently active environment...\".format(old_env_name))\n    out(\"Swapping environment cnames: {} will become active, {} will become inactive.\".format(new_env_name,\n                                                                                              old_env_name))\n    helper.swap_environment_cnames(old_env_name, new_env_name)\n    helper.wait_for_environments([old_env_name, new_env_name], status='Ready', include_deleted=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute(helper, config, args):\n    env = parse_env_config(config, args.environment)\n    option_settings = env.get('option_settings', {})\n    settings = parse_option_settings(option_settings)\n    for setting in settings:\n        out(str(setting))", "response": "dump command dumps things"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cached_property(f):\n    @property\n    @functools.wraps(f)\n    def wrapped(self, name=f.__name__):\n        try:\n            cache = self.__cache__\n        except AttributeError:\n            self.__cache__ = cache = {}\n        try:\n            return cache[name]\n        except KeyError:\n            cache[name] = rv = f(self)\n            return rv\n    return wrapped", "response": "A property decorator that caches the result of a function."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints the current state of the current application.", "response": "def execute(helper, config, args):\n    \"\"\"\n    Lists environments\n    \"\"\"\n    envs = config.get('app', {}).get('environments', [])\n    out(\"Parsed environments:\")\n    for name, conf in list(envs.items()):\n        out('\\t'+name)\n    envs = helper.get_environments()\n    out(\"Deployed environments:\")\n    for env in envs:\n        if env['Status'] != 'Terminated':\n            out('\\t'+str(env['EnvironmentName'])+' ('+str(env['Status'])+', '+str(env['CNAME'])+')')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete an application and wait for all environments to terminate", "response": "def execute(helper, config, args):\n    \"\"\"\n    Deletes an environment\n    \"\"\"\n    helper.delete_application()\n\n    # wait\n    if not args.dont_wait:\n\n        # get environments\n        environment_names = []\n        for env in helper.get_environments():\n            environment_names.append(env['EnvironmentName'])\n\n        # wait for them\n        helper.wait_for_environments(environment_names, status='Terminated')\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute(helper, config, args):\n\n    env_config = parse_env_config(config, args.environment)\n    environments_to_wait_for_term = []\n    environments = helper.get_environments()\n\n    for env in environments:\n        if env['EnvironmentName'] == args.environment:\n            if env['Status'] != 'Ready':\n                out(\"Unable to delete \" + env['EnvironmentName']\n                    + \" because it's not in status Ready (\"\n                    + env['Status'] + \")\")\n            else:\n                out(\"Deleting environment: \"+env['EnvironmentName'])\n                helper.delete_environment(env['EnvironmentName'])\n                environments_to_wait_for_term.append(env['EnvironmentName'])\n\n    if not args.dont_wait:\n        helper.wait_for_environments(environments_to_wait_for_term,\n                                     status='Terminated',\n                                     include_deleted=True)\n\n    out(\"Environment deleted\")\n    return 0", "response": "Deletes an environment and waits for the termination of the environment"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute(helper, config, args):\n    version_label = args.version_label\n    env_config = parse_env_config(config, args.environment)\n    env_name = args.environment\n\n    # upload or build an archive\n    version_label = upload_application_archive(\n        helper, env_config, archive=args.archive,\n        directory=args.directory, version_label=version_label)\n\n    import datetime\n    start_time = datetime.datetime.utcnow().isoformat() + 'Z'\n    # deploy it\n    helper.deploy_version(env_name, version_label)\n\n    # wait\n    if not args.dont_wait:\n        helper.wait_for_environments(env_name, status='Ready',\n                                     version_label=version_label,\n                                     include_deleted=False)\n\n    # update it\n    env = parse_env_config(config, env_name)\n    option_settings = parse_option_settings(env.get('option_settings', {}))\n    helper.update_environment(env_name,\n                              description=env.get('description', None),\n                              option_settings=option_settings,\n                              tier_type=env.get('tier_type'),\n                              tier_name=env.get('tier_name'),\n                              tier_version=env.get('tier_version'))\n\n    # wait\n    if not args.dont_wait:\n        helper.wait_for_environments(env_name, health='Green',\n                                     status='Ready', version_label=version_label,\n                                     include_deleted=False)\n\n    events = helper.ebs.describe_events(start_time=start_time, environment_name=env_name)\n    import json\n    if args.log_events_to_file:\n        with open('ebs_events.json', 'w+') as f:\n            json.dump(events, f)\n\n    # delete unused\n    helper.delete_unused_versions(versions_to_keep=int(get(config, 'app.versions_to_keep', 10)))", "response": "Deploy or upload an application to an environment\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd the arguments for the deploy command", "response": "def add_arguments(parser):\n    \"\"\"\n    adds arguments for the deploy command\n    \"\"\"\n    parser.add_argument('-e', '--environment',      help='Environment name', required=True)\n    parser.add_argument('-w', '--dont-wait',        help='Skip waiting for the init to finish', action='store_true')\n    parser.add_argument('-l', '--version-label',    help='Version label', required=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeploying to an environment", "response": "def execute(helper, config, args):\n    \"\"\"\n    Deploys to an environment\n    \"\"\"\n    env_config = parse_env_config(config, args.environment)\n    cname_prefix = env_config.get('cname_prefix', None)\n    env_name = args.environment\n\n    # change version\n    if args.version_label:\n        helper.deploy_version(env_name, args.version_label)\n        if not args.dont_wait:\n            helper.wait_for_environments(env_name, status='Ready', version_label=args.version_label)\n\n    # update it\n    env = parse_env_config(config, env_name)\n    option_settings = parse_option_settings(env.get('option_settings', {}))\n    helper.update_environment(env_name,\n        description=env.get('description', None),\n        option_settings=option_settings,\n        tier_type=env.get('tier_type'),\n        tier_name=env.get('tier_name'),\n        tier_version=env.get('tier_version'))\n\n    # wait\n    if not args.dont_wait:\n        helper.wait_for_environments(env_name, health='Green', status='Ready', version_label=args.version_label)\n\n    # delete unused\n    helper.delete_unused_versions(versions_to_keep=int( get(config, 'app.versions_to_keep', 10) ))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\njoining a Hangul letter from Korean phonemes.", "response": "def join_phonemes(*args):\n    \"\"\"Joins a Hangul letter from Korean phonemes.\"\"\"\n    # Normalize arguments as onset, nucleus, coda.\n    if len(args) == 1:\n        # tuple of (onset, nucleus[, coda])\n        args = args[0]\n    if len(args) == 2:\n        args += (CODAS[0],)\n    try:\n        onset, nucleus, coda = args\n    except ValueError:\n        raise TypeError('join_phonemes() takes at most 3 arguments')\n    offset = (\n        (ONSETS.index(onset) * NUM_NUCLEUSES + NUCLEUSES.index(nucleus)) *\n        NUM_CODAS + CODAS.index(coda)\n    )\n    return unichr(FIRST_HANGUL_OFFSET + offset)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsplit Korean phonemes from a single letter.", "response": "def split_phonemes(letter, onset=True, nucleus=True, coda=True):\n    \"\"\"Splits Korean phonemes as known as \"\uc790\uc18c\" from a Hangul letter.\n\n    :returns: (onset, nucleus, coda)\n    :raises ValueError: `letter` is not a Hangul single letter.\n\n    \"\"\"\n    if len(letter) != 1 or not is_hangul(letter):\n        raise ValueError('Not Hangul letter: %r' % letter)\n    offset = ord(letter) - FIRST_HANGUL_OFFSET\n    phonemes = [None] * 3\n    if onset:\n        phonemes[0] = ONSETS[offset // (NUM_NUCLEUSES * NUM_CODAS)]\n    if nucleus:\n        phonemes[1] = NUCLEUSES[(offset // NUM_CODAS) % NUM_NUCLEUSES]\n    if coda:\n        phonemes[2] = CODAS[offset % NUM_CODAS]\n    return tuple(phonemes)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef combine_words(word1, word2):\n    if word1 and word2 and is_consonant(word2[0]):\n        onset, nucleus, coda = split_phonemes(word1[-1])\n        if not coda:\n            glue = join_phonemes(onset, nucleus, word2[0])\n            return word1[:-1] + glue + word2[1:]\n    return word1 + word2", "response": "Combines two words into one single word."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a regex pattern which can be used to index the given particles.", "response": "def index_particles(particles):\n    \"\"\"Indexes :class:`Particle` objects.  It returns a regex pattern which\n    matches to any particle morphs and a dictionary indexes the given particles\n    by regex groups.\n    \"\"\"\n    patterns, indices = [], {}\n    for x, p in enumerate(particles):\n        group = u'_%d' % x\n        indices[group] = x\n        patterns.append(u'(?P<%s>%s)' % (group, p.regex_pattern()))\n    pattern = re.compile(u'|'.join(patterns))\n    return pattern, indices"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwait for an environment to be healthy", "response": "def execute(helper, config, args):\n    \"\"\"\n    Waits for an environment to be healthy\n    \"\"\"\n    helper.wait_for_environments(args.environment, health=args.health)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute(helper, config, args):\n    versions = helper.get_versions()\n    out(\"Deployed versions:\")\n    for version in versions:\n        out(version)", "response": "List all versions of the current node"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd command line arguments for the init command", "response": "def add_arguments(parser):\n    \"\"\"\n    Args for the init command\n    \"\"\"\n    parser.add_argument('-e', '--environment',  help='Environment name', required=False, nargs='+')\n    parser.add_argument('-w', '--dont-wait', help='Skip waiting for the app to be deleted', action='store_true')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef execute(helper, config, args):\n    environment_name = args.environment\n\n    (events, next_token) = helper.describe_events(environment_name, start_time=datetime.now().isoformat())\n\n    # swap C-Names\n    for event in events:\n        print((\"[\"+event['Severity']+\"] \"+event['Message']))", "response": "describe recent events for an environment"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrebuilds an environment and waits for all environments to be ready.", "response": "def execute(helper, config, args):\n    \"\"\"\n    Rebuilds an environment\n    \"\"\"\n    env_config = parse_env_config(config, args.environment)\n    helper.rebuild_environment(args.environment)\n\n    # wait\n    if not args.dont_wait:\n        helper.wait_for_environments(args.environment, health='Green', status='Ready')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates all reasonable tolerant particle morphs.", "response": "def generate_tolerances(morph1, morph2):\n    \"\"\"Generates all reasonable tolerant particle morphs::\n\n    >>> set(generate_tolerances(u'\uc774', u'\uac00'))\n    set([u'\uc774(\uac00)', u'(\uc774)\uac00', u'\uac00(\uc774)', u'(\uac00)\uc774'])\n    >>> set(generate_tolerances(u'\uc774\uba74', u'\uba74'))\n    set([u'(\uc774)\uba74'])\n\n    \"\"\"\n    if morph1 == morph2:\n        # Tolerance not required.\n        return\n    if not (morph1 and morph2):\n        # Null allomorph exists.\n        yield u'(%s)' % (morph1 or morph2)\n        return\n    len1, len2 = len(morph1), len(morph2)\n    if len1 != len2:\n        longer, shorter = (morph1, morph2) if len1 > len2 else (morph2, morph1)\n        if longer.endswith(shorter):\n            # Longer morph ends with shorter morph.\n            yield u'(%s)%s' % (longer[:-len(shorter)], shorter)\n            return\n    # Find common suffix between two morphs.\n    for x, (let1, let2) in enumerate(zip(reversed(morph1), reversed(morph2))):\n        if let1 != let2:\n            break\n    if x:\n        # They share the common suffix.\n        x1, x2 = len(morph1) - x, len(morph2) - x\n        common_suffix = morph1[x1:]\n        morph1, morph2 = morph1[:x1], morph2[:x2]\n    else:\n        # No similarity with each other.\n        common_suffix = ''\n    for morph1, morph2 in [(morph1, morph2), (morph2, morph1)]:\n        yield u'%s(%s)%s' % (morph1, morph2, common_suffix)\n        yield u'(%s)%s%s' % (morph1, morph2, common_suffix)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nresolve a tolerance style of the given particle morph.", "response": "def parse_tolerance_style(style, registry=None):\n    \"\"\"Resolves a tolerance style of the given tolerant particle morph::\n\n    >>> parse_tolerance_style(u'\uc740(\ub294)')\n    0\n    >>> parse_tolerance_style(u'(\uc740)\ub294')\n    1\n    >>> parse_tolerance_style(OPTIONAL_MORPH2_AND_MORPH1)\n    3\n\n    \"\"\"\n    if isinstance(style, integer_types):\n        return style\n    if registry is None:\n        from . import registry\n    particle = registry.parse(style)\n    if len(particle.tolerances) != 4:\n        raise ValueError('Set tolerance style by general allomorphic particle')\n    return particle.tolerances.index(style)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist available solution stacks", "response": "def execute(helper, config, args):\n    \"\"\"\n    Lists solution stacks\n    \"\"\"\n    out(\"Available solution stacks\")\n    for stack in helper.list_available_solution_stacks():\n        out(\"    \"+str(stack))\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd the arguments for the deploy command to the argument parser", "response": "def add_arguments(parser):\n    \"\"\"\n    adds arguments for the deploy command\n    \"\"\"\n    parser.add_argument('-e', '--environment', help='Environment name', required=True)\n    parser.add_argument('-w', '--dont-wait', help='Skip waiting', action='store_true')\n    parser.add_argument('-a', '--archive', help='Archive file', required=False)\n    parser.add_argument('-d', '--directory', help='Directory', required=False)\n    parser.add_argument('-l', '--version-label', help='Version label', required=False)\n    parser.add_argument('-t', '--termination-delay',\n                        help='Delay termination of old environment by this number of seconds',\n                        type=int, required=False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute(helper, config, args):\n    version_label = args.version_label\n    archive = args.archive\n\n    # get the environment configuration\n    env_config = parse_env_config(config, args.environment)\n    option_settings = parse_option_settings(env_config.get('option_settings', {}))\n    cname_prefix = env_config.get('cname_prefix', None)\n\n    # no zdt for anything but web server\n    tier_name = env_config.get('tier_name', 'WebServer')\n    if tier_name != 'WebServer':\n        raise Exception(\n            \"Only able to do zero downtime deployments for \"\n            \"WebServer tiers, can't do them for %s\" % (tier_name, ))\n\n    # find an available environment name\n    out(\"Determining new environment name...\")\n    new_env_name = None\n    if not helper.environment_exists(args.environment):\n        new_env_name = args.environment\n    else:\n        for i in range(10):\n            temp_env_name = args.environment + '-' + str(i)\n            if not helper.environment_exists(temp_env_name):\n                new_env_name = temp_env_name\n                break\n    if new_env_name is None:\n        raise Exception(\"Unable to determine new environment name\")\n    out(\"New environment name will be \" + new_env_name)\n\n    # find an available cname name\n    out(\"Determining new environment cname...\")\n    new_env_cname = None\n    for i in range(10):\n        temp_cname = cname_prefix + '-' + str(i)\n        if not helper.environment_name_for_cname(temp_cname):\n            new_env_cname = temp_cname\n            break\n    if new_env_cname is None:\n        raise Exception(\"Unable to determine new environment cname\")\n    out(\"New environment cname will be \" + new_env_cname)\n\n    # upload or build an archive\n    version_label = upload_application_archive(\n        helper, env_config, archive=args.archive, directory=args.directory, version_label=version_label)\n\n    # create the new environment\n    helper.create_environment(new_env_name,\n                              solution_stack_name=env_config.get('solution_stack_name'),\n                              cname_prefix=new_env_cname,\n                              description=env_config.get('description', None),\n                              option_settings=option_settings,\n                              version_label=version_label,\n                              tier_name=tier_name,\n                              tier_type=env_config.get('tier_type'),\n                              tier_version=env_config.get('tier_version'))\n    helper.wait_for_environments(new_env_name, status='Ready', health='Green', include_deleted=False)\n\n    # find existing environment name\n    old_env_name = helper.environment_name_for_cname(cname_prefix)\n    if old_env_name is None:\n        raise Exception(\"Unable to find current environment with cname: \" + cname_prefix)\n    out(\"Current environment name is \" + old_env_name)\n\n    # swap C-Names\n    out(\"Swapping environment cnames\")\n    helper.swap_environment_cnames(old_env_name, new_env_name)\n    helper.wait_for_environments([old_env_name, new_env_name], status='Ready', include_deleted=False)\n\n    # delete the old environment\n    if args.termination_delay:\n        out(\"Termination delay specified, sleeping for {} seconds...\".format(args.termination_delay))\n        time.sleep(args.termination_delay)\n    out(\"Deleting old environment {}\".format(old_env_name))\n    helper.delete_environment(old_env_name)\n\n    # delete unused\n    helper.delete_unused_versions(versions_to_keep=int(get(config, 'app.versions_to_keep', 10)))", "response": "Execute the zdt deployment"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a word which removes insignificant letters at the end of the given .", "response": "def filter_only_significant(word):\n    \"\"\"Gets a word which removes insignificant letters at the end of the given\n    word::\n\n    >>> pick_significant(u'\ub125\uc2a8(\ucf54\ub9ac\uc544)')\n    \ub125\uc2a8\n    >>> pick_significant(u'\uba54\uc774\ud50c\uc2a4\ud1a0\ub9ac...')\n    \uba54\uc774\ud50c\uc2a4\ud1a0\ub9ac\n\n    \"\"\"\n    if not word:\n        return word\n    # Unwrap a complete parenthesis.\n    if word.startswith(u'(') and word.endswith(u')'):\n        return filter_only_significant(word[1:-1])\n    x = len(word)\n    while x > 0:\n        x -= 1\n        c = word[x]\n        # Skip a complete parenthesis.\n        if c == u')':\n            m = INSIGNIFICANT_PARENTHESIS_PATTERN.search(word[:x + 1])\n            if m is not None:\n                x = m.start()\n            continue\n        # Skip unreadable characters such as punctuations.\n        unicode_category = unicodedata.category(c)\n        if not SIGNIFICANT_UNICODE_CATEGORY_PATTERN.match(unicode_category):\n            continue\n        break\n    return word[:x + 1]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npick only a coda from a Hangul letter. It returns None if the letter is not Hangul.", "response": "def pick_coda_from_letter(letter):\n    \"\"\"Picks only a coda from a Hangul letter.  It returns ``None`` if the\n    given letter is not Hangul.\n    \"\"\"\n    try:\n        __, __, coda = \\\n            split_phonemes(letter, onset=False, nucleus=False, coda=True)\n    except ValueError:\n        return None\n    else:\n        return coda"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npicks only a coda from a decimal.", "response": "def pick_coda_from_decimal(decimal):\n    \"\"\"Picks only a coda from a decimal.\"\"\"\n    decimal = Decimal(decimal)\n    __, digits, exp = decimal.as_tuple()\n    if exp < 0:\n        return DIGIT_CODAS[digits[-1]]\n    __, digits, exp = decimal.normalize().as_tuple()\n    index = bisect_right(EXP_INDICES, exp) - 1\n    if index < 0:\n        return DIGIT_CODAS[digits[-1]]\n    else:\n        return EXP_CODAS[EXP_INDICES[index]]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfetches a deposit identifier.", "response": "def deposit_fetcher(record_uuid, data):\n    \"\"\"Fetch a deposit identifier.\n\n    :param record_uuid: Record UUID.\n    :param data: Record content.\n    :returns: A :class:`invenio_pidstore.fetchers.FetchedPID` that contains\n        data['_deposit']['id'] as pid_value.\n    \"\"\"\n    return FetchedPID(\n        provider=DepositProvider,\n        pid_type=DepositProvider.pid_type,\n        pid_value=str(data['_deposit']['id']),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nminting a deposit identifier.", "response": "def deposit_minter(record_uuid, data):\n    \"\"\"Mint a deposit identifier.\n\n    A PID with the following characteristics is created:\n\n    .. code-block:: python\n\n        {\n            \"object_type\": \"rec\",\n            \"object_uuid\": record_uuid,\n            \"pid_value\": \"<new-pid-value>\",\n            \"pid_type\": \"depid\",\n        }\n\n    The following deposit meta information are updated:\n\n    .. code-block:: python\n\n        deposit['_deposit'] = {\n            \"id\": \"<new-pid-value>\",\n            \"status\": \"draft\",\n        }\n\n    :param record_uuid: Record UUID.\n    :param data: Record content.\n    :returns: A :class:`invenio_pidstore.models.PersistentIdentifier` object.\n    \"\"\"\n    provider = DepositProvider.create(\n        object_type='rec',\n        object_uuid=record_uuid,\n        pid_value=uuid.uuid4().hex,\n    )\n    data['_deposit'] = {\n        'id': provider.pid.pid_value,\n        'status': 'draft',\n    }\n    return provider.pid"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef admin_permission_factory():\n    try:\n        pkg_resources.get_distribution('invenio-access')\n        from invenio_access.permissions import DynamicPermission as Permission\n    except pkg_resources.DistributionNotFound:\n        from flask_principal import Permission\n\n    return Permission(action_admin_access)", "response": "Factory for creating a permission for an admin deposit - admin - access."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating Invenio - Deposit - UI blueprint.", "response": "def create_blueprint(endpoints):\n    \"\"\"Create Invenio-Deposit-UI blueprint.\n\n    See: :data:`invenio_deposit.config.DEPOSIT_RECORDS_UI_ENDPOINTS`.\n\n    :param endpoints: List of endpoints configuration.\n    :returns: The configured blueprint.\n    \"\"\"\n    from invenio_records_ui.views import create_url_rule\n\n    blueprint = Blueprint(\n        'invenio_deposit_ui',\n        __name__,\n        static_folder='../static',\n        template_folder='../templates',\n        url_prefix='',\n    )\n\n    @blueprint.errorhandler(PIDDeletedError)\n    def tombstone_errorhandler(error):\n        \"\"\"Render tombstone page.\"\"\"\n        return render_template(\n            current_app.config['DEPOSIT_UI_TOMBSTONE_TEMPLATE'],\n            pid=error.pid,\n            record=error.record or {},\n        ), 410\n\n    for endpoint, options in (endpoints or {}).items():\n        options = deepcopy(options)\n        options.pop('jsonschema', None)\n        options.pop('schemaform', None)\n        blueprint.add_url_rule(**create_url_rule(endpoint, **options))\n\n    @blueprint.route('/deposit')\n    @login_required\n    def index():\n        \"\"\"List user deposits.\"\"\"\n        return render_template(current_app.config['DEPOSIT_UI_INDEX_TEMPLATE'])\n\n    @blueprint.route('/deposit/new')\n    @login_required\n    def new():\n        \"\"\"Create new deposit.\"\"\"\n        deposit_type = request.values.get('type')\n        return render_template(\n            current_app.config['DEPOSIT_UI_NEW_TEMPLATE'],\n            record={'_deposit': {'id': None}},\n            jsonschema=current_deposit.jsonschemas[deposit_type],\n            schemaform=current_deposit.schemaforms[deposit_type],\n        )\n\n    return blueprint"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndefault view method. Sends ``record_viewed`` signal and renders template.", "response": "def default_view_method(pid, record, template=None):\n    \"\"\"Default view method.\n\n    Sends ``record_viewed`` signal and renders template.\n    \"\"\"\n    record_viewed.send(\n        current_app._get_current_object(),\n        pid=pid,\n        record=record,\n    )\n\n    deposit_type = request.values.get('type')\n\n    return render_template(\n        template,\n        pid=pid,\n        record=record,\n        jsonschema=current_deposit.jsonschemas[deposit_type],\n        schemaform=current_deposit.schemaforms[deposit_type],\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(cls, object_type=None, object_uuid=None, **kwargs):\n        assert 'pid_value' in kwargs\n        kwargs.setdefault('status', cls.default_status)\n        return super(DepositProvider, cls).create(\n            object_type=object_type, object_uuid=object_uuid, **kwargs)", "response": "Create a new deposit identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_actions_from_class(record_class):\n    for name in dir(record_class):\n        method = getattr(record_class, name, None)\n        if method and getattr(method, '__deposit_action__', False):\n            yield method.__name__", "response": "Extract actions from class."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbases permission factory that checks OAuth2 scope and can_method.", "response": "def check_oauth2_scope(can_method, *myscopes):\n    \"\"\"Base permission factory that check OAuth2 scope and can_method.\n\n    :param can_method: Permission check function that accept a record in input\n        and return a boolean.\n    :param myscopes: List of scopes required to permit the access.\n    :returns: A :class:`flask_principal.Permission` factory.\n    \"\"\"\n    def check(record, *args, **kwargs):\n        @require_api_auth()\n        @require_oauth_scopes(*myscopes)\n        def can(self):\n            return can_method(record)\n\n        return type('CheckOAuth2Scope', (), {'can': can})()\n    return check"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if a given record is indexed.", "response": "def can_elasticsearch(record):\n    \"\"\"Check if a given record is indexed.\n\n    :param record: A record object.\n    :returns: If the record is indexed returns `True`, otherwise `False`.\n    \"\"\"\n    search = request._methodview.search_class()\n    search = search.get_record(str(record.id))\n    return search.count() == 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_error_handlers(blueprint):\n    blueprint.errorhandler(PIDInvalidAction)(create_api_errorhandler(\n        status=403, message='Invalid action'\n    ))\n    records_rest_error_handlers(blueprint)", "response": "Create error handlers on blueprint."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate Invenio - Deposit - REST blueprint.", "response": "def create_blueprint(endpoints):\n    \"\"\"Create Invenio-Deposit-REST blueprint.\n\n    See: :data:`invenio_deposit.config.DEPOSIT_REST_ENDPOINTS`.\n\n    :param endpoints: List of endpoints configuration.\n    :returns: The configured blueprint.\n    \"\"\"\n    blueprint = Blueprint(\n        'invenio_deposit_rest',\n        __name__,\n        url_prefix='',\n    )\n    create_error_handlers(blueprint)\n\n    for endpoint, options in (endpoints or {}).items():\n        options = deepcopy(options)\n\n        if 'files_serializers' in options:\n            files_serializers = options.get('files_serializers')\n            files_serializers = {mime: obj_or_import_string(func)\n                                 for mime, func in files_serializers.items()}\n            del options['files_serializers']\n        else:\n            files_serializers = {}\n\n        if 'record_serializers' in options:\n            serializers = options.get('record_serializers')\n            serializers = {mime: obj_or_import_string(func)\n                           for mime, func in serializers.items()}\n        else:\n            serializers = {}\n\n        file_list_route = options.pop(\n            'file_list_route',\n            '{0}/files'.format(options['item_route'])\n        )\n        file_item_route = options.pop(\n            'file_item_route',\n            '{0}/files/<path:key>'.format(options['item_route'])\n        )\n\n        options.setdefault('search_class', DepositSearch)\n        search_class = obj_or_import_string(options['search_class'])\n\n        # records rest endpoints will use the deposit class as record class\n        options.setdefault('record_class', Deposit)\n        record_class = obj_or_import_string(options['record_class'])\n\n        # backward compatibility for indexer class\n        options.setdefault('indexer_class', None)\n\n        for rule in records_rest_url_rules(endpoint, **options):\n            blueprint.add_url_rule(**rule)\n\n        search_class_kwargs = {}\n        if options.get('search_index'):\n            search_class_kwargs['index'] = options['search_index']\n\n        if options.get('search_type'):\n            search_class_kwargs['doc_type'] = options['search_type']\n\n        ctx = dict(\n            read_permission_factory=obj_or_import_string(\n                options.get('read_permission_factory_imp')\n            ),\n            create_permission_factory=obj_or_import_string(\n                options.get('create_permission_factory_imp')\n            ),\n            update_permission_factory=obj_or_import_string(\n                options.get('update_permission_factory_imp')\n            ),\n            delete_permission_factory=obj_or_import_string(\n                options.get('delete_permission_factory_imp')\n            ),\n            record_class=record_class,\n            search_class=partial(search_class, **search_class_kwargs),\n            default_media_type=options.get('default_media_type'),\n        )\n\n        deposit_actions = DepositActionResource.as_view(\n            DepositActionResource.view_name.format(endpoint),\n            serializers=serializers,\n            pid_type=options['pid_type'],\n            ctx=ctx,\n        )\n\n        blueprint.add_url_rule(\n            '{0}/actions/<any({1}):action>'.format(\n                options['item_route'],\n                ','.join(extract_actions_from_class(record_class)),\n            ),\n            view_func=deposit_actions,\n            methods=['POST'],\n        )\n\n        deposit_files = DepositFilesResource.as_view(\n            DepositFilesResource.view_name.format(endpoint),\n            serializers=files_serializers,\n            pid_type=options['pid_type'],\n            ctx=ctx,\n        )\n\n        blueprint.add_url_rule(\n            file_list_route,\n            view_func=deposit_files,\n            methods=['GET', 'POST', 'PUT'],\n        )\n\n        deposit_file = DepositFileResource.as_view(\n            DepositFileResource.view_name.format(endpoint),\n            serializers=files_serializers,\n            pid_type=options['pid_type'],\n            ctx=ctx,\n        )\n\n        blueprint.add_url_rule(\n            file_item_route,\n            view_func=deposit_file,\n            methods=['GET', 'PUT', 'DELETE'],\n        )\n    return blueprint"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef post(self, pid, record, action):\n        record = getattr(record, action)(pid=pid)\n\n        db.session.commit()\n        # Refresh the PID and record metadata\n        db.session.refresh(pid)\n        db.session.refresh(record.model)\n        post_action.send(current_app._get_current_object(), action=action,\n                         pid=pid, deposit=record)\n        response = self.make_response(pid, record,\n                                      202 if action == 'publish' else 201)\n        endpoint = '.{0}_item'.format(pid.pid_type)\n        location = url_for(endpoint, pid_value=pid.pid_value, _external=True)\n        response.headers.extend(dict(Location=location))\n        return response", "response": "Handle deposit action.\n\n        After the action is executed, a\n        :class:`invenio_deposit.signals.post_action` signal is sent.\n\n        Permission required: `update_permission_factory`.\n\n        :param pid: Pid object (from url).\n        :param record: Record object resolved from the pid.\n        :param action: The action to execute."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, pid, record):\n        return self.make_response(obj=record.files, pid=pid, record=record)", "response": "Get files.\n\n        Permission required: `read_permission_factory`.\n\n        :param pid: Pid object (from url).\n        :param record: Record object resolved from the pid.\n        :returns: The files."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle POST deposit files. Permission required: `update_permission_factory`. :param pid: Pid object (from url). :param record: Record object resolved from the pid.", "response": "def post(self, pid, record):\n        \"\"\"Handle POST deposit files.\n\n        Permission required: `update_permission_factory`.\n\n        :param pid: Pid object (from url).\n        :param record: Record object resolved from the pid.\n        \"\"\"\n        # load the file\n        uploaded_file = request.files['file']\n        # file name\n        key = secure_filename(\n            request.form.get('name') or uploaded_file.filename\n        )\n        # check if already exists a file with this name\n        if key in record.files:\n            raise FileAlreadyExists()\n        # add it to the deposit\n        record.files[key] = uploaded_file.stream\n        record.commit()\n        db.session.commit()\n        return self.make_response(\n            obj=record.files[key].obj, pid=pid, record=record, status=201)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef put(self, pid, record):\n        try:\n            ids = [data['id'] for data in json.loads(\n                request.data.decode('utf-8'))]\n        except KeyError:\n            raise WrongFile()\n\n        record.files.sort_by(*ids)\n        record.commit()\n        db.session.commit()\n        return self.make_response(obj=record.files, pid=pid, record=record)", "response": "Handle the sort of the files through the PUT deposit files."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget file. Permission required: `read_permission_factory`. :param pid: Pid object (from url). :param record: Record object resolved from the pid. :param key: Unique identifier for the file in the deposit. :param version_id: File version. Optional. If no version is provided, the last version is retrieved. :returns: the file content.", "response": "def get(self, pid, record, key, version_id, **kwargs):\n        \"\"\"Get file.\n\n        Permission required: `read_permission_factory`.\n\n        :param pid: Pid object (from url).\n        :param record: Record object resolved from the pid.\n        :param key: Unique identifier for the file in the deposit.\n        :param version_id: File version. Optional. If no version is provided,\n            the last version is retrieved.\n        :returns: the file content.\n        \"\"\"\n        try:\n            obj = record.files[str(key)].get_version(version_id=version_id)\n            return self.make_response(\n                obj=obj or abort(404), pid=pid, record=record)\n        except KeyError:\n            abort(404)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef put(self, pid, record, key):\n        try:\n            data = json.loads(request.data.decode('utf-8'))\n            new_key = data['filename']\n        except KeyError:\n            raise WrongFile()\n        new_key_secure = secure_filename(new_key)\n        if not new_key_secure or new_key != new_key_secure:\n            raise WrongFile()\n        try:\n            obj = record.files.rename(str(key), new_key_secure)\n        except KeyError:\n            abort(404)\n        record.commit()\n        db.session.commit()\n        return self.make_response(obj=obj, pid=pid, record=record)", "response": "Handle the file rename through the PUT deposit file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling DELETE deposit file.", "response": "def delete(self, pid, record, key):\n        \"\"\"Handle DELETE deposit file.\n\n        Permission required: `update_permission_factory`.\n\n        :param pid: Pid object (from url).\n        :param record: Record object resolved from the pid.\n        :param key: Unique identifier for the file in the deposit.\n        \"\"\"\n        try:\n            del record.files[str(key)]\n            record.commit()\n            db.session.commit()\n            return make_response('', 204)\n        except KeyError:\n            abort(404, 'The specified object does not exist or has already '\n                  'been deleted.')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload records from file.", "response": "def records():\n    \"\"\"Load records.\"\"\"\n    import pkg_resources\n    from dojson.contrib.marc21 import marc21\n    from dojson.contrib.marc21.utils import create_record, split_blob\n    from flask_login import login_user, logout_user\n    from invenio_accounts.models import User\n    from invenio_deposit.api import Deposit\n\n    users = User.query.all()\n\n    # pkg resources the demodata\n    data_path = pkg_resources.resource_filename(\n        'invenio_records', 'data/marc21/bibliographic.xml'\n    )\n    with open(data_path) as source:\n        with current_app.test_request_context():\n            indexer = RecordIndexer()\n            with db.session.begin_nested():\n                for index, data in enumerate(split_blob(source.read()),\n                                             start=1):\n                    login_user(users[index % len(users)])\n                    # do translate\n                    record = marc21.do(create_record(data))\n                    # create record\n                    indexer.index(Deposit.create(record))\n                    logout_user()\n            db.session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading deposit JSON schemas.", "response": "def jsonschemas(self):\n        \"\"\"Load deposit JSON schemas.\"\"\"\n        _jsonschemas = {\n            k: v['jsonschema']\n            for k, v in self.app.config['DEPOSIT_RECORDS_UI_ENDPOINTS'].items()\n            if 'jsonschema' in v\n        }\n        return defaultdict(\n            lambda: self.app.config['DEPOSIT_DEFAULT_JSONSCHEMA'], _jsonschemas\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload deposit schema forms.", "response": "def schemaforms(self):\n        \"\"\"Load deposit schema forms.\"\"\"\n        _schemaforms = {\n            k: v['schemaform']\n            for k, v in self.app.config['DEPOSIT_RECORDS_UI_ENDPOINTS'].items()\n            if 'schemaform' in v\n        }\n        return defaultdict(\n            lambda: self.app.config['DEPOSIT_DEFAULT_SCHEMAFORM'], _schemaforms\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef init_app(self, app):\n        self.init_config(app)\n        app.register_blueprint(ui.create_blueprint(\n            app.config['DEPOSIT_RECORDS_UI_ENDPOINTS']\n        ))\n        app.extensions['invenio-deposit'] = _DepositState(app)\n        if app.config['DEPOSIT_REGISTER_SIGNALS']:\n            post_action.connect(index_deposit_after_publish, sender=app,\n                                weak=False)", "response": "Flask application initialization.\n\n        Initialize the UI endpoints.  Connect all signals if\n        `DEPOSIT_REGISTER_SIGNALS` is ``True``.\n\n        :param app: An instance of :class:`flask.Flask`."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes the Flask application.", "response": "def init_app(self, app):\n        \"\"\"Flask application initialization.\n\n        Initialize the REST endpoints.  Connect all signals if\n        `DEPOSIT_REGISTER_SIGNALS` is True.\n\n        :param app: An instance of :class:`flask.Flask`.\n        \"\"\"\n        self.init_config(app)\n        blueprint = rest.create_blueprint(\n            app.config['DEPOSIT_REST_ENDPOINTS']\n        )\n\n        # FIXME: This is a temporary fix. This means that\n        # invenio-records-rest's endpoint_prefixes cannot be used before\n        # the first request or in other processes, ex: Celery tasks.\n        @app.before_first_request\n        def extend_default_endpoint_prefixes():\n            \"\"\"Extend redirects between PID types.\"\"\"\n            endpoint_prefixes = utils.build_default_endpoint_prefixes(\n                dict(app.config['DEPOSIT_REST_ENDPOINTS'])\n            )\n            current_records_rest = app.extensions['invenio-records-rest']\n            overlap = set(endpoint_prefixes.keys()) & set(\n                current_records_rest.default_endpoint_prefixes\n            )\n            if overlap:\n                raise RuntimeError(\n                    'Deposit wants to override endpoint prefixes {0}.'.format(\n                        ', '.join(overlap)\n                    )\n                )\n            current_records_rest.default_endpoint_prefixes.update(\n                endpoint_prefixes\n            )\n\n        app.register_blueprint(blueprint)\n        app.extensions['invenio-deposit-rest'] = _DepositState(app)\n        if app.config['DEPOSIT_REGISTER_SIGNALS']:\n            post_action.connect(index_deposit_after_publish, sender=app,\n                                weak=False)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deposit_links_factory(pid):\n    links = default_links_factory(pid)\n\n    def _url(name, **kwargs):\n        \"\"\"URL builder.\"\"\"\n        endpoint = '.{0}_{1}'.format(\n            current_records_rest.default_endpoint_prefixes[pid.pid_type],\n            name,\n        )\n        return url_for(endpoint, pid_value=pid.pid_value, _external=True,\n                       **kwargs)\n\n    links['files'] = _url('files')\n\n    ui_endpoint = current_app.config.get('DEPOSIT_UI_ENDPOINT')\n    if ui_endpoint is not None:\n        links['html'] = ui_endpoint.format(\n            host=request.host,\n            scheme=request.scheme,\n            pid_value=pid.pid_value,\n        )\n\n    deposit_cls = Deposit\n    if 'pid_value' in request.view_args:\n        deposit_cls = request.view_args['pid_value'].data[1].__class__\n\n    for action in extract_actions_from_class(deposit_cls):\n        links[action] = _url('actions', action=action)\n    return links", "response": "Factory for record links generation."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads minter from PIDStore registry based on given value.", "response": "def process_minter(value):\n    \"\"\"Load minter from PIDStore registry based on given value.\n\n    :param value: Name of the minter.\n    :returns: The minter.\n    \"\"\"\n    try:\n        return current_pidstore.minters[value]\n    except KeyError:\n        raise click.BadParameter(\n            'Unknown minter {0}. Please use one of {1}.'.format(\n                value, ', '.join(current_pidstore.minters.keys())\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading schema from JSONSchema registry based on given value.", "response": "def process_schema(value):\n    \"\"\"Load schema from JSONSchema registry based on given value.\n\n    :param value: Schema path, relative to the directory when it was\n        registered.\n    :returns: The schema absolute path.\n    \"\"\"\n    schemas = current_app.extensions['invenio-jsonschemas'].schemas\n    try:\n        return schemas[value]\n    except KeyError:\n        raise click.BadParameter(\n            'Unknown schema {0}. Please use one of:\\n {1}'.format(\n                value, '\\n'.join(schemas.keys())\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef json_serializer(pid, data, *args):\n    if data is not None:\n        response = Response(\n            json.dumps(data.dumps()),\n            mimetype='application/json'\n        )\n    else:\n        response = Response(mimetype='application/json')\n    return response", "response": "Builds a JSON Flask response using the given data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nserializing a object version to a dictionary.", "response": "def file_serializer(obj):\n    \"\"\"Serialize a object.\n\n    :param obj: A :class:`invenio_files_rest.models.ObjectVersion` instance.\n    :returns: A dictionary with the fields to serialize.\n    \"\"\"\n    return {\n        \"id\": str(obj.file_id),\n        \"filename\": obj.key,\n        \"filesize\": obj.file.size,\n        \"checksum\": obj.file.checksum,\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef json_file_response(obj=None, pid=None, record=None, status=None):\n    from invenio_records_files.api import FilesIterator\n\n    if isinstance(obj, FilesIterator):\n        return json_files_serializer(obj, status=status)\n    else:\n        return json_file_serializer(obj, status=status)", "response": "Returns a Flask response with JSON data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef index_deposit_after_publish(sender, action=None, pid=None, deposit=None):\n    if action == 'publish':\n        _, record = deposit.fetch_published()\n        index_record.delay(str(record.id))", "response": "Index the record after publishing."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef has_status(method=None, status='draft'):\n    if method is None:\n        return partial(has_status, status=status)\n\n    @wraps(method)\n    def wrapper(self, *args, **kwargs):\n        \"\"\"Check current deposit status.\"\"\"\n        if status != self.status:\n            raise PIDInvalidAction()\n\n        return method(self, *args, **kwargs)\n    return wrapper", "response": "Decorator to check that the current deposit has a defined status."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npreserves fields in deposit. :param method: Function to execute. (Default: ``None``) :param result: If `True` returns the result of method execution, otherwise `self`. (Default: ``True``) :param fields: List of fields to preserve (default: ``('_deposit',)``).", "response": "def preserve(method=None, result=True, fields=None):\n    \"\"\"Preserve fields in deposit.\n\n    :param method: Function to execute. (Default: ``None``)\n    :param result: If `True` returns the result of method execution,\n        otherwise `self`. (Default: ``True``)\n    :param fields: List of fields to preserve (default: ``('_deposit',)``).\n    \"\"\"\n    if method is None:\n        return partial(preserve, result=result, fields=fields)\n\n    fields = fields or ('_deposit', )\n\n    @wraps(method)\n    def wrapper(self, *args, **kwargs):\n        \"\"\"Check current deposit status.\"\"\"\n        data = {field: self[field] for field in fields if field in self}\n        result_ = method(self, *args, **kwargs)\n        replace = result_ if result else self\n        for field in data:\n            replace[field] = data[field]\n        return result_\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an instance of deposit PID.", "response": "def pid(self):\n        \"\"\"Return an instance of deposit PID.\"\"\"\n        pid = self.deposit_fetcher(self.id, self)\n        return PersistentIdentifier.get(pid.pid_type,\n                                        pid.pid_value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert deposit schema to a valid record schema.", "response": "def record_schema(self):\n        \"\"\"Convert deposit schema to a valid record schema.\"\"\"\n        schema_path = current_jsonschemas.url_to_path(self['$schema'])\n        schema_prefix = current_app.config['DEPOSIT_JSONSCHEMAS_PREFIX']\n        if schema_path and schema_path.startswith(schema_prefix):\n            return current_jsonschemas.path_to_url(\n                schema_path[len(schema_prefix):]\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting record schema to a valid deposit schema.", "response": "def build_deposit_schema(self, record):\n        \"\"\"Convert record schema to a valid deposit schema.\n\n        :param record: The record used to build deposit schema.\n        :returns: The absolute URL to the schema or `None`.\n        \"\"\"\n        schema_path = current_jsonschemas.url_to_path(record['$schema'])\n        schema_prefix = current_app.config['DEPOSIT_JSONSCHEMAS_PREFIX']\n        if schema_path:\n            return current_jsonschemas.path_to_url(\n                schema_prefix + schema_path\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a tuple with PID and published record.", "response": "def fetch_published(self):\n        \"\"\"Return a tuple with PID and published record.\"\"\"\n        pid_type = self['_deposit']['pid']['type']\n        pid_value = self['_deposit']['pid']['value']\n\n        resolver = Resolver(\n            pid_type=pid_type, object_type='rec',\n            getter=partial(self.published_record_class.get_record,\n                           with_deleted=True)\n        )\n        return resolver.resolve(pid_value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmerge changes with latest published version.", "response": "def merge_with_published(self):\n        \"\"\"Merge changes with latest published version.\"\"\"\n        pid, first = self.fetch_published()\n        lca = first.revisions[self['_deposit']['pid']['revision_id']]\n        # ignore _deposit and $schema field\n        args = [lca.dumps(), first.dumps(), self.dumps()]\n        for arg in args:\n            del arg['$schema'], arg['_deposit']\n        args.append({})\n        m = Merger(*args)\n        try:\n            m.run()\n        except UnresolvedConflictsException:\n            raise MergeConflict()\n        return patch(m.unified_patches, lca)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef commit(self, *args, **kwargs):\n        return super(Deposit, self).commit(*args, **kwargs)", "response": "Store changes on current instance in database and index it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(cls, data, id_=None):\n        data.setdefault('$schema', current_jsonschemas.path_to_url(\n            current_app.config['DEPOSIT_DEFAULT_JSONSCHEMA']\n        ))\n        if '_deposit' not in data:\n            id_ = id_ or uuid.uuid4()\n            cls.deposit_minter(id_, data)\n\n        data['_deposit'].setdefault('owners', list())\n        if current_user and current_user.is_authenticated:\n            creator_id = int(current_user.get_id())\n\n            if creator_id not in data['_deposit']['owners']:\n                data['_deposit']['owners'].append(creator_id)\n\n            data['_deposit']['created_by'] = creator_id\n\n        return super(Deposit, cls).create(data, id_=id_)", "response": "Create a new deposit."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _process_files(self, record_id, data):\n        if self.files:\n            assert not self.files.bucket.locked\n            self.files.bucket.locked = True\n            snapshot = self.files.bucket.snapshot(lock=True)\n            data['_files'] = self.files.dumps(bucket=snapshot.id)\n            yield data\n            db.session.add(RecordsBuckets(\n                record_id=record_id, bucket_id=snapshot.id\n            ))\n        else:\n            yield data", "response": "Add files in record during first publishing."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _publish_new(self, id_=None):\n        minter = current_pidstore.minters[\n            current_app.config['DEPOSIT_PID_MINTER']\n        ]\n        id_ = id_ or uuid.uuid4()\n        record_pid = minter(id_, self)\n\n        self['_deposit']['pid'] = {\n            'type': record_pid.pid_type,\n            'value': record_pid.pid_value,\n            'revision_id': 0,\n        }\n\n        data = dict(self.dumps())\n        data['$schema'] = self.record_schema\n\n        with self._process_files(id_, data):\n            record = self.published_record_class.create(data, id_=id_)\n\n        return record", "response": "Publish a new record."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npublish the deposit after editing.", "response": "def _publish_edited(self):\n        \"\"\"Publish the deposit after for editing.\"\"\"\n        record_pid, record = self.fetch_published()\n        if record.revision_id == self['_deposit']['pid']['revision_id']:\n            data = dict(self.dumps())\n        else:\n            data = self.merge_with_published()\n\n        data['$schema'] = self.record_schema\n        data['_deposit'] = self['_deposit']\n        record = record.__class__(data, model=record.model)\n        return record"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npublish a new version of a deposit.", "response": "def publish(self, pid=None, id_=None):\n        \"\"\"Publish a deposit.\n\n        If it's the first time:\n\n        * it calls the minter and set the following meta information inside\n            the deposit:\n\n        .. code-block:: python\n\n            deposit['_deposit'] = {\n                'type': pid_type,\n                'value': pid_value,\n                'revision_id': 0,\n            }\n\n        * A dump of all information inside the deposit is done.\n\n        * A snapshot of the files is done.\n\n        Otherwise, published the new edited version.\n        In this case, if in the mainwhile someone already published a new\n        version, it'll try to merge the changes with the latest version.\n\n        .. note:: no need for indexing as it calls `self.commit()`.\n\n        Status required: ``'draft'``.\n\n        :param pid: Force the new pid value. (Default: ``None``)\n        :param id_: Force the new uuid value as deposit id. (Default: ``None``)\n        :returns: Returns itself.\n        \"\"\"\n        pid = pid or self.pid\n\n        if not pid.is_registered():\n            raise PIDInvalidAction()\n\n        self['_deposit']['status'] = 'published'\n\n        if self['_deposit'].get('pid') is None:  # First publishing\n            self._publish_new(id_=id_)\n        else:  # Update after edit\n            record = self._publish_edited()\n            record.commit()\n        self.commit()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating selected keys. :param record: The record to prepare.", "response": "def _prepare_edit(self, record):\n        \"\"\"Update selected keys.\n\n        :param record: The record to prepare.\n        \"\"\"\n        data = record.dumps()\n        # Keep current record revision for merging.\n        data['_deposit']['pid']['revision_id'] = record.revision_id\n        data['_deposit']['status'] = 'draft'\n        data['$schema'] = self.build_deposit_schema(record)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nedits the current object.", "response": "def edit(self, pid=None):\n        \"\"\"Edit deposit.\n\n        #. The signal :data:`invenio_records.signals.before_record_update`\n           is sent before the edit execution.\n\n        #. The following meta information are saved inside the deposit:\n\n        .. code-block:: python\n\n            deposit['_deposit']['pid'] = record.revision_id\n            deposit['_deposit']['status'] = 'draft'\n            deposit['$schema'] = deposit_schema_from_record_schema\n\n        #. The signal :data:`invenio_records.signals.after_record_update` is\n            sent after the edit execution.\n\n        #. The deposit index is updated.\n\n        Status required: `published`.\n\n        .. note:: the process fails if the pid has status\n            :attr:`invenio_pidstore.models.PIDStatus.REGISTERED`.\n\n        :param pid: Force a pid object. (Default: ``None``)\n        :returns: A new Deposit object.\n        \"\"\"\n        pid = pid or self.pid\n\n        with db.session.begin_nested():\n            before_record_update.send(\n                current_app._get_current_object(), record=self)\n\n            record_pid, record = self.fetch_published()\n            assert PIDStatus.REGISTERED == record_pid.status\n            assert record['_deposit'] == self['_deposit']\n\n            self.model.json = self._prepare_edit(record)\n\n            flag_modified(self.model, 'json')\n            db.session.merge(self.model)\n\n        after_record_update.send(\n            current_app._get_current_object(), record=self)\n        return self.__class__(self.model.json, model=self.model)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef discard(self, pid=None):\n        pid = pid or self.pid\n\n        with db.session.begin_nested():\n            before_record_update.send(\n                current_app._get_current_object(), record=self)\n\n            _, record = self.fetch_published()\n            self.model.json = deepcopy(record.model.json)\n            self.model.json['$schema'] = self.build_deposit_schema(record)\n\n            flag_modified(self.model, 'json')\n            db.session.merge(self.model)\n\n        after_record_update.send(\n            current_app._get_current_object(), record=self)\n        return self.__class__(self.model.json, model=self.model)", "response": "Discards the current record."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete deposit. Status required: ``'draft'``. :param force: Force deposit delete. (Default: ``True``) :param pid: Force pid object. (Default: ``None``) :returns: A new Deposit object.", "response": "def delete(self, force=True, pid=None):\n        \"\"\"Delete deposit.\n\n        Status required: ``'draft'``.\n\n        :param force: Force deposit delete.  (Default: ``True``)\n        :param pid: Force pid object.  (Default: ``None``)\n        :returns: A new Deposit object.\n        \"\"\"\n        pid = pid or self.pid\n\n        if self['_deposit'].get('pid'):\n            raise PIDInvalidAction()\n        if pid:\n            pid.delete()\n        return super(Deposit, self).delete(force=force)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclear only drafts. Status required: ``'draft'``. Meta information inside `_deposit` are preserved.", "response": "def clear(self, *args, **kwargs):\n        \"\"\"Clear only drafts.\n\n        Status required: ``'draft'``.\n\n        Meta information inside `_deposit` are preserved.\n        \"\"\"\n        super(Deposit, self).clear(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates only drafts. Status required : drafts. Meta information inside _deposit are preserved.", "response": "def update(self, *args, **kwargs):\n        \"\"\"Update only drafts.\n\n        Status required: ``'draft'``.\n\n        Meta information inside `_deposit` are preserved.\n        \"\"\"\n        super(Deposit, self).update(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef patch(self, *args, **kwargs):\n        return super(Deposit, self).patch(*args, **kwargs)", "response": "Patch only drafts.\n        Status required."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef files(self):\n        files_ = super(Deposit, self).files\n\n        if files_:\n            sort_by_ = files_.sort_by\n\n            def sort_by(*args, **kwargs):\n                \"\"\"Only in draft state.\"\"\"\n                if 'draft' != self.status:\n                    raise PIDInvalidAction()\n                return sort_by_(*args, **kwargs)\n\n            files_.sort_by = sort_by\n\n        return files_", "response": "List of files inside the deposit."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a reStructuredText into its node", "response": "def rst2node(doc_name, data):\n    \"\"\"Converts a reStructuredText into its node\n    \"\"\"\n    if not data:\n        return\n    parser = docutils.parsers.rst.Parser()\n    document = docutils.utils.new_document('<%s>' % doc_name)\n    document.settings = docutils.frontend.OptionParser().get_default_values()\n    document.settings.tab_width = 4\n    document.settings.pep_references = False\n    document.settings.rfc_references = False\n    document.settings.env = Env()\n    parser.parse(data, document)\n    if len(document.children) == 1:\n        return document.children[0]\n    else:\n        par = docutils.nodes.paragraph()\n        for child in document.children:\n            par += child\n        return par"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setup(app):\n    if 'http' not in app.domains:\n        httpdomain.setup(app)\n\n    app.add_directive('autopyramid', RouteDirective)", "response": "Hook the directives when Sphinx asks for it."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_response(self, response):\n        if not self._raise_errors:\n            return response\n\n        is_4xx_error = str(response.status_code)[0] == '4'\n        is_5xx_error = str(response.status_code)[0] == '5'\n        content = response.content\n\n        if response.status_code == 403:\n            raise AuthenticationError(content)\n        elif is_4xx_error:\n            raise APIError(content)\n        elif is_5xx_error:\n            raise ServerError(content)\n\n        return response", "response": "Parses the response and raises appropriate errors if raise_errors is set to True."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _api_request(self, endpoint, http_method, *args, **kwargs):\n        logger.debug(' > Sending API request to endpoint: %s' % endpoint)\n\n        auth = self._build_http_auth()\n\n        headers = self._build_request_headers(kwargs.get('headers'))\n        logger.debug('\\theaders: %s' % headers)\n\n        path = self._build_request_path(endpoint)\n        logger.debug('\\tpath: %s' % path)\n\n        data = self._build_payload(kwargs.get('payload'))\n        if not data:\n            data = kwargs.get('data')\n        logger.debug('\\tdata: %s' % data)\n\n        req_kw = dict(\n            auth=auth,\n            headers=headers,\n            timeout=kwargs.get('timeout', self.DEFAULT_TIMEOUT)\n        )\n\n        # do some error handling\n        if (http_method == self.HTTP_POST):\n            if (data):\n                r = requests.post(path, data=data, **req_kw)\n            else:\n                r = requests.post(path, **req_kw)\n        elif http_method == self.HTTP_PUT:\n            if (data):\n                r = requests.put(path, data=data, **req_kw)\n            else:\n                r = requests.put(path, **req_kw)\n        elif http_method == self.HTTP_DELETE:\n            r = requests.delete(path, **req_kw)\n        else:\n            r = requests.get(path, **req_kw)\n\n        logger.debug('\\tresponse code:%s' % r.status_code)\n        try:\n            logger.debug('\\tresponse: %s' % r.json())\n        except:\n            logger.debug('\\tresponse: %s' % r.content)\n\n        return self._parse_response(r)", "response": "Private method for making API requests"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_log(self, log_id, timeout=None):\n        return self._api_request(\n            self.GET_LOG_ENDPOINT % log_id,\n            self.HTTP_GET,\n            timeout=timeout\n        )", "response": "Get a specific log entry"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting log events for a specific log entry", "response": "def get_log_events(self, log_id, timeout=None):\n        \"\"\" API call to get a specific log entry \"\"\"\n        return self._api_request(\n            self.GET_LOG_EVENTS_ENDPOINT % log_id,\n            self.HTTP_GET,\n            timeout=timeout\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a list of templates", "response": "def templates(self, timeout=None):\n        \"\"\" API call to get a list of templates \"\"\"\n        return self._api_request(\n            self.TEMPLATES_ENDPOINT,\n            self.HTTP_GET,\n            timeout=timeout\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_new_version(\n        self,\n        name,\n        subject,\n        text='',\n        template_id=None,\n        html=None,\n        locale=None,\n        timeout=None\n    ):\n        \"\"\" API call to create a new version of a template \"\"\"\n        if(html):\n            payload = {\n                'name': name,\n                'subject': subject,\n                'html': html,\n                'text': text\n            }\n        else:\n            payload = {\n                'name': name,\n                'subject': subject,\n                'text': text\n            }\n\n        if locale:\n            url = self.TEMPLATES_SPECIFIC_LOCALE_VERSIONS_ENDPOINT % (\n                template_id,\n                locale\n            )\n        else:\n            url = self.TEMPLATES_NEW_VERSION_ENDPOINT % template_id\n\n        return self._api_request(\n            url,\n            self.HTTP_POST,\n            payload=payload,\n            timeout=timeout\n        )", "response": "This method creates a new version of a template."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_template_version(\n        self,\n        name,\n        subject,\n        template_id,\n        version_id,\n        text='',\n        html=None,\n        timeout=None\n    ):\n        \"\"\" API call to update a template version \"\"\"\n        if(html):\n            payload = {\n                'name': name,\n                'subject': subject,\n                'html': html,\n                'text': text\n            }\n        else:\n            payload = {\n                'name': name,\n                'subject': subject,\n                'text': text\n            }\n\n        return self._api_request(\n            self.TEMPLATES_VERSION_ENDPOINT % (template_id, version_id),\n            self.HTTP_PUT,\n            payload=payload,\n            timeout=timeout\n        )", "response": "Update a template version"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets list of snippets from the API", "response": "def snippets(self, timeout=None):\n        \"\"\" API call to get list of snippets \"\"\"\n        return self._api_request(\n            self.SNIPPETS_ENDPOINT,\n            self.HTTP_GET,\n            timeout=timeout\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_snippet(self, snippet_id, timeout=None):\n        return self._api_request(\n            self.SNIPPET_ENDPOINT % (snippet_id),\n            self.HTTP_GET,\n            timeout=timeout\n        )", "response": "Get a specific Snippet"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_snippet(self, name, body, timeout=None):\n        payload = {\n            'name': name,\n            'body': body\n        }\n        return self._api_request(\n            self.SNIPPETS_ENDPOINT,\n            self.HTTP_POST,\n            payload=payload,\n            timeout=timeout\n        )", "response": "API call to create a Snippet"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking a dictionary with filename and base64 file data", "response": "def _make_file_dict(self, f):\n        \"\"\"Make a dictionary with filename and base64 file data\"\"\"\n        if isinstance(f, dict):\n            file_obj = f['file']\n            if 'filename' in f:\n                file_name = f['filename']\n            else:\n                file_name = file_obj.name\n        else:\n            file_obj = f\n            file_name = f.name\n\n        b64_data = base64.b64encode(file_obj.read())\n        return {\n            'id': file_name,\n            'data': b64_data.decode() if six.PY3 else b64_data,\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend an email to the specified recipient.", "response": "def send(\n        self,\n        email_id,\n        recipient,\n        email_data=None,\n        sender=None,\n        cc=None,\n        bcc=None,\n        tags=[],\n        headers={},\n        esp_account=None,\n        locale=None,\n        email_version_name=None,\n        inline=None,\n        files=[],\n        timeout=None\n    ):\n        \"\"\" API call to send an email \"\"\"\n        if not email_data:\n            email_data = {}\n\n        # for backwards compatibility, will be removed\n        if isinstance(recipient, string_types):\n            warnings.warn(\n                \"Passing email directly for recipient is deprecated\",\n                DeprecationWarning)\n            recipient = {'address': recipient}\n\n        payload = {\n            'email_id': email_id,\n            'recipient': recipient,\n            'email_data': email_data\n        }\n\n        if sender:\n            payload['sender'] = sender\n        if cc:\n            if not type(cc) == list:\n                logger.error(\n                    'kwarg cc must be type(list), got %s' % type(cc))\n            payload['cc'] = cc\n        if bcc:\n            if not type(bcc) == list:\n                logger.error(\n                    'kwarg bcc must be type(list), got %s' % type(bcc))\n            payload['bcc'] = bcc\n\n        if tags:\n            if not type(tags) == list:\n                logger.error(\n                    'kwarg tags must be type(list), got %s' % (type(tags)))\n            payload['tags'] = tags\n\n        if headers:\n            if not type(headers) == dict:\n                logger.error(\n                    'kwarg headers must be type(dict), got %s' % (\n                        type(headers)\n                    )\n                )\n            payload['headers'] = headers\n\n        if esp_account:\n            if not isinstance(esp_account, string_types):\n                logger.error(\n                    'kwarg esp_account must be a string, got %s' % (\n                        type(esp_account)\n                    )\n                )\n            payload['esp_account'] = esp_account\n\n        if locale:\n            if not isinstance(locale, string_types):\n                logger.error(\n                    'kwarg locale must be a string, got %s' % (type(locale))\n                )\n            payload['locale'] = locale\n\n        if email_version_name:\n            if not isinstance(email_version_name, string_types):\n                logger.error(\n                    'kwarg email_version_name must be a string, got %s' % (\n                        type(email_version_name)))\n            payload['version_name'] = email_version_name\n\n        if inline:\n            payload['inline'] = self._make_file_dict(inline)\n\n        if files:\n            payload['files'] = [self._make_file_dict(f) for f in files]\n\n        return self._api_request(\n            self.SEND_ENDPOINT,\n            self.HTTP_POST,\n            payload=payload,\n            timeout=timeout\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _api_request(self, endpoint, http_method, *args, **kwargs):\n        logger.debug(' > Queing batch api request for endpoint: %s' % endpoint)\n\n        path = self._build_request_path(endpoint, absolute=False)\n        logger.debug('\\tpath: %s' % path)\n\n        data = None\n        if 'payload' in kwargs:\n            data = kwargs['payload']\n        logger.debug('\\tdata: %s' % data)\n\n        command = {\n            \"path\": path,\n            \"method\": http_method\n        }\n        if data:\n            command['body'] = data\n\n        self._commands.append(command)", "response": "Private method for api requests"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute all currently queued batch commands", "response": "def execute(self, timeout=None):\n        \"\"\"Execute all currently queued batch commands\"\"\"\n        logger.debug(' > Batch API request (length %s)' % len(self._commands))\n\n        auth = self._build_http_auth()\n\n        headers = self._build_request_headers()\n        logger.debug('\\tbatch headers: %s' % headers)\n\n        logger.debug('\\tbatch command length: %s' % len(self._commands))\n\n        path = self._build_request_path(self.BATCH_ENDPOINT)\n\n        data = json.dumps(self._commands, cls=self._json_encoder)\n        r = requests.post(\n            path,\n            auth=auth,\n            headers=headers,\n            data=data,\n            timeout=(self.DEFAULT_TIMEOUT if timeout is None else timeout)\n        )\n\n        self._commands = []\n\n        logger.debug('\\tresponse code:%s' % r.status_code)\n        try:\n            logger.debug('\\tresponse: %s' % r.json())\n        except:\n            logger.debug('\\tresponse: %s' % r.content)\n\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_group_tabs(self):\n        if self.tab_group is None:\n            raise ImproperlyConfigured(\n                \"%s requires a definition of 'tab_group'\" %\n                self.__class__.__name__)\n        group_members = [t for t in self._registry if t.tab_group == self.tab_group]\n        return [t() for t in group_members]", "response": "Return all other tabs that are members of the tab s tab_group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing and prepares tabs.", "response": "def _process_tabs(self, tabs, current_tab, group_current_tab):\n        \"\"\"\n        Process and prepare tabs.\n\n        This includes steps like updating references to the current tab,\n        filtering out hidden tabs, sorting tabs etc...\n\n        Args:\n            tabs:\n                The list of tabs to process.\n            current_tab:\n                The reference to the currently loaded tab.\n            group_current_tab:\n                The reference to the active tab in the current tab group. For\n                parent tabs, this is different than for the current tab group.\n\n        Returns:\n            Processed list of tabs. Note that the method may have side effects.\n\n        \"\"\"\n        # Update references to the current tab\n        for t in tabs:\n            t.current_tab = current_tab\n            t.group_current_tab = group_current_tab\n\n        # Filter out hidden tabs\n        tabs = list(filter(lambda t: t.tab_visible, tabs))\n\n        # Sort remaining tabs in-place\n        tabs.sort(key=lambda t: t.weight)\n\n        return tabs"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding tab information to the context.", "response": "def get_context_data(self, **kwargs):\n        \"\"\"\n        Adds tab information to context.\n\n        To retrieve a list of all group tab instances, use\n        ``{{ tabs }}`` in your template.\n\n        The id of the current tab is added as ``current_tab_id`` to the\n        template context.\n\n        If the current tab has a parent tab the parent's id is added to\n        the template context as ``parent_tab_id``. Instances of all tabs\n        of the parent level are added as ``parent_tabs`` to the context.\n\n        If the current tab has children they are added to the template\n        context as ``child_tabs``.\n\n        \"\"\"\n        context = super(TabView, self).get_context_data(**kwargs)\n\n        # Update the context with kwargs, TemplateView doesn't do this.\n        context.update(kwargs)\n\n        # Add tabs and \"current\" references to context\n        process_tabs_kwargs = {\n            'tabs': self.get_group_tabs(),\n            'current_tab': self,\n            'group_current_tab': self,\n        }\n        context['tabs'] = self._process_tabs(**process_tabs_kwargs)\n        context['current_tab_id'] = self.tab_id\n\n        # Handle parent tabs\n        if self.tab_parent is not None:\n            # Verify that tab parent is valid\n            if self.tab_parent not in self._registry:\n                msg = '%s has no attribute _is_tab' % self.tab_parent.__class__.__name__\n                raise ImproperlyConfigured(msg)\n\n            # Get parent tab instance\n            parent = self.tab_parent()\n\n            # Add parent tabs to context\n            process_parents_kwargs = {\n                'tabs': parent.get_group_tabs(),\n                'current_tab': self,\n                'group_current_tab': parent,\n            }\n            context['parent_tabs'] = self._process_tabs(**process_parents_kwargs)\n            context['parent_tab_id'] = parent.tab_id\n\n        # Handle child tabs\n        if self.tab_id in self._children:\n            process_children_kwargs = {\n                'tabs': [t() for t in self._children[self.tab_id]],\n                'current_tab': self,\n                'group_current_tab': None,\n            }\n            context['child_tabs'] = self._process_tabs(**process_children_kwargs)\n\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a string into a valid python attribute name.", "response": "def normalize_name(s):\n    \"\"\"Convert a string into a valid python attribute name.\n    This function is called to convert ASCII strings to something that can pass as\n    python attribute name, to be used with namedtuples.\n\n    >>> str(normalize_name('class'))\n    'class_'\n    >>> str(normalize_name('a-name'))\n    'a_name'\n    >>> str(normalize_name('a n\\u00e4me'))\n    'a_name'\n    >>> str(normalize_name('Name'))\n    'Name'\n    >>> str(normalize_name(''))\n    '_'\n    >>> str(normalize_name('1'))\n    '_1'\n    \"\"\"\n    s = s.replace('-', '_').replace('.', '_').replace(' ', '_')\n    if s in keyword.kwlist:\n        return s + '_'\n    s = '_'.join(slug(ss, lowercase=False) for ss in s.split('_'))\n    if not s:\n        s = '_'\n    if s[0] not in string.ascii_letters + '_':\n        s = '_' + s\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef schema(tg):\n    tables = {}\n    for tname, table in tg.tabledict.items():\n        t = TableSpec.from_table_metadata(table)\n        tables[t.name] = t\n        for at in t.many_to_many.values():\n            tables[at.name] = at\n\n    # We must determine the order in which tables must be created!\n    ordered = OrderedDict()\n    i = 0\n\n    # We loop through the tables repeatedly, and whenever we find one, which has all\n    # referenced tables already in ordered, we move it from tables to ordered.\n    while tables and i < 100:\n        i += 1\n        for table in list(tables.keys()):\n            if all((ref[1] in ordered) or ref[1] == table for ref in tables[table].foreign_keys):\n                # All referenced tables are already created (or self-referential).\n                ordered[table] = tables.pop(table)\n                break\n    if tables:  # pragma: no cover\n        raise ValueError('there seem to be cyclic dependencies between the tables')\n\n    return list(ordered.values())", "response": "Convert the table and column descriptions of a TableGroup into a pair of tables and reference tables."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write(self, _force=False, _exists_ok=False, **items):\n        if self.fname and self.fname.exists():\n            raise ValueError('db file already exists, use force=True to overwrite')\n\n        with self.connection() as db:\n            for table in self.tables:\n                db.execute(table.sql(translate=self.translate))\n\n            db.execute('PRAGMA foreign_keys = ON;')\n            db.commit()\n\n            refs = defaultdict(list)  # collects rows in association tables.\n            for t in self.tables:\n                if t.name not in items:\n                    continue\n                rows, keys = [], []\n                cols = {c.name: c for c in t.columns}\n                for i, row in enumerate(items[t.name]):\n                    pk = row[t.primary_key[0]] \\\n                        if t.primary_key and len(t.primary_key) == 1 else None\n                    values = []\n                    for k, v in row.items():\n                        if k in t.many_to_many:\n                            assert pk\n                            at = t.many_to_many[k]\n                            atkey = tuple([at.name] + [c.name for c in at.columns])\n                            for vv in v:\n                                fkey, context = self.association_table_context(t, k, vv)\n                                refs[atkey].append((pk, fkey, context))\n                        else:\n                            col = cols[k]\n                            if isinstance(v, list):\n                                # Note: This assumes list-valued columns are of datatype string!\n                                v = (col.separator or ';').join(\n                                    col.convert(vv) for vv in v)\n                            else:\n                                v = col.convert(v) if v is not None else None\n                            if i == 0:\n                                keys.append(col.name)\n                            values.append(v)\n                    rows.append(tuple(values))\n                insert(db, self.translate, t.name, keys, *rows)\n\n            for atkey, rows in refs.items():\n                insert(db, self.translate, atkey[0], atkey[1:], *rows)\n\n            db.commit()", "response": "Writes the items to the database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iterrows(lines_or_file, namedtuples=False, dicts=False, encoding='utf-8', **kw):\n    if namedtuples and dicts:\n        raise ValueError('either namedtuples or dicts can be chosen as output format')\n    elif namedtuples:\n        _reader = NamedTupleReader\n    elif dicts:\n        _reader = UnicodeDictReader\n    else:\n        _reader = UnicodeReader\n\n    with _reader(lines_or_file, encoding=encoding, **fix_kw(kw)) as r:\n        for item in r:\n            yield item", "response": "A generator function that yields the rows of a n - tuple or dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter_rows_as_dict(fname, filter_, **kw):\n    filter_ = DictFilter(filter_)\n    rewrite(fname, filter_, **kw)\n    return filter_.removed", "response": "Rewrite a dsv file with filtering the rows."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump_grid(grid):\n    header = 'ver:%s' % dump_str(str(grid._version), version=grid._version)\n    if bool(grid.metadata):\n        header += ' ' + dump_meta(grid.metadata, version=grid._version)\n    columns = dump_columns(grid.column, version=grid._version)\n    rows = dump_rows(grid)\n    return '\\n'.join([header, columns] + rows + [''])", "response": "Dump a single grid to its ZINC representation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the given Zinc text and returns the equivalent data.", "response": "def parse(grid_str, mode=MODE_ZINC, charset='utf-8'):\n    '''\n    Parse the given Zinc text and return the equivalent data.\n    '''\n    # Decode incoming text (or python3 will whine!)\n    if isinstance(grid_str, six.binary_type):\n        grid_str = grid_str.decode(encoding=charset)\n\n    # Split the separate grids up, the grammar definition has trouble splitting\n    # them up normally.  This will truncate the newline off the end of the last\n    # row.\n    _parse = functools.partial(parse_grid, mode=mode,\n            charset=charset)\n    if mode == MODE_JSON:\n        if isinstance(grid_str, six.string_types):\n            grid_data = json.loads(grid_str)\n        else:\n            grid_data = grid_str\n        if isinstance(grid_data, dict):\n            return _parse(grid_data)\n        else:\n            return list(map(_parse, grid_data))\n    else:\n        return list(map(_parse, GRID_SEP.split(grid_str.rstrip())))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef append(self, key, value=MARKER, replace=True):\n        '''\n        Append the item to the metadata.\n        '''\n        return self.add_item(key, value, replace=replace)", "response": "Append the item to the metadata.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extend(self, items, replace=True):\n        '''\n        Append the items to the metadata.\n        '''\n        if isinstance(items, dict) or isinstance(items, SortableDict):\n            items = list(items.items())\n\n        for (key, value) in items:\n            self.append(key, value, replace=replace)", "response": "Append the items to the metadata."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef regular_polygon(cls, center, radius, n_vertices, start_angle=0, **kwargs):\n        angles = (np.arange(n_vertices) * 2 * np.pi / n_vertices) + start_angle\n        return cls(center + radius * np.array([np.cos(angles), np.sin(angles)]).T, **kwargs)", "response": "Construct a regular polygon."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconstruct a circle. Parameters ---------- center : array-like radius : float n_vertices : int, optional Number of points to draw. Decrease for performance, increase for appearance. kwargs Other keyword arguments are passed to the |Shape| constructor.", "response": "def circle(cls, center, radius, n_vertices=50, **kwargs):\n        \"\"\"Construct a circle.\n\n        Parameters\n        ----------\n        center : array-like\n        radius : float\n        n_vertices : int, optional\n            Number of points to draw.\n            Decrease for performance, increase for appearance.\n        kwargs\n            Other keyword arguments are passed to the |Shape| constructor.\n\n        \"\"\"\n        return cls.regular_polygon(center, radius, n_vertices, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rectangle(cls, vertices, **kwargs):\n        bottom_left, top_right = vertices\n        top_left = [bottom_left[0], top_right[1]]\n        bottom_right = [top_right[0], bottom_left[1]]\n        return cls([bottom_left, bottom_right, top_right, top_left], **kwargs)", "response": "Shortcut for creating a rectangle aligned with the screen axes from only two corners."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a |Shape| from a dictionary specification.", "response": "def from_dict(cls, spec):\n        \"\"\"Create a |Shape| from a dictionary specification.\n\n        Parameters\n        ----------\n        spec : dict\n            A dictionary with either the fields ``'center'`` and ``'radius'`` (for a circle),\n            ``'center'``, ``'radius'``, and ``'n_vertices'`` (for a regular polygon),\n            or ``'vertices'``.\n            If only two vertices are given, they are assumed to be lower left and top right corners of a rectangle.\n            Other fields are interpreted as keyword arguments.\n\n        \"\"\"\n        spec = spec.copy()\n        center = spec.pop('center', None)\n        radius = spec.pop('radius', None)\n        if center and radius:\n            return cls.circle(center, radius, **spec)\n\n        vertices = spec.pop('vertices')\n        if len(vertices) == 2:\n            return cls.rectangle(vertices, **spec)\n\n        return cls(vertices, **spec)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrotates the shape in - place.", "response": "def rotate(self, angle, center=None):\n        \"\"\"Rotate the shape, in-place.\n\n        Parameters\n        ----------\n        angle : float\n            Angle to rotate, in radians counter-clockwise.\n        center : array-like, optional\n            Point about which to rotate.\n            If not passed, the center of the shape will be used.\n\n        \"\"\"\n        args = [angle]\n        if center is not None:\n            args.extend(center)\n        self.poly.rotate(*args)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nflips the shape in the x direction in - place.", "response": "def flip_x(self, center=None):\n        \"\"\"Flip the shape in the x direction, in-place.\n\n        Parameters\n        ----------\n        center : array-like, optional\n            Point about which to flip.\n            If not passed, the center of the shape will be used.\n\n         \"\"\"\n        if center is None:\n            self.poly.flip()\n        else:\n            self.poly.flip(center[0])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef flip_y(self, center=None):\n        if center is None:\n            self.poly.flop()\n        else:\n            self.poly.flop(center[1])\n        return self", "response": "Flip the shape in the y direction in - place."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nflipping the shape in an arbitrary direction.", "response": "def flip(self, angle, center=None):\n        \"\"\" Flip the shape in an arbitrary direction.\n\n        Parameters\n        ----------\n        angle : array-like\n            The angle, in radians counter-clockwise from the horizontal axis,\n            defining the angle about which to flip the shape (of a line through `center`).\n        center : array-like, optional\n            The point about which to flip.\n            If not passed, the center of the shape will be used.\n\n        \"\"\"\n        return self.rotate(-angle, center=center).flip_y(center=center).rotate(angle, center=center)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw(self):\n        if self.enabled:\n            self._vertex_list.colors = self._gl_colors\n            self._vertex_list.vertices = self._gl_vertices\n            self._vertex_list.draw(pyglet.gl.GL_TRIANGLES)", "response": "Draw the shape in the current OpenGL context."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the shape s position by moving it forward according to its velocity.", "response": "def update(self, dt):\n        \"\"\"Update the shape's position by moving it forward according to its velocity.\n\n        Parameters\n        ----------\n        dt : float\n\n        \"\"\"\n        self.translate(dt * self.velocity)\n        self.rotate(dt * self.angular_velocity)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmaps the official Haystack timezone list to those recognised by pytz.", "response": "def _map_timezones():\n    \"\"\"\n    Map the official Haystack timezone list to those recognised by pytz.\n    \"\"\"\n    tz_map = {}\n    todo = HAYSTACK_TIMEZONES_SET.copy()\n    for full_tz in pytz.all_timezones:\n        # Finished case:\n        if not bool(todo): # pragma: no cover\n            # This is nearly impossible for us to cover, and an unlikely case.\n            break\n\n        # Case 1: exact match\n        if full_tz in todo:\n            tz_map[full_tz] = full_tz   # Exact match\n            todo.discard(full_tz)\n            continue\n\n        # Case 2: suffix match after '/'\n        if '/' not in full_tz:\n            continue\n\n        (prefix, suffix) = full_tz.split('/',1)\n        # Case 2 exception: full timezone contains more than one '/' -> ignore\n        if '/' in suffix:\n            continue\n\n        if suffix in todo:\n            tz_map[suffix] = full_tz\n            todo.discard(suffix)\n            continue\n\n    return tz_map"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves the Haystack timezone", "response": "def timezone(haystack_tz, version=LATEST_VER):\n    \"\"\"\n    Retrieve the Haystack timezone\n    \"\"\"\n    tz_map = get_tz_map(version=version)\n    try:\n        tz_name = tz_map[haystack_tz]\n    except KeyError:\n        raise ValueError('%s is not a recognised timezone on this host' \\\n                % haystack_tz)\n    return pytz.timezone(tz_name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef timezone_name(dt, version=LATEST_VER):\n    tz_rmap = get_tz_rmap(version=version)\n    if dt.tzinfo is None:\n        raise ValueError('%r has no timezone' % dt)\n\n    # Easy case: pytz timezone.\n    try:\n        tz_name = dt.tzinfo.zone\n        return tz_rmap[tz_name]\n    except KeyError:\n        # Not in timezone map\n        pass\n    except AttributeError:\n        # Not a pytz-compatible tzinfo\n        pass\n\n    # Hard case, try to find one that's equivalent.  Hopefully we don't get\n    # many of these.  Start by getting the current timezone offset, and a\n    # timezone-na\u00efve copy of the timestamp.\n    offset  = dt.utcoffset()\n    dt_notz = dt.replace(tzinfo=None)\n\n    if offset == datetime.timedelta(0):\n        # UTC?\n        return 'UTC'\n\n    for olson_name, haystack_name in list(tz_rmap.items()):\n        if pytz.timezone(olson_name).utcoffset(dt_notz) == offset:\n            return haystack_name\n\n    raise ValueError('Unable to get timezone of %r' % dt)", "response": "Determine an appropriate timezone name for the given datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _unescape(s, uri=False):\n    out = ''\n    while len(s) > 0:\n        c = s[0]\n        if c == '\\\\':\n            # Backslash escape\n            esc_c = s[1]\n\n            if esc_c in ('u', 'U'):\n                # Unicode escape\n                out += six.unichr(int(s[2:6], base=16))\n                s = s[6:]\n                continue\n            else:\n                if esc_c == 'b':\n                    out += '\\b'\n                elif esc_c == 'f':\n                    out += '\\f'\n                elif esc_c == 'n':\n                    out += '\\n'\n                elif esc_c == 'r':\n                    out += '\\r'\n                elif esc_c == 't':\n                    out += '\\t'\n                else:\n                    if uri and (esc_c == '#'):\n                        # \\# is passed through with backslash.\n                        out += '\\\\'\n                    # Pass through\n                    out += esc_c\n                s = s[2:]\n                continue\n        else:\n            out += c\n            s = s[1:]\n    return out", "response": "Iterative parser for string escapes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_grid(grid_data):\n    try:\n        # Split the grid up.\n        grid_parts = NEWLINE_RE.split(grid_data)\n        if len(grid_parts) < 2:\n            raise ZincParseException('Malformed grid received',\n                    grid_data, 1, 1)\n\n        # Grid and column metadata are the first two lines.\n        grid_meta_str = grid_parts.pop(0)\n        col_meta_str = grid_parts.pop(0)\n\n        # First element is the grid metadata\n        ver_match = VERSION_RE.match(grid_meta_str)\n        if ver_match is None:\n            raise ZincParseException(\n                    'Could not determine version from %r' % grid_meta_str,\n                    grid_data, 1, 1)\n        version = Version(ver_match.group(1))\n\n        # Now parse the rest of the grid accordingly\n        try:\n            grid_meta = hs_gridMeta[version].parseString(grid_meta_str, parseAll=True)[0]\n        except pp.ParseException as pe:\n            # Raise a new exception with the appropriate line number.\n            raise ZincParseException(\n                    'Failed to parse grid metadata: %s' % pe,\n                    grid_data, 1, pe.col)\n        except: # pragma: no cover\n            # Report an error to the log if we fail to parse something.\n            LOG.debug('Failed to parse grid meta: %r', grid_meta_str)\n            raise\n\n        try:\n            col_meta = hs_cols[version].parseString(col_meta_str, parseAll=True)[0]\n        except pp.ParseException as pe:\n            # Raise a new exception with the appropriate line number.\n            raise ZincParseException(\n                    'Failed to parse column metadata: %s' \\\n                            % reformat_exception(pe, 2),\n                    grid_data, 2, pe.col)\n        except: # pragma: no cover\n            # Report an error to the log if we fail to parse something.\n            LOG.debug('Failed to parse column meta: %r', col_meta_str)\n            raise\n\n        row_grammar = hs_row[version]\n        def _parse_row(row_num_and_data):\n            (row_num, row) = row_num_and_data\n            line_num = row_num + 3\n\n            try:\n                return dict(zip(col_meta.keys(),\n                    row_grammar.parseString(row, parseAll=True)[0].asList()))\n            except pp.ParseException as pe:\n                # Raise a new exception with the appropriate line number.\n                raise ZincParseException(\n                        'Failed to parse row: %s' \\\n                            % reformat_exception(pe, line_num),\n                        grid_data, line_num, pe.col)\n            except: # pragma: no cover\n                # Report an error to the log if we fail to parse something.\n                LOG.debug('Failed to parse row: %r', row)\n                raise\n\n        g = Grid(version=grid_meta.pop('ver'),\n                metadata=grid_meta,\n                columns=list(col_meta.items()))\n        g.extend(map(_parse_row, filter(lambda gp : bool(gp[1]), enumerate(grid_parts))))\n        return g\n    except:\n        LOG.debug('Failing grid: %r', grid_data)\n        raise", "response": "Parses the incoming grid and returns a list of objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a Zinc scalar in Zinc format.", "response": "def parse_scalar(scalar_data, version):\n    \"\"\"\n    Parse a Project Haystack scalar in ZINC format.\n    \"\"\"\n    try:\n        return hs_scalar[version].parseString(scalar_data, parseAll=True)[0]\n    except pp.ParseException as pe:\n        # Raise a new exception with the appropriate line number.\n        raise ZincParseException(\n                'Failed to parse scalar: %s' % reformat_exception(pe),\n                scalar_data, 1, pe.col)\n    except:\n        LOG.debug('Failing scalar data: %r (version %r)',\n                scalar_data, version)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_item(self, key, value, after=False, index=None, pos_key=None,\n            replace=True):\n        \"\"\"\n        Add an item at a specific location, possibly replacing the\n        existing item.\n\n        If after is True, we insert *after* the given index, otherwise we\n        insert before.\n\n        The position is specified using either index or pos_key, the former\n        specifies the position from the start of the array (base 0).  pos_key\n        specifies the name of another key, and positions the new key relative\n        to that key.\n\n        When replacing, the position will be left un-changed unless a location\n        is specified explicitly.\n        \"\"\"\n        if self._validate_fn:\n            self._validate_fn(value)\n\n        if (index is not None) and (pos_key is not None):\n            raise ValueError('Either specify index or pos_key, not both.')\n        elif pos_key is not None:\n            try:\n                index = self.index(pos_key)\n            except ValueError:\n                raise KeyError('%r not found' % pos_key)\n\n        if after and (index is not None):\n            # insert inserts *before* index, so increment by one.\n            index += 1\n\n        if key in self._values:\n            if not replace:\n                raise KeyError('%r is duplicate' % key)\n\n            if index is not None:\n                # We are re-locating.\n                del self[key]\n            else:\n                # We are updating\n                self._values[key] = value\n                return\n\n        if index is not None:\n            # Place at given position\n            self._order.insert(index, key)\n        else:\n            # Place at end\n            self._order.append(key)\n        self._values[key] = value", "response": "Add an item to the internal dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndump the given grids in the specified over - the - wire format.", "response": "def dump(grids, mode=MODE_ZINC):\n    \"\"\"\n    Dump the given grids in the specified over-the-wire format.\n    \"\"\"\n    if isinstance(grids, Grid):\n        return dump_grid(grids, mode=mode)\n    _dump = functools.partial(dump_grid, mode=mode)\n    if mode == MODE_ZINC:\n        return '\\n'.join(map(_dump, grids))\n    elif mode == MODE_JSON:\n        return '[%s]' % ','.join(map(_dump, grids))\n    else: # pragma: no cover\n        raise NotImplementedError('Format not implemented: %s' % mode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a unit to a haystack unit.", "response": "def to_haystack(unit):\n    \"\"\"\n    Some parsing tweaks to fit pint units / handling of edge cases.\n    \"\"\"\n    unit = str(unit)\n    global HAYSTACK_CONVERSION\n    global PINT_CONVERSION\n    if unit == 'per_minute' or \\\n        unit == '/min' or \\\n        unit == 'per_second' or \\\n        unit == '/s' or \\\n        unit == 'per_hour' or \\\n        unit == '/h' or \\\n        unit == None:\n        return ''\n        # Those units are not units... they are impossible to fit anywhere in Pint\n    \n    for pint_value, haystack_value in PINT_CONVERSION:\n        unit = unit.replace(pint_value, haystack_value)\n    for haystack_value, pint_value in HAYSTACK_CONVERSION:\n        if pint_value == '':\n            continue\n        unit = unit.replace(pint_value, haystack_value)\n    return unit"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a given unit to a pint unit.", "response": "def to_pint(unit):\n    \"\"\"\n    Some parsing tweaks to fit pint units / handling of edge cases.\n    \"\"\"\n    global HAYSTACK_CONVERSION\n    if unit == 'per_minute' or \\\n        unit == '/min' or \\\n        unit == 'per_second' or \\\n        unit == '/s' or \\\n        unit == 'per_hour' or \\\n        unit == '/h' or \\\n        unit == None:\n        return ''\n        # Those units are not units... they are impossible to fit anywhere in Pint\n    for haystack_value, pint_value in HAYSTACK_CONVERSION:\n        unit = unit.replace(haystack_value, pint_value)\n    return unit"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndefines the units that are missing in project - haystack.", "response": "def define_haystack_units():\n    \"\"\"\n    Missing units found in project-haystack\n    Added to the registry\n    \"\"\"\n    ureg = UnitRegistry()\n    ureg.define('% = [] = percent')\n    ureg.define('pixel = [] = px = dot = picture_element = pel')\n    ureg.define('decibel = [] = dB')\n    ureg.define('ppu = [] = parts_per_unit')\n    ureg.define('ppm = [] = parts_per_million')\n    ureg.define('ppb = [] = parts_per_billion')\n    ureg.define('%RH = [] = percent_relative_humidity = percentRH')\n    ureg.define('cubic_feet = ft ** 3 = cu_ft')\n    ureg.define('cfm = cu_ft * minute = liter_per_second / 0.4719475')\n    ureg.define('cfh = cu_ft * hour')\n    ureg.define('cfs = cu_ft * second')\n    ureg.define('VAR = volt * ampere')\n    ureg.define('kVAR = 1000 * volt * ampere')\n    ureg.define('MVAR = 1000000 * volt * ampere')\n    ureg.define('inH2O = in_H2O')\n    ureg.define('dry_air = []')\n    ureg.define('gas = []')\n    ureg.define('energy_efficiency_ratio = [] = EER')\n    ureg.define('coefficient_of_performance = [] = COP')\n    ureg.define('data_center_infrastructure_efficiency = [] = DCIE')\n    ureg.define('power_usage_effectiveness = [] = PUE')\n    ureg.define('formazin_nephelometric_unit = [] = fnu')\n    ureg.define('nephelometric_turbidity_units = [] = ntu')\n    ureg.define('power_factor = [] = PF')\n    ureg.define('degree_day_celsius = [] = degdaysC')\n    ureg.define('degree_day_farenheit = degree_day_celsius * 9 / 5 = degdaysF')\n    ureg.define('footcandle = lumen / sq_ft = ftcd')\n    ureg.define('Nm = newton * meter')\n    ureg.define('%obsc = [] = percent_obscuration = percentobsc')\n    ureg.define('cycle = []')\n    ureg.define('cph = cycle / hour')\n    ureg.define('cpm = cycle / minute')\n    ureg.define('cps = cycle / second')\n    ureg.define('hecto_cubic_foot = 100 * cubic_foot')\n    ureg.define('tenths_second = second / 10')\n    ureg.define('hundredths_second = second / 100')\n\n    #ureg.define('irradiance = W / sq_meter = irr')\n    # In the definition of project haystack, there's a redundancy as irr = W/m^2\n    # no need to use : watts_per_square_meter_irradiance\n    \n    # CURRENCY\n    # I know...we won'T be able to convert right now !\n    ureg.define('australian_dollar = [] = AUD')\n    ureg.define('british_pound = [] = GBP = \u00a3')\n    ureg.define('canadian_dollar = [] = CAD')\n    ureg.define('chinese_yuan = [] = CNY = \u5143')\n    ureg.define('emerati_dirham = [] = AED')\n    ureg.define('euro = [] = EUR = \u20ac')\n    ureg.define('indian_rupee = [] = INR = \u20b9')\n    ureg.define('japanese_yen = [] = JPY = \u00a5')\n    ureg.define('russian_ruble = [] = RUB = \u0440\u0443\u0431')\n    ureg.define('south_korean_won = [] = KRW = \u20a9')\n    ureg.define('swedish_krona = [] = SEK = kr')\n    ureg.define('swiss_franc = [] = CHF = Fr')\n    ureg.define('taiwan_dollar = [] = TWD')\n    ureg.define('us_dollar = [] = USD = $')\n    ureg.define('new_israeli_shekel = [] = NIS')\n\n    return ureg"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetecting the version used from the row content or validate against the version if given.", "response": "def _detect_or_validate(self, val):\n        '''\n        Detect the version used from the row content, or validate against\n        the version if given.\n        '''\n        if isinstance(val, list) \\\n                or isinstance(val, dict) \\\n                or isinstance(val, SortableDict) \\\n                or isinstance(val, Grid):\n            # Project Haystack 3.0 type.\n            self._assert_version(VER_3_0)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nassert that the grid version is equal to or above the given value.", "response": "def _assert_version(self, version):\n        '''\n        Assert that the grid version is equal to or above the given value.\n        If no version is set, set the version.\n        '''\n        if self.nearest_version < version:\n            if self._version_given:\n                raise ValueError(\n                        'Data type requires version %s' \\\n                        % version)\n            else:\n                self._version = version"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _cmp(self, other):\n        if not isinstance(other, Version):\n            other = Version(other)\n\n        num1 = self.version_nums\n        num2 = other.version_nums\n\n        # Pad both to be the same length\n        ver_len = max(len(num1), len(num2))\n        num1 += tuple([0 for n in range(len(num1), ver_len)])\n        num2 += tuple([0 for n in range(len(num2), ver_len)])\n\n        # Compare the versions\n        for (p1, p2) in zip(num1, num2):\n            if p1 < p2:\n                return -1\n            elif p1 > p2:\n                return 1\n\n        # All the same, compare the extra strings.\n        # If a version misses the extra part; we consider that as coming *before*.\n        if self.version_extra is None:\n            if other.version_extra is None:\n                return 0\n            else:\n                return -1\n        elif other.version_extra is None:\n            return 1\n        elif self.version_extra == other.version_extra:\n            return 0\n        elif self.version_extra < other.version_extra:\n            return -1\n        else:\n            return 1", "response": "Compares two Project Haystack version strings and returns a value of 0 if self < other 0 if self > other"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nearest(self, ver):\n        if not isinstance(ver, Version):\n            ver = Version(ver)\n\n        if ver in OFFICIAL_VERSIONS:\n            return ver\n\n        # We might not have an exact match for that.\n        # See if we have one that's newer than the grid we're looking at.\n        versions = list(OFFICIAL_VERSIONS)\n        versions.sort(reverse=True)\n        best = None\n        for candidate in versions:\n            # Due to ambiguities, we might have an exact match and not know it.\n            # '2.0' will not hash to the same value as '2.0.0', but both are\n            # equivalent.\n            if candidate == ver:\n                # We can't beat this, make a note of the match for later\n                return candidate\n\n            # If we have not seen a better candidate, and this is older\n            # then we may have to settle for that.\n            if (best is None) and (candidate < ver):\n                warnings.warn('This version of hszinc does not yet '\\\n                            'support version %s, please seek a newer version '\\\n                            'or file a bug.  Closest (older) version supported is %s.'\\\n                            % (ver, candidate))\n                return candidate\n\n            # Probably the best so far, but see if we can go closer\n            if candidate > ver:\n                best = candidate\n\n        # Unhappy path, no best option?  This should not happen.\n        assert best is not None\n        warnings.warn('This version of hszinc does not yet '\\\n                    'support version %s, please seek a newer version '\\\n                    'or file a bug.  Closest (newer) version supported is %s.'\\\n                    % (ver, best))\n        return best", "response": "Retrieve the official version nearest the one given."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nencrypt a file with gpg and random generated password", "response": "def encrypt_files(selected_host, only_link, file_name):\n    \"\"\"\n    Encrypts file with gpg and random generated password\n    \"\"\"\n    if ENCRYPTION_DISABLED:\n        print('For encryption please install gpg')\n        exit()\n    passphrase = '%030x' % random.randrange(16**30)\n    source_filename = file_name\n    cmd = 'gpg --batch --symmetric --cipher-algo AES256 --passphrase-fd 0 ' \\\n          '--output - {}'.format(source_filename)\n    encrypted_output = Popen(shlex.split(cmd), stdout=PIPE, stdin=PIPE, stderr=PIPE)\n    encrypted_data = encrypted_output.communicate(passphrase.encode())[0]\n    return upload_files(encrypted_data, selected_host, only_link, file_name)+'#'+passphrase"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the file size is greater than max_size", "response": "def check_max_filesize(chosen_file, max_size):\n    \"\"\"\n    Checks file sizes for host\n    \"\"\"\n    if os.path.getsize(chosen_file) > max_size:\n        return False\n    else:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake the arguments and returns a string that can be used to create a new resource.", "response": "def parse_arguments(args, clone_list):\n    \"\"\"\n    Makes parsing arguments a function.\n    \"\"\"\n    returned_string=\"\"\n    host_number = args.host\n    if args.show_list:\n        print(generate_host_string(clone_list, \"Available hosts: \"))\n        exit()\n    if args.decrypt:\n        for i in args.files:\n            print(decrypt_files(i))\n            exit()\n    if args.files:\n        for i in args.files:\n            if args.limit_size:\n                if args.host == host_number and host_number is not None:\n                    if not check_max_filesize(i, clone_list[host_number][3]):\n                        host_number = None\n                for n, host in enumerate(clone_list):\n                    if not check_max_filesize(i, host[3]):\n                        clone_list[n] = None\n                if not clone_list:\n                    print('None of the clones is able to support so big file.')\n            if args.no_cloudflare:\n                if args.host == host_number and host_number is not None and not clone_list[host_number][4]:\n                    print(\"This host uses Cloudflare, please choose different host.\")\n                    exit(1)\n                else:\n                    for n, host in enumerate(clone_list):\n                        if not host[4]:\n                            clone_list[n] = None\n            clone_list = list(filter(None, clone_list))\n            if host_number is None or args.host != host_number:\n                host_number = random.randrange(0, len(clone_list))\n            while True:\n                try:\n                    if args.encrypt:\n                        returned_string = encrypt_files(clone_list[host_number], args.only_link, i)\n                    else:\n                        returned_string = upload_files(open(i, 'rb'), \\\n                              clone_list[host_number], args.only_link, i)\n                    if args.only_link:\n                        print(returned_string[0])\n                    else:\n                        print(returned_string)\n                except IndexError:\n                    #print('Selected server (' + clone_list[host_number][0] + ') is offline.')\n                    #print('Trying other host.')\n                    host_number = random.randrange(0, len(clone_list))\n                    continue\n                except IsADirectoryError:\n                    print('limf does not support directory upload, if you want to upload ' \\\n                          'every file in directory use limf {}/*.'.format(i.replace('/', '')))\n                \n                if args.log:\n                    with open(os.path.expanduser(args.logfile), \"a+\") as logfile:\n                        if args.only_link:\n                            logfile.write(returned_string[1])\n                        else:\n                            logfile.write(returned_string)\n                        logfile.write(\"\\n\")\n                break\n    else:\n        print(\"limf: try 'limf -h' for more information\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef upload_files(selected_file, selected_host, only_link, file_name):\n    try:\n        answer = requests.post(\n            url=selected_host[0]+\"upload.php\",\n            files={'files[]':selected_file})\n        file_name_1 = re.findall(r'\"url\": *\"((h.+\\/){0,1}(.+?))\"[,\\}]', \\\n            answer.text.replace(\"\\\\\", \"\"))[0][2]\n        if only_link:\n            return [selected_host[1]+file_name_1, \"{}: {}{}\".format(file_name, selected_host[1], file_name_1)]\n        else:\n            return \"{}: {}{}\".format(file_name, selected_host[1], file_name_1)\n    except requests.exceptions.ConnectionError:\n        print(file_name + ' couldn\\'t be uploaded to ' + selected_host[0])", "response": "Uploads selected file to the host"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nserving the Swagger UI page", "response": "def swagger_ui_template_view(request):\n    \"\"\"\n    Serves Swagger UI page, default Swagger UI config is used but you can\n    override the callable that generates the `<script>` tag by setting\n    `cornice_swagger.swagger_ui_script_generator` in pyramid config, it defaults\n    to 'cornice_swagger.views:swagger_ui_script_template'\n\n    :param request:\n    :return:\n    \"\"\"\n    script_generator = request.registry.settings.get(\n        'cornice_swagger.swagger_ui_script_generator',\n        'cornice_swagger.views:swagger_ui_script_template')\n    package, callable = script_generator.split(':')\n    imported_package = importlib.import_module(package)\n    script_callable = getattr(imported_package, callable)\n    template = pkg_resources.resource_string(\n        'cornice_swagger', 'templates/index.html').decode('utf8')\n\n    html = Template(template).safe_substitute(\n        ui_css_url=ui_css_url,\n        ui_js_bundle_url=ui_js_bundle_url,\n        ui_js_standalone_url=ui_js_standalone_url,\n        swagger_ui_script=script_callable(request),\n    )\n    return Response(html)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef open_api_json_view(request):\n    doc = cornice_swagger.CorniceSwagger(\n        cornice.service.get_services(), pyramid_registry=request.registry)\n    kwargs = request.registry.settings['cornice_swagger.spec_kwargs']\n    my_spec = doc.generate(**kwargs)\n    return my_spec", "response": "Generates JSON representation of the current object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate the script code that bootstraps Swagger UI into the index template", "response": "def swagger_ui_script_template(request, **kwargs):\n    \"\"\"\n    :param request:\n    :return:\n\n    Generates the <script> code that bootstraps Swagger UI, it will be injected\n    into index template\n    \"\"\"\n    swagger_spec_url = request.route_url('cornice_swagger.open_api_path')\n    template = pkg_resources.resource_string(\n        'cornice_swagger',\n        'templates/index_script_template.html'\n    ).decode('utf8')\n    return Template(template).safe_substitute(\n        swagger_spec_url=swagger_spec_url,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_value(request):\n\n        key = request.matchdict['key']\n        _VALUES[key] = request.json_body\n        return _VALUES.get(key)", "response": "Set the value and returns True or False."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_schema(self, schema_node, base_name=None):\n        return self._ref_recursive(self.type_converter(schema_node), self.ref, base_name)", "response": "Creates a Swagger definition from a colander schema."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _ref_recursive(self, schema, depth, base_name=None):\n\n        if depth == 0:\n            return schema\n\n        if schema['type'] != 'object':\n            return schema\n\n        name = base_name or schema['title']\n\n        pointer = self.json_pointer + name\n        for child_name, child in schema.get('properties', {}).items():\n            schema['properties'][child_name] = self._ref_recursive(child, depth-1)\n\n        self.definition_registry[name] = schema\n\n        return {'$ref': pointer}", "response": "Recursively references a nested schema into several definitions using JSON pointers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a list of Swagger parameters from a colander request schema.", "response": "def from_schema(self, schema_node):\n        \"\"\"\n        Creates a list of Swagger params from a colander request schema.\n\n        :param schema_node:\n            Request schema to be transformed into Swagger.\n        :param validators:\n            Validators used in colander with the schema.\n\n        :rtype: list\n        :returns: List of Swagger parameters.\n        \"\"\"\n\n        params = []\n\n        for param_schema in schema_node.children:\n            location = param_schema.name\n            if location is 'body':\n                name = param_schema.__class__.__name__\n                if name == 'body':\n                    name = schema_node.__class__.__name__ + 'Body'\n                param = self.parameter_converter(location,\n                                                 param_schema)\n                param['name'] = name\n                if self.ref:\n                    param = self._ref(param)\n                params.append(param)\n\n            elif location in (('path', 'header', 'headers', 'querystring', 'GET')):\n                for node_schema in param_schema.children:\n                    param = self.parameter_converter(location, node_schema)\n                    if self.ref:\n                        param = self._ref(param)\n                    params.append(param)\n\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a list of Swagger path params from a cornice service path.", "response": "def from_path(self, path):\n        \"\"\"\n        Create a list of Swagger path params from a cornice service path.\n\n        :type path: string\n        :rtype: list\n        \"\"\"\n        path_components = path.split('/')\n        param_names = [comp[1:-1] for comp in path_components\n                       if comp.startswith('{') and comp.endswith('}')]\n\n        params = []\n        for name in param_names:\n            param_schema = colander.SchemaNode(colander.String(), name=name)\n            param = self.parameter_converter('path', param_schema)\n            if self.ref:\n                param = self._ref(param)\n            params.append(param)\n\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a JSON pointer to the original parameter definition.", "response": "def _ref(self, param, base_name=None):\n        \"\"\"\n        Store a parameter schema and return a reference to it.\n\n        :param schema:\n            Swagger parameter definition.\n        :param base_name:\n            Name that should be used for the reference.\n\n        :rtype: dict\n        :returns: JSON pointer to the original parameter definition.\n        \"\"\"\n\n        name = base_name or param.get('title', '') or param.get('name', '')\n\n        pointer = self.json_pointer + name\n        self.parameter_registry[name] = param\n\n        return {'$ref': pointer}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_schema_mapping(self, schema_mapping):\n\n        responses = {}\n\n        for status, response_schema in schema_mapping.items():\n\n            response = {}\n            if response_schema.description:\n                response['description'] = response_schema.description\n            else:\n                raise CorniceSwaggerException('Responses must have a description.')\n\n            for field_schema in response_schema.children:\n                location = field_schema.name\n\n                if location == 'body':\n                    title = field_schema.__class__.__name__\n                    if title == 'body':\n                        title = response_schema.__class__.__name__ + 'Body'\n                    field_schema.title = title\n                    response['schema'] = self.definitions.from_schema(field_schema)\n\n                elif location in ('header', 'headers'):\n                    header_schema = self.type_converter(field_schema)\n                    headers = header_schema.get('properties')\n                    if headers:\n                        # Response headers doesn't accept titles\n                        for header in headers.values():\n                            header.pop('title')\n\n                        response['headers'] = headers\n\n            pointer = response_schema.__class__.__name__\n            if self.ref:\n                response = self._ref(response, pointer)\n            responses[status] = response\n\n        return responses", "response": "Creates a Swagger response object from a dict of response schemas."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ref(self, resp, base_name=None):\n\n        name = base_name or resp.get('title', '') or resp.get('name', '')\n\n        pointer = self.json_pointer + name\n        self.response_registry[name] = resp\n\n        return {'$ref': pointer}", "response": "Store a response schema and return a reference to it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate(self, title=None, version=None, base_path=None,\n                 info=None, swagger=None, **kwargs):\n        \"\"\"Generate a Swagger 2.0 documentation. Keyword arguments may be used\n        to provide additional information to build methods as such ignores.\n\n        :param title:\n            The name presented on the swagger document.\n        :param version:\n            The version of the API presented on the swagger document.\n        :param base_path:\n            The path that all requests to the API must refer to.\n        :param info:\n            Swagger info field.\n        :param swagger:\n            Extra fields that should be provided on the swagger documentation.\n\n        :rtype: dict\n        :returns: Full OpenAPI/Swagger compliant specification for the application.\n        \"\"\"\n        title = title or self.api_title\n        version = version or self.api_version\n        info = info or self.swagger.get('info', {})\n        swagger = swagger or self.swagger\n        base_path = base_path or self.base_path\n\n        swagger = swagger.copy()\n        info.update(title=title, version=version)\n        swagger.update(swagger='2.0', info=info, basePath=base_path)\n\n        paths, tags = self._build_paths()\n\n        # Update the provided tags with the extracted ones preserving order\n        if tags:\n            swagger.setdefault('tags', [])\n            tag_names = {t['name'] for t in swagger['tags']}\n            for tag in tags:\n                if tag['name'] not in tag_names:\n                    swagger['tags'].append(tag)\n\n        # Create/Update swagger sections with extracted values where not provided\n        if paths:\n            swagger.setdefault('paths', {})\n            merge_dicts(swagger['paths'], paths)\n\n        definitions = self.definitions.definition_registry\n        if definitions:\n            swagger.setdefault('definitions', {})\n            merge_dicts(swagger['definitions'], definitions)\n\n        parameters = self.parameters.parameter_registry\n        if parameters:\n            swagger.setdefault('parameters', {})\n            merge_dicts(swagger['parameters'], parameters)\n\n        responses = self.responses.response_registry\n        if responses:\n            swagger.setdefault('responses', {})\n            merge_dicts(swagger['responses'], responses)\n\n        return swagger", "response": "Generate a full OpenAPI 2. 0 documentation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding the Swagger paths and tags attributes from cornice service and method.", "response": "def _build_paths(self):\n        \"\"\"\n        Build the Swagger \"paths\" and \"tags\" attributes from cornice service\n        definitions.\n        \"\"\"\n        paths = {}\n        tags = []\n\n        for service in self.services:\n            path, path_obj = self._extract_path_from_service(service)\n\n            service_tags = getattr(service, 'tags', [])\n            self._check_tags(service_tags)\n            tags = self._get_tags(tags, service_tags)\n\n            for method, view, args in service.definitions:\n\n                if method.lower() in map(str.lower, self.ignore_methods):\n                    continue\n\n                op = self._extract_operation_from_view(view, args)\n\n                if any(ctype in op.get('consumes', []) for ctype in self.ignore_ctypes):\n                    continue\n\n                # XXX: Swagger doesn't support different schemas for for a same method\n                # with different ctypes as cornice. If this happens, you may ignore one\n                # content-type from the documentation otherwise we raise an Exception\n                # Related to https://github.com/OAI/OpenAPI-Specification/issues/146\n                previous_definition = path_obj.get(method.lower())\n                if previous_definition:\n                    raise CorniceSwaggerException((\"Swagger doesn't support multiple \"\n                                                   \"views for a same method. You may \"\n                                                   \"ignore one.\"))\n\n                # If tag not defined and a default tag is provided\n                if 'tags' not in op and self.default_tags:\n                    if callable(self.default_tags):\n                        op['tags'] = self.default_tags(service, method)\n                    else:\n                        op['tags'] = self.default_tags\n\n                op_tags = op.get('tags', [])\n                self._check_tags(op_tags)\n\n                # Add service tags\n                if service_tags:\n                    new_tags = service_tags + op_tags\n                    op['tags'] = list(OrderedDict.fromkeys(new_tags))\n\n                # Add method tags to root tags\n                tags = self._get_tags(tags, op_tags)\n\n                # If operation id is not defined and a default generator is provided\n                if 'operationId' not in op and self.default_op_ids:\n                    if not callable(self.default_op_ids):\n                        raise CorniceSwaggerException('default_op_id should be a callable.')\n                    op['operationId'] = self.default_op_ids(service, method)\n\n                # If security options not defined and default is provided\n                if 'security' not in op and self.default_security:\n                    if callable(self.default_security):\n                        op['security'] = self.default_security(service, method)\n                    else:\n                        op['security'] = self.default_security\n\n                if not isinstance(op.get('security', []), list):\n                    raise CorniceSwaggerException('security should be a list or callable')\n\n                path_obj[method.lower()] = op\n            paths[path] = path_obj\n\n        return paths, tags"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _extract_path_from_service(self, service):\n\n        path_obj = {}\n        path = service.path\n        route_name = getattr(service, 'pyramid_route', None)\n        # handle services that don't create fresh routes,\n        # we still need the paths so we need to grab pyramid introspector to\n        # extract that information\n        if route_name:\n            # avoid failure if someone forgets to pass registry\n            registry = self.pyramid_registry or get_current_registry()\n            route_intr = registry.introspector.get('routes', route_name)\n            if route_intr:\n                path = route_intr['pattern']\n            else:\n                msg = 'Route `{}` is not found by ' \\\n                      'pyramid introspector'.format(route_name)\n                raise ValueError(msg)\n\n        # handle traverse and subpath as regular parameters\n        # docs.pylonsproject.org/projects/pyramid/en/latest/narr/hybrid.html\n        for subpath_marker in ('*subpath', '*traverse'):\n            path = path.replace(subpath_marker, '{subpath}')\n\n        # Extract path parameters\n        parameters = self.parameters.from_path(path)\n        if parameters:\n            path_obj['parameters'] = parameters\n\n        return path, path_obj", "response": "Extract path object and its parameters from service definitions."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _extract_operation_from_view(self, view, args):\n\n        op = {\n            'responses': {\n                'default': {\n                    'description': 'UNDOCUMENTED RESPONSE'\n                }\n            },\n        }\n\n        # If 'produces' are not defined in the view, try get from renderers\n        renderer = args.get('renderer', '')\n\n        if \"json\" in renderer:  # allows for \"json\" or \"simplejson\"\n            produces = ['application/json']\n        elif renderer == 'xml':\n            produces = ['text/xml']\n        else:\n            produces = None\n\n        if produces:\n            op.setdefault('produces', produces)\n\n        # Get explicit accepted content-types\n        consumes = args.get('content_type')\n\n        if consumes is not None:\n            # convert to a list, if it's not yet one\n            consumes = to_list(consumes)\n\n            # It is possible to add callables for content_type, so we have to\n            # to filter those out, since we cannot evaluate those here.\n            consumes = [x for x in consumes if not callable(x)]\n            op['consumes'] = consumes\n\n        # Get parameters from view schema\n        is_colander = self._is_colander_schema(args)\n        if is_colander:\n            schema = self._extract_transform_colander_schema(args)\n            parameters = self.parameters.from_schema(schema)\n        else:\n            # Bail out for now\n            parameters = None\n        if parameters:\n            op['parameters'] = parameters\n\n        # Get summary from docstring\n        if isinstance(view, six.string_types):\n            if 'klass' in args:\n                ob = args['klass']\n                view_ = getattr(ob, view.lower())\n                docstring = trim(view_.__doc__)\n        else:\n            docstring = str(trim(view.__doc__))\n\n        if docstring and self.summary_docstrings:\n            op['summary'] = docstring\n\n        # Get response definitions\n        if 'response_schemas' in args:\n            op['responses'] = self.responses.from_schema_mapping(args['response_schemas'])\n\n        # Get response tags\n        if 'tags' in args:\n            op['tags'] = args['tags']\n\n        # Get response operationId\n        if 'operation_id' in args:\n            op['operationId'] = args['operation_id']\n\n        # Get security policies\n        if 'api_security' in args:\n            op['security'] = args['api_security']\n\n        return op", "response": "Extracts the swagger operation details from colander view definitions."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting schema from view args and transform it using the pipeline of schema transformers", "response": "def _extract_transform_colander_schema(self, args):\n        \"\"\"\n        Extract schema from view args and transform it using\n        the pipeline of schema transformers\n\n        :param args:\n            Arguments from the view decorator.\n\n        :rtype: colander.MappingSchema()\n        :returns: View schema cloned and transformed\n        \"\"\"\n\n        schema = args.get('schema', colander.MappingSchema())\n        if not isinstance(schema, colander.Schema):\n            schema = schema()\n        schema = schema.clone()\n        for transformer in self.schema_transformers:\n            schema = transformer(schema, args)\n        return schema"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating arguments and parses user input", "response": "def main():\n    \"\"\"Creates arguments and parses user input\"\"\"\n    parser = argparse.ArgumentParser(\n        description=_('Uploads selected file to working pomf.se clone'))\n    parser.add_argument('files', metavar='file', nargs='*', type=str,\n                        help=_('Files to upload'))\n    parser.add_argument('-c', metavar='host_number', type=int,\n                        dest='host', default=None,\n                        help=_('The number (0-n) of the selected host (default is random)'))\n    parser.add_argument('-l', dest='only_link', action='store_const',\n                        const=True, default=False,\n                        help=_('Changes output to just link to the file'))\n    parser.add_argument('-e', dest='encrypt', action='store_const',\n                        const=True, default=False,\n                        help=_('Encrypts then uploads the files.'))\n    parser.add_argument('-d', dest='decrypt', action='store_const',\n                        const=True, default=False,\n                        help=_('Decrypts files from links with encrypted files'))\n    parser.add_argument('-j', dest=\"local_list\",\n                        default=False, help=_('Path to a local list file'))\n    parser.add_argument('-s', dest=\"show_list\", action='store_const',\n                        const=True, default=False,\n                        help=_('Show the host list (will not upload your files when called)'))\n    parser.add_argument('-m', dest='limit_size', action='store_const',\n                        const=True, default=False,\n                        help=_('Do not upload file if it exceeds the certain host limit'))\n    parser.add_argument('-nc', dest='no_cloudflare', action='store_const',\n                        const=True, default=False,\n                        help=_('Do not use hosts which use Cloudflare.'))\n    parser.add_argument('--log-file', metavar=\"LOGFILE\", dest=\"logfile\",\n                        default=\"~/limf.log\",\n                        help=_(\"The location of log file\"))\n    parser.add_argument('--log', dest='log', action=\"store_const\",\n                        const=True, default=False,\n                        help=_(\"Enables the logging feature, default logfile is ~/limf.log\"))\n    args = parser.parse_args()\n    try:\n        if args.local_list:\n            clone_list = retrieve_local_host_list(args.local_list)\n        else:\n            clone_list = retrieve_online_host_list()\n        if len(min(clone_list, key=len)) < 5 and (args.limit_size or args.no_cloudflare):\n            print(_(\"For newer options, please update your host_list.\"))\n            exit()\n        if args.host and not(0 <= args.host < len(clone_list)):\n            print(generate_host_string(clone_list))\n            exit()\n\n        parse_arguments(args, clone_list)\n    except FileNotFoundError:\n        print(_('Plese enter valid file.'))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a node schema into a parameter object.", "response": "def convert(self, schema_node, definition_handler):\n        \"\"\"\n        Convert node schema into a parameter object.\n        \"\"\"\n\n        converted = {\n            'name': schema_node.name,\n            'in': self._in,\n            'required': schema_node.required\n        }\n        if schema_node.description:\n            converted['description'] = schema_node.description\n\n        if schema_node.default:\n            converted['default'] = schema_node.default\n\n        schema = definition_handler(schema_node)\n        # Parameters shouldn't have a title\n        schema.pop('title', None)\n        converted.update(schema)\n\n        if schema.get('type') == 'array':\n            converted['items'] = {'type': schema['items']['type']}\n\n        return converted"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cornice_enable_openapi_view(\n        config,\n        api_path='/api-explorer/swagger.json',\n        permission=NO_PERMISSION_REQUIRED,\n        route_factory=None, **kwargs):\n    \"\"\"\n    :param config:\n        Pyramid configurator object\n    :param api_path:\n        where to expose swagger JSON definition view\n    :param permission:\n        pyramid permission for those views\n    :param route_factory:\n        factory for context object for those routes\n    :param kwargs:\n        kwargs that will be passed to CorniceSwagger's `generate()`\n\n    This registers and configures the view that serves api definitions\n    \"\"\"\n    config.registry.settings['cornice_swagger.spec_kwargs'] = kwargs\n    config.add_route('cornice_swagger.open_api_path', api_path,\n                     factory=route_factory)\n    config.add_view('cornice_swagger.views.open_api_json_view',\n                    renderer='json', permission=permission,\n                    route_name='cornice_swagger.open_api_path')", "response": "Enables the OpenAPI view for the given resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cornice_enable_openapi_explorer(\n        config,\n        api_explorer_path='/api-explorer',\n        permission=NO_PERMISSION_REQUIRED,\n        route_factory=None,\n        **kwargs):\n    \"\"\"\n    :param config:\n        Pyramid configurator object\n    :param api_explorer_path:\n        where to expose Swagger UI interface view\n    :param permission:\n        pyramid permission for those views\n    :param route_factory:\n        factory for context object for those routes\n\n    This registers and configures the view that serves api explorer\n    \"\"\"\n    config.add_route('cornice_swagger.api_explorer_path', api_explorer_path,\n                     factory=route_factory)\n    config.add_view('cornice_swagger.views.swagger_ui_template_view',\n                    permission=permission,\n                    route_name='cornice_swagger.api_explorer_path')", "response": "Enable the OpenAPI explorer for the given resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrimming the given docstring and return a new string.", "response": "def trim(docstring):\n    \"\"\"\n    Remove the tabs to spaces, and remove the extra spaces / tabs that are in\n    front of the text in docstrings.\n\n    Implementation taken from http://www.python.org/dev/peps/pep-0257/\n    \"\"\"\n    if not docstring:\n        return ''\n    # Convert tabs to spaces (following the normal Python rules)\n    # and split into a list of lines:\n    lines = six.u(docstring).expandtabs().splitlines()\n    lines = [line.strip() for line in lines]\n    res = six.u('\\n').join(lines)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmerging a dict into a recursively without overwriting values.", "response": "def merge_dicts(base, changes):\n    \"\"\"Merge b into a recursively, without overwriting values.\n\n    :param base: the dict that will be altered.\n    :param changes: changes to update base.\n    \"\"\"\n    for k, v in changes.items():\n        if isinstance(v, dict):\n            merge_dicts(base.setdefault(k, {}), v)\n        else:\n            base.setdefault(k, v)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a viewset method for the provided transition_name", "response": "def get_transition_viewset_method(transition_name, **kwargs):\n    '''\n    Create a viewset method for the provided `transition_name`\n    '''\n    @detail_route(methods=['post'], **kwargs)\n    def inner_func(self, request, pk=None, **kwargs):\n        object = self.get_object()\n        transition_method = getattr(object, transition_name)\n\n        transition_method(by=self.request.user)\n\n        if self.save_after_transition:\n            object.save()\n\n        serializer = self.get_serializer(object)\n        return Response(serializer.data)\n\n    return inner_func"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_viewset_transition_action_mixin(model, **kwargs):\n    '''\n    Find all transitions defined on `model`, then create a corresponding\n    viewset action method for each and apply it to `Mixin`. Finally, return\n    `Mixin`\n    '''\n    instance = model()\n\n    class Mixin(object):\n        save_after_transition = True\n\n    transitions = instance.get_all_status_transitions()\n    transition_names = set(x.name for x in transitions)\n    for transition_name in transition_names:\n        setattr(\n            Mixin,\n            transition_name,\n            get_transition_viewset_method(transition_name, **kwargs)\n        )\n\n    return Mixin", "response": "Returns a Mixin class that will create all transitions defined on the model and apply it to it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrefresh the project from the original cookiecutter template.", "response": "def fresh_cookies(ctx, mold=''):\n    \"\"\"Refresh the project from the original cookiecutter template.\"\"\"\n    mold = mold or \"https://github.com/Springerle/py-generic-project.git\"  # TODO: URL from config\n    tmpdir = os.path.join(tempfile.gettempdir(), \"cc-upgrade-pygments-markdown-lexer\")\n\n    if os.path.isdir('.git'):\n        # TODO: Ensure there are no local unstashed changes\n        pass\n\n    # Make a copy of the new mold version\n    if os.path.isdir(tmpdir):\n        shutil.rmtree(tmpdir)\n    if os.path.exists(mold):\n        shutil.copytree(mold, tmpdir, ignore=shutil.ignore_patterns(\n            \".git\", \".svn\", \"*~\",\n        ))\n    else:\n        ctx.run(\"git clone {} {}\".format(mold, tmpdir))\n\n    # Copy recorded \"cookiecutter.json\" into mold\n    shutil.copy2(\"project.d/cookiecutter.json\", tmpdir)\n\n    with pushd('..'):\n        ctx.run(\"cookiecutter --no-input {}\".format(tmpdir))\n    if os.path.exists('.git'):\n        ctx.run(\"git status\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ci(ctx):\n    opts = ['']\n\n    # 'tox' makes no sense in Travis\n    if os.environ.get('TRAVIS', '').lower() == 'true':\n        opts += ['test.pytest']\n    else:\n        opts += ['test.tox']\n\n    ctx.run(\"invoke --echo --pty clean --all build --docs check --reports{}\".format(' '.join(opts)))", "response": "Perform continuous integration tasks."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns project s metadata as a dict.", "response": "def _build_metadata(): # pylint: disable=too-many-locals, too-many-branches\n    \"Return project's metadata as a dict.\"\n    # Handle metadata in package source\n    expected_keys = ('url', 'version', 'license', 'author', 'author_email', 'long_description', 'keywords')\n    metadata = {}\n    with io.open(srcfile('src', package_name, '__init__.py'), encoding='utf-8') as handle:\n        pkg_init = handle.read()\n        # Get default long description from docstring\n        metadata['long_description'] = re.search(r'^\"\"\"(.+?)^\"\"\"$', pkg_init, re.DOTALL|re.MULTILINE).group(1)\n        for line in pkg_init.splitlines():\n            match = re.match(r\"\"\"^__({0})__ += (?P<q>['\"])(.+?)(?P=q)$\"\"\".format('|'.join(expected_keys)), line)\n            if match:\n                metadata[match.group(1)] = match.group(3)\n\n    if not all(i in metadata for i in expected_keys):\n        raise RuntimeError(\"Missing or bad metadata in '{0}' package: {1}\"\n                           .format(name, ', '.join(sorted(set(expected_keys) - set(metadata.keys()))),))\n\n    text = metadata['long_description'].strip()\n    if text:\n        metadata['description'], text = text.split('.', 1)\n        metadata['description'] = ' '.join(metadata['description'].split()).strip() + '.' # normalize whitespace\n        metadata['long_description'] = textwrap.dedent(text).strip()\n    metadata['keywords'] = metadata['keywords'].replace(',', ' ').strip().split()\n\n    # Load requirements files\n    requirements_files = dict(\n        install = 'requirements.txt',\n        setup = 'setup-requirements.txt',\n        test = 'test-requirements.txt',\n    )\n    requires = {}\n    for key, filename in requirements_files.items():\n        requires[key] = []\n        if os.path.exists(srcfile(filename)):\n            with io.open(srcfile(filename), encoding='utf-8') as handle:\n                for line in handle:\n                    line = line.strip()\n                    if line and not line.startswith('#'):\n                        if any(line.startswith(i) for i in ('-e', 'http://', 'https://')):\n                            line = line.split('#egg=')[1]\n                        requires[key].append(line)\n    if not any('pytest' == re.split('[\\t ,<=>]', i.lower())[0] for i in requires['test']):\n        requires['test'].append('pytest') # add missing requirement\n\n    # CLI entry points\n    console_scripts = []\n    for path, dirs, files in os.walk(srcfile('src', package_name)):\n        dirs = [i for i in dirs if not i.startswith('.')]\n        if '__main__.py' in files:\n            path = path[len(srcfile('src') + os.sep):]\n            appname = path.split(os.sep)[-1]\n            with io.open(srcfile('src', path, '__main__.py'), encoding='utf-8') as handle:\n                for line in handle.readlines():\n                    match = re.match(r\"\"\"^__app_name__ += (?P<q>['\"])(.+?)(?P=q)$\"\"\", line)\n                    if match:\n                        appname = match.group(2)\n            console_scripts.append('{0} = {1}.__main__:cli'.format(appname, path.replace(os.sep, '.')))\n\n    # Add some common files to EGG-INFO\n    candidate_files = [\n        'LICENSE', 'NOTICE',\n        'README', 'README.md', 'README.rst', 'README.txt',\n        'CHANGES', 'CHANGELOG', 'debian/changelog',\n    ]\n    data_files = defaultdict(list)\n    for filename in candidate_files:\n        if os.path.exists(srcfile(filename)):\n            data_files['EGG-INFO'].append(filename)\n\n    # Complete project metadata\n    classifiers = []\n    for classifiers_txt in ('classifiers.txt', 'project.d/classifiers.txt'):\n        classifiers_txt = srcfile(classifiers_txt)\n        if os.path.exists(classifiers_txt):\n            with io.open(classifiers_txt, encoding='utf-8') as handle:\n                classifiers = [i.strip() for i in handle if i.strip() and not i.startswith('#')]\n            break\n    entry_points.setdefault('console_scripts', []).extend(console_scripts)\n\n    metadata.update(dict(\n        name = name,\n        package_dir = {'': 'src'},\n        packages = find_packages(srcfile('src'), exclude=['tests']),\n        data_files = data_files.items(),\n        zip_safe = False,\n        include_package_data = True,\n        install_requires = requires['install'],\n        setup_requires = requires['setup'],\n        tests_require =  requires['test'],\n        classifiers = classifiers,\n        cmdclass = dict(\n            test = PyTest,\n        ),\n        entry_points = entry_points,\n    ))\n    return metadata"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef py_hash(key, num_buckets):\n    b, j = -1, 0\n\n    if num_buckets < 1:\n        raise ValueError('num_buckets must be a positive number')\n\n    while j < num_buckets:\n        b = int(j)\n        key = ((key * long(2862933555777941757)) + 1) & 0xffffffffffffffff\n        j = float(b + 1) * (float(1 << 31) / float((key >> 33) + 1))\n\n    return int(b)", "response": "Generate a number in the range [ 0 num_buckets )."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setup(app):\n    lexer = MarkdownLexer()\n    for alias in lexer.aliases:\n        app.add_lexer(alias, lexer)\n\n    return dict(version=__version__)", "response": "Setup Sphinx extension API."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(self):\n        ret = {}\n\n        # Read the mdstat file\n        with open(self.get_path(), 'r') as f:\n            # lines is a list of line (with \\n)\n            lines = f.readlines()\n\n        # First line: get the personalities\n        # The \"Personalities\" line tells you what RAID level the kernel currently supports.\n        # This can be changed by either changing the raid modules or recompiling the kernel.\n        # Possible personalities include: [raid0] [raid1] [raid4] [raid5] [raid6] [linear] [multipath] [faulty]\n        ret['personalities'] = self.get_personalities(lines[0])\n\n        # Second to last before line: Array definition\n        ret['arrays'] = self.get_arrays(lines[1:-1], ret['personalities'])\n\n        # Save the file content as it for the __str__ method\n        self.content = reduce(lambda x, y: x + y, lines)\n\n        return ret", "response": "Load the stats from the file and return a dict of stats."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of personalities readed from the input line.", "response": "def get_personalities(self, line):\n        \"\"\"Return a list of personalities readed from the input line.\"\"\"\n        return [split('\\W+', i)[1] for i in line.split(':')[1].split(' ') if i.startswith('[')]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dict of arrays.", "response": "def get_arrays(self, lines, personalities=[]):\n        \"\"\"Return a dict of arrays.\"\"\"\n        ret = {}\n\n        i = 0\n        while i < len(lines):\n            try:\n                # First array line: get the md device\n                md_device = self.get_md_device_name(lines[i])\n            except IndexError:\n                # No array detected\n                pass\n            else:\n                # Array detected\n                if md_device is not None:\n                    # md device line\n                    ret[md_device] = self.get_md_device(lines[i], personalities)\n                    # md config/status line\n                    i += 1\n                    ret[md_device].update(self.get_md_status(lines[i]))\n            i += 1\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dict of md device define in the line.", "response": "def get_md_device(self, line, personalities=[]):\n        \"\"\"Return a dict of md device define in the line.\"\"\"\n        ret = {}\n\n        splitted = split('\\W+', line)\n        # Raid status\n        # Active or 'started'. An inactive array is usually faulty.\n        # Stopped arrays aren't visible here.\n        ret['status'] = splitted[1]\n        if splitted[2] in personalities:\n            # Raid type (ex: RAID5)\n            ret['type'] = splitted[2]\n            # Array's components\n            ret['components'] = self.get_components(line, with_type=True)\n        else:\n            # Raid type (ex: RAID5)\n            ret['type'] = None\n            # Array's components\n            ret['components'] = self.get_components(line, with_type=False)\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dict of md status define in the line.", "response": "def get_md_status(self, line):\n        \"\"\"Return a dict of md status define in the line.\"\"\"\n        ret = {}\n\n        splitted = split('\\W+', line)\n        if len(splitted) < 7:\n            ret['available'] = None\n            ret['used'] = None\n            ret['config'] = None\n        else:\n            # The final 2 entries on this line: [n/m] [UUUU_]\n            # [n/m] means that ideally the array would have n devices however, currently, m devices are in use.\n            # Obviously when m >= n then things are good.\n            ret['available'] = splitted[-4]\n            ret['used'] = splitted[-3]\n            # [UUUU_] represents the status of each device, either U for up or _ for down.\n            ret['config'] = splitted[-2]\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dict of components in the line.", "response": "def get_components(self, line, with_type=True):\n        \"\"\"Return a dict of components in the line.\n\n        key: device name (ex: 'sdc1')\n        value: device role number\n        \"\"\"\n        ret = {}\n\n        # Ignore (F) (see test 08)\n        line2 = reduce(lambda x, y: x + y, split('\\(.+\\)', line))\n        if with_type:\n            splitted = split('\\W+', line2)[3:]\n        else:\n            splitted = split('\\W+', line2)[2:]\n        ret = dict(zip(splitted[0::2], splitted[1::2]))\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister signal receivers which send events.", "response": "def register_receivers(app, config):\n    \"\"\"Register signal receivers which send events.\"\"\"\n    for event_name, event_config in config.items():\n        event_builders = [\n            obj_or_import_string(func)\n            for func in event_config.get('event_builders', [])\n        ]\n\n        signal = obj_or_import_string(event_config['signal'])\n        signal.connect(\n            EventEmmiter(event_name, event_builders), sender=app, weak=False\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check(self, query):\n        if query.get_type() != Keyword.DELETE:\n            return Ok(True)\n\n        return Err(\"Delete queries are forbidden.\")", "response": "Check if the query is for DELETE type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_scheduled(self):\n        with self._idle_lock:\n            if self._idle:\n                self._idle = False\n                return True\n        return False", "response": "Returns True if state was successfully changed from idle to scheduled."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check(self, query):\n        if query.get_type() not in {Keyword.SELECT, Keyword.DELETE}:\n            # Only select and delete queries deal with time durations\n            # All others are not affected by this rule. Bailing out.\n            return Ok(True)\n\n        datapoints = query.get_datapoints()\n        if datapoints <= self.max_datapoints:\n            return Ok(True)\n\n        return Err((\"Expecting {} datapoints from that query, which is above the threshold! \"\n                    \"Set a date range (e.g. where time > now() - 24h), \"\n                    \"increase grouping (e.g. group by time(24h) \"\n                    \"or limit the number of datapoints (e.g. limit 100)\").format(datapoints))", "response": "Check if the given query is valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches for the oldest event timestamp.", "response": "def _get_oldest_event_timestamp(self):\n        \"\"\"Search for the oldest event timestamp.\"\"\"\n        # Retrieve the oldest event in order to start aggregation\n        # from there\n        query_events = Search(\n            using=self.client,\n            index=self.event_index\n        )[0:1].sort(\n            {'timestamp': {'order': 'asc'}}\n        )\n        result = query_events.execute()\n        # There might not be any events yet if the first event have been\n        # indexed but the indices have not been refreshed yet.\n        if len(result) == 0:\n            return None\n        return parser.parse(result[0]['timestamp'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the last aggregation date.", "response": "def get_bookmark(self):\n        \"\"\"Get last aggregation date.\"\"\"\n        if not Index(self.aggregation_alias,\n                     using=self.client).exists():\n            if not Index(self.event_index,\n                         using=self.client).exists():\n                return datetime.date.today()\n            return self._get_oldest_event_timestamp()\n\n        # retrieve the oldest bookmark\n        query_bookmark = Search(\n            using=self.client,\n            index=self.aggregation_alias,\n            doc_type=self.bookmark_doc_type\n        )[0:1].sort(\n            {'date': {'order': 'desc'}}\n        )\n        bookmarks = query_bookmark.execute()\n        # if no bookmark is found but the index exist, the bookmark was somehow\n        # lost or never written, so restart from the beginning\n        if len(bookmarks) == 0:\n            return self._get_oldest_event_timestamp()\n\n        # change it to doc_id_suffix\n        bookmark = datetime.datetime.strptime(bookmarks[0].date,\n                                              self.doc_id_suffix)\n        return bookmark"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset bookmark for starting next aggregation.", "response": "def set_bookmark(self):\n        \"\"\"Set bookmark for starting next aggregation.\"\"\"\n        def _success_date():\n            bookmark = {\n                'date': self.new_bookmark or datetime.datetime.utcnow().\n                strftime(self.doc_id_suffix)\n            }\n\n            yield dict(_index=self.last_index_written,\n                       _type=self.bookmark_doc_type,\n                       _source=bookmark)\n        if self.last_index_written:\n            bulk(self.client,\n                 _success_date(),\n                 stats_only=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nformatting the datetime to the closest aggregation interval.", "response": "def _format_range_dt(self, d):\n        \"\"\"Format range filter datetime to the closest aggregation interval.\"\"\"\n        if not isinstance(d, six.string_types):\n            d = d.isoformat()\n        return '{0}||/{1}'.format(\n            d, self.dt_rounding_map[self.aggregation_interval])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\naggregate and return an iterator over the event index entries.", "response": "def agg_iter(self, lower_limit=None, upper_limit=None):\n        \"\"\"Aggregate and return dictionary to be indexed in ES.\"\"\"\n        lower_limit = lower_limit or self.get_bookmark().isoformat()\n        upper_limit = upper_limit or (\n            datetime.datetime.utcnow().replace(microsecond=0).isoformat())\n        aggregation_data = {}\n\n        self.agg_query = Search(using=self.client,\n                                index=self.event_index).\\\n            filter('range', timestamp={\n                'gte': self._format_range_dt(lower_limit),\n                'lte': self._format_range_dt(upper_limit)})\n\n        # apply query modifiers\n        for modifier in self.query_modifiers:\n            self.agg_query = modifier(self.agg_query)\n\n        hist = self.agg_query.aggs.bucket(\n            'histogram',\n            'date_histogram',\n            field='timestamp',\n            interval=self.aggregation_interval\n        )\n        terms = hist.bucket(\n            'terms', 'terms', field=self.aggregation_field, size=0\n        )\n        top = terms.metric(\n            'top_hit', 'top_hits', size=1, sort={'timestamp': 'desc'}\n        )\n        for dst, (metric, src, opts) in self.metric_aggregation_fields.items():\n            terms.metric(dst, metric, field=src, **opts)\n\n        results = self.agg_query.execute()\n        index_name = None\n        for interval in results.aggregations['histogram'].buckets:\n            interval_date = datetime.datetime.strptime(\n                interval['key_as_string'], '%Y-%m-%dT%H:%M:%S')\n            for aggregation in interval['terms'].buckets:\n                aggregation_data['timestamp'] = interval_date.isoformat()\n                aggregation_data[self.aggregation_field] = aggregation['key']\n                aggregation_data['count'] = aggregation['doc_count']\n\n                if self.metric_aggregation_fields:\n                    for f in self.metric_aggregation_fields:\n                        aggregation_data[f] = aggregation[f]['value']\n\n                doc = aggregation.top_hit.hits.hits[0]['_source']\n                for destination, source in self.copy_fields.items():\n                    if isinstance(source, six.string_types):\n                        aggregation_data[destination] = doc[source]\n                    else:\n                        aggregation_data[destination] = source(\n                            doc,\n                            aggregation_data\n                        )\n\n                index_name = 'stats-{0}-{1}'.\\\n                             format(self.event,\n                                    interval_date.strftime(\n                                        self.index_name_suffix))\n                self.indices.add(index_name)\n                yield dict(_id='{0}-{1}'.\n                           format(aggregation['key'],\n                                  interval_date.strftime(\n                                      self.doc_id_suffix)),\n                           _index=index_name,\n                           _type=self.aggregation_doc_type,\n                           _source=aggregation_data)\n        self.last_index_written = index_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_bookmarks(self, start_date=None, end_date=None, limit=None):\n        query = Search(\n            using=self.client,\n            index=self.aggregation_alias,\n            doc_type=self.bookmark_doc_type\n        ).sort({'date': {'order': 'desc'}})\n\n        range_args = {}\n        if start_date:\n            range_args['gte'] = self._format_range_dt(\n                start_date.replace(microsecond=0))\n        if end_date:\n            range_args['lte'] = self._format_range_dt(\n                end_date.replace(microsecond=0))\n        if range_args:\n            query = query.filter('range', date=range_args)\n\n        return query[0:limit].execute() if limit else query.scan()", "response": "List the aggregation s bookmarks."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the data resolution of a query in seconds", "response": "def parse(self, group_by_stmt):\n        \"\"\"\n        Extract the data resolution of a query in seconds\n        E.g. \"group by time(99s)\" => 99\n\n        :param group_by_stmt: A raw InfluxDB group by statement\n        \"\"\"\n        if not group_by_stmt:\n            return Resolution.MAX_RESOLUTION\n\n        m = self.GROUP_BY_TIME_PATTERN.match(group_by_stmt)\n        if not m:\n            return None\n\n        value = int(m.group(1))\n        unit = m.group(2)\n        resolution = self.convert_to_seconds(value, unit)\n\n        # We can't have a higher resolution than the max resolution\n        return max(resolution, Resolution.MAX_RESOLUTION)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, timeout=None):\n        result = None\n        try:\n            result = self._result.get(True, timeout=timeout)\n        except Empty:\n            raise Timeout()\n\n        if isinstance(result, Failure):\n            six.reraise(*result.exc_info)\n        else:\n            return result", "response": "Get the next entry from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef consume(self, event_type, no_ack=True, payload=True):\n        assert event_type in self.events\n        return current_queues.queues['stats-{}'.format(event_type)].consume(\n            payload=payload)", "response": "Comsume all pending events."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitializes the application with the given Flask application.", "response": "def init_app(self, app,\n                 entry_point_group_events='invenio_stats.events',\n                 entry_point_group_aggs='invenio_stats.aggregations',\n                 entry_point_group_queries='invenio_stats.queries'):\n        \"\"\"Flask application initialization.\"\"\"\n        self.init_config(app)\n\n        state = _InvenioStatsState(\n            app,\n            entry_point_group_events=entry_point_group_events,\n            entry_point_group_aggs=entry_point_group_aggs,\n            entry_point_group_queries=entry_point_group_queries\n        )\n        self._state = app.extensions['invenio-stats'] = state\n\n        if app.config['STATS_REGISTER_RECEIVERS']:\n            signal_receivers = {key: value for key, value in\n                                app.config.get('STATS_EVENTS', {}).items()\n                                if 'signal' in value}\n            register_receivers(app, signal_receivers)\n\n        return state"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a message to this actor. Asynchronous fire - and - forget.", "response": "def tell(self, message, sender=no_sender):\n        \"\"\" Send a message to this actor. Asynchronous fire-and-forget.\n\n        :param message: The message to send.\n        :type message: Any\n\n        :param sender: The sender of the message. If provided it will be made\n            available to the receiving actor via the :attr:`Actor.sender` attribute.\n        :type sender: :class:`Actor`\n        \"\"\"\n        if sender is not no_sender and not isinstance(sender, ActorRef):\n            raise ValueError(\"Sender must be actor reference\")\n\n        self._cell.send_message(message, sender)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_anonymization_salt(ts):\n    salt_key = 'stats:salt:{}'.format(ts.date().isoformat())\n    salt = current_cache.get(salt_key)\n    if not salt:\n        salt_bytes = os.urandom(32)\n        salt = b64encode(salt_bytes).decode('utf-8')\n        current_cache.set(salt_key, salt, timeout=60 * 60 * 24)\n    return salt", "response": "Get the anonymization salt based on the event timestamp s day."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_user():\n    return dict(\n        ip_address=request.remote_addr,\n        user_agent=request.user_agent.string,\n        user_id=(\n            current_user.get_id() if current_user.is_authenticated else None\n        ),\n        session_id=session.get('sid_s')\n    )", "response": "User information.\n\n    .. note::\n\n       **Privacy note** A users IP address, user agent string, and user id\n       (if logged in) is sent to a message queue, where it is stored for about\n       5 minutes. The information is used to:\n\n       - Detect robot visits from the user agent string.\n       - Generate an anonymized visitor id (using a random salt per day).\n       - Detect the users host contry based on the IP address.\n\n       The information is then discarded."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef default_permission_factory(query_name, params):\n    from invenio_stats import current_stats\n    if current_stats.queries[query_name].permission_factory is None:\n        return AllowAllPermission\n    else:\n        return current_stats.queries[query_name].permission_factory(\n            query_name, params\n        )", "response": "Default permission factory.\n\n    It enables by default the statistics if they don't have a dedicated\n    permission factory."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_config():\n    # We start with the default config\n    config = flatten(default_config.DEFAULT_CONFIG)\n\n    # Read commandline arguments\n    cli_config = flatten(parse_args())\n\n    if \"configfile\" in cli_config:\n        logging.info(\"Reading config file {}\".format(cli_config['configfile']))\n        configfile = parse_configfile(cli_config['configfile'])\n        config = overwrite_config(config, configfile)\n\n    # Parameters from commandline take precedence over all others\n    config = overwrite_config(config, cli_config)\n\n    # Set verbosity level\n    if 'verbose' in config:\n        if config['verbose'] == 1:\n            logging.getLogger().setLevel(logging.INFO)\n        elif config['verbose'] > 1:\n            logging.getLogger().setLevel(logging.DEBUG)\n\n    return ObjectView(config)", "response": "Load settings from default config and optionally overwrite with config file and commandline parameters\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads settings from file ridge", "response": "def parse_configfile(configfile):\n    \"\"\"\n    Read settings from file\n    :param configfile:\n    \"\"\"\n    with open(configfile) as f:\n        try:\n            return yaml.safe_load(f)\n        except Exception as e:\n            logging.fatal(\"Could not load default config file: %s\", e)\n            exit(-1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister elasticsearch templates for events and aggregations.", "response": "def register_templates():\n    \"\"\"Register elasticsearch templates for events.\"\"\"\n    event_templates = [current_stats._events_config[e]\n                       ['templates']\n                       for e in\n                       current_stats._events_config]\n    aggregation_templates = [current_stats._aggregations_config[a]\n                             ['templates']\n                             for a in\n                             current_stats._aggregations_config]\n    return event_templates + aggregation_templates"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck that the series name is not too short.", "response": "def check(self, query):\n        \"\"\"\n        :param query:\n        \"\"\"\n        if query.get_type() in {Keyword.LIST, Keyword.DROP}:\n            series = query.series_stmt\n        else:\n            series = query.from_stmt\n\n        if len(series) >= self.min_series_name_length:\n            return Ok(True)\n\n        return Err(\"Series name too short. Please be more precise.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a message to actor and return a future holding the result.", "response": "def ask(actor, message):\n    \"\"\"\n    Send a message to `actor` and return a :class:`Future` holding a possible\n    reply.\n\n    To receive a result, the actor MUST send a reply to `sender`.\n\n    :param actor:\n    :type actor: :class:`ActorRef`.\n\n    :param message:\n    :type message: :type: Any\n\n    :return: A future holding the result.\n    \"\"\"\n    sender = PromiseActorRef()\n    actor.tell(message, sender)\n    return sender.promise.future"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a list of all queries from an URL parameter string", "response": "def get_queries(parameters):\n        \"\"\"\n        Get a list of all queries (q=... parameters) from an URL parameter string\n        :param parameters: The url parameter list\n        \"\"\"\n        parsed_params = urlparse.parse_qs(parameters)\n        if 'q' not in parsed_params:\n            return []\n        queries = parsed_params['q']\n\n        # Check if only one query string is given\n        # in this case make it a list\n        if not isinstance(queries, list):\n            queries = [queries]\n        return queries"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _handle_request(self, scheme, netloc, path, headers, body=None, method=\"GET\"):\n        backend_url = \"{}://{}{}\".format(scheme, netloc, path)\n        try:\n            response = self.http_request.request(backend_url, method=method, body=body, headers=dict(headers))\n            self._return_response(response)\n        except Exception as e:\n            body = \"Invalid response from backend: '{}' Server might be busy\".format(e.message)\n            logging.debug(body)\n            self.send_error(httplib.SERVICE_UNAVAILABLE, body)", "response": "Handle the request from the backend and return the response."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends and log plain text error reply.", "response": "def send_error(self, code, message=None):\n        \"\"\"\n        Send and log plain text error reply.\n        :param code:\n        :param message:\n        \"\"\"\n        message = message.strip()\n        self.log_error(\"code %d, message %s\", code, message)\n        self.send_response(code)\n        self.send_header(\"Content-Type\", \"text/plain\")\n        self.send_header('Connection', 'close')\n        self.end_headers()\n        if message:\n            self.wfile.write(message)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _return_response(self, response):\n        self.filter_headers(response.msg)\n        if \"content-length\" in response.msg:\n            del response.msg[\"content-length\"]\n\n        self.send_response(response.status, response.reason)\n        for header_key, header_value in response.msg.items():\n            self.send_header(header_key, header_value)\n        body = response.read()\n        self.send_header('Content-Length', str(len(body)))\n        self.end_headers()\n        self.wfile.write(body)", "response": "Send the response to the client."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef hash_id(iso_timestamp, msg):\n    return '{0}-{1}'.format(iso_timestamp,\n                            hashlib.sha1(\n                                msg.get('unique_id').encode('utf-8') +\n                                str(msg.get('visitor_id')).\n                                encode('utf-8')).\n                            hexdigest())", "response": "Generate event id optimized for ES."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef actionsiter(self):\n        for msg in self.queue.consume():\n            try:\n                for preproc in self.preprocessors:\n                    msg = preproc(msg)\n                    if msg is None:\n                        break\n                if msg is None:\n                    continue\n                suffix = arrow.get(msg.get('timestamp')).strftime(self.suffix)\n                ts = parser.parse(msg.get('timestamp'))\n                # Truncate timestamp to keep only seconds. This is to improve\n                # elasticsearch performances.\n                ts = ts.replace(microsecond=0)\n                msg['timestamp'] = ts.isoformat()\n                # apply timestamp windowing in order to group events too close\n                # in time\n                if self.double_click_window > 0:\n                    timestamp = mktime(utc.localize(ts).utctimetuple())\n                    ts = ts.fromtimestamp(\n                        timestamp // self.double_click_window *\n                        self.double_click_window\n                    )\n                yield dict(\n                    _id=hash_id(ts.isoformat(), msg),\n                    _op_type='index',\n                    _index='{0}-{1}'.format(self.index, suffix),\n                    _type=self.doctype,\n                    _source=msg,\n                )\n            except Exception:\n                current_app.logger.exception(u'Error while processing event')", "response": "Iterate over the messages in the queue and yield the events that were processed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the number of datapoints in a given duration in seconds.", "response": "def parse(duration_seconds, resolution_seconds=Resolution.MAX_RESOLUTION, limit=None):\n        \"\"\"\n        num_datapoints = min(duration/resolution, limit)\n\n        :param duration_seconds: Time duration (in seconds) for which datapoints should be returned\n        :param resolution_seconds: Time interval (in seconds) between data points\n        :param limit: Maximum number of datapoints to return\n        \"\"\"\n\n        if not duration_seconds or duration_seconds < 0:\n            return 0\n\n        if not resolution_seconds or resolution_seconds <= 0:\n            return None\n\n        num_datapoints = duration_seconds / resolution_seconds\n\n        if limit:\n            num_datapoints = min(int(limit), num_datapoints)\n\n        return int(math.ceil(num_datapoints))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a series with num_series datapoints and write them to the client.", "response": "def create_series(self, num_series, batch_size=5000):\n        \"\"\"\n        Write one data point for each series name to initialize the series\n        :param num_series: Number of different series names to create\n        :param batch_size: Number of series to create at the same time\n        :return:\n        \"\"\"\n        datapoints = []\n        for _ in range(num_series):\n            name = self.dummy_seriesname()\n            datapoints.append(self.create_datapoint(name, [\"value\"], [[1]]))\n        for data in tqdm(self.batch(datapoints, batch_size)):\n            self.client.write_points(data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_points(self, series_name, start_date, end_date, resolution=10, batch_size=5000):\n        start_ts = int(start_date.strftime(\"%s\"))\n        end_ts = int(end_date.strftime(\"%s\"))\n\n        range_seconds = end_ts - start_ts\n        num_datapoints = range_seconds / resolution\n\n        timestamps = [start_ts + i * resolution for i in range(num_datapoints)]\n\n        columns = [\"time\", \"value\"]\n        for batch in tqdm(self.batch(timestamps, batch_size)):\n            points = []\n            for timestamp in batch:\n                point = random.randint(1, 100)\n                points.append([timestamp, point])\n            datapoint = self.create_datapoint(series_name, columns, points)\n            self.client.write_points([datapoint])", "response": "Create sample datapoints between two dates with the given resolution"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check(self, query):\n        if query.get_type() not in {Keyword.SELECT}:\n            # Bailing out for non select queries\n            return Ok(True)\n\n        if query.get_resolution() > 0:\n            return Ok(True)\n\n        return Err(\"Group by statements need a positive time value (e.g. time(10s))\")", "response": "Check that the query is valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a raw InfluxDB query string into a dictionary of fields.", "response": "def parse(self, raw_query_string):\n        \"\"\"\n        Parse a raw query string into fields\n        :param raw_query_string: Raw InfluxDB query string\n        \"\"\"\n\n        self._reset()\n\n        if not isinstance(raw_query_string, basestring):\n            return None\n\n        query_string = self._cleanup(raw_query_string)\n        parts = self._split(query_string)\n        parts = self._sanitize_keywords(parts)\n        tokens = self._tokenize(parts)\n\n        if tokens:\n            # Run subparsers to analyze parts of the query\n            self.parsed_resolution = self._parse_resolution(tokens)\n            self.parsed_time = self._parse_time(tokens)\n            self.parsed_time_overlap = self._parse_duration(self.parsed_time)\n            self.parsed_datapoints = self._parse_datapoints(\n                self.parsed_time_overlap.timespan_seconds(),\n                self.parsed_resolution,\n                self.parse_keyword(Keyword.LIMIT, tokens)\n            )\n\n        return self.create_query_object(tokens)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nanalyzing query tokens and create an InfluxDBStatement from them", "response": "def create_query_object(self, tokens):\n        \"\"\"\n        Analyze query tokens and create an InfluxDBStatement from them\n        Return None on error\n        :param tokens: A list of InfluxDB query tokens\n        \"\"\"\n        try:\n            query_type = tokens['type']\n            return getattr(self, 'create_%s_query' % query_type)(tokens)\n        except (KeyError, TypeError):\n            return self.invalid_query(tokens)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_select_query(self, tokens):\n        if not tokens[Keyword.SELECT]:\n            return None\n        if not tokens[Keyword.FROM]:\n            return None\n\n        return SelectQuery(\n            self.parse_keyword(Keyword.SELECT, tokens),\n            self.parse_keyword(Keyword.FROM, tokens),\n            where_stmt=self.parse_keyword(Keyword.WHERE, tokens),\n            limit_stmt=self.parse_keyword(Keyword.LIMIT, tokens),\n            group_by_stmt=self.parse_group(tokens),\n            duration=self.parsed_time_overlap.timespan_seconds(),\n            resolution=self.parsed_resolution,\n            time_ranges=self.parsed_time,\n            time_overlap=self.parsed_time_overlap,\n            datapoints=self.parsed_datapoints\n        )", "response": "Parse the list of tokens of select query"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_list_query(self, tokens):\n        if not tokens[Keyword.SERIES]:\n            # A list series keyword is allowed\n            # without a series name or regex\n            tokens[Keyword.SERIES] = ''\n        return ListQuery(self.parse_keyword(Keyword.SERIES, tokens))", "response": "Parse the list query from the tokens."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the list of tokens of drop query", "response": "def create_drop_query(self, tokens):\n        \"\"\"\n        Parse tokens of drop query\n        :param tokens: A list of InfluxDB query tokens\n        \"\"\"\n        if not tokens[Keyword.SERIES]:\n            return None\n        return DropQuery(self.parse_keyword(Keyword.SERIES, tokens))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_delete_query(self, tokens):\n        # From keyword is required\n        if not tokens[Keyword.FROM]:\n            return None\n        where_stmt = self.parse_keyword(Keyword.WHERE, tokens)\n        if where_stmt:\n            if not where_stmt.startswith('time'):\n                return None\n        return DeleteQuery(\n            self.parse_keyword(Keyword.FROM, tokens),\n            self.parse_keyword(Keyword.WHERE, tokens)\n        )", "response": "Parse the tokens of delete query"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_time(self, tokens):\n        return self.time_parser.parse(self.parse_keyword(Keyword.WHERE, tokens))", "response": "Parse the time range for the query\n        Eg. WHERE time < now - 48h and time < now - 24h"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the resolution from the GROUP BY statement.", "response": "def _parse_resolution(self, tokens):\n        \"\"\"\n        Parse resolution from the GROUP BY statement.\n        E.g. GROUP BY time(10s) would mean a 10 second resolution\n        :param tokens:\n        :return:\n        \"\"\"\n        return self.resolution_parser.parse(self.parse_keyword(Keyword.GROUP_BY, tokens))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the number of datapoints of a query.", "response": "def _parse_datapoints(self, parsed_duration, parsed_resolution, limit):\n        \"\"\"\n        Parse the number of datapoints of a query.\n        This can be calculated from the given duration and resolution of the query.\n        E.g. if the query has a duation of 2*60*60 = 7200 seconds and a resolution of 10 seconds\n        then the number of datapoints would be 7200/10 => 7200 datapoints.\n\n        :param parsed_duration:\n        :param parsed_resolution:\n        :param limit:\n        :return:\n        \"\"\"\n        return self.datapoints_parser.parse(parsed_duration, parsed_resolution, limit)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the current time is before the earliest date.", "response": "def check(self, query):\n        \"\"\"\n        :param query:\n        \"\"\"\n        if query.get_type() not in {Keyword.SELECT}:\n            # Only select queries need to be checked here\n            # All others are not affected by this rule. Bailing out.\n            return Ok(True)\n\n        earliest_date = query.get_earliest_date()\n        if earliest_date >= self.min_start_date:\n            return Ok(True)\n\n        if query.limit_stmt:\n            return Ok(True)\n\n        return Err((\"Querying for data before {} is prohibited. \"\n                    \"Your beginning date is {}, which is before that.\").format(self.min_start_date.strftime(\"%Y-%m-%d\"),\n                                                                              earliest_date))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts date from string if necessary.", "response": "def extract_date(self, date):\n        \"\"\"Extract date from string if necessary.\n\n        :returns: the extracted date.\n        \"\"\"\n        if isinstance(date, six.string_types):\n            try:\n                date = dateutil.parser.parse(date)\n            except ValueError:\n                raise ValueError(\n                    'Invalid date format for statistic {}.'\n                ).format(self.query_name)\n        if not isinstance(date, datetime):\n            raise TypeError(\n                'Invalid date type for statistic {}.'\n            ).format(self.query_name)\n        return date"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_arguments(self, interval, start_date, end_date, **kwargs):\n        if interval not in self.allowed_intervals:\n            raise InvalidRequestInputError(\n                'Invalid aggregation time interval for statistic {}.'\n            ).format(self.query_name)\n        if set(kwargs) < set(self.required_filters):\n            raise InvalidRequestInputError(\n                'Missing one of the required parameters {0} in '\n                'query {1}'.format(set(self.required_filters.keys()),\n                                   self.query_name)\n            )", "response": "Validate the query arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_query(self, interval, start_date, end_date, **kwargs):\n        agg_query = Search(using=self.client,\n                           index=self.index,\n                           doc_type=self.doc_type)[0:0]\n        if start_date is not None or end_date is not None:\n            time_range = {}\n            if start_date is not None:\n                time_range['gte'] = start_date.isoformat()\n            if end_date is not None:\n                time_range['lte'] = end_date.isoformat()\n            agg_query = agg_query.filter(\n                'range',\n                **{self.time_field: time_range})\n\n        for modifier in self.query_modifiers:\n            agg_query = modifier(agg_query, **kwargs)\n\n        base_agg = agg_query.aggs.bucket(\n            'histogram',\n            'date_histogram',\n            field=self.time_field,\n            interval=interval\n        )\n\n        for destination, (metric, field, opts) in self.metric_fields.items():\n            base_agg.metric(destination, metric, field=field, **opts)\n\n        if self.copy_fields:\n            base_agg.metric(\n                'top_hit', 'top_hits', size=1, sort={'timestamp': 'desc'}\n            )\n\n        for query_param, filtered_field in self.required_filters.items():\n            if query_param in kwargs:\n                agg_query = agg_query.filter(\n                    'term', **{filtered_field: kwargs[query_param]}\n                )\n\n        return agg_query", "response": "Build the elasticsearch query."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_query_result(self, query_result, interval,\n                             start_date, end_date):\n        \"\"\"Build the result using the query result.\"\"\"\n        def build_buckets(agg):\n            \"\"\"Build recursively result buckets.\"\"\"\n            bucket_result = dict(\n                key=agg['key'],\n                date=agg['key_as_string'],\n            )\n            for metric in self.metric_fields:\n                bucket_result[metric] = agg[metric]['value']\n            if self.copy_fields and agg['top_hit']['hits']['hits']:\n                doc = agg['top_hit']['hits']['hits'][0]['_source']\n                for destination, source in self.copy_fields.items():\n                    if isinstance(source, six.string_types):\n                        bucket_result[destination] = doc[source]\n                    else:\n                        bucket_result[destination] = source(bucket_result, doc)\n            return bucket_result\n\n        # Add copy_fields\n        buckets = query_result['aggregations']['histogram']['buckets']\n        return dict(\n            interval=interval,\n            key_type='date',\n            start_date=start_date.isoformat() if start_date else None,\n            end_date=end_date.isoformat() if end_date else None,\n            buckets=[build_buckets(b) for b in buckets]\n        )", "response": "Process the query result."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating the arguments for the query.", "response": "def validate_arguments(self, start_date, end_date, **kwargs):\n        \"\"\"Validate query arguments.\"\"\"\n        if set(kwargs) < set(self.required_filters):\n            raise InvalidRequestInputError(\n                'Missing one of the required parameters {0} in '\n                'query {1}'.format(set(self.required_filters.keys()),\n                                   self.query_name)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_query(self, start_date, end_date, **kwargs):\n        agg_query = Search(using=self.client,\n                           index=self.index,\n                           doc_type=self.doc_type)[0:0]\n        if start_date is not None or end_date is not None:\n            time_range = {}\n            if start_date is not None:\n                time_range['gte'] = start_date.isoformat()\n            if end_date is not None:\n                time_range['lte'] = end_date.isoformat()\n            agg_query = agg_query.filter(\n                'range',\n                **{self.time_field: time_range})\n\n        for modifier in self.query_modifiers:\n            agg_query = modifier(agg_query, **kwargs)\n\n        base_agg = agg_query.aggs\n\n        def _apply_metric_aggs(agg):\n            for dst, (metric, field, opts) in self.metric_fields.items():\n                agg.metric(dst, metric, field=field, **opts)\n\n        _apply_metric_aggs(base_agg)\n        if self.aggregated_fields:\n            cur_agg = base_agg\n            for term in self.aggregated_fields:\n                cur_agg = cur_agg.bucket(term, 'terms', field=term, size=0)\n                _apply_metric_aggs(cur_agg)\n\n        if self.copy_fields:\n            base_agg.metric(\n                'top_hit', 'top_hits', size=1, sort={'timestamp': 'desc'}\n            )\n\n        for query_param, filtered_field in self.required_filters.items():\n            if query_param in kwargs:\n                agg_query = agg_query.filter(\n                    'term', **{filtered_field: kwargs[query_param]}\n                )\n\n        return agg_query", "response": "Build the elasticsearch query."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses the query result and return a dictionary of the result.", "response": "def process_query_result(self, query_result, start_date, end_date):\n        \"\"\"Build the result using the query result.\"\"\"\n        def build_buckets(agg, fields, bucket_result):\n            \"\"\"Build recursively result buckets.\"\"\"\n            # Add metric results for current bucket\n            for metric in self.metric_fields:\n                bucket_result[metric] = agg[metric]['value']\n            if fields:\n                current_level = fields[0]\n                bucket_result.update(dict(\n                    type='bucket',\n                    field=current_level,\n                    key_type='terms',\n                    buckets=[build_buckets(b, fields[1:], dict(key=b['key']))\n                             for b in agg[current_level]['buckets']]\n                ))\n            return bucket_result\n\n        # Add copy_fields\n        aggs = query_result['aggregations']\n        result = dict(\n            start_date=start_date.isoformat() if start_date else None,\n            end_date=end_date.isoformat() if end_date else None,\n        )\n        if self.copy_fields and aggs['top_hit']['hits']['hits']:\n            doc = aggs['top_hit']['hits']['hits'][0]['_source']\n            for destination, source in self.copy_fields.items():\n                if isinstance(source, six.string_types):\n                    result[destination] = doc[source]\n                else:\n                    result[destination] = source(result, doc)\n\n        return build_buckets(aggs, self.aggregated_fields, result)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\noverride error handling to suppress socket and ssl related errors", "response": "def handle_error(self, request, client_address):\n        \"\"\"\n        Overwrite error handling to suppress socket/ssl related errors\n        :param client_address: Address of client\n        :param request: Request causing an error\n        \"\"\"\n        cls, e = sys.exc_info()[:2]\n        if cls is socket.error or cls is ssl.SSLError:\n            pass\n        else:\n            return HTTPServer.handle_error(self, request, client_address)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a file - download event.", "response": "def file_download_event_builder(event, sender_app, obj=None, **kwargs):\n    \"\"\"Build a file-download event.\"\"\"\n    event.update(dict(\n        # When:\n        timestamp=datetime.datetime.utcnow().isoformat(),\n        # What:\n        bucket_id=str(obj.bucket_id),\n        file_id=str(obj.file_id),\n        file_key=obj.key,\n        size=obj.file.size,\n        referrer=request.referrer,\n        # Who:\n        **get_user()\n    ))\n    return event"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild a record - view event.", "response": "def record_view_event_builder(event, sender_app, pid=None, record=None,\n                              **kwargs):\n    \"\"\"Build a record-view event.\"\"\"\n    event.update(dict(\n        # When:\n        timestamp=datetime.datetime.utcnow().isoformat(),\n        # What:\n        record_id=str(record.id),\n        pid_type=pid.pid_type,\n        pid_value=str(pid.pid_value),\n        referrer=request.referrer,\n        # Who:\n        **get_user()\n    ))\n    return event"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_write_permissions(file):\n    try:\n        open(file, 'a')\n    except IOError:\n        print(\"Can't open file {}. \"\n              \"Please grant write permissions or change the path in your config\".format(file))\n        sys.exit(1)", "response": "Check if we can write to the given file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef show_rules():\n    from rules.loader import import_rules\n    from rules.rule_list import all_rules\n    rules = import_rules(all_rules)\n    print(\"\")\n    for name, rule in rules.iteritems():\n        heading = \"{} (`{}`)\".format(rule.description(), name)\n        print(\"#### {} ####\".format(heading))\n        for line in rule.reason():\n            print(line)\n        print(\"\")\n    sys.exit(0)", "response": "Show the list of available rules and quit\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts the http proxy", "response": "def start_proxy(config):\n    \"\"\"\n    Start the http proxy\n    :param config:\n    :return:\n    \"\"\"\n    protector = Protector(config.rules, config.whitelist)\n    protector_daemon = ProtectorDaemon(config=config, protector=protector)\n\n    daemon = daemonocle.Daemon(\n        pidfile=config.pidfile,\n        detach=(not config.foreground),\n        shutdown_callback=shutdown,\n        worker=protector_daemon.run\n    )\n    daemon.do_action(config.command)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding n batches of the sequence.", "response": "def batches(iterable, n=1):\n    \"\"\"\n    From http://stackoverflow.com/a/8290508/270334\n    :param n:\n    :param iterable:\n    \"\"\"\n    l = len(iterable)\n    for ndx in range(0, l, n):\n        yield iterable[ndx:min(ndx + n, l)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _is_root():\n    import os\n    import ctypes\n    try:\n        return os.geteuid() == 0\n    except AttributeError:\n        return ctypes.windll.shell32.IsUserAnAdmin() != 0\n    return False", "response": "Checks if the user is rooted."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cmdclass(path, enable=None, user=None):\n    import warnings\n    from setuptools.command.install import install\n    from setuptools.command.develop import develop\n    from os.path import dirname, join, exists, realpath\n    from traceback import extract_stack\n\n    try:\n        # IPython/Jupyter 4.0\n        from notebook.nbextensions import install_nbextension\n        from notebook.services.config import ConfigManager\n    except ImportError:\n        # Pre-schism\n        try:\n            from IPython.html.nbextensions import install_nbextension\n            from IPython.html.services.config import ConfigManager\n        except ImportError:\n            warnings.warn(\"No jupyter notebook found in your environment. \"\n                          \"Hence jupyter nbextensions were not installed. \"\n                          \"If you would like to have them,\"\n                          \"please issue 'pip install jupyter'.\")\n            return {}\n\n    # Check if the user flag was set.\n    if user is None:\n        user = not _is_root()\n\n    # Get the path of the extension\n    calling_file = extract_stack()[-2][0]\n    fullpath = realpath(calling_file)\n    if not exists(fullpath):\n        raise Exception('Could not find path of setup file.')\n    extension_dir = join(dirname(fullpath), path)\n\n    # Installs the nbextension\n    def run_nbextension_install(develop):\n        import sys\n        sysprefix = hasattr(sys, 'real_prefix')\n        if sysprefix:\n            install_nbextension(\n                extension_dir, symlink=develop, sys_prefix=sysprefix)\n        else:\n            install_nbextension(extension_dir, symlink=develop, user=user)\n        if enable is not None:\n            print(\"Enabling the extension ...\")\n            cm = ConfigManager()\n            cm.update('notebook', {\"load_extensions\": {enable: True}})\n\n    # Command used for standard installs\n    class InstallCommand(install):\n        def run(self):\n            print(\"Installing Python module...\")\n            install.run(self)\n            print(\"Installing nbextension ...\")\n            run_nbextension_install(False)\n\n    # Command used for development installs (symlinks the JS)\n    class DevelopCommand(develop):\n        def run(self):\n            print(\"Installing Python module...\")\n            develop.run(self)\n            print(\"Installing nbextension ...\")\n            run_nbextension_install(True)\n\n    return {\n        'install': InstallCommand,\n        'develop': DevelopCommand,\n    }", "response": "Build the nbextension commandclass dict for the notebook notebook."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef count_subgraph_sizes(graph: BELGraph, annotation: str = 'Subgraph') -> Counter[int]:\n    return count_dict_values(group_nodes_by_annotation(graph, annotation))", "response": "Count the number of nodes in each subgraph induced by an annotation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calculate_subgraph_edge_overlap(\n        graph: BELGraph,\n        annotation: str = 'Subgraph'\n) -> Tuple[\n    Mapping[str, EdgeSet],\n    Mapping[str, Mapping[str, EdgeSet]],\n    Mapping[str, Mapping[str, EdgeSet]],\n    Mapping[str, Mapping[str, float]],\n]:\n    \"\"\"Build a DatafFame to show the overlap between different sub-graphs.\n\n    Options:\n    1. Total number of edges overlap (intersection)\n    2. Percentage overlap (tanimoto similarity)\n\n    :param graph: A BEL graph\n    :param annotation: The annotation to group by and compare. Defaults to 'Subgraph'\n    :return: {subgraph: set of edges}, {(subgraph 1, subgraph2): set of intersecting edges},\n            {(subgraph 1, subgraph2): set of unioned edges}, {(subgraph 1, subgraph2): tanimoto similarity},\n    \"\"\"\n    sg2edge = defaultdict(set)\n\n    for u, v, d in graph.edges(data=True):\n        if not edge_has_annotation(d, annotation):\n            continue\n        sg2edge[d[ANNOTATIONS][annotation]].add((u, v))\n\n    subgraph_intersection = defaultdict(dict)\n    subgraph_union = defaultdict(dict)\n    result = defaultdict(dict)\n\n    for sg1, sg2 in itt.product(sg2edge, repeat=2):\n        subgraph_intersection[sg1][sg2] = sg2edge[sg1] & sg2edge[sg2]\n        subgraph_union[sg1][sg2] = sg2edge[sg1] | sg2edge[sg2]\n        result[sg1][sg2] = len(subgraph_intersection[sg1][sg2]) / len(subgraph_union[sg1][sg2])\n\n    return sg2edge, subgraph_intersection, subgraph_union, result", "response": "Calculate the overlap between two sub - graphs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef summarize_subgraph_edge_overlap(graph: BELGraph, annotation: str = 'Subgraph') -> Mapping[str, Mapping[str, float]]:\n    _, _, _, subgraph_overlap = calculate_subgraph_edge_overlap(graph, annotation)\n    return subgraph_overlap", "response": "Summarize the similarity matrix between all subgraphs or other given annotation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef summarize_subgraph_node_overlap(graph: BELGraph, node_predicates=None, annotation: str = 'Subgraph'):\n    r1 = group_nodes_by_annotation_filtered(graph, node_predicates=node_predicates, annotation=annotation)\n    return calculate_tanimoto_set_distances(r1)", "response": "Summarize the similarity between nodes passing the given filter."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rank_subgraph_by_node_filter(graph: BELGraph,\n                                 node_predicates: Union[NodePredicate, Iterable[NodePredicate]],\n                                 annotation: str = 'Subgraph',\n                                 reverse: bool = True,\n                                 ) -> List[Tuple[str, int]]:\n    \"\"\"Rank sub-graphs by which have the most nodes matching an given filter.\n\n    A use case for this function would be to identify which subgraphs contain the most differentially expressed\n    genes.\n\n    >>> from pybel import from_pickle\n    >>> from pybel.constants import GENE\n    >>> from pybel_tools.integration import overlay_type_data\n    >>> from pybel_tools.summary import rank_subgraph_by_node_filter\n    >>> import pandas as pd\n    >>> graph = from_pickle('~/dev/bms/aetionomy/alzheimers.gpickle')\n    >>> df = pd.read_csv('~/dev/bananas/data/alzheimers_dgxp.csv', columns=['Gene', 'log2fc'])\n    >>> data = {gene: log2fc for _, gene, log2fc in df.itertuples()}\n    >>> overlay_type_data(graph, data, 'log2fc', GENE, 'HGNC', impute=0.0)\n    >>> results = rank_subgraph_by_node_filter(graph, lambda g, n: 1.3 < abs(g[n]['log2fc']))\n    \"\"\"\n    r1 = group_nodes_by_annotation_filtered(graph, node_predicates=node_predicates, annotation=annotation)\n    r2 = count_dict_values(r1)\n    # TODO use instead: r2.most_common()\n    return sorted(r2.items(), key=itemgetter(1), reverse=reverse)", "response": "Rank subgraphs by which have the most nodes matching a given filter."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrendering the graph as JavaScript in a Jupyter Notebook.", "response": "def to_jupyter(graph: BELGraph, chart: Optional[str] = None) -> Javascript:\n    \"\"\"Render the graph as JavaScript in a Jupyter Notebook.\"\"\"\n    with open(os.path.join(HERE, 'render_with_javascript.js'), 'rt') as f:\n        js_template = Template(f.read())\n\n    return Javascript(js_template.render(**_get_context(graph, chart=chart)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_html(graph: BELGraph, chart: Optional[str] = None) -> str:\n    with open(os.path.join(HERE, 'index.html'), 'rt') as f:\n        html_template = Template(f.read())\n\n    return html_template.render(**_get_context(graph, chart=chart))", "response": "Render the graph as an HTML string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prerender(graph: BELGraph) -> Mapping[str, Mapping[str, Any]]:\n    import bio2bel_hgnc\n    from bio2bel_hgnc.models import HumanGene\n\n    graph: BELGraph = graph.copy()\n    enrich_protein_and_rna_origins(graph)\n    collapse_all_variants(graph)\n    genes: Set[Gene] = get_nodes_by_function(graph, GENE)\n    hgnc_symbols = {\n        gene.name\n        for gene in genes\n        if gene.namespace.lower() == 'hgnc'\n    }\n\n    result = {}\n\n    hgnc_manager = bio2bel_hgnc.Manager()\n    human_genes = (\n        hgnc_manager.session\n            .query(HumanGene.symbol, HumanGene.location)\n            .filter(HumanGene.symbol.in_(hgnc_symbols))\n            .all()\n    )\n    for human_gene in human_genes:\n        result[human_gene.symbol] = {\n            'name': human_gene.symbol,\n            'chr': (\n                human_gene.location.split('q')[0]\n                if 'q' in human_gene.location else\n                human_gene.location.split('p')[0]\n            ),\n        }\n\n    df = get_df()\n\n    for _, (gene_id, symbol, start, stop) in df[df['Symbol'].isin(hgnc_symbols)].iterrows():\n        result[symbol]['start'] = start\n        result[symbol]['stop'] = stop\n\n    return result", "response": "Generate the annotations JSON for Ideogram."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplots your graph summary statistics on the given axes.", "response": "def plot_summary_axes(graph: BELGraph, lax, rax, logx=True):\n    \"\"\"Plots your graph summary statistics on the given axes.\n\n    After, you should run :func:`plt.tight_layout` and you must run :func:`plt.show` to view.\n\n    Shows:\n    1. Count of nodes, grouped by function type\n    2. Count of edges, grouped by relation type\n\n    :param pybel.BELGraph graph: A BEL graph\n    :param lax: An axis object from matplotlib\n    :param rax: An axis object from matplotlib\n\n    Example usage:\n\n    >>> import matplotlib.pyplot as plt\n    >>> from pybel import from_pickle\n    >>> from pybel_tools.summary import plot_summary_axes\n    >>> graph = from_pickle('~/dev/bms/aetionomy/parkinsons.gpickle')\n    >>> fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n    >>> plot_summary_axes(graph, axes[0], axes[1])\n    >>> plt.tight_layout()\n    >>> plt.show()\n    \"\"\"\n    ntc = count_functions(graph)\n    etc = count_relations(graph)\n\n    df = pd.DataFrame.from_dict(dict(ntc), orient='index')\n    df_ec = pd.DataFrame.from_dict(dict(etc), orient='index')\n\n    df.sort_values(0, ascending=True).plot(kind='barh', logx=logx, ax=lax)\n    lax.set_title('Number of nodes: {}'.format(graph.number_of_nodes()))\n\n    df_ec.sort_values(0, ascending=True).plot(kind='barh', logx=logx, ax=rax)\n    rax.set_title('Number of edges: {}'.format(graph.number_of_edges()))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_summary(graph: BELGraph, plt, logx=True, **kwargs):\n    fig, axes = plt.subplots(1, 2, **kwargs)\n    lax = axes[0]\n    rax = axes[1]\n\n    plot_summary_axes(graph, lax, rax, logx=logx)\n    plt.tight_layout()\n\n    return fig, axes", "response": "Plots your graph summary statistics."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove nodes with the given function and namespace.", "response": "def remove_nodes_by_function_namespace(graph: BELGraph, func: str, namespace: Strings) -> None:\n    \"\"\"Remove nodes with the given function and namespace.\n\n    This might be useful to exclude information learned about distant species, such as excluding all information\n    from MGI and RGD in diseases where mice and rats don't give much insight to the human disease mechanism.\n    \"\"\"\n    remove_filtered_nodes(graph, function_namespace_inclusion_builder(func, namespace))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef preprocessing_br_projection_excel(path: str) -> pd.DataFrame:\n    if not os.path.exists(path):\n        raise ValueError(\"Error: %s file not found\" % path)\n\n    return pd.read_excel(path, sheetname=0, header=0)", "response": "Preprocess the excel file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_nift_values() -> Mapping[str, str]:\n    r = get_bel_resource(NIFT)\n    return {\n        name.lower(): name\n        for name in r['Values']\n    }", "response": "Extract the list of NIFT names from the BEL resource and build a dictionary mapping from the lowercased version to uppercase version."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_neurommsig_bel(file,\n                         df: pd.DataFrame,\n                         disease: str,\n                         nift_values: Mapping[str, str],\n                         ):\n    \"\"\"Writes the NeuroMMSigDB excel sheet to BEL\n\n    :param file: a file or file-like that can be writen to\n    :param df:\n    :param disease:\n    :param nift_values: a dictionary of lowercased to normal names in NIFT\n    \"\"\"\n    write_neurommsig_biolerplate(disease, file)\n\n    missing_features = set()\n    fixed_caps = set()\n    nift_value_originals = set(nift_values.values())\n\n    graph = BELGraph(\n        name=f'NeuroMMSigDB for {disease}',\n        description=f'SNP and Clinical Features for Subgraphs in {disease}',\n        authors='Daniel Domingo-Fern\u00e1ndez, Charles Tapley Hoyt, Mufassra Naz, Aybuge Altay, Anandhi Iyappan',\n        contact='daniel.domingo.fernandez@scai.fraunhofer.de',\n        version=time.strftime('%Y%m%d'),\n    )\n\n    for pathway, pathway_df in df.groupby(pathway_column):\n        sorted_pathway_df = pathway_df.sort_values(genes_column)\n        sliced_df = sorted_pathway_df[columns].itertuples()\n\n        for _, gene, pubmeds, lit_snps, gwas_snps, ld_block_snps, clinical_features, clinical_snps in sliced_df:\n            gene = ensure_quotes(gene)\n\n            for snp in itt.chain(lit_snps or [], gwas_snps or [], ld_block_snps or [], clinical_snps or []):\n                if not snp.strip():\n                    continue\n                graph.add_association(\n                    Gene('HGNC', gene),\n                    Gene('DBSNP', snp),\n                    evidence='Serialized from NeuroMMSigDB',\n                    citation='28651363',\n                    annotations={\n                        'MeSHDisease': disease,\n                    },\n                )\n\n            for clinical_feature in clinical_features or []:\n                if not clinical_feature.strip():\n                    continue\n\n                if clinical_feature.lower() not in nift_values:\n                    missing_features.add(clinical_feature)\n                    continue\n\n                if clinical_feature not in nift_value_originals:\n                    fixed_caps.add((clinical_feature, nift_values[clinical_feature.lower()]))\n                    clinical_feature = nift_values[clinical_feature.lower()]  # fix capitalization\n\n                graph.add_association(\n                    Gene('HGNC', gene),\n                    Abundance('NIFT', clinical_feature),\n                    evidence='Serialized from NeuroMMSigDB',\n                    citation='28651363',\n                    annotations={\n                        'MeSHDisease': disease,\n                    },\n                )\n\n                if clinical_snps:\n                    for clinical_snp in clinical_snps:\n                        graph.add_association(\n                            Gene('DBSNP', clinical_snp),\n                            Abundance('NIFT', clinical_feature),\n                            evidence='Serialized from NeuroMMSigDB',\n                            citation='28651363',\n                            annotations={\n                                'MeSHDisease': disease,\n                            },\n                        )\n\n    if missing_features:\n        log.warning('Missing Features in %s', disease)\n        for feature in missing_features:\n            log.warning(feature)\n\n    if fixed_caps:\n        log.warning('Fixed capitalization')\n        for broken, fixed in fixed_caps:\n            log.warning('%s -> %s', broken, fixed)", "response": "Writes the NeuroMMSigDB excel sheet to file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_contradiction_summary(graph: BELGraph) -> Iterable[Tuple[BaseEntity, BaseEntity, str]]:\n    for u, v in set(graph.edges()):\n        relations = {data[RELATION] for data in graph[u][v].values()}\n        if relation_set_has_contradictions(relations):\n            yield u, v, relations", "response": "Yields triplets of source node target node and set of relations that have multiple contradictory relations."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_regulatory_pairs(graph: BELGraph) -> Set[NodePair]:\n    cg = get_causal_subgraph(graph)\n\n    results = set()\n\n    for u, v, d in cg.edges(data=True):\n        if d[RELATION] not in CAUSAL_INCREASE_RELATIONS:\n            continue\n\n        if cg.has_edge(v, u) and any(dd[RELATION] in CAUSAL_DECREASE_RELATIONS for dd in cg[v][u].values()):\n            results.add((u, v))\n\n    return results", "response": "Find pairs of nodes that have mutual causal edges that are regulating each other such that A - | B - | A."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_chaotic_pairs(graph: BELGraph) -> SetOfNodePairs:\n    cg = get_causal_subgraph(graph)\n\n    results = set()\n\n    for u, v, d in cg.edges(data=True):\n        if d[RELATION] not in CAUSAL_INCREASE_RELATIONS:\n            continue\n\n        if cg.has_edge(v, u) and any(dd[RELATION] in CAUSAL_INCREASE_RELATIONS for dd in cg[v][u].values()):\n            results.add(tuple(sorted([u, v], key=str)))\n\n    return results", "response": "Find pairs of nodes that have mutual causal edges that are increasing each other such that A - > B and B - > A."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_correlation_graph(graph: BELGraph) -> Graph:\n    result = Graph()\n\n    for u, v, d in graph.edges(data=True):\n        if d[RELATION] not in CORRELATIVE_RELATIONS:\n            continue\n\n        if not result.has_edge(u, v):\n            result.add_edge(u, v, **{d[RELATION]: True})\n\n        elif d[RELATION] not in result[u][v]:\n            log.log(5, 'broken correlation relation for %s, %s', u, v)\n            result[u][v][d[RELATION]] = True\n            result[v][u][d[RELATION]] = True\n\n    return result", "response": "Extract an undirected graph of only correlative relationships."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a set of all the correlation triangles pointed by the given node.", "response": "def get_correlation_triangles(graph: BELGraph) -> SetOfNodeTriples:\n    \"\"\"Return a set of all triangles pointed by the given node.\"\"\"\n    return {\n        tuple(sorted([n, u, v], key=str))\n        for n in graph\n        for u, v in itt.combinations(graph[n], 2)\n        if graph.has_edge(u, v)\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a set of triples representing the 3 - cycle nodes in a directional graph.", "response": "def get_triangles(graph: DiGraph) -> SetOfNodeTriples:\n    \"\"\"Get a set of triples representing the 3-cycles from a directional graph.\n\n    Each 3-cycle is returned once, with nodes in sorted order.\n    \"\"\"\n    return {\n        tuple(sorted([a, b, c], key=str))\n        for a, b in graph.edges()\n        for c in graph.successors(b)\n        if graph.has_edge(c, a)\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nyielding all unstable correlation triples in a given graph.", "response": "def get_separate_unstable_correlation_triples(graph: BELGraph) -> Iterable[NodeTriple]:\n    \"\"\"Yield all triples of nodes A, B, C such that ``A pos B``, ``A pos C``, and ``B neg C``.\n\n    :return: An iterator over triples of unstable graphs, where the second two are negative\n    \"\"\"\n    cg = get_correlation_graph(graph)\n\n    for a, b, c in get_correlation_triangles(cg):\n        if POSITIVE_CORRELATION in cg[a][b] and POSITIVE_CORRELATION in cg[b][c] and NEGATIVE_CORRELATION in \\\n                cg[a][c]:\n            yield b, a, c\n        if POSITIVE_CORRELATION in cg[a][b] and NEGATIVE_CORRELATION in cg[b][c] and POSITIVE_CORRELATION in \\\n                cg[a][c]:\n            yield a, b, c\n        if NEGATIVE_CORRELATION in cg[a][b] and POSITIVE_CORRELATION in cg[b][c] and POSITIVE_CORRELATION in \\\n                cg[a][c]:\n            yield c, a, b"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nyields all non - negative non - negative non - negative correlation triples in the graph.", "response": "def get_mutually_unstable_correlation_triples(graph: BELGraph) -> Iterable[NodeTriple]:\n    \"\"\"Yield triples of nodes (A, B, C) such that ``A neg B``, ``B neg C``, and ``C neg A``.\"\"\"\n    cg = get_correlation_graph(graph)\n\n    for a, b, c in get_correlation_triangles(cg):\n        if all(NEGATIVE_CORRELATION in x for x in (cg[a][b], cg[b][c], cg[a][c])):\n            yield a, b, c"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying Jens transformation to the graph.", "response": "def jens_transformation_alpha(graph: BELGraph) -> DiGraph:\n    \"\"\"Apply Jens' transformation (Type 1) to the graph.\n\n    1. Induce a sub-graph over causal + correlative edges\n    2. Transform edges by the following rules:\n        - increases => increases\n        - decreases => backwards increases\n        - positive correlation => two way increases\n        - negative correlation => delete\n\n    The resulting graph can be used to search for 3-cycles, which now symbolize unstable triplets where ``A -> B``,\n    ``A -| C`` and ``B positiveCorrelation C``.\n    \"\"\"\n    result = DiGraph()\n\n    for u, v, d in graph.edges(data=True):\n        relation = d[RELATION]\n\n        if relation == POSITIVE_CORRELATION:\n            result.add_edge(u, v)\n            result.add_edge(v, u)\n\n        elif relation in CAUSAL_INCREASE_RELATIONS:\n            result.add_edge(u, v)\n\n        elif relation in CAUSAL_DECREASE_RELATIONS:\n            result.add_edge(v, u)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply Jens - Correlation transformation to the graph.", "response": "def jens_transformation_beta(graph: BELGraph) -> DiGraph:\n    \"\"\"Apply Jens' Transformation (Type 2) to the graph.\n\n    1. Induce a sub-graph over causal and correlative relations\n    2. Transform edges with the following rules:\n        - increases => backwards decreases\n        - decreases => decreases\n        - positive correlation => delete\n        - negative correlation => two way decreases\n\n    The resulting graph can be used to search for 3-cycles, which now symbolize stable triples where ``A -> B``,\n    ``A -| C`` and ``B negativeCorrelation C``.\n    \"\"\"\n    result = DiGraph()\n\n    for u, v, d in graph.edges(data=True):\n        relation = d[RELATION]\n\n        if relation == NEGATIVE_CORRELATION:\n            result.add_edge(u, v)\n            result.add_edge(v, u)\n\n        elif relation in CAUSAL_INCREASE_RELATIONS:\n            result.add_edge(v, u)\n\n        elif relation in CAUSAL_DECREASE_RELATIONS:\n            result.add_edge(u, v)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_jens_unstable(graph: BELGraph) -> Iterable[NodeTriple]:\n    r = jens_transformation_alpha(graph)\n    return get_triangles(r)", "response": "Returns an iterable of nodes that are not in Jens unstable state."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef summarize_stability(graph: BELGraph) -> Mapping[str, int]:\n    regulatory_pairs = get_regulatory_pairs(graph)\n    chaotic_pairs = get_chaotic_pairs(graph)\n    dampened_pairs = get_dampened_pairs(graph)\n    contraditory_pairs = get_contradiction_summary(graph)\n    separately_unstable_triples = get_separate_unstable_correlation_triples(graph)\n    mutually_unstable_triples = get_mutually_unstable_correlation_triples(graph)\n    jens_unstable_triples = get_jens_unstable(graph)\n    increase_mismatch_triples = get_increase_mismatch_triplets(graph)\n    decrease_mismatch_triples = get_decrease_mismatch_triplets(graph)\n    chaotic_triples = get_chaotic_triplets(graph)\n    dampened_triples = get_dampened_triplets(graph)\n\n    return {\n        'Regulatory Pairs': _count_or_len(regulatory_pairs),\n        'Chaotic Pairs': _count_or_len(chaotic_pairs),\n        'Dampened Pairs': _count_or_len(dampened_pairs),\n        'Contradictory Pairs': _count_or_len(contraditory_pairs),\n        'Separately Unstable Triples': _count_or_len(separately_unstable_triples),\n        'Mutually Unstable Triples': _count_or_len(mutually_unstable_triples),\n        'Jens Unstable Triples': _count_or_len(jens_unstable_triples),\n        'Increase Mismatch Triples': _count_or_len(increase_mismatch_triples),\n        'Decrease Mismatch Triples': _count_or_len(decrease_mismatch_triples),\n        'Chaotic Triples': _count_or_len(chaotic_triples),\n        'Dampened Triples': _count_or_len(dampened_triples)\n    }", "response": "Summarize the stability of the graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nflattens the complex or composite abundance.", "response": "def flatten_list_abundance(node: ListAbundance) -> ListAbundance:\n    \"\"\"Flattens the complex or composite abundance.\"\"\"\n    return node.__class__(list(chain.from_iterable(\n        (\n            flatten_list_abundance(member).members\n            if isinstance(member, ListAbundance) else\n            [member]\n        )\n        for member in node.members\n    )))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexpand all list abundances to simple subject - predicate - object networks.", "response": "def list_abundance_cartesian_expansion(graph: BELGraph) -> None:\n    \"\"\"Expand all list abundances to simple subject-predicate-object networks.\"\"\"\n    for u, v, k, d in list(graph.edges(keys=True, data=True)):\n        if CITATION not in d:\n            continue\n\n        if isinstance(u, ListAbundance) and isinstance(v, ListAbundance):\n            for u_member, v_member in itt.product(u.members, v.members):\n                graph.add_qualified_edge(\n                    u_member, v_member,\n                    relation=d[RELATION],\n                    citation=d.get(CITATION),\n                    evidence=d.get(EVIDENCE),\n                    annotations=d.get(ANNOTATIONS),\n                )\n\n        elif isinstance(u, ListAbundance):\n            for member in u.members:\n                graph.add_qualified_edge(\n                    member, v,\n                    relation=d[RELATION],\n                    citation=d.get(CITATION),\n                    evidence=d.get(EVIDENCE),\n                    annotations=d.get(ANNOTATIONS),\n                )\n\n        elif isinstance(v, ListAbundance):\n            for member in v.members:\n                graph.add_qualified_edge(\n                    u, member,\n                    relation=d[RELATION],\n                    citation=d.get(CITATION),\n                    evidence=d.get(EVIDENCE),\n                    annotations=d.get(ANNOTATIONS),\n                )\n\n    _remove_list_abundance_nodes(graph)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _reaction_cartesion_expansion_unqualified_helper(\n        graph: BELGraph,\n        u: BaseEntity,\n        v: BaseEntity,\n        d: dict,\n) -> None:\n    \"\"\"Helper to deal with cartension expansion in unqualified edges.\"\"\"\n    if isinstance(u, Reaction) and isinstance(v, Reaction):\n        enzymes = _get_catalysts_in_reaction(u) | _get_catalysts_in_reaction(v)\n\n        for reactant, product in chain(itt.product(u.reactants, u.products),\n                                       itt.product(v.reactants, v.products)):\n            if reactant in enzymes or product in enzymes:\n                continue\n\n            graph.add_unqualified_edge(\n                reactant, product, INCREASES\n            )\n        for product, reactant in itt.product(u.products, u.reactants):\n\n            if reactant in enzymes or product in enzymes:\n                continue\n\n            graph.add_unqualified_edge(\n                product, reactant, d[RELATION],\n            )\n\n    elif isinstance(u, Reaction):\n\n        enzymes = _get_catalysts_in_reaction(u)\n\n        for product in u.products:\n\n            # Skip create increases edges between enzymes\n            if product in enzymes:\n                continue\n\n            # Only add edge between v and reaction if the node is not part of the reaction\n            # In practice skips hasReactant, hasProduct edges\n            if v not in u.products and v not in u.reactants:\n                graph.add_unqualified_edge(\n                    product, v, INCREASES\n                )\n            for reactant in u.reactants:\n                graph.add_unqualified_edge(\n                    reactant, product, INCREASES\n                )\n\n    elif isinstance(v, Reaction):\n\n        enzymes = _get_catalysts_in_reaction(v)\n\n        for reactant in v.reactants:\n\n            # Skip create increases edges between enzymes\n            if reactant in enzymes:\n                continue\n\n            # Only add edge between v and reaction if the node is not part of the reaction\n            # In practice skips hasReactant, hasProduct edges\n            if u not in v.products and u not in v.reactants:\n                graph.add_unqualified_edge(\n                    u, reactant, INCREASES\n                )\n            for product in v.products:\n                graph.add_unqualified_edge(\n                    reactant, product, INCREASES\n                )", "response": "Helper to deal with cartension expansion in unqualified edges."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns nodes that are both in reactants and reactions in a reaction.", "response": "def _get_catalysts_in_reaction(reaction: Reaction) -> Set[BaseAbundance]:\n    \"\"\"Return nodes that are both in reactants and reactions in a reaction.\"\"\"\n    return {\n        reactant\n        for reactant in reaction.reactants\n        if reactant in reaction.products\n    }"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reaction_cartesian_expansion(graph: BELGraph, accept_unqualified_edges: bool = True) -> None:\n    for u, v, d in list(graph.edges(data=True)):\n        # Deal with unqualified edges\n        if CITATION not in d and accept_unqualified_edges:\n            _reaction_cartesion_expansion_unqualified_helper(graph, u, v, d)\n            continue\n\n        if isinstance(u, Reaction) and isinstance(v, Reaction):\n            catalysts = _get_catalysts_in_reaction(u) | _get_catalysts_in_reaction(v)\n\n            for reactant, product in chain(itt.product(u.reactants, u.products), itt.product(v.reactants, v.products)):\n                if reactant in catalysts or product in catalysts:\n                    continue\n                graph.add_increases(\n                    reactant, product,\n                    citation=d.get(CITATION),\n                    evidence=d.get(EVIDENCE),\n                    annotations=d.get(ANNOTATIONS),\n                )\n\n            for product, reactant in itt.product(u.products, u.reactants):\n                if reactant in catalysts or product in catalysts:\n                    continue\n\n                graph.add_qualified_edge(\n                    product, reactant,\n                    relation=d[RELATION],\n                    citation=d.get(CITATION),\n                    evidence=d.get(EVIDENCE),\n                    annotations=d.get(ANNOTATIONS),\n                )\n\n        elif isinstance(u, Reaction):\n            catalysts = _get_catalysts_in_reaction(u)\n\n            for product in u.products:\n                # Skip create increases edges between enzymes\n                if product in catalysts:\n                    continue\n\n                # Only add edge between v and reaction if the node is not part of the reaction\n                # In practice skips hasReactant, hasProduct edges\n                if v not in u.products and v not in u.reactants:\n                    graph.add_increases(\n                        product, v,\n                        citation=d.get(CITATION),\n                        evidence=d.get(EVIDENCE),\n                        annotations=d.get(ANNOTATIONS),\n                    )\n\n                for reactant in u.reactants:\n                    graph.add_increases(\n                        reactant, product,\n                        citation=d.get(CITATION),\n                        evidence=d.get(EVIDENCE),\n                        annotations=d.get(ANNOTATIONS),\n                    )\n\n        elif isinstance(v, Reaction):\n            for reactant in v.reactants:\n                catalysts = _get_catalysts_in_reaction(v)\n\n                # Skip create increases edges between enzymes\n                if reactant in catalysts:\n                    continue\n\n                # Only add edge between v and reaction if the node is not part of the reaction\n                # In practice skips hasReactant, hasProduct edges\n                if u not in v.products and u not in v.reactants:\n                    graph.add_increases(\n                        u, reactant,\n                        citation=d.get(CITATION),\n                        evidence=d.get(EVIDENCE),\n                        annotations=d.get(ANNOTATIONS),\n                    )\n                for product in v.products:\n                    graph.add_increases(\n                        reactant, product,\n                        citation=d.get(CITATION),\n                        evidence=d.get(EVIDENCE),\n                        annotations=d.get(ANNOTATIONS),\n                    )\n\n    _remove_reaction_nodes(graph)", "response": "Expand all reactions to simple subject - predicate - object networks."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insert_graph(self, graph: BELGraph, **_kwargs) -> Network:\n        result = _Namespace()\n        result.id = len(self.networks)\n\n        self.networks[result.id] = graph\n\n        return result", "response": "Insert a graph and return the resulting ORM object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting several graphs by their identifiers.", "response": "def get_graphs_by_ids(self, network_ids: Iterable[int]) -> List[BELGraph]:\n        \"\"\"Get several graphs by their identifiers.\"\"\"\n        return [\n            self.networks[network_id]\n            for network_id in network_ids\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _generate_citation_dict(graph: BELGraph) -> Mapping[str, Mapping[Tuple[BaseEntity, BaseEntity], str]]:\n    results = defaultdict(lambda: defaultdict(set))\n\n    for u, v, data in graph.edges(data=True):\n        if CITATION not in data:\n            continue\n        results[data[CITATION][CITATION_TYPE]][u, v].add(data[CITATION][CITATION_REFERENCE].strip())\n\n    return dict(results)", "response": "Prepare a citation data dictionary from a graph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_pmid_by_keyword(keyword: str,\n                        graph: Optional[BELGraph] = None,\n                        pubmed_identifiers: Optional[Set[str]] = None,\n                        ) -> Set[str]:\n    \"\"\"Get the set of PubMed identifiers beginning with the given keyword string.\n    \n    :param keyword: The beginning of a PubMed identifier\n    :param graph: A BEL graph\n    :param pubmed_identifiers: A set of pre-cached PubMed identifiers\n    :return: A set of PubMed identifiers starting with the given string\n    \"\"\"\n    if pubmed_identifiers is not None:\n        return {\n            pubmed_identifier\n            for pubmed_identifier in pubmed_identifiers\n            if pubmed_identifier.startswith(keyword)\n        }\n\n    if graph is None:\n        raise ValueError('Graph not supplied')\n\n    return {\n        pubmed_identifier\n        for pubmed_identifier in iterate_pubmed_identifiers(graph)\n        if pubmed_identifier.startswith(keyword)\n    }", "response": "Get the set of PubMed identifiers starting with the given keyword string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef count_citations(graph: BELGraph, **annotations) -> Counter:\n    citations = defaultdict(set)\n\n    annotation_dict_filter = build_edge_data_filter(annotations)\n\n    for u, v, _, d in filter_edges(graph, annotation_dict_filter):\n        if CITATION not in d:\n            continue\n\n        citations[u, v].add((d[CITATION][CITATION_TYPE], d[CITATION][CITATION_REFERENCE].strip()))\n\n    return Counter(itt.chain.from_iterable(citations.values()))", "response": "Counts the citations in a given graph based on a given set of annotations."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngrouping the citation counters by subgraphs induced by the annotation.", "response": "def count_citations_by_annotation(graph: BELGraph, annotation: str) -> Mapping[str, typing.Counter[str]]:\n    \"\"\"Group the citation counters by subgraphs induced by the annotation.\n\n    :param graph: A BEL graph\n    :param annotation: The annotation to use to group the graph\n    :return: A dictionary of Counters {subgraph name: Counter from {citation: frequency}}\n    \"\"\"\n    citations = defaultdict(lambda: defaultdict(set))\n    for u, v, data in graph.edges(data=True):\n        if not edge_has_annotation(data, annotation) or CITATION not in data:\n            continue\n\n        k = data[ANNOTATIONS][annotation]\n\n        citations[k][u, v].add((data[CITATION][CITATION_TYPE], data[CITATION][CITATION_REFERENCE].strip()))\n\n    return {k: Counter(itt.chain.from_iterable(v.values())) for k, v in citations.items()}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef count_author_publications(graph: BELGraph) -> typing.Counter[str]:\n    authors = group_as_dict(_iter_author_publiations(graph))\n    return Counter(count_dict_values(count_defaultdict(authors)))", "response": "Count the number of publications of each author to the given graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the set of authors that are a substring of the given keyword.", "response": "def get_authors_by_keyword(keyword: str, graph=None, authors=None) -> Set[str]:\n    \"\"\"Get authors for whom the search term is a substring.\n    \n    :param pybel.BELGraph graph: A BEL graph\n    :param keyword: The keyword to search the author strings for\n    :param set[str] authors: An optional set of pre-cached authors calculated from the graph\n    :return: A set of authors with the keyword as a substring\n    \"\"\"\n    keyword_lower = keyword.lower()\n\n    if authors is not None:\n        return {\n            author\n            for author in authors\n            if keyword_lower in author.lower()\n        }\n\n    if graph is None:\n        raise ValueError('Graph not supplied')\n\n    return {\n        author\n        for author in get_authors(graph)\n        if keyword_lower in author.lower()\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngroup the author counters by sub - graphs induced by the annotation.", "response": "def count_authors_by_annotation(graph: BELGraph, annotation: str = 'Subgraph') -> Mapping[str, typing.Counter[str]]:\n    \"\"\"Group the author counters by sub-graphs induced by the annotation.\n\n    :param graph: A BEL graph\n    :param annotation: The annotation to use to group the graph\n    :return: A dictionary of Counters {subgraph name: Counter from {author: frequency}}\n    \"\"\"\n    authors = group_as_dict(_iter_authors_by_annotation(graph, annotation=annotation))\n    return count_defaultdict(authors)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_evidences_by_pmid(graph: BELGraph, pmids: Union[str, Iterable[str]]):\n    result = defaultdict(set)\n\n    for _, _, _, data in filter_edges(graph, build_pmid_inclusion_filter(pmids)):\n        result[data[CITATION][CITATION_REFERENCE]].add(data[EVIDENCE])\n\n    return dict(result)", "response": "Get a dictionary from the given PubMed identifiers to the sets of all evidence strings associated with each\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncount the number of citations from each year.", "response": "def count_citation_years(graph: BELGraph) -> typing.Counter[int]:\n    \"\"\"Count the number of citations from each year.\"\"\"\n    result = defaultdict(set)\n\n    for _, _, data in graph.edges(data=True):\n        if CITATION not in data or CITATION_DATE not in data[CITATION]:\n            continue\n\n        try:\n            dt = _ensure_datetime(data[CITATION][CITATION_DATE])\n            result[dt.year].add((data[CITATION][CITATION_TYPE], data[CITATION][CITATION_REFERENCE]))\n        except Exception:\n            continue\n\n    return count_dict_values(result)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a citation timeline from the graph.", "response": "def get_citation_years(graph: BELGraph) -> List[Tuple[int, int]]:\n    \"\"\"Create a citation timeline counter from the graph.\"\"\"\n    return create_timeline(count_citation_years(graph))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncomplete the Counter timeline.", "response": "def create_timeline(year_counter: typing.Counter[int]) -> List[Tuple[int, int]]:\n    \"\"\"Complete the Counter timeline.\n\n    :param Counter year_counter: counter dict for each year\n    :return: complete timeline\n    \"\"\"\n    if not year_counter:\n        return []\n\n    from_year = min(year_counter) - 1\n    until_year = datetime.now().year + 1\n\n    return [\n        (year, year_counter.get(year, 0))\n        for year in range(from_year, until_year)\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncounts the confidences in the graph.", "response": "def count_confidences(graph: BELGraph) -> typing.Counter[str]:\n    \"\"\"Count the confidences in the graph.\"\"\"\n    return Counter(\n        (\n            'None'\n            if ANNOTATIONS not in data or 'Confidence' not in data[ANNOTATIONS] else\n            list(data[ANNOTATIONS]['Confidence'])[0]\n        )\n        for _, _, data in graph.edges(data=True)\n        if CITATION in data  # don't bother with unqualified statements\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\noverwrite all PubMed citations with values from NCBI s eUtils lookup service.", "response": "def enrich_pubmed_citations(graph: BELGraph, manager: Manager) -> Set[str]:\n    \"\"\"Overwrite all PubMed citations with values from NCBI's eUtils lookup service.\n\n    :return: A set of PMIDs for which the eUtils service crashed\n    \"\"\"\n    pmids = get_pubmed_identifiers(graph)\n    pmid_data, errors = get_citations_by_pmids(manager=manager, pmids=pmids)\n\n    for u, v, k in filter_edges(graph, has_pubmed):\n        pmid = graph[u][v][k][CITATION][CITATION_REFERENCE].strip()\n\n        if pmid not in pmid_data:\n            log.warning('Missing data for PubMed identifier: %s', pmid)\n            errors.add(pmid)\n            continue\n\n        graph[u][v][k][CITATION].update(pmid_data[pmid])\n\n    return errors"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the context of a subgraph from the universe of all knowledge.", "response": "def update_context(universe: BELGraph, graph: BELGraph):\n    \"\"\"Update the context of a subgraph from the universe of all knowledge.\"\"\"\n    for namespace in get_namespaces(graph):\n        if namespace in universe.namespace_url:\n            graph.namespace_url[namespace] = universe.namespace_url[namespace]\n        elif namespace in universe.namespace_pattern:\n            graph.namespace_pattern[namespace] = universe.namespace_pattern[namespace]\n        else:\n            log.warning('namespace: %s missing from universe', namespace)\n\n    for annotation in get_annotations(graph):\n        if annotation in universe.annotation_url:\n            graph.annotation_url[annotation] = universe.annotation_url[annotation]\n        elif annotation in universe.annotation_pattern:\n            graph.annotation_pattern[annotation] = universe.annotation_pattern[annotation]\n        elif annotation in universe.annotation_list:\n            graph.annotation_list[annotation] = universe.annotation_list[annotation]\n        else:\n            log.warning('annotation: %s missing from universe', annotation)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef highlight_nodes(graph: BELGraph, nodes: Optional[Iterable[BaseEntity]] = None, color: Optional[str]=None):\n    color = color or NODE_HIGHLIGHT_DEFAULT_COLOR\n    for node in nodes if nodes is not None else graph:\n        graph.node[node][NODE_HIGHLIGHT] = color", "response": "Adds a highlight tag to the given nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns if the given node is highlighted.", "response": "def is_node_highlighted(graph: BELGraph, node: BaseEntity) -> bool:\n    \"\"\"Returns if the given node is highlighted.\n\n    :param graph: A BEL graph\n    :param node: A BEL node\n    :type node: tuple\n    :return: Does the node contain highlight information?\n    :rtype: bool\n    \"\"\"\n    return NODE_HIGHLIGHT in graph.node[node]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_highlight_nodes(graph: BELGraph, nodes: Optional[Iterable[BaseEntity]]=None) -> None:\n    for node in graph if nodes is None else nodes:\n        if is_node_highlighted(graph, node):\n            del graph.node[node][NODE_HIGHLIGHT]", "response": "Removes the highlight from the given nodes if none given."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a highlight tag to the given edges.", "response": "def highlight_edges(graph: BELGraph, edges=None, color: Optional[str]=None) -> None:\n    \"\"\"Adds a highlight tag to the given edges.\n\n    :param graph: A BEL graph\n    :param edges: The edges (4-tuples of u, v, k, d) to add a highlight tag on\n    :type edges: iter[tuple]\n    :param str color: The color to highlight (use something that works with CSS)\n    \"\"\"\n    color = color or EDGE_HIGHLIGHT_DEFAULT_COLOR\n    for u, v, k, d in edges if edges is not None else graph.edges(keys=True, data=True):\n        graph[u][v][k][EDGE_HIGHLIGHT] = color"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_edge_highlighted(graph: BELGraph, u, v, k) -> bool:\n    return EDGE_HIGHLIGHT in graph[u][v][k]", "response": "Returns True if the given edge is highlighted."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_highlight_edges(graph: BELGraph, edges=None):\n    for u, v, k, _ in graph.edges(keys=True, data=True) if edges is None else edges:\n        if is_edge_highlighted(graph, u, v, k):\n            del graph[u][v][k][EDGE_HIGHLIGHT]", "response": "Removes the highlight from the given edges or all edges if none given."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhighlight all nodes and edges in the given graph that are in the given universe.", "response": "def highlight_subgraph(universe: BELGraph, graph: BELGraph):\n    \"\"\"Highlight all nodes/edges in the universe that in the given graph.\n\n    :param universe: The universe of knowledge\n    :param graph: The BEL graph to mutate\n    \"\"\"\n    highlight_nodes(universe, graph)\n    highlight_edges(universe, graph.edges())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_highlight_subgraph(graph: BELGraph, subgraph: BELGraph):\n    remove_highlight_nodes(graph, subgraph.nodes())\n    remove_highlight_edges(graph, subgraph.edges())", "response": "Remove the highlight from all nodes and edges in the subgraph."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the out - edges to the given node that are causal.", "response": "def get_causal_out_edges(\n        graph: BELGraph,\n        nbunch: Union[BaseEntity, Iterable[BaseEntity]],\n) -> Set[Tuple[BaseEntity, BaseEntity]]:\n    \"\"\"Get the out-edges to the given node that are causal.\n\n    :return: A set of (source, target) pairs where the source is the given node\n    \"\"\"\n    return {\n        (u, v)\n        for u, v, k, d in graph.out_edges(nbunch, keys=True, data=True)\n        if is_causal_relation(graph, u, v, k, d)\n    }"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a set of all nodes that have a causal origin from within the graph.", "response": "def get_causal_source_nodes(graph: BELGraph, func: str) -> Set[BaseEntity]:\n    \"\"\"Return a set of all nodes that have an in-degree of 0.\n\n    This likely means that it is an external perturbagen and is not known to have any causal origin from within the\n    biological system. These nodes are useful to identify because they generally don't provide any mechanistic insight.\n    \"\"\"\n    return {\n        node\n        for node in graph\n        if node.function == func and is_causal_source(graph, node)\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a set of all nodes that are causal central.", "response": "def get_causal_central_nodes(graph: BELGraph, func: str) -> Set[BaseEntity]:\n    \"\"\"Return a set of all nodes that have both an in-degree > 0 and out-degree > 0.\n\n    This means that they are an integral part of a pathway, since they are both produced and consumed.\n    \"\"\"\n    return {\n        node\n        for node in graph\n        if node.function == func and is_causal_central(graph, node)\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_causal_sink_nodes(graph: BELGraph, func) -> Set[BaseEntity]:\n    return {\n        node\n        for node in graph\n        if node.function == func and is_causal_sink(graph, node)\n    }", "response": "Returns a set of all causal sink nodes that have a causal out - degree of 0."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the most common number of nodes in a graph.", "response": "def count_top_centrality(graph: BELGraph, number: Optional[int] = 30) -> Mapping[BaseEntity, int]:\n    \"\"\"Get top centrality dictionary.\"\"\"\n    dd = nx.betweenness_centrality(graph)\n    dc = Counter(dd)\n    return dict(dc.most_common(number))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_modifications_count(graph: BELGraph) -> Mapping[str, int]:\n    return remove_falsy_values({\n        'Translocations': len(get_translocated(graph)),\n        'Degradations': len(get_degradations(graph)),\n        'Molecular Activities': len(get_activities(graph)),\n    })", "response": "Get a modifications count dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving all values that are zero.", "response": "def remove_falsy_values(counter: Mapping[Any, int]) -> Mapping[Any, int]:\n    \"\"\"Remove all values that are zero.\"\"\"\n    return {\n        label: count\n        for label, count in counter.items()\n        if count\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _collapse_variants_by_function(graph: BELGraph, func: str) -> None:\n    for parent_node, variant_node, data in graph.edges(data=True):\n        if data[RELATION] == HAS_VARIANT and parent_node.function == func:\n            collapse_pair(graph, from_node=variant_node, to_node=parent_node)", "response": "Collapse all of the given functions s variants to their parents in - place."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrewire all protein variants to Gene objects.", "response": "def rewire_variants_to_genes(graph: BELGraph) -> None:\n    \"\"\"Find all protein variants that are pointing to a gene and not a protein and fixes them by changing their\n    function to be :data:`pybel.constants.GENE`, in place\n\n    A use case is after running :func:`collapse_to_genes`.\n    \"\"\"\n    mapping = {}\n\n    for node in graph:\n        if not isinstance(node, Protein) or not node.variants:\n            continue\n\n        mapping[node] = Gene(\n            name=node.name,\n            namespace=node.namespace,\n            identifier=node.identifier,\n            variants=node.variants,\n        )\n\n    nx.relabel_nodes(graph, mapping, copy=False)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _collapse_edge_passing_predicates(graph: BELGraph, edge_predicates: EdgePredicates = None) -> None:\n    for u, v, _ in filter_edges(graph, edge_predicates=edge_predicates):\n        collapse_pair(graph, survivor=u, victim=v)", "response": "Collapse all edges passing the given edge predicates."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncollapses pairs of nodes with the given namespaces that have the given relationship.", "response": "def _collapse_edge_by_namespace(graph: BELGraph,\n                                victim_namespaces: Strings,\n                                survivor_namespaces: str,\n                                relations: Strings) -> None:\n    \"\"\"Collapse pairs of nodes with the given namespaces that have the given relationship.\n\n    :param graph: A BEL Graph\n    :param victim_namespaces: The namespace(s) of the node to collapse\n    :param survivor_namespaces: The namespace of the node to keep\n    :param relations: The relation(s) to search\n    \"\"\"\n    relation_filter = build_relation_predicate(relations)\n    source_namespace_filter = build_source_namespace_filter(victim_namespaces)\n    target_namespace_filter = build_target_namespace_filter(survivor_namespaces)\n\n    edge_predicates = [\n        relation_filter,\n        source_namespace_filter,\n        target_namespace_filter\n    ]\n\n    _collapse_edge_passing_predicates(graph, edge_predicates=edge_predicates)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef collapse_equivalencies_by_namespace(graph: BELGraph, victim_namespace: Strings, survivor_namespace: str) -> None:\n    _collapse_edge_by_namespace(graph, victim_namespace, survivor_namespace, EQUIVALENT_TO)", "response": "Collapse pairs of nodes with the given namespaces that have equivalence relationships between them."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncollapse nodes with the given namespaces that have orthology relationships.", "response": "def collapse_orthologies_by_namespace(graph: BELGraph, victim_namespace: Strings, survivor_namespace: str) -> None:\n    \"\"\"Collapse pairs of nodes with the given namespaces that have orthology relationships.\n\n    :param graph: A BEL Graph\n    :param victim_namespace: The namespace(s) of the node to collapse\n    :param survivor_namespace: The namespace of the node to keep\n\n    To collapse all MGI nodes to their HGNC orthologs, use:\n    >>> collapse_orthologies_by_namespace('MGI', 'HGNC')\n\n\n    To collapse collapse both MGI and RGD nodes to their HGNC orthologs, use:\n    >>> collapse_orthologies_by_namespace(['MGI', 'RGD'], 'HGNC')\n    \"\"\"\n    _collapse_edge_by_namespace(graph, victim_namespace, survivor_namespace, ORTHOLOGOUS)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncollapse all equivalence edges away from Entrez. Assumes well formed 2 - way equivalencies.", "response": "def collapse_entrez_equivalencies(graph: BELGraph):\n    \"\"\"Collapse all equivalence edges away from Entrez. Assumes well formed, 2-way equivalencies.\"\"\"\n    relation_filter = build_relation_predicate(EQUIVALENT_TO)\n    source_namespace_filter = build_source_namespace_filter(['EGID', 'EG', 'ENTREZ'])\n\n    edge_predicates = [\n        relation_filter,\n        source_namespace_filter,\n    ]\n\n    _collapse_edge_passing_predicates(graph, edge_predicates=edge_predicates)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncollapse consistent edges together.", "response": "def collapse_consistent_edges(graph: BELGraph):\n    \"\"\"Collapse consistent edges together.\n\n    .. warning:: This operation doesn't preserve evidences or other annotations\n    \"\"\"\n    for u, v in graph.edges():\n        relation = pair_is_consistent(graph, u, v)\n\n        if not relation:\n            continue\n\n        edges = [(u, v, k) for k in graph[u][v]]\n        graph.remove_edges_from(edges)\n        graph.add_edge(u, v, attr_dict={RELATION: relation})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef collapse_to_protein_interactions(graph: BELGraph) -> BELGraph:\n    rv: BELGraph = graph.copy()\n\n    collapse_to_genes(rv)\n\n    def is_edge_ppi(_: BELGraph, u: BaseEntity, v: BaseEntity, __: str) -> bool:\n        \"\"\"Check if an edge is a PPI.\"\"\"\n        return isinstance(u, Gene) and isinstance(v, Gene)\n\n    return get_subgraph_by_edge_filter(rv, edge_predicates=[has_polarity, is_edge_ppi])", "response": "Collapse a graph made of only causal gene and protein edges."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncollapsing all nodes with the same name merging namespaces by picking first alphabetical one.", "response": "def collapse_nodes_with_same_names(graph: BELGraph) -> None:\n    \"\"\"Collapse all nodes with the same name, merging namespaces by picking first alphabetical one.\"\"\"\n    survivor_mapping = defaultdict(set) # Collapse mapping dict\n    victims = set() # Things already mapped while iterating\n\n    it = tqdm(itt.combinations(graph, r=2), total=graph.number_of_nodes() * (graph.number_of_nodes() - 1) / 2)\n    for a, b in it:\n        if b in victims:\n            continue\n\n        a_name, b_name = a.get(NAME), b.get(NAME)\n        if not a_name or not b_name or a_name.lower() != b_name.lower():\n            continue\n\n        if a.keys() != b.keys():  # not same version (might have variants)\n            continue\n\n        # Ensure that the values in the keys are also the same\n        for k in set(a.keys()) - {NAME, NAMESPACE}:\n            if a[k] != b[k]:  # something different\n                continue\n\n        survivor_mapping[a].add(b)\n        # Keep track of things that has been already mapped\n        victims.add(b)\n\n    collapse_nodes(graph, survivor_mapping)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noutputting the HBP knowledge graph to the desktop", "response": "def main(output):\n    \"\"\"Output the HBP knowledge graph to the desktop\"\"\"\n    from hbp_knowledge import get_graph\n    graph = get_graph()\n    text = to_html(graph)\n    print(text, file=output)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef node_is_upstream_leaf(graph: BELGraph, node: BaseEntity) -> bool:\n    return 0 == len(graph.predecessors(node)) and 1 == len(graph.successors(node))", "response": "Return if the node is an upstream leaf."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_unweighted_upstream_leaves(graph: BELGraph, key: Optional[str] = None) -> Iterable[BaseEntity]:\n    if key is None:\n        key = WEIGHT\n\n    return filter_nodes(graph, [node_is_upstream_leaf, data_missing_key_builder(key)])", "response": "Get unweighted upstream leaves."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_unweighted_leaves(graph: BELGraph, key: Optional[str] = None) -> None:\n    unweighted_leaves = list(get_unweighted_upstream_leaves(graph, key=key))\n    graph.remove_nodes_from(unweighted_leaves)", "response": "Removes nodes that are leaves and that don t have a weight attribute set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_unweighted_source(graph: BELGraph, node: BaseEntity, key: str) -> bool:\n    return graph.in_degree(node) == 0 and key not in graph.nodes[node]", "response": "Check if the node is both a source and also has an annotation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_unweighted_sources(graph: BELGraph, key: Optional[str] = None) -> Iterable[BaseEntity]:\n    if key is None:\n        key = WEIGHT\n\n    for node in graph:\n        if is_unweighted_source(graph, node, key):\n            yield node", "response": "Get nodes that are unweighted and on the given key."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprunes unannotated nodes on the periphery of the sub - graph.", "response": "def remove_unweighted_sources(graph: BELGraph, key: Optional[str] = None) -> None:\n    \"\"\"Prune unannotated nodes on the periphery of the sub-graph.\n\n    :param graph: A BEL graph\n    :param key: The key in the node data dictionary representing the experimental data. Defaults to\n     :data:`pybel_tools.constants.WEIGHT`.\n    \"\"\"\n    nodes = list(get_unweighted_sources(graph, key=key))\n    graph.remove_nodes_from(nodes)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prune_mechanism_by_data(graph, key: Optional[str] = None) -> None:\n    remove_unweighted_leaves(graph, key=key)\n    remove_unweighted_sources(graph, key=key)", "response": "Removes all nodes that don t have weights."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_mechanism(graph: BELGraph, node: BaseEntity, key: Optional[str] = None) -> BELGraph:\n    subgraph = get_upstream_causal_subgraph(graph, node)\n    expand_upstream_causal(graph, subgraph)\n    remove_inconsistent_edges(subgraph)\n    collapse_consistent_edges(subgraph)\n\n    if key is not None:  # FIXME when is it not pruned?\n        prune_mechanism_by_data(subgraph, key)\n\n    return subgraph", "response": "Generate a mechanistic sub - graph upstream of the given node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_bioprocess_mechanisms(graph, key: Optional[str] = None) -> Mapping[BiologicalProcess, BELGraph]:\n    return {\n        biological_process: generate_mechanism(graph, biological_process, key=key)\n        for biological_process in get_nodes_by_function(graph, BIOPROCESS)\n    }", "response": "Generate a mechanistic sub - graph for each biological process in the graph."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary mapping annotation value to a NeuroMMSig composite score.", "response": "def get_neurommsig_scores(graph: BELGraph,\n                          genes: List[Gene],\n                          annotation: str = 'Subgraph',\n                          ora_weight: Optional[float] = None,\n                          hub_weight: Optional[float] = None,\n                          top_percent: Optional[float] = None,\n                          topology_weight: Optional[float] = None,\n                          preprocess: bool = False\n                          ) -> Optional[Mapping[str, float]]:\n    \"\"\"Preprocess the graph, stratify by the given annotation, then run the NeuroMMSig algorithm on each.\n\n    :param graph: A BEL graph\n    :param genes: A list of gene nodes\n    :param annotation: The annotation to use to stratify the graph to subgraphs\n    :param ora_weight: The relative weight of the over-enrichment analysis score from\n     :py:func:`neurommsig_gene_ora`. Defaults to 1.0.\n    :param hub_weight: The relative weight of the hub analysis score from :py:func:`neurommsig_hubs`.\n     Defaults to 1.0.\n    :param top_percent: The percentage of top genes to use as hubs. Defaults to 5% (0.05).\n    :param topology_weight: The relative weight of the topolgical analysis core from\n     :py:func:`neurommsig_topology`. Defaults to 1.0.\n    :param preprocess: If true, preprocess the graph.\n    :return: A dictionary from {annotation value: NeuroMMSig composite score}\n\n    Pre-processing steps:\n\n    1. Infer the central dogma with :func:``\n    2. Collapse all proteins, RNAs and miRNAs to genes with :func:``\n    3. Collapse variants to genes with :func:``\n    \"\"\"\n    if preprocess:\n        graph = neurommsig_graph_preprocessor.run(graph)\n\n    if not any(gene in graph for gene in genes):\n        logger.debug('no genes mapping to graph')\n        return\n\n    subgraphs = get_subgraphs_by_annotation(graph, annotation=annotation)\n\n    return get_neurommsig_scores_prestratified(\n        subgraphs=subgraphs,\n        genes=genes,\n        ora_weight=ora_weight,\n        hub_weight=hub_weight,\n        top_percent=top_percent,\n        topology_weight=topology_weight,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake a set of graphs and runs neurommsig on each node. Returns a dictionary of annotation values that are used to identify the nodes in the graph.", "response": "def get_neurommsig_scores_prestratified(subgraphs: Mapping[str, BELGraph],\n                                        genes: List[Gene],\n                                        ora_weight: Optional[float] = None,\n                                        hub_weight: Optional[float] = None,\n                                        top_percent: Optional[float] = None,\n                                        topology_weight: Optional[float] = None,\n                                        ) -> Optional[Mapping[str, float]]:\n    \"\"\"Takes a graph stratification and runs neurommsig on each\n\n    :param subgraphs: A pre-stratified set of graphs\n    :param genes: A list of gene nodes\n    :param ora_weight: The relative weight of the over-enrichment analysis score from\n     :py:func:`neurommsig_gene_ora`. Defaults to 1.0.\n    :param hub_weight: The relative weight of the hub analysis score from :py:func:`neurommsig_hubs`.\n     Defaults to 1.0.\n    :param top_percent: The percentage of top genes to use as hubs. Defaults to 5% (0.05).\n    :param topology_weight: The relative weight of the topolgical analysis core from\n     :py:func:`neurommsig_topology`. Defaults to 1.0.\n    :return: A dictionary from {annotation value: NeuroMMSig composite score}\n\n    Pre-processing steps:\n\n    1. Infer the central dogma with :func:``\n    2. Collapse all proteins, RNAs and miRNAs to genes with :func:``\n    3. Collapse variants to genes with :func:``\n    \"\"\"\n    return {\n        name: get_neurommsig_score(\n            graph=subgraph,\n            genes=genes,\n            ora_weight=ora_weight,\n            hub_weight=hub_weight,\n            top_percent=top_percent,\n            topology_weight=topology_weight,\n        )\n        for name, subgraph in subgraphs.items()\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the NeuroMMSig composite score for a given list of genes.", "response": "def get_neurommsig_score(graph: BELGraph,\n                         genes: List[Gene],\n                         ora_weight: Optional[float] = None,\n                         hub_weight: Optional[float] = None,\n                         top_percent: Optional[float] = None,\n                         topology_weight: Optional[float] = None) -> float:\n    \"\"\"Calculate the composite NeuroMMSig Score for a given list of genes.\n\n    :param graph: A BEL graph\n    :param genes: A list of gene nodes\n    :param ora_weight: The relative weight of the over-enrichment analysis score from\n     :py:func:`neurommsig_gene_ora`. Defaults to 1.0.\n    :param hub_weight: The relative weight of the hub analysis score from :py:func:`neurommsig_hubs`.\n     Defaults to 1.0.\n    :param top_percent: The percentage of top genes to use as hubs. Defaults to 5% (0.05).\n    :param topology_weight: The relative weight of the topolgical analysis core from\n     :py:func:`neurommsig_topology`. Defaults to 1.0.\n    :return: The NeuroMMSig composite score\n    \"\"\"\n    ora_weight = ora_weight or 1.0\n    hub_weight = hub_weight or 1.0\n    topology_weight = topology_weight or 1.0\n    total_weight = ora_weight + hub_weight + topology_weight\n\n    genes = list(genes)\n\n    ora_score = neurommsig_gene_ora(graph, genes)\n    hub_score = neurommsig_hubs(graph, genes, top_percent=top_percent)\n    topology_score = neurommsig_topology(graph, genes)\n\n    weighted_sum = (\n            ora_weight * ora_score +\n            hub_weight * hub_score +\n            topology_weight * topology_score\n    )\n\n    return weighted_sum / total_weight"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the percentage of target genes mappable to the graph.", "response": "def neurommsig_gene_ora(graph: BELGraph, genes: List[Gene]) -> float:\n    \"\"\"Calculate the percentage of target genes mappable to the graph.\n    \n    Assume: graph central dogma inferred, collapsed to genes, collapsed variants \n    \"\"\"\n    graph_genes = set(get_nodes_by_function(graph, GENE))\n    return len(graph_genes.intersection(genes)) / len(graph_genes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef neurommsig_hubs(graph: BELGraph, genes: List[Gene], top_percent: Optional[float] = None) -> float:\n    top_percent = top_percent or 0.05\n\n    if graph.number_of_nodes() < 20:\n        logger.debug('Graph has less than 20 nodes')\n        return 0.0\n\n    graph_genes = set(get_nodes_by_function(graph, GENE))\n\n    bc = Counter({\n        node: betweenness_centrality\n        for node, betweenness_centrality in calculate_betweenness_centality(graph).items()\n        if node in graph_genes\n    })\n\n    # TODO consider continuous analog with weighting by percentile\n    number_central_nodes = int(len(graph_genes) * top_percent)\n\n    if number_central_nodes < 1:\n        number_central_nodes = 1\n\n    number_mappable_central_nodes = sum(\n        node in genes\n        for node in bc.most_common(number_central_nodes)\n    )\n\n    return number_mappable_central_nodes / number_central_nodes", "response": "Calculate the percentage of target genes mappable to the graph."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef neurommsig_topology(graph: BELGraph, nodes: List[BaseEntity]) -> float:\n    nodes = list(nodes)\n    number_nodes = len(nodes)\n\n    if number_nodes <= 1:\n        # log.debug('')\n        return 0.0\n\n    unnormalized_sum = sum(\n        u in graph[v]\n        for u, v in itt.product(nodes, repeat=2)\n        if v in graph and u != v\n    )\n\n    return unnormalized_sum / (number_nodes * (number_nodes - 1.0))", "response": "Calculate the neighbor score for a given list of nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms a single run over all microstates and return the canonical cluster statistics", "response": "def bond_run(perc_graph_result, seed, ps, convolution_factors_tasks):\n    \"\"\"\n    Perform a single run (realization) over all microstates and return the\n    canonical cluster statistics\n    \"\"\"\n    microcanonical_statistics = percolate.hpc.bond_microcanonical_statistics(\n        seed=seed, **perc_graph_result\n    )\n\n    # initialize statistics array\n    canonical_statistics = np.empty(\n        ps.size,\n        dtype=percolate.hpc.canonical_statistics_dtype(\n            spanning_cluster=SPANNING_CLUSTER,\n        )\n    )\n\n    # loop over all p's and convolve canonical statistics\n    # http://docs.scipy.org/doc/numpy/reference/arrays.nditer.html#modifying-array-values\n    for row, convolution_factors_task in zip(\n        np.nditer(canonical_statistics, op_flags=['writeonly']),\n        convolution_factors_tasks,\n    ):\n        # load task result\n        # http://jug.readthedocs.org/en/latest/api.html#jug.Task.load\n        assert not convolution_factors_task.is_loaded()\n        convolution_factors_task.load()\n        # fetch task result\n        my_convolution_factors = convolution_factors_task.result\n\n        # convolve to canonical statistics\n        row[...] = percolate.hpc.bond_canonical_statistics(\n            microcanonical_statistics=microcanonical_statistics,\n            convolution_factors=my_convolution_factors,\n            spanning_cluster=SPANNING_CLUSTER,\n        )\n        # explicitly unload task to save memory\n        # http://jug.readthedocs.org/en/latest/api.html#jug.Task.unload\n        convolution_factors_task.unload()\n\n    # initialize canonical averages for reduce\n    ret = percolate.hpc.bond_initialize_canonical_averages(\n        canonical_statistics=canonical_statistics,\n        spanning_cluster=SPANNING_CLUSTER,\n    )\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform a number of runs The number of runs is the number of seeds convolution_factors_tasks_iterator needs to be an iterator We shield the convolution factors tasks from jug value/result mechanism by supplying an iterator to the list of tasks for lazy evaluation http://github.com/luispedro/jug/blob/43f0d80a78f418fd3aa2b8705eaf7c4a5175fff7/jug/task.py#L100 http://github.com/luispedro/jug/blob/43f0d80a78f418fd3aa2b8705eaf7c4a5175fff7/jug/task.py#L455", "response": "def bond_task(\n    perc_graph_result, seeds, ps, convolution_factors_tasks_iterator\n):\n    \"\"\"\n    Perform a number of runs\n\n    The number of runs is the number of seeds\n\n    convolution_factors_tasks_iterator needs to be an iterator\n\n    We shield the convolution factors tasks from jug value/result mechanism\n    by supplying an iterator to the list of tasks for lazy evaluation\n    http://github.com/luispedro/jug/blob/43f0d80a78f418fd3aa2b8705eaf7c4a5175fff7/jug/task.py#L100\n    http://github.com/luispedro/jug/blob/43f0d80a78f418fd3aa2b8705eaf7c4a5175fff7/jug/task.py#L455\n    \"\"\"\n\n    # restore the list of convolution factors tasks\n    convolution_factors_tasks = list(convolution_factors_tasks_iterator)\n\n    return reduce(\n        percolate.hpc.bond_reduce,\n        map(\n            bond_run,\n            itertools.repeat(perc_graph_result),\n            seeds,\n            itertools.repeat(ps),\n            itertools.repeat(convolution_factors_tasks),\n        )\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an iterable over all nodes in a BEL graph with only a connection to one node. Useful for gene and anomaly.", "response": "def get_leaves_by_type(graph, func=None, prune_threshold=1):\n    \"\"\"Returns an iterable over all nodes in graph (in-place) with only a connection to one node. Useful for gene and\n     RNA. Allows for optional filter by function type.\n\n    :param pybel.BELGraph graph: A BEL graph\n    :param func: If set, filters by the node's function from :mod:`pybel.constants` like\n                    :data:`pybel.constants.GENE`, :data:`pybel.constants.RNA`,  :data:`pybel.constants.PROTEIN`, or \n                    :data:`pybel.constants.BIOPROCESS`\n    :type func: str\n    :param prune_threshold: Removes nodes with less than or equal to this number of connections. Defaults to :code:`1`\n    :type prune_threshold: int\n    :return: An iterable over nodes with only a connection to one node\n    :rtype: iter[tuple]\n    \"\"\"\n    for node, data in graph.nodes(data=True):\n        if func and func != data.get(FUNCTION):\n            continue\n\n        if graph.in_degree(node) + graph.out_degree(node) <= prune_threshold:\n            yield node"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the set of possible successor edges peripheral to the sub - graph.", "response": "def get_peripheral_successor_edges(graph: BELGraph, subgraph: BELGraph) -> EdgeIterator:\n    \"\"\"Get the set of possible successor edges peripheral to the sub-graph.\n\n    The source nodes in this iterable are all inside the sub-graph, while the targets are outside.\n    \"\"\"\n    for u in subgraph:\n        for _, v, k in graph.out_edges(u, keys=True):\n            if v not in subgraph:\n                yield u, v, k"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the set of possible predecessor edges peripheral to the sub - graph.", "response": "def get_peripheral_predecessor_edges(graph: BELGraph, subgraph: BELGraph) -> EdgeIterator:\n    \"\"\"Get the set of possible predecessor edges peripheral to the sub-graph.\n\n    The target nodes in this iterable are all inside the sub-graph, while the sources are outside.\n    \"\"\"\n    for v in subgraph:\n        for u, _, k in graph.in_edges(v, keys=True):\n            if u not in subgraph:\n                yield u, v, k"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef count_sources(edge_iter: EdgeIterator) -> Counter:\n    return Counter(u for u, _, _ in edge_iter)", "response": "Count the source nodes in an edge iterator with keys and data.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncounting the target nodes in an edge iterator with keys and data.", "response": "def count_targets(edge_iter: EdgeIterator) -> Counter:\n    \"\"\"Count the target nodes in an edge iterator with keys and data.\n\n    :return: A counter of target nodes in the iterable\n    \"\"\"\n    return Counter(v for _, v, _ in edge_iter)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an iterable of all edges from a given subgraph whose source and target nodes pass all of the given filters .", "response": "def get_subgraph_edges(graph: BELGraph,\n                       annotation: str,\n                       value: str,\n                       source_filter=None,\n                       target_filter=None,\n                       ):\n    \"\"\"Gets all edges from a given subgraph whose source and target nodes pass all of the given filters\n\n    :param pybel.BELGraph graph: A BEL graph\n    :param str annotation:  The annotation to search\n    :param str value: The annotation value to search by\n    :param source_filter: Optional filter for source nodes (graph, node) -> bool\n    :param target_filter: Optional filter for target nodes (graph, node) -> bool\n    :return: An iterable of (source node, target node, key, data) for all edges that match the annotation/value and\n             node filters\n    :rtype: iter[tuple]\n    \"\"\"\n    if source_filter is None:\n        source_filter = keep_node_permissive\n\n    if target_filter is None:\n        target_filter = keep_node_permissive\n\n    for u, v, k, data in graph.edges(keys=True, data=True):\n        if not edge_has_annotation(data, annotation):\n            continue\n        if data[ANNOTATIONS][annotation] == value and source_filter(graph, u) and target_filter(graph, v):\n            yield u, v, k, data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a summary dictionary of all peripheral nodes to a given sub - graph.", "response": "def get_subgraph_peripheral_nodes(graph: BELGraph,\n                                  subgraph: Iterable[BaseEntity],\n                                  node_predicates: NodePredicates = None,\n                                  edge_predicates: EdgePredicates = None,\n                                  ):\n    \"\"\"Get a summary dictionary of all peripheral nodes to a given sub-graph.\n\n    :return: A dictionary of {external node: {'successor': {internal node: list of (key, dict)},\n                                            'predecessor': {internal node: list of (key, dict)}}}\n    :rtype: dict\n\n    For example, it might be useful to quantify the number of predecessors and successors:\n\n    >>> from pybel.struct.filters import exclude_pathology_filter\n    >>> value = 'Blood vessel dilation subgraph'\n    >>> sg = get_subgraph_by_annotation_value(graph, annotation='Subgraph', value=value)\n    >>> p = get_subgraph_peripheral_nodes(graph, sg, node_predicates=exclude_pathology_filter)\n    >>> for node in sorted(p, key=lambda n: len(set(p[n]['successor']) | set(p[n]['predecessor'])), reverse=True):\n    >>>     if 1 == len(p[value][node]['successor']) or 1 == len(p[value][node]['predecessor']):\n    >>>         continue\n    >>>     print(node,\n    >>>           len(p[node]['successor']),\n    >>>           len(p[node]['predecessor']),\n    >>>           len(set(p[node]['successor']) | set(p[node]['predecessor'])))\n    \"\"\"\n    node_filter = concatenate_node_predicates(node_predicates=node_predicates)\n    edge_filter = and_edge_predicates(edge_predicates=edge_predicates)\n\n    result = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n\n    for u, v, k, d in get_peripheral_successor_edges(graph, subgraph):\n        if not node_filter(graph, v) or not node_filter(graph, u) or not edge_filter(graph, u, v, k):\n            continue\n        result[v]['predecessor'][u].append((k, d))\n\n    for u, v, k, d in get_peripheral_predecessor_edges(graph, subgraph):\n        if not node_filter(graph, v) or not node_filter(graph, u) or not edge_filter(graph, u, v, k):\n            continue\n        result[u]['successor'][v].append((k, d))\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\niterate over all possible edges, peripheral to a given subgraph, that could be added from the given graph. Edges could be added if they go to nodes that are involved in relationships that occur with more than the threshold (default 2) number of nodes in the subgraph. :param universe: The universe of BEL knowledge :param graph: The (sub)graph to expand :param threshold: Minimum frequency of betweenness occurrence to add a gap node A reasonable edge filter to use is :func:`pybel_tools.filters.keep_causal_edges` because this function can allow for huge expansions if there happen to be hub nodes.", "response": "def expand_periphery(universe: BELGraph,\n                     graph: BELGraph,\n                     node_predicates: NodePredicates = None,\n                     edge_predicates: EdgePredicates = None,\n                     threshold: int = 2,\n                     ) -> None:\n    \"\"\"Iterates over all possible edges, peripheral to a given subgraph, that could be added from the given graph.\n    Edges could be added if they go to nodes that are involved in relationships that occur with more than the\n    threshold (default 2) number of nodes in the subgraph.\n\n    :param universe: The universe of BEL knowledge\n    :param graph: The (sub)graph to expand\n    :param threshold: Minimum frequency of betweenness occurrence to add a gap node\n\n    A reasonable edge filter to use is :func:`pybel_tools.filters.keep_causal_edges` because this function can allow\n    for huge expansions if there happen to be hub nodes.\n    \"\"\"\n    nd = get_subgraph_peripheral_nodes(universe, graph, node_predicates=node_predicates,\n                                       edge_predicates=edge_predicates)\n\n    for node, dd in nd.items():\n        pred_d = dd['predecessor']\n        succ_d = dd['successor']\n\n        in_subgraph_connections = set(pred_d) | set(succ_d)\n\n        if threshold > len(in_subgraph_connections):\n            continue\n\n        graph.add_node(node, attr_dict=universe[node])\n\n        for u, edges in pred_d.items():\n            for k, d in edges:\n                safe_add_edge(graph, u, node, k, d)\n\n        for v, edges in succ_d.items():\n            for k, d in edges:\n                safe_add_edge(graph, node, v, k, d)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding all of the members of the complex abundances to the graph.", "response": "def enrich_complexes(graph: BELGraph) -> None:\n    \"\"\"Add all of the members of the complex abundances to the graph.\"\"\"\n    nodes = list(get_nodes_by_function(graph, COMPLEX))\n    for u in nodes:\n        for v in u.members:\n            graph.add_has_component(u, v)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nenrich the composite abundances in the graph with the members of the composite abundances.", "response": "def enrich_composites(graph: BELGraph):\n    \"\"\"Adds all of the members of the composite abundances to the graph.\"\"\"\n    nodes = list(get_nodes_by_function(graph, COMPOSITE))\n    for u in nodes:\n        for v in u.members:\n            graph.add_has_component(u, v)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds all of the reactants and products of reactions to the graph.", "response": "def enrich_reactions(graph: BELGraph):\n    \"\"\"Adds all of the reactants and products of reactions to the graph.\"\"\"\n    nodes = list(get_nodes_by_function(graph, REACTION))\n    for u in nodes:\n        for v in u.reactants:\n            graph.add_has_reactant(u, v)\n\n        for v in u.products:\n            graph.add_has_product(u, v)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enrich_variants(graph: BELGraph, func: Union[None, str, Iterable[str]] = None):\n    if func is None:\n        func = {PROTEIN, RNA, MIRNA, GENE}\n\n    nodes = list(get_nodes_by_function(graph, func))\n    for u in nodes:\n        parent = u.get_parent()\n\n        if parent is None:\n            continue\n\n        if parent not in graph:\n            graph.add_has_variant(parent, u)", "response": "Add the reference nodes for all variants of the given function to the given graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nenriching the sub - graph with the unqualified edges from the graph.", "response": "def enrich_unqualified(graph: BELGraph):\n    \"\"\"Enrich the sub-graph with the unqualified edges from the graph.\n\n    The reason you might want to do this is you induce a sub-graph from the original graph based on an annotation\n    filter, but the unqualified edges that don't have annotations that most likely connect elements within your graph\n    are not included.\n\n    .. seealso::\n\n        This function thinly wraps the successive application of the following functions:\n\n        - :func:`enrich_complexes`\n        - :func:`enrich_composites`\n        - :func:`enrich_reactions`\n        - :func:`enrich_variants`\n\n    Equivalent to:\n\n    >>> enrich_complexes(graph)\n    >>> enrich_composites(graph)\n    >>> enrich_reactions(graph)\n    >>> enrich_variants(graph)\n    \"\"\"\n    enrich_complexes(graph)\n    enrich_composites(graph)\n    enrich_reactions(graph)\n    enrich_variants(graph)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef expand_internal(universe: BELGraph, graph: BELGraph, edge_predicates: EdgePredicates = None) -> None:\n    edge_filter = and_edge_predicates(edge_predicates)\n\n    for u, v in itt.product(graph, repeat=2):\n        if graph.has_edge(u, v) or not universe.has_edge(u, v):\n            continue\n\n        rs = defaultdict(list)\n        for key, data in universe[u][v].items():\n            if not edge_filter(universe, u, v, key):\n                continue\n\n            rs[data[RELATION]].append((key, data))\n\n        if 1 == len(rs):\n            relation = list(rs)[0]\n            for key, data in rs[relation]:\n                graph.add_edge(u, v, key=key, **data)\n        else:\n            log.debug('Multiple relationship types found between %s and %s', u, v)", "response": "Expand the internal information of the given universe."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef expand_internal_causal(universe: BELGraph, graph: BELGraph) -> None:\n    expand_internal(universe, graph, edge_predicates=is_causal_relation)", "response": "Add causal edges between entities in the sub - graph."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the set of all namespaces with incorrect names in the graph.", "response": "def get_namespaces_with_incorrect_names(graph: BELGraph) -> Set[str]:\n    \"\"\"Return the set of all namespaces with incorrect names in the graph.\"\"\"\n    return {\n        exc.namespace\n        for _, exc, _ in graph.warnings\n        if isinstance(exc, (MissingNamespaceNameWarning, MissingNamespaceRegexWarning))\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_undefined_namespaces(graph: BELGraph) -> Set[str]:\n    return {\n        exc.namespace\n        for _, exc, _ in graph.warnings\n        if isinstance(exc, UndefinedNamespaceWarning)\n    }", "response": "Get all namespaces that are not actually defined in the BEL graph."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the set of all incorrect names from the given namespace in the graph.", "response": "def get_incorrect_names_by_namespace(graph: BELGraph, namespace: str) -> Set[str]:\n    \"\"\"Return the set of all incorrect names from the given namespace in the graph.\n\n    :return: The set of all incorrect names from the given namespace in the graph\n    \"\"\"\n    return {\n        exc.name\n        for _, exc, _ in graph.warnings\n        if isinstance(exc, (MissingNamespaceNameWarning, MissingNamespaceRegexWarning)) and exc.namespace == namespace\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the names from a namespace that was not actually defined.", "response": "def get_undefined_namespace_names(graph: BELGraph, namespace: str) -> Set[str]:\n    \"\"\"Get the names from a namespace that wasn't actually defined.\n\n    :return: The set of all names from the undefined namespace\n    \"\"\"\n    return {\n        exc.name\n        for _, exc, _ in graph.warnings\n        if isinstance(exc, UndefinedNamespaceWarning) and exc.namespace == namespace\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_incorrect_names(graph: BELGraph) -> Mapping[str, Set[str]]:\n    return {\n        namespace: get_incorrect_names_by_namespace(graph, namespace)\n        for namespace in get_namespaces(graph)\n    }", "response": "Return the dict of all incorrect names from the given namespace in the graph."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_undefined_annotations(graph: BELGraph) -> Set[str]:\n    return {\n        exc.annotation\n        for _, exc, _ in graph.warnings\n        if isinstance(exc, UndefinedAnnotationWarning)\n    }", "response": "Get all undefined annotations that aren t actually defined in the graph."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngroup all of the incorrect identifiers in a dictionary of namespace to list of erroneous names.", "response": "def calculate_incorrect_name_dict(graph: BELGraph) -> Mapping[str, str]:\n    \"\"\"Group all of the incorrect identifiers in a dict of {namespace: list of erroneous names}.\n\n    :return: A dictionary of {namespace: list of erroneous names}\n    \"\"\"\n    missing = defaultdict(list)\n\n    for _, e, ctx in graph.warnings:\n        if not isinstance(e, (MissingNamespaceNameWarning, MissingNamespaceRegexWarning)):\n            continue\n        missing[e.namespace].append(e.name)\n\n    return dict(missing)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef group_errors(graph: BELGraph) -> Mapping[str, List[int]]:\n    warning_summary = defaultdict(list)\n\n    for _, exc, _ in graph.warnings:\n        warning_summary[str(exc)].append(exc.line_number)\n\n    return dict(warning_summary)", "response": "Group the errors together for analysis of the most frequent error."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the n most common errors in a graph.", "response": "def get_most_common_errors(graph: BELGraph, n: Optional[int] = 20):\n    \"\"\"Get the (n) most common errors in a graph.\"\"\"\n    return count_dict_values(group_errors(graph)).most_common(n)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking the names from the graph in a given namespace and returns them together", "response": "def get_names_including_errors_by_namespace(graph: BELGraph, namespace: str) -> Set[str]:\n    \"\"\"Takes the names from the graph in a given namespace (:func:`pybel.struct.summary.get_names_by_namespace`) and\n    the erroneous names from the same namespace (:func:`get_incorrect_names_by_namespace`) and returns them together\n    as a unioned set\n\n    :return: The set of all correct and incorrect names from the given namespace in the graph\n    \"\"\"\n    return get_names_by_namespace(graph, namespace) | get_incorrect_names_by_namespace(graph, namespace)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_names_including_errors(graph: BELGraph) -> Mapping[str, Set[str]]:\n    return {\n        namespace: get_names_including_errors_by_namespace(graph, namespace)\n        for namespace in get_namespaces(graph)\n    }", "response": "Takes the names from the graph in a given namespace and returns the set of all correct and incorrect names in the given namespace."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\niterating over pairs in list s -> s0 s1 s2 s3...", "response": "def pairwise(iterable: Iterable[X]) -> Iterable[Tuple[X, X]]:\n    \"\"\"Iterate over pairs in list s -> (s0,s1), (s1,s2), (s2, s3), ...\"\"\"\n    a, b = itt.tee(iterable)\n    next(b, None)\n    return zip(a, b)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncount the number of elements in each value of the dictionary.", "response": "def count_defaultdict(dict_of_lists: Mapping[X, List[Y]]) -> Mapping[X, typing.Counter[Y]]:\n    \"\"\"Count the number of elements in each value of the dictionary.\"\"\"\n    return {\n        k: Counter(v)\n        for k, v in dict_of_lists.items()\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncounts the number of elements in each value in a dictionary.", "response": "def count_dict_values(dict_of_counters: Mapping[X, Sized]) -> typing.Counter[X]:\n    \"\"\"Count the number of elements in each value (can be list, Counter, etc).\n\n    :param dict_of_counters: A dictionary of things whose lengths can be measured (lists, Counters, dicts)\n    :return: A Counter with the same keys as the input but the count of the length of the values list/tuple/set/Counter\n    \"\"\"\n    return Counter({\n        k: len(v)\n        for k, v in dict_of_counters.items()\n    })"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_percentage(x: Iterable[X], y: Iterable[X]) -> float:\n    a, b = set(x), set(y)\n\n    if not a:\n        return 0.0\n\n    return len(a & b) / len(a)", "response": "Calculates the percentage of the elements in x contained within y."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the tanimoto set similarity.", "response": "def tanimoto_set_similarity(x: Iterable[X], y: Iterable[X]) -> float:\n    \"\"\"Calculate the tanimoto set similarity.\"\"\"\n    a, b = set(x), set(y)\n    union = a | b\n\n    if not union:\n        return 0.0\n\n    return len(a & b) / len(union)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef min_tanimoto_set_similarity(x: Iterable[X], y: Iterable[X]) -> float:\n    a, b = set(x), set(y)\n\n    if not a or not b:\n        return 0.0\n\n    return len(a & b) / min(len(a), len(b))", "response": "Calculate the similarity between two sets of tanimoto sets."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef calculate_single_tanimoto_set_distances(target: Iterable[X], dict_of_sets: Mapping[Y, Set[X]]) -> Mapping[Y, float]:\n    target_set = set(target)\n\n    return {\n        k: tanimoto_set_similarity(target_set, s)\n        for k, s in dict_of_sets.items()\n    }", "response": "Calculates the similarity between the target set and the set in the given dict of sets."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calculate_tanimoto_set_distances(dict_of_sets: Mapping[X, Set]) -> Mapping[X, Mapping[X, float]]:\n    result: Dict[X, Dict[X, float]] = defaultdict(dict)\n\n    for x, y in itt.combinations(dict_of_sets, 2):\n        result[x][y] = result[y][x] = tanimoto_set_similarity(dict_of_sets[x], dict_of_sets[y])\n\n    for x in dict_of_sets:\n        result[x][x] = 1.0\n\n    return dict(result)", "response": "Calculates the distance matrix for each set in the given dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef safe_add_edge(graph, u, v, key, attr_dict, **attr):\n    if key < 0:\n        graph.add_edge(u, v, key=key, attr_dict=attr_dict, **attr)\n    else:\n        graph.add_edge(u, v, attr_dict=attr_dict, **attr)", "response": "Adds an edge while preserving negative keys and paying no respect to positive ones."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprepare a C3 bar chart from a Counter", "response": "def prepare_c3(data: Union[List[Tuple[str, int]], Mapping[str, int]],\n               y_axis_label: str = 'y',\n               x_axis_label: str = 'x',\n               ) -> str:\n    \"\"\"Prepares C3 JSON for making a bar chart from a Counter\n\n    :param data: A dictionary of {str: int} to display as bar chart\n    :param y_axis_label: The Y axis label\n    :param x_axis_label: X axis internal label. Should be left as default 'x')\n    :return: A JSON dictionary for making a C3 bar chart\n    \"\"\"\n    if not isinstance(data, list):\n        data = sorted(data.items(), key=itemgetter(1), reverse=True)\n\n    try:\n        labels, values = zip(*data)\n    except ValueError:\n        log.info(f'no values found for {x_axis_label}, {y_axis_label}')\n        labels, values = [], []\n\n    return json.dumps([\n        [x_axis_label] + list(labels),\n        [y_axis_label] + list(values),\n    ])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprepares C3 JSON string dump for a time series.", "response": "def prepare_c3_time_series(data: List[Tuple[int, int]], y_axis_label: str = 'y', x_axis_label: str = 'x') -> str:\n    \"\"\"Prepare C3 JSON string dump for a time series.\n\n    :param data: A list of tuples [(year, count)]\n    :param y_axis_label: The Y axis label\n    :param x_axis_label: X axis internal label. Should be left as default 'x')\n    \"\"\"\n    years, counter = zip(*data)\n\n    years = [\n        datetime.date(year, 1, 1).isoformat()\n        for year in years\n    ]\n\n    return json.dumps([\n        [x_axis_label] + list(years),\n        [y_axis_label] + list(counter)\n    ])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the betweenness centrality over nodes in the graph.", "response": "def calculate_betweenness_centality(graph: BELGraph, number_samples: int = CENTRALITY_SAMPLES) -> Counter:\n    \"\"\"Calculate the betweenness centrality over nodes in the graph.\n\n    Tries to do it with a certain number of samples, but then tries a complete approach if it fails.\n    \"\"\"\n    try:\n        res = nx.betweenness_centrality(graph, k=number_samples)\n    except Exception:\n        res = nx.betweenness_centrality(graph)\n    return Counter(res)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\niterate over all possible circulations of an ordered collection.", "response": "def get_circulations(elements: T) -> Iterable[T]:\n    \"\"\"Iterate over all possible circulations of an ordered collection (tuple or list).\n\n    Example:\n\n    >>> list(get_circulations([1, 2, 3]))\n    [[1, 2, 3], [2, 3, 1], [3, 1, 2]]\n    \"\"\"\n    for i in range(len(elements)):\n        yield elements[i:] + elements[:i]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a canonical representation of the ordered collection by finding its minimum circulation with the given sort key.", "response": "def canonical_circulation(elements: T, key: Optional[Callable[[T], bool]] = None) -> T:\n    \"\"\"Get get a canonical representation of the ordered collection by finding its minimum circulation with the\n    given sort key\n    \"\"\"\n    return min(get_circulations(elements), key=key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pair_has_contradiction(graph: BELGraph, u: BaseEntity, v: BaseEntity) -> bool:\n    relations = {data[RELATION] for data in graph[u][v].values()}\n    return relation_set_has_contradictions(relations)", "response": "Check if a pair of nodes has any contradictions in their causal relationships."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning if the set of BEL relations contains a contradiction.", "response": "def relation_set_has_contradictions(relations: Set[str]) -> bool:\n    \"\"\"Return if the set of BEL relations contains a contradiction.\"\"\"\n    has_increases = any(relation in CAUSAL_INCREASE_RELATIONS for relation in relations)\n    has_decreases = any(relation in CAUSAL_DECREASE_RELATIONS for relation in relations)\n    has_cnc = any(relation == CAUSES_NO_CHANGE for relation in relations)\n    return 1 < sum([has_cnc, has_decreases, has_increases])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares the (internal) percolation graph from a given graph Helper function to prepare the given graph for spanning cluster detection (if required). Basically it strips off the auxiliary nodes and edges again. It also returns fundamental graph quantitities (number of nodes and edges). Parameters ---------- graph spanning_cluster Returns ------- ret : tuple", "response": "def percolation_graph(graph, spanning_cluster=True):\n    \"\"\"\n    Prepare the (internal) percolation graph from a given graph\n\n    Helper function to prepare the given graph for spanning cluster detection\n    (if required).\n    Basically it strips off the auxiliary nodes and edges again.\n    It also returns fundamental graph quantitities (number of nodes and edges).\n\n    Parameters\n    ----------\n    graph\n    spanning_cluster\n\n    Returns\n    -------\n    ret : tuple\n\n    \"\"\"\n    ret = dict()\n\n    ret['graph'] = graph\n    ret['spanning_cluster'] = bool(spanning_cluster)\n\n    # initialize percolation graph\n    if spanning_cluster:\n        spanning_auxiliary_node_attributes = nx.get_node_attributes(\n            graph, 'span'\n        )\n        ret['auxiliary_node_attributes'] = spanning_auxiliary_node_attributes\n        auxiliary_nodes = spanning_auxiliary_node_attributes.keys()\n        if not list(auxiliary_nodes):\n            raise ValueError(\n                'Spanning cluster is to be detected, but no auxiliary nodes '\n                'given.'\n            )\n\n        spanning_sides = list(set(spanning_auxiliary_node_attributes.values()))\n        if len(spanning_sides) != 2:\n            raise ValueError(\n                'Spanning cluster is to be detected, but auxiliary nodes '\n                'of less or more than 2 types (sides) given.'\n            )\n\n        ret['spanning_sides'] = spanning_sides\n        ret['auxiliary_edge_attributes'] = nx.get_edge_attributes(\n            graph, 'span'\n        )\n\n    # get subgraph on which percolation is to take place (strip off the\n    # auxiliary nodes)\n    if spanning_cluster:\n        perc_graph = graph.subgraph(\n            [\n                node for node in graph.nodes_iter()\n                if 'span' not in graph.node[node]\n            ]\n        )\n    else:\n        perc_graph = graph\n\n    ret['perc_graph'] = perc_graph\n\n    # number of nodes N\n    ret['num_nodes'] = nx.number_of_nodes(perc_graph)\n\n    # number of edges M\n    ret['num_edges'] = nx.number_of_edges(perc_graph)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sample_states(\n    graph, spanning_cluster=True, model='bond', copy_result=True\n):\n    '''\n    Generate successive sample states of the percolation model\n\n    This is a :ref:`generator function <python:tut-generators>` to successively\n    add one edge at a time from the graph to the percolation model.\n    At each iteration, it calculates and returns the cluster statistics.\n\n    Parameters\n    ----------\n    graph : networkx.Graph\n        The substrate graph on which percolation is to take place\n\n    spanning_cluster : bool, optional\n        Whether to detect a spanning cluster or not.\n        Defaults to ``True``.\n\n    model : str, optional\n        The percolation model (either ``'bond'`` or ``'site'``).\n        Defaults to ``'bond'``.\n\n        .. note:: Other models than ``'bond'`` are not supported yet.\n\n    copy_result : bool, optional\n        Whether to return a copy or a reference to the result dictionary.\n        Defaults to ``True``.\n\n    Yields\n    ------\n    ret : dict\n        Cluster statistics\n\n    ret['n'] : int\n        Number of occupied bonds\n\n    ret['N'] : int\n        Total number of sites\n\n    ret['M'] : int\n        Total number of bonds\n\n    ret['has_spanning_cluster'] : bool\n        ``True`` if there is a spanning cluster, ``False`` otherwise.\n        Only exists if `spanning_cluster` argument is set to ``True``.\n\n    ret['max_cluster_size'] : int\n        Size of the largest cluster (absolute number of sites)\n\n    ret['moments'] : 1-D :py:class:`numpy.ndarray` of int\n        Array of size ``5``.\n        The ``k``-th entry is the ``k``-th raw moment of the (absolute) cluster\n        size distribution, with ``k`` ranging from ``0`` to ``4``.\n\n    Raises\n    ------\n    ValueError\n        If `model` does not equal ``'bond'``.\n\n    ValueError\n        If `spanning_cluster` is ``True``, but `graph` does not contain any\n        auxiliary nodes to detect spanning clusters.\n\n    See also\n    --------\n\n    microcanonical_averages : Evolves multiple sample states in parallel\n\n    Notes\n    -----\n    Iterating through this generator is a single run of the Newman-Ziff\n    algorithm. [2]_\n    The first iteration yields the trivial state with :math:`n = 0` occupied\n    bonds.\n\n    Spanning cluster\n\n        In order to detect a spanning cluster, `graph` needs to contain\n        auxiliary nodes and edges, cf. Reference [2]_, Figure 6.\n        The auxiliary nodes and edges have the ``'span'`` `attribute\n        <http://networkx.github.io/documentation/latest/tutorial/tutorial.html#node-attributes>`_.\n        The value is either ``0`` or ``1``, distinguishing the two sides of the\n        graph to span.\n\n    Raw moments of the cluster size distribution\n\n        The :math:`k`-th raw moment of the (absolute) cluster size distribution\n        is :math:`\\sum_s' s^k N_s`, where :math:`s` is the cluster size and\n        :math:`N_s` is the number of clusters of size :math:`s`. [3]_\n        The primed sum :math:`\\sum'` signifies that the largest cluster is\n        excluded from the sum. [4]_\n\n    References\n    ----------\n    .. [2] Newman, M. E. J. & Ziff, R. M. Fast monte carlo algorithm for site\n        or bond percolation. Physical Review E 64, 016706+ (2001),\n        `doi:10.1103/physreve.64.016706 <http://dx.doi.org/10.1103/physreve.64.016706>`_.\n\n    .. [3] Stauffer, D. & Aharony, A. Introduction to Percolation Theory (Taylor &\n       Francis, London, 1994), second edn.\n\n    .. [4] Binder, K. & Heermann, D. W. Monte Carlo Simulation in Statistical\n       Physics (Springer, Berlin, Heidelberg, 2010),\n       `doi:10.1007/978-3-642-03163-2 <http://dx.doi.org/10.1007/978-3-642-03163-2>`_.\n    '''\n\n    if model != 'bond':\n        raise ValueError('Only bond percolation supported.')\n\n    if spanning_cluster:\n        auxiliary_node_attributes = nx.get_node_attributes(graph, 'span')\n        auxiliary_nodes = auxiliary_node_attributes.keys()\n        if not list(auxiliary_nodes):\n            raise ValueError(\n                'Spanning cluster is to be detected, but no auxiliary nodes '\n                'given.'\n            )\n\n        spanning_sides = list(set(auxiliary_node_attributes.values()))\n        if len(spanning_sides) != 2:\n            raise ValueError(\n                'Spanning cluster is to be detected, but auxiliary nodes '\n                'of less or more than 2 types (sides) given.'\n            )\n\n        auxiliary_edge_attributes = nx.get_edge_attributes(graph, 'span')\n\n    # get subgraph on which percolation is to take place (strip off the\n    # auxiliary nodes)\n    if spanning_cluster:\n        perc_graph = graph.subgraph(\n            [\n                node for node in graph.nodes_iter()\n                if 'span' not in graph.node[node]\n            ]\n        )\n    else:\n        perc_graph = graph\n\n    # get a list of edges for easy access in later iterations\n    perc_edges = perc_graph.edges()\n\n    # number of nodes N\n    num_nodes = nx.number_of_nodes(perc_graph)\n\n    # number of edges M\n    num_edges = nx.number_of_edges(perc_graph)\n\n    # initial iteration: no edges added yet (n == 0)\n    ret = dict()\n\n    ret['n'] = 0\n    ret['N'] = num_nodes\n    ret['M'] = num_edges\n    ret['max_cluster_size'] = 1\n    ret['moments'] = np.ones(5) * (num_nodes - 1)\n\n    if spanning_cluster:\n        ret['has_spanning_cluster'] = False\n\n    if copy_result:\n        yield copy.deepcopy(ret)\n    else:\n        yield ret\n\n    # permute edges\n    perm_edges = np.random.permutation(num_edges)\n\n    # set up disjoint set (union-find) data structure\n    ds = nx.utils.union_find.UnionFind()\n    if spanning_cluster:\n        ds_spanning = nx.utils.union_find.UnionFind()\n\n        # merge all auxiliary nodes for each side\n        side_roots = dict()\n        for side in spanning_sides:\n            nodes = [\n                node for (node, node_side) in auxiliary_node_attributes.items()\n                if node_side is side\n            ]\n            ds_spanning.union(*nodes)\n            side_roots[side] = ds_spanning[nodes[0]]\n\n        for (edge, edge_side) in auxiliary_edge_attributes.items():\n            ds_spanning.union(side_roots[edge_side], *edge)\n\n        side_roots = [\n            ds_spanning[side_root] for side_root in side_roots.values()\n        ]\n\n    # get first node\n    max_cluster_root = next(perc_graph.nodes_iter())\n\n    # loop over all edges (n == 1..M)\n    for n in range(num_edges):\n        ret['n'] = n + 1\n\n        # draw new edge from permutation\n        edge_index = perm_edges[n]\n        edge = perc_edges[edge_index]\n        ret['edge'] = edge\n\n        # find roots and weights\n        roots = [\n            ds[node] for node in edge\n        ]\n        weights = [\n            ds.weights[root] for root in roots\n        ]\n\n        if roots[0] is not roots[1]:\n            # not same cluster: union!\n            ds.union(*roots)\n            if spanning_cluster:\n                ds_spanning.union(*roots)\n\n                ret['has_spanning_cluster'] = (\n                    ds_spanning[side_roots[0]] == ds_spanning[side_roots[1]]\n                )\n\n            # find new root and weight\n            root = ds[edge[0]]\n            weight = ds.weights[root]\n\n            # moments and maximum cluster size\n\n            # deduct the previous sub-maximum clusters from moments\n            for i in [0, 1]:\n                if roots[i] is max_cluster_root:\n                    continue\n                ret['moments'] -= weights[i] ** np.arange(5)\n\n            if max_cluster_root in roots:\n                # merged with maximum cluster\n                max_cluster_root = root\n                ret['max_cluster_size'] = weight\n            else:\n                # merged previously sub-maximum clusters\n                if ret['max_cluster_size'] >= weight:\n                    # previously largest cluster remains largest cluster\n                    # add merged cluster to moments\n                    ret['moments'] += weight ** np.arange(5)\n                else:\n                    # merged cluster overtook previously largest cluster\n                    # add previously largest cluster to moments\n                    max_cluster_root = root\n                    ret['moments'] += ret['max_cluster_size'] ** np.arange(5)\n                    ret['max_cluster_size'] = weight\n\n        if copy_result:\n            yield copy.deepcopy(ret)\n        else:\n            yield ret", "response": "Generates a successive sample of the states of the given graph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef single_run_arrays(spanning_cluster=True, **kwargs):\n    r'''\n    Generate statistics for a single run\n\n    This is a stand-alone helper function to evolve a single sample state\n    (realization) and return the cluster statistics.\n\n    Parameters\n    ----------\n    spanning_cluster : bool, optional\n        Whether to detect a spanning cluster or not.\n        Defaults to ``True``.\n\n    kwargs : keyword arguments\n        Piped through to :func:`sample_states`\n\n    Returns\n    -------\n\n    ret : dict\n        Cluster statistics\n\n    ret['N'] : int\n        Total number of sites\n\n    ret['M'] : int\n        Total number of bonds\n\n    ret['max_cluster_size'] : 1-D :py:class:`numpy.ndarray` of int, size ``ret['M'] + 1``\n        Array of the sizes of the largest cluster (absolute number of sites) at\n        the respective occupation number.\n\n    ret['has_spanning_cluster'] : 1-D :py:class:`numpy.ndarray` of bool, size ``ret['M'] + 1``\n        Array of booleans for each occupation number.\n        The respective entry is ``True`` if there is a spanning cluster,\n        ``False`` otherwise.\n        Only exists if `spanning_cluster` argument is set to ``True``.\n\n    ret['moments'] : 2-D :py:class:`numpy.ndarray` of int\n        Array of shape ``(5, ret['M'] + 1)``.\n        The ``(k, m)``-th entry is the ``k``-th raw moment of the (absolute)\n        cluster size distribution, with ``k`` ranging from ``0`` to ``4``, at\n        occupation number ``m``.\n\n    See Also\n    --------\n\n    sample_states\n\n    '''\n\n    # initial iteration\n    # we do not need a copy of the result dictionary since we copy the values\n    # anyway\n    kwargs['copy_result'] = False\n    ret = dict()\n\n    for n, state in enumerate(sample_states(\n        spanning_cluster=spanning_cluster, **kwargs\n    )):\n\n        # merge cluster statistics\n        if 'N' in ret:\n            assert ret['N'] == state['N']\n        else:\n            ret['N'] = state['N']\n\n        if 'M' in ret:\n            assert ret['M'] == state['M']\n        else:\n            ret['M'] = state['M']\n            number_of_states = state['M'] + 1\n            max_cluster_size = np.empty(number_of_states)\n            if spanning_cluster:\n                has_spanning_cluster = np.empty(number_of_states, dtype=np.bool)\n            moments = np.empty((5, number_of_states))\n\n        max_cluster_size[n] = state['max_cluster_size']\n        for k in range(5):\n            moments[k, n] = state['moments'][k]\n        if spanning_cluster:\n            has_spanning_cluster[n] = state['has_spanning_cluster']\n\n    ret['max_cluster_size'] = max_cluster_size\n    ret['moments'] = moments\n    if spanning_cluster:\n        ret['has_spanning_cluster'] = has_spanning_cluster\n\n    return ret", "response": "r Generate statistics for a single run of a single state tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _microcanonical_average_spanning_cluster(has_spanning_cluster, alpha):\n    r'''\n    Compute the average number of runs that have a spanning cluster\n\n    Helper function for :func:`microcanonical_averages`\n\n    Parameters\n    ----------\n\n    has_spanning_cluster : 1-D :py:class:`numpy.ndarray` of bool\n        Each entry is the ``has_spanning_cluster`` field of the output of\n        :func:`sample_states`:\n        An entry is ``True`` if there is a spanning cluster in that respective\n        run, and ``False`` otherwise.\n\n    alpha : float\n        Significance level.\n\n    Returns\n    -------\n\n    ret : dict\n        Spanning cluster statistics\n\n    ret['spanning_cluster'] : float\n        The average relative number (Binomial proportion) of runs that have a\n        spanning cluster.\n        This is the Bayesian point estimate of the posterior mean, with a\n        uniform prior.\n\n    ret['spanning_cluster_ci'] : 1-D :py:class:`numpy.ndarray` of float, size 2\n        The lower and upper bounds of the Binomial proportion confidence\n        interval with uniform prior.\n\n    See Also\n    --------\n\n    sample_states : spanning cluster detection\n\n    microcanonical_averages : spanning cluster statistics\n\n    Notes\n    -----\n\n    Averages and confidence intervals for Binomial proportions\n\n    As Cameron [8]_ puts it, the normal approximation to the confidence\n    interval for a Binomial proportion :math:`p` \"suffers a *systematic*\n    decline in performance (...) towards extreme values of :math:`p` near\n    :math:`0` and :math:`1`, generating binomial [confidence intervals]\n    with effective coverage far below the desired level.\" (see also\n    References [6]_ and [7]_).\n\n    A different approach to quantifying uncertainty is Bayesian inference.\n    [5]_\n    For :math:`n` independent Bernoulli trails with common success\n    probability :math:`p`, the *likelihood* to have :math:`k` successes\n    given :math:`p` is the binomial distribution\n\n    .. math::\n\n        P(k|p) = \\binom{n}{k} p^k (1-p)^{n-k} \\equiv B(a,b),\n\n    where :math:`B(a, b)` is the *Beta distribution* with parameters\n    :math:`a = k + 1` and :math:`b = n - k + 1`.\n    Assuming a uniform prior :math:`P(p) = 1`, the *posterior* is [5]_\n\n    .. math::\n\n        P(p|k) = P(k|p)=B(a,b).\n\n    A point estimate is the posterior mean\n\n    .. math::\n\n        \\bar{p} = \\frac{k+1}{n+2}\n\n    with the :math:`1 - \\alpha` credible interval :math:`(p_l, p_u)` given\n    by\n\n    .. math::\n\n        \\int_0^{p_l} dp B(a,b) = \\int_{p_u}^1 dp B(a,b) = \\frac{\\alpha}{2}.\n\n    References\n    ----------\n\n    .. [5] Wasserman, L. All of Statistics (Springer New York, 2004),\n       `doi:10.1007/978-0-387-21736-9 <http://dx.doi.org/10.1007/978-0-387-21736-9>`_.\n\n    .. [6] DasGupta, A., Cai, T. T. & Brown, L. D. Interval Estimation for a\n       Binomial Proportion. Statistical Science 16, 101-133 (2001).\n       `doi:10.1214/ss/1009213286 <http://dx.doi.org/10.1214/ss/1009213286>`_.\n\n    .. [7] Agresti, A. & Coull, B. A. Approximate is Better than \"Exact\" for\n       Interval Estimation of Binomial Proportions. The American Statistician\n       52, 119-126 (1998),\n       `doi:10.2307/2685469 <http://dx.doi.org/10.2307/2685469>`_.\n\n    .. [8] Cameron, E. On the Estimation of Confidence Intervals for Binomial\n       Population Proportions in Astronomy: The Simplicity and Superiority of\n       the Bayesian Approach. Publications of the Astronomical Society of\n       Australia 28, 128-139 (2011),\n       `doi:10.1071/as10046 <http://dx.doi.org/10.1071/as10046>`_.\n\n    '''\n\n    ret = dict()\n    runs = has_spanning_cluster.size\n\n    # Bayesian posterior mean for Binomial proportion (uniform prior)\n    k = has_spanning_cluster.sum(dtype=np.float)\n    ret['spanning_cluster'] = (\n        (k + 1) / (runs + 2)\n    )\n\n    # Bayesian credible interval for Binomial proportion (uniform\n    # prior)\n    ret['spanning_cluster_ci'] = scipy.stats.beta.ppf(\n        [alpha / 2, 1 - alpha / 2], k + 1, runs - k + 1\n    )\n\n    return ret", "response": "r Returns the microcanonical average of the spanning cluster of the given base."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _microcanonical_average_max_cluster_size(max_cluster_size, alpha):\n\n    ret = dict()\n    runs = max_cluster_size.size\n    sqrt_n = np.sqrt(runs)\n\n    max_cluster_size_sample_mean = max_cluster_size.mean()\n    ret['max_cluster_size'] = max_cluster_size_sample_mean\n\n    max_cluster_size_sample_std = max_cluster_size.std(ddof=1)\n    if max_cluster_size_sample_std:\n        old_settings = np.seterr(all='raise')\n        ret['max_cluster_size_ci'] = scipy.stats.t.interval(\n            1 - alpha,\n            df=runs - 1,\n            loc=max_cluster_size_sample_mean,\n            scale=max_cluster_size_sample_std / sqrt_n\n        )\n        np.seterr(**old_settings)\n    else:\n        ret['max_cluster_size_ci'] = (\n            max_cluster_size_sample_mean * np.ones(2)\n        )\n\n    return ret", "response": "Compute the average size of the largest cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the microcanonical average moments of the cluster size distributions.", "response": "def _microcanonical_average_moments(moments, alpha):\n    \"\"\"\n    Compute the average moments of the cluster size distributions\n\n    Helper function for :func:`microcanonical_averages`\n\n    Parameters\n    ----------\n\n    moments : 2-D :py:class:`numpy.ndarray` of int\n        ``moments.shape[1] == 5`.\n        Each array ``moments[r, :]`` is the ``moments`` field of the output of\n        :func:`sample_states`:\n        The ``k``-th entry is the ``k``-th raw moment of the (absolute) cluster\n        size distribution.\n\n    alpha: float\n        Significance level.\n\n    Returns\n    -------\n\n    ret : dict\n        Moment statistics\n\n    ret['moments'] : 1-D :py:class:`numpy.ndarray` of float, size 5\n        The ``k``-th entry is the average ``k``-th raw moment of the (absolute)\n        cluster size distribution, with ``k`` ranging from ``0`` to ``4``.\n\n    ret['moments_ci'] : 2-D :py:class:`numpy.ndarray` of float, shape (5,2)\n        ``ret['moments_ci'][k]`` are the lower and upper bounds of the normal\n        confidence interval of the average ``k``-th raw moment of the\n        (absolute) cluster size distribution, with ``k`` ranging from ``0`` to\n        ``4``.\n\n    See Also\n    --------\n\n    sample_states : computation of moments\n\n    microcanonical_averages : moment statistics\n    \"\"\"\n\n    ret = dict()\n    runs = moments.shape[0]\n    sqrt_n = np.sqrt(runs)\n\n    moments_sample_mean = moments.mean(axis=0)\n    ret['moments'] = moments_sample_mean\n\n    moments_sample_std = moments.std(axis=0, ddof=1)\n    ret['moments_ci'] = np.empty((5, 2))\n    for k in range(5):\n        if moments_sample_std[k]:\n            old_settings = np.seterr(all='raise')\n            ret['moments_ci'][k] = scipy.stats.t.interval(\n                1 - alpha,\n                df=runs - 1,\n                loc=moments_sample_mean[k],\n                scale=moments_sample_std[k] / sqrt_n\n            )\n            np.seterr(**old_settings)\n        else:\n            ret['moments_ci'][k] = (\n                moments_sample_mean[k] * np.ones(2)\n            )\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef microcanonical_averages(\n    graph, runs=40, spanning_cluster=True, model='bond', alpha=alpha_1sigma,\n    copy_result=True\n):\n    r'''\n    Generate successive microcanonical percolation ensemble averages\n\n    This is a :ref:`generator function <python:tut-generators>` to successively\n    add one edge at a time from the graph to the percolation model for a number\n    of independent runs in parallel.\n    At each iteration, it calculates and returns the averaged cluster\n    statistics.\n\n    Parameters\n    ----------\n    graph : networkx.Graph\n        The substrate graph on which percolation is to take place\n\n    runs : int, optional\n        Number of independent runs.\n        Defaults to ``40``.\n\n    spanning_cluster : bool, optional\n        Defaults to ``True``.\n\n    model : str, optional\n        The percolation model (either ``'bond'`` or ``'site'``).\n        Defaults to ``'bond'``.\n\n        .. note:: Other models than ``'bond'`` are not supported yet.\n\n    alpha: float, optional\n        Significance level.\n        Defaults to 1 sigma of the normal distribution.\n        ``1 - alpha`` is the confidence level.\n\n    copy_result : bool, optional\n        Whether to return a copy or a reference to the result dictionary.\n        Defaults to ``True``.\n\n    Yields\n    ------\n    ret : dict\n        Cluster statistics\n\n    ret['n'] : int\n        Number of occupied bonds\n\n    ret['N'] : int\n        Total number of sites\n\n    ret['M'] : int\n        Total number of bonds\n\n    ret['spanning_cluster'] : float\n        The average number (Binomial proportion) of runs that have a spanning\n        cluster.\n        This is the Bayesian point estimate of the posterior mean, with a\n        uniform prior.\n        Only exists if `spanning_cluster` is set to ``True``.\n\n    ret['spanning_cluster_ci'] : 1-D :py:class:`numpy.ndarray` of float, size 2\n        The lower and upper bounds of the Binomial proportion confidence\n        interval with uniform prior.\n        Only exists if `spanning_cluster` is set to ``True``.\n\n    ret['max_cluster_size'] : float\n        Average size of the largest cluster (absolute number of sites)\n\n    ret['max_cluster_size_ci'] : 1-D :py:class:`numpy.ndarray` of float, size 2\n        Lower and upper bounds of the normal confidence interval of the average\n        size of the largest cluster (absolute number of sites)\n\n    ret['moments'] : 1-D :py:class:`numpy.ndarray` of float, size 5\n        The ``k``-th entry is the average ``k``-th raw moment of the (absolute)\n        cluster size distribution, with ``k`` ranging from ``0`` to ``4``.\n\n    ret['moments_ci'] : 2-D :py:class:`numpy.ndarray` of float, shape (5,2)\n        ``ret['moments_ci'][k]`` are the lower and upper bounds of the normal\n        confidence interval of the average ``k``-th raw moment of the\n        (absolute) cluster size distribution, with ``k`` ranging from ``0`` to\n        ``4``.\n\n    Raises\n    ------\n    ValueError\n        If `runs` is not a positive integer\n\n    ValueError\n        If `alpha` is not a float in the interval (0, 1)\n\n    See also\n    --------\n\n    sample_states\n\n    percolate.percolate._microcanonical_average_spanning_cluster\n\n    percolate.percolate._microcanonical_average_max_cluster_size\n\n    Notes\n    -----\n    Iterating through this generator corresponds to several parallel runs of\n    the Newman-Ziff algorithm.\n    Each iteration yields a microcanonical percolation ensemble for the number\n    :math:`n` of occupied bonds. [9]_\n    The first iteration yields the trivial microcanonical percolation ensemble\n    with :math:`n = 0` occupied bonds.\n\n    Spanning cluster\n\n        .. seealso:: :py:func:`sample_states`\n\n    Raw moments of the cluster size distribution\n\n        .. seealso:: :py:func:`sample_states`\n\n\n    References\n    ----------\n    .. [9] Newman, M. E. J. & Ziff, R. M. Fast monte carlo algorithm for site\n        or bond percolation. Physical Review E 64, 016706+ (2001),\n        `doi:10.1103/physreve.64.016706 <http://dx.doi.org/10.1103/physreve.64.016706>`_.\n\n    '''\n\n    try:\n        runs = int(runs)\n    except:\n        raise ValueError(\"runs needs to be a positive integer\")\n\n    if runs <= 0:\n        raise ValueError(\"runs needs to be a positive integer\")\n\n    try:\n        alpha = float(alpha)\n    except:\n        raise ValueError(\"alpha needs to be a float in the interval (0, 1)\")\n\n    if alpha <= 0.0 or alpha >= 1.0:\n        raise ValueError(\"alpha needs to be a float in the interval (0, 1)\")\n\n    # initial iteration\n    # we do not need a copy of the result dictionary since we copy the values\n    # anyway\n    run_iterators = [\n        sample_states(\n            graph, spanning_cluster=spanning_cluster, model=model,\n            copy_result=False\n        )\n        for _ in range(runs)\n    ]\n\n    ret = dict()\n    for microcanonical_ensemble in zip(*run_iterators):\n        # merge cluster statistics\n        ret['n'] = microcanonical_ensemble[0]['n']\n        ret['N'] = microcanonical_ensemble[0]['N']\n        ret['M'] = microcanonical_ensemble[0]['M']\n\n        max_cluster_size = np.empty(runs)\n        moments = np.empty((runs, 5))\n        if spanning_cluster:\n            has_spanning_cluster = np.empty(runs)\n\n        for r, state in enumerate(microcanonical_ensemble):\n            assert state['n'] == ret['n']\n            assert state['N'] == ret['N']\n            assert state['M'] == ret['M']\n            max_cluster_size[r] = state['max_cluster_size']\n            moments[r] = state['moments']\n            if spanning_cluster:\n                has_spanning_cluster[r] = state['has_spanning_cluster']\n\n        ret.update(_microcanonical_average_max_cluster_size(\n            max_cluster_size, alpha\n        ))\n\n        ret.update(_microcanonical_average_moments(moments, alpha))\n\n        if spanning_cluster:\n            ret.update(_microcanonical_average_spanning_cluster(\n                has_spanning_cluster, alpha\n            ))\n\n        if copy_result:\n            yield copy.deepcopy(ret)\n        else:\n            yield ret", "response": "r Returns a dictionary of microcanonical percolation ensemble averages for the given number of independent runs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a linear chain with auxiliary nodes for spanning cluster detection.", "response": "def spanning_1d_chain(length):\n    \"\"\"\n    Generate a linear chain with auxiliary nodes for spanning cluster detection\n\n    Parameters\n    ----------\n\n    length : int\n       Number of nodes in the chain, excluding the auxiliary nodes.\n\n    Returns\n    -------\n\n    networkx.Graph\n       A linear chain graph with auxiliary nodes for spanning cluster detection\n\n    See Also\n    --------\n\n    sample_states : spanning cluster detection\n\n    \"\"\"\n    ret = nx.grid_graph(dim=[int(length + 2)])\n\n    ret.node[0]['span'] = 0\n    ret[0][1]['span'] = 0\n    ret.node[length + 1]['span'] = 1\n    ret[length][length + 1]['span'] = 1\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef spanning_2d_grid(length):\n    ret = nx.grid_2d_graph(length + 2, length)\n\n    for i in range(length):\n        # side 0\n        ret.node[(0, i)]['span'] = 0\n        ret[(0, i)][(1, i)]['span'] = 0\n\n        # side 1\n        ret.node[(length + 1, i)]['span'] = 1\n        ret[(length + 1, i)][(length, i)]['span'] = 1\n\n    return ret", "response": "Generate a 2D grid of the given number of nodes in one dimension excluding the auxiliary nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef microcanonical_averages_arrays(microcanonical_averages):\n\n    ret = dict()\n\n    for n, microcanonical_average in enumerate(microcanonical_averages):\n        assert n == microcanonical_average['n']\n        if n == 0:\n            num_edges = microcanonical_average['M']\n            num_sites = microcanonical_average['N']\n            spanning_cluster = ('spanning_cluster' in microcanonical_average)\n            ret['max_cluster_size'] = np.empty(num_edges + 1)\n            ret['max_cluster_size_ci'] = np.empty((num_edges + 1, 2))\n\n            if spanning_cluster:\n                ret['spanning_cluster'] = np.empty(num_edges + 1)\n                ret['spanning_cluster_ci'] = np.empty((num_edges + 1, 2))\n\n            ret['moments'] = np.empty((5, num_edges + 1))\n            ret['moments_ci'] = np.empty((5, num_edges + 1, 2))\n\n        ret['max_cluster_size'][n] = microcanonical_average['max_cluster_size']\n        ret['max_cluster_size_ci'][n] = (\n            microcanonical_average['max_cluster_size_ci']\n        )\n\n        if spanning_cluster:\n            ret['spanning_cluster'][n] = (\n                microcanonical_average['spanning_cluster']\n            )\n            ret['spanning_cluster_ci'][n] = (\n                microcanonical_average['spanning_cluster_ci']\n            )\n\n        ret['moments'][:, n] = microcanonical_average['moments']\n        ret['moments_ci'][:, n] = microcanonical_average['moments_ci']\n\n    # normalize by number of sites\n    for key in ret:\n        if 'spanning_cluster' in key:\n            continue\n        ret[key] /= num_sites\n\n    ret['M'] = num_edges\n    ret['N'] = num_sites\n    return ret", "response": "Returns a dictionary that contains the microcanonical averages over all iteration steps into a single array."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _binomial_pmf(n, p):\n\n    n = int(n)\n    ret = np.empty(n + 1)\n\n    nmax = int(np.round(p * n))\n\n    ret[nmax] = 1.0\n\n    old_settings = np.seterr(under='ignore')  # seterr to known value\n\n    for i in range(nmax + 1, n + 1):\n        ret[i] = ret[i - 1] * (n - i + 1.0) / i * p / (1.0 - p)\n\n    for i in range(nmax - 1, -1, -1):\n        ret[i] = ret[i + 1] * (i + 1.0) / (n - i) * (1.0 - p) / p\n\n    np.seterr(**old_settings)  # reset to default\n\n    return ret / ret.sum()", "response": "Compute the binomial PMF according to Newman and Ziff."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the canonical cluster statistics from microcanonical statistics This is according to Newman and Ziff, Equation (2). Note that we also simply average the bounds of the confidence intervals according to this formula. Parameters ---------- ps : iterable of float Each entry is a probability for which to form the canonical ensemble and compute the weighted statistics from the microcanonical statistics microcanonical_averages_arrays Typically the output of :func:`microcanonical_averages_arrays` Returns ------- ret : dict Canonical ensemble cluster statistics ret['ps'] : iterable of float The parameter `ps` ret['N'] : int Total number of sites ret['M'] : int Total number of bonds ret['spanning_cluster'] : 1-D :py:class:`numpy.ndarray` of float The percolation probability: The normalized average number of runs that have a spanning cluster. ret['spanning_cluster_ci'] : 2-D :py:class:`numpy.ndarray` of float, size 2 The lower and upper bounds of the percolation probability. ret['max_cluster_size'] : 1-D :py:class:`numpy.ndarray` of float The percolation strength: Average relative size of the largest cluster ret['max_cluster_size_ci'] : 2-D :py:class:`numpy.ndarray` of float Lower and upper bounds of the normal confidence interval of the percolation strength. ret['moments'] : 2-D :py:class:`numpy.ndarray` of float, shape (5, M + 1) Average raw moments of the (relative) cluster size distribution. ret['moments_ci'] : 3-D :py:class:`numpy.ndarray` of float, shape (5, M + 1, 2) Lower and upper bounds of the normal confidence interval of the raw moments of the (relative) cluster size distribution. See Also -------- microcanonical_averages microcanonical_averages_arrays", "response": "def canonical_averages(ps, microcanonical_averages_arrays):\n    \"\"\"\n    Compute the canonical cluster statistics from microcanonical statistics\n\n    This is according to Newman and Ziff, Equation (2).\n    Note that we also simply average the bounds of the confidence intervals\n    according to this formula.\n\n    Parameters\n    ----------\n\n    ps : iterable of float\n       Each entry is a probability for which to form the canonical ensemble\n       and compute the weighted statistics from the microcanonical statistics\n\n    microcanonical_averages_arrays\n       Typically the output of :func:`microcanonical_averages_arrays`\n\n    Returns\n    -------\n\n    ret : dict\n       Canonical ensemble cluster statistics\n\n    ret['ps'] : iterable of float\n        The parameter `ps`\n\n    ret['N'] : int\n        Total number of sites\n\n    ret['M'] : int\n        Total number of bonds\n\n    ret['spanning_cluster'] : 1-D :py:class:`numpy.ndarray` of float\n        The percolation probability:\n        The normalized average number of runs that have a spanning cluster.\n\n    ret['spanning_cluster_ci'] : 2-D :py:class:`numpy.ndarray` of float, size 2\n        The lower and upper bounds of the percolation probability.\n\n    ret['max_cluster_size'] : 1-D :py:class:`numpy.ndarray` of float\n        The percolation strength:\n        Average relative size of the largest cluster\n\n    ret['max_cluster_size_ci'] : 2-D :py:class:`numpy.ndarray` of float\n        Lower and upper bounds of the normal confidence interval of the\n        percolation strength.\n\n    ret['moments'] : 2-D :py:class:`numpy.ndarray` of float, shape (5, M + 1)\n        Average raw moments of the (relative) cluster size distribution.\n\n    ret['moments_ci'] : 3-D :py:class:`numpy.ndarray` of float, shape (5, M + 1, 2)\n        Lower and upper bounds of the normal confidence interval of the raw\n        moments of the (relative) cluster size distribution.\n\n    See Also\n    --------\n\n    microcanonical_averages\n\n    microcanonical_averages_arrays\n\n\n    \"\"\"\n\n    num_sites = microcanonical_averages_arrays['N']\n    num_edges = microcanonical_averages_arrays['M']\n    spanning_cluster = ('spanning_cluster' in microcanonical_averages_arrays)\n\n    ret = dict()\n    ret['ps'] = ps\n    ret['N'] = num_sites\n    ret['M'] = num_edges\n\n    ret['max_cluster_size'] = np.empty(ps.size)\n    ret['max_cluster_size_ci'] = np.empty((ps.size, 2))\n\n    if spanning_cluster:\n        ret['spanning_cluster'] = np.empty(ps.size)\n        ret['spanning_cluster_ci'] = np.empty((ps.size, 2))\n\n    ret['moments'] = np.empty((5, ps.size))\n    ret['moments_ci'] = np.empty((5, ps.size, 2))\n\n    for p_index, p in enumerate(ps):\n        binomials = _binomial_pmf(n=num_edges, p=p)\n\n        for key, value in microcanonical_averages_arrays.items():\n            if len(key) <= 1:\n                continue\n\n            if key in ['max_cluster_size', 'spanning_cluster']:\n                ret[key][p_index] = np.sum(binomials * value)\n            elif key in ['max_cluster_size_ci', 'spanning_cluster_ci']:\n                ret[key][p_index] = np.sum(\n                    np.tile(binomials, (2, 1)).T * value, axis=0\n                )\n            elif key == 'moments':\n                ret[key][:, p_index] = np.sum(\n                    np.tile(binomials, (5, 1)) * value, axis=1\n                )\n            elif key == 'moments_ci':\n                ret[key][:, p_index] = np.sum(\n                    np.rollaxis(np.tile(binomials, (5, 2, 1)), 2, 1) * value,\n                    axis=1\n                )\n            else:\n                raise NotImplementedError(\n                    '{}-dimensional array'.format(value.ndim)\n                )\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef statistics(\n    graph, ps, spanning_cluster=True, model='bond', alpha=alpha_1sigma, runs=40\n):\n    \"\"\"\n    Helper function to compute percolation statistics\n\n    See Also\n    --------\n\n    canonical_averages\n\n    microcanonical_averages\n\n    sample_states\n\n    \"\"\"\n\n    my_microcanonical_averages = microcanonical_averages(\n        graph=graph, runs=runs, spanning_cluster=spanning_cluster, model=model,\n        alpha=alpha\n    )\n\n    my_microcanonical_averages_arrays = microcanonical_averages_arrays(\n        my_microcanonical_averages\n    )\n\n    return canonical_averages(ps, my_microcanonical_averages_arrays)", "response": "Helper function to compute percolation statistics for a given cluster."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrendering the graph as an HTML string.", "response": "def to_html(graph: BELGraph) -> str:\n    \"\"\"Render the graph as an HTML string.\n\n    Common usage may involve writing to a file like:\n\n    >>> from pybel.examples import sialic_acid_graph\n    >>> with open('html_output.html', 'w') as file:\n    ...     print(to_html(sialic_acid_graph), file=file)\n    \"\"\"\n    context = get_network_summary_dict(graph)\n    summary_dict = graph.summary_dict()\n\n    citation_years = context['citation_years']\n    function_count = context['function_count']\n    relation_count = context['relation_count']\n    error_count = context['error_count']\n    transformations_count = context['modifications_count']\n    hub_data = context['hub_data']\n    disease_data = context['disease_data']\n    authors_count = context['authors_count']\n    variants_count = context['variants_count']\n    namespaces_count = context['namespaces_count']\n    confidence_count = context['confidence_count']\n    confidence_data = [\n        (label, confidence_count.get(label, 0))\n        for label in ('None', 'Very Low', 'Low', 'Medium', 'High', 'Very High')\n    ]\n\n    template = environment.get_template('index.html')\n    return template.render(\n        graph=graph,\n        # Node Charts\n        chart_1_data=prepare_c3(function_count, 'Node Count'),\n        chart_6_data=prepare_c3(namespaces_count, 'Node Count'),\n        chart_5_data=prepare_c3(variants_count, 'Node Count'),\n        number_variants=sum(variants_count.values()),\n        number_namespaces=len(namespaces_count),\n        # Edge Charts\n        chart_2_data=prepare_c3(relation_count, 'Edge Count'),\n        chart_4_data=prepare_c3(transformations_count, 'Edge Count') if transformations_count else None,\n        number_transformations=sum(transformations_count.values()),\n        # Error Charts\n        chart_3_data=prepare_c3(error_count, 'Error Type') if error_count else None,\n        # Topology Charts\n        chart_7_data=prepare_c3(hub_data, 'Degree'),\n        chart_9_data=prepare_c3(disease_data, 'Degree') if disease_data else None,\n        # Bibliometrics Charts\n        chart_authors_count=prepare_c3(authors_count, 'Edges Contributed'),\n        chart_10_data=prepare_c3_time_series(citation_years, 'Number of Articles') if citation_years else None,\n        chart_confidence_count=prepare_c3(confidence_data, 'Edge Count'),\n        summary_dict=summary_dict,\n        # Everything else :)\n        **context\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_network_summary_dict(graph: BELGraph) -> Mapping:\n    return dict(\n        # Counters\n        function_count=count_functions(graph),\n        modifications_count=get_modifications_count(graph),\n        relation_count=count_relations(graph),\n        authors_count=count_authors(graph).most_common(15),\n        variants_count=count_variants(graph),\n        namespaces_count=count_namespaces(graph),\n        hub_data={\n            (\n                node.name or node.identifier\n                if NAME in node or IDENTIFIER in node else\n                str(node)\n            ): degree\n            for node, degree in get_top_hubs(graph, n=15)\n        },\n        disease_data={\n            (\n                node.name or node.identifier\n                if NAME in node or IDENTIFIER in node else\n                str(node)\n            ): count\n            for node, count in get_top_pathologies(graph, n=15)\n        },\n        # BioGrammar\n        regulatory_pairs=[\n            get_pair_tuple(u, v)\n            for u, v in get_regulatory_pairs(graph)\n        ],\n        unstable_pairs=list(itt.chain(\n            (get_pair_tuple(u, v) + ('Chaotic',) for u, v, in get_chaotic_pairs(graph)),\n            (get_pair_tuple(u, v) + ('Dampened',) for u, v, in get_dampened_pairs(graph)),\n        )),\n        contradictory_pairs=[\n            get_pair_tuple(u, v) + (relation,)\n            for u, v, relation in get_contradiction_summary(graph)\n        ],\n        contradictory_triplets=list(itt.chain(\n            (get_triplet_tuple(a, b, c) + ('Separate',) for a, b, c in\n             get_separate_unstable_correlation_triples(graph)),\n            (get_triplet_tuple(a, b, c) + ('Mutual',) for a, b, c in get_mutually_unstable_correlation_triples(graph)),\n            (get_triplet_tuple(a, b, c) + ('Jens',) for a, b, c in get_jens_unstable(graph)),\n            (get_triplet_tuple(a, b, c) + ('Increase Mismatch',) for a, b, c in get_increase_mismatch_triplets(graph)),\n            (get_triplet_tuple(a, b, c) + ('Decrease Mismatch',) for a, b, c in get_decrease_mismatch_triplets(graph)),\n        )),\n        unstable_triplets=list(itt.chain(\n            (get_triplet_tuple(a, b, c) + ('Chaotic',) for a, b, c in get_chaotic_triplets(graph)),\n            (get_triplet_tuple(a, b, c) + ('Dampened',) for a, b, c in get_dampened_triplets(graph)),\n        )),\n        causal_pathologies=sorted({\n            get_pair_tuple(u, v) + (graph[u][v][k][RELATION],)\n            for u, v, k in filter_edges(graph, has_pathology_causal)\n        }),\n        # Misc.\n        undefined_namespaces=get_undefined_namespaces(graph),\n        undefined_annotations=get_undefined_annotations(graph),\n        namespaces_with_incorrect_names=get_namespaces_with_incorrect_names(graph),\n        unused_namespaces=get_unused_namespaces(graph),\n        unused_annotations=get_unused_annotations(graph),\n        unused_list_annotation_values=get_unused_list_annotation_values(graph),\n        naked_names=get_naked_names(graph),\n        error_count=count_error_types(graph),\n        # Errors\n        error_groups=get_most_common_errors(graph),\n        syntax_errors=get_syntax_errors(graph),\n        # Bibliometrics\n        citation_years=get_citation_years(graph),\n        confidence_count=count_confidences(graph),\n    )", "response": "Create a summary dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the pair as a tuple of BEL and hashes.", "response": "def get_pair_tuple(a: BaseEntity, b: BaseEntity) -> Tuple[str, str, str, str]:\n    \"\"\"Get the pair as a tuple of BEL/hashes.\"\"\"\n    return a.as_bel(), a.sha512, b.as_bel(), b.sha512"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the triple as a tuple of BEL / hashes.", "response": "def get_triplet_tuple(a: BaseEntity, b: BaseEntity, c: BaseEntity) -> Tuple[str, str, str, str, str, str]:\n    \"\"\"Get the triple as a tuple of BEL/hashes.\"\"\"\n    return a.as_bel(), a.sha512, b.as_bel(), b.sha512, c.as_bel(), c.sha512"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rank_causalr_hypothesis(graph, node_to_regulation, regulator_node):\n    upregulation_hypothesis = {\n        'correct': 0,\n        'incorrect': 0,\n        'ambiguous': 0\n    }\n    downregulation_hypothesis = {\n        'correct': 0,\n        'incorrect': 0,\n        'ambiguous': 0\n    }\n\n    targets = [\n        node\n        for node in node_to_regulation\n        if node != regulator_node\n    ]\n\n    predicted_regulations = run_cna(graph, regulator_node, targets)  # + signed hypothesis\n\n    for _, target_node, predicted_regulation in predicted_regulations:\n\n        if (predicted_regulation is Effect.inhibition or predicted_regulation is Effect.activation) and (\n                predicted_regulation.value == node_to_regulation[target_node]):\n            upregulation_hypothesis['correct'] += 1\n            downregulation_hypothesis['incorrect'] += 1\n\n        elif predicted_regulation is Effect.ambiguous:\n            upregulation_hypothesis['ambiguous'] += 1\n            downregulation_hypothesis['ambiguous'] += 1\n\n        elif predicted_regulation is Effect.no_effect:\n            continue\n\n        else:\n            downregulation_hypothesis['correct'] += 1\n            upregulation_hypothesis['incorrect'] += 1\n\n    upregulation_hypothesis['score'] = upregulation_hypothesis['correct'] - upregulation_hypothesis['incorrect']\n    downregulation_hypothesis['score'] = downregulation_hypothesis['correct'] - downregulation_hypothesis['incorrect']\n\n    return upregulation_hypothesis, downregulation_hypothesis", "response": "This method tests the regulator hypothesis of the given node on the input data using the causal r algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the CNA algorithm.", "response": "def run_cna(graph, root, targets, relationship_dict=None):\n    \"\"\" Returns the effect from the root to the target nodes represented as {-1,1}\n\n    :param pybel.BELGraph graph: A BEL graph\n    :param BaseEntity root: The root node\n    :param iter targets: The targets nodes\n    :param dict relationship_dict: dictionary with relationship effects\n    :return list[tuple]:\n    \"\"\"\n    causal_effects = []\n\n    relationship_dict = causal_effect_dict if relationship_dict is None else relationship_dict\n\n    for target in targets:\n        try:\n            shortest_paths = nx.all_shortest_paths(graph, source=root, target=target)\n\n            effects_in_path = set()\n\n            for shortest_path in shortest_paths:\n                effects_in_path.add(get_path_effect(graph, shortest_path, relationship_dict))\n\n            if len(effects_in_path) == 1:\n                causal_effects.append((root, target, next(iter(effects_in_path))))  # Append the only predicted effect\n\n            elif Effect.activation in effects_in_path and Effect.inhibition in effects_in_path:\n                causal_effects.append((root, target, Effect.ambiguous))\n\n            elif Effect.activation in effects_in_path and Effect.inhibition not in effects_in_path:\n                causal_effects.append((root, target, Effect.activation))\n\n            elif Effect.inhibition in effects_in_path and Effect.activation not in effects_in_path:\n                causal_effects.append((root, target, Effect.inhibition))\n\n            else:\n                log.warning('Exception in set: {}.'.format(effects_in_path))\n\n        except nx.NetworkXNoPath:\n            log.warning('No shortest path between: {} and {}.'.format(root, target))\n\n    return causal_effects"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_path_effect(graph, path, relationship_dict):\n    causal_effect = []\n\n    for predecessor, successor in pairwise(path):\n\n        if pair_has_contradiction(graph, predecessor, successor):\n            return Effect.ambiguous\n\n        edges = graph.get_edge_data(predecessor, successor)\n\n        edge_key, edge_relation, _ = rank_edges(edges)\n\n        relation = graph[predecessor][successor][edge_key][RELATION]\n\n        # Returns Effect.no_effect if there is a non causal edge in path\n        if relation not in relationship_dict or relationship_dict[relation] == 0:\n            return Effect.no_effect\n\n        causal_effect.append(relationship_dict[relation])\n\n    final_effect = reduce(lambda x, y: x * y, causal_effect)\n\n    return Effect.activation if final_effect == 1 else Effect.inhibition", "response": "Calculate the final effect of the root node to the sink node in the path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rank_edges(edges, edge_ranking=None):\n    edge_ranking = default_edge_ranking if edge_ranking is None else edge_ranking\n\n    edges_scores = [\n        (edge_id, edge_data[RELATION], edge_ranking[edge_data[RELATION]])\n        for edge_id, edge_data in edges.items()\n    ]\n\n    return max(edges_scores, key=itemgetter(2))", "response": "Return the highest ranked edge from a multiedge."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngrouping the nodes occurring in edges by the given annotation.", "response": "def group_nodes_by_annotation(graph: BELGraph, annotation: str = 'Subgraph') -> Mapping[str, Set[BaseEntity]]:\n    \"\"\"Group the nodes occurring in edges by the given annotation.\"\"\"\n    result = defaultdict(set)\n\n    for u, v, d in graph.edges(data=True):\n        if not edge_has_annotation(d, annotation):\n            continue\n\n        result[d[ANNOTATIONS][annotation]].add(u)\n        result[d[ANNOTATIONS][annotation]].add(v)\n\n    return dict(result)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a mapping from subgraphs to their average value based on the average of all nodes values.", "response": "def average_node_annotation(graph: BELGraph,\n                            key: str,\n                            annotation: str = 'Subgraph',\n                            aggregator: Optional[Callable[[Iterable[X]], X]] = None,\n                            ) -> Mapping[str, X]:\n    \"\"\"Groups graph into subgraphs and assigns each subgraph a score based on the average of all nodes values\n    for the given node key\n\n    :param pybel.BELGraph graph: A BEL graph\n    :param key: The key in the node data dictionary representing the experimental data\n    :param annotation: A BEL annotation to use to group nodes\n    :param aggregator: A function from list of values -> aggregate value. Defaults to taking the average of a list of\n                       floats.\n    :type aggregator: lambda\n    \"\"\"\n\n    if aggregator is None:\n        def aggregator(x):\n            \"\"\"Calculates the average\"\"\"\n            return sum(x) / len(x)\n\n    result = {}\n\n    for subgraph, nodes in group_nodes_by_annotation(graph, annotation).items():\n        values = [graph.nodes[node][key] for node in nodes if key in graph.nodes[node]]\n        result[subgraph] = aggregator(values)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef group_nodes_by_annotation_filtered(graph: BELGraph,\n                                       node_predicates: NodePredicates = None,\n                                       annotation: str = 'Subgraph',\n                                       ) -> Mapping[str, Set[BaseEntity]]:\n    \"\"\"Group the nodes occurring in edges by the given annotation, with a node filter applied.\n\n    :param graph: A BEL graph\n    :param node_predicates: A predicate or list of predicates (graph, node) -> bool\n    :param annotation: The annotation to use for grouping\n    :return: A dictionary of {annotation value: set of nodes}\n    \"\"\"\n    node_filter = concatenate_node_predicates(node_predicates)\n\n    return {\n        key: {\n            node\n            for node in nodes\n            if node_filter(graph, node)\n        }\n        for key, nodes in group_nodes_by_annotation(graph, annotation).items()\n    }", "response": "Group the nodes occurring in edges by the given annotation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dict with keys = nodes that match the namespace and in names and values other nodes = variants orthologous or this node.", "response": "def get_mapped_nodes(graph: BELGraph, namespace: str, names: Iterable[str]) -> Mapping[BaseEntity, Set[BaseEntity]]:\n    \"\"\"Return a dict with keys: nodes that match the namespace and in names and values other nodes (complexes, variants, orthologous...) or this node.\n    \n    :param graph: A BEL graph\n    :param namespace: The namespace to search\n    :param names: List or set of values from which we want to map nodes from\n    :return: Main node to variants/groups.\n    \"\"\"\n    parent_to_variants = defaultdict(set)\n    names = set(names)\n\n    for u, v, d in graph.edges(data=True):\n        if d[RELATION] in {HAS_MEMBER, HAS_COMPONENT} and v.get(NAMESPACE) == namespace and v.get(NAME) in names:\n            parent_to_variants[v].add(u)\n\n        elif d[RELATION] == HAS_VARIANT and u.get(NAMESPACE) == namespace and u.get(NAME) in names:\n            parent_to_variants[u].add(v)\n\n        elif d[RELATION] == ORTHOLOGOUS and u.get(NAMESPACE) == namespace and u.get(NAME) in names:\n            parent_to_variants[u].add(v)\n\n    return dict(parent_to_variants)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_expand_node_neighborhood_by_hash(manager: Manager) -> Callable[[BELGraph, BELGraph, str], None]:\n\n    @uni_in_place_transformation\n    def expand_node_neighborhood_by_hash(universe: BELGraph, graph: BELGraph, node_hash: str) -> None:\n        \"\"\"Expand around the neighborhoods of a node by identifier.\"\"\"\n        node = manager.get_dsl_by_hash(node_hash)\n        return expand_node_neighborhood(universe, graph, node)\n\n    return expand_node_neighborhood_by_hash", "response": "Builds an expand function that expands around the neighborhoods of a node by its hash."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds a delete function that can be used to remove a node by its hash.", "response": "def build_delete_node_by_hash(manager: Manager) -> Callable[[BELGraph, str], None]:\n    \"\"\"Make a delete function that's bound to the manager.\"\"\"\n\n    @in_place_transformation\n    def delete_node_by_hash(graph: BELGraph, node_hash: str) -> None:\n        \"\"\"Remove a node by identifier.\"\"\"\n        node = manager.get_dsl_by_hash(node_hash)\n        graph.remove_node(node)\n\n    return delete_node_by_hash"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bel_to_spia_matrices(graph: BELGraph) -> Mapping[str, pd.DataFrame]:\n    index_nodes = get_matrix_index(graph)\n    spia_matrices = build_spia_matrices(index_nodes)\n\n    for u, v, edge_data in graph.edges(data=True):\n        # Both nodes are CentralDogma abundances\n        if isinstance(u, CentralDogma) and isinstance(v, CentralDogma):\n            # Update matrix dict\n            update_spia_matrices(spia_matrices, u, v, edge_data)\n\n        # Subject is CentralDogmaAbundance and node is ListAbundance\n        elif isinstance(u, CentralDogma) and isinstance(v, ListAbundance):\n            # Add a relationship from subject to each of the members in the object\n            for node in v.members:\n                # Skip if the member is not in CentralDogma\n                if not isinstance(node, CentralDogma):\n                    continue\n\n                update_spia_matrices(spia_matrices, u, node, edge_data)\n\n        # Subject is ListAbundance and node is CentralDogmaAbundance\n        elif isinstance(u, ListAbundance) and isinstance(v, CentralDogma):\n            # Add a relationship from each of the members of the subject to the object\n            for node in u.members:\n                # Skip if the member is not in CentralDogma\n                if not isinstance(node, CentralDogma):\n                    continue\n\n                update_spia_matrices(spia_matrices, node, v, edge_data)\n\n        # Both nodes are ListAbundance\n        elif isinstance(u, ListAbundance) and isinstance(v, ListAbundance):\n            for sub_member, obj_member in product(u.members, v.members):\n                # Update matrix if both are CentralDogma\n                if isinstance(sub_member, CentralDogma) and isinstance(obj_member, CentralDogma):\n                    update_spia_matrices(spia_matrices, sub_member, obj_member, edge_data)\n\n        # else Not valid edge\n\n    return spia_matrices", "response": "Convert a BEL graph to a list of SPIA matrices."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn set of HGNC names from Proteins / Rnas / Genes / miRNA nodes that can be used by SPIA.", "response": "def get_matrix_index(graph: BELGraph) -> Set[str]:\n    \"\"\"Return set of HGNC names from Proteins/Rnas/Genes/miRNA, nodes that can be used by SPIA.\"\"\"\n    # TODO: Using HGNC Symbols for now\n    return {\n        node.name\n        for node in graph\n        if isinstance(node, CentralDogma) and node.namespace.upper() == 'HGNC'\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_spia_matrices(nodes: Set[str]) -> Dict[str, pd.DataFrame]:\n    nodes = list(sorted(nodes))\n\n    # Create sheets of the excel in the given order\n    matrices = OrderedDict()\n    for relation in KEGG_RELATIONS:\n        matrices[relation] = pd.DataFrame(0, index=nodes, columns=nodes)\n\n    return matrices", "response": "Build an adjacency matrix for each KEGG relationship and return in a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_spia_matrices(spia_matrices: Dict[str, pd.DataFrame],\n                         u: CentralDogma,\n                         v: CentralDogma,\n                         edge_data: EdgeData,\n                         ) -> None:\n    \"\"\"Populate the adjacency matrix.\"\"\"\n    if u.namespace.upper() != 'HGNC' or v.namespace.upper() != 'HGNC':\n        return\n\n    u_name = u.name\n    v_name = v.name\n    relation = edge_data[RELATION]\n\n    if relation in CAUSAL_INCREASE_RELATIONS:\n        # If it has pmod check which one and add it to the corresponding matrix\n        if v.variants and any(isinstance(variant, ProteinModification) for variant in v.variants):\n            for variant in v.variants:\n                if not isinstance(variant, ProteinModification):\n                    continue\n                if variant[IDENTIFIER][NAME] == \"Ub\":\n                    spia_matrices[\"activation_ubiquination\"][u_name][v_name] = 1\n                elif variant[IDENTIFIER][NAME] == \"Ph\":\n                    spia_matrices[\"activation_phosphorylation\"][u_name][v_name] = 1\n        elif isinstance(v, (Gene, Rna)):  # Normal increase, add activation\n            spia_matrices['expression'][u_name][v_name] = 1\n        else:\n            spia_matrices['activation'][u_name][v_name] = 1\n\n    elif relation in CAUSAL_DECREASE_RELATIONS:\n        # If it has pmod check which one and add it to the corresponding matrix\n        if v.variants and any(isinstance(variant, ProteinModification) for variant in v.variants):\n            for variant in v.variants:\n                if not isinstance(variant, ProteinModification):\n                    continue\n                if variant[IDENTIFIER][NAME] == \"Ub\":\n                    spia_matrices['inhibition_ubiquination'][u_name][v_name] = 1\n                elif variant[IDENTIFIER][NAME] == \"Ph\":\n                    spia_matrices[\"inhibition_phosphorylation\"][u_name][v_name] = 1\n        elif isinstance(v, (Gene, Rna)):  # Normal decrease, check which matrix\n            spia_matrices[\"repression\"][u_name][v_name] = 1\n        else:\n            spia_matrices[\"inhibition\"][u_name][v_name] = 1\n\n    elif relation == ASSOCIATION:\n        spia_matrices[\"binding_association\"][u_name][v_name] = 1", "response": "Populate the adjacency matrix."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexport a SPIA data dictionary into an Excel sheet at the given path.", "response": "def spia_matrices_to_excel(spia_matrices: Mapping[str, pd.DataFrame], path: str) -> None:\n    \"\"\"Export a SPIA data dictionary into an Excel sheet at the given path.\n\n    .. note::\n\n        # The R import should add the values:\n        # [\"nodes\"] from the columns\n        # [\"title\"] from the name of the file\n        # [\"NumberOfReactions\"] set to \"0\"\n    \"\"\"\n    writer = pd.ExcelWriter(path, engine='xlsxwriter')\n\n    for relation, df in spia_matrices.items():\n        df.to_excel(writer, sheet_name=relation, index=False)\n\n    # Save excel\n    writer.save()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef spia_matrices_to_tsvs(spia_matrices: Mapping[str, pd.DataFrame], directory: str) -> None:\n    os.makedirs(directory, exist_ok=True)\n    for relation, df in spia_matrices.items():\n        df.to_csv(os.path.join(directory, f'{relation}.tsv'), index=True)", "response": "Export a SPIA data dictionary into a directory as several TSV documents."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main(graph: BELGraph, xlsx: str, tsvs: str):\n    if not xlsx and not tsvs:\n        click.secho('Specify at least one option --xlsx or --tsvs', fg='red')\n        sys.exit(1)\n\n    spia_matrices = bel_to_spia_matrices(graph)\n\n    if xlsx:\n        spia_matrices_to_excel(spia_matrices, xlsx)\n\n    if tsvs:\n        spia_matrices_to_tsvs(spia_matrices, tsvs)", "response": "Export the graph to a SPIA Excel sheet."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\noverlays tabular data on the network.", "response": "def overlay_data(graph: BELGraph,\n                 data: Mapping[BaseEntity, Any],\n                 label: Optional[str] = None,\n                 overwrite: bool = False,\n                 ) -> None:\n    \"\"\"Overlays tabular data on the network\n\n    :param graph: A BEL Graph\n    :param data: A dictionary of {tuple node: data for that node}\n    :param label: The annotation label to put in the node dictionary\n    :param overwrite: Should old annotations be overwritten?\n    \"\"\"\n    if label is None:\n        label = WEIGHT\n\n    for node, value in data.items():\n        if node not in graph:\n            log.debug('%s not in graph', node)\n            continue\n\n        if label in graph.nodes[node] and not overwrite:\n            log.debug('%s already on %s', label, node)\n            continue\n\n        graph.nodes[node][label] = value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef overlay_type_data(graph: BELGraph,\n                      data: Mapping[str, float],\n                      func: str,\n                      namespace: str,\n                      label: Optional[str] = None,\n                      overwrite: bool = False,\n                      impute: Optional[float] = None,\n                      ) -> None:\n    \"\"\"Overlay tabular data on the network for data that comes from an data set with identifiers that lack\n    namespaces.\n\n    For example, if you want to overlay differential gene expression data from a table, that table\n    probably has HGNC identifiers, but no specific annotations that they are in the HGNC namespace or\n    that the entities to which they refer are RNA.\n\n    :param graph: A BEL Graph\n    :param dict data: A dictionary of {name: data}\n    :param func: The function of the keys in the data dictionary\n    :param namespace: The namespace of the keys in the data dictionary\n    :param label: The annotation label to put in the node dictionary\n    :param overwrite: Should old annotations be overwritten?\n    :param impute: The value to use for missing data\n    \"\"\"\n    new_data = {\n        node: data.get(node[NAME], impute)\n        for node in filter_nodes(graph, function_namespace_inclusion_builder(func, namespace))\n    }\n\n    overlay_data(graph, new_data, label=label, overwrite=overwrite)", "response": "Overlay tabular data on the network for data that comes from a table with identifiers that lack the HGNC identifiers."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads and pre - process a differential gene expression data.", "response": "def load_differential_gene_expression(path: str,\n                                      gene_symbol_column: str = 'Gene.symbol',\n                                      logfc_column: str = 'logFC',\n                                      aggregator: Optional[Callable[[List[float]], float]] = None,\n                                      ) -> Mapping[str, float]:\n    \"\"\"Load and pre-process a differential gene expression data.\n\n    :param path: The path to the CSV\n    :param gene_symbol_column: The header of the gene symbol column in the data frame\n    :param logfc_column: The header of the log-fold-change column in the data frame\n    :param aggregator: A function that aggregates a list of differential gene expression values. Defaults to\n                       :func:`numpy.median`. Could also use: :func:`numpy.mean`, :func:`numpy.average`,\n                       :func:`numpy.min`, or :func:`numpy.max`\n    :return: A dictionary of {gene symbol: log fold change}\n    \"\"\"\n    if aggregator is None:\n        aggregator = np.median\n\n    # Load the data frame\n    df = pd.read_csv(path)\n\n    # Check the columns exist in the data frame\n    assert gene_symbol_column in df.columns\n    assert logfc_column in df.columns\n\n    # throw away columns that don't have gene symbols - these represent control sequences\n    df = df.loc[df[gene_symbol_column].notnull(), [gene_symbol_column, logfc_column]]\n\n    values = defaultdict(list)\n\n    for _, gene_symbol, log_fold_change in df.itertuples():\n        values[gene_symbol].append(log_fold_change)\n\n    return {\n        gene_symbol: aggregator(log_fold_changes)\n        for gene_symbol, log_fold_changes in values.items()\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads many namespaces and merges their names.", "response": "def get_merged_namespace_names(locations, check_keywords=True):\n    \"\"\"Loads many namespaces and combines their names.\n\n    :param iter[str] locations: An iterable of URLs or file paths pointing to BEL namespaces.\n    :param bool check_keywords: Should all the keywords be the same? Defaults to ``True``\n    :return: A dictionary of {names: labels}\n    :rtype: dict[str, str]\n\n    Example Usage\n\n    >>> from pybel.resources import write_namespace\n    >>> from pybel_tools.definition_utils import export_namespace, get_merged_namespace_names\n    >>> graph = ...\n    >>> original_ns_url = ...\n    >>> export_namespace(graph, 'MBS') # Outputs in current directory to MBS.belns\n    >>> value_dict = get_merged_namespace_names([original_ns_url, 'MBS.belns'])\n    >>> with open('merged_namespace.belns', 'w') as f:\n    >>> ...  write_namespace('MyBrokenNamespace', 'MBS', 'Other', 'Charles Hoyt', 'PyBEL Citation', value_dict, file=f)\n    \"\"\"\n    resources = {location: get_bel_resource(location) for location in locations}\n\n    if check_keywords:\n        resource_keywords = set(config['Namespace']['Keyword'] for config in resources.values())\n        if 1 != len(resource_keywords):\n            raise ValueError('Tried merging namespaces with different keywords: {}'.format(resource_keywords))\n\n    result = {}\n    for resource in resources:\n        result.update(resource['Values'])\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge_namespaces(input_locations, output_path, namespace_name, namespace_keyword, namespace_domain, author_name,\n                     citation_name, namespace_description=None, namespace_species=None, namespace_version=None,\n                     namespace_query_url=None, namespace_created=None, author_contact=None, author_copyright=None,\n                     citation_description=None, citation_url=None, citation_version=None, citation_date=None,\n                     case_sensitive=True, delimiter='|', cacheable=True, functions=None, value_prefix='',\n                     sort_key=None, check_keywords=True):\n    \"\"\"Merges namespaces from multiple locations to one.\n\n    :param iter input_locations: An iterable of URLs or file paths pointing to BEL namespaces.\n    :param str output_path: The path to the file to write the merged namespace\n    :param str namespace_name: The namespace name\n    :param str namespace_keyword: Preferred BEL Keyword, maximum length of 8\n    :param str namespace_domain: One of: :data:`pybel.constants.NAMESPACE_DOMAIN_BIOPROCESS`,\n                            :data:`pybel.constants.NAMESPACE_DOMAIN_CHEMICAL`,\n                            :data:`pybel.constants.NAMESPACE_DOMAIN_GENE`, or\n                            :data:`pybel.constants.NAMESPACE_DOMAIN_OTHER`\n    :param str author_name: The namespace's authors\n    :param str citation_name: The name of the citation\n    :param str namespace_query_url: HTTP URL to query for details on namespace values (must be valid URL)\n    :param str namespace_description: Namespace description\n    :param str namespace_species: Comma-separated list of species taxonomy id's\n    :param str namespace_version: Namespace version\n    :param str namespace_created: Namespace public timestamp, ISO 8601 datetime\n    :param str author_contact: Namespace author's contact info/email address\n    :param str author_copyright: Namespace's copyright/license information\n    :param str citation_description: Citation description\n    :param str citation_url: URL to more citation information\n    :param str citation_version: Citation version\n    :param str citation_date: Citation publish timestamp, ISO 8601 Date\n    :param bool case_sensitive: Should this config file be interpreted as case-sensitive?\n    :param str delimiter: The delimiter between names and labels in this config file\n    :param bool cacheable: Should this config file be cached?\n    :param functions: The encoding for the elements in this namespace\n    :type functions: iterable of characters\n    :param str value_prefix: a prefix for each name\n    :param sort_key: A function to sort the values with :func:`sorted`\n    :param bool check_keywords: Should all the keywords be the same? Defaults to ``True``\n    \"\"\"\n    results = get_merged_namespace_names(input_locations, check_keywords=check_keywords)\n\n    with open(output_path, 'w') as file:\n        write_namespace(\n            namespace_name=namespace_name,\n            namespace_keyword=namespace_keyword,\n            namespace_domain=namespace_domain,\n            author_name=author_name,\n            citation_name=citation_name,\n            values=results,\n            namespace_species=namespace_species,\n            namespace_description=namespace_description,\n            namespace_query_url=namespace_query_url,\n            namespace_version=namespace_version,\n            namespace_created=namespace_created,\n            author_contact=author_contact,\n            author_copyright=author_copyright,\n            citation_description=citation_description,\n            citation_url=citation_url,\n            citation_version=citation_version,\n            citation_date=citation_date,\n            case_sensitive=case_sensitive,\n            delimiter=delimiter,\n            cacheable=cacheable,\n            functions=functions,\n            value_prefix=value_prefix,\n            sort_key=sort_key,\n            file=file\n        )", "response": "Merges multiple BEL namespaces into one."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the reverse causal reasoning algorithm on a graph.", "response": "def run_rcr(graph, tag='dgxp'):\n    \"\"\"Run the reverse causal reasoning algorithm on a graph.\n\n    Steps:\n\n    1. Get all downstream controlled things into map (that have at least 4 downstream things)\n    2. calculate population of all things that are downstream controlled\n\n    .. note:: Assumes all nodes have been pre-tagged with data\n\n    :param pybel.BELGraph graph:\n    :param str tag: The key for the nodes' data dictionaries that corresponds to the integer value for its differential\n                    expression.\n    \"\"\"\n\n    # Step 1: Calculate the hypothesis subnetworks (just simple star graphs)\n    hypotheses = defaultdict(set)\n    increases = defaultdict(set)\n    decreases = defaultdict(set)\n\n    for u, v, d in graph.edges(data=True):\n        hypotheses[u].add(v)\n\n        if d[RELATION] in CAUSAL_INCREASE_RELATIONS:\n            increases[u].add(v)\n\n        elif d[RELATION] in CAUSAL_DECREASE_RELATIONS:\n            decreases[u].add(v)\n\n    # Step 2: Calculate the matching of the data points to the causal relationships\n\n    #: A dictionary from {tuple controller node: int count of correctly matching observations}\n    correct = defaultdict(int)\n    #: A dictionary from {tuple controller node: int count of incorrectly matching observations}\n    contra = defaultdict(int)\n    #: A dictionary from {tuple controller node: int count of ambiguous observations}\n    ambiguous = defaultdict(int)\n    #: A dictionary from {tuple controller node: int count of missing obvservations}\n    missing = defaultdict(int)\n\n    for controller, downstream_nodes in hypotheses.items():\n        if len(downstream_nodes) < 4:\n            continue  # need enough data to make reasonable calculations!\n\n        for node in downstream_nodes:\n\n            if node in increases[controller] and node in decreases[controller]:\n                ambiguous[controller] += 1\n\n            elif node in increases[controller]:\n                if graph.node[node][tag] == 1:\n                    correct[controller] += 1\n                elif graph.node[node][tag] == -1:\n                    contra[controller] += 1\n\n            elif node in decreases[controller]:\n                if graph.node[node][tag] == 1:\n                    contra[controller] += 1\n                elif graph.node[node][tag] == -1:\n                    correct[controller] += 1\n\n            else:\n                missing[controller] += 1\n\n    # Step 3: Keep only controller nodes who have 4 or more downstream nodes\n    controllers = {\n        controller\n        for controller, downstream_nodes in hypotheses.items()\n        if 4 <= len(downstream_nodes)\n    }\n\n    # Step 4: Calculate concordance scores\n    concordance_scores = {\n        controller: scipy.stats.beta(0.5, correct[controller], contra[controller])\n        for controller in controllers\n    }\n\n    # Step 5: Calculate richness scores\n    # TODO\n\n    # Calculate the population as the union of all downstream nodes for all controllers\n    population = {\n        node\n        for controller in controllers\n        for node in hypotheses[controller]\n    }\n    population_size = len(population)\n\n    # Step 6: Export\n\n    return pandas.DataFrame({\n        'contra': contra,\n        'correct': correct,\n        'concordance': concordance_scores\n    })"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef export_namespace(graph, namespace, directory=None, cacheable=False):\n    directory = os.getcwd() if directory is None else directory\n    path = os.path.join(directory, '{}.belns'.format(namespace))\n\n    with open(path, 'w') as file:\n        log.info('Outputting to %s', path)\n        right_names = get_names_by_namespace(graph, namespace)\n        log.info('Graph has %d correct names in %s', len(right_names), namespace)\n        wrong_names = get_incorrect_names_by_namespace(graph, namespace)\n        log.info('Graph has %d incorrect names in %s', len(right_names), namespace)\n        undefined_ns_names = get_undefined_namespace_names(graph, namespace)\n        log.info('Graph has %d names in missing namespace %s', len(right_names), namespace)\n\n        names = (right_names | wrong_names | undefined_ns_names)\n\n        if 0 == len(names):\n            log.warning('%s is empty', namespace)\n\n        write_namespace(\n            namespace_name=namespace,\n            namespace_keyword=namespace,\n            namespace_domain='Other',\n            author_name=graph.authors,\n            author_contact=graph.contact,\n            citation_name=graph.name,\n            values=names,\n            cacheable=cacheable,\n            file=file\n        )", "response": "Exports all names and missing names from the given namespace to its own BEL Namespace files in the given directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhelps remove extraneous whitespace from the lines of a file", "response": "def lint_file(in_file, out_file=None):\n    \"\"\"Helps remove extraneous whitespace from the lines of a file\n\n    :param file in_file: A readable file or file-like\n    :param file out_file: A writable file or file-like\n    \"\"\"\n    for line in in_file:\n        print(line.strip(), file=out_file)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a linted version of each document in the source directory to the target directory ArcGIS does not have a. bel extension.", "response": "def lint_directory(source, target):\n    \"\"\"Adds a linted version of each document in the source directory to the target directory\n\n    :param str source: Path to directory to lint\n    :param str target: Path to directory to output\n    \"\"\"\n    for path in os.listdir(source):\n        if not path.endswith('.bel'):\n            continue\n\n        log.info('linting: %s', path)\n        with open(os.path.join(source, path)) as i, open(os.path.join(target, path), 'w') as o:\n            lint_file(i, o)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_pubmed_abstract_group(pmids: Iterable[Union[str, int]]) -> Iterable[str]:\n    for pmid in set(pmids):\n        yield ''\n\n        res = requests.get(title_url_fmt.format(pmid))\n        title = res.content.decode('utf-8').strip()\n\n        yield 'SET Citation = {{\"{}\", \"{}\"}}'.format(title, pmid)\n\n        res = requests.get(abstract_url_fmt.format(pmid))\n        abstract = res.content.decode('utf-8').strip()\n\n        yield 'SET Evidence = \"{}\"'.format(abstract)\n        yield '\\nUNSET Evidence\\nUNSET Citation'", "response": "Build a skeleton for the citations and evidence groups."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_entrez_gene_data(entrez_ids: Iterable[Union[str, int]]):\n    url = PUBMED_GENE_QUERY_URL.format(','.join(str(x).strip() for x in entrez_ids))\n    response = requests.get(url)\n    tree = ElementTree.fromstring(response.content)\n\n    return {\n        element.attrib['uid']: {\n            'summary': _sanitize(element.find('Summary').text),\n            'description': element.find('Description').text\n        }\n        for element in tree.findall('./DocumentSummarySet/DocumentSummary')\n    }", "response": "Get gene info from Entrez."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild a skeleton for the PubMed gene summaries", "response": "def make_pubmed_gene_group(entrez_ids: Iterable[Union[str, int]]) -> Iterable[str]:\n    \"\"\"Builds a skeleton for gene summaries\n\n    :param entrez_ids: A list of Entrez Gene identifiers to query the PubMed service\n    :return: An iterator over statement lines for NCBI Entrez Gene summaries\n    \"\"\"\n    url = PUBMED_GENE_QUERY_URL.format(','.join(str(x).strip() for x in entrez_ids))\n    response = requests.get(url)\n    tree = ElementTree.fromstring(response.content)\n\n    for x in tree.findall('./DocumentSummarySet/DocumentSummary'):\n        yield '\\n# {}'.format(x.find('Description').text)\n        yield 'SET Citation = {{\"Other\", \"PubMed Gene\", \"{}\"}}'.format(x.attrib['uid'])\n        yield 'SET Evidence = \"{}\"'.format(x.find('Summary').text.strip().replace('\\n', ''))\n        yield '\\nUNSET Evidence\\nUNSET Citation'"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites a BEL document to a file.", "response": "def write_boilerplate(name: str,\n                      version: Optional[str] = None,\n                      description: Optional[str] = None,\n                      authors: Optional[str] = None,\n                      contact: Optional[str] = None,\n                      copyright: Optional[str] = None,\n                      licenses: Optional[str] = None,\n                      disclaimer: Optional[str] = None,\n                      namespace_url: Optional[Mapping[str, str]] = None,\n                      namespace_patterns: Optional[Mapping[str, str]] = None,\n                      annotation_url: Optional[Mapping[str, str]] = None,\n                      annotation_patterns: Optional[Mapping[str, str]] = None,\n                      annotation_list: Optional[Mapping[str, Set[str]]] = None,\n                      pmids: Optional[Iterable[Union[str, int]]] = None,\n                      entrez_ids: Optional[Iterable[Union[str, int]]] = None,\n                      file: Optional[TextIO] = None,\n                      ) -> None:\n    \"\"\"Write a boilerplate BEL document, with standard document metadata, definitions.\n\n    :param name: The unique name for this BEL document\n    :param contact: The email address of the maintainer\n    :param description: A description of the contents of this document\n    :param authors: The authors of this document\n    :param version: The version. Defaults to current date in format ``YYYYMMDD``.\n    :param copyright: Copyright information about this document\n    :param licenses: The license applied to this document\n    :param disclaimer: The disclaimer for this document\n    :param namespace_url: an optional dictionary of {str name: str URL} of namespaces\n    :param namespace_patterns: An optional dictionary of {str name: str regex} namespaces\n    :param annotation_url: An optional dictionary of {str name: str URL} of annotations\n    :param annotation_patterns: An optional dictionary of {str name: str regex} of regex annotations\n    :param annotation_list: An optional dictionary of {str name: set of names} of list annotations\n    :param pmids: A list of PubMed identifiers to auto-populate with citation and abstract\n    :param entrez_ids: A list of Entrez identifiers to autopopulate the gene summary as evidence\n    :param file: A writable file or file-like. If None, defaults to :data:`sys.stdout`\n    \"\"\"\n    lines = make_knowledge_header(\n        name=name,\n        version=version or '1.0.0',\n        description=description,\n        authors=authors,\n        contact=contact,\n        copyright=copyright,\n        licenses=licenses,\n        disclaimer=disclaimer,\n        namespace_url=namespace_url,\n        namespace_patterns=namespace_patterns,\n        annotation_url=annotation_url,\n        annotation_patterns=annotation_patterns,\n        annotation_list=annotation_list,\n    )\n\n    for line in lines:\n        print(line, file=file)\n\n    if pmids is not None:\n        for line in make_pubmed_abstract_group(pmids):\n            print(line, file=file)\n\n    if entrez_ids is not None:\n        for line in make_pubmed_gene_group(entrez_ids):\n            print(line, file=file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninduces a sub - graph on the nodes that pass the given predicates.", "response": "def get_subgraph_by_node_filter(graph: BELGraph, node_predicates: NodePredicates) -> BELGraph:\n    \"\"\"Induce a sub-graph on the nodes that pass the given predicate(s).\"\"\"\n    return get_subgraph_by_induction(graph, filter_nodes(graph, node_predicates))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_subgraph_by_node_search(graph: BELGraph, query: Strings) -> BELGraph:\n    nodes = search_node_names(graph, query)\n    return get_subgraph_by_induction(graph, nodes)", "response": "Get a sub - graph induced over all nodes matching the query string."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the largest giant component of a graph.", "response": "def get_largest_component(graph: BELGraph) -> BELGraph:\n    \"\"\"Get the giant component of a graph.\"\"\"\n    biggest_component_nodes = max(nx.weakly_connected_components(graph), key=len)\n    return subgraph(graph, biggest_component_nodes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef random_by_nodes(graph: BELGraph, percentage: Optional[float] = None) -> BELGraph:\n    percentage = percentage or 0.9\n\n    assert 0 < percentage <= 1\n\n    nodes = graph.nodes()\n    n = int(len(nodes) * percentage)\n\n    subnodes = random.sample(nodes, n)\n\n    result = graph.subgraph(subnodes)\n\n    update_node_helper(graph, result)\n\n    return result", "response": "Get a random graph by inducing over a percentage of the original nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef random_by_edges(graph: BELGraph, percentage: Optional[float] = None) -> BELGraph:\n    percentage = percentage or 0.9\n    assert 0 < percentage <= 1\n\n    edges = graph.edges(keys=True)\n    n = int(graph.number_of_edges() * percentage)\n\n    subedges = random.sample(edges, n)\n\n    rv = graph.fresh_copy()\n\n    for u, v, k in subedges:\n        safe_add_edge(rv, u, v, k, graph[u][v][k])\n\n    update_node_helper(graph, rv)\n\n    return rv", "response": "Get a random graph by keeping a certain percentage of original edges."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nshuffles the node s data dictionary.", "response": "def shuffle_node_data(graph: BELGraph, key: str, percentage: Optional[float] = None) -> BELGraph:\n    \"\"\"Shuffle the node's data.\n\n    Useful for permutation testing.\n\n    :param graph: A BEL graph\n    :param key: The node data dictionary key\n    :param percentage: What percentage of possible swaps to make\n    \"\"\"\n    percentage = percentage or 0.3\n    assert 0 < percentage <= 1\n\n    n = graph.number_of_nodes()\n    swaps = int(percentage * n * (n - 1) / 2)\n\n    result: BELGraph = graph.copy()\n\n    for _ in range(swaps):\n        s, t = random.sample(result.node, 2)\n        result.nodes[s][key], result.nodes[t][key] = result.nodes[t][key], result.nodes[s][key]\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef shuffle_relations(graph: BELGraph, percentage: Optional[str] = None) -> BELGraph:\n    percentage = percentage or 0.3\n    assert 0 < percentage <= 1\n\n    n = graph.number_of_edges()\n    swaps = int(percentage * n * (n - 1) / 2)\n\n    result: BELGraph = graph.copy()\n\n    edges = result.edges(keys=True)\n\n    for _ in range(swaps):\n        (s1, t1, k1), (s2, t2, k2) = random.sample(edges, 2)\n        result[s1][t1][k1], result[s2][t2][k2] = result[s2][t2][k2], result[s1][t1][k1]\n\n    return result", "response": "Shuffle the relations.\n\n    Useful for permutation testing.\n\n    :param graph: A BEL graph\n    :param percentage: What percentage of possible swaps to make"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_edge_consistent(graph, u, v):\n    if not graph.has_edge(u, v):\n        raise ValueError('{} does not contain an edge ({}, {})'.format(graph, u, v))\n\n    return 0 == len(set(d[RELATION] for d in graph.edge[u][v].values()))", "response": "Check if all edges between two nodes have the same relation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef all_edges_consistent(graph):\n    return all(\n        is_edge_consistent(graph, u, v)\n        for u, v in graph.edges()\n    )", "response": "Return True if all edges are consistent in a BEL graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrewires a graph s edges target nodes.", "response": "def rewire_targets(graph, rewiring_probability):\n    \"\"\"Rewire a graph's edges' target nodes.\n\n    - For BEL graphs, assumes edge consistency (all edges between two given nodes are have the same relation)\n    - Doesn't make self-edges\n\n    :param pybel.BELGraph graph: A BEL graph\n    :param float rewiring_probability: The probability of rewiring (between 0 and 1)\n    :return: A rewired BEL graph\n    \"\"\"\n    if not all_edges_consistent(graph):\n        raise ValueError('{} is not consistent'.format(graph))\n\n    result = graph.copy()\n    nodes = result.nodes()\n\n    for u, v in result.edges():\n        if random.random() < rewiring_probability:\n            continue\n\n        w = random.choice(nodes)\n\n        while w == u or result.has_edge(u, w):\n            w = random.choice(nodes)\n\n        result.add_edge(w, v)\n        result.remove_edge(u, v)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef self_edge_filter(_: BELGraph, source: BaseEntity, target: BaseEntity, __: str) -> bool:\n    return source == target", "response": "Check if the source and target nodes are the same."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if a protein modification of source causes activity of target.", "response": "def has_protein_modification_increases_activity(graph: BELGraph,\n                                                source: BaseEntity,\n                                                target: BaseEntity,\n                                                key: str,\n                                                ) -> bool:\n    \"\"\"Check if pmod of source causes activity of target.\"\"\"\n    edge_data = graph[source][target][key]\n    return has_protein_modification(graph, source) and part_has_modifier(edge_data, OBJECT, ACTIVITY)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the degradation of source causes activity of target.", "response": "def has_degradation_increases_activity(data: Dict) -> bool:\n    \"\"\"Check if the degradation of source causes activity of target.\"\"\"\n    return part_has_modifier(data, SUBJECT, DEGRADATION) and part_has_modifier(data, OBJECT, ACTIVITY)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef has_translocation_increases_activity(data: Dict) -> bool:\n    return part_has_modifier(data, SUBJECT, TRANSLOCATION) and part_has_modifier(data, OBJECT, ACTIVITY)", "response": "Check if the translocation of source causes activity of target."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndo the given complex contain the member?", "response": "def complex_has_member(graph: BELGraph, complex_node: ComplexAbundance, member_node: BaseEntity) -> bool:\n    \"\"\"Does the given complex contain the member?\"\"\"\n    return any(  # TODO can't you look in the members of the complex object (if it's enumerated)\n        v == member_node\n        for _, v, data in graph.out_edges(complex_node, data=True)\n        if data[RELATION] == HAS_COMPONENT\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the formation of a complex with u increases the activity of v.", "response": "def complex_increases_activity(graph: BELGraph, u: BaseEntity, v: BaseEntity, key: str) -> bool:\n    \"\"\"Return if the formation of a complex with u increases the activity of v.\"\"\"\n    return (\n        isinstance(u, (ComplexAbundance, NamedComplexAbundance)) and\n        complex_has_member(graph, u, v) and\n        part_has_modifier(graph[u][v][key], OBJECT, ACTIVITY)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds edges that are A - A meaning that some conditions in the edge best describe the interaction.", "response": "def find_activations(graph: BELGraph):\n    \"\"\"Find edges that are A - A, meaning that some conditions in the edge best describe the interaction.\"\"\"\n    for u, v, key, data in graph.edges(keys=True, data=True):\n        if u != v:\n            continue\n\n        bel = graph.edge_to_bel(u, v, data)\n\n        line = data.get(LINE)\n\n        if line is None:\n            continue  # this was inferred, so need to investigate another way\n\n        elif has_protein_modification_increases_activity(graph, u, v, key):\n            print(line, '- pmod changes -', bel)\n            find_related(graph, v, data)\n\n        elif has_degradation_increases_activity(data):\n            print(line, '- degradation changes -', bel)\n            find_related(graph, v, data)\n\n        elif has_translocation_increases_activity(data):\n            print(line, '- translocation changes -', bel)\n            find_related(graph, v, data)\n\n        elif complex_increases_activity(graph, u, v, key):\n            print(line, '- complex changes - ', bel)\n            find_related(graph, v, data)\n\n        elif has_same_subject_object(graph, u, v, key):\n            print(line, '- same sub/obj -', bel)\n\n        else:\n            print(line, '- *** - ', bel)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pairwise(iterable):\n    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n    a, b = itt.tee(iterable)\n    next(b, None)\n    return zip(a, b)", "response": "s -> s0 s1 s2 s3..."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntakes in a path and calculates a score for the edge that is ranked.", "response": "def rank_path(graph, path, edge_ranking=None):\n    \"\"\"Takes in a path (a list of nodes in the graph) and calculates a score\n\n    :param pybel.BELGraph graph: A BEL graph\n    :param list[tuple] path: A list of nodes in the path (includes terminal nodes)\n    :param dict edge_ranking: A dictionary of {relationship: score}\n    :return: The score for the edge\n    :rtype: int\n    \"\"\"\n    edge_ranking = default_edge_ranking if edge_ranking is None else edge_ranking\n\n    return sum(max(edge_ranking[d[RELATION]] for d in graph.edge[u][v].values()) for u, v in pairwise(path))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_root_in_path(graph, path_nodes):\n    path_graph = graph.subgraph(path_nodes)\n\n    # node_in_degree_tuple: list of tuples with (node,in_degree_of_node) in ascending order\n    node_in_degree_tuple = sorted([(n, d) for n, d in path_graph.in_degree().items()], key=itemgetter(1))\n    # node_out_degree_tuple: ordered list of tuples with (node,in_degree_of_node) in descending order\n    node_out_degree_tuple = sorted([(n, d) for n, d in path_graph.out_degree().items()], key=itemgetter(1),\n                                   reverse=True)\n\n    # In case all have the same in degree it needs to be reference before\n    tied_root_index = 0\n\n    # Get index where the min in_degree stops (in case they are duplicates)\n    for i in range(0, (len(node_in_degree_tuple) - 1)):\n        if node_in_degree_tuple[i][1] < node_in_degree_tuple[i + 1][1]:\n            tied_root_index = i\n            break\n\n    # If there are multiple nodes with minimum in_degree take the one with max out degree\n    # (in case multiple have the same out degree pick one random)\n    if tied_root_index != 0:\n        root_tuple = max(node_out_degree_tuple[:tied_root_index], key=itemgetter(1))\n    else:\n        root_tuple = node_in_degree_tuple[0]\n\n    return path_graph, root_tuple[0]", "response": "Find the root node of the path in the graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef summarize_edge_filter(graph: BELGraph, edge_predicates: EdgePredicates) -> None:\n    passed = count_passed_edge_filter(graph, edge_predicates)\n    print('{}/{} edges passed {}'.format(\n        passed, graph.number_of_edges(),\n        (\n            ', '.join(edge_filter.__name__ for edge_filter in edge_predicates)\n            if isinstance(edge_predicates, Iterable) else\n            edge_predicates.__name__\n        )\n    ))", "response": "Prints a summary of the number of edges passing a given set of filters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_edge_data_filter(annotations: Mapping, partial_match: bool = True) -> EdgePredicate: # noqa: D202\n\n    @edge_predicate\n    def annotation_dict_filter(data: EdgeData) -> bool:\n        \"\"\"A filter that matches edges with the given dictionary as a sub-dictionary.\"\"\"\n        return subdict_matches(data, annotations, partial_match=partial_match)\n\n    return annotation_dict_filter", "response": "Build a filter that keeps edges whose data dictionaries are super - dictionaries to the given dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds an edge predicate that returns True if the given PubMed identifiers are not contained in the given PubMed identifiers.", "response": "def build_pmid_exclusion_filter(pmids: Strings) -> EdgePredicate:\n    \"\"\"Fail for edges with citations whose references are one of the given PubMed identifiers.\n\n    :param pmids: A PubMed identifier or list of PubMed identifiers to filter against\n    \"\"\"\n    if isinstance(pmids, str):\n        @edge_predicate\n        def pmid_exclusion_filter(data: EdgeData) -> bool:\n            \"\"\"Fail for edges with PubMed citations matching the contained PubMed identifier.\n\n            :return: If the edge has a PubMed citation with the contained PubMed identifier\n            \"\"\"\n            return has_pubmed(data) and data[CITATION][CITATION_REFERENCE] != pmids\n\n    elif isinstance(pmids, Iterable):\n        pmids = set(pmids)\n\n        @edge_predicate\n        def pmid_exclusion_filter(data: EdgeData) -> bool:\n            \"\"\"Pass for edges with PubMed citations matching one of the contained PubMed identifiers.\n\n            :return: If the edge has a PubMed citation with one of the contained PubMed identifiers\n            \"\"\"\n            return has_pubmed(data) and data[CITATION][CITATION_REFERENCE] not in pmids\n\n    else:\n        raise TypeError\n\n    return pmid_exclusion_filter"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef node_has_namespace(node: BaseEntity, namespace: str) -> bool:\n    ns = node.get(NAMESPACE)\n    return ns is not None and ns == namespace", "response": "Pass for nodes that have the given namespace."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npassing for nodes that have one of the given namespaces.", "response": "def node_has_namespaces(node: BaseEntity, namespaces: Set[str]) -> bool:\n    \"\"\"Pass for nodes that have one of the given namespaces.\"\"\"\n    ns = node.get(NAMESPACE)\n    return ns is not None and ns in namespaces"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_source_namespace_filter(namespaces: Strings) -> EdgePredicate:\n    if isinstance(namespaces, str):\n        def source_namespace_filter(_, u: BaseEntity, __, ___) -> bool:\n            return node_has_namespace(u, namespaces)\n\n    elif isinstance(namespaces, Iterable):\n        namespaces = set(namespaces)\n\n        def source_namespace_filter(_, u: BaseEntity, __, ___) -> bool:\n            return node_has_namespaces(u, namespaces)\n\n    else:\n        raise TypeError\n\n    return source_namespace_filter", "response": "Build a filter function that returns true if the source nodes have the given namespace or one of the given namespaces."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_target_namespace_filter(namespaces: Strings) -> EdgePredicate:\n    if isinstance(namespaces, str):\n        def target_namespace_filter(_, __, v: BaseEntity, ___) -> bool:\n            return node_has_namespace(v, namespaces)\n\n    elif isinstance(namespaces, Iterable):\n        namespaces = set(namespaces)\n\n        def target_namespace_filter(_, __, v: BaseEntity, ___) -> bool:\n            return node_has_namespaces(v, namespaces)\n\n    else:\n        raise TypeError\n\n    return target_namespace_filter", "response": "Build a filter that only passes for edges whose target nodes have the given namespace or one of the given namespaces."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search_node_namespace_names(graph, query, namespace):\n    node_predicates = [\n        namespace_inclusion_builder(namespace),\n        build_node_name_search(query)\n    ]\n\n    return filter_nodes(graph, node_predicates)", "response": "Search for nodes with the given namespace and whose names containing a given string ( s )."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nassigning if a value is greater than or less than a cutoff.", "response": "def get_cutoff(value: float, cutoff: Optional[float] = None) -> int:\n    \"\"\"Assign if a value is greater than or less than a cutoff.\"\"\"\n    cutoff = cutoff if cutoff is not None else 0\n\n    if value > cutoff:\n        return 1\n\n    if value < (-1 * cutoff):\n        return - 1\n\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhelping calculate the concordance tree for a given node data dictionary key", "response": "def calculate_concordance_helper(graph: BELGraph,\n                                 key: str,\n                                 cutoff: Optional[float] = None,\n                                 ) -> Tuple[int, int, int, int]:\n    \"\"\"Help calculate network-wide concordance\n\n    Assumes data already annotated with given key\n\n    :param graph: A BEL graph\n    :param key: The node data dictionary key storing the logFC\n    :param cutoff: The optional logFC cutoff for significance\n    \"\"\"\n    scores = defaultdict(int)\n\n    for u, v, k, d in graph.edges(keys=True, data=True):\n        c = edge_concords(graph, u, v, k, d, key, cutoff=cutoff)\n        scores[c] += 1\n\n    return (\n        scores[Concordance.correct],\n        scores[Concordance.incorrect],\n        scores[Concordance.ambiguous],\n        scores[Concordance.unassigned],\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the concordance of a node in a network.", "response": "def calculate_concordance(graph: BELGraph, key: str, cutoff: Optional[float] = None,\n                          use_ambiguous: bool = False) -> float:\n    \"\"\"Calculates network-wide concordance.\n\n    Assumes data already annotated with given key\n\n    :param graph: A BEL graph\n    :param key: The node data dictionary key storing the logFC\n    :param cutoff: The optional logFC cutoff for significance\n    :param use_ambiguous: Compare to ambiguous edges as well\n    \"\"\"\n    correct, incorrect, ambiguous, _ = calculate_concordance_helper(graph, key, cutoff=cutoff)\n\n    try:\n        return correct / (correct + incorrect + (ambiguous if use_ambiguous else 0))\n    except ZeroDivisionError:\n        return -1.0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the one - sided probability of getting a value more extreme than the distribution.", "response": "def one_sided(value: float, distribution: List[float]) -> float:\n    \"\"\"Calculate the one-sided probability of getting a value more extreme than the distribution.\"\"\"\n    assert distribution\n    return sum(value < element for element in distribution) / len(distribution)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calculate_concordance_probability(graph: BELGraph,\n                                      key: str,\n                                      cutoff: Optional[float] = None,\n                                      permutations: Optional[int] = None,\n                                      percentage: Optional[float] = None,\n                                      use_ambiguous: bool = False,\n                                      permute_type: str = 'shuffle_node_data',\n                                      ) -> Tuple[float, List[float], float]:\n    \"\"\"Calculates a graph's concordance as well as its statistical probability.\n\n\n\n    :param graph: A BEL graph\n    :param str key: The node data dictionary key storing the logFC\n    :param float cutoff: The optional logFC cutoff for significance\n    :param int permutations: The number of random permutations to test. Defaults to 500\n    :param float percentage: The percentage of the graph's edges to maintain. Defaults to 0.9\n    :param bool use_ambiguous: Compare to ambiguous edges as well\n    :returns: A triple of the concordance score, the null distribution, and the p-value.\n    \"\"\"\n    if permute_type == 'random_by_edges':\n        permute_func = partial(random_by_edges, percentage=percentage)\n    elif permute_type == 'shuffle_node_data':\n        permute_func = partial(shuffle_node_data, key=key, percentage=percentage)\n    elif permute_type == 'shuffle_relations':\n        permute_func = partial(shuffle_relations, percentage=percentage)\n    else:\n        raise ValueError('Invalid permute_type: {}'.format(permute_type))\n\n    graph: BELGraph = graph.copy()\n    collapse_to_genes(graph)\n    collapse_all_variants(graph)\n\n    score = calculate_concordance(graph, key, cutoff=cutoff)\n\n    distribution = []\n\n    for _ in range(permutations or 500):\n        permuted_graph = permute_func(graph)\n        permuted_graph_scores = calculate_concordance(permuted_graph, key, cutoff=cutoff, use_ambiguous=use_ambiguous)\n        distribution.append(permuted_graph_scores)\n\n    return score, distribution, one_sided(score, distribution)", "response": "Calculates the concordance probability of a graph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef calculate_concordance_by_annotation(graph, annotation, key, cutoff=None):\n    return {\n        value: calculate_concordance(subgraph, key, cutoff=cutoff)\n        for value, subgraph in get_subgraphs_by_annotation(graph, annotation).items()\n    }", "response": "Calculates the concordance scores for each stratified graph based on the given annotation and returns the concordance scores for each stratified graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the concordance probability of each node in the graph with the given annotation.", "response": "def calculate_concordance_probability_by_annotation(graph, annotation, key, cutoff=None, permutations=None,\n                                                    percentage=None,\n                                                    use_ambiguous=False):\n    \"\"\"Returns the results of concordance analysis on each subgraph, stratified by the given annotation.\n\n    :param pybel.BELGraph graph: A BEL graph\n    :param str annotation: The annotation to group by.\n    :param str key: The node data dictionary key storing the logFC\n    :param float cutoff: The optional logFC cutoff for significance\n    :param int permutations: The number of random permutations to test. Defaults to 500\n    :param float percentage: The percentage of the graph's edges to maintain. Defaults to 0.9\n    :param bool use_ambiguous: Compare to ambiguous edges as well\n    :rtype: dict[str,tuple]\n    \"\"\"\n    result = [\n        (value, calculate_concordance_probability(\n            subgraph,\n            key,\n            cutoff=cutoff,\n            permutations=permutations,\n            percentage=percentage,\n            use_ambiguous=use_ambiguous,\n        ))\n        for value, subgraph in get_subgraphs_by_annotation(graph, annotation).items()\n    ]\n\n    return dict(result)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_drug_target_interactions(manager: Optional['bio2bel_drugbank.manager'] = None) -> Mapping[str, List[str]]:\n    if manager is None:\n        import bio2bel_drugbank\n        manager = bio2bel_drugbank.Manager()\n\n    if not manager.is_populated():\n        manager.populate()\n\n    return manager.get_drug_to_hgnc_symbols()", "response": "Get a mapping from drugs to their list of gene names."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun EpiCom analysis on many graphs.", "response": "def multi_run_epicom(graphs: Iterable[BELGraph], path: Union[None, str, TextIO]) -> None:\n    \"\"\"Run EpiCom analysis on many graphs.\"\"\"\n    if isinstance(path, str):\n        with open(path, 'w') as file:\n            _multi_run_helper_file_wrapper(graphs, file)\n\n    else:\n        _multi_run_helper_file_wrapper(graphs, path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts the Alzheimer s and Parkinson s disease NeuroMMSig excel sheets to BEL.", "response": "def main():\n    \"\"\"Convert the Alzheimer's and Parkinson's disease NeuroMMSig excel sheets to BEL.\"\"\"\n    logging.basicConfig(level=logging.INFO)\n    log.setLevel(logging.INFO)\n\n    bms_base = get_bms_base()\n    neurommsig_base = get_neurommsig_base()\n    neurommsig_excel_dir = os.path.join(neurommsig_base, 'resources', 'excels', 'neurommsig')\n\n    nift_values = get_nift_values()\n\n    log.info('Starting Alzheimers')\n\n    ad_path = os.path.join(neurommsig_excel_dir, 'alzheimers', 'alzheimers.xlsx')\n    ad_df = preprocess(ad_path)\n    with open(os.path.join(bms_base, 'aetionomy', 'alzheimers', 'neurommsigdb_ad.bel'), 'w') as ad_file:\n        write_neurommsig_bel(ad_file, ad_df, mesh_alzheimer, nift_values)\n\n    log.info('Starting Parkinsons')\n\n    pd_path = os.path.join(neurommsig_excel_dir, 'parkinsons', 'parkinsons.xlsx')\n    pd_df = preprocess(pd_path)\n    with open(os.path.join(bms_base, 'aetionomy', 'parkinsons', 'neurommsigdb_pd.bel'), 'w') as pd_file:\n        write_neurommsig_bel(pd_file, pd_df, mesh_parkinson, nift_values)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_inconsistent_edges(graph: BELGraph) -> None:\n    for u, v in get_inconsistent_edges(graph):\n        edges = [(u, v, k) for k in graph[u][v]]\n        graph.remove_edges_from(edges)", "response": "Remove all edges between node pairs with inconsistent edges."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_walks_exhaustive(graph, node, length):\n    if 0 == length:\n        return (node,),\n\n    return tuple(\n        (node, key) + path\n        for neighbor in graph.edge[node]\n        for path in get_walks_exhaustive(graph, neighbor, length - 1)\n        if node not in path\n        for key in graph.edge[node][neighbor]\n    )", "response": "Returns a list of paths that are not in the same node as the given node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef match_simple_metapath(graph, node, simple_metapath):\n    if 0 == len(simple_metapath):\n        yield node,\n\n    else:\n        for neighbor in graph.edges[node]:\n            if graph.nodes[neighbor][FUNCTION] == simple_metapath[0]:\n                for path in match_simple_metapath(graph, neighbor, simple_metapath[1:]):\n                    if node not in path:\n                        yield (node,) + path", "response": "Matches a simple metapath starting at the given node and returns an iterable over the nodes that match the given simple metapath."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_database(manager: pybel.Manager, annotation_url: Optional[str] = None) -> None:\n    annotation_url = annotation_url or NEUROMMSIG_DEFAULT_URL\n\n    annotation = manager.get_namespace_by_url(annotation_url)\n\n    if annotation is None:\n        raise RuntimeError('no graphs in database with given annotation')\n\n    networks = get_networks_using_annotation(manager, annotation)\n\n    dtis = ...\n\n    for network in networks:\n        graph = network.as_bel()\n\n        scores = epicom_on_graph(graph, dtis)\n\n        for (drug_name, subgraph_name), score in scores.items():\n            drug_model = get_drug_model(manager, drug_name)\n            subgraph_model = manager.get_annotation_entry(annotation_url, subgraph_name)\n\n            score_model = Score(\n                network=network,\n                annotation=subgraph_model,\n                drug=drug_model,\n                score=score\n            )\n\n            manager.session.add(score_model)\n\n    t = time.time()\n    logger.info('committing scores')\n    manager.session.commit()\n    logger.info('committed scores in %.2f seconds', time.time() - t)", "response": "Build a database of scores for NeuroMMSig annotated graphs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the average scores over all biological processes in a graph.", "response": "def calculate_average_scores_on_graph(\n        graph: BELGraph,\n        key: Optional[str] = None,\n        tag: Optional[str] = None,\n        default_score: Optional[float] = None,\n        runs: Optional[int] = None,\n        use_tqdm: bool = False,\n):\n    \"\"\"Calculate the scores over all biological processes in the sub-graph.\n\n    As an implementation, it simply computes the sub-graphs then calls :func:`calculate_average_scores_on_subgraphs` as\n    described in that function's documentation.\n\n    :param graph: A BEL graph with heats already on the nodes\n    :param key: The key in the node data dictionary representing the experimental data. Defaults to\n     :data:`pybel_tools.constants.WEIGHT`.\n    :param tag: The key for the nodes' data dictionaries where the scores will be put. Defaults to 'score'\n    :param default_score: The initial score for all nodes. This number can go up or down.\n    :param runs: The number of times to run the heat diffusion workflow. Defaults to 100.\n    :param use_tqdm: Should there be a progress bar for runners?\n    :return: A dictionary of {pybel node tuple: results tuple}\n    :rtype: dict[tuple, tuple]\n\n    Suggested usage with :mod:`pandas`:\n\n    >>> import pandas as pd\n    >>> from pybel_tools.analysis.heat import calculate_average_scores_on_graph\n    >>> graph = ...  # load graph and data\n    >>> scores = calculate_average_scores_on_graph(graph)\n    >>> pd.DataFrame.from_items(scores.items(), orient='index', columns=RESULT_LABELS)\n\n    \"\"\"\n    subgraphs = generate_bioprocess_mechanisms(graph, key=key)\n    scores = calculate_average_scores_on_subgraphs(\n        subgraphs,\n        key=key,\n        tag=tag,\n        default_score=default_score,\n        runs=runs,\n        use_tqdm=use_tqdm\n    )\n    return scores"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calculate_average_scores_on_subgraphs(\n        subgraphs: Mapping[H, BELGraph],\n        key: Optional[str] = None,\n        tag: Optional[str] = None,\n        default_score: Optional[float] = None,\n        runs: Optional[int] = None,\n        use_tqdm: bool = False,\n        tqdm_kwargs: Optional[Mapping[str, Any]] = None,\n) -> Mapping[H, Tuple[float, float, float, float, int, int]]:\n    \"\"\"Calculate the scores over precomputed candidate mechanisms.\n\n    :param subgraphs: A dictionary of keys to their corresponding subgraphs\n    :param key: The key in the node data dictionary representing the experimental data. Defaults to\n     :data:`pybel_tools.constants.WEIGHT`.\n    :param tag: The key for the nodes' data dictionaries where the scores will be put. Defaults to 'score'\n    :param default_score: The initial score for all nodes. This number can go up or down.\n    :param runs: The number of times to run the heat diffusion workflow. Defaults to 100.\n    :param use_tqdm: Should there be a progress bar for runners?\n    :return: A dictionary of keys to results tuples\n\n    Example Usage:\n\n    >>> import pandas as pd\n    >>> from pybel_tools.generation import generate_bioprocess_mechanisms\n    >>> from pybel_tools.analysis.heat import calculate_average_scores_on_subgraphs\n    >>> # load graph and data\n    >>> graph = ...\n    >>> candidate_mechanisms = generate_bioprocess_mechanisms(graph)\n    >>> scores = calculate_average_scores_on_subgraphs(candidate_mechanisms)\n    >>> pd.DataFrame.from_items(scores.items(), orient='index', columns=RESULT_LABELS)\n    \"\"\"\n    results = {}\n\n    log.info('calculating results for %d candidate mechanisms using %d permutations', len(subgraphs), runs)\n\n    it = subgraphs.items()\n\n    if use_tqdm:\n        _tqdm_kwargs = dict(total=len(subgraphs), desc='Candidate mechanisms')\n        if tqdm_kwargs:\n            _tqdm_kwargs.update(tqdm_kwargs)\n        it = tqdm(it, **_tqdm_kwargs)\n\n    for node, subgraph in it:\n        number_first_neighbors = subgraph.in_degree(node)\n        number_first_neighbors = 0 if isinstance(number_first_neighbors, dict) else number_first_neighbors\n        mechanism_size = subgraph.number_of_nodes()\n\n        runners = workflow(subgraph, node, key=key, tag=tag, default_score=default_score, runs=runs)\n        scores = [runner.get_final_score() for runner in runners]\n\n        if 0 == len(scores):\n            results[node] = (\n                None,\n                None,\n                None,\n                None,\n                number_first_neighbors,\n                mechanism_size,\n            )\n            continue\n\n        scores = np.array(scores)\n\n        average_score = np.average(scores)\n        score_std = np.std(scores)\n        med_score = np.median(scores)\n        chi_2_stat, norm_p = stats.normaltest(scores)\n\n        results[node] = (\n            average_score,\n            score_std,\n            norm_p,\n            med_score,\n            number_first_neighbors,\n            mechanism_size,\n        )\n\n    return results", "response": "Calculates the average scores over the given subgraphs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef workflow(\n        graph: BELGraph,\n        node: BaseEntity,\n        key: Optional[str] = None,\n        tag: Optional[str] = None,\n        default_score: Optional[float] = None,\n        runs: Optional[int] = None,\n        minimum_nodes: int = 1,\n) -> List['Runner']:\n    \"\"\"Generate candidate mechanisms and run the heat diffusion workflow.\n\n    :param graph: A BEL graph\n    :param node: The BEL node that is the focus of this analysis\n    :param key: The key in the node data dictionary representing the experimental data. Defaults to\n     :data:`pybel_tools.constants.WEIGHT`.\n    :param tag: The key for the nodes' data dictionaries where the scores will be put. Defaults to 'score'\n    :param default_score: The initial score for all nodes. This number can go up or down.\n    :param runs: The number of times to run the heat diffusion workflow. Defaults to 100.\n    :param minimum_nodes: The minimum number of nodes a sub-graph needs to try running heat diffusion\n    :return: A list of runners\n    \"\"\"\n    subgraph = generate_mechanism(graph, node, key=key)\n\n    if subgraph.number_of_nodes() <= minimum_nodes:\n        return []\n\n    runners = multirun(subgraph, node, key=key, tag=tag, default_score=default_score, runs=runs)\n    return list(runners)", "response": "Generate candidate mechanisms and run the heat diffusion workflow."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns the heat diffusion workflow multiple times each time yielding a Runner object upon completion.", "response": "def multirun(graph: BELGraph,\n             node: BaseEntity,\n             key: Optional[str] = None,\n             tag: Optional[str] = None,\n             default_score: Optional[float] = None,\n             runs: Optional[int] = None,\n             use_tqdm: bool = False,\n             ) -> Iterable['Runner']:\n    \"\"\"Run the heat diffusion workflow multiple times, each time yielding a :class:`Runner` object upon completion.\n\n    :param graph: A BEL graph\n    :param node: The BEL node that is the focus of this analysis\n    :param key: The key in the node data dictionary representing the experimental data. Defaults to\n     :data:`pybel_tools.constants.WEIGHT`.\n    :param tag: The key for the nodes' data dictionaries where the scores will be put. Defaults to 'score'\n    :param default_score: The initial score for all nodes. This number can go up or down.\n    :param runs: The number of times to run the heat diffusion workflow. Defaults to 100.\n    :param use_tqdm: Should there be a progress bar for runners?\n    :return: An iterable over the runners after each iteration\n    \"\"\"\n    if runs is None:\n        runs = 100\n\n    it = range(runs)\n\n    if use_tqdm:\n        it = tqdm(it, total=runs)\n\n    for i in it:\n        try:\n            runner = Runner(graph, node, key=key, tag=tag, default_score=default_score)\n            runner.run()\n            yield runner\n        except Exception:\n            log.debug('Run %s failed for %s', i, node)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef workflow_aggregate(graph: BELGraph,\n                       node: BaseEntity,\n                       key: Optional[str] = None,\n                       tag: Optional[str] = None,\n                       default_score: Optional[float] = None,\n                       runs: Optional[int] = None,\n                       aggregator: Optional[Callable[[Iterable[float]], float]] = None,\n                       ) -> Optional[float]:\n    \"\"\"Get the average score over multiple runs.\n\n    This function is very simple, and can be copied to do more interesting statistics over the :class:`Runner`\n    instances. To iterate over the runners themselves, see :func:`workflow`\n\n    :param graph: A BEL graph\n    :param node: The BEL node that is the focus of this analysis\n    :param key: The key in the node data dictionary representing the experimental data. Defaults to\n     :data:`pybel_tools.constants.WEIGHT`.\n    :param tag: The key for the nodes' data dictionaries where the scores will be put. Defaults to 'score'\n    :param default_score: The initial score for all nodes. This number can go up or down.\n    :param runs: The number of times to run the heat diffusion workflow. Defaults to 100.\n    :param aggregator: A function that aggregates a list of scores. Defaults to :func:`numpy.average`.\n                       Could also use: :func:`numpy.mean`, :func:`numpy.median`, :func:`numpy.min`, :func:`numpy.max`\n    :return: The average score for the target node\n    \"\"\"\n    runners = workflow(graph, node, key=key, tag=tag, default_score=default_score, runs=runs)\n    scores = [runner.get_final_score() for runner in runners]\n\n    if not scores:\n        log.warning('Unable to run the heat diffusion workflow for %s', node)\n        return\n\n    if aggregator is None:\n        return np.average(scores)\n\n    return aggregator(scores)", "response": "Get the average score over multiple runners."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef workflow_all(graph: BELGraph,\n                 key: Optional[str] = None,\n                 tag: Optional[str] = None,\n                 default_score: Optional[float] = None,\n                 runs: Optional[int] = None,\n                 ) -> Mapping[BaseEntity, List[Runner]]:\n    \"\"\"Run the heat diffusion workflow and get runners for every possible candidate mechanism\n\n    1. Get all biological processes\n    2. Get candidate mechanism induced two level back from each biological process\n    3. Heat diffusion workflow for each candidate mechanism for multiple runs\n    4. Return all runner results\n\n    :param graph: A BEL graph\n    :param key: The key in the node data dictionary representing the experimental data. Defaults to\n     :data:`pybel_tools.constants.WEIGHT`.\n    :param tag: The key for the nodes' data dictionaries where the scores will be put. Defaults to 'score'\n    :param default_score: The initial score for all nodes. This number can go up or down.\n    :param runs: The number of times to run the heat diffusion workflow. Defaults to 100.\n    :return: A dictionary of {node: list of runners}\n    \"\"\"\n    results = {}\n\n    for node in get_nodes_by_function(graph, BIOPROCESS):\n        results[node] = workflow(graph, node, key=key, tag=tag, default_score=default_score, runs=runs)\n\n    return results", "response": "Run the heat diffusion workflow on all nodes in the graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the heat diffusion workflow to get average score for every possible candidate mechanism. 1. Get all biological processes 2. Get candidate mechanism induced two level back from each biological process 3. Heat diffusion workflow on each candidate mechanism for multiple runs 4. Report average scores for each candidate mechanism :param graph: A BEL graph :param key: The key in the node data dictionary representing the experimental data. Defaults to :data:`pybel_tools.constants.WEIGHT`. :param tag: The key for the nodes' data dictionaries where the scores will be put. Defaults to 'score' :param default_score: The initial score for all nodes. This number can go up or down. :param runs: The number of times to run the heat diffusion workflow. Defaults to 100. :param aggregator: A function that aggregates a list of scores. Defaults to :func:`numpy.average`. Could also use: :func:`numpy.mean`, :func:`numpy.median`, :func:`numpy.min`, :func:`numpy.max` :return: A dictionary of {node: upstream causal subgraph}", "response": "def workflow_all_aggregate(graph: BELGraph,\n                           key: Optional[str] = None,\n                           tag: Optional[str] = None,\n                           default_score: Optional[float] = None,\n                           runs: Optional[int] = None,\n                           aggregator: Optional[Callable[[Iterable[float]], float]] = None,\n                           ):\n    \"\"\"Run the heat diffusion workflow to get average score for every possible candidate mechanism.\n\n    1. Get all biological processes\n    2. Get candidate mechanism induced two level back from each biological process\n    3. Heat diffusion workflow on each candidate mechanism for multiple runs\n    4. Report average scores for each candidate mechanism\n\n    :param graph: A BEL graph\n    :param key: The key in the node data dictionary representing the experimental data. Defaults to\n     :data:`pybel_tools.constants.WEIGHT`.\n    :param tag: The key for the nodes' data dictionaries where the scores will be put. Defaults to 'score'\n    :param default_score: The initial score for all nodes. This number can go up or down.\n    :param runs: The number of times to run the heat diffusion workflow. Defaults to 100.\n    :param aggregator: A function that aggregates a list of scores. Defaults to :func:`numpy.average`.\n                       Could also use: :func:`numpy.mean`, :func:`numpy.median`, :func:`numpy.min`, :func:`numpy.max`\n    :return: A dictionary of {node: upstream causal subgraph}\n    \"\"\"\n    results = {}\n\n    bioprocess_nodes = list(get_nodes_by_function(graph, BIOPROCESS))\n\n    for bioprocess_node in tqdm(bioprocess_nodes):\n        subgraph = generate_mechanism(graph, bioprocess_node, key=key)\n\n        try:\n            results[bioprocess_node] = workflow_aggregate(\n                graph=subgraph,\n                node=bioprocess_node,\n                key=key,\n                tag=tag,\n                default_score=default_score,\n                runs=runs,\n                aggregator=aggregator\n            )\n        except Exception:\n            log.exception('could not run on %', bioprocess_node)\n\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef calculate_average_score_by_annotation(\n        graph: BELGraph,\n        annotation: str,\n        key: Optional[str] = None,\n        runs: Optional[int] = None,\n        use_tqdm: bool = False,\n) -> Mapping[str, float]:\n    \"\"\"For each sub-graph induced over the edges matching the annotation, calculate the average score\n    for all of the contained biological processes\n\n    Assumes you haven't done anything yet\n\n    1. Generates biological process upstream candidate mechanistic sub-graphs with\n       :func:`generate_bioprocess_mechanisms`\n    2. Calculates scores for each sub-graph with :func:`calculate_average_scores_on_sub-graphs`\n    3. Overlays data with pbt.integration.overlay_data\n    4. Calculates averages with pbt.selection.group_nodes.average_node_annotation\n\n    :param graph: A BEL graph\n    :param annotation: A BEL annotation\n    :param key: The key in the node data dictionary representing the experimental data. Defaults to\n     :data:`pybel_tools.constants.WEIGHT`.\n    :param runs: The number of times to run the heat diffusion workflow. Defaults to 100.\n    :param use_tqdm: Should there be a progress bar for runners?\n    :return: A dictionary from {str annotation value: tuple scores}\n\n    Example Usage:\n\n    >>> import pybel\n    >>> from pybel_tools.integration import overlay_data\n    >>> from pybel_tools.analysis.heat import calculate_average_score_by_annotation\n    >>> graph = pybel.from_path(...)\n    >>> scores = calculate_average_score_by_annotation(graph, 'subgraph')\n    \"\"\"\n    candidate_mechanisms = generate_bioprocess_mechanisms(graph, key=key)\n\n    #: {bp tuple: list of scores}\n    scores: Mapping[BaseEntity, Tuple] = calculate_average_scores_on_subgraphs(\n        subgraphs=candidate_mechanisms,\n        key=key,\n        runs=runs,\n        use_tqdm=use_tqdm,\n    )\n\n    subgraph_bp: Mapping[str, List[BaseEntity]] = defaultdict(list)\n    subgraphs: Mapping[str, BELGraph] = get_subgraphs_by_annotation(graph, annotation)\n    for annotation_value, subgraph in subgraphs.items():\n        subgraph_bp[annotation_value].extend(get_nodes_by_function(subgraph, BIOPROCESS))\n\n    #: Pick the average by slicing with 0. Refer to :func:`calculate_average_score_on_subgraphs`\n    return {\n        annotation_value: np.average(scores[bp][0] for bp in bps)\n        for annotation_value, bps in subgraph_bp.items()\n    }", "response": "Calculates the average score of each node in the graph that has an annotation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iter_leaves(self) -> Iterable[BaseEntity]:\n        for node in self.graph:\n            if self.tag in self.graph.nodes[node]:\n                continue\n\n            if not any(self.tag not in self.graph.nodes[p] for p in self.graph.predecessors(node)):\n                yield node", "response": "Return an iterable over all nodes that are leaves."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the ratio of in - degree to out - degree of a node.", "response": "def in_out_ratio(self, node: BaseEntity) -> float:\n        \"\"\"Calculate the ratio of in-degree / out-degree of a node.\"\"\"\n        return self.graph.in_degree(node) / float(self.graph.out_degree(node))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unscored_nodes_iter(self) -> BaseEntity:\n        for node, data in self.graph.nodes(data=True):\n            if self.tag not in data:\n                yield node", "response": "Iterate over all nodes without a score."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_random_edge(self):\n        nodes = [\n            (n, self.in_out_ratio(n))\n            for n in self.unscored_nodes_iter()\n            if n != self.target_node\n        ]\n\n        node, deg = min(nodes, key=itemgetter(1))\n        log.log(5, 'checking %s (in/out ratio: %.3f)', node, deg)\n\n        possible_edges = self.graph.in_edges(node, keys=True)\n        log.log(5, 'possible edges: %s', possible_edges)\n\n        edge_to_remove = random.choice(possible_edges)\n        log.log(5, 'chose: %s', edge_to_remove)\n\n        return edge_to_remove", "response": "This function is used to get a random edge from the graph. It will take a random in - edge to the lowest in - degree ratio node and the edge to remove."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_random_edge(self):\n        u, v, k = self.get_random_edge()\n        log.log(5, 'removing %s, %s (%s)', u, v, k)\n        self.graph.remove_edge(u, v, k)", "response": "Remove a random in - edge from the node with the lowest in - degree ratio."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove random edges until there is at least one leaf node.", "response": "def remove_random_edge_until_has_leaves(self) -> None:\n        \"\"\"Remove random edges until there is at least one leaf node.\"\"\"\n        while True:\n            leaves = set(self.iter_leaves())\n            if leaves:\n                return\n            self.remove_random_edge()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the score for all leaves.", "response": "def score_leaves(self) -> Set[BaseEntity]:\n        \"\"\"Calculate the score for all leaves.\n\n        :return: The set of leaf nodes that were scored\n        \"\"\"\n        leaves = set(self.iter_leaves())\n\n        if not leaves:\n            log.warning('no leaves.')\n            return set()\n\n        for leaf in leaves:\n            self.graph.nodes[leaf][self.tag] = self.calculate_score(leaf)\n            log.log(5, 'chomping %s', leaf)\n\n        return leaves"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_with_graph_transformation(self) -> Iterable[BELGraph]:\n        yield self.get_remaining_graph()\n        while not self.done_chomping():\n            while not list(self.iter_leaves()):\n                self.remove_random_edge()\n                yield self.get_remaining_graph()\n            self.score_leaves()\n            yield self.get_remaining_graph()", "response": "Yields the graph in a loop that yields the remaining graphs until all nodes have been scored."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef done_chomping(self) -> bool:\n        return self.tag in self.graph.nodes[self.target_node]", "response": "Determines if the algorithm is complete by checking if the target node of this analysis has been scored\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_final_score(self) -> float:\n        if not self.done_chomping():\n            raise ValueError('algorithm has not yet completed')\n\n        return self.graph.nodes[self.target_node][self.tag]", "response": "Return the final score for the target node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the new score of the given node.", "response": "def calculate_score(self, node: BaseEntity) -> float:\n        \"\"\"Calculate the new score of the given node.\"\"\"\n        score = (\n            self.graph.nodes[node][self.tag]\n            if self.tag in self.graph.nodes[node] else\n            self.default_score\n        )\n\n        for predecessor, _, d in self.graph.in_edges(node, data=True):\n            if d[RELATION] in CAUSAL_INCREASE_RELATIONS:\n                score += self.graph.nodes[predecessor][self.tag]\n            elif d[RELATION] in CAUSAL_DECREASE_RELATIONS:\n                score -= self.graph.nodes[predecessor][self.tag]\n\n        return score"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the numpy structured array data type for sample states in the microcanonical statistics table.", "response": "def microcanonical_statistics_dtype(spanning_cluster=True):\n    \"\"\"\n    Return the numpy structured array data type for sample states\n\n    Helper function\n\n    Parameters\n    ----------\n    spanning_cluster : bool, optional\n        Whether to detect a spanning cluster or not.\n        Defaults to ``True``.\n\n    Returns\n    -------\n    ret : list of pairs of str\n        A list of tuples of field names and data types to be used as ``dtype``\n        argument in numpy ndarray constructors\n\n    See Also\n    --------\n    http://docs.scipy.org/doc/numpy/user/basics.rec.html\n    canonical_statistics_dtype\n    \"\"\"\n    fields = list()\n    fields.extend([\n        ('n', 'uint32'),\n        ('edge', 'uint32'),\n    ])\n    if spanning_cluster:\n        fields.extend([\n            ('has_spanning_cluster', 'bool'),\n        ])\n    fields.extend([\n        ('max_cluster_size', 'uint32'),\n        ('moments', '(5,)uint64'),\n    ])\n    return _ndarray_dtype(fields)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a successive sample of the bond percolation model.", "response": "def bond_sample_states(\n    perc_graph, num_nodes, num_edges, seed, spanning_cluster=True,\n    auxiliary_node_attributes=None, auxiliary_edge_attributes=None,\n    spanning_sides=None,\n    **kwargs\n):\n    '''\n    Generate successive sample states of the bond percolation model\n\n    This is a :ref:`generator function <python:tut-generators>` to successively\n    add one edge at a time from the graph to the percolation model.\n    At each iteration, it calculates and returns the cluster statistics.\n    CAUTION: it returns a reference to the internal array, not a copy.\n\n    Parameters\n    ----------\n    perc_graph : networkx.Graph\n        The substrate graph on which percolation is to take place\n\n    num_nodes : int\n        Number ``N`` of sites in the graph\n\n    num_edges : int\n        Number ``M`` of bonds in the graph\n\n    seed : {None, int, array_like}\n        Random seed initializing the pseudo-random number generator.\n        Piped through to `numpy.random.RandomState` constructor.\n\n    spanning_cluster : bool, optional\n        Whether to detect a spanning cluster or not.\n        Defaults to ``True``.\n\n    auxiliary_node_attributes : optional\n        Return value of ``networkx.get_node_attributes(graph, 'span')``\n\n    auxiliary_edge_attributes : optional\n        Return value of ``networkx.get_edge_attributes(graph, 'span')``\n\n    spanning_sides : list, optional\n        List of keys (attribute values) of the two sides of the auxiliary\n        nodes.\n        Return value of ``list(set(auxiliary_node_attributes.values()))``\n\n    Yields\n    ------\n    ret : ndarray\n        Structured array with dtype ``dtype=[('has_spanning_cluster', 'bool'),\n        ('max_cluster_size', 'uint32'), ('moments', 'int64', 5)]``\n\n    ret['n'] : ndarray of int\n        The number of bonds added at the particular iteration\n\n    ret['edge'] : ndarray of int\n        The index of the edge added at the particular iteration\n        Note that in the first step, when ``ret['n'] == 0``, this value is\n        undefined!\n\n    ret['has_spanning_cluster'] : ndarray of bool\n        ``True`` if there is a spanning cluster, ``False`` otherwise.\n        Only exists if `spanning_cluster` argument is set to ``True``.\n\n    ret['max_cluster_size'] : int\n        Size of the largest cluster (absolute number of sites)\n\n    ret['moments'] : 1-D :py:class:`numpy.ndarray` of int\n        Array of size ``5``.\n        The ``k``-th entry is the ``k``-th raw moment of the (absolute) cluster\n        size distribution, with ``k`` ranging from ``0`` to ``4``.\n\n    Raises\n    ------\n    ValueError\n        If `spanning_cluster` is ``True``, but `graph` does not contain any\n        auxiliary nodes to detect spanning clusters.\n\n    See also\n    --------\n\n    numpy.random.RandomState\n\n    microcanonical_statistics_dtype\n\n    Notes\n    -----\n    Iterating through this generator is a single run of the Newman-Ziff\n    algorithm. [12]_\n    The first iteration yields the trivial state with :math:`n = 0` occupied\n    bonds.\n\n    Spanning cluster\n\n        In order to detect a spanning cluster, `graph` needs to contain\n        auxiliary nodes and edges, cf. Reference [12]_, Figure 6.\n        The auxiliary nodes and edges have the ``'span'`` `attribute\n        <http://networkx.github.io/documentation/latest/tutorial/tutorial.html#node-attributes>`_.\n        The value is either ``0`` or ``1``, distinguishing the two sides of the\n        graph to span.\n\n    Raw moments of the cluster size distribution\n\n        The :math:`k`-th raw moment of the (absolute) cluster size distribution\n        is :math:`\\sum_s' s^k N_s`, where :math:`s` is the cluster size and\n        :math:`N_s` is the number of clusters of size :math:`s`. [13]_\n        The primed sum :math:`\\sum'` signifies that the largest cluster is\n        excluded from the sum. [14]_\n\n    References\n    ----------\n    .. [12] Newman, M. E. J. & Ziff, R. M. Fast monte carlo algorithm for site\n        or bond percolation. Physical Review E 64, 016706+ (2001),\n        `doi:10.1103/physreve.64.016706 <http://dx.doi.org/10.1103/physreve.64.016706>`_.\n\n    .. [13] Stauffer, D. & Aharony, A. Introduction to Percolation Theory (Taylor &\n       Francis, London, 1994), second edn.\n\n    .. [14] Binder, K. & Heermann, D. W. Monte Carlo Simulation in Statistical\n       Physics (Springer, Berlin, Heidelberg, 2010),\n       `doi:10.1007/978-3-642-03163-2 <http://dx.doi.org/10.1007/978-3-642-03163-2>`_.\n    '''\n\n    # construct random number generator\n    rng = np.random.RandomState(seed=seed)\n\n    if spanning_cluster:\n        if len(spanning_sides) != 2:\n            raise ValueError(\n                'Spanning cluster is to be detected, but auxiliary nodes '\n                'of less or more than 2 types (sides) given.'\n            )\n\n    # get a list of edges for easy access in later iterations\n    perc_edges = perc_graph.edges()\n    perm_edges = rng.permutation(num_edges)\n\n    # initial iteration: no edges added yet (n == 0)\n    ret = np.empty(\n        1, dtype=microcanonical_statistics_dtype(spanning_cluster)\n    )\n\n    ret['n'] = 0\n    ret['max_cluster_size'] = 1\n    ret['moments'] = np.ones(5, dtype='uint64') * (num_nodes - 1)\n\n    if spanning_cluster:\n        ret['has_spanning_cluster'] = False\n\n    # yield cluster statistics for n == 0\n    yield ret\n\n    # set up disjoint set (union-find) data structure\n    ds = nx.utils.union_find.UnionFind()\n    if spanning_cluster:\n        ds_spanning = nx.utils.union_find.UnionFind()\n\n        # merge all auxiliary nodes for each side\n        side_roots = dict()\n        for side in spanning_sides:\n            nodes = [\n                node for (node, node_side) in auxiliary_node_attributes.items()\n                if node_side is side\n            ]\n            ds_spanning.union(*nodes)\n            side_roots[side] = ds_spanning[nodes[0]]\n\n        for (edge, edge_side) in auxiliary_edge_attributes.items():\n            ds_spanning.union(side_roots[edge_side], *edge)\n\n        side_roots = [\n            ds_spanning[side_root] for side_root in side_roots.values()\n        ]\n\n    # get first node\n    max_cluster_root = next(perc_graph.nodes_iter())\n\n    # loop over all edges (n == 1..M)\n    for n in range(num_edges):\n\n        ret['n'] += 1\n\n        # draw new edge from permutation\n        edge_index = perm_edges[n]\n        edge = perc_edges[edge_index]\n        ret['edge'] = edge_index\n\n        # find roots and weights\n        roots = [\n            ds[node] for node in edge\n        ]\n        weights = [\n            ds.weights[root] for root in roots\n        ]\n\n        if roots[0] is not roots[1]:\n            # not same cluster: union!\n            ds.union(*roots)\n            if spanning_cluster:\n                ds_spanning.union(*roots)\n\n                ret['has_spanning_cluster'] = (\n                    ds_spanning[side_roots[0]] == ds_spanning[side_roots[1]]\n                )\n\n            # find new root and weight\n            root = ds[edge[0]]\n            weight = ds.weights[root]\n\n            # moments and maximum cluster size\n\n            # deduct the previous sub-maximum clusters from moments\n            for i in [0, 1]:\n                if roots[i] is max_cluster_root:\n                    continue\n                ret['moments'] -= weights[i] ** np.arange(5, dtype='uint64')\n\n            if max_cluster_root in roots:\n                # merged with maximum cluster\n                max_cluster_root = root\n                ret['max_cluster_size'] = weight\n            else:\n                # merged previously sub-maximum clusters\n                if ret['max_cluster_size'] >= weight:\n                    # previously largest cluster remains largest cluster\n                    # add merged cluster to moments\n                    ret['moments'] += weight ** np.arange(5, dtype='uint64')\n                else:\n                    # merged cluster overtook previously largest cluster\n                    # add previously largest cluster to moments\n                    max_cluster_root = root\n                    ret['moments'] += ret['max_cluster_size'] ** np.arange(\n                        5, dtype='uint64'\n                    )\n                    ret['max_cluster_size'] = weight\n\n        yield ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nevolve a single run over all microstates (bond occupation numbers) Return the cluster statistics for each microstate Parameters ---------- perc_graph : networkx.Graph The substrate graph on which percolation is to take place num_nodes : int Number ``N`` of sites in the graph num_edges : int Number ``M`` of bonds in the graph seed : {None, int, array_like} Random seed initializing the pseudo-random number generator. Piped through to `numpy.random.RandomState` constructor. spanning_cluster : bool, optional Whether to detect a spanning cluster or not. Defaults to ``True``. auxiliary_node_attributes : optional Value of ``networkx.get_node_attributes(graph, 'span')`` auxiliary_edge_attributes : optional Value of ``networkx.get_edge_attributes(graph, 'span')`` spanning_sides : list, optional List of keys (attribute values) of the two sides of the auxiliary nodes. Return value of ``list(set(auxiliary_node_attributes.values()))`` Returns ------- ret : ndarray of size ``num_edges + 1`` Structured array with dtype ``dtype=[('has_spanning_cluster', 'bool'), ('max_cluster_size', 'uint32'), ('moments', 'uint64', 5)]`` ret['n'] : ndarray of int The number of bonds added at the particular iteration ret['edge'] : ndarray of int The index of the edge added at the particular iteration. Note that ``ret['edge'][0]`` is undefined! ret['has_spanning_cluster'] : ndarray of bool ``True`` if there is a spanning cluster, ``False`` otherwise. Only exists if `spanning_cluster` argument is set to ``True``. ret['max_cluster_size'] : int Size of the largest cluster (absolute number of sites) ret['moments'] : 2-D :py:class:`numpy.ndarray` of int Array of shape ``(num_edges + 1, 5)``. The ``k``-th entry is the ``k``-th raw moment of the (absolute) cluster size distribution, with ``k`` ranging from ``0`` to ``4``. See also -------- bond_sample_states microcanonical_statistics_dtype numpy.random.RandomState", "response": "def bond_microcanonical_statistics(\n    perc_graph, num_nodes, num_edges, seed,\n    spanning_cluster=True,\n    auxiliary_node_attributes=None, auxiliary_edge_attributes=None,\n    spanning_sides=None,\n    **kwargs\n):\n    \"\"\"\n    Evolve a single run over all microstates (bond occupation numbers)\n\n    Return the cluster statistics for each microstate\n\n    Parameters\n    ----------\n    perc_graph : networkx.Graph\n        The substrate graph on which percolation is to take place\n\n    num_nodes : int\n        Number ``N`` of sites in the graph\n\n    num_edges : int\n        Number ``M`` of bonds in the graph\n\n    seed : {None, int, array_like}\n        Random seed initializing the pseudo-random number generator.\n        Piped through to `numpy.random.RandomState` constructor.\n\n    spanning_cluster : bool, optional\n        Whether to detect a spanning cluster or not.\n        Defaults to ``True``.\n\n    auxiliary_node_attributes : optional\n        Value of ``networkx.get_node_attributes(graph, 'span')``\n\n    auxiliary_edge_attributes : optional\n        Value of ``networkx.get_edge_attributes(graph, 'span')``\n\n    spanning_sides : list, optional\n        List of keys (attribute values) of the two sides of the auxiliary\n        nodes.\n        Return value of ``list(set(auxiliary_node_attributes.values()))``\n\n    Returns\n    -------\n    ret : ndarray of size ``num_edges + 1``\n        Structured array with dtype ``dtype=[('has_spanning_cluster', 'bool'),\n        ('max_cluster_size', 'uint32'), ('moments', 'uint64', 5)]``\n\n    ret['n'] : ndarray of int\n        The number of bonds added at the particular iteration\n\n    ret['edge'] : ndarray of int\n        The index of the edge added at the particular iteration.\n        Note that ``ret['edge'][0]`` is undefined!\n\n    ret['has_spanning_cluster'] : ndarray of bool\n        ``True`` if there is a spanning cluster, ``False`` otherwise.\n        Only exists if `spanning_cluster` argument is set to ``True``.\n\n    ret['max_cluster_size'] : int\n        Size of the largest cluster (absolute number of sites)\n\n    ret['moments'] : 2-D :py:class:`numpy.ndarray` of int\n        Array of shape ``(num_edges + 1, 5)``.\n        The ``k``-th entry is the ``k``-th raw moment of the (absolute) cluster\n        size distribution, with ``k`` ranging from ``0`` to ``4``.\n\n    See also\n    --------\n\n    bond_sample_states\n    microcanonical_statistics_dtype\n\n    numpy.random.RandomState\n\n    \"\"\"\n\n    # initialize generator\n    sample_states = bond_sample_states(\n        perc_graph=perc_graph,\n        num_nodes=num_nodes,\n        num_edges=num_edges,\n        seed=seed,\n        spanning_cluster=spanning_cluster,\n        auxiliary_node_attributes=auxiliary_node_attributes,\n        auxiliary_edge_attributes=auxiliary_edge_attributes,\n        spanning_sides=spanning_sides,\n    )\n\n    # get cluster statistics over all microstates\n    return np.fromiter(\n        sample_states,\n        dtype=microcanonical_statistics_dtype(spanning_cluster),\n        count=num_edges + 1\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the NumPy Structured Array type for the canonical statistics of the microcanoncial statistics.", "response": "def canonical_statistics_dtype(spanning_cluster=True):\n    \"\"\"\n    The NumPy Structured Array type for canonical statistics\n\n    Helper function\n\n    Parameters\n    ----------\n    spanning_cluster : bool, optional\n        Whether to detect a spanning cluster or not.\n        Defaults to ``True``.\n\n    Returns\n    -------\n    ret : list of pairs of str\n        A list of tuples of field names and data types to be used as ``dtype``\n        argument in numpy ndarray constructors\n\n    See Also\n    --------\n    http://docs.scipy.org/doc/numpy/user/basics.rec.html\n    microcanoncial_statistics_dtype\n    canonical_averages_dtype\n    \"\"\"\n    fields = list()\n    if spanning_cluster:\n        fields.extend([\n            ('percolation_probability', 'float64'),\n        ])\n    fields.extend([\n        ('max_cluster_size', 'float64'),\n        ('moments', '(5,)float64'),\n    ])\n    return _ndarray_dtype(fields)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef canonical_averages_dtype(spanning_cluster=True):\n    fields = list()\n    fields.extend([\n        ('number_of_runs', 'uint32'),\n    ])\n    if spanning_cluster:\n        fields.extend([\n            ('percolation_probability_mean', 'float64'),\n            ('percolation_probability_m2', 'float64'),\n        ])\n    fields.extend([\n        ('max_cluster_size_mean', 'float64'),\n        ('max_cluster_size_m2', 'float64'),\n        ('moments_mean', '(5,)float64'),\n        ('moments_m2', '(5,)float64'),\n    ])\n    return _ndarray_dtype(fields)", "response": "Returns the NumPy Structured Array type for canonical averages over several base classes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bond_initialize_canonical_averages(\n    canonical_statistics, **kwargs\n):\n    \"\"\"\n    Initialize the canonical averages from a single-run cluster statistics\n\n    Parameters\n    ----------\n    canonical_statistics : 1-D structured ndarray\n        Typically contains the canonical statistics for a range of values\n        of the occupation probability ``p``.\n        The dtype is the result of `canonical_statistics_dtype`.\n\n    Returns\n    -------\n    ret : structured ndarray\n        The dype is the result of `canonical_averages_dtype`.\n\n    ret['number_of_runs'] : 1-D ndarray of int\n        Equals ``1`` (initial run).\n\n    ret['percolation_probability_mean'] : 1-D array of float\n        Equals ``canonical_statistics['percolation_probability']``\n        (if ``percolation_probability`` is present)\n\n    ret['percolation_probability_m2'] : 1-D array of float\n        Each entry is ``0.0``\n\n    ret['max_cluster_size_mean'] : 1-D array of float\n        Equals ``canonical_statistics['max_cluster_size']``\n\n    ret['max_cluster_size_m2'] : 1-D array of float\n        Each entry is ``0.0``\n\n    ret['moments_mean'] : 2-D array of float\n        Equals ``canonical_statistics['moments']``\n\n    ret['moments_m2'] : 2-D array of float\n        Each entry is ``0.0``\n\n    See Also\n    --------\n    canonical_averages_dtype\n    bond_canonical_statistics\n\n    \"\"\"\n    # initialize return array\n    spanning_cluster = (\n        'percolation_probability' in canonical_statistics.dtype.names\n    )\n    # array should have the same size as the input array\n    ret = np.empty_like(\n        canonical_statistics,\n        dtype=canonical_averages_dtype(spanning_cluster=spanning_cluster),\n    )\n    ret['number_of_runs'] = 1\n\n    # initialize percolation probability mean and sum of squared differences\n    if spanning_cluster:\n        ret['percolation_probability_mean'] = (\n            canonical_statistics['percolation_probability']\n        )\n        ret['percolation_probability_m2'] = 0.0\n\n    # initialize maximum cluster size mean and sum of squared differences\n    ret['max_cluster_size_mean'] = (\n        canonical_statistics['max_cluster_size']\n    )\n    ret['max_cluster_size_m2'] = 0.0\n\n    # initialize moments means and sums of squared differences\n    ret['moments_mean'] = canonical_statistics['moments']\n    ret['moments_m2'] = 0.0\n\n    return ret", "response": "Initialize the canonical averages from a single - run cluster statistics."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bond_reduce(row_a, row_b):\n    spanning_cluster = (\n        'percolation_probability_mean' in row_a.dtype.names and\n        'percolation_probability_mean' in row_b.dtype.names and\n        'percolation_probability_m2' in row_a.dtype.names and\n        'percolation_probability_m2' in row_b.dtype.names\n    )\n\n    # initialize return array\n    ret = np.empty_like(row_a)\n\n    def _reducer(key, transpose=False):\n        mean_key = '{}_mean'.format(key)\n        m2_key = '{}_m2'.format(key)\n        res = simoa.stats.online_variance(*[\n            (\n                row['number_of_runs'],\n                row[mean_key].T if transpose else row[mean_key],\n                row[m2_key].T if transpose else row[m2_key],\n            )\n            for row in [row_a, row_b]\n        ])\n\n        (\n            ret[mean_key],\n            ret[m2_key],\n        ) = (\n            res[1].T,\n            res[2].T,\n        ) if transpose else res[1:]\n\n    if spanning_cluster:\n        _reducer('percolation_probability')\n\n    _reducer('max_cluster_size')\n    _reducer('moments', transpose=True)\n\n    ret['number_of_runs'] = row_a['number_of_runs'] + row_b['number_of_runs']\n\n    return ret", "response": "This function reduces the canonical averages over several runs in a single tree tree."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the NumPy Structured Array type for finalized canonical averages over the base class of the base class.", "response": "def finalized_canonical_averages_dtype(spanning_cluster=True):\n    \"\"\"\n    The NumPy Structured Array type for finalized canonical averages over\n    several runs\n\n    Helper function\n\n    Parameters\n    ----------\n    spanning_cluster : bool, optional\n        Whether to detect a spanning cluster or not.\n        Defaults to ``True``.\n\n    Returns\n    -------\n    ret : list of pairs of str\n        A list of tuples of field names and data types to be used as ``dtype``\n        argument in numpy ndarray constructors\n\n    See Also\n    --------\n    http://docs.scipy.org/doc/numpy/user/basics.rec.html\n    canonical_averages_dtype\n    \"\"\"\n    fields = list()\n    fields.extend([\n        ('number_of_runs', 'uint32'),\n        ('p', 'float64'),\n        ('alpha', 'float64'),\n    ])\n    if spanning_cluster:\n        fields.extend([\n            ('percolation_probability_mean', 'float64'),\n            ('percolation_probability_std', 'float64'),\n            ('percolation_probability_ci', '(2,)float64'),\n        ])\n    fields.extend([\n        ('percolation_strength_mean', 'float64'),\n        ('percolation_strength_std', 'float64'),\n        ('percolation_strength_ci', '(2,)float64'),\n        ('moments_mean', '(5,)float64'),\n        ('moments_std', '(5,)float64'),\n        ('moments_ci', '(5,2)float64'),\n    ])\n    return _ndarray_dtype(fields)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef finalize_canonical_averages(\n    number_of_nodes, ps, canonical_averages, alpha,\n):\n    \"\"\"\n    Finalize canonical averages\n    \"\"\"\n\n    spanning_cluster = (\n        (\n            'percolation_probability_mean' in\n            canonical_averages.dtype.names\n        ) and\n        'percolation_probability_m2' in canonical_averages.dtype.names\n    )\n\n    # append values of p as an additional field\n    ret = np.empty_like(\n        canonical_averages,\n        dtype=finalized_canonical_averages_dtype(\n            spanning_cluster=spanning_cluster\n        ),\n    )\n\n    n = canonical_averages['number_of_runs']\n    sqrt_n = np.sqrt(canonical_averages['number_of_runs'])\n\n    ret['number_of_runs'] = n\n    ret['p'] = ps\n    ret['alpha'] = alpha\n\n    def _transform(\n        original_key, final_key=None, normalize=False, transpose=False,\n    ):\n        if final_key is None:\n            final_key = original_key\n        keys_mean = [\n            '{}_mean'.format(key)\n            for key in [original_key, final_key]\n        ]\n        keys_std = [\n            '{}_m2'.format(original_key),\n            '{}_std'.format(final_key),\n        ]\n        key_ci = '{}_ci'.format(final_key)\n\n        # calculate sample mean\n        ret[keys_mean[1]] = canonical_averages[keys_mean[0]]\n        if normalize:\n            ret[keys_mean[1]] /= number_of_nodes\n\n        # calculate sample standard deviation\n        array = canonical_averages[keys_std[0]]\n        result = np.sqrt(\n            (array.T if transpose else array) / (n - 1)\n        )\n        ret[keys_std[1]] = (\n            result.T if transpose else result\n        )\n        if normalize:\n            ret[keys_std[1]] /= number_of_nodes\n\n        # calculate standard normal confidence interval\n        array = ret[keys_std[1]]\n        scale = (array.T if transpose else array) / sqrt_n\n        array = ret[keys_mean[1]]\n        mean = (array.T if transpose else array)\n        result = scipy.stats.t.interval(\n            1 - alpha,\n            df=n - 1,\n            loc=mean,\n            scale=scale,\n        )\n        (\n            ret[key_ci][..., 0], ret[key_ci][..., 1]\n        ) = ([my_array.T for my_array in result] if transpose else result)\n\n    if spanning_cluster:\n        _transform('percolation_probability')\n\n    _transform('max_cluster_size', 'percolation_strength', normalize=True)\n    _transform('moments', normalize=True, transpose=True)\n\n    return ret", "response": "Finalize the canonical averages of a node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomparing the given graph with the given annotation.", "response": "def compare(graph: BELGraph, annotation: str = 'Subgraph') -> Mapping[str, Mapping[str, float]]:\n    \"\"\"Compare generated mechanisms to actual ones.\n\n    1. Generates candidate mechanisms for each biological process\n    2. Gets sub-graphs for all NeuroMMSig signatures\n    3. Make tanimoto similarity comparison for all sets\n\n    :return: A dictionary table comparing the canonical subgraphs to generated ones\n    \"\"\"\n    canonical_mechanisms = get_subgraphs_by_annotation(graph, annotation)\n    canonical_nodes = _transform_graph_dict_to_node_dict(canonical_mechanisms)\n\n    candidate_mechanisms = generate_bioprocess_mechanisms(graph)\n    candidate_nodes = _transform_graph_dict_to_node_dict(candidate_mechanisms)\n\n    results: Dict[str, Dict[str, float]] = defaultdict(dict)\n\n    it = itt.product(canonical_nodes.items(), candidate_nodes.items())\n    for (canonical_name, canonical_graph), (candidate_bp, candidate_graph) in it:\n        tanimoto = tanimoto_set_similarity(candidate_nodes, canonical_nodes)\n        results[canonical_name][candidate_bp] = tanimoto\n\n    return dict(results)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef summarize_node_filter(graph: BELGraph, node_filters: NodePredicates) -> None:\n    passed = count_passed_node_filter(graph, node_filters)\n    print('{}/{} nodes passed'.format(passed, graph.number_of_nodes()))", "response": "Prints a summary of the number of nodes passed a given set of node filters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a filter that only passes on nodes in the given list.", "response": "def node_inclusion_filter_builder(nodes: Iterable[BaseEntity]) -> NodePredicate:\n    \"\"\"Build a filter that only passes on nodes in the given list.\n\n    :param nodes: An iterable of BEL nodes\n    \"\"\"\n    node_set = set(nodes)\n\n    def inclusion_filter(_: BELGraph, node: BaseEntity) -> bool:\n        \"\"\"Pass only for a node that is in the enclosed node list.\n\n        :return: If the node is contained within the enclosed node list\n        \"\"\"\n        return node in node_set\n\n    return inclusion_filter"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef node_exclusion_filter_builder(nodes: Iterable[BaseEntity]) -> NodePredicate:\n    node_set = set(nodes)\n\n    def exclusion_filter(_: BELGraph, node: BaseEntity) -> bool:\n        \"\"\"Pass only for a node that isn't in the enclosed node list\n\n        :return: If the node isn't contained within the enclosed node list\n        \"\"\"\n        return node not in node_set\n\n    return exclusion_filter", "response": "Build a filter that fails on nodes in the given list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a filter that fails on nodes of the given function.", "response": "def function_exclusion_filter_builder(func: Strings) -> NodePredicate:\n    \"\"\"Build a filter that fails on nodes of the given function(s).\n\n    :param func: A BEL Function or list/set/tuple of BEL functions\n    \"\"\"\n    if isinstance(func, str):\n        def function_exclusion_filter(_: BELGraph, node: BaseEntity) -> bool:\n            \"\"\"Pass only for a node that doesn't have the enclosed function.\n\n            :return: If the node doesn't have the enclosed function\n            \"\"\"\n            return node[FUNCTION] != func\n\n        return function_exclusion_filter\n\n    elif isinstance(func, Iterable):\n        functions = set(func)\n\n        def functions_exclusion_filter(_: BELGraph, node: BaseEntity) -> bool:\n            \"\"\"Pass only for a node that doesn't have the enclosed functions.\n\n            :return: If the node doesn't have the enclosed functions\n            \"\"\"\n            return node[FUNCTION] not in functions\n\n        return functions_exclusion_filter\n\n    raise ValueError('Invalid type for argument: {}'.format(func))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef function_namespace_inclusion_builder(func: str, namespace: Strings) -> NodePredicate:\n    if isinstance(namespace, str):\n        def function_namespaces_filter(_: BELGraph, node: BaseEntity) -> bool:\n            \"\"\"Pass only for nodes that have the enclosed function and enclosed namespace.\"\"\"\n            if func != node[FUNCTION]:\n                return False\n            return NAMESPACE in node and node[NAMESPACE] == namespace\n\n    elif isinstance(namespace, Iterable):\n        namespaces = set(namespace)\n\n        def function_namespaces_filter(_: BELGraph, node: BaseEntity) -> bool:\n            \"\"\"Pass only for nodes that have the enclosed function and namespace in the enclose set.\"\"\"\n            if func != node[FUNCTION]:\n                return False\n            return NAMESPACE in node and node[NAMESPACE] in namespaces\n\n    else:\n        raise ValueError('Invalid type for argument: {}'.format(namespace))\n\n    return function_namespaces_filter", "response": "Build a filter function for matching the given function with the given namespace or namespaces."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef data_contains_key_builder(key: str) -> NodePredicate:  # noqa: D202\n\n    def data_contains_key(_: BELGraph, node: BaseEntity) -> bool:\n        \"\"\"Pass only for a node that contains the enclosed key in its data dictionary.\n\n        :return: If the node contains the enclosed key in its data dictionary\n        \"\"\"\n        return key in node\n\n    return data_contains_key", "response": "Build a filter that passes only on nodes that have the given key in their data dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning all variants of the given node.", "response": "def variants_of(\n        graph: BELGraph,\n        node: Protein,\n        modifications: Optional[Set[str]] = None,\n) -> Set[Protein]:\n    \"\"\"Returns all variants of the given node.\"\"\"\n    if modifications:\n        return _get_filtered_variants_of(graph, node, modifications)\n\n    return {\n        v\n        for u, v, key, data in graph.edges(keys=True, data=True)\n        if (\n            u == node\n            and data[RELATION] == HAS_VARIANT\n            and pybel.struct.has_protein_modification(v)\n        )\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a mapping from a given node to all of its upstream controllers.", "response": "def get_variants_to_controllers(\n        graph: BELGraph,\n        node: Protein,\n        modifications: Optional[Set[str]] = None,\n) -> Mapping[Protein, Set[Protein]]:\n    \"\"\"Get a mapping from variants of the given node to all of its upstream controllers.\"\"\"\n    rv = defaultdict(set)\n    variants = variants_of(graph, node, modifications)\n    for controller, variant, data in graph.in_edges(variants, data=True):\n        if data[RELATION] in CAUSAL_RELATIONS:\n            rv[variant].add(controller)\n    return rv"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef group_dict_set(iterator: Iterable[Tuple[A, B]]) -> Mapping[A, Set[B]]:\n    d = defaultdict(set)\n    for key, value in iterator:\n        d[key].add(value)\n    return dict(d)", "response": "Make a dict that accumulates the values for each key in an iterator of doubles."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a dictionary of node pair to set of edge types.", "response": "def get_edge_relations(graph: BELGraph) -> Mapping[Tuple[BaseEntity, BaseEntity], Set[str]]:\n    \"\"\"Build a dictionary of {node pair: set of edge types}.\"\"\"\n    return group_dict_set(\n        ((u, v), d[RELATION])\n        for u, v, d in graph.edges(data=True)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef count_unique_relations(graph: BELGraph) -> Counter:\n    return Counter(itt.chain.from_iterable(get_edge_relations(graph).values()))", "response": "Return a histogram of the different types of relations present in a graph."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_annotations_containing_keyword(graph: BELGraph, keyword: str) -> List[Mapping[str, str]]:\n    return [\n        {\n            'annotation': annotation,\n            'value': value\n        }\n        for annotation, value in iter_annotation_value_pairs(graph)\n        if keyword.lower() in value.lower()\n    ]", "response": "Get annotation value pairs for values that contain the given keyword"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncounting how many edges each annotation appears in a graph.", "response": "def count_annotation_values(graph: BELGraph, annotation: str) -> Counter:\n    \"\"\"Count in how many edges each annotation appears in a graph\n\n    :param graph: A BEL graph\n    :param annotation: The annotation to count\n    :return: A Counter from {annotation value: frequency}\n    \"\"\"\n    return Counter(iter_annotation_values(graph, annotation))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef count_annotation_values_filtered(graph: BELGraph,\n                                     annotation: str,\n                                     source_predicate: Optional[NodePredicate] = None,\n                                     target_predicate: Optional[NodePredicate] = None,\n                                     ) -> Counter:\n    \"\"\"Count in how many edges each annotation appears in a graph, but filter out source nodes and target nodes.\n\n    See :func:`pybel_tools.utils.keep_node` for a basic filter.\n\n    :param graph: A BEL graph\n    :param annotation: The annotation to count\n    :param source_predicate: A predicate (graph, node) -> bool for keeping source nodes\n    :param target_predicate: A predicate (graph, node) -> bool for keeping target nodes\n    :return: A Counter from {annotation value: frequency}\n    \"\"\"\n    if source_predicate and target_predicate:\n        return Counter(\n            data[ANNOTATIONS][annotation]\n            for u, v, data in graph.edges(data=True)\n            if edge_has_annotation(data, annotation) and source_predicate(graph, u) and target_predicate(graph, v)\n        )\n    elif source_predicate:\n        return Counter(\n            data[ANNOTATIONS][annotation]\n            for u, v, data in graph.edges(data=True)\n            if edge_has_annotation(data, annotation) and source_predicate(graph, u)\n        )\n    elif target_predicate:\n        return Counter(\n            data[ANNOTATIONS][annotation]\n            for u, v, data in graph.edges(data=True)\n            if edge_has_annotation(data, annotation) and target_predicate(graph, u)\n        )\n    else:\n        return Counter(\n            data[ANNOTATIONS][annotation]\n            for u, v, data in graph.edges(data=True)\n            if edge_has_annotation(data, annotation)\n        )", "response": "Count how many edges each annotation appears in a graph but filter out source and target nodes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn if the edges between the given nodes are consistent meaning they all have the same relation.", "response": "def pair_is_consistent(graph: BELGraph, u: BaseEntity, v: BaseEntity) -> Optional[str]:\n    \"\"\"Return if the edges between the given nodes are consistent, meaning they all have the same relation.\n\n    :return: If the edges aren't consistent, return false, otherwise return the relation type\n    \"\"\"\n    relations = {data[RELATION] for data in graph[u][v].values()}\n\n    if 1 != len(relations):\n        return\n\n    return list(relations)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_contradictory_pairs(graph: BELGraph) -> Iterable[Tuple[BaseEntity, BaseEntity]]:\n    for u, v in graph.edges():\n        if pair_has_contradiction(graph, u, v):\n            yield u, v", "response": "Iterates over the nodes that have contradictory causal edges."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_consistent_edges(graph: BELGraph) -> Iterable[Tuple[BaseEntity, BaseEntity]]:\n    for u, v in graph.edges():\n        if pair_is_consistent(graph, u, v):\n            yield u, v", "response": "Yields pairs of source node and target node pairs corresponding to edges with many inconsistent relations."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef infer_missing_two_way_edges(graph):\n    for u, v, k, d in graph.edges(data=True, keys=True):\n        if d[RELATION] in TWO_WAY_RELATIONS:\n            infer_missing_backwards_edge(graph, u, v, k)", "response": "Infer missing edges from the graph when a two way edge exists and the opposite direction doesn t exist."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninfer the missing edge in the opposite direction if not already present.", "response": "def infer_missing_backwards_edge(graph, u, v, k):\n    \"\"\"Add the same edge, but in the opposite direction if not already present.\n\n    :type graph: pybel.BELGraph\n    :type u: tuple\n    :type v: tuple\n    :type k: int\n    \"\"\"\n    if u in graph[v]:\n        for attr_dict in graph[v][u].values():\n            if attr_dict == graph[u][v][k]:\n                return\n\n    graph.add_edge(v, u, key=k, **graph[u][v][k])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef enrich_internal_unqualified_edges(graph, subgraph):\n    for u, v in itt.combinations(subgraph, 2):\n        if not graph.has_edge(u, v):\n            continue\n\n        for k in graph[u][v]:\n            if k < 0:\n                subgraph.add_edge(u, v, key=k, **graph[u][v][k])", "response": "Add the unqualified edges between entities in the graph that are contained within the full graph."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef boilerplate(name, contact, description, pmids, version, copyright, authors, licenses, disclaimer, output):\n    from .document_utils import write_boilerplate\n\n    write_boilerplate(\n        name=name,\n        version=version,\n        description=description,\n        authors=authors,\n        contact=contact,\n        copyright=copyright,\n        licenses=licenses,\n        disclaimer=disclaimer,\n        pmids=pmids,\n        file=output,\n    )", "response": "Build a template BEL document with the given PubMed identifiers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a BEL document then serialize the given namespaces to the given directory.", "response": "def serialize_namespaces(namespaces, connection: str, path, directory):\n    \"\"\"Parse a BEL document then serializes the given namespaces (errors and all) to the given directory.\"\"\"\n    from .definition_utils import export_namespaces\n\n    graph = from_lines(path, manager=connection)\n    export_namespaces(namespaces, graph, directory)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\noutputs PubMed identifiers from a graph to a stream.", "response": "def get_pmids(graph: BELGraph, output: TextIO):\n    \"\"\"Output PubMed identifiers from a graph to a stream.\"\"\"\n    for pmid in get_pubmed_identifiers(graph):\n        click.echo(pmid, file=output)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getrowcount(self, window_name, object_name):\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        return len(object_handle.AXRows)", "response": "Get count of rows in table object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef selectrow(self, window_name, object_name, row_text, partial_match=False):\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n\n        for cell in object_handle.AXRows:\n            if re.match(row_text,\n                        cell.AXChildren[0].AXValue):\n                if not cell.AXSelected:\n                    object_handle.activate()\n                    cell.AXSelected = True\n                else:\n                    # Selected\n                    pass\n                return 1\n        raise LdtpServerException(u\"Unable to select row: %s\" % row_text)", "response": "Select a row from a window in an object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nselect multiple row in a window.", "response": "def multiselect(self, window_name, object_name, row_text_list, partial_match=False):\n        \"\"\"\n        Select multiple row\n\n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n        @param row_text_list: Row list with matching text to select\n        @type row_text: string\n\n        @return: 1 on success.\n        @rtype: integer\n        \"\"\"\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n\n        object_handle.activate()\n        selected = False\n        try:\n            window = self._get_front_most_window()\n        except (IndexError,):\n            window = self._get_any_window()\n        for row_text in row_text_list:\n            selected = False\n            for cell in object_handle.AXRows:\n                parent_cell = cell\n                cell = self._getfirstmatchingchild(cell, \"(AXTextField|AXStaticText)\")\n                if not cell:\n                    continue\n                if re.match(row_text, cell.AXValue):\n                    selected = True\n                    if not parent_cell.AXSelected:\n                        x, y, width, height = self._getobjectsize(parent_cell)\n                        window.clickMouseButtonLeftWithMods((x + width / 2,\n                                                             y + height / 2),\n                                                            ['<command_l>'])\n                        # Following selection doesn't work\n                        # parent_cell.AXSelected=True\n                        self.wait(0.5)\n                    else:\n                        # Selected\n                        pass\n                    break\n            if not selected:\n                raise LdtpServerException(u\"Unable to select row: %s\" % row_text)\n        if not selected:\n            raise LdtpServerException(u\"Unable to select any row\")\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef selectrowpartialmatch(self, window_name, object_name, row_text):\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n\n        for cell in object_handle.AXRows:\n            if re.search(row_text,\n                         cell.AXChildren[0].AXValue):\n                if not cell.AXSelected:\n                    object_handle.activate()\n                    cell.AXSelected = True\n                else:\n                    # Selected\n                    pass\n                return 1\n        raise LdtpServerException(u\"Unable to select row: %s\" % row_text)", "response": "Select the first occurrence of a partial match in a row of a window."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef selectrowindex(self, window_name, object_name, row_index):\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n\n        count = len(object_handle.AXRows)\n        if row_index < 0 or row_index > count:\n            raise LdtpServerException('Row index out of range: %d' % row_index)\n        cell = object_handle.AXRows[row_index]\n        if not cell.AXSelected:\n            object_handle.activate()\n            cell.AXSelected = True\n        else:\n            # Selected\n            pass\n        return 1", "response": "Select the entry in the object with the given index."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef selectlastrow(self, window_name, object_name):\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n\n        cell = object_handle.AXRows[-1]\n        if not cell.AXSelected:\n            object_handle.activate()\n            cell.AXSelected = True\n        else:\n            # Selected\n            pass\n        return 1", "response": "Select the last entry in the object table."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the value of a cell in a given window and object.", "response": "def getcellvalue(self, window_name, object_name, row_index, column=0):\n        \"\"\"\n        Get cell value\n\n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n        @param row_index: Row index to get\n        @type row_index: integer\n        @param column: Column index to get, default value 0\n        @type column: integer\n\n        @return: cell value on success.\n        @rtype: string\n        \"\"\"\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n\n        count = len(object_handle.AXRows)\n        if row_index < 0 or row_index > count:\n            raise LdtpServerException('Row index out of range: %d' % row_index)\n        cell = object_handle.AXRows[row_index]\n        count = len(cell.AXChildren)\n        if column < 0 or column > count:\n            raise LdtpServerException('Column index out of range: %d' % column)\n        obj = cell.AXChildren[column]\n        if not re.search(\"AXColumn\", obj.AXRole):\n            obj = cell.AXChildren[column]\n        return obj.AXValue"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting table row index matching given text.", "response": "def gettablerowindex(self, window_name, object_name, row_text):\n        \"\"\"\n        Get table row index matching given text\n\n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n        @param row_text: Row text to select\n        @type row_text: string\n\n        @return: row index matching the text on success.\n        @rtype: integer\n        \"\"\"\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n\n        index = 0\n        for cell in object_handle.AXRows:\n            if re.match(row_text,\n                        cell.AXChildren[0].AXValue):\n                return index\n            index += 1\n        raise LdtpServerException(u\"Unable to find row: %s\" % row_text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndoubles click row matching given text.", "response": "def doubleclickrow(self, window_name, object_name, row_text):\n        \"\"\"\n        Double click row matching given text\n\n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n        @param row_text: Row text to select\n        @type row_text: string\n\n        @return: row index matching the text on success.\n        @rtype: integer\n        \"\"\"\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n\n        object_handle.activate()\n        self.wait(1)\n        for cell in object_handle.AXRows:\n            cell = self._getfirstmatchingchild(cell, \"(AXTextField|AXStaticText)\")\n            if not cell:\n                continue\n            if re.match(row_text, cell.AXValue):\n                x, y, width, height = self._getobjectsize(cell)\n                # Mouse double click on the object\n                cell.doubleClickMouse((x + width / 2, y + height / 2))\n                return 1\n        raise LdtpServerException('Unable to get row text: %s' % row_text)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef doubleclickrowindex(self, window_name, object_name, row_index, col_index=0):\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n\n        count = len(object_handle.AXRows)\n        if row_index < 0 or row_index > count:\n            raise LdtpServerException('Row index out of range: %d' % row_index)\n        cell = object_handle.AXRows[row_index]\n        self._grabfocus(cell)\n        x, y, width, height = self._getobjectsize(cell)\n        # Mouse double click on the object\n        cell.doubleClickMouse((x + width / 2, y + height / 2))\n        return 1", "response": "Double click the row matching given text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nverify the value of a given table cell with given text.", "response": "def verifytablecell(self, window_name, object_name, row_index,\n                        column_index, row_text):\n        \"\"\"\n        Verify table cell value with given text\n\n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n        @param row_index: Row index to get\n        @type row_index: integer\n        @param column_index: Column index to get, default value 0\n        @type column_index: integer\n        @param row_text: Row text to match\n        @type string\n\n        @return: 1 on success 0 on failure.\n        @rtype: integer\n        \"\"\"\n        try:\n            value = getcellvalue(window_name, object_name, row_index, column_index)\n            if re.match(row_text, value):\n                return 1\n        except LdtpServerException:\n            pass\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef doesrowexist(self, window_name, object_name, row_text,\n                     partial_match=False):\n        \"\"\"\n        Verify table cell value with given text\n\n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n        @param row_text: Row text to match\n        @type string\n        @param partial_match: Find partial match strings\n        @type boolean\n\n        @return: 1 on success 0 on failure.\n        @rtype: integer\n        \"\"\"\n        try:\n            object_handle = self._get_object_handle(window_name, object_name)\n            if not object_handle.AXEnabled:\n                return 0\n\n            for cell in object_handle.AXRows:\n                if not partial_match and re.match(row_text,\n                                                  cell.AXChildren[0].AXValue):\n                    return 1\n                elif partial_match and re.search(row_text,\n                                                 cell.AXChildren[0].AXValue):\n                    return 1\n        except LdtpServerException:\n            pass\n        return 0", "response": "Verify that a given row value with given text exists in a given window."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify partial table cell value", "response": "def verifypartialtablecell(self, window_name, object_name, row_index,\n                               column_index, row_text):\n        \"\"\"\n        Verify partial table cell value\n\n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n        @param row_index: Row index to get\n        @type row_index: integer\n        @param column_index: Column index to get, default value 0\n        @type column_index: integer\n        @param row_text: Row text to match\n        @type string\n\n        @return: 1 on success 0 on failure.\n        @rtype: integer\n        \"\"\"\n        try:\n            value = getcellvalue(window_name, object_name, row_index, column_index)\n            if re.searchmatch(row_text, value):\n                return 1\n        except LdtpServerException:\n            pass\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getapplist(self):\n        app_list = []\n        # Update apps list, before parsing the list\n        self._update_apps()\n        for gui in self._running_apps:\n            name = gui.localizedName()\n            # default type was objc.pyobjc_unicode\n            # convert to Unicode, else exception is thrown\n            # TypeError: \"cannot marshal <type 'objc.pyobjc_unicode'> objects\"\n            try:\n                name = unicode(name)\n            except NameError:\n                name = str(name)\n            except UnicodeEncodeError:\n                pass\n            app_list.append(name)\n        # Return unique application list\n        return list(set(app_list))", "response": "Get all accessibility application name that are currently running\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef startprocessmonitor(self, process_name, interval=2):\n        if process_name in self._process_stats:\n            # Stop previously running instance\n            # At any point, only one process name can be tracked\n            # If an instance already exist, then stop it\n            self._process_stats[process_name].stop()\n        # Create an instance of process stat\n        self._process_stats[process_name] = ProcessStats(process_name, interval)\n        # start monitoring the process\n        self._process_stats[process_name].start()\n        return 1", "response": "Start memory and CPU monitoring for the given process name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstop memory and CPU monitoring for a process.", "response": "def stopprocessmonitor(self, process_name):\n        \"\"\"\n        Stop memory and CPU monitoring\n\n        @param process_name: Process name, ex: firefox-bin.\n        @type process_name: string\n\n        @return: 1 on success\n        @rtype: integer\n        \"\"\"\n        if process_name in self._process_stats:\n            # Stop monitoring process\n            self._process_stats[process_name].stop()\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getcpustat(self, process_name):\n        # Create an instance of process stat\n        _stat_inst = ProcessStats(process_name)\n        _stat_list = []\n        for p in _stat_inst.get_cpu_memory_stat():\n            try:\n                _stat_list.append(p.get_cpu_percent())\n            except psutil.AccessDenied:\n                pass\n        return _stat_list", "response": "get cpu usage for the given process name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getmemorystat(self, process_name):\n        # Create an instance of process stat\n        _stat_inst = ProcessStats(process_name)\n        _stat_list = []\n        for p in _stat_inst.get_cpu_memory_stat():\n            # Memory percent returned with 17 decimal values\n            # ex: 0.16908645629882812, round it to 2 decimal values\n            # as 0.03\n            try:\n                _stat_list.append(round(p.get_memory_percent(), 2))\n            except psutil.AccessDenied:\n                pass\n        return _stat_list", "response": "get memory stat list of process name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getobjectlist(self, window_name):\n        try:\n            window_handle, name, app = self._get_window_handle(window_name, True)\n            object_list = self._get_appmap(window_handle, name, True)\n        except atomac._a11y.ErrorInvalidUIElement:\n            # During the test, when the window closed and reopened\n            # ErrorInvalidUIElement exception will be thrown\n            self._windows = {}\n            # Call the method again, after updating apps\n            window_handle, name, app = self._get_window_handle(window_name, True)\n            object_list = self._get_appmap(window_handle, name, True)\n        return object_list.keys()", "response": "Get list of items in given GUI."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets object properties. @param window_name: Window name to look for, either full name, LDTP's name convention, or a Unix glob. @type window_name: string @param object_name: Object name to look for, either full name, LDTP's name convention, or a Unix glob. @type object_name: string @return: list of properties @rtype: list", "response": "def getobjectinfo(self, window_name, object_name):\n        \"\"\"\n        Get object properties.\n\n        @param window_name: Window name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type object_name: string\n\n        @return: list of properties\n        @rtype: list\n        \"\"\"\n        try:\n            obj_info = self._get_object_map(window_name, object_name,\n                                            wait_for_object=False)\n        except atomac._a11y.ErrorInvalidUIElement:\n            # During the test, when the window closed and reopened\n            # ErrorInvalidUIElement exception will be thrown\n            self._windows = {}\n            # Call the method again, after updating apps\n            obj_info = self._get_object_map(window_name, object_name,\n                                            wait_for_object=False)\n        props = []\n        if obj_info:\n            for obj_prop in obj_info.keys():\n                if not obj_info[obj_prop] or obj_prop == \"obj\":\n                    # Don't add object handle to the list\n                    continue\n                props.append(obj_prop)\n        return props"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets object property value.", "response": "def getobjectproperty(self, window_name, object_name, prop):\n        \"\"\"\n        Get object property value.\n\n        @param window_name: Window name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type object_name: string\n        @param prop: property name.\n        @type prop: string\n\n        @return: property\n        @rtype: string\n        \"\"\"\n        try:\n            obj_info = self._get_object_map(window_name, object_name,\n                                            wait_for_object=False)\n        except atomac._a11y.ErrorInvalidUIElement:\n            # During the test, when the window closed and reopened\n            # ErrorInvalidUIElement exception will be thrown\n            self._windows = {}\n            # Call the method again, after updating apps\n            obj_info = self._get_object_map(window_name, object_name,\n                                            wait_for_object=False)\n        if obj_info and prop != \"obj\" and prop in obj_info:\n            if prop == \"class\":\n                # ldtp_class_type are compatible with Linux and Windows class name\n                # If defined class name exist return that,\n                # else return as it is\n                return ldtp_class_type.get(obj_info[prop], obj_info[prop])\n            else:\n                return obj_info[prop]\n        raise LdtpServerException('Unknown property \"%s\" in %s' % \\\n                                  (prop, object_name))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the list of objects that match the given name or role name or both.", "response": "def getchild(self, window_name, child_name='', role='', parent=''):\n        \"\"\"\n        Gets the list of object available in the window, which matches\n        component name or role name or both.\n\n        @param window_name: Window name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param child_name: Child name to search for.\n        @type child_name: string\n        @param role: role name to search for, or an empty string for wildcard.\n        @type role: string\n        @param parent: parent name to search for, or an empty string for wildcard.\n        @type role: string\n        @return: list of matched children names\n        @rtype: list\n        \"\"\"\n        matches = []\n        if role:\n            role = re.sub(' ', '_', role)\n        self._windows = {}\n        if parent and (child_name or role):\n            _window_handle, _window_name = \\\n                self._get_window_handle(window_name)[0:2]\n            if not _window_handle:\n                raise LdtpServerException('Unable to find window \"%s\"' % \\\n                                          window_name)\n            appmap = self._get_appmap(_window_handle, _window_name)\n            obj = self._get_object_map(window_name, parent)\n\n            def _get_all_children_under_obj(obj, child_list):\n                if role and obj['class'] == role:\n                    child_list.append(obj['label'])\n                elif child_name and self._match_name_to_appmap(child_name, obj):\n                    child_list.append(obj['label'])\n                if obj:\n                    children = obj['children']\n                if not children:\n                    return child_list\n                for child in children.split():\n                    return _get_all_children_under_obj( \\\n                        appmap[child],\n                        child_list)\n\n            matches = _get_all_children_under_obj(obj, [])\n            if not matches:\n                if child_name:\n                    _name = 'name \"%s\" ' % child_name\n                if role:\n                    _role = 'role \"%s\" ' % role\n                if parent:\n                    _parent = 'parent \"%s\"' % parent\n                exception = 'Could not find a child %s%s%s' % (_name, _role, _parent)\n                raise LdtpServerException(exception)\n\n            return matches\n\n        _window_handle, _window_name = \\\n            self._get_window_handle(window_name)[0:2]\n        if not _window_handle:\n            raise LdtpServerException('Unable to find window \"%s\"' % \\\n                                      window_name)\n        appmap = self._get_appmap(_window_handle, _window_name)\n        for name in appmap.keys():\n            obj = appmap[name]\n            # When only role arg is passed\n            if role and not child_name and obj['class'] == role:\n                matches.append(name)\n            # When parent and child_name arg is passed\n            if parent and child_name and not role and \\\n                    self._match_name_to_appmap(parent, obj):\n                matches.append(name)\n            # When only child_name arg is passed\n            if child_name and not role and \\\n                    self._match_name_to_appmap(child_name, obj):\n                return name\n                matches.append(name)\n            # When role and child_name args are passed\n            if role and child_name and obj['class'] == role and \\\n                    self._match_name_to_appmap(child_name, obj):\n                matches.append(name)\n\n        if not matches:\n            _name = ''\n            _role = ''\n            _parent = ''\n            if child_name:\n                _name = 'name \"%s\" ' % child_name\n            if role:\n                _role = 'role \"%s\" ' % role\n            if parent:\n                _parent = 'parent \"%s\"' % parent\n            exception = 'Could not find a child %s%s%s' % (_name, _role, _parent)\n            raise LdtpServerException(exception)\n\n        return matches"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlaunch application by bundle id or path.", "response": "def launchapp(self, cmd, args=[], delay=0, env=1, lang=\"C\"):\n        \"\"\"\n        Launch application.\n\n        @param cmd: Command line string to execute.\n        @type cmd: string\n        @param args: Arguments to the application\n        @type args: list\n        @param delay: Delay after the application is launched\n        @type delay: int\n        @param env: GNOME accessibility environment to be set or not\n        @type env: int\n        @param lang: Application language to be used\n        @type lang: string\n\n        @return: 1 on success\n        @rtype: integer\n\n        @raise LdtpServerException: When command fails\n        \"\"\"\n        try:\n            atomac.NativeUIElement.launchAppByBundleId(cmd)\n            return 1\n        except RuntimeError:\n            if atomac.NativeUIElement.launchAppByBundlePath(cmd, args):\n                # Let us wait so that the application launches\n                try:\n                    time.sleep(int(delay))\n                except ValueError:\n                    time.sleep(5)\n                return 1\n            else:\n                raise LdtpServerException(u\"Unable to find app '%s'\" % cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef activatewindow(self, window_name):\n        window_handle = self._get_window_handle(window_name)\n        self._grabfocus(window_handle)\n        return 1", "response": "Activate window.\n\n        @param window_name: Window name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n\n        @return: 1 on success.\n        @rtype: integer"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef click(self, window_name, object_name):\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        size = self._getobjectsize(object_handle)\n        self._grabfocus(object_handle)\n        self.wait(0.5)\n\n        # If object doesn't support Press, trying clicking with the object\n        # coordinates, where size=(x, y, width, height)\n        # click on center of the widget\n        # Noticed this issue on clicking AXImage\n        # click('Instruments*', 'Automation')\n        self.generatemouseevent(size[0] + size[2] / 2, size[1] + size[3] / 2, \"b1c\")\n        return 1", "response": "Click an object in the specified window."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget all states of given object_name in given window_name.", "response": "def getallstates(self, window_name, object_name):\n        \"\"\"\n        Get all states of given object\n\n        @param window_name: Window name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type object_name: string\n\n        @return: list of string on success.\n        @rtype: list\n        \"\"\"\n        object_handle = self._get_object_handle(window_name, object_name)\n        _obj_states = []\n        if object_handle.AXEnabled:\n            _obj_states.append(\"enabled\")\n        if object_handle.AXFocused:\n            _obj_states.append(\"focused\")\n        else:\n            try:\n                if object_handle.AXFocused:\n                    _obj_states.append(\"focusable\")\n            except:\n                pass\n        if re.match(\"AXCheckBox\", object_handle.AXRole, re.M | re.U | re.L) or \\\n                re.match(\"AXRadioButton\", object_handle.AXRole,\n                         re.M | re.U | re.L):\n            if object_handle.AXValue:\n                _obj_states.append(\"checked\")\n        return _obj_states"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hasstate(self, window_name, object_name, state, guiTimeOut=0):\n        try:\n            object_handle = self._get_object_handle(window_name, object_name)\n            if state == \"enabled\":\n                return int(object_handle.AXEnabled)\n            elif state == \"focused\":\n                return int(object_handle.AXFocused)\n            elif state == \"focusable\":\n                return int(object_handle.AXFocused)\n            elif state == \"checked\":\n                if re.match(\"AXCheckBox\", object_handle.AXRole,\n                            re.M | re.U | re.L) or \\\n                        re.match(\"AXRadioButton\", object_handle.AXRole,\n                                 re.M | re.U | re.L):\n                    if object_handle.AXValue:\n                        return 1\n        except:\n            pass\n        return 0", "response": "Check if the current object has the given state."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getobjectsize(self, window_name, object_name=None):\n        if not object_name:\n            handle, name, app = self._get_window_handle(window_name)\n        else:\n            handle = self._get_object_handle(window_name, object_name)\n        return self._getobjectsize(handle)", "response": "Get object size of a specific object in a given window."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef grabfocus(self, window_name, object_name=None):\n        if not object_name:\n            handle, name, app = self._get_window_handle(window_name)\n        else:\n            handle = self._get_object_handle(window_name, object_name)\n        return self._grabfocus(handle)", "response": "Grab focus from the specified object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking whether a window or component exists.", "response": "def guiexist(self, window_name, object_name=None):\n        \"\"\"\n        Checks whether a window or component exists.\n\n        @param window_name: Window name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type object_name: string\n\n        @return: 1 on success.\n        @rtype: integer\n        \"\"\"\n        try:\n            self._windows = {}\n            if not object_name:\n                handle, name, app = self._get_window_handle(window_name, False)\n            else:\n                handle = self._get_object_handle(window_name, object_name,\n                                                 wait_for_object=False,\n                                                 force_remap=True)\n            # If window and/or object exist, exception will not be thrown\n            # blindly return 1\n            return 1\n        except LdtpServerException:\n            pass\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwait till a window or component exists.", "response": "def waittillguiexist(self, window_name, object_name='',\n                         guiTimeOut=30, state=''):\n        \"\"\"\n        Wait till a window or component exists.\n\n        @param window_name: Window name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type object_name: string\n        @param guiTimeOut: Wait timeout in seconds\n        @type guiTimeOut: integer\n        @param state: Object state used only when object_name is provided.\n        @type object_name: string\n\n        @return: 1 if GUI was found, 0 if not.\n        @rtype: integer\n        \"\"\"\n        timeout = 0\n        while timeout < guiTimeOut:\n            if self.guiexist(window_name, object_name):\n                return 1\n            # Wait 1 second before retrying\n            time.sleep(1)\n            timeout += 1\n        # Object and/or window doesn't appear within the timeout period\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwaits till a window does not exist.", "response": "def waittillguinotexist(self, window_name, object_name='', guiTimeOut=30):\n        \"\"\"\n        Wait till a window does not exist.\n\n        @param window_name: Window name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type object_name: string\n        @param guiTimeOut: Wait timeout in seconds\n        @type guiTimeOut: integer\n\n        @return: 1 if GUI has gone away, 0 if not.\n        @rtype: integer\n        \"\"\"\n        timeout = 0\n        while timeout < guiTimeOut:\n            if not self.guiexist(window_name, object_name):\n                return 1\n            # Wait 1 second before retrying\n            time.sleep(1)\n            timeout += 1\n        # Object and/or window still appears within the timeout period\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef objectexist(self, window_name, object_name):\n        try:\n            object_handle = self._get_object_handle(window_name, object_name)\n            return 1\n        except LdtpServerException:\n            return 0", "response": "Checks whether a window or component exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stateenabled(self, window_name, object_name):\n        try:\n            object_handle = self._get_object_handle(window_name, object_name)\n            if object_handle.AXEnabled:\n                return 1\n        except LdtpServerException:\n            pass\n        return 0", "response": "Check whether an object state is enabled or not."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if an object is in the LDTP s name convention.", "response": "def check(self, window_name, object_name):\n        \"\"\"\n        Check item.\n\n        @param window_name: Window name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type object_name: string\n\n        @return: 1 on success.\n        @rtype: integer\n        \"\"\"\n        # FIXME: Check for object type\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        if object_handle.AXValue == 1:\n            # Already checked\n            return 1\n        # AXPress doesn't work with Instruments\n        # So did the following work around\n        self._grabfocus(object_handle)\n        x, y, width, height = self._getobjectsize(object_handle)\n        # Mouse left click on the object\n        # Note: x + width/2, y + height / 2 doesn't work\n        self.generatemouseevent(x + width / 2, y + height / 2, \"b1c\")\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef verifycheck(self, window_name, object_name):\n        try:\n            object_handle = self._get_object_handle(window_name, object_name,\n                                                    wait_for_object=False)\n            if object_handle.AXValue == 1:\n                return 1\n        except LdtpServerException:\n            pass\n        return 0", "response": "Verify check item.\n\n        @param window_name: Window name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type object_name: string\n\n        @return: 1 on success 0 on failure.\n        @rtype: integer"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the access key of given object and return it in string format.", "response": "def getaccesskey(self, window_name, object_name):\n        \"\"\"\n        Get access key of given object\n\n        @param window_name: Window name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to look for, either full name,\n        LDTP's name convention, or a Unix glob. Or menu heirarchy\n        @type object_name: string\n\n        @return: access key in string format on success, else LdtpExecutionError on failure.\n        @rtype: string\n        \"\"\"\n        # Used http://www.danrodney.com/mac/ as reference for\n        # mapping keys with specific control\n        # In Mac noticed (in accessibility inspector) only menu had access keys\n        # so, get the menu_handle of given object and\n        # return the access key\n        menu_handle = self._get_menu_handle(window_name, object_name)\n        key = menu_handle.AXMenuItemCmdChar\n        modifiers = menu_handle.AXMenuItemCmdModifiers\n        glpyh = menu_handle.AXMenuItemCmdGlyph\n        virtual_key = menu_handle.AXMenuItemCmdVirtualKey\n        modifiers_type = \"\"\n        if modifiers == 0:\n            modifiers_type = \"<command>\"\n        elif modifiers == 1:\n            modifiers_type = \"<shift><command>\"\n        elif modifiers == 2:\n            modifiers_type = \"<option><command>\"\n        elif modifiers == 3:\n            modifiers_type = \"<option><shift><command>\"\n        elif modifiers == 4:\n            modifiers_type = \"<ctrl><command>\"\n        elif modifiers == 6:\n            modifiers_type = \"<ctrl><option><command>\"\n        # Scroll up\n        if virtual_key == 115 and glpyh == 102:\n            modifiers = \"<option>\"\n            key = \"<cursor_left>\"\n        # Scroll down\n        elif virtual_key == 119 and glpyh == 105:\n            modifiers = \"<option>\"\n            key = \"<right>\"\n        # Page up\n        elif virtual_key == 116 and glpyh == 98:\n            modifiers = \"<option>\"\n            key = \"<up>\"\n        # Page down\n        elif virtual_key == 121 and glpyh == 107:\n            modifiers = \"<option>\"\n            key = \"<down>\"\n        # Line up\n        elif virtual_key == 126 and glpyh == 104:\n            key = \"<up>\"\n        # Line down\n        elif virtual_key == 125 and glpyh == 106:\n            key = \"<down>\"\n        # Noticed in  Google Chrome navigating next tab\n        elif virtual_key == 124 and glpyh == 101:\n            key = \"<right>\"\n        # Noticed in  Google Chrome navigating previous tab\n        elif virtual_key == 123 and glpyh == 100:\n            key = \"<left>\"\n        # List application in a window to Force Quit\n        elif virtual_key == 53 and glpyh == 27:\n            key = \"<escape>\"\n        # FIXME:\n        # * Instruments Menu View->Run Browser\n        # modifiers==12 virtual_key==48 glpyh==2\n        # * Terminal Menu Edit->Start Dictation\n        # fn fn - glpyh==148 modifiers==24\n        # * Menu Chrome->Clear Browsing Data in Google Chrome\n        # virtual_key==51 glpyh==23 [Delete Left (like Backspace on a PC)]\n        if not key:\n            raise LdtpServerException(\"No access key associated\")\n        return modifiers_type + key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef paste(cls):\n        pb = AppKit.NSPasteboard.generalPasteboard()\n\n        # If we allow for multiple data types (e.g. a list of data types)\n        # we will have to add a condition to check just the first in the\n        # list of datatypes)\n        data = pb.stringForType_(cls.STRING)\n        return data", "response": "Get the clipboard data ('Paste')."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncopying the clipboard data to the clipboard.", "response": "def copy(cls, data):\n        \"\"\"Set the clipboard data ('Copy').\n\n        Parameters: data to set (string)\n        Optional: datatype if it's not a string\n        Returns: True / False on successful copy, Any exception raised (like\n                 passes the NSPasteboardCommunicationError) should be caught\n                 by the caller.\n        \"\"\"\n        pp = pprint.PrettyPrinter()\n\n        copy_data = 'Data to copy (put in pasteboard): %s'\n        logging.debug(copy_data % pp.pformat(data))\n\n        # Clear the pasteboard first:\n        cleared = cls.clearAll()\n        if not cleared:\n            logging.warning('Clipboard could not clear properly')\n            return False\n\n        # Prepare to write the data\n        # If we just use writeObjects the sequence to write to the clipboard is\n        # a) Call clearContents()\n        # b) Call writeObjects() with a list of objects to write to the\n        #    clipboard\n        if not isinstance(data, types.ListType):\n            data = [data]\n\n        pb = AppKit.NSPasteboard.generalPasteboard()\n        pb_set_ok = pb.writeObjects_(data)\n\n        return bool(pb_set_ok)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclear contents of general pasteboard.", "response": "def clearContents(cls):\n        \"\"\"Clear contents of general pasteboard.\n\n        Future enhancement can include specifying which clipboard to clear\n        Returns: True on success; caller should expect to catch exceptions,\n                 probably from AppKit (ValueError)\n        \"\"\"\n        log_msg = 'Request to clear contents of pasteboard: general'\n        logging.debug(log_msg)\n        pb = AppKit.NSPasteboard.generalPasteboard()\n        pb.clearContents()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _ldtpize_accessible(self, acc):\n        actual_role = self._get_role(acc)\n        label = self._get_title(acc)\n        if re.match(\"AXWindow\", actual_role, re.M | re.U | re.L):\n            # Strip space and new line from window title\n            strip = r\"( |\\n)\"\n        else:\n            # Strip space, colon, dot, underscore and new line from\n            # all other object types\n            strip = r\"( |:|\\.|_|\\n)\"\n        if label:\n            # Return the role type (if, not in the know list of roles,\n            # return ukn - unknown), strip the above characters from name\n            # also return labely_by string\n            label = re.sub(strip, u\"\", label)\n        role = abbreviated_roles.get(actual_role, \"ukn\")\n        if self._ldtp_debug and role == \"ukn\":\n            print(actual_role, acc)\n        return role, label", "response": "Return object type stripped object name associated with an object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if pattern matches given string.", "response": "def _glob_match(self, pattern, string):\n        \"\"\"\n        Match given string, by escaping regex characters\n        \"\"\"\n        # regex flags Multi-line, Unicode, Locale\n        return bool(re.match(fnmatch.translate(pattern), string,\n                             re.M | re.U | re.L))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nselect a menu item.", "response": "def selectmenuitem(self, window_name, object_name):\n        \"\"\"\n        Select (click) a menu item.\n\n        @param window_name: Window name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to look for, either full name,\n        LDTP's name convention, or a Unix glob. Or menu heirarchy\n        @type object_name: string\n\n        @return: 1 on success.\n        @rtype: integer\n        \"\"\"\n        menu_handle = self._get_menu_handle(window_name, object_name)\n        if not menu_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        menu_handle.Press()\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef doesmenuitemexist(self, window_name, object_name):\n        try:\n            menu_handle = self._get_menu_handle(window_name, object_name,\n                                                False)\n            return 1\n        except LdtpServerException:\n            return 0", "response": "Check a menu item exist."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef menuitemenabled(self, window_name, object_name):\n        try:\n            menu_handle = self._get_menu_handle(window_name, object_name,\n                                                False)\n            if menu_handle.AXEnabled:\n                return 1\n        except LdtpServerException:\n            pass\n        return 0", "response": "Verify a menu item is enabled by checking if a menu item is enabled by the object name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists all children of a menu item under a given object name.", "response": "def listsubmenus(self, window_name, object_name):\n        \"\"\"\n        List children of menu item\n        \n        @param window_name: Window name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to look for, either full name,\n        LDTP's name convention, or a Unix glob. Or menu heirarchy\n        @type object_name: string\n\n        @return: menu item in list on success.\n        @rtype: list\n        \"\"\"\n        menu_handle = self._get_menu_handle(window_name, object_name)\n        role, label = self._ldtpize_accessible(menu_handle)\n        menu_clicked = False\n        try:\n            if not menu_handle.AXChildren:\n                menu_clicked = True\n                try:\n                    menu_handle.Press()\n                    self.wait(1)\n                except atomac._a11y.ErrorCannotComplete:\n                    pass\n                if not menu_handle.AXChildren:\n                    raise LdtpServerException(u\"Unable to find children under menu %s\" % \\\n                                              label)\n            children = menu_handle.AXChildren[0]\n            sub_menus = []\n            for current_menu in children.AXChildren:\n                role, label = self._ldtpize_accessible(current_menu)\n                if not label:\n                    # All splitters have empty label\n                    continue\n                sub_menus.append(u\"%s%s\" % (role, label))\n        finally:\n            if menu_clicked:\n                menu_handle.Cancel()\n        return sub_menus"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef menucheck(self, window_name, object_name):\n        menu_handle = self._get_menu_handle(window_name, object_name)\n        if not menu_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        try:\n            if menu_handle.AXMenuItemMarkChar:\n                # Already checked\n                return 1\n        except atomac._a11y.Error:\n            pass\n        menu_handle.Press()\n        return 1", "response": "Check a menu item."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a list of the running applications.", "response": "def _getRunningApps(cls):\n        \"\"\"Get a list of the running applications.\"\"\"\n\n        def runLoopAndExit():\n            AppHelper.stopEventLoop()\n\n        AppHelper.callLater(1, runLoopAndExit)\n        AppHelper.runConsoleEventLoop()\n        # Get a list of running applications\n        ws = AppKit.NSWorkspace.sharedWorkspace()\n        apps = ws.runningApplications()\n        return apps"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the current frontmost application. Raise a ValueError exception if no frontmost application is found.", "response": "def getFrontmostApp(cls):\n        \"\"\"Get the current frontmost application.\n\n        Raise a ValueError exception if no GUI applications are found.\n        \"\"\"\n        # Refresh the runningApplications list\n        apps = cls._getRunningApps()\n        for app in apps:\n            pid = app.processIdentifier()\n            ref = cls.getAppRefByPid(pid)\n            try:\n                if ref.AXFrontmost:\n                    return ref\n            except (_a11y.ErrorUnsupported,\n                    _a11y.ErrorCannotComplete,\n                    _a11y.ErrorAPIDisabled,\n                    _a11y.ErrorNotImplemented):\n                # Some applications do not have an explicit GUI\n                # and so will not have an AXFrontmost attribute\n                # Trying to read attributes from Google Chrome Helper returns\n                # ErrorAPIDisabled for some reason - opened radar bug 12837995\n                pass\n        raise ValueError('No GUI application found.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getAnyAppWithWindow(cls):\n        # Refresh the runningApplications list\n        apps = cls._getRunningApps()\n        for app in apps:\n            pid = app.processIdentifier()\n            ref = cls.getAppRefByPid(pid)\n            if hasattr(ref, 'windows') and len(ref.windows()) > 0:\n                return ref\n        raise ValueError('No GUI application found.')", "response": "Get a random app that has windows. Raise a ValueError exception if no GUI applications are found."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlaunching the application with the specified bundle ID.", "response": "def launchAppByBundleId(bundleID):\n        \"\"\"Launch the application with the specified bundle ID\"\"\"\n        # NSWorkspaceLaunchAllowingClassicStartup does nothing on any\n        # modern system that doesn't have the classic environment installed.\n        # Encountered a bug when passing 0 for no options on 10.6 PyObjC.\n        ws = AppKit.NSWorkspace.sharedWorkspace()\n        # Sorry about the length of the following line\n        r = ws.launchAppWithBundleIdentifier_options_additionalEventParamDescriptor_launchIdentifier_(\n            bundleID,\n            AppKit.NSWorkspaceLaunchAllowingClassicStartup,\n            AppKit.NSAppleEventDescriptor.nullDescriptor(),\n            None)\n        # On 10.6, this returns a tuple - first element bool result, second is\n        # a number. Let's use the bool result.\n        if not r[0]:\n            raise RuntimeError('Error launching specified application.')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlaunch app with a given bundle path.", "response": "def launchAppByBundlePath(bundlePath, arguments=None):\n        \"\"\"Launch app with a given bundle path.\n\n        Return True if succeed.\n        \"\"\"\n        if arguments is None:\n            arguments = []\n\n        bundleUrl = NSURL.fileURLWithPath_(bundlePath)\n        workspace = AppKit.NSWorkspace.sharedWorkspace()\n        arguments_strings = list(map(lambda a: NSString.stringWithString_(str(a)),\n                                arguments))\n        arguments = NSDictionary.dictionaryWithDictionary_({\n            AppKit.NSWorkspaceLaunchConfigurationArguments: NSArray.arrayWithArray_(\n                arguments_strings)\n        })\n\n        return workspace.launchApplicationAtURL_options_configuration_error_(\n            bundleUrl,\n            AppKit.NSWorkspaceLaunchAllowingClassicStartup,\n            arguments,\n            None)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nterminate an application with a given bundle ID. Requires 10. 6.", "response": "def terminateAppByBundleId(bundleID):\n        \"\"\"Terminate app with a given bundle ID.\n        Requires 10.6.\n\n        Return True if succeed.\n        \"\"\"\n        ra = AppKit.NSRunningApplication\n        if getattr(ra, \"runningApplicationsWithBundleIdentifier_\"):\n            appList = ra.runningApplicationsWithBundleIdentifier_(bundleID)\n            if appList and len(appList) > 0:\n                app = appList[0]\n                return app and app.terminate() and True or False\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _postQueuedEvents(self, interval=0.01):\n        while len(self.eventList) > 0:\n            (nextEvent, args) = self.eventList.popleft()\n            nextEvent(*args)\n            time.sleep(interval)", "response": "Private method to post queued events to the local cache."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a keypress to the queue.", "response": "def _addKeyToQueue(self, keychr, modFlags=0, globally=False):\n        \"\"\"Add keypress to queue.\n\n        Parameters: key character or constant referring to a non-alpha-numeric\n                    key (e.g. RETURN or TAB)\n                    modifiers\n                    global or app specific\n        Returns: None or raise ValueError exception.\n        \"\"\"\n        # Awkward, but makes modifier-key-only combinations possible\n        # (since sendKeyWithModifiers() calls this)\n        if not keychr:\n            return\n\n        if not hasattr(self, 'keyboard'):\n            self.keyboard = AXKeyboard.loadKeyboard()\n\n        if keychr in self.keyboard['upperSymbols'] and not modFlags:\n            self._sendKeyWithModifiers(keychr,\n                                       [AXKeyCodeConstants.SHIFT],\n                                       globally)\n            return\n\n        if keychr.isupper() and not modFlags:\n            self._sendKeyWithModifiers(\n                keychr.lower(),\n                [AXKeyCodeConstants.SHIFT],\n                globally\n            )\n            return\n\n        if keychr not in self.keyboard:\n            self._clearEventQueue()\n            raise ValueError('Key %s not found in keyboard layout' % keychr)\n\n        # Press the key\n        keyDown = Quartz.CGEventCreateKeyboardEvent(None,\n                                                    self.keyboard[keychr],\n                                                    True)\n        # Release the key\n        keyUp = Quartz.CGEventCreateKeyboardEvent(None,\n                                                  self.keyboard[keychr],\n                                                  False)\n        # Set modflags on keyDown (default None):\n        Quartz.CGEventSetFlags(keyDown, modFlags)\n        # Set modflags on keyUp:\n        Quartz.CGEventSetFlags(keyUp, modFlags)\n\n        # Post the event to the given app\n        if not globally:\n            # To direct output to the correct application need the PSN (macOS <=10.10) or PID(macOS > 10.10):\n            macVer, _, _ = platform.mac_ver()\n            macVer = int(macVer.split('.')[1])\n            if macVer > 10:\n                appPid = self._getPid()\n                self._queueEvent(Quartz.CGEventPostToPid, (appPid, keyDown))\n                self._queueEvent(Quartz.CGEventPostToPid, (appPid, keyUp))\n            else:\n                appPsn = self._getPsnForPid(self._getPid())\n                self._queueEvent(Quartz.CGEventPostToPSN, (appPsn, keyDown))\n                self._queueEvent(Quartz.CGEventPostToPSN, (appPsn, keyUp))\n        else:\n            self._queueEvent(Quartz.CGEventPost, (0, keyDown))\n            self._queueEvent(Quartz.CGEventPost, (0, keyUp))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _sendKey(self, keychr, modFlags=0, globally=False):\n        escapedChrs = {\n            '\\n': AXKeyCodeConstants.RETURN,\n            '\\r': AXKeyCodeConstants.RETURN,\n            '\\t': AXKeyCodeConstants.TAB,\n        }\n        if keychr in escapedChrs:\n            keychr = escapedChrs[keychr]\n\n        self._addKeyToQueue(keychr, modFlags, globally=globally)\n        self._postQueuedEvents()", "response": "Send one character with no modifiers."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npress given modifiers (provided in list form). Parameters: modifiers list, global or app specific Optional: keypressed state (default is True (down)) Returns: Unsigned int representing flags to set", "response": "def _pressModifiers(self, modifiers, pressed=True, globally=False):\n        \"\"\"Press given modifiers (provided in list form).\n\n        Parameters: modifiers list, global or app specific\n        Optional: keypressed state (default is True (down))\n        Returns: Unsigned int representing flags to set\n        \"\"\"\n        if not isinstance(modifiers, list):\n            raise TypeError('Please provide modifiers in list form')\n\n        if not hasattr(self, 'keyboard'):\n            self.keyboard = AXKeyboard.loadKeyboard()\n\n        modFlags = 0\n\n        # Press given modifiers\n        for nextMod in modifiers:\n            if nextMod not in self.keyboard:\n                errStr = 'Key %s not found in keyboard layout'\n                self._clearEventQueue()\n                raise ValueError(errStr % self.keyboard[nextMod])\n            modEvent = Quartz.CGEventCreateKeyboardEvent(\n                Quartz.CGEventSourceCreate(0),\n                self.keyboard[nextMod],\n                pressed\n            )\n            if not pressed:\n                # Clear the modflags:\n                Quartz.CGEventSetFlags(modEvent, 0)\n            if globally:\n                self._queueEvent(Quartz.CGEventPost, (0, modEvent))\n            else:\n                # To direct output to the correct application need the PSN (macOS <=10.10) or PID(macOS > 10.10):\n                macVer, _, _ = platform.mac_ver()\n                macVer = int(macVer.split('.')[1])\n                if macVer > 10:\n                    appPid = self._getPid()\n                    self._queueEvent(Quartz.CGEventPostToPid, (appPid, modEvent))\n                else:\n                    appPsn = self._getPsnForPid(self._getPid())\n                    self._queueEvent(Quartz.CGEventPostToPSN, (appPsn, modEvent))\n            # Add the modifier flags\n            modFlags += AXKeyboard.modKeyFlagConstants[nextMod]\n\n        return modFlags"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _holdModifierKeys(self, modifiers):\n        modFlags = self._pressModifiers(modifiers)\n        # Post the queued keypresses:\n        self._postQueuedEvents()\n        return modFlags", "response": "Hold given modifier keys."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrelease given modifiers (provided in list form). Parameters: modifiers list Returns: None", "response": "def _releaseModifiers(self, modifiers, globally=False):\n        \"\"\"Release given modifiers (provided in list form).\n\n        Parameters: modifiers list\n        Returns: None\n        \"\"\"\n        # Release them in reverse order from pressing them:\n        modifiers.reverse()\n        modFlags = self._pressModifiers(modifiers, pressed=False,\n                                        globally=globally)\n        return modFlags"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _releaseModifierKeys(self, modifiers):\n        modFlags = self._releaseModifiers(modifiers)\n        # Post the queued keypresses:\n        self._postQueuedEvents()\n        return modFlags", "response": "Release given modifier keys."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck whether given key character is a single character.", "response": "def _isSingleCharacter(keychr):\n        \"\"\"Check whether given keyboard character is a single character.\n\n        Parameters: key character which will be checked.\n        Returns: True when given key character is a single character.\n        \"\"\"\n        if not keychr:\n            return False\n        # Regular character case.\n        if len(keychr) == 1:\n            return True\n        # Tagged character case.\n        return keychr.count('<') == 1 and keychr.count('>') == 1 and \\\n               keychr[0] == '<' and keychr[-1] == '>'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _sendKeyWithModifiers(self, keychr, modifiers, globally=False):\n        if not self._isSingleCharacter(keychr):\n            raise ValueError('Please provide only one character to send')\n\n        if not hasattr(self, 'keyboard'):\n            self.keyboard = AXKeyboard.loadKeyboard()\n\n        modFlags = self._pressModifiers(modifiers, globally=globally)\n\n        # Press the non-modifier key\n        self._sendKey(keychr, modFlags, globally=globally)\n\n        # Release the modifiers\n        self._releaseModifiers(modifiers, globally=globally)\n\n        # Post the queued keypresses:\n        self._postQueuedEvents()", "response": "Send one character with the given modifiers pressed."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _queueMouseButton(self, coord, mouseButton, modFlags, clickCount=1,\n                          dest_coord=None):\n        \"\"\"Private method to handle generic mouse button clicking.\n\n        Parameters: coord (x, y) to click, mouseButton (e.g.,\n                    kCGMouseButtonLeft), modFlags set (int)\n        Optional: clickCount (default 1; set to 2 for double-click; 3 for\n                  triple-click on host)\n        Returns: None\n        \"\"\"\n        # For now allow only left and right mouse buttons:\n        mouseButtons = {\n            Quartz.kCGMouseButtonLeft: 'LeftMouse',\n            Quartz.kCGMouseButtonRight: 'RightMouse',\n        }\n        if mouseButton not in mouseButtons:\n            raise ValueError('Mouse button given not recognized')\n\n        eventButtonDown = getattr(Quartz,\n                                  'kCGEvent%sDown' % mouseButtons[mouseButton])\n        eventButtonUp = getattr(Quartz,\n                                'kCGEvent%sUp' % mouseButtons[mouseButton])\n        eventButtonDragged = getattr(Quartz,\n                                     'kCGEvent%sDragged' % mouseButtons[\n                                         mouseButton])\n\n        # Press the button\n        buttonDown = Quartz.CGEventCreateMouseEvent(None,\n                                                    eventButtonDown,\n                                                    coord,\n                                                    mouseButton)\n        # Set modflags (default None) on button down:\n        Quartz.CGEventSetFlags(buttonDown, modFlags)\n\n        # Set the click count on button down:\n        Quartz.CGEventSetIntegerValueField(buttonDown,\n                                           Quartz.kCGMouseEventClickState,\n                                           int(clickCount))\n\n        if dest_coord:\n            # Drag and release the button\n            buttonDragged = Quartz.CGEventCreateMouseEvent(None,\n                                                           eventButtonDragged,\n                                                           dest_coord,\n                                                           mouseButton)\n            # Set modflags on the button dragged:\n            Quartz.CGEventSetFlags(buttonDragged, modFlags)\n\n            buttonUp = Quartz.CGEventCreateMouseEvent(None,\n                                                      eventButtonUp,\n                                                      dest_coord,\n                                                      mouseButton)\n        else:\n            # Release the button\n            buttonUp = Quartz.CGEventCreateMouseEvent(None,\n                                                      eventButtonUp,\n                                                      coord,\n                                                      mouseButton)\n        # Set modflags on the button up:\n        Quartz.CGEventSetFlags(buttonUp, modFlags)\n\n        # Set the click count on button up:\n        Quartz.CGEventSetIntegerValueField(buttonUp,\n                                           Quartz.kCGMouseEventClickState,\n                                           int(clickCount))\n        # Queue the events\n        self._queueEvent(Quartz.CGEventPost,\n                         (Quartz.kCGSessionEventTap, buttonDown))\n        if dest_coord:\n            self._queueEvent(Quartz.CGEventPost,\n                             (Quartz.kCGHIDEventTap, buttonDragged))\n        self._queueEvent(Quartz.CGEventPost,\n                         (Quartz.kCGSessionEventTap, buttonUp))", "response": "Private method to handle generic mouse button clicking."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _leftMouseDragged(self, stopCoord, strCoord, speed):\n        # To direct output to the correct application need the PSN:\n        appPid = self._getPid()\n        # Get current position as start point if strCoord not given\n        if strCoord == (0, 0):\n            loc = AppKit.NSEvent.mouseLocation()\n            strCoord = (loc.x, Quartz.CGDisplayPixelsHigh(0) - loc.y)\n\n        # To direct output to the correct application need the PSN:\n        appPid = self._getPid()\n\n        # Press left button down\n        pressLeftButton = Quartz.CGEventCreateMouseEvent(\n            None,\n            Quartz.kCGEventLeftMouseDown,\n            strCoord,\n            Quartz.kCGMouseButtonLeft\n        )\n        # Queue the events\n        Quartz.CGEventPost(Quartz.CoreGraphics.kCGHIDEventTap, pressLeftButton)\n        # Wait for reponse of system, a fuzzy icon appears\n        time.sleep(5)\n        # Simulate mouse moving speed, k is slope\n        speed = round(1 / float(speed), 2)\n        xmoved = stopCoord[0] - strCoord[0]\n        ymoved = stopCoord[1] - strCoord[1]\n        if ymoved == 0:\n            raise ValueError('Not support horizontal moving')\n        else:\n            k = abs(ymoved / xmoved)\n\n        if xmoved != 0:\n            for xpos in range(int(abs(xmoved))):\n                if xmoved > 0 and ymoved > 0:\n                    currcoord = (strCoord[0] + xpos, strCoord[1] + xpos * k)\n                elif xmoved > 0 and ymoved < 0:\n                    currcoord = (strCoord[0] + xpos, strCoord[1] - xpos * k)\n                elif xmoved < 0 and ymoved < 0:\n                    currcoord = (strCoord[0] - xpos, strCoord[1] - xpos * k)\n                elif xmoved < 0 and ymoved > 0:\n                    currcoord = (strCoord[0] - xpos, strCoord[1] + xpos * k)\n                # Drag with left button\n                dragLeftButton = Quartz.CGEventCreateMouseEvent(\n                    None,\n                    Quartz.kCGEventLeftMouseDragged,\n                    currcoord,\n                    Quartz.kCGMouseButtonLeft\n                )\n                Quartz.CGEventPost(Quartz.CoreGraphics.kCGHIDEventTap,\n                                   dragLeftButton)\n                # Wait for reponse of system\n                time.sleep(speed)\n        else:\n            raise ValueError('Not support vertical moving')\n        upLeftButton = Quartz.CGEventCreateMouseEvent(\n            None,\n            Quartz.kCGEventLeftMouseUp,\n            stopCoord,\n            Quartz.kCGMouseButtonLeft\n        )\n        # Wait for reponse of system, a plus icon appears\n        time.sleep(5)\n        # Up left button up\n        Quartz.CGEventPost(Quartz.CoreGraphics.kCGHIDEventTap, upLeftButton)", "response": "Private method to handle generic mouse left button dragging and dropping and dropping."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwaiting for a particular UI event to occur ; this can be built upon in NativeUIElement for specific convenience methods.", "response": "def _waitFor(self, timeout, notification, **kwargs):\n        \"\"\"Wait for a particular UI event to occur; this can be built\n        upon in NativeUIElement for specific convenience methods.\n        \"\"\"\n        callback = self._matchOther\n        retelem = None\n        callbackArgs = None\n        callbackKwargs = None\n\n        # Allow customization of the callback, though by default use the basic\n        # _match() method\n        if 'callback' in kwargs:\n            callback = kwargs['callback']\n            del kwargs['callback']\n\n            # Deal with these only if callback is provided:\n            if 'args' in kwargs:\n                if not isinstance(kwargs['args'], tuple):\n                    errStr = 'Notification callback args not given as a tuple'\n                    raise TypeError(errStr)\n\n                # If args are given, notification will pass back the returned\n                # element in the first positional arg\n                callbackArgs = kwargs['args']\n                del kwargs['args']\n\n            if 'kwargs' in kwargs:\n                if not isinstance(kwargs['kwargs'], dict):\n                    errStr = 'Notification callback kwargs not given as a dict'\n                    raise TypeError(errStr)\n\n                callbackKwargs = kwargs['kwargs']\n                del kwargs['kwargs']\n            # If kwargs are not given as a dictionary but individually listed\n            # need to update the callbackKwargs dict with the remaining items in\n            # kwargs\n            if kwargs:\n                if callbackKwargs:\n                    callbackKwargs.update(kwargs)\n                else:\n                    callbackKwargs = kwargs\n        else:\n            callbackArgs = (retelem,)\n            # Pass the kwargs to the default callback\n            callbackKwargs = kwargs\n\n        return self._setNotification(timeout, notification, callback,\n                                     callbackArgs,\n                                     callbackKwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef waitForFocusToMatchCriteria(self, timeout=10, **kwargs):\n\n        def _matchFocused(retelem, **kwargs):\n            return retelem if retelem._match(**kwargs) else None\n\n        retelem = None\n        return self._waitFor(timeout, 'AXFocusedUIElementChanged',\n                             callback=_matchFocused,\n                             args=(retelem,),\n                             **kwargs)", "response": "Convenience method to wait for focused element to change the specified kwargs criteria."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves a list of actions supported by the object.", "response": "def _getActions(self):\n        \"\"\"Retrieve a list of actions supported by the object.\"\"\"\n        actions = _a11y.AXUIElement._getActions(self)\n        # strip leading AX from actions - help distinguish them from attributes\n        return [action[2:] for action in actions]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _performAction(self, action):\n        try:\n            _a11y.AXUIElement._performAction(self, 'AX%s' % action)\n        except _a11y.ErrorUnsupported as e:\n            sierra_ver = '10.12'\n            if mac_ver()[0] < sierra_ver:\n                raise e\n            else:\n                pass", "response": "Perform the specified action."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _generateChildren(self):\n        try:\n            children = self.AXChildren\n        except _a11y.Error:\n            return\n        if children:\n            for child in children:\n                yield child", "response": "Generator which yields all AXChildren of the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _matchOther(self, obj, **kwargs):\n        if obj is not None:\n            # Need to check that the returned UI element wasn't destroyed first:\n            if self._findFirstR(**kwargs):\n                return obj._match(**kwargs)\n        return False", "response": "Perform _match but on another object not self."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _generateFind(self, **kwargs):\n        for needle in self._generateChildren():\n            if needle._match(**kwargs):\n                yield needle", "response": "Generator which yields matches on AXChildren."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of all children that match the specified criteria.", "response": "def _findAll(self, **kwargs):\n        \"\"\"Return a list of all children that match the specified criteria.\"\"\"\n        result = []\n        for item in self._generateFind(**kwargs):\n            result.append(item)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of all children that match the specified criteria.", "response": "def _findAllR(self, **kwargs):\n        \"\"\"Return a list of all children (recursively) that match the specified\n        criteria.\n        \"\"\"\n        result = []\n        for item in self._generateFindR(**kwargs):\n            result.append(item)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _getApplication(self):\n        app = self\n        while True:\n            try:\n                app = app.AXParent\n            except _a11y.ErrorUnsupported:\n                break\n        return app", "response": "Get the base application UIElement."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _menuItem(self, menuitem, *args):\n        self._activate()\n        for item in args:\n            # If the item has an AXMenu as a child, navigate into it.\n            # This seems like a silly abstraction added by apple's a11y api.\n            if menuitem.AXChildren[0].AXRole == 'AXMenu':\n                menuitem = menuitem.AXChildren[0]\n            # Find AXMenuBarItems and AXMenuItems using a handy wildcard\n            role = 'AXMenu*Item'\n            try:\n                menuitem = menuitem.AXChildren[int(item)]\n            except ValueError:\n                menuitem = menuitem.findFirst(AXRole='AXMenu*Item',\n                                              AXTitle=item)\n        return menuitem", "response": "Return the specified menu item."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _activate(self):\n        ra = AppKit.NSRunningApplication\n        app = ra.runningApplicationWithProcessIdentifier_(\n            self._getPid())\n        # NSApplicationActivateAllWindows | NSApplicationActivateIgnoringOtherApps\n        # == 3 - PyObjC in 10.6 does not expose these constants though so I have\n        # to use the int instead of the symbolic names\n        app.activateWithOptions_(3)", "response": "Activate the application ( bringing menus and windows forward."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _getBundleId(self):\n        ra = AppKit.NSRunningApplication\n        app = ra.runningApplicationWithProcessIdentifier_(\n            self._getPid())\n        return app.bundleIdentifier()", "response": "Return the bundle ID of the application."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef menuItem(self, *args):\n        menuitem = self._getApplication().AXMenuBar\n        return self._menuItem(menuitem, *args)", "response": "Return the specified menu item."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the specified item in a pop up menu.", "response": "def popUpItem(self, *args):\n        \"\"\"Return the specified item in a pop up menu.\"\"\"\n        self.Press()\n        time.sleep(.5)\n        return self._menuItem(self, *args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndragging the left mouse button without modifiers pressed. Parameters: coordinates to click on screen (tuple (x, y)) dest coordinates to drag to (tuple (x, y)) interval to send event of btn down, drag and up Returns: None", "response": "def dragMouseButtonLeft(self, coord, dest_coord, interval=0.5):\n        \"\"\"Drag the left mouse button without modifiers pressed.\n\n        Parameters: coordinates to click on screen (tuple (x, y))\n                    dest coordinates to drag to (tuple (x, y))\n                    interval to send event of btn down, drag and up\n        Returns: None\n        \"\"\"\n\n        modFlags = 0\n        self._queueMouseButton(coord, Quartz.kCGMouseButtonLeft, modFlags,\n                               dest_coord=dest_coord)\n        self._postQueuedEvents(interval=interval)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef doubleClickDragMouseButtonLeft(self, coord, dest_coord, interval=0.5):\n        modFlags = 0\n        self._queueMouseButton(coord, Quartz.kCGMouseButtonLeft, modFlags,\n                               dest_coord=dest_coord)\n        self._queueMouseButton(coord, Quartz.kCGMouseButtonLeft, modFlags,\n                               dest_coord=dest_coord,\n                               clickCount=2)\n        self._postQueuedEvents(interval=interval)", "response": "Double - click and drag the left mouse button without modifiers."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clickMouseButtonLeft(self, coord, interval=None):\n\n        modFlags = 0\n        self._queueMouseButton(coord, Quartz.kCGMouseButtonLeft, modFlags)\n        if interval:\n            self._postQueuedEvents(interval=interval)\n        else:\n            self._postQueuedEvents()", "response": "Click the left mouse button without modifiers pressed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clickMouseButtonRight(self, coord):\n        modFlags = 0\n        self._queueMouseButton(coord, Quartz.kCGMouseButtonRight, modFlags)\n        self._postQueuedEvents()", "response": "Click the right mouse button without modifiers pressed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clickMouseButtonLeftWithMods(self, coord, modifiers, interval=None):\n        modFlags = self._pressModifiers(modifiers)\n        self._queueMouseButton(coord, Quartz.kCGMouseButtonLeft, modFlags)\n        self._releaseModifiers(modifiers)\n        if interval:\n            self._postQueuedEvents(interval=interval)\n        else:\n            self._postQueuedEvents()", "response": "Click the left mouse button with modifiers pressed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclick the right mouse button with modifiers pressed.", "response": "def clickMouseButtonRightWithMods(self, coord, modifiers):\n        \"\"\"Click the right mouse button with modifiers pressed.\n\n        Parameters: coordinates to click; modifiers (list)\n        Returns: None\n        \"\"\"\n        modFlags = self._pressModifiers(modifiers)\n        self._queueMouseButton(coord, Quartz.kCGMouseButtonRight, modFlags)\n        self._releaseModifiers(modifiers)\n        self._postQueuedEvents()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef leftMouseDragged(self, stopCoord, strCoord=(0, 0), speed=1):\n        self._leftMouseDragged(stopCoord, strCoord, speed)", "response": "Click the left mouse button and drag object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef doubleClickMouse(self, coord):\n        modFlags = 0\n        self._queueMouseButton(coord, Quartz.kCGMouseButtonLeft, modFlags)\n        # This is a kludge:\n        # If directed towards a Fusion VM the clickCount gets ignored and this\n        # will be seen as a single click, so in sequence this will be a double-\n        # click\n        # Otherwise to a host app only this second one will count as a double-\n        # click\n        self._queueMouseButton(coord, Quartz.kCGMouseButtonLeft, modFlags,\n                               clickCount=2)\n        self._postQueuedEvents()", "response": "Double - click primary mouse button."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef doubleMouseButtonLeftWithMods(self, coord, modifiers):\n        modFlags = self._pressModifiers(modifiers)\n        self._queueMouseButton(coord, Quartz.kCGMouseButtonLeft, modFlags)\n        self._queueMouseButton(coord, Quartz.kCGMouseButtonLeft, modFlags,\n                               clickCount=2)\n        self._releaseModifiers(modifiers)\n        self._postQueuedEvents()", "response": "Double mouse button left with modifiers pressed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tripleClickMouse(self, coord):\n        # Note above re: double-clicks applies to triple-clicks\n        modFlags = 0\n        for i in range(2):\n            self._queueMouseButton(coord, Quartz.kCGMouseButtonLeft, modFlags)\n        self._queueMouseButton(coord, Quartz.kCGMouseButtonLeft, modFlags,\n                               clickCount=3)\n        self._postQueuedEvents()", "response": "Triple - click primary mouse button."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef waitForValueToChange(self, timeout=10):\n        # Want to identify that the element whose value changes matches this\n        # object's.  Unique identifiers considered include role and position\n        # This seems to work best if you set the notification at the application\n        # level\n        callback = AXCallbacks.returnElemCallback\n        retelem = None\n        return self.waitFor(timeout, 'AXValueChanged', callback=callback,\n                            args=(retelem,))", "response": "Convenience method to wait for value attribute of given element to\n        change."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef waitForFocusToChange(self, newFocusedElem, timeout=10):\n        return self.waitFor(timeout, 'AXFocusedUIElementChanged',\n                            AXRole=newFocusedElem.AXRole,\n                            AXPosition=newFocusedElem.AXPosition)", "response": "Convenience method to wait for the focused element to change."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _convenienceMatch(self, role, attr, match):\n        kwargs = {}\n        # If the user supplied some text to search for,\n        # supply that in the kwargs\n        if match:\n            kwargs[attr] = match\n        return self.findAll(AXRole=role, **kwargs)", "response": "Method used by role based convenience functions to find a match"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _convenienceMatchR(self, role, attr, match):\n        kwargs = {}\n        # If the user supplied some text to search for,\n        # supply that in the kwargs\n        if match:\n            kwargs[attr] = match\n        return self.findAllR(AXRole=role, **kwargs)", "response": "Method used by role based convenience functions to find a match"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef imagecapture(self, window_name=None, x=0, y=0,\n                     width=None, height=None):\n        \"\"\"\n        Captures screenshot of the whole desktop or given window\n        \n        @param window_name: Window name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param x: x co-ordinate value\n        @type x: int\n        @param y: y co-ordinate value\n        @type y: int\n        @param width: width co-ordinate value\n        @type width: int\n        @param height: height co-ordinate value\n        @type height: int\n\n        @return: screenshot with base64 encoded for the client\n        @rtype: string\n        \"\"\"\n        if x or y or (width and width != -1) or (height and height != -1):\n            raise LdtpServerException(\"Not implemented\")\n        if window_name:\n            handle, name, app = self._get_window_handle(window_name)\n            try:\n                self._grabfocus(handle)\n            except:\n                pass\n            rect = self._getobjectsize(handle)\n            screenshot = CGWindowListCreateImage(NSMakeRect(rect[0],\n                                                            rect[1], rect[2], rect[3]), 1, 0, 0)\n        else:\n            screenshot = CGWindowListCreateImage(CGRectInfinite, 1, 0, 0)\n        image = CIImage.imageWithCGImage_(screenshot)\n        bitmapRep = NSBitmapImageRep.alloc().initWithCIImage_(image)\n        blob = bitmapRep.representationUsingType_properties_(NSPNGFileType, None)\n        tmpFile = tempfile.mktemp('.png', 'ldtpd_')\n        blob.writeToFile_atomically_(tmpFile, False)\n        rv = b64encode(open(tmpFile).read())\n        os.remove(tmpFile)\n        return rv", "response": "Takes a screenshot of the whole desktop or given window\necords x y width height and returns the base64 encoded image for the client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef startlog(filename, overwrite=True):\n\n    if not filename:\n        return 0\n\n    if overwrite:\n        # Create new file, by overwriting existing file\n        _mode = 'w'\n    else:\n        # Append existing file\n        _mode = 'a'\n    global _file_logger\n    # Create logging file handler\n    _file_logger = logging.FileHandler(os.path.expanduser(filename), _mode)\n    # Log 'Levelname: Messages', eg: 'ERROR: Logged message'\n    _formatter = logging.Formatter('%(levelname)-8s: %(message)s')\n    _file_logger.setFormatter(_formatter)\n    logger.addHandler(_file_logger)\n    if _ldtp_debug:\n        # On debug, change the default log level to DEBUG\n        _file_logger.setLevel(logging.DEBUG)\n    else:\n        # else log in case of ERROR level and above\n        _file_logger.setLevel(logging.ERROR)\n\n    return 1", "response": "Start logging on the specified file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove registered callback on window create", "response": "def removecallback(window_name):\n    \"\"\"\n    Remove registered callback on window create\n\n    @param window_name: Window name to look for, either full name,\n    LDTP's name convention, or a Unix glob.\n    @type window_name: string\n\n    @return: 1 if registration was successful, 0 if not.\n    @rtype: integer\n    \"\"\"\n\n    if window_name in _pollEvents._callback:\n        del _pollEvents._callback[window_name]\n    return _remote_removecallback(window_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef callAfter(func, *args, **kwargs):\n    pool = NSAutoreleasePool.alloc().init()\n    obj = PyObjCAppHelperCaller_wrap.alloc().initWithArgs_((func, args, kwargs))\n    obj.callAfter_(None)\n    del obj\n    del pool", "response": "call a function on the main thread"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls a function on the main thread after a delay", "response": "def callLater(delay, func, *args, **kwargs):\n    \"\"\"call a function on the main thread after a delay (async)\"\"\"\n    pool = NSAutoreleasePool.alloc().init()\n    obj = PyObjCAppHelperCaller_wrap.alloc().initWithArgs_((func, args, kwargs))\n    obj.callLater_(delay)\n    del obj\n    del pool"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstops the current event loop if possible.", "response": "def stopEventLoop():\n    \"\"\"\n    Stop the current event loop if possible\n    returns True if it expects that it was successful, False otherwise\n    \"\"\"\n    stopper = PyObjCAppHelperRunLoopStopper_wrap.currentRunLoopStopper()\n    if stopper is None:\n        if NSApp() is not None:\n            NSApp().terminate_(None)\n            return True\n        return False\n    NSTimer.scheduledTimerWithTimeInterval_target_selector_userInfo_repeats_(\n        0.0,\n        stopper,\n        'performStop:',\n        None,\n        False)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun the event loop.", "response": "def runEventLoop(argv=None, unexpectedErrorAlert=None, installInterrupt=None, pdb=None, main=NSApplicationMain):\n    \"\"\"Run the event loop, ask the user if we should continue if an\n    exception is caught. Use this function instead of NSApplicationMain().\n    \"\"\"\n    if argv is None:\n        argv = sys.argv\n\n    if pdb is None:\n        pdb = 'USE_PDB' in os.environ\n\n    if pdb:\n        from PyObjCTools import Debugging\n        Debugging.installVerboseExceptionHandler()\n        # bring it to the front, starting from terminal\n        # often won't\n        activator = PyObjCAppHelperApplicationActivator_wrap.alloc().init()\n        NSNotificationCenter.defaultCenter().addObserver_selector_name_object_(\n            activator,\n            'activateNow:',\n            NSApplicationDidFinishLaunchingNotification,\n            None,\n        )\n    else:\n        Debugging = None\n\n    if installInterrupt is None and pdb:\n        installInterrupt = True\n\n    if unexpectedErrorAlert is None:\n        unexpectedErrorAlert = unexpectedErrorAlertPdb\n\n    runLoop = NSRunLoop.currentRunLoop()\n    stopper = PyObjCAppHelperRunLoopStopper_wrap.alloc().init()\n    PyObjCAppHelperRunLoopStopper_wrap.addRunLoopStopper_toRunLoop_(stopper, runLoop)\n\n    firstRun = NSApp() is None\n    try:\n\n        while stopper.shouldRun():\n            try:\n                if firstRun:\n                    firstRun = False\n                    if installInterrupt:\n                        installMachInterrupt()\n                    main(argv)\n                else:\n                    NSApp().run()\n            except RAISETHESE:\n                traceback.print_exc()\n                break\n            except:\n                exctype, e, tb = sys.exc_info()\n                objc_exception = False\n                if isinstance(e, objc.error):\n                    NSLog(\"%@\", str(e))\n                elif not unexpectedErrorAlert():\n                    NSLog(\"%@\", \"An exception has occured:\")\n                    traceback.print_exc()\n                    sys.exit(0)\n                else:\n                    NSLog(\"%@\", \"An exception has occured:\")\n                    traceback.print_exc()\n            else:\n                break\n\n    finally:\n        if Debugging is not None:\n            Debugging.removeExceptionHandler()\n        PyObjCAppHelperRunLoopStopper_wrap.removeRunLoopStopperFromRunLoop_(runLoop)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef keypress(self, data):\n        try:\n            window = self._get_front_most_window()\n        except (IndexError,):\n            window = self._get_any_window()\n        key_press_action = KeyPressAction(window, data)\n        return 1", "response": "Keypress key. NOTE : keyrelease should be called\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreleases key. NOTE: keypress should be called before this @param data: data to type. @type data: string @return: 1 on success. @rtype: integer", "response": "def keyrelease(self, data):\n        \"\"\"\n        Release key. NOTE: keypress should be called before this\n\n        @param data: data to type.\n        @type data: string\n\n        @return: 1 on success.\n        @rtype: integer\n        \"\"\"\n        try:\n            window = self._get_front_most_window()\n        except (IndexError,):\n            window = self._get_any_window()\n        key_release_action = KeyReleaseAction(window, data)\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enterstring(self, window_name, object_name='', data=''):\n        if not object_name and not data:\n            return self.generatekeyevent(window_name)\n        else:\n            object_handle = self._get_object_handle(window_name, object_name)\n            if not object_handle.AXEnabled:\n                raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n            self._grabfocus(object_handle)\n            object_handle.sendKeys(data)\n            return 1", "response": "Type string sequence.\n        \n        @param window_name: Window name to focus on, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to focus on, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n        @param data: data to type.\n        @type data: string\n\n        @return: 1 on success.\n        @rtype: integer"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gettextvalue(self, window_name, object_name, startPosition=0, endPosition=0):\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        return object_handle.AXValue", "response": "Get the text value of a specific object in a given window."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inserttext(self, window_name, object_name, position, data):\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        existing_data = object_handle.AXValue\n        size = len(existing_data)\n        if position < 0:\n            position = 0\n        if position > size:\n            position = size\n        object_handle.AXValue = existing_data[:position] + data + \\\n                                existing_data[position:]\n        return 1", "response": "Insert string sequence in given position."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nverifies partial text for a given object name and window name.", "response": "def verifypartialmatch(self, window_name, object_name, partial_text):\n        \"\"\"\n        Verify partial text\n        \n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n        @param partial_text: Partial text to match\n        @type object_name: string\n\n        @return: 1 on success.\n        @rtype: integer\n        \"\"\"\n        try:\n            if re.search(fnmatch.translate(partial_text),\n                         self.gettextvalue(window_name,\n                                           object_name)):\n                return 1\n        except:\n            pass\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef verifysettext(self, window_name, object_name, text):\n        try:\n            return int(re.match(fnmatch.translate(text),\n                                self.gettextvalue(window_name,\n                                                  object_name)))\n        except:\n            return 0", "response": "Verify that the text is set correctly with the object name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nverifies if text state of an object is enabled or not.", "response": "def istextstateenabled(self, window_name, object_name):\n        \"\"\"\n        Verifies text state enabled or not\n        \n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n\n        @return: 1 on success 0 on failure.\n        @rtype: integer\n        \"\"\"\n        try:\n            object_handle = self._get_object_handle(window_name, object_name)\n            if object_handle.AXEnabled:\n                return 1\n        except LdtpServerException:\n            pass\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getcharcount(self, window_name, object_name):\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        return object_handle.AXNumberOfCharacters", "response": "Get the number of characters in an object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef appendtext(self, window_name, object_name, data):\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        object_handle.AXValue += data\n        return 1", "response": "Append string sequence.\n        \n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n        @param data: data to type.\n        @type data: string\n\n        @return: 1 on success.\n        @rtype: integer"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget cursor position of the object in the specified window.", "response": "def getcursorposition(self, window_name, object_name):\n        \"\"\"\n        Get cursor position\n        \n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n\n        @return: Cursor position on success.\n        @rtype: integer\n        \"\"\"\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        return object_handle.AXSelectedTextRange.loc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the cursor position of the object in the specified window.", "response": "def setcursorposition(self, window_name, object_name, cursor_position):\n        \"\"\"\n        Set cursor position\n        \n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n        @param cursor_position: Cursor position to be set\n        @type object_name: string\n\n        @return: 1 on success.\n        @rtype: integer\n        \"\"\"\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        object_handle.AXSelectedTextRange.loc = cursor_position\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cuttext(self, window_name, object_name, start_position, end_position=-1):\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        size = object_handle.AXNumberOfCharacters\n        if end_position == -1 or end_position > size:\n            end_position = size\n        if start_position < 0:\n            start_position = 0\n        data = object_handle.AXValue\n        Clipboard.copy(data[start_position:end_position])\n        object_handle.AXValue = data[:start_position] + data[end_position:]\n        return 1", "response": "Cut text from start position to end position\n Arcs."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef deletetext(self, window_name, object_name, start_position, end_position=-1):\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        size = object_handle.AXNumberOfCharacters\n        if end_position == -1 or end_position > size:\n            end_position = size\n        if start_position < 0:\n            start_position = 0\n        data = object_handle.AXValue\n        object_handle.AXValue = data[:start_position] + data[end_position:]\n        return 1", "response": "Delete all the text from start_position to end_position."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npasting text from start position to end position @param window_name: Window name to type in, either full name, LDTP's name convention, or a Unix glob. @type window_name: string @param object_name: Object name to type in, either full name, LDTP's name convention, or a Unix glob. @type object_name: string @param position: Position to paste the text, default 0 @type object_name: integer @return: 1 on success. @rtype: integer", "response": "def pastetext(self, window_name, object_name, position=0):\n        \"\"\"\n        paste text from start position to end position\n        \n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n        @param position: Position to paste the text, default 0\n        @type object_name: integer\n\n        @return: 1 on success.\n        @rtype: integer\n        \"\"\"\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        size = object_handle.AXNumberOfCharacters\n        if position > size:\n            position = size\n        if position < 0:\n            position = 0\n        clipboard = Clipboard.paste()\n        data = object_handle.AXValue\n        object_handle.AXValue = data[:position] + clipboard + data[position:]\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main(port=4118, parentpid=None):\n    if \"LDTP_DEBUG\" in os.environ:\n        _ldtp_debug = True\n    else:\n        _ldtp_debug = False\n    _ldtp_debug_file = os.environ.get('LDTP_DEBUG_FILE', None)\n    if _ldtp_debug:\n        print(\"Parent PID: {}\".format(int(parentpid)))\n    if _ldtp_debug_file:\n        with open(unicode(_ldtp_debug_file), \"a\") as fp:\n            fp.write(\"Parent PID: {}\".format(int(parentpid)))\n    server = LDTPServer(('', port), allow_none=True, logRequests=_ldtp_debug,\n                        requestHandler=RequestHandler)\n    server.register_introspection_functions()\n    server.register_multicall_functions()\n    ldtp_inst = core.Core()\n    server.register_instance(ldtp_inst)\n    if parentpid:\n        thread.start_new_thread(notifyclient, (parentpid,))\n    try:\n        server.serve_forever()\n    except KeyboardInterrupt:\n        pass\n    except:\n        if _ldtp_debug:\n            print(traceback.format_exc())\n        if _ldtp_debug_file:\n            with open(_ldtp_debug_file, \"a\") as fp:\n                fp.write(traceback.format_exc())", "response": "Entry point. Parse command line options and start up a server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlog the message in the root logger with the log level level.", "response": "def log(self, message, level=logging.DEBUG):\n        \"\"\"\n        Logs the message in the root logger with the log level\n        @param message: Message to be logged\n        @type message: string\n        @param level: Log level, defaul DEBUG\n        @type level: integer\n    \n        @return: 1 on success and 0 on error\n        @rtype: integer\n        \"\"\"\n        if _ldtp_debug:\n            print(message)\n        self.logger.log(level, str(message))\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstop logging. @return: 1 on success and 0 on error @rtype: integer", "response": "def stoplog(self):\n        \"\"\" Stop logging.\n    \n        @return: 1 on success and 0 on error\n        @rtype: integer\n        \"\"\"\n        if self._file_logger:\n            self.logger.removeHandler(_file_logger)\n            self._file_logger = None\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncapturing the entire desktop or given window.", "response": "def imagecapture(self, window_name=None, out_file=None, x=0, y=0,\n                     width=None, height=None):\n        \"\"\"\n        Captures screenshot of the whole desktop or given window\n\n        @param window_name: Window name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param x: x co-ordinate value\n        @type x: integer\n        @param y: y co-ordinate value\n        @type y: integer\n        @param width: width co-ordinate value\n        @type width: integer\n        @param height: height co-ordinate value\n        @type height: integer\n\n        @return: screenshot filename\n        @rtype: string\n        \"\"\"\n        if not out_file:\n            out_file = tempfile.mktemp('.png', 'ldtp_')\n        else:\n            out_file = os.path.expanduser(out_file)\n\n        ### Windows compatibility\n        if _ldtp_windows_env:\n            if width == None:\n                width = -1\n            if height == None:\n                height = -1\n            if window_name == None:\n                window_name = ''\n        ### Windows compatibility - End\n        data = self._remote_imagecapture(window_name, x, y, width, height)\n        f = open(out_file, 'wb')\n        f.write(b64decode(data))\n        f.close()\n        return out_file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall by the LDTP when a new window is created.", "response": "def onwindowcreate(self, window_name, fn_name, *args):\n        \"\"\"\n        On window create, call the function with given arguments\n\n        @param window_name: Window name to look for, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param fn_name: Callback function\n        @type fn_name: function\n        @param *args: arguments to be passed to the callback function\n        @type *args: var args\n\n        @return: 1 if registration was successful, 0 if not.\n        @rtype: integer\n        \"\"\"\n        self._pollEvents._callback[window_name] = [\"onwindowcreate\", fn_name, args]\n        return self._remote_onwindowcreate(window_name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef registerevent(self, event_name, fn_name, *args):\n        if not isinstance(event_name, str):\n            raise ValueError(\"event_name should be string\")\n        self._pollEvents._callback[event_name] = [event_name, fn_name, args]\n        return self._remote_registerevent(event_name)", "response": "Register a new event in the poll events list."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deregisterevent(self, event_name):\n\n        if event_name in self._pollEvents._callback:\n            del self._pollEvents._callback[event_name]\n        return self._remote_deregisterevent(event_name)", "response": "Removes callback of registered event with given event name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering a keystroke event in the poll events list.", "response": "def registerkbevent(self, keys, modifiers, fn_name, *args):\n        \"\"\"\n        Register keystroke events\n\n        @param keys: key to listen\n        @type keys: string\n        @param modifiers: control / alt combination using gtk MODIFIERS\n        @type modifiers: int\n        @param fn_name: Callback function\n        @type fn_name: function\n        @param *args: arguments to be passed to the callback function\n        @type *args: var args\n\n        @return: 1 if registration was successful, 0 if not.\n        @rtype: integer\n        \"\"\"\n        event_name = \"kbevent%s%s\" % (keys, modifiers)\n        self._pollEvents._callback[event_name] = [event_name, fn_name, args]\n        return self._remote_registerkbevent(keys, modifiers)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deregisterkbevent(self, keys, modifiers):\n\n        event_name = \"kbevent%s%s\" % (keys, modifiers)\n        if event_name in _pollEvents._callback:\n            del _pollEvents._callback[event_name]\n        return self._remote_deregisterkbevent(keys, modifiers)", "response": "Removes a callback from the event loop that was registered with the given keys and modifiers."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef windowuptime(self, window_name):\n        tmp_time = self._remote_windowuptime(window_name)\n        if tmp_time:\n            tmp_time = tmp_time.split('-')\n            start_time = tmp_time[0].split(' ')\n            end_time = tmp_time[1].split(' ')\n            _start_time = datetime.datetime(int(start_time[0]), int(start_time[1]),\n                                            int(start_time[2]), int(start_time[3]),\n                                            int(start_time[4]), int(start_time[5]))\n            _end_time = datetime.datetime(int(end_time[0]), int(end_time[1]),\n                                          int(end_time[2]), int(end_time[3]),\n                                          int(end_time[4]), int(end_time[5]))\n            return _start_time, _end_time\n        return None", "response": "Get the uptime of a given window."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef verifyscrollbarvertical(self, window_name, object_name):\n        try:\n            object_handle = self._get_object_handle(window_name, object_name)\n            if object_handle.AXOrientation == \"AXVerticalOrientation\":\n                return 1\n        except:\n            pass\n        return 0", "response": "Verify scrollbar is vertical"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nverify scrollbar is horizontal.", "response": "def verifyscrollbarhorizontal(self, window_name, object_name):\n        \"\"\"\n        Verify scrollbar is horizontal\n\n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type object_name: string\n\n        @return: 1 on success.\n        @rtype: integer\n        \"\"\"\n        try:\n            object_handle = self._get_object_handle(window_name, object_name)\n            if object_handle.AXOrientation == \"AXHorizontalOrientation\":\n                return 1\n        except:\n            pass\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setmax(self, window_name, object_name):\n        object_handle = self._get_object_handle(window_name, object_name)\n        object_handle.AXValue = 1\n        return 1", "response": "Set the max value of the object name in the specified window."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the minimum value of the object name in the specified window.", "response": "def setmin(self, window_name, object_name):\n        \"\"\"\n        Set min value\n\n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type object_name: string\n\n        @return: 1 on success.\n        @rtype: integer\n        \"\"\"\n        object_handle = self._get_object_handle(window_name, object_name)\n        object_handle.AXValue = 0\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scrollup(self, window_name, object_name):\n        if not self.verifyscrollbarvertical(window_name, object_name):\n            raise LdtpServerException('Object not vertical scrollbar')\n        return self.setmin(window_name, object_name)", "response": "Scroll up the object in the specified window."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nscroll down the object in the specified window.", "response": "def scrolldown(self, window_name, object_name):\n        \"\"\"\n        Scroll down\n\n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type object_name: string\n\n        @return: 1 on success.\n        @rtype: integer\n        \"\"\"\n        if not self.verifyscrollbarvertical(window_name, object_name):\n            raise LdtpServerException('Object not vertical scrollbar')\n        return self.setmax(window_name, object_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef scrollleft(self, window_name, object_name):\n        if not self.verifyscrollbarhorizontal(window_name, object_name):\n            raise LdtpServerException('Object not horizontal scrollbar')\n        return self.setmin(window_name, object_name)", "response": "Scroll left operation for the given object in the specified window."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef scrollright(self, window_name, object_name):\n        if not self.verifyscrollbarhorizontal(window_name, object_name):\n            raise LdtpServerException('Object not horizontal scrollbar')\n        return self.setmax(window_name, object_name)", "response": "Scrolls the right of an object in the specified window."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npress scrollbar up with number of iterations to perform on slider increase", "response": "def oneup(self, window_name, object_name, iterations):\n        \"\"\"\n        Press scrollbar up with number of iterations\n\n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type object_name: string\n        @param interations: iterations to perform on slider increase\n        @type iterations: integer\n\n        @return: 1 on success.\n        @rtype: integer\n        \"\"\"\n        if not self.verifyscrollbarvertical(window_name, object_name):\n            raise LdtpServerException('Object not vertical scrollbar')\n        object_handle = self._get_object_handle(window_name, object_name)\n        i = 0\n        minValue = 1.0 / 8\n        flag = False\n        while i < iterations:\n            if object_handle.AXValue <= 0:\n                raise LdtpServerException('Minimum limit reached')\n            object_handle.AXValue -= minValue\n            time.sleep(1.0 / 100)\n            flag = True\n            i += 1\n        if flag:\n            return 1\n        else:\n            raise LdtpServerException('Unable to decrease scrollbar')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npresses scrollbar right with number of iterations", "response": "def oneright(self, window_name, object_name, iterations):\n        \"\"\"\n        Press scrollbar right with number of iterations\n\n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type object_name: string\n        @param interations: iterations to perform on slider increase\n        @type iterations: integer\n\n        @return: 1 on success.\n        @rtype: integer\n        \"\"\"\n        if not self.verifyscrollbarhorizontal(window_name, object_name):\n            raise LdtpServerException('Object not horizontal scrollbar')\n        object_handle = self._get_object_handle(window_name, object_name)\n        i = 0\n        maxValue = 1.0 / 8\n        flag = False\n        while i < iterations:\n            if object_handle.AXValue >= 1:\n                raise LdtpServerException('Maximum limit reached')\n            object_handle.AXValue += maxValue\n            time.sleep(1.0 / 100)\n            flag = True\n            i += 1\n        if flag:\n            return 1\n        else:\n            raise LdtpServerException('Unable to increase scrollbar')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npressing scrollbar left with number of iterations @param window_name: Window name to type in, either full name, LDTP's name convention, or a Unix glob. @type window_name: string @param object_name: Object name to type in, either full name, LDTP's name convention, or a Unix glob. @type object_name: string @param interations: iterations to perform on slider increase @type iterations: integer @return: 1 on success. @rtype: integer", "response": "def oneleft(self, window_name, object_name, iterations):\n        \"\"\"\n        Press scrollbar left with number of iterations\n\n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type object_name: string\n        @param interations: iterations to perform on slider increase\n        @type iterations: integer\n\n        @return: 1 on success.\n        @rtype: integer\n        \"\"\"\n        if not self.verifyscrollbarhorizontal(window_name, object_name):\n            raise LdtpServerException('Object not horizontal scrollbar')\n        object_handle = self._get_object_handle(window_name, object_name)\n        i = 0\n        minValue = 1.0 / 8\n        flag = False\n        while i < iterations:\n            if object_handle.AXValue <= 0:\n                raise LdtpServerException('Minimum limit reached')\n            object_handle.AXValue -= minValue\n            time.sleep(1.0 / 100)\n            flag = True\n            i += 1\n        if flag:\n            return 1\n        else:\n            raise LdtpServerException('Unable to decrease scrollbar')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef selecttabindex(self, window_name, object_name, tab_index):\n        children = self._get_tab_children(window_name, object_name)\n        length = len(children)\n        if tab_index < 0 or tab_index > length:\n            raise LdtpServerException(u\"Invalid tab index %s\" % tab_index)\n        tab_handle = children[tab_index]\n        if not tab_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        tab_handle.Press()\n        return 1", "response": "Select tab based on index."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef verifytabname(self, window_name, object_name, tab_name):\n        try:\n            tab_handle = self._get_tab_handle(window_name, object_name, tab_name)\n            if tab_handle.AXValue:\n                return 1\n        except LdtpServerException:\n            pass\n        return 0", "response": "Verify the object name of a specific object in a given window."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the number of children of a given object in a given window.", "response": "def gettabcount(self, window_name, object_name):\n        \"\"\"\n        Get tab count.\n        \n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n\n        @return: tab count on success.\n        @rtype: integer\n        \"\"\"\n        children = self._get_tab_children(window_name, object_name)\n        return len(children)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the tab name of a given object.", "response": "def gettabname(self, window_name, object_name, tab_index):\n        \"\"\"\n        Get tab name\n        \n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n        @param tab_index: Index of tab (zero based index)\n        @type object_name: int\n\n        @return: text on success.\n        @rtype: string\n        \"\"\"\n        children = self._get_tab_children(window_name, object_name)\n        length = len(children)\n        if tab_index < 0 or tab_index > length:\n            raise LdtpServerException(u\"Invalid tab index %s\" % tab_index)\n        tab_handle = children[tab_index]\n        if not tab_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        return tab_handle.AXTitle"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generatemouseevent(self, x, y, eventType=\"b1c\",\n                           drag_button_override='drag_default_button'):\n        \"\"\"\n        Generate mouse event on x, y co-ordinates.\n        \n        @param x: X co-ordinate\n        @type x: int\n        @param y: Y co-ordinate\n        @type y: int\n        @param eventType: Mouse click type\n        @type eventType: str\n        @param drag_button_override: Any drag_xxx value\n                Only relevant for movements, i.e. |type| = \"abs\" or \"rel\"\n                Quartz is not fully compatible with windows, so for drags\n                the drag button must be explicitly defined. generatemouseevent\n                will remember the last button pressed by default, and drag\n                that button, use this argument to override that.\n        @type drag_button_override: str\n\n        @return: 1 on success.\n        @rtype: integer\n        \"\"\"\n        if drag_button_override not in mouse_click_override:\n            raise ValueError('Unsupported drag_button_override type: %s' % \\\n                             drag_button_override)\n        global drag_button_remembered\n        point = (x, y)\n        button = centre  # Only matters for \"other\" buttons\n        click_type = None\n        if eventType == \"abs\" or eventType == \"rel\":\n            if drag_button_override is not 'drag_default_button':\n                events = [mouse_click_override[drag_button_override]]\n            elif drag_button_remembered:\n                events = [drag_button_remembered]\n            else:\n                events = [move]\n            if eventType == \"rel\":\n                point = CGEventGetLocation(CGEventCreate(None))\n                point.x += x\n                point.y += y\n        elif eventType == \"b1p\":\n            events = [press_left]\n            drag_button_remembered = drag_left\n        elif eventType == \"b1r\":\n            events = [release_left]\n            drag_button_remembered = None\n        elif eventType == \"b1c\":\n            events = [press_left, release_left]\n        elif eventType == \"b1d\":\n            events = [press_left, release_left]\n            click_type = double_click\n        elif eventType == \"b2p\":\n            events = [press_other]\n            drag_button_remembered = drag_other\n        elif eventType == \"b2r\":\n            events = [release_other]\n            drag_button_remembered = None\n        elif eventType == \"b2c\":\n            events = [press_other, release_other]\n        elif eventType == \"b2d\":\n            events = [press_other, release_other]\n            click_type = double_click\n        elif eventType == \"b3p\":\n            events = [press_right]\n            drag_button_remembered = drag_right\n        elif eventType == \"b3r\":\n            events = [release_right]\n            drag_button_remembered = None\n        elif eventType == \"b3c\":\n            events = [press_right, release_right]\n        elif eventType == \"b3d\":\n            events = [press_right, release_right]\n            click_type = double_click\n        else:\n            raise LdtpServerException(u\"Mouse event '%s' not implemented\" % eventType)\n\n        for event in events:\n            CG_event = CGEventCreateMouseEvent(None, event, point, button)\n            if click_type:\n                CGEventSetIntegerValueField(\n                    CG_event, kCGMouseEventClickState, click_type)\n            CGEventPost(kCGHIDEventTap, CG_event)\n            # Give the event time to happen\n            time.sleep(0.01)\n        return 1", "response": "Generate mouse event on x y."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef doubleclick(self, window_name, object_name):\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        self._grabfocus(object_handle)\n        x, y, width, height = self._getobjectsize(object_handle)\n        window = self._get_front_most_window()\n        # Mouse double click on the object\n        # object_handle.doubleClick()\n        window.doubleClickMouse((x + width / 2, y + height / 2))\n        return 1", "response": "Double click on the object with the given name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef selectitem(self, window_name, object_name, item_name):\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        self._grabfocus(object_handle.AXWindow)\n        try:\n            object_handle.Press()\n        except AttributeError:\n            # AXPress doesn't work with Instruments\n            # So did the following work around\n            x, y, width, height = self._getobjectsize(object_handle)\n            # Mouse left click on the object\n            # Note: x + width/2, y + height / 2 doesn't work\n            self.generatemouseevent(x + 5, y + 5, \"b1c\")\n            self.wait(5)\n            handle = self._get_sub_menu_handle(object_handle, item_name)\n            x, y, width, height = self._getobjectsize(handle)\n            # on OSX 10.7 default \"b1c\" doesn't work\n            # so using \"b1d\", verified with Fusion test, this works\n            self.generatemouseevent(x + 5, y + 5, \"b1d\")\n            return 1\n        # Required for menuitem to appear in accessibility list\n        self.wait(1)\n        menu_list = re.split(\";\", item_name)\n        try:\n            menu_handle = self._internal_menu_handler(object_handle, menu_list,\n                                                      True)\n            # Required for menuitem to appear in accessibility list\n            self.wait(1)\n            if not menu_handle.AXEnabled:\n                raise LdtpServerException(u\"Object %s state disabled\" % \\\n                                          menu_list[-1])\n            menu_handle.Press()\n        except LdtpServerException:\n            object_handle.activate()\n            object_handle.sendKey(AXKeyCodeConstants.ESCAPE)\n            raise\n        return 1", "response": "Select a specific item in a combo box or layered pane."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nselecting combo box item based on index.", "response": "def selectindex(self, window_name, object_name, item_index):\n        \"\"\"\n        Select combo box item / layered pane based on index\n        \n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n        @param item_index: Item index to select\n        @type object_name: integer\n\n        @return: 1 on success.\n        @rtype: integer\n        \"\"\"\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        self._grabfocus(object_handle.AXWindow)\n        try:\n            object_handle.Press()\n        except AttributeError:\n            # AXPress doesn't work with Instruments\n            # So did the following work around\n            x, y, width, height = self._getobjectsize(object_handle)\n            # Mouse left click on the object\n            # Note: x + width/2, y + height / 2 doesn't work\n            self.generatemouseevent(x + 5, y + 5, \"b1c\")\n        # Required for menuitem to appear in accessibility list\n        self.wait(2)\n        if not object_handle.AXChildren:\n            raise LdtpServerException(u\"Unable to find menu\")\n        # Get AXMenu\n        children = object_handle.AXChildren[0]\n        if not children:\n            raise LdtpServerException(u\"Unable to find menu\")\n        children = children.AXChildren\n        tmp_children = []\n        for child in children:\n            role, label = self._ldtpize_accessible(child)\n            # Don't add empty label\n            # Menu separator have empty label's\n            if label:\n                tmp_children.append(child)\n        children = tmp_children\n        length = len(children)\n        try:\n            if item_index < 0 or item_index > length:\n                raise LdtpServerException(u\"Invalid item index %d\" % item_index)\n            menu_handle = children[item_index]\n            if not menu_handle.AXEnabled:\n                raise LdtpServerException(u\"Object %s state disabled\" % menu_list[-1])\n            self._grabfocus(menu_handle)\n            x, y, width, height = self._getobjectsize(menu_handle)\n            # on OSX 10.7 default \"b1c\" doesn't work\n            # so using \"b1d\", verified with Fusion test, this works\n            window = object_handle.AXWindow\n            # For some reason,\n            # self.generatemouseevent(x + 5, y + 5, \"b1d\")\n            # doesn't work with Fusion settings\n            # Advanced window, so work around with this\n            # ldtp.selectindex('*Advanced', 'Automatic', 1)\n            \"\"\"\n            Traceback (most recent call last):\n               File \"build/bdist.macosx-10.8-intel/egg/atomac/ldtpd/utils.py\", line 178, in _dispatch\n                  return getattr(self, method)(*args)\n               File \"build/bdist.macosx-10.8-intel/egg/atomac/ldtpd/combo_box.py\", line 146, in selectindex\n                  self.generatemouseevent(x + 5, y + 5, \"b1d\")\n               File \"build/bdist.macosx-10.8-intel/egg/atomac/ldtpd/mouse.py\", line 97, in generatemouseevent\n                  window=self._get_front_most_window()\n               File \"build/bdist.macosx-10.8-intel/egg/atomac/ldtpd/utils.py\", line 185, in _get_front_most_window\n                  front_app=atomac.NativeUIElement.getFrontmostApp()\n               File \"build/bdist.macosx-10.8-intel/egg/atomac/AXClasses.py\", line 114, in getFrontmostApp\n                  raise ValueError('No GUI application found.')\n            ValueError: No GUI application found.\n            \"\"\"\n            window.doubleClickMouse((x + 5, y + 5))\n            # If menuitem already pressed, set child to None\n            # So, it doesn't click back in combobox in finally block\n            child = None\n        finally:\n            if child:\n                child.Cancel()\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget all menu items from a specific object.", "response": "def getallitem(self, window_name, object_name):\n        \"\"\"\n        Get all combo box item\n\n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n\n        @return: list of string on success.\n        @rtype: list\n        \"\"\"\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        object_handle.Press()\n        # Required for menuitem to appear in accessibility list\n        self.wait(1)\n        child = None\n        try:\n            if not object_handle.AXChildren:\n                raise LdtpServerException(u\"Unable to find menu\")\n            # Get AXMenu\n            children = object_handle.AXChildren[0]\n            if not children:\n                raise LdtpServerException(u\"Unable to find menu\")\n            children = children.AXChildren\n            items = []\n            for child in children:\n                label = self._get_title(child)\n                # Don't add empty label\n                # Menu separator have empty label's\n                if label:\n                    items.append(label)\n        finally:\n            if child:\n                # Set it back, by clicking combo box\n                child.Cancel()\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshowing combo box list or menu entry for a given object.", "response": "def showlist(self, window_name, object_name):\n        \"\"\"\n        Show combo box list / menu\n        \n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n\n        @return: 1 on success.\n        @rtype: integer\n        \"\"\"\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        object_handle.Press()\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hidelist(self, window_name, object_name):\n        object_handle = self._get_object_handle(window_name, object_name)\n        object_handle.activate()\n        object_handle.sendKey(AXKeyCodeConstants.ESCAPE)\n        return 1", "response": "Hide combo box list / menu\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nverifying drop down list / menu poped up by object name.", "response": "def verifydropdown(self, window_name, object_name):\n        \"\"\"\n        Verify drop down list / menu poped up\n        \n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n\n        @return: 1 on success 0 on failure.\n        @rtype: integer\n        \"\"\"\n        try:\n            object_handle = self._get_object_handle(window_name, object_name)\n            if not object_handle.AXEnabled or not object_handle.AXChildren:\n                return 0\n            # Get AXMenu\n            children = object_handle.AXChildren[0]\n            if children:\n                return 1\n        except LdtpServerException:\n            pass\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef verifyselect(self, window_name, object_name, item_name):\n        try:\n            object_handle = self._get_object_handle(window_name, object_name)\n            if not object_handle.AXEnabled:\n                return 0\n            role, label = self._ldtpize_accessible(object_handle)\n            title = self._get_title(object_handle)\n            if re.match(item_name, title, re.M | re.U | re.L) or \\\n                    re.match(item_name, label, re.M | re.U | re.L) or \\\n                    re.match(item_name, u\"%u%u\" % (role, label),\n                             re.M | re.U | re.L):\n                return 1\n        except LdtpServerException:\n            pass\n        return 0", "response": "Verify the selected item in combo box."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets current selected combobox value.", "response": "def getcombovalue(self, window_name, object_name):\n        \"\"\"\n        Get current selected combobox value\n        \n        @param window_name: Window name to type in, either full name,\n        LDTP's name convention, or a Unix glob.\n        @type window_name: string\n        @param object_name: Object name to type in, either full name,\n        LDTP's name convention, or a Unix glob. \n        @type object_name: string\n\n        @return: selected item on success, else LdtpExecutionError on failure.\n        @rtype: string\n        \"\"\"\n        object_handle = self._get_object_handle(window_name, object_name)\n        if not object_handle.AXEnabled:\n            raise LdtpServerException(u\"Object %s state disabled\" % object_name)\n        return self._get_title(object_handle)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nauthenticating the gmusicapi Mobileclient instance.", "response": "def login(self, username=None, password=None, android_id=None):\n\t\t\"\"\"Authenticate the gmusicapi Mobileclient instance.\n\n\t\tParameters:\n\t\t\tusername (Optional[str]): Your Google Music username. Will be prompted if not given.\n\n\t\t\tpassword (Optional[str]): Your Google Music password. Will be prompted if not given.\n\n\t\t\tandroid_id (Optional[str]): The 16 hex digits from an Android device ID.\n\t\t\t\tDefault: Use gmusicapi.Mobileclient.FROM_MAC_ADDRESS to create ID from computer's MAC address.\n\n\t\tReturns:\n\t\t\t``True`` on successful login or ``False`` on unsuccessful login.\n\t\t\"\"\"\n\n\t\tcls_name = type(self).__name__\n\n\t\tif username is None:\n\t\t\tusername = input(\"Enter your Google username or email address: \")\n\n\t\tif password is None:\n\t\t\tpassword = getpass.getpass(\"Enter your Google Music password: \")\n\n\t\tif android_id is None:\n\t\t\tandroid_id = Mobileclient.FROM_MAC_ADDRESS\n\n\t\ttry:\n\t\t\tself.api.login(username, password, android_id)\n\t\texcept OSError:\n\t\t\tlogger.exception(\"{} authentication failed.\".format(cls_name))\n\n\t\tif not self.is_authenticated:\n\t\t\tlogger.warning(\"{} authentication failed.\".format(cls_name))\n\n\t\t\treturn False\n\n\t\tlogger.info(\"{} authentication succeeded.\\n\".format(cls_name))\n\n\t\treturn True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a list of Google Music songs from the user s Google Music library.", "response": "def get_google_songs(self, include_filters=None, exclude_filters=None, all_includes=False, all_excludes=False):\n\t\t\"\"\"Create song list from user's Google Music library.\n\n\t\tParameters:\n\t\t\tinclude_filters (list): A list of ``(field, pattern)`` tuples.\n\t\t\t\tFields are any valid Google Music metadata field available to the Mobileclient client.\n\t\t\t\tPatterns are Python regex patterns.\n\t\t\t\tGoogle Music songs are filtered out if the given metadata field values don't match any of the given patterns.\n\n\t\t\texclude_filters (list): A list of ``(field, pattern)`` tuples.\n\t\t\t\tFields are any valid Google Music metadata field available to the Mobileclient client.\n\t\t\t\tPatterns are Python regex patterns.\n\t\t\t\tGoogle Music songs are filtered out if the given metadata field values match any of the given patterns.\n\n\t\t\tall_includes (bool): If ``True``, all include_filters criteria must match to include a song.\n\n\t\t\tall_excludes (bool): If ``True``, all exclude_filters criteria must match to exclude a song.\n\n\t\tReturns:\n\t\t\tA list of Google Music song dicts matching criteria and\n\t\t\ta list of Google Music song dicts filtered out using filter criteria.\n\t\t\"\"\"\n\n\t\tlogger.info(\"Loading Google Music songs...\")\n\n\t\tgoogle_songs = self.api.get_all_songs()\n\n\t\tmatched_songs, filtered_songs = filter_google_songs(\n\t\t\tgoogle_songs, include_filters=include_filters, exclude_filters=exclude_filters,\n\t\t\tall_includes=all_includes, all_excludes=all_excludes\n\t\t)\n\n\t\tlogger.info(\"Filtered {0} Google Music songs\".format(len(filtered_songs)))\n\t\tlogger.info(\"Loaded {0} Google Music songs\".format(len(matched_songs)))\n\n\t\treturn matched_songs, filtered_songs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget playlist information from a user - generated Google Music playlist.", "response": "def get_google_playlist(self, playlist):\n\t\t\"\"\"Get playlist information of a user-generated Google Music playlist.\n\n\t\tParameters:\n\t\t\tplaylist (str): Name or ID of Google Music playlist. Names are case-sensitive.\n\t\t\t\tGoogle allows multiple playlists with the same name.\n\t\t\t\tIf multiple playlists have the same name, the first one encountered is used.\n\n\t\tReturns:\n\t\t\tdict: The playlist dict as returned by Mobileclient.get_all_user_playlist_contents.\n\t\t\"\"\"\n\n\t\tlogger.info(\"Loading playlist {0}\".format(playlist))\n\n\t\tfor google_playlist in self.api.get_all_user_playlist_contents():\n\t\t\tif google_playlist['name'] == playlist or google_playlist['id'] == playlist:\n\t\t\t\treturn google_playlist\n\t\telse:\n\t\t\tlogger.warning(\"Playlist {0} does not exist.\".format(playlist))\n\t\t\treturn {}"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates song list from a user-generated Google Music playlist. Parameters: playlist (str): Name or ID of Google Music playlist. Names are case-sensitive. Google allows multiple playlists with the same name. If multiple playlists have the same name, the first one encountered is used. include_filters (list): A list of ``(field, pattern)`` tuples. Fields are any valid Google Music metadata field available to the Musicmanager client. Patterns are Python regex patterns. Google Music songs are filtered out if the given metadata field values don't match any of the given patterns. exclude_filters (list): A list of ``(field, pattern)`` tuples. Fields are any valid Google Music metadata field available to the Musicmanager client. Patterns are Python regex patterns. Google Music songs are filtered out if the given metadata field values match any of the given patterns. all_includes (bool): If ``True``, all include_filters criteria must match to include a song. all_excludes (bool): If ``True``, all exclude_filters criteria must match to exclude a song. Returns: A list of Google Music song dicts in the playlist matching criteria and a list of Google Music song dicts in the playlist filtered out using filter criteria.", "response": "def get_google_playlist_songs(self, playlist, include_filters=None, exclude_filters=None, all_includes=False, all_excludes=False):\n\t\t\"\"\"Create song list from a user-generated Google Music playlist.\n\n\t\tParameters:\n\t\t\tplaylist (str): Name or ID of Google Music playlist. Names are case-sensitive.\n\t\t\t\tGoogle allows multiple playlists with the same name.\n\t\t\t\tIf multiple playlists have the same name, the first one encountered is used.\n\n\t\t\tinclude_filters (list): A list of ``(field, pattern)`` tuples.\n\t\t\t\tFields are any valid Google Music metadata field available to the Musicmanager client.\n\t\t\t\tPatterns are Python regex patterns.\n\t\t\t\tGoogle Music songs are filtered out if the given metadata field values don't match any of the given patterns.\n\n\t\t\texclude_filters (list): A list of ``(field, pattern)`` tuples.\n\t\t\t\tFields are any valid Google Music metadata field available to the Musicmanager client.\n\t\t\t\tPatterns are Python regex patterns.\n\t\t\t\tGoogle Music songs are filtered out if the given metadata field values match any of the given patterns.\n\n\t\t\tall_includes (bool): If ``True``, all include_filters criteria must match to include a song.\n\n\t\t\tall_excludes (bool): If ``True``, all exclude_filters criteria must match to exclude a song.\n\n\t\tReturns:\n\t\t\tA list of Google Music song dicts in the playlist matching criteria and\n\t\t\ta list of Google Music song dicts in the playlist filtered out using filter criteria.\n\t\t\"\"\"\n\n\t\tlogger.info(\"Loading Google Music playlist songs...\")\n\n\t\tgoogle_playlist = self.get_google_playlist(playlist)\n\n\t\tif not google_playlist:\n\t\t\treturn [], []\n\n\t\tplaylist_song_ids = [track['trackId'] for track in google_playlist['tracks']]\n\t\tplaylist_songs = [song for song in self.api.get_all_songs() if song['id'] in playlist_song_ids]\n\n\t\tmatched_songs, filtered_songs = filter_google_songs(\n\t\t\tplaylist_songs, include_filters=include_filters, exclude_filters=exclude_filters,\n\t\t\tall_includes=all_includes, all_excludes=all_excludes\n\t\t)\n\n\t\tlogger.info(\"Filtered {0} Google playlist songs\".format(len(filtered_songs)))\n\t\tlogger.info(\"Loaded {0} Google playlist songs\".format(len(matched_songs)))\n\n\t\treturn matched_songs, filtered_songs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cast_to_list(position):\n\n\t@wrapt.decorator\n\tdef wrapper(function, instance, args, kwargs):\n\t\tif not isinstance(args[position], list):\n\t\t\targs = list(args)\n\t\t\targs[position] = [args[position]]\n\t\t\targs = tuple(args)\n\n\t\treturn function(*args, **kwargs)\n\n\treturn wrapper", "response": "Cast the positional argument at given position into a list if not already a list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _pybossa_req(method, domain, id=None, payload=None, params={},\n                 headers={'content-type': 'application/json'},\n                 files=None):\n    \"\"\"\n    Send a JSON request.\n\n    Returns True if everything went well, otherwise it returns the status\n    code of the response.\n    \"\"\"\n    url = _opts['endpoint'] + '/api/' + domain\n    if id is not None:\n        url += '/' + str(id)\n    if 'api_key' in _opts:\n        params['api_key'] = _opts['api_key']\n    if method == 'get':\n        r = requests.get(url, params=params)\n    elif method == 'post':\n        if files is None and headers['content-type'] == 'application/json':\n            r = requests.post(url, params=params, headers=headers,\n                              data=json.dumps(payload))\n        else:\n            r = requests.post(url, params=params, files=files, data=payload)\n    elif method == 'put':\n        r = requests.put(url, params=params, headers=headers,\n                         data=json.dumps(payload))\n    elif method == 'delete':\n        r = requests.delete(url, params=params, headers=headers,\n                            data=json.dumps(payload))\n    if r.status_code // 100 == 2:\n        if r.text and r.text != '\"\"':\n            return json.loads(r.text)\n        else:\n            return True\n    else:\n        return json.loads(r.text)", "response": "Send a JSON request to the NCBI server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of registered projects.", "response": "def get_projects(limit=100, offset=0, last_id=None):\n    \"\"\"Return a list of registered projects.\n\n    :param limit: Number of returned items, default 100\n    :type limit: integer\n    :param offset: Offset for the query, default 0\n    :type offset: integer\n    :param last_id: id of the last project, used for pagination. If provided, offset is ignored\n    :type last_id: integer\n    :rtype: list\n    :returns: A list of PYBOSSA Projects\n\n    \"\"\"\n    if last_id is not None:\n        params = dict(limit=limit, last_id=last_id)\n    else:\n        print(OFFSET_WARNING)\n        params = dict(limit=limit, offset=offset)\n    try:\n        res = _pybossa_req('get', 'project',\n                           params=params)\n        if type(res).__name__ == 'list':\n            return [Project(project) for project in res]\n        else:\n            raise TypeError\n    except:  # pragma: no cover\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a project object for the project_id.", "response": "def get_project(project_id):\n    \"\"\"Return a PYBOSSA Project for the project_id.\n\n    :param project_id: PYBOSSA Project ID\n    :type project_id: integer\n    :rtype: PYBOSSA Project\n    :returns: A PYBOSSA Project object\n\n    \"\"\"\n    try:\n        res = _pybossa_req('get', 'project', project_id)\n        if res.get('id'):\n            return Project(res)\n        else:\n            return res\n    except:  # pragma: no cover\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list with matching project arguments.", "response": "def find_project(**kwargs):\n    \"\"\"Return a list with matching project arguments.\n\n    :param kwargs: PYBOSSA Project members\n    :rtype: list\n    :returns: A list of projects that match the kwargs\n\n    \"\"\"\n    try:\n        res = _pybossa_req('get', 'project', params=kwargs)\n        if type(res).__name__ == 'list':\n            return [Project(project) for project in res]\n        else:\n            return res\n    except:  # pragma: no cover\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a project. :param name: PYBOSSA Project Name :type name: string :param short_name: PYBOSSA Project short name or slug :type short_name: string :param description: PYBOSSA Project description :type decription: string :returns: True -- the response status code", "response": "def create_project(name, short_name, description):\n    \"\"\"Create a project.\n\n    :param name: PYBOSSA Project Name\n    :type name: string\n    :param short_name: PYBOSSA Project short name or slug\n    :type short_name: string\n    :param description: PYBOSSA Project description\n    :type decription: string\n    :returns: True -- the response status code\n\n    \"\"\"\n    try:\n        project = dict(name=name, short_name=short_name,\n                       description=description)\n        res = _pybossa_req('post', 'project', payload=project)\n        if res.get('id'):\n            return Project(res)\n        else:\n            return res\n    except:  # pragma: no cover\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_project(project):\n    try:\n        project_id = project.id\n        project = _forbidden_attributes(project)\n        res = _pybossa_req('put', 'project', project_id, payload=project.data)\n        if res.get('id'):\n            return Project(res)\n        else:\n            return res\n    except:  # pragma: no cover\n        raise", "response": "Update a project instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_project(project_id):\n    try:\n        res = _pybossa_req('delete', 'project', project_id)\n        if type(res).__name__ == 'bool':\n            return True\n        else:\n            return res\n    except:  # pragma: no cover\n        raise", "response": "Delete a project from the database"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a list of all available categories.", "response": "def get_categories(limit=20, offset=0, last_id=None):\n    \"\"\"Return a list of registered categories.\n\n    :param limit: Number of returned items, default 20\n    :type limit: integer\n    :param offset: Offset for the query, default 0\n    :type offset: integer\n    :param last_id: id of the last category, used for pagination. If provided, offset is ignored\n    :type last_id: integer\n    :rtype: list\n    :returns: A list of PYBOSSA Categories\n\n    \"\"\"\n    if last_id is not None:\n        params = dict(limit=limit, last_id=last_id)\n    else:\n        params = dict(limit=limit, offset=offset)\n        print(OFFSET_WARNING)\n    try:\n        res = _pybossa_req('get', 'category',\n                           params=params)\n        if type(res).__name__ == 'list':\n            return [Category(category) for category in res]\n        else:\n            raise TypeError\n    except:\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_category(category_id):\n    try:\n        res = _pybossa_req('get', 'category', category_id)\n        if res.get('id'):\n            return Category(res)\n        else:\n            return res\n    except:  # pragma: no cover\n        raise", "response": "Get a PYBOSSA Category for the category_id."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_category(**kwargs):\n    try:\n        res = _pybossa_req('get', 'category', params=kwargs)\n        if type(res).__name__ == 'list':\n            return [Category(category) for category in res]\n        else:\n            return res\n    except:  # pragma: no cover\n        raise", "response": "Return a list with matching Category arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a Category. :param name: PYBOSSA Category Name :type name: string :param description: PYBOSSA Category description :type decription: string :returns: True -- the response status code", "response": "def create_category(name, description):\n    \"\"\"Create a Category.\n\n    :param name: PYBOSSA Category Name\n    :type name: string\n    :param description: PYBOSSA Category description\n    :type decription: string\n    :returns: True -- the response status code\n    \"\"\"\n    try:\n        category = dict(name=name, short_name=name.lower().replace(\" \", \"\"),\n                        description=description)\n        res = _pybossa_req('post', 'category', payload=category)\n        if res.get('id'):\n            return Category(res)\n        else:\n            return res\n    except:  # pragma: no cover\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_category(category):\n    try:\n        res = _pybossa_req('put', 'category',\n                           category.id, payload=category.data)\n        if res.get('id'):\n            return Category(res)\n        else:\n            return res\n    except:  # pragma: no cover\n        raise", "response": "Update a Category instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting a Category with id = category_id. Returns True if the request was successful False otherwise.", "response": "def delete_category(category_id):\n    \"\"\"Delete a Category with id = category_id.\n\n    :param category_id: PYBOSSA Category ID\n    :type category_id: integer\n    :returns: True -- the response status code\n\n    \"\"\"\n    try:\n        res = _pybossa_req('delete', 'category', category_id)\n        if type(res).__name__ == 'bool':\n            return True\n        else:\n            return res\n    except:  # pragma: no cover\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of tasks for a given project ID.", "response": "def get_tasks(project_id, limit=100, offset=0, last_id=None):\n    \"\"\"Return a list of tasks for a given project ID.\n\n    :param project_id: PYBOSSA Project ID\n    :type project_id: integer\n    :param limit: Number of returned items, default 100\n    :type limit: integer\n    :param offset: Offset for the query, default 0\n    :param last_id: id of the last task, used for pagination. If provided, offset is ignored\n    :type last_id: integer\n    :type offset: integer\n    :returns: True -- the response status code\n\n    \"\"\"\n    if last_id is not None:\n        params = dict(limit=limit, last_id=last_id)\n    else:\n        params = dict(limit=limit, offset=offset)\n        print(OFFSET_WARNING)\n    params['project_id'] = project_id\n    try:\n        res = _pybossa_req('get', 'task',\n                           params=params)\n        if type(res).__name__ == 'list':\n            return [Task(task) for task in res]\n        else:\n            return res\n    except:  # pragma: no cover\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_tasks(project_id, **kwargs):\n    try:\n        kwargs['project_id'] = project_id\n        res = _pybossa_req('get', 'task', params=kwargs)\n        if type(res).__name__ == 'list':\n            return [Task(task) for task in res]\n        else:\n            return res\n    except:  # pragma: no cover\n        raise", "response": "Return a list of tasks that match the kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a task for a given project ID.", "response": "def create_task(project_id, info, n_answers=30, priority_0=0, quorum=0):\n    \"\"\"Create a task for a given project ID.\n\n    :param project_id: PYBOSSA Project ID\n    :type project_id: integer\n    :param info: PYBOSSA Project info JSON field\n    :type info: dict\n    :param n_answers: Number of answers or TaskRuns per task, default 30\n    :type n_answers: integer\n    :param priority_0: Value between 0 and 1 indicating priority of task within\n        Project (higher = more important), default 0.0\n    :type priority_0: float\n    :param quorum: Number of times this task should be done by different users,\n        default 0\n    :type quorum: integer\n    :returns: True -- the response status code\n    \"\"\"\n    try:\n        task = dict(\n            project_id=project_id,\n            info=info,\n            calibration=0,\n            priority_0=priority_0,\n            n_answers=n_answers,\n            quorum=quorum\n        )\n        res = _pybossa_req('post', 'task', payload=task)\n        if res.get('id'):\n            return Task(res)\n        else:\n            return res\n    except:  # pragma: no cover\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_task(task):\n    try:\n        task_id = task.id\n        task = _forbidden_attributes(task)\n        res = _pybossa_req('put', 'task', task_id, payload=task.data)\n        if res.get('id'):\n            return Task(res)\n        else:\n            return res\n    except:  # pragma: no cover\n        raise", "response": "Update a task with a given task ID."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a task from the task list.", "response": "def delete_task(task_id):\n    \"\"\"Delete a task for a given task ID.\n\n    :param task: PYBOSSA task\n\n    \"\"\"\n    #: :arg task: A task\n    try:\n        res = _pybossa_req('delete', 'task', task_id)\n        if type(res).__name__ == 'bool':\n            return True\n        else:\n            return res\n    except:  # pragma: no cover\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of task runs for a given project ID.", "response": "def get_taskruns(project_id, limit=100, offset=0, last_id=None):\n    \"\"\"Return a list of task runs for a given project ID.\n\n    :param project_id: PYBOSSA Project ID\n    :type project_id: integer\n    :param limit: Number of returned items, default 100\n    :type limit: integer\n    :param offset: Offset for the query, default 0\n    :type offset: integer\n    :param last_id: id of the last taskrun, used for pagination. If provided, offset is ignored\n    :type last_id: integer\n    :rtype: list\n    :returns: A list of task runs for the given project ID\n\n    \"\"\"\n    if last_id is not None:\n        params = dict(limit=limit, last_id=last_id)\n    else:\n        params = dict(limit=limit, offset=offset)\n        print(OFFSET_WARNING)\n    params['project_id'] = project_id\n    try:\n        res = _pybossa_req('get', 'taskrun',\n                           params=params)\n        if type(res).__name__ == 'list':\n            return [TaskRun(taskrun) for taskrun in res]\n        else:\n            raise TypeError\n    except:\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_taskruns(project_id, **kwargs):\n    try:\n        kwargs['project_id'] = project_id\n        res = _pybossa_req('get', 'taskrun', params=kwargs)\n        if type(res).__name__ == 'list':\n            return [TaskRun(taskrun) for taskrun in res]\n        else:\n            return res\n    except:  # pragma: no cover\n        raise", "response": "Return a list of task runs that match the query members\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting the given taskrun.", "response": "def delete_taskrun(taskrun_id):\n    \"\"\"Delete the given taskrun.\n\n    :param task: PYBOSSA task\n    \"\"\"\n    try:\n        res = _pybossa_req('delete', 'taskrun', taskrun_id)\n        if type(res).__name__ == 'bool':\n            return True\n        else:\n            return res\n    except:  # pragma: no cover\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of results for a given project ID.", "response": "def get_results(project_id, limit=100, offset=0, last_id=None):\n    \"\"\"Return a list of results for a given project ID.\n\n    :param project_id: PYBOSSA Project ID\n    :type project_id: integer\n    :param limit: Number of returned items, default 100\n    :type limit: integer\n    :param offset: Offset for the query, default 0\n    :param last_id: id of the last result, used for pagination. If provided, offset is ignored\n    :type last_id: integer\n    :type offset: integer\n    :returns: True -- the response status code\n\n    \"\"\"\n    if last_id is not None:\n        params = dict(limit=limit, last_id=last_id)\n    else:\n        params = dict(limit=limit, offset=offset)\n        print(OFFSET_WARNING)\n    params['project_id'] = project_id\n    try:\n        res = _pybossa_req('get', 'result',\n                           params=params)\n        if type(res).__name__ == 'list':\n            return [Result(result) for result in res]\n        else:\n            return res\n    except:  # pragma: no cover\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of matched results for a given project ID.", "response": "def find_results(project_id, **kwargs):\n    \"\"\"Return a list of matched results for a given project ID.\n\n    :param project_id: PYBOSSA Project ID\n    :type project_id: integer\n    :param kwargs: PYBOSSA Results members\n    :type info: dict\n    :rtype: list\n    :returns: A list of results that match the kwargs\n\n    \"\"\"\n    try:\n        kwargs['project_id'] = project_id\n        res = _pybossa_req('get', 'result', params=kwargs)\n        if type(res).__name__ == 'list':\n            return [Result(result) for result in res]\n        else:\n            return res\n    except:  # pragma: no cover\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate a result for a given result ID.", "response": "def update_result(result):\n    \"\"\"Update a result for a given result ID.\n\n    :param result: PYBOSSA result\n\n    \"\"\"\n    try:\n        result_id = result.id\n        result = _forbidden_attributes(result)\n        res = _pybossa_req('put', 'result', result_id, payload=result.data)\n        if res.get('id'):\n            return Result(res)\n        else:\n            return res\n    except:  # pragma: no cover\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _forbidden_attributes(obj):\n    for key in list(obj.data.keys()):\n        if key in list(obj.reserved_keys.keys()):\n            obj.data.pop(key)\n    return obj", "response": "Return the object without the forbidden attributes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_helpingmaterial(project_id, info, media_url=None, file_path=None):\n    try:\n        helping = dict(\n            project_id=project_id,\n            info=info,\n            media_url=None,\n        )\n        if file_path:\n            files = {'file': open(file_path, 'rb')}\n            payload = {'project_id': project_id}\n            res = _pybossa_req('post', 'helpingmaterial',\n                               payload=payload, files=files)\n        else:\n            res = _pybossa_req('post', 'helpingmaterial', payload=helping)\n        if res.get('id'):\n            return HelpingMaterial(res)\n        else:\n            return res\n    except:  # pragma: no cover\n        raise", "response": "Create a helping material for a given project ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_helping_materials(project_id, limit=100, offset=0, last_id=None):\n    if last_id is not None:\n        params = dict(limit=limit, last_id=last_id)\n    else:\n        params = dict(limit=limit, offset=offset)\n        print(OFFSET_WARNING)\n    params['project_id'] = project_id\n    try:\n        res = _pybossa_req('get', 'helpingmaterial',\n                           params=params)\n        if type(res).__name__ == 'list':\n            return [HelpingMaterial(helping) for helping in res]\n        else:\n            return res\n    except:  # pragma: no cover\n        raise", "response": "Get a list of helping materials for a given project ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_helping_materials(project_id, **kwargs):\n    try:\n        kwargs['project_id'] = project_id\n        res = _pybossa_req('get', 'helpingmaterial', params=kwargs)\n        if type(res).__name__ == 'list':\n            return [HelpingMaterial(helping) for helping in res]\n        else:\n            return res\n    except:  # pragma: no cover\n        raise", "response": "Return a list of matched helping materials for a given project ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate a helping material for a given ID.", "response": "def update_helping_material(helpingmaterial):\n    \"\"\"Update a helping material for a given helping material ID.\n\n    :param helpingmaterial: PYBOSSA helping material\n\n    \"\"\"\n    try:\n        helpingmaterial_id = helpingmaterial.id\n        helpingmaterial = _forbidden_attributes(helpingmaterial)\n        res = _pybossa_req('put', 'helpingmaterial',\n                           helpingmaterial_id, payload=helpingmaterial.data)\n        if res.get('id'):\n            return HelpingMaterial(res)\n        else:\n            return res\n    except:  # pragma: no cover\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef login(self, oauth_filename=\"oauth\", uploader_id=None):\n\n\t\tcls_name = type(self).__name__\n\n\t\toauth_cred = os.path.join(os.path.dirname(OAUTH_FILEPATH), oauth_filename + '.cred')\n\n\t\ttry:\n\t\t\tif not self.api.login(oauth_credentials=oauth_cred, uploader_id=uploader_id):\n\t\t\t\ttry:\n\t\t\t\t\tself.api.perform_oauth(storage_filepath=oauth_cred)\n\t\t\t\texcept OSError:\n\t\t\t\t\tlogger.exception(\"\\nUnable to login with specified oauth code.\")\n\n\t\t\t\tself.api.login(oauth_credentials=oauth_cred, uploader_id=uploader_id)\n\t\texcept (OSError, ValueError):\n\t\t\tlogger.exception(\"{} authentication failed.\".format(cls_name))\n\n\t\t\treturn False\n\n\t\tif not self.is_authenticated:\n\t\t\tlogger.warning(\"{} authentication failed.\".format(cls_name))\n\n\t\t\treturn False\n\n\t\tlogger.info(\"{} authentication succeeded.\\n\".format(cls_name))\n\n\t\treturn True", "response": "Authenticate the gmusicapi Musicmanager instance with the specified oauth code."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a list of Google Music songs from the user s Google Music library.", "response": "def get_google_songs(\n\t\tself, include_filters=None, exclude_filters=None, all_includes=False, all_excludes=False,\n\t\tuploaded=True, purchased=True):\n\t\t\"\"\"Create song list from user's Google Music library.\n\n\t\tParameters:\n\t\t\tinclude_filters (list): A list of ``(field, pattern)`` tuples.\n\t\t\t\tFields are any valid Google Music metadata field available to the Musicmanager client.\n\t\t\t\tPatterns are Python regex patterns.\n\t\t\t\tGoogle Music songs are filtered out if the given metadata field values don't match any of the given patterns.\n\n\t\t\texclude_filters (list): A list of ``(field, pattern)`` tuples.\n\t\t\t\tFields are any valid Google Music metadata field available to the Musicmanager client.\n\t\t\t\tPatterns are Python regex patterns.\n\t\t\t\tGoogle Music songs are filtered out if the given metadata field values match any of the given patterns.\n\n\t\t\tall_includes (bool): If ``True``, all include_filters criteria must match to include a song.\n\n\t\t\tall_excludes (bool): If ``True``, all exclude_filters criteria must match to exclude a song.\n\n\t\t\tuploaded (bool): Include uploaded songs. Default: ``True``.\n\n\t\t\tpurchased (bool): Include purchased songs. Default: ``True``.\n\n\t\tReturns:\n\t\t\tA list of Google Music song dicts matching criteria and\n\t\t\ta list of Google Music song dicts filtered out using filter criteria.\n\t\t\"\"\"\n\n\t\tif not uploaded and not purchased:\n\t\t\traise ValueError(\"One or both of uploaded/purchased parameters must be True.\")\n\n\t\tlogger.info(\"Loading Google Music songs...\")\n\n\t\tgoogle_songs = []\n\n\t\tif uploaded:\n\t\t\tgoogle_songs += self.api.get_uploaded_songs()\n\n\t\tif purchased:\n\t\t\tfor song in self.api.get_purchased_songs():\n\t\t\t\tif song not in google_songs:\n\t\t\t\t\tgoogle_songs.append(song)\n\n\t\tmatched_songs, filtered_songs = filter_google_songs(\n\t\t\tgoogle_songs, include_filters=include_filters, exclude_filters=exclude_filters,\n\t\t\tall_includes=all_includes, all_excludes=all_excludes\n\t\t)\n\n\t\tlogger.info(\"Filtered {0} Google Music songs\".format(len(filtered_songs)))\n\t\tlogger.info(\"Loaded {0} Google Music songs\".format(len(matched_songs)))\n\n\t\treturn matched_songs, filtered_songs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading a list of songs.", "response": "def download(self, songs, template=None):\n\t\t\"\"\"Download Google Music songs.\n\n\t\tParameters:\n\t\t\tsongs (list or dict): Google Music song dict(s).\n\n\t\t\ttemplate (str): A filepath which can include template patterns.\n\n\t\tReturns:\n\t\t\tA list of result dictionaries.\n\t\t\t::\n\n\t\t\t\t[\n\t\t\t\t\t{'result': 'downloaded', 'id': song_id, 'filepath': downloaded[song_id]},  # downloaded\n\t\t\t\t\t{'result': 'error', 'id': song_id, 'message': error[song_id]}   # error\n\t\t\t\t]\n\t\t\"\"\"\n\n\t\tif not template:\n\t\t\ttemplate = os.getcwd()\n\n\t\tsongnum = 0\n\t\ttotal = len(songs)\n\t\tresults = []\n\t\terrors = {}\n\t\tpad = len(str(total))\n\n\t\tfor result in self._download(songs, template):\n\t\t\tsong_id = songs[songnum]['id']\n\t\t\tsongnum += 1\n\n\t\t\tdownloaded, error = result\n\n\t\t\tif downloaded:\n\t\t\t\tlogger.info(\n\t\t\t\t\t\"({num:>{pad}}/{total}) Successfully downloaded -- {file} ({song_id})\".format(\n\t\t\t\t\t\tnum=songnum, pad=pad, total=total, file=downloaded[song_id], song_id=song_id\n\t\t\t\t\t)\n\t\t\t\t)\n\n\t\t\t\tresults.append({'result': 'downloaded', 'id': song_id, 'filepath': downloaded[song_id]})\n\t\t\telif error:\n\t\t\t\ttitle = songs[songnum].get('title', \"<empty>\")\n\t\t\t\tartist = songs[songnum].get('artist', \"<empty>\")\n\t\t\t\talbum = songs[songnum].get('album', \"<empty>\")\n\n\t\t\t\tlogger.info(\n\t\t\t\t\t\"({num:>{pad}}/{total}) Error on download -- {title} -- {artist} -- {album} ({song_id})\".format(\n\t\t\t\t\t\tnum=songnum, pad=pad, total=total, title=title, artist=artist, album=album, song_id=song_id\n\t\t\t\t\t)\n\t\t\t\t)\n\n\t\t\t\tresults.append({'result': 'error', 'id': song_id, 'message': error[song_id]})\n\n\t\tif errors:\n\t\t\tlogger.info(\"\\n\\nThe following errors occurred:\\n\")\n\t\t\tfor filepath, e in errors.items():\n\t\t\t\tlogger.info(\"{file} | {error}\".format(file=filepath, error=e))\n\t\t\tlogger.info(\"\\nThese files may need to be synced again.\\n\")\n\n\t\treturn results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupload local songs to Google Music.", "response": "def upload(self, filepaths, enable_matching=False, transcode_quality='320k', delete_on_success=False):\n\t\t\"\"\"Upload local songs to Google Music.\n\n\t\tParameters:\n\t\t\tfilepaths (list or str): Filepath(s) to upload.\n\n\t\t\tenable_matching (bool): If ``True`` attempt to use `scan and match\n\t\t\t\t<http://support.google.com/googleplay/bin/answer.py?hl=en&answer=2920799&topic=2450455>`__.\n\t\t\t\tThis requieres ffmpeg or avconv.\n\n\t\t\ttranscode_quality (str or int): If int, pass to ffmpeg/avconv ``-q:a`` for libmp3lame `VBR quality\n\t\t\t\t<http://trac.ffmpeg.org/wiki/Encode/MP3#VBREncoding>'__.\n\t\t\t\tIf string, pass to ffmpeg/avconv ``-b:a`` for libmp3lame `CBR quality\n\t\t\t\t<http://trac.ffmpeg.org/wiki/Encode/MP3#CBREncoding>'__.\n\t\t\t\tDefault: ``320k``\n\n\t\t\tdelete_on_success (bool): Delete successfully uploaded local files. Default: ``False``\n\n\t\tReturns:\n\t\t\tA list of result dictionaries.\n\t\t\t::\n\n\t\t\t\t[\n\t\t\t\t\t{'result': 'uploaded', 'filepath': <filepath>, 'id': <song_id>},  # uploaded\n\t\t\t\t\t{'result': 'matched', 'filepath': <filepath>, 'id': <song_id>},  # matched\n\t\t\t\t\t{'result': 'error', 'filepath': <filepath>, 'message': <error_message>},  # error\n\t\t\t\t\t{'result': 'not_uploaded', 'filepath': <filepath>, 'id': <song_id>, 'message': <reason_message>},  # not_uploaded ALREADY_EXISTS\n\t\t\t\t\t{'result': 'not_uploaded', 'filepath': <filepath>, 'message': <reason_message>}  # not_uploaded\n\t\t\t\t]\n\t\t\"\"\"\n\n\t\tfilenum = 0\n\t\ttotal = len(filepaths)\n\t\tresults = []\n\t\terrors = {}\n\t\tpad = len(str(total))\n\t\texist_strings = [\"ALREADY_EXISTS\", \"this song is already uploaded\"]\n\n\t\tfor result in self._upload(filepaths, enable_matching=enable_matching, transcode_quality=transcode_quality):\n\t\t\tfilepath = filepaths[filenum]\n\t\t\tfilenum += 1\n\n\t\t\tuploaded, matched, not_uploaded, error = result\n\n\t\t\tif uploaded:\n\t\t\t\tlogger.info(\n\t\t\t\t\t\"({num:>{pad}}/{total}) Successfully uploaded -- {file} ({song_id})\".format(\n\t\t\t\t\t\tnum=filenum, pad=pad, total=total, file=filepath, song_id=uploaded[filepath]\n\t\t\t\t\t)\n\t\t\t\t)\n\n\t\t\t\tresults.append({'result': 'uploaded', 'filepath': filepath, 'id': uploaded[filepath]})\n\t\t\telif matched:\n\t\t\t\tlogger.info(\n\t\t\t\t\t\"({num:>{pad}}/{total}) Successfully scanned and matched -- {file} ({song_id})\".format(\n\t\t\t\t\t\tnum=filenum, pad=pad, total=total, file=filepath, song_id=matched[filepath]\n\t\t\t\t\t)\n\t\t\t\t)\n\n\t\t\t\tresults.append({'result': 'matched', 'filepath': filepath, 'id': matched[filepath]})\n\t\t\telif error:\n\t\t\t\tlogger.warning(\"({num:>{pad}}/{total}) Error on upload -- {file}\".format(num=filenum, pad=pad, total=total, file=filepath))\n\n\t\t\t\tresults.append({'result': 'error', 'filepath': filepath, 'message': error[filepath]})\n\t\t\t\terrors.update(error)\n\t\t\telse:\n\t\t\t\tif any(exist_string in not_uploaded[filepath] for exist_string in exist_strings):\n\t\t\t\t\tresponse = \"ALREADY EXISTS\"\n\n\t\t\t\t\tsong_id = GM_ID_RE.search(not_uploaded[filepath]).group(0)\n\n\t\t\t\t\tlogger.info(\n\t\t\t\t\t\t\"({num:>{pad}}/{total}) Failed to upload -- {file} ({song_id}) | {response}\".format(\n\t\t\t\t\t\t\tnum=filenum, pad=pad, total=total, file=filepath, response=response, song_id=song_id\n\t\t\t\t\t\t)\n\t\t\t\t\t)\n\n\t\t\t\t\tresults.append({'result': 'not_uploaded', 'filepath': filepath, 'id': song_id, 'message': not_uploaded[filepath]})\n\t\t\t\telse:\n\t\t\t\t\tresponse = not_uploaded[filepath]\n\n\t\t\t\t\tlogger.info(\n\t\t\t\t\t\t\"({num:>{pad}}/{total}) Failed to upload -- {file} | {response}\".format(\n\t\t\t\t\t\t\tnum=filenum, pad=pad, total=total, file=filepath, response=response\n\t\t\t\t\t\t)\n\t\t\t\t\t)\n\n\t\t\t\t\tresults.append({'result': 'not_uploaded', 'filepath': filepath, 'message': not_uploaded[filepath]})\n\n\t\t\tsuccess = (uploaded or matched) or (not_uploaded and 'ALREADY_EXISTS' in not_uploaded[filepath])\n\n\t\t\tif success and delete_on_success:\n\t\t\t\ttry:\n\t\t\t\t\tos.remove(filepath)\n\t\t\t\texcept (OSError, PermissionError):\n\t\t\t\t\tlogger.warning(\"Failed to remove {} after successful upload\".format(filepath))\n\n\t\tif errors:\n\t\t\tlogger.info(\"\\n\\nThe following errors occurred:\\n\")\n\n\t\t\tfor filepath, e in errors.items():\n\t\t\t\tlogger.info(\"{file} | {error}\".format(file=filepath, error=e))\n\t\t\tlogger.info(\"\\nThese filepaths may need to be synced again.\\n\")\n\n\t\treturn results"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_cygwin_path(path):\n\n\ttry:\n\t\twin_path = subprocess.check_output([\"cygpath\", \"-aw\", path], universal_newlines=True).strip()\n\texcept (FileNotFoundError, subprocess.CalledProcessError):\n\t\tlogger.exception(\"Call to cygpath failed.\")\n\t\traise\n\n\treturn win_path", "response": "Convert Unix path from Cygwin to Windows path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_mutagen_metadata(filepath):\n\n\ttry:\n\t\tmetadata = mutagen.File(filepath, easy=True)\n\texcept mutagen.MutagenError:\n\t\tlogger.warning(\"Can't load {} as music file.\".format(filepath))\n\t\traise\n\n\treturn metadata", "response": "Get mutagen metadata dict from a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _mutagen_fields_to_single_value(metadata):\n\n\treturn dict((k, v[0]) for k, v in metadata.items() if v)", "response": "Replace mutagen metadata field list values in mutagen tags with the first list value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _split_field_to_single_value(field):\n\n\tsplit_field = re.match(r'(\\d+)/\\d+', field)\n\n\treturn split_field.group(1) or field", "response": "Convert number field values split by a slash to a single number value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nnormalize metadata to improve match accuracy.", "response": "def _normalize_metadata(metadata):\n\t\"\"\"Normalize metadata to improve match accuracy.\"\"\"\n\n\tmetadata = str(metadata)\n\tmetadata = metadata.lower()\n\n\tmetadata = re.sub(r'\\/\\s*\\d+', '', metadata)  # Remove \"/<totaltracks>\" from track number.\n\tmetadata = re.sub(r'^0+([0-9]+)', r'\\1', metadata)  # Remove leading zero(s) from track number.\n\tmetadata = re.sub(r'^\\d+\\.+', '', metadata)  # Remove dots from track number.\n\tmetadata = re.sub(r'[^\\w\\s]', '', metadata)  # Remove any non-words.\n\tmetadata = re.sub(r'\\s+', ' ', metadata)  # Reduce multiple spaces to a single space.\n\tmetadata = re.sub(r'^\\s+', '', metadata)  # Remove leading space.\n\tmetadata = re.sub(r'\\s+$', '', metadata)  # Remove trailing space.\n\tmetadata = re.sub(r'^the\\s+', '', metadata, re.I)  # Remove leading \"the\".\n\n\treturn metadata"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncompares two song collections to find missing songs.", "response": "def compare_song_collections(src_songs, dst_songs):\n\t\"\"\"Compare two song collections to find missing songs.\n\n\tParameters:\n\t\tsrc_songs (list): Google Music song dicts or filepaths of local songs.\n\n\t\tdest_songs (list): Google Music song dicts or filepaths of local songs.\n\n\tReturns:\n\t\tA list of Google Music song dicts or local song filepaths from source missing in destination.\n\t\"\"\"\n\n\tdef gather_field_values(song):\n\t\treturn tuple((_normalize_metadata(song[field]) for field in _filter_comparison_fields(song)))\n\n\tdst_songs_criteria = {gather_field_values(_normalize_song(dst_song)) for dst_song in dst_songs}\n\n\treturn [src_song for src_song in src_songs if gather_field_values(_normalize_song(src_song)) not in dst_songs_criteria]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_supported_filepaths(filepaths, supported_extensions, max_depth=float('inf')):\n\n\tsupported_filepaths = []\n\n\tfor path in filepaths:\n\t\tif os.name == 'nt' and CYGPATH_RE.match(path):\n\t\t\tpath = convert_cygwin_path(path)\n\n\t\tif os.path.isdir(path):\n\t\t\tfor root, __, files in walk_depth(path, max_depth):\n\t\t\t\tfor f in files:\n\t\t\t\t\tif f.lower().endswith(supported_extensions):\n\t\t\t\t\t\tsupported_filepaths.append(os.path.join(root, f))\n\t\telif os.path.isfile(path) and path.lower().endswith(supported_extensions):\n\t\t\tsupported_filepaths.append(path)\n\n\treturn supported_filepaths", "response": "Get filepaths with supported extensions from given filepaths."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef exclude_filepaths(filepaths, exclude_patterns=None):\n\n\tif not exclude_patterns:\n\t\treturn filepaths, []\n\n\texclude_re = re.compile(\"|\".join(pattern for pattern in exclude_patterns))\n\n\tincluded_songs = []\n\texcluded_songs = []\n\n\tfor filepath in filepaths:\n\t\tif exclude_patterns and exclude_re.search(filepath):\n\t\t\texcluded_songs.append(filepath)\n\t\telse:\n\t\t\tincluded_songs.append(filepath)\n\n\treturn included_songs, excluded_songs", "response": "Exclude file paths based on regex patterns."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _check_field_value(field_value, pattern):\n\n\tif isinstance(field_value, list):\n\t\treturn any(re.search(pattern, str(value), re.I) for value in field_value)\n\telse:\n\t\treturn re.search(pattern, str(field_value), re.I)", "response": "Check a song metadata field value for a pattern."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks a song metadata dict against a set of metadata filters.", "response": "def _check_filters(song, include_filters=None, exclude_filters=None, all_includes=False, all_excludes=False):\n\t\"\"\"Check a song metadata dict against a set of metadata filters.\"\"\"\n\n\tinclude = True\n\n\tif include_filters:\n\t\tif all_includes:\n\t\t\tif not all(field in song and _check_field_value(song[field], pattern) for field, pattern in include_filters):\n\t\t\t\tinclude = False\n\t\telse:\n\t\t\tif not any(field in song and _check_field_value(song[field], pattern) for field, pattern in include_filters):\n\t\t\t\tinclude = False\n\n\tif exclude_filters:\n\t\tif all_excludes:\n\t\t\tif all(field in song and _check_field_value(song[field], pattern) for field, pattern in exclude_filters):\n\t\t\t\tinclude = False\n\t\telse:\n\t\t\tif any(field in song and _check_field_value(song[field], pattern) for field, pattern in exclude_filters):\n\t\t\t\tinclude = False\n\n\treturn include"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filter_google_songs(songs, include_filters=None, exclude_filters=None, all_includes=False, all_excludes=False):\n\n\tmatched_songs = []\n\tfiltered_songs = []\n\n\tif include_filters or exclude_filters:\n\t\tfor song in songs:\n\t\t\tif _check_filters(\n\t\t\t\t\tsong, include_filters=include_filters, exclude_filters=exclude_filters,\n\t\t\t\t\tall_includes=all_includes, all_excludes=all_excludes):\n\t\t\t\tmatched_songs.append(song)\n\t\t\telse:\n\t\t\t\tfiltered_songs.append(song)\n\telse:\n\t\tmatched_songs += songs\n\n\treturn matched_songs, filtered_songs", "response": "Match a Google Music song dict against a set of metadata filters."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmatch a local file against a set of metadata filters.", "response": "def filter_local_songs(filepaths, include_filters=None, exclude_filters=None, all_includes=False, all_excludes=False):\n\t\"\"\"Match a local file against a set of metadata filters.\n\n\tParameters:\n\t\tfilepaths (list): Filepaths to filter.\n\n\t\tinclude_filters (list): A list of ``(field, pattern)`` tuples.\n\t\t\tFields are any valid mutagen metadata fields.\n\t\t\tPatterns are Python regex patterns.\n\t\t\tLocal songs are filtered out if the given metadata field values don't match any of the given patterns.\n\n\t\texclude_filters (list): A list of ``(field, pattern)`` tuples.\n\t\t\tFields are any valid mutagen metadata fields.\n\t\t\tPatterns are Python regex patterns.\n\t\t\tLocal songs are filtered out if the given metadata field values match any of the given patterns.\n\n\t\tall_includes (bool): If ``True``, all include_filters criteria must match to include a song.\n\n\t\tall_excludes (bool): If ``True``, all exclude_filters criteria must match to exclude a song.\n\n\tReturns:\n\t\tA list of local song filepaths matching criteria and\n\t\ta list of local song filepaths filtered out using filter criteria.\n\t\tInvalid music files are also filtered out.\n\t\t::\n\n\t\t\t(matched, filtered)\n\t\"\"\"\n\n\tmatched_songs = []\n\tfiltered_songs = []\n\n\tfor filepath in filepaths:\n\t\ttry:\n\t\t\tsong = _get_mutagen_metadata(filepath)\n\t\texcept mutagen.MutagenError:\n\t\t\tfiltered_songs.append(filepath)\n\t\telse:\n\t\t\tif include_filters or exclude_filters:\n\t\t\t\tif _check_filters(\n\t\t\t\t\t\tsong, include_filters=include_filters, exclude_filters=exclude_filters,\n\t\t\t\t\t\tall_includes=all_includes, all_excludes=all_excludes):\n\t\t\t\t\tmatched_songs.append(filepath)\n\t\t\t\telse:\n\t\t\t\t\tfiltered_songs.append(filepath)\n\t\t\telse:\n\t\t\t\tmatched_songs.append(filepath)\n\n\treturn matched_songs, filtered_songs"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a filename based on a song based on metadata.", "response": "def get_suggested_filename(metadata):\n\t\"\"\"Generate a filename for a song based on metadata.\n\n\tParameters:\n\t\tmetadata (dict): A metadata dict.\n\n\tReturns:\n\t\tA filename.\n\t\"\"\"\n\n\tif metadata.get('title') and metadata.get('track_number'):\n\t\tsuggested_filename = '{track_number:0>2} {title}'.format(**metadata)\n\telif metadata.get('title') and metadata.get('trackNumber'):\n\t\tsuggested_filename = '{trackNumber:0>2} {title}'.format(**metadata)\n\telif metadata.get('title') and metadata.get('tracknumber'):\n\t\tsuggested_filename = '{tracknumber:0>2} {title}'.format(**metadata)\n\telse:\n\t\tsuggested_filename = '00 {}'.format(metadata.get('title', ''))\n\n\treturn suggested_filename"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a filepath based on a template.", "response": "def template_to_filepath(template, metadata, template_patterns=None):\n\t\"\"\"Create directory structure and file name based on metadata template.\n\n\tParameters:\n\t\ttemplate (str): A filepath which can include template patterns as defined by :param template_patterns:.\n\n\t\tmetadata (dict): A metadata dict.\n\n\t\ttemplate_patterns (dict): A dict of ``pattern: field`` pairs used to replace patterns with metadata field values.\n\t\t\tDefault: :const TEMPLATE_PATTERNS:\n\n\tReturns:\n\t\tA filepath.\n\t\"\"\"\n\n\tif template_patterns is None:\n\t\ttemplate_patterns = TEMPLATE_PATTERNS\n\n\tmetadata = metadata if isinstance(metadata, dict) else _mutagen_fields_to_single_value(metadata)\n\tassert isinstance(metadata, dict)\n\n\tsuggested_filename = get_suggested_filename(metadata).replace('.mp3', '')\n\n\tif template == os.getcwd() or template == '%suggested%':\n\t\tfilepath = suggested_filename\n\telse:\n\t\tt = template.replace('%suggested%', suggested_filename)\n\t\tfilepath = _replace_template_patterns(t, metadata, template_patterns)\n\n\treturn filepath"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef walk_depth(path, max_depth=float('inf')):\n\n\tstart_level = os.path.abspath(path).count(os.path.sep)\n\n\tfor dir_entry in os.walk(path):\n\t\troot, dirs, _ = dir_entry\n\t\tlevel = root.count(os.path.sep) - start_level\n\n\t\tyield dir_entry\n\n\t\tif level >= max_depth:\n\t\t\tdirs[:] = []", "response": "Walk a directory tree with configurable depth."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads local songs from local filepaths.", "response": "def get_local_songs(\n\t\t\tfilepaths, include_filters=None, exclude_filters=None, all_includes=False, all_excludes=False,\n\t\t\texclude_patterns=None, max_depth=float('inf')):\n\t\t\"\"\"Load songs from local filepaths.\n\n\t\tParameters:\n\t\t\tfilepaths (list or str): Filepath(s) to search for music files.\n\n\t\t\tinclude_filters (list): A list of ``(field, pattern)`` tuples.\n\t\t\t\tFields are any valid mutagen metadata fields. Patterns are Python regex patterns.\n\t\t\t\tLocal songs are filtered out if the given metadata field values don't match any of the given patterns.\n\n\t\t\texclude_filters (list): A list of ``(field, pattern)`` tuples.\n\t\t\t\tFields are any valid mutagen metadata fields. Patterns are Python regex patterns.\n\t\t\t\tLocal songs are filtered out if the given metadata field values match any of the given patterns.\n\n\t\t\tall_includes (bool): If ``True``, all include_filters criteria must match to include a song.\n\n\t\t\tall_excludes (bool): If ``True``, all exclude_filters criteria must match to exclude a song.\n\n\t\t\texclude_patterns (list or str): Pattern(s) to exclude.\n\t\t\t\tPatterns are Python regex patterns.\n\t\t\t\tFilepaths are excluded if they match any of the exclude patterns.\n\n\t\t\tmax_depth (int): The depth in the directory tree to walk.\n\t\t\t\tA depth of '0' limits the walk to the top directory.\n\t\t\t\tDefault: No limit.\n\n\t\tReturns:\n\t\t\tA list of local song filepaths matching criteria,\n\t\t\ta list of local song filepaths filtered out using filter criteria,\n\t\t\tand a list of local song filepaths excluded using exclusion criteria.\n\n\t\t\"\"\"\n\n\t\tlogger.info(\"Loading local songs...\")\n\n\t\tsupported_filepaths = get_supported_filepaths(filepaths, SUPPORTED_SONG_FORMATS, max_depth=max_depth)\n\n\t\tincluded_songs, excluded_songs = exclude_filepaths(supported_filepaths, exclude_patterns=exclude_patterns)\n\n\t\tmatched_songs, filtered_songs = filter_local_songs(\n\t\t\tincluded_songs, include_filters=include_filters, exclude_filters=exclude_filters,\n\t\t\tall_includes=all_includes, all_excludes=all_excludes\n\t\t)\n\n\t\tlogger.info(\"Excluded {0} local songs\".format(len(excluded_songs)))\n\t\tlogger.info(\"Filtered {0} local songs\".format(len(filtered_songs)))\n\t\tlogger.info(\"Loaded {0} local songs\".format(len(matched_songs)))\n\n\t\treturn matched_songs, filtered_songs, excluded_songs"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads playlists from local filepaths.", "response": "def get_local_playlists(filepaths, exclude_patterns=None, max_depth=float('inf')):\n\t\t\"\"\"Load playlists from local filepaths.\n\n\t\tParameters:\n\t\t\tfilepaths (list or str): Filepath(s) to search for music files.\n\n\t\t\texclude_patterns (list or str): Pattern(s) to exclude.\n\t\t\t\tPatterns are Python regex patterns.\n\t\t\t\tFilepaths are excluded if they match any of the exclude patterns.\n\n\t\t\tmax_depth (int): The depth in the directory tree to walk.\n\t\t\t\tA depth of '0' limits the walk to the top directory.\n\t\t\t\tDefault: No limit.\n\n\t\tReturns:\n\t\t\tA list of local playlist filepaths matching criteria\n\t\t\tand a list of local playlist filepaths excluded using exclusion criteria.\n\t\t\"\"\"\n\n\t\tlogger.info(\"Loading local playlists...\")\n\n\t\tincluded_playlists = []\n\t\texcluded_playlists = []\n\n\t\tsupported_filepaths = get_supported_filepaths(filepaths, SUPPORTED_PLAYLIST_FORMATS, max_depth=max_depth)\n\n\t\tincluded_playlists, excluded_playlists = exclude_filepaths(supported_filepaths, exclude_patterns=exclude_patterns)\n\n\t\tlogger.info(\"Excluded {0} local playlists\".format(len(excluded_playlists)))\n\t\tlogger.info(\"Loaded {0} local playlists\".format(len(included_playlists)))\n\n\t\treturn included_playlists, excluded_playlists"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_local_playlist_songs(\n\t\tplaylist, include_filters=None, exclude_filters=None,\n\t\tall_includes=False, all_excludes=False, exclude_patterns=None):\n\t\t\"\"\"Load songs from local playlist.\n\n\t\tParameters:\n\t\t\tplaylist (str): An M3U(8) playlist filepath.\n\n\t\t\tinclude_filters (list): A list of ``(field, pattern)`` tuples.\n\t\t\t\tFields are any valid mutagen metadata fields. Patterns are Python regex patterns.\n\t\t\t\tLocal songs are filtered out if the given metadata field values don't match any of the given patterns.\n\n\t\t\texclude_filters (list): A list of ``(field, pattern)`` tuples.\n\t\t\t\tFields are any valid mutagen metadata fields. Patterns are Python regex patterns.\n\t\t\t\tLocal songs are filtered out if the given metadata field values match any of the given patterns.\n\n\t\t\tall_includes (bool): If ``True``, all include_filters criteria must match to include a song.\n\n\t\t\tall_excludes (bool): If ``True``, all exclude_filters criteria must match to exclude a song.\n\n\t\t\texclude_patterns (list or str): Pattern(s) to exclude.\n\t\t\t\tPatterns are Python regex patterns.\n\t\t\t\tFilepaths are excluded if they match any of the exclude patterns.\n\n\t\tReturns:\n\t\t\tA list of local playlist song filepaths matching criteria,\n\t\t\ta list of local playlist song filepaths filtered out using filter criteria,\n\t\t\tand a list of local playlist song filepaths excluded using exclusion criteria.\n\t\t\"\"\"\n\n\t\tlogger.info(\"Loading local playlist songs...\")\n\n\t\tif os.name == 'nt' and CYGPATH_RE.match(playlist):\n\t\t\tplaylist = convert_cygwin_path(playlist)\n\n\t\tfilepaths = []\n\t\tbase_filepath = os.path.dirname(os.path.abspath(playlist))\n\n\t\twith open(playlist) as local_playlist:\n\t\t\tfor line in local_playlist.readlines():\n\t\t\t\tline = line.strip()\n\n\t\t\t\tif line.lower().endswith(SUPPORTED_SONG_FORMATS):\n\t\t\t\t\tpath = line\n\n\t\t\t\t\tif not os.path.isabs(path):\n\t\t\t\t\t\tpath = os.path.join(base_filepath, path)\n\n\t\t\t\t\tif os.path.isfile(path):\n\t\t\t\t\t\tfilepaths.append(path)\n\n\t\tsupported_filepaths = get_supported_filepaths(filepaths, SUPPORTED_SONG_FORMATS)\n\n\t\tincluded_songs, excluded_songs = exclude_filepaths(supported_filepaths, exclude_patterns=exclude_patterns)\n\n\t\tmatched_songs, filtered_songs = filter_local_songs(\n\t\t\tincluded_songs, include_filters=include_filters, exclude_filters=exclude_filters,\n\t\t\tall_includes=all_includes, all_excludes=all_excludes\n\t\t)\n\n\t\tlogger.info(\"Excluded {0} local playlist songs\".format(len(excluded_songs)))\n\t\tlogger.info(\"Filtered {0} local playlist songs\".format(len(filtered_songs)))\n\t\tlogger.info(\"Loaded {0} local playlist songs\".format(len(matched_songs)))\n\n\t\treturn matched_songs, filtered_songs, excluded_songs", "response": "Load songs from local playlist."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprepare the lines read from the text file before starting to process it.", "response": "def _prepare_lines_(self, lines):\n        \"\"\"\n        Prepare the lines read from the text file before starting to process\n        it.\n        \"\"\"\n\n        result = []\n        for line in lines:\n            # Remove all whitespace from the start and end of the line.\n            line = line.strip()\n\n            # Replace all tabs with spaces.\n            line = line.replace('\\t', ' ')\n\n            # Replace all repeating spaces with a single space.\n            while line.find('  ') > -1:\n                line = line.replace('  ', ' ')\n\n            result.append(line)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an alphabetically sorted list of elements from the compounds of the material.", "response": "def _create_element_list_(self):\n        \"\"\"\n        Extract an alphabetically sorted list of elements from the compounds of\n        the material.\n\n        :returns: An alphabetically sorted list of elements.\n        \"\"\"\n\n        element_set = stoich.elements(self.compounds)\n        return sorted(list(element_set))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds an assay to the material.", "response": "def add_assay(self, name, assay):\n        \"\"\"\n        Add an assay to the material.\n\n        :param name: The name of the new assay.\n        :param assay: A list containing the compound mass fractions for\n          the assay. The sequence of the assay's elements must correspond to\n          the sequence of the material's compounds.\n        \"\"\"\n\n        if not type(assay) is list:\n            raise Exception('Invalid assay. It must be a list.')\n\n        elif not len(assay) == self.compound_count:\n            raise Exception('Invalid assay: It must have the same number of '\n                            'elements as the material has compounds.')\n\n        elif name in self.assays:\n            raise Exception('Invalid assay: An assay with that name already '\n                            'exists.')\n\n        self.assays[name] = assay"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _is_compound_mass_tuple(self, value):\n\n        if not type(value) is tuple:\n            return False\n        elif not len(value) == 2:\n            return False\n        elif not type(value[0]) is str:\n            return False\n        elif not type(value[1]) is float:\n            return False\n        else:\n            return True", "response": "Determines whether value is a compound mass tuple."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a complete copy of self.", "response": "def clone(self):\n        \"\"\"\n        Create a complete copy of self.\n\n        :returns: A MaterialPackage that is identical to self.\n        \"\"\"\n\n        result = copy.copy(self)\n        result.compound_masses = copy.deepcopy(self.compound_masses)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the assay of the species", "response": "def get_assay(self):\n        \"\"\"\n        Determine the assay of self.\n\n        :returns: [mass fractions] An array containing the assay of self.\n        \"\"\"\n\n        masses_sum = sum(self.compound_masses)\n        return [m / masses_sum for m in self.compound_masses]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the element masses of elements in the package.", "response": "def get_element_masses(self):\n        \"\"\"\n        Get the masses of elements in the package.\n\n        :returns: [kg] An array of element masses. The sequence of the elements\n          in the result corresponds with the sequence of elements in the\n          element list of the material.\n        \"\"\"\n\n        result = [0] * len(self.material.elements)\n        for compound in self.material.compounds:\n            c = self.get_compound_mass(compound)\n            f = [c * x for x in emf(compound, self.material.elements)]\n            result = [v+f[ix] for ix, v in enumerate(result)]\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_element_mass(self, element):\n\n        result = [0]\n        for compound in self.material.compounds:\n            c = self.get_compound_mass(compound)\n            f = [c * x for x in emf(compound, [element])]\n            result = [v+f[ix] for ix, v in enumerate(result)]\n\n        return result[0]", "response": "Determine the masses of elements in the package."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract(self, other):\n\n        # Extract the specified mass.\n        if type(other) is float:\n\n            if other > self.get_mass():\n                raise Exception('Invalid extraction operation. Cannot extract'\n                                'a mass larger than the package\\'s mass.')\n\n            fraction_to_subtract = other / self.get_mass()\n            result = MaterialPackage(\n                self.material,\n                [m * fraction_to_subtract for m in self.compound_masses])\n            self.compound_masses = [m * (1.0 - fraction_to_subtract)\n                                    for m in self.compound_masses]\n\n            return result\n\n        # Extract the specified mass of the specified compound.\n        elif self._is_compound_mass_tuple(other):\n            index = self.material.get_compound_index(other[0])\n\n            if other[1] > self.compound_masses[index]:\n                raise Exception('Invalid extraction operation. Cannot extract'\n                                'a compound mass larger than what the package'\n                                'contains.')\n\n            self.compound_masses[index] -= other[1]\n            resultarray = [0.0] * len(self.compound_masses)\n            resultarray[index] = other[1]\n            result = MaterialPackage(self.material, resultarray)\n\n            return result\n\n        # Extract all of the specified compound.\n        elif type(other) is str:\n            index = self.material.get_compound_index(other)\n            result = self * 0.0\n            result.compound_masses[index] = self.compound_masses[index]\n            self.compound_masses[index] = 0.0\n\n            return result\n\n        # If not one of the above, it must be an invalid argument.\n        else:\n            raise TypeError('Invalid extraction argument.')", "response": "This method extracts the other from self modifying self and returning the extracted material package as a new package."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_to(self, other):\n\n        # Add another package.\n        if type(other) is MaterialPackage:\n\n            # Packages of the same material.\n            if self.material == other.material:\n                self.compound_masses += other.compound_masses\n\n            # Packages of different materials.\n            else:\n                for compound in other.material.compounds:\n                    if compound not in self.material.compounds:\n                        raise Exception(\"Packages of '\" + other.material.name +\n                                        \"' cannot be added to packages of '\" +\n                                        self.material.name +\n                                        \"'. The compound '\" + compound +\n                                        \"' was not found in '\" +\n                                        self.material.name + \"'.\")\n                    self.add_to((compound, other.get_compound_mass(compound)))\n\n        # Add the specified mass of the specified compound.\n        elif self._is_compound_mass_tuple(other):\n            # Added material variables.\n            compound = other[0]\n            compound_index = self.material.get_compound_index(compound)\n            mass = other[1]\n\n            # Create the result package.\n            self.compound_masses[compound_index] += mass\n\n        # If not one of the above, it must be an invalid argument.\n        else:\n            raise TypeError('Invalid addition argument.')", "response": "Adds another chemical material package to this material package."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef calculate(self, **state):\n        super().calculate(**state)\n        return self.mm * self.P / R / state[\"T\"]", "response": "Calculates the density at the specified temperature."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the density at the specified temperature pressure and the specified mole fractions.", "response": "def calculate(self, **state):\n        \"\"\"\n        Calculate the density at the specified temperature, pressure, and\n        composition.\n\n        :param T: [K] temperature\n        :param P: [Pa] pressure\n        :param x: [mole fraction] dictionary of compounds and mole fractions\n\n        :returns: [kg/m3] density\n\n        The **state parameter contains the keyword argument(s) specified above\\\n        that are used to describe the state of the material.\n        \"\"\"\n        super().calculate(**state)\n        mm_average = 0.0\n        for compound, molefraction in state[\"x\"].items():\n            mm_average += molefraction * mm(compound)\n        mm_average /= 1000.0\n\n        return mm_average * state[\"P\"] / R / state[\"T\"]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the parent path and the path from the new parent path.", "response": "def set_parent_path(self, value):\n        \"\"\"\n        Set the parent path and the path from the new parent path.\n\n        :param value: The path to the object's parent\n        \"\"\"\n\n        self._parent_path = value\n        self.path = value + r'/' + self.name\n        self._update_childrens_parent_path()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_account(self, name, number=None, description=None):\n\n        new_account = GeneralLedgerAccount(name, description, number,\n                                           self.account_type)\n        new_account.set_parent_path(self.path)\n        self.accounts.append(new_account)\n        return new_account", "response": "Create a sub account in the ledger."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_account(self, name):\n\n        acc_to_remove = None\n        for a in self.accounts:\n            if a.name == name:\n                acc_to_remove = a\n        if acc_to_remove is not None:\n            self.accounts.remove(acc_to_remove)", "response": "Removes an account from the account s sub accounts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_child_account(self, account_name):\n\n        if r'/' in account_name:\n            accs_in_path = account_name.split(r'/', 1)\n\n            curr_acc = self[accs_in_path[0]]\n            if curr_acc is None:\n                return None\n            return curr_acc.get_child_account(accs_in_path[1])\n            pass\n        else:\n            return self[account_name]", "response": "Retrieves a child account."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _create_account_(self, name, number, account_type):\n\n        new_acc = GeneralLedgerAccount(name, None, number, account_type)\n        self.accounts.append(new_acc)\n        return new_acc", "response": "Create an account in the general ledger structure."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an array of all the decendants of the account.", "response": "def get_account_descendants(self, account):\n        \"\"\"\n        Retrieves an account's descendants from the general ledger structure\n        given the account name.\n\n        :param account_name: The account name.\n\n        :returns: The decendants of the account.\n        \"\"\"\n\n        result = []\n        for child in account.accounts:\n            self._get_account_and_descendants_(child, result)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the account and all of it's sub accounts. :param account: The account. :param result: The list to add all the accounts to.", "response": "def _get_account_and_descendants_(self, account, result):\n        \"\"\"\n        Returns the account and all of it's sub accounts.\n\n        :param account: The account.\n        :param result: The list to add all the accounts to.\n        \"\"\"\n\n        result.append(account)\n        for child in account.accounts:\n            self._get_account_and_descendants_(child, result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_account_names(self, names):\n\n        for name in names:\n            if self.get_account(name) is None:\n                raise ValueError(\"The account '{}' does not exist in the\"\n                                 \"  general ledger structure.\".format(name))", "response": "Validates that the accounts in a list of account names exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a report of this class.", "response": "def report(self, format=ReportFormat.printout, output_path=None):\n        \"\"\"\n        Returns a report of this class.\n\n        :param format: The format of the report.\n        :param output_path: The path to the file the report is written to.\n          If None, then the report is not written to a file.\n\n        :returns: The descendants of the account.\n        \"\"\"\n\n        rpt = GlsRpt(self, output_path)\n        return rpt.render(format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_transaction(self, name, description=None,\n                           tx_date=datetime.min.date(),\n                           dt_account=None, cr_account=None,\n                           source=None, amount=0.00):\n        \"\"\"\n        Create a transaction in the general ledger.\n\n        :param name: The transaction's name.\n        :param description: The transaction's description.\n        :param tx_date: The date of the transaction.\n        :param cr_account: The transaction's credit account's name.\n        :param dt_account: The transaction's debit account's name.\n        :param source: The name of source the transaction originated from.\n        :param amount: The transaction amount.\n\n        :returns: The created transaction.\n        \"\"\"\n\n        new_tx = Transaction(name, description, tx_date,\n                             dt_account, cr_account, source, amount)\n        self.transactions.append(new_tx)\n        return new_tx", "response": "Create a new transaction in the general ledger."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a transaction list report.", "response": "def transaction_list(self, start=datetime.min,\n                         end=datetime.max,\n                         format=ReportFormat.printout,\n                         component_path=\"\",\n                         output_path=None):\n        \"\"\"\n        Generate a transaction list report.\n\n        :param start: The start date to generate the report for.\n        :param end: The end date to generate the report for.\n        :param format: The format of the report.\n        :param component_path: The path of the component to filter the report's\n          transactions by.\n        :param output_path: The path to the file the report is written to.\n          If None, then the report is not written to a file.\n\n        :returns: The generated report.\n        \"\"\"\n\n        rpt = TransactionList(self, start, end, component_path, output_path)\n        return rpt.render(format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef balance_sheet(self, end=datetime.max,\n                      format=ReportFormat.printout, output_path=None):\n        \"\"\"\n        Generate a transaction list report.\n\n        :param end: The end date to generate the report for.\n        :param format: The format of the report.\n        :param output_path: The path to the file the report is written to.\n          If None, then the report is not written to a file.\n\n        :returns: The generated report.\n        \"\"\"\n\n        rpt = BalanceSheet(self, end, output_path)\n        return rpt.render(format)", "response": "Generate a balance sheet report."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a income statement report.", "response": "def income_statement(self, start=datetime.min,\n                         end=datetime.max,\n                         format=ReportFormat.printout,\n                         component_path=\"\",\n                         output_path=None):\n        \"\"\"\n        Generate a transaction list report.\n\n        :param start: The start date to generate the report for.\n        :param end: The end date to generate the report for.\n        :param format: The format of the report.\n        :param component_path: The path of the component to filter the report's\n          transactions by.\n        :param output_path: The path to the file the report is written to.\n          If None, then the report is not written to a file.\n\n        :returns: The generated report.\n        \"\"\"\n\n        rpt = IncomeStatement(self, start, end, component_path, output_path)\n        return rpt.render(format)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates a path relative to the specified module file.", "response": "def get_path_relative_to_module(module_file_path, relative_target_path):\n    \"\"\"\n    Calculate a path relative to the specified module file.\n\n    :param module_file_path: The file path to the module.\n    \"\"\"\n    module_path = os.path.dirname(module_file_path)\n    path = os.path.join(module_path, relative_target_path)\n    path = os.path.abspath(path)\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_date(date):\n    if type(date) is str:\n        return datetime.strptime(date, '%Y-%m-%d').date()\n    else:\n        return date", "response": "Get the date from a value that could be a date object or a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the friction factor of turbulent flow in a rough duct.", "response": "def f_tr_Haaland(Re_D, \u025b, D, warn=True):\n    \"\"\"\n    Calculate the friction factor of turbulent flow (t) in a rough duct (r) for\n    the provided conditions with Haaland's equation.\n\n    :param Re_D: Reynolds number for the specified hydraulic diameter.\n    :param \u025b: [m] Surface roughness.\n    :param D: [m] Duct hydraulic diameter.\n    :return: Friction factor.\n\n    Source: lienhard2018, Eq. 7.50.\n    \"\"\"\n    if warn:\n        try:\n            if (\u025b / D) < 0.0 or (\u025b / D) > 0.05:\n                raise Warning(\n                    f\"\u025b/D '{\u025b / D:.3e}' out of range 0.0 <= \u025b/D <= 0.05.\")\n        except Warning as w:\n            ex_type, ex_value, ex_traceback = sys.exc_info()\n            print(color_warn(\"WARNING: \"), ex_value)\n\n        try:\n            if Re_D < 4000.0 or Re_D > 1.0E8:\n                raise Warning(\n                    f\"Reynolds number '{Re_D:.3e}' out of range \"\n                    \"4000 <= Re_D <= 1E8.\")\n        except Warning as w:\n            ex_type, ex_value, ex_traceback = sys.exc_info()\n            print(color_warn(\"WARNING: \"), ex_value)\n\n    return 1 / (1.8 * log10((6.9 / Re_D) + (\u025b / D / 3.7)**1.11))**2"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the local Nusselt number.", "response": "def Nu_x(self, L, theta, Ts, **statef):\n        \"\"\"\n        Calculate the local Nusselt number.\n\n        :param L: [m] characteristic length of the heat transfer surface\n        :param theta: [\u00b0] angle of the surface with the vertical\n        :param Ts: [K] heat transfer surface temperature\n        :param Tf: [K] bulk fluid temperature\n\n        :returns: float\n        \"\"\"\n\n        Tf = statef['T']\n        thetar = radians(theta)\n\n        if self._isgas:\n            self.Tr = Ts - 0.38 * (Ts - Tf)\n            beta = self._fluid.beta(T=Tf)\n        else:  # for liquids\n            self.Tr = Ts - 0.5 * (Ts - Tf)\n            beta = self._fluid.beta(T=self.Tr)\n\n        if Ts > Tf:  # hot surface\n            if 0.0 < theta < 45.0:\n                g = const.g*cos(thetar)\n            else:\n                g = const.g\n        else:  # cold surface\n            if -45.0 < theta < 0.0:\n                g = const.g*cos(thetar)\n            else:\n                g = const.g\n\n        nu = self._fluid.nu(T=self.Tr)\n        alpha = self._fluid.alpha(T=self.Tr)\n\n        Gr = dq.Gr(L, Ts, Tf, beta, nu, g)\n        Pr = dq.Pr(nu, alpha)\n        Ra = Gr * Pr\n\n        eq = [self.equation_dict[r]\n              for r in self.regions if r.contains_point(theta, Ra)][0]\n\n        return eq(self, Ra, Pr)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the average Nusselt number.", "response": "def Nu_L(self, L, theta, Ts, **statef):\n        \"\"\"\n        Calculate the average Nusselt number.\n\n        :param L: [m] characteristic length of the heat transfer surface\n        :param theta: [\u00b0] angle of the surface with the vertical\n        :param Ts: [K] heat transfer surface temperature\n        :param **statef: [K] bulk fluid temperature\n\n        :returns: float\n        \"\"\"\n\n        return self.Nu_x(L, theta, Ts, **statef) / 0.75"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the local heat transfer coefficient.", "response": "def h_x(self, L, theta, Ts, **statef):\n        \"\"\"\n        Calculate the local heat transfer coefficient.\n\n        :param L: [m] characteristic length of the heat transfer surface\n        :param theta: [\u00b0] angle of the surface with the vertical\n        :param Ts: [K] heat transfer surface temperature\n        :param Tf: [K] bulk fluid temperature\n\n        :returns: [W/m2/K] float\n        \"\"\"\n\n        Nu_x = self.Nu_x(L, theta, Ts, **statef)\n        k = self._fluid.k(T=self.Tr)\n        return Nu_x * k / L"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef h_L(self, L, theta, Ts, **statef):\n\n        Nu_L = self.Nu_L(L, theta, Ts, **statef)\n        k = self._fluid.k(T=self.Tr)\n        return Nu_L * k / L", "response": "Calculates the average heat transfer coefficient."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npreparing the lines read from the text file before starting to process it.", "response": "def _prepare_lines(self, lines):\n        \"\"\"\n        Prepare the lines read from the text file before starting to process\n        it.\n        \"\"\"\n\n        result = list()\n        for line in lines:\n            # Remove all whitespace characters (e.g. spaces, line breaks, etc.)\n            # from the start and end of the line.\n            line = line.strip()\n            # Replace all tabs with spaces.\n            line = line.replace(\"\\t\", \" \")\n            # Replace all repeating spaces with a single space.\n            while line.find(\"  \") > -1:\n                line = line.replace(\"  \", \" \")\n            result.append(line)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_assay(self, name, solid_density, H2O_fraction, assay):\n\n        if not type(solid_density) is float:\n            raise Exception(\"Invalid solid density. It must be a float.\")\n        self.solid_densities[name] = solid_density\n\n        if not type(H2O_fraction) is float:\n            raise Exception(\"Invalid H2O fraction. It must be a float.\")\n        self.H2O_fractions[name] = H2O_fraction\n\n        if not type(assay) is numpy.ndarray:\n            raise Exception(\"Invalid assay. It must be a numpy array.\")\n        elif not assay.shape == (self.size_class_count,):\n            raise Exception(\n                \"Invalid assay: It must have the same number of elements as \"\n                \"the material has size classes.\")\n        elif name in self.assays.keys():\n            raise Exception(\n                \"Invalid assay: An assay with that name already exists.\")\n        self.assays[name] = assay", "response": "Adds an assay to the material."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a MaterialPackage based on the specified parameters.", "response": "def create_package(self, assay=None, mass=0.0, normalise=True):\n        \"\"\"\n        Create a MaterialPackage based on the specified parameters.\n\n        :param assay: The name of the assay based on which the package\n          must be created.\n        :param mass: [kg] The mass of the package.\n        :param normalise: Indicates whether the assay must be normalised\n          before creating the package.\n\n        :returns: The created MaterialPackage.\n        \"\"\"\n\n        if assay is None:\n            return MaterialPackage(self, 1.0, 0.0, self.create_empty_assay())\n\n        if normalise:\n            assay_total = self.get_assay_total(assay)\n            if assay_total == 0.0:\n                assay_total = 1.0\n        else:\n            assay_total = 1.0\n        H2O_mass = mass * self.H2O_fractions[assay]\n        solid_mass = mass - H2O_mass\n        return MaterialPackage(self,\n                               self.solid_densities[assay],\n                               H2O_mass,\n                               solid_mass * self.assays[assay] / assay_total)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks whether the value is a tuple of the required format.", "response": "def _is_size_class_mass_tuple(self, value):\n        \"\"\"\n        Determines whether value is a tuple of the format\n        (size class(float), mass(float)).\n\n        :param value: The value to check.\n\n        :returns: Whether the value is a tuple in the required format.\n        \"\"\"\n\n        if not type(value) is tuple:\n            return False\n        elif not len(value) == 2:\n            return False\n        elif not type(value[0]) is float:\n            return False\n        elif not type(value[1]) is float and \\\n                not type(value[1]) is numpy.float64 and \\\n                not type(value[1]) is numpy.float32:\n            return False\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clone(self):\n\n        result = copy.copy(self)\n        result.size_class_masses = copy.deepcopy(self.size_class_masses)\n        return result", "response": "Create a complete copy of self."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclear the internal state of the internal memory.", "response": "def clear(self):\n        \"\"\"\n        Set all the size class masses and H20_mass in the package to zero\n        and the solid_density to 1.0\n        \"\"\"\n\n        self.solid_density = 1.0\n        self.H2O_mass = 0.0\n        self.size_class_masses = self.size_class_masses * 0.0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a template file for a data set.", "response": "def create_template(material, path, show=False):\n        \"\"\"\n        Create a template csv file for a data set.\n\n        :param material: the name of the material\n        :param path: the path of the directory where the file must be written\n        :param show: a boolean indicating whether the created file should be \\\n        displayed after creation\n        \"\"\"\n        file_name = 'dataset-%s.csv' % material.lower()\n        file_path = os.path.join(path, file_name)\n\n        with open(file_path, 'w', newline='') as csvfile:\n            writer = csv.writer(csvfile, delimiter=',',\n                                quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n            writer.writerow(['Name', material])\n            writer.writerow(['Description', '<Add a data set description '\n                                            'here.>'])\n            writer.writerow(['Reference', '<Add a reference to the source of '\n                                          'the data set here.>'])\n            writer.writerow(['Temperature', '<parameter 1 name>',\n                            '<parameter 2 name>', '<parameter 3 name>'])\n            writer.writerow(['T', '<parameter 1 display symbol>',\n                             '<parameter 2 display symbol>',\n                             '<parameter 3 display symbol>'])\n            writer.writerow(['K', '<parameter 1 units>',\n                             '<parameter 2 units>', '<parameter 3 units>'])\n            writer.writerow(['T', '<parameter 1 symbol>',\n                             '<parameter 2 symbol>', '<parameter 3 symbol>'])\n            for i in range(10):\n                writer.writerow([100.0 + i*50, float(i), 10.0 + i, 100.0 + i])\n\n        if show is True:\n            webbrowser.open_new(file_path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbase calculate method for models. Validates the material state parameter s. raises a ValidationError if the state parameter is invalid.", "response": "def calculate(self, **state):\n        \"\"\"\n        Base calculate method for models.\n        Validates the material state parameter(s).\n\n        :param **state: The material state\n        \"\"\"\n        if not self.state_validator.validate(state):\n            msg = f\"{self.material} {self.property} model. The state \"\n            msg += f\"description ({state}) contains errors:\"\n            for key, value in self.state_validator.errors.items():\n                msg += ' %s: %s;' % (key, value)\n            msg = msg[0:-1]+'.'\n            raise ValidationError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(self, endpoint, data, url_data=None, parameters=None):\n        return self.request_handler.request(\n            self._url(endpoint, url_data, parameters),\n            method=Api._method['delete'],\n            body=urllib.urlencode(data)\n        )", "response": "Returns the response and body for a DELETE request"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the response and body for a head request", "response": "def head(self, endpoint, url_data=None, parameters=None):\n        \"\"\"Returns the response and body for a head request\n            endpoints = 'users'  # resource to access\n            url_data = {}, ()  # Used to modularize endpoints, see __init__\n            parameters = {}, ((),()) # URL paramters, ex: google.com?q=a&f=b\n        \"\"\"\n        return self.request_handler.request(\n            self._url(endpoint, url_data, parameters),\n            method=Api._method['head']\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates the URL on the modularized endpoints and url parameters", "response": "def _url(self, endpoint, url_data=None, parameters=None):\n        \"\"\"Generate URL on the modularized endpoints and url parameters\"\"\"\n        try:\n            url = '%s/%s' % (self.base_url, self.endpoints[endpoint])\n        except KeyError:\n            raise EndPointDoesNotExist(endpoint)\n        if url_data:\n            url = url % url_data\n        if parameters:\n            # url = url?key=value&key=value&key=value...\n            url = '%s?%s' % (url, urllib.urlencode(parameters, True))\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nuse to instantiate a regular HTTP request object", "response": "def _httplib2_init(username, password):\n        \"\"\"Used to instantiate a regular HTTP request object\"\"\"\n        obj = httplib2.Http()\n        if username and password:\n            obj.add_credentials(username, password)\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef calculate(self, **state):\n\n        T = state['T']\n        x = state['x']\n\n        # normalise mole fractions\n        x_total = sum(x.values())\n        x = {compound: x[compound]/x_total for compound in x.keys()}\n\n        xg = x.get('SiO2', .00) + x.get('P2O5', 0.0)\n        xm = x.get('CaO', 0.0) + x.get('MgO', 0.0) + x.get('Na2O', 0.0) + \\\n            x.get('K2O', 0.0) + 3.0*x.get('CaF2', 0.0) + x.get('FeO', 0.0) + \\\n            x.get('MnO', 0.0) + 2.0*x.get('TiO2', 0.0) + 2.0*x.get('ZrO2', 0.0)\n\n        xa = x.get('Al2O3', 0.0) + x.get('Fe2O3', 0.0) + x.get('B2O3', 0.0)\n\n        # Note 2*XFeO1.5 = XFe2O3\n\n        norm = 1.0 + x.get('CaF2', 0.0) + x.get('Fe2O3', 0.0) + \\\n            x.get('TiO2', 0.0) + x.get('ZrO2', 0.0)\n\n        xg_norm = xg / norm\n        xm_norm = xm / norm\n        xa_norm = xa / norm\n\n        alpha = xm_norm / (xm_norm + xa_norm)\n\n        B0 = 13.8 + 39.9355*alpha - 44.049*alpha**2.0\n        B1 = 30.481 - 117.1505*alpha + 129.9978*alpha**2.0\n        B2 = -40.9429 + 234.0846*alpha - 300.04*alpha**2.0\n        B3 = 60.7619 - 153.9276*alpha + 211.1616*alpha**2.0\n\n        B = B0 + B1*xg_norm + B2*xg_norm**2.0 + B3*xg_norm**3.0\n\n        A = exp(-0.2693*B - 11.6725)\n\n        result = A*T*exp(1000.0*B/T)  # [P]\n\n        return result / 10.0", "response": "Calculates the dynamic viscosity at the specified temperature and composition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating dynamic viscosity at the specified temperature and composition dictionary.", "response": "def calculate(self, **state):\n        \"\"\"\n        Calculate dynamic viscosity at the specified temperature and\n        composition:\n\n        :param T: [K] temperature\n        :param y: [mass fraction] composition dictionary , e.g. \\\n        {'SiO2': 0.25, 'CaO': 0.25, 'MgO': 0.25, 'FeO': 0.25}\n\n        :returns: [Pa.s] dynamic viscosity\n\n        The **state parameter contains the keyword argument(s) specified above\\\n        that are used to describe the state of the material.\n        \"\"\"\n\n        T = state['T']\n        y = state['y']\n        x = amount_fractions(y)\n        return super().calculate(T=T, x=x)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calculate(self, **state):\n\n        T = state['T']\n        x = state['x']\n\n        # create the slag constituent categories\n        compounds_sio2 = ['SiO2', 'PO2.5', 'TiO2', 'ZrO2']\n        compounds_cao = ['CaO', 'MgO', 'FeO1.5', 'FeO', 'MnO', 'BO1.5']\n        compounds_al2o3 = ['Al2O3']\n        compounds_caf2 = ['CaF2']\n        compounds_na2o = ['Na2O', 'K2O']\n        compounds_all = (compounds_sio2 + compounds_cao + compounds_al2o3 +\n                         compounds_caf2 + compounds_na2o)\n\n        # convert compounds with two cations to single cation equivalents\n        if 'P2O5' in x:\n            x['PO2.5'] = 2.0 * x['P2O5']\n        if 'Fe2O3' in x:\n            x['FeO1.5'] = 2.0 * x['Fe2O3']\n        if 'B2O3' in x:\n            x['BO1.5'] = 2.0 * x['B2O3']\n\n        # normalise mole fractions, use only compounds in compounds_all\n        x_total = sum([x.get(c, 0.0) for c in compounds_all])\n        x = {c: x.get(c, 0.0)/x_total for c in compounds_all}\n\n        # calculate the cateogry mole fractions\n        x1 = sum([x.get(c, 0.0) for c in compounds_sio2])\n        x2 = sum([x.get(c, 0.0) for c in compounds_cao])\n        x3 = sum([x.get(c, 0.0) for c in compounds_al2o3])\n        x4 = sum([x.get(c, 0.0) for c in compounds_caf2])\n        x5 = sum([x.get(c, 0.0) for c in compounds_na2o])\n\n        # TODO: Why is x1 not used? This looks suspicious.\n        A = exp(-17.51 + 1.73*x2 + 5.82*x4 + 7.02*x5 - 33.76*x3)\n        B = 31140.0 - 23896.0*x2 - 46356.0*x4 - 39159.0*x5 + 68833.0*x3\n\n        result = A*T*exp(B/T)  # [P]\n\n        return result / 10.0", "response": "Calculates the dynamic viscosity at the specified temperature and composition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the alpha value given the material state.", "response": "def alpha(self, **state):\n        \"\"\"\n        Calculate the alpha value given the material state.\n\n        :param **state: material state\n\n        :returns: float\n        \"\"\"\n\n        return self.k(**state) / self.rho(**state) / self.Cp(**state)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the mean atomic weight for the specified element mass fractions.", "response": "def _calc_a(self, y_C, y_H, y_O, y_N, y_S):\n        \"\"\"\n        Calculate the mean atomic weight for the specified element mass\n        fractions.\n        \n        :param y_C: Carbon mass fraction\n        :param y_H: Hydrogen mass fraction\n        :param y_O: Oxygen mass fraction\n        :param y_N: Nitrogen mass fraction\n        :param y_S: Sulphur mass fraction\n       \n        :returns: [kg/kmol] mean atomic weight\n\n        See equation at bottom of page 538 of Merrick1983a.\n        \"\"\"\n\n        return 1 / (y_C/mm(\"C\") + y_H/mm(\"H\") + y_O/mm(\"O\") + y_N/mm(\"N\") +\n                    y_S/mm(\"S\"))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calculate(self, **state):\n\n        T = state['T']\n        y_C = state['y_C']\n        y_H = state['y_H']\n        y_O = state['y_O']\n        y_N = state['y_N']\n        y_S = state['y_S']\n\n        a = self._calc_a(y_C, y_H, y_O, y_N, y_S) / 1000  # kg/mol\n        result = (R/a) * (380*self._calc_g0(380/T) + 3600*self._calc_g0(1800/T))\n        return result", "response": "Calculates the enthalpy at the specified temperature and composition\n        using equation 9 in Merrick1983b."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates an entity and add it to the list of entities.", "response": "def create_entity(self, name, gl_structure, description=None):\n        \"\"\"\n        Create an entity and add it to the model.\n\n        :param name: The entity name.\n        :param gl_structure: The entity's general ledger structure.\n        :param description: The entity description.\n\n        :returns: The created entity.\n        \"\"\"\n\n        new_entity = Entity(name, gl_structure, description=description)\n        self.entities.append(new_entity)\n        return new_entity"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove an entity from the model.", "response": "def remove_entity(self, name):\n        \"\"\"\n        Remove an entity from the model.\n\n        :param name: The name of the entity to remove.\n        \"\"\"\n\n        entity_to_remove = None\n        for e in self.entities:\n            if e.name == name:\n                entity_to_remove = e\n        if entity_to_remove is not None:\n            self.entities.remove(entity_to_remove)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prepare_to_run(self):\n\n        self.clock.reset()\n        for e in self.entities:\n            e.prepare_to_run(self.clock, self.period_count)", "response": "Prepare the model for execution."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an alphabetically sorted list of elements from the material s compounds.", "response": "def _create_element_list(self):\n        \"\"\"\n        Extract an alphabetically sorted list of elements from the\n        material's compounds.\n\n        :returns: Alphabetically sorted list of elements.\n        \"\"\"\n\n        element_set = stoich.elements(self.compounds)\n        return sorted(list(element_set))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds an assay to the material.", "response": "def add_assay(self, name, assay):\n        \"\"\"\n        Add an assay to the material.\n\n        :param name:  Assay name.\n        :param assay: Numpy array containing the compound mass fractions for\n          the assay. The sequence of the assay's elements must correspond to\n          the sequence of the material's compounds.\n        \"\"\"\n\n        if not type(assay) is numpy.ndarray:\n            raise Exception(\"Invalid assay. It must be a numpy array.\")\n        elif not assay.shape == (self.compound_count,):\n            raise Exception(\"Invalid assay: It must have the same number of \"\n                            \"elements as the material has compounds.\")\n        elif name in self.raw_assays.keys():\n            raise Exception(\"Invalid assay: An assay with that name already \"\n                            \"exists.\")\n        self.raw_assays[name] = assay\n        self.converted_assays[name] = assay"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a MaterialPackage object based on the specified parameters.", "response": "def create_package(self, assay=None, mass=0.0, P=1.0, T=25.0,\n                       normalise=True):\n        \"\"\"\n        Create a MaterialPackage based on the specified parameters.\n\n        :param assay:     Name of the assay to be used to create the package.\n        :param mass:      Package mass. [kg]\n        :param P:         Package pressure. [atm]\n        :param T:         Package temperature. [\u00b0C]\n        :param normalise: Indicates whether the assay must be normalised\n          before creating the package.\n\n        :returns: MaterialPackage object.\n        \"\"\"\n\n        if assay is None:\n            return MaterialPackage(self, self.create_empty_assay(), P, T)\n\n        if normalise:\n            assay_total = self.get_assay_total(assay)\n        else:\n            assay_total = 1.0\n\n        return MaterialPackage(self, mass * self.converted_assays[assay] /\n                               assay_total, P, T, self._isCoal(assay),\n                               self._get_HHV(assay))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_stream(self, assay=None, mfr=0.0, P=1.0, T=25.0,\n                      normalise=True):\n        \"\"\"\n        Create a MaterialStream based on the specified parameters.\n\n        :param assay: Name of the assay to be used to create the stream.\n        :param mfr: Stream mass flow rate. [kg/h]\n        :param P: Stream pressure. [atm]\n        :param T: Stream temperature. [\u00b0C]\n        :param normalise: Indicates whether the assay must be normalised\n        before creating the Stream.\n\n        :returns: MaterialStream object.\n        \"\"\"\n\n        if assay is None:\n            return MaterialStream(self, self.create_empty_assay(), P, T)\n\n        if normalise:\n            assay_total = self.get_assay_total(assay)\n        else:\n            assay_total = 1.0\n\n        return MaterialStream(self, mfr * self.converted_assays[assay] /\n                              assay_total, P, T, self._isCoal(assay),\n                              self._get_HHV(assay))", "response": "Create a MaterialStream based on the specified parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the enthalpy of the package at the specified temperature.", "response": "def _calculate_H(self, T):\n        \"\"\"\n        Calculate the enthalpy of the package at the specified temperature.\n\n        :param T: Temperature. [\u00b0C]\n\n        :returns: Enthalpy. [kWh]\n        \"\"\"\n\n        if self.isCoal:\n            return self._calculate_Hfr_coal(T)\n\n        H = 0.0\n        for compound in self.material.compounds:\n            index = self.material.get_compound_index(compound)\n            dH = thermo.H(compound, T, self._compound_masses[index])\n            H = H + dH\n        return H"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the enthalpy of the package at the specified temperature.", "response": "def _calculate_H_coal(self, T):\n        \"\"\"\n        Calculate the enthalpy of the package at the specified temperature, in\n        case the material is coal.\n\n        :param T: [\u00b0C] temperature\n\n        :returns: [kWh] enthalpy\n        \"\"\"\n\n        m_C = 0  # kg\n        m_H = 0  # kg\n        m_O = 0  # kg\n        m_N = 0  # kg\n        m_S = 0  # kg\n\n        H = 0.0  # kWh/h\n        for compound in self.material.compounds:\n            index = self.material.get_compound_index(compound)\n            if stoich.element_mass_fraction(compound, 'C') == 1.0:\n                m_C += self._compound_masses[index]\n            elif stoich.element_mass_fraction(compound, 'H') == 1.0:\n                m_H += self._compound_masses[index]\n            elif stoich.element_mass_fraction(compound, 'O') == 1.0:\n                m_O += self._compound_masses[index]\n            elif stoich.element_mass_fraction(compound, 'N') == 1.0:\n                m_N += self._compound_masses[index]\n            elif stoich.element_mass_fraction(compound, 'S') == 1.0:\n                m_S += self._compound_masses[index]\n            else:\n                dH = thermo.H(compound, T, self._compound_masses[index])\n                H += dH\n\n        m_total = y_C + y_H + y_O + y_N + y_S  # kg/h\n        y_C = m_C / m_total\n        y_H = m_H / m_total\n        y_O = m_O / m_total\n        y_N = m_N / m_total\n        y_S = m_S / m_total\n\n        hmodel = coals.DafHTy()\n        H = hmodel.calculate(T=T+273.15, y_C=y_C, y_H=y_H, y_O=y_O, y_N=y_N,\n                             y_S=y_S) / 3.6e6  # kWh/kg\n        H298 = hmodel.calculate(T=298.15, y_C=y_C, y_H=y_H, y_O=y_O, y_N=y_N,\n                                y_S=y_S) / 3.6e6  # kWh/kg\n        Hdaf = H - H298 + self._DH298  # kWh/kg\n        Hdaf *= m_total  # kWh\n\n        H += Hdaf\n\n        return H"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _calculate_T(self, H):\n\n        # Create the initial guesses for temperature.\n        x = list()\n        x.append(self._T)\n        x.append(self._T + 10.0)\n\n        # Evaluate the enthalpy for the initial guesses.\n        y = list()\n        y.append(self._calculate_H(x[0]) - H)\n        y.append(self._calculate_H(x[1]) - H)\n\n        # Solve for temperature.\n        for i in range(2, 50):\n            x.append(x[i-1] - y[i-1]*((x[i-1] - x[i-2])/(y[i-1] - y[i-2])))\n            y.append(self._calculate_H(x[i]) - H)\n            if abs(y[i-1]) < 1.0e-5:\n                break\n\n        return x[len(x) - 1]", "response": "Calculates the temperature of the package given the specified enthalpy."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine whether the value is a tuple of the format ( compound ( str", "response": "def _is_compound_mass_tuple(self, value):\n        \"\"\"\n        Determines whether value is a tuple of the format\n        (compound(str), mass(float)).\n\n        :param value: The value to be tested.\n\n        :returns: True or False\n        \"\"\"\n\n        if not type(value) is tuple:\n            return False\n        elif not len(value) == 2:\n            return False\n        elif not type(value[0]) is str:\n            return False\n        elif not type(value[1]) is float and \\\n                not type(value[1]) is numpy.float64 and \\\n                not type(value[1]) is numpy.float32:\n            return False\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef H(self, H):\n\n        self._H = H\n        self._T = self._calculate_T(H)", "response": "Sets the enthalpy of the package to the specified value and recalculate it s temperature."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef T(self, T):\n\n        self._T = T\n        self._H = self._calculate_H(T)", "response": "Sets the temperature of the package and recalculate it s enthalpy."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clone(self):\n\n        result = copy.copy(self)\n        result._compound_masses = copy.deepcopy(self._compound_masses)\n        return result", "response": "Create a complete copy of the package."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_compound_mass(self, compound):\n\n        if compound in self.material.compounds:\n            return self._compound_masses[\n                self.material.get_compound_index(compound)]\n        else:\n            return 0.0", "response": "Returns the mass of the specified compound in the package."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_compound_amounts(self):\n\n        result = self._compound_masses * 1.0\n        for compound in self.material.compounds:\n            index = self.material.get_compound_index(compound)\n            result[index] = stoich.amount(compound, result[index])\n        return result", "response": "Determine the mole amounts of all the compounds."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines the mole amount of the specified compound.", "response": "def get_compound_amount(self, compound):\n        \"\"\"\n        Determine the mole amount of the specified compound.\n\n        :returns: Amount. [kmol]\n        \"\"\"\n\n        index = self.material.get_compound_index(compound)\n        return stoich.amount(compound, self._compound_masses[index])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines the sum of mole amounts of all the compounds.", "response": "def amount(self):\n        \"\"\"\n        Determine the sum of mole amounts of all the compounds.\n\n        :returns: Amount. [kmol]\n        \"\"\"\n\n        return sum(self.get_compound_amount(c) for c in self.material.compounds)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the element masses of the elements in the package.", "response": "def get_element_masses(self, elements=None):\n        \"\"\"\n        Determine the masses of elements in the package.\n\n        :returns: Array of element masses. [kg]\n        \"\"\"\n\n        if elements is None:\n            elements = self.material.elements\n        result = numpy.zeros(len(elements))\n\n        for compound in self.material.compounds:\n            result += self.get_compound_mass(compound) *\\\n                numpy.array(stoich.element_mass_fractions(compound, elements))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the element symbols and masses of elements in the package and return as a dictionary.", "response": "def get_element_mass_dictionary(self):\n        \"\"\"\n        Determine the masses of elements in the package and return as a\n        dictionary.\n\n        :returns: Dictionary of element symbols and masses. [kg]\n        \"\"\"\n\n        element_symbols = self.material.elements\n        element_masses = self.get_element_masses()\n\n        return {s: m for s, m in zip(element_symbols, element_masses)}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetermine the mass of the specified elements in the package.", "response": "def get_element_mass(self, element):\n        \"\"\"\n        Determine the mass of the specified elements in the package.\n\n        :returns: Masses. [kg]\n        \"\"\"\n\n        result = numpy.zeros(1)\n        for compound in self.material.compounds:\n            result += self.get_compound_mass(compound) *\\\n                numpy.array(stoich.element_mass_fractions(compound, [element]))\n        return result[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract(self, other):\n\n        # Extract the specified mass.\n        if type(other) is float or \\\n           type(other) is numpy.float64 or \\\n           type(other) is numpy.float32:\n            return self._extract_mass(other)\n\n        # Extract the specified mass of the specified compound.\n        elif self._is_compound_mass_tuple(other):\n            return self._extract_compound_mass(other[0], other[1])\n\n        # Extract all of the specified compound.\n        elif type(other) is str:\n            return self._extract_compound(other)\n\n        # TODO: Test\n        # Extract all of the compounds of the specified material.\n        elif type(other) is Material:\n            return self._extract_material(other)\n\n        # If not one of the above, it must be an invalid argument.\n        else:\n            raise TypeError(\"Invalid extraction argument.\")", "response": "Extracts the material from this package modifying this package and returning the extracted material as a new package."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _calculate_Hfr(self, T):\n\n        if self.isCoal:\n            return self._calculate_Hfr_coal(T)\n\n        Hfr = 0.0\n        for compound in self.material.compounds:\n            index = self.material.get_compound_index(compound)\n            dHfr = thermo.H(compound, T, self._compound_mfrs[index])\n            Hfr = Hfr + dHfr\n        return Hfr", "response": "Calculates the enthalpy flow rate of the stream at the specified temperature."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the enthalpy of formation of the dry -ash - free ( daf ) component of the coal.", "response": "def _calculate_DH298_coal(self):\n        \"\"\"\n        Calculate the enthalpy of formation of the dry-ash-free (daf) component of the coal.\n\n        :returns: [kWh/kg daf] enthalpy of formation of daf coal\n        \"\"\"\n\n        m_C = 0  # kg\n        m_H = 0  # kg\n        m_O = 0  # kg\n        m_N = 0  # kg\n        m_S = 0  # kg\n\n        T = 25  # \u00b0C\n        Hin = 0.0  # kWh\n        for compound in self.material.compounds:\n            index = self.material.get_compound_index(compound)\n            formula = compound.split('[')[0]\n            if stoich.element_mass_fraction(formula, 'C') == 1.0:\n                m_C += self._compound_mfrs[index]\n                Hin += thermo.H(compound, T, self._compound_mfrs[index])\n            elif stoich.element_mass_fraction(formula, 'H') == 1.0:\n                m_H += self._compound_mfrs[index]\n                Hin += thermo.H(compound, T, self._compound_mfrs[index])\n            elif stoich.element_mass_fraction(formula, 'O') == 1.0:\n                m_O += self._compound_mfrs[index]\n                Hin += thermo.H(compound, T, self._compound_mfrs[index])\n            elif stoich.element_mass_fraction(formula, 'N') == 1.0:\n                m_N += self._compound_mfrs[index]\n                Hin += thermo.H(compound, T, self._compound_mfrs[index])\n            elif stoich.element_mass_fraction(formula, 'S') == 1.0:\n                m_S += self._compound_mfrs[index]\n                Hin += thermo.H(compound, T, self._compound_mfrs[index])\n\n        m_total = m_C + m_H + m_O + m_N + m_S  # kg\n\n        Hout = 0.0  # kWh\n        Hout += thermo.H('CO2[G]', T, cc(m_C, 'C', 'CO2', 'C'))\n        Hout += thermo.H('H2O[L]', T, cc(m_H, 'H', 'H2O', 'H'))\n        Hout += thermo.H('O2[G]', T, m_O)\n        Hout += thermo.H('N2[G]', T, m_N)\n        Hout += thermo.H('SO2[G]', T, cc(m_S, 'S', 'SO2', 'S'))\n        Hout /= m_total\n\n        if self.HHV is None:\n            # If no HHV is specified, calculate it from the proximate assay\n            # using C-H-O-N-S.\n            HHV = (Hout - Hin) / m_total  # kWh/kg daf\n        else:\n            # If an HHV is specified, convert it from MJ/kg coal to kWh/kg daf.\n            HHV = self.HHV / 3.6  # kWh/kg coal\n            HHV *= self.mfr / m_total  # kWh/kg daf\n\n        return HHV + Hout"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the enthalpy flow rate of the stream at the specified temperature.", "response": "def _calculate_Hfr_coal(self, T):\n        \"\"\"\n        Calculate the enthalpy flow rate of the stream at the specified\n        temperature, in the case of it being coal.\n\n        :param T: Temperature. [\u00b0C]\n\n        :returns: Enthalpy flow rate. [kWh/h]\n        \"\"\"\n\n        m_C = 0  # kg/h\n        m_H = 0  # kg/h\n        m_O = 0  # kg/h\n        m_N = 0  # kg/h\n        m_S = 0  # kg/h\n\n        Hfr = 0.0  # kWh/h\n        for compound in self.material.compounds:\n            index = self.material.get_compound_index(compound)\n            formula = compound.split('[')[0]\n            if stoich.element_mass_fraction(formula, 'C') == 1.0:\n                m_C += self._compound_mfrs[index]\n            elif stoich.element_mass_fraction(formula, 'H') == 1.0:\n                m_H += self._compound_mfrs[index]\n            elif stoich.element_mass_fraction(formula, 'O') == 1.0:\n                m_O += self._compound_mfrs[index]\n            elif stoich.element_mass_fraction(formula, 'N') == 1.0:\n                m_N += self._compound_mfrs[index]\n            elif stoich.element_mass_fraction(formula, 'S') == 1.0:\n                m_S += self._compound_mfrs[index]\n            else:\n                dHfr = thermo.H(compound, T, self._compound_mfrs[index])\n                Hfr += dHfr\n\n        m_total = m_C + m_H + m_O + m_N + m_S  # kg/h\n        y_C = m_C / m_total\n        y_H = m_H / m_total\n        y_O = m_O / m_total\n        y_N = m_N / m_total\n        y_S = m_S / m_total\n\n        hmodel = coals.DafHTy()\n        H = hmodel.calculate(T=T+273.15, y_C=y_C, y_H=y_H, y_O=y_O, y_N=y_N,\n                             y_S=y_S) / 3.6e6  # kWh/kg\n        H298 = hmodel.calculate(T=298.15, y_C=y_C, y_H=y_H, y_O=y_O, y_N=y_N,\n                                y_S=y_S) / 3.6e6  # kWh/kg\n        Hdaf = H - H298 + self._DH298  # kWh/kg\n        Hdaf *= m_total  # kWh/h\n\n        Hfr += Hdaf\n\n        return Hfr"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the temperature of the stream given the specified enthalpy flow rate.", "response": "def _calculate_T(self, Hfr):\n        \"\"\"\n        Calculate the temperature of the stream given the specified\n        enthalpy flow rate using a secant algorithm.\n\n        :param H: Enthalpy flow rate. [kWh/h]\n\n        :returns: Temperature. [\u00b0C]\n        \"\"\"\n\n        # Create the initial guesses for temperature.\n        x = list()\n        x.append(self._T)\n        x.append(self._T + 10.0)\n\n        # Evaluate the enthalpy for the initial guesses.\n        y = list()\n        y.append(self._calculate_Hfr(x[0]) - Hfr)\n        y.append(self._calculate_Hfr(x[1]) - Hfr)\n\n        # Solve for temperature.\n        for i in range(2, 50):\n            x.append(x[i-1] - y[i-1]*((x[i-1] - x[i-2])/(y[i-1] - y[i-2])))\n            y.append(self._calculate_Hfr(x[i]) - Hfr)\n            if abs(y[i-1]) < 1.0e-5:\n                break\n\n        return x[len(x) - 1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines whether the value is a tuple of the format mfr_temperature tuple.", "response": "def _is_compound_mfr_temperature_tuple(self, value):\n        \"\"\"Determines whether value is a tuple of the format\n        (compound(str), mfr(float), temperature(float)).\n\n        :param value: The value to be tested.\n\n        :returns: True or False\"\"\"\n\n        if not type(value) is tuple:\n            return False\n        elif not len(value) == 3:\n            return False\n        elif not type(value[0]) is str:\n            return False\n        elif not type(value[1]) is float and \\\n                not type(value[1]) is numpy.float64 and \\\n                not type(value[1]) is numpy.float32:\n            return False\n        elif not type(value[1]) is float and \\\n                not type(value[1]) is numpy.float64 and \\\n                not type(value[1]) is numpy.float32:\n            return False\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the enthalpy flow rate of the stream to the specified value and recalculate it s temperature.", "response": "def Hfr(self, Hfr):\n        \"\"\"\n        Set the enthalpy flow rate of the stream to the specified value, and\n        recalculate it's temperature.\n\n        :param H: The new enthalpy flow rate value. [kWh/h]\n        \"\"\"\n\n        self._Hfr = Hfr\n        self._T = self._calculate_T(Hfr)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef T(self, T):\n\n        self._T = T\n        self._Hfr = self._calculate_Hfr(T)", "response": "Sets the temperature of the stream to the specified value and recalculate it s enthalpy."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef HHV(self, HHV):\n\n        self._HHV = HHV  # MJ/kg coal\n        if self.isCoal:\n            self._DH298 = self._calculate_DH298_coal()", "response": "Sets the higher heating value of the stream to the specified value and recalculate the formation enthalpy of the daf coal."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a complete copy of the stream.", "response": "def clone(self):\n        \"\"\"Create a complete copy of the stream.\n\n        :returns: A new MaterialStream object.\"\"\"\n\n        result = copy.copy(self)\n        result._compound_mfrs = copy.deepcopy(self._compound_mfrs)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_compound_mfr(self, compound):\n\n        if compound in self.material.compounds:\n            return self._compound_mfrs[\n                self.material.get_compound_index(compound)]\n        else:\n            return 0.0", "response": "Determines the mass flow rate of a compound in the stream."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine the amount flow rates of all the compounds.", "response": "def get_compound_afrs(self):\n        \"\"\"\n        Determine the amount flow rates of all the compounds.\n\n        :returns: List of amount flow rates. [kmol/h]\n        \"\"\"\n\n        result = self._compound_mfrs * 1.0\n        for compound in self.material.compounds:\n            index = self.material.get_compound_index(compound)\n            result[index] = stoich.amount(compound, result[index])\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining the amount flow rate of the specified compound.", "response": "def get_compound_afr(self, compound):\n        \"\"\"\n        Determine the amount flow rate of the specified compound.\n\n        :returns: Amount flow rate. [kmol/h]\n        \"\"\"\n\n        index = self.material.get_compound_index(compound)\n        return stoich.amount(compound, self._compound_mfrs[index])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef afr(self):\n\n        result = 0.0\n        for compound in self.material.compounds:\n            result += self.get_compound_afr(compound)\n        return result", "response": "Determines the sum of amount flow rates of all the compounds."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the mass flow rates of elements in the stream.", "response": "def get_element_mfrs(self, elements=None):\n        \"\"\"\n        Determine the mass flow rates of elements in the stream.\n\n        :returns: Array of element mass flow rates. [kg/h]\n        \"\"\"\n\n        if elements is None:\n            elements = self.material.elements\n        result = numpy.zeros(len(elements))\n        for compound in self.material.compounds:\n            result += self.get_compound_mfr(compound) *\\\n                stoich.element_mass_fractions(compound, elements)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the mass flow rates of elements in the stream and return as a dictionary.", "response": "def get_element_mfr_dictionary(self):\n        \"\"\"\n        Determine the mass flow rates of elements in the stream and return as\n        a dictionary.\n\n        :returns: Dictionary of element symbols and mass flow rates. [kg/h]\n        \"\"\"\n\n        element_symbols = self.material.elements\n        element_mfrs = self.get_element_mfrs()\n        result = dict()\n        for s, mfr in zip(element_symbols, element_mfrs):\n            result[s] = mfr\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetermines the mass flow rate of the specified elements in the stream.", "response": "def get_element_mfr(self, element):\n        \"\"\"\n        Determine the mass flow rate of the specified elements in the stream.\n\n        :returns: Mass flow rates. [kg/h]\n        \"\"\"\n\n        result = 0.0\n        for compound in self.material.compounds:\n            formula = compound.split('[')[0]\n            result += self.get_compound_mfr(compound) *\\\n                stoich.element_mass_fraction(formula, element)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting the other from this stream modifying this stream and returning the new stream.", "response": "def extract(self, other):\n        \"\"\"\n        Extract 'other' from this stream, modifying this stream and returning\n        the extracted material as a new stream.\n\n        :param other: Can be one of the following:\n\n          * float: A mass flow rate equal to other is extracted from self. Self\n            is reduced by other and the extracted stream is returned as\n            a new stream.\n          * tuple (compound, mass): The other tuple specifies the mass flow\n            rate of a compound to be extracted. It is extracted from self and\n            the extracted mass flow rate is returned as a new stream.\n          * string: The 'other' string specifies the compound to be\n            extracted. All of the mass flow rate of that compound will be\n            removed from self and a new stream created with it.\n          * Material: The 'other' material specifies the list of\n            compounds to extract.\n\n\n        :returns: New MaterialStream object.\n        \"\"\"\n\n        # Extract the specified mass flow rate.\n        if type(other) is float or \\\n           type(other) is numpy.float64 or \\\n           type(other) is numpy.float32:\n            return self._extract_mfr(other)\n\n        # Extract the specified mass flow rateof the specified compound.\n        elif self._is_compound_mfr_tuple(other):\n            return self._extract_compound_mfr(other[0], other[1])\n\n        # Extract all of the specified compound.\n        elif type(other) is str:\n            return self._extract_compound(other)\n\n        # TODO: Test\n        # Extract all of the compounds of the specified material.\n        elif type(other) is Material:\n            return self._extract_material(other)\n\n        # If not one of the above, it must be an invalid argument.\n        else:\n            raise TypeError(\"Invalid extraction argument.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Gr(L: float, Ts: float, Tf: float, beta: float, nu: float, g: float):\n\n    return g * beta * (Ts - Tf) * L**3.0 / nu**2.0", "response": "Calculates the Grashof number."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the Reynolds number.", "response": "def Re(L: float, v: float, nu: float) -> float:\n    \"\"\"\n    Calculate the Reynolds number.\n\n    :param L: [m] surface characteristic length.\n    :param v: [m/s] fluid velocity relative to the object.\n    :param nu: [m2/s] fluid kinematic viscosity.\n\n    :returns: float\n    \"\"\"\n\n    return v * L / nu"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the Ralleigh number.", "response": "def Ra(L: float, Ts: float, Tf: float, alpha: float, beta: float, nu: float\n       ) -> float:\n    \"\"\"\n    Calculate the Ralleigh number.\n\n    :param L: [m] heat transfer surface characteristic length.\n    :param Ts: [K] heat transfer surface temperature.\n    :param Tf: [K] bulk fluid temperature.\n    :param alpha: [m2/s] fluid thermal diffusivity.\n    :param beta: [1/K] fluid coefficient of thermal expansion.\n    :param nu: [m2/s] fluid kinematic viscosity.\n\n    :returns: float\n\n    Ra = Gr*Pr\n\n    Characteristic dimensions:\n        * vertical plate: vertical length\n        * pipe: diameter\n        * bluff body: diameter\n    \"\"\"\n\n    return g * beta * (Ts - Tinf) * L**3.0 / (nu * alpha)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the Nusselt number.", "response": "def Nu(L: float, h: float, k: float) -> float:\n    \"\"\"\n    Calculate the Nusselt number.\n\n    :param L: [m] heat transfer surface characteristic length.\n    :param h: [W/K/m2] convective heat transfer coefficient.\n    :param k: [W/K/m] fluid thermal conductivity.\n\n    :returns: float\n    \"\"\"\n\n    return h * L / k"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Sh(L: float, h: float, D: float) -> float:\n\n    return h * L / D", "response": "Calculates the Sherwood number."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new PolynomialModelT object from the data set for the specified by the supplied symbol and the specified polynomial degree.", "response": "def create(dataset, symbol, degree):\n        \"\"\"\n        Create a model object from the data set for the property specified by\n        the supplied symbol, using the specified polynomial degree.\n\n        :param dataset: a DataSet object\n        :param symbol: the symbol of the property to be described, e.g. 'rho'\n        :param degree: the polynomial degree to use\n\n        :returns: a new PolynomialModelT object\n        \"\"\"\n\n        x_vals = dataset.data['T'].tolist()\n        y_vals = dataset.data[symbol].tolist()\n        coeffs = np.polyfit(x_vals, y_vals, degree)\n\n        result = PolynomialModelT(dataset.material,\n                                  dataset.names_dict[symbol],\n                                  symbol, dataset.display_symbols_dict[symbol],\n                                  dataset.units_dict[symbol],\n                                  None, [dataset.name], coeffs)\n\n        result.state_schema['T']['min'] = float(min(x_vals))\n        result.state_schema['T']['max'] = float(max(x_vals))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef calculate(self, **state):\n        super().calculate(**state)\n        return np.polyval(self._coeffs, state['T'])", "response": "Calculates the material physical property at the specified temperature in the units specified by the object s property_units property."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prepare_to_run(self, clock, period_count):\n\n        if self.start_period_ix == -1 and self.start_datetime != datetime.min:\n            # Set the Start period index\n            for i in range(0, period_count):\n                if clock.get_datetime_at_period_ix(i) > self.start_datetime:\n                    self.start_period_ix = i\n                    break\n        if self.start_period_ix == -1:\n            self.start_period_ix = 0\n        if self.period_count == -1 and self.end_datetime != datetime.max:\n            # Set the Start date\n            for i in range(0, period_count):\n                if clock.get_datetime_at_period_ix(i) > self.end_datetime:\n                    self.period_count = i - self.start_period_ix\n                    break\n        if self.period_count != -1:\n            self.end_period_ix = self.start_period_ix + self.period_count\n        else:\n            self.end_period_ix = self.start_period_ix + period_count", "response": "This method is called by the activity manager to prepare the activity for execution."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_component(self, name, description=None):\n\n        new_comp = Component(name, self.gl, description=description)\n        new_comp.set_parent_path(self.path)\n        self.components.append(new_comp)\n        return new_comp", "response": "Create a new sub component in the business component."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_component(self, name):\n\n        component_to_remove = None\n        for c in self.components:\n            if c.name == name:\n                component_to_remove = c\n        if component_to_remove is not None:\n            self.components.remove(component_to_remove)", "response": "Removes a sub component from the component list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_component(self, name):\n\n        return [c for c in self.components if c.name == name][0]", "response": "Retrieve a child component given its name."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds an activity to the component.", "response": "def add_activity(self, activity):\n        \"\"\"\n        Add an activity to the component.\n\n        :param activity: The activity.\n        \"\"\"\n\n        self.gl.structure.validate_account_names(\n            activity.get_referenced_accounts())\n        self.activities.append(activity)\n        activity.set_parent_path(self.path)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_activity(self, name):\n\n        return [a for a in self.activities if a.name == name][0]", "response": "Retrieve an activity given its name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npreparing the component and activity for execution.", "response": "def prepare_to_run(self, clock, period_count):\n        \"\"\"\n        Prepare the component for execution.\n\n        :param clock: The clock containing the execution start time and\n          execution period information.\n        :param period_count: The total amount of periods this activity will be\n          requested to be run for.\n        \"\"\"\n\n        for c in self.components:\n            c.prepare_to_run(clock, period_count)\n        for a in self.activities:\n            a.prepare_to_run(clock, period_count)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self, clock, generalLedger):\n\n        for c in self.components:\n            c.run(clock, generalLedger)\n        for a in self.activities:\n            a.run(clock, generalLedger)", "response": "Execute the component at the current clock cycle."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprepares the activity for execution.", "response": "def prepare_to_run(self, clock, period_count):\n        \"\"\"\n        Prepare the entity for execution.\n\n        :param clock: The clock containing the execution start time and\n          execution period information.\n        :param period_count: The total amount of periods this activity will be\n          requested to be run for.\n        \"\"\"\n\n        self.period_count = period_count\n\n        self._exec_year_end_datetime = clock.get_datetime_at_period_ix(\n            period_count)\n        self._prev_year_end_datetime = clock.start_datetime\n        self._curr_year_end_datetime = clock.start_datetime + relativedelta(\n            years=1)\n\n        # Remove all the transactions\n        del self.gl.transactions[:]\n\n        for c in self.components:\n            c.prepare_to_run(clock, period_count)\n\n        self.negative_income_tax_total = 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes the entity at the current clock cycle.", "response": "def run(self, clock):\n        \"\"\"\n        Execute the entity at the current clock cycle.\n\n        :param clock: The clock containing the current execution time and\n          period information.\n        \"\"\"\n\n        if clock.timestep_ix >= self.period_count:\n            return\n\n        for c in self.components:\n            c.run(clock, self.gl)\n\n        self._perform_year_end_procedure(clock)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating group counts with multiplier", "response": "def count_with_multiplier(groups, multiplier):\n    \"\"\" Update group counts with multiplier\n\n    This is for handling atom counts on groups like (OH)2\n\n    :param groups: iterable of Group/Element\n    :param multiplier: the number to multiply by\n\n    \"\"\"\n    counts = collections.defaultdict(float)\n    for group in groups:\n        for element, count in group.count().items():\n            counts[element] += count*multiplier\n    return counts"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef amounts(masses):\n\n    return {compound: amount(compound, masses[compound])\n            for compound in masses.keys()}", "response": "Calculate the amounts from the specified masses."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the mole fractions from the specified masses.", "response": "def amount_fractions(masses):\n    \"\"\"\n    Calculate the mole fractions from the specified compound masses.\n\n    :param masses: [kg] dictionary, e.g. {'SiO2': 3.0, 'FeO': 1.5}\n\n    :returns: [mole fractions] dictionary\n    \"\"\"\n\n    n = amounts(masses)\n    n_total = sum(n.values())\n    return {compound: n[compound]/n_total for compound in n.keys()}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef masses(amounts):\n\n    return {compound: mass(compound, amounts[compound])\n            for compound in amounts.keys()}", "response": "Calculate the masses from the specified amounts."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mass_fractions(amounts):\n\n    m = masses(amounts)\n    m_total = sum(m.values())\n    return {compound: m[compound]/m_total for compound in m.keys()}", "response": "Calculate the mole fractions from the specified compound amounts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting the specified mass of the source compound to the specified mass of the target compound.", "response": "def convert_compound(mass, source, target, element):\n    \"\"\"\n    Convert the specified mass of the source compound to the target using\n    element as basis.\n\n    :param mass: Mass of from_compound. [kg]\n    :param source: Formula and phase of the original compound, e.g.\n      'Fe2O3[S1]'.\n    :param target: Formula and phase of the target compound, e.g. 'Fe[S1]'.\n    :param element: Element to use as basis for the conversion, e.g. 'Fe' or\n      'O'.\n\n    :returns: Mass of target. [kg]\n    \"\"\"\n\n    # Perform the conversion.\n    target_mass_fraction = element_mass_fraction(target, element)\n    if target_mass_fraction == 0.0:\n        # If target_formula does not contain element, just return 0.0.\n        return 0.0\n    else:\n        source_mass_fraction = element_mass_fraction(source, element)\n        return mass * source_mass_fraction / target_mass_fraction"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef element_mass_fraction(compound, element):\n\n    coeff = stoichiometry_coefficient(compound, element)\n\n    if coeff == 0.0:\n        return 0.0\n\n    formula_mass = molar_mass(compound)\n    element_mass = molar_mass(element)\n    return coeff * element_mass / formula_mass", "response": "Determines the mass fraction of an element in a chemical compound."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetermine the set of elements present in a list of chemical compounds.", "response": "def elements(compounds):\n    \"\"\"\n    Determine the set of elements present in a list of chemical compounds.\n\n    The list of elements is sorted alphabetically.\n\n    :param compounds: List of compound formulas and phases, e.g.\n      ['Fe2O3[S1]', 'Al2O3[S1]'].\n\n    :returns: List of elements.\n    \"\"\"\n\n    elementlist = [parse_compound(compound).count().keys()\n                   for compound in compounds]\n    return set().union(*elementlist)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef molar_mass(compound=''):\n\n    result = 0.0\n    if compound is None or len(compound) == 0:\n        return result\n\n    compound = compound.strip()\n\n    parsed = parse_compound(compound)\n\n    return parsed.molar_mass()", "response": "Determines the molar mass of a chemical compound."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining the stoichiometry coefficient of an element in a chemical compound.", "response": "def stoichiometry_coefficient(compound, element):\n    \"\"\"\n    Determine the stoichiometry coefficient of an element in a chemical\n    compound.\n\n    :param compound: Formula of a chemical compound, e.g. 'SiO2'.\n    :param element:  Element, e.g. 'Si'.\n\n    :returns: Stoichiometry coefficient.\n    \"\"\"\n\n    stoichiometry = parse_compound(compound.strip()).count()\n\n    return stoichiometry[element]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stoichiometry_coefficients(compound, elements):\n\n    stoichiometry = parse_compound(compound.strip()).count()\n\n    return [stoichiometry[element] for element in elements]", "response": "Determines the stoichiometry coefficients of the specified elements in\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd an assay to the material.", "response": "def add_assay(self, name, assay):\n        \"\"\"\n        Add an assay to the material.\n\n        :param name: The name of the new assay.\n        :param assay: A numpy array containing the size class mass fractions\n          for the assay. The sequence of the assay's elements must correspond\n          to the sequence of the material's size classes.\n        \"\"\"\n\n        if not type(assay) is numpy.ndarray:\n            raise Exception(\"Invalid assay. It must be a numpy array.\")\n        elif not assay.shape == (self.size_class_count,):\n            raise Exception(\n                \"Invalid assay: It must have the same number of elements \"\n                \"as the material has size classes.\")\n        elif name in self.assays.keys():\n            raise Exception(\n                \"Invalid assay: An assay with that name already exists.\")\n        self.assays[name] = assay"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a MaterialPackage based on the specified parameters.", "response": "def create_package(self, assay=None, mass=0.0, normalise=True):\n        \"\"\"\n        Create a MaterialPackage based on the specified parameters.\n\n        :param assay: The name of the assay based on which the package must be\n          created.\n        :param mass: [kg] The mass of the package.\n        :param normalise: Indicates whether the assay must be normalised before\n          creating the package.\n\n        :returns: The created MaterialPackage.\n        \"\"\"\n\n        if assay is None:\n            return MaterialPackage(self, self.create_empty_assay())\n\n        if normalise:\n            assay_total = self.get_assay_total(assay)\n        else:\n            assay_total = 1.0\n        return MaterialPackage(self, mass * self.assays[assay] / assay_total)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract 'other' from self, modifying self and returning the extracted material as a new package. :param other: Can be one of the following: * float: A mass equal to other is extracted from self. Self is reduced by other and the extracted package is returned as a new package. * tuple (size class, mass): The other tuple specifies the mass of a size class to be extracted. It is extracted from self and the extracted mass is returned as a new package. * string: The 'other' string specifies the size class to be extracted. All of the mass of that size class will be removed from self and a new package created with it. :returns: A new material package containing the material that was extracted from self.", "response": "def extract(self, other):\n        \"\"\"\n        Extract 'other' from self, modifying self and returning the extracted\n        material as a new package.\n\n        :param other: Can be one of the following:\n\n          * float: A mass equal to other is extracted from self. Self is\n            reduced by other and the extracted package is returned as a new\n            package.\n          * tuple (size class, mass): The other tuple specifies the mass\n            of a size class to be extracted. It is extracted from self and\n            the extracted mass is returned as a new package.\n          * string: The 'other' string specifies the size class to be\n            extracted. All of the mass of that size class will be removed\n            from self and a new package created with it.\n\n\n        :returns: A new material package containing the material that was\n          extracted from self.\n        \"\"\"\n\n        # Extract the specified mass.\n        if type(other) is float or \\\n                type(other) is numpy.float64 or \\\n                type(other) is numpy.float32:\n            if other > self.get_mass():\n                raise Exception(\n                    \"Invalid extraction operation. \"\n                    \"Cannot extract a mass larger than the package's mass.\")\n            fraction_to_subtract = other / self.get_mass()\n            result = MaterialPackage(\n                self.material, self.size_class_masses * fraction_to_subtract)\n            self.size_class_masses = self.size_class_masses * (\n                1.0 - fraction_to_subtract)\n            return result\n\n        # Extract the specified mass of the specified size class.\n        elif self._is_size_class_mass_tuple(other):\n            index = self.material.get_size_class_index(other[0])\n            if other[1] > self.size_class_masses[index]:\n                raise Exception(\n                    \"Invalid extraction operation. \"\n                    \"Cannot extract a size class mass larger than what the \"\n                    \"package contains.\")\n            self.size_class_masses[index] = \\\n                self.size_class_masses[index] - other[1]\n            resultarray = self.size_class_masses*0.0\n            resultarray[index] = other[1]\n            result = MaterialPackage(self.material, resultarray)\n            return result\n\n        # Extract all of the specified size class.\n        elif type(other) is str:\n            index = self.material.get_size_class_index(float(other))\n            result = self * 0.0\n            result.size_class_masses[index] = self.size_class_masses[index]\n            self.size_class_masses[index] = 0.0\n            return result\n\n        # If not one of the above, it must be an invalid argument.\n        else:\n            raise TypeError(\"Invalid extraction argument.\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding another psd material package to this material package.", "response": "def add_to(self, other):\n        \"\"\"\n        Add another psd material package to this material package.\n\n        :param other: The other material package.\n        \"\"\"\n\n        # Add another package.\n        if type(other) is MaterialPackage:\n            # Packages of the same material.\n            if self.material == other.material:\n                self.size_class_masses = \\\n                        self.size_class_masses + other.size_class_masses\n            else:  # Packages of different materials.\n                for size_class in other.material.size_classes:\n                    if size_class not in self.material.size_classes:\n                        raise Exception(\n                            \"Packages of '\" + other.material.name +\n                            \"' cannot be added to packages of '\" +\n                            self.material.name +\n                            \"'. The size class '\" + size_class +\n                            \"' was not found in '\" + self.material.name + \"'.\")\n                    self.add_to(\n                        (size_class, other.get_size_class_mass(size_class)))\n\n        # Add the specified mass of the specified size class.\n        elif self._is_size_class_mass_tuple(other):\n            # Added material variables.\n            size_class = other[0]\n            compound_index = self.material.get_size_class_index(size_class)\n            mass = other[1]\n\n            # Create the result package.\n            self.size_class_masses[compound_index] = \\\n                self.size_class_masses[compound_index] + mass\n\n        # If not one of the above, it must be an invalid argument.\n        else:\n            raise TypeError(\"Invalid addition argument.\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self, clock, generalLedger):\n\n        if not self._meet_execution_criteria(clock.timestep_ix):\n            return\n\n        generalLedger.create_transaction(\n            self.description if self.description is not None else self.name,\n            description='',\n            tx_date=clock.get_datetime(),\n            dt_account=self.dt_account,\n            cr_account=self.cr_account,\n            source=self.path,\n            amount=self.amount)", "response": "Execute the activity at the current clock cycle."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prepare_to_run(self, clock, period_count):\n\n        super(BasicLoanActivity, self).prepare_to_run(clock, period_count)\n\n        self._months_executed = 0\n        self._amount_left = self.amount", "response": "Prepare the activity for execution."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting the activity at the current clock cycle.", "response": "def run(self, clock, generalLedger):\n        \"\"\"\n        Execute the activity at the current clock cycle.\n\n        :param clock: The clock containing the current execution time and\n          period information.\n        :param generalLedger: The general ledger into which to create the\n          transactions.\n        \"\"\"\n\n        if not self._meet_execution_criteria(clock.timestep_ix):\n            return\n\n        if self.description is None:\n            tx_name = self.name\n        else:\n            tx_name = self.description\n\n        if self._months_executed == 0:\n            generalLedger.create_transaction(\n                tx_name,\n                description='Make a loan',\n                tx_date=clock.get_datetime(),\n                dt_account=self.bank_account,\n                cr_account=self.loan_account,\n                source=self.path,\n                amount=self.amount)\n        else:\n            curr_interest_amount = (self._amount_left *\n                                    self.interest_rate) / 12.0\n\n            generalLedger.create_transaction(\n                tx_name,\n                description='Consider interest',\n                tx_date=clock.get_datetime(),\n                dt_account=self.interest_account,\n                cr_account=self.loan_account,\n                source=self.path,\n                amount=curr_interest_amount)\n\n            generalLedger.create_transaction(\n                tx_name,\n                description='Pay principle',\n                tx_date=clock.get_datetime(),\n                dt_account=self.loan_account,\n                cr_account=self.bank_account,\n                source=self.path,\n                amount=self._monthly_payment)\n\n            self._amount_left += curr_interest_amount - self._monthly_payment\n\n        self._months_executed += self.interval"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the datetime at a given time period.", "response": "def get_datetime_at_period_ix(self, ix):\n        \"\"\"\n        Get the datetime at a given period.\n\n        :param period: The index of the period.\n\n        :returns: The datetime.\n        \"\"\"\n\n        if self.timestep_period_duration == TimePeriod.millisecond:\n            return self.start_datetime + timedelta(milliseconds=ix)\n        elif self.timestep_period_duration == TimePeriod.second:\n            return self.start_datetime + timedelta(seconds=ix)\n        elif self.timestep_period_duration == TimePeriod.minute:\n            return self.start_datetime + timedelta(minutes=ix)\n        elif self.timestep_period_duration == TimePeriod.hour:\n            return self.start_datetime + timedelta(hours=ix)\n        elif self.timestep_period_duration == TimePeriod.day:\n            return self.start_datetime + relativedelta(days=ix)\n        elif self.timestep_period_duration == TimePeriod.week:\n            return self.start_datetime + relativedelta(days=ix*7)\n        elif self.timestep_period_duration == TimePeriod.month:\n            return self.start_datetime + relativedelta(months=ix)\n        elif self.timestep_period_duration == TimePeriod.year:\n            return self.start_datetime + relativedelta(years=ix)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_default_data_path_():\n\n    module_path = os.path.dirname(sys.modules[__name__].__file__)\n    data_path = os.path.join(module_path, r'data/rao')\n    data_path = os.path.abspath(data_path)\n    return data_path", "response": "Calculate the default path in which thermochemical data is stored."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the factsage thermochemical data from a file.", "response": "def _read_compound_from_factsage_file_(file_name):\n    \"\"\"\n    Build a dictionary containing the factsage thermochemical data of a\n    compound by reading the data from a file.\n\n    :param file_name: Name of file to read the data from.\n\n    :returns: Dictionary containing compound data.\n    \"\"\"\n\n    with open(file_name) as f:\n        lines = f.readlines()\n\n    compound = {'Formula': lines[0].split(' ')[1]}\n    # FIXME: replace with logging\n    print(compound['Formula'])\n    compound['Phases'] = phs = {}\n\n    started = False\n    phaseold = 'zz'\n    recordold = '0'\n\n    for line in lines:\n        if started:\n            if line.startswith('_'):  # line indicating end of data\n                break\n            line = line.replace(' 298 ', ' 298.15 ')\n            line = line.replace(' - ', ' ')\n            while '  ' in line:\n                line = line.replace('  ', ' ')\n            line = line.replace(' \\n', '')\n            line = line.replace('\\n', '')\n            strings = line.split(' ')\n            if len(strings) < 2:  # empty line\n                continue\n            phase = strings[0]\n            if phase != phaseold:  # new phase detected\n                phaseold = phase\n                ph = phs[phase] = {}\n                ph['Symbol'] = phase\n                ph['DHref'] = float(strings[2])\n                ph['Sref'] = float(strings[3])\n                cprecs = ph['Cp_records'] = {}\n                record = strings[1]\n                if record != recordold:  # new record detected\n                    recordold = record\n                    Tmax = float(strings[len(strings) - 1])\n                    cprecs[Tmax] = {}\n                    cprecs[Tmax]['Tmin'] = float(strings[len(strings) - 2])\n                    cprecs[Tmax]['Tmax'] = float(strings[len(strings) - 1])\n                    cprecs[Tmax]['Terms'] = []\n                    t = {'Coefficient': float(strings[4]),\n                         'Exponent': float(strings[5])}\n                    cprecs[Tmax]['Terms'].append(t)\n                    if len(strings) == 10:\n                        t = {'Coefficient': float(strings[6]),\n                             'Exponent': float(strings[7])}\n                        cprecs[Tmax]['Terms'].append(t)\n                else:  # old record detected\n                    t = {'Coefficient': float(strings[2]),\n                         'Exponent': float(strings[3])}\n                    cprecs[Tmax]['Terms'].append(t)\n                    if len(strings) == 8:\n                        t = {'Coefficient': float(strings[4]),\n                             'Exponent': float(strings[5])}\n                        cprecs[Tmax]['Terms'].append(t)\n            else:  # old phase detected\n                ph = phs[phase]\n                record = strings[1]\n                if record != recordold:  # new record detected\n                    recordold = record\n                    Tmax = float(strings[len(strings) - 1])\n                    cprecs = ph['Cp_records']\n                    cprecs[Tmax] = {}\n                    cprecs[Tmax]['Tmin'] = float(strings[len(strings) - 2])\n                    cprecs[Tmax]['Tmax'] = float(strings[len(strings) - 1])\n                    cprecs[Tmax]['Terms'] = []\n                    t = {'Coefficient': float(strings[2]),\n                         'Exponent': float(strings[3])}\n                    cprecs[Tmax]['Terms'].append(t)\n                    if len(strings) == 8:\n                        t = {'Coefficient': float(strings[4]),\n                             'Exponent': float(strings[5])}\n                        cprecs[Tmax]['Terms'].append(t)\n                else:  # old record detected\n                    t = {'Coefficient': float(strings[2]),\n                         'Exponent': float(strings[3])}\n                    cprecs[Tmax]['Terms'].append(t)\n                    if len(strings) == 8:\n                        t = {'Coefficient': float(strings[4]),\n                             'Exponent': float(strings[5])}\n                        cprecs[Tmax]['Terms'].append(t)\n        if line.startswith('_'):  # line indicating the start of the data\n            started = True\n\n    for name, ph in phs.items():\n        cprecs = ph['Cp_records']\n        first = cprecs[min(cprecs.keys())]\n        first['Tmin'] = 298.15\n\n    return compound"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsplits a compound s combined formula and phase into separate strings for the formula and phase of a chemical compound.", "response": "def _split_compound_string_(compound_string):\n    \"\"\"\n    Split a compound's combined formula and phase into separate strings for\n    the formula and phase.\n\n    :param compound_string: Formula and phase of a chemical compound, e.g.\n      'SiO2[S1]'.\n\n    :returns: Formula of chemical compound.\n    :returns: Phase of chemical compound.\n    \"\"\"\n\n    formula = compound_string.replace(']', '').split('[')[0]\n    phase = compound_string.replace(']', '').split('[')[1]\n\n    return formula, phase"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the value to its final form by unit conversions and multiplying by mass.", "response": "def _finalise_result_(compound, value, mass):\n    \"\"\"\n    Convert the value to its final form by unit conversions and multiplying\n    by mass.\n\n    :param compound: Compound object.\n    :param value: [J/mol] Value to be finalised.\n    :param mass: [kg] Mass of compound.\n\n    :returns: [kWh] Finalised value.\n    \"\"\"\n\n    result = value / 3.6E6  # J/x -> kWh/x\n    result = result / compound.molar_mass  # x/mol -> x/kg\n    result = result * mass  # x/kg -> x\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites a compound to an auxi file at the specified directory.", "response": "def write_compound_to_auxi_file(directory, compound):\n    \"\"\"\n    Writes a compound to an auxi file at the specified directory.\n\n    :param dir: The directory.\n    :param compound: The compound.\n    \"\"\"\n\n    file_name = \"Compound_\" + compound.formula + \".json\"\n    with open(os.path.join(directory, file_name), 'w') as f:\n        f.write(str(compound))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload all the thermochemical data factsage files located at a path.", "response": "def load_data_factsage(path=''):\n    \"\"\"\n    Load all the thermochemical data factsage files located at a path.\n\n    :param path: Path at which the data files are located.\n    \"\"\"\n\n    compounds.clear()\n\n    if path == '':\n        path = default_data_path\n    if not os.path.exists(path):\n        warnings.warn('The specified data file path does not exist. (%s)' % path)\n        return\n\n    files = glob.glob(os.path.join(path, 'Compound_*.txt'))\n\n    for file in files:\n        compound = Compound(_read_compound_from_factsage_file_(file))\n        compounds[compound.formula] = compound"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads all the thermochemical data auxi files located at a path.", "response": "def load_data_auxi(path=''):\n    \"\"\"\n    Load all the thermochemical data auxi files located at a path.\n\n    :param path: Path at which the data files are located.\n    \"\"\"\n\n    compounds.clear()\n\n    if path == '':\n        path = default_data_path\n    if not os.path.exists(path):\n        warnings.warn('The specified data file path does not exist. (%s)' % path)\n        return\n\n    files = glob.glob(os.path.join(path, 'Compound_*.json'))\n\n    for file in files:\n        compound = Compound.read(file)\n        compounds[compound.formula] = compound"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_compounds():\n\n    print('Compounds currently loaded:')\n    for compound in sorted(compounds.keys()):\n        phases = compounds[compound].get_phase_list()\n        print('%s: %s' % (compound, ', '.join(phases)))", "response": "List all compounds currently loaded in the thermo module and their phases."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Cp(compound_string, T, mass=1.0):\n\n    formula, phase = _split_compound_string_(compound_string)\n    TK = T + 273.15\n    compound = compounds[formula]\n    result = compound.Cp(phase, TK)\n\n    return _finalise_result_(compound, result, mass)", "response": "Calculates the heat capacity of the chemical compound for the specified temperature T and mass."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Cp(self, T):\n\n        result = 0.0\n        for c, e in zip(self._coefficients, self._exponents):\n            result += c*T**e\n        return result", "response": "Calculates the heat capacity of the compound phase."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef H(self, T):\n\n        result = 0.0\n        if T < self.Tmax:\n            lT = T\n        else:\n            lT = self.Tmax\n        Tref = self.Tmin\n\n        for c, e in zip(self._coefficients, self._exponents):\n            # Analytically integrate Cp(T).\n            if e == -1.0:\n                result += c * math.log(lT/Tref)\n            else:\n                result += c * (lT**(e+1.0) - Tref**(e+1.0)) / (e+1.0)\n        return result", "response": "Calculates the portion of enthalpy of the compound phase covered by this\n            Cp record."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the portion of entropy of the compound phase covered by this Cp record.", "response": "def S(self, T):\n        \"\"\"\n        Calculate the portion of entropy of the compound phase covered by this\n        Cp record.\n\n        :param T: [K] temperature\n\n        :returns: Entropy. [J/mol/K]\n        \"\"\"\n\n        result = 0.0\n        if T < self.Tmax:\n            lT = T\n        else:\n            lT = self.Tmax\n        Tref = self.Tmin\n        for c, e in zip(self._coefficients, self._exponents):\n            # Create a modified exponent to analytically integrate Cp(T)/T\n            # instead of Cp(T).\n            e_modified = e - 1.0\n            if e_modified == -1.0:\n                result += c * math.log(lT/Tref)\n            else:\n                e_mod = e_modified + 1.0\n                result += c * (lT**e_mod - Tref**e_mod) / e_mod\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the heat capacity of the compound phase at the specified temperature.", "response": "def Cp(self, T):\n        \"\"\"\n        Calculate the heat capacity of the compound phase at the specified\n        temperature.\n\n        :param T: [K] temperature\n\n        :returns: [J/mol/K] The heat capacity of the compound phase.\n        \"\"\"\n\n        # TODO: Fix str/float conversion\n        for Tmax in sorted([float(TT) for TT in self._Cp_records.keys()]):\n            if T < Tmax:\n                return self._Cp_records[str(Tmax)].Cp(T) + self.Cp_mag(T)\n\n        Tmax = max([float(TT) for TT in self._Cp_records.keys()])\n\n        return self._Cp_records[str(Tmax)].Cp(Tmax) + self.Cp_mag(T)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Cp_mag(self, T):\n\n        tau = T / self.Tc_mag\n\n        if tau <= 1.0:\n            c = (self._B_mag*(2*tau**3 + 2*tau**9/3 + 2*tau**15/5))/self._D_mag\n        else:\n            c = (2*tau**-5 + 2*tau**-15/3 + 2*tau**-25/5)/self._D_mag\n\n        result = R*math.log(self.beta0_mag + 1)*c\n\n        return result", "response": "Calculate the magnetic contribution to the compound phase at the specified temperature."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the enthalpy of the specified temperature.", "response": "def H(self, T):\n        \"\"\"\n        Calculate the enthalpy of the compound phase at the specified\n        temperature.\n\n        :param T: [K] temperature\n\n        :returns: [J/mol] The enthalpy of the compound phase.\n        \"\"\"\n\n        result = self.DHref\n\n        for Tmax in sorted([float(TT) for TT in self._Cp_records.keys()]):\n            result += self._Cp_records[str(Tmax)].H(T)\n            if T <= Tmax:\n                return result + self.H_mag(T)\n\n        # Extrapolate beyond the upper limit by using a constant heat capacity.\n        Tmax = max([float(TT) for TT in self._Cp_records.keys()])\n        result += self.Cp(Tmax)*(T - Tmax)\n\n        return result + self.H_mag(T)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef H_mag(self, T):\n\n        tau = T / self.Tc_mag\n\n        if tau <= 1.0:\n            h = (-self._A_mag/tau +\n                 self._B_mag*(tau**3/2 + tau**9/15 + tau**15/40))/self._D_mag\n        else:\n            h = -(tau**-5/2 + tau**-15/21 + tau**-25/60)/self._D_mag\n\n        return R*T*math.log(self.beta0_mag + 1)*h", "response": "Calculate the magnetic contribution to enthalpy at the specified temperature."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the entropy of the compound phase at the specified temperature.", "response": "def S(self, T):\n        \"\"\"\n        Calculate the entropy of the compound phase at the specified\n        temperature.\n\n        :param T: [K] temperature\n\n        :returns: [J/mol/K] The entropy of the compound phase.\n        \"\"\"\n\n        result = self.Sref\n\n        for Tmax in sorted([float(TT) for TT in self._Cp_records.keys()]):\n            result += self._Cp_records[str(Tmax)].S(T)\n            if T <= Tmax:\n                return result + self.S_mag(T)\n\n        # Extrapolate beyond the upper limit by using a constant heat capacity.\n        Tmax = max([float(TT) for TT in self._Cp_records.keys()])\n        result += self.Cp(Tmax)*math.log(T / Tmax)\n\n        return result + self.S_mag(T)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the magnetic contribution to the phase at the specified temperature.", "response": "def S_mag(self, T):\n        \"\"\"\n        Calculate the phase's magnetic contribution to entropy at the\n        specified temperature.\n\n        :param T: [K] temperature\n\n        :returns: [J/mol/K] The magnetic entropy of the compound phase.\n\n        Dinsdale, A. T. (1991). SGTE data for pure elements. Calphad, 15(4),\n        317\u2013425. http://doi.org/10.1016/0364-5916(91)90030-N\n        \"\"\"\n\n        tau = T / self.Tc_mag\n\n        if tau <= 1.0:\n            s = 1 - (self._B_mag*(2*tau**3/3 + 2*tau**9/27 + 2*tau**15/75)) / \\\n                self._D_mag\n        else:\n            s = (2*tau**-5/5 + 2*tau**-15/45 + 2*tau**-25/125)/self._D_mag\n\n        return -R*math.log(self.beta0_mag + 1)*s"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the Gibbs free energy of the compound phase at the specified temperature.", "response": "def G(self, T):\n        \"\"\"Calculate the heat capacity of the compound phase at the specified\n        temperature.\n\n        :param T: [K] temperature\n\n        :returns: [J/mol] The Gibbs free energy of the compound phase.\n        \"\"\"\n\n        h = self.DHref\n        s = self.Sref\n\n        for Tmax in sorted([float(TT) for TT in self._Cp_records.keys()]):\n            h = h + self._Cp_records[str(Tmax)].H(T)\n            s = s + self._Cp_records[str(Tmax)].S(T)\n            if T <= Tmax:\n                return h - T * s + self.G_mag(T)\n\n        # Extrapolate beyond the upper limit by using a constant heat capacity.\n        Tmax = max([float(TT) for TT in self._Cp_records.keys()])\n        h = h + self.Cp(Tmax)*(T - Tmax)\n        s = s + self.Cp(Tmax)*math.log(T / Tmax)\n\n        return h - T * s + self.G_mag(T)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef G_mag(self, T):\n\n        tau = T / self.Tc_mag\n\n        if tau <= 1.0:\n            g = 1 - (self._A_mag/tau +\n                     self._B_mag*(tau**3/6 + tau**9/135 + tau**15/600)) /\\\n                    self._D_mag\n        else:\n            g = -(tau**-5/10 + tau**-15/315 + tau**-25/1500)/self._D_mag\n\n        return R*T*math.log(self.beta0_mag + 1)*g", "response": "Calculates the magnetic contribution to Gibbs energy at the specified temperature."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Cp(self, phase, T):\n\n        if phase not in self._phases:\n            raise Exception(\"The phase '%s' was not found in compound '%s'.\" %\n                            (phase, self.formula))\n\n        return self._phases[phase].Cp(T)", "response": "Calculates the heat capacity of a specified phase of the compound at a specified temperature."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the enthalpy of a specified phase of the compound at a specified temperature.", "response": "def H(self, phase, T):\n        \"\"\"\n        Calculate the enthalpy of a phase of the compound at a specified\n        temperature.\n\n        :param phase: A phase of the compound, e.g. 'S', 'L', 'G'.\n        :param T: [K] temperature\n\n        :returns: [J/mol] Enthalpy.\n        \"\"\"\n\n        try:\n            return self._phases[phase].H(T)\n        except KeyError:\n            raise Exception(\"The phase '{}' was not found in compound '{}'.\"\n                            .format(phase, self.formula))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a polynomial model for the specified property based on the specified data set and save it to a. json file.", "response": "def _create_polynomial_model(\n    name: str,\n    symbol: str,\n    degree: int,\n    ds: DataSet,\n    dss: dict):\n    \"\"\"\n    Create a polynomial model to describe the specified property based on the\n    specified data set, and save it to a .json file.\n\n    :param name: material name.\n    :param symbol: property symbol.\n    :param degree: polynomial degree.\n    :param ds: the source data set.\n    :param dss: dictionary of all datasets.\n    \"\"\"\n    ds_name = ds.name.split(\".\")[0].lower()\n    file_name = f\"{name.lower()}-{symbol.lower()}-polynomialmodelt-{ds_name}\"\n    newmod = PolynomialModelT.create(ds, symbol, degree)\n    newmod.plot(dss, _path(f\"data/{file_name}.pdf\"), False)\n    newmod.write(_path(f\"data/{file_name}.json\"))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_air():\n    name = \"Air\"\n    namel = name.lower()\n    mm = 28.9645  # g/mol\n\n    ds_dict = _create_ds_dict([\n        \"dataset-air-lienhard2015\",\n        \"dataset-air-lienhard2018\"])\n    active_ds = \"dataset-air-lienhard2018\"\n\n    # create polynomial models to describe material properties\n    #   comment it out after model creation is complete, so that it does not\n    #   run every time during use.\n    # _create_polynomial_model(name, \"Cp\", 13, ds_dict[active_ds], ds_dict)\n    # _create_polynomial_model(name, \"k\", 8, ds_dict[active_ds], ds_dict)\n    # _create_polynomial_model(name, \"mu\", 8, ds_dict[active_ds], ds_dict)\n    # _create_polynomial_model(name, \"rho\", 14, ds_dict[active_ds], ds_dict)\n\n    # IgRhoT(mm, 101325.0).plot(ds_dict, _path(f\"data/{namel}-rho-igrhot.pdf\"))\n\n    model_dict = {\n        \"rho\": IgRhoT(mm, 101325.0),\n        \"beta\": IgBetaT()}\n\n    model_type = \"polynomialmodelt\"\n    for property in [\"Cp\", \"mu\", \"k\"]:\n        name = f\"data/{namel}-{property.lower()}-{model_type}-{active_ds}.json\"\n        model_dict[property] = PolynomialModelT.read(_path(name))\n\n    material = Material(name, StateOfMatter.gas, model_dict)\n\n    return material, ds_dict", "response": "Create a dictionary of datasets and a material object for air."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calculate(self, **state):\n\n        def phi(i, j, mu_i, mu_j):\n            M_i = M(i)\n            M_j = M(j)\n\n            result = (1.0 + (mu_i / mu_j)**0.5 * (M_j / M_i)**0.25)**2.0\n            result /= (4.0 / sqrt(2.0))\n            result /= (1.0 + M_i / M_j)**0.5\n\n            return result\n\n        T = state['T']\n        x = state['x']\n\n        # normalise mole fractions\n        x_total = sum([\n            x for compound, x in x.items()\n            if compound in materials])\n        x = {\n            compound: x[compound]/x_total\n            for compound in x.keys()\n            if compound in materials}\n\n        result = 0.0  # Pa.s\n        mu = {i: materials[i].mu(T=T) for i in x.keys()}\n        for i in x.keys():\n            sum_i = 0.0\n            for j in x.keys():\n                if j == i: continue\n                sum_i += x[j] * phi(i, j, mu[i], mu[j])\n\n            result += x[i] * mu[i] / (x[i] + sum_i)\n\n        return result", "response": "Calculates dynamic viscosity at the specified temperature and composition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calculate(self, **state):\n\n        T = state['T']\n        x = state['x']\n\n        # normalise mole fractions\n        x_total = sum([\n            x for compound, x in x.items()\n            if compound in materials])\n        x = {\n            compound: x[compound]/x_total\n            for compound in x.keys()\n            if compound in materials}\n\n        mu = {i: materials[i].mu(T=T) for i in x.keys()}\n\n        result = sum([mu[i] * x[i] * sqrt(M(i)) for i in x.keys()])\n        result /= sum([x[i] * sqrt(M(i)) for i in x.keys()])\n\n        return result", "response": "Calculates dynamic viscosity at the specified temperature and composition."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrender the report in the specified format", "response": "def render(self, format=ReportFormat.printout):\n        \"\"\"\n        Render the report in the specified format\n\n        :param format: The format. The default format is to print\n          the report to the console.\n\n        :returns: If the format was set to 'string' then a string\n          representation of the report is returned.\n        \"\"\"\n\n        table = self._generate_table_()\n        if format == ReportFormat.printout:\n            print(tabulate(table, headers=\"firstrow\", tablefmt=\"simple\"))\n        elif format == ReportFormat.latex:\n            self._render_latex_(table)\n        elif format == ReportFormat.txt:\n            self._render_txt_(table)\n        elif format == ReportFormat.csv:\n            self._render_csv_(table)\n        elif format == ReportFormat.string:\n            return str(tabulate(table, headers=\"firstrow\", tablefmt=\"simple\"))\n        elif format == ReportFormat.matplotlib:\n            self._render_matplotlib_()\n        elif format == ReportFormat.png:\n            if self.output_path is None:\n                self._render_matplotlib_()\n            else:\n                self._render_matplotlib_(True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert an RGB color representation to a HEX color representation.", "response": "def rgb_to_hex(rgb):\n    \"\"\"\n    Convert an RGB color representation to a HEX color representation.\n\n    (r, g, b) :: r -> [0, 255]\n                 g -> [0, 255]\n                 b -> [0, 255]\n\n    :param rgb: A tuple of three numeric values corresponding to the red, green, and blue value.\n    :return: HEX representation of the input RGB value.\n    :rtype: str\n    \"\"\"\n    r, g, b = rgb\n    return \"#{0}{1}{2}\".format(hex(int(r))[2:].zfill(2), hex(int(g))[2:].zfill(2), hex(int(b))[2:].zfill(2))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rgb_to_yiq(rgb):\n    r, g, b = rgb[0] / 255, rgb[1] / 255, rgb[2] / 255\n    y = (0.299 * r) + (0.587 * g) + (0.114 * b)\n    i = (0.596 * r) - (0.275 * g) - (0.321 * b)\n    q = (0.212 * r) - (0.528 * g) + (0.311 * b)\n    return round(y, 3), round(i, 3), round(q, 3)", "response": "Convert an RGB color representation to a YIQ color representation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rgb_to_hsv(rgb):\n    r, g, b = rgb[0] / 255, rgb[1] / 255, rgb[2] / 255\n    _min = min(r, g, b)\n    _max = max(r, g, b)\n    v = _max\n    delta = _max - _min\n\n    if _max == 0:\n        return 0, 0, v\n\n    s = delta / _max\n\n    if delta == 0:\n        delta = 1\n\n    if r == _max:\n        h = 60 * (((g - b) / delta) % 6)\n\n    elif g == _max:\n        h = 60 * (((b - r) / delta) + 2)\n\n    else:\n        h = 60 * (((r - g) / delta) + 4)\n\n    return round(h, 3), round(s, 3), round(v, 3)", "response": "Convert an RGB color representation to an HSV color representation."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a HEX color representation to an RGB color representation.", "response": "def hex_to_rgb(_hex):\n    \"\"\"\n    Convert a HEX color representation to an RGB color representation.\n\n    hex :: hex -> [000000, FFFFFF]\n\n    :param _hex: The 3- or 6-char hexadecimal string representing the color value.\n    :return: RGB representation of the input HEX value.\n    :rtype: tuple\n    \"\"\"\n    _hex = _hex.strip('#')\n    n = len(_hex) // 3\n    if len(_hex) == 3:\n        r = int(_hex[:n] * 2, 16)\n        g = int(_hex[n:2 * n] * 2, 16)\n        b = int(_hex[2 * n:3 * n] * 2, 16)\n    else:\n        r = int(_hex[:n], 16)\n        g = int(_hex[n:2 * n], 16)\n        b = int(_hex[2 * n:3 * n], 16)\n    return r, g, b"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef yiq_to_rgb(yiq):\n    y, i, q = yiq\n    r = y + (0.956 * i) + (0.621 * q)\n    g = y - (0.272 * i) - (0.647 * q)\n    b = y - (1.108 * i) + (1.705 * q)\n\n    r = 1 if r > 1 else max(0, r)\n    g = 1 if g > 1 else max(0, g)\n    b = 1 if b > 1 else max(0, b)\n\n    return round(r * 255, 3), round(g * 255, 3), round(b * 255, 3)", "response": "Converts a YIQ color representation to an RGB color representation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting an HSV color representation to an RGB color representation.", "response": "def hsv_to_rgb(hsv):\n    \"\"\"\n    Convert an HSV color representation to an RGB color representation.\n\n    (h, s, v) :: h -> [0, 360)\n                 s -> [0, 1]\n                 v -> [0, 1]\n\n    :param hsv: A tuple of three numeric values corresponding to the hue, saturation, and value.\n    :return: RGB representation of the input HSV value.\n    :rtype: tuple\n    \"\"\"\n    h, s, v = hsv\n    c = v * s\n    h /= 60\n    x = c * (1 - abs((h % 2) - 1))\n    m = v - c\n\n    if h < 1:\n        res = (c, x, 0)\n    elif h < 2:\n        res = (x, c, 0)\n    elif h < 3:\n        res = (0, c, x)\n    elif h < 4:\n        res = (0, x, c)\n    elif h < 5:\n        res = (x, 0, c)\n    elif h < 6:\n        res = (c, 0, x)\n    else:\n        raise ColorException(\"Unable to convert from HSV to RGB\")\n\n    r, g, b = res\n    return round((r + m)*255, 3), round((g + m)*255, 3), round((b + m)*255, 3)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef offset_random_rgb(seed, amount=1):\n    r, g, b = seed\n\n    results = []\n    for _ in range(amount):\n        base_val = ((r + g + b) / 3) + 1  # Add one to eliminate case where the base value would otherwise be 0\n        new_val = base_val + (random.random() * rgb_max_val / 5)  # Randomly offset with an arbitrary multiplier\n        ratio = new_val / base_val\n        results.append((min(int(r*ratio), rgb_max_val), min(int(g*ratio), rgb_max_val), min(int(b*ratio), rgb_max_val)))\n\n    return results[0] if len(results) > 1 else results", "response": "Given a seed color generate a specified number of random colors from the seed color."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a start color, end color, and a number of steps, returns a list of colors which represent a 'scale' between the start and end color. :param start_color: The color starting the run :param end_color: The color ending the run :param step_count: The number of colors to have between the start and end color :param inclusive: Flag determining whether to include start and end values in run (default True) :param to_color: Flag indicating return values should be Color objects (default True) :return: List of colors between the start and end color :rtype: list", "response": "def color_run(start_color, end_color, step_count, inclusive=True, to_color=True):\n    \"\"\"\n    Given a start color, end color, and a number of steps, returns a list of colors which represent a 'scale' between\n    the start and end color.\n\n    :param start_color: The color starting the run\n    :param end_color: The color ending the run\n    :param step_count: The number of colors to have between the start and end color\n    :param inclusive: Flag determining whether to include start and end values in run (default True)\n    :param to_color: Flag indicating return values should be Color objects (default True)\n    :return: List of colors between the start and end color\n    :rtype: list\n    \"\"\"\n    if isinstance(start_color, Color):\n        start_color = start_color.rgb\n\n    if isinstance(end_color, Color):\n        end_color = end_color.rgb\n\n    step = tuple((end_color[i] - start_color[i])/step_count for i in range(3))\n\n    add = lambda x, y: tuple(sum(z) for z in zip(x, y))\n    mult = lambda x, y: tuple(y * z for z in x)\n\n    run = [add(start_color, mult(step, i)) for i in range(1, step_count)]\n\n    if inclusive:\n        run = [start_color] + run + [end_color]\n\n    return run if not to_color else [Color(c) for c in run]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the color of the text in the order that it should be shown.", "response": "def text_color(background, dark_color=rgb_min, light_color=rgb_max):\n    \"\"\"\n    Given a background color in the form of an RGB 3-tuple, returns the color the text should be (defaulting to white\n    and black) for best readability. The light (white) and dark (black) defaults can be overridden to return preferred\n    values.\n\n    :param background:\n    :param dark_color:\n    :param light_color:\n    :return:\n    \"\"\"\n    max_y = rgb_to_yiq(rgb_max)[0]\n    return light_color if rgb_to_yiq(background)[0] <= max_y / 2 else dark_color"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef minify_hex(_hex):\n    size = len(_hex.strip('#'))\n    if size == 3:\n        return _hex\n    elif size == 6:\n        if _hex[1] == _hex[2] and _hex[3] == _hex[4] and _hex[5] == _hex[6]:\n            return _hex[0::2]\n        else:\n            return _hex\n    else:\n        raise ColorException('Unexpected HEX size when minifying: {}'.format(size))", "response": "Given a HEX value tries to reduce it to a 3 character HEX representation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, key, default=None):\n        if self.in_memory:\n            return self._memory_db.get(key, default)\n        else:\n            db = self._read_file()\n            return db.get(key, default)", "response": "Get key value return default if key doesn t exist"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread the db file and return the dict", "response": "def _read_file(self):\n        \"\"\"\n        read the db file content\n        :rtype: dict\n        \"\"\"\n        if not os.path.exists(self.db_path):\n            return {}\n        with open(self.db_path, 'r') as f:\n            content = f.read()\n            return json.loads(content)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an A - HREF tag that points to another page usable in paginate.", "response": "def paginate_link_tag(item):\n    \"\"\"\n    Create an A-HREF tag that points to another page usable in paginate.\n    \"\"\"\n    a_tag = Page.default_link_tag(item)\n    if item['type'] == 'current_page':\n        return make_html_tag('li', a_tag, **{'class': 'blue white-text'})\n    return make_html_tag('li', a_tag)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset a devices state.", "response": "def set_state(_id, body):\n        \"\"\"\n        Set a devices state.\n        \"\"\"\n        url = DEVICE_URL % _id\n        if \"mode\" in body:\n            url = MODES_URL % _id\n        arequest = requests.put(url, headers=HEADERS, data=json.dumps(body))\n        status_code = str(arequest.status_code)\n        if status_code != '202':\n            _LOGGER.error(\"State not accepted. \" + status_code)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a list of the available modes for a given id.", "response": "def get_modes(_id):\n        \"\"\"\n        Pull a water heater's modes from the API.\n        \"\"\"\n        url = MODES_URL % _id\n        arequest = requests.get(url, headers=HEADERS)\n        status_code = str(arequest.status_code)\n        if status_code == '401':\n            _LOGGER.error(\"Token expired.\")\n            return False\n        return arequest.json()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a water heater s usage report.", "response": "def get_usage(_id):\n        \"\"\"\n        Pull a water heater's usage report from the API.\n        \"\"\"\n        url = USAGE_URL % _id\n        arequest = requests.get(url, headers=HEADERS)\n        status_code = str(arequest.status_code)\n        if status_code == '401':\n            _LOGGER.error(\"Token expired.\")\n            return False\n        try:\n            return arequest.json()\n        except ValueError:\n            _LOGGER.info(\"Failed to get usage. Not supported by unit?\")\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a device from the API.", "response": "def get_device(_id):\n        \"\"\"\n        Pull a device from the API.\n        \"\"\"\n        url = DEVICE_URL % _id\n        arequest = requests.get(url, headers=HEADERS)\n        status_code = str(arequest.status_code)\n        if status_code == '401':\n            _LOGGER.error(\"Token expired.\")\n            return False\n        return arequest.json()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the locations from the API.", "response": "def get_locations():\n        \"\"\"\n        Pull the accounts locations.\n        \"\"\"\n        arequest = requests.get(LOCATIONS_URL, headers=HEADERS)\n        status_code = str(arequest.status_code)\n        if status_code == '401':\n            _LOGGER.error(\"Token expired.\")\n            return False\n        return arequest.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the accounts vacations.", "response": "def get_vacations():\n        \"\"\"\n        Pull the accounts vacations.\n        \"\"\"\n        arequest = requests.get(VACATIONS_URL, headers=HEADERS)\n        status_code = str(arequest.status_code)\n        if status_code == '401':\n            _LOGGER.error(\"Token expired.\")\n            return False\n        return arequest.json()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_vacation(_id):\n        arequest = requests.delete(VACATIONS_URL + \"/\" + _id, headers=HEADERS)\n        status_code = str(arequest.status_code)\n        if status_code != '202':\n            _LOGGER.error(\"Failed to delete vacation. \" + status_code)\n            return False\n        return True", "response": "Delete a vacation by ID."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _authenticate(self):\n        auth_url = BASE_URL + \"/auth/token\"\n        payload = {'username': self.email, 'password': self.password, 'grant_type': 'password'}\n        arequest = requests.post(auth_url, data=payload, headers=BASIC_HEADERS)\n        status = arequest.status_code\n        if status != 200:\n            _LOGGER.error(\"Authentication request failed, please check credintials. \" + str(status))\n            return False\n        response = arequest.json()\n        _LOGGER.debug(str(response))\n        self.token = response.get(\"access_token\")\n        self.refresh_token = response.get(\"refresh_token\")\n        _auth = HEADERS.get(\"Authorization\")\n        _auth = _auth % self.token\n        HEADERS[\"Authorization\"] = _auth\n        _LOGGER.info(\"Authentication was successful, token set.\")\n        return True", "response": "Authenticate with the API and return an authentication token."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of water heater devices.", "response": "def get_water_heaters(self):\n        \"\"\"\n        Return a list of water heater devices.\n\n        Parses the response from the locations endpoint in to a pyeconet.WaterHeater.\n        \"\"\"\n        water_heaters = []\n        for location in self.locations:\n            _location_id = location.get(\"id\")\n            for device in location.get(\"equipment\"):\n                if device.get(\"type\") == \"Water Heater\":\n                    water_heater_modes = self.api_interface.get_modes(device.get(\"id\"))\n                    water_heater_usage = self.api_interface.get_usage(device.get(\"id\"))\n                    water_heater = self.api_interface.get_device(device.get(\"id\"))\n                    vacations = self.api_interface.get_vacations()\n                    device_vacations = []\n                    for vacation in vacations:\n                        for equipment in vacation.get(\"participatingEquipment\"):\n                            if equipment.get(\"id\") == water_heater.get(\"id\"):\n                                device_vacations.append(EcoNetVacation(vacation, self.api_interface))\n                    water_heaters.append(EcoNetWaterHeater(water_heater, water_heater_modes, water_heater_usage,\n                                                           _location_id,\n                                                           device_vacations,\n                                                           self.api_interface))\n        return water_heaters"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a list of all Uber products based on latitude and longitude.", "response": "def get_products(self, latitude, longitude):\n        \"\"\"\n        Get a list of all Uber products based on latitude and longitude coordinates.\n        :param latitude: Latitude for which product list is required.\n        :param longitude: Longitude for which product list is required.\n        :return: JSON\n        \"\"\"\n        endpoint = 'products'\n        query_parameters = {\n            'latitude': latitude,\n            'longitude': longitude\n        }\n\n        return self.get_json(endpoint, 'GET', query_parameters, None, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_price_estimate(self, start_latitude, start_longitude, end_latitude, end_longitude):\n        endpoint = 'estimates/price'\n        query_parameters = {\n            'start_latitude': start_latitude,\n            'start_longitude': start_longitude,\n            'end_latitude': end_latitude,\n            'end_longitude': end_longitude\n        }\n\n        return self.get_json(endpoint, 'GET', query_parameters, None, None)", "response": "Returns the price estimate based on two sets of coordinates."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the ETA for Uber products.", "response": "def get_time_estimate(self, start_latitude, start_longitude, customer_uuid=None, product_id=None):\n        \"\"\"\n        Get the ETA for Uber products.\n        :param start_latitude: Starting latitude.\n        :param start_longitude: Starting longitude.\n        :param customer_uuid: (Optional) Customer unique ID.\n        :param product_id: (Optional) If ETA is needed only for a specific product type.\n        :return: JSON\n        \"\"\"\n\n        endpoint = 'estimates/time'\n        query_parameters = {\n            'start_latitude': start_latitude,\n            'start_longitude': start_longitude\n        }\n\n        if customer_uuid is not None:\n            query_parameters['customer_uuid'] = customer_uuid\n        elif product_id is not None:\n            query_parameters['product_id'] = product_id\n        elif customer_uuid is not None and product_id is not None:\n            query_parameters['customer_uuid'] = customer_uuid\n            query_parameters['product_id'] = product_id\n\n        return self.get_json(endpoint, 'GET', query_parameters, None, None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwrapping all sqlalchemy models in settings.", "response": "def models_preparing(app):\n    \"\"\" Wrap all sqlalchemy model in settings.\n    \"\"\"\n\n    def wrapper(resource, parent):\n        if isinstance(resource, DeclarativeMeta):\n            resource = ListResource(resource)\n        if not getattr(resource, '__parent__', None):\n            resource.__parent__ = parent\n        return resource\n\n    resources_preparing_factory(app, wrapper)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks the status of the response and raise exceptions and errors.", "response": "def check_status(content, response):\n        \"\"\"\n        Check the response that is returned for known exceptions and errors.\n        :param response: Response that is returned from the call.\n        :raise:\n         MalformedRequestException if `response.status` is 400\n         UnauthorisedException if `response.status` is 401\n         NotFoundException if `response.status` is 404\n         UnacceptableContentException if `response.status` is 406\n         InvalidRequestException if `response.status` is 422\n         RateLimitException if `response.status` is 429\n         ServerException if `response.status` > 500\n        \"\"\"\n\n        if response.status == 400:\n            raise MalformedRequestException(content, response)\n\n        if response.status == 401:\n            raise UnauthorisedException(content, response)\n\n        if response.status == 404:\n            raise NotFoundException(content, response)\n\n        if response.status == 406:\n            raise UnacceptableContentException(content, response)\n\n        if response.status == 422:\n            raise InvalidRequestException(content, response)\n\n        if response.status == 429:\n            raise RateLimitException(content, response)\n\n        if response.status >= 500:\n            raise ServerException(content, response)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding the HTTP request by adding query parameters to the path.", "response": "def build_request(self, path, query_parameters):\n        \"\"\"\n        Build the HTTP request by adding query parameters to the path.\n        :param path: API endpoint/path to be used.\n        :param query_parameters: Query parameters to be added to the request.\n        :return: string\n        \"\"\"\n        url = 'https://api.uber.com/v1' + self.sanitise_path(path)\n        url += '?' + urlencode(query_parameters)\n\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_json(self, uri_path, http_method='GET', query_parameters=None, body=None, headers=None):\n        query_parameters = query_parameters or {}\n        headers = headers or {}\n\n        # Add credentials to the request\n        query_parameters = self.add_credentials(query_parameters)\n\n        # Build the request uri with parameters\n        uri = self.build_request(uri_path, query_parameters)\n\n        if http_method in ('POST', 'PUT', 'DELETE') and 'Content-Type' not in headers:\n            headers['Content-Type'] = 'application/json'\n\n        headers['Accept'] = 'application/json'\n        response, content = self.client.request(\n            uri=uri,\n            method=http_method,\n            body=body,\n            headers=headers\n        )\n\n        # Check for known errors that could be returned\n        self.check_status(content, response)\n\n        return json.loads(content.decode('utf-8'))", "response": "Fetches the JSON returned after making a request."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _translateCommands(commands):\n    for command in commands.split(','):\n        # each command results in 2 bytes of binary data\n        result = [0, 0]\n        device, command = command.strip().upper().split(None, 1)\n\n        # translate the house code\n        result[0] = houseCodes[device[0]]\n\n        # translate the device number if there is one\n        if len(device) > 1:\n            deviceNumber = deviceNumbers[device[1:]]\n            result[0] |= deviceNumber[0]\n            result[1] = deviceNumber[1]\n\n        # translate the command\n        result[1] |= commandCodes[command]\n\n        # convert 2 bytes to bit strings and yield them\n        yield ' '.join(map(_strBinary, result))", "response": "Translate a comma seperated list of commands into a list of binary strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _sendBinaryData(port, data):\n    _reset(port)\n    time.sleep(leadInOutDelay)\n    for digit in data:\n        _sendBit(port, digit)\n    time.sleep(leadInOutDelay)", "response": "Send a string of binary data to the FireCracker with proper timing."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends an individual bit to the FireCracker module usr RTS / DTR.", "response": "def _sendBit(port, bit):\n    \"\"\"Send an individual bit to the FireCracker module usr RTS/DTR.\"\"\"\n    if bit == '0':\n        _setRTSDTR(port, 0, 1)\n    elif bit == '1':\n        _setRTSDTR(port, 1, 0)\n    else:\n        return\n    time.sleep(bitDelay)\n    _setRTSDTR(port, 1, 1)\n    time.sleep(bitDelay)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting RTS and DTR to the requested state.", "response": "def _setRTSDTR(port, RTS, DTR):\n    \"\"\"Set RTS and DTR to the requested state.\"\"\"\n    port.setRTS(RTS)\n    port.setDTR(DTR)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends X10 commands to a specific device on a specific device on a specific device.", "response": "def sendCommands(comPort, commands):\n    \"\"\"Send X10 commands using the FireCracker on comPort\n\n    comPort should be the name of a serial port on the host platform. On\n    Windows, for example, 'com1'.\n\n    commands should be a string consisting of X10 commands separated by\n    commas. For example. 'A1 On, A Dim, A Dim, A Dim, A Lamps Off'. The\n    letter is a house code (A-P) and the number is the device number (1-16).\n    Possible commands for a house code / device number combination are\n    'On' and 'Off'. The commands 'Bright' and 'Dim' should be used with a\n    house code alone after sending an On command to a specific device. The\n    'All On', 'All Off', 'Lamps On', and 'Lamps Off' commands should also\n    be used with a house code alone.\n\n    # Turn on module A1\n    >>> sendCommands('com1', 'A1 On')\n\n    # Turn all modules with house code A off\n    >>> sendCommands('com1', 'A All Off')\n\n    # Turn all lamp modules with house code B on\n    >>> sendCommands('com1', 'B Lamps On')\n\n    # Turn on module A1 and dim it 3 steps, then brighten it 1 step\n    >>> sendCommands('com1', 'A1 On, A Dim, A Dim, A Dim, A Bright')\n    \"\"\"\n    mutex.acquire()\n    try:\n        try:\n            port = serial.Serial(port=comPort)\n            header = '11010101 10101010'\n            footer = '10101101'\n            for command in _translateCommands(commands):\n                _sendBinaryData(port, header + command + footer)\n        except serial.SerialException:\n            print('Unable to open serial port %s' % comPort)\n            print('')\n            raise\n    finally:\n        mutex.release()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main(argv=None):\n    if len(argv):\n        # join all the arguments together by spaces so that quotes\n        # aren't required on the command line.\n        commands = ' '.join(argv)\n\n        # the comPort is everything leading up to the first space\n        comPort, commands = commands.split(None, 1)\n\n        sendCommands(comPort, commands)\n\n    return 0", "response": "Send X10 commands when module is used from the command line."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a normalized house code i. e. upper case.", "response": "def normalize_housecode(house_code):\n    \"\"\"Returns a normalized house code, i.e. upper case.\n    Raises exception X10InvalidHouseCode if house code appears to be invalid\n    \"\"\"\n    if house_code is None:\n        raise X10InvalidHouseCode('%r is not a valid house code' % house_code)\n    if not isinstance(house_code, basestring):\n        raise X10InvalidHouseCode('%r is not a valid house code' % house_code)\n    if len(house_code) != 1:\n        raise X10InvalidHouseCode('%r is not a valid house code' % house_code)\n    house_code = house_code.upper()\n    if not ('A' <= house_code <= 'P'):\n        raise X10InvalidHouseCode('%r is not a valid house code' % house_code)\n    return house_code"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nnormalizes the unit number of a node in the sequence.", "response": "def normalize_unitnumber(unit_number):\n    \"\"\"Returns a normalized unit number, i.e. integers\n    Raises exception X10InvalidUnitNumber if unit number appears to be invalid\n    \"\"\"\n    try:\n        try:\n            unit_number = int(unit_number)\n        except ValueError:\n            raise X10InvalidUnitNumber('%r not a valid unit number' % unit_number)\n    except TypeError:\n        raise X10InvalidUnitNumber('%r not a valid unit number' % unit_number)\n    if not (1 <= unit_number <= 16):\n        raise X10InvalidUnitNumber('%r not a valid unit number' % unit_number)\n    return unit_number"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending X10 command to??? unit.", "response": "def x10_command(self, house_code, unit_number, state):\n        \"\"\"Send X10 command to ??? unit.\n\n        @param house_code (A-P) - example='A'\n        @param unit_number (1-16)- example=1 (or None to impact entire house code)\n        @param state - Mochad command/state, See\n                https://sourceforge.net/p/mochad/code/ci/master/tree/README\n                examples=OFF, 'OFF', 'ON', ALL_OFF, 'all_units_off', 'xdim 128', etc.\n\n        Examples:\n            x10_command('A', '1', ON)\n            x10_command('A', '1', OFF)\n            x10_command('A', '1', 'ON')\n            x10_command('A', '1', 'OFF')\n            x10_command('A', None, ON)\n            x10_command('A', None, OFF)\n            x10_command('A', None, 'all_lights_off')\n            x10_command('A', None, 'all_units_off')\n            x10_command('A', None, ALL_OFF)\n            x10_command('A', None, 'all_lights_on')\n            x10_command('A', 1, 'xdim 128')\n        \"\"\"\n\n        house_code = normalize_housecode(house_code)\n        if unit_number is not None:\n            unit_number = normalize_unitnumber(unit_number)\n        # else command is intended for the entire house code, not a single unit number\n        # TODO normalize/validate state\n\n        return self._x10_command(house_code, unit_number, state)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _x10_command(self, house_code, unit_number, state):\n        print('x10_command%r' % ((house_code, unit_number, state), ))\n        raise NotImplementedError()", "response": "Implementation of x10 command."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _x10_command(self, house_code, unit_number, state):\n\n        # log = log or default_logger\n        log = default_logger\n        if state.startswith('xdim') or state.startswith('dim') or state.startswith('bright'):\n            raise NotImplementedError('xdim/dim/bright %r' % ((house_code, unit_num, state), ))\n\n        if unit_number is not None:\n            house_and_unit = '%s%d' % (house_code, unit_number)\n        else:\n            raise NotImplementedError('mochad all ON/OFF %r' % ((house_code, unit_number, state), ))\n            house_and_unit = house_code\n\n        house_and_unit = to_bytes(house_and_unit)\n        # TODO normalize/validate state\n        state = to_bytes(state)\n        mochad_cmd = self.default_type + b' ' + house_and_unit + b' ' + state + b'\\n'  # byte concat works with older Python 3.4\n        log.debug('mochad send: %r', mochad_cmd)\n        mochad_host, mochad_port = self.device_address\n        result = netcat(mochad_host, mochad_port, mochad_cmd)\n        log.debug('mochad received: %r', result)", "response": "Implementation of the X10 command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _x10_command(self, house_code, unit_number, state):\n\n        # log = log or default_logger\n        log = default_logger\n\n        # FIXME move these functions?\n        def scale_255_to_8(x):\n            \"\"\"Scale x from 0..255 to 0..7\n            0 is considered OFF\n            8 is considered fully on\n            \"\"\"\n            factor = x / 255.0\n            return 8 - int(abs(round(8 * factor)))\n\n        def scale_31_to_8(x):\n            \"\"\"Scale x from 0..31 to 0..7\n            0 is considered OFF\n            8 is considered fully on\n            \"\"\"\n            factor = x / 31.0\n            return 8 - int(abs(round(8 * factor)))\n\n        serial_port_name = self.device_address\n        house_code = normalize_housecode(house_code)\n        if unit_number is not None:\n            unit_number = normalize_unitnumber(unit_number)\n        else:\n            # command is intended for the entire house code, not a single unit number\n            if firecracker:\n                log.error('using python-x10-firecracker-interface NO support for all ON/OFF')\n        # TODO normalize/validate state, sort of implemented below\n\n        if firecracker:\n            log.debug('firecracker send: %r', (serial_port_name, house_code, unit_number, state))\n            firecracker.send_command(serial_port_name, house_code, unit_number, state)\n        else:\n            if unit_number is not None:\n                if state.startswith('xdim') or state.startswith('dim') or state.startswith('bright'):\n                    dim_count = int(state.split()[-1])\n                    if state.startswith('xdim'):\n                        dim_count = scale_255_to_8(dim_count)\n                    else:\n                        # assumed dim or bright\n                        dim_count = scale_31_to_8(dim_count)\n                    dim_str = ', %s dim' % (house_code, )\n                    dim_list = []\n                    for _ in range(dim_count):\n                        dim_list.append(dim_str)\n                    dim_str = ''.join(dim_list)\n                    if dim_count == 0:\n                        # No dim\n                        x10_command_str = '%s%s %s' % (house_code, unit_number, 'on')\n                    else:\n                        # If lamp is already dimmed, need to turn it off and then back on\n                        x10_command_str = '%s%s %s, %s%s %s%s' % (house_code, unit_number, 'off', house_code, unit_number, 'on', dim_str)\n                else:\n                    x10_command_str = '%s%s %s' % (house_code, unit_number, state)\n            else:\n                # Assume a command for house not a specific unit\n                state = x10_mapping[state]\n\n                x10_command_str = '%s %s' % (house_code, state)\n            log.debug('x10_command_str send: %r', x10_command_str)\n            x10.sendCommands(serial_port_name, x10_command_str)", "response": "This function is used to send a command to the device."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates an appropriate argument parser for the command line.", "response": "def get_parser():\n    \"\"\"\n    Generate an appropriate parser.\n\n    :returns: an argument parser\n    :rtype: `ArgumentParser`\n    \"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"package\",\n        choices=arg_map.keys(),\n        help=\"designates the package to test\")\n    parser.add_argument(\"--ignore\", help=\"ignore these files\")\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_command(namespace):\n    cmd = [\"pylint\", namespace.package] + arg_map[namespace.package]\n    if namespace.ignore:\n        cmd.append(\"--ignore=%s\" % namespace.ignore)\n    return cmd", "response": "Get the pylint command for these arguments."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping a generated function so that it catches all Type- and ValueErrors and raises IntoDPValueErrors. :param func: the transforming function", "response": "def _wrapper(func):\n    \"\"\"\n    Wraps a generated function so that it catches all Type- and ValueErrors\n    and raises IntoDPValueErrors.\n\n    :param func: the transforming function\n    \"\"\"\n\n    @functools.wraps(func)\n    def the_func(expr):\n        \"\"\"\n        The actual function.\n\n        :param object expr: the expression to be xformed to dbus-python types\n        \"\"\"\n        try:\n            return func(expr)\n        except (TypeError, ValueError) as err:\n            raise IntoDPValueError(expr, \"expr\", \"could not be transformed\") \\\n               from err\n\n    return the_func"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the list of xformer functions for the given signature.", "response": "def xformers(sig):\n    \"\"\"\n    Get the list of xformer functions for the given signature.\n\n    :param str sig: a signature\n    :returns: a list of xformer functions for the given signature.\n    :rtype: list of tuple of a function * str\n\n    Each function catches all TypeErrors it encounters and raises\n    corresponding IntoDPValueError exceptions.\n    \"\"\"\n    return \\\n       [(_wrapper(f), l) for (f, l) in \\\n       _XFORMER.PARSER.parseString(sig, parseAll=True)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef xformer(signature):\n\n    funcs = [f for (f, _) in xformers(signature)]\n\n    def the_func(objects):\n        \"\"\"\n        Returns the a list of objects, transformed.\n\n        :param objects: a list of objects\n        :type objects: list of object\n\n        :returns: transformed objects\n        :rtype: list of object (in dbus types)\n        \"\"\"\n        if len(objects) != len(funcs):\n            raise IntoDPValueError(\n                objects,\n                \"objects\",\n                \"must have exactly %u items, has %u\" % \\\n                  (len(funcs), len(objects))\n            )\n        return [x for (x, _) in (f(a) for (f, a) in zip(funcs, objects))]\n\n    return the_func", "response": "Returns a transformer function for the given signature."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the level for the current variant.", "response": "def _variant_levels(level, variant):\n        \"\"\"\n        Gets the level for the variant.\n\n        :param int level: the current variant level\n        :param int variant: the value for this level if variant\n\n        :returns: a level for the object and one for the function\n        :rtype: int * int\n        \"\"\"\n        return (level + variant, level + variant) \\\n           if variant != 0 else (variant, level)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _handle_variant(self):\n\n        def the_func(a_tuple, variant=0):\n            \"\"\"\n            Function for generating a variant value from a tuple.\n\n            :param a_tuple: the parts of the variant\n            :type a_tuple: (str * object) or list\n            :param int variant: object's variant index\n            :returns: a value of the correct type with correct variant level\n            :rtype: object * int\n            \"\"\"\n            # pylint: disable=unused-argument\n            (signature, an_obj) = a_tuple\n            (func, sig) = self.COMPLETE.parseString(signature)[0]\n            assert sig == signature\n            (xformed, _) = func(an_obj, variant=variant + 1)\n            return (xformed, xformed.variant_level)\n\n        return (the_func, 'v')", "response": "Generate the correct function for a variant."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating the correct function for an array signature.", "response": "def _handle_array(toks):\n        \"\"\"\n        Generate the correct function for an array signature.\n\n        :param toks: the list of parsed tokens\n        :returns: function that returns an Array or Dictionary value\n        :rtype: ((or list dict) -> ((or Array Dictionary) * int)) * str\n        \"\"\"\n\n        if len(toks) == 5 and toks[1] == '{' and toks[4] == '}':\n            subtree = toks[2:4]\n            signature = ''.join(s for (_, s) in subtree)\n            [key_func, value_func] = [f for (f, _) in subtree]\n\n            def the_dict_func(a_dict, variant=0):\n                \"\"\"\n                Function for generating a Dictionary from a dict.\n\n                :param a_dict: the dictionary to transform\n                :type a_dict: dict of (`a * `b)\n                :param int variant: variant level\n\n                :returns: a dbus dictionary of transformed values and level\n                :rtype: Dictionary * int\n                \"\"\"\n                elements = \\\n                   [(key_func(x), value_func(y)) for (x, y) in a_dict.items()]\n                level = 0 if elements == [] \\\n                   else max(max(x, y) for ((_, x), (_, y)) in elements)\n                (obj_level, func_level) = \\\n                   _ToDbusXformer._variant_levels(level, variant)\n                return (dbus.types.Dictionary(\n                    ((x, y) for ((x, _), (y, _)) in elements),\n                    signature=signature,\n                    variant_level=obj_level), func_level)\n\n            return (the_dict_func, 'a{' + signature + '}')\n\n        if len(toks) == 2:\n            (func, sig) = toks[1]\n\n            def the_array_func(a_list, variant=0):\n                \"\"\"\n                Function for generating an Array from a list.\n\n                :param a_list: the list to transform\n                :type a_list: list of `a\n                :param int variant: variant level of the value\n                :returns: a dbus Array of transformed values and variant level\n                :rtype: Array * int\n                \"\"\"\n                if isinstance(a_list, dict):\n                    raise IntoDPValueError(a_list, \"a_list\",\n                                           \"is a dict, must be an array\")\n                elements = [func(x) for x in a_list]\n                level = 0 if elements == [] else max(x for (_, x) in elements)\n                (obj_level, func_level) = \\\n                   _ToDbusXformer._variant_levels(level, variant)\n\n                return (dbus.types.Array(\n                    (x for (x, _) in elements),\n                    signature=sig,\n                    variant_level=obj_level), func_level)\n\n            return (the_array_func, 'a' + sig)\n\n        raise IntoDPValueError(toks, \"toks\",\n                               \"unexpected tokens\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _handle_struct(toks):\n        subtrees = toks[1:-1]\n        signature = ''.join(s for (_, s) in subtrees)\n        funcs = [f for (f, _) in subtrees]\n\n        def the_func(a_list, variant=0):\n            \"\"\"\n            Function for generating a Struct from a list.\n\n            :param a_list: the list to transform\n            :type a_list: list or tuple\n            :param int variant: variant index\n            :returns: a dbus Struct of transformed values and variant level\n            :rtype: Struct * int\n            :raises IntoDPValueError:\n            \"\"\"\n            if isinstance(a_list, dict):\n                raise IntoDPValueError(a_list, \"a_list\",\n                                       \"must be a simple sequence, is a dict\")\n            if len(a_list) != len(funcs):\n                raise IntoDPValueError(\n                    a_list,\n                    \"a_list\",\n                    \"must have exactly %u items, has %u\" % \\\n                      (len(funcs), len(a_list))\n                )\n            elements = [f(x) for (f, x) in zip(funcs, a_list)]\n            level = 0 if elements == [] else max(x for (_, x) in elements)\n            (obj_level, func_level) = \\\n                _ToDbusXformer._variant_levels(level, variant)\n            return (dbus.types.Struct(\n                (x for (x, _) in elements),\n                signature=signature,\n                variant_level=obj_level), func_level)\n\n        return (the_func, '(' + signature + ')')", "response": "Handles the struct token."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_base_case(klass, symbol):\n\n        def the_func(value, variant=0):\n            \"\"\"\n            Base case.\n\n            :param int variant: variant level for this object\n            :returns: a tuple of a dbus object and the variant level\n            :rtype: dbus object * int\n            \"\"\"\n            (obj_level, func_level) = _ToDbusXformer._variant_levels(\n                0, variant)\n            return (klass(value, variant_level=obj_level), func_level)\n\n        return lambda: (the_func, symbol)", "response": "Handle a base case."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef signature(dbus_object, unpack=False):\n    # pylint: disable=too-many-return-statements\n    # pylint: disable=too-many-branches\n\n    if dbus_object.variant_level != 0 and not unpack:\n        return 'v'\n\n    if isinstance(dbus_object, dbus.Array):\n        sigs = frozenset(signature(x) for x in dbus_object)\n        len_sigs = len(sigs)\n        if len_sigs > 1:  # pragma: no cover\n            raise IntoDPValueError(dbus_object, \"dbus_object\",\n                                   \"has bad signature\")\n\n        if len_sigs == 0:\n            return 'a' + dbus_object.signature\n\n        return 'a' + [x for x in sigs][0]\n\n    if isinstance(dbus_object, dbus.Struct):\n        sigs = (signature(x) for x in dbus_object)\n        return '(' + \"\".join(x for x in sigs) + ')'\n\n    if isinstance(dbus_object, dbus.Dictionary):\n        key_sigs = frozenset(signature(x) for x in dbus_object.keys())\n        value_sigs = frozenset(signature(x) for x in dbus_object.values())\n\n        len_key_sigs = len(key_sigs)\n        len_value_sigs = len(value_sigs)\n\n        if len_key_sigs != len_value_sigs:  # pragma: no cover\n            raise IntoDPValueError(dbus_object, \"dbus_object\",\n                                   \"has bad signature\")\n\n        if len_key_sigs > 1:  # pragma: no cover\n            raise IntoDPValueError(dbus_object, \"dbus_object\",\n                                   \"has bad signature\")\n\n        if len_key_sigs == 0:\n            return 'a{' + dbus_object.signature + '}'\n\n        return 'a{' + [x for x in key_sigs][0] + [x\n                                                  for x in value_sigs][0] + '}'\n\n    if isinstance(dbus_object, dbus.Boolean):\n        return 'b'\n\n    if isinstance(dbus_object, dbus.Byte):\n        return 'y'\n\n    if isinstance(dbus_object, dbus.Double):\n        return 'd'\n\n    if isinstance(dbus_object, dbus.Int16):\n        return 'n'\n\n    if isinstance(dbus_object, dbus.Int32):\n        return 'i'\n\n    if isinstance(dbus_object, dbus.Int64):\n        return 'x'\n\n    if isinstance(dbus_object, dbus.ObjectPath):\n        return 'o'\n\n    if isinstance(dbus_object, dbus.Signature):\n        return 'g'\n\n    if isinstance(dbus_object, dbus.String):\n        return 's'\n\n    if isinstance(dbus_object, dbus.UInt16):\n        return 'q'\n\n    if isinstance(dbus_object, dbus.UInt32):\n        return 'u'\n\n    if isinstance(dbus_object, dbus.UInt64):\n        return 't'\n\n    if isinstance(dbus_object, dbus.types.UnixFd):  # pragma: no cover\n        return 'h'\n\n    raise IntoDPValueError(dbus_object, \"dbus_object\",\n                           \"has no signature\")", "response": "Get the signature of a dbus object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plot_indices(mis, dims=None, weights=None, groups=1,legend = True,index_labels=None, colors = None,axis_labels = None,size_exponent=0.1,ax=None):\n    '''\n    Plot multi-index set\n    \n    :param mis: Multi-index set\n    :type mis: Iterable of SparseIndices\n    :param dims: Which dimensions to use for plotting\n    :type dims: List of integers.\n    :param weights: Weights associated with each multi-index\n    :type weights: Dictionary\n    :param quantiles: Number of groups plotted in different colors\n    :type quantiles: Integer>=1 or list of colors\n    \n    TODO: exchange index_labels and dims, exchange quantiles and dims\n    '''\n    if weights is None:\n        weights = {mi: 1 for mi in mis}\n    if Function.valid(weights):\n        weights = {mi:weights(mi) for mi in mis}\n    values = list(weights.values())\n    if Integer.valid(groups):\n        N_g = groups\n        groups = [[mi for mi in mis if (weights[mi] > np.percentile(values, 100/groups*g) or g==0) and weights[mi] <= np.percentile(values, 100/groups*(g+1))] for g in range(N_g)]\n        group_names = ['{:.0f} -- {:.0f} percentile'.format(100/N_g*(N_g-i-1),100/N_g*(N_g-i)) for i in reversed(range(N_g))]\n    else:\n        if Function.valid(groups):\n            groups = {mi:groups(mi) for mi in mis}\n        group_names = unique(list(groups.values()))\n        groups = [[mi for mi in mis if groups[mi]==name] for name in group_names]\n        N_g = len(group_names)\n    if colors is None: \n        colors = matplotlib.cm.rainbow(np.linspace(0, 1, N_g))  # @UndefinedVariable\n    if Dict.valid(mis):\n        if index_labels is None or weights is None:\n            temp = list(mis.keys())\n            if (List|Tuple).valid(temp[0]):\n                if not (index_labels is None and weights is None):\n                    raise ValueError('mis cannot be dictionary with tuple entries if both index_labels and weights are specified separately')\n                weights = {mi:mis[mi][0] for mi in mis}\n                index_labels=  {mi:mis[mi][1] for mi in mis}\n            else:\n                if weights is None:\n                    weights = mis\n                else:\n                    index_labels = mis\n            mis = temp\n        else:\n            raise ValueError('mis cannot be dictionary if index_labels are specified separately')\n    if dims is None:\n        try:\n            dims = len(mis[0])\n        except TypeError:\n            dims = sorted(list(set.union(*(set(mi.active_dims()) for mi in mis))))   \n    if len(dims) > 3:\n        raise ValueError('Cannot plot in more than three dimensions.')\n    if len(dims) < 1:\n        warnings.warn('Sure you don\\'t want to plot anything?')\n        return\n    if ax is None:\n        fig = plt.figure() # Creates new figure, because adding onto old axes doesn't work if they were created without 3d\n        if len(dims) == 3:\n            ax = fig.gca(projection='3d')\n        else:\n            ax = fig.gca()\n    size_function = lambda mi: sum([weights[mi2] for mi2 in mis if mi.equal_mod(mi2, lambda dim: dim not in dims)]) \n    sizes = {mi: np.power(size_function(mi), size_exponent) for mi in mis}\n    for i,plot_indices in enumerate(groups):\n        X = np.array([mi[dims[0]] for mi in plot_indices])\n        if len(dims) > 1:\n            Y = np.array([mi[dims[1]] for mi in plot_indices])\n        else:\n            Y = np.array([0 for mi in plot_indices])\n        if len(dims) > 2:\n            Z = np.array([mi[dims[2]] for mi in plot_indices])\n        else:\n            Z = np.array([0 for mi in plot_indices])   \n        sizes_plot = np.array([sizes[mi] for mi in plot_indices])\n        if weights:\n            if len(dims) == 3:\n                ax.scatter(X, Y, Z, s = 50 * sizes_plot / max(sizes.values()), color=colors[i], alpha=1)            \n            else:\n                ax.scatter(X, Y, s = 50 * sizes_plot / max(sizes.values()), color=colors[i], alpha=1)\n        else:\n            if len(dims) == 3:\n                ax.scatter(X, Y, Z,color = colors[i],alpha=1)\n            else:\n                ax.scatter(X, Y,color=colors[i],alpha=1)\n        if True:\n            if len(dims)==3:\n                axs='xyz'\n            else:\n                axs='xy'\n            extents = np.array([getattr(ax, 'get_{}lim'.format(dim))() for dim in axs])\n            sz = extents[:,1] - extents[:,0]\n            maxsize = max(abs(sz))\n            for dim in axs:\n                getattr(ax, 'set_{}lim'.format(dim))(0, maxsize)\n    if axis_labels is not None:\n        ax.set_xlabel(axis_labels[0])\n        if len(dims)>1:\n            ax.set_ylabel(axis_labels[1])\n        if len(dims)>1:\n            ax.set_zlabel(axis_labels[2])\n    else:\n        ax.set_xlabel('$k_' + str(dims[0])+'$',size=20)\n        if len(dims) > 1:\n            ax.set_ylabel('$k_' + str(dims[1])+'$',size=20)\n        if len(dims) > 2:\n            ax.set_zlabel('$k_' + str(dims[2])+'$',size=20)\n        plt.grid()\n    x_coordinates = [mi[dims[0]] for mi in mis]\n    xticks=list(range(min(x_coordinates),max(x_coordinates)+1))\n    ax.set_xticks(xticks)\n    if len(dims)>1:\n        y_coordinates = [mi[dims[1]] for mi in mis]\n        ax.set_yticks(list(range(min(y_coordinates),max(y_coordinates)+1)))\n    if len(dims)>2:\n        z_coordinates = [mi[dims[2]] for mi in mis]\n        ax.set_zticks(list(range(min(z_coordinates),max(z_coordinates)+1)))\n    if index_labels:\n        for mi in index_labels:\n            ax.annotate('{:.3g}'.format(index_labels[mi]),xy=(mi[0],mi[1]))\n    if legend and len(group_names)>1:\n        ax.legend([patches.Patch(color=color) for color in np.flipud(colors)],group_names)\n    return ax", "response": "Plot indices of a multi - index set."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots a polynomial approximation of a single object.", "response": "def ezplot(f,xlim,ylim=None,ax = None,vectorized=True,N=None,contour = False,args=None,kwargs=None,dry_run=False,show=None,include_endpoints=False):\n    '''\n    Plot polynomial approximation.\n    \n    :param vectorized: `f` can handle an array of inputs\n    '''\n    kwargs = kwargs or {}\n    args = args or []\n    d = 1 if ylim is None else 2\n    if ax is None:\n        fig = plt.figure()\n        show = show if show is not None else True\n        ax = fig.gca() if (d==1 or contour) else fig.gca(projection='3d')\n    if d == 1:\n        if N is None:\n            N = 200\n        if include_endpoints:\n            X = np.linspace(xlim[0],xlim[1],N)\n        else:\n            L = xlim[1] - xlim[0]\n            X = np.linspace(xlim[0] + L / N, xlim[1] - L / N, N)\n        X = X.reshape((-1, 1))\n        if vectorized:\n            Z = f(X)\n        else:\n            Z = np.array([f(x) for x in X])\n        if not dry_run:\n            C = ax.plot(X, Z,*args,**kwargs)\n    elif d == 2:\n        if N is None:\n            N = 30\n        T = np.zeros((N, 2))\n        if include_endpoints:\n            T[:,0]=np.linspace(xlim[0],xlim[1],N)\n            T[:,1]=np.linspace(ylim[0],ylim[1],N)\n        else:\n            L = xlim[1] - xlim[0]\n            T[:, 0] = np.linspace(xlim[0] + L / N, xlim[1] - L / N, N) \n            L = ylim[1] - ylim[0]\n            T[:, 1] = np.linspace(ylim[0] + L / N, ylim[1] - L / N, N) \n        X, Y = meshgrid(T[:, 0], T[:, 1])\n        Z = grid_evaluation(X, Y, f,vectorized=vectorized)\n        if contour:\n            if not dry_run:\n                # C = ax.contour(X,Y,Z,levels = np.array([0.001,1000]),colors=['red','blue'])\n                N=200\n                colors=np.concatenate((np.ones((N,1)),np.tile(np.linspace(1,0,N).reshape(-1,1),(1,2))),axis=1)\n                colors = [ [1,1,1],*colors,[1,0,0]]\n                print('max',np.max(Z[:]))\n                C = ax.contourf(X,Y,Z,levels = [-np.inf,*np.linspace(-20,20,N),np.inf],colors=colors)\n        else:\n            if not dry_run:\n                C = ax.plot_surface(X, Y, Z)#cmap=cm.coolwarm, \n                # C = ax.plot_wireframe(X, Y, Z, rcount=30,ccount=30)\n    if show:\n        plt.show()\n    return ax,C,Z"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating X and Y using for example Hierarchy", "response": "def plot3D(X, Y, Z):\n    '''\n    Surface plot.\n    \n    Generate X and Y using, for example\n          X,Y = np.mgrid[0:1:50j, 0:1:50j]\n        or\n          X,Y= np.meshgrid([0,1,2],[1,2,3]).\n    \n    :param X: 2D-Array of x-coordinates\n    :param Y: 2D-Array of y-coordinates\n    :param Z: 2D-Array of z-coordinates\n    '''\n    fig = plt.figure()\n    ax = Axes3D(fig)\n    light = LightSource(90, 90)\n    illuminated_surface = light.shade(Z, cmap=cm.coolwarm)  # @UndefinedVariable\n    Xmin = np.amin(X)\n    Xmax = np.amax(X)\n    Ymin = np.amin(Y)\n    Ymax = np.amax(Y)\n    Zmin = np.amin(Z)\n    Zmax = np.amax(Z)\n    ax.contourf(X, Y, Z, zdir='x', offset=Xmin - 0.1 * (Xmax - Xmin), cmap=cm.coolwarm, alpha=1)  # @UndefinedVariable\n    ax.contourf(X, Y, Z, zdir='y', offset=Ymax + 0.1 * (Ymax - Ymin), cmap=cm.coolwarm, alpha=1)  # @UndefinedVariable\n    ax.contourf(X, Y, Z, zdir='z', offset=Zmin - 0.1 * (Zmax - Zmin), cmap=cm.coolwarm, alpha=1)  # @UndefinedVariable\n    ax.plot_surface(X, Y, Z, cstride=5, rstride=5, facecolors=illuminated_surface, alpha=0.5)\n    plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplot a single convergence order for a set of values.", "response": "def plot_convergence(times, values, name=None, title=None, reference='self', convergence_type='algebraic', expect_residuals=None,\n                     expect_times=None, plot_rate='fit', base = np.exp(0),xlabel = 'x', p=2, preasymptotics=True, stagnation=False, marker='.',\n                     legend='lower left',relative = False,ax = None):\n    '''\n    Show loglog or semilogy convergence plot.\n    \n    Specify :code:`reference` if exact limit is known. Otherwise limit is \n    taken to be last entry of :code:`values`.\n    \n    Distance to limit is computed as RMSE (or analogous p-norm if p is specified)\n    \n    Specify either :code:`plot_rate`(pass number or 'fit') or \n    :code:`expect_residuals` and :code:`expect_times` to add a second plot with\n    the expected convergence.\n    \n    :param times: Runtimes\n    :type times: List of positive numbers\n    :param values: Outputs\n    :type values: List of arrays\n    :param reference: Exact solution, or 'self' if not available\n    :type reference: Array or 'self'\n    :param convergence_type: Convergence type\n    :type convergence_type: 'algebraic' or 'exponential'\n    :param expect_residuals: Expected residuals\n    :type expect_residuals: List of positive numbers\n    :param expect_times: Expected runtimes\n    :type expect_times: List of positive numbers\n    :param plot_rate: Expected convergence order\n    :type plot_rate: Real or 'fit'\n    :param preasymptotics: Ignore initial entries for rate fitting\n    :type preasymptotics: Boolean\n    :param stagnation: Ignore final entries from rate fitting\n    :type stagnation: Boolean\n    :param marker: Marker for data points\n    :type marker: Matplotlib marker string\n    :return: fitted convergence order\n    '''\n    name = name or ''\n    self_reference = (isinstance(reference,str) and reference=='self') #reference == 'self' complains when reference is a numpy array\n    ax = ax or plt.gca()\n    color = next(ax._get_lines.prop_cycler)['color']\n    ax.tick_params(labeltop=False, labelright=True, right=True, which='both')\n    ax.yaxis.grid(which=\"minor\", linestyle='-', alpha=0.5)\n    ax.yaxis.grid(which=\"major\", linestyle='-', alpha=0.6)\n    c_ticks = 3\n    ACCEPT_MISFIT = 0.1\n    values, times = np.squeeze(values), np.squeeze(times)\n    assert(times.ndim == 1)\n    assert(len(times) == len(values))\n    sorting = np.argsort(times)\n    times = times[sorting]\n    values = values[sorting]\n    if plot_rate == True:\n        plot_rate = 'fit'\n    if plot_rate !='fit':\n        plot_rate = plot_rate*np.log(base)#Convert to a rate w.r.t. exp\n    if self_reference:\n        if len(times) <= 2:\n            raise ValueError('Too few data points')\n        limit = values[-1]\n        limit_time = times[-1]\n        times = times[0:-1]\n        values = values[0:-1]\n    else:\n        limit = np.squeeze(reference)\n        limit_time = np.Inf\n    residuals = np.zeros(len(times))\n    N = limit.size\n    for L in range(len(times)):\n        if p < np.Inf:\n            residuals[L] = np.power(np.sum(np.power(np.abs(values[L] - limit), p) / N), 1. / p)  #\n        else:\n            residuals[L] = np.amax(np.abs(values[L] - limit))\n    if relative:\n        if p<np.Inf:\n            residuals /= np.power(np.sum(np.power(np.abs(limit),p)/N),1./p)\n        else:\n            residuals /= np.amax(np.abs(limit))\n    try:\n        remove = np.isnan(times) | np.isinf(times) | np.isnan(residuals) | np.isinf(residuals) | (residuals == 0) | ((times == 0) & (convergence_type == 'algebraic'))\n    except TypeError:\n        print(times,residuals)\n    times = times[~remove]\n    if sum(~remove) < (2 if self_reference else 1):\n        raise ValueError('Too few valid data points')\n    residuals = residuals[~remove]\n    if convergence_type == 'algebraic':\n        x = np.log(times)\n        limit_x = np.log(limit_time)\n    else:\n        x = times\n        limit_x = limit_time\n    #min_x = min(x)\n    max_x = max(x)\n    y = np.log(residuals)\n    try:\n        rate, offset, min_x_fit, max_x_fit = _fit_rate(x, y, stagnation, preasymptotics, limit_x, have_rate=False if (plot_rate == 'fit' or plot_rate is None) else plot_rate)\n    except FitError as e:\n        warnings.warn(str(e))\n        plot_rate = False\n        rate = None\n    if self_reference:\n        if rate >= 0:\n            warnings.warn('No sign of convergence')\n        else:\n            real_rate = _real_rate(rate, l_bound=min_x_fit, r_bound=max_x_fit, reference_x=limit_x)\n            if (real_rate is None or abs((real_rate - rate) / rate) >= ACCEPT_MISFIT):\n                warnings.warn(('Self-convergence strongly affects plot and would yield misleading fit.')\n                              + (' Estimated true rate: {}.'.format(real_rate) if real_rate else '')\n                              + (' Fitted rate: {}.'.format(rate) if rate else ''))      \n    if plot_rate:\n        name += 'Fitted rate: ' if plot_rate == 'fit' else 'Plotted rate: '\n        if convergence_type == 'algebraic':\n            name+='{:.2g})'.format(rate) \n        else:\n            base_rate = rate/np.log(base)\n            base_rate_str = f'{base_rate:.2g}'\n            if base_rate_str=='-1':\n                base_rate_str='-'\n            if base_rate_str =='1':\n                base_rate_str = ''\n            name+=f'${base}^{{{base_rate_str}{xlabel}}}$'\n        if convergence_type == 'algebraic':\n            X = np.linspace(np.exp(min_x_fit), np.exp(max_x_fit), c_ticks)\n            ax.loglog(X, np.exp(offset) * X ** rate, '--', color=color)\n        else:\n            X = np.linspace(min_x_fit, max_x_fit, c_ticks)\n            ax.semilogy(X, np.exp(offset + rate * X), '--', color=color)\n    max_x_data = max_x\n    keep_1 = (x <= max_x_data)\n    if convergence_type == 'algebraic':\n        ax.loglog(np.array(times)[keep_1], np.array(residuals)[keep_1], label=name, marker=marker, color=color)\n        ax.loglog(np.array(times), np.array(residuals), marker=marker, color=color, alpha=0.5)\n    else:\n        ax.semilogy(np.array(times)[keep_1], np.array(residuals)[keep_1], label=name, marker=marker, color=color)\n        ax.semilogy(np.array(times), np.array(residuals), marker=marker, color=color, alpha=0.5)\n    if expect_times is not None and expect_residuals is not None:\n        ax.loglog(expect_times, expect_residuals, '--', marker=marker, color=color) \n    if name:\n        ax.legend(loc=legend)\n    if title:\n        ax.set_title(title)\n    return rate"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lower(option,value):\n    '''\n    Enforces lower case options and option values where appropriate\n    '''\n    if type(option) is str:\n        option=option.lower()\n    if type(value) is str:\n        value=value.lower()\n    return (option,value)", "response": "Enforces lower case options and option values where appropriate\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_float(option,value):\n    '''\n    Converts string values to floats when appropriate\n    '''\n    if type(value) is str:\n        try:\n            value=float(value)\n        except ValueError:\n            pass\n    return (option,value)", "response": "Converts string values to floats when appropriate\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_bool(option,value):\n    '''\n    Converts string values to booleans when appropriate\n    '''\n    if type(value) is str:\n        if value.lower() == 'true':\n            value=True\n        elif value.lower() == 'false':\n            value=False\n    return (option,value)", "response": "Converts string values to booleans when appropriate\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fork(self,name):\n        '''\n        Create fork and store it in current instance\n        '''\n        fork=deepcopy(self)\n        self[name]=fork\n        return fork", "response": "Create a new instance of the current instance and store it in the current instance"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef smart_range(*args):\n    '''\n    smart_range(1,3,9)==[1,3,5,7,9]\n    '''\n    if len(args)==1:#String\n        string_input = True\n        string = args[0].replace(' ','')\n        original_args=string.split(',')\n        args = []\n        for arg in original_args:\n            try:\n                args.append(ast.literal_eval(arg))\n            except (ValueError,SyntaxError):\n                try:# Maybe an arithmetic expression?\n                    args.append(eval(arg,{'__builtins__':{}}))\n                except (NameError,SyntaxError):#Input was actually meant to be a string, e.g. smart_range('a,...,z'), or input was interval type, e.g. smart_range('[1,3]/10')\n                    args.append(arg)\n    else:\n        string_input = False\n    arg_start = args[0]\n    if len(args)>2:\n        arg_step = args[1]\n        if len(args)>3:\n            raise ValueError('At most 3 arguments: start, step, stop')\n    else:\n        arg_step = None\n    arg_end = args[-1]\n    if String.valid(arg_start) and len(arg_start)==1:#Character\n        range_type = 'char'\n    elif all(Integer.valid(arg) for arg in args):\n        range_type = 'integer'\n    else: \n        if string_input and original_args[0][0] in ['(','[']:\n            range_type = 'linspace'\n        else:\n            range_type = 'float'\n\n    if range_type == 'char':\n        start = ord(arg_start)\n        step = (ord(arg_step)- start) if arg_step else 1\n        end = ord(arg_end)\n        out = [chr(i) for i in range(start,end+step,step)]\n        if np.sign(step)*(ord(out[-1])-end)>0:\n            del out[-1]\n        return out\n    elif range_type == 'integer':\n        if string_input:\n            if len(args)==2 and all('**' in oa for oa in original_args):#Attempt geometric progresesion\n                bases,exponents = zip(*[oa.split('**') for oa in original_args])\n                if len(set(bases))==1:#Keep attempting geometric progression\n                    return [int(bases[0])**exponent for exponent in smart_range(','.join(exponents))]\n        start = arg_start\n        step = (arg_step - arg_start) if arg_step is not None else 1\n        end = arg_end\n        out = list(range(start,end+step,step))\n        if np.sign(step)*(out[-1]-end)>0:\n            del out[-1]\n        return out\n    elif range_type == 'float':\n        if len(args)==2 and all('**' in oa for oa in original_args):#Attempt geometric progresesion\n            bases,exponents = zip(*[oa.split('**') for oa in original_args])\n            if len(set(bases))==1:#Keep attempting geometric progression\n                return [float(bases[0])**exponent for exponent in smart_range(','.join(exponents)) ]\n        if len(args) == 2:\n            raise ValueError()\n        start = arg_start\n        step = arg_step - arg_start\n        end = arg_end\n        out = list(np.arange(start,end+1e-12*step,step))\n        return out\n    elif range_type == 'linspace':\n        lopen,start = (original_args[0][0]=='('),float(original_args[0][1:])\n        end,N = original_args[1].split('/')\n        end,ropen = float(end[:-1]),(end[-1]==')')\n        N = ast.literal_eval(N)+lopen +ropen\n        points = np.linspace(start,end,num=N)\n        return points[lopen:len(points)-ropen]", "response": "A smart range function that returns a single object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting list of dictionaries to dictionary of lists", "response": "def ld_to_dl(ld):\n    '''\n    Convert list of dictionaries to dictionary of lists\n    '''\n    if ld:\n        keys = list(ld[0])\n        dl = {key:[d[key] for d in ld] for key in keys}\n        return dl\n    else:\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef chain(*fs):\n    '''\n    Concatenate functions\n    '''\n    def chained(x):\n        for f in reversed(fs):\n            if f:\n                x=f(x)\n        return x\n    return chained", "response": "Chain a sequence of functions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsplitting list into N lists", "response": "def split_list(l,N):\n    '''\n    Subdivide list into N lists\n    '''\n    npmode = isinstance(l,np.ndarray)\n    if npmode:\n        l=list(l)\n    g=np.concatenate((np.array([0]),np.cumsum(split_integer(len(l),length=N))))\n    s=[l[g[i]:g[i+1]] for i in range(N)]\n    if npmode:\n        s=[np.array(sl) for sl in s]\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef random_word(length,dictionary = False):#may return offensive words if dictionary = True\n    '''\n    Creates random lowercase words from dictionary or by alternating vowels and consonants\n    \n    The second method chooses from 85**length words.\n    The dictionary method chooses from 3000--12000 words for 3<=length<=12\n    (though this of course depends on the available dictionary)\n    \n    :param length: word length\n    :param dictionary: Try reading from dictionary, else fall back to artificial words\n    '''\n    if dictionary:\n        try:\n            with open('/usr/share/dict/words') as fp:\n                words = [word.lower()[:-1] for word in fp.readlines() if re.match('[A-Za-z0-9]{}$'.format('{'+str(length)+'}'),word)]\n            return random.choice(words)\n        except FileNotFoundError:\n            pass\n    vowels = list('aeiou')\n    consonants = list('bcdfghklmnprstvwz')\n    pairs = [(random.choice(consonants),random.choice(vowels)) for _ in range(length//2+1)] \n    return ''.join([l for p in pairs for l in p])[:length]", "response": "Returns a random word from the dictionary or by alternating vowels and consonants."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef string_from_seconds(seconds):\n    '''\n    Converts seconds into elapsed time string of form \n    \n    (X days(s)?,)? HH:MM:SS.YY\n    \n    '''\n    td = str(timedelta(seconds = seconds))\n    parts = td.split('.')\n    if len(parts) == 1:\n        td = td+'.00'\n    elif len(parts) == 2:\n        td = '.'.join([parts[0],parts[1][:2]])\n    return td", "response": "Converts seconds into elapsed time string of form \n HH. MM. YY."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a list of keyword pairs into a path or filename AttributeNames", "response": "def path_from_keywords(keywords,into='path'):\n    '''\n    turns keyword pairs into path or filename \n    \n    if `into=='path'`, then keywords are separted by underscores, else keywords are used to create a directory hierarchy\n    '''\n    subdirs = []\n    def prepare_string(s):\n        s = str(s)\n        s = re.sub('[][{},*\"'+f\"'{os.sep}]\",'_',s)#replace characters that make bash life difficult by underscore \n        if into=='file':\n            s = s.replace('_', ' ')#Remove underscore because they will be used as separator\n        if ' ' in s:\n            s = s.title()\n            s = s.replace(' ','')\n        return s\n    if isinstance(keywords,set):\n        keywords_list = sorted(keywords)\n        for property in keywords_list:\n            subdirs.append(prepare_string(property))\n    else:\n        keywords_list = sorted(keywords.items())\n        for property,value in keywords_list:  # @reservedassignment\n            if Bool.valid(value):\n                subdirs.append(('' if value else ('not_' if into=='path' else 'not'))+prepare_string(property))\n            #elif String.valid(value):\n            #    subdirs.append(prepare_string(value))\n            elif (Float|Integer).valid(value):\n                subdirs.append('{}{}'.format(prepare_string(property),prepare_string(value)))\n            else:\n                subdirs.append('{}{}{}'.format(prepare_string(property),'_' if into == 'path' else '',prepare_string(value)))\n    if into == 'path':\n        out = os.path.join(*subdirs)\n    else:\n        out = '_'.join(subdirs)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds files in a node tree.", "response": "def find_files(pattern, path=None,match_name=False):\n    '''\n    https://stackoverflow.com/questions/1724693/find-a-file-in-python\n\n    WARNING: pattern is by default matched to entire path not to file names\n    '''\n    if not path:\n        path = os.getcwd()\n    result = []\n    for root, __, files in os.walk(path):\n        for name in files:\n            if fnmatch.fnmatch(name if match_name else os.path.join(root,name),pattern):\n                result.append(os.path.join(root, name))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_directories(pattern, path=None,match_name=False):\n    '''\n    WARNING: pattern is matched to entire path, not directory names, unless\n    match_name = True\n    '''\n    if not path:\n        path = os.getcwd()\n    result = []\n    for root, __, __ in os.walk(path):\n        match_against = os.path.basename(root) if match_name else root\n        try:\n            does_match = pattern.match(match_against)\n        except AttributeError:\n            does_match = fnmatch.fnmatch(match_against,pattern)\n        if does_match:\n            result.append(root)\n    return result", "response": "Find all directories that match a pattern."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nzips a directory of all the files in source_dir into zip_name.", "response": "def zip_dir(zip_name, source_dir,rename_source_dir=False):\n    '''\n    https://stackoverflow.com/questions/1855095/how-to-create-a-zip-archive-of-a-directory\n    '''\n    src_path = Path(source_dir).expanduser().resolve()\n    with ZipFile(zip_name, 'w', ZIP_DEFLATED) as zf:\n        for file in src_path.rglob('*'):\n            path_in_zip = str(file.relative_to(src_path.parent))\n            if rename_source_dir != False:\n                _,tail = path_in_zip.split(os.sep,1)\n                path_in_zip=os.sep.join([rename_source_dir,tail])\n            zf.write(str(file.resolve()), path_in_zip)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef integral(A=None,dF=None,F=None,axis = 0,trapez = False,cumulative = False):\n    '''\n    Turns an array A of length N (the function values in N points)\n    and an array dF of length N-1 (the masses of the N-1 intervals)\n    into an array of length N (the integral \\int A dF at N points, with first entry 0)\n    \n    :param A: Integrand (optional, default ones, length N)\n    :param dF: Integrator (optional, default ones, length N-1)\n    :param F: Alternative to dF (optional, length N)\n    :param trapez: Use trapezoidal rule (else left point)\n    '''\n    ndim = max(v.ndim for v in (A,dF,F) if v is not None)\n    def broadcast(x):\n        new_shape = [1]*ndim\n        new_shape[axis] = -1\n        return np.reshape(x,new_shape)\n    if F is not None:\n        assert(dF is None)\n        if F.ndim<ndim:\n            F = broadcast(F)\n        N = F.shape[axis]\n        dF = F.take(indices = range(1,N),axis = axis)-F.take(indices = range(N-1),axis = axis)\n    elif dF is not None:\n        if dF.ndim<ndim:\n            dF = broadcast(dF)\n        N = dF.shape[axis]+1\n    else:\n        if A.ndim<ndim:\n            A = broadcast(A)\n        N = A.shape[axis]\n    if A is not None:\n        if trapez:\n            midA = (A.take(indices = range(1,N),axis = axis)+A.take(indices = range(N-1),axis = axis))/2\n        else:\n            midA = A.take(indices=range(N-1),axis=axis)\n        if dF is not None:\n            dY = midA*dF\n        else:\n            dY = midA\n    else:\n        dY = dF\n    pad_shape = list(dY.shape)\n    pad_shape[axis] = 1\n    pad = np.zeros(pad_shape)\n    if cumulative:\n        return np.concatenate((pad,np.cumsum(dY,axis = axis)),axis = axis)\n    else:\n        return np.sum(dY,axis = axis)", "response": "This function takes an array A dF and an array F and returns an array of length N with first entry 0."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmultiply a Toeplitz matrix with first row a and first column b with vector v", "response": "def toeplitz_multiplication(a,b,v):\n    '''\n    Multiply Toeplitz matrix with first row a and first column b with vector v\n    \n    Normal matrix multiplication would require storage and runtime O(n^2);\n    embedding into a circulant matrix and using FFT yields O(log(n)n)\n    '''\n    a = np.reshape(a,(-1))\n    b = np.reshape(b,(-1))\n    n = len(a)\n    c = np.concatenate((a[[0]],b[1:],np.zeros(1),a[-1:0:-1]))\n    p = ifft(fft(c)*fft(v.T,n=2*n)).T#fft autopads input with zeros if n is supplied\n    if np.all(np.isreal(a)) and np.all(np.isreal(b)) and np.all(np.isreal(v)):\n        return np.real(p[:n])\n    else:\n        return p[:n]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nevaluate function on given grid and return values in grid format", "response": "def grid_evaluation(X, Y, f,vectorized=True):\n    '''\n    Evaluate function on given grid and return values in grid format\n    \n    Assume X and Y are 2-dimensional arrays containing x and y coordinates, \n    respectively, of a two-dimensional grid, and f is a function that takes\n    1-d arrays with two entries. This function evaluates f on the grid points\n    described by X and Y and returns another 2-dimensional array of the shape \n    of X and Y that contains the values of f.\n\n    :param X: 2-dimensional array of x-coordinates\n    :param Y: 2-dimensional array of y-coordinates\n    :param f: function to be evaluated on grid\n    :param vectorized: `f` can handle arrays of inputs\n    :return: 2-dimensional array of values of f\n    '''\n    XX = np.reshape(np.concatenate([X[..., None], Y[..., None]], axis=2), (X.size, 2), order='C')\n    if vectorized:\n        ZZ = f(XX)\n    else:\n        ZZ = np.array([f(x) for x in XX])\n    return np.reshape(ZZ, X.shape, order='C')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef orthonormal_complement_basis(v:NDim(1)):\n    '''\n    Return orthonormal basis of complement of vector.\n    \n    :param v: 1-dimensional numpy array \n    :return: Matrix whose .dot() computes coefficients w.r.t. an orthonormal basis of the complement of v \n        (i.e. whose row vectors form an orthonormal basis of the complement of v)\n    '''\n    _, _, V = np.linalg.svd(np.array([v]))\n    return V[1:]", "response": "Returns the orthonormal basis of complement of vector."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the element that is weighted by the sum of weights below and above are equal", "response": "def weighted_median(values, weights):\n    '''\n    Returns element such that sum of weights below and above are (roughly) equal\n    \n    :param values: Values whose median is sought\n    :type values: List of reals\n    :param weights: Weights of each value\n    :type weights: List of positive reals\n    :return: value of weighted median\n    :rtype: Real\n    '''\n    if len(values) == 1:\n        return values[0]\n    if len(values) == 0:\n        raise ValueError('Cannot take median of empty list')\n    values = [float(value) for value in values]\n    indices_sorted = np.argsort(values)\n    values = [values[ind] for ind in indices_sorted]\n    weights = [weights[ind] for ind in indices_sorted]\n    total_weight = sum(weights)\n    below_weight = 0\n    i = -1\n    while below_weight < total_weight / 2:\n        i += 1\n        below_weight += weights[i]\n    return values[i]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef log_calls(function):\n    '''\n    Decorator that logs function calls in their self.log\n    '''\n    def wrapper(self,*args,**kwargs):  \n        self.log.log(group=function.__name__,message='Enter') \n        function(self,*args,**kwargs)\n        self.log.log(group=function.__name__,message='Exit') \n    return wrapper", "response": "Decorator that logs function calls in their self. log\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef print_memory(function):\n    '''\n    Decorator that prints memory information at each call of the function\n    '''\n    import memory_profiler\n    def wrapper(*args,**kwargs):\n        m = StringIO()\n        temp_func = memory_profiler.profile(func = function,stream=m,precision=4)\n        output = temp_func(*args,**kwargs)\n        print(m.getvalue())\n        m.close()\n        return output\n    return wrapper", "response": "Decorator that prints memory information at each call of the function\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_profile(function):\n    '''\n    Decorator that prints memory and runtime information at each call of the function\n    '''\n    import memory_profiler\n    def wrapper(*args,**kwargs):\n        m=StringIO()\n        pr=cProfile.Profile()\n        pr.enable()\n        temp_func = memory_profiler.profile(func=function,stream=m,precision=4)\n        output = temp_func(*args,**kwargs)\n        print(m.getvalue())\n        pr.disable()\n        ps = pstats.Stats(pr)\n        ps.sort_stats('cumulative').print_stats('(?!.*memory_profiler.*)(^.*$)',20)\n        m.close()\n        return output\n    return wrapper", "response": "Decorator that prints memory and runtime information at each call of the function\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint peak memory usage (in MB) of a function call :param func: Function to be called :param stream: Stream to write peak memory usage (defaults to stdout) https://stackoverflow.com/questions/9850995/tracking-maximum-memory-usage-by-a-python-function", "response": "def print_peak_memory(func,stream = None):\n    \"\"\"\n    Print peak memory usage (in MB) of a function call\n    \n    :param func: Function to be called\n    :param stream: Stream to write peak memory usage (defaults to stdout)  \n    \n    https://stackoverflow.com/questions/9850995/tracking-maximum-memory-usage-by-a-python-function\n    \"\"\"\n    import time\n    import psutil\n    import os\n    memory_denominator=1024**2\n    memory_usage_refresh=0.05\n    def wrapper(*args,**kwargs):\n        from multiprocessing.pool import ThreadPool\n        pool = ThreadPool(processes=1)\n        process = psutil.Process(os.getpid())\n        start_mem = process.memory_info().rss\n        delta_mem = 0\n        max_memory = 0\n        async_result = pool.apply_async(func, args,kwargs)\n        # do some other stuff in the main process\n        while(not async_result.ready()):\n            current_mem = process.memory_info().rss\n            delta_mem = current_mem - start_mem\n            if delta_mem > max_memory:\n                max_memory = delta_mem\n            # Check to see if the library call is complete\n            time.sleep(memory_usage_refresh)\n        \n        return_val = async_result.get()  # get the return value from your function.\n        max_memory /= memory_denominator\n        if stream is not None:\n            stream.write(str(max_memory))\n        return return_val\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate(arg, spec):\n    '''\n    Make sure `arg` adheres to specification\n    \n    :param arg: Anything\n    :param spec: Specification\n    :type spec: Specification\n    \n    :return: Validated object\n    '''\n    rejection_subreason = None\n    if spec is None:\n        return arg\n    try:\n        return spec._validate(arg)\n    except Exception as e:\n        rejection_subreason = e\n    try:\n        lenience = spec.lenience\n    except AttributeError:\n        pass\n    else:\n        for level in range(1, lenience + 1):\n            temp = None\n            try:\n                temp = spec.forgive(arg=arg, level=level)\n            except Exception:\n                pass  # Forgiving might fail, it is very hard to predict what happens when you do stuff to things that aren't what you think\n            if temp is not None and temp is not arg:\n                arg = temp\n                try:\n                    return spec._validate(arg)\n                except Exception as e:\n                    rejection_subreason = e\n    rejection_reason = '`{}` was rejected by `{}`.'.format(arg, spec)\n    rejection_subreason = ' ({}: {})'.format(rejection_subreason.__class__.__name__, rejection_subreason) if rejection_subreason is not None else ''\n    raise ValidationError(rejection_reason + rejection_subreason)", "response": "Make sure `arg` adheres to specification\n    \n    :param arg: Anything\n    :param spec: Specification\n    :type spec: Specification\n    \n    :return: Validated object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _validate_many(args, specs, defaults,passed_conditions,value_conditions,\n                  allow_unknowns,unknowns_spec): \n    '''\n    Similar to validate but validates multiple objects at once, each with their own specification. \n    \n    Fill objects that were specified but not provided with NotPassed or default values\n    Apply `value_condition` to object dictionary as a whole \n    '''\n    validated_args = builtins.dict() \n    passed_but_not_specified = set(args.keys()) - set(specs.keys())\n    if passed_but_not_specified:\n        if not allow_unknowns:\n            raise ValueError(('Arguments {} were passed but not specified (use ' + \n                 '`allow_unknowns=True` to avoid this error)'.format(passed_but_not_specified)))\n        else:\n            for arg in passed_but_not_specified:\n                if unknowns_spec is not None:\n                    specs[arg] = unknowns_spec\n    if passed_conditions:\n        validate(args, Dict(passed_conditions=passed_conditions))\n    for arg in specs:\n        if (not arg in args) or NotPassed(args[arg]):\n            if arg in defaults:\n                if isinstance(defaults[arg],DefaultGenerator):\n                    validated_args[arg] = defaults[arg]()\n                else:\n                    validated_args[arg] = defaults[arg]\n            else:\n                validated_args[arg] = NotPassed\n        else:#Default values and NotPassed values are not validated. Former has advantage that default values need to be `correct` without validation and thus encourage the user to pass stuff that doesn't need validation, and is therefore faster\n            validated_args[arg] = validate(args[arg], specs[arg])\n    if value_conditions:\n        validated_args = validate(validated_args, value_conditions)\n    return validated_args", "response": "Validate a list of objects at once."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef black_scholes(times,r,sigma,S0,d,M,dW=None):\n    '''\n    Return M Euler-Maruyama sample paths with N time steps of S_t, where \n        dS_t = S_t*r*dt+S_t*sigma*dW_t\n        S(0)=S0\n    \n    :rtype: M x N x d array\n    '''\n    N=len(times)\n    times = times.flatten()\n    p0 = np.log(S0)\n    if dW is None:\n        dW=np.sqrt(times[1:]-times[:-1])[None,:,None]*np.random.normal(size=(M,N-1,d))\n    if np.squeeze(sigma).ndim<=1:\n        dF = sigma*dW\n        ito_correction = np.squeeze(sigma**2/2)\n    else:\n        dF = np.einsum('ij,...j',sigma,dW)\n        ito_correction = np.sum(sigma**2,1)/2\n    drift  = (r-ito_correction)*times[None,:,None]\n    diffusion = integral(dF=dF,axis=1,cumulative = True)\n    return np.exp(p0 + drift + diffusion)", "response": "Return the black scholes of the given time steps."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn M x N x d array with M Euler - Maruyama sample paths with N time steps of S_t.", "response": "def heston(times,mu,rho,kappa,theta,xi,S0,nu0,d,M,nu_1d=True):\n    '''\n    Return M Euler-Maruyama sample paths with N time steps of (S_t,v_t), where\n        (S_t,v_t) follows the Heston model of mathematical finance\n\n    :rtype: M x N x d array\n    '''\n    d_nu = 1 if nu_1d else d\n    nu = np.zeros((M,len(times),d_nu))\n    S = np.zeros((M,len(times),d))\n    nu[:,0,:] = nu0\n    S[:,0,:] = S0\n    if 2*kappa*theta<=xi**2:\n        raise ValueError('Feller condition not satisfied')\n    test = np.std(np.diff(times.flatten())) \n    if test>1e-12:\n        raise ValueError\n    dt = times[1]-times[0]\n    N = len(times)\n    if d == 1:\n        if np.array(rho).size ==1:\n            rho = np.array([[1,rho],[rho,1]])\n    chol = np.linalg.cholesky(rho)\n    dW = np.sqrt(dt)*np.einsum('ij,...j',chol,np.random.normal(size=(M,N-1,d+d_nu)))\n    for i in range(1,N):\n        dt = times[i]-times[i-1]\n        nu[:,i,:] = np.abs(nu[:,i-1,:] + kappa*(theta-nu[:,i-1,:])*dt+xi*np.sqrt(nu[:,i-1,:])*dW[:,i-1,d:])\n    S = S0*np.exp(integral(np.sqrt(nu),dF = dW[:,:,:d],axis=1,cumulative = True)+integral(mu - 0.5*nu,F = times,axis=1,trapez=False,cumulative = True))\n    return np.concatenate((S,nu),axis=-1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a fractional Brownian motion with differentiability index H for each time step.", "response": "def fBrown(H,T,N,M,dW = None,cholesky = False):\n    '''\n    Sample fractional Brownian motion with differentiability index H \n    on interval [0,T] (H=1/2 yields standard Brownian motion)\n    \n    :param H: Differentiability, larger than 0\n    :param T: Final time\n    :param N: Number of time steps\n    :param M: Number of samples\n    :param dW: Driving noise, optional\n    '''\n    alpha = 0.5-H\n    times = np.linspace(0, T, N)\n    dt = T/(N-1)\n    if cholesky:\n        if dW is not None:\n            raise ValueError('Cannot use provided dW if Cholesky method is used')\n        times = times[1:]\n        tdt = times/np.reshape(times,(-1,1))\n        tdt[np.tril_indices(N-1,-1)]=0\n        cov = np.reshape(times,(-1,1))**(1-2*alpha)*(1/(1-alpha))*(tdt-1)**(-alpha)*scipy.special.hyp2f1(alpha,1-alpha,2-alpha,1/(1-tdt))\n        cov[0,:] = 0\n        np.fill_diagonal(cov,times**(1-2*alpha)/(1-2*alpha))\n        cov[np.tril_indices(N-1,-1)] = cov.T[np.tril_indices(N-1,-1)]\n        L = scipy.linalg.cholesky(cov)\n        return np.concatenate((np.zeros((1,M)),L.T@np.random.normal(size=(N-1,M))))\n    if dW is None:\n        dW = np.sqrt(dt)*np.random.normal(size=(N-1,M))\n    if H == 0.5:\n        return integral(dF = dW,cumulative = True)  \n    a = 1/dt/(1-alpha)*((T-times[N-2::-1])**(1-alpha)-(T-times[:0:-1])**(1-alpha))#a is array that is convolved with dW. Values arise from conditioning integral pieces on dW \n    out = toeplitz_multiplication(a,np.zeros_like(a),dW[::-1])[::-1]\n    out -=a[0]*dW#Redo last bit of defining integral with exact simulation below\n    cov = np.array([[ dt**(1-2*alpha)/(1-2*alpha),dt**(1-alpha)/(1-alpha)],[dt**(1-alpha)/(1-alpha),dt]])\n    var = cov[0,0]-cov[0,1]**2/cov[1,1]\n    out += cov[0,1]/cov[1,1]*dW #Conditional mean\n    out += np.sqrt(var)*np.random.normal(size = (N-1,M))#Conditional variance\n    out = np.concatenate((np.zeros((1,M)),out))\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef r_bergomi(H,T,eta,xi,rho,S0,r,N,M,dW=None,dW_orth=None,cholesky = False,return_v=False):\n    '''\n    Return M Euler-Maruyama sample paths with N time steps of (S_t,v_t), where\n        (S_t,v_t) follows the rBergomi model of mathematical finance\n\n    :rtype: M x N x d array\n    '''\n    times = np.linspace(0, T, N)\n    dt = T/(N-1)\n    times = np.reshape(times,(-1,1))\n    if dW is None:\n        dW = np.sqrt(dt)*np.random.normal(size=(N-1,M))\n    if dW_orth is None:\n        dW_orth = np.sqrt(dt)*np.random.normal(size=(N-1,M))\n    dZ = rho*dW+np.sqrt(1-rho**2)*dW_orth\n    Y = eta*np.sqrt(2*H)*fBrown(H,T,N,M,dW =dW,cholesky = cholesky)\n    v = xi*np.exp(Y-0.5*(eta**2)*times**(2*H))\n    S = S0*np.exp(integral(np.sqrt(v),dF = dZ,axis=0,cumulative = True)+integral(r - 0.5*v,F = times,axis=0,trapez=False,cumulative = True))\n    if return_v:\n        return np.array([S,v]).T\n    else:\n        return np.array([S]).T", "response": "Return M Euler - Maruyama sample paths with N time steps of S_t and v_t."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unique(seq):\n    '''\n    https://stackoverflow.com/questions/480214/how-do-you-remove-duplicates-from-a-list-in-whilst-preserving-order\n    '''\n    has = []\n    return [x for x in seq if not (x in has or has.append(x))]", "response": "Returns a list of unique elements in a sequence."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_default_fields(self):\n        field_names = self._meta.get_all_field_names()\n        if 'id' in field_names:\n            field_names.remove('id')\n\n        return field_names", "response": "get all default fields of the model"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_field_value(self, field, value_verbose=True):\n        if not value_verbose:\n            \"\"\"\n            value_verbose == false, return raw value\n            \"\"\"\n            value = field._get_val_from_obj(self)\n        else:\n            if isinstance(field, ForeignKey):\n                # \u83b7\u53d6\u5916\u952e\u7684\u5185\u5bb9\n                value = getattr(self, field.name)\n            else:\n                # \u975e\u5916\u952e\n                try:\n                    value =  self._get_FIELD_display(field)\n                except :\n                    value = field._get_val_from_obj(self)\n        if(value == True or value == False or isinstance(value, (int, float))):\n            return value\n        return unicode(value)", "response": "Get the value of a field."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_fields(self, field_verbose=True, value_verbose=True, fields=[], extra_fields=[], remove_fields = []):\n        '''\n        \u8fd4\u56de\u5b57\u6bb5\u540d\u53ca\u5176\u5bf9\u5e94\u503c\u7684\u5217\u8868\n        field_verbose \u4e3aTrue\uff0c\u8fd4\u56de\u5b9a\u4e49\u4e2d\u7684\u5b57\u6bb5\u7684verbose_name\uff0c False\u8fd4\u56de\u5176name\n        value_verbose \u4e3aTrue\uff0c\u8fd4\u56de\u6570\u636e\u7684\u663e\u793a\u6570\u636e\uff0c\u4f1a\u8f6c\u6362\u4e3achoice\u7684\u5185\u5bb9\uff0c\u4e3aFalse\uff0c \u8fd4\u56de\u6570\u636e\u7684\u5b9e\u9645\u503c\n        fields \u6307\u5b9a\u4e86\u8981\u663e\u793a\u7684\u5b57\u6bb5\n        extra_fields \u6307\u5b9a\u4e86\u8981\u7279\u6b8a\u5904\u7406\u7684\u975efield\uff0c\u6bd4\u5982\u662f\u51fd\u6570\n        remove_fields \u6307\u5b9a\u4e86\u4e0d\u663e\u793a\u7684\u5b57\u6bb5\n        '''\n        field_list = []\n        for field in self.__class__._meta.fields:\n            if field.name in remove_fields:\n                # \u4e0d\u663e\u793a\u7684\u5b57\u6bb5\uff0c\u8df3\u8fc7\u5faa\u73af\n                continue\n\n            if fields and field.name not in fields:\n                # fields \u4e0d\u4e3a\u7a7a\u5217\u8868\uff0c\u5373\u6307\u5b9a\u4e86\u8981\u663e\u793a\u7684\u5b57\u6bb5\uff0c\u5e76\u4e14field.name  \u4e0d\u518d\u6307\u5b9a\u7684\u5217\u8868\u4e2d\uff0c\u8df3\u8fc7\u5faa\u73af\n                continue\n\n            if field.verbose_name and field_verbose:\n                value_tuple = (field.verbose_name, self.get_field_value(field, value_verbose))\n            else:\n                value_tuple = (field.name, self.get_field_value(field, value_verbose))\n\n            field_list.append(value_tuple)\n\n        for name in extra_fields:\n            # \u5904\u7406\u51fd\u6570\n            method = getattr(self, name)\n            result = method()\n            value_tuple = (name, result)\n            field_list.append(value_tuple)\n\n        return field_list", "response": "Returns a list of all the fields in the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_url(request):\n\n    menu_id = request.GET.get('menu_id')\n    m_object = Menu.objects.get(pk=menu_id)\n    namespace = m_object.namespace\n    viewname = m_object.viewname\n    url_string = '%s:%s' %(namespace, viewname)\n    url = reverse(url_string)\n\n    return HttpResponse(url)", "response": "Get url of the last available menu item."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles POST requests only argument: row_index HTML\u4e2d\u7b2c\u51e0\u884c\u7684\u6807\u8bb0\uff0c\u539f\u503c\u8fd4\u56de app_label model_name pk app_label + model_name + pk \u53ef\u4ee5\u83b7\u53d6\u4e00\u4e2aobject method object + method \u5f97\u5230\u8981\u8c03\u7528\u7684\u65b9\u6cd5 \u5176\u5b83\u53c2\u6570\uff0chtml\u548cmethod\u4e2d\u540c\u65f6\u5b9a\u4e49, \u5728\u4e0a\u9762\u7684\u65b9\u6cd5\u4e2d\u4f7f\u7528", "response": "def post(self, request, *args, **kwargs):\n        \"\"\"\n        Handles POST requests only\n        argument:\n            row_index HTML\u4e2d\u7b2c\u51e0\u884c\u7684\u6807\u8bb0\uff0c\u539f\u503c\u8fd4\u56de\n            app_label\n            model_name\n            pk   app_label + model_name + pk \u53ef\u4ee5\u83b7\u53d6\u4e00\u4e2aobject\n            method  object + method \u5f97\u5230\u8981\u8c03\u7528\u7684\u65b9\u6cd5 \n            \u5176\u5b83\u53c2\u6570\uff0chtml\u548cmethod\u4e2d\u540c\u65f6\u5b9a\u4e49, \u5728\u4e0a\u9762\u7684\u65b9\u6cd5\u4e2d\u4f7f\u7528\n        \"\"\"\n        query_dict = dict(self.request.POST.items())\n        # row_index\u539f\u503c\u8fd4\u56de\uff0c\u5728datagrid\u5bf9\u5e94\u884c\u663e\u793a\u7ed3\u679c \n        row_index = query_dict.pop('row_index')\n        # \u5982\u679c\u547d\u4ee4\u6267\u884c\u6210\u529f\uff0c\u5e76\u4e14\u6ca1\u6709\u8fd4\u56de\u503c\uff0c\u5219\u8fd4\u56de \"text+'\u6210\u529f'\" \u7684\u63d0\u793a\n        text = query_dict.pop('text', None)\n\n        app_label = query_dict.pop('app_label')\n        model_name  = query_dict.pop('model_name')\n        method  = query_dict.pop('method')\n        pk = query_dict.pop('pk')\n        model = get_model(app_label, model_name)\n        object = model.objects.get(pk=pk)\n\n        try:\n            status = 0 # 0 success;  else fail\n            func = getattr(object, method)\n            # query_dict\u4e2d\u7684\u5176\u5b83\u53c2\u6570\u4f20\u9012\u7ed9\u8c03\u7528\u7684\u65b9\u6cd5, \u6240\u6709\u53c2\u6570\u90fd\u662f\u5b57\u7b26\u4e32\n            print query_dict\n            return_value = func(**query_dict)\n            message = return_value\n        except Exception, error_message:\n            # ajax \u5904\u7406\u5931\u8d25\n            status = 1  # 1 means fail\n            message = unicode(error_message)\n\n        # \u5982\u679c\u547d\u4ee4\u6267\u884c\u6210\u529f\uff0c\u5e76\u4e14\u6ca1\u6709\u8fd4\u56de\u503c\uff0c\u5219\u8fd4\u56de \"text+'\u6210\u529f'\" \u7684\u63d0\u793a\n        if not message:\n            message = text+'\u6210\u529f'\n\n        return self.render_to_json_response({'status':status, 'message':message, 'row_index':row_index})"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the list of checked items from the user menu.", "response": "def get_menu_checked(self, request):\n        \"\"\"\n        \u83b7\u53d6\u7528\u6237\u6216\u8005\u7528\u6237\u7ec4checked\u7684\u83dc\u5355\u5217\u8868\n        usermenu_form.html \u4e2d\u5b9a\u4e49\n        usermenu  \u8fd9\u4e24\u4e2amodel\u7684\u5b9a\u4e49\u7c7b\u4f3c\uff0c\u6bd4\u5982menus_checked\u548cmenus_show\n        groupmenu\n        @return  eg. ['1', '8', '9', '10' ]\n        \u83b7\u53d6\u7528\u6237\u6216\u8005\u7528\u6237\u7ec4\u7684check_ids,\u4f1a\u7ed9\u51faapp_label, model_name, pk eg. /easyui/menulistview/?app_label=easyui&model_name=UserMenu&pk=1\n        \"\"\"\n        checked_id = []\n        qd = request.GET\n        query_dict = dict(qd.items())\n        if query_dict:\n            #object = get_object(**query_dict)\n            app_label = query_dict['app_label']\n            model_name = query_dict['model_name']\n            pk = query_dict['pk']\n            model = get_model(app_label, model_name)\n            object =  model.objects.get(pk=pk)\n            checked_id = object.menus_checked.split(',')\n\n        return checked_id"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fetch(self, url, path, filename):\n        logger.debug('initializing download in ', url)\n        remote_file_size = self.get_remote_file_size(url)\n\n        if exists(join(path, filename)):\n            size = getsize(join(path, filename))\n            if size == remote_file_size:\n                logger.error('%s already exists on your system' % filename)\n                print('%s already exists on your system' % filename)\n                return [join(path, filename), size]\n\n        logger.debug('Downloading: %s' % filename)\n        print('Downloading: %s' % filename)\n        fetch(url, path)\n        print('stored at %s' % path)\n        logger.debug('stored at %s' % path)\n        return [join(path, filename), remote_file_size]", "response": "Verify if the file is already downloaded and complete. If it is not download it and return a list with the path of the downloaded file and the size of the remote file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_sceneInfo(self):\n        if self.sceneInfo.prefix not in self.__satellitesMap:\n            logger.error('Google Downloader: Prefix of %s (%s) is invalid'\n                % (self.sceneInfo.name, self.sceneInfo.prefix))\n            raise WrongSceneNameError('Google Downloader: Prefix of %s (%s) is invalid'\n                % (self.sceneInfo.name, self.sceneInfo.prefix))", "response": "Check if the scene name and whether remote file exists. Raises WrongSceneNameError if the scene name is wrong."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download(self, bands, download_dir=None, metadata=False):\n        super(GoogleDownloader, self).validate_bands(bands)\n        pattern = re.compile('^[^\\s]+_(.+)\\.tiff?', re.I)\n        image_list = []\n        band_list = ['B%i' % (i,) if isinstance(i, int) else i for i in bands]\n\n        if download_dir is None:\n            download_dir = DOWNLOAD_DIR\n\n        check_create_folder(join(download_dir, self.sceneInfo.name))\n        filename = \"%s%s\" % (self.sceneInfo.name, self.__remote_file_ext)\n        downloaded = self.fetch(self.remote_file_url, download_dir, filename)\n        try:\n\n            tar = tarfile.open(downloaded[0], 'r')\n            folder_path = join(download_dir, self.sceneInfo.name)\n            logger.debug('Starting data extraction in directory ', folder_path)\n            tar.extractall(folder_path)\n            remove(downloaded[0])\n            images_path = listdir(folder_path)\n\n            for image_path in images_path:\n                matched = pattern.match(image_path)\n                file_path = join(folder_path, image_path)\n                if matched and matched.group(1) in band_list:\n                    image_list.append([file_path, getsize(file_path)])\n                elif matched:\n                    remove(file_path)\n\n        except tarfile.ReadError as error:\n            logger.error('Error when extracting files: ', error)\n            print('Error when extracting files.')\n\n        return image_list", "response": "Download remote. tar. bz2 file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_sceneInfo(self):\n        if self.sceneInfo.prefix not in self.__prefixesValid:\n            raise WrongSceneNameError('AWS: Prefix of %s (%s) is invalid'\n                % (self.sceneInfo.name, self.sceneInfo.prefix))", "response": "Check whether the sceneInfo is valid to download from AWS Storage."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify whether the file exists on AWS Storage.", "response": "def remote_file_exists(self):\n        \"\"\"Verify whether the file (scene) exists on AWS Storage.\"\"\"\n        url = join(self.base_url, 'index.html')\n        return super(AWSDownloader, self).remote_file_exists(url)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndownloading each specified band and metadata.", "response": "def download(self, bands, download_dir=None, metadata=False):\n        \"\"\"Download each specified band and metadata.\"\"\"\n        super(AWSDownloader, self).validate_bands(bands)\n        if download_dir is None:\n            download_dir = DOWNLOAD_DIR\n\n        dest_dir = check_create_folder(join(download_dir, self.sceneInfo.name))\n        downloaded = []\n\n        for band in bands:\n            if band == 'BQA':\n                filename = '%s_%s.%s' % (self.sceneInfo.name, band, self.__remote_file_ext)\n            else:\n                filename = '%s_B%s.%s' % (self.sceneInfo.name, band, self.__remote_file_ext)\n\n            band_url = join(self.base_url, filename)\n            downloaded.append(self.fetch(band_url, dest_dir, filename))\n\n        if metadata:\n            filename = '%s_MTL.txt' % (self.sceneInfo.name)\n            url = join(self.base_url, filename)\n            self.fetch(url, dest_dir, filename)\n        return downloaded"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef open_archive(fs_url, archive):\n    it = pkg_resources.iter_entry_points('fs.archive.open_archive')\n    entry_point = next((ep for ep in it if archive.endswith(ep.name)), None)\n\n    if entry_point is None:\n        raise UnsupportedProtocol(\n            'unknown archive extension: {}'.format(archive))\n\n    try:\n        archive_opener = entry_point.load()\n    except pkg_resources.DistributionNotFound as df: # pragma: no cover\n        six.raise_from(UnsupportedProtocol(\n            'extension {} requires {}'.format(entry_point.name, df.req)), None)\n\n    try:\n        binfile = None\n        archive_fs = None\n        fs = open_fs(fs_url)\n\n        if issubclass(archive_opener, base.ArchiveFS):\n            try:\n                binfile = fs.openbin(archive, 'r+')\n            except errors.ResourceNotFound:\n                binfile = fs.openbin(archive, 'w')\n            except errors.ResourceReadOnly:\n                binfile = fs.openbin(archive, 'r')\n                archive_opener = archive_opener._read_fs_cls\n\n        elif issubclass(archive_opener, base.ArchiveReadFS):\n            binfile = fs.openbin(archive, 'r')\n\n        if not hasattr(binfile, 'name'):\n            binfile.name = basename(archive)\n\n        archive_fs = archive_opener(binfile)\n\n    except Exception:\n        getattr(archive_fs, 'close', lambda: None)()\n        getattr(binfile, 'close', lambda: None)()\n        raise\n\n    else:\n        return archive_fs", "response": "Open an archive on a filesystem."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iso_name_increment(name, is_dir=False, max_length=8):\n    # Split the extension if needed\n    if not is_dir and '.' in name:\n        name, ext = name.rsplit('.')\n        ext = '.{}'.format(ext)\n    else:\n        ext = ''\n\n    # Find the position of the last letter\n    for position, char in reversed(list(enumerate(name))):\n        if char not in string.digits:\n            break\n\n    # Extract the numbers and the text from the name\n    base, tag = name[:position+1], name[position+1:]\n    tag = str(int(tag or 0) + 1)\n\n    # Crop the text if the numbers are too long\n    if len(tag) + len(base) > max_length:\n        base = base[:max_length - len(tag)]\n\n    # Return the name with the extension\n    return ''.join([base, tag, ext])", "response": "Increment an ISO name to avoid name collision."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_querydict(self):\n        if self.method:\n            querydict =  getattr(self.request, self.method.upper())\n        else:\n            querydict =  getattr(self.request, 'POST'.upper())\n        # copy make querydict mutable\n\n        query_dict =  dict(querydict.items())\n        return query_dict", "response": "get querydict from request"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_slice_start(self):\n        value = None\n        if self.easyui_page:\n            value = (self.easyui_page -1) * self.easyui_rows\n        return  value", "response": "get slice start value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_queryset(self):\n        filter_dict = self.get_filter_dict()\n        queryset = super(EasyUIListMixin, self).get_queryset()\n        queryset =  queryset.filter(**filter_dict)\n        if self.easyui_order:\n            # \u5982\u679c\u6307\u5b9a\u4e86\u6392\u5e8f\u5b57\u6bb5\uff0c\u8fd4\u56de\u6392\u5e8f\u7684queryset\n            queryset = queryset.order_by(self.easyui_order)\n\n        return queryset", "response": "Returns queryset of all the available items."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dict with the current context data.", "response": "def get_easyui_context(self, **kwargs):\n        \"\"\"\n        \u521d\u59cb\u5316\u4e00\u4e2a\u7a7a\u7684context\n        \"\"\"\n        context = {}\n        queryset = self.get_queryset()\n        limit_queryset =  self.get_limit_queryset()\n        data = model_serialize(limit_queryset, self.extra_fields, self.remove_fields)\n        count = queryset.count()\n        # datagrid \u8fd4\u56de\u7684\u6570\u636e\u4e2d\uff0ctotal\u662f\u603b\u7684\u884c\u6570\uff0crows\u662f\u67e5\u8be2\u5230\u7684\u7ed3\u679c\u96c6\n        context.update(rows=data)\n        context.update(total=count)\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_views(app_name, view_filename, urlpatterns=None):\n    app_module = __import__(app_name)\n    view_module = getattr(app_module, view_filename)\n    views = dir(view_module)\n    for view_name in views:\n        if view_name.endswith('View'):\n            view = getattr(view_module, view_name)\n            if isinstance(view, object):\n                if urlpatterns:\n                    urlpatterns  += patterns('',\n                            url(r'^(?i)%s/$' % view_name, view.as_view(),  name=view_name),\n                            )\n                else:\n                    urlpatterns = patterns('',\n                            url(r'^(?i)%s/$' % view_name, view.as_view(),  name=view_name),\n                            )\n            else:\n                pass\n    return urlpatterns", "response": "app_name - App name view_filename - filename of view to register urlpatterns - urlpatterns to be used for urlpatterns"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of template names that can be used to render the datagrid.", "response": "def get_template_names(self):\n        \"\"\"\n        datagrid\u7684\u9ed8\u8ba4\u6a21\u677f\n        \"\"\"\n        names = super(EasyUIDatagridView, self).get_template_names()\n        names.append('easyui/datagrid.html')\n        return names"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of template names that can be used to render the form.", "response": "def get_template_names(self):\n        \"\"\"\n        datagrid\u7684\u9ed8\u8ba4\u6a21\u677f\n        \"\"\"\n        names = super(EasyUICreateView, self).get_template_names()\n        names.append('easyui/form.html')\n        return names"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_template_names(self):\n        names = super(EasyUIUpdateView, self).get_template_names()\n        names.append('easyui/form.html')\n        return names", "response": "Returns a list of template names that can be used to render the update view."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\noverriding to add easyui delete. html to the template names", "response": "def get_template_names(self):\n        \"\"\"\n        datagrid\u7684\u9ed8\u8ba4\u6a21\u677f\n        \"\"\"\n        names = super(EasyUIDeleteView, self).get_template_names()\n        names.append('easyui/confirm_delete.html')\n        return names"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_template_names(self):\n        names = super(CommandDatagridView, self).get_template_names()\n        names.append('easyui/command_datagrid.html')\n        return names", "response": "Returns a list of template names that can be used to render the datagrid."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if user has permission to access this object", "response": "def dispatch(self, request, *args, **kwargs):\n        \"\"\"\n        \u589e\u52a0\u4e86\u6743\u9650\u63a7\u5236\uff0c\u5f53self\u5b58\u5728model\u548cpermission_required\u65f6\uff0c\u624d\u4f1a\u68c0\u67e5\u6743\u9650\n        \"\"\"\n        if getattr(self, 'model', None) and self.permission_required:\n            app_label = self.model._meta.app_label\n            model_name = self.model.__name__.lower()\n            permission_required = self.permission_required.lower()\n            permission = '%(app_label)s.%(permission_required)s_%(model_name)s' % {\n                'app_label':app_label,\n                'permission_required':permission_required,\n                'model_name': model_name\n            }\n            if not self.request.user.has_perm(permission):\n                return HttpResponseRedirect(reverse_lazy('easyui:login'))\n\n        return super(LoginRequiredMixin, self).dispatch(request, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef writable_path(path):\n    if os.path.exists(path):\n        return os.access(path, os.W_OK)\n    try:\n        with open(path, 'w'):\n            pass\n    except (OSError, IOError):\n        return False\n    else:\n        os.remove(path)\n        return True", "response": "Test whether a path can be written to."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef writable_stream(handle):\n    if isinstance(handle, io.IOBase) and sys.version_info >= (3, 5):\n        return handle.writable()\n    try:\n        handle.write(b'')\n    except (io.UnsupportedOperation, IOError):\n        return False\n    else:\n        return True", "response": "Test whether a stream can be written to."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_curvilinear(cls, x, y, z, formatter=numpy_formatter):\n        return cls(x, y, z, formatter)", "response": "Construct a contour generator from a curvilinear grid of data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_rectilinear(cls, x, y, z, formatter=numpy_formatter):\n        x = np.asarray(x, dtype=np.float64)\n        y = np.asarray(y, dtype=np.float64)\n        z = np.ma.asarray(z, dtype=np.float64)\n        # Check arguments.\n        if x.ndim != 1:\n            raise TypeError(\n                \"'x' must be a 1D array but is a {:d}D array\".format(x.ndim))\n        if y.ndim != 1:\n            raise TypeError(\n                \"'y' must be a 1D array but is a {:d}D array\".format(y.ndim))\n        if z.ndim != 2:\n            raise TypeError(\n                \"'z' must be a 2D array but it a {:d}D array\".format(z.ndim))\n        if x.size != z.shape[1]:\n            raise TypeError(\n                (\"the length of 'x' must be equal to the number of columns in \"\n                 \"'z' but the length of 'x' is {:d} and 'z' has {:d} \"\n                 \"columns\").format(x.size, z.shape[1]))\n        if y.size != z.shape[0]:\n            raise TypeError(\n                (\"the length of 'y' must be equal to the number of rows in \"\n                 \"'z' but the length of 'y' is {:d} and 'z' has {:d} \"\n                 \"rows\").format(y.size, z.shape[0]))\n        # Convert to curvilinear format and call constructor.\n        y, x = np.meshgrid(y, x, indexing='ij')\n        return cls(x, y, z, formatter)", "response": "Construct a contour generator from a rectilinear grid of data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_uniform(\n            cls, z, origin=(0, 0), step=(1, 1), formatter=numpy_formatter):\n        \"\"\"Construct a contour generator from a uniform grid.\n\n        NOTE\n        ----\n        The default `origin` and `step` values is equivalent to calling\n        :meth:`matplotlib.axes.Axes.contour` with only the `z` argument.\n\n        Parameters\n        ----------\n        z : array_like\n            The 2-dimensional uniform grid of data to compute contours for.\n            Masked arrays are supported.\n        origin : (number.Number, number.Number)\n            The (x, y) coordinate of data point `z[0,0]`.\n        step :  (number.Number, number.Number)\n            The (x, y) distance between data points in `z`.\n        formatter : callable\n            A conversion function to convert from the internal `Matplotlib`_\n            contour format to an external format.  See :ref:`formatters` for\n            more information.\n\n        Returns\n        -------\n        : :class:`QuadContourGenerator`\n            Initialized contour generator.\n\n        \"\"\"\n        z = np.ma.asarray(z, dtype=np.float64)\n        # Check arguments.\n        if z.ndim != 2:\n            raise TypeError(\n                \"'z' must be a 2D array but it a {:d}D array\".format(z.ndim))\n        if len(origin) != 2:\n            raise TypeError(\n                \"'origin' must be of length 2 but has length {:d}\".format(\n                    len(origin)))\n        if len(step) != 2:\n            raise TypeError(\n                \"'step' must be of length 2 but has length {:d}\".format(\n                    len(step)))\n        if any(s == 0 for s in step):\n            raise ValueError(\n                \"'step' must have non-zero values but is {:s}\".format(\n                    str(step)))\n        # Convert to curvilinear format and call constructor.\n        y, x = np.mgrid[\n            origin[0]:(origin[0]+step[0]*z.shape[0]):step[0],\n            origin[1]:(origin[1]+step[1]*z.shape[1]):step[1]]\n        return cls(x, y, z, formatter)", "response": "Construct a contour generator from a uniform grid of data points."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd Sphinx options to the parser.", "response": "def options(self, parser, env=None):\n        \"\"\"\n        Sphinx config file that can optionally take the following python\n        template string arguments:\n\n        ``database_name``\n        ``database_password``\n        ``database_username``\n        ``database_host``\n        ``database_port``\n        ``sphinx_search_data_dir``\n        ``searchd_log_dir``\n        \"\"\"\n        if env is None:\n            env = os.environ\n        parser.add_option(\n            '--sphinx-config-tpl',\n            help='Path to the Sphinx configuration file template.',\n        )\n\n        super(SphinxSearchPlugin, self).options(parser, env)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwaits until we can make a socket connection to sphinx.", "response": "def _wait_for_connection(self, port):\n        \"\"\"\n        Wait until we can make a socket connection to sphinx.\n        \"\"\"\n        connected = False\n        max_tries = 10\n        num_tries = 0\n        wait_time = 0.5\n        while not connected or num_tries >= max_tries:\n            time.sleep(wait_time)\n            try:\n                af = socket.AF_INET\n                addr = ('127.0.0.1', port)\n                sock = socket.socket(af, socket.SOCK_STREAM)\n                sock.connect(addr)\n            except socket.error:\n                if sock:\n                    sock.close()\n                num_tries += 1\n                continue\n            connected = True\n\n        if not connected:\n            print(\"Error connecting to sphinx searchd\", file=sys.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_unique_token(self):\n        if self._unique_token is None:\n            self._unique_token = self._random_token()\n\n        return self._unique_token", "response": "Get a unique token for usage in differentiating test runs that need to be run in parallel."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _random_token(self, bits=128):\n        alphabet = string.ascii_letters + string.digits + '-_'\n        # alphabet length is 64, so each letter provides lg(64) = 6 bits\n        num_letters = int(math.ceil(bits / 6.0))\n        return ''.join(random.choice(alphabet) for i in range(num_letters))", "response": "Generates a random token using the url - safe base64 alphabet."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef url(self):\n        if self.id is None:\n            return ''\n        return '{}/{}'.format(strawpoll.API._BASE_URL, self.id)", "response": "Returns the url of the poll."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_poll(self, arg, *, request_policy=None):\n        if isinstance(arg, str):\n            # Maybe we received an url to parse\n            match = self._url_re.match(arg)\n            if match:\n                arg = match.group('id')\n\n        return self._http_client.get('{}/{}'.format(self._POLLS, arg),\n                                     request_policy=request_policy,\n                                     cls=strawpoll.Poll)", "response": "Retrieves a poll from strawpoll."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsubmit a poll on strawpoll.", "response": "def submit_poll(self, poll, *, request_policy=None):\n        \"\"\"Submits a poll on strawpoll.\n\n        :param poll: The poll to submit.\n        :type poll: :class:`Poll`\n        :param request_policy: Overrides :attr:`API.requests_policy` for that \\\n        request.\n        :type request_policy: Optional[:class:`RequestsPolicy`]\n\n        :raises ExistingPoll: This poll instance has already been submitted.\n        :raises HTTPException: The submission failed.\n\n        :returns: The given poll updated with the data sent back from the submission.\n        :rtype: :class:`Poll`\n\n        .. note::\n            Only polls that have a non empty title and between 2 and 30 options\n            can be submitted.\n        \"\"\"\n        if poll.id is not None:\n            raise ExistingPoll()\n\n        options = poll.options\n        data = {\n            'title': poll.title,\n            'options': options,\n            'multi': poll.multi,\n            'dupcheck': poll.dupcheck,\n            'captcha': poll.captcha\n        }\n\n        return self._http_client.post(self._POLLS,\n                                      data=data,\n                                      request_policy=request_policy,\n                                      cls=strawpoll.Poll)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef numpy_formatter(_, vertices, codes=None):\n    if codes is None:\n        return vertices\n    numpy_vertices = []\n    for vertices_, codes_ in zip(vertices, codes):\n        starts = np.nonzero(codes_ == MPLPATHCODE.MOVETO)[0]\n        stops = np.nonzero(codes_ == MPLPATHCODE.CLOSEPOLY)[0]\n        for start, stop in zip(starts, stops):\n            numpy_vertices.append(vertices_[start:stop+1, :])\n    return numpy_vertices", "response": "NumPy_ style contour formatter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef shapely_formatter(_, vertices, codes=None):\n    elements = []\n    if codes is None:\n        for vertices_ in vertices:\n            if np.all(vertices_[0, :] == vertices_[-1, :]):\n                # Contour is single point.\n                if len(vertices) < 3:\n                    elements.append(Point(vertices_[0, :]))\n                # Contour is closed.\n                else:\n                    elements.append(LinearRing(vertices_))\n            # Contour is open.\n            else:\n                elements.append(LineString(vertices_))\n    else:\n        for vertices_, codes_ in zip(vertices, codes):\n            starts = np.nonzero(codes_ == MPLPATHCODE.MOVETO)[0]\n            stops = np.nonzero(codes_ == MPLPATHCODE.CLOSEPOLY)[0]\n            try:\n                rings = [LinearRing(vertices_[start:stop+1, :])\n                        for start, stop in zip(starts, stops)]\n                elements.append(Polygon(rings[0], rings[1:]))\n            except ValueError as err:\n                # Verify error is from degenerate (single point) polygon.\n                if np.any(stop - start - 1 == 0):\n                    # Polygon is single point, remove the polygon.\n                    if stops[0] < starts[0]+2:\n                        pass\n                    # Polygon has single point hole, remove the hole.\n                    else:\n                        rings = [\n                            LinearRing(vertices_[start:stop+1, :])\n                            for start, stop in zip(starts, stops)\n                            if stop >= start+2]\n                        elements.append(Polygon(rings[0], rings[1:]))\n                else:\n                    raise(err)\n    return elements", "response": "This function returns a list of shapely. geometry. LineStrings LinearRing and Polygon objects for a list of vertices."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef contour(self, level):\n        if not isinstance(level, numbers.Number):\n            raise TypeError(\n                (\"'_level' must be of type 'numbers.Number' but is \"\n                 \"'{:s}'\").format(type(level)))\n        vertices = self._contour_generator.create_contour(level)\n        return self.formatter(level, vertices)", "response": "Returns the contour lines at the given level."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filled_contour(self, min=None, max=None):\n        # pylint: disable=redefined-builtin,redefined-outer-name\n        # Get the contour vertices.\n        if min is None:\n            min = np.finfo(np.float64).min\n        if max is None:\n            max = np.finfo(np.float64).max\n        vertices, codes = (\n            self._contour_generator.create_filled_contour(min, max))\n        return self.formatter((min, max), vertices, codes)", "response": "Returns a string containing the filled contour of the contour in the contour format between min and max."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef connect(self, axis0, n0_index, source_angle, axis1, n1_index, target_angle, **kwargs):\n        n0    = axis0.nodes[n0_index]\n        n1    = axis1.nodes[n1_index]\n\n        pth  = self.dwg.path(d=\"M %s %s\" % (n0.x, n0.y), fill='none', **kwargs) # source\n\n        # compute source control point\n        alfa = axis0.angle() + radians(source_angle)\n        length = sqrt( ((n0.x - axis0.start[0])**2) + ((n0.y-axis0.start[1])**2)) \n        x = axis0.start[0] + length * cos(alfa);\n        y = axis0.start[1] + length * sin(alfa);\n\n        pth.push(\"C %s %s\" % (x, y)) # first control point in path\n\n        # compute target control point\n        alfa = axis1.angle() + radians(target_angle)\n        length = sqrt( ((n1.x - axis1.start[0])**2) + ((n1.y-axis1.start[1])**2)) \n        x = axis1.start[0] + length * cos(alfa);\n        y = axis1.start[1] + length * sin(alfa);\n        \n        pth.push(\"%s %s\" % (x, y))   # second control point in path\n\n        pth.push(\"%s %s\" % (n1.x, n1.y)) # target\n        self.dwg.add(pth)", "response": "Draw edges as B\u00e9zier curves."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_node(self, node, offset):\n        # calculate x,y from offset considering axis start and end points\n        width  = self.end[0] - self.start[0]\n        height = self.end[1] - self.start[1]        \n        node.x = self.start[0] + (width * offset)\n        node.y = self.start[1] + (height * offset)\n        self.nodes[node.ID] = node", "response": "Adds a Node object to the nodes dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_settings_path(settings_module):\n    '''\n    Hunt down the settings.py module by going up the FS path\n    '''\n    cwd = os.getcwd()\n    settings_filename = '%s.py' % (\n        settings_module.split('.')[-1]\n    )\n    while cwd:\n        if settings_filename in os.listdir(cwd):\n            break\n        cwd = os.path.split(cwd)[0]\n        if os.name == 'nt' and NT_ROOT.match(cwd):\n            return None\n        elif cwd == '/':\n            return None\n    return cwd", "response": "Get the path to the settings. py module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize the test database and schema.", "response": "def begin(self):\n        \"\"\"\n        Create the test database and schema, if needed, and switch the\n        connection over to that database. Then call install() to install\n        all apps listed in the loaded settings module.\n        \"\"\"\n        for plugin in self.nose_config.plugins.plugins:\n            if getattr(plugin, 'django_plugin', False):\n                self.django_plugins.append(plugin)\n\n        os.environ['DJANGO_SETTINGS_MODULE'] = self.settings_module\n\n        if self.conf.addPaths:\n            map(add_path, self.conf.where)\n\n        try:\n            __import__(self.settings_module)\n            self.settings_path = self.settings_module\n        except ImportError:\n            # Settings module is not found in PYTHONPATH. Try to do\n            # some funky backwards crawling in directory tree, ie. add\n            # the working directory (and any package parents) to\n            # sys.path before trying to import django modules;\n            # otherwise, they won't be able to find project.settings\n            # if the working dir is project/ or project/..\n\n            self.settings_path = get_settings_path(self.settings_module)\n\n            if not self.settings_path:\n                # short circuit if no settings file can be found\n                raise RuntimeError(\"Can't find Django settings file!\")\n\n            add_path(self.settings_path)\n            sys.path.append(self.settings_path)\n\n        from django.conf import settings\n\n        # Some Django code paths evaluate differently\n        # between DEBUG and not DEBUG.  Example of this include the url\n        # dispatcher when 404's are hit.  Django's own test runner forces DEBUG\n        # to be off.\n        settings.DEBUG = False\n\n        self.call_plugins_method('beforeConnectionSetup', settings)\n\n        from django.core import management\n        from django.test.utils import setup_test_environment\n\n        if hasattr(settings, 'DATABASES'):\n            self.old_db = settings.DATABASES['default']['NAME']\n        else:\n            self.old_db = settings.DATABASE_NAME\n        from django.db import connections\n\n        self._monkeypatch_test_classes()\n\n        for connection in connections.all():\n            self.call_plugins_method(\n                'beforeTestSetup', settings, setup_test_environment,\n                connection)\n        try:\n            setup_test_environment()\n        except RuntimeError:  # Django 1.11 + multiprocess this happens.\n            pass\n        import django\n        if hasattr(django, 'setup'):\n            django.setup()\n\n        self.call_plugins_method('afterTestSetup', settings)\n\n        management.get_commands()\n        # Ensure that nothing (eg. South) steals away our syncdb command\n        if self.django_version < self.DJANGO_1_7:\n            management._commands['syncdb'] = 'django.core'\n\n        for connection in connections.all():\n            self.call_plugins_method(\n                'beforeTestDb', settings, connection, management)\n            connection.creation.create_test_db(\n                verbosity=self.verbosity,\n                autoclobber=True,\n            )\n            logger.debug(\"Running syncdb\")\n            self._num_syncdb_calls += 1\n            self.call_plugins_method('afterTestDb', settings, connection)\n        self.store_original_transaction_methods()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _should_use_transaction_isolation(self, test, settings):\n        if not getattr(test.context, 'use_transaction_isolation', True):\n            # The test explicitly says not to use transaction isolation\n            return False\n        if getattr(settings, 'DISABLE_TRANSACTION_MANAGEMENT', False):\n            # Do not use transactions if user has forbidden usage.\n            return False\n        if hasattr(settings, 'DATABASE_SUPPORTS_TRANSACTIONS'):\n            if not settings.DATABASE_SUPPORTS_TRANSACTIONS:\n                # The DB doesn't support transactions. Don't try it\n                return False\n\n        return True", "response": "Determine if the given test is using transaction isolation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinalizing the test database and schema.", "response": "def finalize(self, result=None):\n        \"\"\"\n        Clean up any created database and schema.\n        \"\"\"\n        if not self.settings_path:\n            # short circuit if no settings file can be found\n            return\n\n        from django.test.utils import teardown_test_environment\n        from django.db import connection\n        from django.conf import settings\n\n        self.call_plugins_method('beforeDestroyTestDb', settings, connection)\n        try:\n            connection.creation.destroy_test_db(\n                self.old_db,\n                verbosity=self.verbosity,\n            )\n        except Exception:\n            # If we can't tear down the test DB, don't worry about it.\n            pass\n        self.call_plugins_method('afterDestroyTestDb', settings, connection)\n\n        self.call_plugins_method(\n            'beforeTeardownTestEnv', settings, teardown_test_environment)\n        teardown_test_environment()\n        self.call_plugins_method('afterTeardownTestEnv', settings)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nnormalizing a field to a uin8 on [ 0 255 )", "response": "def norm(field, vmin=0, vmax=255):\n    \"\"\"Truncates field to 0,1; then normalizes to a uin8 on [0,255]\"\"\"\n    field = 255*np.clip(field, 0, 1)\n    field = field.astype('uint8')\n    return field"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_field(state, field='exp-particles'):\n    es, pp = field.split('-')  #exp vs sim, particles vs platonic\n    #1. The weights for the field, based off the platonic vs particles\n    if pp == 'particles':\n        o = state.get('obj')\n        if isinstance(o, peri.comp.comp.ComponentCollection):\n            wts = 0*o.get()[state.inner]\n            for c in o.comps:\n                if isinstance(c, peri.comp.objs.PlatonicSpheresCollection):\n                    wts += c.get()[state.inner]\n        else:\n            wts = o.get()[state.inner]\n    elif pp == 'platonic':\n        wts = state.get('obj').get()[state.inner]\n    else:\n        raise ValueError('Not a proper field.')\n    #2. Exp vs sim-like data\n    if es == 'exp':\n        out = (1-state.data) * (wts > 1e-5)\n    elif es == 'sim':\n        out = wts\n    else:\n        raise ValueError('Not a proper field.')\n    return norm(clip(roll(out)))", "response": "Given a state extract a field from the state."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender a single volume of a field.", "response": "def volume_render(field, outfile, maxopacity=1.0, cmap='bone',\n        size=600, elevation=45, azimuth=45, bkg=(0.0, 0.0, 0.0),\n        opacitycut=0.35, offscreen=False, rayfunction='smart'):\n    \"\"\"\n    Uses vtk to make render an image of a field, with control over the\n    camera angle and colormap.\n\n    Input Parameters\n    ----------------\n        field : np.ndarray\n            3D array of the field to render.\n        outfile : string\n            The save name of the image.\n        maxopacity : Float\n            Default is 1.0\n        cmap : matplotlib colormap string\n            Passed to cmap2colorfunc. Default is bone.\n        size : 2-element list-like of ints or Int\n            The size of the final rendered image.\n        elevation : Numeric\n            The elevation of the camera angle, in degrees. Default is 45\n        azimuth : Numeric\n            The azimuth of the camera angle, in degrees. Default is 45\n        bkg : Tuple of floats\n            3-element tuple of floats on [0,1] of the background image color.\n            Default is (0., 0., 0.).\n    \"\"\"\n    sh = field.shape\n\n    dataImporter = vtk.vtkImageImport()\n    dataImporter.SetDataScalarTypeToUnsignedChar()\n    data_string = field.tostring()\n    dataImporter.SetNumberOfScalarComponents(1)\n    dataImporter.CopyImportVoidPointer(data_string, len(data_string))\n\n    dataImporter.SetDataExtent(0, sh[2]-1, 0, sh[1]-1, 0, sh[0]-1)\n    dataImporter.SetWholeExtent(0, sh[2]-1, 0, sh[1]-1, 0, sh[0]-1)\n\n    alphaChannelFunc = vtk.vtkPiecewiseFunction()\n    alphaChannelFunc.AddPoint(0, 0.0)\n    alphaChannelFunc.AddPoint(int(255*opacitycut), maxopacity)\n\n    volumeProperty = vtk.vtkVolumeProperty()\n    colorFunc = cmap2colorfunc(cmap)\n    volumeProperty.SetColor(colorFunc)\n    volumeProperty.SetScalarOpacity(alphaChannelFunc)\n\n    volumeMapper = vtk.vtkVolumeRayCastMapper()\n    if rayfunction == 'mip':\n        comp = vtk.vtkVolumeRayCastMIPFunction()\n        comp.SetMaximizeMethodToOpacity()\n    elif rayfunction == 'avg':\n        comp = vtk.vtkVolumeRayCastCompositeFunction()\n    elif rayfunction == 'iso':\n        comp = vtk.vtkVolumeRayCastIsosurfaceFunction()\n        comp.SetIsoValue(maxopacity/2)\n    else:\n        comp = vtk.vtkVolumeRayCastIsosurfaceFunction()\n    volumeMapper.SetSampleDistance(0.1)\n    volumeMapper.SetVolumeRayCastFunction(comp)\n\n    if rayfunction == 'smart':\n        volumeMapper = vtk.vtkSmartVolumeMapper()\n    volumeMapper.SetInputConnection(dataImporter.GetOutputPort())\n\n    volume = vtk.vtkVolume()\n    volume.SetMapper(volumeMapper)\n    volume.SetProperty(volumeProperty)\n\n    light = vtk.vtkLight()\n    light.SetLightType(vtk.VTK_LIGHT_TYPE_HEADLIGHT)\n    light.SetIntensity(5.5)\n    light.SwitchOn()\n\n    renderer = vtk.vtkRenderer()\n    renderWin = vtk.vtkRenderWindow()\n    renderWin.AddRenderer(renderer)\n    renderWin.SetOffScreenRendering(1);\n\n    if not hasattr(size, '__iter__'):\n        size = (size, size)\n\n    renderer.AddVolume(volume)\n    renderer.AddLight(light)\n    renderer.SetBackground(*bkg)\n    renderWin.SetSize(*size)\n\n    if offscreen:\n        renderWin.SetOffScreenRendering(1)\n\n    def exitCheck(obj, event):\n        if obj.GetEventPending() != 0:\n            obj.SetAbortRender(1)\n\n    renderWin.AddObserver(\"AbortCheckEvent\", exitCheck)\n\n    renderInteractor = vtk.vtkRenderWindowInteractor()\n    renderInteractor.Initialize()\n    renderWin.Render()\n    renderInteractor.Start()\n\n    #writer = vtk.vtkFFMPEGWriter()\n    #writer.SetQuality(2)\n    #writer.SetRate(24)\n    #w2i = vtk.vtkWindowToImageFilter()\n    #w2i.SetInput(renderWin)\n    #writer.SetInputConnection(w2i.GetOutputPort())\n    #writer.SetFileName('movie.avi')\n    #writer.Start()\n    #writer.End()\n\n    writer = vtk.vtkPNGWriter()\n    w2i = vtk.vtkWindowToImageFilter()\n    w2i.SetInput(renderWin)\n    writer.SetInputConnection(w2i.GetOutputPort())\n\n    renderWin.Render()\n    ac = renderer.GetActiveCamera()\n    ac.Elevation(elevation)\n    ac.Azimuth(azimuth)\n    renderer.ResetCameraClippingRange()\n    renderWin.Render()\n    w2i.Modified()\n    writer.SetFileName(outfile)\n    writer.Write()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking a matplotlib. pyplot. Figure with no tooltips or keybindings.", "response": "def make_clean_figure(figsize, remove_tooltips=False, remove_keybindings=False):\n    \"\"\"\n    Makes a `matplotlib.pyplot.Figure` without tooltips or keybindings\n\n    Parameters\n    ----------\n    figsize : tuple\n        Figsize as passed to `matplotlib.pyplot.figure`\n    remove_tooltips, remove_keybindings : bool\n        Set to True to remove the tooltips bar or any key bindings,\n        respectively. Default is False\n\n    Returns\n    -------\n    fig : `matplotlib.pyplot.Figure`\n    \"\"\"\n    tooltip = mpl.rcParams['toolbar']\n    if remove_tooltips:\n        mpl.rcParams['toolbar'] = 'None'\n    fig = pl.figure(figsize=figsize)\n    mpl.rcParams['toolbar'] = tooltip\n    if remove_keybindings:\n        fig.canvas.mpl_disconnect(fig.canvas.manager.key_press_handler_id)\n    return fig"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _particle_func(self, coords, pos, wid):\n        dx, dy, dz = [c - p for c,p in zip(coords, pos)]\n        dr2 = dx*dx + dy*dy + dz*dz\n        return np.exp(-dr2/(2*wid*wid))", "response": "Draws a gaussian particle"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _remove_closest_particle(self, p):\n        #1. find closest pos:\n        dp = self.pos - p\n        dist2 = (dp*dp).sum(axis=1)\n        ind = dist2.argmin()\n        rp = self.pos[ind].copy()\n        #2. delete\n        self.pos = np.delete(self.pos, ind, axis=0)\n        return rp", "response": "removes the closest particle in self. pos to p"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef diffusion(diffusion_constant=0.2, exposure_time=0.05, samples=200):\n    radius = 5\n    psfsize = np.array([2.0, 1.0, 3.0])\n\n    # create a base image of one particle\n    s0 = init.create_single_particle_state(imsize=4*radius, \n            radius=radius, psfargs={'params': psfsize, 'error': 1e-6})\n\n    # add up a bunch of trajectories\n    finalimage = 0*s0.get_model_image()[s0.inner]\n    position = 0*s0.obj.pos[0]\n\n    for i in xrange(samples):\n        offset = np.sqrt(6*diffusion_constant*exposure_time)*np.random.randn(3)\n        s0.obj.pos[0] = np.array(s0.image.shape)/2 + offset\n        s0.reset()\n\n        finalimage += s0.get_model_image()[s0.inner]\n        position += s0.obj.pos[0]\n\n    finalimage /= float(samples)\n    position /= float(samples)\n\n    # place that into a new image at the expected parameters\n    s = init.create_single_particle_state(imsize=4*radius, sigma=0.05,\n            radius=radius, psfargs={'params': psfsize, 'error': 1e-6})\n    s.reset()\n\n    # measure the true inferred parameters\n    return s, finalimage, position", "response": "Create a new state and a base image of one particle and a random position."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef diffusion_correlated(diffusion_constant=0.2, exposure_time=0.05,\n        samples=40, phi=0.25):\n    \"\"\"\n    Calculate the (perhaps) correlated diffusion effect between particles\n    during the exposure time of the confocal microscope. diffusion_constant is\n    in terms of seconds and pixel sizes exposure_time is in seconds\n\n    1 micron radius particle:\n        D = kT / (6 a\\pi\\eta)\n        for 80/20 g/w (60 mPas), 3600 nm^2/sec ~ 0.15 px^2/sec\n        for 100 % w  (0.9 mPas),               ~ 10.1 px^2/sec\n    a full 60 layer scan takes 0.1 sec, so a particle is 0.016 sec exposure\n    \"\"\"\n    radius = 5\n    psfsize = np.array([2.0, 1.0, 3.0])/2\n\n    pos, rad, tile = nbody.initialize_particles(N=50, phi=phi, polydispersity=0.0)\n    sim = nbody.BrownianHardSphereSimulation(\n        pos, rad, tile, D=diffusion_constant, dt=exposure_time/samples\n    )\n    sim.dt = 1e-2\n    sim.relax(2000)\n    sim.dt = exposure_time/samples\n\n    # move the center to index 0 for easier analysis later\n    c = ((sim.pos - sim.tile.center())**2).sum(axis=-1).argmin()\n    pc = sim.pos[c].copy()\n    sim.pos[c] = sim.pos[0]\n    sim.pos[0] = pc\n\n    # which particles do we want to simulate motion for? particle\n    # zero and its neighbors\n    mask = np.zeros_like(sim.rad).astype('bool')\n    neigh = sim.neighbors(3*radius, 0)\n    for i in neigh+[0]:\n        mask[i] = True\n\n    img = np.zeros(sim.tile.shape)\n    s0 = runner.create_state(img, sim.pos, sim.rad, ignoreimage=True)\n\n    # add up a bunch of trajectories\n    finalimage = 0*s0.get_model_image()[s0.inner]\n    position = 0*s0.obj.pos\n\n    for i in xrange(samples):\n        sim.step(1, mask=mask)\n        s0.obj.pos = sim.pos.copy() + s0.pad\n        s0.reset()\n\n        finalimage += s0.get_model_image()[s0.inner]\n        position += s0.obj.pos\n\n    finalimage /= float(samples)\n    position /= float(samples)\n\n    # place that into a new image at the expected parameters\n    s = runner.create_state(img, sim.pos, sim.rad, ignoreimage=True)\n    s.reset()\n\n    # measure the true inferred parameters\n    return s, finalimage, position", "response": "Calculate the correlated diffusion effect between particles in a confocal microscope."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nplots the dorun of the current object.", "response": "def dorun(SNR=20, ntimes=20, samples=10, noise_samples=10, sweeps=20, burn=10,\n        correlated=False):\n    \"\"\"\n    we want to display the errors introduced by pixelation so we plot:\n        * CRB, sampled error vs exposure time\n\n    a = dorun(ntimes=10, samples=5, noise_samples=5, sweeps=20, burn=8)\n    \"\"\"\n    if not correlated:\n        times = np.logspace(-3, 0, ntimes)\n    else:\n        times = np.logspace(np.log10(0.05), np.log10(30), ntimes)\n\n    crbs, vals, errs, poss = [], [], [], []\n\n    for i,t in enumerate(times):\n        print '###### time', i, t\n\n        for j in xrange(samples):\n            print 'image', j, '|', \n            if not correlated:\n                s,im,pos = diffusion(diffusion_constant=0.2, exposure_time=t)\n            else:\n                s,im,pos = diffusion_correlated(diffusion_constant=0.2, exposure_time=t)\n\n            # typical image\n            common.set_image(s, im, 1.0/SNR)\n            crbs.append(common.crb(s))\n\n            val, err = common.sample(s, im, 1.0/SNR, N=noise_samples, sweeps=sweeps, burn=burn)\n            poss.append(pos)\n            vals.append(val)\n            errs.append(err)\n\n\n    shape0 = (ntimes, samples, -1)\n    shape1 = (ntimes, samples, noise_samples, -1)\n\n    crbs = np.array(crbs).reshape(shape0)\n    vals = np.array(vals).reshape(shape1)\n    errs = np.array(errs).reshape(shape1)\n    poss = np.array(poss).reshape(shape0)\n\n    return  [crbs, vals, errs, poss, times]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a guess at particle positions using heuristic centroid methods.", "response": "def feature_guess(st, rad, invert='guess', minmass=None, use_tp=False,\n                  trim_edge=False, **kwargs):\n    \"\"\"\n    Makes a guess at particle positions using heuristic centroid methods.\n\n    Parameters\n    ----------\n    st : :class:`peri.states.State`\n        The state to check adding particles to.\n    rad : Float\n        The feature size for featuring.\n    invert : {'guess', True, False}, optional\n        Whether to invert the image; set to True for there are dark\n        particles on a bright background, False for bright particles.\n        The default is to guess from the state's current particles.\n    minmass : Float or None, optional\n        The minimum mass/masscut of a particle. Default is ``None`` =\n        calculated internally.\n    use_tp : Bool, optional\n        Whether or not to use trackpy. Default is ``False``, since trackpy\n        cuts out particles at the edge.\n    trim_edge : Bool, optional\n        Whether to trim particles at the edge pixels of the image. Can be\n        useful for initial featuring but is bad for adding missing particles\n        as they are frequently at the edge. Default is ``False``.\n\n    Returns\n    -------\n    guess : [N,3] numpy.ndarray\n        The featured positions of the particles, sorted in order of decreasing\n        feature mass.\n    npart : Int\n        The number of added particles.\n    \"\"\"\n    # FIXME does not use the **kwargs, but needs b/c called with wrong kwargs\n    if invert == 'guess':\n        invert = guess_invert(st)\n    if invert:\n        im = 1 - st.residuals\n    else:\n        im = st.residuals\n    return _feature_guess(im, rad, minmass=minmass, use_tp=use_tp,\n                          trim_edge=trim_edge)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_add_particles(st, guess, rad='calc', do_opt=True, im_change_frac=0.2,\n                        min_derr='3sig', **kwargs):\n    \"\"\"\n    Checks whether to add particles at a given position by seeing if adding\n    the particle improves the fit of the state.\n\n    Parameters\n    ----------\n    st : :class:`peri.states.State`\n        The state to check adding particles to.\n    guess : [N,3] list-like\n        The positions of particles to check to add.\n    rad : {Float, ``'calc'``}, optional.\n        The radius of the newly-added particles. Default is ``'calc'``,\n        which uses the states current radii's median.\n    do_opt : Bool, optional\n        Whether to optimize the particle position before checking if it\n        should be kept. Default is True (optimizes position).\n    im_change_frac : Float\n        How good the change in error needs to be relative to the change in\n        the difference image. Default is 0.2; i.e. if the error does not\n        decrease by 20% of the change in the difference image, do not add\n        the particle.\n    min_derr : Float or '3sig'\n        The minimal improvement in error to add a particle. Default\n        is ``'3sig' = 3*st.sigma``.\n\n    Returns\n    -------\n    accepts : Int\n        The number of added particles\n    new_poses : [N,3] list\n        List of the positions of the added particles. If ``do_opt==True``,\n        then these positions will differ from the input 'guess'.\n    \"\"\"\n    # FIXME does not use the **kwargs, but needs b/c called with wrong kwargs\n    if min_derr == '3sig':\n        min_derr = 3 * st.sigma\n    accepts = 0\n    new_poses = []\n    if rad == 'calc':\n        rad = guess_add_radii(st)\n    message = ('-'*30 + 'ADDING' + '-'*30 +\n               '\\n  Z\\t  Y\\t  X\\t  R\\t|\\t ERR0\\t\\t ERR1')\n    with log.noformat():\n        CLOG.info(message)\n    for a in range(guess.shape[0]):\n        p0 = guess[a]\n        absent_err = st.error\n        absent_d = st.residuals.copy()\n        ind = st.obj_add_particle(p0, rad)\n        if do_opt:\n            # the slowest part of this\n            opt.do_levmarq_particles(\n                st, ind, damping=1.0, max_iter=1, run_length=3,\n                eig_update=False, include_rad=False)\n        present_err = st.error\n        present_d = st.residuals.copy()\n        dont_kill = should_particle_exist(\n                absent_err, present_err, absent_d, present_d,\n                im_change_frac=im_change_frac, min_derr=min_derr)\n        if dont_kill:\n            accepts += 1\n            p = tuple(st.obj_get_positions()[ind].ravel())\n            r = tuple(st.obj_get_radii()[ind].ravel())\n            new_poses.append(p)\n            part_msg = '%2.2f\\t%3.2f\\t%3.2f\\t%3.2f\\t|\\t%4.3f  \\t%4.3f' % (\n                    p + r + (absent_err, st.error))\n            with log.noformat():\n                CLOG.info(part_msg)\n        else:\n            st.obj_remove_particle(ind)\n            if np.abs(absent_err - st.error) > 1e-4:\n                raise RuntimeError('updates not exact?')\n    return accepts, new_poses", "response": "Checks whether to add new particles at a given position by seeing if they are improved."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_remove_particle(st, ind, im_change_frac=0.2, min_derr='3sig',\n                          **kwargs):\n    \"\"\"\n    Checks whether to remove particle 'ind' from state 'st'. If removing the\n    particle increases the error by less than max( min_derr, change in image *\n    im_change_frac), then the particle is removed.\n\n    Parameters\n    ----------\n    st : :class:`peri.states.State`\n        The state to check adding particles to.\n    ind : Int\n        The index of the particle to check to remove.\n    im_change_frac : Float\n        How good the change in error needs to be relative to the change in\n        the difference image. Default is 0.2; i.e. if the error does not\n        decrease by 20% of the change in the difference image, do not add\n        the particle.\n    min_derr : Float or '3sig'\n        The minimal improvement in error to add a particle. Default is\n        ``'3sig' = 3*st.sigma``.\n\n    Returns\n    -------\n    killed : Bool\n        Whether the particle was removed.\n    p : Tuple\n        The position of the removed particle.\n    r : Tuple\n        The radius of the removed particle.\n    \"\"\"\n    # FIXME does not use the **kwargs, but needs b/c called with wrong kwargs\n    if min_derr == '3sig':\n        min_derr = 3 * st.sigma\n    present_err = st.error\n    present_d = st.residuals.copy()\n    p, r = st.obj_remove_particle(ind)\n    p = p[0]\n    r = r[0]\n    absent_err = st.error\n    absent_d = st.residuals.copy()\n\n    if should_particle_exist(absent_err, present_err, absent_d, present_d,\n                             im_change_frac=im_change_frac, min_derr=min_derr):\n        st.obj_add_particle(p, r)\n        killed = False\n    else:\n        killed = True\n    return killed, tuple(p), (r,)", "response": "Checks whether to remove a particle from state st."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks whether or not a particle already exists in the current state.", "response": "def should_particle_exist(absent_err, present_err, absent_d, present_d,\n                          im_change_frac=0.2, min_derr=0.1):\n    \"\"\"\n    Checks whether or not adding a particle should be present.\n\n    Parameters\n    ----------\n    absent_err : Float\n        The state error without the particle.\n    present_err : Float\n        The state error with the particle.\n    absent_d : numpy.ndarray\n        The state residuals without the particle.\n    present_d : numpy.ndarray\n        The state residuals with the particle.\n    im_change_frac : Float, optional\n        How good the change in error needs to be relative to the change in\n        the residuals. Default is 0.2; i.e. return False if the error does\n        not decrease by 0.2 x the change in the residuals.\n    min_derr : Float, optional\n        The minimal improvement in error. Default is 0.1\n\n    Returns\n    -------\n    Bool\n        True if the errors is better with the particle present.\n    \"\"\"\n    delta_im = np.ravel(present_d - absent_d)\n    im_change = np.dot(delta_im, delta_im)\n    err_cutoff = max([im_change_frac * im_change, min_derr])\n    return (absent_err - present_err) >= err_cutoff"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_missing_particles(st, rad='calc', tries=50, **kwargs):\n    if rad == 'calc':\n        rad = guess_add_radii(st)\n\n    guess, npart = feature_guess(st, rad, **kwargs)\n    tries = np.min([tries, npart])\n\n    accepts, new_poses = check_add_particles(\n        st, guess[:tries], rad=rad, **kwargs)\n    return accepts, new_poses", "response": "Returns a new state that has no particles added to the state."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves improperly - featured particles from the state.", "response": "def remove_bad_particles(st, min_rad='calc', max_rad='calc', min_edge_dist=2.0,\n                         check_rad_cutoff=[3.5, 15], check_outside_im=True,\n                         tries=50, im_change_frac=0.2, **kwargs):\n    \"\"\"\n    Removes improperly-featured particles from the state, based on a\n    combination of particle size and the change in error on removal.\n\n    Parameters\n    -----------\n    st : :class:`peri.states.State`\n        The state to remove bad particles from.\n    min_rad : Float, optional\n        All particles with radius below min_rad are automatically deleted.\n        Set to 'calc' to make it the median rad - 25* radius std.\n        Default is 'calc'.\n\n    max_rad : Float, optional\n        All particles with radius above max_rad are automatically deleted.\n        Set to 'calc' to make it the median rad + 15* radius std.\n        Default is 'calc'.\n\n    min_edge_dist : Float, optional\n        All particles within min_edge_dist of the (padded) image\n        edges are automatically deleted. Default is 2.0\n\n    check_rad_cutoff : 2-element list of floats, optional\n        Particles with radii < check_rad_cutoff[0] or > check_rad_cutoff[1]\n        are checked if they should be deleted. Set to 'calc' to make it the\n        median rad +- 3.5 * radius std. Default is [3.5, 15].\n\n    check_outside_im : Bool, optional\n        If True, checks if particles located outside the unpadded image\n        should be deleted. Default is True.\n\n    tries : Int, optional\n        The maximum number of particles with radii < check_rad_cutoff\n        to try to remove. Checks in increasing order of radius size.\n        Default is 50.\n\n    im_change_frac : Float, , optional\n        Number between 0 and 1. If removing a particle decreases the\n        error by less than im_change_frac*the change in the image, then\n        the particle is deleted. Default is 0.2\n\n    Returns\n    -------\n    removed: Int\n        The cumulative number of particles removed.\n    \"\"\"\n    is_near_im_edge = lambda pos, pad: (((pos + st.pad) < pad) | (pos >\n            np.array(st.ishape.shape) + st.pad - pad)).any(axis=1)\n    # returns True if the position is within 'pad' of the _outer_ image edge\n    removed = 0\n    attempts = 0\n\n    n_tot_part = st.obj_get_positions().shape[0]\n    q10 = int(0.1 * n_tot_part)  # 10% quartile\n    r_sig = np.sort(st.obj_get_radii())[q10:-q10].std()\n    r_med = np.median(st.obj_get_radii())\n    if max_rad == 'calc':\n        max_rad = r_med + 15*r_sig\n    if min_rad == 'calc':\n        min_rad = r_med - 25*r_sig\n    if check_rad_cutoff == 'calc':\n        check_rad_cutoff = [r_med - 7.5*r_sig, r_med + 7.5*r_sig]\n\n    # 1. Automatic deletion:\n    rad_wrong_size = np.nonzero(\n            (st.obj_get_radii() < min_rad) | (st.obj_get_radii() > max_rad))[0]\n    near_im_edge = np.nonzero(is_near_im_edge(st.obj_get_positions(),\n                              min_edge_dist - st.pad))[0]\n    delete_inds = np.unique(np.append(rad_wrong_size, near_im_edge)).tolist()\n    delete_poses = st.obj_get_positions()[delete_inds].tolist()\n    message = ('-'*27 + 'SUBTRACTING' + '-'*28 +\n               '\\n  Z\\t  Y\\t  X\\t  R\\t|\\t ERR0\\t\\t ERR1')\n    with log.noformat():\n        CLOG.info(message)\n\n    for pos in delete_poses:\n        ind = st.obj_closest_particle(pos)\n        old_err = st.error\n        p, r = st.obj_remove_particle(ind)\n        p = p[0]\n        r = r[0]\n        part_msg = '%2.2f\\t%3.2f\\t%3.2f\\t%3.2f\\t|\\t%4.3f  \\t%4.3f' % (\n                tuple(p) + (r,) + (old_err, st.error))\n        with log.noformat():\n            CLOG.info(part_msg)\n        removed += 1\n\n    # 2. Conditional deletion:\n    check_rad_inds = np.nonzero((st.obj_get_radii() < check_rad_cutoff[0]) |\n                                (st.obj_get_radii() > check_rad_cutoff[1]))[0]\n    if check_outside_im:\n        check_edge_inds = np.nonzero(\n            is_near_im_edge(st.obj_get_positions(), st.pad))[0]\n        check_inds = np.unique(np.append(check_rad_inds, check_edge_inds))\n    else:\n        check_inds = check_rad_inds\n\n    check_inds = check_inds[np.argsort(st.obj_get_radii()[check_inds])]\n    tries = np.min([tries, check_inds.size])\n    check_poses = st.obj_get_positions()[check_inds[:tries]].copy()\n    for pos in check_poses:\n        old_err = st.error\n        ind = st.obj_closest_particle(pos)\n        killed, p, r = check_remove_particle(\n            st, ind, im_change_frac=im_change_frac)\n        if killed:\n            removed += 1\n            check_inds[check_inds > ind] -= 1  # cleaning up indices....\n            delete_poses.append(pos)\n            part_msg = '%2.2f\\t%3.2f\\t%3.2f\\t%3.2f\\t|\\t%4.3f  \\t%4.3f' % (\n                    p + r + (old_err, st.error))\n            with log.noformat():\n                CLOG.info(part_msg)\n    return removed, delete_poses"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_subtract(st, max_iter=7, max_npart='calc', max_mem=2e8,\n                 always_check_remove=False, **kwargs):\n    \"\"\"\n    Automatically adds and subtracts missing & extra particles.\n\n    Operates by removing bad particles then adding missing particles on\n    repeat, until either no particles are added/removed or after `max_iter`\n    attempts.\n\n    Parameters\n    ----------\n    st: :class:`peri.states.State`\n        The state to add and subtract particles to.\n    max_iter : Int, optional\n        The maximum number of add-subtract loops to use. Default is 7.\n        Terminates after either max_iter loops or when nothing has changed.\n    max_npart : Int or 'calc', optional\n        The maximum number of particles to add before optimizing the non-psf\n        globals. Default is ``'calc'``, which uses 5% of the initial number\n        of particles.\n    max_mem : Int, optional\n        The maximum memory to use for optimization after adding max_npart\n        particles. Default is 2e8.\n    always_check_remove : Bool, optional\n        Set to True to always check whether to remove particles. If ``False``,\n        only checks for removal while particles were removed on the previous\n        attempt. Default is False.\n\n    Other Parameters\n    ----------------\n    invert : Bool, optional\n        ``True`` if the particles are dark on a bright background, ``False``\n        if they are bright on a dark background. Default is ``True``.\n    min_rad : Float, optional\n        Particles with radius below ``min_rad`` are automatically deleted.\n        Default is ``'calc'`` = median rad - 25* radius std.\n    max_rad : Float, optional\n        Particles with radius above ``max_rad`` are automatically deleted.\n        Default is ``'calc'`` = median rad + 15* radius std, but you should\n        change this for your particle sizes.\n\n    min_edge_dist : Float, optional\n        Particles closer to the edge of the padded image than this are\n        automatically deleted. Default is 2.0.\n    check_rad_cutoff : 2-element float list.\n        Particles with ``radii < check_rad_cutoff[0]`` or ``> check...[1]``\n        are checked if they should be deleted (not automatic). Default is\n        ``[3.5, 15]``.\n    check_outside_im : Bool, optional\n        Set to True to check whether to delete particles whose positions are\n        outside the un-padded image.\n\n    rad : Float, optional\n        The initial radius for added particles; added particles radii are\n        not fit until the end of ``add_subtract``. Default is ``'calc'``,\n        which uses the median radii of active particles.\n\n    tries : Int, optional\n        The number of particles to attempt to remove or add, per iteration.\n        Default is 50.\n\n    im_change_frac : Float, optional\n        How good the change in error needs to be relative to the change in\n        the difference image. Default is 0.2; i.e. if the error does not\n        decrease by 20% of the change in the difference image, do not add\n        the particle.\n\n    min_derr : Float, optional\n        The minimum change in the state's error to keep a particle in the\n        image. Default is ``'3sig'`` which uses ``3*st.sigma``.\n\n    do_opt : Bool, optional\n        Set to False to avoid optimizing particle positions after adding.\n    minmass : Float, optional\n        The minimum mass for a particle to be identified as a feature,\n        as used by trackpy. Defaults to a decent guess.\n\n    use_tp : Bool, optional\n        Set to True to use trackpy to find missing particles inside the\n        image. Not recommended since trackpy deliberately cuts out particles\n        at the edge of the image. Default is ``False``.\n\n    Returns\n    -------\n    total_changed : Int\n        The total number of adds and subtracts done on the data. Not the\n        same as ``changed_inds.size`` since the same particle or particle\n        index can be added/subtracted multiple times.\n    added_positions : [N_added,3] numpy.ndarray\n        The positions of particles that have been added at any point in the\n        add-subtract cycle.\n    removed_positions : [N_added,3] numpy.ndarray\n        The positions of particles that have been removed at any point in\n        the add-subtract cycle.\n\n    Notes\n    ------\n    Occasionally after the intial featuring a cluster of particles is\n    featured as 1 big particle. To fix these mistakes, it helps to set\n    max_rad to a physical value. This removes the big particle and allows\n    it to be re-featured by (several passes of) the adds.\n\n    The added/removed positions returned are whether or not the position\n    has been added or removed ever. It's possible that a position is\n    added, then removed during a later iteration.\n    \"\"\"\n    if max_npart == 'calc':\n        max_npart = 0.05 * st.obj_get_positions().shape[0]\n\n    total_changed = 0\n    _change_since_opt = 0\n    removed_poses = []\n    added_poses0 = []\n    added_poses = []\n\n    nr = 1  # Check removal on the first loop\n    for _ in range(max_iter):\n        if (nr != 0) or (always_check_remove):\n            nr, rposes = remove_bad_particles(st, **kwargs)\n        na, aposes = add_missing_particles(st, **kwargs)\n        current_changed = na + nr\n        removed_poses.extend(rposes)\n        added_poses0.extend(aposes)\n        total_changed += current_changed\n        _change_since_opt += current_changed\n        if current_changed == 0:\n            break\n        elif _change_since_opt > max_npart:\n            _change_since_opt *= 0\n            CLOG.info('Start add_subtract optimization.')\n            opt.do_levmarq(st, opt.name_globals(st, remove_params=st.get(\n                    'psf').params), max_iter=1, run_length=4, num_eig_dirs=3,\n                    max_mem=max_mem, eig_update_frequency=2, rz_order=0,\n                    use_accel=True)\n            CLOG.info('After optimization:\\t{:.6}'.format(st.error))\n\n    # Optimize the added particles' radii:\n    for p in added_poses0:\n        i = st.obj_closest_particle(p)\n        opt.do_levmarq_particles(st, np.array([i]), max_iter=2, damping=0.3)\n        added_poses.append(st.obj_get_positions()[i])\n    return total_changed, np.array(removed_poses), np.array(added_poses)", "response": "A function that adds and subtracts missing particles from a state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef identify_misfeatured_regions(st, filter_size=5, sigma_cutoff=8.):\n    # 1. Field of local std\n    r = st.residuals\n    weights = np.ones([filter_size]*len(r.shape), dtype='float')\n    weights /= weights.sum()\n    f = np.sqrt(nd.filters.convolve(r*r, weights, mode='reflect'))\n\n    # 2. Maximal reasonable value of the field.\n    if sigma_cutoff == 'otsu':\n        max_ok = initializers.otsu_threshold(f)\n    else:\n        # max_ok = f.mean() * (1 + sigma_cutoff / np.sqrt(weights.size))\n        max_ok = f.mean() + sigma_cutoff * f.std()\n\n    # 3. Label & Identify\n    bad = f > max_ok\n    labels, n = nd.measurements.label(bad)\n    inds = []\n    for i in range(1, n+1):\n        inds.append(np.nonzero(labels == i))\n\n    # 4. Parse into tiles\n    tiles = [Tile(np.min(ind, axis=1), np.max(ind, axis=1)+1) for ind in inds]\n\n    # 5. Sort and return\n    volumes = [t.volume for t in tiles]\n    return [tiles[i] for i in np.argsort(volumes)[::-1]]", "response": "This function returns a list of tiles that are not mis - featured."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds and subtracts missing & extra particles from a state s current particles.", "response": "def add_subtract_misfeatured_tile(\n        st, tile, rad='calc', max_iter=3, invert='guess', max_allowed_remove=20,\n        minmass=None, use_tp=False, **kwargs):\n    \"\"\"\n    Automatically adds and subtracts missing & extra particles in a region\n    of poor fit.\n\n    Parameters\n    ----------\n    st: :class:`peri.states.State`\n        The state to add and subtract particles to.\n    tile : :class:`peri.util.Tile`\n        The poorly-fit region to examine.\n    rad : Float or 'calc', optional\n        The initial radius for added particles; added particles radii are\n        not fit until the end of add_subtract. Default is ``'calc'``, which\n        uses the median radii of active particles.\n    max_iter : Int, optional\n        The maximum number of loops for attempted adds at one tile location.\n        Default is 3.\n    invert : {'guess', True, False}, optional\n        Whether to invert the image for feature_guess -- True for dark\n        particles on a bright background, False for bright particles. The\n        default is to guess from the state's current particles.\n    max_allowed_remove : Int, optional\n        The maximum number of particles to remove. If the misfeatured tile\n        contains more than this many particles, raises an error. If it\n        contains more than half as many particles, logs a warning. If more\n        than this many particles are added, they are optimized in blocks of\n        ``max_allowed_remove``. Default is 20.\n\n    Other Parameters\n    ----------------\n    im_change_frac : Float on [0, 1], optional.\n        If adding or removing a particle decreases the error less than\n        ``im_change_frac``*the change in the image, the particle is deleted.\n        Default is 0.2.\n\n    min_derr : {Float, ``'3sig'``}, optional\n        The minimum change in the state's error to keep a particle in the\n        image. Default is ``'3sig'`` which uses ``3*st.sigma``.\n\n    do_opt : Bool, optional\n        Set to False to avoid optimizing particle positions after adding\n        them. Default is True.\n\n    minmass : Float, optional\n        The minimum mass for a particle to be identified as a feature, as\n        used by trackpy. Defaults to a decent guess.\n\n    use_tp : Bool, optional\n        Set to True to use trackpy to find missing particles inside the\n        image. Not recommended since trackpy deliberately cuts out particles\n        at the edge of the image. Default is False.\n\n    Outputs\n    -------\n    n_added : Int\n        The change in the number of particles, i.e. ``n_added-n_subtracted``\n    ainds: List of ints\n        The indices of the added particles.\n\n    Notes\n    --------\n    The added/removed positions returned are whether or not the\n    position has been added or removed ever. It's possible/probably that\n    a position is added, then removed during a later iteration.\n\n    Algorithm is:\n    1.  Remove all particles within the tile.\n    2.  Feature and add particles to the tile.\n    3.  Optimize the added particles positions only.\n    4.  Run 2-3 until no particles have been added.\n    5.  Optimize added particle radii\n    Because all the particles are removed within a tile, it is important\n    to set max_allowed_remove to a reasonable value. Otherwise, if the\n    tile is the size of the image it can take a long time to remove all\n    the particles and re-add them.\n    \"\"\"\n    if rad == 'calc':\n        rad = guess_add_radii(st)\n    if invert == 'guess':\n        invert = guess_invert(st)\n    # 1. Remove all possibly bad particles within the tile.\n    initial_error = np.copy(st.error)\n    rinds = np.nonzero(tile.contains(st.obj_get_positions()))[0]\n    if rinds.size >= max_allowed_remove:\n        CLOG.fatal('Misfeatured region too large!')\n        raise RuntimeError\n    elif rinds.size >= max_allowed_remove/2:\n        CLOG.warn('Large misfeatured regions.')\n    elif rinds.size > 0:\n        rpos, rrad = st.obj_remove_particle(rinds)\n\n    # 2-4. Feature & add particles to the tile, optimize, run until none added\n    n_added = -rinds.size\n    added_poses = []\n    for _ in range(max_iter):\n        if invert:\n            im = 1 - st.residuals[tile.slicer]\n        else:\n            im = st.residuals[tile.slicer]\n        guess, _ = _feature_guess(im, rad, minmass=minmass, use_tp=use_tp)\n        accepts, poses = check_add_particles(\n                st, guess+tile.l, rad=rad, do_opt=True, **kwargs)\n        added_poses.extend(poses)\n        n_added += accepts\n        if accepts == 0:\n            break\n    else:  # for-break-else\n        CLOG.warn('Runaway adds or insufficient max_iter')\n\n    # 5. Optimize added pos + rad:\n    ainds = []\n    for p in added_poses:\n        ainds.append(st.obj_closest_particle(p))\n    if len(ainds) > max_allowed_remove:\n        for i in range(0, len(ainds), max_allowed_remove):\n            opt.do_levmarq_particles(\n                st, np.array(ainds[i:i + max_allowed_remove]),\n                include_rad=True, max_iter=3)\n    elif len(ainds) > 0:\n        opt.do_levmarq_particles(st, ainds, include_rad=True, max_iter=3)\n\n    # 6. Ensure that current error after add-subtracting is lower than initial\n    did_something = (rinds.size > 0) or (len(ainds) > 0)\n    if did_something & (st.error > initial_error):\n        CLOG.info('Failed addsub, Tile {} -> {}'.format(\n            tile.l.tolist(), tile.r.tolist()))\n        if len(ainds) > 0:\n            _ = st.obj_remove_particle(ainds)\n        if rinds.size > 0:\n            for p, r in zip(rpos.reshape(-1, 3), rrad.reshape(-1)):\n                _ = st.obj_add_particle(p, r)\n        n_added = 0\n        ainds = []\n    return n_added, ainds"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_subtract_locally(st, region_depth=3, filter_size=5, sigma_cutoff=8,\n                         **kwargs):\n    \"\"\"\n    Automatically adds and subtracts missing particles based on local\n    regions of poor fit.\n\n    Calls identify_misfeatured_regions to identify regions, then\n    add_subtract_misfeatured_tile on the tiles in order of size until\n    region_depth tiles have been checked without adding any particles.\n\n    Parameters\n    ----------\n    st: :class:`peri.states.State`\n        The state to add and subtract particles to.\n    region_depth : Int\n        The minimum amount of regions to try; the algorithm terminates if\n        region_depth regions have been tried without adding particles.\n\n    Other Parameters\n    ----------------\n    filter_size : Int, optional\n        The size of the filter for calculating the local standard deviation;\n        should approximately be the size of a poorly featured region in each\n        dimension. Best if odd. Default is 5.\n    sigma_cutoff : Float, optional\n        The max allowed deviation of the residuals from what is expected,\n        in units of the residuals' standard deviation. Lower means more\n        sensitive, higher = less sensitive. Default is 8.0, i.e. one pixel\n        out of every ``7*10^11`` is mis-identified randomly. In practice the\n        noise is not Gaussian so there are still some regions mis-\n        identified as improperly featured.\n    rad : Float or 'calc', optional\n        The initial radius for added particles; added particles radii are\n        not fit until the end of add_subtract. Default is ``'calc'``, which\n        uses the median radii of active particles.\n    max_iter : Int, optional\n        The maximum number of loops for attempted adds at one tile location.\n        Default is 3.\n    invert : Bool, optional\n        Whether to invert the image for feature_guess. Default is ``True``,\n        i.e. dark particles on bright background.\n    max_allowed_remove : Int, optional\n        The maximum number of particles to remove. If the misfeatured tile\n        contains more than this many particles, raises an error. If it\n        contains more than half as many particles, throws a warning. If more\n        than this many particles are added, they are optimized in blocks of\n        ``max_allowed_remove``. Default is 20.\n    im_change_frac : Float, between 0 and 1.\n        If adding or removing a particle decreases the error less than\n        ``im_change_frac *`` the change in the image, the particle is deleted.\n        Default is 0.2.\n    min_derr : Float\n        The minimum change in the state's error to keep a particle in the\n        image. Default is ``'3sig'`` which uses ``3*st.sigma``.\n    do_opt : Bool, optional\n        Set to False to avoid optimizing particle positions after adding\n        them. Default is True\n    minmass : Float, optional\n        The minimum mass for a particle to be identified as a feature, as\n        used by trackpy. Defaults to a decent guess.\n    use_tp : Bool, optional\n        Set to True to use trackpy to find missing particles inside the\n        image. Not recommended since trackpy deliberately cuts out\n        particles at the edge of the image. Default is False.\n    max_allowed_remove : Int, optional\n        The maximum number of particles to remove. If the misfeatured tile\n        contains more than this many particles, raises an error. If it\n        contains more than half as many particles, throws a warning. If more\n        than this many particles are added, they are optimized in blocks of\n        ``max_allowed_remove``. Default is 20.\n\n    Returns\n    -------\n    n_added : Int\n        The change in the number of particles; i.e the number added - number\n        removed.\n    new_poses : List\n        [N,3] element list of the added particle positions.\n\n    Notes\n    -----\n    Algorithm Description\n\n    1. Identify mis-featured regions by how much the local residuals\n       deviate from the global residuals, as measured by the standard\n       deviation of both.\n    2. Loop over each of those regions, and:\n\n       a. Remove every particle in the current region.\n       b. Try to add particles in the current region until no more\n          can be added while adequately decreasing the error.\n       c. Terminate if at least region_depth regions have been\n          checked without successfully adding a particle.\n\n    Because this algorithm is more judicious about chooosing regions to\n    check, and more aggressive about removing particles in those regions,\n    it runs faster and does a better job than the (global) add_subtract.\n    However, this function usually does not work better as an initial add-\n    subtract on an image, since (1) it doesn't check for removing small/big\n    particles per se, and (2) when the poorly-featured regions of the image\n    are large or when the fit is bad, it will remove essentially all of the\n    particles, taking a long time. As a result, it's usually best to do a\n    normal add_subtract first and using this function for tough missing or\n    double-featured particles.\n    \"\"\"\n    # 1. Find regions of poor tiles:\n    tiles = identify_misfeatured_regions(\n        st, filter_size=filter_size, sigma_cutoff=sigma_cutoff)\n    # 2. Add and subtract in the regions:\n    n_empty = 0\n    n_added = 0\n    new_poses = []\n    for t in tiles:\n        curn, curinds = add_subtract_misfeatured_tile(st, t, **kwargs)\n        if curn == 0:\n            n_empty += 1\n        else:\n            n_added += curn\n            new_poses.extend(st.obj_get_positions()[curinds])\n        if n_empty > region_depth:\n            break  # some message or something?\n    else:  # for-break-else\n        pass\n        # CLOG.info('All regions contained particles.')\n        # something else?? this is not quite true\n    return n_added, new_poses", "response": "A function that adds and subtracts missing particles from a state that is not in the state of a poor fit."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef guess_invert(st):\n    pos = st.obj_get_positions()\n    pxinds_ar = np.round(pos).astype('int')\n    inim = st.ishape.translate(-st.pad).contains(pxinds_ar)\n    pxinds_tuple = tuple(pxinds_ar[inim].T)\n    pxvals = st.data[pxinds_tuple]\n    invert = np.median(pxvals) < np.median(st.data)  # invert if dark particles\n    return invert", "response": "Guesses whether particles are bright on a dark bkg or vice - versa\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_wisdom(wisdomfile):\n    if wisdomfile is None:\n        return\n\n    try:\n        pyfftw.import_wisdom(pickle.load(open(wisdomfile, 'rb')))\n    except (IOError, TypeError) as e:\n        log.warn(\"No wisdom present, generating some at %r\" % wisdomfile)\n        save_wisdom(wisdomfile)", "response": "Load the FFTW with knowledge of which FFTs are best on this machine by loading the wisdom file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving the acquired wisdom to file.", "response": "def save_wisdom(wisdomfile):\n    \"\"\"\n    Save the acquired 'wisdom' generated by FFTW to file so that future\n    initializations of FFTW will be faster.\n    \"\"\"\n    if wisdomfile is None:\n        return\n\n    if wisdomfile:\n        pickle.dump(\n            pyfftw.export_wisdom(), open(wisdomfile, 'wb'),\n            protocol=2\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tile_overlap(inner, outer, norm=False):\n    div = 1.0/inner.volume if norm else 1.0\n    return div*(inner.volume - util.Tile.intersection(inner, outer).volume)", "response": "How much of inner is in outer by volume"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a tiling of space by state shift and size find the closest tile to another external tile", "response": "def closest_uniform_tile(s, shift, size, other):\n    \"\"\"\n    Given a tiling of space (by state, shift, and size), find the closest\n    tile to another external tile\n    \"\"\"\n    region = util.Tile(size, dim=s.dim, dtype='float').translate(shift - s.pad)\n    vec = np.round((other.center - region.center) / region.shape)\n    return region.translate(region.shape * vec)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a state returns a list of groups of particles that are located near each other in the image.", "response": "def separate_particles_into_groups(s, region_size=40, bounds=None):\n    \"\"\"\n    Given a state, returns a list of groups of particles. Each group of\n    particles are located near each other in the image. Every particle\n    located in the desired region is contained in exactly 1 group.\n\n    Parameters:\n    -----------\n    s : state\n        The PERI state to find particles in.\n\n    region_size: int or list of ints\n        The size of the box. Groups particles into boxes of shape region_size.\n        If region_size is a scalar, the box is a cube of length region_size.\n        Default is 40.\n\n    bounds: 2-element list-like of 3-element lists.\n        The sub-region of the image over which to look for particles.\n            bounds[0]: The lower-left  corner of the image region.\n            bounds[1]: The upper-right corner of the image region.\n        Default (None -> ([0,0,0], s.oshape.shape)) is a box of the entire\n        image size, i.e. the default places every particle in the image\n        somewhere in the groups.\n\n    Returns:\n    -----------\n    particle_groups: list\n        Each element of particle_groups is an int numpy.ndarray of the\n        group of nearby particles. Only contains groups with a nonzero\n        number of particles, so the elements don't necessarily correspond\n        to a given image region.\n    \"\"\"\n    imtile = (\n        s.oshape.translate(-s.pad) if bounds is None else\n        util.Tile(bounds[0], bounds[1])\n    )\n\n    # does all particle including out of image, is that correct?\n    region = util.Tile(region_size, dim=s.dim)\n    trange = np.ceil(imtile.shape.astype('float') / region.shape)\n\n    translations = util.Tile(trange).coords(form='vector')\n    translations = translations.reshape(-1, translations.shape[-1])\n\n    groups = []\n    positions = s.obj_get_positions()\n    for v in translations:\n        tmptile = region.copy().translate(region.shape * v - s.pad)\n        groups.append(find_particles_in_tile(positions, tmptile))\n\n    return [g for g in groups if len(g) > 0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_comparison_state(image, position, radius=5.0, snr=20,\n        method='constrained-cubic', extrapad=2, zscale=1.0):\n    \"\"\"\n    Take a platonic image and position and create a state which we can\n    use to sample the error for peri. Also return the blurred platonic\n    image so we can vary the noise on it later\n    \"\"\"\n    # first pad the image slightly since they are pretty small\n    image = common.pad(image, extrapad, 0)\n\n    # place that into a new image at the expected parameters\n    s = init.create_single_particle_state(imsize=np.array(image.shape), sigma=1.0/snr,\n            radius=radius, psfargs={'params': np.array([2.0, 1.0, 3.0]), 'error': 1e-6, 'threads': 2},\n            objargs={'method': method}, stateargs={'sigmapad': False, 'pad': 4, 'zscale': zscale})\n    s.obj.pos[0] = position + s.pad + extrapad\n    s.reset()\n    s.model_to_true_image()\n\n    timage = 1-np.pad(image, s.pad, mode='constant', constant_values=0)\n    timage = s.psf.execute(timage)\n    return s, timage[s.inner]", "response": "Create a state which we can use to sample the error for peri."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dorun(method, platonics=None, nsnrs=20, noise_samples=30, sweeps=30, burn=15):\n    sigmas = np.logspace(np.log10(1.0/2048), 0, nsnrs)\n    crbs, vals, errs, poss = [], [], [], []\n\n    for sigma in sigmas:\n        print \"#### sigma:\", sigma\n\n        for i, (image, pos) in enumerate(platonics):\n            print 'image', i, '|', \n            s,im = create_comparison_state(image, pos, method=method)\n\n            # typical image\n            set_image(s, im, sigma)\n            crbs.append(crb(s))\n\n            val, err = sample(s, im, sigma, N=noise_samples, sweeps=sweeps, burn=burn)\n            poss.append(pos)\n            vals.append(val)\n            errs.append(err)\n\n\n    shape0 = (nsnrs, len(platonics), -1)\n    shape1 = (nsnrs, len(platonics), noise_samples, -1)\n\n    crbs = np.array(crbs).reshape(shape0)\n    vals = np.array(vals).reshape(shape1)\n    errs = np.array(errs).reshape(shape1)\n    poss = np.array(poss).reshape(shape0)\n\n    return  [crbs, vals, errs, poss, sigmas]", "response": "This function generates a dorun of the given platonics."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef perfect_platonic_per_pixel(N, R, scale=11, pos=None, zscale=1.0, returnpix=None):\n    # enforce odd scale size\n    if scale % 2 != 1:\n        scale += 1\n\n    if pos is None:\n        # place the default position in the center of the grid\n        pos = np.array([(N-1)/2.0]*3)\n\n    # limit positions to those that are exact on the size 1./scale\n    # positions have the form (d = divisions):\n    #   p = N + m/d\n    s = 1.0/scale\n    f = zscale**2\n\n    i = pos.astype('int')\n    p = i + s*((pos - i)/s).astype('int')\n    pos = p + 1e-10 # unfortunately needed to break ties\n\n    # make the output arrays\n    image = np.zeros((N,)*3)\n    x,y,z = np.meshgrid(*(xrange(N),)*3, indexing='ij')\n\n    # for each real pixel in the image, integrate a bunch of superres pixels\n    for x0,y0,z0 in zip(x.flatten(),y.flatten(),z.flatten()):\n\n        # short-circuit things that are just too far away!\n        ddd = np.sqrt(f*(x0-pos[0])**2 + (y0-pos[1])**2 + (z0-pos[2])**2)\n        if ddd > R + 4:\n            image[x0,y0,z0] = 0.0\n            continue\n\n        # otherwise, build the local mesh and count the volume\n        xp,yp,zp = np.meshgrid(\n            *(np.linspace(i-0.5+s/2, i+0.5-s/2, scale, endpoint=True) for i in (x0,y0,z0)),\n            indexing='ij'\n        )\n        ddd = np.sqrt(f*(xp-pos[0])**2 + (yp-pos[1])**2 + (zp-pos[2])**2)\n\n        if returnpix is not None and returnpix == [x0,y0,z0]:\n            outpix = 1.0 * (ddd < R)\n\n        vol = (1.0*(ddd < R) + 0.0*(ddd == R)).sum()\n        image[x0,y0,z0] = vol / float(scale**3)\n\n    #vol_true = 4./3*np.pi*R**3\n    #vol_real = image.sum()\n    #print vol_true, vol_real, (vol_true - vol_real)/vol_true\n\n    if returnpix:\n        return image, pos, outpix\n    return image, pos", "response": "Create a perfect platonic sphere of a given radius R with a given scale and a given position."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef translate_fourier(image, dx):\n    N = image.shape[0]\n\n    f = 2*np.pi*np.fft.fftfreq(N)\n    kx,ky,kz = np.meshgrid(*(f,)*3, indexing='ij')\n    kv = np.array([kx,ky,kz]).T\n\n    q = np.fft.fftn(image)*np.exp(-1.j*(kv*dx).sum(axis=-1)).T\n    return np.real(np.fft.ifftn(q))", "response": "Translate an image in fourier - space with plane waves"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstandardizing the plot format of the does_matter section. See any of the accompaning files to see how to use this generalized plot. image0 : ground true image1 : difference image xs : list of x values for the plots crbs : list of lines of values of the crbs errors : list of lines of errors labels : legend labels for each curve", "response": "def doplot(image0, image1, xs, crbs, errors, labels, diff_image_scale=0.1,\n        dolabels=True, multiple_crbs=True, xlim=None, ylim=None, highlight=None,\n        detailed_labels=False, xlabel=\"\", title=\"\"):\n    \"\"\"\n    Standardizing the plot format of the does_matter section.  See any of the\n    accompaning files to see how to use this generalized plot.\n\n    image0 : ground true\n    image1 : difference image\n    xs : list of x values for the plots\n    crbs : list of lines of values of the crbs\n    errors : list of lines of errors\n    labels : legend labels for each curve\n    \"\"\"\n    if len(crbs) != len(errors) or len(crbs) != len(labels):\n        raise IndexError, \"lengths are not consistent\"\n\n    fig = pl.figure(figsize=(14,7))\n\n    ax = fig.add_axes([0.43, 0.15, 0.52, 0.75])\n    gs = ImageGrid(fig, rect=[0.05, 0.05, 0.25, 0.90], nrows_ncols=(2,1), axes_pad=0.25,\n            cbar_location='right', cbar_mode='each', cbar_size='10%', cbar_pad=0.04)\n\n    diffm = diff_image_scale*np.ceil(np.abs(image1).max()/diff_image_scale)\n\n    im0 = gs[0].imshow(image0, vmin=0, vmax=1, cmap='bone_r')\n    im1 = gs[1].imshow(image1, vmin=-diffm, vmax=diffm, cmap='RdBu')\n    cb0 = pl.colorbar(im0, cax=gs[0].cax, ticks=[0,1])\n    cb1 = pl.colorbar(im1, cax=gs[1].cax, ticks=[-diffm,diffm]) \n    cb0.ax.set_yticklabels(['0', '1'])\n    cb1.ax.set_yticklabels(['-%0.1f' % diffm, '%0.1f' % diffm])\n    image_names = [\"Reference\", \"Difference\"]\n\n    for i in xrange(2):\n        gs[i].set_xticks([])\n        gs[i].set_yticks([])\n        gs[i].set_ylabel(image_names[i])\n\n        if dolabels:\n            lbl(gs[i], figlbl[i])\n\n    symbols = ['o', '^', 'D', '>']\n    for i in xrange(len(labels)):\n        c = COLORS[i]\n\n        if multiple_crbs or i == 0:\n            if multiple_crbs:\n                label = labels[i] if (i != 0 and not detailed_labels) else '%s CRB' % labels[i]\n            else:\n                label = 'CRB'\n            ax.plot(xs[i], crbs[i], '-', c=c, lw=3, label=label)\n\n        label = labels[i] if (i != 0 and not detailed_labels) else '%s Error' % labels[i]\n        ax.plot(xs[i], errors[i], symbols[i], ls='--', lw=2, c=c, label=label, ms=12)\n\n    if dolabels:\n        lbl(ax, 'D')\n    ax.loglog()\n    if xlim:\n        ax.set_xlim(xlim)\n    if ylim:\n        ax.set_ylim(ylim)\n    ax.legend(loc='upper left', ncol=2, prop={'size': 18}, numpoints=1)\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(r\"Position CRB, Error\")\n    ax.grid(False, which='both', axis='both')\n    ax.set_title(title)\n\n    return gs, ax"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads default users and groups.", "response": "def users():\n    \"\"\"Load default users and groups.\"\"\"\n    from invenio_groups.models import Group, Membership, \\\n        PrivacyPolicy, SubscriptionPolicy\n\n    admin = accounts.datastore.create_user(\n        email='admin@inveniosoftware.org',\n        password=encrypt_password('123456'),\n        active=True,\n    )\n    reader = accounts.datastore.create_user(\n        email='reader@inveniosoftware.org',\n        password=encrypt_password('123456'),\n        active=True,\n    )\n\n    admins = Group.create(name='admins', admins=[admin])\n    for i in range(10):\n        Group.create(name='group-{0}'.format(i), admins=[admin])\n    Membership.create(admins, reader)\n    db.session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the log priors of the log priors of the related resources.", "response": "def _calculate(self):\n        self.logpriors = np.zeros_like(self.rad)\n\n        for i in range(self.N-1):\n            o = np.arange(i+1, self.N)\n\n            dist = ((self.zscale*(self.pos[i] - self.pos[o]))**2).sum(axis=-1)\n            dist0 = (self.rad[i] + self.rad[o])**2\n\n            update = self.prior_func(dist - dist0)\n            self.logpriors[i] += np.sum(update)\n            self.logpriors[o] += update\n\n        \"\"\"\n        # This is equivalent\n        for i in range(self.N-1):\n            for j in range(i+1, self.N):\n                d = ((self.zscale*(self.pos[i] - self.pos[j]))**2).sum(axis=-1)\n                r = (self.rad[i] + self.rad[j])**2\n\n                cost = self.prior_func(d - r)\n                self.logpriors[i] += cost\n                self.logpriors[j] += cost\n        \"\"\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nweighting function for Barnes", "response": "def _weight(self, rsq, sigma=None):\n        \"\"\"weighting function for Barnes\"\"\"\n        sigma = sigma or self.filter_size\n\n        if not self.clip:\n            o = np.exp(-rsq / (2*sigma**2))\n        else:\n            o = np.zeros(rsq.shape, dtype='float')\n            m = (rsq < self.clipsize**2)\n            o[m] = np.exp(-rsq[m] / (2*sigma**2))\n        return o"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _newcall(self, rvecs):\n        # 1. Initial guess for output:\n        sigma = 1*self.filter_size\n        out = self._eval_firstorder(rvecs, self.d, sigma)\n        # 2. There are differences between 0th order at the points and\n        #    the passed data, so we iterate to remove:\n        ondata = self._eval_firstorder(self.x, self.d, sigma)\n        for i in range(self.iterations):\n            out += self._eval_firstorder(rvecs, self.d-ondata, sigma)\n            ondata += self._eval_firstorder(self.x, self.d-ondata, sigma)\n            sigma *= self.damp\n        return out", "response": "Correct normalized version of Barnes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbarn w/o normalizing the weights", "response": "def _oldcall(self, rvecs):\n        \"\"\"Barnes w/o normalizing the weights\"\"\"\n        g = self.filter_size\n\n        dist0 = self._distance_matrix(self.x, self.x)\n        dist1 = self._distance_matrix(rvecs, self.x)\n\n        tmp = self._weight(dist0, g).dot(self.d)\n        out = self._weight(dist1, g).dot(self.d)\n\n        for i in range(self.iterations):\n            out = out + self._weight(dist1, g).dot(self.d - tmp)\n            tmp = tmp + self._weight(dist0, g).dot(self.d - tmp)\n            g *= self.damp\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _distance_matrix(self, a, b):\n        def sq(x): return (x * x)\n        # matrix = np.sum(map(lambda a,b: sq(a[:,None] - b[None,:]), a.T,\n        #   b.T), axis=0)\n        # A faster version than above:\n        matrix = sq(a[:, 0][:, None] - b[:, 0][None, :])\n        for x, y in zip(a.T[1:], b.T[1:]):\n            matrix += sq(x[:, None] - y[None, :])\n        return matrix", "response": "Pairwise distance between each point in a and each point in b."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _x2c(self, x):\n        return ((2 * x - self.window[1] - self.window[0]) /\n                (self.window[1] - self.window[0]))", "response": "Convert windowdow coordinates to cheb coordinates - 1 - 1 - 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _c2x(self, c):\n        return 0.5 * (self.window[0] + self.window[1] +\n                      c * (self.window[1] - self.window[0]))", "response": "Convert cheb coordinates to windowdow coordinates"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstruct the coefficients for the logarithmic logarithm of logarithm of logarithm of logarithmic logarithmic", "response": "def _construct_coefficients(self):\n        \"\"\"Calculate the coefficients based on the func, degree, and\n        interpolating points.\n        _coeffs is a [order, N,M,....] array\n\n        Notes\n        -----\n        Moved the -c0 to the coefficients defintion\n        app -= 0.5 * self._coeffs[0] -- moving this to the coefficients\n        \"\"\"\n        coeffs = [0]*self.degree\n\n        N = float(self.evalpts)\n\n        lvals = np.arange(self.evalpts).astype('float')\n        xpts = self._c2x(np.cos(np.pi*(lvals + 0.5)/N))\n        fpts = np.rollaxis(self.func(xpts, *self.args), -1)\n\n        for a in range(self.degree):\n            inner = [\n                fpts[b] * np.cos(np.pi*a*(lvals[b]+0.5)/N)\n                for b in range(self.evalpts)\n            ]\n            coeffs[a] = 2.0/N * np.sum(inner, axis=0)\n\n        coeffs[0] *= 0.5\n        self._coeffs = np.array(coeffs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nevaluates an individual Chebyshev polynomial k in coordinate space with proper transformation given the window x.", "response": "def tk(self, k, x):\n        \"\"\"\n        Evaluates an individual Chebyshev polynomial `k` in coordinate space\n        with proper transformation given the window\n        \"\"\"\n        weights = np.diag(np.ones(k+1))[k]\n        return np.polynomial.chebyshev.chebval(self._x2c(x), weights)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates subscription policy value.", "response": "def validate(cls, policy):\n        \"\"\"Validate subscription policy value.\"\"\"\n        return policy in [cls.OPEN, cls.APPROVAL, cls.CLOSED]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates privacy policy value.", "response": "def validate(cls, policy):\n        \"\"\"Validate privacy policy value.\"\"\"\n        return policy in [cls.PUBLIC, cls.MEMBERS, cls.ADMINS]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(cls, name=None, description='', privacy_policy=None,\n               subscription_policy=None, is_managed=False, admins=None):\n        \"\"\"Create a new group.\n\n        :param name: Name of group. Required and must be unique.\n        :param description: Description of group. Default: ``''``\n        :param privacy_policy: PrivacyPolicy\n        :param subscription_policy: SubscriptionPolicy\n        :param admins: list of user and/or group objects. Default: ``[]``\n        :returns: Newly created group\n        :raises: IntegrityError: if group with given name already exists\n        \"\"\"\n        assert name\n        assert privacy_policy is None or PrivacyPolicy.validate(privacy_policy)\n        assert subscription_policy is None or \\\n            SubscriptionPolicy.validate(subscription_policy)\n        assert admins is None or isinstance(admins, list)\n\n        with db.session.begin_nested():\n            obj = cls(\n                name=name,\n                description=description,\n                privacy_policy=privacy_policy,\n                subscription_policy=subscription_policy,\n                is_managed=is_managed,\n            )\n            db.session.add(obj)\n\n            for a in admins or []:\n                db.session.add(GroupAdmin(\n                    group=obj, admin_id=a.get_id(),\n                    admin_type=resolve_admin_type(a)))\n\n        return obj", "response": "Create a new group."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes a group and all associated memberships.", "response": "def delete(self):\n        \"\"\"Delete a group and all associated memberships.\"\"\"\n        with db.session.begin_nested():\n            Membership.query_by_group(self).delete()\n            GroupAdmin.query_by_group(self).delete()\n            GroupAdmin.query_by_admin(self).delete()\n            db.session.delete(self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the properties of the current object.", "response": "def update(self, name=None, description=None, privacy_policy=None,\n               subscription_policy=None, is_managed=None):\n        \"\"\"Update group.\n\n        :param name: Name of group.\n        :param description: Description of group.\n        :param privacy_policy: PrivacyPolicy\n        :param subscription_policy: SubscriptionPolicy\n        :returns: Updated group\n        \"\"\"\n        with db.session.begin_nested():\n            if name is not None:\n                self.name = name\n            if description is not None:\n                self.description = description\n            if (\n                privacy_policy is not None and\n                PrivacyPolicy.validate(privacy_policy)\n            ):\n                self.privacy_policy = privacy_policy\n            if (\n                subscription_policy is not None and\n                SubscriptionPolicy.validate(subscription_policy)\n            ):\n                self.subscription_policy = subscription_policy\n            if is_managed is not None:\n                self.is_managed = is_managed\n\n            db.session.merge(self)\n\n        return self"}
