{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an instance of the model_class from the cache if it is present.", "response": "def peek_record(self, model_class, record_id):\n        \"\"\"Return an instance of the model_class from the cache if it is present.\n\n        Args:\n            model_class (:class:`cinder_data.model.CinderModel`): A subclass of\n                :class:`cinder_data.model.CinderModel` of your chosen model.\n            record_id (int): The id of the record requested.\n\n        Returns:\n            :class:`cinder_data.model.CinderModel`: An instance of model_class or None.\n        \"\"\"\n        if self._cache:\n            return self._cache.get_record(model_class.__name__, record_id)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_all(self, model_class, params={}):\n        url = '{host}/{namespace}/{model}{params}'.format(\n            host=self._host,\n            namespace=self._namespace,\n            model=self._translate_name(model_class.__name__),\n            params=self._build_param_string(params)\n        )\n        data = self._get_json(url)['data']\n        fresh_models = []\n        for item in data:\n            fresh_model = model_class(item['attributes'])\n            fresh_model.id = item['id']\n            fresh_model.validate()\n            fresh_models.append(fresh_model)\n            if self._cache is not None:\n                self._cache.set_record(model_class.__name__, fresh_model.id, fresh_model)\n        return fresh_models", "response": "Return an array of models from the API and caches the result."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of models from the local cache.", "response": "def peek_all(self, model_class):\n        \"\"\"Return a list of models from the local cache.\n\n        Args:\n            model_class (:class:`cinder_data.model.CinderModel`): A subclass of\n                :class:`cinder_data.model.CinderModel` of your chosen model.\n\n        Returns:\n            list: A list of instances of you model_class or and empty list.\n        \"\"\"\n        if self._cache:\n            return self._cache.get_records(model_class.__name__)\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a single record from the API.", "response": "def _get_record(self, model_class, record_id):\n        \"\"\"Get a single record from the API.\n\n        Args:\n            model_class (:class:`cinder_data.model.CinderModel`): A subclass of\n                :class:`cinder_data.model.CinderModel` of your chosen model.\n            record_id (int): The id of the record requested.\n\n        Returns:\n            :class:`cinder_data.model.CinderModel`: An instance of model_class or None.\n        \"\"\"\n        url = '{host}/{namespace}/{model}/{id}'.format(\n            host=self._host,\n            namespace=self._namespace,\n            model=self._translate_name(model_class.__name__),\n            id=record_id\n        )\n        data = self._get_json(url)['data']\n        fresh_model = model_class(data['attributes'])\n        fresh_model.id = data['id']\n        fresh_model.validate()\n        if self._cache is not None:\n            self._cache.set_record(model_class.__name__, fresh_model.id, fresh_model)\n        return fresh_model"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntranslating the class name to the API endpoint.", "response": "def _translate_name(name):\n        \"\"\"Translate the class name to the API endpoint.\n\n        For example, Car would become cars, FastCar would become fast-cars.\n\n        Args:\n            name (string): Camel case name (singular)\n\n        Returns:\n            string: A pluraised, dasherized string.\n        \"\"\"\n        underscored = inflection.underscore(name)\n        dasherized = inflection.dasherize(underscored)\n        words = dasherized.split('-')\n        last_word = words.pop()\n        words.append(inflection.pluralize(last_word))\n        return '-'.join(words)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a query string from a dictionary of params.", "response": "def _build_param_string(params):\n        \"\"\"Build query params string from a dictionary.\n\n        Args:\n            params (dict): A dictionary of params\n\n        Returns:\n            string: A valid url query params string.\n        \"\"\"\n        pairs = []\n        for key, value in params.iteritems():\n            if value is None:\n                value = ''\n            pairs.append('{0}={1}'.format(key, value))\n        if len(pairs) > 0:\n            return '?{0}'.format('&'.join(pairs))\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nresolve the given URL using the settings dictionary.", "response": "def _resolve_by_settings_urls(request, url, urlconf=None):\n    \"\"\"\n    Finds appropriate URL in settings dictionary ``NAVIGATION_URL_MAP`` and\n    returns the Crumb object based on the value. The values can be strings or\n    functions (or any callables). The functions are called as views. The\n    callable values do not require that an existing endpoint and always get\n    only one argument: the ``request`` object.\n    \"\"\"\n    mapping = getattr(settings, 'NAVIGATION_URL_MAP', {})\n    title = mapping.get(url, None)\n    if title is not None:\n        if hasattr(title, '__call__'):\n            title = title(request)\n#            try:\n#                endpoint, args, kwargs = _resolve_url(url, request,\n#                                                      urlconf=urlconf)\n#            except urlresolvers.Resolver404:\n#                # call at least somehow\n#                title = title(request)#, *args, **kwargs)\n#            else:\n#                # call with full params\n#                title = title(request, *args, **kwargs)\n        return Crumb(url, title)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _resolve_by_callback(request, url, urlconf=None):\n    try:\n        callback, args, kwargs = _resolve_url(url, request, urlconf=urlconf)\n    except urlresolvers.Resolver404:\n        return None\n\n    bc = getattr(callback, 'breadcrumb', None)\n    if bc is None:\n        bc = getattr(callback, 'navigation', None)\n        if bc is not None:  # pragma: nocover\n            import warnings\n            warnings.warn('The \"navigation\" attribute is deprecated, use '\n                          '\"breadcrumb\" instead.')\n    if bc is None:\n        return None\n\n    if hasattr(bc, '__call__'):\n        # the breadcrumb is a function with an API identical to that of views.\n        try:\n            title = bc(request, *args, **kwargs)\n        except http.Http404:\n            return None\n        assert isinstance(title, basestring), (\n            'Breadcrumb function must return Unicode, not %s' % title)\n    else:\n        title = unicode(bc)    # handle i18n proxy objects\n\n    return Crumb(url, title)", "response": "Resolves a url by urlconf and returns a Crumb object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a the defined message to the backend.", "response": "def send(self, message):\n        \"\"\"Send a the defined message to the backend.\n\n        :param message: Message to be send, usually a Python dictionary.\n        \"\"\"\n        try:\n            self.ws.send(json.dumps(message))\n        except websocket._exceptions.WebSocketConnectionClosedException:\n            raise SelenolWebSocketClosedException()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef recv(self):\n        try:\n            message = self.ws.recv()\n            return json.loads(message)\n        except websocket._exceptions.WebSocketConnectionClosedException as ex:\n            raise SelenolWebSocketClosedException() from ex", "response": "Receive a message from the backend or wait unilt next message."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_client(host, project_name, api_key, create_project):\n    if host is None:\n        raise click.BadParameter('No grano server host is set', param=host)\n    if project_name is None:\n        raise click.BadParameter('No grano project slug is set',\n                                 param=project_name)\n    if api_key is None:\n        raise click.BadParameter('No grano API key is set', param=api_key)\n\n    client = Grano(api_host=host,\n                   api_key=api_key)\n    try:\n        return client.get(project_name)\n    except NotFound:\n        if not create_project:\n            sys.exit(-1)\n        data = {'slug': project_name, 'label': project_name}\n        return client.projects.create(data)", "response": "Create a new client based on the environment variables or\n    command line settings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a CSV file into a grano instance.", "response": "def csv(ctx, force, threads, mapping, data):\n    \"\"\" Load CSV data into a grano instance using a mapping specification. \"\"\"\n\n    # Find out how many lines there are (for the progress bar).\n    lines = 0\n    for line in DictReader(data):\n        lines += 1\n    data.seek(0)\n\n    # set up objects\n    mapping = yaml.load(mapping)\n    mapping_loader = MappingLoader(ctx.obj['grano'], mapping)\n\n    def process_row(row):\n        try:\n            mapping_loader.load(row)\n        except GranoException, ge:\n            msg = '\\nServer error: %s' % ge.message\n            click.secho(msg, fg='red', bold=True)\n            if not force:\n                os._exit(1)\n        except RowException, re:\n            if not force:\n                msg = '\\nRow %s: %s' % (row['__row_id__'], re.message)\n                click.secho(msg, fg='red', bold=True)\n                os._exit(1)\n\n    def generate():\n        with click.progressbar(DictReader(data),\n                               label=data.name,\n                               length=lines) as bar:\n            for i, row in enumerate(bar):\n                row['__row_id__'] = i\n                yield row\n\n    threaded(generate(), process_row, num_threads=threads,\n             max_queue=1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef schema(ctx, schema):\n    data = yaml.load(schema)\n    if not isinstance(data, (list, tuple)):\n        data = [data]\n    with click.progressbar(data, label=schema.name) as bar:\n        for schema in bar:\n            ctx.obj['grano'].schemata.upsert(schema)", "response": "Load schema definitions from a YAML file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse ISO - 8601 values from JSON databases.", "response": "def json_using_iso8601(__obj: Dict) -> Dict:\n    \"\"\"Parse ISO-8601 values from JSON databases.\n\n    See :class:`json.JSONDecoder`\n\n    Args:\n        __obj: Object to decode\n    \"\"\"\n    for key, value in __obj.items():\n        with suppress(TypeError, ValueError):\n            __obj[key] = parse_datetime(value)\n        with suppress(TypeError, ValueError):\n            __obj[key] = parse_delta(value)\n    return __obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new script", "response": "def create_driver_script(name, create=None):  # noqa: E501\n    \"\"\"Create a new script\n\n    Create a new script # noqa: E501\n\n    :param name: Get status of a driver with this name\n    :type name: str\n    :param create: The data needed to create this script\n    :type create: dict | bytes\n\n    :rtype: Response\n    \"\"\"\n    if connexion.request.is_json:\n        create = Create1.from_dict(connexion.request.get_json())  # noqa: E501\n\n    response = errorIfUnauthorized(role='developer')\n    if response:\n        return response\n    else:\n        response = ApitaxResponse()\n\n    driver: Driver = LoadedDrivers.getDriver(name)\n    driver.saveDriverScript(create.script.name, create.script.content)\n\n    return Response(status=200, body=response.getResponseBody())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_driver_script(name, name2=None):  # noqa: E501\n    response = errorIfUnauthorized(role='user')\n    if response:\n        return response\n    else:\n        response = ApitaxResponse()\n\n    print(name)\n    print(name2)\n\n\n    driver: Driver = LoadedDrivers.getDriver(name2)\n\n    response.body.add({'content': driver.getDriverScript(name)})\n\n    return Response(status=200, body=response.getResponseBody())", "response": "Retrieve the contents of a script in a node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_driver_script_catalog(name):  # noqa: E501\n\n    response = errorIfUnauthorized(role='user')\n    if response:\n        return response\n    else:\n        response = ApitaxResponse()\n\n    driver: Driver = LoadedDrivers.getDriver(name)\n\n    response.body.add(driver.getDriverScriptCatalog().get())\n\n    return Response(status=200, body=response.getResponseBody())", "response": "Retrieve the script catalog of a driver with this name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rename_driver_script(name, rename=None):  # noqa: E501\n    if connexion.request.is_json:\n        rename = Rename.from_dict(connexion.request.get_json())  # noqa: E501\n\n    response = errorIfUnauthorized(role='developer')\n    if response:\n        return response\n    else:\n        response = ApitaxResponse()\n\n    driver: Driver = LoadedDrivers.getDriver(name)\n    if not driver.renameDriverScript(rename.original.name, rename.new.name):\n        return ErrorResponse(status=500, message='Cannot rename to an existing file.')\n\n    return Response(status=200, body=response.getResponseBody())", "response": "Rename a script in a driver"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_driver_script(name, save=None):  # noqa: E501\n    if connexion.request.is_json:\n        save = Save1.from_dict(connexion.request.get_json())  # noqa: E501\n\n    response = errorIfUnauthorized(role='developer')\n    if response:\n        return response\n    else:\n        response = ApitaxResponse()\n\n    driver: Driver = LoadedDrivers.getDriver(name)\n    driver.saveDriverScript(save.script.name, save.script.content)\n\n    return Response(status=200, body=response.getResponseBody())", "response": "Save a script of a driver"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a temporary directory and returns its path.", "response": "def get_tmpdir():\n    \"\"\"\n    On first invocation, creates a temporary directory and returns its\n    path. Subsequent invocations uses the same directory.\n\n    :returns: A temporary directory created for this run of glerbl.\n    :rtype: :class:`str`\n    \"\"\"\n    global __tmpdir\n    if __tmpdir is not None:\n        return __tmpdir\n\n    __tmpdir = tempfile.mkdtemp(prefix='.tmp.glerbl.', dir=\".\")\n    atexit.register(__clean_tmpdir)\n\n    return __tmpdir"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_against():\n    global __cached_against\n    if __cached_against is not None:\n        return __cached_against\n\n    status = subprocess.call([\"git\", \"rev-parse\", \"--verify\", \"HEAD\"],\n                             stdout=open(os.devnull, 'w'),\n                             stderr=subprocess.STDOUT)\n    if not status:\n        against = 'HEAD'\n    else:\n\t# Initial commit: diff against an empty tree object\n        against = '4b825dc642cb6eb9a060e54bf8d69288fbee4904'\n\n    __cached_against = against\n    return against", "response": "Determines the revision against which the staged data ought to be checked."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes function when module is run directly.", "response": "def entry_point(__func: Callable) -> Callable:\n    \"\"\"Execute function when module is run directly.\n\n    Note:\n        This allows fall through for importing modules that use it.\n\n    Args:\n        __func: Function to run\n    \"\"\"\n    if __func.__module__ == '__main__':\n        import sys\n        sys.exit(__func())\n    else:\n        return __func"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding the authorization uri that a user must be redirected to for the application.", "response": "def build_auth_uri(endpoint, client_id, redirect_uri=None, scope=None, state=None):\n        \"\"\"\n        Helper method builds the uri that a user must be redirected to for\n        authentication/authorization using the authorization_code grant type.\n\n            endpoint - The authorization endpoint\n\n            client_id - The client id\n\n            redirect_uri - The redirect uri\n\n            scope - A list of permissions to request\n\n            state - An application state that will be sent back by the\n              authorization server\n        \"\"\"\n        params = {'response_type': 'code', 'client_id': client_id}\n        if redirect_uri is not None:\n            params['redirect_uri'] = redirect_uri\n\n        if scope is not None:\n            params['scope'] = ' '.join(scope)\n\n        if state is not None:\n            params['state'] = state\n\n        return '%s?%s' % (endpoint, urlencode(params))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn column numbers and letters that repeat up to NUM_REPEATS.", "response": "def create_col_nums():\n    \"\"\"Return column numbers and letters that repeat up to NUM_REPEATS.\n\n    I.e., NUM_REPEATS = 2 would return a list of 26 * 26 = 676 2-tuples.\n\n    \"\"\"\n    NUM_REPEATS = 2\n    column_letters = list(\n        string.ascii_uppercase\n    ) + map(\n        ''.join,\n        itertools.product(\n            string.ascii_uppercase,\n            repeat=NUM_REPEATS\n        )\n    )\n    letter_numbers = []\n\n    count = 1\n    for letter in column_letters:\n        letter_numbers.append((count, str(count) + ' (' + letter + ')'))\n        count += 1\n\n    return tuple(letter_numbers)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds comment to a thread.", "response": "def add_comment(self, body, allow_create=False, allow_hashes=False,\n                    summary=None):\n        \"\"\"Add comment as required by comments.CommentThread parent class.\n        \"\"\"\n        thread_id = self.lookup_thread_id()\n        if not allow_create and not self.redis.exists(thread_id):\n            raise ValueError('Tried to add comment to non-exist thread %s' % (\n                thread_id))\n\n        comment = comments.SingleComment(\n            self.user, datetime.datetime.now(datetime.timezone.utc), body, \n            summary=summary)\n        lpush = self.redis.lpush(thread_id, comment.to_json())\n        logging.debug('Pushing comment to redis returned %s', str(lpush))\n        if self.ltrim:\n            ltrim = self.redis.ltrim(thread_id, 0, self.ltrim)\n            logging.debug('Redis ltrim returend %s', str(ltrim))\n        else:\n            ltrim = None\n\n        return {'status': 'OK', 'lpush': lpush, 'ltrim': ltrim}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef submit_task(rel_path, cache_string, buffer):\n    global upload_queue\n    global upload_thread\n    upload_queue.put((rel_path, cache_string, buffer))\n\n    if upload_thread is None or not upload_thread.is_alive():\n        upload_thread = UploaderThread()\n        upload_thread.start()", "response": "Put a task on the queue and start the thread if required"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove(self, rel_path, propagate=False):\n        '''Delete the file from the cache, and from the upstream'''\n\n        if not self.upstream:\n            raise Exception(\"Must have an upstream\")\n\n        # Must always propagate, since this is really just a filter.\n        self.upstream.remove(self._rename(rel_path), propagate)", "response": "Delete the file from the cache and from the upstream"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a list of all of the files in the repository", "response": "def list(self, path=None, with_metadata=False, include_partitions=False):\n        '''get a list of all of the files in the repository'''\n        return self.upstream.list(\n            path,\n            with_metadata=with_metadata,\n            include_partitions=include_partitions)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_verse(self, v=1):\n        verse_count = len(self.verses)\n        if v - 1 < verse_count:\n            return self.verses[v - 1]", "response": "Get a specific verse."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_line(self, line=1):\n        verse_size = len(self.get_verse()) + 1\n        if line > 1:\n            verse = math.floor((line - 1) / verse_size)\n            line_in_verse = (line - 1) % verse_size\n            try:\n                return self.verses[verse][line_in_verse]\n            except IndexError:\n                return ''\n        else:\n            return self.verses[0][0]", "response": "Return a specific line."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint all the verses.", "response": "def print_poem(self):\n        \"\"\"Print all the verses.\"\"\"\n        for index, verse in enumerate(self.verses):\n            for line in verse:\n                print(line)\n            if index != len(self.verses) - 1:\n                print('')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_mods(package):\n    pkgdir = package.__path__[0]\n    matches = filter(None, [PYMOD_RE.match(f) for f in os.listdir(pkgdir)])\n    parse_match = lambda groups: (groups[0], int(groups[1]), int(groups[2]))\n    return sorted(list(set([parse_match(m.groups()) for m in matches])),\n                  key=lambda x: (x[1], x[2]))", "response": "List all loadable python modules in a directory"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_new(modules, min_major_version, min_minor_version):\n    for mod_data in modules:\n        (modname, mod_major_version, mod_minor_version) = mod_data\n        if (mod_major_version > min_major_version or\n                (mod_major_version == min_major_version and\n                    mod_minor_version >= min_minor_version)):\n            yield mod_data", "response": "Get list of migrations that haven t been run yet"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_mod(module, package):\n    name = '%s.%s' % (package.__name__, module)\n    if name in sys.modules:\n        return sys.modules[name]\n    return importlib.import_module(name, package=package.__name__)", "response": "Loads a module named module from given search path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unpack_version(version):\n    minor_version = version % VERSION_MULTIPLIER\n    major_version = (version - minor_version) / VERSION_MULTIPLIER\n    return (major_version, minor_version)", "response": "Unpack a single version integer into the two major and minor components."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nquerying database and return migration version.", "response": "def get_version(db, name):\n    \"\"\" Query database and return migration version. WARNING: side effecting\n    function! if no version information can be found, any existing database\n    matching the passed one's name will be deleted and recreated.\n\n    :param db:      connetion object\n    :param name:    associated name\n    :returns:       current migration version\n    \"\"\"\n    try:\n        result = db.fetchone(GET_VERSION_SQL, dict(name=name))\n    except psycopg2.ProgrammingError as exc:\n        if 'does not exist' in str(exc):\n            return recreate(db, name)\n        raise\n    else:\n        if result is None:\n            set_version(db, name, 0, 0)\n            return (0, 0)\n        version = result['version']\n        return unpack_version(version)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_version(db, name, major_version, minor_version):\n    version = pack_version(major_version, minor_version)\n    db.execute(SET_VERSION_SQL, dict(name=name, version=version))", "response": "Set database migration version"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the migration script for the current node.", "response": "def run_migration(name, major_version, minor_version, db, mod, conf={}):\n    \"\"\" Run migration script\n\n    :param major_version: major version number of the migration\n    :param minor_version: minor version number of the migration\n    :param db:            database connection object\n    :param path:          path of the migration script\n    :param conf:          application configuration (if any)\n    \"\"\"\n    with db.transaction():\n        mod.up(db, conf)\n        set_version(db, name, major_version, minor_version)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef migrate(db, name, package, conf={}):\n    (current_major_version, current_minor_version) = get_version(db, name)\n    package = importlib.import_module(package)\n    logging.debug('Migration version for %s is %s.%s',\n                  package.__name__,\n                  current_major_version,\n                  current_minor_version)\n    mods = get_mods(package)\n    migrations = get_new(mods,\n                         current_major_version,\n                         current_minor_version + 1)\n    for (modname, major_version, minor_version) in migrations:\n        mod = load_mod(modname, package)\n        run_migration(name, major_version, minor_version, db, mod, conf)\n        logging.debug(\"Finished migrating to %s\", modname)", "response": "Run all migrations that have not been run inside a transaction."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert hypertext markup into vt markup.", "response": "def html2vtml(vtmarkup):\n    \"\"\" Convert hypertext markup into vt markup.\n    The output can be given to `vtmlrender` for converstion to VT100\n    sequences. \"\"\"\n    try:\n        htmlconv.feed(vtmarkup)\n        htmlconv.close()\n        return htmlconv.getvalue()\n    finally:\n        htmlconv.reset()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef htmlprint(*values, plain=None, **options):\n    print(*[htmlrender(x, plain=plain) for x in values], **options)", "response": "Convert HTML to VTML and then print it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrender the template in the given scope with the given locals.", "response": "def render(self,scope=None,local_vars=None,block=None):\n\t\t''' Render the template in the given scope with the locals specified. If a\n\t\t\tblock is given, it is typically available within the template via\n\t\t\t+yield+.\n\t\t'''\n\n\t\tif not scope:\n\t\t\tclass Scope(object):\n\t\t\t\tpass\n\n\t\t\tscope = Scope()\n\n\t\treturn self.evaluate(scope,local_vars or {}, block)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef evaluate(self,scope,local_vars,block=None):\n\t\t''' Execute the compiled template and return the result string. Template\n\t\t\tevaluation is guaranteed to be performed in the scope object with the\n\t\t\tlocals specified and with support for yielding to the block.\n\t\t\t   \n\t\t\t   This method is only used by source generating templates. Subclasses that\n\t\t\toverride render() may not support all features.\n\t\t'''\n\t\tmethod = self.compiled_method(local_vars.keys())\n\t\tsetattr(scope\t,'compiled',method)\n\t\t\n\t\treturn scope.compiled(local_vars,block=block)", "response": "Execute the compiled template and return the result string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter(self, filter):\n        new_query_set = self.clone()\n        new_query_set.query.add_filter(filter)\n        \n        return new_query_set", "response": "Add a filter to the query set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef limit(self, n, skip=None):\n        if self.query.limit is not None:\n            raise MonSQLException('LIMIT already defined')\n\n        new_query_set = self.clone()\n        new_query_set.query.limit = n\n        new_query_set.query.skip = skip\n\n        return new_query_set", "response": "Limit the result set to a certain number of rows."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new QuerySet with distinct row.", "response": "def distinct(self):\n        \"\"\"\n        Only return distinct row. \n        Return a new query set with distinct mark\n        \"\"\"\n        new_query_set = self.clone()\n        new_query_set.query.distinct = True\n        return new_query_set"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of GradDegree objects.", "response": "def _process_json(json_data):\n    \"\"\"\n    return a list of GradDegree objects.\n    \"\"\"\n    requests = []\n    for item in json_data:\n        degree = GradDegree()\n        degree.degree_title = item[\"degreeTitle\"]\n        degree.exam_place = item[\"examPlace\"]\n        degree.exam_date = parse_datetime(item.get(\"examDate\"))\n        degree.req_type = item[\"requestType\"]\n        degree.major_full_name = item[\"majorFullName\"]\n        degree.submit_date = parse_datetime(item.get(\"requestSubmitDate\"))\n        degree.decision_date = parse_datetime(item.get('decisionDate'))\n        degree.status = item[\"status\"]\n        degree.target_award_year = item[\"targetAwardYear\"]\n        if item.get(\"targetAwardQuarter\")and\\\n           len(item.get(\"targetAwardQuarter\")):\n            degree.target_award_quarter = item[\"targetAwardQuarter\"].lower()\n\n        requests.append(degree)\n    return requests"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a server object into a dictionary representation.", "response": "def server_to_dict(server):\n    \"\"\"\n    Returns the :class:`dict` representation of a server object.\n\n    The returned :class:`dict` is meant to be consumed by\n    :class:`~bang.deployers.cloud.ServerDeployer` objects.\n\n    \"\"\"\n    return {\n            A.server.ID: server.id,\n            A.server.PUBLIC_IPS: [server.public_dns_name],\n            A.server.PRIVATE_IPS: [server.private_dns_name],\n            }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of server dictionaries that match the given tags.", "response": "def find_servers(self, tags, running=True):\n        \"\"\"\n        Returns any servers in the region that have tags that match the\n        key-value pairs in :attr:`tags`.\n\n        :param Mapping tags:  A mapping object in which the keys are the tag\n            names and the values are the tag values.\n\n        :param bool running:  A flag to limit server list to instances that are\n            actually *running*.\n\n        :rtype:  :class:`list` of :class:`dict` objects.  Each :class:`dict`\n            describes a single server instance.\n\n        \"\"\"\n        filters = dict([('tag:%s' % key, val) for key, val in tags.items()])\n        if running:\n            filters['instance-state-name'] = 'running'\n\n        res = self.ec2.get_all_instances(filters=filters)\n        instances = [server_to_dict(i) for r in res for i in r.instances]\n        log.debug('instances: %s' % instances)\n        return instances"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_server(self, basename, disk_image_id, instance_type,\n            ssh_key_name, tags=None, availability_zone=None,\n            timeout_s=DEFAULT_TIMEOUT_S, **provider_extras):\n        \"\"\"\n        Creates a new server instance.  This call blocks until the server is\n        created and available for normal use, or :attr:`timeout_s` has elapsed.\n\n        :param str basename:  An identifier for the server.  A random postfix\n            will be appended to this basename to work around OpenStack Nova\n            REST API limitations.\n\n        :param str disk_image_id:  The identifier of the base disk image to use\n            as the rootfs.\n\n        :param str instance_type:  The name of an EC2 instance type.\n\n        :param str ssh_key_name:  The name of the ssh key to inject into the\n            target server's ``authorized_keys`` file.  The key must already\n            have been registered in the target EC2 region.\n\n        :param tags:  Up to 5 key-value pairs of arbitrary strings to use as\n            *tags* for the server instance.\n        :type tags:  :class:`Mapping`\n\n        :param str availability_zone:  The name of the availability zone in\n            which to place the server.\n\n        :param float timeout_s:  The number of seconds to poll for an active\n            server before failing.  Defaults to ``0`` (i.e. Expect server to be\n            active immediately).\n\n        :rtype:  :class:`dict`\n\n        \"\"\"\n        log.info(\n                'Launching server %s... this could take a while...'\n                % basename\n                )\n        if 'disable_api_termination' not in provider_extras:\n            provider_extras['disable_api_termination'] = True\n\n        # ec2 api has the following rule:\n        #\n        #     if you specify a subnet_id, you must specify secgroups as\n        #     security_group_ids\n        #\n        # so, we'll assume that if you specify a subnet_id, you don't mean to\n        # have secgroups\n        if 'subnet_id' in provider_extras:\n            secgroups = provider_extras.pop('security_groups', None)\n            if secgroups:\n                log.warn(\n                        \"... When using subnet_id you must use\"\n                        \" security_group_ids.  Ignoring security_groups %s.\"\n                        % secgroups\n                        )\n\n        res = self.ec2.run_instances(\n                disk_image_id,\n                instance_type=instance_type,\n                key_name=ssh_key_name,\n                placement=availability_zone,\n                **provider_extras\n                )\n        instance = res.instances[0]\n\n        # we're too fast for EC2... slow down a little bit, twice\n        time.sleep(2)\n\n        def apply_tags():\n            try:\n                for key, val in tags.items():\n                    instance.add_tag(key, val)\n                return True\n            except EC2ResponseError:\n                pass\n        if not poll_with_timeout(timeout_s, apply_tags, 5):\n            raise TimeoutError('Could not tag server %s' % instance.id)\n\n        def find_running_instance():\n            if instance.update() == 'running':\n                return instance\n        running = poll_with_timeout(timeout_s, find_running_instance, 5)\n        if not running:\n            raise TimeoutError('Could not launch server within allotted time.')\n        return server_to_dict(running)", "response": "Creates a new server instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_secgroup(self, name):\n        res = self.ec2.get_all_security_groups(filters={'group-name': name})\n        if res:\n            return EC2SecGroup(res[0])", "response": "Find a security group by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new security group.", "response": "def create_secgroup(self, name, description):\n        \"\"\"\n        Creates a new server security group.\n\n        :param str name:  The name of the security group to create.\n        :param str description:  A short description of the group.\n\n        \"\"\"\n        return self.ec2.create_security_group(name, description)\n        log.debug(\"... created group %s\" % name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a security group rule.", "response": "def create_secgroup_rule(self, protocol, from_port, to_port,\n            source, target):\n        \"\"\"\n        Creates a new server security group rule.\n\n        :param str protocol:  E.g. ``tcp``, ``icmp``, etc...\n        :param int from_port:  E.g. ``1``\n        :param int to_port:  E.g. ``65535``\n        :param str source:\n        :param str target:  The target security group.  I.e. the group in which\n            this rule should be created.\n\n        \"\"\"\n        kwargs = {\n            'ip_protocol': protocol,\n            'from_port': from_port,\n            'to_port': to_port\n        }\n        sg = self.find_secgroup(target).ec2sg\n        if not sg:\n            raise BangError(\"Security group not found, %s\" % target)\n        if '/' in source:\n            # Treat as cidr (/ is mask)\n            kwargs['cidr_ip'] = source\n        else:\n            kwargs['src_group'] = self.find_secgroup(source).ec2sg\n        sg.authorize(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_bucket(self, name):\n        log.info('Creating bucket %s...' % name)\n        self.s3.create_bucket(name)", "response": "Creates a new S3 bucket."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads meta data from Little Leonardo data files.", "response": "def read_meta(path_dir, tag_model, tag_id):\n    '''Read meta data from Little Leonardo data header rows\n\n    Args\n    ----\n    path_dir: str\n        Parent directory containing lleo data files\n    tag_model: str\n        Little Leonardo tag model name\n    tag_id: str, int\n        Little Leonardo tag ID number\n\n    Returns\n    -------\n    meta: dict\n        dictionary with meta data from header lines of lleo data files\n    '''\n    from collections import OrderedDict\n    import os\n    import yamlord\n\n    from . import utils\n\n    def _parse_meta_line(line):\n        '''Return key, value pair parsed from data header line'''\n\n        # Parse the key and its value from the line\n        key, val = line.replace(':', '').replace('\"', '').split(',')\n\n        return key.strip(), val.strip()\n\n\n    def _read_meta_all(f, meta, n_header):\n        '''Read all meta data from header rows of data file'''\n\n        # Skip 'File name' line\n        f.seek(0)\n        _ = f.readline()\n\n        # Create child dictionary for channel / file\n        line = f.readline()\n        key_ch, val_ch = _parse_meta_line(line)\n        val_ch = utils.posix_string(val_ch)\n        meta['parameters'][val_ch] = OrderedDict()\n\n        # Write header values to channel dict\n        for _ in range(n_header-2):\n            line = f.readline()\n            key, val = _parse_meta_line(line)\n            meta['parameters'][val_ch][key] = val.strip()\n\n        return meta\n\n\n    def _create_meta(path_dir, tag_model, tag_id):\n        '''Create meta data dictionary'''\n        import datetime\n        from . import utils\n\n        param_strs = utils.get_tag_params(tag_model)\n\n        # Create dictionary of meta data\n        meta = OrderedDict()\n\n        # Create fields for the parameters in data directory name\n        exp_name = os.path.split(path_dir)[1]\n        params_tag = utils.parse_experiment_params(exp_name)\n        for key, value in params_tag.items():\n            meta[key] = value\n\n        fmt = \"%Y-%m-%d %H:%M:%S\"\n        meta['date_modified'] = datetime.datetime.now().strftime(fmt)\n\n        meta['parameters'] = OrderedDict()\n\n        for param_str in param_strs:\n            print('Create meta entry for {}'.format(param_str))\n\n            path_file = utils.find_file(path_dir, param_str, '.TXT')\n            # Get number of header rows\n            enc = utils.predict_encoding(path_file, n_lines=20)\n            with open(path_file, 'r', encoding=enc) as f:\n                n_header = utils.get_n_header(f)\n                f.seek(0)\n                meta = _read_meta_all(f, meta, n_header=n_header)\n\n        return meta\n\n\n    # Load meta data from YAML file if it already exists\n    meta_yaml_path = os.path.join(path_dir, 'meta.yml')\n\n    # Load file if exists else create\n    if os.path.isfile(meta_yaml_path):\n        meta = yamlord.read_yaml(meta_yaml_path)\n\n    # Else create meta dictionary and save to YAML\n    else:\n        meta = _create_meta(path_dir, tag_model, tag_id)\n        yamlord.write_yaml(meta, meta_yaml_path)\n\n    return meta"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_data(meta, path_dir, sample_f=1, decimate=False, overwrite=False):\n    '''Read accelerometry data from leonardo txt files\n\n    Args\n    ----\n    meta: dict\n        Dictionary of meta data from header lines of lleo data files\n    path_dir: str\n        Parent directory containing lleo data files\n    sample_f: int\n        Return every `sample_f` data points\n\n    Returns\n    -------\n    acc: pandas.DataFrame\n        Dataframe containing accelerometry data on x, y, z axes [m/s^2]\n    depth: pandas.DataFrame\n        Dataframe containing depth data [m]\n    prop: pandas.DataFrame\n        Dataframe containing speed data from propeller\n    temp: pandas.DataFrame\n        Dataframe containing temperature data\n    '''\n    import os\n    import pandas\n\n    from . import utils\n\n    def _generate_datetimes(date, time, interval_s, n_timestamps):\n        '''Generate list of datetimes from date/time with given interval'''\n        from datetime import datetime, timedelta\n        import pandas\n\n        # TODO problematic if both m/d d/m options\n        fmts  = ['%Y/%m/%d %H%M%S',\n                 '%d/%m/%Y %H%M%S',\n                 '%m/%d/%Y %I%M%S %p',\n                 '%d/%m/%Y %I%M%S %p',]\n\n        for fmt in fmts:\n            try:\n                start = pandas.to_datetime('{} {}'.format(date,time), format=fmt)\n            except:\n                print('Date format {:18} incorrect, '\n                      'trying next...'.format(fmt))\n            else:\n                print('Date format {:18} correct.'.format(fmt))\n                break\n\n        # Create datetime array\n        datetimes = list()\n        for i in range(n_timestamps):\n            secs = interval_s*i\n            datetimes.append(start + timedelta(seconds=secs))\n\n        return datetimes\n\n\n    def _read_data_file(meta, path_dir, param_str):\n        '''Read single Little Leonardo txt data file'''\n        import numpy\n        import os\n        import pandas\n\n        from . import utils\n\n        # Get path of data file and associated pickle file\n        path_file = utils.find_file(path_dir, param_str, '.TXT')\n        col_name = utils.posix_string(param_str)\n\n        # Get number of header rows in file\n        enc = utils.predict_encoding(path_file, n_lines=20)\n        with open(path_file, 'r', encoding=enc) as f:\n            n_header = utils.get_n_header(f)\n\n        print('\\nReading: {}'.format(col_name))\n\n        data = numpy.genfromtxt(path_file, skip_header=n_header)\n\n        interval_s = float(meta['parameters'][col_name]['Interval(Sec)'])\n        date = meta['parameters'][col_name]['Start date']\n        time = meta['parameters'][col_name]['Start time']\n\n        # TODO review\n        # Generate summed data if propeller sampling rate not 1\n        if (col_name == 'propeller') and (interval_s < 1):\n            print('Too high sampling interval, taking sums')\n            # Sampling rate\n            fs = int(1/interval_s)\n\n            print('data before', data.max())\n            # Drop elements to make divisible by fs for summing\n            data = data[:-int(len(data)%fs)]\n\n            # Reshape to 2D with columns `fs` in length to be summed\n            data = data.reshape(fs, int(len(data)/fs))\n            data = numpy.sum(data, axis=0)\n            interval_s = 1\n\n            print('data after', data.max())\n\n        datetimes = _generate_datetimes(date, time, interval_s, len(data))\n        data      = numpy.vstack((datetimes, data)).T\n        df        = pandas.DataFrame(data, columns=['datetimes', col_name])\n\n        return df\n\n    # Get list of string parameter names for tag model\n    param_names = utils.get_tag_params(meta['tag_model'])\n\n    # Load pickle file exists and code unchanged\n    pickle_file = os.path.join(path_dir, 'pydata_'+meta['experiment']+'.p')\n\n    # Load or create pandas DataFrame with parameters associated with tag model\n    if (os.path.exists(pickle_file)) and (overwrite is not True):\n        data_df = pandas.read_pickle(pickle_file)\n    else:\n        first_col = True\n        for name in param_names:\n            next_df = _read_data_file(meta, path_dir, name)\n            if first_col == False:\n                data_df = pandas.merge(data_df, next_df, on='datetimes', how='left')\n            else:\n                data_df = next_df\n                first_col = False\n        print('')\n\n        # Covert columns to `datetime64` or `float64` types\n        data_df = data_df.apply(lambda x: pandas.to_numeric(x, errors='ignore'))\n\n        # Save file to pickle\n        data_df.to_pickle(pickle_file)\n\n    # Return DataFrame with ever `sample_f` values\n    return data_df.iloc[::sample_f,:]", "response": "Read data from leonardo txt files and return every sample_f data points."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_loaded_configs(self, values):\n        unresolved_value_keys = self._process_config_values([], values, [])\n        if len(unresolved_value_keys) > 0:\n            msg = \"Unresolved values for: {}\".format(unresolved_value_keys)\n            # Even though we will fail, there might be a situation when we want to \n            # do something with the list of missing values, so pass it to a handler.\n            self.on_process_loaded_configs_failure(values, unresolved_value_keys)\n            if self.ignore_errors:\n                # If we're ignoring errors, at least log it\n                logging.warn(msg)\n            else:\n                # end program\n                raise LookupError(msg)\n\n        # All the config values were checked and everything looks good, \n        # let's inform post handler for any additional work.\n        self.on_process_loaded_configs_complete(values)\n        \n        return values", "response": "Takes the loaded config values and performs the necessary cleanup steps."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nattempt to resolve any missing value that is missing from the config file.", "response": "def _process_config_values(self, dict_path, values, unresolved=[]):\n        \"\"\"Attempts to resolve any config value that is missing (e.g. None).\n\n        @param dict_path our current path as we traverse the values dict\n        @param values dictionary containing configs we want to resolve\n        @param unresolved keep track of config values that are missing\n        @returns list containing all unresolved configs\n        \"\"\"\n        if isinstance(values, dict):\n            for k, v in values.items():\n                if not k.isupper():\n                    del values[k]\n                    # Flask only supports config values that are uppercase.\n                    # see: http://flask.pocoo.org/docs/1.0/config/#configuring-from-files\n                    continue\n                dict_path.append(''.join(['_', k])) # track our dict traversal\n                # Found a missing value, try to resolve\n                if v is None:\n                    path = (''.join(dict_path))[1:]\n                    resolved_value = self.resolve_missing_value(k, values, path)\n                    if resolved_value is None:\n                        unresolved.append(path)\n                    else:\n                        values[k] = resolved_value\n                # is config has value, and it's another dict, traverse it\n                elif hasattr(v, '__iter__'):\n                    self._process_config_values(dict_path, v, unresolved)\n                # again, update where we are in dict traversal\n                dict_path.pop()\n        elif isinstance(values, list):\n            for _ in values:\n                self._process_config_values(dict_path, _, unresolved)\n        return unresolved"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _load_all_configs(self, paths, values={}):\n        if not isinstance(values, dict):\n            raise TypeError('values must be a dictionary!')\n        for p in paths:\n            # delegate load of actual config values, then merge with any existing values\n            self._merge_values(values, self._load_config(p))\n        return values", "response": "Loads configuration values for each of the files in paths merging duplicate values with existing values."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _merge_values(self, to_values, from_values):\n        if from_values is not None:\n            for k, v in from_values.items():\n                if k in to_values and isinstance(to_values[k], dict):\n                    self._merge_values(to_values[k], v) # merge\n                else:\n                    to_values[k] = v # replaces instead of merge\n        return to_values", "response": "Merges two dictionaries of values recursively."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _load_config(self, path):\n        try:\n            with open(path) as f:\n                values = yaml.safe_load(f)\n                if isinstance(values, dict):\n                    return values\n                else:\n                    raise yaml.YAMLError('Unable to parse/load {}'.format(path))\n        except(IOError, yaml.YAMLError) as e:\n            if self.ignore_errors:\n                return None\n            else:\n                raise e", "response": "Load the config file and return a dictionary of the config values."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _normalize_file_paths(self, *args):\n        paths = []\n        for arg in args:\n            if arg is None:\n                continue\n            elif self._is_valid_file(arg):\n                paths.append(arg)\n            elif isinstance(arg, list) and all(self._is_valid_file(_) for _ in arg):\n                paths = paths + arg\n            elif not self.ignore_errors:\n                raise TypeError('Config file paths must be string path or list of paths!')\n        return paths", "response": "Returns all given configuration file paths as one list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _is_valid_file(self, path):\n        return isinstance(path, basestring) and os.path.isfile(path)", "response": "Simple check to see if file path exists. Does not check for valid YAML format."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsmart display width handling when showing a list of stuff.", "response": "def columnize(items, width=None, file=sys.stdout):\n    \"\"\" Smart display width handling when showing a list of stuff. \"\"\"\n    if not items:\n        return\n    if width is None:\n        width = shutil.get_terminal_size()[0] if file is sys.stdout else 80\n    items = [rendering.vtmlrender(x) for x in items]\n    maxcol = max(items, key=len)\n    colsize = len(maxcol) + 2\n    cols = width // colsize\n    if cols < 2:\n        for x in items:\n            print(x, file=file)\n        return\n    lines = math.ceil(len(items) / cols)\n    for i in range(lines):\n        row = items[i:None:lines]\n        print(*[x.ljust(colsize) for x in row], sep='', file=file)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_args(argv=None):\n    parser = ArgumentParser()\n    parser.add_argument('--password', dest=\"password\", type=str)\n    parser.add_argument('--user', dest=\"user\", type=str)\n    parser.add_argument('--config-file', dest=\"config_file\", type=str)\n\n    options = parser.parse_args(argv)\n    return options", "response": "Parse command line options."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, pattern, method=None, call=None, name=None):\n        if not pattern.endswith('/'):\n            pattern += '/'\n        parts = tuple(pattern.split('/')[1:])\n        node = self._routes\n        for part in parts:\n            node = node.setdefault(part, {})\n        if method is None:\n            node['GET'] = call\n        elif isinstance(method, str):\n            node[method.upper()] = call\n        else:\n            for m in method:\n                node[m.upper()] = call\n\n        if name is not None:\n            self._reverse[name] = pattern", "response": "Add a url pattern to the internal dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds a callable for the specified URL path and HTTP method.", "response": "def find_call(self, path, method):\n        \"\"\"Find callable for the specified URL path and HTTP method.\n\n        Args:\n            path (:obj:`str`): URL path to match\n            method (:obj:`str`): HTTP method\n\n        Note:\n            A trailing '/' is always assumed in the path.\n        \"\"\"\n        if not path.endswith('/'):\n            path += '/'\n        path = path.split('/')[1:]\n        return self._recursive_route_match(self._routes, path, method, [])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract the complete set of data based on missingness over all the locus.", "response": "def get_variables(self, missing_in_geno=None):\n        \"\"\"Extract the complete set of data based on missingness over all\n        for the current locus.\n\n        :param missing_in_geno: mask associated with missingness in genotype\n        :return: (phenotypes, covariates, nonmissing used for this set of vars)\n        \"\"\"\n        count = 0\n        mismatch = 0\n\n        if missing_in_geno is None:\n            nonmissing = numpy.invert(self.missing[self.idx])\n        else:\n            nonmissing = numpy.invert(self.missing[self.idx] | missing_in_geno)\n        nmcount = sum(nonmissing)\n        covars = numpy.zeros((self.covar_count, nmcount))\n        for idx in range(0, self.covar_count):\n            covars[idx] = self.covariates[idx][nonmissing]\n            min = covars[idx][covars[idx] != pheno_covar.PhenoCovar.missing_encoding].min()\n            max = covars[idx][covars[idx] != pheno_covar.PhenoCovar.missing_encoding].max()\n            if min == max:\n                raise InvariantVar(\"Covar %s doesn't have enough variation to continue\" % (self.datasource.covariate_labels[idx]))\n\n        min = self.phenotypes[self.idx][nonmissing].min()\n        max = self.phenotypes[self.idx][nonmissing].max()\n        if min == max:\n            raise InvariantVar(\"Phenotype %s doesn't have enough variation to continue\" % (self.datasource.phenotype_names[self.idx]))\n        return (self.phenotypes[self.idx][nonmissing], covars, nonmissing)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstandardizes the variables within a range [-1. 0 and 1. 0 )", "response": "def standardize(self):\n        \"\"\"Standardize the variables within a range [-1.0 and 1.0]\n\n        This replaces the local copies of this data. When it's time to\n        scale back, use destandardize from the datasource for that.\n\n        \"\"\"\n        self.covariates = self.datasource.covariate_data\n        self.phenotypes = self.datasource.phenotype_data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntaking an LDAP date in the form YYYYmmdd - > YYYYMMDD - > YYYYMMDD - > YYYYMMDD - > YYYYMMDD - > YYYYMMDD - > YYYYMMDD - > YYYYMMDD - > YYYYMMDD - > YYYYMMDD YYYYDD YYYYMMDD YYYYMM", "response": "def dateFromLDAPTimestamp(timestamp):\n    \"\"\" Takes an LDAP date (In the form YYYYmmdd\n        with whatever is after that) and returns a\n        datetime.date object.\n    \"\"\"\n    # only check the first 8 characters: YYYYmmdd\n    numberOfCharacters = len(\"YYYYmmdd\")\n    timestamp = timestamp[:numberOfCharacters]\n    try:\n        day = datetime.strptime(timestamp, '%Y%m%d')\n        return date(year=day.year, month=day.month, day=day.day)\n    except:\n        print(timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of dict containing all users who have the specified uid.", "response": "def members(self, uid=\"*\", objects=False):\n        \"\"\" members() issues an ldap query for all users, and returns a dict\n            for each matching entry. This can be quite slow, and takes roughly\n            3s to complete. You may optionally restrict the scope by specifying\n            a uid, which is roughly equivalent to a search(uid='foo')\n        \"\"\"\n        entries = self.search(uid='*')\n        if objects:\n            return self.memberObjects(entries)\n        result = []\n        for entry in entries:\n            result.append(entry[1])\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef member(self, user, objects=False):\n        try:\n            member = self.search(uid=user, objects=objects)[0]\n        except IndexError:\n            return None\n        if objects:\n            return member\n        return member[1]", "response": "Returns a user as a dict of attributes\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef eboard(self, objects=False):\n        # self.committee used as base because that's where eboard\n        # info is kept\n        committees = self.search(base = self.committees, cn='*')\n        directors = []\n        for committee in committees:\n            for head in committee[1]['head']:\n                director = self.search(dn=head)[0]\n                director[1]['committee'] = committee[1]['cn'][0]\n                directors.append(director)\n        if objects:\n            return self.memberObjects(directors)\n        return directors", "response": "Returns a list of eboard members formatted as a search\n            inserts an extra ['commmittee'] attribute\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef drinkAdmins(self, objects=False):\n        admins = self.group('drink', objects=objects)\n        return admins", "response": "Returns a list of all drink admins in the current locale"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching LDAP for matching entries in LDAP.", "response": "def search( self, base=False, trim=False, objects=False, **kwargs ):\n        \"\"\" Returns matching entries for search in ldap\n            structured as [(dn, {attributes})]\n            UNLESS searching by dn, in which case the first match\n            is returned\n        \"\"\"\n        scope = pyldap.SCOPE_SUBTREE\n        if not base:\n            base = self.users\n\n        filterstr =''\n        for key, value in kwargs.iteritems():\n            filterstr += '({0}={1})'.format(key,value)\n            if key == 'dn':\n                filterstr = '(objectClass=*)'\n                base = value\n                scope = pyldap.SCOPE_BASE\n                break\n\n        if len(kwargs) > 1:\n            filterstr = '(&'+filterstr+')'\n\n        result = self.ldap.search_s(base, pyldap.SCOPE_SUBTREE, filterstr, ['*','+'])\n        if base == self.users:\n            for member in result:\n                groups = self.getGroups(member[0])\n                member[1]['groups'] = groups\n                if 'eboard' in member[1]['groups']:\n                    member[1]['committee'] = self.search(base=self.committees, \\\n                           head=member[0])[0][1]['cn'][0]\n        if objects:\n            return self.memberObjects(result)\n        finalResult = self.trimResult(result) if trim else result\n        return finalResult"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef isBirthday(self):\n        if not self.birthday:\n            return False\n        birthday = self.birthdate()\n        today = date.today()\n        return (birthday.month == today.month and\n                birthday.day == today.day)", "response": "Is the user s birthday today?"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef age(self):\n        if not self.birthdate():\n            return -1\n        adjuster = 0\n        today = date.today()\n        birthday = self.birthdate()\n        if today.month == birthday.month:\n            if today.day < birthday.day:\n                adjuster -= 1\n        elif today.month < birthday.month:\n            adjuster -= 1\n        return (today.year - birthday.year) + adjuster", "response": "Returns the age of the user based on their birthday date"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reload(self):\n        if not self.ldap:\n            return\n        self.memberDict = self.ldap.member(self.uid)", "response": "Reloads the internal dictionary of another\n            instance of this member."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fullName(self):\n        if self.givenName and self.sn:\n            return \"{0} {1}\".format(self.givenName, self.sn)\n        if self.givenName:\n            return self.givenName\n        if self.sn:\n            return self.sn\n        return self.uid", "response": "Returns a reliable full name for every available attribute."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconsume given stream and returns processing stats.", "response": "def consume(self, stream, source=None, chunksize=1):\n        \"\"\" Consuming given strem object and returns processing stats.\n\n        :param stream: streaming object to consume\n        :type stream: iterable\n        :param source: source of stream to consume\n        :type source: string\n        :param chunksize: chunk size for multiprocessing\n        :type chunksize: integer\n        :rtype: dict\n        \"\"\"\n        stats = {\n            PROCESSING_TOTAL: 0,\n            PROCESSING_SKIPPED: 0,\n            PROCESSING_SUCCESS: 0,\n            PROCESSING_ERROR: 0\n        }\n        if source:\n            stats['source'] = source\n\n        def skip_unless(r):\n            if r:\n                return r\n            stats[PROCESSING_SKIPPED] += 1\n            stats[PROCESSING_TOTAL] += 1\n\n        rs = ifilter(skip_unless, stream)\n        if self.processes:\n            pool = multiprocessing.Pool(processes=self.processes)\n            for f in self.procedures:\n                rs = pool.imap_unordered(f, ifilter(skip_unless, rs),\n                        chunksize=chunksize)\n        else:\n            for f in self.procedures:\n                rs = imap(f, ifilter(skip_unless, rs))\n        start = time.time()\n        i = 0\n        try:\n            while 1:\n                processed = next(rs)\n                if processed is None:\n                    stats[PROCESSING_SKIPPED] += 1\n                elif processed is False:\n                    stats[PROCESSING_ERROR] += 1\n                else:\n                    stats[PROCESSING_SUCCESS] += 1\n                    self.collect(processed)\n                i += 1\n                stats[PROCESSING_TOTAL] += 1\n                if i % self.reporting_interval == 0:\n                    logging.info(\" ===> Processed %dth item <=== \", i)\n        except StopIteration:\n            pass\n        except KeyboardInterrupt:\n            logging.info(\"Stopped by user interruption at %dth item.\", i)\n            raise\n        except:\n            e = sys.exc_info()[1]\n            logging.error(e)\n            raise\n        finally:\n            if self.processes:\n                pool.close()\n                pool.join()\n            stats[PROCESSING_TIME] = time.time() - start\n            logging.info(\n                'STATS: total=%d, skipped=%d, success=%d, error=%d on %f[sec]'\n                ' from \"%s\"',\n                stats[PROCESSING_TOTAL], stats[PROCESSING_SKIPPED],\n                stats[PROCESSING_SUCCESS], stats[PROCESSING_ERROR],\n                stats[PROCESSING_TIME], stats.get('source', 'unknown'))\n            return stats"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle(self, files, encoding, chunksize=1):\n        stats = []\n        if files:\n            logging.info(\"Input file count: %d\", len(files))\n            for fp in files:\n                stream = self.reader(fp, encoding)\n                parsed = self.streamer.consume(stream,\n                    source=fp.name, chunksize=chunksize)\n                stats.append(parsed)\n                if not fp.closed:\n                    fp.close()\n        else:\n            stream = sys.stdin\n            if self.delimiter:\n                stream = csvreader(stream, encoding, delimiter=self.delimiter)\n            parsed = self.streamer.consume(stream, chunksize=chunksize)\n            stats.append(parsed)\n        return stats", "response": "Handle given files with given encoding."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize the base module.", "response": "def init(parser = None):\n    \"\"\" module needs to be initialized by 'init'.\n\n    Can be called with parser to use a pre-built parser, otherwise\n    a simple default parser is created\n    \"\"\"\n\n    global p,subparsers\n    if parser is None:\n        p = argparse.ArgumentParser()\n    else:\n        p = parser\n\n    arg = p.add_argument\n\n    subparsers = p.add_subparsers()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sub(name, func,**kwarg):\n    sp = subparsers.add_parser(name, **kwarg)\n    sp.set_defaults(func=func)\n    sp.arg = sp.add_argument\n    return sp", "response": "Add a subparser to subparsers with the specified name and func."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef authenticate(self):\n        if self._auth_token is None or self._token_expiry < time.time():\n            self._perform_auth()\n\n        yield self._auth_token", "response": "Authenticates with the PA Oauth system"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _query_api(self, method, url, fields=None, extra_headers=None, req_body=None):\n        with self.auth.authenticate() as token:\n            logging.debug('PA Authentication returned token %s', token)\n            headers = {\n                'Authorization': 'Bearer %s' % (token,),\n                'Realm': self.auth_realm\n            }\n            if extra_headers is not None:\n                headers.update(extra_headers)\n\n            logging.info('[%s] %s', method, url)\n            if req_body is not None:\n                response = self.http.request(method, url, fields, headers, body=req_body)\n            else:\n                response = self.http.request(method, url, fields, headers)                \n            if response.status != 200:\n                print(response.data)\n                logging.warning('Got non-200 HTTP status from API: %d', response.status)\n                raise ApiQueryError(\"Failed to get API data\", response.status)\n            return json.loads(response.data.decode())", "response": "Abstracts http queries to the API"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_all_jobtemplates(self):\n        endpoint = self._build_url('jobTemplates', {\n            'paginationPageSize': self.PAGE_SIZE\n        })\n        data = self._query_api('GET', endpoint)\n        return data['results']", "response": "Retrieves the list of jobTemplates for the current realm."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a job template", "response": "def create_job_template(self, template):\n        \"\"\"\n        Creates a job template\n        \"\"\"\n        endpoint = self._build_url('jobTemplates')\n        data = self._query_api('POST',\n                               endpoint,\n                               None,\n                               {'Content-Type': 'application/json'},\n                               json.dumps(template))\n        return data['results']"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a job with the given template URI.", "response": "def create_job(self, job_template_uri):\n        \"\"\"\n        Creates a job\n        \"\"\"\n        endpoint = self._build_url('jobs')\n        data = self._query_api('POST',\n                               endpoint,\n                               None,\n                               {'Content-Type': 'application/json'},\n                               json.dumps({'jobTemplateUri': job_template_uri}))\n        return data['results']"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normalize_to_range(\n    values,\n    minimum = 0.0,\n    maximum = 1.0\n    ):\n\n    \"\"\"\n    This function normalizes values of a list to a specified range and returns\n    the original object if the values are not of the types integer or float.\n    \"\"\"\n\n    normalized_values = []\n    minimum_value = min(values)\n    maximum_value = max(values)\n    for value in values:\n        numerator = value - minimum_value\n        denominator = maximum_value - minimum_value\n        value_normalized = (maximum - minimum) * numerator/denominator + minimum\n        normalized_values.append(value_normalized)\n    return normalized_values", "response": "This function normalizes the values of a list to a specified range and returns the original list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_element_combinations_variadic(\n    elements_specification\n    ):\n\n    \"\"\"\n    This function accepts a specification of lists of elements for each place in\n    lists in the form of a list, the elements of which are lists of possible\n    elements and returns a list of lists corresponding to the combinations of\n    elements of the specification with varying numbers of elements.\n\n    For example, the list elements specification [[10, 20], [30, 40], [50, 60]]\n    yields the following lists:\n\n    [10]\n    [20]\n    [10, 30]\n    [10, 40]\n    [20, 30]\n    [20, 40]\n    [10, 30, 50]\n    [10, 30, 60]\n    [10, 40, 50]\n    [10, 40, 60]\n    [20, 30, 50]\n    [20, 30, 60]\n    [20, 40, 50]\n    [20, 40, 60]\n    \"\"\"\n\n    lists = [list(list_generated) for index, element_specification in enumerate(elements_specification) for list_generated in itertools.product(*elements_specification[:index + 1])]\n    return lists", "response": "This function returns a list of lists corresponding to the combinations of possible elements of the given list elements specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef steppify(x, y):\n\n    \"\"\"\n    Steppify a curve (x, y). This is useful for filling histograms manually.\n    \"\"\"\n\n    dx = 0.5 * (x[1:] + x[:-1])\n    xx = numpy.zeros(2 * len(dx), dtype=float)\n    yy = numpy.zeros(2 * len(y), dtype=float)\n    xx[0::2], xx[1::2] = dx, dx\n    yy[0::2], yy[1::2] = y, y\n    xx = numpy.concatenate((\n        [x[0] - (dx[0] - x[0])],\n        xx,\n        [x[-1] + (x[-1] - dx[-1])]\n    ))\n    return xx, yy", "response": "Steppify a curve x y."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transpose(matrix):\n\n    \"\"\"\n    transpose 2D matrix (list)\n    \"\"\"\n\n    return [[x[i] for x in matrix] for i in range(len(matrix[0]))]", "response": "transpose 2D matrix (list)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extent(self):\n\n        \"\"\"\n        return range of 2D data\n        \"\"\"\n\n        return [min(self.x), max(self.x), min(self.y), max(self.y)]", "response": "get extent of 2D data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning line oriented approximatively along the slope value", "response": "def _get_symbol_by_slope(\n        self,\n        slope,\n        default_symbol\n        ):\n\n        \"\"\"\n        return line oriented approximatively along the slope value\n        \"\"\"\n\n        if slope > math.tan(3 * math.pi / 8):\n            draw_symbol = \"|\"\n        elif math.tan(math.pi / 8) < slope < math.tan(3 * math.pi / 8):\n            draw_symbol = u\"\\u27cb\" # \"/\"\n        elif abs(slope) < math.tan(math.pi / 8):\n            draw_symbol = \"-\"\n        elif slope < math.tan(-math.pi / 8) and\\\n            slope > math.tan(-3 * math.pi / 8):\n            draw_symbol = u\"\\u27CD\" # \"\\\\\"\n        elif slope < math.tan(-3 * math.pi / 8):\n            draw_symbol = \"|\"\n        else:\n            draw_symbol = default_symbol\n        return draw_symbol"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _plot_line(\n        self,\n        start,\n        end,\n        data\n        ):\n        \"\"\"\n        plot line from start = (x0, y0) to end = (x1, y1)\n        \"\"\"\n\n        clipped_line = self.canvas._clip_line(start, end)\n\n        if clipped_line is None:\n            return False\n\n        start, end = clipped_line\n\n        x0 = self.get_coordinates(\n            start[0],\n            self.canvas.min_x,\n            self.canvas.step_x\n        )\n        y0 = self.get_coordinates(\n            start[1],\n            self.canvas.min_y,\n            self.canvas.step_y\n        )\n        x1 = self.get_coordinates(\n            end[0],\n            self.canvas.min_x,\n            self.canvas.step_x\n        )\n        y1 = self.get_coordinates(\n            end[1],\n            self.canvas.min_y,\n            self.canvas.step_y\n        )\n\n        if (x0, y0) == (x1, y1):\n            return True\n\n        #x_zero_coordinates = self.get_coordinates(\n        #    0,\n        #    self.canvas.min_x,\n        #    self.canvas.step_x\n        #)\n        y_zero_coordinates = self.get_coordinates(\n            0,\n            self.canvas.min_y,\n            self.canvas.step_y,\n            limits = [1, self.canvas.y_size]\n        )\n\n        if start[0] - end[0] == 0:\n            draw_symbol = u\"|\"\n        elif start[1] - end[1] == 0:\n            draw_symbol = \"-\"\n        else:\n            slope =\\\n                (1.0 / self.canvas.ratio) * (end[1] - start[1])\\\n                / (end[0] - start[0])\n            draw_symbol = self._get_symbol_by_slope(slope, data.marker)\n\n        dx = x1 - x0\n        dy = y1 - y0\n        if abs(dx) > abs(dy):\n            s = sign(dx)\n            slope = float(dy) / dx\n            for i in range(0, abs(int(dx))):\n                current_draw_symbol = draw_symbol\n                x = i * s\n                current_y = int(y0 + slope * x)\n                if\\\n                    (self.draw_axes) and\\\n                    (current_y == y_zero_coordinates) and\\\n                    (draw_symbol == self.x_axis_symbol):\n                    current_draw_symbol = \"-\"\n                self.out_buffer[x0 + x][current_y] = current_draw_symbol\n        else:\n            s = sign(dy)\n            slope = float(dx) / dy\n            for i in range(0, abs(int(dy))):\n                y = i * s\n                current_draw_symbol = draw_symbol\n                current_y = y0 + y\n                if\\\n                    (self.draw_axes) and\\\n                    (current_y == y_zero_coordinates) and\\\n                    (draw_symbol == self.x_axis_symbol):\n                    current_draw_symbol = \"-\"\n                self.out_buffer[\n                    int(x0 + slope * y)\n                ][\n                    current_y\n                ] = current_draw_symbol\n\n        return False", "response": "This function plots a line of the logarithmic area."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the limits of the current axes", "response": "def limit_x(\n        self,\n        limit_lower = None, # float\n        limit_upper = None  # float\n        ):\n\n        \"\"\"\n        get or set x limits of the current axes\n\n        x_min, x_max = limit_x() # return the current limit_x\n        limit_x(x_min, x_max)    # set the limit_x to x_min, x_max\n        \"\"\"\n\n        if limit_lower is None and limit_upper is None:\n            return self._limit_x\n        elif hasattr(limit_lower, \"__iter__\"):\n            self._limit_x = limit_lower[:2]\n        else:\n            self._limit_x = [limit_lower, limit_upper]\n        if self._limit_x[0] == self._limit_x[1]:\n            self._limit_x[1] += 1\n        self._limit_x[0] -= self.mod_x\n        self._limit_x[1] += self.mod_x"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef limit_y(\n        self,\n        limit_lower = None,\n        limit_upper = None\n        ):\n\n        \"\"\"\n        get or set y limits of the current axes\n\n        y_min, y_max = limit_x() # return the current limit_y\n        limit_y(y_min, y_max)    # set the limit_y to y_min, y_max\n        \"\"\"\n\n        if limit_lower is None and limit_upper is None:\n            return self._limit_y\n        elif hasattr(limit_lower, \"__iter__\"):\n            self._limit_y = limit_lower[:2]\n        else:\n            self._limit_y = [limit_lower, limit_upper]\n        if self._limit_y[0] == self._limit_y[1]:\n            self._limit_y[1] += 1\n        self._limit_y[0] -= self.mod_y\n        self._limit_y[1] += self.mod_y", "response": "set the y limits of the current axes"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if coordinates x y are inside the data box.", "response": "def coordinates_inside_data(\n        self,\n        x,\n        y\n        ):\n\n        \"\"\"\n        return Boolean to check if co\u00f6rdinate (x, y) is in the data box\n        \"\"\"\n\n        return (self.min_x <= x < self.max_x) and (self.min_y <= y < self.max_y)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _clip_line(\n        self,\n        line_pt_1,\n        line_pt_2\n        ):\n\n        \"\"\"\n        clip line to canvas\n        \"\"\"\n\n        x_min = min(line_pt_1[0], line_pt_2[0])\n        x_max = max(line_pt_1[0], line_pt_2[0])\n        y_min = min(line_pt_1[1], line_pt_2[1])\n        y_max = max(line_pt_1[1], line_pt_2[1])\n\n        extent = self.extent()\n\n        if line_pt_1[0] == line_pt_2[0]:\n            return (\n                (line_pt_1[0], max(y_min, extent[1])),\n                (line_pt_1[0], min(y_max, extent[3]))\n            )\n\n        if line_pt_1[1] == line_pt_2[1]:\n            return (\n                (max(x_min, extent[0]), line_pt_1[1]),\n                (min(x_max, extent[2]), line_pt_1[1])\n            )\n\n        if ((extent[0] <= line_pt_1[0] < extent[2]) and\n            (extent[1] <= line_pt_1[1] < extent[3]) and\n            (extent[0] <= line_pt_2[0] < extent[2]) and\n            (extent[1] <= line_pt_2[1] < extent[3])):\n            return line_pt_1, line_pt_2\n\n        ts = [0.0,\n              1.0,\n              float(extent[0] - line_pt_1[0]) / (line_pt_2[0] - line_pt_1[0]),\n              float(extent[2] - line_pt_1[0]) / (line_pt_2[0] - line_pt_1[0]),\n              float(extent[1] - line_pt_1[1]) / (line_pt_2[1] - line_pt_1[1]),\n              float(extent[3] - line_pt_1[1]) / (line_pt_2[1] - line_pt_1[1])\n              ]\n        ts.sort()\n\n        if (ts[2] < 0) or (ts[2] >= 1) or (ts[3] < 0) or (ts[2] >= 1):\n            return None\n\n        result =\\\n            [(pt_1 + t * (pt_2 - pt_1))\\\n                for t in (ts[2], ts[3])\\\n                    for (pt_1, pt_2) in zip(line_pt_1, line_pt_2)]\n\n        return (result[:2], result[2:])", "response": "clip line to canvas"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the value of a percent of a number CTYPE", "response": "def percent_of(percent, whole):\n    \"\"\"Calculates the value of a percent of a number\n    ie: 5% of 20 is what --> 1\n    \n    Args:\n        percent (float): The percent of a number\n        whole (float): The whole of the number\n        \n    Returns:\n        float: The value of a percent\n        \n    Example:\n    >>> percent_of(25, 100)\n    25.0\n    >>> percent_of(5, 20)\n    1.0\n    \n    \"\"\"\n    percent = float(percent)\n    whole = float(whole)\n    return (percent * whole) / 100"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef percentage(part, whole, resolution=2):\n    if whole == 0:\n        raise ZeroDivisionError\n\n    percent = 100 * float(part)/float(whole)\n    \n    return round(percent, resolution) if resolution >=1 else int(percent)", "response": "Calculates the percentage of a number given a part and a whole."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_dyndns_records(login, password):\n    params = dict(action='getdyndns', sha=get_auth_key(login, password))\n    response = requests.get('http://freedns.afraid.org/api/', params=params, timeout=timeout)\n    raw_records = (line.split('|') for line in response.content.split())\n\n    try:\n        records = frozenset(DnsRecord(*record) for record in raw_records)\n    except TypeError:\n        raise ApiError(\"Couldn't parse the server's response\",\n                response.content)\n\n    return records", "response": "Gets the set of dynamic DNS records associated with this account"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates records every update_interval seconds", "response": "def update_continuously(records, update_interval=600):\n    \"\"\"Update `records` every `update_interval` seconds\"\"\"\n    while True:\n        for record in records:\n            try:\n                record.update()\n            except (ApiError, RequestException):\n                pass\n        time.sleep(update_interval)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses command - line arguments", "response": "def parse_args(args=None):\n    \"\"\"Parse command-line arguments\"\"\"\n    parser = argparse.ArgumentParser(description='afraid.org dyndns client')\n\n    ## positional arguments\n\n    parser.add_argument('user')\n    parser.add_argument('password')\n    parser.add_argument('hosts',\n            nargs='*',\n            help='(deafult: all associated hosts)',\n            default=None\n    )\n\n    ## optional arguments\n\n    # should we fork?\n    parser.add_argument('--daemonize', '-d',\n        action='store_true',\n        default=False,\n        help='run in background (default: no)',\n    )\n\n    # log to a file or stdout\n    parser.add_argument('--log',\n        help='log to file (default: log to stdout)',\n        type=argparse.FileType('w'),\n        default=sys.stdout,\n        metavar='file'\n    )\n\n    # how long to sleep between updates\n    parser.add_argument('--interval',\n        help='update interval, in seconds (default: 21600)',\n        metavar='seconds',\n        default=6 * 60 * 60, # 6 hours\n        type=int\n    )\n\n    return parser.parse_args(args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the remote DNS record by requesting its special endpoint URL", "response": "def update(self):\n        \"\"\"Updates remote DNS record by requesting its special endpoint URL\"\"\"\n        response = requests.get(self.update_url, timeout=timeout)\n        match = ip_pattern.search(response.content)\n\n        # response must contain an ip address, or else we can't parse it\n        if not match:\n            raise ApiError(\"Couldn't parse the server's response\",\n                    response.content)\n\n        self.ip = match.group(0)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply a geo=$circle/$center filter. Radius is in meters.", "response": "def within(self, lat, lon, radius):\n\t\t'''\n\t\tApply a geo=$circle/$center filter. Radius is in meters. Subsequent within() \n\t\tcalls replace earlier geo filters on this query.\n\t\t'''\n\t\tself._geo = { \"$circle\": { \n\t\t\t\t\t\t\"$center\": [\n\t\t\t\t\t\t\tfactual.common.shared_filter_helpers.GeoScalar(lat), \n\t\t\t\t\t\t\tfactual.common.shared_filter_helpers.GeoScalar(lon), \n\t\t\t\t\t\t\t], \n\t\t\t\t\t\t\"$meters\": radius \n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\treturn self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npushing account to intercom account cache", "response": "def push_account_task(obj_id):\n    \"\"\"\n    Async: push_account_task.delay(Account.id)\n    \"\"\"\n    lock_id = \"%s-push-account-%s\" % (settings.ENV_PREFIX, obj_id)\n    acquire_lock = lambda: cache.add(lock_id, \"true\", LOCK_EXPIRE)  # noqa: E731\n    release_lock = lambda: cache.delete(lock_id)  # noqa: E731\n    if acquire_lock():\n        UserModel = get_user_model()\n        try:\n            upload_intercom_user(obj_id)\n        except UserModel.DoesNotExist:\n            #  seems like account was removed before it was pushed\n            release_lock()\n\n        release_lock()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npush Intercom event to intercom.", "response": "def push_intercom_event_task(obj_id):\n    \"\"\"\n    Async: push_intercom_event_task.delay(event.id)\n    \"\"\"\n    lock_id = \"%s-push-intercom_event-%s\" % (settings.ENV_PREFIX, obj_id)\n    acquire_lock = lambda: cache.add(lock_id, \"true\", LOCK_EXPIRE)  # noqa: E731\n    release_lock = lambda: cache.delete(lock_id)  # noqa: E731\n\n    if acquire_lock():\n        from aa_intercom.models import IntercomEvent\n        try:\n            instance = IntercomEvent.objects.get(pk=obj_id)\n            if instance.is_sent:\n                return\n\n            data = instance.get_intercom_data()\n            try:\n                if instance.user:\n                    upload_intercom_user(instance.user.pk)\n                else:\n                    upload_not_registered_user_data({\"email\": data[\"metadata\"][\"email\"]})\n                if not getattr(settings, \"SKIP_INTERCOM\", False):\n                    intercom.events.create(**data)\n                    IntercomEvent.objects.filter(pk=obj_id).update(\n                        is_sent=True\n                    )\n            except IntercomError:\n                IntercomEvent.objects.filter(pk=obj_id).update(\n                    is_sent=False\n                )\n                release_lock()\n                raise  # FIXME - to check when errror happens\n\n        except IntercomEvent.DoesNotExist:\n            release_lock()\n            raise\n        release_lock()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef push_not_registered_user_data_task(data):\n    lock_id = \"%s-push-not-registered-user-data-task-%s\" % (settings.ENV_PREFIX, data[\"email\"])\n    acquire_lock = lambda: cache.add(lock_id, \"true\", LOCK_EXPIRE)  # noqa: E731\n    release_lock = lambda: cache.delete(lock_id)  # noqa: E731\n\n    if acquire_lock():\n        try:\n            upload_not_registered_user_data(data)\n        except (KeyError, NotImplementedError, MultipleMatchingUsersError):\n            release_lock()\n            raise\n        release_lock()", "response": "A task that uploads the not registered user data to the master."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, slug):\n        kb = api.get_kb_by_slug(slug)\n\n        # check if is accessible from api\n        check_knowledge_access(kb)\n\n        parser = reqparse.RequestParser()\n        parser.add_argument(\n            'from', type=str,\n            help=\"Return only entries where key matches this.\")\n        parser.add_argument(\n            'to', type=str,\n            help=\"Return only entries where value matches this.\")\n        parser.add_argument('page', type=int,\n                            help=\"Require a specific page\")\n        parser.add_argument('per_page', type=int,\n                            help=\"Set how much result per page\")\n        parser.add_argument('match_type', type=str,\n                            help=\"s=substring, e=exact, sw=startswith\")\n        parser.add_argument('sortby', type=str,\n                            help=\"the sorting criteria ('from' or 'to')\")\n        args = parser.parse_args()\n        kb_dict = kb.to_dict()\n        kb_dict['mappings'] = KnwKBMappingsResource \\\n            .search_mappings(kb=kb, key=args['from'], value=args['to'],\n                             match_type=args['match_type'],\n                             sortby=args['sortby'], page=args['page'],\n                             per_page=args['per_page'])\n        return kb_dict", "response": "Get a specific entry from KnwKB by its slug."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search_mappings(kb, key=None, value=None, match_type=None,\n                        sortby=None, page=None, per_page=None):\n        \"\"\"Search tags for knowledge.\"\"\"\n        if kb.kbtype == models.KnwKB.KNWKB_TYPES['written_as']:\n            return pagination.RestfulSQLAlchemyPagination(\n                api.query_kb_mappings(\n                    kbid=kb.id,\n                    key=key or '',\n                    value=value or '',\n                    match_type=match_type or 's',\n                    sortby=sortby or 'to',\n                ), page=page or 1, per_page=per_page or 10\n            ).items\n        return []", "response": "Search tags for knowledge."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, slug):\n        kb = api.get_kb_by_slug(slug)\n\n        # check if is accessible from api\n        check_knowledge_access(kb)\n\n        parser = reqparse.RequestParser()\n        parser.add_argument(\n            'from', type=str,\n            help=\"Return only entries where 'from' matches this.\")\n        parser.add_argument(\n            'to', type=str,\n            help=\"Return only entries where 'to' matches this.\")\n        parser.add_argument('page', type=int,\n                            help=\"Require a specific page\")\n        parser.add_argument('per_page', type=int,\n                            help=\"Set how much result per page\")\n        parser.add_argument('match_type', type=str,\n                            help=\"s=substring, e=exact, sw=startswith\")\n        parser.add_argument('sortby', type=str,\n                            help=\"the sorting criteria ('from' or 'to')\")\n        args = parser.parse_args()\n        return KnwKBMappingsResource \\\n            .search_mappings(kb, args['from'], args['to'],\n                             args['match_type'], args['sortby'],\n                             args['page'], args['per_page'])", "response": "Get list of mappings for a given slug."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch mappings to for knowledge.", "response": "def search_list(kb, value=None, match_type=None,\n                    page=None, per_page=None, unique=False):\n        \"\"\"Search \"mappings to\" for knowledge.\"\"\"\n        # init\n        page = page or 1\n        per_page = per_page or 10\n\n        if kb.kbtype == models.KnwKB.KNWKB_TYPES['written_as']:\n            # get the base query\n            query = api.query_kb_mappings(\n                kbid=kb.id,\n                value=value or '',\n                match_type=match_type or 's'\n            ).with_entities(models.KnwKBRVAL.m_value)\n            # if you want a 'unique' list\n            if unique:\n                query = query.distinct()\n            # run query and paginate\n            return [item.m_value for item in\n                    pagination.RestfulSQLAlchemyPagination(\n                        query, page=page or 1,\n                        per_page=per_page or 10\n                    ).items]\n        elif kb.kbtype == models.KnwKB.KNWKB_TYPES['dynamic']:\n            items = api.get_kbd_values(kb.name, value)\n            return pagination.RestfulPagination(\n                page=page, per_page=per_page,\n                total_count=len(items)\n            ).slice(items)\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsearch for mapping from for knowledge.", "response": "def search_list(kb, from_=None, match_type=None,\n                    page=None, per_page=None, unique=False):\n        \"\"\"Search \"mapping from\" for knowledge.\"\"\"\n        # init\n        page = page or 1\n        per_page = per_page or 10\n\n        if kb.kbtype == models.KnwKB.KNWKB_TYPES['written_as']:\n            # get the base query\n            query = api.query_kb_mappings(\n                kbid=kb.id,\n                key=from_ or '',\n                match_type=match_type or 's'\n            ).with_entities(models.KnwKBRVAL.m_key)\n            # if you want a 'unique' list\n            if unique:\n                query = query.distinct()\n            # run query and paginate\n            return [item.m_key for item in\n                    pagination.RestfulSQLAlchemyPagination(\n                        query, page=page or 1,\n                        per_page=per_page or 10\n                    ).items]\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, slug):\n        kb = api.get_kb_by_slug(slug)\n\n        # check if is accessible from api\n        check_knowledge_access(kb)\n\n        parser = reqparse.RequestParser()\n        parser.add_argument(\n            'unique', type=bool,\n            help=\"The list contains unique names of 'mapping to'\")\n        parser.add_argument(\n            'filter', type=str,\n            help=\"Return only entries where 'from' matches this.\")\n        parser.add_argument('page', type=int,\n                            help=\"Require a specific page\")\n        parser.add_argument('per_page', type=int,\n                            help=\"Set how much result per page\")\n        parser.add_argument('match_type', type=str,\n                            help=\"s=substring, e=exact, sw=startswith\")\n        args = parser.parse_args()\n        return KnwKBMappingsFromResource \\\n            .search_list(kb, args['filter'],\n                         args['match_type'],\n                         args['page'], args['per_page'], args['unique'])", "response": "Get a list of mappings from a specific entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nimporting a mep as a representative from the json dict fetched from parltrack", "response": "def manage_mep(self, mep_json):\n        '''\n        Import a mep as a representative from the json dict fetched from\n        parltrack\n        '''\n\n        # Some versions of memopol will connect to this and skip inactive meps.\n        responses = representative_pre_import.send(sender=self,\n                representative_data=mep_json)\n\n        for receiver, response in responses:\n            if response is False:\n                logger.debug(\n                    'Skipping MEP %s', mep_json['Name']['full'])\n                return\n\n        changed = False\n        slug = slugify('%s-%s' % (\n            mep_json[\"Name\"][\"full\"] if 'full' in mep_json[\"Name\"]\n            else mep_json[\"Name\"][\"sur\"] + \" \" + mep_json[\"Name\"][\"family\"],\n            _parse_date(mep_json[\"Birth\"][\"date\"])\n        ))\n        try:\n            representative = Representative.objects.get(slug=slug)\n        except Representative.DoesNotExist:\n            representative = Representative(slug=slug)\n            changed = True\n\n        # Save representative attributes\n        self.import_representative_details(representative, mep_json, changed)\n\n        self.add_mandates(representative, mep_json)\n\n        self.add_contacts(representative, mep_json)\n\n        logger.debug('Imported MEP %s', unicode(representative))\n\n        return representative"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _path_to_id(path):\n    if path.endswith(\"/\"):\n        path = path[:-1]\n\n    return os.path.basename(path)", "response": "Returns the basename of the root directory of the info. xml file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating size of all files in path.", "response": "def _calc_dir_size(path):\n    \"\"\"\n    Calculate size of all files in `path`.\n\n    Args:\n        path (str): Path to the directory.\n\n    Returns:\n        int: Size of the directory in bytes.\n    \"\"\"\n    dir_size = 0\n    for (root, dirs, files) in os.walk(path):\n        for fn in files:\n            full_fn = os.path.join(root, fn)\n            dir_size += os.path.getsize(full_fn)\n\n    return dir_size"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the absolute path relative to root_dir.", "response": "def _get_localized_fn(path, root_dir):\n    \"\"\"\n    Return absolute `path` relative to `root_dir`.\n\n    When `path` == ``/home/xex/somefile.txt`` and `root_dir` == ``/home``,\n    returned path will be ``/xex/somefile.txt``.\n\n    Args:\n        path (str): Absolute path beginning in `root_dir`.\n        root_dir (str): Absolute path containing `path` argument.\n\n    Returns:\n        str: Local `path` when `root_dir` is considered as root of FS.\n    \"\"\"\n    local_fn = path\n    if path.startswith(root_dir):\n        local_fn = path.replace(root_dir, \"\", 1)\n\n    if not local_fn.startswith(\"/\"):\n        return \"/\" + local_fn\n\n    return local_fn"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compose_info(root_dir, files, hash_fn, aleph_record, urn_nbn=None):\n    # compute hash for hashfile\n    with open(hash_fn) as f:\n        hash_file_md5 = hashlib.md5(f.read()).hexdigest()\n\n    schema_location = \"http://www.ndk.cz/standardy-digitalizace/info11.xsd\"\n    document = odict[\n        \"info\": odict[\n            \"@xmlns:xsi\": \"http://www.w3.org/2001/XMLSchema-instance\",\n            \"@xsi:noNamespaceSchemaLocation\": schema_location,\n\n            \"created\": time.strftime(\"%Y-%m-%dT%H:%M:%S\", time.gmtime()),\n            \"metadataversion\": \"1.0\",\n            \"packageid\": _path_to_id(root_dir),\n\n            # not used in SIP\n            # \"mainmets\": _get_localized_fn(metadata_fn, root_dir),\n\n            \"titleid\": None,\n            \"collection\": \"edeposit\",\n            \"institution\": None,\n            \"creator\": None,\n            \"size\": _calc_dir_size(root_dir) / 1024,  # size in kiB\n            \"itemlist\": odict[\n                \"@itemtotal\": \"2\",\n                \"item\": map(\n                    lambda x: _get_localized_fn(x, root_dir),\n                    files\n                )\n            ],\n            \"checksum\": odict[\n                \"@type\": \"MD5\",\n                \"@checksum\": hash_file_md5,\n                \"#text\": _get_localized_fn(hash_fn, root_dir)\n            ],\n        ]\n    ]\n\n    # get informations from MARC record\n    record = MARCXMLRecord(aleph_record)\n\n    # get publisher info\n    publisher = unicode(record.get_publisher(), \"utf-8\")\n    if record.get_publisher(None):\n        document[\"info\"][\"institution\"] = remove_hairs(publisher)\n\n    # get <creator> info\n    creator = record.getDataRecords(\"910\", \"a\", False)\n    alt_creator = record.getDataRecords(\"040\", \"d\", False)\n    document[\"info\"][\"creator\"] = creator[0] if creator else alt_creator[-1]\n\n    # collect informations for <titleid> tags\n    isbns = record.get_ISBNs()\n\n    ccnb = record.getDataRecords(\"015\", \"a\", False)\n    ccnb = ccnb[0] if ccnb else None\n\n    if any([isbns, ccnb, urn_nbn]):  # TODO: issn\n        document[\"info\"][\"titleid\"] = []\n\n    for isbn in isbns:\n        document[\"info\"][\"titleid\"].append({\n            \"@type\": \"isbn\",\n            \"#text\": isbn\n        })\n\n    if ccnb:\n        document[\"info\"][\"titleid\"].append({\n            \"@type\": \"ccnb\",\n            \"#text\": ccnb\n        })\n\n    if urn_nbn:\n        document[\"info\"][\"titleid\"].append({\n            \"@type\": \"urnnbn\",\n            \"#text\": urn_nbn\n        })\n\n    # TODO: later\n    # if issn:\n    #     document[\"info\"][\"titleid\"].append({\n    #         \"@type\": \"issn\",\n    #         \"#text\": issn\n    #     })\n\n    # remove unset options\n    unset_keys = [\n        key\n        for key in document[\"info\"]\n        if key is None\n    ]\n    for key in unset_keys:\n        del document[key]\n\n    xml_document = xmltodict.unparse(document, pretty=True)\n    return xml_document.encode(\"utf-8\")", "response": "Generates an info XML file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating and configure Flask Application", "response": "def create_app(configobj=ProdConfig):\n    \"\"\" Create and configure Flask Application \"\"\"\n\n    app = Flask(__name__)\n    app.config.from_object(configobj)\n    configure_blueprints(app)\n    configure_extensions(app)\n    configure_callbacks(app)\n    configure_filters(app)\n    configure_error_handlers(app)\n    return app"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef configure_filters(app):\n\n    for (name, filter) in _filters.iteritems():\n        app.jinja_env.filters[name] = filter", "response": "Configure application filters (jinja2)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef configure_error_handlers(app):\n\n    def render_error(error):\n        return (render_template('errors/%s.html' % error.code,\n                title=error_messages[error.code], code=error.code), error.code)\n\n    for (errcode, title) in error_messages.iteritems():\n        app.errorhandler(errcode)(render_error)", "response": "Configure error handlers for the application."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _elapsed_time(begin_time, end_time):\n\n    bt = _str2datetime(begin_time)\n    et = _str2datetime(end_time)\n\n    return float((et - bt).seconds)", "response": "Returns the elapsed time in seconds between begin_time and end_time"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlogging a special message at the indent level.", "response": "def _special(self, message: str, with_gap: bool=True):\n        \"\"\" Logs a special (colored) message at the indent level. \"\"\"\n        if with_gap:\n            self._line_break()\n        self._log(self._set_color(message, self.GREEN))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlog a special message at the indent level.", "response": "def _header(self, message: str, with_gap=True):\n        \"\"\" Logs a special (colored) message at the indent level. \"\"\"\n        if with_gap:\n            self._line_break()\n        self._log(self._set_color(message, self.YELLOW))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _strip_colors(self, message: str) -> str:\n        for c in self.COLORS:\n            message = message.replace(c, \"\")\n        return message", "response": "Remove all of the color tags from the message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_str(window, line_num, str):\n    try:\n        window.addstr(line_num, 0, str)\n    except curses.error:\n        pass", "response": "add str to the current line"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites a file to descriptor returns True if the file was successfully written False otherwise", "response": "def write_file_to_descriptor(input_queue, descriptor):\n    \"\"\"\n    get item from input_queue and write it to descriptor\n    returns True if and only if it was successfully written\n    \"\"\"\n    try:\n        file_name = input_queue.get(timeout=2)\n        descriptor.write(\"{}\\n\".format(file_name))\n        descriptor.flush()\n        input_queue.task_done()\n        return True\n    except Empty:\n        # no more files in queue\n        descriptor.close()\n        return False\n    except IOError:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding a generator which smooths all elements as if the given list was of depth 1.", "response": "def smooth(l):\n    \"\"\"Yields a generator which smooths all elements as if the given list\n    was of depth 1.\n\n    **Examples**:\n    ::\n        list(auxly.listy.smooth([1,[2,[3,[4]]]]))\n        # [1, 2, 3, 4]\n    \"\"\"\n    if type(l) in [list, tuple]:\n        for i in l:\n            for j in smooth(i):\n                yield j\n    else:\n        yield l"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main():\n    parser = argparse.ArgumentParser(description='A site preprocessor based \\\n        on Jinja2, a templating engine for Python')\n    subparsers = parser.add_subparsers(description='The following options \\\n        are available:')\n\n    # 'create' command\n    parser_create = subparsers.add_parser('create', help='Create a new \\\n        project')\n    parser_create.add_argument('--path', help='The path where the project \\\n        will be created')\n    parser_create.set_defaults(target=create)\n\n    args = parser.parse_args()\n\n    arg_values = {key : value for key, value in vars(args).items() \\\n    if key != 'target'}\n\n    args.target(**arg_values)", "response": "A command line interface for the\n    command line interface."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the path as an S3 schema", "response": "def s3path(self, rel_path):\n        \"\"\"Return the path as an S3 schema\"\"\"\n        import urlparse\n\n        path = self.path(rel_path, public_url=True)\n\n        parts = list(urlparse.urlparse(path))\n\n        parts[0] = 's3'\n        parts[1] = self.bucket_name\n\n        return urlparse.urlunparse(parts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_stream(self, rel_path, cb=None, return_meta=False):\n        from boto.s3.key import Key\n        from boto.exception import S3ResponseError\n\n        import StringIO\n        from . import MetadataFlo\n\n        b = StringIO.StringIO()\n        try:\n            k = self._get_boto_key(rel_path)\n            if not k:\n                return None\n\n            k.get_contents_to_file(b, cb=cb, num_cb=100)\n\n            b.seek(0)\n\n            if return_meta:\n                d = k.metadata\n                d['size'] = k.size\n                d['etag'] = k.etag\n            else:\n                d = {}\n\n            return MetadataFlo(b, d)\n\n        except S3ResponseError as e:\n            if e.status == 404:\n                return None\n            else:\n                raise e", "response": "Return the object as a stream"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncopies a file to the repository", "response": "def put_key(self, source, rel_path):\n        '''Copy a file to the repository\n\n        Args:\n            source: Absolute path to the source file, or a file-like object\n            rel_path: path relative to the root of the repository\n\n        '''\n        k = self._get_boto_key(rel_path)\n\n        try:\n            k.set_contents_from_file(source)\n        except AttributeError:\n            if os.path.getsize(source) > 4.8 * 1024 * 1024 * 1024:\n                # Need to do multi-part uploads here\n                k.set_contents_from_filename(source)\n            else:\n                k.set_contents_from_filename(source)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef put_stream(self, rel_path, metadata=None, cb=None):\n        '''Return a Flo object that can be written to to send data to S3.\n        This will result in a multi-part upload, possibly with each part\n        being sent in its own thread '''\n\n        import Queue\n        import time\n        import threading\n\n        md5 = metadata.get('md5', None) if metadata else None\n\n        # Horrible, but doing it anyway because I can.\n        acl = ('public-read' if metadata.get('public',\n                                             False) else metadata.get('acl',\n                                                                      'public-read')) if metadata else 'public-read'\n\n        path = self._prefix(self._rename(rel_path))\n\n        class ThreadUploader(threading.Thread):\n\n            \"\"\"Thread class for uploading a part to S3\"\"\"\n\n            def __init__(self, n, queue):\n                threading.Thread.__init__(self)\n                self.n = n\n                self.queue = queue\n\n            def run(self):\n\n                while True:\n                    mp, part_number, buf = self.queue.get()\n                    if mp is None:  # Signal to die\n                        logger.debug(\n                            \"put_stream: Thread {} exiting\".format(\n                                self.n))\n                        self.queue.task_done()\n                        return\n                    logger.debug(\n                        \"put_stream: Thread {}: processing part: {}\".format(\n                            self.n,\n                            part_number))\n                    t1 = time.time()\n                    try:\n                        mp.upload_part_from_file(buf, part_number)\n                    finally:\n                        self.queue.task_done()\n                        t2 = time.time()\n                        logger.debug(\"put_stream: Thread {}, part {}. time = {} rate =  {} b/s\" .format(\n                            self.n, part_number, round(t2 - t1, 3), round((float(buf.tell()) / (t2 - t1)), 2)))\n\n        if metadata is None:\n            metadata = {}\n\n        if md5:\n            metadata['md5'] = md5  # Multipart uploads don't use md5 for etag\n\n        # Some libraries, including apparently, boto, have troubles properly calcing the hash when\n        # metadata values are null, empty, 0, etc.\n        # https://forums.aws.amazon.com/thread.jspa?threadID=117580\n        for k, v in metadata.items():\n            if not v:\n                del metadata[k]\n\n        this = self\n\n        buffer_size = 50 * 1024 * 1024  # Min part size is 5MB\n        num_threads = 4\n        thread_upload_queue = Queue.Queue(maxsize=100)\n\n        for i in range(num_threads):\n            t = ThreadUploader(i, thread_upload_queue)\n            t.setDaemon(True)\n            t.start()\n\n        class flo:\n\n            '''Object that is returned to the caller, for the caller to issue\n            write() or writeline() calls on '''\n\n            def __init__(self, rel_path):\n                import io\n\n                self.mp = this.bucket.initiate_multipart_upload(\n                    path,\n                    metadata=metadata)\n                self.part_number = 1\n                self.buffer = io.BytesIO()\n                self.total_size = 0\n\n                self.rel_path = rel_path\n\n            def _send_buffer(self):\n                '''Schedules a buffer to be sent in a thread by queuing it'''\n                logger.debug(\n                    \"_send_buffer: sending part {} to thread pool size: {}, total_size = {}\" .format(\n                        self.part_number,\n                        self.buffer.tell(),\n                        self.total_size))\n                self.buffer.seek(0)\n                thread_upload_queue.put(\n                    (self.mp, self.part_number, self.buffer))\n\n            def write(self, d):\n                import io\n\n                self.buffer.write(d)  # Load the requested data into a buffer\n                self.total_size += len(d)\n                # After the buffer is large enough, send it, then create a new\n                # buffer.\n                if self.buffer.tell() > buffer_size:\n                    self._send_buffer()\n\n                    self.part_number += 1\n                    self.buffer = io.BytesIO()\n\n            def writelines(self, lines):\n                raise NotImplemented()\n\n            def close(self):\n\n                if self.buffer.tell() > 0:\n                    self._send_buffer()\n\n                # Wait for all of th upload to complete\n                thread_upload_queue.join()\n\n                for i in range(num_threads):\n                    thread_upload_queue.put(\n                        (None, None, None))  # Tell all of the threads to die\n\n                # Wait for all of the threads to exit\n                thread_upload_queue.join()\n\n                # Multi-part uploads throw a 400 Bad Request if they are\n                # completed without writing any data.\n                if self.total_size > 0:\n                    self.mp.complete_upload()\n\n                    this.bucket.set_acl(acl, path)\n\n                this.put_metadata(self.rel_path, metadata)\n\n            def __enter__(self):\n                return self\n\n            def __exit__(self, type_, value, traceback):\n                if type_:\n                    return False\n\n                self.close()\n\n        return flo(rel_path)", "response": "Return a Flo object that can be written to send data to S3."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove(self, rel_path, propagate=False):\n        '''Delete the file from the cache, and from the upstream'''\n\n        key = self._get_boto_key(rel_path)\n        if key:\n            key.delete()", "response": "Delete the file from the cache and from the upstream"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list(self, path=None, with_metadata=False, include_partitions=False):\n        '''Get a list of all of bundle files in the cache. Does not return partition files'''\n        import json\n\n        sub_path = self.prefix + '/' + path.strip('/') if path else self.prefix\n\n        l = {}\n\n        for e in self.bucket.list(sub_path):\n\n            path = e.name.replace(self.prefix, '', 1).strip('/')\n            if path.startswith('_') or path.startswith('meta'):\n                continue\n\n            # TODO 'include_partitions' doesn't make any sense outside of ambry\n            if not include_partitions and path.count('/') > 1:\n                continue  # partition files\n\n            if with_metadata:\n                d = self.metadata(path)\n                if d and 'identity' in d:\n                    d['identity'] = json.loads(d['identity'])\n            else:\n                d = {}\n\n            d['caches'] = [self.repo_id]\n\n            if path:\n                l[path] = d\n\n        return l", "response": "Get a list of all of bundle files in the cache. Does not return partition files"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _send_streamify(self, frame):\n\n        # Get the state and framer\n        state = self._send_framer_state\n        framer = self._send_framer\n\n        # Reset the state as needed\n        state._reset(framer)\n\n        # Now pass the frame through streamify() and return the result\n        return framer.streamify(state, frame)", "response": "Helper method to streamify a frame."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _recv_frameify(self, data):\n\n        # Get the state and framer\n        state = self._recv_framer_state\n        framer = None\n\n        # Grab off as many frames as we can\n        frameify = None\n        while True:\n            # Check if we need to change framers\n            if framer != self._recv_framer:\n                # Notify the currently-running framer\n                if frameify:\n                    try:\n                        frameify.throw(framers.FrameSwitch)\n                    except StopIteration:\n                        pass\n\n                # Set up the new framer\n                framer = self._recv_framer\n                state._reset(framer)\n                frameify = framer.frameify(state, data)\n                data = ''  # Now part of the state's buffer\n\n            # Get the next frame\n            try:\n                frame = frameify.next()\n            except StopIteration:\n                # OK, we've extracted as many frames as we can\n                break\n\n            # OK, send the frame to the application\n            if self._application:\n                self._application.recv_frame(frame)", "response": "Internal method to frameify a data stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef closed(self, error=None):\n\n        if self._application:\n            try:\n                self._application.closed(error)\n            except Exception:\n                # Ignore exceptions from the notification\n                pass", "response": "Notify the application that the connection has been closed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the framer used for sending the message.", "response": "def send_framer(self, value):\n        \"\"\"\n        Set the framer in use for the sending side of the connection.\n        The framer state will be reset next time the framer is used.\n        \"\"\"\n\n        if not isinstance(value, framers.Framer):\n            raise ValueError(\"framer must be an instance of tendril.Framer\")\n\n        self._send_framer = value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the framer used for the receiving side of the tendril connection.", "response": "def recv_framer(self, value):\n        \"\"\"\n        Set the framer in use for the receiving side of the\n        connection.  The framer state will be reset next time the\n        framer is used.\n        \"\"\"\n\n        if not isinstance(value, framers.Framer):\n            raise ValueError(\"framer must be an instance of tendril.Framer\")\n\n        self._recv_framer = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef framers(self, value):\n\n        # Handle sequence values\n        if isinstance(value, collections.Sequence):\n            if len(value) != 2:\n                raise ValueError('need exactly 2 values to unpack')\n            elif (not isinstance(value[0], framers.Framer) or\n                  not isinstance(value[1], framers.Framer)):\n                raise ValueError(\"framer must be an instance of \"\n                                 \"tendril.Framer\")\n\n            self._send_framer, self._recv_framer = value\n\n        # If we have a single value, assume it's a framer\n        else:\n            if not isinstance(value, framers.Framer):\n                raise ValueError(\"framer must be an instance of \"\n                                 \"tendril.Framer\")\n\n            self._send_framer = value\n            self._recv_framer = value", "response": "Sets the framers in use for the connection."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresets the framers in use for the connection.", "response": "def framers(self):\n        \"\"\"\n        Reset the framers in use for the connection to be a\n        tendril.IdentityFramer.  The framer states will be reset next\n        time their respective framer is used.\n        \"\"\"\n\n        f = self.default_framer()\n        self._send_framer = f\n        self._recv_framer = f"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build():\n    test_files()\n    with open('content.rst') as f:\n        content = publish_parts(f.read(), writer_name='html')\n        title = content['title']\n        body =  content['html_body'].replace('\\n',' ')\n\n    with open('template.jinja', 'r') as f:\n        loader = FileSystemLoader(getcwd())\n        env= Environment(loader=loader)\n        template = env.get_template('template.jinja')\n        page =  template.render(title=title,\n                                content=body)\n\n    with open('index.html', 'w') as f:\n        f.write(page)", "response": "Builds pages given template. jinja style. css and content. rst produces index. html."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize a new site in the directory", "response": "def init(directory=None):\n    \"\"\"\n    Initializes a new site in the `directory`\n    Current working dir if directory is None.\n    \"\"\"\n    if directory is not None and not path.exists(directory):\n        makedirs(directory)\n    else:\n        print('%s already exists, populating with template files' % (directory))\n        directory = ''\n\n    if not path.isfile(path.join(directory,'style.css')):\n        grab('style.css', directory)\n        print('Added sample style')\n    if not path.isfile(path.join(directory,'template.jinja')):\n        grab('template.jinja', directory)\n        print('Added sample template.jinja')\n    if not path.isfile(path.join(directory,'content.rst')):\n        grab('content.rst', directory)\n        print('Added sample content.rst')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef grab(filename, directory):\n    r = requests.get('https://raw.githubusercontent.com/ElijahCaine/pageup/master/pageup/data/'+filename)\n    with open(path.join(directory,filename), 'wb') as f:\n        f.write(r.content)", "response": "Grab a file from Github and store it in a directory"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering an arbitrary callback and arguments.", "response": "def callback(self, callback, *args, **kwds):\n        \"\"\" Registers an arbitrary callback and arguments.\n\n            Cannot suppress exceptions.\n        \"\"\"\n        return self << _CloseDummy(callback, args, kwds)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npreserves the context stack by transferring it to a new instance", "response": "def pop_all(self):\n        \"\"\" Preserve the context stack by transferring it to a new instance \"\"\"\n        ret = ExitStack()\n        ret._context_stack.append(self._context_stack.pop())\n        self._context_stack.append([])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, **kwargs):\n        self.validate(**kwargs)\n        for attr, value in kwargs.items():\n            setattr(self, attr, value)\n        return self", "response": "Update the fields on the model with the values from the kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate(cls, partial=True, **kwargs):\n        data = kwargs\n        if not partial:\n            data = dict(**kwargs, **{col.name: None for col in cls.__table__.c\n                                     if col.name not in kwargs})\n\n        errors = defaultdict(list)\n        for name, value in data.items():\n            for validator in cls._get_validators(name):\n                try:\n                    validator(value)\n                except ValidationError as e:\n                    e.model = cls\n                    e.column = name\n                    errors[name].append(str(e))\n\n        if errors:\n            raise ValidationErrors(errors)", "response": "Validate kwargs before setting attributes on the model"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef of(fixture_classes: Iterable[type], context: Union[None, 'torment.TestContext'] = None) -> Iterable['torment.fixtures.Fixture']:\n    '''Obtain all Fixture objects of the provided classes.\n\n    **Parameters**\n\n    :``fixture_classes``: classes inheriting from ``torment.fixtures.Fixture``\n    :``context``:         a ``torment.TestContext`` to initialize Fixtures with\n\n    **Return Value(s)**\n\n    Instantiated ``torment.fixtures.Fixture`` objects for each individual\n    fixture class that inherits from one of the provided classes.\n\n    '''\n\n    classes = list(copy.copy(fixture_classes))\n    fixtures = []  # type: Iterable[torment.fixtures.Fixture]\n\n    while len(classes):\n        current = classes.pop()\n        subclasses = current.__subclasses__()\n\n        if len(subclasses):\n            classes.extend(subclasses)\n        elif current not in fixture_classes:\n            fixtures.append(current(context))\n\n    return fixtures", "response": "Obtain all Fixture objects of the provided classes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register(namespace, base_classes: Tuple[type], properties: Dict[str, Any]) -> None:\n    '''Register a Fixture class in namespace with the given properties.\n\n    Creates a Fixture class (not object) and inserts it into the provided\n    namespace.  The properties is a dict but allows functions to reference other\n    properties and acts like a small DSL (domain specific language).  This is\n    really just a declarative way to compose data about a test fixture and make\n    it repeatable.\n\n    Files calling this function are expected to house one or more Fixtures and\n    have a name that ends with a UUID without its hyphens.  For example:\n    foo_38de9ceec5694c96ace90c9ca37e5bcb.py.  This UUID is used to uniquely\n    track the Fixture through the test suite and allow Fixtures to scale without\n    concern.\n\n    **Parameters**\n\n    :``namespace``:    dictionary to insert the generated class into\n    :``base_classes``: list of classes the new class should inherit\n    :``properties``:   dictionary of properties with their values\n\n    Properties can have the following forms:\n\n    :functions: invoked with the Fixture as it's argument\n    :classes:   instantiated without any arguments (unless it subclasses\n                ``torment.fixtures.Fixture`` in which case it's passed context)\n    :literals:  any standard python type (i.e. int, str, dict)\n\n    .. note::\n        function execution may error (this will be emitted as a logging event).\n        functions will continually be tried until they resolve or the same set\n        of functions is continually erroring.  These functions that failed to\n        resolve are left in tact for later processing.\n\n    Properties by the following names also have defined behavior:\n\n    :description: added to the Fixture's description as an addendum\n    :error:       must be a dictionary with three keys:\n                  :class:  class to instantiate (usually an exception)\n                  :args:   arguments to pass to class initialization\n                  :kwargs: keyword arguments to pass to class initialization\n    :mocks:       dictionary mapping mock symbols to corresponding values\n\n    Properties by the following names are reserved and should not be used:\n\n    * name\n\n    '''\n\n    # ensure we have a clean copy of the data\n    # and won't stomp on re-uses elsewhere in\n    # someone's code\n    props = copy.deepcopy(properties)\n\n    desc = props.pop('description', None)  # type: Union[str, None]\n\n    caller_frame = inspect.stack()[1]\n\n    caller_file = caller_frame[1]\n    caller_module = inspect.getmodule(caller_frame[0])\n\n    my_uuid = uuid.UUID(os.path.basename(caller_file).replace('.py', '').rsplit('_', 1)[-1])\n    class_name = _unique_class_name(namespace, my_uuid)\n\n    @property\n    def description(self) -> str:\n        _ = super(self.__class__, self).description\n\n        if desc is not None:\n            _ += '\u2014' + desc\n\n        return _\n\n    def __init__(self, context: 'torment.TestContext') -> None:\n        super(self.__class__, self).__init__(context)\n\n        functions = {}\n\n        for name, value in props.items():\n            if name == 'error':\n                self.error = value['class'](*value.get('args', ()), **value.get('kwargs', {}))\n                continue\n\n            if inspect.isclass(value):\n                if issubclass(value, Fixture):\n                    value = value(self.context)\n                else:\n                    value = value()\n\n            if inspect.isfunction(value):\n                functions[name] = value\n                continue\n\n            setattr(self, name, value)\n\n        _resolve_functions(functions, self)\n\n        self.initialize()\n\n    def setup(self) -> None:\n        if hasattr(self, 'mocks'):\n            logger.debug('self.mocks: %s', self.mocks)\n\n            for mock_symbol, mock_result in self.mocks.items():\n                if _find_mocker(mock_symbol, self.context)():\n                    _prepare_mock(self.context, mock_symbol, **mock_result)\n\n        super(self.__class__, self).setup()\n\n    namespace[class_name] = type(class_name, base_classes, {\n        'description': description,\n        '__init__': __init__,\n        '__module__': caller_module,\n        'setup': setup,\n        'uuid': my_uuid,\n    })", "response": "Register a Fixture class in namespace with the given properties."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprepare the mock for a given symbol.", "response": "def _prepare_mock(context: 'torment.contexts.TestContext', symbol: str, return_value = None, side_effect = None) -> None:\n    '''Sets return value or side effect of symbol's mock in context.\n\n    .. seealso:: :py:func:`_find_mocker`\n\n    **Parameters**\n\n    :``context``:       the search context\n    :``symbol``:        the symbol to be located\n    :``return_value``:  pass through to mock ``return_value``\n    :``side_effect``:   pass through to mock ``side_effect``\n\n    '''\n\n    methods = symbol.split('.')\n    index = len(methods)\n\n    mock = None\n\n    while index > 0:\n        name = 'mocked_' + '_'.join(methods[:index]).lower()\n        logger.debug('name: %s', name)\n\n        if hasattr(context, name):\n            mock = getattr(context, name)\n            break\n\n        index -= 1\n\n    logger.debug('mock: %s', mock)\n\n    if mock is not None:\n        mock = functools.reduce(getattr, methods[index:], mock)\n        logger.debug('mock: %s', mock)\n\n        if return_value is not None:\n            mock.return_value = return_value\n\n        if side_effect is not None:\n            mock.side_effect = side_effect\n\n        mock.reset_mock()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the mocker method that resembles the symbol.", "response": "def _find_mocker(symbol: str, context: 'torment.contexts.TestContext') -> Callable[[], bool]:\n    '''Find method within the context that mocks symbol.\n\n    Given a symbol (i.e. ``tornado.httpclient.AsyncHTTPClient.fetch``), find\n    the shortest ``mock_`` method that resembles the symbol. Resembles means\n    the lowercased and periods replaced with underscores.\n\n    If no match is found, a dummy function (only returns False) is returned.\n\n    **Parameters**\n\n    :``symbol``:  the symbol to be located\n    :``context``: the search context\n\n    **Return Value(s)**\n\n    The method used to mock the symbol.\n\n    **Examples**\n\n    Assuming the symbol is ``tornado.httpclient.AsyncHTTPClient.fetch``, the\n    first of the following methods would be returned:\n\n    * ``mock_tornado``\n    * ``mock_tornado_httpclient``\n    * ``mock_tornado_httpclient_asynchttpclient``\n    * ``mock_tornado_httpclient_asynchttpclient_fetch``\n\n    '''\n\n    components = []\n    method = None\n\n    for component in symbol.split('.'):\n        components.append(component.lower())\n        name = '_'.join([ 'mock' ] + components)\n\n        if hasattr(context, name):\n            method = getattr(context, name)\n            break\n\n    if method is None:\n        logger.warn('no mocker for %s', symbol)\n\n        def noop(*args, **kwargs):\n            return False\n\n        method = noop\n\n    return method"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nresolve functions and collect values as properteis on fixture.", "response": "def _resolve_functions(functions: Dict[str, Callable[[Any], Any]], fixture: Fixture) -> None:\n    '''Apply functions and collect values as properties on fixture.\n\n    Call functions and apply their values as properteis on fixture.\n    Functions will continue to get applied until no more functions resolve.\n    All unresolved functions are logged and the last exception to have\n    occurred is also logged.  This function does not return but adds the\n    results to fixture directly.\n\n    **Parameters**\n\n    :``functions``: dict mapping function names (property names) to\n                    callable functions\n    :``fixture``:   Fixture to add values to\n\n    '''\n\n    exc_info = last_function = None\n    function_count = float('inf')\n\n    while function_count > len(functions):\n        function_count = len(functions)\n\n        for name, function in copy.copy(functions).items():\n            try:\n                setattr(fixture, name, copy.deepcopy(function(fixture)))\n                del functions[name]\n            except:\n                exc_info = sys.exc_info()\n\n                logger.debug('name: %s', name)\n                logger.debug('exc_info: %s', exc_info)\n\n                last_function = name\n\n    if len(functions):\n        logger.warning('unprocessed Fixture properties: %s', ','.join(functions.keys()))\n        logger.warning('last exception from %s.%s:', fixture.name, last_function, exc_info = exc_info)\n\n        setattr(fixture, '_last_resolver_exception', ( last_function, exc_info, ))\n\n        for name, function in copy.copy(functions).items():\n            setattr(fixture, name, function)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _unique_class_name(namespace: Dict[str, Any], uuid: uuid.UUID) -> str:\n    '''Generate unique to namespace name for a class using uuid.\n\n    **Parameters**\n\n    :``namespace``: the namespace to verify uniqueness against\n    :``uuid``:      the \"unique\" portion of the name\n\n    **Return Value(s)**\n\n    A unique string (in namespace) using uuid.\n\n    '''\n\n    count = 0\n\n    name = original_name = 'f_' + uuid.hex\n    while name in namespace:\n        count += 1\n        name = original_name + '_' + str(count)\n\n    return name", "response": "Generate unique class name for a class using uuid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the name of the fixture s category", "response": "def category(self) -> str:\n        '''Fixture's category (the containing testing module name)\n\n        **Examples**\n\n        :module:   test_torment.test_unit.test_fixtures.fixture_a44bc6dda6654b1395a8c2cbd55d964d\n        :category: fixtures\n\n        '''\n\n        logger.debug('dir(self.__module__): %s', dir(self.__module__))\n\n        return self.__module__.__name__.rsplit('.', 2)[-2].replace('test_', '')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef description(self) -> str:\n        '''Test name in nose output (intended to be overridden).'''\n\n        return '{0.uuid.hex}\u2014{1}'.format(self, self.context.module)", "response": "Test name in nose output ( intended to be overridden."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute the core test loop for the Fixture.", "response": "def _execute(self) -> None:\n        '''Run Fixture actions (setup, run, check).\n\n        Core test loop for Fixture.  Executes setup, run, and check in order.\n\n        '''\n\n        if hasattr(self, '_last_resolver_exception'):\n            logger.warning('last exception from %s.%s:', self.__class__.__name__, self._last_resolver_exception[0], exc_info = self._last_resolver_exception[1])\n\n        self.setup()\n        self.run()\n        self.check()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self) -> None:\n        '''Calls sibling with exception expectation.'''\n\n        with self.context.assertRaises(self.error.__class__) as error:\n            super().run()\n\n        self.exception = error.exception", "response": "Calls sibling with exception expectation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cache_keys(keys):\n    d = known_keys()\n    known_names = dict(zip(d.values(), d.keys()))\n    for k in keys:\n        i = (ord(k),) if len(k) == 1 else known_names[k]\n        _key_cache.insert(0, i)", "response": "Cache the given list of keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_keycodes():\n    try:\n        return _key_cache.pop()\n    except IndexError:\n        pass\n    result = []\n    terminators = 'ABCDFHPQRS~'\n    with TerminalContext():\n        code = get_ord()\n        result.append(code)\n        if code == 27:\n            with TimerContext(0.1) as timer:\n                code = get_ord()\n            if not timer.timed_out:\n                result.append(code)\n                result.append(get_ord())\n                if 64 < result[-1] < 69:\n                    pass\n                elif result[1] == 91:\n                    while True:\n                        code = get_ord()\n                        result.append(code)\n                        if chr(code) in terminators:\n                            break\n    return tuple(result)", "response": "Read keypress giving a tuple of key codes"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_key():\n    character_name = chr\n    codes = _get_keycodes()\n    if len(codes) == 1:\n        code = codes[0]\n        if code >= 32:\n            return character_name(code)\n        return control_key_name(code)\n    return get_extended_key_name(codes)", "response": "Get a key from the keyboard as a string\n    A key will be a single char control_key_name or extended_key_name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_string():\n    keycodes = _get_keycodes()\n    initial_code, codes = keycodes[0], keycodes[1:]\n    initial_char = chr(initial_code)\n    if initial_code == 27:\n        initial_char = '\\\\e'\n    elif not ascii.isgraph(initial_char):\n        initial_char = '\\\\x%x' % initial_code\n    chars = ''.join([chr(c) for c in codes])\n    return ''.join((initial_char, chars))", "response": "A better str method"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck ports exist on bridge.", "response": "def check_ports_on_br(self, bridge='br-ex', ports=['eth3']):\n        \"\"\"Check ports exist on bridge.\n\n        ovs-vsctl list-ports bridge\n        \"\"\"\n        LOG.info(\"RPC: check_ports_on_br bridge: %s, ports: %s\" %\n                 (bridge, ports))\n        cmd = ['ovs-vsctl', 'list-ports', bridge]\n        stdcode, stdout = agent_utils.execute(cmd, root=True)\n        data = dict()\n        if stdcode == 0:\n            for port in ports:\n                if port in stdout:\n                    data[port] = True\n                    stdout.remove(port)\n                else:\n                    data[port] = False\n            return agent_utils.make_response(code=stdcode, data=data)\n        # execute failed.\n        message = stdout.pop(0)\n        return agent_utils.make_response(code=stdcode,\n                                         message=message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npings the hosts or broadcast.", "response": "def ping(self, ips, boardcast=False,\n             count=2, timeout=2, interface=None):\n        \"\"\"Ping host or broadcast.\n\n        ping host -c 2 -W 2\n        \"\"\"\n        cmd = ['ping', '-c', str(count), '-W', str(timeout)]\n        True if not interface else cmd.extend(['-I', interface])\n        True if not boardcast else cmd.append('-b')\n        # Batch create subprocess\n        data = dict()\n        try:\n            for ip in ips:\n                stdcode, stdout = agent_utils.execute(cmd + [ip])\n                if stdcode:\n                    data[ip] = 100\n                else:\n                    pattern = r',\\s([0-9]+)%\\spacket\\sloss'\n                    data[ip] = re.search(pattern, stdout[-2]).groups()[0]\n            return agent_utils.make_response(code=0, data=data)\n        except Exception as e:\n            message = e.message\n            return agent_utils.make_response(code=1, message=message)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_vlan_to_interface(self, interface, vlan_id):\n        subif = '%s.%s' % (interface, vlan_id)\n        vlan_id = '%s' % vlan_id\n        cmd = ['ip', 'link', 'add', 'link', interface, 'name',\n               subif, 'type', 'vlan', 'id', vlan_id]\n        stdcode, stdout = agent_utils.execute(cmd, root=True)\n        if stdcode == 0:\n            return agent_utils.make_response(code=stdcode)\n        # execute failed.\n        message = stdout.pop(0)\n        return agent_utils.make_response(code=stdcode, message=message)", "response": "Add vlan to interface."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_interface(self, interface='eth0'):\n        LOG.info(\"RPC: get_interface interfae: %s\" % interface)\n        code, message, data = agent_utils.get_interface(interface)\n        return agent_utils.make_response(code, message, data)", "response": "Get the current cache entry for an interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setup_link(self, interface, cidr):\n        # clear old ipaddr in interface\n        cmd = ['ip', 'addr', 'flush', 'dev', interface]\n        agent_utils.execute(cmd, root=True)\n        ip = IPNetwork(cidr)\n        cmd = ['ip', 'addr', 'add', cidr, 'broadcast',\n               str(ip.broadcast), 'dev', interface]\n        stdcode, stdout = agent_utils.execute(cmd, root=True)\n        if stdcode == 0:\n            cmd = ['ip', 'link', 'set', 'dev', interface, 'up']\n            stdcode, stdout = agent_utils.execute(cmd, root=True)\n            if stdcode == 0:\n                return agent_utils.make_response(code=stdcode)\n        # execute failed.\n        message = stdout.pop(0)\n        return agent_utils.make_response(code=stdcode, message=message)", "response": "Setup a link.\n\n        ip addr add dev interface\n        ip link  set dev interface up"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntelling whether a variable is an object reference.", "response": "def isreference(a):\n    \"\"\"\n    Tell whether a variable is an object reference.\n\n    Due to garbage collection, some objects happen to get the id of a distinct variable.\n    As a consequence, linking is not ready yet and `isreference` returns ``False``.\n    \"\"\"\n    return False\n    return id(a) != id(copy.copy(a))\n    check = ('__dict__', '__slots__')\n    for attr in check:\n        try:\n            getattr(a, attr)\n        except (SystemExit, KeyboardInterrupt):\n            raise\n        except:\n            pass\n        else:\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lookup_type(storable_type):\n    if storable_type.startswith('Python'):\n        _, module_name = storable_type.split('.', 1)\n    else:\n        module_name = storable_type\n    #type_name, module_name = \\\n    names = [ _name[::-1] for _name in module_name[::-1].split('.', 1) ]\n    if names[1:]:\n        type_name, module_name = names\n    else:\n        type_name = names[0]\n        return eval(type_name)\n    try:\n        module = importlib.import_module(module_name)\n        python_type = getattr(module, type_name)\n    except (ImportError, AttributeError):\n        python_type = None\n    return python_type", "response": "Look for the Python type that corresponds to a storable type name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef poke(exposes):\n    def _poke(store, objname, obj, container, visited=None, _stack=None):\n        try:\n            sub_container = store.newContainer(objname, obj, container)\n        except (SystemExit, KeyboardInterrupt):\n            raise\n        except:\n            raise ValueError('generic poke not supported by store')\n        #_stack = _add_to_stack(_stack, objname)\n        for iobjname in exposes:\n            try:\n                iobj = getattr(obj, iobjname)\n            except AttributeError:\n                pass\n            else:\n                store.poke(iobjname, iobj, sub_container, visited=visited, \\\n                    _stack=_stack)\n    return _poke", "response": "Returns a serializer function that creates a new container for the given set of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef default_peek(python_type, exposes):\n    with_args = False\n    make = python_type\n    try:\n        make()\n    except (SystemExit, KeyboardInterrupt):\n        raise\n    except:\n        make = lambda: python_type.__new__(python_type)\n        try:\n            make()\n        except (SystemExit, KeyboardInterrupt):\n            raise\n        except:\n            make = lambda args: python_type.__new__(python_type, *args)\n            with_args = True\n    def missing(attr):\n        return AttributeError(\"can't set attribute '{}' ({})\".format(attr, python_type))\n    if with_args:\n        def peek(store, container, _stack=None):\n            state = []\n            for attr in exposes: # force order instead of iterating over `container`\n                #print((attr, attr in container)) # debugging\n                if attr in container:\n                    state.append(store.peek(attr, container, _stack=_stack))\n                else:\n                    state.append(None)\n            return make(state)\n    elif '__dict__' in exposes:\n        def peek(store, container, _stack=None):\n            obj = make()\n            for attr in container:\n                val = store.peek(attr, container, _stack=_stack)\n                try:\n                    setattr(obj, attr, val)\n                except AttributeError:\n                    raise missing(attr)\n            return obj\n    else:\n        def peek(store, container, _stack=None):\n            obj = make()\n            for attr in exposes: # force order instead of iterating over `container`\n                #print((attr, attr in container)) # debugging\n                if attr in container:\n                    val = store.peek(attr, container, _stack=_stack)\n                else:\n                    val = None\n                try:\n                    setattr(obj, attr, val)\n                except AttributeError:\n                    raise missing(attr)\n            return obj\n    return peek", "response": "Default deserializer for the base class."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a deserializer function that takes a dictionary of keyworded arguments to the constructor.", "response": "def peek_with_kwargs(init, args=[]):\n    \"\"\"\n    Make datatypes passing keyworded arguments to the constructor.\n\n    This is a factory function; returns the actual `peek` routine.\n\n    Arguments:\n\n        init (callable): type constructor.\n\n        args (iterable): arguments NOT to be keyworded; order does matter.\n\n    Returns:\n\n        callable: deserializer (`peek` routine).\n\n    All the peeked attributes that are not referenced in `args` are passed to `init` as\n    keyworded arguments.\n    \"\"\"\n    def peek(store, container, _stack=None):\n        return init(\\\n            *[ store.peek(attr, container, _stack=_stack) for attr in args ], \\\n            **dict([ (attr, store.peek(attr, container, _stack=_stack)) \\\n                for attr in container if attr not in args ]))\n    return peek"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef peek(init, exposes, debug=False):\n    def _peek(store, container, _stack=None):\n        args = [ store.peek(objname, container, _stack=_stack) \\\n            for objname in exposes ]\n        if debug:\n            print(args)\n        return init(*args)\n    return _peek", "response": "Return a deserializer function that returns the next set of attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of attributes exposed by the objects of a given type.", "response": "def most_exposes(python_type):\n    \"\"\"\n    Core engine for the automatic generation of storable instances.\n\n    Finds the attributes exposed by the objects of a given type.\n\n    Mostly Python3-only.\n    Does not handle types which `__new__` method requires extra arguments either.\n\n    Arguments:\n\n        python_type (type): object type.\n\n    Returns:\n\n        list: attributes exposed.\n\n    \"\"\"\n    _exposes = set()\n    try:\n        # list all standard class attributes and methods:\n        do_not_expose = set(python_type.__dir__(object) + \\\n            ['__slots__', '__module__', '__weakref__']) # may raise `AttributeError`\n        empty = python_type.__new__(python_type) # may raise `TypeError`\n    except AttributeError: # Py2 does not have `__dir__`\n        try:\n            _exposes = python_type.__slots__\n        except AttributeError:\n            pass\n    except TypeError: # `__new__` requires input arguments\n        for _workaround in storable_workarounds:\n            try:\n                _exposes = _workaround(python_type)\n            except (SystemExit, KeyboardInterrupt):\n                raise\n            except:\n                pass\n            else:\n                break\n    else:\n        # note that slots from parent classes are not in `__dict__` (like all slots)\n        # and - in principle - not in `__slots__` either.\n        all_members = empty.__dir__() # all slots are supposed to appear in this list\n        for attr in all_members:\n            if attr in do_not_expose:\n                # note that '__dict__' is in `do_not_expose` (comes from `object`)\n                continue\n            try: # identify the methods and properties\n                getattr(empty, attr)\n            except AttributeError as e: # then `attr` might be a slot\n                # properties can still throw an `AttributeError`;\n                # try to filter some more out\n                if e.args:\n                    msg = e.args[0]\n                    if msg == attr or msg.endswith(\"' object has no attribute '{}'\".format(attr)):\n                        _exposes.add(attr)\n            except (SystemExit, KeyboardInterrupt):\n                raise\n            except:\n                pass\n        for attr in ('__dict__',):\n            if attr in all_members:\n                _exposes.add(attr)\n    return list(_exposes)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndefaulting mechanics for building a new Storable instance for a given type.", "response": "def default_storable(python_type, exposes=None, version=None, storable_type=None, peek=default_peek):\n    \"\"\"\n    Default mechanics for building the storable instance for a type.\n\n    Arguments:\n\n        python_type (type): type.\n\n        exposes (iterable): attributes exposed by the type.\n\n        version (tuple): version number.\n\n        storable_type (str): universal string identifier for the type.\n\n        peek (callable): peeking routine.\n\n    Returns:\n\n        Storable: storable instance.\n\n    \"\"\"\n    if not exposes:\n        for extension in expose_extensions:\n            try:\n                exposes = extension(python_type)\n            except (SystemExit, KeyboardInterrupt):\n                raise\n            except:\n                pass\n            else:\n                if exposes:\n                    break\n        if not exposes:\n            raise AttributeError('`exposes` required for type: {!r}'.format(python_type))\n    return Storable(python_type, key=storable_type, \\\n        handlers=StorableHandler(version=version, exposes=exposes, \\\n        poke=poke(exposes), peek=peek(python_type, exposes)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new Storable object with a kwarg - style init and exposes.", "response": "def kwarg_storable(python_type, exposes=None, version=None, storable_type=None, init=None, args=[]):\n    \"\"\"\n    **Deprecated**\n    \"\"\"\n    warnings.warn('kwarg_storable', DeprecationWarning)\n    if init is None:\n        init = python_type\n    if exposes is None:\n        try:\n            exposes = python_type.__slots__\n        except (SystemExit, KeyboardInterrupt):\n            raise\n        except:\n            # take __dict__ and sort out the class methods\n            raise AttributeError('either define the `exposes` argument or the `__slots__` attribute for type: {!r}'.format(python_type))\n    return Storable(python_type, key=storable_type, handlers=StorableHandler(version=version, \\\n        poke=poke(exposes), peek=peek_with_kwargs(init, args), exposes=exposes))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new unserializable version of the given type.", "response": "def not_storable(_type):\n    \"\"\"\n    Helper for tagging unserializable types.\n\n    Arguments:\n\n        _type (type): type to be ignored.\n\n    Returns:\n\n        Storable: storable instance that does not poke.\n\n    \"\"\"\n    return Storable(_type, handlers=StorableHandler(poke=fake_poke, peek=fail_peek(_type)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef force_auto(service, _type):\n    storable = service.byPythonType(_type, istype=True)\n    version = max(handler.version[0] for handler in storable.handlers) + 1\n    _storable = default_storable(_type, version=(version, ))\n    storable.handlers.append(_storable.handlers[0])", "response": "Force auto - serialization of a datatype with already registered explicit\n    storable instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a serializer for types which state can be natively serialized.", "response": "def poke_native(getstate):\n    \"\"\"\n    Serializer factory for types which state can be natively serialized.\n\n    Arguments:\n\n        getstate (callable): takes an object and returns the object's state\n            to be passed to `pokeNative`.\n\n    Returns:\n\n        callable: serializer (`poke` routine).\n\n    \"\"\"\n    def poke(service, objname, obj, container, visited=None, _stack=None):\n        service.pokeNative(objname, getstate(obj), container)\n    return poke"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef peek_native(make):\n    def peek(service, container, _stack=None):\n        return make(service.peekNative(container))\n    return peek", "response": "Returns a deserializer factory for types which state can be natively serialized."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a Storable for a namedtuple.", "response": "def namedtuple_storable(namedtuple, *args, **kwargs):\n    \"\"\"\n    Storable factory for named tuples.\n    \"\"\"\n    return default_storable(namedtuple, namedtuple._fields, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npoking a storable instance.", "response": "def pokeStorable(self, storable, objname, obj, container, visited=None, _stack=None, **kwargs):\n        \"\"\"\n        Arguments:\n\n            storable (StorableHandler): storable instance.\n\n            objname (any): record reference.\n\n            obj (any): object to be serialized.\n\n            container (any): container.\n\n            visited (dict): map of the previously serialized objects that are\n                passed by references; keys are the objects' IDs.\n\n            _stack (CallStack): stack of parent object names.\n\n        Trailing keyword arguments are passed to the :class:`Storable` instance's\n        :attr:`~Storable.poke`.\n        \"\"\"\n        #print((objname, storable.storable_type)) # debug\n        storable.poke(self, objname, obj, container, visited=visited, _stack=_stack, **kwargs)\n        try:\n            record = self.getRecord(objname, container)\n        except KeyError:\n            # fake storable; silently skip\n            if self.verbose:\n                print(\"skipping `{}` (type: {})\".format(objname, storable.storable_type))\n                if 1 < self.verbose:\n                    print(traceback.format_exc())\n        else:\n            self.setRecordAttr('type', storable.storable_type, record)\n            if storable.version is not None:\n                self.setRecordAttr('version', from_version(storable.version), record)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pokeVisited(self, objname, obj, record, existing, visited=None, _stack=None, **kwargs):\n        if self.hasPythonType(obj):\n            storable = self.byPythonType(obj).asVersion()\n            self.pokeStorable(storable, objname, obj, record, visited=visited, \\\n                _stack=_stack, **kwargs)\n        else:\n            try:\n                self.pokeNative(objname, obj, record)\n            except (SystemExit, KeyboardInterrupt):\n                raise\n            except:\n                self.dump_stack(_stack)\n                raise", "response": "Serialize an already serialized object into the internal store."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the next object from the given object.", "response": "def peekStorable(self, storable, record, _stack=None, **kwargs):\n        \"\"\"\n        Arguments:\n\n            storable (StorableHandler): storable instance.\n\n            record (any): record.\n\n            _stack (CallStack): stack of parent object names.\n\n        Returns:\n\n            any: deserialized object.\n\n        Trailing keyword arguments are passed to the :class:`Storable` instance's\n        :attr:`~Storable.peek`.\n        \"\"\"\n        return storable.peek(self, record, _stack=_stack, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef defaultStorable(self, python_type=None, storable_type=None, version=None, **kwargs):\n        if python_type is None:\n            python_type = lookup_type(storable_type)\n        if self.verbose:\n            print('generating storable instance for type: {}'.format(python_type))\n        self.storables.registerStorable(default_storable(python_type, \\\n                version=version, storable_type=storable_type), **kwargs)\n        return self.byPythonType(python_type, True).asVersion(version)", "response": "Generate a default StorableHandler for the given type."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, name: str, default: Any = None) -> Any:\n        return super().get(name, [default])[0]", "response": "Return the first value of the named key or the default if no key is given."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getlist(self, name: str, default: Any = None) -> List[Any]:\n        return super().get(name, default)", "response": "Return the entire list of the named object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the href of the current instance.", "response": "def href(self) -> str:\n        \"\"\"\n        \u628a url \u4ece\u65b0\u6784\u5efa\n        \"\"\"\n        href_arr = cast(List[str], [])\n        href_arr.append(self.schema)\n        href_arr.append(\"://\")\n        if self.userinfo is not None:\n            href_arr.append(self.userinfo)\n            href_arr.append(\"@\")\n        href_arr.append(self.host)\n        if self.port is not None:\n            href_arr.append(\":%d\" % self.port)\n        if self.path is not None:\n            href_arr.append(self.path)\n        if self.querystring is not None:\n            href_arr.append(\"?\")\n            href_arr.append(self.querystring)\n        if self.fragment is not None:\n            href_arr.append(\"#\")\n            href_arr.append(self.fragment)\n        href_str = \"\".join(href_arr)\n        return href_str"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef feed_data(self, data: bytes) -> None:\n        if self._parser is not None:\n            self._parser.feed_data(data)", "response": "Feed data into the parser."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_header(self, name: bytes, value: bytes) -> None:\n        name_ = decode_bytes(name).casefold()\n        val = decode_bytes(value)\n        if name_ == \"cookie\":\n            # \u52a0\u8f7d\u4e0a\u6b21\u7684 cookie\n            self._cookies.load(val)\n        if name_ in self._headers:\n            # \u591a\u4e2a\u76f8\u540c\u7684 header\n            old = self._headers[name_]\n            if isinstance(old, list):\n                old.append(val)\n            else:\n                self._headers[name_] = [old, val]\n        else:\n            self._headers[name_] = val", "response": "Handle incoming HTTP header."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting method from parser", "response": "def method(self) -> str:\n        \"\"\"\n        \u83b7\u53d6\u8bf7\u6c42\u65b9\u6cd5\n        \"\"\"\n        if self._method is None:\n            self._method = decode_bytes(self._parser.get_method())\n        return self._method"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the application is proxy.", "response": "def proxy(self) -> bool:\n        \"\"\"\n        \u4ece app \u8bfb\u53d6\u662f\u5426\u5224\u65ad proxy\n        \"\"\"\n        if self.app is None:\n            return False\n        return bool(cast(Any, self.app).proxy)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef length(self) -> Optional[int]:\n        len_ = self.get(\"content-length\")\n        if len_ is not None:\n            return int(cast(str, len_))\n        return None", "response": "Get the length of the message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the value of a header.", "response": "def get(self, name: str) -> Union[None, str, List[str]]:\n        \"\"\"\n        \u83b7\u53d6 header\n        \"\"\"\n        name = name.casefold()\n        if name == \"referer\" or name == \"referrer\":\n            if \"referrer\" in self._headers:\n                return self._headers[\"referrer\"]\n            elif \"referer\" in self._headers:\n                return self._headers[\"referer\"]\n            else:\n                return None\n        elif name in self._headers:\n            return self._headers[name]\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets a header value.", "response": "def set(self, name: str, value: str) -> None:\n        \"\"\"\n        \u91cd\u5199\u8bf7\u6c42\u4e2d\u7684 header, \u4e0d\u63a8\u8350\u4f7f\u7528\n        \"\"\"\n        name = name.casefold()\n        self._headers[name] = value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef url(self) -> str:\n        url_str = self.parse_url.path or \"\"\n        if self.parse_url.querystring is not None:\n            url_str += \"?\" + self.parse_url.querystring\n        return url_str", "response": "Returns the URL of the current resource."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef path(self) -> Optional[str]:\n        path_str = self.parse_url.path\n        if path_str is not None and \"%\" in path_str:\n            path_str = unquote(path_str)\n        return path_str", "response": "Get the path of the resource."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_url(self) -> RequestUrl:\n        if self._URL is None:\n            current_url = b\"%s://%s%s\" % (\n                encode_str(self.schema),\n                encode_str(self.host),\n                self._current_url\n            )\n            self._URL = RequestUrl(current_url)\n        return cast(RequestUrl, self._URL)", "response": "Parse the URL of the current resource."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef schema(self) -> str:\n        if self._ssl:\n            return \"https\"\n        proxy = bool(self.app and self.app.proxy)\n        if not proxy:\n            return \"http\"\n        proto = cast(str, self.get(\"X-Forwarded-Proto\") or \"http\")\n        return proto.split(\",\")[0].strip()", "response": "Returns the schema of the current session."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn charset from Content - Type header.", "response": "def charset(self) -> Optional[str]:\n        \"\"\"\n        \u83b7\u53d6 charset\n        \"\"\"\n        type_str = cast(str, self.get(\"Content-Type\"))\n        if type_str is None or \"charset\" not in type_str:\n            return None\n        for i in type_str.split(\";\"):\n            item = i.strip()\n            if item.startswith(\"charset\"):\n                return item.split(\"=\")[1].strip()\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the type of the content - type header.", "response": "def type(self) -> Optional[str]:\n        \"\"\"\n        \u83b7\u53d6 type\n        \"\"\"\n        type_str = cast(Optional[str], self.get(\"Content-Type\"))\n        if type_str is not None:\n            return type_str.split(\";\")[0]\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef host(self) -> str:\n        host = cast(Optional[str], None)\n        if self.proxy and 'X-Forwarded-Host' in self._headers:\n            xhost = cast(Optional[str], self.get('X-Forwarded-Host'))\n            if xhost is not None:\n                host = xhost.split(\",\")[0].strip()\n        host = host or cast(str, self.get('Host'))\n        return host", "response": "get host from headers"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ips(self) -> Optional[List[str]]:\n        if self.proxy and \"X-Forwarded-For\" in self._headers:\n            val = cast(str, self.get('X-Forwarded-For'))\n            ips = [i.strip() for i in val.split(\",\")]\n            return ips if len(ips) > 0 else None\n        return None", "response": "Get the list of IP s that are sent to the client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ip(self) -> Optional[str]:\n        ips = self.ips\n        if ips and len(ips) > 0:\n            return ips[0]\n        if self._transport:\n            return cast(\n                str,\n                self._transport.get_extra_info(\"peername\"),\n            )\n        return None", "response": "Returns the IP of the current instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if the current request is still valid.", "response": "def fresh(self) -> bool:\n        \"\"\"\n        \u68c0\u67e5\u8bf7\u6c42\u7f13\u5b58\u662f\u5426\u201c\u65b0\u9c9c\u201d\uff0c\u4e5f\u5c31\u662f\u5185\u5bb9\u6ca1\u6709\u6539\u53d8\u3002\n        \u6b64\u65b9\u6cd5\u7528\u4e8e If-None-Match / ETag, \u548c If-Modified-Since \u548c Last-Modified \u4e4b\u95f4\u7684\u7f13\u5b58\u534f\u5546\u3002\n        \u5728\u8bbe\u7f6e\u4e00\u4e2a\u6216\u591a\u4e2a\u8fd9\u4e9b\u54cd\u5e94\u5934\u540e\u5e94\u8be5\u5f15\u7528\u5b83\u3002\n        \"\"\"\n        method_str = self.method\n        if method_str != 'GET' and method_str != 'HEAD':\n            return False\n        s = self.ctx.status\n        if (s >= 200 and s < 300) or s == 304:\n            return fresh(\n                self.headers,\n                (self.response and self.response.headers) or {},\n            )\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning path against filter sets and return True if all pass", "response": "def validate(self, path):\n        \"\"\"Run path against filter sets and return True if all pass\"\"\"\n        # Exclude hidden files and folders with '.' prefix\n        if os.path.basename(path).startswith('.'):\n            return False\n\n        # Check that current path level is more than min path and less than max path\n        if not self.check_level(path):\n            return False\n\n        if self.filters:\n            if not self._level_filters(path):\n                return False\n\n        # Force include and exclude iterations to be strings in case of integer filters\n        # Handle exclusions\n        if self.to_exclude:\n            if any(str(ex).lower() in path.lower() for ex in self.to_exclude):\n                return False\n\n        # Handle inclusions\n        if self.to_include:\n            if not any(str(inc).lower() in path.lower() for inc in self.to_include):\n                return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef comment_thread(cls, backend, *args, **kwargs):\n        ct_cls = cls._known_backends.get(backend)\n        if not ct_cls:\n            return None\n        return ct_cls(*args, **kwargs)", "response": "A method to create a comment thread for the desired backend."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_dossier(data):\n    '''\n    Find dossier with reference matching either 'ref_an' or 'ref_sen',\n    create it if not found.  Ensure its reference is 'ref_an' if both fields\n    are present.\n    '''\n\n    changed = False\n    dossier = None\n    reffield = None\n\n    for field in [k for k in ('ref_an', 'ref_sen') if k in data]:\n        try:\n            dossier = Dossier.objects.get(reference=data[field])\n            reffield = field\n            break\n        except Dossier.DoesNotExist:\n            pass\n\n    if dossier is None:\n        reffield = 'ref_an' if 'ref_an' in data else 'ref_sen'\n        dossier = Dossier(reference=data[reffield])\n        logger.debug('Created dossier %s' % data[reffield])\n        changed = True\n\n    if 'ref_an' in data and reffield != 'ref_an':\n        logger.debug('Changed dossier reference to %s' % data['ref_an'])\n        dossier.reference = data['ref_an']\n        changed = True\n\n    return dossier, changed", "response": "Find dossier with reference matching either ref_an or ref_sen create it if not found."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates and save form model data to database", "response": "def saveform(cls, form):\n        \"\"\" Create and save form model data to database \"\"\"\n\n        columns = dict()\n        for name, field in cls.form_fields.iteritems():\n            columns[name] = getattr(form, field).data\n        instance = cls(**columns)\n        return instance.save()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_by_id(cls, id):\n\n        if any((isinstance(id, basestring) and id.isdigit(), isinstance(id,\n               (int, float)))):\n            return cls.query.get(int(id))\n        return None", "response": "Get a single resource by its identifier."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the attributes of the current object and save to database", "response": "def update(self, commit=True, **kwargs):\n        \"\"\" Update model attributes and save to database \"\"\"\n\n        for (attr, value) in kwargs.iteritems():\n            setattr(self, attr, value)\n        return commit and self.save() or self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save(self, commit=True):\n\n        db.session.add(self)\n        if commit:\n            db.session.commit()\n        return self", "response": "Save model to database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, commit=True):\n\n        db.session.delete(self)\n        return commit and db.session.commit()", "response": "Delete the current record from database"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if given directory to see if it is usable by s2.", "response": "def verify_dir_structure(full_path):\n    '''Check if given directory to see if it is usable by s2.\n\n    Checks that all required directories exist under the given \n    directory, and also checks that they are writable.\n\n    '''\n    if full_path == None:\n        return False\n    r = True\n    for d2c in PREDEFINED_DIR_NAMES:\n        #if d2c == \"s2\":\n        #    d2c = \".s2\"\n        cp2c = os.path.join(full_path, d2c)  #complete path to check\n        if not os.path.isdir(cp2c):\n            r = False\n            break\n        else:  #exists, let's check it's writable\n            if not os.access(cp2c, os.W_OK): \n                r = False\n                break\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntrues if d is a string and it s an existing directory.", "response": "def dir_param_valid(d):\n    '''True if d is a string and it's an existing directory.'''\n    r = True\n    if not isinstance(d, str) :\n        r = False\n        raise TypeError\n    if not os.path.isdir(d):\n        r = False\n        raise ValueError\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if given directory is empty false otherwise.", "response": "def dir_empty(d):\n    '''Return True if given directory is empty, false otherwise.'''\n    flist = glob.glob(os.path.join(d,'*'))\n    return (len(flist) == 0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_base_dir(d):\n    '''True if the dir is valid and it contains a dir called s2'''\n    if not dir_param_valid(d): # pragma: no cover\n        raise \n    else:\n        mfn = os.path.join(d,'s2') #marker name. it must be a directory.\n        return os.path.isdir(mfn)", "response": "True if the dir is valid and contains a dir called s2"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef discover_base_dir(start_dir):\n    '''Return start_dir or the parent dir that has the s2 marker.\n\n    Starting from the specified directory, and going up the parent\n    chain, check each directory to see if it's a base_dir (contains\n    the \"marker\" directory *s2*) and return it. Otherwise, return\n    the start_dir.\n\n    '''\n    if is_base_dir(start_dir):\n        return start_dir\n    pcl = start_dir.split('/')  #path component list\n    found_base_dir = None\n    for i in range(1, len(pcl)+1):\n        d2c = '/'.join(pcl[:-i])\n        if (d2c == ''):\n            d2c = '/'\n        if is_base_dir(d2c):\n            found_base_dir = d2c\n            break\n    return found_base_dir", "response": "Return the base_dir of the specified directory or the parent dir that contains the s2 marker."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef package_data_location():\n    '''Get the locations of themes distributed with this package.\n\n    Just finds if there are templates, and returns a dictionary with\n    the corresponding values.\n\n    '''\n    pkg_dir = os.path.split(__file__)[0]\n    pkg_data_dir = os.path.join(pkg_dir,'data')\n    return pkg_data_dir", "response": "Get the locations of themes distributed with this package."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize variables based on evidence about the directories.", "response": "def _set_directories(self):\n        '''Initialize variables based on evidence about the directories.'''\n        if self._dirs['initial'] == None:\n            self._dirs['base'] = discover_base_dir(self._dirs['run'])  \n        else:\n            self._dirs['base'] = discover_base_dir(self._dirs['initial'])  \n        # now, if 'base' is None (no base directory was found) then the only\n        # allowed operation is init \n        self._update_dirs_on_base()\n        # we might have set the directory variables fine, but the tree\n        # might not exist yet. _tree_ready is a flag for that.\n        self._tree_ready = verify_dir_structure(self._dirs['base'])\n        if self._tree_ready:\n            self._read_site_config()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _update_dirs_on_base(self):\n        '''Fill up the names of dirs based on the contents of 'base'.'''\n        if self._dirs['base'] != None:\n            for d in self._predefined_dir_names:\n                dstr = d\n                #if d == \"s2\":\n                #    dstr = '.'+d\n                self._dirs[d] = os.path.join(self._dirs['base'], dstr)", "response": "Fill up the names of dirs based on the contents of base."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitializes a directory to serve as a Simply Static site.", "response": "def init_structure(self):\n        '''Initialize a directory to serve as a Simply Static site.\n\n        Initialization is done on the base_dir (base_dir is set upon\n        __init__, so it has a value when this method is called), and it\n        is only performed if base_dir is empty and it is writeable.\n\n        This operation creates the directories, copies any existing \n        templates to the source_dir and common_dir, and creates the \n        default configuration file within the directory s2\n\n        '''\n        if self._dirs['base'] != None:  # pragma: no cover \n            #there's a base here or up the chain\n            raise ValueError   #cannot initialize\n        else:\n            if self._dirs['initial'] != None: # pragma: no cover\n                self._dirs['base'] = self._dirs['initial']\n            else:  # pragma: no cover\n                self._dirs['base'] = self._dirs['run']\n            #now proceed\n            self._update_dirs_on_base()\n            if (not dir_empty(self._dirs['base']) ) or  \\\n               (not os.access(self._dirs['base'], os.W_OK)):\n                raise ValueError\n            \n            # copy the dirs from package data to the base dir (common,themes)\n            pdl = package_data_location()\n            datadirs = glob.glob(os.path.join(pdl,\"*\"))\n            for dd in datadirs:\n                if os.path.isdir(dd):\n                    shutil.copytree(dd, os.path.join(self._dirs['base'],\n                                    os.path.split(dd)[1]))\n            # create all predefined dirs that don't exist yet in base\n            for d in self._dirs:\n                if not d in ['initial', 'run', 'base']:\n                    if not os.path.isdir(self._dirs[d]):\n                        os.mkdir(self._dirs[d])\n            self._tree_ready = verify_dir_structure(self._dirs['base']) \n            self.site_config = self._create_default_config()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_page_names(self):\n        '''Return a list of page names (directories) under source_dir.'''\n        fis = [p  for p in glob.glob(os.path.join(self._dirs['source'], \\\n                                     \"*\")) if os.path.isdir(p)]\n        fis = [os.path.split(p)[1] for p in fis ]\n        return fis", "response": "Return a list of page names under source_dir."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate(self):\n        '''Generate the whole static site.\n\n        Iterates through all existing s2 pages, rendering and writing\n        them (and copying all common files along). \n        It also generates the toc, a sitemap, and the atom feed\n        etc. (in the future it should handle tags and categories)\n\n        '''\n        if self._dirs['base'] == None or not self._tree_ready:\n            #there's NO base here or up the chain\n            raise ValueError   #cannot generate!\n\n        # wipe www dir & recreate\n        self._wipe_www_dir()#copy common files\n        #shutil.copytree(self.dirs['common'],\n        #                os.path.join(self.dirs['www'],\"common\"))\n        slist = glob.glob(os.path.join(self.dirs['common'],\"*\"))\n        for fo in slist:\n            rfn = os.path.split(fo)[1]\n            if os.path.isdir(fo):\n                shutil.copytree(fo, os.path.join(self.dirs['www'], rfn))\n            else:\n                shutil.copy(fo, self.dirs['www'])\n\n        # init atom file\n        title = self.site_config['site_title']\n        if title == '':\n            title = \"<No title>\"\n        feed = AtomFeed(title=title,\n                subtitle=self.site_config['site_subtitle'],\n                feed_url= os.path.join( self.site_config['site_url'],\"atom.xml\"),\n                url=self.site_config['site_url'],\n                author=self.site_config['default_author'])\n\n\n        themes_to_copy = []  # full paths!\n        generated_page_info = []\n        for slug in self._pages_to_generate():  #this list of pages is in reverse chrono order\n            p = s2page.Page(self, slug, isslug=True)\n            generated_page_info.append( {'slug': p.slug,\n                                         'title':p.title,\n                                         'date': p.creation_date,\n                                         'in_toc': p.in_toc })\n            t = p.theme_path\n            if not t in themes_to_copy:\n                themes_to_copy.append(t)\n            # wipe destination.\n            self._wipe_www_page(slug)\n            pg_content = p.generate() #generate page\n            # add atom entry\n            try:\n                cdd = datetime.strptime(p.creation_date, '%Y-%m-%d') # feed.add needs the dat in datetime format\n            except:\n                print \"Wrong date format in page '%s'. It should be YYYY-MM-DD.\"%p.slug\n                print \"Site Generation stopped!!  correct the date and generate again.\"\n                self._wipe_www_dir()\n                sys.exit()\n            feed.add(title= p.title,\n                     content=pg_content,\n                     content_type=\"html\",\n                     author=p.author,\n                     url=os.path.join( self.site_config['site_url'],\"atom.xml\") ,\n                     updated=cdd)\n\n        # copy themes\n        wthemesdir = os.path.join(self.dirs['www'],\"themes\")\n        os.mkdir(wthemesdir)\n        for d in themes_to_copy:\n            dname = os.path.split(d)[1]\n            destpath = os.path.join(wthemesdir, dname)\n            shutil.copytree(d, destpath)\n            # delete tpl files\n            ttr = glob.glob(os.path.join(destpath,\"*tpl\"))\n            for f in ttr:\n                os.remove(f)\n\n        # write atom file\n        atomfile= codecs.open(os.path.join(self.dirs['www'],\"atom.xml\"), \"w\", encoding=\"utf-8\", errors=\"xmlcharrefreplace\")\n        atomfile.write(feed.to_string())\n        atomfile.close()\n\n        # create front page/s\n        #print \"generated_page_info for gf \",generated_page_info\n        ff = self.site_config['fixed_frontpage']\n        if ff != None and ff != '':\n            self._set_fixed_frontpage(ff)\n        else:\n            self.generate_front(generated_page_info)\n        self._generate_site_map(generated_page_info)", "response": "Generate the whole static site."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating random page write it and return the corresponding \\ ncoptag.", "response": "def random_page(self, title=None, content=None, \n                    creation_date=None, tags=None):\n        '''Generate random page, write it and return the corresponding \\\nobject.'''\n        if title == None:\n            title = util.random_title()\n        if content == None:\n            content = util.random_md_page()\n        if creation_date == None:\n            creation_date = util.random_date()\n        if tags == None:\n            tags = []\n        # yes, we pass self as a param. It's a ref to this site, that\n        # is needed by the page\n        p = s2page.Page(self, title)\n        #here, set date and tags??\n        # date = util.random_date()\n        p.content = content\n        p.creation_date = creation_date\n        p.tags = tags\n        p.write()\n        return p"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef page_exists_on_disk(self, slug):\n        '''Return true if post directory and post file both exist.'''\n\n        r = False\n        page_dir = os.path.join(self.dirs['source'], slug)\n        page_file_name = os.path.join(page_dir, slug + '.md')\n        if os.path.isdir(page_dir):\n            if os.path.isfile(page_file_name):\n                r = True\n        return r", "response": "Return true if post directory and post file both exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads the page corresponding to the slug and rename it.", "response": "def rename_page(self, old_slug, new_title):\n        '''Load the page corresponding to the slug, and rename it.'''\n        #load page\n        p = s2page.Page(self, old_slug, isslug=True)\n        p.rename(new_title)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _wipe_www_page(self, slug):\n        '''Remove all data in www about the page identified by slug.'''\n        wd = os.path.join(self._dirs['www'], slug)\n        if os.path.isdir(wd): # pragma: no cover\n            shutil.rmtree(wd)", "response": "Remove all data in www about the page identified by slug."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn list of slugs that correspond to pages to generate.", "response": "def _pages_to_generate(self):\n        '''Return list of slugs that correspond to pages to generate.'''\n        # right now it gets all the files. In theory, It should only\n        # get what's changed... but the program is not doing that yet.\n\n        all_pages = self.get_page_names()\n        # keep only those whose status is published\n        ptg = []\n        for slug in all_pages:\n            p = s2page.Page(self, slug, isslug=True)\n            if p.published:\n                ptg.append({'slug': p.slug, 'title':p.title, 'date': p.creation_date })\n\n        # sort the ptg array in reverse chronological order of its entries.\n        sptg = sorted(ptg, key=lambda x : x['date'],reverse=True)\n        res = [ pinfo['slug'] for pinfo in sptg]\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_default_config(self):\n        '''Create and write to disk a default site config file.'''\n        # maybe I should read the default config from somewhere in the package?\n        cfg = { 'site_title': '',\n                'site_subtitle': '',\n                'default_author': '',\n                'site_url': '',\n                'default_theme': 'blog1',\n                'default_template': 'main.html.tpl',\n                'fixed_frontpage': ''\n              }\n\n\n        file_name = os.path.join(self._dirs['s2'],'config.yml')\n        f = open(file_name,'w')\n        f.write(yaml.dump(cfg,default_flow_style=False))\n        f.close()\n        return cfg", "response": "Create and write to disk a default site config file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _read_site_config(self):\n        '''Read and return the site config, as a dictionary.'''\n        file_name = os.path.join(self._dirs['s2'],'config.yml')\n        if os.path.isfile(file_name):\n            f = open(file_name,'r')\n            cfg = yaml.load(f.read())\n            f.close()\n        else:\n            cfg = self._create_default_config()\n        return cfg", "response": "Read and return the site config as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses an integer from the buffer given the interval of bytes", "response": "def parse_int(self, buff, start, end):\n        '''\n            parse an integer from the buffer given the interval of bytes\n        :param buff:\n        :param start:\n        :param end:\n        '''\n#         num = self.parse_uint(buff, start, end)\n#         l = (end - start)\n#         return self.twos_comp(num, l * 8)\n        return struct.unpack_from(self.structmap[end - start], buff, start)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering a template class for a given extension or range of extensions.", "response": "def register(template_class,*extensions):\n\t\t''' Register a template for a given extension or range of extensions '''\n\t\tfor ext in extensions:\n\t\t\text = normalize(ext)\n\t\t\tif not Lean.template_mappings.has_key(ext):\n\t\t\t\tLean.template_mappings[ext] = []\n\n\t\t\tLean.template_mappings[ext].insert(0,template_class)\n\t\t\tLean.template_mappings[ext] = unique(Lean.template_mappings[ext])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake a template class preferred for the given file extensions.", "response": "def prefer(template_class,*extensions):\n    ''' Makes a template class preferred for the given file extensions. If you\n        don't provide any extensions, it will be preferred for all its already\n        registered extensions:\n      \n        # Prefer Markdown for its registered file extensions:\n        Lean.prefer(MarkdownTemplate)\n        \n        # Prefer Markdown only for the .md elxtensions:\n        Lean.prefer(MarkdownTemplate, '.md')\n    '''\n\n    if len(extensions):\n      for (ext,klasses) in Lean.template_mappings.items():\n        if klasses.count(template_class):\n          Lean.preferred_mappings[ext] = template_class\n    else:\n      for ext in extensions:\n        ext = normalize(ext)\n        Lean.register(template_class,ext)\n        Lean.preferred_mappings[ext] = template_class"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn true when a template exists on an exact match of the provided file extension", "response": "def is_registered(ext):\n    ''' Returns true when a template exists on an exact match of the provided file extension '''\n    return Lean.template_mappings.has_key(ext.lower()) and len(Lean.template_mappings[ext])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading a new template from a file.", "response": "def load(file,line=None,options={},block=None):\n    ''' Create a new template for the given file using the file's extension\n        to determine the the template mapping.\n    '''\n\n    template_class = Lean.get_template(file)\n    if template_class:\n      return template_class(file,line,options,block)\n    else:\n      raise LookupError('No template engine registered for ' + os.path.basename(file))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlooks up a template class for the given file or file ProductId extension. Return nil when no implementation is found.", "response": "def get_template(file):\n    ''' Lookup a template class for the given filename or file\n        extension. Return nil when no implementation is found.\n    '''\n\n    pattern = str(file).lower()\n    while len(pattern) and not Lean.is_registered(pattern):\n      pattern = os.path.basename(pattern)\n      pattern = re.sub(r'^[^.]*\\.?','',pattern)\n\n  \t# Try to find a preferred engine.\n    preferred_klass = Lean.preferred_mappings[pattern] if Lean.preferred_mappings.has_key(pattern) else None\n\n    if preferred_klass:\n  \t\treturn preferred_klass\n\n  \t# Fall back to the general list of mappings\n    klasses = Lean.template_mappings[pattern]\n\n  \t# Try to find an engine which is already loaded\n    template = None\n    for klass in klasses:\n  \t\tif hasattr(klass,'is_engine_initialized') and callable(klass.is_engine_initialized):\n  \t\t\tif klass.is_engine_initialized():\n  \t\t\t\ttemplate = klass\n  \t\t\t\tbreak\n\n \t\tif template:\n \t\t\treturn template\n\n \t\t# Try each of the classes until one succeeds. If all of them fails,\n   \t# we'll raise the error of the first class.\n    first_failure = None\n\n    for klass in klasses:\n      try:\n        return klass\n      except Exception, e:\n        if not first_failure:\n          first_failure = e\n\n   \tif first_failure:\n   \t\traise Exception(first_failure)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating the Sphinx configuration and Makefile.", "response": "def generate(organization, package, destination):\n    \"\"\"Generates the Sphinx configuration and Makefile.\n\n    Args:\n        organization (str): the organization name.\n        package (str): the package to be documented.\n        destination (str): the destination directory.\n    \"\"\"\n    gen = ResourceGenerator(organization, package)\n\n    tmp = tempfile.NamedTemporaryFile(mode='w+t', delete=False)\n    try:\n        tmp.write(gen.conf())\n    finally:\n        tmp.close()\n\n    shutil.copy(tmp.name, os.path.join(destination, 'conf.py'))\n\n    tmp = tempfile.NamedTemporaryFile(mode='w+t', delete=False)\n    try:\n        tmp.write(gen.makefile())\n    finally:\n        tmp.close()\n\n    shutil.copy(tmp.name, os.path.join(destination, 'Makefile'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the first self uri with the content_type", "response": "def get_self_uri(self, content_type):\n        \"return the first self uri with the content_type\"\n        try:\n            return [self_uri for self_uri in self.self_uri_list\n                    if self_uri.content_type == content_type][0]\n        except IndexError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pretty(self):\n        \"sort values and format output for viewing and comparing in test scenarios\"\n        pretty_obj = OrderedDict()\n        for key, value in sorted(iteritems(self.__dict__)):\n            if value is None:\n                pretty_obj[key] = None\n            elif is_str_or_unicode(value):\n                pretty_obj[key] = self.__dict__.get(key)\n            elif isinstance(value, list):\n                pretty_obj[key] = []\n            elif isinstance(value, dict):\n                pretty_obj[key] = {}\n            else:\n                pretty_obj[key] = unicode_value(value)\n        return pretty_obj", "response": "sort values and format output for viewing and comparing in test scenarios"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the path of the support_files directory", "response": "def _support_directory():\n    \"\"\"Get the path of the support_files directory\"\"\"\n    from os.path import join, dirname, abspath\n    return join(dirname(abspath(__file__)), 'support_files')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new UO from the given configuration and template.", "response": "def create_uo(self, configuration=None, tpl=None, keys=None, obj_type=None):\n        \"\"\"\n        Create a new UserObject from the given template.\n\n        :param configuration:  EB configuration to use\n        :param tpl: CreateUserObject template, contain misc settings\n        :param keys: dictionary of keys, create_uo.KeyTypes. Communication keys, application key (if applicable).\n        :param obj_type: optional field for easy object type entry - required flags are computed from keys dict and tpl.\n        :return: UO - user object ready to use\n        \"\"\"\n        if configuration is not None:\n            self.configuration = configuration\n        if tpl is not None:\n            self.tpl = tpl\n        if keys is not None:\n            self.keys = keys\n        if self.keys is None:\n            self.keys = dict()\n\n        # generate comm keys if not present\n        TemplateProcessor.generate_comm_keys_if_not_present(self.keys)\n\n        # obj_type infer\n        if obj_type is not None:\n            tpl_type = CreateUO.get_uo_type(obj_type, KeyTypes.COMM_ENC in self.keys, KeyTypes.APP_KEY in self.keys)\n            self.tpl = CreateUO.set_type(self.tpl if self.tpl is not None else dict(), tpl_type)\n\n        # Create template specifications, using local config and defaults.\n        spec = CreateUO.get_template_request_spec(self.configuration)\n        if self.tpl is not None:\n            if isinstance(self.tpl, dict):\n                spec = EBUtils.update(spec, self.tpl)\n            else:\n                raise ValueError('Unknown tpl format')\n\n        # Fetch template for new UO.\n        tpl_resp = CreateUO.template_request(self.configuration, spec)\n\n        # Process the template, fill in the keys, do the crypto\n        tpl_processor = TemplateProcessor(configuration=self.configuration, keys=self.keys, tpl_response=tpl_resp)\n        tpl_req = tpl_processor.process()\n\n        # Import the initialized UO\n        self.import_resp = CreateUO.import_object(configuration=self.configuration, tpl=tpl_req)\n\n        # Build UO\n        uo = CreateUO.build_imported_object(configuration=self.configuration, tpl_import_req=tpl_req,\n                                            import_resp=self.import_resp)\n        return uo"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_default_template():\n        return {\n            \"format\": 1,\n            \"protocol\": 1,\n            \"environment\": Environment.DEV,  # shows whether the UO should be for production (live),\n                                             # test (pre-production testing), or dev (development)\n            \"maxtps\": \"one\",  # maximum guaranteed TPS\n            \"core\": \"empty\",  # how many cards have UO loaded permanently\n            \"persistence\": \"one_minute\",  # once loaded onto card, how long will the UO stay there without use\n                                          # (this excludes the \"core\")\n            \"priority\": \"default\",  # this defines a) priority when the server capacity is fully utilised and it also\n                                    # defines how quickly new copies of UO are installed (pre-empting icreasing demand)\n            \"separation\": \"time\",  # \"complete\" = only one UO can be loaded on a smartcard at one one time\n            \"bcr\": TemplateFields.yes,  # \"yes\" will ensure the UO is replicated to provide high availability for any\n                                        # possible service disruption\n            \"unlimited\": TemplateFields.yes,  #  if \"yes\", we expect the data starts with an IV to initialize decryption\n                                              #  of data - this is for communication security\n            \"clientiv\": TemplateFields.yes,  # if \"yes\", we expect the data starting with a diversification 16B for\n                                             # communication keys\n            \"clientdiv\": TemplateFields.no,\n            \"resource\": \"global\",\n            \"credit\": 32677,  # <1-32767>, a limit a seed card can provide to the EB service\n\n            TemplateFields.generation: {\n                TemplateFields.commkey: Gen.CLIENT,\n                TemplateFields.billingkey: Gen.LEGACY_RANDOM,\n                TemplateFields.appkey: Gen.LEGACY_RANDOM\n            }\n        }", "response": "Returns default template for a given set of UO resources."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn get template request specification using default values if not present in spec.", "response": "def get_template_request_spec(spec):\n        \"\"\"\n        Returns get template request specification, using default values if not present in spec.\n        If dictionary is provided, it is considered as JSON.\n        If Configuration is provided, we look at createTpl object\n        :param spec:\n        :return:\n        \"\"\"\n        dst = CreateUO.get_default_template()\n        src = None\n        if isinstance(spec, Configuration):\n            src = spec.create_tpl\n        elif isinstance(spec, dict):\n            src = spec\n        else:\n            raise ValueError('Unrecognized spec type')\n\n        if spec is not None:\n            dst = EBUtils.merge(dst, src)\n\n        return dst"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_type(spec, obj_type):\n        if spec is None:\n            raise ValueError('Spec cannot be None')\n        if TemplateFields.generation not in spec:\n            spec[TemplateFields.generation] = {}\n\n        spec[TemplateFields.generation][TemplateFields.commkey] = \\\n            Gen.CLIENT if (obj_type & (int(1) << TemplateFields.FLAG_COMM_GEN)) > 0 else Gen.LEGACY_RANDOM\n        spec[TemplateFields.generation][TemplateFields.appkey] = \\\n            Gen.CLIENT if (obj_type & (int(1) << TemplateFields.FLAG_APP_GEN)) > 0 else Gen.LEGACY_RANDOM\n        spec[TemplateFields.type] = \"%x\" % obj_type\n        return spec", "response": "Updates the type integer in the cerate UO specification."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstruct the UO type from the operation and keys provided clears bits set ib obj_type before unless None is specified to the given parameters.", "response": "def get_uo_type(obj_type, comm_keys_provided=True, app_keys_provided=True):\n        \"\"\"\n        Constructs UO type from the operation and keys provided, clears bits set ib obj_type before\n        unless None is specified to the given parameters.\n\n        :param obj_type:\n        :param comm_keys_provided:\n        :param app_keys_provided:\n        :return:\n        \"\"\"\n        if comm_keys_provided is not None and comm_keys_provided == False:\n            obj_type &= ~(int(1) << TemplateFields.FLAG_COMM_GEN)\n        elif comm_keys_provided:\n            obj_type |= (int(1) << TemplateFields.FLAG_COMM_GEN)\n\n        if app_keys_provided is not None and app_keys_provided == False:\n            obj_type &= ~(int(1) << TemplateFields.FLAG_APP_GEN)\n        elif app_keys_provided:\n            obj_type |= (int(1) << TemplateFields.FLAG_APP_GEN)\n\n        return obj_type"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds API request block.", "response": "def get_template_request(configuration, spec):\n        \"\"\"\n        Builds API request block.\n        :param configuration:\n        :param spec:\n        :return:\n        \"\"\"\n        req = RequestHolder()\n        req.api_method = 'GetUserObjectTemplate'\n        req.nonce = EBUtils.generate_nonce()\n        req.api_object = EBUtils.build_api_object(api_key=configuration.api_key, uo_id=0x1)\n        req.body = {\"data\": spec}\n        req.configuration = configuration\n        req.endpoint = configuration.endpoint_enroll\n        return req"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef template_request(configuration, spec):\n        # Template request, nonce will be regenerated.\n        req = CreateUO.get_template_request(configuration, spec)\n\n        # Do the request with retry.\n        caller = RequestCall(req)\n        resp = caller.call()\n        return resp", "response": "Calls the get template request"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a usable uo from the imported object.", "response": "def build_imported_object(configuration, tpl_import_req, import_resp):\n        \"\"\"\n        Builds uo from the imported object to the EB.\n        Imported object = result of CreateUserObject call in EB.\n        Returns usable uo - you may call ProcessData with it.\n        \"\"\"\n        if import_resp is None \\\n                or import_resp.response is None \\\n                or 'result' not in import_resp.response \\\n                or 'handle' not in import_resp.response['result']:\n            logger.info('Invalid result: %s', import_resp)\n            raise InvalidResponse('Invalid import result')\n\n        # TEST_API00000022480000300004\n        handle = import_resp.response['result']['handle']\n        handle_len = len(handle)\n\n        api_key     = handle[0:                   handle_len-10-10]\n        uo_id_str   = handle[handle_len-10-10+2:  handle_len-10]\n        uo_type_str = handle[handle_len-10+2:]\n\n        uo_id = bytes_to_long(from_hex(uo_id_str))\n        uo_type = bytes_to_long(from_hex(uo_type_str))\n\n        uo = UO(uo_id=uo_id,\n                uo_type=uo_type,\n                enc_key=tpl_import_req.keys[KeyTypes.COMM_ENC].key,\n                mac_key=tpl_import_req.keys[KeyTypes.COMM_MAC].key)\n\n        uo.configuration = configuration\n\n        # Store API key only if it differs from slot.\n        if configuration is not None and configuration.api_key != api_key:\n            uo.api_key = api_key\n\n        return uo"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset flags representing generation way accordingly - commkeys are client generated app key is server generated", "response": "def set_flags(self):\n        \"\"\"\n        Set flags representing generation way accordingly - commkeys are client generated, app key is server generated.\n        :return:\n        \"\"\"\n        offset = self.template['flagoffset']//8\n\n        # comm keys provided?\n        self.tpl_buff = bytes_transform(self.tpl_buff, offset+1, offset+2, lambda x: self.set_flag_bit(x))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions internally used in set_flags.", "response": "def set_flag_bit(self, x):\n        \"\"\"\n        Function internally used in set_flags. No multi-line lambdas in python :/\n        :param x:\n        :return:\n        \"\"\"\n        x = bytes_to_byte(x)\n        if KeyTypes.COMM_ENC in self.keys:\n            x &= ~0x8\n        if KeyTypes.APP_KEY in self.keys:\n            x &= ~0x10\n        return byte_to_bytes(x)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encrypt_template(self, enc_key, mac_key, enc_offset):\n\n        # AES-256-CBC/PKCS7Padding\n        to_encrypt = self.tpl_buff[enc_offset:]\n        encrypted = aes_enc(enc_key, PKCS7.pad(to_encrypt))\n\n        # Mac the whole buffer\n        to_mac = PKCS7.pad(self.tpl_buff[:enc_offset] + encrypted)\n        mac = cbc_mac(mac_key, to_mac)\n\n        return to_mac + mac", "response": "Encrypts the current tpl_buff according to the protocol - symmetric encryption\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_best_import_key(self, import_keys):\n        rsa2048 = None\n        rsa1024 = None\n\n        for c_key in import_keys:\n            if c_key is None \\\n                    or 'type' not in c_key \\\n                    or c_key['type'] is None:\n                logger.info(\"Invalid key: %s\", c_key)\n                continue\n\n            if rsa1024 is None and c_key['type'] == 'rsa1024':\n                rsa1024 = c_key\n            if rsa2048 is None and c_key['type'] == 'rsa2048':\n                rsa2048 = c_key\n\n        return rsa2048 if rsa2048 is not None else rsa1024", "response": "Returns the best RSA key for import from the import keys arrays."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encrypt_with_import_key(self, plain):\n\n        n, e = TemplateProcessor.read_serialized_rsa_pub_key(self.import_key['key'])\n        n_bit_size = long_bit_size(n)\n        bs = 0\n        if n_bit_size > 1024-10 and n_bit_size < 1024+10:\n            bs = 128\n        elif n_bit_size > 2048-10 and n_bit_size < 2048+10:\n            bs = 256\n        else:\n            raise CryptoError('Unknown RSA modulus size: %d', n_bit_size)\n\n        padded = PKCS15.pad(plain, bs=bs, bt=2)\n        return rsa_enc(padded, n, e)", "response": "Encrypts the given buffer with the import key."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread serialized RSA pub key and returns n e", "response": "def read_serialized_rsa_pub_key(serialized):\n        \"\"\"\n        Reads serialized RSA pub key\n        TAG|len-2B|value. 81 = exponent, 82 = modulus\n\n        :param serialized:\n        :return: n, e\n        \"\"\"\n        n = None\n        e = None\n        rsa = from_hex(serialized)\n\n        pos = 0\n        ln = len(rsa)\n        while pos < ln:\n            tag = bytes_to_byte(rsa, pos)\n            pos += 1\n            length = bytes_to_short(rsa, pos)\n            pos += 2\n\n            if tag == 0x81:\n                e = bytes_to_long(rsa[pos:pos+length])\n            elif tag == 0x82:\n                n = bytes_to_long(rsa[pos:pos+length])\n\n            pos += length\n\n        if e is None or n is None:\n            logger.warning(\"Could not process import key\")\n            raise ValueError('Public key deserialization failed')\n\n        return n, e"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the environment variable or assume a default.", "response": "def env(var_name, default=False):\n    \"\"\" Get the environment variable or assume a default, but let the user know about the error.\"\"\"\n    try:\n        value = os.environ[var_name]\n        if str(value).strip().lower() in ['false', 'no', 'off' '0', 'none', 'null']:\n            return None\n        return value\n    except:\n        from traceback import format_exc\n        msg = format_exc() + '\\n' + \"Unable to find the %s environment variable.\\nUsing the value %s (the default) instead.\\n\" % (var_name, default)\n        warnings.warn(msg)\n        return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks that the negated goals occur in positive goals.", "response": "def check_negated_goals(self,safe_variables,query):\n        ''' Create a list of variables which occur in negated goals. '''\n        variables_in_negated_goals = \\\n            [y for x in query.relations for y in list(x.variables) if x.is_negated()]\n\n        # And check them:\n        for variable in variables_in_negated_goals:\n            if not (variable in safe_variables):\n                raise NotSafeException('Query not safe because ' + \\\n                    variable.name + \\\n                    ' from a negated goal does not occur in a positive goal')\n                return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_non_equality_explicit_constraints(self,safe_variables,query):\n        ''' Checking variables which occur in explicit constraints with non equality\n        operators '''\n        # Create a list of variables which occur in explicit constraints with non\n        # equality operators\n        variables_in_constraints_with_non_equality_operators = \\\n            [y for x in query.constraints \\\n               for y in [x.get_left_side(), x.get_right_side()] \\\n               if y.is_variable() and not x.is_equality_constraint()]\n\n        for variable in variables_in_constraints_with_non_equality_operators:\n            if not (variable in safe_variables):\n                raise NotSafeException('Query not safe because ' + \\\n                    variable.name + \\\n                    ' from a non_equality comparison does not occur in a positive goal')\n                return False\n\n        return True", "response": "Checks that explicit constraints with non equality - related operators occur in the query."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_database(destroy_existing=False):\r\n    if not os.path.exists(DB_NAME):\r\n        logger.info('Create database: {0}'.format(DB_NAME))\r\n        open(DB_NAME, 'a').close()\r\n        Show.create_table()\r\n        Episode.create_table()\r\n        Setting.create_table()", "response": "Create database if it doesn t exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef magic_api(word):\r\n    result = sum(ord(x)-65 + randint(1,50) for x in word)\r\n    delta = timedelta(seconds=result)\r\n    cached_until = datetime.now() + delta\r\n    return result, cached_until", "response": "This is our magic API that we re simulating."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the value of a portfolio", "response": "def portfolio_value(portfolio, date, price='close'):\n    \"\"\"Total value of a portfolio (dict mapping symbols to numbers of shares)\n\n    $CASH used as symbol for USD\n    \"\"\"\n    value = 0.0\n    for (sym, sym_shares) in portfolio.iteritems():\n        sym_price = None\n        if sym_shares:\n            sym_price = get_price(symbol=sym, date=date, price=price)\n        # print sym, sym_shares, sym_price\n        # print last_date, k, price\n        if sym_price != None:\n            if np.isnan(sym_price):\n                print 'Invalid price, shares, value, total: ', sym_price, sym_shares, (float(sym_shares) * float(sym_price)) if sym_shares and sym_price else 'Invalid', value\n                if sym_shares:\n                    return float('nan')\n            else:\n                # print ('{0} shares of {1} = {2} * {3} = {4}'.format(sym_shares, sym, sym_shares, sym_price, sym_shares * sym_price))\n                value += sym_shares * sym_price\n                # print 'new price, value = {0}, {1}'.format(sym_price, value)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndisplaying a graph of the price history for the list of ticker symbols provided.", "response": "def chart(\n    symbols=(\"AAPL\", \"GLD\", \"GOOG\", \"$SPX\", \"XOM\", \"msft\"),\n    start=datetime.datetime(2008, 1, 1),\n    end=datetime.datetime(2009, 12, 31),  # data stops at 2013/1/1\n    normalize=True,\n    ):\n    \"\"\"Display a graph of the price history for the list of ticker symbols provided\n\n\n    Arguments:\n      symbols (list of str): Ticker symbols like \"GOOG\", \"AAPL\", etc\n      start (datetime): The date at the start of the period being analyzed.\n      end (datetime): The date at the end of the period being analyzed.\n      normalize (bool): Whether to normalize prices to 1 at the start of the time series.\n    \"\"\"\n\n    start = util.normalize_date(start or datetime.date(2008, 1, 1))\n    end = util.normalize_date(end or datetime.date(2009, 12, 31))\n    symbols = [s.upper() for s in symbols]\n    timeofday = datetime.timedelta(hours=16)\n    timestamps = du.getNYSEdays(start, end, timeofday)\n\n    ls_keys = ['open', 'high', 'low', 'close', 'volume', 'actual_close']\n    ldf_data = da.get_data(timestamps, symbols, ls_keys)\n    d_data = dict(zip(ls_keys, ldf_data))\n\n    na_price = d_data['close'].values\n    if normalize:\n        na_price /= na_price[0, :]\n    plt.clf()\n    plt.plot(timestamps, na_price)\n    plt.legend(symbols)\n    plt.ylabel('Adjusted Close')\n    plt.xlabel('Date')\n    plt.savefig('chart.pdf', format='pdf')\n    plt.grid(True)\n    plt.show()\n    return na_price"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef chart_series(series, market_sym='$SPX', price='actual_close', normalize=True):\n    series = util.make_dataframe(series)\n    start = util.normalize_date(series.index[0] or datetime.datetime(2008, 1, 1))\n    end = util.normalize_date(series.index[-1] or datetime.datetime(2009, 12, 28))\n    timestamps = du.getNYSEdays(start, end, datetime.timedelta(hours=16))\n\n    if market_sym:\n        if isinstance(market_sym, basestring):\n            market_sym = [market_sym.upper().strip()]\n        reference_prices = da.get_data(timestamps, market_sym, [price])[0]\n        reference_dict = dict(zip(market_sym, reference_prices))\n        for sym, market_data in reference_dict.iteritems():\n            series[sym] = pd.Series(market_data, index=timestamps)\n    # na_price = reference_dict[price].values\n    # if normalize:\n    #     na_price /= na_price[0, :]\n    series.plot()\n    # plt.clf()\n    # plt.plot(timestamps, na_price)\n    # plt.legend(symbols)\n    # plt.ylabel(price.title())\n    # plt.xlabel('Date')\n    # # plt.savefig('portfolio.chart_series.pdf', format='pdf')\n    plt.grid(True)\n    plt.show()\n    return series", "response": "Display a graph of the price history for the given market symbol and price."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the prices of a list of equities as a DataFrame", "response": "def price_dataframe(symbols='sp5002012',\n    start=datetime.datetime(2008, 1, 1),\n    end=datetime.datetime(2009, 12, 31),  \n    price_type='actual_close',\n    cleaner=clean_dataframe,\n    ):\n    \"\"\"Retrieve the prices of a list of equities as a DataFrame (columns = symbols)\n\n    Arguments:\n      symbols (list of str): Ticker symbols like \"GOOG\", \"AAPL\", etc\n        e.g. [\"AAPL\", \" slv \", GLD\", \"GOOG\", \"$SPX\", \"XOM\", \"msft\"]\n      start (datetime): The date at the start of the period being analyzed.\n      end (datetime): The date at the end of the period being analyzed.\n        Yahoo data stops at 2013/1/1\n    \"\"\"\n    if isinstance(price_type, basestring):\n        price_type = [price_type]\n    start = util.normalize_date(start or datetime.date(2008, 1, 1))\n    end = util.normalize_date(end or datetime.date(2009, 12, 31))\n    symbols = normalize_symbols(symbols)\n    t = du.getNYSEdays(start, end, datetime.timedelta(hours=16))\n    df = clean_dataframes(dataobj.get_data(t, symbols, price_type))\n    if not df or len(df) > 1:\n        return cleaner(df)\n    else:\n        return cleaner(df[0])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef portfolio_prices(\n    symbols=(\"AAPL\", \"GLD\", \"GOOG\", \"$SPX\", \"XOM\", \"msft\"),\n    start=datetime.datetime(2005, 1, 1),\n    end=datetime.datetime(2011, 12, 31),  # data stops at 2013/1/1\n    normalize=True,\n    allocation=None, \n    price_type='actual_close',\n    ):\n    \"\"\"Calculate the Sharpe Ratio and other performance metrics for a portfolio\n\n    Arguments:\n      symbols (list of str): Ticker symbols like \"GOOG\", \"AAPL\", etc\n      start (datetime): The date at the start of the period being analyzed.\n      end (datetime): The date at the end of the period being analyzed.\n      normalize (bool): Whether to normalize prices to 1 at the start of the time series.\n      allocation (list of float): The portion of the portfolio allocated to each equity.\n    \"\"\"    \n    symbols = normalize_symbols(symbols)\n    start = util.normalize_date(start)\n    end = util.normalize_date(end)\n    if allocation is None:\n        allocation = [1. / len(symbols)] * len(symbols)\n    if len(allocation) < len(symbols):\n        allocation = list(allocation) + [1. / len(symbols)] * (len(symbols) - len(allocation))\n    total = np.sum(allocation.sum)\n    allocation = np.array([(float(a) / total) for a in allocation])\n\n    timestamps = du.getNYSEdays(start, end, datetime.timedelta(hours=16))\n\n    ls_keys = [price_type]\n    ldf_data = da.get_data(timestamps, symbols, ls_keys)\n    d_data = dict(zip(ls_keys, ldf_data))\n\n    na_price = d_data[price_type].values\n    if normalize:\n        na_price /= na_price[0, :]\n    na_price *= allocation\n    return np.sum(na_price, axis=1)", "response": "Calculate the Sharpe Ratio and other performance metrics for a single portfolio."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the Bolinger indicator value for a given symbol.", "response": "def symbol_bollinger(symbol='GOOG',\n    start=datetime.datetime(2008, 1, 1), end=datetime.datetime(2009, 12, 31), price_type='close', cleaner=clean_dataframe,\n    window=20, sigma=1.):\n    \"\"\"Calculate the Bolinger indicator value\n\n    >>> symbol_bollinger(\"goog\", '2008-1-1', '2008-2-1')[-1]  # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE\n    -1.8782...\n    \"\"\"\n    symbols = normalize_symbols(symbol)\n    prices = price_dataframe(symbols, start=start, end=end, price_type=price_type, cleaner=cleaner)\n    return series_bollinger(prices[symbols[0]], window=window, sigma=sigma, plot=False)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the Bolinger for a list or set of symbols", "response": "def symbols_bollinger(symbols='sp5002012',\n    start=datetime.datetime(2008, 1, 1), end=datetime.datetime(2009, 12, 31), price_type='adjusted_close', cleaner=clean_dataframe,\n    window=20, sigma=1.):\n    \"\"\"Calculate the Bolinger for a list or set of symbols\n\n    Example:\n    >>> symbols_bollinger([\"AAPL\", \"GOOG\", \"IBM\", \"MSFT\"], '10-12-01', '10-12-30')[-5:]  # doctest: +NORMALIZE_WHITESPACE\n                             GOOG      AAPL       IBM      MSFT\n    2010-12-23 16:00:00  1.298178  1.185009  1.177220  1.237684\n    2010-12-27 16:00:00  1.073603  1.371298  0.590403  0.932911\n    2010-12-28 16:00:00  0.745548  1.436278  0.863406  0.812844\n    2010-12-29 16:00:00  0.874885  1.464894  2.096242  0.752602\n    2010-12-30 16:00:00  0.634661  0.793493  1.959324  0.498395\n    \"\"\"\n    symbols = normalize_symbols(symbols)\n    prices = price_dataframe(symbols, start=start, end=end, price_type=price_type, cleaner=cleaner)\n    return frame_bollinger(prices, window=window, sigma=sigma, plot=False)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the volatiliy average daily return Sharpe ratio and cumulative return", "response": "def metrics(prices, fudge=False, sharpe_days=252., baseline='$SPX'):\n    \"\"\"Calculate the volatiliy, average daily return, Sharpe ratio, and cumulative return\n\n    Arguments:\n      prices (file or basestring or iterable): path to file or file pointer or sequence of prices/values of a portfolio or equity\n      fudge (bool): Whether to use Tucker Balche's erroneous division by N or the more accurate N-1 for stddev of returns\n      sharpe_days: Number of trading days in a year. Sharpe ratio = sqrt(sharpe_days) * total_return / std_dev_of_daily_returns\n\n    Examples:\n      >>> metrics(np.array([1,2,3,4])) == {'mean': 0.61111111111111105, 'return': 4.0, 'sharpe': 34.245718429742873, 'std': 0.28327886186626583}\n      True\n      >>> metrics(portfolio_prices(symbols=['AAPL', 'GLD', 'GOOG', 'XOM'], start=datetime.datetime(2011,1,1), end=datetime.datetime(2011,12,31), allocations=[0.4, 0.4, 0.0, 0.2])\n      ...        ) == {'std': 0.0101467067654, 'mean': 0.000657261102001, 'sharpe': 1.02828403099, 'return': 1.16487261965} \n      True\n    \"\"\"\n    if isinstance(prices, basestring) and os.path.isfile(prices):\n        prices = open(prices, 'rU')\n    if isinstance(prices, file):\n        values = {}\n        csvreader = csv.reader(prices, dialect='excel', quoting=csv.QUOTE_MINIMAL)\n        for row in csvreader:\n            # print row\n            values[tuple(int(s) for s in row[:3])] = row[-1]\n        prices.close()\n        prices = [v for (k,v) in sorted(values.items())]\n        print prices\n    if isinstance(prices[0], (tuple, list)):\n        prices = [row[-1] for row in prices]\n    if sharpe_days == None:\n        sharpe_days = len(prices)\n    prices = np.array([float(p) for p in prices])\n    if not isinstance(fudge, bool) and fudge:\n        fudge = float(fudge)\n    elif fudge == True or (isinstance(fudge, float) and fudge == 0.0):\n        fudge = (len(prices) - 1.) / len(prices)\n    else:\n        fudge = 1.0\n    daily_returns = np.diff(prices) / prices[0:-1]\n    # print daily_returns\n    end_price = float(prices[-1])\n    start_price = (prices[0])\n    mean = fudge * np.average(daily_returns)\n    variance = fudge * np.sum((daily_returns - mean) * (daily_returns - mean)) / float(len(daily_returns))\n    results = {\n        'standared deviation of daily returns': math.sqrt(variance), \n        'variance of daily returns': variance, \n        'average daily return': mean, \n        'Sharpe ratio': mean * np.sqrt(sharpe_days) / np.sqrt(variance), \n        'total return': end_price / start_price,\n        'final value': end_price,\n        'starting value': start_price, \n        }\n    results['return rate'] = results['total return'] - 1.0\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute and display an event profile for multiple sets of symbols", "response": "def buy_on_drop(symbol_set=\"sp5002012\", \n            dataobj=dataobj, \n            start=datetime.datetime(2008, 1, 3), \n            end=datetime.datetime(2009, 12, 28),\n            market_sym='$SPX',\n            threshold=6,\n            sell_delay=5,\n            ):\n    '''Compute and display an \"event profile\" for multiple sets of symbols'''\n    if symbol_set:\n        if isinstance(symbol_set, basestring):\n            if symbol_set.lower().startswith('sp'):\n                symbol_set = dataobj.get_symbols_from_list(symbol_set.lower())\n            else:\n                symbol_set = [sym.stip().upper() for sym in symbol_set.split(\",\")]\n    else:\n        symbol_set = dataobj.get_symbols_from_list(\"sp5002012\")\n    if market_sym:\n        symbol_set.append(market_sym)\n\n    print \"Starting Event Study, retrieving data for the {0} symbol list...\".format(symbol_set)\n    market_data = get_clean_prices(symbol_set, dataobj=dataobj, start=start, end=end)\n    print \"Finding events for {0} symbols between {1} and {2}...\".format(len(symbol_set), start, end)\n    trigger_kwargs={'threshold': threshold}\n    events = find_events(symbol_set, market_data,  market_sym=market_sym, trigger=drop_below, trigger_kwargs=trigger_kwargs)\n\n    csvwriter = csv.writer(getattr(args, 'outfile', open('buy_on_drop_outfile.csv', 'w')), dialect='excel', quoting=csv.QUOTE_MINIMAL)\n    for order in generate_orders(events, sell_delay=sell_delay, sep=None):\n        csvwriter.writerow(order)\n\n    print \"Creating Study report for {0} events...\".format(len(events))\n    ep.eventprofiler(events, market_data, \n                         i_lookback=20, i_lookforward=20,\n                         s_filename='Event report--buy on drop below {0} for {1} symbols.pdf'.format(threshold, len(symbol_set)),\n                         b_market_neutral=True,\n                         b_errorbars=True,\n                         s_market_sym=market_sym,\n                         )\n    return events"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsimulating a sequence of trades indicated in infile and write the portfolio value time series to outfile", "response": "def trade(args):\n    \"\"\"Simulate a sequence of trades indicated in `infile` and write the portfolio value time series to `outfile`\"\"\"\n    print args\n    print vars(args)['funds']\n    print args.funds\n    portfolio = { '$CASH': args.funds }\n    print portfolio\n    csvreader = csv.reader(args.infile, dialect='excel', quoting=csv.QUOTE_MINIMAL)\n    csvwriter = csv.writer(args.outfile, dialect='excel', quoting=csv.QUOTE_MINIMAL)\n    detailed = not args.simple\n    history = []\n    portfolio_history = []\n\n    #trading_days = du.getNYSEdays(datetime.datetime(2010,01,01), datetime.datetime(2012,01,01), datetime.timedelta(hours=16))\n    for row in csvreader:\n        # print '-'*30 + ' CSV Row ' + '-'*30\n        # print ', '.join(row)\n        trade_date = datetime.datetime(*[int(i) for i in (row[:3] + [16])])\n\n        if history:\n            last_date = datetime.datetime(*(history[-1][:3] + [16])) + datetime.timedelta(days=1)\n            # print (date.date() - last_date).days\n            while (trade_date - last_date).days > 0:\n                print 'Filling in the blanks for {0}'.format(last_date)\n                value = portfolio_value(portfolio, last_date, price='close')\n                print '   the portfolio value on that date is: {0}'.format(value)\n                assert(value != None)\n                # NaN for porfolio value indicates a non-trading day\n                if not np.isnan(value):\n                    history += [[last_date.year, last_date.month, last_date.day] \n                                + ([\"$CASH\", \"0.0\", \"0.0\"] if args.trades else [])\n                                + ([json.dumps(portfolio)] if detailed else []) + [value]]\n                    portfolio_history += [datetime.datetime(last_date.year, last_date.month, last_date.day, 16), portfolio]\n                    csvwriter.writerow(history[-1])\n                last_date += datetime.timedelta(days=1)\n    \n        trade_symbol = row[3]\n        trade_shares = float(row[5])\n        trade_sign = 1 - 2 * int(row[4].strip().upper()[0]=='S')\n        # If this the first row in the CSV and the symbol is $CASH then it represents an initial deposit (Sell) or withdrawal (Buy) of cash\n        # otherwise se need to add or deduct whatever security was bought or sold.\n        # if not (trade_symbol == '$CASH') or history:\n        portfolio[trade_symbol] = portfolio.get(trade_symbol, 0) + trade_sign * trade_shares\n        trade_price = get_price(symbol=trade_symbol, date=trade_date, price='close')\n        while trade_price == None or np.isnan(trade_price) or float(trade_price) == float('nan'):\n            trade_date += datetime.timedelta(days=1)\n            trade_price = get_price(symbol=trade_symbol, date=trade_date, price='close')\n        #print trade_date, trade_symbol, trade_sign, trade_shares, trade_price\n        if trade_price and trade_shares and trade_sign in (-1, 1):\n            print 'spending cash: {0}'.format(trade_sign * trade_shares * trade_price)\n            portfolio['$CASH'] = portfolio.get('$CASH',0.) - trade_sign * trade_shares * trade_price\n        else:\n            print 'ERROR: bad price, sign, shares: ', trade_price, trade_sign, trade_shares\n        history += [[trade_date.year, trade_date.month, trade_date.day, trade_symbol, trade_sign, trade_shares] + ([json.dumps(portfolio)] if detailed else []) + [portfolio_value(portfolio, trade_date, price='close')]]\n        csvwriter.writerow(history[-1])\n    return metrics(history)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_orders(events, sell_delay=5, sep=','):\n    sell_delay = float(unicode(sell_delay)) or 1\n    for i, (t, row) in enumerate(events.iterrows()):\n        for sym, event in row.to_dict().iteritems():\n            # print sym, event, type(event)\n            # return events\n            if event and not np.isnan(event):\n                # add a sell event `sell_delay` in the future within the existing `events` DataFrame\n                # modify the series, but only in the future and be careful not to step on existing events\n                if event > 0:\n                    sell_event_i = min(i + sell_delay, len(events) - 1)\n                    sell_event_t = events.index[sell_event_i]\n                    sell_event = events[sym][sell_event_i]\n                    if np.isnan(sell_event):\n                        events[sym][sell_event_t] = -1\n                    else:\n                        events[sym][sell_event_t] += -1\n                order = (t.year, t.month, t.day, sym, 'Buy' if event > 0 else 'Sell', abs(event) * 100)\n                if isinstance(sep, basestring):\n                    yield sep.join(order)\n                yield order", "response": "Generate CSV orders based on events indicated in a DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef orders_from_events(events, sell_delay=5, num_shares=100):\n\n    buy = events.copy() * num_shares\n    sell = -1 * pd.DataFrame(buy.copy().values[:-sell_delay], index=buy.index[sell_delay:], columns=buy.columns)\n    sell = pd.concat([0 * buy.iloc[:sell_delay], sell])\n    for i in range(sell_delay):\n        sell.iloc[-1] -= buy.iloc[-sell_delay + i]\n    orders = buy + sell\n    return orders", "response": "Create a DataFrame of orders based on events"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef portfolio_from_orders(orders, funds=1e5, price_type='close'):\n    portfolio = orders.copy()\n    prices = price_dataframe(orders.columns, start=orders.index[0], end=orders.index[-1],\n                             price_type=price_type, cleaner=clean_dataframe)\n    portfolio[\"$CASH\"] = funds - (orders * prices).sum(axis=1).cumsum()\n    portfolio[\"total_value\"] = portfolio[\"$CASH\"] + (orders.cumsum() * prices).sum(axis=1)\n    return portfolio", "response": "Create a DataFrame of portfolio holdings from a list of orders."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clipping_params(ts, capacity=100):\n    ts_sorted = ts.order(ascending=False)\n    i, t0, t1, integral = 1, None, None, 0\n    while integral <= capacity and i+1 < len(ts):\n        i += 1\n        t0_within_capacity = t0\n        t1_within_capacity = t1\n        t0 = min(ts_sorted.index[:i])\n        t1 = max(ts_sorted.index[:i])\n        integral = integrated_change(ts[t0:t1])\n        print i, t0, ts[t0], t1, ts[t1], integral\n    if t0_within_capacity and t1_within_capacity:\n        return t0_within_capacity, t1_within_capacity", "response": "Returns start and end indices that clips the price or value of a time series."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_events(symbols, d_data, market_sym='$SPX', trigger=drop_below, trigger_kwargs={}):\n    '''Return dataframe of 1's (event happened) and NaNs (no event), 1 column for each symbol'''\n\n    df_close = d_data['actual_close']\n    ts_market = df_close[market_sym]\n\n    print \"Finding `{0}` events with kwargs={1} for {2} ticker symbols\".format(trigger.func_name, trigger_kwargs, len(symbols))\n    print 'Trigger docstring says:\\n\\n{0}\\n\\n'.format(trigger.func_doc)\n\n    # Creating an empty dataframe\n    df_events = copy.deepcopy(df_close)\n    df_events = df_events * np.NAN\n\n    # Time stamps for the event range\n    ldt_timestamps = df_close.index\n\n    for s_sym in symbols:\n        if s_sym == market_sym:\n            continue\n        for i in range(1, len(ldt_timestamps)):\n            # Calculating the returns for this timestamp\n            kwargs = dict(trigger_kwargs)\n            kwargs['price_today'] = df_close[s_sym].ix[ldt_timestamps[i]]\n            kwargs['price_yest'] = df_close[s_sym].ix[ldt_timestamps[i - 1]]\n            kwargs['return_today'] = (kwargs['price_today'] / (kwargs['price_yest'] or 1.)) - 1\n            kwargs['market_price_today'] = ts_market.ix[ldt_timestamps[i]]\n            kwargs['market_price_yest'] = ts_market.ix[ldt_timestamps[i - 1]]\n            kwargs['market_return_today'] = (kwargs['market_price_today'] / (kwargs['market_price_yest'] or 1.)) - 1\n\n            if trigger(**kwargs):\n                df_events[s_sym].ix[ldt_timestamps[i]] = 1\n    print 'Found {0} events where priced dropped below {1}.'.format(df_events.sum(axis=1).sum(axis=0), trigger_kwargs['threshold'])\n    return df_events", "response": "Find events for each symbol in symbols."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndownload file from http url link", "response": "def download_file(save_path, file_url):\n    \"\"\" Download file from http url link \"\"\"\n\n    r = requests.get(file_url)  # create HTTP response object\n\n    with open(save_path, 'wb') as f:\n        f.write(r.content)\n\n    return save_path"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_banners(slug, **kwargs):\n    place = BannerPlace.objects.published().get(slug=slug)\n    banners = place.banner_set.published().order_by('sort').all()\n    rendered = []\n    for banner in banners:\n        renderer = get_renderer(banner)\n        rendered.append(renderer(banner))\n    return {'rendered': rendered, 'banners': banners, 'data': kwargs}", "response": "\u041f\u0440\u0438\u043c\u0435\u0440 \u0438\u0437 \u043c\u0435\u0441\u0442\u0430\u043d\u043e\u0433\u043e \u0441\u0438\u043c\u0432\u043e\u043b\u044c\u043d\u044b\u0439 \u043a\u043e\u0434 \u0431\u0430\u043d\u0435\u0440\u0435\u0440\u0430 \u043e\u0431\u0440\u0430\u0436\u0430\u0435\u0442"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a Storage value as a list.", "response": "def getlist(self, key):\n        \"\"\"Returns a Storage value as a list.\n\n        If the value is a list it will be returned as-is.\n        If object is None, an empty list will be returned.\n        Otherwise, `[value]` will be returned.\n\n        Example output for a query string of `?x=abc&y=abc&y=def`::\n\n            >>> request = Storage()\n            >>> request.vars = Storage()\n            >>> request.vars.x = 'abc'\n            >>> request.vars.y = ['abc', 'def']\n            >>> request.vars.getlist('x')\n            ['abc']\n            >>> request.vars.getlist('y')\n            ['abc', 'def']\n            >>> request.vars.getlist('z')\n            []\n\n        \"\"\"\n        \n        value = self.get(key, [])\n        if value is None or isinstance(value, (list, tuple)):\n            return value\n        else:\n            return [value]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getfirst(self, key, default=None):\n        \n        values = self.getlist(key)\n        return values[0] if values else default", "response": "Returns the first value of a list or the value itself when given a\n        request. vars style key."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the last value of a list or value itself when given a request. vars style key.", "response": "def getlast(self, key, default=None):\n        \"\"\"Returns the last value of a list or value itself when given a\n        `request.vars` style key.\n\n        If the value is a list, the last item will be returned;\n        otherwise, the value will be returned as-is.\n\n        Simulated output with a query string of `?x=abc&y=abc&y=def`::\n\n            >>> request = Storage()\n            >>> request.vars = Storage()\n            >>> request.vars.x = 'abc'\n            >>> request.vars.y = ['abc', 'def']\n            >>> request.vars.getlast('x')\n            'abc'\n            >>> request.vars.getlast('y')\n            'def'\n            >>> request.vars.getlast('z')\n\n        \"\"\"\n        \n        values = self.getlist(key)\n        return values[-1] if values else default"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef popitem(self):\n        all_items = self.items()\n        removed_item = random.choice(all_items)\n        self[removed_item[0]] = None\n        return removed_item", "response": "Unlike dict. popitem this is actually random"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nserialize values like date and time. Respect other values.", "response": "def _serialize_value(self, value):\n        \"\"\"\n        Serialize values like date and time. Respect other values:\n        :return:\n        \"\"\"\n\n        if isinstance(value, datetime.datetime):\n            return value.strftime(self.datetime_format)\n        elif isinstance(value, datetime.date):\n            return value.strftime(self.date_format)\n        elif isinstance(value, datetime.time):\n            return value.strftime(self.time_format)\n        return text_type(value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of TrackingReportColumn builders for the column names and column values of the current request.", "response": "def get_report_column_builders(self, request, model):\n        \"\"\"\n        Returns builders for column names and column values\n          for the elements, being each element like this:\n          1. A header fetcher: will retrieve the title for the column.\n          2. A value fetcher: will retrieve the value for the column.\n        :param model: model to analyze and fetch.\n        :param request: current request being processed.\n        :return: A list of TrackingReportColumn pairs.\n        \"\"\"\n\n        meta = model._meta\n        field_names = set(field.name for field in meta.fields)\n        list_report = self.get_list_report(request) or field_names\n        _s = self._cell_value\n\n        def header(list_report_item):\n            if list_report_item in field_names:\n                return text_type(capfirst(meta.get_field(list_report_item).verbose_name))\n            else:\n                if isinstance(list_report_item, string_types):\n                    # model member (method or property)\n                    model_member = getattr(model, list_report_item, None)\n                    # method check\n                    if functions.is_method(model_member, functions.METHOD_UNBOUND|functions.METHOD_INSTANCE):\n                        return text_type(capfirst(getattr(model_member, 'short_description',\n                                                          list_report_item.replace('_', ' '))))\n                    # property check\n                    if isinstance(model_member, property):\n                        if model_member.getter:\n                            return text_type(capfirst(getattr(model_member, 'short_description',\n                                                              list_report_item.replace('_', ' '))))\n                        raise ValueError('Property item in `list_report` member, or returned by `get_list_report()` '\n                                         'must be readable')\n                    # report member (method)\n                    report_member = getattr(self, list_report_item, None)\n                    if functions.is_method(report_member, functions.METHOD_UNBOUND|functions.METHOD_INSTANCE):\n                        return text_type(capfirst(getattr(report_member, 'short_description',\n                                                          list_report_item.replace('_', ' '))))\n\n                # regular callable\n                if callable(list_report_item):\n                    return text_type(capfirst(getattr(list_report_item, 'short_description', None) or\n                                              getattr(list_report_item, '__name__', None) or '<unknown>'))\n\n                # invalid value\n                raise TypeError('Item in `list_report` member, or returned by `get_list_report()` must be a model '\n                                'field name, or model instance method, current report''s instance method, or '\n                                'a regular callable')\n\n        def fetcher(list_report_item):\n            if list_report_item in field_names:\n                return lambda obj: _s(getattr(obj, list_report_item))\n            else:\n                if isinstance(list_report_item, string_types):\n                    # model member (method or property)\n                    model_member = getattr(model, list_report_item, None)\n                    # method check\n                    if functions.is_method(model_member, functions.METHOD_UNBOUND|functions.METHOD_INSTANCE):\n                        return lambda obj: _s(getattr(obj, list_report_item)())\n                    # property check\n                    if isinstance(model_member, property):\n                        if model_member.getter:\n                            return lambda obj: _s(getattr(obj, list_report_item))\n                        raise ValueError('Property item in `list_report` member, or returned by `get_list_report()` '\n                                         'must be readable')\n                    # report member (method)\n                    report_member = getattr(self, list_report_item, None)\n                    if functions.is_method(report_member, functions.METHOD_UNBOUND|functions.METHOD_INSTANCE):\n                        return lambda obj: _s(getattr(self, list_report_item)(obj))\n\n                # regular callable\n                if callable(list_report_item):\n                    return lambda obj: _s(list_report_item(obj))\n\n                # invalid value\n                raise TypeError('Item in `list_report` member, or returned by `get_list_report()` must be a model '\n                                'field name, or model instance method, current report''s instance method, or '\n                                'a regular callable')\n\n        return [TrackingReportColumn(header=header(item), fetcher=fetcher(item)) for item in list_report]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a TrackingReportResult with the headers and rows.", "response": "def get_report_data_rows(self, request, queryset):\n        \"\"\"\n        Using the builders for the queryset model, iterates over the queryset to generate a result\n          with headers and rows. This queryset must be the exact same received in the .process method,\n          which tells us that this function should be called inside .process implementation.\n        :param queryset: Provided queryset\n        :return: Result with headers and rows\n        \"\"\"\n\n        model = queryset.model\n        meta = model._meta\n        field_names = set(field.name for field in meta.fields)\n        list_report = self.get_list_report(request) or field_names\n        queried_field_named = [l for l in list_report if l in field_names] or ['id']\n\n        columns = self.get_report_column_builders(request, model)\n        headers = [column.header for column in columns]\n        rows = []\n        for instance in queryset.only(*queried_field_named):\n            rows.append([column.fetcher(instance) for column in columns])\n\n        return TrackingReportResult(headers=headers, values=rows)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the generated file content.", "response": "def get_attachment_content(self, request, queryset):\n        \"\"\"\n        Returns the generated file content.\n        :param request: The request being processed.\n        :param queryset: The model class being processed.\n        :return: The report content (usually expressed in raw bytes but could be unicode as well).\n        \"\"\"\n\n        return self.dump_report_content(request, self.get_report_data_rows(request, queryset))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process(self, request, queryset, period):\n\n        response = HttpResponse(content=self.get_attachment_content(request, queryset) or '',\n                                content_type=self.get_attachment_content_type(request) or 'text/plain')\n        response['Content-Disposition'] = 'attachment; filename=' + (self.get_attachment_filename(request, period) or\n                                                                     'report.txt')\n        return response", "response": "Will process the request and return an appropriate Response object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dump_report_content(self, request, result):\n\n        output = StringIO()\n        writer = csv.writer(output, **self.csv_kwargs)\n        writer.writerows([result.headers] + result.values)\n        return output.getvalue()", "response": "Dumps the content of the result to a string suitable to be written on a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nevaluates an option value and returns the value of type str bool int float or list", "response": "def eval_option_value(self, option):\n        \"\"\" Evaluates an option\n        :param option: a string\n        :return: an object of type str, bool, int, float or list\n        \"\"\"\n        try:\n            value = eval(option, {}, {})\n        except (SyntaxError, NameError, TypeError):\n            return option\n        if type(value) in (str, bool, int, float):\n            return value\n        elif type(value) in (list, tuple):\n            for v in value:\n                if type(v) not in (str, bool, int, float):\n                    self._write_error(\"Value of element of list object has wrong type %s\" % v)\n            return value\n        return option"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_options_from_file(self, options):\n        options_file = self.python_options.get('options_file') or self._variables.get('OPTIONS_FILE')\n        if not options_file:\n            self._variables['options_file_path'] = None\n            return\n        options_path = self._variables.get('OPTIONS_PATH')\n        options_dict, options_file_path = None, None\n        try:\n            if options_path or os.path.isabs(options_file):\n                options_file_path, options_dict = read_configuration(options_file, options_path)\n            else:\n                for path in (os.getcwd(), os.path.expanduser('~/.clingon'), '/etc/clingon/'):\n                    try:\n                        options_file_path, options_dict = read_configuration(options_file, path)\n                        break\n                    except RuntimeError as e:\n                        error = e\n        except (RuntimeError, TypeError) as e:\n            self._write_error(str(e))\n        self._variables['options_file_path'] = options_file_path\n        if options_dict:\n            for k in list(self.python_options):\n                default = options_dict.get(k)\n                if default is not None:\n                    options[k] = self.eval_option_value(default)\n        else:\n            self._write_error(str(error))", "response": "Search and read a configuration file to override options."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse command line parameters and stores them in the internal state", "response": "def start(self, param_string=None):\n        \"\"\" Parses command line parameters\n            A string can be passed to simulate a cli for test purpose\n        \"\"\"\n        external_opt = {}\n        self.get_options_from_environ(external_opt)\n        self.get_options_from_file(external_opt)\n        # construct optional args, required args and variable args as we find then in the command line\n        optargs = {}\n        reqargs, varargs = [], []\n\n        # get parameters from command line, or from parameter string (latter essentially for tests)\n        if param_string is None:\n            argv = sys.argv[1:]\n        else:\n            import shlex\n            argv = shlex.split(param_string)\n\n        self._eval_variables()\n        i = 0\n        while i < len(argv):\n            # get next parameter\n            x = argv[i]\n            # check for help\n            if x in self._help_options:\n                self._print_help()\n                return\n            # check for version\n            if x in self._version_options and self._get_variable('VERSION'):\n                self._print_version()\n                return\n            # parameter is an option\n            if x in self.options:\n                o_x = self.options[x]\n                oe_x = self.options_equ[x]\n                # check for duplicates\n                if oe_x in optargs:\n                    raise RunnerError(\"Option '%s' found twice\" % x)\n                # proceed with lists or tuples\n                if isinstance(o_x, (list, tuple)):\n                    argpos = i\n                    optargs[oe_x] = []\n                    i += 1\n                    # iterate till end of parameters list, or to next option occurrence\n                    while i < len(argv) and argv[i] not in self.options:\n                        # try to convert element to expected type, then store it\n                        try:\n                            optargs[oe_x].append(type(o_x[0])(argv[i]))\n                        except ValueError:\n                            raise RunnerErrorWithUsage(\"Argument %d of option %s has wrong type (%s expected)\" %\n                                                       (i - argpos, x, self._format_type(o_x[0])))\n                        # if no expected type, just store element\n                        except IndexError:\n                            optargs[oe_x].append(argv[i])\n                        i += 1\n                    # check that list option is not empty\n                    if not len(optargs[oe_x]) and not len(o_x):\n                        raise RunnerErrorWithUsage(\"Option '%s' should be followed by a list of values\" % x)\n                    # check number of element if default list/tuple is not empty\n                    if len(o_x) and len(optargs[oe_x]) != len(o_x):\n                        raise RunnerErrorWithUsage(\"Option '%s' should be followed by a list of %d %s, found %d\" %\n                                                   (x, len(o_x), self._format_type(o_x[0]), len(optargs[oe_x])))\n                # proceed boolean\n                elif type(o_x) is bool:\n                    optargs[oe_x] = True\n                    i += 1\n                # proceed other types (string, integer, float)\n                else:\n                    i += 1\n                    # check that option is given a value\n                    if i >= len(argv) or argv[i] in self.options:\n                        raise RunnerErrorWithUsage(\"Option '%s' should be followed by a %s\" %\n                                                   (x, self._format_type(o_x)))\n                    # try to convert element to expected type, then store it\n                    try:\n                        optargs[oe_x] = type(o_x)(argv[i])\n                    except ValueError:\n                        raise RunnerErrorWithUsage(\"Argument of option %s has wrong type (%s expected)\" %\n                                                   (x, self._format_type(o_x)))\n                    i += 1\n            # parameter may be a required or a variable parameter, or unrecognized\n            else:\n                if x.startswith('-'):\n                    raise RunnerErrorWithUsage(\"Unrecognized option '%s'\" % argv[i])\n                elif len(reqargs) < len(self.reqargs):\n                    reqargs.append(argv[i])\n                elif self.varargs:\n                    varargs.append(argv[i])\n                else:\n                    raise RunnerErrorWithUsage(\"Unrecognized parameter '%s'\" % argv[i])\n                i += 1\n        # check number of required parameters\n        if self.reqargs and len(reqargs) < len(self.reqargs):\n            raise RunnerErrorWithUsage(\"Too few parameters (%d required)\" % len(self.reqargs))\n        # merge required, optional args and options in allargs\n        options = OrderedDict(self.python_options)\n        options.update(external_opt)\n        options.update(optargs)\n        allargs = reqargs\n        allargs.extend(options.values())\n        allargs.extend(varargs)\n        if DEBUG:\n            print('clize call parameters:', allargs)\n        # all parameters are filled, call wrapped function\n        return self.func(*allargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints the help for the current instance of the class.", "response": "def _print_help(self):\n        \"\"\"\n        Help is automatically generated from the __doc__ of the subclass if present\n        and from the names of the args of run(). Therefore args names selection\n        is more important than ever here !\n        \"\"\"\n        options = self._print_usage('\\n  ', file=sys.stdout)\n        if self.docstring:\n            print()\n            try:\n                doc_string = self.docstring.format(**self._variables)\n            except KeyError:\n                doc_string = self.docstring\n            for doc in doc_string.split('\\n'):\n                doc = doc.strip()\n                if len(doc) > 2:\n                    print(textwrap.fill(textwrap.dedent(doc).strip(),\n                                        width=80, initial_indent='  ',\n                                        subsequent_indent='   '))\n        print()\n        if options:\n            print('Options:')\n            width = max(len(k) for k in self._options)\n            for x, t in self._options.items():\n                print(self._format_option(x, t, width))\n            if self._get_variable('VERSION'):\n                print('{0:{1}}'.format(self._version_options[0], width), end=' ')\n                print('| ' + ' | '.join(self._version_options[1:]), 'print version',\n                      '(%s)' % self._get_variable('VERSION'))\n            print('{0:{1}}'.format(self._help_options[0], width), end=' ')\n            print('| ' + ' | '.join(self._help_options[1:]), 'print this help')\n            print()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef defer(callable):\n    '''Defers execution of the callable to a thread.\n\n    For example:\n\n        >>> def foo():\n        ...     print('bar')\n        >>> join = defer(foo)\n        >>> join()\n    '''\n    t = threading.Thread(target=callable)\n    t.start()\n    return t.join", "response": "Defer execution of the callable to a thread."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclose all file descriptors.", "response": "def close_fds():\n    '''Close extraneous file descriptors.\n\n    On Linux, close everything but stdin, stdout, and stderr. On Mac, close\n    stdin, stdout, and stderr and everything owned by our user id.\n    '''\n    def close(fd):\n        with ignored(OSError):\n            os.close(fd)\n\n    if sys.platform == 'linux':\n        fd_dir = '/proc/self/fd'\n        fds = set(map(int, os.listdir(fd_dir)))\n        for x in (fds - {0, 1, 2}):\n            close(x)\n\n    elif sys.platform == 'darwin':\n        uid = os.getuid()\n        fd_dir = '/dev/fd'\n        fds = set(map(int, os.listdir(fd_dir)))\n        for x in (fds - {0, 1, 2}):\n            path = '/dev/fd/' + str(x)\n            if not os.access(path, os.R_OK):\n                continue\n            stat = os.fstat(x)\n            if stat.st_uid != uid:\n                continue\n            close(x)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_over():\n    '''Calls :py:func:`os.exec` with executable and args derived from sys.'''\n    path = sys.executable\n    args = [path] + sys.argv\n\n    # And the rest, after a sudden wet thud, was silence.\n    os.execv(path, args)", "response": "Calls os. exec with executable and args derived from sys."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbinding an extension to the processor.", "response": "def bind(self, extension: Extension) -> 'DictMentor':\n        \"\"\"\n        Add any predefined or custom extension.\n\n        Args:\n            extension: Extension to add to the processor.\n\n        Returns:\n            The DictMentor itself for chaining.\n        \"\"\"\n        if not Extension.is_valid_extension(extension):\n            raise ValueError(\"Cannot bind extension due to missing interface requirements\")\n        self._extensions.append(extension)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef augment(self, dct: NonAugmentedDict,\n                document: Optional[YamlDocument] = None) -> AugmentedDict:\n        \"\"\"\n        Augments the given dictionary by using all the bound extensions.\n\n        Args:\n            dct: Dictionary to augment.\n            document: The document the dictionary was loaded from.\n\n        Returns:\n            The augmented dictionary.\n        \"\"\"\n        Validator.instance_of(dict, raise_ex=True, dct=dct)\n\n        # Apply any configured loader\n        for instance in self._extensions:\n            nodes = list(dict_find_pattern(dct, **instance.config()))\n            for parent, k, val in nodes:\n                parent.pop(k)\n                fragment = instance.apply(\n                    ExtensionContext(\n                        mentor=self,\n                        document=document or dct,\n                        dct=dct,\n                        parent_node=parent,\n                        node=(k, val)\n                    )\n                )\n                if fragment is not None:\n                    parent.update(fragment)\n\n        return dct", "response": "Augments the given dictionary by applying all the extensions."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads the yaml document into a python dictionary.", "response": "def _load_plain_yaml(cls, _yaml: YamlDocument) -> Any:\n        \"\"\"\n        Will just load the yaml without executing any extensions. You will get the plain dictionary\n        without augmentation. It is equivalent to just perform `yaml.safe_load`. Besides that you\n        can specify a stream, a file or just a string that contains yaml/json data.\n\n        Examples:\n            >>> jstr = '{\"a\":1, \"b\": {\"c\": 3, \"d\": \"d\"}}'\n            >>> d = DictMentor._load_plain_yaml(jstr)\n            >>> d['a'], d['b']['c'], d['b']['d']\n            (1, 3, 'd')\n\n        Args:\n            yaml_: Whether a stream (e.g. file pointer), a file name of an existing file or string\n                containing yaml/json data.\n\n        Returns:\n            Returns the yaml_ data as a python dictionary.\n        \"\"\"\n        if Validator.is_stream(yaml_=_yaml):\n            return yaml.safe_load(_yaml)\n        if Validator.is_file(yaml_=_yaml):\n            with open(_yaml) as fhandle:  # type: ignore\n                return yaml.safe_load(fhandle)\n        if Validator.instance_of(target_type=str, yaml_=_yaml):\n            return yaml.safe_load(_yaml)\n\n        raise TypeError(\"Argument '_yaml' is whether a stream, nor a file, nor a string\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads a partial yaml and augments it.", "response": "def load_yaml(self, _yaml: YamlDocument) -> AugmentedDict:\n        \"\"\"\n        Loads a partial yaml and augments it. A partial yaml in this context is a yaml that is\n        syntactically correct, but is not yet complete in terms of content.\n        The yaml will be completed by augmenting with some external resources and/or executing so\n        called extensions.\n\n        Args:\n            _yaml: Whether a stream (e.g. file pointer), a file name of an existing file or string\n                containing yaml data.\n\n        Returns:\n            Returns the yaml data as an augmented python dictionary.\n        \"\"\"\n        return self.augment(self._load_plain_yaml(_yaml), document=_yaml)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Date(value):\n    from datetime import datetime\n    try:\n        return datetime(*reversed([int(val) for val in value.split('/')]))\n    except Exception as err:\n        raise argparse.ArgumentTypeError(\"invalid date '%s'\" % value)", "response": "Custom type for managing dates in the command - line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(clients_num, clients_host, clients_port, people_num, throttle):\n    res = []\n    for number in range(clients_num):\n        sc = EchoClient({\n            'id': number,\n            'listen_bind_ip': clients_host,\n            #'multicast_bind_ip': \"127.0.0.1\",\n            'listen_port': clients_port + number\n        })\n        people = []\n        for person_number in range(people_num):\n            people.append(Person(id=person_number))\n        wrapper = WrapperEchoClient({\n            'client': sc,\n            'people': people,\n            'throttle': throttle\n        })\n        res.append(wrapper)\n\n    return res, cmd_line", "response": "Prepare clients to execute"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _packet_loop(self):\n        while self._is_running:\n            # Only wait if there are no more packets in the inbox\n            if self.inbox.empty() \\\n                    and not self.new_packet.wait(self._packet_timeout):\n                continue\n            ip, port, packet = self.inbox.get()\n            if self.inbox.empty():\n                self.new_packet.clear()\n            self.debug(u\"{}\".format(packet))\n\n            if packet.header.message_type == MsgType.CONFIG:\n                self._do_config_packet(packet, ip, port)\n            elif packet.header.message_type == MsgType.UPDATE:\n                self._do_update_packet(packet)", "response": "Loop over the inbox and process packets."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef strlify(a):\n    '''\n    Used to turn hexlify() into hex string.\n\n    Does nothing in Python 2, but is necessary for Python 3, so that\n    all inputs and outputs are always the same encoding.  Most of the\n    time it doesn't matter, but some functions in Python 3 brick when\n    they get bytes instead of a string, so it's safer to just\n    strlify() everything.\n\n    In Python 3 for example (examples commented out for doctest):\n#   >>> hexlify(unhexlify(\"a1b2c3\"))\n    b'a1b2c3'\n#   >>> b'a1b2c3' == 'a1b2c3'\n    False\n#   >>> strlify(hexlify(unhexlify(\"a1b2c3\")))\n    'a1b2c3'\n\n    Whereas in Python 2, the results would be:\n#   >>> hexlify(unhexlify(\"a1b2c3\"))\n    'a1b2c3'\n#   >>> b'a1b2c3' == 'a1b2c3'\n    True\n#   >>> strlify(hexlify(unhexlify(\"a1b2c3\")))\n    'a1b2c3'\n\n    Safe to use redundantly on hex and base64 that may or may not be\n    byte objects, as well as base58, since hex and base64 and base58\n    strings will never have \"b'\" in the middle of them.\n\n    Obviously it's NOT safe to use on random strings which might have\n    \"b'\" in the middle of the string.\n\n    Use this for making sure base 16/58/64 objects are in string\n    format.\n\n    Use normalize_input() below to convert unicode objects back to\n    ascii strings when possible.\n    '''\n\n    if a == b'b' or a == 'b':\n        return 'b'\n\n    return str(a).rstrip(\"'\").replace(\"b'\",\"\",1).replace(\"'\",\"\")", "response": "Convert a string into a base - 16 - 58 - 64 string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nnormalizing the input string to the correct format.", "response": "def normalize_input(input,preferunicodeoverstring=False,nfconly=False):\n    '''\n    This looks dirty as crap, but the try/catch failure series goes in\n    the correct order and it's a lot easier to use this most of the\n    time, and it works for every situation I needed to use it in. That\n    said, I'm kind of hoping nobody ever sees this...\n    '''\n\n    if nfconly:\n        try:\n            return unhexlify(hexlify(unicodedata.normalize('NFC',unicode(input)).encode('utf-8')))\n        except:\n            try:\n                return unhexlify(hexlify(unicodedata.normalize('NFC',input).encode('utf-8'))).decode('utf-8')\n            except:\n                try:\n                    return unhexlify(hexlify(unicodedata.normalize('NFC',unicode(input,'utf-8')).encode('utf-8')))\n                except:\n                    raise Exception(\"Unable to NFC normalize.\")\n    if sys.version_info[0] == 2:\n        input = unicode(input)\n    if preferunicodeoverstring:\n        return unicodedata.normalize('NFKD',input)\n    else:\n        try:\n            return str(unicodedata.normalize('NFKD',input))\n        except:\n            return unicodedata.normalize('NFKD',input)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndecorate request parameters to transform them into Selenol objects.", "response": "def selenol_params(**kwargs):\n    \"\"\"Decorate request parameters to transform them into Selenol objects.\"\"\"\n    def params_decorator(func):\n        \"\"\"Param decorator.\n\n        :param f: Function to decorate, typically on_request.\n        \"\"\"\n        def service_function_wrapper(service, message):\n            \"\"\"Wrap function call.\n\n            :param service: SelenolService object.\n            :param message: SelenolMessage request.\n            \"\"\"\n            params = {k: f(service, message) for k, f in kwargs.items()}\n            return func(service, **params)\n        return service_function_wrapper\n    return params_decorator"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_value(data_structure, key):\n    if len(key) == 0:\n        raise KeyError()\n    value = data_structure[key[0]]\n    if len(key) > 1:\n        return _get_value(value, key[1:])\n    return value", "response": "Return the value of a data_structure given a path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_value_from_session(key):\n    def value_from_session_function(service, message):\n        \"\"\"Actual implementation of get_value_from_session function.\n\n        :param service: SelenolService object.\n        :param message: SelenolMessage request.\n        \"\"\"\n        return _get_value(message.session, key)\n    return value_from_session_function", "response": "Get a value from the session."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a value from the content of the specified key.", "response": "def get_value_from_content(key):\n    \"\"\"Get a value from the path specifed.\n\n    :param key: Array that defines the path of the value inside the message.\n    \"\"\"\n    def value_from_content_function(service, message):\n        \"\"\"Actual implementation of get_value_from_content function.\n\n        :param service: SelenolService object.\n        :param message: SelenolMessage request.\n        \"\"\"\n        return _get_value(message.content, key)\n    return value_from_content_function"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_object_from_content(entity, key):\n    def object_from_content_function(service, message):\n        \"\"\"Actual implementation of get_object_from_content function.\n\n        :param service: SelenolService object.\n        :param message: SelenolMessage request.\n        \"\"\"\n        id_ = get_value_from_content(key)(service, message)\n        result = service.session.query(entity).get(id_)\n        if not result:\n            raise SelenolInvalidArgumentException(key, id_)\n        return result\n    return object_from_content_function", "response": "Get an object from the database given an entity and the content key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_object_from_session(entity, key):\n    def object_from_session_function(service, message):\n        \"\"\"Actual implementation of get_object_from_session function.\n\n        :param service: SelenolService object.\n        :param message: SelenolMessage request.\n        \"\"\"\n        id_ = get_value_from_session(key)(service, message)\n        result = service.session.query(entity).get(id_)\n        if not result:\n            raise SelenolInvalidArgumentException(key, id_)\n        return result\n    return object_from_session_function", "response": "Get an object from the database given an entity and the session key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_forces(line, lines):\n    units = line.split()[4].rstrip(\":\")\n    next(lines)\n    newline = next(lines)\n    total = []; non_local = []; ionic = []; local = []; core_correction = []\n    hubbard = []; scf = []; types = []\n    while (not \"The non-local contrib.\" in newline) and len(newline.split()) > 0:\n        if \"=\" in newline:\n            total.append([float(x) for x in newline.partition(\"=\")[2].split()])\n            types.append(int(newline.split()[3]))\n        newline = next(lines)\n\n    if len(newline.split()) > 0:\n        while not \"The ionic contribution\" in newline:\n            if \"=\" in newline:\n                non_local.append([float(x) for x in newline.partition(\"=\")[2].split()])\n            newline = next(lines)\n        while not \"The local contribution\" in newline:\n            if \"=\" in newline:\n                ionic.append([float(x) for x in newline.partition(\"=\")[2].split()])\n            newline = next(lines)\n        while not \"The core correction contribution\" in newline:\n            if \"=\" in newline:\n                local.append([float(x) for x in newline.partition(\"=\")[2].split()])\n            newline = next(lines)\n        while not \"The Hubbard contrib.\" in newline:\n            if \"=\" in newline:\n                core_correction.append([float(x) for x in newline.partition(\"=\")[2].split()])\n            newline = next(lines)\n        while not \"The SCF correction term\" in newline:\n            if \"=\" in newline:\n                hubbard.append([float(x) for x in newline.partition(\"=\")[2].split()])\n            newline = next(lines)\n        while len(newline.split()) > 0:\n            if \"=\" in newline:\n                scf.append([float(x) for x in newline.partition(\"=\")[2].split()])\n            newline = next(lines)\n    newline = next(lines)\n    total_force = float(newline.split()[3])\n    total_scf = float(newline.split()[8])\n    return {\n        \"force units\": units,\n        \"total force\": total_force,\n        \"total SCF correction\": total_scf,\n        \"forces\": total,\n        \"non-local contribution to forces\": non_local,\n        \"ionic contribution to forces\": ionic,\n        \"local contribution to forces\": local,\n        \"core corrections to forces\": core_correction,\n        \"Hubbard contribution to forces\": hubbard,\n        \"SCF correction term to forces\": scf,\n        \"Atomic species index for forces\": types\n    }", "response": "Parse the forces block."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of GradPetition objects.", "response": "def _process_json(data):\n    \"\"\"\n    return a list of GradPetition objects.\n    \"\"\"\n    requests = []\n    for item in data:\n        petition = GradPetition()\n        petition.description = item.get('description')\n        petition.submit_date = parse_datetime(item.get('submitDate'))\n        petition.decision_date = parse_datetime(item.get('decisionDate'))\n\n        if item.get('deptRecommend') and len(item.get('deptRecommend')):\n            petition.dept_recommend = item.get('deptRecommend').lower()\n\n        if item.get('gradSchoolDecision') and\\\n           len(item.get('gradSchoolDecision')):\n            petition.gradschool_decision =\\\n                item.get('gradSchoolDecision').lower()\n        requests.append(petition)\n    return requests"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef example_add_line_to_file():\n    my_file = FileAsObj('/tmp/example_file.txt')\n    my_file.add('foo')\n    my_file.append('bar')\n    # Add a new line to my_file that contains the word 'lol' and print True|False if my_file was changed.\n    print(my_file + 'lol')\n    # Add line even if it already exists in the file.\n    my_file.unique = False\n    my_file.add('foo')", "response": "Same as example_add_line_to_file but for the same file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntry to remove all comments from a file and save it if changes were made.", "response": "def example_write_file_to_disk_if_changed():\n    \"\"\" Try to remove all comments from a file, and save it if changes were made. \"\"\"\n    my_file = FileAsObj('/tmp/example_file.txt')\n    my_file.rm(my_file.egrep('^#'))\n    if my_file.changed:\n        my_file.save()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuse a bunch of methods on a file.", "response": "def example_all():\n    \"\"\"\n    Use a bunch of methods on a file.\n    \"\"\"\n    my_file = FileAsObj()\n    my_file.filename = '/tmp/example_file.txt'\n    my_file.add('# First change!')\n    my_file.save()\n    my_file = FileAsObj('/tmp/example_file.txt')\n    my_file.unique = True\n    my_file.sorted = True\n    my_file.add('1')\n    my_file.add('1')\n    my_file.add('2')\n    my_file.add('20 foo')\n    my_file.add('200 bar')\n    my_file.add('# Comment')\n    my_file.unique = False\n    my_file.add('# Comment')\n    my_file.add('# Comment')\n    my_file.unique = True\n    my_file.rm(my_file.egrep('^#.*'))\n    my_file.rm(my_file.grep('foo'))\n    my_file.replace(my_file.egrep('^2'), 'This line was replaced.')\n    print(my_file)\n    print(my_file.log)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_cal_data(data_df, cal_dict, param):\n    '''Get data along specified axis during calibration intervals\n\n    Args\n    ----\n    data_df: pandas.DataFrame\n        Pandas dataframe with lleo data\n    cal_dict: dict\n        Calibration dictionary\n\n    Returns\n    -------\n    lower: pandas dataframe\n        slice of lleo datafram containing points at -1g calibration position\n    upper: pandas dataframe\n        slice of lleo datafram containing points at -1g calibration position\n\n    See also\n    --------\n    lleoio.read_data: creates pandas dataframe `data_df`\n    read_cal: creates `cal_dict` and describes fields\n    '''\n\n    param = param.lower().replace(' ','_').replace('-','_')\n\n    idx_lower_start = cal_dict['parameters'][param]['lower']['start']\n    idx_lower_end   = cal_dict['parameters'][param]['lower']['end']\n    idx_upper_start = cal_dict['parameters'][param]['upper']['start']\n    idx_upper_end   = cal_dict['parameters'][param]['upper']['end']\n\n    idx_lower = (data_df.index >= idx_lower_start) & \\\n                (data_df.index <= idx_lower_end)\n\n    idx_upper = (data_df.index >= idx_upper_start) & \\\n                (data_df.index <= idx_upper_end)\n\n    return data_df[param][idx_lower], data_df[param][idx_upper]", "response": "Get data along specified axis during calibration intervals"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload calibration file if exists else create", "response": "def read_cal(cal_yaml_path):\n    '''Load calibration file if exists, else create\n\n    Args\n    ----\n    cal_yaml_path: str\n        Path to calibration YAML file\n\n    Returns\n    -------\n    cal_dict: dict\n        Key value pairs of calibration meta data\n    '''\n    from collections import OrderedDict\n    import datetime\n    import os\n    import warnings\n    import yamlord\n\n    from . import utils\n\n    def __create_cal(cal_yaml_path):\n        cal_dict = OrderedDict()\n\n        # Add experiment name for calibration reference\n        base_path, _ = os.path.split(cal_yaml_path)\n        _, exp_name = os.path.split(base_path)\n        cal_dict['experiment'] = exp_name\n\n        return cal_dict\n\n    # Try reading cal file, else create\n    if os.path.isfile(cal_yaml_path):\n        cal_dict = yamlord.read_yaml(cal_yaml_path)\n    else:\n        cal_dict = __create_cal(cal_yaml_path)\n        cal_dict['parameters'] = OrderedDict()\n\n    for key, val in utils.parse_experiment_params(cal_dict['experiment']).items():\n        cal_dict[key] = val\n\n    fmt = \"%Y-%m-%d %H:%M:%S\"\n    cal_dict['date_modified'] = datetime.datetime.now().strftime(fmt)\n\n    return cal_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate calibration times for give parameter and boundary", "response": "def update(data_df, cal_dict, param, bound, start, end):\n    '''Update calibration times for give parameter and boundary'''\n    from collections import OrderedDict\n\n    if param not in cal_dict['parameters']:\n        cal_dict['parameters'][param] = OrderedDict()\n    if bound not in cal_dict['parameters'][param]:\n        cal_dict['parameters'][param][bound] = OrderedDict()\n\n    cal_dict['parameters'][param][bound]['start'] = start\n    cal_dict['parameters'][param][bound]['end']   = end\n\n    return cal_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fit1d(lower, upper):\n    '''Fit acceleration data at lower and upper boundaries of gravity\n\n    Args\n    ----\n    lower: pandas dataframe\n        slice of lleo datafram containing points at -1g calibration position\n    upper: pandas dataframe\n        slice of lleo datafram containing points at -1g calibration position\n\n    Returns\n    -------\n    p: ndarray\n        Polynomial coefficients, highest power first. If y was 2-D, the\n        coefficients for k-th data set are in p[:,k]. From `numpy.polyfit()`.\n\n    NOTE\n    ----\n    This method should be compared agaist alternate linalg method, which allows\n    for 2d for 2d poly, see - http://stackoverflow.com/a/33966967/943773\n\n    A = numpy.vstack(lower, upper).transpose()\n    y = A[:,1]\n    m, c = numpy.linalg.lstsq(A, y)[0]\n    '''\n    import numpy\n\n    # Get smallest size as index position for slicing\n    idx = min(len(lower), len(upper))\n\n    # Stack accelerometer count values for upper and lower bounds of curve\n    x = numpy.hstack((lower[:idx].values, upper[:idx].values))\n    x = x.astype(float)\n\n    # Make corresponding y array where all lower bound points equal -g\n    # and all upper bound points equal +g\n    y = numpy.zeros(len(x), dtype=float)\n    y[:idx] = -1.0 # negative gravity\n    y[idx:] =  1.0 # positive gravity\n\n    return numpy.polyfit(x, y, deg=1)", "response": "Fit acceleration data at lower and upper boundaries of gravity\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render_pep440_bare(pieces):\n    if pieces[\"closest-tag\"]:\n        rendered = pieces[\"closest-tag\"]\n        if pieces[\"distance\"] or pieces[\"dirty\"]:\n            rendered += \".%d\" % pieces[\"distance\"]\n            if pieces[\"dirty\"]:\n                rendered += \".dev0\"\n    else:\n        # exception #1\n        rendered = \"0.%d\" % pieces[\"distance\"]\n        if pieces[\"dirty\"]:\n            rendered += \".dev0\"\n    return rendered", "response": "Render a bare tag."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a function that moves smoothly between a minimal value and a maximal one when its value increases from a given witch point to infinity.", "response": "def get_smooth_step_function(min_val, max_val, switch_point, smooth_factor):\n    \"\"\"Returns a function that moves smoothly between a minimal value and a\n    maximal one when its value increases from a given witch point to infinity.\n\n    Arguments\n    ---------\n    min_val: float\n        max_val value the function will return when x=switch_point.\n    min_val: float\n        The value the function will converge to when x -> infinity.\n    switch_point: float\n        The point in which the function's value will become min_val. Smaller\n        x values will return values smaller than min_val.\n    smooth_factor: float\n        The bigger the smoother, and less cliff-like, is the function.\n\n    Returns\n    -------\n    function\n        The desired smooth function.\n    \"\"\"\n    dif = max_val - min_val\n    def _smooth_step(x):\n        return min_val + dif * tanh((x - switch_point) / smooth_factor)\n    return _smooth_step"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stack_sources():\n    # lazy imports\n    import linecache\n    result = []\n    for frame_info in reversed(inspect.stack()):\n        _frame, filename, line_number, _function, _context, _index = frame_info\n        linecache.lazycache(filename, {})\n        _line = linecache.getline(filename, line_number).rstrip()\n\n    # Each record contains a frame object, filename, line number, function\n    # name, a list of lines of context, and index within the context\n    _sources = [(path, line) for _, path, line, _, _, _ in inspect.stack()]\n    return result", "response": "A list of sources for frames above this"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_leftmost_selector(selector_list):\n    classes = set()\n    ids = set()\n    elements = set()\n    #    print \"Selector list: %s \\n\\n\\n\\n\\n\\n\" % selector_list\n    for selector in selector_list:\n        selector = selector.split()[0]\n        if selector[0] == '.':\n            classes.add(selector)\n        elif selector[0] == '#':\n            ids.add(selector)\n        else:\n            elements.add(selector)\n    return { \n             'classes':classes,\n             'ids':ids,\n             'elements':elements,\n             }", "response": "Extract the leftmost selector from a list of selectors."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle_data(self, data):\n        if self.get_data == True:\n            self.inline_css_data.append(data)\n            #print self.inline_css_data\n            #print \"Sending to parser\"\n            self.parse_inline_styles(data, 'string')\n            self.get_data = False", "response": "Handles the data received from the HTML tag."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle_startendtag(self, tag, attrs):\n        dattrs = dict(attrs)\n        if tag.lower() == 'link':\n            #print \"Found link\"\n            if all (k in dattrs for k in ('rel', 'href', 'type')):\n                if ( dattrs['rel'].lower() == 'stylesheet' and \n                     dattrs['type'].lower() == 'text/css' ):\n                    #try to open the url...\n                    #print \"Trying to read %s\"  % dattrs['href']\n                    if (dattrs['href'][:5].lower() == 'http:' or \n                       dattrs['href'][:6].lower() == 'https:'):\n                        self.linked_sheets.append(dattrs['href'])\n                    else:\n                        self.linked_sheets.append(self.url_root+dattrs['href'])\n        self.append_styles(tag, attrs)", "response": "Called when the Cssparser finds a tag that does not have a closing tag such as a link or a meta tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef append_styles(self, tag, attrs):\n        dattrs = dict(attrs)\n        if 'class' in dattrs:\n            #print \"Found classes '%s'\" % dattrs['class']\n            class_names = dattrs['class'].split()\n            dotted_names = map(prepend_dot,class_names)\n            dotted_names.sort()\n            self.used_classes.extend(' '.join(dotted_names))\n            self.unchained_classes.extend(dotted_names)\n        if 'id' in dattrs:\n            #print \"Found id '%s'\" % dattrs['id']\n            self.used_ids.extend(prepend_hash(dattrs['id'].strip()))", "response": "Append classes found in HTML elements to the list of styles used."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_inline_styles(self, data=None, import_type ='string'):\n        if data is None:\n            raise\n        parser = cssutils.CSSParser()\n        if import_type == 'string':\n            #print \"importing string with url=%s\" % self.url_root\n            sheet = parser.parseString(data,href=self.url_root)\n        elif import_type == 'url':\n          if data[:5].lower() == 'http:' or data[:6].lower() == 'https:':\n            print \"YES because it was: %s \" % data[:5].lower()\n            try:\n                sheet = parser.parseUrl(data)\n            except:\n                sys.stderr.write(\"WARNING: Failed attempting to parse %s\" % data)\n                return\n        elif import_type == 'file':\n            sheet = parser.parseFile(data)\n        else:\n            raise\n\n        hrefs = []\n        for i in range(len(sheet.cssRules)):\n            if sheet.cssRules[i].type == cssutils.css.CSSStyleRule.STYLE_RULE:\n                selector = sheet.cssRules[i].selectorText\n                #print \"cssparser found  selector: %s\" % selector\n                selectors = selector.split(',')\n                self.defined_classes.extend(selectors)\n\n            elif ( self.follow_css_links == True and\n                  sheet.cssRules[i].type == cssutils.css.CSSStyleRule.IMPORT_RULE ):\n                href = sheet.cssRules[i].href\n                sys.stderr.write(\"Added %s to the stylesheets to crawl\" % href)\n                \n                if href[:5].lower() == 'http:' or href[:6].lower() == 'https:':\n                    self.linked_sheets.append(href)\n                else:\n                    # We'll have to try to add in a url root here, if these are relative\n                    # links.\n                    self.linked_sheets.append(self.url_root+href)\n                    self.parse_inline_styles(data=self.url_root+href, import_type='url')\n            else:\n                # We won't worry about the other rule types.\n                pass", "response": "Function for parsing inline styles."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the geocoding of a given location or object", "response": "def get_geocode(city, state, street_address=\"\", zipcode=\"\"):\n    \"\"\"\n    For given location or object, takes address data and returns\n    latitude and longitude coordinates from Google geocoding service\n\n    get_geocode(self, street_address=\"1709 Grand Ave.\", state=\"MO\", zip=\"64112\")\n\n    Returns a tuple of (lat, long)\n    Most times you'll want to join the return.\n\n    \"\"\"\n    try:\n        key = settings.GMAP_KEY\n    except AttributeError:\n        return \"You need to put GMAP_KEY in settings\"\n\n    # build valid location string\n    location = \"\"\n    if street_address:\n        location += '{}+'.format(street_address.replace(\" \", \"+\"))\n    location += '{}+{}'.format(city.replace(\" \", \"+\"), state)\n    if zipcode:\n        location += \"+{}\".format(zipcode)\n\n    url = \"http://maps.google.com/maps/geo?q={}&output=xml&key={}\".format(location, key)\n    file = urllib.urlopen(url).read()\n    try:\n        xml = xmltramp.parse(file)\n    except Exception as error:\n        print(\"Failed to parse xml file {}: {}\".format(file, error))\n        return None\n\n    status = str(xml.Response.Status.code)\n    if status == \"200\":\n        geocode = str(xml.Response.Placemark.Point.coordinates).split(',')\n         # Flip geocode because geocoder returns long/lat while Maps wants lat/long.\n         # Yes, it's dumb.\n        return (geocode[1], geocode[0])\n    else:\n        print(status)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef append(self,*args,toSection=None,**kwargs):\n        if not toSection and toSection is not 0:\n            s = Section(*args,**kwargs)\n            self.subs.append(s)\n            self.lastSection = s\n            s._parentSection = self\n            s._reportSection = self._reportSection\n        else:\n            if type(toSection) is int: toSection = (toSection,)\n            s = self.subs[toSection[0]].append(*args,toSection=toSection[1:],**kwargs)\n        return s", "response": "Append a new section to the main section or subsection list."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps a callback function in a wrapper that will be applied to all [sub]sections. Returns: function", "response": "def walkerWrapper(callback):\n        \"\"\"\n        Wraps a callback function in a wrapper that will be applied to all [sub]sections.\n\n        Returns:\n            function\n        \"\"\"\n        def wrapper(*args,**kwargs):\n            #args[0] => has to be the current walked section\n            return Section.sectionWalker(args[0],callback,*args[1:],**kwargs)\n        return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef listTables(self,walkTrace=tuple(),case=None,element=None):\n        if case == 'sectionmain': print(walkTrace,self.title)\n        if case == 'table':\n            caption,tab = element\n            try:\n                print(walkTrace,tab._leopardref,caption)\n            except AttributeError:\n                tab._leopardref = next(self._reportSection._tabnr)\n                print(walkTrace,tab._leopardref,caption)", "response": "List tables in the report."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprepare section for zip output", "response": "def sectionOutZip(self,zipcontainer,zipdir='',figtype='png'):\n        \"\"\"Prepares section for zip output\n        \"\"\"\n        from io import StringIO, BytesIO\n        text = self.p if not self.settings['doubleslashnewline'] else self.p.replace('//','\\n')\n        zipcontainer.writestr(\n            zipdir+'section.txt',\n            '# {}\\n{}'.format(self.title,text).encode()\n        )\n        c = count(1)\n        for ftitle,f in self.figs.items():\n            figfile = zipdir+'fig{}_{}.{}'.format(next(c),ftitle.replace(' ','_'),figtype)\n            b = BytesIO()\n            f.savefig(b,format=figtype,transparent=True)\n            b.seek(0)\n            zipcontainer.writestr(figfile,b.getvalue())\n        c = count(1)\n        for ttitle,t in self.tabs.items():\n            b = StringIO()\n            t.to_csv(b,sep=csvsep,decimal=csvdec)\n            b.seek(0)\n            zipcontainer.writestr(\n                zipdir+'table{}_{}.csv'.format(next(c),ttitle.replace(' ','_')),\n                b.read().encode()\n            )\n        c = count(1)\n        for s in self.subs:\n            s.sectionOutZip(zipcontainer,'{}s{}_{}/'.format(zipdir,next(c),s.title.replace(' ','_')),figtype=figtype)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprepare section for PDF output.", "response": "def sectionsPDF(self,walkTrace=tuple(),case=None,element=None,doc=None):\n        \"\"\"Prepares section for PDF output.\n        \"\"\"\n        import pylatex as pl\n        if case == 'sectionmain':\n            if self.settings['clearpage']: doc.append(pl.utils.NoEscape(r'\\clearpage'))\n            with doc.create(pl.Section(self.title) if len(walkTrace) == 1 else\n                            pl.Subsection(self.title) if len(walkTrace) == 2 else\n                            pl.Subsubsection(self.title)):\n                text = (self.p.replace('\\n',' ').replace('//','\\n')\n                        if self.settings['doubleslashnewline'] else\n                        renewliner(self.p))\n                if r'\\ref' not in text: doc.append(text)\n                else:\n                    figrefs = re.compile(r'\\\\ref\\{figref\\d+\\}')\n                    #latexcode = re.compile(r'&@\\\\.+')\n                    lastpos = 0\n                    for fr in figrefs.finditer(text):\n                        doc.append(text[lastpos:fr.start()])\n                        doc.append(pl.utils.NoEscape(text[fr.start():fr.end()]))\n                        lastpos = fr.end()\n                    doc.append(text[lastpos:])\n                \n        if case == 'figure':\n            width = r'1\\textwidth'\n            figtitle,fig = element\n            #if fig._suptitle: fig.suptitle('Figure {}: {}'.format(fig.number,fig._suptitle.get_text()))\n            #figtitle = fig._suptitle.get_text() if fig._suptitle else ''\n            #fig.suptitle('')\n            with doc.create(pl.Figure(position='htbp')) as plot:\n                plt.figure(fig.number)\n                plot.add_plot(width=pl.NoEscape(width))\n                plot.add_caption(figtitle)\n                plot.append(pl.utils.NoEscape(r'\\label{figref'+str(fig.number)+r'}'))\n            #fig.suptitle(figtitle if figtitle else None)\n            \n        if case == 'table':\n            caption,t = element\n            t = pdSeriesToFrame(t) if type(t) == pd.Series else t\n            if self.settings['tablehead']:\n                t = t.head(self.settings['tablehead'])\n            if self.settings['tablecolumns']:\n                t = t[self.settings['tablecolumns']]\n            with doc.create(pl.Table(position='ht')) as tablenv:\n                tablenv.add_caption(caption)\n                with doc.create(pl.Tabular('r|'+'l'*len(t.columns))) as table:\n                    table.add_hline()\n                    table.add_row(('',)+tuple(t.columns))\n                    for row in t.to_records():\n                        table.add_row(row)\n                    table.add_hline(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sectionsWord(self,walkTrace=tuple(),case=None,element=None,doc=None):\n        from docx.shared import Inches\n        from io import BytesIO\n        #p.add_run('italic.').italic = True\n                \n        if case == 'sectionmain':\n            if self.settings['clearpage']: doc.add_page_break()\n            \n            doc.add_heading(self.title, level = len(walkTrace))\n            for p in renewliner(self.p).split('\\n'):\n                doc.add_paragraph(p)\n                \n        if case == 'figure':\n            bf=BytesIO()\n            figtitle,fig = element\n            width = fig.get_size_inches()[0]\n            width = Inches(width if width < 6 else 6)\n            fig.savefig(bf)\n            doc.add_picture(bf, width=width)\n            doc.add_heading('Figure {}: {}'.format(\n                fig._leopardref,\n                figtitle),level=6)\n            \n        if case == 'table':\n            caption,t = element\n            tableref = t._leopardref\n            t = pdSeriesToFrame(t) if type(t) == pd.Series else t\n            if self.settings['tablehead']:\n                t = t.head(self.settings['tablehead'])\n            if self.settings['tablecolumns']:\n                t = t[self.settings['tablecolumns']]\n\n            doc.add_heading('Table {}: {}'.format(\n                tableref,\n                caption),level=6)\n            table = doc.add_table(t.shape[0]+1,t.shape[1]+1)\n            for tcell,col in zip(table.rows[0].cells[1:],t.columns):\n                tcell.text = str(col)\n            for trow,rrow in zip(table.rows[1:],t.to_records()):\n                for tcell,rcell in zip(trow.cells,rrow):\n                    tcell.text = str(rcell)", "response": "Prepares section for word output."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sectionFromFunction(function,*args,**kwargs):\n        figures, tables = function(*args,**kwargs)\n        title = inspect.getcomments(function)[1:].strip()\n        text = inspect.getdoc(function)\n        code = inspect.getsource(function)\n        return Section(title=title,text=text,figures=figures,tables=tables,code=code)", "response": "This staticmethod executes the function that returns a Section object and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list(self):\n        for i in range(len(self.sections)):\n            self.sections[i].list(walkTrace=(i+1,))", "response": "Get an overview of the report content list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef outputZip(self,figtype='png'):\n        from zipfile import ZipFile\n        with ZipFile(self.outfile+'.zip', 'w') as zipcontainer:\n            zipcontainer.writestr(\n                'summary.txt',\n                '# {}\\n\\n{}\\n{}'.format(\n                    self.title,\n                    self.p,\n                    ('\\n## Conclusion\\n' if self.conclusion else '')+self.conclusion\n                ).encode()\n            )\n            c = count(1)\n            for section in self.sections:\n                section.sectionOutZip(zipcontainer,'s{}_{}/'.format(next(c),section.title.replace(' ','_')),\n                                      figtype=figtype)", "response": "Outputs the report in a zip container."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef outputPDF(self,**kwargs):\n        import pylatex as pl\n        geometry_options = {\"tmargin\": \"2cm\", \"lmargin\": \"2cm\"}\n        doc = pl.Document(geometry_options=geometry_options)\n        #Following option avoids float error when to many unplaced figs or tabs\n        # (to force placing floats also \\clearpage can be used after a section for example)\n        doc.append(pl.utils.NoEscape(r'\\extrafloats{100}'))\n        doc.append(pl.utils.NoEscape(r'\\title{'+self.title+'}'))\n        if self.addTime:\n            from time import localtime, strftime\n            doc.append(pl.utils.NoEscape(r'\\date{'+strftime(\"%Y-%m-%d %H:%M:%S\", localtime())+r'}'))\n        else: doc.append(pl.utils.NoEscape(r'\\date{\\today}'))\n        if self.author: doc.append(pl.utils.NoEscape(r'\\author{'+self.author+'}'))\n        doc.append(pl.utils.NoEscape(r'\\maketitle'))\n\n        # Append introduction\n        if self.p:\n            with doc.create(pl.Section('Introduction')):\n                doc.append(renewliner(self.p))\n\n        # Sections\n        c = count(1)\n        for section in self.sections:\n            section.sectionsPDF(walkTrace=(next(c),),doc=doc)\n\n        # Append conclusion\n        if self.conclusion:\n            with doc.create(pl.Section('Conclusion')):\n                doc.append(renewliner(self.conclusion))\n\n        # Generate pdf\n        doc.generate_pdf(self.outfile,**kwargs)", "response": "Makes a pdf report with pylatex\n        and writes it to self. outfile."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\noutputs the report to word docx", "response": "def outputWord(self):\n        \"\"\"Output report to word docx\n        \"\"\"\n        import docx\n        from docx.enum.text import WD_ALIGN_PARAGRAPH\n        \n        doc = docx.Document()\n        doc.styles['Normal'].paragraph_format.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY\n        \n        doc.add_heading(self.title, level=0)\n        if self.addTime:\n            from time import localtime, strftime\n            doc.add_heading(strftime(\"%Y-%m-%d %H:%M:%S\", localtime()), level=1)\n            \n         # Append introduction\n        if self.p:\n            doc.add_heading('Introduction',level=1)\n            for p in renewliner(self.p).split('\\n'):\n                doc.add_paragraph(p)\n\n        # Sections\n        c = count(1)\n        #Prepare fig and table numbers\n        self.listFigures(tuple())\n        self.listTables(tuple())\n        for section in self.sections:\n            section.sectionsWord((next(c),),doc=doc)\n\n        # Append conclusion\n        if self.conclusion:\n            doc.add_heading('Conclusion', level=1)\n            for p in renewliner(self.conclusion).split('\\n'):\n                doc.add_paragraph(p)\n\n        # Generate Word document\n        doc.save(self.outfile+'.docx')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a pandas table from a previous report.", "response": "def getReportTable(reportzipfile,tablefilename,inReportsDir=True,verbose=False):\n        \"\"\"Get a pandas table from a previous report\n\n        Args:\n            reportzipfile (str): Zip folder location, '.zip' extension is optional.\n            tablefilename (str or list int): Table location within the zip folder.\n                Can be provided as the filename within the zip folder, or a list of integers\n                indicating its exact position (1-indexed). If you provide an empty string or\n                list, all available table filenames in the zip folder will be printed.\n            inReportsDir (bool): Search reportzipfile relative to reportsDir.\n\n        Returns:\n            pd.DataFrame\n        \"\"\"\n        import zipfile, io, re\n\n        # zipfilename preparation\n        if not reportzipfile.endswith('.zip'): reportzipfile+='.zip'\n        if inReportsDir: reportzipfile = os.path.join(reportsDir,reportzipfile)\n        with zipfile.ZipFile(reportzipfile) as z:\n            # print all table filenames if tablefilename is not provided\n            if not tablefilename:\n                for f in z.filelist:\n                    if 'table' in f.filename: print(f.filename)\n                return\n            # tablefilename preparation if int list\n            if isinstance(tablefilename,list):\n                tablelocation = tablefilename\n                tablefilename = None\n                location = re.compile(r'(s|table)(\\d+)_')\n                for f in z.filelist:\n                    if 'table' not in f.filename or f.filename.count('/') != (len(tablelocation)-1): continue\n                    if [int(location.match(s).groups()[1]) for s in f.filename.split('/')] == tablelocation:\n                        tablefilename = f.filename\n                        if verbose: print('Loading',tablefilename)\n                        break\n                if tablefilename is None: raise FileNotFoundError('Table location not found in zip folder.')\n            # read table\n            with z.open(tablefilename) as f:\n                ft = io.TextIOWrapper(f)\n                return pd.read_csv(ft,index_col=0,sep=csvsep,decimal=csvdec)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_api_call_func(api, verb):\n\n    # Scopes some local context in which we can build\n    # request functions with reflection that primed with\n    # some static parameters.\n    def api_call_func(self, **kwargs):\n\n        request = api.request_classes[verb](**kwargs)\n        params = dict([ (k,v) for k,v in request.items() if v is not None ])\n\n\n        if HTTPVerb.GET == verb:\n            raw_response = requests.get(api.url, params=params, **self.reqargs)\n\n        elif HTTPVerb.POST == verb:\n            raw_response = requests.post(api.url, data=params, **self.reqargs)\n\n        else:\n            raise RuntimeError('{} is not a handled http verb'.format(verb))\n\n        if raw_response.status_code != HTTPStatus.OK:\n            raw_response.raise_for_status()\n\n        # The object hook will convert all dictionaries from the json\n        # objects in the response to a . attribute access\n        ResponseClass = api.response_classes[verb]\n        try:\n            response = raw_response.json(object_hook=lambda obj: ResponseClass(obj))\n        except ValueError as e:\n            response = ResponseClass({'content' : raw_response.content})\n\n        return response\n\n    method_name = api_method_name(verb, api)\n\n    api_call_func.__name__ = method_name\n    api_call_func.__doc__ = '{}\\n{}'.format(\n        method_name, ''.join(api.request_classes[verb].__doc__.splitlines(True)[1:]))\n\n    return api_call_func", "response": "Create a function that can be used to dispatch the request to the appropriate requests module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a function that asynchronously dispatches the request to the appropriate requests module.", "response": "def create_async_api_call_func(api, verb):\n    \"\"\"\n    From an api definition object create the related api call method\n    that will validate the arguments for the api call and then\n    dynamically dispatch the request to the appropriate requests module\n    convenience method for the specific HTTP verb .\n    \"\"\"\n\n    # Scopes some local context in which we can build\n    # request functions with reflection that primed with\n    # some static parameters.\n    def api_call_func(self, **kwargs):\n\n        def _async_call_handler():\n            api_method = getattr(self, api_method_name(verb, api))\n            return api_method(**kwargs)\n\n        return self._executor.submit(_async_call_handler)\n\n    method_name = async_api_method_name(verb, api)\n\n    api_call_func.__name__ = method_name\n    api_call_func.__doc__ = \"{}\\nParameters:\\n  {}\".format(\n        method_name, '\\n  '.join(api.request_classes[verb]().keys()))\n\n    return api_call_func"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a RestClient subclass with the given name and a list of apis.", "response": "def create_rest_client_class(name, apis, BaseClass=RestClient):\n    \"\"\"\n    Generate the api call functions and attach them to the generated\n    RestClient subclass with the name <Service>Client.\n    \"\"\"\n\n    apis_with_actions = list(itertools.chain.from_iterable([ zip([api] * len(api.actions), api.actions) for api in apis]))\n\n    api_funcs = [create_api_call_func(api, verb) for api, verb in apis_with_actions]\n    api_funcs.extend([create_async_api_call_func(api, verb) for api, verb in apis_with_actions])\n    api_mapper = dict([ (f.__name__, f) for f in api_funcs ])\n\n    # Adapted from :\n    # http://stackoverflow.com/questions/15247075/how-can-i-dynamically-create-derived-classes-from-a-base-class\n    def __init__(self, thread_count=_ASYNC_WORKER_THREAD_COUNT, **reqargs):\n        BaseClass.__init__(self)\n        setattr(self, 'reqargs', read_only_dict(reqargs))\n        self._executor = concurrent.futures.ThreadPoolExecutor(thread_count)\n\n    api_mapper['__init__'] =  __init__\n\n    ClientClass = type(_CLIENT_NAME_FMT.format(name), (BaseClass,), api_mapper)\n    return ClientClass"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload a restful service from a YAML file at config_path.", "response": "def load_service(config):\n   \"\"\"\n   Load a restful service specified by some YAML file at config_path.\n\n   :param config_path: A pathlib Path object that points to the yaml\n       config\n   :returns: A python module containing a Client class, call factory,\n       and the definition of each of the APIs defined by the config.\n   \"\"\"\n   if isinstance(config, collections.abc.Mapping):\n       service_config = config\n   elif isinstance(config, str):\n       service_config = load_config(pathlib.Path(config))\n   elif isinstance(config, pathlib.Path):\n       service_config = load_config(config)\n   else:\n       raise TypeError('Cannot load config from type: {}'.format(type(config)))\n\n   apis = []\n   for api, defn in service_config['apis'].items():\n       api_def= create_api_definition(api, defn, service_config['base_url'])\n       apis.append(api_def)\n\n   service_module = create_service_module(service_config['name'], apis)\n   return service_module"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef estimate_allele_frequency(ac, an, a=1, b=100):\n    # Credible interval is 95% highest posterior density\n    td = dict(zip(['ci_lower', 'ci_upper'], \n                  stats.beta(a + ac, b + an - ac).interval(0.95)))\n    td['af'] = (a + ac) / (a + b + an)\n    td['af_mle'] = np.array(ac).astype(float) / np.array(an)\n    out = pd.DataFrame(td)[['af_mle', 'af', 'ci_lower', 'ci_upper']]\n    if type(ac) == pd.Series:\n        out.index = ac.index\n    return(out)", "response": "Estimate the frequency of each sample in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntransforming a series or the rows of a dataframe to the values of a standard normal based on rank.", "response": "def transform_standard_normal(df):\n    \"\"\"Transform a series or the rows of a dataframe to the values of a standard\n    normal based on rank.\"\"\"\n    import pandas as pd\n    import scipy.stats as stats\n    if type(df) == pd.core.frame.DataFrame:\n        gc_ranks = df.rank(axis=1)\n        gc_ranks = gc_ranks / (gc_ranks.shape[1] + 1)\n        std_norm = stats.norm.ppf(gc_ranks)\n        std_norm = pd.DataFrame(std_norm, index=gc_ranks.index, \n                                columns=gc_ranks.columns)\n    elif type(df) == pd.core.series.Series:\n        gc_ranks = df.rank()\n        gc_ranks = gc_ranks / (gc_ranks.shape[0] + 1)\n        std_norm = stats.norm.ppf(gc_ranks)\n        std_norm = pd.Series(std_norm, index=df.index)\n    return std_norm"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a gzipped text file from a URL and return contents as a string.", "response": "def read_gzipped_text_url(url):\n    \"\"\"Read a gzipped text file from a URL and return \n    contents as a string.\"\"\"\n    import urllib2\n    import zlib\n    from StringIO import StringIO\n\n    opener = urllib2.build_opener() \n    request = urllib2.Request(url)\n    request.add_header('Accept-encoding', 'gzip')\n    respond = opener.open(request)\n    compressedData = respond.read()\n    respond.close()\n    opener.close()\n    compressedDataBuf = StringIO(compressedData)\n    d = zlib.decompressobj(16+zlib.MAX_WBITS)\n    buffer = compressedDataBuf.read(1024)\n    #saveFile = open('/tmp/test.txt', \"wb\")\n    s = []\n    while buffer:\n        s.append(d.decompress(buffer))\n        buffer = compressedDataBuf.read(1024)\n    s = ''.join(s)\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a region of type chr1 10 - 20 or chr1 10 - 20 or chr1 10 - 20 + or chr1 10 - 20 + or chr1 10 - 20 + or chr1 10 - 20 + or chr1 10 - 20 +.", "response": "def parse_region(region):\n    \"\"\"\n    Parse region of type chr1:10-20 or chr1:10-20:+\n\n    Parameters:\n    -----------\n\n    region : str\n        Region of type chr1:10-20 or chr1:10-20:+.\n\n    Returns\n    -------\n    groups : tuple\n        Tuple of groups from regex e.g. (chr1, 10, 20) or (chr1, 10, 20, +).\n\n    \"\"\"\n    m = R_REGEX_STRAND.search(region)\n    if not m:\n        m = R_REGEX.search(region)\n    if m:\n        groups = m.groups()\n        return groups\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of sample names for the given files.", "response": "def _sample_names(files, kwargs):\n    \"\"\"\n    Make sample (or other) names.\n\n    Parameters:\n    -----------\n\n    files : list of string\n        Typically a list of file paths although could be any list of strings\n        that you want to make names for. If neither names nor define_sample_name\n        are provided, then files is returned as is.\n\n    kwargs : dict\n        kwargs from another function. Can include the following keys with\n        appropriate arguments.\n\n    names : list of strings\n        Names to use. Overrides define_sample_name if provided.\n\n    define_sample_name : function that takes string as input\n        Function mapping string to name. For instance, you may have a sample\n        name in a file path and use a regex to extract it.\n\n    \"\"\"\n    if 'define_sample_name' not in kwargs.keys():\n        define_sample_name = lambda x: x\n    else:\n        define_sample_name = kwargs['define_sample_name']\n    \n    if 'names' in kwargs.keys():\n        names = kwargs['names']\n    else:\n        names = [define_sample_name(f) for f in files]\n    \n    assert len(names) == len(files)\n    return names"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nnaming content_recommendations Parameters: access_token, content_item_id Return: dictionary", "response": "def content_recommendations(access_token, content_item_id):\n\t'''\n\tName: content_recommendations\n\tParameters: access_token, content_item_id\n\tReturn: dictionary\n\t'''\n\n\theaders = {'Authorization': 'Bearer ' + str(access_token)}\n\trecommendations_url =\\\n\t\tconstruct_content_recommendations_url(enrichment_url, content_item_id)\n\n\trequest = requests.get(recommendations_url, headers=headers)\n\tif request.status_code == 200:\n\t\trecommendations = request.json()\n\t\treturn recommendations\n\n\treturn {'status': request.status_code, \"message\": request.text}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nnaming recommendations Parameters: access_token, payload Return: dictionary", "response": "def recommendations(access_token, payload): # (Legacy)\n\t'''\n\tName: recommendations\n\tParameters: access_token, payload\n\tReturn: dictionary\n\t'''\n\n\theaders = {'Authorization': 'Bearer ' + str(access_token)}\n\trequest = requests.post(recommendations_url, json=payload, headers=headers)\n\tif request.status_code == 200:\n\t\tmetadata = request.json()\n\t\treturn metadata\n\n\treturn {'status': request.status_code, \"message\": request.text}"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a change flag to the flags dictionary.", "response": "def flag_change(self, flags, level, location=None, worksheet=None, message=''):\n        '''\n        Wraps the pushing of a change flag into the flags dictionary to handle\n        all edge cases/auto-filling.\n        '''\n        if not isinstance(level, basestring):\n            try:\n                level = self.FLAG_LEVEL_CODES[level]\n            except KeyError:\n                level = 'fatal'\n\n        if location == None:\n            location = (-1, -1)\n\n        ftuple = self.FlagLevelTuple(level, location, worksheet, message)\n\n        # Handle flags[level] not being present\n        try:\n            flags[level].append(ftuple)\n        except KeyError:\n            flags[level] = [ftuple]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines the worst flag level present in the provided flags.", "response": "def get_worst_flag_level(self, flags):\n        '''\n        Determines the worst flag present in the provided flags. If no\n        flags are given then a 'minor' value is returned.\n        '''\n        worst_flag_level = 0\n        for flag_level_name in flags:\n            flag_level = self.FLAG_LEVELS[flag_level_name]\n            if flag_level > worst_flag_level:\n                worst_flag_level = flag_level\n        return self.FLAG_LEVEL_CODES[worst_flag_level]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(line):\n    m = LOG_FORMAT.match(line)\n    if m is None:\n        return\n    access = Access._make(m.groups())\n    entry = {\n        'host': access.host,\n        'path': access.path,\n        'query': access.query,\n        'method': access.method,\n        'protocol': access.protocol,\n        'status': int(access.status)\n    }\n    entry['time'] = datetime.datetime(\n        int(access.year), MONTH_ABBR[access.month], int(access.day),\n        int(access.hour), int(access.minute), int(access.second))\n    # Parse timezone string; \"+YYMM\" format.\n    entry['utcoffset'] = (1 if access.timezone[0] == '+' else -1) * \\\n        datetime.timedelta(hours=int(access.timezone[1:3]),\n                           minutes=int(access.timezone[3:5]))\n    if access.ident != '-':\n        entry['ident'] = access.ident\n    if access.user != '-':\n        entry['user'] = access.user\n    if access.size != '-':\n        entry['size'] = int(access.size)\n    if access.referer != '-':\n        entry['referer'] = access.referer\n    if access.ua != '-':\n        entry['ua'] = access.ua\n    if access.trailing:\n        entry['trailing'] = access.trailing.strip()\n    return entry", "response": "Parse accesslog line to map Python dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef logentry(raw):\n    warnings.warn('use \"parse()\" instead', DeprecationWarning)\n    e = parse(raw.rstrip())\n    if e is None:\n        return\n    # backward compat mapping\n    entry = {\n        'access_time': e['time'],\n        'remote_address': e['host'],\n        'request_path': e['path'],\n        'request_query': e['query'],\n        'request_method': e['method'],\n        'request_version': e['protocol'],\n        'response_status': e['status']\n    }\n    if 'size' in e:\n        entry['response_size'] = e['size']\n    if 'user_agent' in e:\n        entry['user_agent'] = e['ua']\n    return entry", "response": "Process accesslog record to map Python dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef logparse(*args, **kwargs):\n    from clitool.cli import clistream\n    from clitool.processor import SimpleDictReporter\n\n    lst = [parse] + args\n    reporter = SimpleDictReporter()\n    stats = clistream(reporter, *lst, **kwargs)\n    return stats, reporter.report()", "response": "Parse the access log on the terminal application."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfiltering outlier detectors by standard deviation.", "response": "def std_filter(array, n_std=2.0, return_index=False):\n    \"\"\"Standard deviation outlier detector.\n\n    :param array: array of data.\n    :param n_std: default 2.0, exclude data out of ``n_std`` standard deviation.\n    :param return_index: boolean, default False, if True, only returns index.\n    \"\"\"\n    if not isinstance(array, np.ndarray):\n        array = np.array(array)\n    mean, std = array.mean(), array.std()\n\n    good_index = np.where(abs(array - mean) <= n_std * std)\n    bad_index = np.where(abs(array - mean) > n_std * std)\n\n    if return_index:\n        return good_index[0], bad_index[0]\n    else:\n        return array[good_index], array[bad_index]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef box_filter(array, n_iqr=1.5, return_index=False):\n    if not isinstance(array, np.ndarray):\n        array = np.array(array)\n    Q3 = np.percentile(array, 75)\n    Q1 = np.percentile(array, 25)\n    IQR = Q3 - Q1\n    lower, upper = Q1 - n_iqr * IQR, Q3 + n_iqr * IQR\n\n    good_index = np.where(np.logical_and(array >= lower, array <= upper))\n    bad_index = np.where(np.logical_or(array < lower, array > upper))\n\n    if return_index:\n        return good_index[0], bad_index[0]\n    else:\n        return array[good_index], array[bad_index]", "response": "Box plot outlier detector."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_exif_GEXIV2(oldfile,newfile):\n\n    # Requires gexiv2 and pygobject package in gentoo \n    # (USE=introspection)\n    try:\n        from gi.repository import GExiv2 \n    except:\n        print(\"Couldn't import GExiv2\")\n        print(\"Are you sure you have GExiv2 installed?\")\n        print(\"See this page: http://goo.gl/0bhDGx\")\n        print(\"For gentoo, emerge media-libs/gexiv2 with introspection USE flag\")\n        return False\n        \n\n\n    # exif of orginal image\n    exif = GExiv2.Metadata(oldfile)\n\n    # exif of resized image\n    newExif = GExiv2.Metadata(newfile)\n\n    # Figure out dimensions\n    imgresize = Image.open(newfile)\n\n    # save all exif data of orinal image to resized\n    for tag in exif.get_exif_tags():\n        newExif[tag] = exif[tag]\n\n    # edit exif data - size \n    newExif['Exif.Photo.PixelXDimension'] = str(imgresize.size[0])\n    newExif['Exif.Photo.PixelYDimension'] = str(imgresize.size[1])\n    # FIXME: Doesn't work with PENTAX JPG\n    # Error is: gi._glib.GError: Unsupported data area offset type\n    newExif.save_file()\n\n    return True", "response": "Transfers oldfile s exif to newfile s exif and updates the width and height EXIF fields"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resize_compute_width_height(fullfile,_megapixels):\n\n    img = Image.open(fullfile)\n    width,height=img.size\n\n    current_megapixels=width*height/(2.0**20)\n    scale=sqrt(_megapixels/float(current_megapixels))\n\n    logger.debug('A resize scale would be %f'%(scale))\n    # Can't make bigger, return original\n    if scale>= 1.0:\n        logger.warning('Image is %0.1f MP, trying to scale to %0.1f MP - just using original!',\n                current_megapixels,_megapixels);\n        return width,height\n\n    new_width=int(width*scale)\n    new_height=int(height*scale)\n\n    return new_width,new_height", "response": "Given image file and desired megapixels computes the new width and height"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getexif_location(directory,fn):\n    lat=None\n    lon=None\n\n    sign_lat=+1.0\n    sign_lon=+1.0\n    # Check if photo as geo info already\n    exif_tags=exifread.process_file(\\\n            open(os.path.join(directory,fn),'rb'))\n    try:\n        d,m,s=exif_tags['GPS GPSLongitude'].values\n        # West is negative longitudes, change sign\n        if exif_tags['GPS GPSLongitudeRef'].values=='W':\n            sign_lon=-1.0\n        lon=float(d.num) +float(m.num)/60.0 +float(s.num/float(s.den))/3600.0\n        lon=lon*sign_lon\n        d,m,s=exif_tags['GPS GPSLatitude'].values\n        # South is negative latitude, change sign\n        if exif_tags['GPS GPSLatitudeRef'].values=='S':\n            sign_lat=-1.0\n        lat=float(d.num)\\\n                +float(m.num)/60.0\\\n                +float(s.num/float(s.den))/3600.0\n        lat=lat*sign_lat\n    except:\n        logger.debug(\"%s - Couldn't extract GPS info\"%(fn))\n\n    return lat,lon", "response": "Returns touple of lat lon if EXIF file is present else returns None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconstructing a CLI. Parameter from an xml node.", "response": "def from_xml_node(xml_node):\n        \"\"\"constructs a CLI.Parameter from an xml node.\n        :param xml_node:\n        :type xml_node: xml.etree.ElementTree.Element\n        :rtype: Executable.Parameter\n        :return:\n        \"\"\"\n\n        def gather_enum_values():\n            l = []\n            for element in xml_node.iterfind('element'):\n                l.append(element.text)\n            return l\n\n        name = xml_node.findtext(\"name\")\n        type = xml_node.tag\n\n        if type in (\"label\", \"description\"): return None\n\n        default = xml_node.findtext(\"default\")\n\n        longflag = xml_node.findtext('longflag')\n\n        if default:\n            default = default.replace('\"', '').replace(\"'\", '')\n\n        index = xml_node.findtext('index')\n\n        label = xml_node.findtext('label') or name or longflag\n\n        doc = xml_node.findtext('description')\n\n        values = gather_enum_values()\n\n        channel = xml_node.findtext('channel')\n\n        file_ext = xml_node.attrib.get('fileExtensions', None)\n\n        return Parameter(name, type, default, doc, channel, values=values, index=index, label=label,\n                         longflag=longflag, file_ext=file_ext)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a valid command line call for the executable given by call arguments in kwargs.", "response": "def cmdline(self, **kwargs):\n        \"\"\"Generates a valid command line call for the executable given by call arguments in `kwargs`\n        :param kwargs: values to call the executable\n        :return: the command line\n        :rtype: list\n        \"\"\"\n\n        args = [self.executable]\n        indexed_args = []\n\n        for key, value in kwargs.iteritems():\n            parameter = self[key]\n            if value != parameter.default:\n                no_value = parameter.type == 'boolean'\n\n                if parameter.longflag:  # use longflag where possible\n                    args.append(\"--%s\" % parameter.longflag)\n                    if no_value:\n                        args.append(str(value))\n                elif parameter.flag:\n                    args.append(\"-%s\" % parameter.flag)\n                    if no_value:\n                        args.append(str(value))\n                elif parameter.index:\n                    indexed_args.insert(int(parameter.index), str(value))\n\n        return args + indexed_args"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconstructs an executable form a given ElementTree structure.", "response": "def from_etree(tree):\n        \"\"\"Constructs an executable form a given ElementTree structure.\n\n        :param tree:\n        :type tree: xml.etree.ElementTree.ElementTree\n\n        :rtype: Executable\n        \"\"\"\n        exe = Executable(tree)\n\n        exe.category = tree.findtext('category')\n        exe.version = tree.findtext('version')\n        exe.title = tree.findtext('title') or exe.name\n        exe.description = tree.findtext('description')\n        exe.license = tree.findtext('license') or \"unknown\"\n        exe.contributor = tree.findtext('contributor')\n\n        for ps in tree.iterfind(\"parameters\"):\n            assert isinstance(ps, ET.Element)\n            paras = ParameterGroup(\n                ps.findtext(\"label\"),\n                ps.findtext(\"description\"),\n                ps.attrib.get('advanced', \"false\") == \"true\",\n                filter(lambda x: x is not None,\n                       map(Parameter.from_xml_node, list(ps))))\n\n            exe.parameter_groups.append(paras)\n\n        return exe"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreport the boundary configuration details.", "response": "def ReportConfiguration(self, f):\n        \"\"\"Report the boundary configuration details\n\n        :param f: File (or standard out/err)\n        :return: None\n        \"\"\"\n\n        if BoundaryCheck.chrom != -1:\n            print >> f, BuildReportLine(\"CHROM\", BoundaryCheck.chrom)\n            if len(self.start_bounds) > 0:\n                bounds = \",\".join([\"%s-%s\" % (a[0], a[1]) for a in zip(self.start_bounds, self.end_bounds)])\n                print >> f, BuildReportLine(\"SNP BOUNDARY\", bounds)\n        if len(self.ignored_rs) > 0:\n            print >> f, BuildReportLine(\"IGNORED RS\", \",\".join(self.ignored_rs))\n        if len(self.target_rs) > 0:\n            print >> f, BuildReportLine(\"TARGET RS\", \",\".join(self.target_rs))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef NoExclusions(self):\n        if len(self.start_bounds) + len(self.target_rs) + len(self.ignored_rs) == 0:\n            return BoundaryCheck.chrom == -1\n        return False", "response": "Determine that there are no exclusion criterion in play\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd host and port attributes", "response": "def set_address(self, host, port):\n        \"\"\"Add host and port attributes\"\"\"\n        self.host = host\n        self.port = port"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconnecting to given host address and port.", "response": "def connect(self, host=None, port=None):\n        \"\"\"Connects to given host address and port.\"\"\"\n        host = self.host if host is None else host\n        port = self.port if port is None else port\n        self.socket.connect(host, port)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a message inside the given file.", "response": "def send_file_message(self, filename):\n        \"\"\"Send message inside the given file.\"\"\"\n        data = self._readFile(filename)\n        self.print_debug_message(data)\n        self.socket.send(data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_message(self, message):\n        self.print_debug_message(message)\n        self.socket.send(message)", "response": "Send a given message to the remote host."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if first_path s mtime is higher than second_path s mtime.", "response": "def modified_after(first_path, second_path):\n    \"\"\"Returns True if first_path's mtime is higher than second_path's mtime.\"\"\"\n    try:\n        first_mtime = os.stat(first_path).st_mtime\n    except EnvironmentError:\n        return False\n    try:\n        second_mtime = os.stat(second_path).st_mtime\n    except EnvironmentError:\n        return True\n    return first_mtime > second_mtime"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send(self, to, from_, body, dm=False):\n        tweet = '@{0} {1}'.format(to, body)\n\n        if from_ not in self.accounts:\n            raise AccountNotFoundError()\n        if len(tweet) > 140:\n            raise TweetTooLongError()\n\n        self.auth.set_access_token(*self.accounts.get(from_))\n        api = tweepy.API(self.auth)\n        if dm:\n            api.send_direct_message(screen_name=to, text=body)\n        else:\n            api.update_status(tweet)\n        return", "response": "Send a message to the specified user."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake an image url and averages it.", "response": "def average_image_url(url, name, timeout=5, max_size=5):\n    \"\"\"Takes an image url and averages the image.\n    Arguments\n    url: str\n        url for image to average\n    name: str\n        name to use\n    timeout: int\n        request timeout in seconds\n    max_size: int\n        max size of request in MB\n    return {red':r_avg, 'green':g_avg, 'blue':b_avg} or None\n    \"\"\"\n    try:\n        shorturl = url.rsplit('/', 1)[-1]\n        logger.debug('Full URL,           %s', url)\n        response = requests.get(url, timeout=timeout, stream=True)\n        length = int(response.headers.get('Content-Length', 0))\n        logger.debug('Request size,       %s - %.2fKB', shorturl, length/1024)\n        if length > (1024 * 1024 * max_size):\n            raise OversizeException(\n                'Response size {2}MB, larger than {0}MB, discarding: {1}'\n                .format(max_size, url, math.ceil(length/1024/1024)))\n        logger.debug('Finished request,   %s', shorturl)\n        result = imagecolor.average(BytesIO(response.content), name=name)\n        logger.debug('Averaging complete, %s', shorturl)\n        return(result)\n    except OversizeException as e:\n        logger.warning('Exception: %s', e)\n        return(None)\n    except Exception as e:\n        logger.warning('Exception: %s @ %s', e, url)\n        logger.debug('Traceback:', exc_info=True)\n        return(None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes a list of image urls and averages the images to get the average color.", "response": "def _image_search_average(url_list, max_threads=2, **kwargs):\n    \"\"\"Takes a list of image urls and averages the images to get the\n    average color. Designed to be implimented with many methods of\n    url sourcing.\n    Arguments\n    url_list: list\n        list of strings with the image urls to average\n    max_threads: int\n        max number of processes to spawn\n    return {red':r_avg, 'green':g_avg, 'blue':b_avg} or None\n    \"\"\"\n    if len(url_list) < 1:\n        raise ZeroResultsException('No urls to average')\n    r_total = 0\n    g_total = 0\n    b_total = 0\n    imagecount = 0\n    num_results = len(url_list)\n    names = [n for n in range(num_results)]\n    if num_results <= max_threads:\n        threads = num_results\n    else:\n        threads = max_threads\n    with Pool(threads) as p:\n        results = p.starmap(partial(\n            average_image_url, **kwargs), zip(url_list, names))\n    logger.debug('All results averaged')\n    for result in results:\n        try:\n            if result is not None:\n                r_total += result['red']\n                g_total += result['green']\n                b_total += result['blue']\n                imagecount += 1\n        except TypeError:\n            logger.debug('TypeError when iterating over results',\n                         exc_info=True)\n    logger.debug('Image count %d', imagecount)\n    if imagecount > 0:\n        logger.debug('Image count greater then 0')\n        r_avg = int(r_total / imagecount)\n        g_avg = int(g_total / imagecount)\n        b_avg = int(b_total / imagecount)\n        return({'red': r_avg, 'green': g_avg, 'blue': b_avg})\n    else:\n        raise ZeroResultsException('Nothing averaged successfully')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef google_average(search_term, num_results, api_key, cse_id, **kwargs):\n    url_list = []\n    result = {'name': search_term}\n    GIS = GoogleImageSearch(api_key, cse_id)\n    url_list = GIS.search(search_term, num_results)\n    result.update(_image_search_average(url_list, **kwargs))\n    return(result)", "response": "Does a Google image search to get the average color of the top x results."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndo a Microsoft Cognitive image search to get the average color of the top x results. Arguments search_term: str tearm to search for num_results: int number of results to average api_key: str Microsoft Cognitive API key max_threads: int max number of processes to spawn return {'name':search_term, 'red':r_avg, 'green':g_avg, 'blue':b_avg} or None", "response": "def mscs_average(search_term, num_results, api_key, **kwargs):\n    \"\"\"Does a Microsoft Cognitive image search to get the average color of the\n    top x results.\n    Arguments\n    search_term: str\n        tearm to search for\n    num_results: int\n        number of results to average\n    api_key: str\n        Microsoft Cognitive API key\n    max_threads: int\n        max number of processes to spawn\n\n    return {'name':search_term, 'red':r_avg, 'green':g_avg, 'blue':b_avg}\n    or None\n    \"\"\"\n    url_list = []\n    result = {'name': search_term}\n    MCIS = MicrosoftCognitiveImageSearch(api_key)\n    url_list = MCIS.search(search_term, num_results)\n    result.update(_image_search_average(url_list, **kwargs))\n    return(result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse an NGINX timestamp from 30 Apr / 2015 - 07 - 32 +0000 and returns it as ISO 8601", "response": "def to_ts(s):\n        \"\"\"Parses an NGINX timestamp from  \"30/Apr/2014:07:32:09 +0000\" and returns it as ISO 8601\" \"\"\"\n\n        # Strip TZ portion if present\n        m = Nginx.DATE_FMT.match(s)\n        if m:\n            s = m.group(1)\n            delta = timedelta(seconds=int(m.group(3)) * (-1 if m.group(2) == '-' else 1)) # Offset from GMT\n        else:\n            delta = timedelta(seconds=0)\n        dt = datetime.strptime(s, \"%d/%b/%Y:%H:%M:%S\")\n        dt += delta\n        return dt.strftime('%Y-%m-%dT%H:%M:%SZ')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nencodes a dictionary for url representation.", "response": "def encode(cls, d):\n        \"\"\"\n        Internal: encode a string for url representation\n        \"\"\"\n        warnings.warn(\n            'The `encode` class method of APIRequestor is deprecated and '\n            'will be removed in version 2.0.'\n            'If you need public access to this function, please email us '\n            'at support@stripe.com.',\n            DeprecationWarning)\n        return urllib.urlencode(list(_api_encode(d)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking a request to the Stripe API.", "response": "def request_raw(self, method, url, params=None, supplied_headers=None):\n        \"\"\"\n        Mechanism for issuing an API call\n        \"\"\"\n        from stripe import api_version\n\n        if self.api_key:\n            my_api_key = self.api_key\n        else:\n            from stripe import api_key\n            my_api_key = api_key\n\n        if my_api_key is None:\n            raise error.AuthenticationError(\n                'No API key provided. (HINT: set your API key using '\n                '\"stripe.api_key = <API-KEY>\"). You can generate API keys '\n                'from the Stripe web interface.  See https://stripe.com/api '\n                'for details, or email support@stripe.com if you have any '\n                'questions.')\n\n        abs_url = '%s%s' % (self.api_base, url)\n\n        encoded_params = urllib.urlencode(list(_api_encode(params or {})))\n\n        if method == 'get' or method == 'delete':\n            if params:\n                abs_url = _build_api_url(abs_url, encoded_params)\n            post_data = None\n        elif method == 'post':\n            if supplied_headers is not None and \\\n                    supplied_headers.get(\"Content-Type\") == \\\n                    \"multipart/form-data\":\n                generator = MultipartDataGenerator()\n                generator.add_params(params or {})\n                post_data = generator.get_post_data()\n                supplied_headers[\"Content-Type\"] = \\\n                    \"multipart/form-data; boundary=%s\" % (generator.boundary,)\n            else:\n                post_data = encoded_params\n        else:\n            raise error.APIConnectionError(\n                'Unrecognized HTTP method %r.  This may indicate a bug in the '\n                'Stripe bindings.  Please contact support@stripe.com for '\n                'assistance.' % (method,))\n\n        ua = {\n            'bindings_version': version.VERSION,\n            'lang': 'python',\n            'publisher': 'stripe',\n            'httplib': self._client.name,\n        }\n        for attr, func in [['lang_version', platform.python_version],\n                           ['platform', platform.platform],\n                           ['uname', lambda: ' '.join(platform.uname())]]:\n            try:\n                val = func()\n            except Exception as e:\n                val = \"!! %s\" % (e,)\n            ua[attr] = val\n\n        headers = {\n            'X-Stripe-Client-User-Agent': util.json.dumps(ua),\n            'User-Agent': 'Stripe/v1 PythonBindings/%s' % (version.VERSION,),\n            'Authorization': 'Bearer %s' % (my_api_key,)\n        }\n\n        if self.stripe_account:\n            headers['Stripe-Account'] = self.stripe_account\n\n        if method == 'post':\n            headers['Content-Type'] = 'application/x-www-form-urlencoded'\n\n        if api_version is not None:\n            headers['Stripe-Version'] = api_version\n\n        if supplied_headers is not None:\n            for key, value in supplied_headers.items():\n                headers[key] = value\n\n        util.log_info('Request to Stripe api', method=method, path=abs_url)\n        util.log_debug(\n            'Post details', post_data=post_data, api_version=api_version)\n\n        rbody, rcode, rheaders = self._client.request(\n            method, abs_url, headers, post_data)\n\n        util.log_info(\n            'Stripe API response', path=abs_url, response_code=rcode)\n        util.log_debug('API response body', body=rbody)\n        if 'Request-Id' in rheaders:\n            util.log_debug('Dashboard link for request',\n                           link=util.dashboard_link(rheaders['Request-Id']))\n        return rbody, rcode, rheaders, my_api_key"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_epsilon(line, lines):\n\n    split_line = line.split()\n\n    energy = float(split_line[0])\n    re_eps_xx = float(split_line[1])\n    im_eps_xx = float(split_line[2])\n    re_eps_zz = float(split_line[3])\n    im_eps_zz = float(split_line[4])\n\n    return {\"energy\": energy, \"re_eps_xx\": re_eps_xx, \"im_eps_xx\": im_eps_xx, \"re_eps_zz\": re_eps_zz,\n            \"im_eps_zz\": im_eps_zz}", "response": "Parse Energy Re_eps_xx Im_eps_xx Re_eps_zz Im_eps_zz "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloops while running the inbox and handle incoming packages.", "response": "def _packet_loop(self):\n        \"\"\"\n        Loop (while running) the inbox and handle incoming packages\n\n        :rtype: None\n        \"\"\"\n        while not self._is_stopped.is_set():\n            if self.inbox.empty() and \\\n                    not self.new_packet.wait(self._packet_wait):\n                continue\n            ip, port, packet = self.inbox.get()\n\n            if self.inbox.empty():\n                self.new_packet.clear()\n\n            self._do_packet(packet, ip, port)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreact to incoming packet", "response": "def _do_packet(self, packet, ip, port):\n        \"\"\"\n        React to incoming packet\n\n        :param packet: Packet to handle\n        :type packet: T >= paps.si.app.message.APPMessage\n        :param ip: Client ip address\n        :type ip: unicode\n        :param port: Client port\n        :type port: int\n        :rtype: None\n        \"\"\"\n        msg_type = packet.header.message_type\n\n        if msg_type == MsgType.JOIN:\n            self._do_join_packet(packet, ip, port)\n        elif msg_type == MsgType.UNJOIN:\n            self._do_unjoin_packet(packet, ip, port)\n        elif msg_type == MsgType.UPDATE:\n            self._do_update_packet(packet, ip, port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _do_join_packet(self, packet, ip, port):\n        self.debug(\"()\")\n        device_id = packet.header.device_id\n        key = u\"{}:{}\".format(ip, port)\n\n        if device_id == Id.REQUEST:\n            device_id = self._new_device_id(key)\n\n        client = self._clients.get(device_id, {})\n        data = {}\n\n        if packet.payload:\n            try:\n                data = packet.payload\n            except:\n                data = {}\n\n        client['device_id'] = device_id\n        client['key'] = key\n        people = []\n        try:\n            for index, person_dict in enumerate(data['people']):\n                person = Person()\n                person.from_dict(person_dict)\n                person.id = u\"{}.{}\".format(device_id, person.id)\n                # To get original id -> id.split('.')[0]\n                people.append(person)\n            self.changer.on_person_new(people)\n        except:\n            self.exception(\"Failed to update people\")\n            return\n\n        # Original ids (without device id)\n        client['people'] = people\n        # Add config to client data?\n        client_dict = dict(client)\n        del client_dict['people']\n\n        self._send_packet(ip, port, APPConfigMessage(payload=client_dict))\n        self._clients[device_id] = client\n        self._key2deviceId[key] = device_id", "response": "React to join packet - add a client to this server"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreacting to unjoin packet - remove a client from this server", "response": "def _do_unjoin_packet(self, packet, ip, port):\n        \"\"\"\n        React to unjoin packet - remove a client from this server\n\n        :param packet: Packet from client that wants to join\n        :type packet: paps.si.app.message.APPJoinMessage\n        :param ip: Client ip address\n        :type ip: unicode\n        :param port: Client port\n        :type port: int\n        :rtype: None\n        \"\"\"\n        self.debug(\"()\")\n        device_id = packet.header.device_id\n\n        if device_id <= Id.SERVER:\n            self.error(\"ProtocolViolation: Invalid device id\")\n            return\n        client = self._clients.get(device_id)\n        if not client:\n            self.error(\"ProtocolViolation: Client is not registered\")\n            return\n        key = u\"{}:{}\".format(ip, port)\n        if client['key'] != key:\n            self.error(\n                u\"ProtocolViolation: Client key ({}) has changed: {}\".format(\n                    client['key'], key\n                )\n            )\n            return\n\n        # Packet info seems ok\n        try:\n            self.changer.on_person_leave(client['people'])\n        except:\n            self.exception(\"Failed to remove people\")\n            return\n\n        # Forget client?\n        del self._clients[device_id]\n        del self._key2deviceId[key]\n        del client"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreacting to update packet - people and person on a device have changed", "response": "def _do_update_packet(self, packet, ip, port):\n        \"\"\"\n        React to update packet - people/person on a device have changed\n\n        :param packet: Packet from client with changes\n        :type packet: paps.si.app.message.APPUpdateMessage\n        :param ip: Client ip address\n        :type ip: unicode\n        :param port: Client port\n        :type port: int\n        :rtype: None\n        \"\"\"\n        self.debug(\"()\")\n        device_id = packet.header.device_id\n        if device_id <= Id.SERVER:\n            self.error(\"ProtocolViolation: Invalid device id\")\n            return\n        client = self._clients.get(device_id, None)\n        if not client:\n            self.error(\"ProtocolViolation: Client is not registered\")\n            return\n        key = u\"{}:{}\".format(ip, port)\n        if client['key'] != key:\n            self.error(\n                u\"ProtocolViolation: Client key ({}) has changed: {}\".format(\n                    client['key'], key\n                )\n            )\n            return\n\n        # Packet info seems ok\n        try:\n            people = packet.people()\n        except ProtocolViolation:\n            self.exception(\"Failed to decode people from packet\")\n            return\n\n        # Verify same number of people in update as registered to client\n        # (APP specific)\n        if len(people) != len(client['people']):\n            self.error(\"ProtocolViolation: Incorrect number of people updated\")\n        changed = []\n        # Add ids to all people\n        # Assumes same order here as on the client (e.g from the join())\n        for index, person in enumerate(people):\n            old = client['people'][index]\n            person.id = old.id\n            if person != old:\n                old.sitting = person.sitting\n                # Maybe sent person to protect access to local saved state\n                changed.append(old)\n        if changed:\n            # Only update if there is really a change\n            try:\n                self.changer.on_person_update(changed)\n            except:\n                self.exception(\"Failed to notify people update\")\n                return\n        else:\n            self.debug(\"No people updated\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _new_device_id(self, key):\n        device_id = Id.SERVER + 1\n        if key in self._key2deviceId:\n            return self._key2deviceId[key]\n        while device_id in self._clients:\n            device_id += 1\n        return device_id", "response": "Generate a new device id for a given key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _init_multicast_socket(self):\n        self.debug(\"()\")\n        # Create a UDP socket\n        self._multicast_socket = socket.socket(\n            socket.AF_INET,\n            socket.SOCK_DGRAM\n        )\n\n        # Allow reuse of addresses\n        self._multicast_socket.setsockopt(\n            socket.SOL_SOCKET,\n            socket.SO_REUSEADDR,\n            1\n        )\n\n        # Set multicast interface to local_ip\n        self._multicast_socket.setsockopt(\n            socket.IPPROTO_IP,\n            socket.IP_MULTICAST_IF,\n            socket.inet_aton(self._multicast_ip)\n        )\n\n        # Set multicast time-to-live\n        # Should keep our multicast packets from escaping the local network\n        self._multicast_socket.setsockopt(\n            socket.IPPROTO_IP,\n            socket.IP_MULTICAST_TTL,\n            self._multicast_ttl\n        )\n\n        self._add_membership_multicast_socket()\n        # Bind socket\n        if platform.system().lower() == \"darwin\":\n            self._multicast_socket.bind((\"0.0.0.0\", self._multicast_bind_port))\n        else:\n            self._multicast_socket.bind(\n                (self._multicast_ip, self._multicast_bind_port)\n            )\n        self._listening.append(self._multicast_socket)", "response": "Initializes the multicast socket and adds membership to the multicast socket list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend the multicast membership request to the multicast socket.", "response": "def _add_membership_multicast_socket(self):\n        \"\"\"\n        Make membership request to multicast\n\n        :rtype: None\n        \"\"\"\n        self._membership_request = socket.inet_aton(self._multicast_group) \\\n            + socket.inet_aton(self._multicast_ip)\n\n        # Send add membership request to socket\n        # See http://www.tldp.org/HOWTO/Multicast-HOWTO-6.html\n        # for explanation of sockopts\n        self._multicast_socket.setsockopt(\n            socket.IPPROTO_IP,\n            socket.IP_ADD_MEMBERSHIP,\n            self._membership_request\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndropping membership to multicast socket.", "response": "def _drop_membership_multicast_socket(self):\n        \"\"\"\n        Drop membership to multicast\n\n        :rtype: None\n        \"\"\"\n        # Leave group\n        self._multicast_socket.setsockopt(\n            socket.IPPROTO_IP,\n            socket.IP_DROP_MEMBERSHIP,\n            self._membership_request\n        )\n        self._membership_request = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start(self, blocking=False):\n        self.debug(\"()\")\n        try:\n            self._init_multicast_socket()\n        except:\n            self._multicast_socket = None\n            self.exception(\"Failed to init multicast socket\")\n            raise SensorStartException(\"Multicast socket init failed\")\n\n        super(SensorServer, self).start(blocking=False)\n        self._is_stopped.clear()\n        try:\n            a_thread = threading.Thread(\n                target=self._thread_wrapper,\n                args=(self._packet_loop,)\n            )\n            a_thread.daemon = True\n            a_thread.start()\n        except:\n            self.exception(\"Failed to run packet loop\")\n            raise SensorStartException(\"Packet loop failed\")\n        self.info(\"Started\")\n        # Blocking\n        super(Sensor, self).start(blocking)", "response": "Start the interface with the specified attributes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstop the sensor server.", "response": "def stop(self):\n        \"\"\"\n        Stop the sensor server (soft stop - signal packet loop to stop)\n        Warning: Is non blocking (server might still do something after this!)\n\n        :rtype: None\n        \"\"\"\n        self.debug(\"()\")\n        super(SensorServer, self).stop()\n        # No new clients\n        if self._multicast_socket is not None:\n            self._shutdown_multicast_socket()\n        # Signal packet loop to shutdown\n        self._is_stopped.set()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nturn off the light by gradually fading it out.", "response": "def fade_out(self, duration=3):\n        \"\"\"Turns off the light by gradually fading it out.\n        The optional `duration` parameter allows for control\n        of the fade out duration (in seconds)\"\"\"\n        super(RgbLight, self).fade_out(duration)\n        self.off()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef evert(iterable: Iterable[Dict[str, Tuple]]) -> Iterable[Iterable[Dict[str, Any]]]:\n    '''Evert dictionaries with tuples.\n\n    Iterates over the list of dictionaries and everts them with their tuple\n    values.  For example:\n\n    ``[ { 'a': ( 1, 2, ), }, ]``\n\n    becomes\n\n    ``[ ( { 'a': 1, }, ), ( { 'a', 2, }, ) ]``\n\n    The resulting iterable contains the same number of tuples as the\n    initial iterable had tuple elements.  The number of dictionaries is the same\n    as the cartesian product of the initial iterable's tuple elements.\n\n    Parameters\n    ----------\n\n    :``iterable``: list of dictionaries whose values are tuples\n\n    Return Value(s)\n    ---------------\n\n    All combinations of the choices in the dictionaries.\n\n    '''\n\n    keys = list(itertools.chain.from_iterable([ _.keys() for _ in iterable ]))\n\n    for values in itertools.product(*[ list(*_.values()) for _ in iterable ]):\n        yield [ dict(( pair, )) for pair in zip(keys, values) ]", "response": "Evert dictionaries with tuples."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extend(base: Dict[Any, Any], extension: Dict[Any, Any]) -> Dict[Any, Any]:\n    '''Extend base by updating with the extension.\n\n    **Arguments**\n\n    :``base``:      dictionary to have keys updated or added\n    :``extension``: dictionary to update base with\n\n    **Return Value(s)**\n\n    Resulting dictionary from updating base with extension.\n\n    '''\n\n    _ = copy.deepcopy(base)\n    _.update(extension)\n\n    return _", "response": "Extend base by updating with the extension."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge(base: Dict[Any, Any], extension: Dict[Any, Any]) -> Dict[Any, Any]:\n    '''Merge extension into base recursively.\n\n    **Argumetnts**\n\n    :``base``:      dictionary to overlay values onto\n    :``extension``: dictionary to overlay with\n\n    **Return Value(s)**\n\n    Resulting dictionary from overlaying extension on base.\n\n    '''\n\n    _ = copy.deepcopy(base)\n\n    for key, value in extension.items():\n        if isinstance(value, Dict) and key in _:\n            _[key] = merge(_[key], value)\n        else:\n            _[key] = value\n\n    return _", "response": "Merge base dictionary with extension into base recursively."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads all python modules in directory and directory s children.", "response": "def import_directory(module_basename: str, directory: str, sort_key = None) -> None:\n    '''Load all python modules in directory and directory's children.\n\n    Parameters\n    ----------\n\n    :``module_basename``: module name prefix for loaded modules\n    :``directory``:       directory to load python modules from\n    :``sort_key``:        function to sort module names with before loading\n\n    '''\n\n    logger.info('loading submodules of %s', module_basename)\n    logger.info('loading modules from %s', directory)\n\n    filenames = itertools.chain(*[ [ os.path.join(_[0], filename) for filename in _[2] ] for _ in os.walk(directory) if len(_[2]) ])\n    modulenames = _filenames_to_modulenames(filenames, module_basename, directory)\n\n    for modulename in sorted(modulenames, key = sort_key):\n        try:\n            importlib.import_module(modulename)\n        except ImportError:\n            logger.warning('failed loading %s', modulename)\n            logger.exception('module loading failure')\n        else:\n            logger.info('successfully loaded %s', modulename)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _filenames_to_modulenames(filenames: Iterable[str], modulename_prefix: str, filename_prefix: str = '') -> Iterable[str]:\n    '''Convert given filenames to module names.\n\n    Any filename that does not have a corresponding module name will be dropped\n    from the result (i.e. __init__.py).\n\n    Parameters\n    ----------\n\n    :``filename_prefix``:   a prefix to drop from all filenames (typically a\n                            common directory); defaults to ''\n    :``filenames``:         the filenames to transform into module names\n    :``modulename_prefix``: a prefix to add to all module names\n\n    Return Value(s)\n    ---------------\n\n    A list of modulenames corresponding to all filenames (for legal module names).\n\n    '''\n\n    modulenames = []  # type: Iterable[str]\n\n    for filename in filenames:\n        if not filename.endswith('.py'):\n            continue\n\n        name = filename\n\n        name = name.replace(filename_prefix, '')\n        name = name.replace('__init__.py', '')\n        name = name.replace('.py', '')\n        name = name.replace('/', '.')\n\n        name = name.strip('.')\n\n        if not len(name):\n            continue\n\n        if not modulename_prefix.endswith('.'):\n            modulename_prefix += '.'\n\n        name = modulename_prefix + name\n\n        known_symbols = set()\n        name = '.'.join([ _ for _ in name.split('.') if _ not in known_symbols and not known_symbols.add(_) ])\n\n        if len(name):\n            modulenames.append(name)\n\n    return modulenames", "response": "Convert given filenames into module names."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _write_object(self, val, outstream):\n        '''\n        Write object into the stream\n        :param val:\n        :param outstream:\n        '''\n        # first attempt using an existing custom serializer\n        serializer = self.__lookup_serializer(getattr(val, '__class__'))\n        if serializer is not None:\n            serializer.serialize(self, val, outstream)\n            return\n        \n        fields = self._fetch_obj_fields(val)\n        validfields = [];\n        encodedfields = []\n        length = 0;\n        for f in fields:\n            encoded = self._encode_field_name(val, f)\n            if encoded:\n                encodedfields.append(encoded)\n                validfields.append(f)\n                length += 1;\n        self.write_object_start(length, outstream)\n        count = 0;\n        if length > 0:\n            mappedname = encodedfields[0]\n            if mappedname is not None:\n                count += 1\n                self.write_object_field(mappedname, getattr(val, validfields[0]), outstream)\n            idx = 1\n            while idx < length:      \n                name = validfields[idx]\n                mappedname = encodedfields[idx]\n                if mappedname is not None:\n                    value = getattr(val, name)\n                    if count > 0:\n                        self.write_object_field_separator(mappedname, value, outstream)\n                    self.write_object_field(mappedname, value, outstream)\n                    count += 1\n                idx += 1\n        self.write_object_end(length, outstream)", "response": "Writes the object into the stream"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites a dictionary of the related class names and values to the output stream.", "response": "def _write_dict(self, val, outstream):\n        '''\n        write a dictionary\n        :param val:\n        :param outstream:\n        '''\n        fields = val.keys()\n        length = len(fields)\n        self.write_dict_start(length, outstream)\n        if length > 0:\n            self.write_dict_field(fields[0], val[fields[0]], outstream)\n            idx = 1\n            while idx < length:\n                name = fields[idx]\n                value = val[fields[idx]]\n                self.write_dict_field_separator(name, value, outstream)\n                self.write_dict_field(name, value, outstream)\n                idx += 1\n        self.write_dict_end(length, outstream)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall whenever an FS event occurs.", "response": "def on_any_event(self, event):\n        \"\"\"Called whenever a FS event occurs.\"\"\"\n        self.updated = True\n        if self._changed:\n            self._changed()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncollect all changes that have been performed on the monitored path and returns them as a tuple.", "response": "def changes(self):\n        \"\"\"Collects all changes that have been performed on the monitored path,\n        returning them as a (created, deleted) tuple.\"\"\"\n        deleted = []\n        for path in list(self.files):\n            isdir = path.endswith(os.sep)\n            abspath = os.path.join(self.path, path)\n            try:\n                is_deleted = (\n                    not os.path.exists(abspath) or  # actually deleted\n                    os.path.isdir(abspath) != isdir  # changed from / to folder\n                )\n            except EnvironmentError:\n                # file is basically inaccessible at this point so we're gonna\n                # assume that it was deleted\n                is_deleted = True\n\n            if is_deleted:\n                deleted.append(path)\n                del self.files[path]\n\n        changed = []\n        for folder, subfolders, subfiles in os.walk(self.path):\n            for path in subfolders:\n                path = os.path.join(folder, path)\n                path = os.path.normcase(os.path.relpath(path, self.path))\n                path += os.sep\n                if path not in self.files:\n                    # don't really care about folder mtime\n                    self.files[path] = 0\n                    changed.append(path)\n\n            for path in subfiles:\n                actual_path = path = os.path.join(folder, path)\n                path = os.path.normcase(os.path.relpath(path, self.path))\n                try:\n                    mtime = os.path.getmtime(actual_path)\n                    if path not in self.files:\n                        # new file; set its mtime to 0 because it will be\n                        # compared in the next few lines\n                        self.files[path] = 0\n\n                    if mtime > self.files[path]:\n                        # file has been changed since last check\n                        self.files[path] = mtime\n                        changed.append(path)\n                except EnvironmentError:\n                    # in 99% of the cases the file has been deleted while\n                    # iterating the parent folder; if the file was previously\n                    # being handled, then stop handling it; otherwise ignore\n                    if path in self.files:\n                        deleted.append(path)\n                        del self.files[path]\n\n        self.updated = False\n        return changed, deleted"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef log(prefix = ''):\n    '''Add start and stop logging messages to the function.\n\n    Parameters\n    ----------\n\n    :``prefix``: a prefix for the function name (optional)\n\n    '''\n\n    function = None\n\n    if inspect.isfunction(prefix):\n        prefix, function = '', prefix\n\n    def _(function):\n        @functools.wraps(function, assigned = functools.WRAPPER_ASSIGNMENTS + ( '__file__', ))\n        def wrapper(*args, **kwargs):\n            name, my_args = function.__name__, args\n\n            if inspect.ismethod(function):\n                name = function.__self__.__class__.__name__ + '.' + function.__name__\n            elif len(args):\n                members = dict(inspect.getmembers(args[0], predicate = lambda _: inspect.ismethod(_) and _.__name__ == function.__name__))\n                logger.debug('members.keys(): %s', members.keys())\n\n                if len(members):\n                    name, my_args = args[0].__class__.__name__ + '.' + function.__name__, args[1:]\n\n            format_args = (\n                prefix + name,\n                ', '.join(list(map(str, my_args)) + [ ' = '.join(map(str, item)) for item in kwargs.items() ]),\n            )\n\n            logger.info('STARTING: %s(%s)', *format_args)\n\n            try:\n                return function(*args, **kwargs)\n            except:\n                logger.exception('EXCEPTION: %s(%s)', *format_args)\n                raise\n            finally:\n                logger.info('STOPPING: %s(%s)', *format_args)\n\n        return wrapper\n\n    if function is not None:\n        _ = _(function)\n\n    return _", "response": "Add start and stop logging messages to the function."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dict with values that can be fed directly into SelectiveRowGenerator", "response": "def spec(self):\n        \"\"\"Return a dict with values that can be fed directly into SelectiveRowGenerator\"\"\"\n        return dict(\n            headers=self.header_lines,\n            start=self.start_line,\n            comments=self.comment_lines,\n            end=self.end_line\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef picture(self, row):\n\n        template = '_Xn'\n        types = (type(None), binary_type, int)\n\n        def guess_type(v):\n\n            try:\n                v = text_type(v).strip()\n            except ValueError:\n                v = binary_type(v).strip()\n                #v = v.decode('ascii', 'replace').strip()\n\n            if not bool(v):\n                return type(None)\n\n            for t in (float, int, binary_type, text_type):\n                try:\n                    return type(t(v))\n                except:\n                    pass\n\n        def p(e):\n            tm = t = None\n\n            try:\n                t = guess_type(e)\n                tm = self.type_map.get(t, t)\n                return template[types.index(tm)]\n            except ValueError as e:\n                raise ValueError(\"Type '{}'/'{}' not in the types list: {} ({})\".format(t, tm, types, e))\n\n        return ''.join(p(e) for e in row)", "response": "Create a simplified character representation of the data row which can be pattern matched\n        with a regex"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self, head_rows, tail_rows=None, n_rows=None):\n\n        from .exceptions import RowIntuitError\n\n        header_rows = []\n        found_header = False\n        MIN_SKIP_ROWS = 30\n\n        try:\n            data_pattern_skip_rows = min(MIN_SKIP_ROWS, len(head_rows) - 8)\n\n        except TypeError:\n            # Hopefully b/c head_rows is a generator, not a sequence\n            raise RowIntuitError(\"Head_rows must be a sequence, not a generator or iterator\")\n\n\n        try:\n            data_pattern, self.data_pattern_source, n_cols = self.data_pattern(head_rows[data_pattern_skip_rows:])\n        except Exception as e:\n            logger.debug(\"Failed to find data pattern\")\n            raise\n\n        patterns = ([('D', data_pattern),\n                     # More than 25% strings in row is header, if it isn't matched as data\n                     ('H', re.compile(r'X{{{},{}}}'.format(max(3, n_cols/8),max(3,n_cols/4)))),\n                     ] +\n                    list(self.patterns))\n\n        if self.debug:\n\n            logger.debug(\"--- Patterns\")\n            for e in patterns:\n                logger.debug(\"    {} {}\".format(e[0], e[1].pattern))\n\n        for i, row in enumerate(head_rows):\n\n            picture = self.picture(row)\n\n            label = self.match_picture(picture, patterns)\n\n            try:\n                # If a header or data has more than half of the line is a continuous nulls,\n                # it's probably a comment.\n                if label != 'B' and len(re.search('_+', picture).group(0)) > len(row)/2:\n                    label = 'C'\n            except AttributeError:\n                pass  # re not matched\n\n            if not found_header and label == 'H':\n                found_header = True\n\n            if label is False:\n\n                if found_header:\n                    label = 'D'\n                else:\n                    # Could be a really wacky header\n                    found_header = True\n                    label = 'H'\n\n            if self.debug:\n                logger.debug(\"HEAD: {:<5} {} {} {}\".format(i, label, picture, row))\n\n            if label == 'C':\n                self.comment_lines.append(i)\n\n            elif label == 'H':\n                self.header_lines.append(i)\n                header_rows.append(row)\n\n            elif label == 'D':\n                self.start_line = i\n                self.headers = self.coalesce_headers(header_rows)\n                break\n\n        if tail_rows:\n            from itertools import takewhile, islice\n\n            for i, row in enumerate(islice(reversed(tail_rows), 0, 10)):\n                picture = self.picture(row)\n                label = self.match_picture(picture, patterns)\n                logger.debug(\"TAIL: {:<5} {} {} {}\".format(i, label, picture, row))\n\n            # Compute the data label for the end line, then reverse them.\n            labels = reversed(list(self.match_picture(self.picture(row), patterns) for row in tail_rows))\n\n            # Count the number of lines, from the end, that are either comment or blank\n            end_line = len(list(takewhile(lambda x: x == 'C' or x == 'B' or x == 'H', labels)))\n\n            if end_line:\n                self.end_line = n_rows-end_line-1\n\n        return self", "response": "This function runs the intuition process."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake a list of header lines and returns a list of headers that are spread across multiple lines into a single row", "response": "def coalesce_headers(cls, header_lines):\n        \"\"\"Collects headers that are spread across multiple lines into a single row\"\"\"\n\n        header_lines = [list(hl) for hl in header_lines if bool(hl)]\n\n        if len(header_lines) == 0:\n            return []\n\n        if len(header_lines) == 1:\n            return header_lines[0]\n\n        # If there are gaps in the values of a line, copy them forward, so there\n        # is some value in every position\n        for hl in header_lines:\n            last = None\n            for i in range(len(hl)):\n                hli = text_type(hl[i])\n                if not hli.strip():\n                    hl[i] = last\n                else:\n                    last = hli\n\n        headers = [' '.join(text_type(col_val).strip() if col_val else '' for col_val in col_set)\n                   for col_set in zip(*header_lines)]\n\n        headers = [slugify(h.strip()) for h in headers]\n\n        return headers"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef map_recursive(function, iterable):\n    if isiterable(iterable):\n        dataOut = iterable.__class__()\n        for i in iterable:\n            if isinstance(dataOut, dict):\n                dataOut[i] = map_recursive(function, iterable[i])\n            else:\n                # convert to list and append\n                if not isinstance(dataOut, list):\n                    dataOut = list(dataOut)\n                dataOut.append(map_recursive(function, i))\n        return dataOut\n    return function(iterable)", "response": "Apply function recursively to every item or value of iterable and returns a\n    new iterable with the results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a cookie value.", "response": "def get(self, key: Any, default: Any = None) -> Any:\n        \"\"\"\n        \u83b7\u53d6 cookie \u4e2d\u7684 value\n        \"\"\"\n        if key in self:\n            return self[key].value\n        return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the value of a cookie.", "response": "def set(self, key: str, value: str, opt: dict = None) -> None:\n        \"\"\"\n        \u8bbe\u7f6e cookie.value \u5e76\u8bbe\u7f6e\u5c5e\u6027\n        \"\"\"\n        self[key] = value\n        if opt is not None:\n            self[key].update(opt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of headers.", "response": "def headers(self) -> Optional[List[str]]:\n        \"\"\"\n        \u751f\u6210 headers\n        \"\"\"\n        if len(self) == 0:\n            return None\n        headers = cast(List[str], [])\n        for cookie in self.values():\n            headers.append(cookie.OutputString())\n        return headers"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mod_liu(q, w):\n\n    q = asarray(q, float)\n    if not all(isfinite(atleast_1d(q))):\n        raise ValueError(\"There are non-finite values in `q`.\")\n\n    w = asarray(w, float)\n    if not all(isfinite(atleast_1d(w))):\n        raise ValueError(\"There are non-finite values in `w`.\")\n\n    d = sum(w)\n    w /= d\n\n    c1 = sum(w)\n\n    c2 = sum(w ** 2)\n\n    c3 = sum(w ** 3)\n\n    c4 = sum(w ** 4)\n\n    s1 = c3 / (c2 ** (3 / 2))\n\n    s2 = c4 / c2 ** 2\n\n    muQ = c1\n\n    sigmaQ = sqrt(2 * c2)\n\n    if s1 ** 2 > s2:\n\n        a = 1 / (s1 - sqrt(s1 ** 2 - s2))\n\n        delta = s1 * a ** 3 - a ** 2\n\n        l = a ** 2 - 2 * delta\n        if l < 0:\n            raise RuntimeError(\"This term cannot be negative.\")\n\n    else:\n\n        delta = 0\n        l = 1 / s2\n        a = sqrt(l)\n\n    Q_norm = (q / d - muQ) / sigmaQ * sqrt(2 * l) + l\n\n    Qq = atleast_1d(chi2(df=l).sf(Q_norm))[0]\n\n    return (Qq, muQ * d, sigmaQ * d, l)", "response": "r Estimates the joint significance of statistics derived from chi2 - squared distributions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve a card from the deck.", "response": "def get_card(self, index=-1, cache=True, remove=True):\n        \"\"\"\n        Retrieve a card any number of cards from the top. Returns a\n        ``Card`` object loaded from a library if one is specified otherwise\n        just it will simply return its code.\n\n        If `index` is not set then the top  card will be retrieved.\n\n        If cache is set to True (the default) it will tell the library to cache\n        the returned card for faster look-ups in the future.\n\n        If remove is true then the card will be removed from the deck before\n        returning it.\n        \"\"\"\n        if len(self.cards) < index:\n            return None\n\n        retriever = self.cards.pop if remove else self.cards.__getitem__\n        code = retriever(index)\n\n        if self.library:\n            return self.library.load_card(code, cache)\n        else:\n            return code"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef top_cards(self, number=1, cache=True, remove=True):\n        getter = partial(self.get_card(cache=cache, remove=remove))\n        return [getter(index=i) for i in range(number)]", "response": "Retrieve the top number of cards in a\n        list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef move_top_cards(self, other, number=1):\n        other.cards.append(reversed(self.cards[-number:]))", "response": "Move the top number of cards to the top of some other deck."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef contians_attribute(self, attribute):\n        if self.library is None:\n            return 0\n\n        load = self.library.load_card\n        matches = 0\n        for code in self.cards:\n            card = load(code)\n            if card.has_attribute(attribute):\n                matches += 1\n        return matches", "response": "Returns the number of cards in the deck that have the specified attribute."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn how many cards in the deck have the specified value under the specified key under the deck instance.", "response": "def contains_info(self, key, value):\n        \"\"\"\n        Returns how many cards in the deck have the specified value under the\n        specified key in their info data.\n\n        This method requires a library to be stored in the deck instance and\n        will return `None` if there is no library.\n        \"\"\"\n        if self.library is None:\n            return 0\n\n        load = self.library.load_card\n        matches = 0\n        for code in self.cards:\n            card = load(code)\n            if card.get_info(key) == value:\n                matches += 1\n        return matches"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef connect(self):\n        if not self.connect_attempted:\n            self.connect_attempted = True\n            self.client.connect(self.host, port=self.port)\n            self.client.loop_start()\n\n            while not self.connected:\n                log.info('waiting for MQTT connection...')\n                time.sleep(1)", "response": "Connect to the MQTT server and wait for server to acknowledge"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef publish(self, topic, message):\n        self.connect()\n        log.info('publish {}'.format(message))\n        self.client.publish(topic, message)", "response": "Publish an MQTT message to a topic."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_option(namespace, option_name):\n    envvalue = _get_env_value(namespace, option_name)\n\n    idx = 0\n    final_value = []\n\n    if envvalue:\n        final_value.append(envvalue)\n\n    while _get_env_value(namespace, option_name, idx):\n        final_value.append(_get_env_value(namespace, option_name, idx))\n        idx += 1\n\n    return final_value", "response": "Gets an option from the environment variables."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending a templated email.", "response": "def send_templated_mail(tpl, subject, context, to=getattr(settings, 'MIDNIGHT_MAIN_ADMIN_EMAIL', 'admin@example.com')):\n    \"\"\"\n    \u041e\u0442\u043f\u0440\u0430\u0432\u043b\u044f\u0435\u0442 \u043f\u0438\u0441\u044c\u043c\u043e \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u0448\u0430\u0431\u043b\u043e\u043d\u0430\n    :param tpl: \u0448\u0430\u0431\u043b\u043e\u043d\n    :param subject: \u0442\u0435\u043c\u0430 \u043f\u0438\u0441\u044c\u043c\u0430\n    :param context: \u043a\u043e\u043d\u0442\u0435\u043a\u0441\u0442 \u0434\u043b\u044f \u0440\u0435\u043d\u0434\u0435\u0440\u0438\u043d\u0433\u0430 \u0448\u0430\u0431\u043b\u043e\u043d\u0430\n    :param to: \u043a\u043e\u043c\u0443 \u0441\u043b\u0430\u0442\u044c \u043f\u0438\u0441\u044c\u043c\u043e\n    :return:\n    \"\"\"\n    msg_html = render_to_string(tpl, {'context': context})\n\n    send_mail(subject, '', getattr(settings, 'MIDNIGHT_MAIN_MAIL_FROM', 'admin@example.com'),  [to], html_message=msg_html,)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_abilities():\n    page = requests.get('http://bulbapedia.bulbagarden.net/wiki/Ability')\n    soup = bs4.BeautifulSoup(page.text)\n    table = soup.find(\"table\", {\"class\": \"sortable\"})\n    tablerows = [tr for tr in table.children if tr != '\\n'][1:]\n    abilities = {}\n\n    for tr in tablerows:\n        cells = tr.find_all('td')\n        ability_name = cells[1].get_text().strip().replace(' ', '-').lower()\n        ability_desc = unicode(cells[2].get_text().strip())\n        abilities[ability_name] = ability_desc\n\n    srcpath = path.dirname(__file__)\n    with io.open(path.join(srcpath, 'abilities.json'), 'w', encoding='utf-8') as f:\n        f.write(json.dumps(abilities, ensure_ascii=False))", "response": "Visit Bulbapedia and pull names and descriptions from the table and list of Abilities. Save as JSON."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nscrapes data from techshop. ws.", "response": "def data_from_techshop_ws(tws_url):\n    \"\"\"Scrapes data from techshop.ws.\"\"\"\n\n    r = requests.get(tws_url)\n    if r.status_code == 200:\n        data = BeautifulSoup(r.text, \"lxml\")\n    else:\n        data = \"There was an error while accessing data on techshop.ws.\"\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_labs(format):\n\n    techshops_soup = data_from_techshop_ws(techshop_us_url)\n    techshops = {}\n\n    # Load all the TechShops\n    # By first parsing the html\n\n    data = techshops_soup.findAll('div', attrs={'id': 'main-content'})\n    for element in data:\n        links = element.findAll('a')\n        hrefs = {}\n        for k, a in enumerate(links):\n            if \"contact\" not in a['href']:\n                hrefs[k] = a['href']\n        for k, v in hrefs.iteritems():\n            if \"http://techshop.ws/\" not in v:\n                hrefs[k] = \"http://techshop.ws/\" + v\n            else:\n                hrefs[k] = v\n        for k, v in hrefs.iteritems():\n            if \"http://techshop.com/\" in v:\n                hrefs[k] = v.replace(\"http://techshop.com/\", \"\")\n\n    # Remove duplicate pages\n    hr = []\n    for key, value in hrefs.iteritems():\n        if value not in hr:\n            hr.append(value)\n    hrefs = hr\n\n    # Check all pages\n    for page in hrefs:\n        data = data_from_techshop_ws(page)\n        current_lab = Techshop()\n        name = data.title.contents[0].split('-- ')[1].encode('utf-8')\n        if \"TechShop\" not in name:\n            name = \"TechShop \" + name\n        current_lab.name = name\n        current_lab.slug = name\n        current_lab.url = page\n        # Find Facebook and Twitter links\n        current_lab.links = {\"facebook\": \"\", \"twitter\": \"\"}\n        page_links = data.findAll('a')\n        for link in page_links:\n            if link.has_attr(\"href\"):\n                if \"facebook\" in link.attrs[\"href\"]:\n                    current_lab.links[\"facebook\"] = link.attrs[\"href\"]\n                if \"twitter\" in link.attrs[\"href\"]:\n                    current_lab.links[\"twitter\"] = link.attrs[\"href\"]\n        # Find the coordinates by analysing the embedded google map\n        iframes = data.findAll('iframe')\n        if len(iframes) != 0:\n            for iframe in iframes:\n                embed_url = iframe.attrs[\"src\"]\n                if \"google\" in embed_url:\n                    two_d = embed_url.find(\"2d\")\n                    three_d = embed_url.find(\"3d\")\n                    longitude = embed_url[two_d:].split('!')[0]\n                    latitude = embed_url[three_d:].split('!')[0]\n                    longitude = longitude[2:]\n                    latitude = latitude[2:]\n        # ... or the link to google map\n        else:\n            page_links = data.findAll('a')\n            for link in page_links:\n                # one case...\n                if \"maps.google.com/\" in link.attrs[\"href\"]:\n                    embed_url = link.attrs[\"href\"]\n                    if \"ll=\" in embed_url:\n                        first_string = embed_url.split('&sspn')[0]\n                        coordinates = first_string.split('ll=')[1]\n                        latitude = coordinates.split(',')[0]\n                        longitude = coordinates.split(',')[1]\n                # ... another case\n                elif \"www.google.com/maps\" in link.attrs[\"href\"]:\n                    embed_url = link.attrs[\"href\"]\n                    if \"1d\" in embed_url:\n                        one_d = embed_url.find(\"1d\")\n                        two_d = embed_url.find(\"2d\")\n                        longitude = embed_url[one_d:].split('!')[0]\n                        latitude = embed_url[two_d:].split('!')[0]\n                        longitude = longitude[2:]\n                        latitude = latitude[2:]\n        current_lab.latitude = latitude\n        current_lab.longitude = longitude\n        current_lab.continent = \"North America\"\n        current_lab.country_code = \"USA\"\n        current_lab.country = \"United States of America\"\n        location = geolocator.reverse((latitude, longitude))\n        if \"city\" in location.raw[\"address\"]:\n            current_lab.county = location.raw[\"address\"][\"city\"].encode(\n                'utf-8')\n        if \"county\" in location.raw[\"address\"]:\n            current_lab.county = location.raw[\"address\"][\"county\"].encode(\n                'utf-8')\n        if \"state\" in location.raw[\"address\"]:\n            current_lab.state = location.raw[\"address\"][\"state\"].encode(\n                'utf-8')\n        if \"postcode\" in location.raw[\"address\"]:\n            current_lab.postal_code = location.raw[\"address\"][\n                \"postcode\"].encode('utf-8')\n        current_lab.address_1 = location.address.encode('utf-8')\n\n        # Add the lab to the list\n        techshops[current_lab.slug] = current_lab\n\n    # Return a dictiornary / json\n    if format.lower() == \"dict\" or format.lower() == \"json\":\n        output = {}\n        for j in techshops:\n            output[j] = techshops[j].__dict__\n    # Return a geojson\n    elif format.lower() == \"geojson\" or format.lower() == \"geo\":\n        labs_list = []\n        for l in techshops:\n            single = techshops[l].__dict__\n            single_lab = Feature(\n                type=\"Feature\",\n                geometry=Point((single[\"latitude\"], single[\"longitude\"])),\n                properties=single)\n            labs_list.append(single_lab)\n        output = dumps(FeatureCollection(labs_list))\n    # Return a Pandas DataFrame\n    elif format.lower() == \"pandas\" or format.lower() == \"dataframe\":\n        output = {}\n        for j in techshops:\n            output[j] = techshops[j].__dict__\n        # Transform the dict into a Pandas DataFrame\n        output = pd.DataFrame.from_dict(output)\n        output = output.transpose()\n    # Return an object\n    elif format.lower() == \"object\" or format.lower() == \"obj\":\n        output = techshops\n    # Default: return an oject\n    else:\n        output = techshops\n    # Return a proper json\n    if format.lower() == \"json\":\n        output = json.dumps(output)\n    return output", "response": "Gets Techshop data from techshop. ws."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clients(self, protocol=None, groups=None):\n\n    groups = self.__group_replace_eval_by_genuine__(groups)\n    groups = self.check_parameters_for_validity(groups, \"group\", self.client_types())\n    # List of the clients\n    q = self.query(Client)\n    if groups:\n      q = q.filter(Client.stype.in_(groups))\n    q = q.order_by(Client.id)\n    return list(q)", "response": "Returns a list of clients for the specific user."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef model_ids(self, protocol=None, groups=None):\n\n    return [client.subid for client in self.models(protocol, groups)]", "response": "Returns a list of model ids for the specific query by the user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if we have a client with a certain integer identifier", "response": "def has_client_id(self, id):\n    \"\"\"Returns True if we have a client with a certain integer identifier\"\"\"\n\n    return self.query(Client).filter(Client.id==id).count() != 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef client(self, id):\n\n    return self.query(Client).filter(Client.id==id).one()", "response": "Returns the client object in the database given a certain id. Raises\n    an error if that does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef objects(self, protocol=None, purposes=None, model_ids=None, groups=None,\n              classes=None):\n    \"\"\"Returns a list of :py:class:`.File` for the specific query by the user.\n\n    Keyword Parameters:\n\n    protocol\n      One of the Biosecurid protocols ('A').\n\n    purposes\n      The purposes required to be retrieved ('enrol', 'probe') or a tuple\n      with several of them. If 'None' is given (this is the default), it is\n      considered the same as a tuple with all possible values. This field is\n      ignored for the data from the \"world\" group.\n\n    model_ids\n      Only retrieves the files for the provided list of model ids (claimed\n      client id). The model ids are string.  If 'None' is given (this is\n      the default), no filter over the model_ids is performed.\n\n    groups\n      One of the groups ('dev', 'eval', 'world') or a tuple with several of them.\n      If 'None' is given (this is the default), it is considered the same as a\n      tuple with all possible values.\n\n    classes\n      The classes (types of accesses) to be retrieved ('client', 'impostor')\n      or a tuple with several of them. If 'None' is given (this is the\n      default), it is considered the same as a tuple with all possible values.\n\n    Returns: A list of :py:class:`.File` objects.\n    \"\"\"\n\n    #groups = self.__group_replace_alias_clients__(groups)\n    protocol = self.check_parameters_for_validity(protocol, \"protocol\", self.protocol_names())\n    purposes = self.check_parameters_for_validity(purposes, \"purpose\", self.purposes())\n    groups = self.check_parameters_for_validity(groups, \"group\", self.groups())\n    classes = self.check_parameters_for_validity(classes, \"class\", ('client', 'impostor'))\n\n    import collections\n    if(model_ids is None):\n      model_ids = ()\n    elif(not isinstance(model_ids,collections.Iterable)):\n      model_ids = (model_ids,)\n\n    # Now query the database\n    retval = []\n\n    if ('eval' in groups):\n      if('enrol' in purposes):\n        q = self.query(File).join(Client).join((ProtocolPurpose, File.protocolPurposes)).join(Protocol).\\\n              filter(Client.stype.in_(['Genuine'])).\\\n              filter(and_(Protocol.name.in_(protocol), ProtocolPurpose.sgroup.in_(groups), ProtocolPurpose.purpose == 'enrol'))\n        if model_ids:\n          q = q.filter(Client.subid.in_(model_ids))\n        q = q.order_by(File.client_id, File.session_id, File.shot_id)\n        retval += list(q)\n\n      if('probe' in purposes):\n        if('client' in classes):\n          q = self.query(File).join(Client).join((ProtocolPurpose, File.protocolPurposes)).join(Protocol).\\\n                filter(Client.stype.in_(['Genuine'])).\\\n                filter(and_(Protocol.name.in_(protocol), ProtocolPurpose.sgroup.in_(groups), ProtocolPurpose.purpose == 'probe'))\n          if model_ids:\n            q = q.filter(Client.subid.in_(model_ids))\n          q = q.order_by(File.client_id, File.session_id, File.shot_id)\n          retval += list(q)\n\n        if('impostor' in classes):\n          q = self.query(File).join(Client).join((ProtocolPurpose, File.protocolPurposes)).join(Protocol).\\\n                filter(Client.stype.in_(['Impostor'])).\\\n                filter(and_(Protocol.name.in_(protocol), ProtocolPurpose.sgroup.in_(groups), ProtocolPurpose.purpose == 'probe'))\n          if model_ids:\n            q = q.filter(Client.subid.in_(model_ids))\n          q = q.order_by(File.client_id, File.session_id, File.shot_id)\n          retval += list(q)\n\n    return list(set(retval))", "response": "Returns a list of objects for the specific query by the user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning all registered protocol names", "response": "def protocol_names(self):\n    \"\"\"Returns all registered protocol names\"\"\"\n\n    l = self.protocols()\n    retval = [str(k.name) for k in l]\n    return retval"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has_protocol(self, name):\n\n    return self.query(Protocol).filter(Protocol.name==name).count() != 0", "response": "Tells if a certain protocol is available"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the protocol object in the database given a certain name. Raises an error if that does not exist.", "response": "def protocol(self, name):\n    \"\"\"Returns the protocol object in the database given a certain name. Raises\n    an error if that does not exist.\"\"\"\n\n    return self.query(Protocol).filter(Protocol.name==name).one()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setup(__pkg: ModuleType) -> Tuple[Callable[[str], str],\n                                      Callable[[str, str, int], str]]:\n    \"\"\"Configure ``gettext`` for given package.\n\n    Args:\n        __pkg: Package to use as location for :program:`gettext` files\n    Returns:\n        :program:`gettext` functions for singular and plural translations\n\n    \"\"\"\n    package_locale = path.join(path.dirname(__pkg.__file__), 'locale')\n    gettext.install(__pkg.__name__, package_locale)\n\n    return gettext.gettext, gettext.ngettext", "response": "Configure gettext for given package."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns a git command and return the output", "response": "def run(sub_command, quiet=False, no_edit=False, no_verify=False):\n    \"\"\"Run a git command\n\n    Prefix that sub_command with \"git \"\n        then run the command in shell\n\n    If quiet if True then do not log results\n    If no_edit is True then prefix the git command with \"GIT_EDITOR=true\"\n        (which does not wait on user's editor)\n\n    If the command gives a non-zero status, raise a GitError exception\n    \"\"\"\n    if _working_dirs[0] != '.':\n        git_command = 'git -C \"%s\"' % _working_dirs[0]\n    else:\n        git_command = 'git'\n    edit = 'GIT_EDITOR=true' if no_edit else ''\n    verify = 'GIT_SSL_NO_VERIFY=true' if no_verify else ''\n    command = '%s %s %s %s' % (verify, edit, git_command, sub_command)\n    if not quiet:\n        logger.info('$ %s', command)\n    status_, output = getstatusoutput(command)\n    if status_:\n        if quiet:\n            logger.info('$ %s', command)\n        logger.error('\\n%s', output)\n        if 'unknown revision' in output:\n            raise UnknownRevision(command, status_, output)\n        elif 'remote ref does not exist' in output:\n            raise NoRemoteRef(command, status_, output)\n        elif 'no such commit' in output:\n            raise NoSuchCommit(command, status_, output)\n        elif 'reference already exists' in output:\n            raise ExistingReference(command, status_, output)\n        elif re.search('Resolved|CONFLICT|Recorded preimage', output):\n            raise ResolveError(command, status_, output)\n        elif re.search('branch named.*already exists', output):\n            raise ExistingBranch(command, status, output)\n        raise GitError(command, status_, output)\n    elif output and not quiet:\n        logger.info('\\n%s', output)\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns a git log... command and return stdout", "response": "def log(args, number=None, oneline=False, quiet=False):\n    \"\"\"Run a \"git log ...\" command, and return stdout\n\n    args is anything which can be added after a normal \"git log ...\"\n        it can be blank\n    number, if true-ish, will be added as a \"-n\" option\n    oneline, if true-ish, will add the \"--oneline\" option\n    \"\"\"\n    options = ' '.join([\n        number and str('-n %s' % number) or '',\n        oneline and '--oneline' or ''\n    ])\n    try:\n        return run('log %s %s' % (options, args), quiet=quiet)\n    except UnknownRevision:\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun \"$ git branch with those options", "response": "def branch(options=False, *args, **kwargs):\n    \"\"\"Run \"$ git branch\" with those options\n\n    If not options then return name of the branch currently checked out\n    \"\"\"\n    return (options\n            and run('branch %s' % options, *args, **kwargs)\n            or rev_parse('--abbrev-ref HEAD', *args, **kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef branches(remotes=False):\n    stdout = branch('--list %s' % (remotes and '-a' or ''), quiet=True)\n    return [_.lstrip('*').strip() for _ in stdout.splitlines()]", "response": "Return a list of all local branches in the repo\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef branches_containing(commit):\n    lines = run('branch --contains %s' % commit).splitlines()\n    return [l.lstrip('* ') for l in lines]", "response": "Return a list of branches conatining that commit"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a path to the git staging area", "response": "def add(path=None, force=False, quiet=False):\n    \"\"\"Add that path to git's staging area (default current dir)\n\n    so that it will be included in next commit\n    \"\"\"\n    option = '-f' if force else ''\n    return run('add %s %s' % (option, path) or '.', quiet=quiet)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef config(key, value, local=True):\n    option = local and '--local' or ''\n    run('config %s \"%s\" \"%s\"' % (option, key, value))", "response": "Set that config key to that value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncloning a local repo from that URL to that path", "response": "def clone(url, path=None, remove=True):\n    \"\"\"Clone a local repo from that URL to that path\n\n    If path is not given, then use the git default: same as repo name\n    If path is given and remove is True\n        then the path is removed before cloning\n\n    Because this is run from a script it is assumed that user should be Admin\n        so set config user values for the GitLab Admin\n    \"\"\"\n    clean = True\n    if path and os.path.isdir(path):\n        if not remove:\n            clean = False\n        else:\n            shutil.rmtree(path)\n    if clean:\n        stdout = run('clone %s %s' % (url, path or ''))\n        into = stdout.splitlines()[0].split(\"'\")[1]\n        path_to_clone = os.path.realpath(into)\n    else:\n        path_to_clone = path\n    old_dir = _working_dirs[0]\n    _working_dirs[0] = path_to_clone\n    config('user.name', 'Release Script')\n    config('user.email', 'gitlab@wwts.com')\n    _working_dirs[0] = old_dir\n    return path_to_clone"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef needs_abort():\n    for line in status().splitlines():\n        if '--abort' in line:\n            for part in line.split('\"'):\n                if '--abort' in part:\n                    return part\n        elif 'All conflicts fixed but you are still merging' in line:\n            return 'git merge --abort'\n        elif 'You have unmerged paths.' in line:\n            return 'git merge --abort'\n        elif 'all conflicts fixed: run \"git rebase --continue\"' in line:\n            return 'git rebase --abort'\n    return None", "response": "A command to abort an operation in progress\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef show_branches(branch1, branch2):\n\n    def find_column(string):\n        \"\"\"Find first non space line in the prefix\"\"\"\n        result = 0\n        for c in string:\n            if c == ' ':\n                result += 1\n        return result\n\n    def parse_show_line(string):\n        \"\"\"Parse a typical line from git show-branch\n\n        >>> parse_show_line('+  [master^2] TOOLS-122 Add bashrc')\n        '+ ', 'master^2', 'TOOLS-122 Add bashrc'\n        \"\"\"\n        regexp = re.compile('(.*)\\[(.*)] (.*)')\n        match = regexp.match(string)\n        if not match:\n            return None\n        prefix, commit, comment = match.groups()\n        return find_column(prefix), commit, comment\n\n    log = run('show-branch --sha1-name \"%s\" \"%s\"' % (branch1, branch2))\n    lines = iter(log.splitlines())\n    line = lines.next()\n    branches = {}\n    while line != '--':\n        column, branch, comment = parse_show_line(line)\n        branches[column] = [branch]\n        line = lines.next()\n    line = lines.next()\n    for line in lines:\n        column, commit, comment = parse_show_line(line)\n        branches[column].append((commit, comment))\n    return branches", "response": "Runs git show - branch between the 2 branches parse result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef commits_with_message(message):\n    output = log(\"--grep '%s'\" % message, oneline=True, quiet=True)\n    lines = output.splitlines()\n    return [l.split(' ', 1)[0] for l in lines]", "response": "All commits with a given message"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef checkout(branch, quiet=False, as_path=False):\n    try:\n        if as_path:\n            branch = '-- %s' % branch\n        run('checkout %s %s' % (quiet and '-q' or '', branch))\n        return True\n    except GitError as e:\n        if 'need to resolve your current index' in e.output:\n            raise\n        return False", "response": "Check out that branch is in a state"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes a new local branch from that start_point and return it", "response": "def renew_local_branch(branch, start_point, remote=False):\n    \"\"\"Make a new local branch from that start_point\n\n    start_point is a git \"commit-ish\", e.g branch, tag, commit\n\n    If a local branch already exists it is removed\n    If remote is true then push the new branch to origin\n    \"\"\"\n    if branch in branches():\n        checkout(start_point)\n        delete(branch, force=True, remote=remote)\n    result = new_local_branch(branch, start_point)\n    if remote:\n        publish(branch)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npublish that branch i. e. push it to origin", "response": "def publish(branch, full_force=False):\n    \"\"\"Publish that branch, i.e. push it to origin\"\"\"\n    checkout(branch)\n    try:\n        push('--force --set-upstream origin', branch)\n    except ExistingReference:\n        if full_force:\n            push('origin --delete', branch)\n            push('--force --set-upstream origin', branch)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef commit(message, add=False, quiet=False):\n    if add:\n        run('add .')\n    try:\n        stdout = run('commit -m %r' % str(message), quiet=quiet)\n    except GitError as e:\n        s = str(e)\n        if 'nothing to commit' in s or 'no changes added to commit' in s:\n            raise EmptyCommit(*e.inits())\n        raise\n    return re.split('[ \\]]', stdout.splitlines()[0])[1]", "response": "Commit with that message and return the SHA1 of the commit\nTaxonomy"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pull(rebase=True, refspec=None):\n    options = rebase and '--rebase' or ''\n    output = run('pull %s %s' % (options, refspec or ''))\n    return not re.search('up.to.date', output)", "response": "Pull refspec from remote repository to local\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a local tag with that name at that commit on cuurent branch", "response": "def tag(name, remote=False, commit=None):\n    \"\"\"Add a local tag with that name at that commit\n\n    If no commit is given, at current commit on cuurent branch\n    If remote is true, also push the tag to origin\n    \"\"\"\n    command = 'tag %s %s' % (name, commit or '')\n    result = run(command)\n    if remote:\n        push('origin %s' % name)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef re_tag(name, remote=False, commit=None):\n    if remote:\n        tags = run('ls-remote --tags', quiet=True).splitlines()\n        if name in tags:\n            hide(name)\n    if is_tag(name):\n        run('tag --delete %s' % name)\n    return tag(name, remote, commit)", "response": "Add a local tag with that name at that commit on cuurent branch\n    If remote is True then re - make it otherwise re - make it"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmerge that branch into current branch", "response": "def merge(branch, fast_forward=False, commit=True, options=None):\n    \"\"\"Merge that branch into current branch\n\n    fast_forward and commit add the eponymous options to the command\n    \"\"\"\n    more_options = [\n        fast_forward and '--ff' or '--no-ff',\n        commit and '--commit' or '--no-commit',\n    ] + (options and options or [])\n    option_string = ' '.join(more_options)\n    all_branches = branches()\n    assert branch in all_branches, 'Missing branch: %s' % branch\n    command = 'merge %s %s' % (option_string, branch)\n    return run(command)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef merge_resolve(branch, fast_forward=False, commit=True, options=None):\n    def get_resolution(resolved=None):\n        return resolved\n\n    with git_continuer(get_resolution):\n        resolved = merge(branch, fast_forward, commit, options)\n        if commit and resolved.resolved:\n            # Then the resolved files were added, better commit them\n            commit(\"Merge branch '%s' into '%s'\" % (branch, current_branch()))", "response": "Merge that branch into current branch\n ArcGIS branch"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_error_close(logger):\n    \n    def make_wrapper(func):\n        \n        @functools.wraps(func)\n        def wrapper(self, *args, **kwargs):\n            \n            d = defer.maybeDeferred(func, self, *args, **kwargs)\n            def on_error(err):\n                logger(\"Unhandled failure in %r:%s\" % (func, err. getTraceback()))\n                \n                if hasattr(self, \"transport\"):\n                    if hasattr(self.transport, \"abortConnection\"):\n                        self.transport.abortConnection()\n                    elif hasattr(self.transport, \"loseConnection\"):\n                        self.transport.loseConnection()\n            d.addErrback(on_error)\n            \n        return wrapper\n    return make_wrapper", "response": "Decorator for callback methods that implement IProtocol."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tempfile_writer(target):\n    '''write cache data to a temporary location.  when writing is\n    complete, rename the file to the actual location.  delete\n    the temporary file on any error'''\n    tmp = target.parent / ('_%s' % target.name)\n    try:\n        with tmp.open('wb') as fd:\n            yield fd\n    except:\n        tmp.unlink()\n        raise\n    LOG.debug('rename %s -> %s', tmp, target)\n    tmp.rename(target)", "response": "A context manager that writes cache data to a temporary location. When writing is\n    complete rename the file to the actual location."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef xform_key(self, key):\n        '''we transform cache keys by taking their sha1 hash so that\n        we don't need to worry about cache keys containing invalid\n        characters'''\n\n        newkey = hashlib.sha1(key.encode('utf-8'))\n        return newkey.hexdigest()", "response": "we transform cache keys by taking their sha1 hash so that\n        we don t need to worry about invalid characters"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclear an item from the cache", "response": "def invalidate(self, key):\n        '''Clear an item from the cache'''\n        path = self.path(self.xform_key(key))\n        try:\n            LOG.debug('invalidate %s (%s)', key, path)\n            path.unlink()\n        except OSError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef invalidate_all(self):\n        '''Clear all items from the cache'''\n\n        LOG.debug('clearing cache')\n        appcache = str(self.get_app_cache())\n        for dirpath, dirnames, filenames in os.walk(appcache):\n            for name in filenames:\n                try:\n                    pathlib.Path(dirpath, name).unlink()\n                except OSError:\n                    pass", "response": "Clear all items from the cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstores content in the cache by iterating over content", "response": "def store_iter(self, key, content):\n        '''stores content in the cache by iterating over\n        content'''\n        cachekey = self.xform_key(key)\n        path = self.path(cachekey)\n\n        with tempfile_writer(path) as fd:\n            for data in content:\n                LOG.debug('writing chunk of %d bytes for %s',\n                          len(data), key)\n                fd.write(data)\n        LOG.debug('%s stored in cache', key)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nliking store_iter but appends a newline to each chunk of content", "response": "def store_lines(self, key, content):\n        '''like store_iter, but appends a newline to each chunk of\n        content'''\n        return self.store_iter(\n            key,\n            (data + '\\n'.encode('utf-8') for data in content))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlook up an item in the cache and return an open file descriptor for the object.", "response": "def load_fd(self, key, noexpire=False):\n        '''Look up an item in the cache and return an open file\n        descriptor for the object.  It is the caller's responsibility\n        to close the file descriptor.'''\n\n        cachekey = self.xform_key(key)\n        path = self.path(cachekey)\n\n        try:\n            stat = path.stat()\n            if not noexpire and stat.st_mtime < time.time() - self.lifetime:\n                LOG.debug('%s has expired', key)\n                path.unlink()\n                raise KeyError(key)\n\n            LOG.debug('%s found in cache', key)\n            return path.open('rb')\n        except OSError:\n            LOG.debug('%s not found in cache', key)\n            raise KeyError(key)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlook up an item in the cache and return a line iterator.", "response": "def load_lines(self, key, noexpire=None):\n        '''Look up up an item in the cache and return a line iterator.\n        The underlying file will be closed once all lines have been\n        consumed.'''\n        return line_iterator(self.load_fd(key, noexpire=noexpire))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_iter(self, key, chunksize=None, noexpire=None):\n        '''Lookup an item in the cache and return an iterator\n        that reads chunksize bytes of data at a time.  The underlying\n        file will be closed when all data has been read'''\n        return chunk_iterator(self.load_fd(key, noexpire=noexpire),\n                              chunksize=chunksize)", "response": "Lookup an item in the cache and return an iterator\n        that reads chunksize bytes of data at a time."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(self, key, noexpire=None):\n        '''Lookup an item in the cache and return the raw content of\n        the file as a string.'''\n        with self.load_fd(key, noexpire=noexpire) as fd:\n            return fd.read()", "response": "Lookup an item in the cache and return the raw content of\n        the file as a string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting a boolean parameter in the API call parameters dictionary.", "response": "def set_bool_param(params, name, value):\n    \"\"\"\n    Set a boolean parameter if applicable.\n\n    :param dict params: A dict containing API call parameters.\n\n    :param str name: The name of the parameter to set.\n\n    :param bool value:\n        The value of the parameter. If ``None``, the field will not be set. If\n        ``True`` or ``False``, the relevant field in ``params`` will be set to\n        ``'true'`` or ``'false'``. Any other value will raise a `ValueError`.\n\n    :returns: ``None``\n    \"\"\"\n    if value is None:\n        return\n\n    if value is True:\n        params[name] = 'true'\n    elif value is False:\n        params[name] = 'false'\n    else:\n        raise ValueError(\"Parameter '%s' must be boolean or None, got %r.\" % (\n            name, value))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_str_param(params, name, value):\n    if value is None:\n        return\n\n    if isinstance(value, str):\n        params[name] = value\n    elif isinstance(value, unicode):\n        params[name] = value.encode('utf-8')\n    else:\n        raise ValueError(\"Parameter '%s' must be a string or None, got %r.\" % (\n            name, value))", "response": "Set a string parameter if applicable."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_float_param(params, name, value, min=None, max=None):\n    if value is None:\n        return\n\n    try:\n        value = float(str(value))\n    except:\n        raise ValueError(\n            \"Parameter '%s' must be numeric (or a numeric string) or None,\"\n            \" got %r.\" % (name, value))\n    if min is not None and value < min:\n        raise ValueError(\n            \"Parameter '%s' must not be less than %r, got %r.\" % (\n                name, min, value))\n    if max is not None and value > max:\n        raise ValueError(\n            \"Parameter '%s' must not be greater than %r, got %r.\" % (\n                name, min, value))\n\n    params[name] = str(value)", "response": "Set a float parameter in the API call."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting an integer parameter in the API call.", "response": "def set_int_param(params, name, value, min=None, max=None):\n    \"\"\"\n    Set a int parameter if applicable.\n\n    :param dict params: A dict containing API call parameters.\n\n    :param str name: The name of the parameter to set.\n\n    :param int value:\n        The value of the parameter. If ``None``, the field will not be set. If\n        an instance of a numeric type or a string that can be turned into a\n        ``int``, the relevant field will be set. Any other value will raise a\n        `ValueError`.\n\n    :param int min:\n        If provided, values less than this will raise ``ValueError``.\n\n    :param int max:\n        If provided, values greater than this will raise ``ValueError``.\n\n    :returns: ``None``\n    \"\"\"\n    if value is None:\n        return\n\n    try:\n        value = int(str(value))\n    except:\n        raise ValueError(\n            \"Parameter '%s' must be an integer (or a string representation of\"\n            \" an integer) or None, got %r.\" % (name, value))\n    if min is not None and value < min:\n        raise ValueError(\n            \"Parameter '%s' must not be less than %r, got %r.\" % (\n                name, min, value))\n    if max is not None and value > max:\n        raise ValueError(\n            \"Parameter '%s' must not be greater than %r, got %r.\" % (\n                name, min, value))\n\n    params[name] = str(value)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting a list parameter if applicable.", "response": "def set_list_param(params, name, value, min_len=None, max_len=None):\n    \"\"\"\n    Set a list parameter if applicable.\n\n    :param dict params: A dict containing API call parameters.\n\n    :param str name: The name of the parameter to set.\n\n    :param list value:\n        The value of the parameter. If ``None``, the field will not be set. If\n        an instance of ``set``, ``tuple``, or type that can be turned into\n        a ``list``, the relevant field will be set. If ``dict``, will raise\n        ``ValueError``. Any other value will raise a ``ValueError``.\n\n    :param int min_len:\n        If provided, values shorter than this will raise ``ValueError``.\n\n    :param int max_len:\n        If provided, values longer than this will raise ``ValueError``.\n    \"\"\"\n    if value is None:\n        return\n\n    if type(value) is dict:\n        raise ValueError(\n            \"Parameter '%s' cannot be a dict.\" % name)\n\n    try:\n        value = list(value)\n    except:\n        raise ValueError(\n            \"Parameter '%s' must be a list (or a type that can be turned into\"\n            \"a list) or None, got %r.\" % (name, value))\n\n    if min_len is not None and len(value) < min_len:\n        raise ValueError(\n            \"Parameter '%s' must not be shorter than %r, got %r.\" % (\n                name, min_len, value))\n    if max_len is not None and len(value) > max_len:\n        raise ValueError(\n            \"Parameter '%s' must not be longer than %r, got %r.\" % (\n                name, max_len, value))\n\n    list_str = ''\n    for item in value:\n        list_str += '%s,' % item\n    set_str_param(params, name, list_str)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of tweets posted by the specified user.", "response": "def statuses_user_timeline(self, user_id=None, screen_name=None,\n                               since_id=None, count=None, max_id=None,\n                               trim_user=None, exclude_replies=None,\n                               contributor_details=None,\n                               include_rts=None):\n        \"\"\"\n        Returns a list of the most recent tweets posted by the specified user.\n\n        https://dev.twitter.com/docs/api/1.1/get/statuses/user_timeline\n\n        Either ``user_id`` or ``screen_name`` must be provided.\n\n        :param str user_id:\n            The ID of the user to return tweets for.\n\n        :param str screen_name:\n            The screen name of the user to return tweets for.\n\n        :param str since_id:\n            Returns results with an ID greater than (that is, more recent than)\n            the specified ID. Tweets newer than this may not be returned due to\n            certain API limits.\n\n        :param int count:\n            Specifies the number of tweets to try and retrieve, up to a maximum\n            of 200.\n\n        :param str max_id:\n            Returns results with an ID less than (that is, older than) or equal\n            to the specified ID.\n\n        :param bool trim_user:\n            When set to ``True``, the tweet's user object includes only the\n            status author's numerical ID.\n\n        :param bool exclude_replies:\n            When set to ``True``, replies will not appear in the timeline.\n\n        :param bool contributor_details:\n            This parameter enhances the contributors element of the status\n            response to include the screen_name of the contributor. By default\n            only the user_id of the contributor is included.\n\n        :param bool include_rts:\n            When set to ``False``, retweets will not appear in the timeline.\n\n        :returns: A list of tweet dicts.\n        \"\"\"\n        params = {}\n        set_str_param(params, 'user_id', user_id)\n        set_str_param(params, 'screen_name', screen_name)\n        set_str_param(params, 'since_id', since_id)\n        set_int_param(params, 'count', count)\n        set_str_param(params, 'max_id', max_id)\n        set_bool_param(params, 'trim_user', trim_user)\n        set_bool_param(params, 'exclude_replies', exclude_replies)\n        set_bool_param(params, 'contributor_details', contributor_details)\n        set_bool_param(params, 'include_rts', include_rts)\n        return self._get_api('statuses/user_timeline.json', params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef statuses_home_timeline(self, count=None, since_id=None, max_id=None,\n                               trim_user=None, exclude_replies=None,\n                               contributor_details=None,\n                               include_entities=None):\n        \"\"\"\n        Returns a collection of the most recent Tweets and retweets posted by\n        the authenticating user and the users they follow.\n\n        https://dev.twitter.com/docs/api/1.1/get/statuses/home_timeline\n\n        :param int count:\n            Specifies the number of tweets to try and retrieve, up to a maximum\n            of 200.\n\n        :param str since_id:\n            Returns results with an ID greater than (that is, more recent than)\n            the specified ID. Tweets newer than this may not be returned due to\n            certain API limits.\n\n        :param str max_id:\n            Returns results with an ID less than (that is, older than) or equal\n            to the specified ID.\n\n        :param bool trim_user:\n            When set to ``True``, the tweet's user object includes only the\n            status author's numerical ID.\n\n        :param bool exclude_replies:\n            When set to ``True``, replies will not appear in the timeline.\n\n        :param bool contributor_details:\n            This parameter enhances the contributors element of the status\n            response to include the screen_name of the contributor. By default\n            only the user_id of the contributor is included.\n\n        :param bool include_entities:\n            When set to ``False``, the ``entities`` node will not be included.\n\n        :returns: A list of tweet dicts.\n        \"\"\"\n        params = {}\n        set_int_param(params, 'count', count)\n        set_str_param(params, 'since_id', since_id)\n        set_str_param(params, 'max_id', max_id)\n        set_bool_param(params, 'trim_user', trim_user)\n        set_bool_param(params, 'exclude_replies', exclude_replies)\n        set_bool_param(params, 'contributor_details', contributor_details)\n        set_bool_param(params, 'include_entities', include_entities)\n        return self._get_api('statuses/home_timeline.json', params)", "response": "Returns a collection of most recent Tweets and retweets posted by the authenticating user and the users they follow."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of the most recent retweets of the Tweet specified by id.", "response": "def statuses_retweets(self, id, count=None, trim_user=None):\n        \"\"\"\n        Returns a list of the most recent retweets of the Tweet specified by\n        the id parameter.\n\n        https://dev.twitter.com/docs/api/1.1/get/statuses/retweets/%3Aid\n\n        :param str id:\n            (*required*) The numerical ID of the desired tweet.\n\n        :param int count:\n            The maximum number of retweets to return. (Max 100)\n\n        :param bool trim_user:\n            When set to ``True``, the tweet's user object includes only the\n            status author's numerical ID.\n\n        :returns: A tweet dict.\n        \"\"\"\n        params = {'id': id}\n        set_int_param(params, 'count', count)\n        set_bool_param(params, 'trim_user', trim_user)\n        return self._get_api('statuses/retweets.json', params)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef statuses_show(self, id, trim_user=None, include_my_retweet=None,\n                      include_entities=None):\n        \"\"\"\n        Returns a single Tweet, specified by the id parameter.\n\n        https://dev.twitter.com/docs/api/1.1/get/statuses/show/%3Aid\n\n        :param str id:\n            (*required*) The numerical ID of the desired tweet.\n\n        :param bool trim_user:\n            When set to ``True``, the tweet's user object includes only the\n            status author's numerical ID.\n\n        :param bool include_my_retweet:\n            When set to ``True``, any Tweet returned that has been retweeted by\n            the authenticating user will include an additional\n            ``current_user_retweet`` node, containing the ID of the source\n            status for the retweet.\n\n        :param bool include_entities:\n            When set to ``False``, the ``entities`` node will not be included.\n\n        :returns: A tweet dict.\n        \"\"\"\n        params = {'id': id}\n        set_bool_param(params, 'trim_user', trim_user)\n        set_bool_param(params, 'include_my_retweet', include_my_retweet)\n        set_bool_param(params, 'include_entities', include_entities)\n        return self._get_api('statuses/show.json', params)", "response": "Returns a single Tweet with the specified ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndestroy the status specified by the ID parameter.", "response": "def statuses_destroy(self, id, trim_user=None):\n        \"\"\"\n        Destroys the status specified by the ID parameter.\n\n        https://dev.twitter.com/docs/api/1.1/post/statuses/destroy/%3Aid\n\n        :param str id:\n            (*required*) The numerical ID of the desired tweet.\n\n        :param bool trim_user:\n            When set to ``True``, the return value's user object includes only\n            the status author's numerical ID.\n\n        :returns:\n            A tweet dict containing the destroyed tweet.\n        \"\"\"\n        params = {'id': id}\n        set_bool_param(params, 'trim_user', trim_user)\n        return self._post_api('statuses/destroy.json', params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the status of a specific entry in the status page.", "response": "def statuses_update(self, status, in_reply_to_status_id=None, lat=None,\n                        long=None, place_id=None, display_coordinates=None,\n                        trim_user=None, media_ids=None):\n        \"\"\"\n        Posts a tweet.\n\n        https://dev.twitter.com/docs/api/1.1/post/statuses/update\n\n        :param str status:\n            (*required*) The text of your tweet, typically up to 140\n            characters. URL encode as necessary. t.co link wrapping may affect\n            character counts.\n\n            There are some special commands in this field to be aware of. For\n            instance, preceding a message with \"D \" or \"M \" and following it\n            with a screen name can create a direct message to that user if the\n            relationship allows for it.\n\n        :param str in_reply_to_status_id:\n            The ID of an existing status that the update is in reply to.\n\n            Note: This parameter will be ignored unless the author of the tweet\n            this parameter references is mentioned within the status text.\n            Therefore, you must include @username, where username is the author\n            of the referenced tweet, within ``status``.\n\n        :param float lat:\n            The latitude of the location this tweet refers to. This parameter\n            will be ignored unless it is inside the range -90.0 to +90.0 (North\n            is positive) inclusive. It will also be ignored if there isn't a\n            corresponding long parameter.\n\n        :param float long:\n            The longitude of the location this tweet refers to. The valid\n            ranges for longitude is -180.0 to +180.0 (East is positive)\n            inclusive. This parameter will be ignored if outside that range, if\n            it is not a number, if geo_enabled is disabled, or if there not a\n            corresponding lat parameter.\n\n        :param str place_id:\n            A place in the world. These IDs can be retrieved from GET\n            geo/reverse_geocode. (TODO: Reference method when it exists.)\n\n        :param bool display_coordinates:\n            Whether or not to put a pin on the exact coordinates a tweet has\n            been sent from.\n\n        :param bool trim_user:\n            When set to ``True``, the return value's user object includes only\n            the status author's numerical ID.\n\n        :param list media_ids:\n            A list of images previously uploaded to Twitter (referenced by\n            their ``media_id``) that are to be embedded in the tweet. Maximum\n            of four images.\n\n        :returns:\n            A tweet dict containing the posted tweet.\n        \"\"\"\n        params = {}\n        set_str_param(params, 'status', status)\n        set_str_param(params, 'in_reply_to_status_id', in_reply_to_status_id)\n        set_float_param(params, 'lat', lat, min=-90, max=90)\n        set_float_param(params, 'long', long, min=-180, max=180)\n        set_str_param(params, 'place_id', place_id)\n        set_bool_param(params, 'display_coordinates', display_coordinates)\n        set_bool_param(params, 'trim_user', trim_user)\n        set_list_param(params, 'media_ids', media_ids, max_len=4)\n        return self._post_api('statuses/update.json', params)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef statuses_retweet(self, id, trim_user=None):\n        params = {'id': id}\n        set_bool_param(params, 'trim_user', trim_user)\n        return self._post_api('statuses/retweet.json', params)", "response": "Retweets the status specified by the ID parameter."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuploads an image to Twitter for later embedding in tweets.", "response": "def media_upload(self, media, additional_owners=None):\n        \"\"\"\n        Uploads an image to Twitter for later embedding in tweets.\n\n        https://dev.twitter.com/rest/reference/post/media/upload\n\n        :param file media:\n            The image file to upload (see the API docs for limitations).\n\n        :param list additional_owners:\n            A list of Twitter users that will be able to access the uploaded\n            file and embed it in their tweets (maximum 100 users).\n\n        :returns:\n            A dict containing information about the file uploaded. (Contains\n            the media id needed to embed the image in the ``media_id`` field).\n        \"\"\"\n        params = {}\n        set_list_param(\n            params, 'additional_owners', additional_owners, max_len=100)\n        return self._upload_media('media/upload.json', media, params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstreaming public messages filtered by various parameters.", "response": "def stream_filter(self, delegate, follow=None, track=None, locations=None,\n                      stall_warnings=None):\n        \"\"\"\n        Streams public messages filtered by various parameters.\n\n        https://dev.twitter.com/docs/api/1.1/post/statuses/filter\n\n        At least one of ``follow``, ``track``, or ``locations`` must be\n        provided. See the API documentation linked above for details on these\n        parameters and the various limits on this API.\n\n        :param delegate:\n            A delegate function that will be called for each message in the\n            stream and will be passed the message dict as the only parameter.\n            The message dicts passed to this function may represent any message\n            type and the delegate is responsible for any dispatch that may be\n            required. (:mod:`txtwitter.messagetools` may be helpful here.)\n\n        :param list follow:\n            A list of user IDs, indicating the users to return statuses for in\n            the stream.\n\n        :param list track:\n            List of keywords to track.\n\n        :param list locations:\n            List of location bounding boxes to track.\n            XXX: Currently unsupported.\n\n        :param bool stall_warnings:\n            Specifies whether stall warnings should be delivered.\n\n        :returns: An unstarted :class:`TwitterStreamService`.\n        \"\"\"\n        params = {}\n        if follow is not None:\n            params['follow'] = ','.join(follow)\n        if track is not None:\n            params['track'] = ','.join(track)\n        if locations is not None:\n            raise NotImplementedError(\n                \"The `locations` parameter is not yet supported.\")\n        set_bool_param(params, 'stall_warnings', stall_warnings)\n\n        svc = TwitterStreamService(\n            lambda: self._post_stream('statuses/filter.json', params),\n            delegate)\n        return svc"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef userstream_user(self, delegate, stall_warnings=None,\n                        with_='followings', replies=None):\n        \"\"\"\n        Streams messages for a single user.\n\n        https://dev.twitter.com/docs/api/1.1/get/user\n\n        The ``stringify_friend_ids`` parameter is always set to ``'true'`` for\n        consistency with the use of string identifiers elsewhere.\n\n        :param delegate:\n            A delegate function that will be called for each message in the\n            stream and will be passed the message dict as the only parameter.\n            The message dicts passed to this function may represent any message\n            type and the delegate is responsible for any dispatch that may be\n            required. (:mod:`txtwitter.messagetools` may be helpful here.)\n\n        :param bool stall_warnings:\n            Specifies whether stall warnings should be delivered.\n\n        :param str with_:\n            If ``'followings'`` (the default), the stream will include messages\n            from both the authenticated user and the authenticated user's\n            followers. If ``'user'``, the stream will only include messages\n            from (or mentioning) the autheticated user. All other values are\n            invalid. (The underscore appended to the parameter name is to avoid\n            conflicting with Python's ``with`` keyword.)\n\n        :param str replies:\n            If set to ``'all'``, replies to tweets will be included even if the\n            authenticated user does not follow both parties.\n\n        :returns: An unstarted :class:`TwitterStreamService`.\n        \"\"\"\n        params = {'stringify_friend_ids': 'true'}\n        set_bool_param(params, 'stall_warnings', stall_warnings)\n        set_str_param(params, 'with', with_)\n        set_str_param(params, 'replies', replies)\n\n        svc = TwitterStreamService(\n            lambda: self._get_userstream('user.json', params),\n            delegate)\n        return svc", "response": "Streams messages for a single user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of dicts containing the most recent direct messages received by the authenticating user.", "response": "def direct_messages(self, since_id=None, max_id=None, count=None,\n                        include_entities=None, skip_status=None):\n        \"\"\"\n        Gets the 20 most recent direct messages received by the authenticating\n        user.\n\n        https://dev.twitter.com/docs/api/1.1/get/direct_messages\n\n        :param str since_id:\n            Returns results with an ID greater than (that is, more recent than)\n            the specified ID. There are limits to the number of Tweets which\n            can be accessed through the API. If the limit of Tweets has occured\n            since the since_id, the since_id will be forced to the oldest ID\n            available.\n\n        :params str max_id:\n            Returns results with an ID less than (that is, older than) or equal\n            to the specified ID.\n\n        :param int count:\n            Specifies the number of direct messages to try and retrieve, up to\n            a maximum of ``200``. The value of count is best thought of as a\n            limit to the number of Tweets to return because suspended or\n            deleted content is removed after the count has been applied.\n\n        :param bool include_entities:\n            The entities node will not be included when set to ``False``.\n\n        :param bool skip_status:\n            When set to ``True``, statuses will not be included in the returned\n            user objects.\n\n        :returns:\n            A list of direct message dicts.\n        \"\"\"\n        params = {}\n        set_str_param(params, 'since_id', since_id)\n        set_str_param(params, 'max_id', max_id)\n        set_int_param(params, 'count', count)\n        set_bool_param(params, 'include_entities', include_entities)\n        set_bool_param(params, 'skip_status', skip_status)\n        return self._get_api('direct_messages.json', params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of dicts containing the most recent direct messages sent by the authenticating user.", "response": "def direct_messages_sent(self, since_id=None, max_id=None, count=None,\n                             include_entities=None, page=None):\n        \"\"\"\n        Gets the 20 most recent direct messages sent by the authenticating\n        user.\n\n        https://dev.twitter.com/docs/api/1.1/get/direct_messages/sent\n\n        :param str since_id:\n            Returns results with an ID greater than (that is, more recent than)\n            the specified ID. There are limits to the number of Tweets which\n            can be accessed through the API. If the limit of Tweets has occured\n            since the since_id, the since_id will be forced to the oldest ID\n            available.\n\n        :params str max_id:\n            Returns results with an ID less than (that is, older than) or equal\n            to the specified ID.\n\n        :param int count:\n            Returns results with an ID less than (that is, older than) or equal\n            to the specified ID.\n\n        :param int page:\n            Specifies the page of results to retrieve.\n\n        :param bool include_entities:\n            The entities node will not be included when set to ``False``.\n\n        :returns:\n            A list of direct message dicts.\n        \"\"\"\n        params = {}\n        set_str_param(params, 'since_id', since_id)\n        set_str_param(params, 'max_id', max_id)\n        set_int_param(params, 'count', count)\n        set_int_param(params, 'page', page)\n        set_bool_param(params, 'include_entities', include_entities)\n        return self._get_api('direct_messages/sent.json', params)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the direct message with the given id.", "response": "def direct_messages_show(self, id):\n        \"\"\"\n        Gets the direct message with the given id.\n\n        https://dev.twitter.com/docs/api/1.1/get/direct_messages/show\n\n        :param str id:\n            (*required*) The ID of the direct message.\n\n        :returns:\n            A direct message dict.\n        \"\"\"\n        params = {}\n        set_str_param(params, 'id', id)\n        d = self._get_api('direct_messages/show.json', params)\n        d.addCallback(lambda dms: dms[0])\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndestroy the direct message with the given id.", "response": "def direct_messages_destroy(self, id, include_entities=None):\n        \"\"\"\n        Destroys the direct message with the given id.\n\n        https://dev.twitter.com/docs/api/1.1/post/direct_messages/destroy\n\n        :param str id:\n            (*required*) The ID of the direct message.\n        :param bool include_entities:\n            The entities node will not be included when set to ``False``.\n\n        :returns:\n            A direct message dict containing the destroyed direct message.\n        \"\"\"\n        params = {}\n        set_str_param(params, 'id', id)\n        set_bool_param(params, 'include_entities', include_entities)\n        return self._post_api('direct_messages/destroy.json', params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef direct_messages_new(self, text, user_id=None, screen_name=None):\n        params = {}\n        set_str_param(params, 'text', text)\n        set_str_param(params, 'user_id', user_id)\n        set_str_param(params, 'screen_name', screen_name)\n        return self._post_api('direct_messages/new.json', params)", "response": "Sends a new direct message to the given user from the authenticating user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef friendships_create(self, user_id=None, screen_name=None,\n                           follow=None):\n        \"\"\"\n        Allows the authenticating users to follow the specified user.\n\n        https://dev.twitter.com/docs/api/1.1/post/friendships/create\n\n        :param str user_id:\n            The screen name of the user for whom to befriend. Required if\n            ``screen_name`` isn't given.\n        :param str screen_name:\n            The ID of the user for whom to befriend. Required if ``user_id``\n            isn't given.\n        :param bool follow:\n            Enable notifications for the target user.\n\n        :returns:\n            A dict containing the newly followed user.\n        \"\"\"\n        params = {}\n        set_str_param(params, 'user_id', user_id)\n        set_str_param(params, 'screen_name', screen_name)\n        set_bool_param(params, 'follow', follow)\n        return self._post_api('friendships/create.json', params)", "response": "Allows the authenticating users to follow the specified user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nallowing the authenticating user to unfollow the specified user.", "response": "def friendships_destroy(self, user_id=None, screen_name=None):\n        \"\"\"\n        Allows the authenticating user to unfollow the specified user.\n\n        https://dev.twitter.com/docs/api/1.1/post/friendships/destroy\n\n        :param str user_id:\n            The screen name of the user for whom to unfollow. Required if\n            ``screen_name`` isn't given.\n        :param str screen_name:\n            The ID of the user for whom to unfollow. Required if ``user_id``\n            isn't given.\n\n        :returns:\n            A dict containing the newly unfollowed user.\n        \"\"\"\n        params = {}\n        set_str_param(params, 'user_id', user_id)\n        set_str_param(params, 'screen_name', screen_name)\n        return self._post_api('friendships/destroy.json', params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbenchmarks an integer count n times.", "response": "def benchmark(store, n=10000):\n    \"\"\"\n    Increments an integer count n times.\n    \"\"\"\n    x = UpdatableItem(store=store, count=0)\n    for _ in xrange(n):\n        x.count += 1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef progressbar(stream, prefix='Loading: ', width=0.5, **options):\n    size = len(stream)\n    if not size:\n        return stream\n    if 'width' not in options:\n        if width <= 1:\n            width = round(shutil.get_terminal_size()[0] * width)\n        options['width'] = width\n    with ProgressBar(max=size, prefix=prefix, **options) as b:\n        b.set(0)\n        for i, x in enumerate(stream, 1):\n            yield x\n            b.set(i)", "response": "Generator to print a progress bar."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_week_dates(year, week, as_timestamp=False):\n    year = int(year)\n    week = int(week)\n    start_date = date(year, 1, 1)\n    if start_date.weekday() > 3:\n        start_date = start_date + timedelta(7 - start_date.weekday())\n    else:\n        start_date = start_date - timedelta(start_date.weekday())\n    dlt = timedelta(days=(week-1)*7)\n    start = start_date + dlt\n    end = start_date + dlt + timedelta(days=6)\n    if as_timestamp:\n        # Add the complete day\n        one_day = timedelta(days=1).total_seconds() - 0.000001\n        end_timestamp = time.mktime(end.timetuple()) + one_day\n        return time.mktime(start.timetuple()), end_timestamp\n    return start, end", "response": "Get the dates or timestamps of a week in a year."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the year and week for a given timestamp.", "response": "def get_year_week(timestamp):\n    \"\"\"Get the year and week for a given timestamp.\"\"\"\n    time_ = datetime.fromtimestamp(timestamp)\n    year = time_.isocalendar()[0]\n    week = time_.isocalendar()[1]\n    return year, week"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_last_weeks(number_of_weeks):\n    time_now = datetime.now()\n    year = time_now.isocalendar()[0]\n    week = time_now.isocalendar()[1]\n    weeks = []\n    for i in range(0, number_of_weeks):\n        start = get_week_dates(year, week - i, as_timestamp=True)[0]\n        n_year, n_week = get_year_week(start)\n        weeks.append((n_year, n_week))\n\n    return weeks", "response": "Get the last number_of_weeks weeks."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gevent_wait_callback(conn, timeout=None):\n    while 1:\n        state = conn.poll()\n        if state == extensions.POLL_OK:\n            break\n        elif state == extensions.POLL_READ:\n            wait_read(conn.fileno(), timeout=timeout)\n        elif state == extensions.POLL_WRITE:\n            wait_write(conn.fileno(), timeout=timeout)\n        else:\n            raise OperationalError(\n                \"Bad result from poll: %r\" % state)", "response": "A wait callback useful to allow gevent to work with Psycopg."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_sections(request):\n    sections = []\n    for section_url in SECTIONS:\n        crumb = find_crumb(request, section_url)\n        if crumb:\n            if section_url == '/':\n                if request.path == section_url:\n                    crumb.is_current = True\n            else:\n                if request.path.startswith(section_url):\n                    crumb.is_current = True\n            sections.append(crumb)\n\n    return sections", "response": "Returns list of sections."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the trail of breadcrumbs excluding base level", "response": "def _get_trail(request, exclude_section=False):\n    \"\"\"\n    Returns trail of breadcrumbs (vertical cut, excluding base level)\n    \"\"\"\n    trail = []\n    url = request.path\n    while url:\n        if url == '/':\n            break\n        if exclude_section and url in SECTIONS:\n            break\n        crumb = find_crumb(request, url)\n        if not crumb:\n            break\n        trail.append(crumb)\n\n        # go one level up\n        url = urljoin(url, '..')\n\n    trail.reverse()\n\n    return trail"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_navigation(request):\n    sections = _get_sections(request)\n    trail = _get_trail(request, exclude_section=True)\n\n    return mark_safe(render_to_string('navigation.html',\n                                      dict(sections=sections,trail=trail)))", "response": "Returns the rendered navigation block."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef named_crumb(context, name, *args, **kwargs):\n    url = reverse(name, args=args, kwargs=kwargs)\n    return find_crumb(context['request'], url)", "response": "Resolves given named URL and returns the relevant breadcrumb label."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nacts like :func:`named_crumb` but also wraps the result into a link tag. Usage:: <ul> <li>{% crumb_link 'auth_login' %}</li> <li>{% crumb_link 'project-index' %}</li> </ul> The result:: <ul> <li><a href=\"/accounts/login/\">Log in</a></li> <li><a href=\"/projects/\">Projects</a></li> </ul> Please note that you have to use quotes, otherwise the arguments are considered variable names.", "response": "def crumb_link(context, name, *args, **kwargs):\n    \"\"\" Acts like :func:`named_crumb` but also wraps the result into a\n    link tag. Usage::\n\n        <ul>\n            <li>{% crumb_link 'auth_login' %}</li>\n            <li>{% crumb_link 'project-index' %}</li>\n        </ul>\n\n    The result::\n\n        <ul>\n            <li><a href=\"/accounts/login/\">Log in</a></li>\n            <li><a href=\"/projects/\">Projects</a></li>\n        </ul>\n\n    Please note that you have to use quotes, otherwise the arguments are\n    considered variable names.\n    \"\"\"\n    url = reverse(name, args=args, kwargs=kwargs)\n    label = find_crumb(context['request'], url)\n    return u'<a href=\"%s\">%s</a>' % (url, label)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef conf(self):\n        return self.env.get_template('conf.py.j2').render(\n            metadata=self.metadata,\n            package=self.package)", "response": "Generate the Sphinx conf. py configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate the documentation Makefile.", "response": "def makefile(self):\n        \"\"\"Generate the documentation Makefile.\n\n        Returns:\n            (str): the contents of the `Makefile`.\n        \"\"\"\n        return self.env.get_template('Makefile.j2').render(\n            metadata=self.metadata,\n            package=self.package)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting unique items in list1 that are not in list2", "response": "def unique(list1, list2):\n    \"\"\"\n    Get unique items in list1 that are not in list2\n    :return: Unique items only in list 1\n    \"\"\"\n    set2 = set(list2)\n    list1_unique = [x for x in tqdm(list1, desc='Unique', total=len(list1)) if x not in set2]\n    return list1_unique"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compare_trees(dir1, dir2):\n    paths1 = DirPaths(dir1).walk()\n    paths2 = DirPaths(dir2).walk()\n    return unique_venn(paths1, paths2)", "response": "Parse two directories and return lists of unique files"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating a data dict against this schema.", "response": "def validate(self, data):\n        '''Validates a data dict against this schema.\n\n        Args:\n            data (dict): The data to be validated.\n\n        Raises:\n            ValidationError: If the data is invalid.\n        '''\n        try:\n            self._validator.validate(data)\n        except jsonschema.ValidationError as e:\n            six.raise_from(ValidationError.create_from(e), e)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_version(request, response):\n    settings = request.registry.settings\n    resolver = DottedNameResolver()\n\n    # get version config\n    version_header = settings.get(\n        'api.version_header',\n        'X-Version',\n    )\n    version_header_value = settings.get('api.version_header_value')\n    if callable(version_header_value):\n        version_header_value = version_header_value()\n    elif version_header_value:\n        version_header_value = resolver.resolve(version_header_value)\n\n    # get revision config\n    revision_header = settings.get(\n        'api.revision_header',\n        'X-Revision',\n    )\n    revision_header_value = settings.get('api.revision_header_value')\n    if callable(revision_header_value):\n        revision_header_value = revision_header_value()\n    elif revision_header_value:\n        revision_header_value = resolver.resolve(revision_header_value)\n\n    if version_header and version_header_value:\n        response.headers[str(version_header)] = str(version_header_value)\n    if revision_header and revision_header_value:\n        response.headers[str(revision_header)] = str(revision_header_value)", "response": "Set version and revision to response\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef api_headers_tween_factory(handler, registry):\n\n    def api_headers_tween(request):\n        response = handler(request)\n        set_version(request, response)\n        set_req_guid(request, response)\n        return response\n\n    return api_headers_tween", "response": "This tween provides necessary API headers"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndownloading a single object from the registry.", "response": "def download(url, retry=5):\n    \"\"\"\n    Proxy function to be used with `enable_requests_cache()`\n    to have the requests cached\n\n    >>> import timeit\n    >>> clean_cache()\n    >>> enable_requests_cache()\n    >>> url = \"https://regardscitoyens.org/\"\n    >>> timeit.timeit(lambda: download(url), number=1) < 0.01\n    False\n    >>> timeit.timeit(lambda: download(url), number=1) < 0.01\n    True\n    \"\"\"\n    try:\n        if CACHE_ENABLED:\n            file = os.path.join(cache_directory(), hashlib.sha224(url.encode('utf-8')).hexdigest())\n            if os.path.exists(file):\n                try:\n                    with open(file, 'rb') as f:\n                        resp = pickle.load(f)\n                        if '--debug' in sys.argv:\n                            print('[download]', url, '[#cached]', file=sys.stderr)\n                        return resp\n                except Exception:\n                    if '--debug' in sys.argv:\n                        print('[download]', url, '[#failed-to-retrieve]', file=sys.stderr)\n\n        if '--debug' in sys.argv:\n            print('[download]', url, file=sys.stderr)\n\n        resp = requests.get(url, headers={\n            'User-Agent': 'https://github.com/regardscitoyens/the-law-factory-parser (Compat: Mozilla)'\n        })\n\n        if 500 <= resp.status_code < 600:\n            raise HTTPError('%s Server Error for url: %s' % (resp.status_code, url), response=resp)\n\n        if CACHE_ENABLED:\n            if not os.path.exists(cache_directory()):\n                os.makedirs(cache_directory())\n            with open(file, 'wb') as f:\n                pickle.dump(resp, f)\n        return resp\n    except (ConnectionError, HTTPError) as e:\n        if retry:\n            time.sleep(1)\n            return download(url, retry=retry-1)\n        raise e"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nnormalizes the url and clean it", "response": "def clean_url(url):\n    \"\"\"\n    Normalize the url and clean it\n\n    >>> clean_url(\"http://www.assemblee-nationale.fr/15/dossiers/le_nouveau_dossier.asp#deuxieme_partie\")\n    'http://www.assemblee-nationale.fr/dyn/15/dossiers/deuxieme_partie'\n    >>> clean_url(\"http://www.conseil-constitutionnel.fr/conseil-constitutionnel/francais/les-decisions/acces-par-date/decisions-depuis-1959/2013/2013-681-dc/decision-n-2013-681-dc-du-5-decembre-2013.138900.html\")\n    'https://www.conseil-constitutionnel.fr/decision/2013/2013681DC.htm'\n    \"\"\"\n    url = url.strip()\n\n    # fix urls like 'pjl09-518.htmlhttp://www.assemblee-nationale.fr/13/ta/ta051`8.asp'\n    if url.find('https://') > 0:\n        url = 'https://' + url.split('https://')[1]\n    if url.find('http://') > 0:\n        url = 'http://' + url.split('http://')[1]\n\n    scheme, netloc, path, params, query, fragment = urlparse(url)\n\n    path = path.replace('//', '/')\n\n    if 'xtor' in fragment:\n        fragment = ''\n\n    # fix url like http://www.senat.fr/dossier-legislatif/www.conseil-constitutionnel.fr/decision/2012/2012646dc.htm\n    if 'www.conseil-' in url:\n        url = urlunparse((scheme, netloc, path, params, query, fragment))\n        url = 'http://www.conseil-' + url.split('www.conseil-')[1]\n        return find_stable_link_for_CC_decision(url)\n\n    if 'legifrance.gouv.fr' in url:\n        params = ''\n        url_jo_params = parse_qs(query)\n\n        if 'WAspad' in path:\n            newurl = get_redirected_url(url)\n            if url != newurl:\n                return clean_url(newurl)\n\n        if 'cidTexte' in url_jo_params:\n            query = 'cidTexte=' + url_jo_params['cidTexte'][0]\n        elif path.endswith('/jo/texte'):\n            newurl = find_jo_link(url)\n            if url != newurl:\n                return clean_url(newurl)\n\n        if netloc == 'legifrance.gouv.fr':\n            netloc = 'www.legifrance.gouv.fr'\n        if 'jo_pdf.do' in path and 'id' in url_jo_params:\n            path = 'affichTexte.do'\n            query = 'cidTexte=' + url_jo_params['id'][0]\n\n        # ensure to link initial version of the text and not furtherly modified ones\n        if query.startswith('cidTexte'):\n            query += '&categorieLien=id'\n\n        path = path.replace('./affichTexte.do', 'affichTexte.do')\n\n    if 'senat.fr' in netloc:\n        path = path.replace('leg/../', '/')\n        path = path.replace('dossierleg/', 'dossier-legislatif/')\n\n        # normalize dosleg url by removing extra url parameters\n        if 'dossier-legislatif/' in path:\n            query = ''\n            fragment = ''\n\n    if netloc == 'webdim':\n        netloc = 'www.assemblee-nationale.fr'\n\n    # force https\n    if 'assemblee-nationale.fr' not in netloc and 'conseil-constitutionnel.fr' not in netloc:\n        scheme = 'https'\n\n    # url like http://www.assemblee-nationale.fr/13/projets/pl2727.asp2727\n    if 'assemblee-nationale.fr' in url:\n        path = re_clean_ending_digits.sub(r\"\\1\", path)\n        if '/dossiers/' in path:\n            url = urlunparse((scheme, netloc, path, params, query, fragment))\n            legislature, slug = parse_national_assembly_url(url)\n            if legislature and slug:\n                template = AN_OLD_URL_TEMPLATE\n                if legislature > 14:\n                    template = AN_NEW_URL_TEMPLATE\n                return template.format(legislature=legislature, slug=slug)\n\n    return urlunparse((scheme, netloc, path, params, query, fragment))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_national_assembly_url(url_an):\n    legislature_match = re.search(r\"\\.fr/(dyn/)?(\\d+)/\", url_an)\n    if legislature_match:\n        legislature = int(legislature_match.group(2))\n    else:\n        legislature = None\n\n    slug = None\n    slug_match = re.search(r\"/([\\w_\\-]*)(?:\\.asp)?(?:#([\\w_\\-]*))?$\", url_an)\n    if slug_match:\n        if legislature and legislature > 14:\n            slug = slug_match.group(2) or slug_match.group(1)\n        else:\n            slug = slug_match.group(1)\n\n    return legislature, slug", "response": "Parses the National Assembly URL into a list of dicts."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(self, given_file):\n        if self.unique is not False and self.unique is not True:\n            raise AttributeError(\"Attribute 'unique' is not True or False.\")\n        self.filename = str.strip(given_file)\n        self.log('Read-only opening {0}'.format(self.filename))\n        with open(self.filename, 'r') as handle:\n            for line in handle:\n                line = line.rstrip('\\r\\n')\n                if line is None:\n                    line = ''  # Blank lines that were just \\n become None so convert them to empty string.\n                if self.unique is False or line not in self.contents:\n                    self.contents.append(line)\n        if self.sorted:\n            self.sort()\n        self.log('Read {0} lines.'.format(len(self.contents)))\n        return True", "response": "Reads given_file into self. contents."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check(self, line):\n        if not isinstance(line, str):\n            raise TypeError(\"Parameter 'line' not a 'string', is {0}\".format(type(line)))\n        if line in self.contents:\n            return line\n        return False", "response": "Check if a line is in the file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nappend line to contents .", "response": "def add(self, line):\n        \"\"\"\n        Append 'line' to contents\n            where 'line' is an entire line or a list of lines.\n\n        If self.unique is False it will add regardless of contents.\n\n        Multi-line strings are converted to a list delimited by new lines.\n\n        :param line: String or List of Strings; arbitrary string(s) to append to file contents.\n        :return: Boolean; whether contents were changed during this method call.\n        \"\"\"\n        if self.unique is not False and self.unique is not True:\n            raise AttributeError(\"Attribute 'unique' is not True or False.\")\n        self.log('add({0}); unique={1}'.format(line, self.unique))\n        if line is False:\n            return False\n        if isinstance(line, str):\n            line = line.split('\\n')\n        if not isinstance(line, list):\n            raise TypeError(\"Parameter 'line' not a 'string' or 'list', is {0}\".format(type(line)))\n        local_changes = False\n        for this in line:\n            if self.unique is False or this not in self.contents:\n                self.contents.append(this)\n                self.changed = local_changes = True\n        if self.sorted and local_changes:\n            self.sort()\n        return local_changes"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves all occurrences of line from contents", "response": "def rm(self, line):\n        \"\"\"\n        Remove all occurrences of 'line' from contents\n            where 'line' is an entire line or a list of lines.\n\n        Return true if the file was changed by rm(), False otherwise.\n\n        Multi-line strings are converted to a list delimited by new lines.\n\n        :param line: String, or List of Strings; each string represents an entire line to be removed from file.\n        :return: Boolean, whether contents were changed.\n        \"\"\"\n        self.log('rm({0})'.format(line))\n        if line is False:\n            return False\n        if isinstance(line, str):\n            line = line.split('\\n')\n        if not isinstance(line, list):\n            raise TypeError(\"Parameter 'line' not a 'string' or 'list', is {0}\".format(type(line)))\n        local_changes = False\n        for this in line:\n            if this in self.contents:\n                while this in self.contents:\n                    self.log('Removed \"{0}\" from position {1}'.format(this, self.contents.index(this)))\n                    self.contents.remove(this)\n                    self.changed = local_changes = True\n            else:\n                self.log('\"{0}\" not in {1}'.format(this, self.filename))\n        if self.sorted and local_changes:\n            self.sort()\n        return local_changes"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite the contents of the current object to the file.", "response": "def write(self):\n        \"\"\"\n        write self.contents to self.filename\n        self.filename was defined during .read()\n\n        There is no self.changed check because we need to let the caller decide whether or not to write. This is\n            useful if you want to force an overwrite of a file that might have been changed on disk even if\n            self.contents did not change.\n        \"\"\"\n        self.log('Writing {0}'.format(self.filename))\n        with open(self.filename, 'w') as handle:\n            for this_line in self.contents:\n                handle.write(this_line+self.linesep)\n        self.changed = False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef grep(self, needle):\n        result = []\n        for line in self.contents:\n            if needle in line:\n                result.append(line)\n        if result:\n            return result\n        return False", "response": "Returns all lines in file for substring needle."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef egrep(self, pattern):\n        pattern = re.compile(pattern)\n        result = []\n        for line in self.contents:\n            if pattern.search(line):\n                result.append(line)\n        if result:\n            return result\n        return False", "response": "REGEX search for pattern in file\n            equiv to : egrep \"^asdf.* [ 0 - 9 ] +$\""}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef replace(self, old, new):\n        self.log('replace({0}, {1})'.format(old, new))\n        if old is False:\n            return False\n        if isinstance(old, str):\n            old = old.split('\\n')\n        if not isinstance(old, list):\n            raise TypeError(\"Parameter 'old' not a 'string' or 'list', is {0}\".format(type(old)))\n        if not isinstance(new, str):\n            raise TypeError(\"Parameter 'new' not a 'string', is {0}\".format(type(new)))\n        local_changes = False\n        for this in old:\n            if this in self.contents:\n                while this in self.contents:\n                    index = self.contents.index(this)\n                    self.changed = local_changes = True\n                    self.contents.remove(this)\n                    self.contents.insert(index, new)\n                    self.log('Replaced \"{0}\" with \"{1}\" at line {2}'.format(this, new, index))\n            else:\n                self.log('\"{0}\" not in {1}'.format(this, self.filename))\n        return local_changes", "response": "Replace all lines of file that match old with new."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sort(self, key=None, reverse=False):\n        self.log('sort()')\n        self.contents.sort(key=key, reverse=reverse)\n        return None", "response": "Sort the contents of the current object by key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef partition(pred, iterable):\n    trues = []\n    falses = []\n    for item in iterable:\n        if pred(item):\n            trues.append(item)\n        else:\n            falses.append(item)\n    return trues, falses", "response": "split the results of an iterable based on a predicate"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef zip_with_output(skip_args=[]):\n    def decorator(fn):\n        def wrapped(*args, **vargs):\n            g = [arg for i, arg in enumerate(args) if i not in skip_args]\n            if len(g) == 1:\n                return(g[0], fn(*args, **vargs))\n            else:\n                return (g, fn(*args, **vargs))\n        return wrapped\n    return decorator", "response": "decorator that zips the input of a function with its output \n        only zips positional arguments"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compose(*funcs):\n    return lambda x: reduce(lambda v, f: f(v), reversed(funcs), x)", "response": "compose a list of functions"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_lst(a, b):\n    if type(a) is list:\n        return a + [b]\n    elif a:\n        return [a, b]\n    else:\n        return b", "response": "function to be folded over a list with initial value None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef map_over_glob(fn, path, pattern):\n    return [fn(x) for x in glob.glob(os.path.join(path, pattern))]", "response": "map a function over a glob pattern relative to a directory"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mkdir_recursive(dirname):\n    parent = os.path.dirname(dirname)\n    if parent != \"\":\n        if not os.path.exists(parent):\n            mkdir_recursive(parent)\n        if not os.path.exists(dirname):\n            os.mkdir(dirname)\n    elif not os.path.exists(dirname):\n        os.mkdir(dirname)", "response": "makes all the directories along a given path if they do not exist"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nindents text according to an operater string and a global indentation level.", "response": "def indent_text(*strs, **kwargs):\n    \"\"\" indents text according to an operater string and a global indentation \n        level. returns a tuple of all passed args, indented according to the\n        operator string\n\n        indent: [defaults to +0]\n            The operator string, of the form\n            ++n : increments the global indentation level by n and indents\n            +n  : indents with the global indentation level + n\n            --n : decrements the global indentation level by n\n            -n  : indents with the global indentation level - n\n            ==n : sets the global indentation level to exactly n and indents\n            =n  : indents with an indentation level of exactly n\n    \"\"\"\n    # python 2.7 workaround\n    indent = kwargs[\"indent\"] if \"indent\" in kwargs else\"+0\"\n    autobreak = kwargs.get(\"autobreak\", False)\n    char_limit = kwargs.get(\"char_limit\", 80)\n    split_char = kwargs.get(\"split_char\", \" \")\n\n    strs = list(strs)\n\n    if autobreak:\n        for index, s in enumerate(strs):\n            if len(s) > char_limit:\n                strs[index] = []\n                spl =  s.split(split_char)\n                result = []\n                collect = \"\"\n                for current_block in spl:\n                    if len(current_block) + len(collect) > char_limit:\n                        strs[index].append(collect[:-1] + \"\\n\") \n                        collect = \"    \"\n                    collect += current_block + split_char\n                strs[index].append(collect + \"\\n\")\n\n        strs = flatten_list(strs)\n\n    global lasting_indent\n    if indent.startswith(\"++\"):\n        lasting_indent = lasting_indent + int(indent[2:])\n        cur_indent = lasting_indent\n    elif indent.startswith(\"+\"):\n        cur_indent = lasting_indent + int(indent[1:])\n    elif indent.startswith(\"--\"):\n        lasting_indent = lasting_indent - int(indent[2:])\n        cur_indent = lasting_indent\n    elif indent.startswith(\"-\"):\n        cur_indent = lasting_indent - int(indent[1:])\n    elif indent.startswith(\"==\"):\n        lasting_indent = int(indent[2:])\n        cur_indent = lasting_indent\n    elif indent.startswith(\"=\"):\n        lasting_indent = int(indent[1:])\n        cur_indent = int(indent[1:])\n    else:\n        raise Exception(\n            \"indent command format '%s' unrecognized (see the docstring)\")\n\n    # mutate indentation level if needed\n    return tuple([\" \" * cur_indent] + [elem.replace(\"\\n\", \"\\n\" + \" \" * cur_indent) \n                  for elem in strs])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef perror(*args, **kwargs):\n\n    if should_msg(kwargs.get(\"groups\", [\"error\"])):\n        # initialize colorama only if uninitialized\n        global colorama_init\n        if not colorama_init:\n            colorama_init = True\n            colorama.init()\n\n        args = indent_text(*args, **kwargs)\n\n        # write to stdout\n        sys.stderr.write(colorama.Fore.RED)\n        sys.stderr.write(\"\".join(args))\n        sys.stderr.write(colorama.Fore.RESET)\n        sys.stderr.write(\"\\n\")", "response": "print formatted output to stderr with indentation control"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pwarning(*args, **kwargs):\n    if should_msg(kwargs.get(\"groups\", [\"warning\"])):\n\n        # initialize colorama only if uninitialized\n        global colorama_init\n        if not colorama_init:\n            colorama_init = True\n            colorama.init()\n\n        args = indent_text(*args, **kwargs)\n\n        # write to stdout\n        sys.stderr.write(colorama.Fore.YELLOW)\n        sys.stderr.write(\"\".join(args))\n        sys.stderr.write(colorama.Fore.RESET)\n        sys.stderr.write(\"\\n\")", "response": "print formatted output to stderr with indentation control"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pdebug(*args, **kwargs):\n    if should_msg(kwargs.get(\"groups\", [\"debug\"])):\n        # initialize colorama only if uninitialized\n        global colorama_init\n        if not colorama_init:\n            colorama_init = True\n            colorama.init()\n\n        args = indent_text(*args, **kwargs)\n\n        # write to stdout\n        sys.stderr.write(colorama.Fore.CYAN)\n        sys.stderr.write(\"\".join(args))\n        sys.stderr.write(colorama.Fore.RESET)\n        sys.stderr.write(\"\\n\")", "response": "print formatted output to stdout with indentation control"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting to stdout maintaining indent level", "response": "def pout(*args, **kwargs):\n    \"\"\"print to stdout, maintaining indent level\"\"\"\n    if should_msg(kwargs.get(\"groups\", [\"normal\"])):\n        args = indent_text(*args, **kwargs)\n\n        # write to stdout\n        sys.stderr.write(\"\".join(args))\n        sys.stderr.write(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef urlretrieve(url, dest, write_mode=\"w\"):\n    response = urllib2.urlopen(url)\n    mkdir_recursive(os.path.dirname(dest))\n    with open(dest, write_mode) as f:\n        f.write(response.read())\n        f.close()", "response": "save a file from a given url to disk"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves duplicates from a sequence preserving order", "response": "def remove_dups(seq):\n    \"\"\"remove duplicates from a sequence, preserving order\"\"\"\n    seen = set()\n    seen_add = seen.add\n    return [x for x in seq if not (x in seen or seen_add(x))]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if json is the preferred output format for the request.", "response": "def json_requested():\n    \"\"\"Check if json is the preferred output format for the request.\"\"\"\n    best = request.accept_mimetypes.best_match(\n        ['application/json', 'text/html'])\n    return (best == 'application/json' and\n            request.accept_mimetypes[best] >\n            request.accept_mimetypes['text/html'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_readme():\n    'Get the long description from the README file'\n\n    here = path.abspath(path.dirname(__file__))\n    with open(path.join(here, 'README.rst'), encoding='utf-8') as my_fd:\n        result = my_fd.read()\n\n    return result", "response": "Get the long description from the README file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninjecting the config from the libraries", "response": "def inject_config(self, config, from_args):\n    \"\"\"\n    :param config:\n    :type config: list\n    :param from_args:\n    :type from_args: dict\n    \"\"\"\n\n    load_libs = self._get_libs()\n\n    all_libs = {}\n    found_libs = []\n    \n    for root, dirs, files in os.walk(library_path):\n      for f in files:\n        if not f.endswith('.so'):\n          continue\n\n        full_path = os.path.join(root, f)\n        if '.' in f:\n          name, ext = f.split('.', 1)\n        else:\n          name = f\n\n        if name in all_libs:\n          all_libs[name].append(full_path)\n        else:\n          all_libs[name] = [full_path]\n\n    for lib in load_libs:\n      if 'lib' + lib in all_libs:\n        p = list(sorted(all_libs['lib' + lib], key=lambda x: len(x))).pop()\n        v = '--volume={0}:{1}'.format(os.path.realpath(p), p)\n        config.append(v)\n      else:\n        print('*** Unknown lib: {}'.format(lib))\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_nc_attrs(nc):\n\n    meta = {\n        'experiment': nc.experiment_id,\n        'frequency': nc.frequency,\n        'institute': nc.institute_id,\n        'model': nc.model_id,\n        'modeling_realm': nc.modeling_realm,\n        'ensemble_member': 'r{}i{}p{}'.format(nc.realization, nc.initialization_method, nc.physics_version),\n    }\n\n    variable_name = get_var_name(nc)\n    if variable_name:\n        meta.update({'variable_name': variable_name})\n\n    return meta", "response": "Gets the netCDF file metadata attributes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nguessing the variable_name of an open NetCDF file", "response": "def get_var_name(nc):\n    \"\"\"Guesses the variable_name of an open NetCDF file\n    \"\"\"\n\n    non_variable_names = [\n        'lat',\n        'lat_bnds',\n        'lon',\n        'lon_bnds',\n        'time',\n        'latitude',\n        'longitude',\n        'bnds'\n    ]\n\n    _vars = set(nc.variables.keys())\n    _vars.difference_update(set(non_variable_names))\n    if len(_vars) == 1:\n        return _vars.pop()\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _update_known_atts(self, **kwargs):\n        for k, v in kwargs.items():\n            if k not in ATTR_KEYS:\n                # Warn if passed in unknown kwargs\n                raise SyntaxWarning('Unknown argument: {}'.format(k))\n            elif not v: # Delete attributes with falsey values\n                delattr(self, k)\n            else:\n                setattr(self, k, v)", "response": "Updates instance attributes with supplied keyword arguments."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_joined_dir_name(self, atts):\n\n        return os.path.join(*[getattr(self, x) for x in atts])", "response": "Returns a joined path populated with the supplied attribute names\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_joined_file_name(self, atts, optional_atts = None):\n\n        return '_'.join(\n            [getattr(self, x) for x in atts] +\n            [getattr(self, x) for x in optional_atts if x in self.__dict__]\n        ) + '.nc'", "response": "Returns a joined path populated with the supplied attribute names\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef savecache(apicache, json_file):\n    if apicache is None or apicache is {}:\n        return \"\"\n    apicachestr = json.dumps(apicache, indent=2)\n    with open(json_file, 'w') as cache_file:\n        cache_file.write(apicachestr)\n    return apicachestr", "response": "Saves apicache dictionary as json_file returns dictionary as indented str\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload a json file as dictionary and feeds it to monkeycache and spits result", "response": "def loadcache(json_file):\n    \"\"\"\n    Loads json file as dictionary, feeds it to monkeycache and spits result\n    \"\"\"\n    f = open(json_file, 'r')\n    data = f.read()\n    f.close()\n    try:\n        apicache = json.loads(data)\n    except ValueError as e:\n        print(\"Error processing json:\", json_file, e)\n        return {}\n    return apicache"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef monkeycache(apis):\n    if isinstance(type(apis), type(None)) or apis is None:\n        return {}\n\n    verbs = set()\n    cache = {}\n    cache['count'] = apis['count']\n    cache['asyncapis'] = []\n\n    apilist = apis['api']\n    if apilist is None:\n        print(\"[monkeycache] Server response issue, no apis found\")\n\n    for api in apilist:\n        name = getvalue(api, 'name')\n        verb, subject = splitverbsubject(name)\n\n        apidict = {}\n        apidict['name'] = name\n        apidict['description'] = getvalue(api, 'description')\n        apidict['isasync'] = getvalue(api, 'isasync')\n        if apidict['isasync']:\n            cache['asyncapis'].append(name)\n        apidict['related'] = splitcsvstring(getvalue(api, 'related'))\n\n        required = []\n        apiparams = []\n        for param in getvalue(api, 'params'):\n            apiparam = {}\n            apiparam['name'] = getvalue(param, 'name')\n            apiparam['description'] = getvalue(param, 'description')\n            apiparam['required'] = (getvalue(param, 'required') is True)\n            apiparam['length'] = int(getvalue(param, 'length'))\n            apiparam['type'] = getvalue(param, 'type')\n            apiparam['related'] = splitcsvstring(getvalue(param, 'related'))\n            if apiparam['required']:\n                required.append(apiparam['name'])\n            apiparams.append(apiparam)\n\n        apidict['requiredparams'] = required\n        apidict['params'] = apiparams\n        if verb not in cache:\n            cache[verb] = {}\n        cache[verb][subject] = apidict\n        verbs.add(verb)\n\n    cache['verbs'] = list(verbs)\n    return cache", "response": "This function returns a dictionary of api bananas and returns a list of all the keys that are in the cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main(json_file):\n    f = open(\"precache.py\", \"w\")\n    f.write(\"\"\"# -*- coding: utf-8 -*-\n# Auto-generated code by cachemaker.py\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\"\"\")\n    f.write(\"\\napicache = %s\" % loadcache(json_file))\n    f.close()", "response": "This function is used to create a cachemaker. py file that can be used to create a precache datastore of all available apis of a CloudStack and dumps the precache dictionary in a python module."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute(self, sql, param=(), times=1):\n        self.log and self.log.debug('%s %s' % ('SQL:', sql))\n        if param is not ():\n            self.log and self.log.debug('%s %s' % ('PARAMs:', param))\n        for i in xrange(times):\n            try:\n                ret, res = self._execute(sql, param)\n                return ret, res\n            except Exception, e:\n                self.log and self.log.warn(\"The %s time execute, fail\" % i)\n                self.log and self.log.warn(e)\n            if i: sleep(i**1.5)\n        self.log and self.log.error(e)\n        return None, e", "response": "This function will try x times to execute the sql and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef connect(self):\n        self.conn = self.db_module.connect(\n                host=self.host, port=int(self.port), user=self.user,\n                passwd=self.passwd, db=self.dbname, charset=self.charset,\n                cursorclass=self.cursorclass)\n        self.conn.autocommit(self.autocommit)\n        return True", "response": "Connect to MySQL database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget Fab Lab data from fablabs. io.", "response": "def get_labs(format):\n    \"\"\"Gets Fab Lab data from fablabs.io.\"\"\"\n\n    fablabs_json = data_from_fablabs_io(fablabs_io_labs_api_url_v0)\n    fablabs = {}\n\n    # Load all the FabLabs\n    for i in fablabs_json[\"labs\"]:\n        current_lab = FabLab()\n        current_lab.name = i[\"name\"]\n        current_lab.address_1 = i[\"address_1\"]\n        current_lab.address_2 = i[\"address_2\"]\n        current_lab.address_notes = i[\"address_notes\"]\n        current_lab.avatar = i[\"avatar_url\"]\n        current_lab.blurb = i[\"blurb\"]\n        current_lab.capabilities = i[\"capabilities\"]\n        if i[\"city\"].isupper():\n            i[\"city\"] = i[\"city\"].title()\n        current_lab.city = i[\"city\"]\n        current_lab.country_code = i[\"country_code\"]\n        current_lab.county = i[\"county\"]\n        current_lab.description = i[\"description\"]\n        current_lab.email = i[\"email\"]\n        current_lab.id = i[\"id\"]\n        current_lab.phone = i[\"phone\"]\n        current_lab.postal_code = i[\"postal_code\"]\n        current_lab.slug = i[\"slug\"]\n        current_lab.url = i[\"url\"]\n\n        current_lab.continent = country_alpha2_to_continent_code(i[\"country_code\"].upper())\n        current_country = pycountry.countries.get(alpha_2=i[\"country_code\"].upper())\n        current_lab.country_code = current_country.alpha_3\n        current_lab.country = current_country.name\n\n        # Check coordinates\n        if i[\"longitude\"] is not None:\n            current_lab.longitude = i[\"longitude\"]\n        else:\n            current_lab.longitude = 0.0\n        if i[\"latitude\"] is not None:\n            current_lab.latitude = i[\"latitude\"]\n        else:\n            current_lab.latitude = 0.0\n\n        # Find Facebook and Twitter links, add also the other ones\n        current_lab.links = {\"facebook\": \"\", \"twitter\": \"\"}\n        for link in i[\"links\"]:\n            if \"facebook\" in link[\"url\"]:\n                current_lab.links[\"facebook\"] = link[\"url\"]\n            elif \"twitter\" in link[\"url\"]:\n                current_lab.links[\"twitter\"] = link[\"url\"]\n            else:\n                current_lab.links[link[\"id\"]] = link[\"url\"]\n\n        # Add the lab to the list\n        fablabs[i[\"slug\"]] = current_lab\n\n    # Return a dictiornary / json\n    if format.lower() == \"dict\" or format.lower() == \"json\":\n        output = {}\n        for j in fablabs:\n            output[j] = fablabs[j].__dict__\n    # Return a geojson\n    elif format.lower() == \"geojson\" or format.lower() == \"geo\":\n        labs_list = []\n        for l in fablabs:\n            single = fablabs[l].__dict__\n            single_lab = Feature(\n                type=\"Feature\",\n                geometry=Point((single[\"latitude\"], single[\"longitude\"])),\n                properties=single)\n            labs_list.append(single_lab)\n        output = dumps(FeatureCollection(labs_list))\n    # Return a Pandas DataFrame\n    elif format.lower() == \"pandas\" or format.lower() == \"dataframe\":\n        output = {}\n        for j in fablabs:\n            output[j] = fablabs[j].__dict__\n        # Transform the dict into a Pandas DataFrame\n        output = pd.DataFrame.from_dict(output)\n        output = output.transpose()\n    # Return an object\n    elif format.lower() == \"object\" or format.lower() == \"obj\":\n        output = fablabs\n    # Default: return an oject\n    else:\n        output = fablabs\n    # Return a proper json\n    if format.lower() == \"json\":\n        output = json.dumps(output)\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget projects data from fablabs. io.", "response": "def get_projects(format):\n    \"\"\"Gets projects data from fablabs.io.\"\"\"\n\n    projects_json = data_from_fablabs_io(fablabs_io_projects_api_url_v0)\n    projects = {}\n    project_url = \"https://www.fablabs.io/projects/\"\n    fablabs = get_labs(format=\"object\")\n\n    # Load all the FabLabs\n    for i in projects_json[\"projects\"]:\n        i = i[\"projects\"]\n        current_project = Project()\n        current_project.id = i[\"id\"]\n        current_project.title = i[\"title\"]\n        current_project.description = i[\"description\"]\n        current_project.github = i[\"github\"]\n        current_project.web = i[\"web\"]\n        current_project.dropbox = i[\"dropbox\"]\n        current_project.bitbucket = i[\"bitbucket\"]\n        current_project.lab_id = i[\"lab_id\"]\n        # Add the lab of the project\n        if i[\"lab_id\"] is not None:\n            for k in fablabs:\n                if fablabs[k].id == i[\"lab_id\"]:\n                    current_project.lab = fablabs[k]\n        else:\n            current_project.lab = None\n        current_project.owner_id = i[\"owner_id\"]\n        current_project.created_at = i[\"created_at\"]\n        current_project.updated_at = i[\"updated_at\"]\n        current_project.vimeo = i[\"vimeo\"]\n        current_project.flickr = i[\"flickr\"]\n        current_project.youtube = i[\"youtube\"]\n        current_project.drive = i[\"drive\"]\n        current_project.twitter = i[\"twitter\"]\n        current_project.facebook = i[\"facebook\"]\n        current_project.googleplus = i[\"googleplus\"]\n        current_project.instagram = i[\"instagram\"]\n        current_project.status = i[\"status\"]\n        current_project.version = i[\"version\"]\n        current_project.faq = i[\"faq\"]\n        current_project.scope = i[\"scope\"]\n        current_project.community = i[\"community\"]\n        current_project.lookingfor = i[\"lookingfor\"]\n        current_project.cover = i[\"cover\"]\n        url = project_url + str(current_project.id)\n        current_project.url = url\n        # Add the project\n        projects[current_project.id] = current_project\n\n    # Return a dictiornary / json\n    if format.lower() == \"dict\" or format.lower() == \"json\":\n        output = {}\n        for j in projects:\n            project_dict = projects[j].__dict__\n            # Convert the lab from a Fab Lab object to a dict\n            if project_dict[\"lab\"] is not None:\n                project_dict[\"lab\"] = project_dict[\"lab\"].__dict__\n            output[j] = project_dict\n    # Return a geojson, only for projects linked to a lab\n    elif format.lower() == \"geojson\" or format.lower() == \"geo\":\n        projects_list = []\n        for p in projects:\n            if projects[p].lab_id is not None:\n                single_project = projects[p].__dict__\n                if projects[p].lab is not None:\n                    single_project[\"lab\"] = single_project[\"lab\"].__dict__\n                for l in fablabs:\n                    single_lab = fablabs[l].__dict__\n                    if single_lab[\"id\"] == single_project[\"lab_id\"]:\n                        project_lab = Feature(\n                            type=\"Feature\",\n                            geometry=Point((single_lab[\"latitude\"],\n                                            single_lab[\"longitude\"])),\n                            properties=single_project)\n                        projects_list.append(project_lab)\n                output = dumps(FeatureCollection(projects_list))\n    # Return an object\n    elif format.lower() == \"object\" or format.lower() == \"obj\":\n        output = projects\n    # Default: return an object\n    else:\n        output = projects\n    # Return a proper json\n    if format.lower() == \"json\":\n        output = json.dumps(output)\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract the metadata from the module or dict argument.", "response": "def get_metadata(source):\n    \"\"\"\n    Extract the metadata from the module or dict argument.\n\n    It returns a `metadata` dictionary that provides keywords arguments\n    for the setuptools `setup` function.\n    \"\"\"\n    if isinstance(source, types.ModuleType):\n        metadata = source.__dict__\n    else:\n        metadata = source\n\n    setuptools_kwargs = {}\n\n    for key in \"name version url license\".split():\n        val = metadata.get(\"__\" + key + \"__\")\n        if val is not None:\n            setuptools_kwargs[key] = val\n\n    version = metadata.get(\"__version__\")\n    if version is not None:\n        setuptools_kwargs[\"version\"] = version\n\n    # Search for author email with a <...@...> syntax in the author field.\n    author = metadata.get(\"__author__\")\n    if author is not None:\n        email_pattern = u\"<([^>]+@[^>]+)>\"\n        match = re.search(email_pattern, author)\n        if match is not None:\n            setuptools_kwargs[\"author_email\"] = email = match.groups()[0]\n            setuptools_kwargs[\"author\"] = author.replace(u\"<\" + email + u\">\", u\"\").strip()\n        else:\n            setuptools_kwargs[\"author\"] = author\n\n    # Get the module summary.\n    summary = metadata.get(\"__summary__\")\n    if summary is not None:\n        setuptools_kwargs[\"description\"] = summary\n\n    # Get and process the module README.\n    README_filenames = [\"README.md\", \"README.txt\", \"README\"]\n    for filename in README_filenames:\n        if os.path.isfile(filename):\n            README = open(filename).read()\n            if hasattr(README, \"decode\"):\n                README = README.decode(\"utf-8\")\n            README_rst = to_rst(README)\n            setuptools_kwargs[\"long_description\"] = README_rst or README\n            break\n\n    # Process keywords that match trove classifiers.\n    keywords = metadata.get(\"__keywords__\")\n    if keywords is not None:\n        classifiers = []\n        keywords = [k.strip() for k in keywords.split(\",\")]\n        for keyword in keywords:\n            trove_id = trove_search(keyword)\n            if trove_id is not None:\n                classifiers.append(trove_id)\n        classifiers = sorted(list(set(classifiers)))\n        setuptools_kwargs[\"classifiers\"] = classifiers\n\n    return setuptools_kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_driver_script(driver, script_create=None):  # noqa: E501\n    if connexion.request.is_json:\n        script_create = ScriptCreate.from_dict(connexion.request.get_json())  # noqa: E501\n\n    response = errorIfUnauthorized(role='developer')\n    if response:\n        return response\n    else:\n        response = ApitaxResponse()\n\n    driver: Driver = LoadedDrivers.getDriver(driver)\n    driver.saveDriverScript(script_create.script.name, script_create.script.content)\n\n    return Response(status=200, body=response.getResponseBody())", "response": "Create a new script"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_driver_script(driver, script_delete=None):  # noqa: E501\n    if connexion.request.is_json:\n        script_delete = ScriptDelete.from_dict(connexion.request.get_json())  # noqa: E501\n\n    response = errorIfUnauthorized(role='developer')\n    if response:\n        return response\n    else:\n        response = ApitaxResponse()\n\n    driver: Driver = LoadedDrivers.getDriver(driver)\n    driver.deleteDriverScript(script_delete.script.name)\n\n    return Response(status=200, body=response.getResponseBody())", "response": "Delete a script from a driver"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves the contents of a script in a node.", "response": "def get_driver_script(driver, script=None):  # noqa: E501\n    \"\"\"Retrieve the contents of a script\n\n    Retrieve the contents of a script # noqa: E501\n\n    :param driver: The driver to use for the request. ie. github\n    :type driver: str\n    :param script: The script name.\n    :type script: str\n\n    :rtype: Response\n    \"\"\"\n\n    response = errorIfUnauthorized(role='user')\n    if response:\n        return response\n    else:\n        response = ApitaxResponse()\n\n    driver: Driver = LoadedDrivers.getDriver(driver)\n\n    response.body.add({'content': driver.getDriverScript(script)})\n\n    return Response(status=200, body=response.getResponseBody())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_driver_script(driver, script_save=None):  # noqa: E501\n    if connexion.request.is_json:\n        script_save = ScriptSave.from_dict(connexion.request.get_json())  # noqa: E501\n\n    response = errorIfUnauthorized(role='developer')\n    if response:\n        return response\n    else:\n        response = ApitaxResponse()\n\n    driver: Driver = LoadedDrivers.getDriver(driver)\n    driver.saveDriverScript(script_save.script.name, script_save.script.content)\n\n    return Response(status=200, body=response.getResponseBody())", "response": "Save a script to a driver"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a string to bytes", "response": "def to_bytes(s):\n    \"\"\"\n    \u5c06\u5b57\u7b26\u4e32\u8f6c\u6362\u6210\u5b57\u8282\u6570\u7ec4\n    :param s: \u8981\u8f6c\u6362\u6210\u5b57\u8282\u6570\u7ec4\u7684\u5b57\u7b26\u4e32\n    :return: \u8f6c\u6362\u6210\u5b57\u8282\u6570\u7ec4\u7684\u5b57\u7b26\u4e32\n    \"\"\"\n    if bytes != str:\n        if type(s) == str:\n            return s.encode('utf-8')\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_str(s):\n    if bytes != str:\n        \"\"\"\n        \u8fd9\u91cc\u7684\u6bd4\u8f83\u5728python2\u4e2d\u662fTrue\uff0c\u5728Python3\u4e2d\u662fFalse\n        \"\"\"\n        if type(s) == bytes:\n            return s.decode('utf-8')\n    return s", "response": "Convert a bytes object to a string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing the input buffer.", "response": "def process(self, buff):\n        '''\n            Process the input buffer. The buffer can contains all or a segment of the bytes from the complete message. \n            The function will buffer what will require extra bytes to be processed. \n        :param buff:\n        '''\n        (self._stack, self._memory, scstateidx, self._state, \n            tmpevents, self._waitingforprop, self._parentismap) = process( buff, self.create_parser_info(), self._deserializers);\n        self._scstate = self.scstatelist[scstateidx-1]\n        \n        self._events = tmpevents"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting the application under the code profiler", "response": "def profile(length=25):\n    \"\"\" Start the application under the code profiler \"\"\"\n\n    from werkzeug.contrib.profiler import ProfilerMiddleware\n    app.wsgi_app = ProfilerMiddleware(app.wsgi_app, restrictions=[length])\n    app.run()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndisplaying both SQLAlchemy and Python help statements", "response": "def _help():\n    \"\"\" Display both SQLAlchemy and Python help statements \"\"\"\n\n    statement = '%s%s' % (shelp, phelp % ', '.join(cntx_.keys()))\n    print statement.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self):\n        try:\n            # Go through the list of possible ports, hoping we can find\n            # one that is free to use for the WSGI server.\n            for index, port in enumerate(self.possible_ports):\n                try:\n                    self.httpd = self._create_server(port)\n                except socket.error as e:\n                    if (index + 1 < len(self.possible_ports) and\n                            e.error == errno.EADDRINUSE):\n                        # This port is already in use, so we go on and try with\n                        # the next one in the list.\n                        continue\n                    else:\n                        # Either none of the given ports are free or the error\n                        # is something else than \"Address already in use\". So\n                        # we let that error bubble up to the main thread.\n                        raise\n                else:\n                    # A free port was found.\n                    self.port = port\n                    break\n\n            self.is_ready.set()\n            self.httpd.serve_forever()\n        except Exception as e:\n            self.error = e\n            self.is_ready.set()", "response": "Starts serving HTTP requests for the given available ports."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef append_column(table, col_name, default_value=None):\r\n    '''\r\n    Appends a column to the raw data without any integrity checks.\r\n\r\n    Args:\r\n        default_value: The value which will assigned, not copied into each row\r\n    '''\r\n    table[0].append(col_name.strip())\r\n    for row in table[1:]:\r\n        row.append(default_value)", "response": "Append a column to the raw data without integrity checks."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_column(table, remove_index):\r\n        '''\r\n        Removes the specified column from the table.\r\n        '''\r\n        for row_index in range(len(table)):\r\n            old_row = table[row_index]\r\n            new_row = []\r\n            for column_index in range(len(old_row)):\r\n                if column_index != remove_index:\r\n                    new_row.append(old_row[column_index])\r\n            table[row_index] = new_row\r\n        return table", "response": "Removes the specified column from the specified table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insert_column(table, insert_column, col_name=None, default_value=None):\r\n    '''\r\n    Inserts a new column before another specified column (by name or index).\r\n\r\n    Args:\r\n        insert_column: The column index or first row name where the insertion should occur\r\n        col_name: The name to insert into the first row of the column. Leaving this argument\r\n            to the default of None will apply the default_value to that row's cell.\r\n        default_value: Can be a value or function which takes (row, index, value) as\r\n            arguments to return a value.\r\n    '''\r\n    column_labels = table[0]\r\n    following_index = 0\r\n\r\n    def set_cell(row, column_index, value):\r\n        # Allow function calls\r\n        if hasattr(value, '__call__'):\r\n            row[column_index] = value(column_labels, row, column_index)\r\n        else:\r\n            row[column_index] = value\r\n\r\n    if isinstance(insert_column, basestring):\r\n        insert_column = insert_column.strip()\r\n        for column_index in range(len(column_labels)):\r\n            if column_labels[column_index] == insert_column:\r\n                following_index = column_index\r\n                break\r\n    else:\r\n        following_index = insert_column\r\n\r\n    col_data_start = 0\r\n    if col_name != None:\r\n        table[0].insert(following_index, col_name.strip())\r\n        col_data_start = 1\r\n    for row in table[col_data_start:]:\r\n        row.insert(following_index, None)\r\n        if default_value:\r\n            set_cell(row, min(following_index, len(row)-1), default_value)", "response": "Adds a new column before another specified column."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstitches a list of blocks together into a single block columnwise.", "response": "def stitch_block(block_list):\r\n    '''\r\n    Stitches blocks together into a single block columnwise. These blocks are 2D tables usually\r\n    generated from tableproc. The final block will be of dimensions (max(num_rows), sum(num_cols)).\r\n    '''\r\n    block_out = [[]]\r\n    for block in block_list:\r\n        num_row = len(block)\r\n        row_len = len(block[0])\r\n        if len(block_out) < num_row:\r\n            for i in range(num_row-len(block_out)):\r\n                block_out.append([None]*len(block_out[0]))\r\n        for row_out, row_in in zip(block_out, block):\r\n            row_out.extend(row_in)\r\n        if len(block_out) > num_row:\r\n            for row_out in block_out[num_row:]:\r\n                row_out.extend([None]*row_len)\r\n    return block_out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stitch_block_rows(block_list):\r\n    '''\r\n    Stitches blocks together into a single block rowwise. These blocks are 2D tables usually\r\n    generated from tableproc. The final block will be of dimensions (sum(num_rows), max(num_cols)).\r\n    '''\r\n    stitched = list(itertools.chain(*block_list))\r\n    max_length = max(len(row) for row in stitched)\r\n    for row in stitched:\r\n        if len(row) < max_length:\r\n            row += [None] * (max_length - len(row))\r\n    return stitched", "response": "Stitches blocks together into a single block rowwise."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef row_content_length(row):\r\n    '''\r\n    Returns the length of non-empty content in a given row.\r\n    '''\r\n    if not row:\r\n        return 0\r\n    try:\r\n        return (index + 1 for index, cell in reversed(list(enumerate(row))) if not is_empty_cell(cell)).next()\r\n    except StopIteration:\r\n        return len(row)", "response": "Returns the length of non - empty content in a given row."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsplitting the block by finding all rows with less consequetive non - empty rows than the min_row_length input.", "response": "def split_block_by_row_length(block, split_row_length):\r\n    '''\r\n    Splits the block by finding all rows with less consequetive, non-empty rows than the\r\n    min_row_length input.\r\n    '''\r\n    split_blocks = []\r\n    current_block = []\r\n    for row in block:\r\n        if row_content_length(row) <= split_row_length:\r\n            if current_block:\r\n                split_blocks.append(current_block)\r\n            split_blocks.append([row])\r\n            current_block = []\r\n        else:\r\n            current_block.append(row)\r\n    if current_block:\r\n        split_blocks.append(current_block)\r\n\r\n    return split_blocks"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_need_install():\n    md5_root, md5_dst = list(), list()\n    need_install_flag = False\n    for root, _, basename_list in os.walk(_ROOT):\n        if os.path.basename(root) != \"__pycache__\":\n            for basename in basename_list:\n                src = os.path.join(root, basename)\n                dst = os.path.join(root.replace(_ROOT, _DST), basename)\n                if os.path.exists(dst):\n                    if md5_of_file(src) != md5_of_file(dst):\n                        return True\n                else:\n                    return True\n    return need_install_flag", "response": "Check if installed package are exactly the same to this one."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_permission_to_view(page, user):\n    if page.permissions.count() == 0:\n        return True\n    for perm in page.permissions.all():\n        perm_label = '%s.%s' % (perm.content_type.app_label, perm.codename)\n        if user.has_perm(perm_label):\n            return True\n    return False", "response": "Check whether the user has permission to view the page."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists all directives supported by the bot", "response": "def do_directives(self, line):\n        \"\"\"List all directives supported by the bot\"\"\"\n        for name, cmd in self.adapter.directives.items():\n            with colorize('blue'):\n                print('bot %s:' % name)\n                if cmd.__doc__:\n                    for line in cmd.__doc__.split('\\n'):\n                        print('  %s' % line)\n                else:\n                    print()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a function that returns True if the given user is not in the current set.", "response": "def BROADCAST_FILTER_OTHERS(user):\n        \"\"\"\n        HIGH-ORDER (pass it as IBroadcast.BROADCAST_FILTER_OTHERS(user-or-sequence))\n        Criteria to broadcast to every user but the current(s).\n        \"\"\"\n        if not isinstance(user, (set,frozenset,list,tuple)):\n            user = (user,)\n        return lambda u, command, *args, **kwargs: u not in user"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef BROADCAST_FILTER_AND(*funcs):\n        return lambda u, command, *args, **kwargs: all(f(u, command, *args, **kwargs) for f in funcs)", "response": "Compose the passed filters into an and - joined filter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef BROADCAST_FILTER_OR(*funcs):\n        return lambda u, command, *args, **kwargs: any(f(u, command, *args, **kwargs) for f in funcs)", "response": "Compose the passed filters into an or - joined filter."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef BROADCAST_FILTER_NOT(func):\n        return lambda u, command, *args, **kwargs: not func(u, command, *args, **kwargs)", "response": "Compose the passed filters into an and - joined filter."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nnotify each user with a specified command.", "response": "def broadcast(self, command, *args, **kwargs):\n        \"\"\"\n        Notifies each user with a specified command.\n        \"\"\"\n        criterion = kwargs.pop('criterion', self.BROADCAST_FILTER_ALL)\n        for index, user in items(self.users()):\n            if criterion(user, command, *args, **kwargs):\n                self.notify(user, command, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_config(basedir, files):\n    config_details = config.find(\n        basedir, files,\n        environment.Environment.from_env_file(basedir))\n\n    return config.load(config_details)", "response": "Returns the config object for the selected docker - compose. yml files"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild images and tags them appropriately.", "response": "def build(config, services):\n    \"\"\" Builds images and tags them appropriately.\n\n    Where \"appropriately\" means with the output of:\n\n        git describe --tags HEAD\n\n    and 'latest' as well (so the \"latest\" image for each will always be the\n    most recently built)\n    \"\"\"\n    filtered_services = {name: service for name, service in services.iteritems() if 'build' in service}\n\n    _call_output('docker-compose build {}'.format(' '.join(filtered_services.iterkeys())))\n\n    version = _get_version()\n\n    for service_name, service_dict in filtered_services.iteritems():\n        # Tag with proper version, they're already tagged latest from build\n        image = service_dict['image']\n        _call('docker tag {image}:latest {image}:{version}'.format(\n                image=image,\n                version=version\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef push(config, services):\n    version = _get_version()\n    for service_name, service_dict in services.iteritems():\n        image = service_dict['image']\n        things = {'image': image, 'version': version}\n        _call_output('docker push {image}:latest'.format(**things))\n        _call_output('docker push {image}:{version}'.format(**things))", "response": "Upload the defined services to their respective repositories."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nanimates a pandas. Panel by flipping through plots of the data in each dataframe and saving the data in a new video frame.", "response": "def animate_panel(panel, keys=None, columns=None, interval=1000, blit=False, titles='', path='animate_panel', xlabel='Time', ylabel='Value', ext='gif', \n                  replot=False, linewidth=3, close=False, fontsize=24, background_color='white', alpha=1, figsize=(12,8), xlabel_rotation=-25, plot_kwargs=(('rotation', 30),), \n                  verbosity=1, **video_kwargs):\n    \"\"\"Animate a pandas.Panel by flipping through plots of the data in each dataframe\n\n    Arguments:\n      panel (pandas.Panel): Pandas Panel of DataFrames to animate (each DataFrame is an animation video frame)\n      keys (list of str): ordered list of panel keys (pages) to animate\n      columns (list of str): ordered list of data series names to include in plot for eath video frame\n      interval (int): number of milliseconds between video frames\n      titles (str or list of str): titles to place in plot on each data frame.\n        default = `keys` so that titles changes with each frame\n      path (str): path and base file name to save *.mp4 animation video ('' to not save) \n      kwargs (dict): pass-through kwargs for `animation.FuncAnimation(...).save(path, **kwargs)`\n        (Not used if `not path`)\n\n    TODO: \n      - Work with other 3-D data formats:\n          - dict (sorted by key) or OrderedDict\n          - list of 2-D arrays/lists\n          - 3-D arrays/lists\n          - generators of 2-D arrays/lists\n          - generators of generators of lists/arrays?\n      - Write json and html5 files for d3 SVG line plots with transitions!\n\n    >>> x = np.arange(0, 2*np.pi, 0.05)\n    >>> panel = pd.Panel(dict((i, pd.DataFrame({\n    ...        'T=10': np.sin(x + i/10.),\n    ...        'T=7': np.sin(x + i/7.),\n    ...        'beat': np.sin(x + i/10.) + np.sin(x + i/7.),\n    ...        }, index=x)\n    ...    ) for i in range(50)))\n    >>> animate_panel(panel, interval=200, path='animate_panel_test')  # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE\n    Drawing frames for a \".gif\" animation...\n    Saving video to animate_panel_test.gif...\n              T=10       T=7      beat\n    0.00  0.000000  0.000000  0.000000\n    0.05  0.049979  0.049979  0.099958\n    ...\n\n    [126 rows x 3 columns]\n    \"\"\"\n    plot_kwargs = plot_kwargs or {}\n    plot_kwargs = dict(plot_kwargs)\n    ext_kwargs = {\n        'mp4': {'writer': 'ffmpeg', 'codec': 'mpeg4', 'dpi': 100, 'bitrate': 2000},\n        'gif': {'writer': 'imagemagick', 'dpi': 100, 'bitrate': 2000},\n        'imagemagic.gif': {'writer': 'imagemagick_gif', 'dpi': 100, 'bitrate': 2000},\n        }\n    ext = str(ext).lower().strip() or 'gif'\n    default_kwargs = ext_kwargs.get(ext, {})\n\n    keys = keys or list(panel.keys())\n    if titles:\n        titles = listify(titles)\n        if len(titles) == 1:\n            titles *= len(keys)\n    else:\n        titles = keys\n    titles = dict((k, title) for k, title in zip(keys, titles))\n    columns = columns or list(panel[keys[0]].columns)\n    \n    fig, ax = plt.subplots(figsize=figsize)\n\n    fig.patch.set_facecolor(background_color)\n    fig.patch.set_alpha(alpha)\n\n\n    i = 0\n    df = panel[keys[i]]\n    x = df.index.values\n    y = df[columns].values\n    lines = ax.plot(x, y)\n    ax.grid('on')\n    ax.patch.set_facecolor(background_color)\n    ax.patch.set_alpha(alpha)\n    ax.title.set_text(titles[keys[0]])\n    ax.title.set_fontsize(fontsize)\n    ax.title.set_fontweight('bold')\n    ax.xaxis.label.set_text(xlabel)\n    plt.setp(ax.get_xticklabels(), rotation=xlabel_rotation)\n    ax.yaxis.label.set_text(ylabel)\n    ax.legend(columns)\n\n\n    def animate(k):\n        df = panel[k]\n        x = df.index.values\n        y = df[columns].values.T\n        if replot:\n            # plt.cla()\n            # fig, ax = plt.subplots(figsize=figsize)\n            fig = ax.figure\n            fig.patch.set_facecolor(background_color)\n            fig.patch.set_alpha(alpha)\n            lines = ax.plot(x, y.T, linewidth=linewidth)\n            ax.grid('on')\n            ax.patch.set_facecolor(background_color)\n            ax.patch.set_alpha(alpha)\n            ax.title.set_text(titles[k])\n            ax.title.set_fontsize(fontsize)\n            ax.title.set_fontweight('bold')\n            ax.xaxis.label.set_text(xlabel)\n            plt.setp(ax.get_xticklabels(), rotation=xlabel_rotation)\n            ax.yaxis.label.set_text(ylabel)\n            ax.legend(columns)\n        else:\n            lines = ax.lines\n            fig = ax.figure\n\n            for i in range(len(lines)):\n                lines[i].set_xdata(x)  # all lines have to share the same x-data\n                lines[i].set_ydata(y[i])  # update the data, don't replot a new line\n                lines[i].set_linewidth(linewidth)\n                lines[i].figure.set_facecolor(background_color)\n                lines[i].figure.set_alpha(alpha)\n                lines[i].axes.patch.set_facecolor(background_color)\n                lines[i].axes.patch.set_alpha(alpha)\n            ax.patch.set_facecolor(background_color)\n            ax.figure.patch.set_alpha(alpha)\n            ax.title.set_text(titles[k])\n            ax.title.set_fontsize(fontsize)\n            ax.title.set_fontweight('bold')\n        if blit:\n            return lines\n\n    # FIXME: doesn't work with ext=mp4\n    # init_func to mask out pixels to be redrawn/cleared which speeds redrawing of plot\n    def mask_lines():\n        if verbosity > 0:\n            print('Initialing mask_lines. . .')\n        df = panel[0]\n        x = df.index.values\n        y = df[columns].values.T\n        for i in range(len(lines)):\n            # FIXME: why are x-values used to set the y-data coordinates of the mask?\n            lines[i].set_xdata(np.ma.array(x, mask=True))\n            lines[i].set_ydata(np.ma.array(y[i], mask=True))\n        return lines\n\n    if verbosity > 0:\n        print('Drawing frames for a \".{0}\" animation{1}. . .'.format(ext, ' with blitting' if blit else ''))\n    animate(keys[0])\n    ani = animation.FuncAnimation(fig, animate, keys, interval=interval, blit=blit) #, init_func=mask_lines, blit=True)\n\n    kwargs = dict(default_kwargs)\n    for k, v in six.iteritems(default_kwargs):\n        kwargs[k] = video_kwargs.get(k, v)\n    # if 'bitrate' in kwargs:\n    #     kwargs['bitrate'] = min(kwargs['bitrate'], int(8e5 / interval))  # low information rate (long interval) might make it impossible to achieve a higher bitrate ight not\n    if path and isinstance(path, basestring):\n        path += '.{0}'.format(ext)\n        if verbosity > 0:\n            print('Saving video to {0}. . .'.format(path))\n        ani.save(path, **kwargs)\n\n    if close:\n        plt.close(fig)\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_bins(bins, values=None):\n    if isinstance(bins, int):\n        bins = (bins,)\n    if isinstance(bins, float):\n        bins = (0, bins)\n\n    if not len(bins) in (1, 2):\n        return bins\n\n    if values is None or not hasattr(values, '__iter__') or not any(values) or not hasattr(values, '__len__') or len(values) < 1:\n        values = [0]\n    value_min, value_max = pd.np.min(values), pd.np.max(values)\n    value_range = value_max - value_min\n\n    if len(bins) == 1:\n        if not value_range:\n            return range(int(bins[0]) + 1)\n        bins = (0, value_range / float(bins[0]))\n    if len(bins) == 2:\n        if not value_range:\n            return bins\n        binwidth = ((bins[1] - bins[0]) or 1)\n        bin0 = bins[0] or pd.np.min(values)\n        if (bin0 / value_range) <= .3:\n            bin0 = 0\n        numbins = int(value_range / float(binwidth))\n        bins = list(pd.np.arange(numbins + 1) * binwidth + bin0)\n    else:\n        binwidth = pd.np.min(pd.np.diff(bins)) or pd.np.mean(pd.np.diff(bins)) or 1.\n    bins = list(bins)\n    while bins[-1] < value_max:\n        bins.append(bins[-1] + binwidth)\n    return bins", "response": "Generate a sequence of bins for numpy. histogram based on values and a requested bin parameters Returns a sequence of length N where N is the number of bins in the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef thin_string_list(list_of_strings, max_nonempty_strings=50, blank=''):\n        # blank some labels to make sure they don't overlap\n    list_of_strings = list(list_of_strings)\n    istep = 2\n    while sum(bool(s) for s in list_of_strings) > max_nonempty_strings:\n        list_of_strings = [blank if i % istep else s for i, s in enumerate(list_of_strings)]\n        istep += 2\n    return list_of_strings", "response": "Designed for composing lists of strings suitable for pyplot axis labels"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndesigning for composing lists of strings suitable for pyplot axis labels.", "response": "def prettify_datetimes(datetimes, format=\"%b %Y\", max_nonempty_strings=None, blank=''):\n    \"\"\"Designed for composing lists of strings suitable for pyplot axis labels\n\n    Often the xtick spacing doesn't allow room for 100's of text labels, so this\n    eliminates every other one, then every other one of those, until they fit.\n\n    >>> thin_string_list(['x']*20, 5)  # doctring: +NORMALIZE_WHITESPACE\n    ['x', '', '', '', 'x', '', '', '', 'x', '', '', '', 'x', '', '', '', 'x', '', '', '']\n    \"\"\"\n        # blank some labels to make sure they don't overlap\n    datetimes = [make_datetime(d) for d in datetimes]\n    datestrs = [d.strftime(\"%b %Y\") for d in datetimes]\n    if max_nonempty_strings:\n        return thin_string_list(datestrs, max_nonempty_strings=max_nonempty_strings, blank=blank)\n    return datestrs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_histogram(hist, width=0.9,\n                   title='', xlabel=None, datetime_format=\"%b %Y\",\n                   labels=None, color=None, alpha=None, normalize=True, percent=False, padding=0.03, num_labels=24,\n                   formatter=None, ylabel_precision=2, resolution=3,\n                   figsize=None, line_color='#C0C0C0', bg_color='white', bg_alpha=1, tight_layout=True,\n                   ylabel=None, grid='on', rotation=-60, ha='left',\n                   save_path='plot_histogram', dpi=200):\n    \"\"\"Plot a bar chart from np.histogram data\n\n    >>> plot_histogram(np.histogram([1]*5+[3]*2+list(range(20))+[19.1]), alpha=1)  # doctest: +NORMALIZE_WHITESPACE, +ELLIPSIS\n    ((array([7, 4, 2, 2, 2, 2, 2, 2, 2, 3]),\n    array([  0.  ,   1.91,   3.82,   5.73,   7.64,   9.55,  11.46,  13.37,\n        15.28,  17.19,  19.1 ])),\n    <matplotlib.figure.Figure at ...)\n    \"\"\"\n    his0, his1 = hist[0], hist[1]\n    if len(his1) == len(his0) + 1:\n        his0, his1 = his1[:-1], his0\n    elif len(his0) == len(his1) + 1:\n        his0 = his0[:-1]\n\n    resolution = resolution or 3\n    if labels in (None, 0, 'date', 'datetime'):\n        try:\n            labels = prettify_datetimes(['-'.join(str(val) for val in datetime_from_ordinal_float(val).timetuple()[:resolution]) for val in his0],\n                format=datetime_format, max_nonempty_strings=num_labels)\n        except ValueError:\n            labels = [('{0:.' + str(resolution) + 'g}').format(val) for val in his0]\n    elif labels == False:\n        labels = [''] * len(his0)\n    if len(labels) != len(his0) or not all(isinstance(val, basestring) for val in labels):\n        labels = list(str(s) for s in labels)\n        labels += [''] * (len(his0) - len(labels))\n    \n    labels = thin_string_list(labels, 50)\n\n    fig = plt.gcf()\n    if figsize and len(figsize)==2:\n        fig.set_size_inches(figsize[0], figsize[1], forward=True)\n    if bg_color or bg_alpha:\n        fig.set_facecolor(bg_color)\n        fig.set_alpha(bg_alpha)\n    if not fig.axes:\n        ax = fig.add_subplot(111)\n    else:\n        ax = fig.gca()\n\n    color = color or 'b'\n    alpha = alpha or .8\n    xlabel = xlabel or ''\n\n    xwidth = (width or 0.9) * pd.np.min(pd.np.diff(his0))\n\n    if not isinstance(ylabel, basestring):\n        ylabel = 'Count (Number of Occurrences)'\n\n\n    xwidth = (width or 0.9) * pd.np.min(pd.np.diff(his0))\n\n    ax.bar(his0, his1, width=xwidth, color=color, alpha=alpha)\n\n    print(his0)\n    plt.xticks([dy + padding*xwidth for dy in his0], labels, rotation=rotation, ha=ha)\n    if xlabel:\n        plt.xlabel(xlabel)\n    if ylabel:\n        plt.ylabel(ylabel)\n    if title:\n        plt.title(title)\n    if formatter and callable(formatter):\n        ax.yaxis.set_major_formatter(plt.matplotlib.ticker.FuncFormatter(formatter))\n    ax.grid(grid, color=(line_color or 'gray'))\n\n    # set all the colors and transparency values \n    fig.patch.set_facecolor(bg_color)\n    fig.patch.set_alpha(bg_alpha)\n    ax.patch.set_alpha(bg_alpha)\n    ax.patch.set_facecolor(bg_color)\n\n    if line_color:\n        for spine in ax.spines.values():\n            spine.set_color(line_color)\n        ax.tick_params(axis='x', colors=line_color)\n        ax.tick_params(axis='y', colors=line_color)\n        ax.xaxis.label.set_color(line_color)\n        ax.yaxis.label.set_color(line_color)\n        ax.title.set_color(line_color)\n\n    if tight_layout:\n        plt.tight_layout()\n\n    try:\n        # ipython notebook overrides plt.show and doesn't have a block kwarg\n        plt.show(block=False)\n    except TypeError:\n        plt.show()\n\n    if save_path:\n        if os.path.isfile(save_path + '.png'):\n            i = 2\n            save_path2 = save_path + '--{0}'.format(i)\n            while os.path.isfile(save_path2 + '.png'):\n                i += 1\n                save_path2 = save_path + '--{0}'.format(i)\n            save_path = save_path2\n        plt.savefig(save_path, facecolor=fig.get_facecolor(), edgecolor='none', dpi=dpi)\n\n    # return in standard numpy histogram format, values before bins, and bins include all fenceposts (edges)\n    his0, his1 = pd.np.array(his0), pd.np.array(his1)\n    his0 = np.append(his0, 2 * his0[-1] - his0[-2])\n    return (his1, his0), fig", "response": "Plot a histogram of the related objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbin a DataFrame of floats or datetime strings and plot the histogram.", "response": "def histogram_and_plot(df, column=0, width=0.9, resolution=2, str_timetags=True, counted=False,\n                   title='', xlabel=None, datetime_format='%b %d, %Y', num_labels=24, bins=None, \n                   labels=None, color=None, alpha=None, normalize=True, percent=False, padding=0.03,\n                   formatter=None, ylabel_precision=2,\n                   figsize=None, line_color='#C0C0C0', bg_color='white', bg_alpha=1, tight_layout=True,\n                   ylabel=None, grid='on', rotation=-60, ha='left',\n                   save_path='plot_histogram', dpi=200):\n    \"\"\"Bin a DataFrame of floats or datetime strings and plot the histogram\n\n    Arguments:\n      df (DataFrame of str or float): table of data containing data to be counted and binned\n      column (str): label of the DataFrame column containing data to be counted and binned\n      width (float): 0 < width <= 1, the graphical width of the bars as a fraction of the bin width\n      resolution (int): 0 < resolution < 7, \n        for a number of timetuple fields to truncate to for binning \n    TODO:\n      - allow more than one column/field/series\n      - add of cumulative histogram line overlay\n      - separate out plotting from counting and datetime conversion\n\n    FIXME:\n      - fail for `label_len=7`\n    \"\"\"\n\n    try:\n        assert len(bins) == len(counted) + 1\n        his0, his1 = bins, counted\n    except:\n        his0, his1 = [], []\n\n        if isinstance(df, basestring) and os.path.isfile(df):\n            df = pd.DataFrame.from_csv(df)\n        if not isinstance(df, pd.DataFrame):\n            df = pd.DataFrame(df)\n        if isinstance(column, int):\n            column = df.columns[column]\n        if not column in df.columns:\n            if not column == 'index':\n                warnings.warn('Unable to find a column named {0}, so using the index named \"{1}\" instead. The available columns are:\\n{2}'.format(\n                    column, df.index.name, df.columns))\n            column = df.index.name\n        if column == df.index.name:\n            df[column] = df.index.values\n\n    if not len(his0) and not len(his1) and not isinstance(df[column].dropna().values[0], (float, int)):\n        if all(isinstance(val, (datetime.datetime, datetime.date, datetime.time, pd.Timestamp, pd.np.datetime64)) for val in df[column].dropna().values):\n            timetag = df[column].values\n        elif str_timetags and all(is_valid_american_date_string(val) for val in df[column].dropna().values):\n            timetag = [datetime.datetime.strptime(val, '%m/%d/%Y') if isinstance(val, basestring) else make_datetime(val) for val in df[column]]\n        else:\n            timetag = [make_datetime(val) for val in df[column].values]\n\n        # r['Returned Ordinal'] = [datetime.datetime.strptime(s, '%m/%d/%Y').date().toordinal() for s in r['Returned']]\n        if resolution and bins in (None, 0):\n            quantized_date = [quantize_datetime(dt, resolution) for dt in timetag]\n            quantized_ordinal = ordinal_float(quantized_date)\n            his0, his1 = zip(*sorted(Counter(quantized_ordinal).items()))\n            bins = his0\n        else:\n            days = ordinal_float(df[column].dropna())\n            bins = generate_bins(bins, days)\n            his1, his0 = pd.np.histogram(days, bins=bins)\n            \n        resolution = int(resolution or 7)\n\n    if counted in (None, 0, False, []):\n        if any(his0) and any(his1):\n            labels = prettify_datetimes(['-'.join(str(val) for val in datetime_from_ordinal_float(ordinal).timetuple()[:resolution]) for ordinal in his0], format=datetime_format)\n        elif isinstance(df[column].values[0], (float, int)):\n            if not any(bins):\n                bins = resolution * 10\n            bins = generate_bins(bins, df[column].dropna())\n            his1, his0 = pd.np.histogram(df[column].dropna(), bins=bins)\n            labels = ['{:.3g}'.format(val) for val in his0[:-1]]\n            # labels = ['{:.3g}-{.3g}'.format(left, right) for left, right in zip(his[0][:-1], his[0][1:])]\n            width = max(width, 0.95)\n            padding = 0\n\n    if len(his0) > len(his1):\n        his0 = his0[:-1]\n    his0 = pd.np.array(his0)\n    his1 = pd.np.array(his1)\n    if normalize:\n        normalize = float(normalize)\n        total = float(pd.np.sum(his1))\n        his1 = normalize * his1 * 1.0 / total\n        if not isinstance(ylabel, basestring):\n            if normalize in (1., 100.):\n                ylabel = 'Frequency (Probability or Count/Total)'\n                if not (formatter and callable(formatter)):\n                    formatter = percent_formatter\n                    if normalize != 1.:\n                        percent_formatter.scale_factor = 1.\n                        percent_formatter.precision = ylabel_precision\n                        normalize = 1.\n            else:\n                ylabel = 'Scaled Frequency ({0:.6g}*Count/Total)'.format(normalize)\n\n    return plot_histogram( hist=(his0, his1), width=width,\n                           title=title, xlabel=xlabel, datetime_format=datetime_format, num_labels=num_labels,\n                           labels=labels, color=color, alpha=alpha, normalize=normalize, percent=percent, padding=padding,\n                           formatter=formatter, ylabel_precision=ylabel_precision,\n                           figsize=figsize, line_color=line_color, bg_color=bg_color, bg_alpha=bg_alpha, tight_layout=tight_layout,\n                           ylabel=ylabel, grid=grid, rotation=rotation, ha=ha,\n                           save_path=save_path, dpi=dpi)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nselecting item with path from target.", "response": "def select(target, path, default=None, slient=True):\n    \"\"\"Select item with path from target. \n\n    If not find item and slient marked as True, return default value.\n    If not find item and slient marked as False, raise KeyError.\n    \"\"\"\n    def _(value, slient):\n        if slient:\n            return value\n        else:\n            raise KeyError(\"\")\n    default = partial(_, default, slient)\n    names = path.split(\".\")\n    node = target\n    for name in names:\n        if isinstance(node, dict):\n            try:\n                node = node[name]\n            except:\n                return default()\n        elif isinstance(node, list) and name.isdigit():\n            try:\n                node = node[int(name)]\n            except:\n                return default()\n        elif hasattr(node, name):\n            node = getattr(node, name)\n        else:\n            return default()\n    return node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating item in path of target with given value.", "response": "def update(target, path, value):\n    \"\"\"Update item in path of target with given value.\n    \"\"\"\n    names = path.split(\".\")\n    names_length = len(names)\n    node = target\n    for index in range(names_length):\n        name = names[index]\n        if index == names_length - 1:\n            last = True\n        else:\n            last = False\n        if isinstance(node, dict):\n            if last:\n                node[name] = value\n                return\n            else:\n                if not name in node:\n                    node[name] = {}\n                node = node[name]\n        elif isinstance(node, list):\n            name = int(name)\n            listpad(node, name+1)\n            if last:\n                node[name] = value\n                return\n            else:\n                node[name] = {}\n                node = node[name]\n        else:\n            if last:\n                setattr(node, name, value)\n            else:\n                setattr(node, name, {})\n                node = getattr(node, name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the output from Picard s BamIndexStast and return as pandas Dataframe.", "response": "def parse_bam_index_stats(fn):\n    \"\"\"\n    Parse the output from Picard's BamIndexStast and return as pandas Dataframe.\n\n    Parameters\n    ----------\n    filename : str of filename or file handle\n        Filename of the Picard output you want to parse.\n\n    Returns\n    -------\n    df : pandas.DataFrame\n        Data from output file.\n\n    \"\"\"\n    with open(fn) as f:\n        lines = [x.strip().split() for x in f.readlines()]\n    no_counts = int(lines[-1][-1])\n    lines = lines[:-1]\n    chrom = [x[0] for x in lines]\n    length = [int(x[2]) for x in lines]\n    aligned = [int(x[4]) for x in lines]\n    unaligned = [int(x[6]) for x in lines]\n    df = pd.DataFrame([length, aligned, unaligned], columns=chrom, \n                      index=['length', 'aligned', 'unaligned']).T\n    df = df.ix[sorted(df.index)]\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the output from Picard s CollectAlignmentSummaryMetrics and return as pandas. DataFrame", "response": "def parse_alignment_summary_metrics(fn):\n    \"\"\"\n    Parse the output from Picard's CollectAlignmentSummaryMetrics and return as\n    pandas Dataframe.\n\n    Parameters\n    ----------\n    filename : str of filename or file handle\n        Filename of the Picard output you want to parse.\n\n    Returns\n    -------\n    df : pandas.DataFrame\n        Data from output file.\n\n    \"\"\"\n    df = pd.read_table(fn, index_col=0, skiprows=range(6) + [10, 11]).T\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_mark_duplicate_metrics(fn):\n    with open(fn) as f:\n        lines = [x.strip().split('\\t') for x in f.readlines()]\n    metrics = pd.Series(lines[7], lines[6])\n    m = pd.to_numeric(metrics[metrics.index[1:]])\n    metrics[m.index] = m.values\n\n    vals = np.array(lines[11:-1])\n    hist = pd.Series(vals[:, 1], index=[int(float(x)) for x in vals[:, 0]])\n    hist = pd.to_numeric(hist)\n    return metrics, hist", "response": "Parse the output from Picard s MarkDuplicates and return as pandas\n    Series."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the output from Picard s CollectInsertSizeMetrics and return as pandas. Series.", "response": "def parse_insert_metrics(fn):\n    \"\"\"\n    Parse the output from Picard's CollectInsertSizeMetrics and return as pandas\n    Series.\n\n    Parameters\n    ----------\n    filename : str of filename or file handle\n        Filename of the Picard output you want to parse.\n\n    Returns\n    -------\n    metrics : pandas.Series\n        Insert size metrics.\n\n    hist : pandas.Series\n        Insert size histogram.\n\n    \"\"\"\n    with open(fn) as f:\n        lines = [x.strip().split('\\t') for x in f.readlines()]\n\n    index = lines[6]\n    vals = lines[7]\n    for i in range(len(index) - len(vals)):\n        vals.append(np.nan)\n    for i, v in enumerate(vals):\n        if type(v) == str:\n            try:\n                vals[i] = int(v)\n            except ValueError:\n                try: \n                    vals[i] = float(v)\n                except ValueError:\n                    continue\n    metrics = pd.Series(vals, index=index)\n    \n    vals = np.array(lines[11:-1])\n    hist = pd.Series(vals[:, 1], index=[int(float(x)) for x in vals[:, 0]])\n    hist = pd.to_numeric(hist)\n    return metrics, hist"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef serialize_query(func):\n        @functools.wraps(func)\n        def wrapper(self, query, *args, **kwargs):\n            if hasattr(query, 'serialize'):\n                query = query.serialize()\n\n            assert isinstance(query, basestring), 'Expected query to be string'\n            if self.debug:\n                print('SQL:', query)\n\n            return func(self, query, *args, **kwargs)\n        return wrapper", "response": "Decorator that ensures any SQLExpression instances are serialized"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the string that can be used by the jQuery Autocomplete plugin.", "response": "def autocomplete_view(self, request):\n        \"\"\"\n        Searches in the fields of the given related model and returns the\n        result as a simple string to be used by the jQuery Autocomplete plugin\n        \"\"\"\n        query = request.GET.get('q', None)\n        app_label = request.GET.get('app_label', None)\n        model_name = request.GET.get('model_name', None)\n        search_fields = request.GET.get('search_fields', None)\n        object_pk = request.GET.get('object_pk', None)\n\n        try:\n            to_string_function = self.related_string_functions[model_name]\n        except KeyError:\n            to_string_function = lambda x: str(x)\n\n        if search_fields and app_label and model_name and (query or object_pk):\n\n            def construct_search(field_name):\n                # use different lookup methods depending on the notation\n                if field_name.startswith('^'):\n                    fmt, name = \"{}__istartswith\", field_name[1:]\n                elif field_name.startswith('='):\n                    fmt, name = \"{}__iexact\", field_name[1:]\n                elif field_name.startswith('@'):\n                    fmt, name = \"{}__search\", field_name[1:]\n                else:\n                    fmt, name = \"{}__icontains\", field_name\n                return fmt.format(name)\n\n            model = apps.get_model(app_label, model_name)\n            queryset = model._default_manager.all()\n            data = ''\n            if query:\n                for bit in query.split():\n                    or_queries = [\n                        models.Q(**{construct_search(smart_str(field_name)): smart_str(bit)})\n                        for field_name\n                        in search_fields.split(',')\n                    ]\n                    other_qs = QuerySet(model)\n                    other_qs.query.select_related = queryset.query.select_related\n                    other_qs = other_qs.filter(reduce(operator.or_, or_queries))\n                    queryset = queryset & other_qs\n\n                if self.autocomplete_limit:\n                    queryset = queryset[:self.autocomplete_limit]\n\n                data = ''.join([\n                    '{}|{}\\n'.format(to_string_function(f), f.pk)\n                    for f\n                    in queryset\n                ])\n            elif object_pk:\n                try:\n                    obj = queryset.get(pk=object_pk)\n                except:\n                    pass\n                else:\n                    data = to_string_function(obj)\n            return HttpResponse(data)\n        return HttpResponseNotFound()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a set of null SNVs based on an input list of SNPs and categorical xsd annotations.", "response": "def generate_null_snvs(df, snvs, num_null_sets=5):\n    \"\"\"\n    Generate a set of null SNVs based on an input list of SNVs and categorical\n    annotations. \n    \n    Parameters\n    ----------\n    df : pandas.DataFrame\n        Pandas dataframe where each column is a categorization of SNPs. \n        The index should be SNPs of the form chrom:pos.\n        \n    snvs : list\n        List of input SNVs in the format chrom:pos. Entries that aren't in\n        the index of df will be dropped.\n        \n    num_null_sets : int\n        Number of sets of null SNVs to generate.\n        \n    Returns\n    -------\n    null_sets : pandas.Dataframe\n        Pandas dataframe with input SNVs as first column and null SNVs as\n        following columns.\n\n    \"\"\"\n    import numpy as np\n    import random\n    random.seed(20151007)\n    input_snvs = list(set(df.index) & set(snvs))\n    sig = df.ix[input_snvs]\n    not_sig = df.ix[set(df.index) - set(snvs)]\n    sig['group'] = sig.apply(lambda x: '::'.join(x), axis=1)\n    not_sig['group'] = not_sig.apply(lambda x: '::'.join(x), axis=1)\n    null_sets = []\n    vc = sig.group.value_counts()\n    bins = {c:sorted(list(df[c].value_counts().index)) for c in df.columns}\n    ordered_inputs = []\n    for i in vc.index:\n        ordered_inputs += list(sig[sig.group == i].index)\n        tdf = not_sig[not_sig.group == i]\n        count = vc[i]\n        for n in xrange(num_null_sets):\n            if tdf.shape[0] == 0:\n                groups = [i]\n                while tdf.shape[0] == 0:\n                    # If there are no potential null SNVs in this group, we'll\n                    # expand the group randomly.\n                    g = groups[-1]\n                    # Choose random bin.\n                    cols = list(not_sig.columns)\n                    cols.remove('group')\n                    b = random.choice(cols)\n                    # Get possibilities for that bin.\n                    t = bins[b]\n                    # Get last set of bin values and the value for the bin we\n                    # want to change.\n                    d = dict(zip(not_sig.columns, g.split('::')))\n                    cat = d[b]\n                    # Randomly walk away from bin value.\n                    ind = t.index(cat)\n                    if ind == 0:\n                        ind += 1\n                    elif ind == len(t) - 1:\n                        ind -= 1\n                    else:\n                        ind += random.choice([-1, 1])\n                    d[b] = t[ind]\n                    groups.append('::'.join(pd.Series(d)[not_sig.columns].astype(str)))\n                    tdf = not_sig[not_sig.group.apply(lambda x: x in groups)]\n            if count <= tdf.shape[0]:\n                ind = random.sample(tdf.index, count)\n            else:\n                ind = list(np.random.choice(tdf.index, size=count, replace=True))\n            if i == vc.index[0]:\n                null_sets.append(ind)\n            else:\n                null_sets[n] += ind\n    null_sets = pd.DataFrame(null_sets).T\n    null_sets.columns = ['null_{}'.format(x) for x in null_sets.columns]\n    cs = list(null_sets.columns)\n    null_sets['input'] = ordered_inputs\n    null_sets = null_sets[['input'] + cs]\n    return null_sets"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_grasp_phenotype_file(fn, pheno, out):\n    import subprocess\n    c = 'awk -F \"\\\\t\" \\'NR == 1 || $12 == \"{}\" \\' {} > {}'.format(\n        pheno.replace(\"'\", '\\\\x27'), fn, out)\n    subprocess.check_call(c, shell=True)", "response": "This function will create a GRASP file for a specific phenotype from a specific GRASP database file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_grasp_gwas(fn):\n    df = pd.read_table(fn, low_memory=False)\n    df = df[df.Pvalue < 1e-5]\n    df = df.sort(columns=['chr(hg19)', 'pos(hg19)', 'Pvalue'])\n    df = df.drop_duplicates(subset=['chr(hg19)', 'pos(hg19)'])\n    df = df[df.Pvalue < 1e-5]\n    df['chrom'] = 'chr' + df['chr(hg19)'].astype(str)\n    df['end'] = df['pos(hg19)']\n    df['start'] = df.end - 1\n    df['rsid'] = df['SNPid(in paper)']\n    df['pvalue'] = df['Pvalue']\n    df = df[['chrom', 'start', 'end', 'rsid', 'pvalue']]\n    df.index = df['chrom'].astype(str) + ':' + df['end'].astype(str)\n    return df", "response": "Read GRASP database and filter for unique hits."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_roadmap_gwas(fn):\n    df = pd.read_table(fn, low_memory=False, \n                       names=['chrom', 'start', 'end', 'rsid', 'pvalue'])\n    df = df[df.pvalue < 1e-5]\n    df = df.sort(columns=['chrom', 'start', 'pvalue'])\n    df = df.drop_duplicates(subset=['chrom', 'start'])\n    df = df[df['chrom'] != 'chrY']\n    df.index = df['chrom'].astype(str) + ':' + df['end'].astype(str)\n    return df", "response": "Read a ROADMAP GWAS file and filter for unique significant SNPs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ld_prune(df, ld_beds, snvs=None):\n    import networkx as nx\n    import tabix\n    if snvs:\n        df = df.ix[set(df.index) & set(snvs)]\n    keep = set()\n    for chrom in ld_beds.keys():\n        tdf = df[df['chrom'].astype(str) == chrom]\n        if tdf.shape[0] > 0:\n            f = tabix.open(ld_beds[chrom])\n            # Make a dict where each key is a SNP and the values are all of the\n            # other SNPs in LD with the key.\n            ld_d = {}\n            for j in tdf.index:\n                p = tdf.ix[j, 'end']\n                ld_d[p] = []\n                try:\n                    r = f.query(chrom, p - 1, p)\n                    while True:\n                        try:\n                            n = r.next()\n                            p1, p2, r2 = n[-1].split(':')\n                            if float(r2) >= 0.8:\n                                ld_d[p].append(int(p2))\n                        except StopIteration:\n                            break\n                except TabixError:\n                    continue\n            # Make adjacency matrix for LD.\n            cols = sorted(list(set(\n                [item for sublist in ld_d.values() for item in sublist])))\n            t = pd.DataFrame(0, index=ld_d.keys(), columns=cols)\n            for k in ld_d.keys():\n                t.ix[k, ld_d[k]] = 1\n            t.index = ['{}:{}'.format(chrom, x) for x in t.index]\n            t.columns = ['{}:{}'.format(chrom, x) for x in t.columns]\n            # Keep all SNPs not in LD with any others. These will be in the index\n            # but not in the columns.\n            keep |= set(t.index) - set(t.columns)\n            # Filter so we only have SNPs that are in LD with at least one other\n            # SNP.\n            ind = list(set(t.columns) & set(t.index))\n            # Keep one most sig. SNP per connected subgraph.\n            t = t.ix[ind, ind]\n            g = nx.Graph(t.values)\n            c = nx.connected_components(g)\n            while True:\n                try:\n                    sg = c.next()\n                    s = tdf.ix[t.index[list(sg)]]\n                    keep.add(s[s.pvalue == s.pvalue.min()].index[0])\n                except StopIteration:\n                    break\n    out = df.ix[keep]\n    return out", "response": "Prune GWAS based on LD and significance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ld_expand(df, ld_beds):\n    import pybedtools as pbt\n    import tabix\n    out_snps = []\n    for chrom in ld_beds.keys():\n        t = tabix.open(ld_beds[chrom])\n        tdf = df[df['chrom'].astype(str) == chrom]\n        for ind in tdf.index:\n            p = tdf.ix[ind, 'end']\n            out_snps.append('{}\\t{}\\t{}\\t{}\\n'.format(chrom, p - 1, p, ind))\n            try:\n                r = t.query('{}'.format(chrom), p - 1, p)\n                while True:\n                    try:\n                        n = r.next()\n                        p1, p2, r2 = n[-1].split(':')\n                        if float(r2) >= 0.8:\n                            out_snps.append('{}\\t{}\\t{}\\t{}\\n'.format(\n                                n[0], int(p2) - 1, int(p2), ind))\n                    except StopIteration:\n                        break\n            except tabix.TabixError:\n                continue\n    bt = pbt.BedTool(''.join(out_snps), from_string=True)\n    bt = bt.sort()\n    return bt", "response": "Expand a set of SNVs into all SNVs with LD > = 0. 8 and return a BedTool of the expanded SNPs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef liftover_bed(\n    bed, \n    chain, \n    mapped=None, \n    unmapped=None,\n    liftOver_path='liftOver',\n):\n    \"\"\"\n    Lift over a bed file using a given chain file. \n\n    Parameters\n    ----------\n    bed : str or pybedtools.BedTool\n        Coordinates to lift over.\n        \n    chain : str\n        Path to chain file to use for lift over.\n\n    mapped : str\n        Path for bed file with coordinates that are lifted over correctly.\n\n    unmapped : str\n        Path for text file to store coordinates that did not lift over\n        correctly. If this is not provided, these are discarded.\n\n    liftOver_path : str\n        Path to liftOver executable if not in path.\n\n    Returns\n    -------\n    new_coords : pandas.DataFrame\n        Pandas data frame with lift over results. Index is old coordinates in\n        the form chrom:start-end and columns are chrom, start, end and loc\n        (chrom:start-end) in new coordinate system.\n    \"\"\"\n    import subprocess\n    import pybedtools as pbt\n    if mapped == None:\n        import tempfile\n        mapped = tempfile.NamedTemporaryFile()\n        mname = mapped.name\n    else:\n        mname = mapped\n    if unmapped == None:\n        import tempfile\n        unmapped = tempfile.NamedTemporaryFile()\n        uname = unmapped.name\n    else:\n        uname = unmapped\n    if type(bed) == str:\n        bt = pbt.BedTool(bed)\n    elif type(bed) == pbt.bedtool.BedTool:\n        bt = bed\n    else:\n        sys.exit(1)\n    bt = bt.sort()\n    c = '{} {} {} {} {}'.format(liftOver_path, bt.fn, chain, mname, uname)\n    subprocess.check_call(c, shell=True)\n    with open(uname) as f:\n        missing = pbt.BedTool(''.join([x for x in f.readlines()[1::2]]),\n                              from_string=True)\n    bt = bt.subtract(missing)\n    bt_mapped = pbt.BedTool(mname)\n    old_loc = []\n    for r in bt:\n        old_loc.append('{}:{}-{}'.format(r.chrom, r.start, r.end))\n    new_loc = []\n    new_chrom = []\n    new_start = []\n    new_end = []\n    for r in bt_mapped:\n        new_loc.append('{}:{}-{}'.format(r.chrom, r.start, r.end))\n        new_chrom.append(r.chrom)\n        new_start.append(r.start)\n        new_end.append(r.end)\n    new_coords = pd.DataFrame({'loc':new_loc, 'chrom': new_chrom, \n                               'start': new_start, 'end': new_end},\n                              index=old_loc)\n    for f in [mapped, unmapped]:\n        try:\n            f.close()\n        except AttributeError:\n            continue\n    return new_coords", "response": "Uses a BEDTool to lift over a set of coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deseq2_size_factors(counts, meta, design):\n    import rpy2.robjects as r\n    from rpy2.robjects import pandas2ri\n    pandas2ri.activate()\n    r.r('suppressMessages(library(DESeq2))')\n    r.globalenv['counts'] = counts\n    r.globalenv['meta'] = meta\n    r.r('dds = DESeqDataSetFromMatrix(countData=counts, colData=meta, '\n        'design={})'.format(design))\n    r.r('dds = estimateSizeFactors(dds)')\n    r.r('sf = sizeFactors(dds)')\n    sf = r.globalenv['sf']\n    return pd.Series(sf, index=counts.columns)", "response": "Get size factors for counts using DESeq2."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef goseq_gene_enrichment(genes, sig, plot_fn=None, length_correct=True):\n    import os\n    import readline\n    import statsmodels.stats.multitest as smm\n    import rpy2.robjects as r\n    genes = list(genes)\n    sig = [bool(x) for x in sig]\n    r.r('suppressMessages(library(goseq))')\n    r.globalenv['genes'] = list(genes)\n    r.globalenv['group'] = list(sig)\n    r.r('group = as.logical(group)')\n    r.r('names(group) = genes')\n    r.r('pwf = nullp(group, \"hg19\", \"ensGene\")')\n    if length_correct:\n        r.r('wall = goseq(pwf, \"hg19\", \"ensGene\")')\n    else:\n        r.r('wall = goseq(pwf, \"hg19\", \"ensGene\", method=\"Hypergeometric\")')\n    r.r('t = as.data.frame(wall)')\n    t = r.globalenv['t']\n    go_results = pd.DataFrame(columns=list(t.colnames))\n    for i, c in enumerate(go_results.columns):\n        go_results[c] = list(t[i])\n    r, c, ask, abf = smm.multipletests(\n        go_results.over_represented_pvalue, alpha=0.05, method='fdr_i')\n    go_results['over_represented_pvalue_bh'] = c \n    r, c, ask, abf = smm.multipletests(\n        go_results.under_represented_pvalue, alpha=0.05, method='fdr_i')\n    go_results['under_represented_pvalue_bh'] = c\n    go_results.index = go_results.category\n    go_results = go_results.drop('category', axis=1)\n    if plot_fn and os.path.exists('Rplots.pdf'):\n        from os import rename\n        rename('Rplots.pdf', plot_fn)\n    elif os.path.exists('Rplots.pdf'):\n        from os import remove\n        remove('Rplots.pdf')\n    return go_results", "response": "Perform goseq enrichment for a list of genes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef categories_to_colors(cats, colormap=None):\n    if colormap is None:\n        colormap = tableau20\n    if type(cats) != pd.Series:\n        cats = pd.Series(cats)\n    legend = pd.Series(dict(zip(set(cats), colormap)))\n    # colors = pd.Series([legend[x] for x in cats.values], index=cats.index)\n    # I've removed this output:\n    # colors : pd.Series\n    #     Series whose values are the colors for each category. If cats was a\n    #     Series, then out will have the same index as cats.\n    return(legend)", "response": "Map categorical data to colors."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot a pandas Series with labels and colors and labels.", "response": "def plot_color_legend(legend, horizontal=False, ax=None):\n    \"\"\"\n    Plot a pandas Series with labels and colors.\n\n    Parameters\n    ----------\n    legend : pandas.Series\n        Pandas Series whose values are RGB triples and whose index contains\n        categorical labels.\n\n    horizontal : bool\n        If True, plot horizontally.\n\n    ax : matplotlib.axis\n        Axis to plot on.\n\n    Returns\n    -------\n    ax : matplotlib.axis\n        Plot axis.\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    import numpy as np\n    t = np.array([np.array([x for x in legend])])\n    if ax is None:\n        fig, ax = plt.subplots(1, 1)\n    if horizontal:\n        ax.imshow(t, interpolation='none')\n        ax.set_yticks([])\n        ax.set_xticks(np.arange(0, legend.shape[0]))\n        t = ax.set_xticklabels(legend.index)\n    else:\n        t = t.reshape([legend.shape[0], 1, 3])\n        ax.imshow(t, interpolation='none')\n        ax.set_xticks([])\n        ax.set_yticks(np.arange(0, legend.shape[0]))\n        t = ax.set_yticklabels(legend.index)\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a list of rectangles and labels for making legends.", "response": "def make_color_legend_rects(colors, labels=None):\n    \"\"\" \n    Make list of rectangles and labels for making legends.\n\n    Parameters\n    ----------\n    colors : pandas.Series or list\n        Pandas series whose values are colors and index is labels.\n        Alternatively, you can provide a list with colors and provide the labels\n        as a list.\n\n    labels : list\n        If colors is a list, this should be the list of corresponding labels.\n\n    Returns\n    -------\n    out : pd.Series\n        Pandas series whose values are matplotlib rectangles and whose index are\n        the legend labels for those rectangles. You can add each of these\n        rectangles to your axis using ax.add_patch(r) for r in out then create a\n        legend whose labels are out.values and whose labels are\n        legend_rects.index:\n            for r in legend_rects:\n                ax.add_patch(r)\n            lgd = ax.legend(legend_rects.values, labels=legend_rects.index)\n\n    \"\"\"\n    from matplotlib.pyplot import Rectangle\n    if labels:\n        d = dict(zip(labels, colors))\n        se = pd.Series(d)\n    else:\n        se = colors\n    rects = []\n    for i in se.index:\n        r = Rectangle((0, 0), 0, 0, fc=se[i])\n        rects.append(r)\n    out = pd.Series(rects, index=se.index)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake a Manhattan plot for GWAS results.", "response": "def manhattan_plot(\n    res, \n    ax, \n    p_filter=1,\n    p_cutoff=None,\n    marker_size=10, \n    font_size=8, \n    chrom_labels=range(1, 23)[0::2],\n    label_column=None,\n    category_order=None,\n    legend=True,\n):\n    \"\"\"\n    Make Manhattan plot for GWAS results. Currently only support autosomes.\n    \n    Parameters\n    ----------\n    res : pandas.DataFrame\n        GWAS results. The following columns are required - chrom (chromsome,\n        int), pos (genomic position, int), P (GWAS p-value, float).\n        \n    ax : matplotlib.axis\n        Matplotlib axis to make Manhattan plot on.\n\n    p_filter : float\n        Only plot p-values smaller than this cutoff. This is useful for testing\n        because filtering on p-values speeds up the plotting.\n        \n    p_cutoff : float\n        Plot horizontal line at this p-value.\n        \n    marker_size : int\n        Size of Manhattan markers.\n\n    font_size : int\n        Font size for plots.\n\n    chrom_labels : list\n        List of ints indicating which chromsomes to label. You may want to\n        modulate this based on the size of the plot. Currently only integers\n        1-22 are supported.\n\n    label_column : str\n        String with column name from res. This column should contain a\n        categorical annotation for each variant. These will be indicated by\n        colors.\n\n    category_order : list\n        If label_column is not None, you can provide a list of the categories\n        that are contained in the label_column. This will be used to assign the\n        color palette and will specify the z-order of the categories.\n\n    legend : boolean\n        If True and label_column is not None, plot a legend.\n        \n    Returns\n    -------\n    res : pandas.Dataframe\n        GWAS results. The results will have additional columns that were used\n        for plotting.\n\n    ax : matplotlib.axis\n        Axis with the Manhattan plot.\n\n    colors : pd.Series or None\n        If label_column is None, this will be None. Otherwise, if a label_column\n        is specified, this will be a series with a mapping between the labels\n        and the colors for each label.\n\n    \"\"\"\n    # TODO: It might make sense to allow a variable that specifies the z-order\n    # of labels in label_column. If there are many labels and points in the same\n    # place, certain annotations will be preferentially shown.\n    import matplotlib as mpl\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import seaborn as sns\n    # Filter results based on p-value.\n    if p_filter < 1:\n        res = res[res['P'] < p_filter]\n    # Assign x coordinates for each association.\n    res['xpos'] = np.nan\n    chrom_vc = res['chrom'].value_counts()\n    # total_length is arbitrary, but it's a little easier than working with the \n    # normalized chromosome sizes to avoid small numbers.\n    total_length = 1000\n    right = chrom_sizes_norm.cumsum()\n    right = right / right[22] * total_length\n    left = chrom_sizes_norm.cumsum() - chrom_sizes_norm[1]\n    left = pd.Series(0, range(1, 23))\n    left[1:23] = right[0:21].values\n    for chrom in range(1, 23):\n        if chrom in res['chrom'].values:\n            res.loc[res['chrom'] == chrom, 'xpos'] = np.linspace(\n                left[chrom], right[chrom], chrom_vc[chrom])\n    # Assign colors.\n    grey = mpl.colors.to_rgb('grey')\n    light_grey = (0.9, 0.9, 0.9)\n    middle_grey = (0.8, 0.8, 0.8)\n    # I first set everything to black, but in the end everything should be\n    # changed to one of the greys (or other colors if there is an annotation\n    # column). If there are black points on the plot, that indicates a problem.\n    res['color'] = 'black'\n    for chrom in range(1, 23)[0::2]:\n        if chrom in res['chrom'].values:\n            ind = res[res.chrom == chrom].index\n            res.loc[ind, 'color'] = pd.Series([grey for x in ind], index=ind)\n    for chrom in range(1, 23)[1::2]:\n        if chrom in res['chrom'].values:\n            ind = res[res.chrom == chrom].index\n            res.loc[ind, 'color'] = pd.Series([middle_grey for x in ind], index=ind)\n    if label_column is not None:\n        if category_order is not None:\n            assert set(category_order) == set(res[label_column].dropna())\n            categories = category_order\n        else:\n            categories = list(set(res[label_column].dropna()))\n        colors = categories_to_colors(\n            categories, \n            colormap=sns.color_palette('colorblind'),\n        )\n        for cat in categories:\n            ind = res[res[label_column] == cat].index\n            res.loc[ind, 'color'] = pd.Series([colors[cat] for x in ind],\n                                              index=ind)\n    \n    # Plot\n    if label_column is not None:\n        ind = res[res[label_column].isnull()].index\n        ax.scatter(\n            res.loc[ind, 'xpos'], \n            -np.log10(res.loc[ind, 'P']),\n            color=res.loc[ind, 'color'], \n            s=marker_size, \n            alpha=0.75,\n            rasterized=True,\n            label=None,\n        )\n        for cat in reversed(categories):\n            ind = res[res[label_column] == cat].index\n            ax.scatter(\n                res.loc[ind, 'xpos'], \n                -np.log10(res.loc[ind, 'P']),\n                color=res.loc[ind, 'color'], \n                s=marker_size, \n                alpha=0.75,\n                rasterized=True,\n                label=None,\n            )\n    else:\n        ax.scatter(\n            res['xpos'], \n            -np.log10(res['P']),\n            color=res['color'], \n            s=marker_size, \n            alpha=0.75,\n            rasterized=True,\n            label=None,\n        )\n    xmin, xmax = ax.get_xlim()\n    ymin, ymax = ax.get_ylim()\n    ax.grid(axis='x')\n    ax.grid(axis='y')\n    ax.grid(axis='y', alpha=0.5, ls='-', lw=0.6)\n    if p_cutoff is not None:\n        ax.hlines(\n            -np.log10(p_cutoff), \n            -5, \n            total_length + 5, \n            color='red', \n            linestyles='--',\n            lw=0.8, \n            alpha=0.5,\n        )\n    # These next two lines add background shading. I may add back in as option.\n    # for chrom in range(1, 23)[0::2]:\n    #     ax.axvspan(left[chrom], right[chrom], facecolor=(0.4, 0.4, 0.4), alpha=0.2, lw=0)\n    ax.set_xlim(-5, total_length + 5)\n    ax.set_ylim(0, ymax)\n    # Set chromosome labels\n    # ind = range(1, 23)[0::2]\n    # if skip19:\n    #     ind = [x for x in ind if x != 19]\n    ind = [x for x in chrom_labels if x in range(1, 23)]\n    ax.set_xticks(left[ind] + (right[ind] - left[ind]) / 2)\n    ax.set_xticklabels(ind, fontsize=font_size)\n    ax.set_ylabel('$-\\log_{10} p$ value', fontsize=font_size)\n    for t in ax.get_xticklabels() + ax.get_yticklabels():\n        t.set_fontsize(font_size)\n    if label_column is not None and legend:\n        for cat in categories:\n            ax.scatter(\n                -100, \n                -100, \n                s=marker_size, \n                color=colors[cat],\n                label=cat,\n            )\n        if legend:\n            ax.legend(\n                fontsize=font_size- 1, \n                framealpha=0.5, \n                frameon=True, \n                facecolor='white',\n            )\n    # TODO: eventually, it would be better to be smarter about the x-axis\n    # limits. Depending on the size of the markers and plot, some of the markers\n    # might be cut off.\n    ax.set_xlim(-5, total_length + 5)\n    # TODO: eventually, it would be better to be smarter about the y-axis\n    # limits. Depending on the size of the markers and plot, some of the markers\n    # might be cut off. Matplotlib doesn't know anything about the size of the\n    # markers, so it might set the y-limit too low.\n    ax.set_ylim(-1 * np.log10(p_filter), ymax)\n    if label_column is None:\n        colors = None\n    return(res, ax, colors)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_variance_explained(self, cumulative=False, xtick_start=1,\n                                xtick_spacing=1, num_pc=None):\n        \"\"\" \n        Plot amount of variance explained by each principal component.\n    \n        Parameters\n        ----------\n        num_pc : int\n            Number of principal components to plot. If None, plot all.\n    \n        cumulative : bool\n            If True, include cumulative variance.\n    \n        xtick_start : int\n            The first principal component to label on the x-axis.\n    \n        xtick_spacing : int\n            The spacing between labels on the x-axis.\n    \n        \"\"\"\n        import matplotlib.pyplot as plt \n        from numpy import arange\n        if num_pc:\n            s_norm = self.s_norm[0:num_pc]\n        else:\n            s_norm = self.s_norm\n        if cumulative:\n            s_cumsum = s_norm.cumsum()\n            plt.bar(range(s_cumsum.shape[0]), s_cumsum.values,\n                    label='Cumulative', color=(0.17254901960784313,\n                                               0.6274509803921569,\n                                               0.17254901960784313))\n            plt.bar(range(s_norm.shape[0]), s_norm.values, label='Per PC',\n                    color=(0.12156862745098039, 0.4666666666666667,\n                           0.7058823529411765))\n            plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n            plt.ylabel('Variance')\n        else:\n            plt.bar(range(s_norm.shape[0]), s_norm.values,\n                    color=(0.12156862745098039, 0.4666666666666667,\n                           0.7058823529411765))\n            plt.ylabel('Proportion variance explained')\n        plt.xlabel('PC')\n        plt.xlim(0, s_norm.shape[0])\n        tick_locs = arange(xtick_start - 1, s_norm.shape[0],\n                              step=xtick_spacing)\n        # 0.8 is the width of the bars.\n        tick_locs = tick_locs + 0.4 \n        plt.xticks(tick_locs, \n                   arange(xtick_start, s_norm.shape[0] + 1, xtick_spacing))", "response": "Plots the amount of variance explained by each principal component."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes a scatter plot of two principal components.", "response": "def plot_pc_scatter(self, pc1, pc2, v=True, subset=None, ax=None,\n                        color=None, s=None, marker=None, color_name=None,\n                        s_name=None, marker_name=None):\n        \"\"\"\n        Make a scatter plot of two principal components. You can create\n        differently colored, sized, or marked scatter points.\n\n        Parameters\n        ----------\n        pc1 : str\n            String of form PCX where X is the number of the principal component\n            you want to plot on the x-axis.\n        \n        pc2 : str\n            String of form PCX where X is the number of the principal component\n            you want to plot on the y-axis.\n\n        v : bool\n            If True, use the v matrix for plotting the principal components\n            (typical if input data was genes as rows and samples as columns).\n            If False, use the u matrix.\n\n        subset : list\n            Make the scatter plot using only a subset of the rows of u or v.\n\n        ax : matplotlib.axes\n            Plot the scatter plot on this axis.\n\n        color : pandas.Series\n            Pandas series containing a categorical variable to color the scatter\n            points. Currently limited to 10 distinct values (colors).\n\n        s : pandas.Series\n            Pandas series containing a categorical variable to size the scatter\n            points. Currently limited to 7 distinct values (sizes).\n\n        marker : pandas.Series\n            Pandas series containing a categorical variable to choose the marker\n            type for the scatter points. Currently limited to 21 distinct values\n            (marker styles).\n\n        color_name : str\n            Name for the color legend if a categorical variable for color is\n            provided.\n\n        s_name : str\n            Name for the size legend if a categorical variable for size is\n            provided.\n\n        marker_name : str\n            Name for the marker legend if a categorical variable for marker type\n            is provided.\n\n        Returns\n        -------\n        ax : matplotlib.axes._subplots.AxesSubplot\n            Scatter plot axis.\n\n        TODO: Add ability to label points. \n        \"\"\"\n        import matplotlib.pyplot as plt\n        if v:\n            df = self.v\n        else:\n            df = self.u\n        if color is not None:\n            colormap = pd.Series(dict(zip(set(color.values),\n                                          tableau20[0:2 * len(set(color)):2])))\n            color = pd.Series([colormap[x] for x in color.values],\n                              index=color.index)\n            color_legend = True\n            if not color_name:\n                color_name = color.index.name\n        else:\n            color = pd.Series([tableau20[0]] * df.shape[0], index=df.index)\n            color_legend = False\n        if s is not None:\n            smap = pd.Series(dict(zip(\n                set(s.values), range(30, 351)[0::50][0:len(set(s)) + 1])))\n            s = pd.Series([smap[x] for x in s.values],\n                          index=s.index)\n            s_legend = True\n            if not s_name:\n                s_name = s.index.name\n        else:\n            s = pd.Series(30, index=df.index)\n            s_legend = False\n        markers = ['o', '*', 's', 'v', '+', 'x', 'd', \n                   'p', '2', '<', '|', '>', '_', 'h', \n                   '1', '2', '3', '4', '8', '^', 'D']\n        if marker is not None:\n            markermap = pd.Series(dict(zip(set(marker.values), markers)))\n            marker = pd.Series([markermap[x] for x in marker.values],\n                               index=marker.index)\n            marker_legend = True\n            if not marker_name:\n                marker_name = marker.index.name\n        else:\n            marker = pd.Series('o', index=df.index)\n            marker_legend = False\n        if ax is None:\n            fig, ax = plt.subplots(1, 1)\n        for m in set(marker.values):\n            mse = marker[marker == m]\n            cse = color[mse.index]\n            sse = s[mse.index]\n            ax.scatter(df.ix[mse.index, pc1], df.ix[mse.index, pc2],\n                       s=sse.values, color=list(cse.values), marker=m, \n                       alpha=0.8)\n        \n        ax.set_title('{} vs. {}'.format(pc1, pc2))\n        ax.set_xlabel(pc1)\n        ax.set_ylabel(pc2)\n    \n        if color_legend:\n            legend_rects = make_color_legend_rects(colormap)\n            for r in legend_rects:\n                ax.add_patch(r)\n            lgd = ax.legend(legend_rects.values, labels=legend_rects.index, \n                             title=color_name,\n                             loc='upper left',\n                             bbox_to_anchor=(1, 1))\n        \n        if s_legend:\n            if lgd:\n                lgd = ax.add_artist(lgd)\n            xa, xb = ax.get_xlim()\n            ya, yb = ax.get_ylim()\n            for i in smap.index:\n                ax.scatter([xb + 1], [yb + 1], marker='o', \n                           s=smap[i], color='black', label=i)\n            lgd = ax.legend(title=s_name, loc='center left', \n                            bbox_to_anchor=(1, 0.5))\n            ax.set_xlim(xa, xb)\n            ax.set_ylim(ya, yb)\n            \n        if marker_legend:\n            if lgd:\n                lgd = ax.add_artist(lgd)\n            xa, xb = ax.get_xlim()\n            ya, yb = ax.get_ylim()\n            for i in markermap.index:\n                t = ax.scatter([xb + 1], [yb + 1], marker=markermap[i], \n                               s=sse.min(), color='black', label=i)\n                \n            handles, labels = ax.get_legend_handles_labels()\n            if s_legend:\n                handles = handles[len(smap):]\n                labels = labels[len(smap):]\n            lgd = ax.legend(handles, labels, title=marker_name, \n                            loc='lower left', bbox_to_anchor=(1, 0))\n            ax.set_xlim(xa, xb)\n            ax.set_ylim(ya, yb)\n        # fig.tight_layout()\n        return fig, ax"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pc_correlation(self, covariates, num_pc=5):\n        from scipy.stats import spearmanr\n        if (covariates.shape[0] == self.u.shape[0] and \n            len(set(covariates.index) & set(self.u.index)) == self.u.shape[0]):\n            mat = self.u\n        elif (covariates.shape[0] == self.v.shape[0] and \n            len(set(covariates.index) & set(self.v.index)) == self.v.shape[0]):\n            mat = self.v\n        else:\n            import sys\n            sys.stderr.write('Covariates differ in size from input data.\\n')\n            sys.exit(1)\n        corr = pd.Panel(items=['rho', 'pvalue'],\n                        major_axis=covariates.columns,\n                        minor_axis=mat.columns[0:num_pc])\n        for i in corr.major_axis:\n            for j in corr.minor_axis:\n                rho, p = spearmanr(covariates[i], mat[j])\n                corr.ix['rho', i, j] = rho\n                corr.ix['pvalue', i, j] = p\n        return corr", "response": "Calculates the correlation between the first num_pc prinicipal components\n        and known covariates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pc_anova(self, covariates, num_pc=5):\n        from scipy.stats import f_oneway\n        if (covariates.shape[0] == self.u.shape[0] and \n            len(set(covariates.index) & set(self.u.index)) == self.u.shape[0]):\n            mat = self.u\n        elif (covariates.shape[0] == self.v.shape[0] and \n            len(set(covariates.index) & set(self.v.index)) == self.v.shape[0]):\n            mat = self.v\n        anova = pd.Panel(items=['fvalue', 'pvalue'],\n                         major_axis=covariates.columns,\n                         minor_axis=mat.columns[0:num_pc])\n        for i in anova.major_axis:\n            for j in anova.minor_axis:\n                t = [mat[j][covariates[i] == x] for x in set(covariates[i])]\n                f, p = f_oneway(*t)\n                anova.ix['fvalue', i, j] = f \n                anova.ix['pvalue', i, j] = p \n        return anova", "response": "Calculates one - way ANOVA between the first num_pc prinicipal components\n        and known covariates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking whether this parser can parse the text", "response": "def can_handle(self, text: str) -> bool:\n        \"\"\"Check whether this parser can parse the text\"\"\"\n        try:\n            changelogs = self.split_changelogs(text)\n            if not changelogs:\n                return False\n            for changelog in changelogs:\n                _header, _changes = self.split_changelog(changelog)\n                if not any((_header, _changes)):\n                    return False\n                header = self.parse_header(_header)\n                changes = self.parse_changes(_changes)\n\n                if not any((header, changes)):\n                    return False\n        except Exception:\n            return False\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a powerup to the given empowered object.", "response": "def remember(empowered, powerupClass, interface):\n    \"\"\"\n    Adds a powerup to ``empowered`` that will instantiate ``powerupClass``\n    with the empowered's store when adapted to the given interface.\n\n    :param empowered: The Empowered (Store or Item) to be powered up.\n    :type empowered: ``axiom.item.Empowered``\n    :param powerupClass: The class that will be powered up to.\n    :type powerupClass: class\n    :param interface: The interface of the powerup.\n    :type interface: ``zope.interface.Interface``\n    :returns: ``None``\n    \"\"\"\n    className = fullyQualifiedName(powerupClass)\n    powerup = _StoredByName(store=empowered.store, className=className)\n    empowered.powerUp(powerup, interface)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef forget(empowered, powerupClass, interface):\n    className = fullyQualifiedName(powerupClass)\n    withThisName = _StoredByName.className == className\n    items = empowered.store.query(_StoredByName, withThisName)\n\n    if items.count() == 0:\n        template = \"No named powerups for {} (interface: {})\".format\n        raise ValueError(template(powerupClass, interface))\n\n    for stored in items:\n        empowered.powerDown(stored, interface)\n        stored.deleteFromStore()", "response": "Forgets powerups previously stored with remember."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing event loop for cell.", "response": "def init_event_loop(self):\n        \"\"\" Every cell should have its own event loop for proper containment.\n        The type of event loop is not so important however. \"\"\"\n        self.loop = asyncio.new_event_loop()\n        self.loop.set_debug(self.debug)\n        if hasattr(self.loop, '_set_coroutine_wrapper'):\n            self.loop._set_coroutine_wrapper(self.debug)\n        elif self.debug:\n            warnings.warn(\"Cannot set debug on loop: %s\" % self.loop)\n        self.loop_policy = IOCellEventLoopPolicy(self.loop)\n        if not hasattr(self.loop, '_exception_handler'):\n            warnings.warn(\"Cannot save exception handler for: %s\" % self.loop)\n            self.loop_exception_handler_save = None\n        else:\n            self.loop_exception_handler_save = self.loop._exception_handler\n        self.loop.set_exception_handler(self.loop_exception_handler)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_tier(self, coro, **kwargs):\n        self.assertNotFinalized()\n        assert asyncio.iscoroutinefunction(coro)\n        tier = self.Tier(self, coro, **kwargs)\n        self.tiers.append(tier)\n        self.tiers_coro_map[coro] = tier\n        return tier", "response": "Add a coroutine function to the cell as a task tier."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef append_tier(self, coro, **kwargs):\n        source = self.tiers[-1] if self.tiers else None\n        return self.add_tier(coro, source=source, **kwargs)", "response": "Add a new tier to the tail tier."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tier(self, *args, append=True, source=None, **kwargs):\n        if len(args) == 1 and not kwargs and callable(args[0]):\n            raise TypeError('Uncalled decorator syntax is invalid')\n\n        def decorator(coro):\n            if not asyncio.iscoroutinefunction(coro):\n                coro = asyncio.coroutine(coro)\n            if append and source is None:\n                self.append_tier(coro, *args, **kwargs)\n            else:\n                self.add_tier(coro, *args, source=source, **kwargs)\n            return coro\n        return decorator", "response": "Decorator for a tier coroutine function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cleaner(self, coro):\n        if not asyncio.iscoroutinefunction(coro):\n            coro = asyncio.coroutine(coro)\n        self.add_cleaner(coro)\n        return coro", "response": "Function decorator for a cleanup coroutine."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the list of run s that are not already done.", "response": "def finalize(self):\n        \"\"\" Look at our tiers and setup the final data flow.  Once this is run\n        a cell can not be modified again. \"\"\"\n        self.assertNotFinalized()\n        starters = []\n        finishers = []\n        for x in self.tiers:\n            if not x.sources:\n                starters.append(x)\n            if not x.dests:\n                finishers.append(x)\n        self.add_tier(self.output_feed, source=finishers)\n        self.coord.setup_wrap(self)\n        self.finalized = True\n        return starters"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nproducing a classic generator for this cell s final results.", "response": "def output(self):\n        \"\"\" Produce a classic generator for this cell's final results. \"\"\"\n        starters = self.finalize()\n        try:\n            yield from self._output(starters)\n        finally:\n            self.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef event_loop(self):\n        if hasattr(self.loop, '._run_once'):\n            self.loop._thread_id = threading.get_ident()\n            try:\n                self.loop._run_once()\n            finally:\n                self.loop._thread_id = None\n        else:\n            self.loop.call_soon(self.loop.stop)\n            self.loop.run_forever()", "response": "Run the event loop forever."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns all of the cleaners added by the user.", "response": "def clean(self):\n        \"\"\" Run all of the cleaners added by the user. \"\"\"\n        if self.cleaners:\n            yield from asyncio.wait([x() for x in self.cleaners],\n                                    loop=self.loop)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts field_name to field_key.", "response": "def convert_keys(self, pydict):\n        \"\"\"Convert field_name to field_key.\n               \n        {\"field_name\": value} => {\"field_key\": value}\n        \"\"\"\n        new_dict = dict()\n        for key, value in pydict.items():\n            new_dict[self.get_field_key(key)] = value\n        return new_dict"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert naive get response data to human readable field name format.", "response": "def get_html_values(self, pydict, recovery_name=True):\n        \"\"\"Convert naive get response data to human readable field name format.\n        \n        using html data format.\n        \"\"\"\n        new_dict = {\"id\": pydict[\"id\"]}\n        for field in self:\n            if field.key in pydict:\n                if recovery_name:\n                    new_dict[field.name] = pydict[field.key]\n                else:\n                    new_dict[field.key] = pydict[field.key]\n        return new_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts naive get response data to human readable field name format.", "response": "def get_raw_values(self, pydict, recovery_name=True):\n        \"\"\"Convert naive get response data to human readable field name format.\n        \n        using raw data format.\n        \"\"\"\n        new_dict = {\"id\": pydict[\"id\"]}\n        for field in self:\n            raw_key = \"%s_raw\" % field.key\n            if raw_key in pydict:\n                if recovery_name:\n                    new_dict[field.name] = pydict[raw_key]\n                else:\n                    new_dict[field.key] = pydict[raw_key]\n        return new_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_values(self, pydict):\n        new_dict = dict()\n        for key, value in pydict.items():\n            try: # is it's BaseDataType Instance\n                new_dict[key] = value._data\n            except AttributeError:\n                new_dict[key] = value\n        return new_dict", "response": "Convert knackhq data type instance to json friendly data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninserts one record. Ref: http://helpdesk.knackhq.com/support/solutions/articles/5000446111-api-reference-root-access#create For more information of the raw structure of all data type, read this: http://helpdesk.knackhq.com/support/solutions/articles/5000446405-field-types :param data: dict type data :param using_name: if you are using field_name in data, please set using_name = True (it's the default), otherwise, False **\u4e2d\u6587\u6587\u6863** \u63d2\u5165\u4e00\u6761\u8bb0\u5f55", "response": "def insert_one(self, data, using_name=True):\n        \"\"\"Insert one record.\n        \n        Ref: http://helpdesk.knackhq.com/support/solutions/articles/5000446111-api-reference-root-access#create\n        \n        For more information of the raw structure of all data type, read this:\n        http://helpdesk.knackhq.com/support/solutions/articles/5000446405-field-types\n        \n        :param data: dict type data\n        :param using_name: if you are using field_name in data,\n          please set using_name = True (it's the default), otherwise, False\n        \n        **\u4e2d\u6587\u6587\u6863**\n        \n        \u63d2\u5165\u4e00\u6761\u8bb0\u5f55\n        \"\"\"\n        data = self.convert_values(data)\n        if using_name:\n            data = self.convert_keys(data)\n        res = self.post(self.post_url, data)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insert(self, data, using_name=True):\n        if isinstance(data, list): # if iterable, insert one by one\n            for d in data:\n                self.insert_one(d, using_name=using_name)\n        else: # not iterable, execute insert_one\n            self.insert_one(data, using_name=using_name)", "response": "Insert one or many records."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_one(self, id_, raw=True, recovery_name=True):\n            \n        url = \"https://api.knackhq.com/v1/objects/%s/records/%s\" % (\n            self.key, id_)\n        res = self.get(url)\n        \n        if raw:\n            try:\n                res = self.get_raw_values(res, recovery_name=recovery_name)\n            except:\n                pass\n        else:\n            try:\n                res = self.get_html_values(res, recovery_name=recovery_name)\n            except:\n                pass\n        return res", "response": "Find one record.\n        \n        Ref: http://helpdesk.knackhq.com/support/solutions/articles/5000446111-api-reference-root-access#retrieve\n        \n        :param id_: record id_\n        :param using_name: if you are using field name in filter and sort_field, \n          please set using_name = True (it's the default), otherwise, False\n        :param raw: Default True, set True if you want the data in raw format. \n          Otherwise, html format\n        :param recovery_name: Default True, set True if you want field name \n          instead of field key\n          \n        **\u4e2d\u6587\u6587\u6863**\n        \n        \u8fd4\u56de\u4e00\u6761\u8bb0\u5f55"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting a find query.", "response": "def find(self, filter=list(), \n             sort_field=None, sort_order=None, \n             page=None, rows_per_page=None,\n             using_name=True, data_only=True, raw=True, recovery_name=True):\n        \"\"\"Execute a find query.\n        \n        Ref: http://helpdesk.knackhq.com/support/solutions/articles/5000446111-api-reference-root-access#retrieve\n        \n        :param filter: list of criterions. For more information: \n          http://helpdesk.knackhq.com/support/solutions/articles/5000447623-api-reference-filters-search\n        :param sort_field: field_name or field_id, taking field_name by default.\n          if using field_id, please set using_name = False.\n        :param sort_order: -1 or 1, 1 means ascending, -1 means descending\n        :param page and rows_per_page: skip first #page * #rows_per_page, \n          returns #rows_per_page of records. For more information:\n          http://helpdesk.knackhq.com/support/solutions/articles/5000444173-working-with-the-api#pagination\n        :param using_name: if you are using field_name in filter and sort_field, \n          please set using_name = True (it's the default), otherwise, False\n        :param data_only: set True you only need the data or the full api\n          response\n        :param raw: Default True, set True if you want the data in raw format. \n          Otherwise, html format\n        :param recovery_name: Default True, set True if you want field name\n          instead of field key\n        \n        **\u4e2d\u6587\u6587\u6863**\n        \n        \u8fd4\u56de\u591a\u6761\u8bb0\u5f55\n        \"\"\"\n        if using_name:            \n            for criterion in filter:\n                criterion[\"field\"] = self.get_field_key(criterion[\"field\"])\n            \n            if sort_field:\n                sort_field = self.get_field_key(sort_field)\n            \n        if sort_order is None:\n            pass\n        elif sort_order == 1:\n            sort_order = \"asc\"\n        elif sort_order == -1:\n            sort_order = \"desc\"\n        else:\n            raise ValueError\n        \n        params = dict()\n        if len(filter) >= 1:\n            params[\"filters\"] = json.dumps(filter)\n        \n        if sort_field:\n            params[\"sort_field\"] = sort_field\n            params[\"sort_order\"] = sort_order\n        \n        if (page is not None) \\\n            and (rows_per_page is not None) \\\n            and isinstance(page, int) \\\n            and isinstance(rows_per_page, int) \\\n            and (page >= 1) \\\n            and (rows_per_page >= 1):\n            params[\"page\"] = page\n            params[\"rows_per_page\"] = rows_per_page\n            \n        res = self.get(self.get_url, params)\n        \n        # handle data_only and recovery\n        if data_only:\n            try:\n                res = res[\"records\"]\n                if raw:\n                    res = [self.get_raw_values(data, recovery_name) for data in res]\n                else:\n                    res = [self.get_html_values(data, recovery_name) for data in res]\n            except KeyError:\n                pass\n        else:\n            if raw:\n                try:\n                    res[\"records\"] = [\n                        self.get_raw_values(data, recovery_name) for data in res[\"records\"]]\n                except KeyError:\n                    pass\n            else:\n                try:\n                    res[\"records\"] = [\n                        self.get_html_values(data, recovery_name) for data in res[\"records\"]]\n                except KeyError:\n                    pass\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_one(self, id_, data, using_name=True):\n        data = self.convert_values(data)\n        if using_name:\n            data = self.convert_keys(data)\n        url = \"https://api.knackhq.com/v1/objects/%s/records/%s\" % (\n            self.key, id_)\n        res = self.put(url, data)\n         \n        return res", "response": "Update one record. Any fields you don't specify will remain unchanged.\n        \n        Ref: http://helpdesk.knackhq.com/support/solutions/articles/5000446111-api-reference-root-access#update\n        \n        :param id_: record id_\n        :param data: the new data fields and values\n        :param using_name: if you are using field name in data,\n          please set using_name = True (it's the default), otherwise, False\n          \n        **\u4e2d\u6587\u6587\u6863**\n        \n        \u5bf9\u4e00\u6761\u8bb0\u5f55\u8fdb\u884c\u66f4\u65b0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting one record. Ref: http://helpdesk.knackhq.com/support/solutions/articles/5000446111-api-reference-root-access#delete :param id_: record id_ **\u4e2d\u6587\u6587\u6863** \u5220\u9664\u4e00\u6761\u8bb0\u5f55", "response": "def delete_one(self, id_):\n        \"\"\"Delete one record.\n        \n        Ref: http://helpdesk.knackhq.com/support/solutions/articles/5000446111-api-reference-root-access#delete\n        \n        :param id_: record id_\n          \n        **\u4e2d\u6587\u6587\u6863**\n        \n        \u5220\u9664\u4e00\u6761\u8bb0\u5f55\n        \"\"\"        \n        url = \"https://api.knackhq.com/v1/objects/%s/records/%s\" % (\n            self.key, id_)\n        res = self.delete(url)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting all records in the table or collection of this object.", "response": "def delete_all(self): \n        \"\"\"Delete all record in the table/collection of this object.\n        \n        **\u4e2d\u6587\u6587\u6863**\n        \n        \u5220\u9664\u8868\u4e2d\u7684\u6240\u6709\u8bb0\u5f55\n        \"\"\"\n        for record in self.find(using_name=False, data_only=True):\n            res = self.delete_one(record[\"id\"])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, url, params=dict()):\n        try:\n            res = requests.get(url, headers=self.headers, params=params)\n            return json.loads(res.text)\n        except Exception as e:\n            print(e)\n            return \"error\"", "response": "Http get method wrapper to support search.\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, url):\n        try:\n            res = requests.delete(url, headers=self.headers)\n            return json.loads(res.text)\n        except Exception as e:\n            print(e)\n            return \"error\"", "response": "Http delete method wrapper to support delete."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_collection(self, key, using_name=True):\n        object_ = self.application.get_object(key, using_name=using_name)\n        collection = Collection.from_dict(object_.__dict__)\n        for http_cmd in [\"get\", \"post\", \"put\", \"delete\"]:\n            collection.__setattr__(http_cmd, self.auth.__getattribute__(http_cmd))\n        return collection", "response": "Get a collection by object key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncombine eXpress output files into one single eXpress output file.", "response": "def combine_express_output(fnL,\n                           column='eff_counts',\n                           names=None,\n                           tg=None,\n                           define_sample_name=None,\n                           debug=False):\n    \"\"\"\n    Combine eXpress output files\n\n    Parameters:\n    -----------\n\n    fnL : list of strs of filenames\n        List of paths to results.xprs files.\n\n    column : string\n        Column name of eXpress output to combine.\n\n    names : list of strings\n        Names to use for columns of output files. Overrides define_sample_name \n        if provided.\n\n    tg : string\n        File with transcript-to-gene mapping. Transcripts should be in first\n        column and genes in second column. \n\n    define_sample_name : function that takes string as input\n        Function mapping filename to sample name (or basename). For instance,\n        you may have the basename in the path and use a regex to extract it.\n        The basenames will be used as the column names. If this is not provided,\n        the columns will be named as the input files.\n\n    debug : boolean\n        Passing True will trigger any debugging statements.\n\n    \"\"\"\n    if names is not None:\n        assert len(names) == len(fnL)\n    if define_sample_name is None:\n        define_sample_name = lambda x: x\n    \n    transcriptL = []\n    for i,fn in enumerate(fnL):\n        if names is not None:\n            bn = names[i]\n        else:\n            bn = define_sample_name(fn)\n        tDF = pd.read_table(fn, index_col=1, header=0)\n        se = tDF[column]\n        se.name = bn\n        transcriptL.append(se)\n    transcriptDF = pd.DataFrame(transcriptL).T\n    transcriptDF.index.name = 'transcript'\n    # There should not be any missing values.\n    if transcriptDF.shape != transcriptDF.dropna().shape:\n        sys.stderr.write('''Missing values in eXpress output. Check that the\n                         same reference was used for all output files.\\n''')\n        sys.exit(1)\n\n    if tg is not None:\n        tgDF = pd.read_table(tg,\n                             index_col=0,\n                             header=None,\n                             names=['gene_id'])\n        import copy\n        geneDF = copy.deepcopy(transcriptDF)\n        geneDF['gene'] = tgDF.ix[geneDF.index]\n        geneDF = geneDF.groupby('gene').sum()\n        return transcriptDF, geneDF\n    else:\n        return transcriptDF, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(text, path):\n    with open(path, \"wb\") as f:\n        f.write(text.encode(\"utf-8\"))", "response": "Write text to file with utf - 8 encoding."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimplements default delay mechanism.", "response": "def _delay(self, ms):\n        \"\"\"Implement default delay mechanism.\n        \"\"\"\n        if ms:\n            self.Delay(ms)\n        else:\n            if self.default_delay:\n                self.Delay(self.default_delay)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nenter some text. :param text: the text you want to enter.", "response": "def SayString(self, text, delay=0):\n        \"\"\"Enter some text.\n        \n        :param text: the text you want to enter.\n        \"\"\"\n        self._delay(delay)\n        cmd = Command(\"SayString\", 'SayString \"%s\"' % text)\n        self.add(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npressing key for n times. :param key: :param n: press key for n times", "response": "def KeyPress(self, key, n=1, delay=0):\n        \"\"\"Press key for n times.\n        \n        :param key:\n        :param n: press key for n times\n        \"\"\"\n        self._delay(delay)\n        cmd = Command(\"KeyPress\", 'KeyPress \"%s\", %s' % (key, n))\n        self.add(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef AltTab(self, n=1, delay=0):\n        self._delay(delay)\n        self.add(Command(\"KeyDown\", 'KeyDown \"%s\", %s' % (BoardKey.Alt, 1)))\n        for i in range(n):\n            self.add(Command(\"KeyPress\", 'KeyPress \"%s\", %s' % (BoardKey.Tab, 1)))\n        self.add(Command(\"KeyUp\", 'KeyUp \"%s\", %s' % (BoardKey.Alt, 1)))", "response": "Press n times Tab then press n times Alt then release Alt."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Ctrl_C(self, delay=0):\n        self._delay(delay)\n        self.add(Command(\"KeyDown\", 'KeyDown \"%s\", %s' % (BoardKey.Ctrl, 1)))\n        self.add(Command(\"KeyPress\", 'KeyPress \"%s\", %s' % (BoardKey.C, 1)))\n        self.add(Command(\"KeyUp\", 'KeyUp \"%s\", %s' % (BoardKey.Ctrl, 1)))", "response": "Ctrl + C shortcut."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Ctrl_V(self, delay=0):\n        self._delay(delay)\n        self.add(Command(\"KeyDown\", 'KeyDown \"%s\", %s' % (BoardKey.Ctrl, 1)))\n        self.add(Command(\"KeyPress\", 'KeyPress \"%s\", %s' % (BoardKey.V, 1)))\n        self.add(Command(\"KeyUp\", 'KeyUp \"%s\", %s' % (BoardKey.Ctrl, 1)))", "response": "Ctrl + V shortcut."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Ctrl_W(self, delay=0):\n        self._delay(delay)\n        self.add(Command(\"KeyDown\", 'KeyDown \"%s\", %s' % (BoardKey.Ctrl, 1)))\n        self.add(Command(\"KeyPress\", 'KeyPress \"%s\", %s' % (BoardKey.W, 1)))\n        self.add(Command(\"KeyUp\", 'KeyUp \"%s\", %s' % (BoardKey.Ctrl, 1)))", "response": "Ctrl + W shortcut."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef subat(orig, index, replace):\n    return \"\".join([(orig[x] if x != index else replace) for x in range(len(orig))])", "response": "Substitutes the replacement string at the given index in the\n    given string returns the modified string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a random string of the given length.", "response": "def randomize(length=6, choices=None):\n    \"\"\"Returns a random string of the given length.\"\"\"\n    if type(choices) == str:\n        choices = list(choices)\n    choices = choices or ascii_lowercase\n    return \"\".join(choice(choices) for _ in range(length))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the score of multiple records for a given node.", "response": "def calc_scores_for_node(G, node, depth_limit=22,\n                         number_of_recommendations=None, impact_mode=10):\n    \"\"\"Calculate the score of multiple records.\"\"\"\n    n, w, dep, _ = dfs_edges(G, node, depth_limit, \"Record\")\n    count_total_ways = len(n)\n    # print \"Number of paths {}\".format(len(n))\n    if impact_mode == 0:\n        impact_div = 12\n    elif impact_mode == 1:\n        impact_div = 1000\n    elif impact_mode == 2:\n        impact_div = 100\n    elif impact_mode == 10:\n        impact_div = count_total_ways\n    elif impact_mode == 11:\n        impact_div = count_total_ways/2\n\n    d_ = {'Nodes': n, 'Scores': w, 'Depth': dep}\n    d = pd.DataFrame(data=d_)\n    del n, w, dep, d_\n    n, w, dep = None, None, None\n    gc.collect()\n\n    nodes = array('I')\n    weight_high = array('f')\n    weight_new = array('f')\n    ways = array('I')\n    nodes_with_weight = d.groupby('Nodes')\n\n    del d\n    gc.collect()\n    # print \"Number nodes {}\".format(len(nodes_with_weight))\n    for node, end_nodes in nodes_with_weight:\n        nodes.append(node)\n        new_score, highest_score, number_of_paths = \\\n            calc_weight_of_multiple_paths(end_nodes, impact_div)\n        weight_high.append(highest_score)\n        weight_new.append(new_score)\n        ways.append(number_of_paths)\n\n    new_weights_d = {'Node': nodes, 'Score_Highest': weight_high,\n                     'Score': weight_new, 'Paths': ways}\n    new_weights = pd.DataFrame(data=new_weights_d)\n    del new_weights_d, nodes, weight_high, weight_new, ways\n    gc.collect()\n    # Numpy sort by score\n    new_weights = new_weights.sort_values(by='Score', ascending=False)\n    new_weights = new_weights[:number_of_recommendations]\n\n    return new_weights"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calc_weight_of_multiple_paths(path_scores, impact_div=12):\n    number_of_paths = len(path_scores)\n    if number_of_paths > 1:\n        score_total = 0.0\n        highest_score = 0.0\n        for score in path_scores.Scores:\n            score_total += score\n            if highest_score < score:\n                highest_score = score\n\n        score_mean = score_total / number_of_paths\n        # print \"score_total: {}\".format(score_total)\n        # print \"score_mean: {}\".format(score_mean)\n        # print \"number_of_paths: {}\".format(number_of_paths)\n\n        # Calculate the weight depending on how many ways are found\n        weight_count_impact = number_of_paths / float(number_of_paths +\n                                                      impact_div)\n        # print \"weight_count_impact: {}\".format(weight_count_impact)\n\n        new_score = highest_score + ((1 + weight_count_impact) * score_mean)\n        # print \"new_score: {}\".format(new_score)\n\n        return new_score, highest_score, number_of_paths\n\n    else:\n        return (path_scores.Scores.iloc[0], path_scores.Scores.iloc[0],\n                number_of_paths)", "response": "Caluculate the weight of multiple paths."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate recommendations for a record.", "response": "def recommend_for_record(self, record_id, depth=4, num_reco=10):\n        \"\"\"Calculate recommendations for record.\"\"\"\n        data = calc_scores_for_node(self._graph, record_id, depth, num_reco)\n        return data.Node.tolist(), data.Score.tolist()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload user profiles from file.", "response": "def load_profile(self, profile_name):\n        \"\"\"Load user profiles from file.\"\"\"\n        data = self.storage.get_user_profiles(profile_name)\n\n        for x in data.get_user_views():\n            self._graph.add_edge(int(x[0]), int(x[1]), {'weight': float(x[2])})\n            self.all_records[int(x[1])] += 1\n\n        return self._graph"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting big nodes with many connections from the graph.", "response": "def del_big_nodes(self, grater_than=215):\n        \"\"\"Delete big nodes with many connections from the graph.\"\"\"\n        G = self._graph\n        it = G.nodes_iter()\n        node_paths = []\n        node_names = []\n        del_nodes = []\n        summe = 1\n        count = 1\n        for node in it:\n            l = len(G[node])\n            if l > grater_than:\n                del_nodes.append(node)\n                continue\n            summe += l\n            node_names.append(node)\n            node_paths.append(l)\n            count += 1\n        for node in del_nodes:\n            G.remove_node(node)\n            if node > 1000000000:\n                self.valid_user.pop(node)\n\n        print(\"Nodes deleted: {}\".format(len(del_nodes)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef punify_filename(filename):\n    path, extension = splitext(filename)\n    return path.encode('punycode').decode('utf8') + extension", "response": "small hackisch workaround for unicode problems with picflash api\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nuploading a file to the NCBI.", "response": "def upload(apikey, picture, resize=None, rotation='00', noexif=False,\n           callback=None):\n    \"\"\"\n    prepares post for regular upload\n\n    :param str apikey: Apikey needed for Autentication on picflash.\n    :param str/tuple/list picture: Path to picture as str or picture data. \\\n        If data a tuple or list with the file name as str \\\n        and data as byte object in that order.\n    :param str resize: Aresolution in the folowing format: \\\n        '80x80'(optional)\n    :param str|degree rotation: The picture will be rotated by this Value. \\\n        Allowed values are 00, 90, 180, 270.(optional)\n    :param boolean noexif: set to True when exif data should be purged.\\\n        (optional)\n    :param function callback: function witch will be called after every read. \\\n        Need to take one argument. you can use the len function to determine \\\n        the body length and call bytes_read().\n    \"\"\"\n\n    if isinstance(picture, str):\n        with open(picture, 'rb') as file_obj:\n            picture_name = picture\n            data = file_obj.read()\n    elif isinstance(picture, (tuple, list)):\n        picture_name = picture[0]\n        data = picture[1]\n    else:\n        raise TypeError(\"The second argument must be str or list/tuple. \"\n                        \"Please refer to the documentation for details.\")\n\n\n    check_rotation(rotation)\n    check_resize(resize)\n    check_callback(callback)\n\n    post_data = compose_post(apikey, resize, rotation, noexif)\n\n    post_data['Datei[]'] = (punify_filename(basename(picture_name)), data)\n\n    return do_upload(post_data, callback)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nuploading a picture to the NCBI server.", "response": "def remote_upload(apikey, picture_url, resize=None,\n                  rotation='00', noexif=False):\n    \"\"\"\n    prepares post for remote upload\n\n    :param str apikey: Apikey needed for Autentication on picflash.\n    :param str picture_url: URL to picture allowd Protocols are: ftp,\n        http, https\n    :param str resize: Aresolution in the folowing format: \\\n        '80x80'(optional)\n    :param str|degree rotation: The picture will be rotated by this Value. \\\n        Allowed values are 00, 90, 180, 270.(optional)\n    :param boolean noexif: set to True when exif data should be purged.\\\n        (optional)\n\n    \"\"\"\n    check_rotation(rotation)\n    check_resize(resize)\n    url = check_if_redirect(picture_url)\n    if url:\n        picture_url = resolve_redirect(url)\n\n    post_data = compose_post(apikey, resize, rotation, noexif)\n    post_data['url[]'] = ('', picture_url)\n\n    return do_upload(post_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compose_post(apikey, resize, rotation, noexif):\n    check_rotation(rotation)\n    check_resize(resize)\n\n    post_data = {\n            'formatliste': ('', 'og'),\n            'userdrehung': ('', rotation),\n            'apikey': ('', apikey)\n            }\n\n    if resize and 'x' in resize:\n        width, height = [ x.strip() for x in resize.split('x')]\n        post_data['udefb'] = ('', width)\n        post_data['udefh'] = ('', height)\n    elif resize and '%' in resize:\n        precentage = resize.strip().strip('%')\n        post_data['udefp'] = precentage\n\n    if noexif:\n        post_data['noexif'] = ('', '')\n\n    return post_data", "response": "compose basic post requests"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_upload(post_data, callback=None):\n\n    encoder = MultipartEncoder(post_data)\n    monitor = MultipartEncoderMonitor(encoder, callback)\n\n    headers = {'User-Agent': USER_AGENT, 'Content-Type': monitor.content_type}\n    response = post(API_URL, data=monitor, headers=headers)\n    check_response(response)\n\n    return response.json()[0]", "response": "Do the actual upload"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping upload function :param str/tuple/list picture: Path to picture as str or picture data. \\ If data a tuple or list with the file name as str \\ and data as byte object in that order. :param str resize: Aresolution in the folowing format: \\ '80x80'(optional) :param str|degree rotation: The picture will be rotated by this Value.\\ Allowed values are 00, 90, 180, 270.(optional) :param boolean noexif: set to True when exif data should be purged.\\ (optional) :param function callback: function will be called after every read. \\ Need to take one argument. you can use the len function to \\ determine the body length and call bytes_read().", "response": "def upload(self, picture, resize=None, rotation=None, noexif=None,\n               callback=None):\n        \"\"\"\n        wraps upload function\n\n        :param str/tuple/list picture: Path to picture as str or picture data. \\\n            If data a tuple or list with the file name as str \\\n            and data as byte object in that order.\n        :param str resize: Aresolution in the folowing format: \\\n            '80x80'(optional)\n        :param str|degree rotation: The picture will be rotated by this Value.\\\n            Allowed values are 00, 90, 180, 270.(optional)\n        :param boolean noexif: set to True when exif data should be purged.\\\n            (optional)\n        :param function callback: function will be called after every read. \\\n            Need to take one argument. you can use the len function to \\\n            determine the body length and call bytes_read().\n\n        \"\"\"\n        if not resize:\n            resize = self._resize\n        if not rotation:\n            rotation = self._rotation\n        if not noexif:\n            noexif = self._noexif\n        if not callback:\n            callback = self._callback\n\n        return upload(self._apikey, picture, resize,\n                      rotation, noexif, callback)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remote_upload(self, picture_url, resize=None,\n                      rotation=None, noexif=None):\n        \"\"\"\n        wraps remote_upload funktion\n\n        :param str picture_url: URL to picture allowd Protocols are: ftp,\\\n            http, https\n        :param str resize: Aresolution in the folowing format: \\\n            '80x80'(optional)\n        :param str|degree rotation: The picture will be rotated by this Value. \\\n            Allowed values are 00, 90, 180, 270.(optional)\n        :param boolean noexif: set to True when exif data should be purged.\\\n            (optional)\n\n        \"\"\"\n        if not resize:\n            resize = self._resize\n        if not rotation:\n            rotation = self._rotation\n        if not noexif:\n            noexif = self._noexif\n\n        return remote_upload(self._apikey, picture_url,\n                             resize, rotation, noexif)", "response": "wraps remote_upload method to set the necessary parameters for the remote_upload function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_identity(config = Config()):\n    return Identity(name = config.get('user', 'name'),\n                    email_ = config.get('user', 'email'),\n                    **config.get_section('smtp'))", "response": "Load the default identity from the configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the full name email address and SMTP information from the user.", "response": "def input_identity(interface = TerminalInterface()):\n    \"\"\"Get the full name, email address and SMTP information from the user.\"\"\"\n\n    while True:\n        identity = interface.input_fields(\"\"\"\n           In order to send your files via email, I need to get your name and\n           email address you will be using to send the files.\"\"\",\n           ( 'name', 'Your full name', 'string' ),\n           ( 'email', 'Your email address', 'string' ))\n\n        try:\n            (localpart, hostname) = identity['email'].split('@')\n            break\n        except ValueError:\n            interface.error(\"\"\"\n                I couldn't understand the email address you entered, please try\n                again.\"\"\")\n\n    while True:\n        # Configure the SMTP information\n        smtp_details = interface.input_fields(\"\"\"\n            I need details of the SMTP server used to send email for your email\n            address '%s'. These values can be obtained from the administrators of\n            your email account.\n            \n            Most of the time, the default options should suffice if you are\n            using a free email provider such as GMail.\"\"\" % identity['email'],\n            ( 'host', 'The SMTP server hostname', 'string', 'smtp.' + hostname),\n            ( 'port', 'The SMTP server port', 'integer', 465),\n            ( 'use_ssl', 'Use SSL to connect', 'boolean', True),\n            ( 'use_tls', 'Use TLS after connecting', 'boolean', False),\n            ( 'use_auth', 'Use a username/password to log in', 'boolean', True)\n            )\n\n        if smtp_details['use_auth']:\n            credentials = interface.input_fields(\"\"\"\n                I need the username and password you use to log into the SMTP\n                server, if you provide a blank password, I'll assume you want me to\n                ask you each time I try to send an email for your password. This is\n                a more secure option but may be tiresome.\"\"\",\n                ( 'username', 'Your username', 'string', localpart),\n                ( 'password', 'Your password', 'password' ))\n            if credentials['password'] == '':\n                credentials['password'] = None\n\n            smtp_details['username'] = credentials['username']\n            smtp_details['password'] = credentials['password']\n\n        new_identity = Identity(identity['name'], identity['email'], **smtp_details)\n\n        # Ask if we want to send a test email.\n        interface.new_section() \n        interface.message(\"\"\"I can try sending a test email to yourself with\n        all the SMTP settings you've given me. This is generally a good idea\n        because if we correct any mistakes now, you don't need to correct them\n        when you want to send a file.\"\"\")\n        if interface.input_boolean('Try sending a test email?', default=True):\n            if new_identity.send_test_email():\n                return new_identity\n\n            interface.message(\"\"\"Sending the test email failed. You can go back\n            and try re-entering your SMTP server details now if you wish.\"\"\")\n            if not interface.input_boolean('Re-enter SMTP server details', default=True):\n                return new_identity"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending an email to one or more recipients.", "response": "def sendmail(self, to, message):\n        \"\"\"Send mail to one or more recipients. The required arguments are a\n        list of RFC 822 to-address strings (a bare string will be treated as a\n        list with 1 address), and a message string.\n\n        \"\"\"\n\n        # If we were passed a bare string as the To: address, convert it to\n        # a single element list.\n        if isinstance(to, str):\n            to = [ to, ]\n\n        # Send one email with the appropriate recipient list.\n        server = self._smtp_server()\n        server.sendmail(self.get_rfc2822_address(), to, message)\n        server.quit()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _smtp_server(self):\n\n        if self._use_ssl:\n            server = smtplib.SMTP_SSL(**self._smtp_vars)\n        else:\n            server = smtplib.SMTP(**self._smtp_vars)\n\n        if self._use_tls:\n            server.starttls()\n\n        if self._credentials is not None:\n            passwd = self._credentials[1]\n            if passwd is None:\n                passwd = self._interface.input( \\\n                    'Password for %s' % (self._credentials[0],), no_echo=True)\n            server.login(*self._credentials)\n\n            # if we succeeded, cache the password\n            self._credentials = (self._credentials[0], passwd)\n\n        return server", "response": "Return a smtplib SMTP object correctly initialised and connected to\n            a SMTP server suitable for sending email on behalf of the user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding clients to the ATVS Keystroke database.", "response": "def add_clients(session, verbose):\n  \"\"\"Add clients to the ATVS Keystroke database.\"\"\"\n  for ctype in ['Genuine', 'Impostor']:\n    for cdid in userid_clients:\n      cid = ctype + '_%d' % cdid\n      if verbose>1: print(\"  Adding user '%s' of type '%s'...\" % (cid, ctype))\n      session.add(Client(cid, ctype, cdid))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_files(session, imagedir, verbose):\n\n  def add_file(session, basename, userid, shotid, sessionid):\n    \"\"\"Parse a single filename and add it to the list.\"\"\"\n    session.add(File(userid, basename, sessionid, shotid))\n\n  filenames = os.listdir(imagedir)\n  for filename in filenames:\n    basename, extension = os.path.splitext(filename)\n    if extension == db_file_extension:\n      if verbose>1: print(\"  Adding file '%s'...\" % (basename))\n      parts = string.split(basename, \"_\")\n      ctype = parts[0]\n      shotid = int(parts[2])\n      userid = ctype + '_%d' % int(parts[1])\n      if parts[0] == \"Impostor\":\n        sessionid = 3\n      elif parts[0] == \"Genuine\" and shotid <= 6:\n        sessionid = 1\n      elif parts[0] == \"Genuine\" and shotid > 6:\n        sessionid = 2\n        shotid = shotid - 6\n      add_file(session, basename, userid, shotid, sessionid)", "response": "Add files to the ATVS Keystroke database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_protocols(session, verbose):\n\n  # 1. DEFINITIONS\n  enroll_session = [1]\n  client_probe_session = [2]\n  impostor_probe_session = [3]\n  protocols = ['A']\n\n  # 2. ADDITIONS TO THE SQL DATABASE\n  protocolPurpose_list = [('eval', 'enrol'), ('eval', 'probe')]\n  for proto in protocols:\n    p = Protocol(proto)\n    # Add protocol\n    if verbose: print(\"Adding protocol %s...\" % (proto))\n    session.add(p)\n    session.flush()\n    session.refresh(p)\n\n    # Add protocol purposes\n    for key in range(len(protocolPurpose_list)):\n      purpose = protocolPurpose_list[key]\n      print p.id, purpose[0], purpose[1]\n      pu = ProtocolPurpose(p.id, purpose[0], purpose[1])\n      if verbose>1: print(\"  Adding protocol purpose ('%s','%s')...\" % (purpose[0], purpose[1]))\n      session.add(pu)\n      session.flush()\n      session.refresh(pu)\n\n      # Add files attached with this protocol purpose\n      if(key == 0): #test enrol\n        q = session.query(File).join(Client).filter(Client.stype == 'Genuine').filter(File.session_id.in_(enroll_session))\n        for k in q:\n          if verbose>1: print(\"    Adding protocol file '%s'...\" % (k.path))\n          pu.files.append(k)\n\n      elif(key == 1): #test probe\n        q = session.query(File).join(Client).filter(Client.stype == 'Genuine').filter(File.session_id.in_(client_probe_session))\n        for k in q:\n          if verbose>1: print(\"    Adding protocol file '%s'...\" % (k.path))\n          pu.files.append(k)\n        q = session.query(File).join(Client).filter(Client.stype == 'Impostor').filter(File.session_id.in_(impostor_probe_session))\n        for k in q:\n          if verbose>1: print(\"    Adding protocol file '%s'...\" % (k.path))\n          pu.files.append(k)", "response": "Adds protocols to the SQL database."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates all necessary tables", "response": "def create_tables(args):\n  \"\"\"Creates all necessary tables (only to be used at the first time)\"\"\"\n\n  from bob.db.utils import create_engine_try_nolock\n  engine = create_engine_try_nolock(args.type, args.files[0], echo=(args.verbose > 2))\n  Base.metadata.create_all(engine)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(args):\n\n  from bob.db.utils import session_try_nolock\n\n  dbfile = args.files[0]\n\n  if args.recreate:\n    if args.verbose and os.path.exists(dbfile):\n      print('unlinking %s...' % dbfile)\n    if os.path.exists(dbfile): os.unlink(dbfile)\n\n  if not os.path.exists(os.path.dirname(dbfile)):\n    os.makedirs(os.path.dirname(dbfile))\n\n  # the real work...\n  create_tables(args)\n  s = session_try_nolock(args.type, dbfile, echo=(args.verbose > 2))\n  add_clients(s, args.verbose)\n  add_files(s, args.imagedir, args.verbose)\n  add_protocols(s, args.verbose)\n  s.commit()\n  s.close()", "response": "Creates or re - creates this database"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding specific subcommands that the action create can use", "response": "def add_command(subparsers):\n  \"\"\"Add specific subcommands that the action \"create\" can use\"\"\"\n\n  parser = subparsers.add_parser('create', help=create.__doc__)\n\n  parser.add_argument('-R', '--recreate', action='store_true', help=\"If set, I'll first erase the current database\")\n  parser.add_argument('-v', '--verbose', action='count', help=\"Do SQL operations in a verbose way?\")\n  parser.add_argument('-D', '--imagedir', metavar='DIR', default='/home/bob/BTAS_Keystroke_files_SingleFile', help=\"Change the relative path to the directory containing the images of the ATVS Keystroke database.\")\n\n  parser.set_defaults(func=create)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning a method as your __main__ via decorator. Example:: @shrew.cli.entrypoint def main(cli): ... Shorthand for:: def main(): cli = shrew.cli.CLI() ... if __name__ == '__main__': method()", "response": "def entrypoint(method, depth=1, cls=None):\n    \"\"\"\n      Run a method as your __main__ via decorator.\n\n      Example::\n\n        @shrew.cli.entrypoint\n        def main(cli):\n          ...\n\n      Shorthand for::\n\n        def main():\n\n          cli = shrew.cli.CLI()\n\n          ...\n\n        if __name__ == '__main__':\n          method()\n    \"\"\"\n\n    current_frame = inspect.currentframe(depth).f_locals\n\n    if '__name__' in current_frame and current_frame['__name__'] == '__main__':\n\n        if cls is None:\n            cls = CLI\n\n        method(cls())\n\n    return method"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_config_option(self, default=None):\n\n        self.argparser.add_argument('--config', default=default, help='Config file to read. Defaults to: %(default)s')\n        self.should_parse_config = True", "response": "Add a -- config option to the argument parser."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding username and password options", "response": "def add_username_password(self, use_store=False):\n        \"\"\" Add --username and --password options\n          :param bool use_store: Name of the section (concept, command line options, API reference)\n        \"\"\"\n        self.argparser.add_argument('--username', default=None, help='Username')\n        self.argparser.add_argument('--password', default=None, help='Password')\n        self.argparser.add_argument('--clear-store', action='store_true', default=False, help='Clear password keystore')\n\n        self.use_username_password_store = use_store"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a documentation link to the list of links to be added to the list of links", "response": "def _add_documentation_link(self, links, section, variable_name, default=None):\n        \"\"\"\n          :param list links: List of links to append link of the form \"Section: <link>\", if link available\n          :param str section: Name of the section (concept, command line options, API reference)\n          :param str variable_name: Variable name in main module that should hold URL to documentation\n          :param str default: Default URL to documentation\n        \"\"\"\n\n        url = getattr(sys.modules['__main__'], variable_name, default)\n\n        if url:\n            links.append('%s: %s' % (section, url))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __parse_args(self, accept_unrecognized_args=False):\n\n        # If the user provided a description, use it. Otherwise grab the doc string.\n        if self.description:\n            self.argparser.description = self.description\n        elif getattr(sys.modules['__main__'], '__doc__', None):\n            self.argparser.description = getattr(sys.modules['__main__'], '__doc__')\n        else:\n            self.argparser.description = 'No documentation defined. Please add a doc string to %s' % sys.modules['__main__'].__file__\n\n        self.argparser.epilog = self.epilog\n\n        # Only if there aren't any other command line arguments.\n        if len(sys.argv) == 1 and self.argument_defaults:\n            self.argparser.set_defaults(**self.argument_defaults)\n\n        if accept_unrecognized_args:\n            self.args, self.unrecognized_args = self.argparser.parse_known_args()\n        else:\n            self.args = self.argparser.parse_args()", "response": "Invoke the argument parser."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninvoke the config file parser.", "response": "def __parse_config(self):\n        \"\"\" Invoke the config file parser. \"\"\"\n\n        if self.should_parse_config and (self.args.config or self.config_file):\n            self.config = ConfigParser.SafeConfigParser()\n            self.config.read(self.args.config or self.config_file)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __process_username_password(self):\n\n        if self.use_username_password_store is not None:\n            if self.args.clear_store:\n                with load_config(sections=AUTH_SECTIONS) as config:\n                    config.remove_option(AUTH_SECTION, 'username')\n            if not self.args.username:\n                self.args.username = get_username(use_store=self.use_username_password_store)\n\n            if self.args.clear_store:\n                remove_password(AUTH_SECTION, username=self.args.username)\n            if not self.args.password:\n                self.args.password = get_password(AUTH_SECTION, username=self.args.username)\n                if self.use_username_password_store:\n                    save_password(AUTH_SECTION, self.args.password, self.args.username)", "response": "Process the username and password"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __finish_initializing(self):\n\n        if self.args.debug or self.args.trace:\n            # Set the console (StreamHandler) to allow debug statements.\n\n            if self.args.debug:\n                self.console.setLevel(logging.DEBUG)\n\n            self.console.setFormatter(logging.Formatter('[%(levelname)s] %(asctime)s %(name)s - %(message)s'))\n\n            # Set the global level to debug.\n            if self.args.debug:\n                self.log.setLevel(logging.DEBUG)\n\n        if self.args.log or self.log_file:\n\n            # Allow the user to override the default log file handler.\n            try:\n                self.log_file_handler = sys.modules['__main__'].log_file_handler(self.args.log or self.log_file)\n            except Exception:\n                self.log_file_handler = logging.FileHandler(self.args.log or self.log_file)\n\n            self.log_file_handler.setFormatter(logging.Formatter('[%(levelname)s] %(asctime)s %(name)s - %(message)s'))\n            self.log_file_handler.setLevel(logging.DEBUG)\n\n            self.log.addHandler(self.log_file_handler)\n\n        # Allow cli.log, args & self to be accessed from __main__\n        if not hasattr(sys.modules['__main__'], 'log'):\n            sys.modules['__main__'].log = self.log\n\n        if not hasattr(sys.modules['__main__'], 'cli'):\n            sys.modules['__main__'].cli = self\n\n        if not hasattr(sys.modules['__main__'], 'args'):\n            sys.modules['__main__'].args = self.args", "response": "Handles any initialization after arguments & config has been parsed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self, accept_unrecognized_args=False):\n\n        self.__parse_args(accept_unrecognized_args)\n        self.__parse_config()\n        self.__process_username_password()\n        self.__finish_initializing()\n\n        exit_status = 0\n\n        try:\n            yield self\n        except ExitedCleanly:\n            pass\n        except (Exception, KeyboardInterrupt) as e:\n            # Run any method a library or caller might have registered.\n            for base in type(e).mro():\n                if base in self.exceptions:\n                    self.exceptions[base](e)\n                    break\n            else:\n                self.log.exception(e)\n\n            exit_status = os.EX_SOFTWARE\n        finally:\n            logging.shutdown()\n\n        sys.exit(exit_status)", "response": "A context manager that runs the context manager."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _make_request(self, suburl):\n        url = \"{}/{}\".format(self.API_BASE_URL, suburl)\n        response = self.session.get(url)\n        response.raise_for_status()\n        return response.json()", "response": "Helper function for making requests to the base url of the ndata store."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a dictionary or object with relevant info about the given item number.", "response": "def get_item(self, item_number, raw=False):\n        \"\"\"\n        Get a dictionary or object with info about the given item number from the Hacker News API.\n        Item can be a poll, story, comment or possibly other entry.\n        Will raise an requests.HTTPError if we got a non-200 response back. Will raise a ValueError\n        if a item_number that can not be converted to int was passed in, or the server has no\n        information for that item number.\n\n        (Possible) response parameters:\n            \"id\"        ->  The item's unique id. Required.\n            \"deleted\"   ->\ttrue if the item is deleted.\n            \"type\"      ->\tThe type of item. One of \"job\", \"story\", \"comment\", \"poll\", or \"pollopt\".\n            \"by\"        ->\tThe username of the item's author.\n            \"time\"      ->\tCreation date of the item, in Unix Time.\n            \"text\"      ->\tThe comment, Ask HN, or poll text. HTML.\n            \"dead\"      ->\ttrue if the item is dead.\n            \"parent\"    ->\tThe item's parent. For comments, either another comment or the relevant story.\n                            For pollopts, the relevant poll.\n            \"kids\"      ->\tThe ids of the item's comments, in ranked display order.\n            \"url\"       ->\tThe URL of the story.\n            \"score\"     ->\tThe story's score, or the votes for a pollopt.\n            \"title\"     ->\tThe title of the story or poll.\n            \"parts\"     ->\tA list of related pollopts, in display order.\n\n        :param item_number: an integer number for the HN item requested\n        :param raw: (optional): If true, return the raw decoded JSON dict, if False, return a nice object\n                    with keywords as attributes. Default if False.\n        :return: A dictionary with relevant info about the item, if successful.\n        \"\"\"\n        if not isinstance(item_number, int):\n            item_number = int(item_number)\n        suburl = \"v0/item/{}.json\".format(item_number)\n        try:\n            item_data = self._make_request(suburl)\n        except requests.HTTPError as e:\n            hn_logger.exception('Faulted on item request for item {}, with status {}'.format(item_number, e.errno))\n            raise e\n        if not item_data:\n            raise ValueError('Item id {} not found!'.format(item_number))\n        return item_data if raw else HackerNewsItem(**item_data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_user(self, user_name, raw=False):\n        suburl = \"v0/user/{}.json\".format(user_name)\n        try:\n            user_data = self._make_request(suburl)\n        except requests.HTTPError as e:\n            hn_logger.exception('Faulted on item request for user {}, with status {}'.format(user_name, e.errno))\n            raise e\n        if not user_data:\n            raise ValueError('User name {} not found, or no data!'.format(user_name))\n        return user_data if raw else HackerNewsUpdates(**user_data)", "response": "Get a dictionary or object with relevant info about a user."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_top_stories(self):\n        suburl = \"v0/topstories.json\"\n        try:\n            top_stories = self._make_request(suburl)\n        except requests.HTTPError as e:\n            hn_logger.exception('Faulted on getting top stories, with status {}'.format(e.errno))\n            raise e\n        return top_stories", "response": "Get the item numbers for the current top stories. Will raise an error if we got a non - 200 response back."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the current maximum item number.", "response": "def get_max_item(self):\n        \"\"\"\n        Get the current maximum item number\n        :return: The current maximum item number.\n        \"\"\"\n        suburl = \"v0/maxitem.json\"\n        try:\n            max_item = self._make_request(suburl)\n        except requests.HTTPError as e:\n            hn_logger.exception('Faulted on get max item, with status {}'.format(e.errno))\n            raise e\n        return max_item"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the most recently updated updates on Hacker News.", "response": "def get_recent_updates(self, raw=True):\n        \"\"\"\n        Get the most recent updates on Hacker News\n\n        Response dictionary parameters:\n            \"items\"     ->  A list of the most recently update items by item number.\n            \"profiles\"  ->  A list of most recently updated user profiles by user name.\n\n        :param raw: (optional): If true, return the raw dictionary, if False, return a nice object with attrs for\n                    keywords. Default is True.\n        :return: A dictionary with relevant info about recent updates.\n        \"\"\"\n        suburl = \"v0/updates.json\"\n        try:\n            updates_data = self._make_request(suburl)\n        except requests.HTTPError as e:\n            hn_logger.exception('Faulted on get max item, with status {}'.format(e.errno))\n            raise e\n        return updates_data if raw else HackerNewsUpdates(**updates_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_first_regex_match(key, regex_candidates):\n    for cand in regex_candidates:\n        try:\n            pattern = re.compile(cap_match_string(cand))\n            if pattern.match(key):\n                return cand\n        except:\n            logging.warn('[ros_interface] Ignoring invalid regex string \"{0!s}\"!'.format(cand))\n\n    return None", "response": "find the first regex that matches with the key"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfilter the match_candidates list to return only the candidate that match the regex", "response": "def regex_match_sublist(regex, match_candidates):\n    \"\"\"\n    Filter the match_candidates list to return only the candidate that match the regex\n    :param regex: a regex used to filter the list of candidates\n    :param match_candidates: the list of candidates\n    :return: the filtered list of only the candidates that match the regex\n    \"\"\"\n    matches = []\n    try:\n        pattern = re.compile(cap_match_string(regex))\n        matches = [cand for cand in match_candidates if pattern.match(cand)]\n    except:\n        logging.warn('[ros_interface] Ignoring invalid regex string \"{0!s}\"!'.format(regex))\n    return matches"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfiltering the match_candidates list to return only the candidates that match the regex", "response": "def regexes_match_sublist(regexes, match_candidates):\n    \"\"\"\n    Filter the match_candidates list to return only the candidate that match the regex\n    :param regexes: a list of regex used to filter the list of candidates\n    :param match_candidates: the list of candidates\n    :return: the filtered list of only the candidates that match the regex\n    \"\"\"\n\n    return [match for sublist in [regex_match_sublist(rgx, match_candidates) for rgx in regexes] for match in sublist]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate an EC2 Server", "response": "def create_server():\n    \"\"\"Creates an EC2 Server\"\"\"\n\n    try:\n        import boto\n    except ImportError:\n        sys.exit(\"boto library required for creating servers with Amazon.\")\n\n    print(green(\"Creating EC2 server\"))\n\n    conn = boto.connect_ec2(\n        get_or_prompt('ec2_key', 'API Key'),\n        get_or_prompt('ec2_secret', 'API Secret'))\n    \n    reservation = conn.run_instances(\n        get_or_prompt(\n            'ec2_ami', 'AMI ID', 'ami-fd589594'),\n        instance_type=get_or_prompt(\n            'ec2_instancetype', 'Instance Type', 't1.micro'),\n        key_name=get_or_prompt(\n            'ec2_keypair', 'Key Pair'),\n        security_groups=get_or_prompt_list(\n            'ec2_secgroups', 'Security Groups'))\n    \n    instance = reservation.instances[0]\n    \n    time.sleep(3)\n\n    tag = get_or_prompt('ec2_tag', 'Instance Tag (blank for none)', '').strip()\n\n    if len(tag) > 0:\n        conn.create_tags([instance.id], {\"Name\": tag})\n    \n    while instance.state != u'running':\n        print(yellow(\"Instance state: %s\" % instance.state))\n        time.sleep(10)\n        instance.update()\n\n    print(green(\"Instance state: %s\" % instance.state))\n    print(green(\"Public dns: %s\" % instance.public_dns_name))\n    print(green(\"Waiting 30 seconds for server to boot\"))\n    \n    time.sleep(30)\n\n    return instance.public_dns_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns formatted strings of time stamps for HTML requests.", "response": "def return_time_elements(time_stamp):\n    \"\"\"Returns formatted strings of time stamps for HTML requests.\n\n    :parameters time_range: pandas.tslib.Timestamp\n    \"\"\"\n    yyyy = str(time_stamp.year)\n    mm = \"%02d\" % (time_stamp.month,)\n    dd = \"%02d\" % (time_stamp.day,)\n    hr = \"%02d\" % (time_stamp.hour,)\n    mins = \"%02d\" % (time_stamp.minute,)\n    return yyyy, mm, dd, hr, mins"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_data(start, end, username=None, password=None,\n             data_path=os.path.abspath(\".\")+'/tmp_data'):\n    \"\"\"**Download data (badly) from Blitzorg**\n\n    Using a specified time stamp for start and end, data is downloaded at a\n    default frequency (10 minute intervals). If a directory called data is not\n    present, it will be added to the cwd as the target for the downloads.\n    This is probably a bad idea however. It is much better to 1) get the data\n    from Blitzorg directly, or 2) if you only want a small part of the data\n    and have an account, download a csv file via their web interface.\n\n    :paramter start: string\n    :parameter end: string\n    :parameter freq: string\n\n    :Example:\n\n    >>> get_data(start=\"2015-02-01T06:30\", end=\"2015-02-01T10:05\")\n    \"\"\"\n    dl_link = \"http://data.blitzortung.org/Data_1/Protected/Strokes/\"\n    if not os.path.exists(data_path):\n        os.makedirs(data_path)\n    if not username:\n        username = input(\"Username to access Blitzorg with:\")\n        password = getpass.getpass(\n            prompt='Enter password for {0}:'.format(username))\n    auth_handler = urllib.request.HTTPBasicAuthHandler()\n    auth_handler.add_password(realm='Blitzortung',\n                              uri='http://data.blitzortung.org',\n                              user=username,\n                              passwd=password)\n    opener = urllib.request.build_opener(auth_handler)\n    urllib.request.install_opener(opener)\n    time_range = pd.date_range(start, end, freq='10min')\n    for time_stamp in tqdm(time_range):\n        tmp_link = dl_link+'/'.join(return_time_elements(time_stamp))\\\n                   + '.json.gz'\n        tmp_name = \"./tmp_data/bz-\"+'-'.join(return_time_elements(time_stamp))\\\n                   + \".json.gz\"\n        if os.path.isfile(tmp_name):\n            print(\"{0} exists. Aborting download attempt\".format(tmp_name))\n        else:\n            try:\n                urllib.request.urlretrieve(tmp_link, tmp_name)\n            except Exception as inst:\n                print(inst)\n                print('  Encountered unknown error. Continuing.')", "response": "Download data from Blitzorg using a specified time stamp for start and end."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef blitz_parser():\n    with gzip.open('tmp_data/bz-2015-02-01-06-30.json.gz', 'rb') as f:\n        file_content = f.read()\n    tx = file_content.strip()\n    k = tx.decode(encoding='utf-8')\n    print(\"{0} elements in k list\".format(len(k.split())))\n    j = json.loads(k.split()[0])  # example of decoding an element to json\n    return", "response": "The start of a blitzorg data parser."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread settings from configuration file", "response": "def fromConfigFile(filename = DEFAULT_CONFIG_FILE):\n    \"\"\" Read settings from configuration file\"\"\"\n    parser = SafeConfigParser()\n    section = 'fenixedu'\n    parser.read(filename)\n\n    client_id = parser.get(section, 'client_id')\n    redirect_uri = parser.get(section, 'redirect_uri')\n    client_secret = parser.get(section, 'client_secret')\n\n    base_url = parser.get(section, 'base_url')\n    api_endpoint = parser.get(section, 'api_endpoint')\n    api_version = parser.get(section, 'api_version')\n\n    return FenixEduConfiguration(client_id = client_id,\n                                  redirect_uri = redirect_uri,\n                                  client_secret = client_secret,\n                                  base_url = base_url,\n                                  api_endpoint = api_endpoint,\n                                  api_version = api_version)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmaps func against all the subcommands attached to our root ArcGIS command.", "response": "def map_subcommands(self, func):\n        \"\"\" Run `func` against all the subcommands attached to our root\n        command. \"\"\"\n\n        def crawl(cmd):\n            for sc in cmd.subcommands.values():\n                yield from crawl(sc)\n            yield cmd\n        return map(func, crawl(self.root_command))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes a command and return the result.", "response": "def execute(self, command, args):\n        \"\"\" Event firing and exception conversion around command execution.\n        Common exceptions are run through our exception handler for\n        pretty-printing or debugging and then converted to SystemExit so the\n        interpretor will exit without further ado (or be caught if\n        interactive). \"\"\"\n        self.fire_event('precmd', command, args)\n        try:\n            try:\n                result = command.run_wrap(args)\n            except BaseException as e:\n                self.fire_event('postcmd', command, args, exc=e)\n                raise e\n            else:\n                self.fire_event('postcmd', command, args, result=result)\n                return result\n        except BrokenPipeError as e:\n            _vprinterr('<dim><red>...broken pipe...</red></dim>')\n            raise SystemExit(1) from e\n        except KeyboardInterrupt as e:\n            _vprinterr('<dim><red>...interrupted...</red></dim>')\n            raise SystemExit(1) from e\n        except SystemExit as e:\n            if e.args and not isinstance(e.args[0], int):\n                _vprinterr(\"<red>%s</red>\" % e)\n                raise SystemExit(1) from e\n            raise e\n        except Exception as e:\n            self.handle_command_error(command, args, e)\n            raise SystemExit(1) from e"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_command_error(self, command, args, exc):\n        verbosity = self.command_error_verbosity\n        if verbosity == 'traceback':\n            self.pretty_print_exc(command, exc, show_traceback=True)\n        elif verbosity == 'debug':\n            pdb.set_trace()\n        elif verbosity == 'raise':\n            raise exc\n        elif verbosity == 'pretty':\n            self.pretty_print_exc(command, exc)\n        else:\n            raise ValueError('Unexpected exception_verbosity: %s' %\n                             verbosity)", "response": "This function is called by the exception handler when a command error occurs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cmd_split(self, line):\n        cmd, *args = line.lstrip().split(' ', 1)\n        return self.root_command.subcommands[cmd], ' '.join(args)", "response": "Get the command associated with this input line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwrapping for readline. wrap_func that handles exceptions raised by completer functions.", "response": "def complete_wrap(self, func, *args, **kwargs):\n        \"\"\" Readline eats exceptions raised by completer functions. \"\"\"\n        # Workaround readline's one-time-read of terminal width.\n        termcols = shutil.get_terminal_size()[0]\n        readline.parse_and_bind('set completion-display-width %d' % termcols)\n        try:\n            return func(*args, **kwargs)\n        except:\n            traceback.print_exc()\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setup_readline(self):\n        readline.parse_and_bind('tab: complete')\n        completer_save = readline.get_completer()\n        delims_save = readline.get_completer_delims()\n        delims = set(delims_save)\n        delims |= self.completer_delim_includes\n        delims -= self.completer_delim_excludes\n        readline.set_completer(self.completer_hook)\n        try:\n            readline.set_completer_delims(''.join(delims))\n            try:\n                yield\n            finally:\n                readline.set_completer_delims(delims_save)\n        finally:\n            readline.set_completer(completer_save)", "response": "Configure our tab completion settings for a context and then\n            restore them on exit."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_loop(self):\n        self.root_command.prog = ''\n        history_file = self.load_history()\n        rendering.vtmlprint(self.intro)\n        try:\n            self.loop()\n        finally:\n            readline.write_history_file(history_file)", "response": "Main entry point for running in interactive mode."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef loop(self):\n        while True:\n            with self.setup_readline():\n                try:\n                    line = input(self.prompt)\n                except EOFError:\n                    _vprinterr('^D')\n                    break\n                except KeyboardInterrupt:\n                    _vprinterr('^C')\n                    continue\n            if not line.strip():\n                continue\n            try:\n                cmd, args = self.cmd_split(line)\n            except KeyError as e:\n                _vprinterr('<red>Invalid command: %s</red>' % e)\n                continue\n            try:\n                cmd(argv=args)\n            except SessionExit:\n                break\n            except SystemExit as e:\n                pass", "response": "Main loop for interactive mode. Do not call directly."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef traverse(self, traverser, **kwargs):\n        lrt = self.left.traverse(traverser, **kwargs)\n        rrt = self.right.traverse(traverser, **kwargs)\n        return traverser.binary_operation_logical(self, lrt, rrt, **kwargs)", "response": "This method traverses the whole rule tree and returns the result of the binary operation_logical method."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef traverse(self, traverser, **kwargs):\n        atr = []\n        for arg in self.args:\n            atr.append(arg.traverse(traverser, **kwargs))\n        return traverser.function(self, atr, **kwargs)", "response": "This method traverses the whole rule tree and returns the result of traversing the left subtree."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nimporting a module given a dotted path in the form of. name. name.", "response": "def import_module(path):\n    \"\"\"\n    Import a module given a dotted *path* in the\n    form of ``.name(.name)*``, and returns the\n    last module (unlike ``__import__`` which just\n    returns the first module).\n\n    :param path: The dotted path to the module.\n    \"\"\"\n    mod = __import__(path, locals={}, globals={})\n    for item in path.split('.')[1:]:\n        try:\n            mod = getattr(mod, item)\n        except AttributeError:\n            raise ImportError('No module named %s' % path)\n    return mod"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate SQL select ... Returns (sql, params) >>> sqlselect('t') ('select * from t', []) >>> sqlselect('t', fields=['name', 'address']) ('select name, address from t', []) >>> sqlselect('t', where={'name': 'Toto', 'country': 'US'}) ('select * from t where country=%s and name=%s', ['US', 'Toto']) >>> sqlselect('t', orderby=['lastname', 'firstname']) ('select * from t order by lastname, firstname', []) >>> sqlselect('t', limit=1) ('select * from t limit 1', []) >>> sqlselect('t', limit='yes') Traceback (most recent call last): ... ValueError: Limit parameter must be an int >>> sqlselect('t', offset=20) ('select * from t offset 20', []) >>> sqlselect('t', offset='yes') Traceback (most recent call last): ... ValueError: Offset parameter must be an int", "response": "def sqlselect(table, fields=['*'], where=None, orderby=None, limit=None,\n              offset=None):\n    \"\"\"Generates SQL select ...\n    Returns (sql, params)\n\n    >>> sqlselect('t')\n    ('select * from t', [])\n    >>> sqlselect('t', fields=['name', 'address'])\n    ('select name, address from t', [])\n    >>> sqlselect('t', where={'name': 'Toto', 'country': 'US'})\n    ('select * from t where country=%s and name=%s', ['US', 'Toto'])\n    >>> sqlselect('t', orderby=['lastname', 'firstname'])\n    ('select * from t order by lastname, firstname', [])\n    >>> sqlselect('t', limit=1)\n    ('select * from t limit 1', [])\n    >>> sqlselect('t', limit='yes')\n    Traceback (most recent call last):\n        ...\n    ValueError: Limit parameter must be an int\n    >>> sqlselect('t', offset=20)\n    ('select * from t offset 20', [])\n    >>> sqlselect('t', offset='yes')\n    Traceback (most recent call last):\n        ...\n    ValueError: Offset parameter must be an int\n    \"\"\"\n    validate_name(table)\n    if fields != ['*']:\n        validate_names(fields)\n    fieldspart = ', '.join(fields)\n    sql = \"select {} from {}\".format(fieldspart, table)\n    values = []\n\n    if where:\n        (whereclause, wherevalues) = sqlwhere(where)\n        if whereclause:\n            sql = sql + \" where \" + whereclause\n            values = wherevalues\n\n    if orderby:\n        validate_names(orderby)\n        sql = sql + \" order by \" + ', '.join(orderby)\n\n    if limit:\n        if not isinstance(limit, int):\n            raise ValueError(\"Limit parameter must be an int\")\n        sql = sql + \" limit {}\".format(limit)\n\n    if offset:\n        if not isinstance(offset, int):\n            raise ValueError(\"Offset parameter must be an int\")\n        sql = sql + \" offset {}\".format(offset)\n\n    return (sql, values)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating SQL insert into table...", "response": "def sqlinsert(table, row):\n    \"\"\"Generates SQL insert into table ...\n    Returns (sql, parameters)\n\n    >>> sqlinsert('mytable', {'field1': 2, 'field2': 'toto'})\n    ('insert into mytable (field1, field2) values (%s, %s)', [2, 'toto'])\n    >>> sqlinsert('t2', {'id': 1, 'name': 'Toto'})\n    ('insert into t2 (id, name) values (%s, %s)', [1, 'Toto'])\n    \"\"\"\n    validate_name(table)\n    fields = sorted(row.keys())\n    validate_names(fields)\n    values = [row[field] for field in fields]\n    sql = \"insert into {} ({}) values ({})\".format(\n        table, ', '.join(fields), ', '.join(['%s'] * len(fields)))\n    return sql, values"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sqlupdate(table, rowupdate, where):\n    validate_name(table)\n    fields = sorted(rowupdate.keys())\n    validate_names(fields)\n    values = [rowupdate[field] for field in fields]\n    setparts = [field + '=%s' for field in fields]\n    setclause = ', '.join(setparts)\n    sql = \"update {} set \".format(table) + setclause\n    (whereclause, wherevalues) = sqlwhere(where)\n    if whereclause:\n        sql = sql + \" where \" + whereclause\n    return (sql, values + wherevalues)", "response": "Generates SQL update table set..."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sqldelete(table, where):\n    validate_name(table)\n    (whereclause, wherevalues) = sqlwhere(where)\n    sql = \"delete from {}\".format(table)\n    if whereclause:\n        sql += \" where \" + whereclause\n    return (sql, wherevalues)", "response": "Generates SQL delete from... where..."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate SQL where clause. Returns tuple of sql and values.", "response": "def sqlwhere(criteria=None):\n    \"\"\"Generates SQL where clause. Returns (sql, values).\n    Criteria is a dictionary of {field: value}.\n\n    >>> sqlwhere()\n    ('', [])\n    >>> sqlwhere({'id': 5})\n    ('id=%s', [5])\n    >>> sqlwhere({'id': 3, 'name': 'toto'})\n    ('id=%s and name=%s', [3, 'toto'])\n    >>> sqlwhere({'id': 3, 'name': 'toto', 'createdon': '2013-12-02'})\n    ('createdon=%s and id=%s and name=%s', ['2013-12-02', 3, 'toto'])\n    \"\"\"\n    if not criteria:\n        return ('', [])\n    fields = sorted(criteria.keys())\n    validate_names(fields)\n    values = [criteria[field] for field in fields]\n    parts = [field + '=%s' for field in fields]\n    sql = ' and '.join(parts)\n    return (sql, values)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a DB URL. Return scheme user password host dbname", "response": "def parse_dburl(dburl):\n    \"\"\"Parse DB URL. Return (scheme, user, password, host, dbname)\n    pg://user:pass@host/dbname\n\n    >>> parse_dburl(\"pg://user:pass@host/name\")\n    ('pg', 'user', 'pass', 'host', 'name')\n    >>> parse_dburl(\"dbm:///dbfile\")\n    ('dbm', '', '', '', 'dbfile')\n    >>> parse_dburl(\"pg://user:@/name\")\n    ('pg', 'user', '', '', 'name')\n    \"\"\"\n    res = urlparse.urlparse(dburl)\n\n    if '@' in res.netloc:\n        (creds, host) = res.netloc.split('@')\n    else:\n        creds = ':'\n        host = res.netloc\n\n    (user, password) = creds.split(':')\n    return (res.scheme, user, password, host, res.path[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef select(self, table, fields=['*'], where=None, orderby=None,\n               limit=None, offset=None):\n        \"\"\"\n        Query and return list of records.\n\n        >>> import getpass\n        >>> s = DB(dbname='test', user=getpass.getuser(), host='localhost',\n        ... password='')\n        >>> s.execute('drop table if exists t2')\n        >>> s.execute('create table t2 (id int, name text)')\n        >>> s.insert('t2', {'id': 1, 'name': 'Toto'})\n        >>> rows = s.select('t2')\n        >>> len(rows)\n        1\n        >>> row = rows[0]\n        >>> row\n        {'id': 1, 'name': 'Toto'}\n        \"\"\"\n        (sql, values) = sqlselect(table, fields, where, orderby, limit, offset)\n        self.execute(sql, values)\n        return self.fetchall()", "response": "Query and return list of records."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef insert(self, table, row):\n        (sql, values) = sqlinsert(table, row)\n        self.execute(sql, values)", "response": "Insert new row into table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self, table, rowupdate, where):\n        (sql, values) = sqlupdate(table, rowupdate, where)\n        return self.execute(sql, values)", "response": "Update matching records in table. rowupdate is a dict with updated fields e. g. John Tata"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute(self, sql, params=None):\n        logging.debug(sql)\n        try:\n            self._cursor.execute(sql, params)\n            if self.autocommit:\n                self._conn.commit()\n            if self._cursor.rowcount > 0:\n                return self._cursor.rowcount\n        except psycopg2.Error, error:\n            logging.debug('PG error ({}): {}'.format(\n                error.pgcode, error.pgerror))\n            self._conn.rollback()\n            raise", "response": "Execute given SQL and return number of affected rows."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cmd_line(line, ctrl):\n    server = ctrl.modules[0]\n    \"\"\" :type : StartServer \"\"\"\n    if line == \"statistic start\":\n        server.stat_gather = True\n    elif line == \"statistic stop\":\n        server.stat_gather = False\n    elif line == \"statistic reset\":\n        server.statistic_reset()\n    elif line == \"statistic\":\n        server.info(u\"Statistic: \\n{}\".format(server.statistic()))\n    return line", "response": "Handle the command line"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(host, port):\n    wrapper = WrapperServer({\n        'server': None\n    })\n    d = {\n        'listen_port': port,\n        'changer': wrapper\n    }\n    if host:\n        d['listen_bind_ip'] = host\n\n    ses = MeasureServer(d)\n    wrapper.server = ses\n    return [wrapper], cmd_line", "response": "Create a new Nagios server and return a list of modules to execute"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef one(iterable, cmp=None):\n    the_one = False\n    for i in iterable:\n        if cmp(i) if cmp else i:\n            if the_one:\n                return False\n            the_one = i\n    return the_one", "response": "Return the one object in the given iterable that evaluates to True."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prepare(self, rule):\n        if self.parser:\n            rule = self.parser.parse(rule)\n        if self.compiler:\n            rule = self.compiler.compile(rule)\n        return rule", "response": "Parse and compile given rule into rule tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef binary_operation_logical(self, rule, left, right, **kwargs):\n        return self.evaluate_binop_logical(rule.operation, left, right, **kwargs)", "response": "Evaluates the logical operation of the given rule."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef binary_operation_comparison(self, rule, left, right, **kwargs):\n        return self.evaluate_binop_comparison(rule.operation, left, right, **kwargs)", "response": "Evaluates the comparison of two binary operations."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef binary_operation_math(self, rule, left, right, **kwargs):\n        return self.evaluate_binop_math(rule.operation, left, right, **kwargs)", "response": "Evaluates the mathematical operation of the given rule."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nevaluate the unary operation of the given rule.", "response": "def unary_operation(self, rule, right, **kwargs):\n        \"\"\"\n        Implementation of :py:func:`pynspect.traversers.RuleTreeTraverser.unary_operation` interface.\n        \"\"\"\n        return self.evaluate_unop(rule.operation, right, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_main(cls, signature=''):\n        instance = cls()\n\n        def decorate(function):\n            instance.main(signature)(function)\n            return instance\n        return decorate", "response": "A class decorator that creates an instance and registers the decorated function as main function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_command(self, name, command):\n        if name in self.commands:\n            raise RuntimeError('%s is already defined' % name)\n        self.commands[name] = command", "response": "Registers the given command with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef option(self, signature, overrideable=False):\n        def decorator(function):\n            try:\n                function = annotations()(function)\n            except RuntimeError:\n                pass\n\n            option = Option.from_string(\n                signature, function, overrideable=overrideable\n            )\n            for name in option.names:\n                if name in self.options and not self.options[name].overrideable:\n                    raise RuntimeError('%s is already defined' % name)\n            self.options.update((name, option) for name in option.names)\n            return function\n        return decorator", "response": "A decorator for registering an option with the given signature."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main(self, signature=''):\n        signature = Signature.from_string(signature, option=False)\n\n        def decorator(function):\n            if self.main_func is not None:\n                raise RuntimeError('main is already defined')\n            try:\n                function = annotations()(function)\n            except RuntimeError:\n                pass\n\n            self.main_func = function\n            self.main_signature = signature\n            if function.__doc__:\n                self.description = textwrap.dedent(function.__doc__).strip()\n            return function\n        return decorator", "response": "A decorator that registers the main function with the given signature."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wordify(text):\n    stopset = set(nltk.corpus.stopwords.words('english'))\n    tokens = nltk.WordPunctTokenizer().tokenize(text)\n    return [w for w in tokens if w not in stopset]", "response": "Generate a list of words given text removing punctuation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef initialize_env(env_file=None, fail_silently=True, load_globally=True):\n    data = {}\n    data.update(os.environ)\n    if env_file:\n        data.update(read_file_values(env_file, fail_silently))\n    \n    if load_globally:\n        os.environ.update(data)\n    \n    return Environment(env_dict=data)", "response": "Initializes the environment dictionary with the values from the environment file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pretty_spaces(level):\n\n    if level is None:\n        return u''\n    return (os.linesep if level >= 0 else u'') + (u' ' * (INDENT * level))", "response": "Return spaces and new line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a mapping object to unicode string.", "response": "def unimapping(arg, level):\n    \"\"\"\n    Mapping object to unicode string.\n\n    :type arg: collections.Mapping\n    :param arg: mapping object\n    :type level: int\n    :param level: deep level\n\n    :rtype: unicode\n    :return: mapping object as unicode string\n    \"\"\"\n\n    if not isinstance(arg, collections.Mapping):\n        raise TypeError(\n            'expected collections.Mapping, {} received'.format(type(arg).__name__)\n        )\n\n    result = []\n    for i in arg.items():\n        result.append(\n            pretty_spaces(level) + u': '.join(map(functools.partial(convert, level=level), i))\n        )\n\n    string = join_strings(result, level)\n    if level is not None:\n        string += pretty_spaces(level - 1)\n\n    return u'{{{}}}'.format(string)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef uniiterable(arg, level):\n\n    if not isinstance(arg, collections.Iterable):\n        raise TypeError(\n            'expected collections.Iterable, {} received'.format(type(arg).__name__)\n        )\n\n    templates = {\n        list: u'[{}]',\n        tuple: u'({})'\n    }\n\n    result = []\n    for i in arg:\n        result.append(pretty_spaces(level) + convert(i, level=level))\n\n    string = join_strings(result, level)\n    if level is not None:\n        string += pretty_spaces(level - 1)\n\n    return templates.get(type(arg), templates[tuple]).format(string)", "response": "Converts an iterable object to unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshowing a particular meetup.", "response": "def show(ctx, city, date):\n    \"\"\"Show a particular meetup.\n\n    city: The meetup series.\n\n    \\b\n    date: The date. May be:\n        - YYYY-MM-DD or YY-MM-DD (e.g. 2015-08-27)\n        - YYYY-MM or YY-MM (e.g. 2015-08)\n        - MM (e.g. 08): the given month in the current year\n        - pN (e.g. p1): show the N-th last meetup\n        - +N (e.g. +2): show the N-th next meetup\n        - Omitted: show the next meetup (same as +1)\n    \"\"\"\n    db = ctx.obj['db']\n    today = ctx.obj['now'].date()\n    term = ctx.obj['term']\n\n    event = cliutil.get_event(db, city, date, today)\n\n    data = event.as_dict()\n    cliutil.handle_raw_output(ctx, data)\n    render_event(term, event, today, verbose=ctx.obj['verbose'])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef srem(self, name, *values):\n        return self.storage.srem(name, *self.dump(values, False))", "response": "remove the specified key from the set"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sismember(self, name, value):\n        return self.storage.sismember(name, self.dump(value))", "response": "Return a boolean indicating if value is a member of set name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_list_fields(self):\n        from trionyx.renderer import renderer\n        model_fields = {f.name: f for f in self.model.get_fields(True, True)}\n\n        def create_list_fields(config_fields, list_fields=None):\n            list_fields = list_fields if list_fields else {}\n\n            for field in config_fields:\n                config = field\n                if isinstance(field, str):\n                    config = {'field': field}\n\n                if 'field' not in config:\n                    raise Exception(\"Field config is missing field: {}\".format(config))\n                if 'label' not in config:\n                    if config['field'] in model_fields:\n                        config['label'] = model_fields[config['field']].verbose_name\n                    else:\n                        config['label'] = config['field']\n                if 'renderer' not in config:\n                    config['renderer'] = renderer.render_field\n\n                list_fields[config['field']] = config\n            return list_fields\n\n        list_fields = create_list_fields(model_fields.keys())\n\n        if self.list_fields:\n            list_fields = create_list_fields(self.list_fields, list_fields)\n\n        return list_fields", "response": "Get all list fields"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_form(self, config_name, only_required=False):\n        if getattr(self, config_name, None):\n            return import_object_by_string(getattr(self, config_name))\n\n        def use_field(field):\n            if not only_required:\n                return True\n            return field.default == NOT_PROVIDED\n\n        return modelform_factory(self.model, fields=[f.name for f in self.model.get_fields() if use_field(f)])", "response": "Get form for given config else create form"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef auto_load_configs(self):\n        for app in apps.get_app_configs():\n            for model in app.get_models():\n                config = ModelConfig(model, getattr(app, model.__name__, None))\n                self.configs[self.get_model_name(model)] = config", "response": "Auto load all configs from app configs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_config(self, model):\n        if not inspect.isclass(model):\n            model = model.__class__\n        return self.configs.get(self.get_model_name(model))", "response": "Get config for given model"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_all_configs(self, trionyx_models_only=True):\n        from trionyx.models import BaseModel\n\n        for index, config in self.configs.items():\n            if not isinstance(config.model(), BaseModel):\n                continue\n\n            yield config", "response": "Get all model configs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nput to only the first upstream.", "response": "def put(self, source, rel_path, metadata=None):\n        \"\"\"Puts to only the first upstream. This is to be symmetric with put_stream.\"\"\"\n        return self.upstreams[0].put(source, rel_path, metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list(self, path=None, with_metadata=False, include_partitions=False):\n\n        l = {}\n        for upstream in [self.alternate, self.upstream]:\n\n            for k, v in upstream.list(path, with_metadata, include_partitions).items():\n                upstreams = (l[k]['caches'] if k in l else []) + \\\n                    v.get('caches', upstream.repo_id)\n\n                l[k] = v\n                l[k]['caches'] = upstreams\n\n        return l", "response": "Combine a listing of all of the upstreams and add a metadata item for the theCOOKIE repository_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncopies the file from the upstream to the alternate and store it in the upstream", "response": "def _copy_across(self, rel_path, cb=None):\n        \"\"\"If the upstream doesn't have the file, get it from the alternate and store it in the upstream\"\"\"\n\n        from . import copy_file_or_flo\n\n        if not self.upstream.has(rel_path):\n\n            if not self.alternate.has(rel_path):\n\n                return None\n\n            source = self.alternate.get_stream(rel_path)\n\n            sink = self.upstream.put_stream(rel_path, metadata=source.meta)\n\n            try:\n                copy_file_or_flo(source, sink, cb=cb)\n            except:\n                self.upstream.remove(rel_path, propagate=True)\n                raise\n\n            source.close()\n            sink.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef input_fields(self, preamble, *args):\n\n        self.new_section()\n        if preamble is not None:\n            self.message(preamble)\n\n        if any([True for x in args if len(x) > 3]):\n            self.message(\"\"\"\n                Some questions have default answers which can be selected by\n                pressing 'Enter' at the prompt.\"\"\")\n\n        output_dict = { }\n        for field in args:\n            (field_name, prompt, field_type) = field[:3]\n\n            default = None\n            if len(field) > 3:\n                default = field[3]\n\n            if field_type == 'string':\n                output_dict[field_name] = self.input(prompt, default = default)\n            elif field_type == 'password':\n                output_dict[field_name] = self.input(prompt, no_echo=True)\n            elif field_type == 'boolean':\n                output_dict[field_name] = self.input_boolean(prompt, default = default)\n            elif field_type == 'integer':\n                output_dict[field_name] = self.input_integer(prompt, default = default)\n\n        return output_dict", "response": "Get a set of fields from the user. Optionally a preamble may be provided to the user and the fields to return. Optionally a preamble may be provided to the user and the fields to return may be shown to the user. Optionally a preamble may be provided to the user and the fields to return may be specified to the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the sigmak line.", "response": "def _parse_sigmak(line, lines):\n    \"\"\"Parse Energy, Re sigma xx, Im sigma xx, Re sigma zz, Im sigma zz\"\"\"\n\n    split_line = line.split()\n\n    energy = float(split_line[0])\n    re_sigma_xx = float(split_line[1])\n    im_sigma_xx = float(split_line[2])\n    re_sigma_zz = float(split_line[3])\n    im_sigma_zz = float(split_line[4])\n\n    return {\"energy\": energy, \"re_sigma_xx\": re_sigma_xx, \"im_sigma_xx\": im_sigma_xx, \"re_sigma_zz\": re_sigma_zz,\n            \"im_sigma_zz\": im_sigma_zz}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef require_self(func, *args, **kwargs):\n\n    try:\n        __import__(package['name'])\n    except ImportError:\n        sys.stderr.write(\n            \"This component needs to be installed first. Run \" +\n            \"`invoke install`\\n\")\n        sys.exit(1)\n    return func(*args, **kwargs)", "response": "Decorator to require that this component be installed"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_migration(initial=False):\n\n    settings = DjangoSettings()\n    if 'south' not in (name.lower() for name in settings.INSTALLED_APPS):\n        print(\"Temporarily adding 'south' into INSTALLED_APPS.\")\n        settings.INSTALLED_APPS.append('south')\n\n    kwargs = dict(initial=True) if initial else dict(auto=True)\n    run_django_cmd('schemamigration', package['name'], **kwargs)", "response": "Create a South migration for this project"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef coverage(reportdir=None, extra=None):\n\n    import coverage as coverage_api\n    cov = coverage_api.coverage()\n    opts = {'directory': reportdir} if reportdir else {}\n\n    cov.start()\n    test(extra)\n    cov.stop()\n    cov.html_report(**opts)", "response": "Test this project with coverage reports"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning manage. py using this component s specific Django settings", "response": "def managepy(cmd, extra=None):\n    \"\"\"Run manage.py using this component's specific Django settings\"\"\"\n\n    extra = extra.split() if extra else []\n    run_django_cli(['invoke', cmd] + extra)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninstalling this component or remove it if it exists.", "response": "def install(editable=True):\n    \"\"\"Install this component (or remove and reinstall)\"\"\"\n\n    try:\n        __import__(package['name'])\n    except ImportError:\n        pass\n    else:\n        run(\"pip uninstall --quiet -y %s\" % package['name'], warn=True)\n\n    cmd = \"pip install --quiet \"\n    cmd += \"-e .\" if editable else \".\"\n\n    run(cmd, warn=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving all Armstrong components from this environment", "response": "def remove_armstrong():\n    \"\"\"Remove all Armstrong components (except for Dev) from this environment\"\"\"\n\n    from pip.util import get_installed_distributions\n    pkgs = get_installed_distributions(local_only=True, include_editables=True)\n    apps = [pkg for pkg in pkgs\n            if pkg.key.startswith('armstrong') and pkg.key != 'armstrong.dev']\n\n    for app in apps:\n        run(\"pip uninstall -y %s\" % app.key)\n\n    if apps:\n        print(\n            \"Note: this hasn't removed other dependencies installed by \"\n            \"these components. There's no substitute for a fresh virtualenv.\")\n    else:\n        print(\"No Armstrong components to remove.\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_total_magnetization(line, lines):\n    toks = line.split()\n    res = {\"number of electrons\": float(toks[3])}\n    if len(toks) > 5:\n        res[\"total magnetization\"] = float(toks[5])\n    return res", "response": "Parse the total magnetization which is somewhat hidden"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main():\n    app = apikit.APIFlask(name=\"Hello\",\n                           version=\"0.0.1\",\n                           repository=\"http://example.repo\",\n                           description=\"Hello World App\")\n\n    # pylint: disable=unused-variable\n    @app.route(\"/\")\n    def hello_world():\n        \"\"\"The main route.\"\"\"\n        return \"Hello, World!\"\n\n    app.run()", "response": "Main entry point for the main function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking for deferred emails that otherwise fill up the queue.", "response": "def deferred_emails():\n    \"\"\"Checks for deferred email, that otherwise fill up the queue.\"\"\"\n    status = SERVER_STATUS['OK']\n    count = Message.objects.deferred().count()\n\n    if DEFERRED_WARNING_THRESHOLD <= count < DEFERRED_DANGER_THRESHOLD:\n        status = SERVER_STATUS['WARNING']\n    if count >= DEFERRED_DANGER_THRESHOLD:\n        status = SERVER_STATUS['DANGER']\n\n    return {\n        'label': 'Deferred Email',\n        'status': status,\n        'info': 'There are currently {0} deferred messages.'.format(count)\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking for emails that fill up the queue without getting sent.", "response": "def email_queue():\n    \"\"\"Checks for emails, that fill up the queue without getting sent.\"\"\"\n    status = SERVER_STATUS['OK']\n    count = Message.objects.exclude(priority=PRIORITY_DEFERRED).filter(\n        when_added__lte=now() - timedelta(minutes=QUEUE_TIMEOUT)).count()\n\n    if QUEUE_WARNING_THRESHOLD <= count < QUEUE_DANGER_THRESHOLD:\n        status = SERVER_STATUS['WARNING']\n    if count >= QUEUE_DANGER_THRESHOLD:\n        status = SERVER_STATUS['DANGER']\n\n    return {\n        'label': 'Queued Email',\n        'status': status,\n        'info': 'There are currently {0} messages in the mail queue.'.format(\n            count)\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef yaml_force_unicode():\n        #/\n        ## modified from |http://stackoverflow.com/a/2967461|\n        if sys.version_info[0] == 2:\n            def construct_func(self, node):\n                return self.construct_scalar(node)\n            yaml.Loader.add_constructor(U('tag:yaml.org,2002:str'), construct_func)\n            yaml.SafeLoader.add_constructor(U('tag:yaml.org,2002:str'), construct_func)", "response": "Force pyyaml to return unicode values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_locale_hints():\n        #/\n        lang, encoding = locale.getdefaultlocale()\n        ## can both be None\n        \n        #/\n        if lang and '_' in lang:\n            lang3, _, lang2 = lang.partition('_')\n        else:\n            lang3 = None\n            lang2 = None\n        \n        #/\n        ll_s = [encoding, lang, lang2, lang3]\n        ## Encoding comes before lang intentionally, e.g.\n        ##  lang |en_US| with encoding |cp936|, |cp936| takes priority.\n        \n        #/\n        ll_s_unique = []\n        \n        for ll in ll_s:\n            if ll:\n                ll = ll.lower()\n                \n                if ll not in ll_s_unique:\n                    ll_s_unique.append(ll)\n        \n        #/\n        return ll_s_unique", "response": "Get a list of locale hints guessed according to Python s default locale info."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_locale_choices(locale_dir):\n        #/\n        file_name_s = os.listdir(locale_dir)\n        \n        #/\n        choice_s = []\n        \n        for file_name in file_name_s:\n            if file_name.endswith(I18n.TT_FILE_EXT_STXT):\n                file_name_noext, _ = os.path.splitext(file_name)\n                if file_name_noext:\n                    choice_s.append(file_name_noext)\n        \n        #/\n        choice_s = sorted(choice_s)\n         \n        #/\n        return choice_s", "response": "Get a list of locale file names in the given locale dir."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_tt_dict(self, locale, tt_d):\n        \n        #/ get the old tt dict of the locale\n        tt_d_old = self.tt_dd.get(locale, None)\n        \n        #/ if has old tt dict\n        ## N\n        if tt_d_old is None:\n            #/ use the new tt dict\n            self.tt_dd[locale] = tt_d\n        ## Y\n        else:\n            #/ update the old tt dict\n            tt_d_old.update(tt_d)", "response": "Load a tt dict into |self. tt_dd|."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading a tt file into self. tt_dd.", "response": "def load_tt_file(self, locale, path_func=None, encoding=None):\n        \"\"\"\n        Load a tt file's tt dict into |self.tt_dd|.\n        |tt| means text transform.\n        \n        locale: locale key into |self.tt_dd|.\n        path_func: tt file path func\n        encoding: tt file encoding\n        \"\"\"\n        \n        #/\n        path_func = path_func or self.path_func\n        \n        encoding = encoding or self.file_encoding\n        \n        #/ get path\n        path = path_func(locale)\n        \n        #/ load dict from locale file\n        tt_file_d = yaml.load(codecs.open(path, mode='r', encoding=encoding))\n        \n        #/\n        target_locale = tt_file_d.get(I18n.TT_FILE_K_SYNONYM, None)\n        \n        #/ if the locale file is in synonym format\n        ## Y\n        if target_locale:\n            #/ load the target locale file instead\n            return self.load_tt_file(locale=target_locale, path_func=path_func, encoding=encoding)\n        ## N\n        \n        #/ get the tt dict from the file dict\n        tt_d = tt_file_d[I18n.TT_FILE_K_TT]\n        \n        #/ add to \n        self.load_tt_dict(locale=locale, tt_d=tt_d)\n        \n        #/ return the true locale\n        ## this is useful in case the original locale file is in synonym format\n        return locale"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the value of the tt key in the locale.", "response": "def tt(self, key, locale=None, locale2=None, default=I18n.DFT):\n        \"\"\"\n        |tt| means text transform.\n        \n        key: tt key.\n        locale: main locale key into |self.tt_dd|. Default to |self.locale|\n        locale2: fallback locale key into |self.tt_dd|. Default to |self.locale2|\n        default: a default value in case tt value is not found. Default to raise KeyError.\n        \"\"\"\n        \n        #/\n        locale = locale or self.locale\n        \n        locale2 = locale2 or self.locale2\n        \n        #/ get tt dict of the locale\n        tt_d = self.tt_dd.get(locale, None)\n        \n        if tt_d is not None:\n            #/\n            val = tt_d.get(key, I18n.DFT)\n            \n            #/ if tt value is found\n            if val is not I18n.DFT:\n                return val\n        \n        #/ tt value is not found\n        \n        #/ if has locale2\n        ## Y\n        if locale2 and locale2 != locale:\n            #/ fall back to locale2\n            return self.tt(key, locale=locale2, default=default)\n        ## N\n        else:\n            #/ if default is specified\n            ## N\n            if default is I18n.DFT:\n                raise KeyError(key)\n            ## Y\n            else:\n                return default"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nseparate method to just get the working set This is intended for reuse by similar recipes.", "response": "def working_set(self, extra=()):\n        \"\"\"Separate method to just get the working set\n\n        This is intended for reuse by similar recipes.\n        \"\"\"\n        options = self.options\n        b_options = self.buildout['buildout']\n\n        # Backward compat. :(\n        options['executable'] = sys.executable\n\n        distributions = [\n            r.strip()\n            for r in options.get('eggs', self.name).split('\\n')\n            if r.strip()]\n        orig_distributions = distributions[:]\n        distributions.extend(extra)\n\n        if self.buildout['buildout'].get('offline') == 'true':\n            ws = zc.buildout.easy_install.working_set(\n                distributions,\n                [options['develop-eggs-directory'], options['eggs-directory']]\n                )\n        else:\n            ws = zc.buildout.easy_install.install(\n                distributions, options['eggs-directory'],\n                links=self.links,\n                index=self.index,\n                path=[options['develop-eggs-directory']],\n                newest=self.buildout['buildout'].get('newest') == 'true',\n                allow_hosts=self.allow_hosts)\n\n        return orig_distributions, ws"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_required(dist):\n    d = pkg_resources.get_distribution(dist)\n    reqs = set(d.requires())\n    allds = set([d])\n    while reqs:\n        newreqs = set([])\n        for r in reqs:\n            dr = pkg_resources.get_distribution(r)\n            allds.add(dr)\n            newreqs = newreqs & set(dr.requires())\n        reqs = newreqs - reqs\n    return allds", "response": "Returns a set with all distributions that are required by dist."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if a given distribution is outdated.", "response": "def is_outdated(dist, dep=False):\n    \"\"\"Return a dict with outdated distributions\n\n    If the given distribution has dependencies, they are checked as well.\n\n    :param dist: a distribution to check\n    :type dist: :class:`pkg_resources.Distribution` | str\n    :param dep: If True, also return all outdated dependencies. If False, only check given dist.\n    :type dep:\n    :returns: dictionary of all distributions that are outdated and are either dependencies\n              of the given distribution or the distribution itself.\n              Keys are the outdated distributions\n              and values are the newest parsed versions.\n    :rtype: dict of :class:`pkg_resources.Distribution`\n    :raises: class:`pkg_resources.DistributionNotFound`\n    \"\"\"\n    if dep:\n        required = get_required(dist)\n    else:\n        required = set([dist])\n    ListCommand = pip.commands['list']\n    lc = ListCommand()\n    options, args = lc.parse_args(['--outdated'])\n    outdated = {}\n    for d, raw_ver, parsed_ver in lc.find_packages_latests_versions(options):\n        for r in required:\n            if d.project_name == r.project_name and parsed_ver > r.parsed_version:\n                outdated[r] = parsed_ver\n    return outdated"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the given distribution and all of its dependencies.", "response": "def update(dist, args=None):\n    \"\"\"Update the given distribution and all of its dependencies\n\n    :param dist: the distribution to check\n    :type dist: :class:`pkg_resources.Distribution` | str\n    :param args: extra arguments for the install command.\n                 this is somewhat equivalent to: pip install -U <dist> args\n    :type args: list\n    :returns: None\n    :rtype: None\n    :raises: class:`pkg_resources.DistributionNotFound`\n    \"\"\"\n    dist = pkg_resources.get_distribution(dist)\n    InstallCommand = pip.commands['install']\n    ic = InstallCommand()\n    iargs = ['-U', dist.project_name]\n    if args:\n        iargs.extend(args)\n    ic.main(iargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrestarts the application the same way it was started", "response": "def restart():\n    \"\"\"Restart the application the same way it was started\n\n    :returns: None\n    :rtype: None\n    :raises: SystemExit\n    \"\"\"\n    python = sys.executable\n    os.execl(python, python, * sys.argv)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the dict representation of a server object.", "response": "def server_to_dict(server):\n    \"\"\"\n    Returns the :class:`dict` representation of a server object.\n\n    The returned :class:`dict` is meant to be consumed by\n    :class:`~bang.deployers.cloud.ServerDeployer` objects.\n\n    \"\"\"\n    def get_ips_for_server(server):\n        public_ips = []\n        private_ips = []\n        def address_is_public(address):\n            return address['OS-EXT-IPS:type'] == 'floating'\n        def address_is_private(address):\n            return not address_is_public(address)\n\n        for network, addresses in server.addresses.iteritems():\n            # TODO: is this right? Can have private floating ips\n            public = filter(address_is_public, addresses)\n            private = filter(address_is_private, addresses)\n            public_ips.extend(public)\n            private_ips.extend(private)\n        return private_ips, public_ips\n\n    addresses = server.addresses\n    pub = addresses.get('public', [])\n    priv = addresses.get('private', [])\n\n    if not pub and not priv:\n        # Openstack 13.5?\n        priv, pub = get_ips_for_server(server)\n\n    return {\n            A.server.ID: server.id,\n            A.server.PUBLIC_IPS: [a['addr'] for a in pub],\n            A.server.PRIVATE_IPS: [a['addr'] for a in priv],\n            }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the dictionary representation of a database object.", "response": "def db_to_dict(db):\n    \"\"\"\n    Returns the :class:`dict` representation of a database object.\n\n    The returned :class:`dict` is meant to be consumed by\n    :class:`~bang.deployers.cloud.ServerDeployer` objects.\n\n    \"\"\"\n    return {\n            A.database.HOST: db.hostname,\n            A.database.PORT: db.port,\n            }"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if an SSH key named name is found otherwise returns False.", "response": "def find_ssh_pub_key(self, name):\n        \"\"\"\n        Returns ``True`` if an SSH key named :attr:`name` is found.\n\n        Otherwise returns ``False``.\n\n        :rtype:  :class:`bool`\n\n        \"\"\"\n        return bool(self.nova.keypairs.findall(name=name))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninstalling the public SSH key under the name name.", "response": "def create_ssh_pub_key(self, name, key):\n        \"\"\"\n        Installs the public SSH key under the name :attr:`name`.\n\n        Once installed, the key can be referenced when creating new server\n        instances.\n\n        \"\"\"\n        self.nova.keypairs.create(name, key)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of servers in the region that have the given tags.", "response": "def find_servers(self, tags, running=True):\n        \"\"\"\n        Returns any servers in the region that have tags that match the\n        key-value pairs in :attr:`tags`.\n\n        :param Mapping tags:  A mapping object in which the keys are the tag\n            names and the values are the tag values.\n\n        :param bool running:  A flag to limit server list to instances that are\n            actually *running*.\n\n        :rtype:  :class:`list` of :class:`dict` objects.  Each :class:`dict`\n            describes a single server instance.\n\n        \"\"\"\n        log.debug(\"Finding instances with tags: %s\" % tags)\n        search_opts = {}\n        if running:\n            search_opts['status'] = 'ACTIVE'\n        all_servers = self.nova.servers.list(search_opts=search_opts)\n        servers = []\n        for s in all_servers:\n            md = s.metadata\n            mismatches = [k for k, v in tags.items() if v != md.get(k)]\n            if mismatches:\n                continue\n            servers.append(server_to_dict(s))\n        return servers"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new server instance.", "response": "def create_server(self, basename, disk_image_id, instance_type,\n            ssh_key_name, tags=None, availability_zone=None,\n            timeout_s=DEFAULT_TIMEOUT_S, floating_ip=True,\n            **kwargs):\n        \"\"\"\n        Creates a new server instance.  This call blocks until the server is\n        created and available for normal use, or :attr:`timeout_s` has elapsed.\n\n        :param str basename:  An identifier for the server.  A random postfix\n            will be appended to this basename to work around OpenStack Nova\n            REST API limitations.\n\n        :param str disk_image_id:  The identifier of the base disk image to use\n            as the rootfs.\n\n        :param str instance_type:  The name of an OpenStack instance type, or\n            *flavor*.  This is specific to the OpenStack provider installation.\n\n       :param str ssh_key_name:  The name of the ssh key to inject into the\n            target server's ``authorized_keys`` file.  The key must already\n            have been registered with the OpenStack Nova provider.\n\n        :param tags:  Up to 5 key-value pairs of arbitrary strings to use as\n            *tags* for the server instance.\n        :type tags:  :class:`Mapping`\n\n        :param str availability_zone:  The name of the availability zone in\n            which to place the server.\n\n        :param float timeout_s:  The number of seconds to poll for an active\n            server before failing.  Defaults to ``0`` (i.e. Expect server to be\n            active immediately).\n\n        :param bool floating_ip:  Allocate a floating IP (in\n            openstack 13.5 this doesn't happen automatically, so only\n            don't do it if you know what you're doing)\n\n\n        :rtype:  :class:`dict`\n\n        \"\"\"\n        nova = self.nova\n        name = self.provider.gen_component_name(basename)\n        log.info('Launching server %s... this could take a while...' % name)\n        flavor = nova.flavors.find(name=instance_type)\n        server = nova.servers.create(\n                name,\n                disk_image_id,\n                flavor,\n                key_name=ssh_key_name,\n                meta=tags,\n                availability_zone=availability_zone,\n                **kwargs\n                )\n\n        def find_active():\n            s = nova.servers.get(server.id)\n            if s and s.status == 'ACTIVE':\n                return s\n\n        instance = poll_with_timeout(timeout_s, find_active, 5)\n        if not instance:\n            raise TimeoutError(\n                    'Server %s failed to launch within allotted time.'\n                    % server.id\n                    )\n\n        if floating_ip:\n            log.info('Creating floating ip for %s', name)\n            floating_ip = nova.floating_ips.create()\n            server.add_floating_ip(floating_ip)\n            log.info('Created floating ip %s for %s', floating_ip.ip, name)\n\n        return server_to_dict(instance)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding a security group by name.", "response": "def find_secgroup(self, name):\n        \"\"\"\n        Find a security group by name.\n\n        Returns a :class:`NovaSecGroup` instance if found, otherwise returns\n        None.\n\n        \"\"\"\n        groups = self.nova.security_groups.findall(name=name)\n        if groups:\n            return NovaSecGroup(groups[0])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new security group.", "response": "def create_secgroup(self, name, desc):\n        \"\"\"\n        Creates a new server security group.\n\n        :param str name:  The name of the security group to create.\n        :param str desc:  A short description of the group.\n\n        \"\"\"\n        self.nova.security_groups.create(name, desc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_secgroup_rule(self, protocol, from_port, to_port,\n            source, target):\n        \"\"\"\n        Creates a new server security group rule.\n\n        :param str protocol:  E.g. ``tcp``, ``icmp``, etc...\n        :param int from_port:  E.g. ``1``\n        :param int to_port:  E.g. ``65535``\n        :param str source:\n        :param str target:\n\n        \"\"\"\n        nova = self.nova\n\n        def get_id(gname):\n            sg = nova.security_groups.find(name=gname)\n            if not sg:\n                raise BangError(\"Security group not found, %s\" % gname)\n            return str(sg.id)\n\n        kwargs = {\n                'ip_protocol': protocol,\n                'from_port': str(from_port),\n                'to_port': str(to_port),\n                'parent_group_id': get_id(target),\n                }\n        if '/' in source:\n            kwargs['cidr'] = source\n        else:\n            kwargs['group_id'] = get_id(source)\n            # not sure if this is an openstack hack or an hpcloud hack, but\n            # this is definitely required to get it working on hpcloud:\n            kwargs['cidr'] = 'null'\n        nova.security_group_rules.create(**kwargs)", "response": "Creates a new security group rule."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_bucket(self, name, headers=None):\n        self.provider.swift_client.put_container(name, headers)", "response": "Creates a new bucket named name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch for a db instance with the given name.", "response": "def find_db_instance(self, name, running=True):\n        \"\"\"\n        Searches for a db instance named :attr:`name`.\n\n        :param str name:  The name of the target db instance\n\n        :param bool running:  A flag to only look for instances that are\n            actually *running*.\n\n        :rtype:  :class:`dict`\n\n        \"\"\"\n        found = None\n        for i in self.provider.reddwarf_client.instances.list():\n            if i.name == name:\n                if not running:  # don't care if it's running or not\n                    found = i\n                if i.status == 'running':\n                    found = i\n        if found:\n            log.info(\"Found existing db, %s (%s)\" % (found.name, found.id))\n            return db_to_dict(found)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_db(self, instance_name, instance_type, admin_username,\n            admin_password, security_groups=None, db_name=None,\n            storage_size_gb=DEFAULT_STORAGE_SIZE_GB,\n            timeout_s=DEFAULT_TIMEOUT_S):\n        \"\"\"\n        Creates a database instance.\n\n        This method blocks until the db instance is active, or until\n        :attr:`timeout_s` has elapsed.\n\n        :param str instance_name:  A name to assign to the db instance.\n\n        :param str instance_type:  The server instance type (e.g. ``medium``).\n\n        :param str admin_username:  The admin username.\n\n        :param str admin_password:  The admin password.\n\n        :param security_groups:  A list of security groups in which to place\n            the db instance.\n        :type security_groups:  :class:`~collections.Iterable`\n\n        :param str db_name:  The database name.  If this is not specified, the\n            database will be named the same as the :attr:`instance_name`.\n\n        :param int storage_size_gb:  The size of the storage volume in GB.\n\n        :param float timeout_s:  The number of seconds to poll for an active\n            database server before failing.\n\n        :rtype:  :class:`dict`\n\n        \"\"\"\n        # TODO: investigate what upstream RedDwarf does for admin users\n        return db_to_dict(\n                self._poll_instance_status(\n                    self._create_db(instance_name, instance_type,\n                        storage_size_gb),\n                    timeout_s\n                    )\n                )", "response": "Creates a database instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nova_client(self):\n        if not self._client:\n            self._client = self._get_nova_client()\n        return self._client", "response": "Returns a nova client object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _translate_struct(inner_dict):\n    try:\n        optional = inner_dict['optional'].items()\n        required = inner_dict['required'].items()\n    except KeyError as ex:\n        raise DeserializationError(\"Missing key: {}\".format(ex))\n    except AttributeError as ex:\n        raise DeserializationError(\n            \"Invalid Structure: {}\".format(inner_dict))\n\n    val_dict = {k: _translate(v) for k, v in required}\n    val_dict.update({Optional(k): _translate(v) for k, v in optional})\n    return val_dict", "response": "Translate a teleport Struct into a val subschema."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntranslate a composite teleport value into a val subschema.", "response": "def _translate_composite(teleport_value):\n    \"\"\"Translate a composite teleport value into a val subschema.\"\"\"\n    for key in (\"Array\", \"Map\", \"Struct\"):\n        value = teleport_value.get(key)\n        if value is None:\n            continue\n        return COMPOSITES[key](value)\n\n    raise DeserializationError(\n        \"Could not interpret %r as a teleport schema.\" % teleport_value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntranslating a teleport value in to a val subschema.", "response": "def _translate(teleport_value):\n    \"\"\"Translate a teleport value in to a val subschema.\"\"\"\n    if isinstance(teleport_value, dict):\n        return _translate_composite(teleport_value)\n\n    if teleport_value in PRIMITIVES:\n        return PRIMITIVES[teleport_value]\n\n    raise DeserializationError(\n        \"Could not interpret %r as a teleport schema.\" % teleport_value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a parsed teleport schema to a val schema.", "response": "def to_val(teleport_schema):\n    \"\"\"Convert a parsed teleport schema to a val schema.\"\"\"\n    translated = _translate(teleport_schema)\n    if isinstance(translated, BaseSchema):\n        return translated\n\n    return Schema(translated)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a val schema dictionary to teleport.", "response": "def _dict_to_teleport(dict_value):\n    \"\"\"Convert a val schema dictionary to teleport.\"\"\"\n    if len(dict_value) == 1:\n        for key, value in dict_value.items():\n            if key is str:\n                return {\"Map\": from_val(value)}\n\n    optional = {}\n    required = {}\n    for key, value in dict_value.items():\n        if isinstance(key, Optional):\n            optional[key.value] = from_val(value)\n        else:\n            required[key] = from_val(value)\n\n    return {\"Struct\": {\n        \"required\": required,\n        \"optional\": optional}}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nserializes a val schema to teleport.", "response": "def from_val(val_schema):\n    \"\"\"Serialize a val schema to teleport.\"\"\"\n    definition = getattr(val_schema, \"definition\", val_schema) if isinstance(\n        val_schema, BaseSchema) else val_schema\n    if isinstance(definition, dict):\n        return _dict_to_teleport(definition)\n\n    if isinstance(definition, list):\n        # teleport only supports a single type by default\n        if len(definition) == 1:\n            return {\"Array\": from_val(definition[0])}\n\n    if definition in VAL_PRIMITIVES:\n        return VAL_PRIMITIVES[definition]\n\n    raise SerializationError(\n        \"Serializing %r not (yet) supported.\" % definition)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef document(schema):\n    teleport_schema = from_val(schema)\n    return json.dumps(teleport_schema, sort_keys=True, indent=2)", "response": "Print a documented teleport version of the schema."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef nice_identifier():\n    'do not use uuid.uuid4, because it can block'\n    big = reduce(mul, struct.unpack('<LLLL', os.urandom(16)), 1)\n    big = big % 2**128\n    return uuid.UUID(int=big).hex", "response": "do not use uuid. uuid4 because it can block"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _acquire_lock(self, identifier, atime=30, ltime=5):\n        '''Acquire a lock for a given identifier.\n\n        If the lock cannot be obtained immediately, keep trying at random\n        intervals, up to 3 seconds, until `atime` has passed.  Once the\n        lock has been obtained, continue to hold it for `ltime`.\n\n        :param str identifier: lock token to write\n        :param int atime: maximum time (in seconds) to acquire lock\n        :param int ltime: maximum time (in seconds) to own lock\n        :return: `identifier` if the lock was obtained, :const:`False`\n          otherwise\n\n        '''\n        conn = redis.Redis(connection_pool=self.pool)\n        end = time.time() + atime\n        while end > time.time():\n            if conn.set(self._lock_name, identifier, ex=ltime, nx=True):\n                # logger.debug(\"won lock %s\" % self._lock_name)\n                return identifier\n            sleep_time = random.uniform(0, 3)\n            time.sleep(sleep_time)\n\n        logger.warn('failed to acquire lock %s for %f seconds',\n                    self._lock_name, atime)\n        return False", "response": "Acquire a lock for a given identifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreleasing the lock. This requires you to actually have owned the lock. On return you definitely do not own it, but if somebody else owned it before calling this function, they still do. :param str identifier: the session lock identifier :return: :const:`True` if you actually did own the lock, :const:`False` if you didn't", "response": "def _release_lock(self, identifier):\n        '''Release the lock.\n\n        This requires you to actually have owned the lock.  On return\n        you definitely do not own it, but if somebody else owned it\n        before calling this function, they still do.\n\n        :param str identifier: the session lock identifier\n        :return: :const:`True` if you actually did own the lock,\n          :const:`False` if you didn't\n\n        '''\n        conn = redis.Redis(connection_pool=self.pool)\n        script = conn.register_script('''\n        if redis.call(\"get\", KEYS[1]) == ARGV[1]\n        then\n            return redis.call(\"del\", KEYS[1])\n        else\n            return -1\n        end\n        ''')\n        num_keys_deleted = script(keys=[self._lock_name],\n                                  args=[identifier])\n        return (num_keys_deleted == 1)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_lock(self):\n        '''Find out who currently owns the namespace global lock.\n\n        This is purely a diagnostic tool.  If you are trying to get\n        the global lock, it is better to just call :meth:`lock`, which\n        will atomically get the lock if possible and retry.\n\n        :return: session identifier of the lock holder, or :const:`None`\n\n        '''\n        return redis.Redis(connection_pool=self.pool).get(self._lock_name)", "response": "Find out who currently owns the namespace global lock."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nforcing clear the global lock.", "response": "def force_clear_lock(self):\n        '''Kick out whoever currently owns the namespace global lock.\n\n        This is intended as purely a last-resort tool.  If another\n        process has managed to get the global lock for a very long time,\n        or if it requested the lock with a long expiration and then\n        crashed, this can make the system functional again.  If the\n        original lock holder is still alive, its session calls may fail\n        with exceptions.\n\n        '''\n        return redis.Redis(connection_pool=self.pool).delete(self._lock_name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreset all priorities in dict_name to priority", "response": "def reset_priorities(self, dict_name, priority):\n        '''set all priorities in dict_name to priority\n\n        :type priority: float or int\n        '''\n        if self._session_lock_identifier is None:\n            raise ProgrammerError('must acquire lock first')\n        ## see comment above for script in update\n        conn = redis.Redis(connection_pool=self.pool)\n        script = conn.register_script('''\n        if redis.call(\"get\", KEYS[1]) == ARGV[1]\n        then\n            local keys = redis.call('ZRANGE', KEYS[2], 0, -1)\n            for i, next_key in ipairs(keys) do\n                redis.call(\"zadd\",  KEYS[2], ARGV[2], next_key)\n            end\n            return 1\n        else\n            -- ERROR: No longer own the lock\n            return 0\n        end\n        ''')\n        dict_name = self._namespace(dict_name)\n        res = script(keys=[self._lock_name,\n                           dict_name + 'keys'],\n                     args=[self._session_lock_identifier,\n                           priority])\n        if not res:\n            # We either lost the lock or something else went wrong\n            raise EnvironmentError(\n                'Unable to add items to %s in registry' % dict_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the number of items in a dictionary within a given range.", "response": "def len(self, dict_name, priority_min='-inf', priority_max='+inf'):\n        '''Get the number of items in (part of) a dictionary.\n\n        Returns number of items in `dict_name` within\n        [`priority_min`, `priority_max`].  This is similar to\n        ``len(filter(dict_name, priority_min, priority_max))`` but\n        does not actually retrieve the items.\n\n        This is a read-only operation that does not require or\n        honor a session lock.\n\n        :param str dict_name: dictionary name to query\n        :param float priority_min: lowest priority score\n        :param float priority_max: highest priority score\n        '''\n        dict_name = self._namespace(dict_name)\n        conn = redis.Redis(connection_pool=self.pool)\n        return conn.zcount(dict_name + 'keys', priority_min, priority_max)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nselect an item and remove it.", "response": "def popitem(self, dict_name, priority_min='-inf', priority_max='+inf'):\n        '''Select an item and remove it.\n\n        The item comes from `dict_name`, and has the lowest score\n        at least `priority_min` and at most `priority_max`.  If some\n        item is found, remove it from `dict_name` and return it.\n\n        This runs as a single atomic operation but still requires a\n        session lock.\n\n        :param str dict_name: source dictionary\n        :param float priority_min: lowest score\n        :param float priority_max: highest score\n        :return: pair of (key, value) if an item was popped, or\n          :const:`None`\n\n        '''\n        if self._session_lock_identifier is None:\n            raise ProgrammerError('must acquire lock first')\n        conn = redis.Redis(connection_pool=self.pool)\n        script = conn.register_script('''\n        if redis.call(\"get\", KEYS[1]) == ARGV[1]\n        then\n            -- remove next item of dict_name\n            local next_key, next_priority = redis.call(\"zrangebyscore\",\n                KEYS[3], ARGV[2], ARGV[3], \"WITHSCORES\", \"LIMIT\", 0, 1)[1]\n\n            if not next_key then\n                return {}\n            end\n            \n            redis.call(\"zrem\", KEYS[3], next_key)\n            local next_val = redis.call(\"hget\", KEYS[2], next_key)\n            -- zrem removed it from list, so also remove from hash\n            redis.call(\"hdel\", KEYS[2], next_key)\n            return {next_key, next_val}\n        else\n            -- ERROR: No longer own the lock\n            return -1\n        end\n        ''')\n        dict_name = self._namespace(dict_name)\n        key_value = script(keys=[self._lock_name,\n                                 dict_name,\n                                 dict_name + \"keys\"],\n                           args=[self._session_lock_identifier,\n                                 priority_min,\n                                 priority_max])\n        if key_value == -1:\n            raise KeyError(\n                'Registry failed to return an item from %s' % dict_name)\n\n        if key_value == []:\n            return None\n\n        return self._decode(key_value[0]), self._decode(key_value[1])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef popitem_move(self, from_dict, to_dict,\n                     priority_min='-inf', priority_max='+inf'):\n        '''Select an item and move it to another dictionary.\n\n        The item comes from `from_dict`, and has the lowest score\n        at least `priority_min` and at most `priority_max`.  If some\n        item is found, remove it from `from_dict`, add it to `to_dict`,\n        and return it.\n\n        This runs as a single atomic operation but still requires a\n        session lock.\n\n        :param str from_dict: source dictionary\n        :param str to_dict: destination dictionary\n        :param float priority_min: lowest score\n        :param float priority_max: highest score\n        :return: pair of (key, value) if an item was moved, or\n          :const:`None`\n\n        '''\n        if self._session_lock_identifier is None:\n            raise ProgrammerError('must acquire lock first')\n        conn = redis.Redis(connection_pool=self.pool)\n        script = conn.register_script('''\n        if redis.call(\"get\", KEYS[1]) == ARGV[1]\n        then\n            -- find the next key and priority\n            local next_items = redis.call(\"zrangebyscore\", KEYS[3],\n                ARGV[2], ARGV[3], \"WITHSCORES\", \"LIMIT\", 0, 1)\n            local next_key = next_items[1]\n            local next_priority = next_items[2]\n            \n            if not next_key then\n                return {}\n            end\n\n            -- remove next item of from_dict\n            redis.call(\"zrem\", KEYS[3], next_key)\n\n            local next_val = redis.call(\"hget\", KEYS[2], next_key)\n            -- zrem removed it from list, so also remove from hash\n            redis.call(\"hdel\", KEYS[2], next_key)\n\n            -- put it in to_dict\n            redis.call(\"hset\", KEYS[4], next_key, next_val)\n            redis.call(\"zadd\", KEYS[5], next_priority, next_key)\n\n            return {next_key, next_val, next_priority}\n        else\n            -- ERROR: No longer own the lock\n            return -1\n        end\n        ''')\n        key_value = script(keys=[self._lock_name, \n                                 self._namespace(from_dict),\n                                 self._namespace(from_dict) + 'keys',\n                                 self._namespace(to_dict),\n                                 self._namespace(to_dict) + 'keys'],\n                           args=[self._session_lock_identifier,\n                                 priority_min, priority_max])\n\n        if key_value == []:\n            return None\n\n        if None in key_value or key_value == -1:\n            raise KeyError(\n                'Registry.popitem_move(%r, %r) --> %r' %\n                (from_dict, to_dict, key_value))\n\n        return self._decode(key_value[0]), self._decode(key_value[1])", "response": "Select an item and move it to another dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef move(self, from_dict, to_dict, mapping, priority=None):\n        '''Move keys between dictionaries, possibly with changes.\n\n        Every key in `mapping` is removed from `from_dict`, and added to\n        `to_dict` with its corresponding value.  The priority will be\n        `priority`, if specified, or else its current priority.\n\n        This operation on its own is atomic and does not require a\n        session lock; however, it does require you to pass in the\n        values, which probably came from a previous query call.  If\n        you do not call this with a session lock but some other caller\n        has one, you will get :class:`rejester.LockError`.  If you do\n        have a session lock, this will check that you still have it.\n\n        :param str from_dict: name of original dictionary\n        :param str to_dict: name of target dictionary\n        :param dict mapping: keys to move with new values\n        :param int priority: target priority, or :const:`None` to use existing\n        :raise rejester.LockError: if the session lock timed out\n        :raise rejester.EnvironmentError: if some items didn't move\n\n        '''\n        items = []\n        ## This flattens the dictionary into a list\n        for key, value in mapping.iteritems():\n            key = self._encode(key)\n            items.append(key)\n            value = self._encode(value)\n            items.append(value)\n\n        conn = redis.Redis(connection_pool=self.pool)\n        script = conn.register_script('''\n        local lock_holder = redis.call(\"get\", KEYS[1])\n        if (not lock_holder) or (lock_holder == ARGV[1])\n        then\n            local count = 0\n            for i = 3, #ARGV, 2  do\n                -- find the priority of the item\n                local next_priority = ARGV[2]\n                if next_priority == \"\" then\n                    next_priority = redis.call(\"zscore\", KEYS[3], ARGV[i])\n                end\n                -- remove item from the sorted set and the real data\n                redis.call(\"hdel\", KEYS[2], ARGV[i])\n                redis.call(\"zrem\", KEYS[3], ARGV[i])\n                -- put it in to_dict\n                redis.call(\"hset\", KEYS[4], ARGV[i], ARGV[i+1])\n                redis.call(\"zadd\", KEYS[5], next_priority, ARGV[i])\n                count = count + 1\n            end\n            return count\n        else\n            -- ERROR: No longer own the lock\n            return -1\n        end\n        ''')\n\n        # Experimental evidence suggests that redis-py passes\n        # *every* value as a string, maybe unless it's obviously\n        # a number.  Empty string is an easy \"odd\" value to test for.\n        if priority is None: priority = ''\n        num_moved = script(keys=[self._lock_name,\n                                 self._namespace(from_dict),\n                                 self._namespace(from_dict) + \"keys\",\n                                 self._namespace(to_dict),\n                                 self._namespace(to_dict) + \"keys\"],\n                           args=[self._session_lock_identifier,\n                                 priority] + items)\n        if num_moved == -1:\n            raise LockError()\n        if num_moved != len(items) / 2:\n            raise EnvironmentError(\n                'Registry failed to move all: num_moved = %d != %d len(items)'\n                % (num_moved, len(items)))", "response": "Move keys between dictionaries possibly with changes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef move_all(self, from_dict, to_dict):\n        '''Move everything from one dictionary to another.\n\n        This can be expensive if the source dictionary is large.\n\n        This always requires a session lock.\n\n        :param str from_dict: source dictionary\n        :param str to_dict: destination dictionary\n\n        '''\n        if self._session_lock_identifier is None:\n            raise ProgrammerError('must acquire lock first')\n        conn = redis.Redis(connection_pool=self.pool)\n        script = conn.register_script('''\n        if redis.call(\"get\", KEYS[1]) == ARGV[1]\n        then\n            local count = 0\n            local keys = redis.call('ZRANGE', KEYS[3], 0, -1)\n            for i, next_key in ipairs(keys) do\n                -- get the value and priority for this key\n                local next_val = redis.call(\"hget\", KEYS[2], next_key)\n                local next_priority = redis.call(\"zscore\", KEYS[3], next_key)\n                -- remove item of from_dict\n                redis.call(\"zrem\", KEYS[3], next_key)\n                -- also remove from hash\n                redis.call(\"hdel\", KEYS[2], next_key)\n                -- put it in to_dict\n                redis.call(\"hset\",  KEYS[4], next_key, next_val)\n                redis.call(\"zadd\", KEYS[5], next_priority, next_key)\n                count = count + 1\n            end\n            return count\n        else\n            -- ERROR: No longer own the lock\n            return 0\n        end\n        ''')\n        num_moved = script(keys=[self._lock_name,\n                                 self._namespace(from_dict), \n                                 self._namespace(from_dict) + 'keys',\n                                 self._namespace(to_dict),\n                                 self._namespace(to_dict) + 'keys'],\n                           args=[self._session_lock_identifier])\n        return num_moved", "response": "Move everything from one dictionary to another."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pull(self, dict_name):\n        '''Get the entire contents of a single dictionary.\n\n        This operates without a session lock, but is still atomic.  In\n        particular this will run even if someone else holds a session\n        lock and you do not.\n\n        This is only suitable for \"small\" dictionaries; if you have\n        hundreds of thousands of items or more, consider\n        :meth:`filter` instead to get a subset of a dictionary.\n\n        :param str dict_name: name of the dictionary to retrieve\n        :return: corresponding Python dictionary\n\n        '''\n        dict_name = self._namespace(dict_name)\n        conn = redis.Redis(connection_pool=self.pool)\n        res = conn.hgetall(dict_name)\n        split_res = dict([(self._decode(key),\n                           self._decode(value))\n                          for key, value in res.iteritems()])\n        return split_res", "response": "Get the entire contents of a single dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter(self, dict_name, priority_min='-inf', priority_max='+inf',\n               start=0, limit=None):\n        '''Get a subset of a dictionary.\n\n        This retrieves only keys with priority scores greater than or\n        equal to `priority_min` and less than or equal to `priority_max`.\n        Of those keys, it skips the first `start` ones, and then returns\n        at most `limit` keys.\n\n        With default parameters, this retrieves the entire dictionary,\n        making it a more expensive version of :meth:`pull`.  This can\n        be used to limit the dictionary by priority score, for instance\n        using the score as a time stamp and only retrieving values\n        before or after a specific time; or it can be used to get\n        slices of the dictionary if there are too many items to use\n        :meth:`pull`.\n\n        This is a read-only operation and does not require a session\n        lock, but if this is run in a session context, the lock will\n        be honored.\n\n        :param str dict_name: name of the dictionary to retrieve\n        :param float priority_min: lowest score to retrieve\n        :param float priority_max: highest score to retrieve\n        :param int start: number of items to skip\n        :param int limit: number of items to retrieve\n        :return: corresponding (partial) Python dictionary\n        :raise rejester.LockError: if the session lock timed out\n\n        '''\n        conn = redis.Redis(connection_pool=self.pool)\n        script = conn.register_script('''\n        if (ARGV[1] == \"\") or (redis.call(\"get\", KEYS[1]) == ARGV[1])\n        then\n            -- find all the keys and priorities within range\n            local next_keys = redis.call(\"zrangebyscore\", KEYS[3],\n                                         ARGV[2], ARGV[3],\n                                         \"limit\", ARGV[4], ARGV[5])\n            \n            if not next_keys[1] then\n                return {}\n            end\n\n            local t = {}\n            for i = 1, #next_keys  do\n                local next_val = redis.call(\"hget\", KEYS[2], next_keys[i])\n                table.insert(t, next_keys[i])\n                table.insert(t, next_val)\n            end\n\n            return t\n        else\n            -- ERROR: No longer own the lock\n            return -1\n        end\n        ''')\n        if limit is None: limit = -1\n        res = script(keys=[self._lock_name,\n                           self._namespace(dict_name),\n                           self._namespace(dict_name) + 'keys'],\n                     args=[self._session_lock_identifier or '',\n                           priority_min, priority_max, start, limit])\n        if res == -1:\n            raise LockError()\n        split_res = dict([(self._decode(res[i]),\n                           self._decode(res[i+1]))\n                          for i in xrange(0, len(res)-1, 2)])\n        return split_res", "response": "Get a subset of a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting two keys to be equal in a 1 - to - 1 mapping.", "response": "def set_1to1(self, dict_name, key1, key2):\n        '''Set two keys to be equal in a 1-to-1 mapping.\n\n        Within `dict_name`, `key1` is set to `key2`, and `key2` is set\n        to `key1`.\n\n        This always requires a session lock.\n\n        :param str dict_name: dictionary to update\n        :param str key1: first key/value\n        :param str key2: second key/value\n\n        '''\n        if self._session_lock_identifier is None:\n            raise ProgrammerError('must acquire lock first')\n        conn = redis.Redis(connection_pool=self.pool)\n        script = conn.register_script('''\n        if redis.call(\"get\", KEYS[1]) == ARGV[1]\n        then\n            redis.call(\"hset\", KEYS[2], ARGV[2], ARGV[3])\n            redis.call(\"hset\", KEYS[2], ARGV[3], ARGV[2])\n        else\n            -- ERROR: No longer own the lock\n            return -1\n        end\n        ''')\n        res = script(keys=[self._lock_name,\n                           self._namespace(dict_name)],\n                     args=[self._session_lock_identifier,\n                           self._encode(key1),\n                           self._encode(key2)])\n        if res == -1:\n            raise EnvironmentError()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the value for a specific key in a specific dictionary.", "response": "def get(self, dict_name, key, default=None, include_priority=False):\n        '''Get the value for a specific key in a specific dictionary.\n\n        If `include_priority` is false (default), returns the value\n        for that key, or `default` (defaults to :const:`None`) if it\n        is absent.  If `include_priority` is true, returns a pair of\n        the value and its priority, or of `default` and :const:`None`.\n\n        This does not use or enforce the session lock, and is read-only,\n        but inconsistent results are conceivably possible if the caller\n        does not hold the lock and `include_priority` is set.\n\n        :param str dict_name: name of dictionary to query\n        :param str key: key in dictionary to query\n        :param default: default value if `key` is absent\n        :param bool include_priority: include score in results\n        :return: value from dictionary, or pair of value and priority\n\n        '''\n        dict_name = self._namespace(dict_name)\n        key = self._encode(key)\n        conn = redis.Redis(connection_pool=self.pool)\n        val = conn.hget(dict_name, key)\n        if val is None:\n            _val = default\n        else:\n            _val = self._decode(val)\n        if include_priority:\n            if val is not None:\n                priority = conn.zscore(dict_name + 'keys', key)\n                return _val, priority\n            else:\n                return _val, None\n        return _val"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set(self, dict_name, key, value, priority=None):\n        '''Set a single value for a single key.\n\n        This requires a session lock.\n\n        :param str dict_name: name of the dictionary to update\n        :param str key: key to update\n        :param str value: value to assign to `key`\n        :param int priority: priority score for the value (if any)\n\n        '''\n        if priority is not None:\n            priorities = {key: priority}\n        else:\n            priorities = None\n        self.update(dict_name, {key: value}, priorities=priorities)", "response": "Set a single value for a single key."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes an entire dictionary.", "response": "def delete(self, dict_name):\n        '''Delete an entire dictionary.\n\n        This operation on its own is atomic and does not require a\n        session lock, but a session lock is honored.\n\n        :param str dict_name: name of the dictionary to delete\n        :raises rejester.exceptions.LockError: if called with a session\n          lock, but the system does not currently have that lock; or if\n          called without a session lock but something else holds it\n        '''\n        conn = redis.Redis(connection_pool=self.pool)\n        script = conn.register_script('''\n        if redis.call(\"get\", KEYS[1]) == ARGV[1]\n        then\n            redis.call(\"del\", KEYS[2], KEYS[3])\n            return 0\n        else\n            return -1\n        end\n        ''')\n        res = script(keys=[self._lock_name,\n                           self._namespace(dict_name),\n                           self._namespace(dict_name) + 'keys'],\n                     args=[self._session_lock_identifier])\n        if res == -1:\n            raise LockError()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute a direct redis call against this Registry instances namespaced keys.", "response": "def direct_call(self, *args):\n        '''execute a direct redis call against this Registry instances\n        namespaced keys.  This is low level is should only be used for\n        prototyping.\n\n        arg[0] = redis function\n        arg[1] = key --- will be namespaced before execution\n        args[2:] = args to function\n\n        :returns raw return value of function:\n\n        Neither args nor return values are encoded/decoded\n        '''\n        conn = redis.Redis(connection_pool=self.pool)\n        command = args[0]\n        key = self._namespace(args[1])\n        args = args[2:]\n        func = getattr(conn, command)\n        return func(key, *args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ask(question):\n    '''\n    Infinite loop to get yes or no answer or quit the script.\n    '''\n    while True:\n        ans = input(question)\n        al = ans.lower()\n        if match('^y(es)?$', al):\n            return True\n        elif match('^n(o)?$', al):\n            return False\n        elif match('^q(uit)?$', al):\n            stdout.write(CYAN)\n            print(\"\\nGoodbye.\\n\")\n            stdout.write(RESET)\n            quit()\n        else:\n            stdout.write(RED)\n            print(\"%s is invalid. Enter (y)es, (n)o or (q)uit.\" % ans)\n            stdout.write(RESET)", "response": "Infinite loop to get yes or no answer or quit the script."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_remote_user(request):\n    if 'HTTP_AUTHORIZATION' not in request.environ:\n        return\n    authorization = request.environ['HTTP_AUTHORIZATION']\n    try:\n        authmeth, auth = authorization.split(' ', 1)\n    except ValueError:  # not enough values to unpack\n        return\n    if authmeth.lower() != 'basic':\n        return\n    try:\n        auth = base64.b64decode(auth.strip().encode('latin1')).decode('latin1')\n    except (binascii.Error, TypeError):  # can't decode\n        return\n    try:\n        login, password = auth.split(':', 1)\n    except ValueError:  # not enough values to unpack\n        return\n    return login, password", "response": "Parse basic HTTP_AUTHORIZATION and return user name and password"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef basic_auth_tween_factory(handler, registry):\n    def basic_auth_tween(request):\n        remote_user = get_remote_user(request)\n        if remote_user is not None:\n            request.environ['REMOTE_USER'] = remote_user[0]\n        return handler(request)\n    return basic_auth_tween", "response": "Create a tween that will parse HTTP_AUTHORIZATION and set remote_user\n            variable to request. environ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plot_triaxial(height, width, tools):\n    '''Plot pandas dataframe containing an x, y, and z column'''\n    import bokeh.plotting\n\n    p = bokeh.plotting.figure(x_axis_type='datetime',\n                              plot_height=height,\n                              plot_width=width,\n                              title=' ',\n                              toolbar_sticky=False,\n                              tools=tools,\n                              active_drag=BoxZoomTool(),\n                              output_backend='webgl')\n\n    p.yaxis.axis_label = 'Acceleration (count)'\n    p.xaxis.axis_label = 'Time (timezone as programmed)'\n\n    # Plot accelerometry data as lines and scatter (for BoxSelectTool)\n    colors = ['#1b9e77', '#d95f02', '#7570b3']\n    axes = ['x', 'y', 'z']\n    lines = [None,]*3\n    scats = [None,]*3\n    for i, (ax, c) in enumerate(zip(axes, colors)):\n        lines[i] = p.line(y=ax, x='dt', color=c, legend=False, source=source)\n        scats[i] = p.scatter(y=ax, x='dt', color=c, legend=False, size=1,\n                             source=source)\n    return p, lines, scats", "response": "Plot pandas dataframe containing an x y and z column"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads data from a directory and return the parameters meta and data.", "response": "def load_data(path_dir):\n    '''Load data, directory parameters, and accelerometer parameter names\n\n    Args\n    ----\n    path_dir: str\n        Path to the data directory\n\n    Returns\n    -------\n    data: pandas.DataFrame\n        Experiment data\n    params_tag: dict\n        A dictionary of parameters parsed from the directory name\n    params_data: list\n        A list of the accelerometer parameter names\n    '''\n    import os\n    import pylleo\n\n    exp_name = os.path.split(path_dir)[1]\n    params_tag = pylleo.utils.parse_experiment_params(exp_name)\n\n    # Load the Little Leonardo tag data\n    meta = pylleo.lleoio.read_meta(path_dir, params_tag['tag_model'],\n                                   params_tag['tag_id'])\n    data = pylleo.lleoio.read_data(meta, path_dir, sample_f=sample_f)\n\n    # Get and curate the parameter names of the loaded dataframe\n    params_data = pylleo.utils.get_tag_params(params_tag['tag_model'])\n    params_data = [pylleo.utils.posix_string(p) for p in params_data]\n    params_data = [p for p in params_data if p.startswith('acc')]\n\n    return data, params_tag, params_data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating data directories drop down with new parent directory", "response": "def callback_parent(attr, old, new):\n    '''Update data directories drop down with new parent directory'''\n    import os\n\n    # Remove accidental white space if copy/pasted\n    new = new.strip()\n    parent_input.value = new\n\n    # Verify new parent path exists and update `datadirs_select` widget\n    if os.path.exists(new):\n        # Create sorted list of data directories, ignore files\n        joinisdir = lambda parent, d: os.path.isdir(os.path.join(parent, d))\n        options = sorted([d for d in os.listdir(new) if joinisdir(new, d)])\n\n        # Update dropdown list of available data directories and select first\n        datadirs_select.options = options\n        datadirs_select.value = options[0]\n        callback_datadirs('value', options[0], options[0])\n\n    else:\n        msg = '''\n              The parent path `{}` does not exist.\n\n              Check that you have entered the absolute path.\n              '''.format(new)\n        output_window.text = output_template.format(msg)\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef callback_datadirs(attr, old, new):\n    '''Update source and controls with data loaded from selected directory'''\n    import os\n\n    global data\n\n    try:\n        # Load data from new data directory\n        path_dir = os.path.join(parent_input.value, new)\n        data, params_tag, params_data = load_data(path_dir)\n\n        # Make title with new data directory\n        p.title.text = 'Calibrating {}'.format(params_tag['experiment'])\n\n        # Update `source` data fields from dataframe\n        dt_str = [dt.strftime(dt_fmt) for dt in data['datetimes']]\n        source.data = dict(x      = list(data['acceleration_x']),\n                           y      = list(data['acceleration_y']),\n                           z      = list(data['acceleration_z']),\n                           ind    = list(data.index),\n                           dt     = list(data['datetimes']),\n                           dt_str = dt_str)\n\n        # Update values for control widgets\n        param_checkbox.active = [0, 1, 2]\n        param_select.options = params_data\n        param_select.value = params_data[0]\n        regions = ['lower', 'upper']\n        region_select.options = regions\n        region_select.value = regions[0]\n        start_input.value = str(data.index[0])\n        end_input.value = str(data.index[-1])\n    except Exception as e:\n        msg = '''\n              Problem loading data directory `{}`.\n\n              Please check that data exists in that directory.\n\n              Details:\n              {}\n              '''.format(new, e)\n        output_window.text = output_template.format(msg)\n\n\n    return None", "response": "Update source and controls with data loaded from selected directory"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate TextInput start and end entries from BoxSelectTool selection", "response": "def callback_box_select(attr, old, new):\n    '''Update TextInput start/end entries from BoxSelectTool selection'''\n\n    # Get indices of selection\n    ind = sorted(new['1d']['indices'])\n\n    if new is None:\n        start_input.value = '0'\n        end_input.value = '0'\n    else:\n        start_input.value = str(source.data['ind'][ind[0]])\n        end_input.value = str(source.data['ind'][ind[-1]])\n        msg = '''\n              New start and end index values set.\n              '''\n        output_window.text = output_template.format(msg)\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef callback_checkbox(attr, old, new):\n    '''Update visible data from parameters selectin in the CheckboxSelect'''\n    import numpy\n\n    for i in range(len(lines)):\n        lines[i].visible = i in param_checkbox.active\n        scats[i].visible = i in param_checkbox.active\n\n    return None", "response": "Update visible data from parameters selectin in the CheckboxSelect"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves index from bokeh textinput", "response": "def callback_save_indices():\n    '''Save index from bokeh textinput'''\n    import datetime\n    import os\n    import pylleo\n    import yamlord\n\n    if datadirs_select.value != 'None':\n        path_dir = os.path.join(parent_input.value, datadirs_select.value)\n        cal_yaml_path = os.path.join(path_dir, 'cal.yml')\n\n        param = (param_select.value).lower().replace('-','_')\n        region = region_select.value\n        start = int(start_input.value)\n        end   = int(end_input.value)\n\n        msg = '''\n              Updated calibration times for:<br>\n              <b>{}/{}</b>\n              <br>\n              <br>\n              star index: {}<br>\n              end index:  {}<br>\n              '''.format(param, region, start, end)\n        output_window.text = output_template.format(msg)\n\n        cal_dict = pylleo.lleocal.read_cal(cal_yaml_path)\n        # Generalize for Class-ifying\n        cal_dict = pylleo.lleocal.update(data, cal_dict, param, region, start, end)\n        yamlord.write_yaml(cal_dict, cal_yaml_path)\n    else:\n        msg = '''\n              You must first load data and select indices for calibration\n              regions before you can save the indices to `cal.yml`\n              '''\n        output_window.text = output_template.format(msg)\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef callback_save_poly():\n    '''Perform polyfit once regions selected\n\n    Globals: cal_fname, data (read-only, so no declaration)\n    '''\n    import datetime\n    import pylleo\n    import yamlord\n    import itertools\n\n    def _check_param_regions(param, regions, cal_dict):\n        msg = '''\n              <b>{}</b> was not found in the calibration dictionary.\n\n              Process that parameter and then try saving the polyfit again.\n              '''.format(param)\n\n        params_present = True\n        if param not in cal_dict['parameters']:\n            params_present = False\n            msg.format(param)\n        else:\n            for region in regions:\n                if region not in cal_dict['parameters'][param]:\n                    params_present = False\n                    msg.format('{}/{}'.format(param, region))\n                    output_window.text = output_template.format(msg)\n\n        return params_present\n\n\n    def _check_index_order(param, regions, cal_dict):\n        '''Check that index positions exist for each calibration region'''\n\n        indices_present = True\n        for region in regions:\n            start = cal_dict['parameters'][param][region]['start']\n            end = cal_dict['parameters'][param][region]['end']\n            # Check if start comes after end\n            if int(start) > int(end):\n                indices_present = False\n                msg = '''\n                      The start index ({}) comes after the end index ({}).\n\n                      Please set new start/end indexes for <b>{}/{}</b>\n                      '''.format(start, end, param, region)\n                msg.format(start, end, param, region)\n                output_window.text = output_template.format(msg)\n\n        return indices_present\n\n\n    if datadirs_select.value != 'None':\n        path_dir = os.path.join(parent_input.value, datadirs_select.value)\n        cal_yaml_path = os.path.join(path_dir, cal_fname)\n        cal_dict = pylleo.lleocal.read_cal(cal_yaml_path)\n\n        # Get currently selected parameter\n        param = param_select.value\n        regions = region_select.options\n\n        # Check that index positions have been recorded in `cal.yml`\n        if not _check_index_order(param, regions, cal_dict):\n            return None\n\n        # Check that index positions are in sequence\n        if not _check_index_order(param, regions, cal_dict):\n            return None\n\n        param = (param_select.value).lower().replace('-','_')\n\n        try:\n            msg = '''\n                  Saved polyfit for <b>{}</b> to <b>{}</b>.\n                  '''.format(param, cal_fname)\n            output_window.text = output_template.format(msg)\n\n            lower, upper = pylleo.lleocal.get_cal_data(data, cal_dict, param)\n            poly = list(pylleo.lleocal.fit1d(lower, upper))\n            poly = [float(str(i)) for i in poly]\n\n            cal_dict['parameters'][param]['poly'] = poly\n            yamlord.write_yaml(cal_dict, cal_yaml_path)\n        except Exception as e:\n            msg = 'Problem saving polyfit: {}'.format(e)\n            output_window.text = output_template.format(msg)\n    else:\n        msg = '''\n              You must first load data and select indices for calibration\n              regions before you can save to polyfit to `cal.yml`\n              '''\n        output_window.text = output_template.format(msg)\n\n    return None", "response": "Save the current calibration dictionary to file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_password(config):\n    password = config.get_option('remote.password')\n\n    if password == '':\n        user = config.get_option('remote.user')\n        url = config.get_option('remote.url')\n        url_obj = urlparse.urlparse(url)\n        server = url_obj.hostname\n        protocol = url_obj.scheme\n\n        if HAS_GNOME_KEYRING_SUPPORT:\n            password = get_password_from_gnome_keyring(user, server, protocol)\n\n        else:\n            prompt = 'Enter %s password for %s at %s: ' % (get_app(), user,\n                                                           server)\n            password = getpass.getpass(prompt)\n\n    return password", "response": "Returns the password for a remote server"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting the passed in list of specs", "response": "def process(specs):\n    \"\"\"\n    Executes the passed in list of specs\n    \"\"\"\n    pout, pin = chain_specs(specs)\n    LOG.info(\"Processing\")\n    sw = StopWatch().start()\n    r = pout.process(pin)\n    if r:\n        print(r)\n    LOG.info(\"Finished in %s\", sw.read())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef chain_specs(specs):\n    LOG.info(\"Parsing %s specs\", len(specs))\n    # First spec is always an input\n    pin = pypein.input_for(specs[0]).__iter__()\n    # If only an input spec was provided, then use json for output\n    if len(specs) == 1:\n        pout = pypeout.output_for(\"json\")\n    else:\n        # Middle specs are filters that successively wrap input\n        for s in specs[1:-1]:\n            pin = pypef.filter_for(s).filter(pin)\n        # Assume output on last spec, but it may be a filter.\n        # If last spec is a filter, use json for output\n        try:\n            pout = pypeout.output_for(specs[-1])\n        except pypeout.NoSuchOutputException:\n            pin = pypef.filter_for(specs[-1]).filter(pin)\n            pout = pypeout.output_for(\"json\")\n    return pout, pin", "response": "Given a list of specs returns a tuple that can be invoked with a tuple pout and pin."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads exception data from the current exception frame.", "response": "def load(self, cause=None, do_message=True):\n        \"\"\"\n        Loads exception data from the current exception frame - should be called inside the except block\n        :return:\n        \"\"\"\n        if cause is not None:\n            self.cause = cause\n            if do_message:\n                self.message = error_message(self, self.base_message, cause)\n\n        self.exc_type, self.exc_value, self.exc_traceback = sys.exc_info()\n        self.traceback_formatted = traceback.format_exc()\n        self.traceback = traceback.extract_tb(self.exc_traceback)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef smartquotes(text):\n    command = shlex.split('pandoc --smart -t plain')\n    com = Popen(command, shell=False, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n    out, err = com.communicate(text.encode('utf-8'))\n    com_out = out.decode('utf-8')\n    text = com_out.replace(u'\\n', u' ').strip()\n    return text", "response": "Runs text through pandoc for smartquote correction."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_by_prefix_surfix(prefix, surfix, maxlen, text):\n        pattern = r\"\"\"(?<=%s)[\\s\\S]{1,%s}(?=%s)\"\"\" % (prefix, maxlen, surfix)\n        return re.findall(pattern, text)", "response": "Extract the text in between a prefix and surfix."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting cmd check exit code return stdout", "response": "def shell(cmd, **kwargs):\n    \"\"\"Execute cmd, check exit code, return stdout\"\"\"\n    logger.debug(\"$ %s\", cmd)\n    return subprocess.check_output(cmd, shell=True, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _cmdline(argv=None):\n    parser = ArgumentParser()\n    parser.add_argument(\"--checkout\", default=\"HEAD\",\n                        help=\"branch, tag, or commit to use [HEAD]\")\n    parser.add_argument(\"--name\", default=_NAME,\n                        help=\"application name [{:s}]\".format(_NAME))\n    parser.add_argument(\"--repo\", default=_REPO,\n                        help=\"source repo [{:s}]\".format(_REPO))\n    parser.add_argument(\"--test\", action=\"store_true\",\n                        help=\"run test suite after installation\")\n    parser.add_argument(\"root\", help=\"installation root\")\n    return parser.parse_args(argv)", "response": "Parse command line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main(argv=None):\n    @contextmanager\n    def tmpdir():\n        \"\"\" Create a self-deleting temporary directory. \"\"\"\n        path = mkdtemp()\n        try:\n            yield path\n        finally:\n            rmtree(path)\n        return\n\n    def test():\n        \"\"\" Execute the test suite. \"\"\"\n        install = \"{:s} install -r requirements-test.txt\"\n        check_call(install.format(pip).split())\n        pytest = join(path, \"bin\", \"py.test\")\n        test = \"{:s} test/\".format(pytest)\n        check_call(test.split())\n        uninstall = \"{:s} uninstall -y -r requirements-test.txt\"\n        check_call(uninstall.format(pip).split())\n        return\n\n    args = _cmdline(argv)\n    path = join(abspath(args.root), args.name)\n    with tmpdir() as tmp:\n        clone = \"git clone {:s} {:s}\".format(args.repo, tmp)\n        check_call(clone.split())\n        chdir(tmp)\n        checkout = \"git checkout {:s}\".format(args.checkout)\n        check_call(checkout.split())\n        virtualenv = \"virtualenv {:s}\".format(path)\n        check_call(virtualenv.split())\n        pip = join(path, \"bin\", \"pip\")\n        install = \"{:s} install -U -r requirements.txt .\".format(pip)\n        check_call(install.split())\n        if args.test:\n            test()\n    return 0", "response": "This is the main entry point for the sequence of commands."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _create_user(self, email, password, is_superuser, **extra_fields):\n        now = timezone.now()\n        if not email:\n            raise ValueError('The given email must be set')\n\n        email = self.normalize_email(email)\n        user = self.model(\n            email=email,\n            password=password,\n            is_active=True,\n            is_superuser=is_superuser, last_login=now,\n            date_joined=now,\n            **extra_fields)\n        user.set_password(password)\n        user.save(using=self._db)\n        return user", "response": "Create a new user record"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget full name if no name is set email is given", "response": "def get_full_name(self):\n        \"\"\"Get full username if no name is set email is given\"\"\"\n        if self.first_name and self.last_name:\n            return \"{} {}\".format(self.first_name, self.last_name)\n        return self.email"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_attribute(self, code, value):\n        attr, _ = self.get_or_create(code=code)\n        attr.value = value\n        attr.save()", "response": "Set attribute for user"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_attribute(self, code, default=None):\n        try:\n            return self.get(code=code).value\n        except models.ObjectDoesNotExist:\n            return default", "response": "Get attribute for user"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef next(self):\n        try:\n            if self.next_id:\n                return Chart(self.next_id)\n            else:\n                log.debug('attempted to get next chart, but none was found')\n                return\n        except AttributeError:\n            #chart does not implement next pointer\n            log.debug('attempted to get next chart from a chart without a next attribute')\n            return None", "response": "fetch the next chart instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef previous(self):\n        try:\n            if self.previous_id:\n                return Chart(self.previous_id)\n            else:\n                log.debug('attempted to get previous chart, but none was found')\n                return\n        except AttributeError:\n            #chart does not implement next pointer\n            log.debug('attempted to get previous chart from a chart without a previous attribute')\n            return None", "response": "get the previous chart instance"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef now(self):\n        try:\n            if self.now_id:\n                return Chart(self.now_id)\n            else:\n                log.debug('attempted to get current chart, but none was found')\n                return\n        except AttributeError:\n            #chart does not implement next pointer\n            log.debug('attempted to get current (\"now\") chart from a chart without a now attribute')\n            return None", "response": "fetch the current chart instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef initial(key, **kwarg):\n        d = dict()\n        DictTree.setattr(d, _rootname = key, **kwarg)\n        return d", "response": "Create an empty dicttree.\n            The root node has a special attribute _rootname."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset an attribute. This is a helper function for setting the _meta key to the value of the _rootname field.", "response": "def setattr(d, **kwarg):\n        \"\"\"Set an attribute.\n\n        set attributes is actually add a special key, value pair in this dict\n        under key = \"_meta\".\n\n        Usage::\n\n            >>> DT.setattr(d, population=27800000)\n            >>> d\n            {'_meta': {'population': 27800000, '_rootname': 'US'}}\n        \"\"\"\n        if _meta not in d:\n            d[_meta] = dict()\n        for k, v in kwarg.items():\n            d[_meta][k] = v"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a children with key and attributes.", "response": "def add_children(d, key, **kwarg):\n        \"\"\"Add a children with key and attributes. If children already EXISTS, \n        OVERWRITE it.\n\n        Usage::\n\n            >>> from pprint import pprint as ppt\n            >>> DT.add_children(d, \"VA\", name=\"virginia\", population=100*1000)\n            >>> DT.add_children(d, \"MD\", name=\"maryland\", population=200*1000)\n            >>> ppt(d)\n            {'_meta': {'population': 27800000, '_rootname': 'US'},\n             'MD': {'_meta': {'name': 'maryland', 'population': 200000}},\n             'VA': {'_meta': {'name': 'virginia', 'population': 100000}}}\n\n            >>> DT.add_children(d[\"VA\"], \"arlington\", \n                    name=\"arlington county\", population=5000)\n            >>> DT.add_children(d[\"VA\"], \"vienna\", \n                    name=\"vienna county\", population=5000)\n            >>> DT.add_children(d[\"MD\"], \"bethesta\", \n                    name=\"montgomery country\", population=5800)\n            >>> DT.add_children(d[\"MD\"], \"germentown\", \n                    name=\"fredrick country\", population=1400)\n\n            >>> DT.add_children(d[\"VA\"][\"arlington\"], \"riverhouse\", \n                    name=\"RiverHouse 1400\", population=437)\n            >>> DT.add_children(d[\"VA\"][\"arlington\"], \"crystal plaza\", \n                    name=\"Crystal plaza South\", population=681)\n            >>> DT.add_children(d[\"VA\"][\"arlington\"], \"loft\", \n                    name=\"loft hotel\", population=216)\n\n            >>> ppt(d)\n            {'MD': {'_meta': {'name': 'maryland', 'population': 200000},\n                    'bethesta': {'_meta': {'name': 'montgomery country',\n                                           'population': 5800}},\n                    'germentown': {'_meta': {'name': 'fredrick country',\n                                             'population': 1400}}},\n             'VA': {'_meta': {'name': 'virginia', 'population': 100000},\n                    'arlington': {'_meta': {'name': 'arlington county',\n                                            'population': 5000},\n                                  'crystal plaza': {'_meta': {'name': 'Crystal plaza South',\n                                                              'population': 681}},\n                                  'loft': {'_meta': {'name': 'loft hotel',\n                                                     'population': 216}},\n                                  'riverhouse': {'_meta': {'name': 'RiverHouse 1400',\n                                                           'population': 437}}},\n                    'vienna': {'_meta': {'name': 'vienna county', 'population': 1500}}},\n             '_meta': {'_rootname': 'US', 'population': 27800000.0}}\n        \"\"\"\n        if kwarg:\n            d[key] = {_meta: kwarg}\n        else:\n            d[key] = dict()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\naliases of self. add_children () <DictTree. add_children >. ac", "response": "def ac(d, key, **kwarg):\n        \"\"\"Alias of :meth:`self.add_children()<DictTree.add_children>`.\n        \"\"\"\n        if kwarg:\n            d[key] = {_meta: kwarg}\n        else:\n            d[key] = dict()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef kv(d):\n        return ((key, value) for key, value in iteritems(d) if key != _meta)", "response": "Equivalent to dict. kv."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef k_depth(d, depth, _counter=1):\n        if depth == 0:\n            yield d[_meta][\"_rootname\"]\n        else:\n            if _counter == depth:\n                for key in DictTree.k(d):\n                    yield key\n            else:\n                _counter += 1\n                for node in DictTree.v(d):\n                    for key in DictTree.k_depth(node, depth, _counter):\n                        yield key", "response": "Iterate keys on specific depth."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\niterate values on specific depth.", "response": "def v_depth(d, depth):\n        \"\"\"Iterate values on specific depth.\n        depth has to be greater equal than 0.\n        Usage reference see :meth:`DictTree.kv_depth()<DictTree.kv_depth>`\n        \"\"\"\n        if depth == 0:\n            yield d\n        else:\n            for node in DictTree.v(d):\n                for node1 in DictTree.v_depth(node, depth-1):\n                    yield node1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\niterating items on specific depth.", "response": "def kv_depth(d, depth, _counter=1):\n        \"\"\"Iterate items on specific depth.\n        depth has to be greater equal than 0.\n    \n        Usage::\n            \n            >>> for key, node in DictTree.kv_depth(d, 2):\n            >>>     print(key, DictTree.getattr(node, \"population\"))   \n            bethesta 5800\n            germentown 1400\n            vienna 1500\n            arlington 5000\n        \"\"\"\n        if depth == 0:\n            yield d[_meta][\"_rootname\"], d\n        else:\n            if _counter == depth:\n                for key, node in DictTree.kv(d):\n                    yield key, node\n            else:\n                _counter += 1\n                for node in DictTree.v(d):\n                    for key, node in DictTree.kv_depth(node, depth, _counter):\n                        yield key, node"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the number of nodes on specific depth.", "response": "def len_on_depth(d, depth):\n        \"\"\"Get the number of nodes on specific depth.\n        \"\"\"\n        counter = 0\n        for node in DictTree.v_depth(d, depth-1):\n            counter += DictTree.length(node)\n        return counter"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes all the nodes on specific depth in this dict", "response": "def del_depth(d, depth):\n        \"\"\"Delete all the nodes on specific depth in this dict\n        \"\"\"\n        for node in DictTree.v_depth(d, depth-1):\n            for key in [key for key in DictTree.k(node)]:\n                del node[key]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prettyprint(d):\n        print(json.dumps(d, sort_keys=True, \n                         indent=4, separators=(\",\" , \": \")))", "response": "Print dicttree in Json - like format. keys are sorted\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndisplays the node stats info on specific depth in this dict.", "response": "def stats_on_depth(d, depth):\n        \"\"\"Display the node stats info on specific depth in this dict\n        \"\"\"\n        root_nodes, leaf_nodes = 0, 0\n        for _, node in DictTree.kv_depth(d, depth):\n            if DictTree.length(node) == 0:\n                leaf_nodes += 1\n            else:\n                root_nodes += 1\n        total = root_nodes + leaf_nodes\n        print(\"On depth %s, having %s root nodes, %s leaf nodes. \"\n              \"%s nodes in total.\" % (depth, root_nodes, leaf_nodes, total))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the database name for the given model.", "response": "def db_for_read(self, model, **hints):\n        \"\"\"\n        If the app has its own database, use it for reads\n        \"\"\"\n        if model._meta.app_label in self._apps:\n            return getattr(model, '_db_alias', model._meta.app_label)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef db_for_write(self, model, **hints):\n        if model._meta.app_label in self._apps:\n            return getattr(model, '_db_alias', model._meta.app_label)\n        return None", "response": "Returns the database name for the given model."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nallows migrations to be performed on the model.", "response": "def allow_migrate(self, db, model):\n        \"\"\"\n        Make sure self._apps go to their own db\n        \"\"\"\n        if model._meta.app_label in self._apps:\n            return getattr(model, '_db_alias', model._meta.app_label) == db\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef db_for_write(self, model, **hints):\n        if model._meta.app_label in MS_apps:\n            return model._meta.app_label\n        # if is_warranty(model):\n        #     return 'warranty'\n        return None", "response": "Return the database name for the given model."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if unused packages are listed on project requirements", "response": "def check(path_dir, requirements_name='requirements.txt'):\n    '''Look for unused packages listed on project requirements'''\n    requirements = _load_requirements(requirements_name, path_dir)\n    imported_modules = _iter_modules(path_dir)\n    installed_packages = _list_installed_packages()\n\n    imported_modules.update(_excluded_imports())\n\n    diff = {lib for lib in installed_packages if lib not in imported_modules}\n    with_dependencies, _ = _list_dependencies(diff)\n    unused_dependencies = sorted([d for d in diff if d in requirements])\n\n    for unused_dependency in unused_dependencies:\n        if with_dependencies.get(unused_dependency):\n            print('    - {}'.format(unused_dependency))\n            for dependency in with_dependencies.get(unused_dependency):\n                print('\\t - {}'.format(dependency))\n        else:\n            print('    - {}'.format(unused_dependency))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a precondition check to the annotated method. The condition is passed the arguments from the annotated method. It does not need to accept all of the methods parameters. The condition is inspected to figure out which parameters to pass.", "response": "def pre(cond):\n    \"\"\"\n     Add a precondition check to the annotated method. The condition\n     is passed the arguments from the annotated method. It does not\n     need to accept all of the methods parameters. The condition\n     is inspected to figure out which parameters to pass.\n    \"\"\"\n    cond_args, cond_varargs, cond_varkw, cond_defaults = inspect.getargspec(cond)\n    source = inspect.getsource(cond).strip()\n\n    def inner(f):\n        if enabled:\n            # deal with the real function, not a wrapper\n            f = getattr(f, 'wrapped_fn', f)\n\n            # need to check if 'self' is the first arg,\n            # since @pre doesn't want the self param\n            member_function = is_member_function(f)\n\n            # need metadata for checking defaults\n            method_args, method_defaults = inspect.getargspec(f)[0::3]\n\n            def check_condition(args, kwargs):\n                cond_kwargs = {}\n\n                if method_defaults is not None and len(method_defaults) > 0 \\\n                and len(method_args) - len(method_defaults) <= len(args) < len(method_args):\n                    args += method_defaults[len(args) - len(method_args):]\n\n                # collection the args\n                for name, value in zip(cond_args, args[member_function:]):\n                    cond_kwargs[name] = value\n\n                # collect the remaining kwargs\n                for name in cond_args:\n                    if name not in cond_kwargs:\n                        cond_kwargs[name] = kwargs.get(name)\n\n                # test the precondition\n                if not cond(**cond_kwargs):\n                    # otherwise raise the exception\n                    raise AssertionError('Precondition failure, %s' % source)\n\n            # append to the rest of the preconditions attached to this method\n            if not hasattr(f, 'preconditions'):\n                f.preconditions = []\n            f.preconditions.append(check_condition)\n\n            return check(f)\n        else:\n            return f\n\n    return inner"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef post(cond):\n    source = inspect.getsource(cond).strip()\n\n    def inner(f):\n        if enabled:\n            # deal with the real function, not a wrapper\n            f = getattr(f, 'wrapped_fn', f)\n\n            def check_condition(result):\n                if not cond(result):\n                    raise AssertionError('Postcondition failure, %s' % source)\n\n            # append to the rest of the postconditions attached to this method\n            if not hasattr(f, 'postconditions'):\n                f.postconditions = []\n            f.postconditions.append(check_condition)\n\n            return check(f)\n        else:\n            return f\n\n    return inner", "response": "Decorator to add a postcondition check to the annotated method."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef takes(*type_list):\n    def inner(f):\n        if enabled:\n            # deal with the real function, not a wrapper\n            f = getattr(f, 'wrapped_fn', f)\n\n            # need to check if 'self' is the first arg,\n            # since @pre doesn't want the self param\n            member_function = is_member_function(f)\n\n            # need metadata for defaults check\n            method_args, method_defaults = inspect.getargspec(f)[0::3]\n            if member_function:\n                method_args = method_args[member_function:]\n\n            def check_condition(args, kwargs):\n                if method_defaults is not None and len(method_defaults) > 0 \\\n                and len(method_args) - len(method_defaults) <= len(args) < len(method_args):\n                    args += method_defaults[len(args) - len(method_args):]\n\n                for i, (arg, t) in enumerate(zip(args[member_function:], type_list)):\n                    method_arg = method_args[i]\n                    if method_arg not in kwargs and not check_type(t, arg):\n                        raise AssertionError('Precondition failure, wrong type for argument')\n\n                for kwarg in kwargs:\n                    arg_position = method_args.index(kwarg)\n                    if arg_position < len(type_list):\n                        t = type_list[arg_position]\n                        if not check_type(t, kwargs.get(kwarg)):\n                            raise AssertionError('Precondition failure, wrong type for argument %s' % kwarg)\n\n            # append to the rest of the postconditions attached to this method\n            if not hasattr(f, 'preconditions'):\n                f.preconditions = []\n            f.preconditions.append(check_condition)\n\n            return check(f)\n        else:\n            return f\n\n    return inner", "response": "Decorator for determining the type of the parameter in a node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check(f):\n    if hasattr(f, 'wrapped_fn'):\n        return f\n    else:\n        @wraps(f)\n        def decorated(*args, **kwargs):\n            return check_conditions(f, args, kwargs)\n        decorated.wrapped_fn = f\n        return decorated", "response": "Decorator that runs all of the the\n    pre and post conditions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_conditions(f, args, kwargs):\n    member_function = is_member_function(f)\n\n    # check the functions direct pre conditions\n    check_preconditions(f, args, kwargs)\n\n    # for member functions check the pre conditions up the chain\n    base_classes = []\n    if member_function:\n        base_classes = inspect.getmro(type(args[0]))[1:-1]\n        for clz in base_classes:\n            super_fn = getattr(clz, f.func_name, None)\n            check_preconditions(super_fn, args, kwargs)\n\n    # run the real function\n    return_value = f(*args, **kwargs)\n\n    # check the functions direct post conditions\n    check_postconditions(f, return_value)\n\n    # for member functions check the post conditions up the chain\n    if member_function:\n        for clz in base_classes:\n            super_fn = getattr(clz, f.func_name, None)\n            check_postconditions(super_fn, return_value)\n\n    return return_value", "response": "This is the main function that checks the conditions on the chain and returns the return value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_preconditions(f, args, kwargs):\n    f = getattr(f, 'wrapped_fn', f)\n    if f and hasattr(f, 'preconditions'):\n        for cond in f.preconditions:\n            cond(args, kwargs)", "response": "Runs all of the preconditions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun all of the postconditions.", "response": "def check_postconditions(f, return_value):\n    \"\"\" Runs all of the postconditions. \"\"\"\n    f = getattr(f, 'wrapped_fn', f)\n    if f and hasattr(f, 'postconditions'):\n        for cond in f.postconditions:\n            cond(return_value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the first argument to the method is self.", "response": "def is_member_function(f):\n    \"\"\" Checks if the first argument to the method is 'self'. \"\"\"\n    f_args, f_varargs, f_varkw, f_defaults = inspect.getargspec(f)\n    return 1 if 'self' in f_args else 0"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_of(cls):\n    return lambda l: isinstance(l, list) and all(isinstance(x, cls) for x in l)", "response": "Returns a function that checks that each element in a list is of a specific type."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_of(cls):\n    return lambda l: isinstance(l, set) and all(isinstance(x, cls) for x in l)", "response": "Returns a function that checks that each element in a sequence is of a specific type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef swallow_stdout(stream=None):\n    saved = sys.stdout\n    if stream is None:\n        stream = StringIO()\n    sys.stdout = stream\n    try:\n        yield\n    finally:\n        sys.stdout = saved", "response": "Divert stdout into the given stream."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread an SJ. out. tab file as produced by the RNA - STAR aligner into a pandas Dataframe.", "response": "def read_sj_out_tab(filename):\n    \"\"\"Read an SJ.out.tab file as produced by the RNA-STAR aligner into a\n    pandas Dataframe.\n\n    Parameters\n    ----------\n    filename : str of filename or file handle\n        Filename of the SJ.out.tab file you want to read in\n\n    Returns\n    -------\n    sj : pandas.DataFrame\n        Dataframe of splice junctions\n\n    \"\"\"\n    def int_to_intron_motif(n):\n        if n == 0:\n            return 'non-canonical'\n        if n == 1:\n            return 'GT/AG'\n        if n == 2:\n            return 'CT/AC'\n        if n == 3:\n            return 'GC/AG'\n        if n == 4:\n            return 'CT/GC'\n        if n == 5:\n            return 'AT/AC'\n        if n == 6:\n            return 'GT/AT'\n\n    sj = pd.read_table(filename, header=None, names=COLUMN_NAMES,\n                       low_memory=False)\n    sj.intron_motif = sj.intron_motif.map(int_to_intron_motif)\n    sj.annotated = sj.annotated.map(bool)\n    sj.strand.astype('object')\n    sj.strand = sj.strand.apply(lambda x: ['unk','+','-'][x])\n    # See https://groups.google.com/d/msg/rna-star/B0Y4oH8ZSOY/NO4OJbbUU4cJ for\n    # definition of strand in SJout files.\n    sj = sj.sort_values(by=['chrom', 'start', 'end'])\n    return sj"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread multiple sj_outs and return a dict with keys as sample names and values as sj_out dataframes.", "response": "def _make_sj_out_dict(fns, jxns=None, define_sample_name=None):\n    \"\"\"Read multiple sj_outs, return dict with keys as sample names and values\n    as sj_out dataframes.\n\n    Parameters\n    ----------\n    fns : list of strs of filenames or file handles\n        List of filename of the SJ.out.tab files to read in\n\n    jxns : set\n        If provided, only keep junctions in this set.\n\n    define_sample_name : function that takes string as input\n        Function mapping filename to sample name. For instance, you may have the\n        sample name in the path and use a regex to extract it.  The sample names\n        will be used as the column names. If this is not provided, the columns\n        will be named as the input files.\n\n    Returns\n    -------\n    sj_outD : dict\n        Dict whose keys are sample names and values are sj_out dataframes\n    \n    \"\"\"\n    if define_sample_name == None:\n        define_sample_name = lambda x: x\n    else:\n        assert len(set([define_sample_name(x) for x in fns])) == len(fns)\n    sj_outD = dict()\n\n    for fn in fns:\n        sample = define_sample_name(fn)\n        df = read_sj_out_tab(fn)\n        # Remove any junctions that don't have any uniquely mapped junction\n        # reads.  Even if a junction passes the cutoff in other samples, we are\n        # only concerned with unique counts.\n        df = df[df.unique_junction_reads > 0]\n        index = (df.chrom + ':' + df.start.astype(str) + '-' \n                 +  df.end.astype(str))\n        assert len(index) == len(set(index))\n        df.index = index\n        # If jxns is provided, only keep those.\n        if jxns:\n            df = df.ix[set(df.index) & jxns]\n        sj_outD[sample] = df\n\n    return sj_outD"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfilters junctions from many sj_out files and make a panel of sj_out files.", "response": "def _make_sj_out_panel(sj_outD, total_jxn_cov_cutoff=20):\n    \"\"\"Filter junctions from many sj_out files and make panel.\n\n    Parameters\n    ----------\n    sj_outD : dict\n        Dict whose keys are sample names and values are sj_out dataframes\n\n    total_jxn_cov_cutoff : int\n        If the unique read coverage of a junction summed over all samples is not\n        greater than or equal to this value, the junction will not be included\n        in the final output.\n\n    Returns\n    -------\n    sj_outP : pandas.Panel\n        Panel where each dataframe corresponds to an sj_out file filtered to\n        remove low coverage junctions. Each dataframe has COUNT_COLS =\n        ('unique_junction_reads', 'multimap_junction_reads', 'max_overhang')\n\n    annotDF : pandas.DataFrame\n        Dataframe with values ANNOTATION_COLS = ('chrom', 'start', \n        'end', 'intron_motif', 'annotated') that are otherwise\n        duplicated in the panel.\n    \n    \"\"\"\n    # num_jxns = dict()\n    # # set of all junctions\n    # jxnS = reduce(lambda x,y: set(x) | set(y),\n    #               [ sj_outD[k].index for k in sj_outD.keys() ])\n\n    # jxn_keepS = set()\n    # jxn_setsD = dict()\n    # for k in sj_outD.keys():\n    #     jxn_setsD[k] = frozenset(sj_outD[k].index)\n    # for j in jxnS:\n    #     if sum([ sj_outD[k].ix[j,'unique_junction_reads'] for k in sj_outD.keys()\n    #              if j in jxn_setsD[k] ]) >= total_jxn_cov_cutoff:\n    #         jxn_keepS.add(j)\n\n    # for k in sj_outD.keys():\n    #     sj_outD[k] = sj_outD[k].ix[jxn_keepS]\n\n    sj_outP = pd.Panel(sj_outD)\n    for col in ['unique_junction_reads', 'multimap_junction_reads',\n                'max_overhang']:\n        sj_outP.ix[:,:,col] = sj_outP.ix[:,:,col].fillna(0)\n\n    # Some dataframes will be missing information like intron_motif etc. for \n    # junctions that were not observed in that sample. The info is somewhere in\n    # the panel though so we can get it.\n    annotDF = reduce(pd.DataFrame.combine_first,\n                     [ sj_outP.ix[item,:,ANNOTATION_COLS].dropna() for item in\n                      sj_outP.items ])\n    annotDF['start'] = annotDF['start'].astype(int)\n    annotDF['end'] = annotDF['end'].astype(int)\n    annotDF['annotated'] = annotDF['annotated'].astype(bool)\n    # Sort annotation and panel\n    annotDF = annotDF.sort_values(by=['chrom', 'start', 'end'])\n    sj_outP = sj_outP.ix[:, annotDF.index, :]\n\n    sj_outP = sj_outP.ix[:,:,COUNT_COLS].astype(int)\n\n    return sj_outP, annotDF"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread external annotation file and return a DataFrame indexed by splice junctions.", "response": "def read_external_annotation(fn):\n    \"\"\"Read file with junctions from some database. This does not have to be the\n    same splice junction database used with STAR.\n\n    Parameters\n    ----------\n    fn : filename str\n        File with splice junctions from annotation. The file should have a\n        header and contain the following columns: 'gene', 'chrom', 'start',\n        'end', 'strand', 'chrom:start', 'chrom:end', 'donor', 'acceptor', \n        'intron'.\n\n    Returns\n    -------\n    extDF : pandas.DataFrame\n        DataFrame indexed by splice junction\n\n    stats : list of strings\n        Human readable statistics about the external database.\n    \n    \"\"\"\n    assert os.path.exists(fn)\n    extDF = pd.read_table(fn, index_col=0, header=0)\n    total_num = extDF.shape[0]\n    \n    # In rare cases, a splice junction might be used by more than one gene. For\n    # my purposes, these cases are confounding, so I will remove all such splice\n    # junctions. \n    intron_count = extDF.intron.value_counts()\n    extDF['intron_count'] = extDF.intron.apply(lambda x: intron_count.ix[x])\n    extDF = extDF[extDF.intron_count == 1]\n    extDF = extDF.drop('intron_count', axis=1)\n\n    stats = []\n    stats.append('External database stats')\n    stats.append('Read external annotation\\t{}'.format(fn))\n    stats.append('Total number of junctions\\t{:,}'.format(total_num))\n    stats.append(('Number of junctions used in only one '\n                  'gene\\t{:,}').format(extDF.shape[0]))\n\n    return extDF, stats"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _filter_jxns_donor_acceptor(sj_outP, annotDF, extDF):\n    import re\n\n    sjRE = re.compile('(.*:.*-.*):(\\+|-)')\n    juncRE = re.compile('(.*):(\\d*)-(\\d*):') \n    \n    # Add column showing whether junction is in external annotation.\n    annotDF = copy.deepcopy(annotDF)\n    annotDF['ext_annotated'] = False\n    annotDF.ix[set(annotDF.index) & set(extDF.intron),\n               'ext_annotated'] = True\n    \n    # Replace strand information from STAR with strand information from external\n    # database.\n    strandSE = pd.Series(extDF.strand.values,index=extDF.intron)\n    strandSE = strandSE[set(strandSE.index) & set(annotDF.index)]\n    annotDF['strand'] = '*'\n    annotDF.ix[strandSE.index,'strand'] = strandSE.values\n\n    # Add column for start and end location (chromosome plus position for\n    # uniqueness).\n    annotDF['chrom:start'] = (annotDF.chrom + ':' + \n                              annotDF.start.astype(int).astype(str))\n    annotDF['chrom:end'] = (annotDF.chrom + ':' +\n                            annotDF.end.astype(int).astype(str))\n\n    ext_startS = set(extDF['chrom:start'].values)\n    ext_endS = set(extDF['chrom:end'].values)\n\n    # Remove junctions that don't have a start or end shared with external\n    # database.\n    tdf = pd.DataFrame(True, columns=['temp_start_in_ext'], index=ext_startS)\n    annotDF = annotDF.merge(tdf, left_on='chrom:start', right_index=True,\n                            how='left')\n    tdf = pd.DataFrame(True, columns=['temp_end_in_ext'], index=ext_endS)\n    annotDF = annotDF.merge(tdf, left_on='chrom:end', right_index=True,\n                            how='left')\n    junctions_to_remove = annotDF[(annotDF.ext_annotated == False) &\n                                  (annotDF.temp_start_in_ext.isnull()) &\n                                  (annotDF.temp_end_in_ext.isnull())].index\n\n    #junctions_to_removeSE = annotDF[annotDF.ext_annotated == False].apply(\n    #    lambda x: (x['chrom:start'] in ext_startS) + \n    #    (x['chrom:end'] in ext_endS) == 0,axis=1)\n    if len(junctions_to_remove) > 0:\n        annotDF = annotDF.drop(junctions_to_remove)\n\n    # Add column indicating which gene the junctions belong to for annotated\n    # jxn's.\n    geneSE = pd.Series(dict(zip(extDF.intron.values,extDF.gene)))\n    annotDF['gene_id'] = ''\n    annotDF['gene_id'] = geneSE[annotDF.index]\n\n    # Now we'll figure out the genes for the junctions that aren't in our\n    # database. We can associate each start and end with a gene and use this.\n    start_gene = dict(zip(extDF['chrom:start'], extDF.gene))\n    end_gene = dict(zip(extDF['chrom:end'], extDF.gene))\n    \n    genes = []\n    for ind in annotDF[annotDF.ext_annotated == False].index:\n        cur_start = annotDF.ix[ind,'chrom:start'] \n        cur_end = annotDF.ix[ind,'chrom:end'] \n        gene = start_gene.get(cur_start, '')\n        if gene == '':\n            gene = end_gene.get(cur_end, '')\n        genes.append(gene)\n    annotDF.ix[annotDF.ext_annotated == False, 'gene_id'] = genes\n\n    # We can use the genes to assign strand to the novel splice junctions.\n    strandSE = pd.Series(dict(zip(extDF.gene,extDF.strand)))\n    ind = annotDF[annotDF.ext_annotated == False].index\n    annotDF.ix[ind, 'strand'] = strandSE[annotDF.ix[ind, 'gene_id']].values\n\n    # And re-index with the strand info.\n    annotDF.index = [ x + ':' + annotDF.ix[x,'strand'] for x in annotDF.index ]\n\n    # Now we'll add donor and acceptor info.\n    pos_ind = annotDF[annotDF.strand == '+'].index\n    neg_ind = annotDF[annotDF.strand == '-'].index\n    annotDF.ix[pos_ind, 'donor'] = (annotDF.ix[pos_ind, 'chrom'] + ':' + \n                                    annotDF.ix[pos_ind, 'start'].astype(str) + \n                                    ':' +  annotDF.ix[pos_ind, 'strand'])\n    annotDF.ix[pos_ind, 'acceptor'] = (annotDF.ix[pos_ind, 'chrom'] + ':' + \n                                       annotDF.ix[pos_ind, 'end'].astype(str) \n                                       + ':' + annotDF.ix[pos_ind, 'strand'])\n    annotDF.ix[neg_ind, 'acceptor'] = (annotDF.ix[neg_ind, 'chrom'] + ':' + \n                                       annotDF.ix[neg_ind, 'start'].astype(str) \n                                       + ':' + annotDF.ix[neg_ind, 'strand'])\n    annotDF.ix[neg_ind, 'donor'] = (annotDF.ix[neg_ind, 'chrom'] + ':' + \n                                    annotDF.ix[neg_ind, 'end'].astype(str) + \n                                    ':' + annotDF.ix[neg_ind, 'strand'])\n\n    # And whether the donor or acceptor is in the external database or not.\n    ext_donor = pd.DataFrame(False, index=list(set(extDF.donor)),\n                             columns=['novel_donor'])\n    ext_acceptor = pd.DataFrame(False, index=list(set(extDF.acceptor)),\n                                columns=['novel_acceptor'])\n    annotDF = annotDF.merge(ext_donor, left_on='donor', right_index=True,\n                            how='left')\n    annotDF.ix[annotDF.novel_donor.isnull(), 'novel_donor'] = True\n    annotDF = annotDF.merge(ext_acceptor, left_on='acceptor', right_index=True,\n                            how='left')\n    annotDF.ix[annotDF.novel_acceptor.isnull(), 'novel_acceptor'] = True\n\n    # ext_donorS = frozenset(extDF.donor)\n    # ext_acceptorS = frozenset(extDF.acceptor)\n    # annotDF['novel_donor'] = False\n    # annotDF['novel_acceptor'] = False\n    # ind = annotDF[annotDF.ext_annotated == False].index\n    # if len(ind) > 0:\n    #     novel_donor = []\n    #     novel_acceptor = []\n    #     for i in ind:\n    #         novel_donor.append(annotDF.ix[i, 'donor'] not in ext_donorS)\n    #         novel_acceptor.append(annotDF.ix[i, 'acceptor'] not in ext_acceptorS)\n    #     annotDF.ix[ind, 'novel_donor'] = novel_donor\n    #     annotDF.ix[ind, 'novel_acceptor'] = novel_acceptor\n\n    # Sort by gene ID and start/end.\n    annotDF = annotDF.sort_values(by=['gene_id', 'start', 'end'])\n\n    # Make file with counts for the junctions we are interested in.\n    L = [ juncRE.match(x).group().strip(':') for x in annotDF.index ]\n    countDF = sj_outP.ix[:, L, 'unique_junction_reads']\n    countDF.index = annotDF.index\n\n    stats = []\n    t = extDF.shape[0]\n    stats.append('Junction filtering stats')\n    stats.append(('Number of junctions in external '\n                  'annotation\\t{0:,}').format(t))\n\n    t = annotDF.annotated.sum()\n    stats.append(('Number observed junctions in STAR '\n                  'annotation\\t{0:,}').format(t))\n\n    t = annotDF.ext_annotated.sum()\n    stats.append(('Number observed junctions in external '\n                  'annotation\\t{0:,}').format(t))\n\n    t = annotDF.shape[0] - annotDF.ext_annotated.sum()\n    stats.append(('Number of observed junctions not in external '\n                  'annotation\\t{0:,}').format(t))\n\n    t = annotDF.ix[annotDF.ext_annotated == False,'annotated'].sum()\n    stats.append(('Number of observed junctions not in external annotation but '\n                  'in STAR annotation\\t{0:,}').format(t))\n\n    t = sum(annotDF.ix[annotDF.ext_annotated == False,'annotated'].values == 0)\n    stats.append(('Number of observed junctions not in external annotation and '\n                  'not in STAR annotation\\t{0:,}').format(t))\n  \n    t = len(set(annotDF.ix[annotDF.novel_donor, 'donor']))\n    stats.append(('Number of novel donors\\t{0:,}').format(t))\n\n    t = annotDF.novel_donor.sum()\n    stats.append(('Number of novel junctions with novel '\n                  'donors\\t{0:,}').format(t))\n\n    t = len(set(annotDF.ix[annotDF.novel_acceptor, 'acceptor']))\n    stats.append(('Number of novel acceptors\\t{0:,}').format(t))\n\n    t = annotDF.novel_acceptor.sum()\n    stats.append(('Number of novel junctions with novel '\n                  'acceptors\\t{0:,}').format(t))\n\n    t = (annotDF[annotDF.ext_annotated == False].shape[0] - \n         sum(annotDF.novel_donor) - \n         sum(annotDF.novel_acceptor))\n    stats.append(('Number of novel junctions with new combination of donor and '\n                  'acceptor\\t{0:,}').format(t))\n    return countDF, annotDF, stats", "response": "Filter out junctions that do not use an annotated donor or acceptor according to external annoation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef combine_sj_out(\n    fns, \n    external_db, \n    total_jxn_cov_cutoff=20, \n    define_sample_name=None,\n    verbose=False,\n):\n    \"\"\"Combine SJ.out.tab files from STAR by filtering based on coverage and\n    comparing to an external annotation to discover novel junctions.\n\n    Parameters\n    ----------\n    fns : list of strings \n        Filenames of SJ.out.tab files to combine.\n\n    external_db : str\n        Filename of splice junction information from external database. The file\n        should have a header and contained the following columns  'gene',\n        'chrom', 'start', 'end', 'strand', 'chrom:start', 'chrom:end', 'donor',\n        'acceptor', 'intron'.\n\n    total_jxn_cov_cutoff : int\n        Discard junctions with less than this many reads summed over all\n        samples.\n\n    define_sample_name : function\n        A function mapping the SJ.out.tab filenames to sample names.\n\n    Returns\n    -------\n    countDF :  pandas.DataFrame\n        Number of unique junction spanning reads for each junction that passed\n        filtering criteria.\n\n    annotDF : pandas.DataFrame\n        Annotation information for junctions that passed filtering criteria.\n\n    stats : list of strings\n        Human readable statistics.\n    \n    \"\"\"\n    if verbose:\n        import sys\n    # I'll start by figuring out which junctions we will keep.\n    counts = _total_jxn_counts(fns) \n    jxns = set(counts[counts >= total_jxn_cov_cutoff].index)\n    if verbose:\n        sys.stderr.write('Counting done\\n')\n\n    stats = []\n    sj_outD = _make_sj_out_dict(fns, jxns=jxns,\n                                define_sample_name=define_sample_name)\n    stats.append('Number of junctions in SJ.out file per sample')\n    for k in sj_outD.keys():\n        stats.append('{0}\\t{1:,}'.format(k, sj_outD[k].shape[0]))\n    stats.append('')\n    if verbose:\n        sys.stderr.write('Dict done\\n')\n\n    sj_outP, annotDF = _make_sj_out_panel(sj_outD, total_jxn_cov_cutoff)\n    stats.append('SJ.out panel size\\t{0}'.format(sj_outP.shape))\n    stats.append('')\n    if verbose:\n        sys.stderr.write('Panel done\\n')\n\n    extDF, ext_stats = read_external_annotation(external_db)\n    stats += ext_stats\n    stats.append('')\n    if verbose:\n        sys.stderr.write('DB read done\\n')\n\n    countsDF, annotDF, filter_stats = _filter_jxns_donor_acceptor(sj_outP, \n                                                                  annotDF, \n                                                                  extDF)\n    if verbose:\n        sys.stderr.write('Filter done\\n')\n\n    annotDF = _find_novel_donor_acceptor_dist(annotDF, extDF)\n    if verbose:\n        sys.stderr.write('Dist done\\n')\n\n    stats += filter_stats\n    return countsDF, annotDF, stats", "response": "Combine the SJ. out. tab files from STAR by filtering based on coverage and an external annotation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _total_jxn_counts(fns):\n    df = pd.read_table(fns[0], header=None, names=COLUMN_NAMES)\n    df.index = (df.chrom + ':' + df.start.astype(int).astype(str) + '-' +\n                df.end.astype(int).astype(str))\n    counts = df.unique_junction_reads\n    for fn in fns[1:]:\n        df = pd.read_table(fn, header=None, names=COLUMN_NAMES)\n        df.index = (df.chrom + ':' + df.start.astype(int).astype(str) + '-' +\n                    df.end.astype(int).astype(str))\n        counts = counts.add(df.unique_junction_reads, fill_value=0)\n    return counts", "response": "Count the total unique coverage junction for junctions in a set of\n    SJ. out. tab files."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _make_splice_targets_dict(df, feature, strand):\n    g = df[df.strand == strand].groupby(feature)\n    d = dict()\n    if strand == '+':\n        if feature == 'donor':\n            target = 'end'\n        if feature == 'acceptor':\n            target = 'start'\n    if strand == '-':\n        if feature == 'donor':\n            target = 'start'\n        if feature == 'acceptor':\n            target = 'end'\n\n    for k in g.groups.keys():\n        d[k] = np.array(list(set(df.ix[g.groups[k], target])))\n        d[k].sort()\n    return d", "response": "Make a dict mapping each donor to the location of all acceptors it splices from or each acceptor to all donors it splices from."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _find_novel_donor_acceptor_dist(annot, ext):\n    pos_donor_to_acceptors = _make_splice_targets_dict(ext, 'donor', '+')\n    pos_acceptor_to_donors = _make_splice_targets_dict(ext, 'acceptor', '+')\n    neg_donor_to_acceptors = _make_splice_targets_dict(ext, 'donor', '-')\n    neg_acceptor_to_donors = _make_splice_targets_dict(ext, 'acceptor', '-')\n\n    annot = copy.deepcopy(annot)\n    annot['upstream_donor_dist'] = np.nan\n    annot['downstream_donor_dist'] = np.nan\n    annot['upstream_acceptor_dist'] = np.nan\n    annot['downstream_acceptor_dist'] = np.nan\n\n    juncs = annot[annot.novel_donor & (annot.strand == '+')].index\n    up, down = _dist_to_annot_donor_acceptor(annot.ix[juncs], \n                                             pos_acceptor_to_donors,\n                                             '+', \n                                             'donor')\n    annot.ix[juncs, 'upstream_donor_dist'] = up\n    annot.ix[juncs, 'downstream_donor_dist'] = down\n\n    juncs = annot[annot.novel_donor & (annot.strand == '-')].index\n    up, down = _dist_to_annot_donor_acceptor(annot.ix[juncs], \n                                             neg_acceptor_to_donors,\n                                             '-', \n                                             'donor')\n    annot.ix[juncs, 'upstream_donor_dist'] = up\n    annot.ix[juncs, 'downstream_donor_dist'] = down\n\n    juncs = annot[annot.novel_acceptor & (annot.strand == '+')].index\n    up, down = _dist_to_annot_donor_acceptor(annot.ix[juncs], \n                                             pos_donor_to_acceptors, \n                                             '+', \n                                             'acceptor')\n    annot.ix[juncs, 'upstream_acceptor_dist'] = up\n    annot.ix[juncs, 'downstream_acceptor_dist'] = down\n\n    juncs = annot[annot.novel_acceptor & (annot.strand == '-')].index\n    up, down = _dist_to_annot_donor_acceptor(annot.ix[juncs], \n                                             neg_donor_to_acceptors, \n                                             '-', \n                                             'acceptor')\n    annot.ix[juncs, 'upstream_acceptor_dist'] = up\n    annot.ix[juncs, 'downstream_acceptor_dist'] = down\n    return annot", "response": "Find nearest annotated upstream donor or upstream acceptor for novel logo and external donor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind nearest annotated upstream and downstream donor or acceptor for a given novel feature.", "response": "def _dist_to_annot_donor_acceptor(df, d, strand, novel_feature):\n    \"\"\"Find nearest annotated upstream/downstream donor/acceptor for novel\n    donor/acceptors.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        Dataframe with observed splice junctions (novel and known) with columns\n        'chrom', 'first_bp_intron', 'last_bp_intron', 'strand', 'intron_motif',\n        'annotated', 'ext_annotated', 'chrom:start', 'chrom:end', 'gene_id',\n        'donor', 'acceptor', 'novel_donor', 'novel_acceptor'.\n\n    d : dict\n        If df contains novel donors, should be a dict whose keys are acceptors\n        and whose values are the locations (integers) of all associated donors.\n        If df contains novel acceptors, should be a dict whose keys are donors\n        and whose values are the locations (integers) of all associated\n        accepators.\n\n    strand : str ('+' or '-')\n        Strand that features are on.\n\n    novel_feature : str ('donor' or 'acceptor')\n        Whether the dataframe contains novel donors or novel acceptors.\n\n    Returns\n    -------\n    up : list\n        List of distances from novel feature to nearest feature (of same type)\n        upstream. If upstream feature does not exist, the list will have a nan.\n\n    down : list\n        List of distances from novel feature to nearest feature (of same type)\n        downstream. If upstream feature does not exist, the list will have a \n        nan.\n    \n    \"\"\"\n    if df.shape[0] > 0:\n        assert len(set(df.strand)) == 1\n    if novel_feature == 'donor':\n        assert df.novel_donor.sum() == df.shape[0]\n    if novel_feature == 'acceptor':\n        assert df.novel_acceptor.sum() == df.shape[0]\n    # For a novel donor, we want to return the distance to the nearest upstream\n    # and downstream donors that use the same acceptor. For a novel acceptor, we\n    # want to return the distance to the nearest upstream and downstream\n    # acceptors that use the same donor. In some cases there may not be one of\n    # the upstream or downstream donors/acceptors. In that case we will just\n    # return nan.\n    if strand == '+':\n        if novel_feature == 'donor':\n            annot_feature = 'acceptor'\n            novel_location = 'start'\n        if novel_feature == 'acceptor':\n            annot_feature = 'donor'\n            novel_location = 'end'\n    if strand == '-':\n        if novel_feature == 'donor':\n            annot_feature = 'acceptor'\n            novel_location = 'end' \n        if novel_feature == 'acceptor':\n            annot_feature = 'donor'\n            novel_location = 'start'\n\n    upstream_dists = []\n    downstream_dists = []\n    \n    for i in df.index:\n        a = df.ix[i, annot_feature]\n        diff = df.ix[i, novel_location] - d[a]\n        pos = diff[diff > 0]\n        neg = diff[diff < 0]\n        if strand == '+':\n            if pos.shape[0] == 0:\n                upstream_dists.append(np.nan)\n            else:\n                upstream_dists.append(pos.min())\n            if neg.shape[0] == 0:\n                downstream_dists.append(np.nan)\n            else:\n                downstream_dists.append(np.abs(neg).min())\n        if strand == '-':\n            if pos.shape[0] == 0:\n                downstream_dists.append(np.nan)\n            else:\n                downstream_dists.append(pos.min())\n            if neg.shape[0] == 0:\n                upstream_dists.append(np.nan)\n            else:\n                upstream_dists.append(np.abs(neg).min())\n    return upstream_dists, downstream_dists"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_log(fn, define_sample_name=None):\n    if define_sample_name == None:\n        define_sample_name = lambda x: x\n    df = pd.read_table(fn, '|', header=None).dropna()\n    df.index = df.ix[:,0].apply(lambda x: x.strip())\n    df = pd.DataFrame(df.ix[:,1].apply(lambda x: x.strip()))\n    if define_sample_name:\n        df.columns = [define_sample_name(fn)]\n    else:\n        df.columns = [fn]\n    return df", "response": "Read STAR Log. final. out file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes pandas DataFrame from multiple STAR Log. final. out files.", "response": "def make_logs_df(fns, define_sample_name=None):\n    \"\"\"Make pandas DataFrame from multiple STAR Log.final.out files.\n\n    Parameters\n    ----------\n    fns : string\n        List of paths to Log.final.out files.\n\n    define_sample_name : function that takes string as input\n        Function mapping filename to sample name. For instance, you may have the\n        sample name in the path and use a regex to extract it.  The sample names\n        will be used as the column names. If this is not provided, the columns\n        will be named as the input files.\n\n    Returns\n    -------\n    df : pandas.DataFrame\n        DataFrame with info from log file.\n\n    \"\"\"\n    dfs = []\n    for fn in fns:\n        dfs.append(_read_log(fn, \n                             define_sample_name=define_sample_name))\n    df = pd.concat(dfs,axis=1)\n    df = df.T\n    for label in [\n            'Mapping speed, Million of reads per hour',\n            'Number of input reads',\n            'Average input read length',\n            'Uniquely mapped reads number',\n            'Average mapped length',\n            'Number of splices: Total',\n            'Number of splices: GT/AG',\n            'Number of splices: GC/AG',\n            'Number of splices: AT/AC',\n            'Number of splices: Non-canonical',\n            'Number of reads mapped to multiple loci',\n            'Number of reads mapped to too many loci']:\n        df[label] = df[label].astype(float)\n\n    for label in [\n        'Uniquely mapped reads %',\n        'Mismatch rate per base, %',\n        'Deletion rate per base',\n        'Insertion rate per base',\n        '% of reads mapped to multiple loci',\n        '% of reads mapped to too many loci',\n        '% of reads unmapped: too many mismatches',\n        '% of reads unmapped: too short',\n        '% of reads unmapped: other']:\n        df[label] = df[label].apply(lambda x: x.strip('%')).astype(float)\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncall when data is received from the socket.", "response": "def data_received(self, data: bytes) -> None:\n        \"\"\"\n        socket \u6536\u5230\u6570\u636e\n        \"\"\"\n        # print(data)\n        if self._request is None:\n            # future = self._loop.create_future()\n            self._request = Request(\n                cast(asyncio.AbstractEventLoop, self._loop),\n                self.complete_handle,\n                cast(asyncio.Transport, self._transport),\n                charset=self._requset_charset,\n            )\n            self._request.parser = HttpRequestParser(self._request)\n        self._request.feed_data(data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef complete_handle(self) -> Generator[Any, None, None]:\n        if self._request is None:\n            return\n        self._response = Response(\n            self._loop,\n            cast(asyncio.Transport, self._transport),\n            self._request.version or DEFAULT_HTTP_VERSION,\n            self._response_charset,\n        )\n        keep_alive = self._request.should_keep_alive\n        if not keep_alive:\n            self._response.set(\"Connection\", \"close\")\n        yield from self._handle(self._request, self._response)\n        if not keep_alive and self._transport is not None:\n            self._transport.close()\n        # self._request_parser = None\n        self._request = None\n        self._response = None", "response": "Complete the HTTP request."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef uptime():\n    from datetime import timedelta\n\n    with open('/proc/uptime', 'r') as f:\n        uptime_seconds = float(f.readline().split()[0])\n        uptime_string = str(timedelta(seconds=uptime_seconds))\n\n    bob.says(uptime_string)", "response": "Uptime of the host machine"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntransforming a python variable to the appropriate representation in SQL", "response": "def value_to_sql_str(v):\n    \"\"\"\n    transform a python variable to the appropriate representation in SQL\n    \"\"\"\n    if v is None:\n        return 'null'\n\n    if type(v) in (types.IntType, types.FloatType, types.LongType):\n        return str(v)\n\n    if type(v) in (types.StringType, types.UnicodeType):\n        return \"'%s'\" %(v.replace(u\"'\", u\"\\\\'\"))\n\n    if isinstance(v, datetime):\n        return \"'%s'\" %(v.strftime(\"%Y-%m-%d %H:%M:%S\"))\n\n    if isinstance(v, date):\n        return \"'%s'\" %(v.strftime(\"%Y-%m-%d\"))\n\n    return str(v)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_component_tarball(bucket, comp_name, comp_config):\n    values = {\n            'name': comp_name,\n            'version': comp_config['version'],\n            'platform': comp_config['platform'],\n            }\n    template = comp_config.get('archive_template')\n    if template:\n        key_name = template % values\n    else:\n        key_name = '%(name)s/%(name)s-%(version)s.tar.gz' % values\n    if not bucket.get_key(key_name):\n        log.error('%s not found' % key_name)\n        return False\n    return True", "response": "Returns True if the component tarball is found in the bucket otherwise returns False."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_bangrc():\n    raw = read_raw_bangrc()\n    return dict((k, raw[k]) for k in raw if k in RC_KEYS)", "response": "Parses the. bangrc file and returns a dictionary containing the current configuration attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nresolving a config_spec to a full path to a config file.", "response": "def resolve_config_spec(config_spec, config_dir=''):\n    \"\"\"\n    Resolves :attr:`config_spec` to a path to a config file.\n\n    :param str config_spec:  Valid config specs:\n\n        - The basename of a YAML config file *without* the ``.yml`` extension.\n          The full path to the config file is resolved by appending ``.yml`` to\n          the basename, then by searching for the result in the\n          :attr:`config_dir`.\n\n        - The path to a YAML config file.  The path may be absolute or may be\n          relative to the current working directory.  If :attr:`config_spec`\n          contains a ``/`` (forward slash), or if it ends in ``.yml``, it is\n          treated as a path.\n\n    :param str config_dir:  The directory in which to search for stack\n        configuration files.\n\n    :rtype:  :class:`str`\n\n    \"\"\"\n    if '/' in config_spec or config_spec.endswith('.yml'):\n        return config_spec\n    return os.path.join(config_dir, '%s.yml' % config_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nalternates constructor that merges config attributes from ``$HOME/.bangrc`` and :attr:`config_specs` into a single :class:`Config` object. The first (and potentially *only* spec) in :attr:`config_specs` should be main configuration file for the stack to be deployed. The returned object's :attr:`filepath` will be set to the absolute path of the first config file. If multiple config specs are supplied, their values are merged together in the order specified in :attr:`config_specs` - That is, later values override earlier values. :param config_specs: List of config specs. :type config_specs: :class:`list` of :class:`str` :param bool prepare: Flag to control whether or not :meth:`prepare` is called automatically before returning the object. :rtype: :class:`Config`", "response": "def from_config_specs(cls, config_specs, prepare=True):\n        \"\"\"\n        Alternate constructor that merges config attributes from\n        ``$HOME/.bangrc`` and :attr:`config_specs` into a single\n        :class:`Config` object.\n\n        The first (and potentially *only* spec) in :attr:`config_specs` should\n        be main configuration file for the stack to be deployed.  The returned\n        object's :attr:`filepath` will be set to the absolute path of the first\n        config file.\n\n        If multiple config specs are supplied, their values are merged together\n        in the order specified in :attr:`config_specs` - That is, later values\n        override earlier values.\n\n        :param config_specs:  List of config specs.\n        :type config_specs:  :class:`list` of :class:`str`\n\n        :param bool prepare:  Flag to control whether or not :meth:`prepare` is\n            called automatically before returning the object.\n\n        :rtype:  :class:`Config`\n\n        \"\"\"\n        bangrc = parse_bangrc()\n        config_dir = bangrc.get(A.CONFIG_DIR, DEFAULT_CONFIG_DIR)\n        config_paths = [\n                resolve_config_spec(cs, config_dir) for cs in config_specs\n                ]\n        config = cls()\n        config.update(bangrc)\n        if config_paths:\n            config.filepath = config_paths[0]\n        for c in config_paths:\n            with open(c) as f:\n                deep_merge_dicts(config, yaml.safe_load(f))\n        if prepare:\n            config.prepare()\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _prepare_servers(self):\n        stack = {\n                A.NAME: self[A.NAME],\n                A.VERSION: self[A.VERSION],\n                }\n        for server in self.get(R.SERVERS, []):\n            # default cloud values\n            if A.PROVIDER in server:\n                if A.server.LAUNCH_TIMEOUT not in server:\n                    server[A.server.LAUNCH_TIMEOUT] = DEFAULT_LAUNCH_TIMEOUT_S\n                if A.server.POST_DELAY not in server:\n                    server[A.server.POST_DELAY] = DEFAULT_LAUNCH_TIMEOUT_S\n                if A.server.AZ not in server:\n                    server[A.server.AZ] = server[A.server.REGION]\n\n            # distribute the config scope attributes\n            svars = {\n                    A.STACK: stack,\n                    A.SERVER_CLASS: server[A.NAME],\n                    }\n            for scope in server.get(A.server.SCOPES, []):\n                # allow scopes to be defined inline\n                if isinstance(scope, collections.Mapping):\n                    svars.update(scope)\n                else:\n                    svars[scope] = self[scope]\n\n            # make all of the launch-time attributes (e.g. disk_image_id,\n            # launch_timeout_s, ssh_key_name, etc...) available as facts in\n            # case you need them in a playbook.\n            sattrs = server.copy()\n            sattrs.pop(A.server.SCOPES, None)\n            svars[A.server.BANG_ATTRS] = sattrs\n\n            server[A.server.VARS] = svars", "response": "Prepares the server variables that are exposed to the servers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _prepare_load_balancers(self):\n        stack = {\n                A.NAME: self[A.NAME],\n                A.VERSION: self[A.VERSION],\n                }\n\n        for load_balancer in self.get(R.LOAD_BALANCERS, []):\n            svars = {A.STACK: stack}\n            load_balancer[A.loadbalancer.VARS] = svars", "response": "Prepare load balancer variables"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _convert_to_list(self, stanza_key, name_key):\n        converted_list = []\n        for k, v in self.get(stanza_key, {}).iteritems():\n            v[name_key] = k\n            converted_list.append(v)\n        return converted_list", "response": "Convert self [ stanza_key name_key ] to a list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreorganize the data such that the deployment logic can find it all where it expects to be. The raw configuration file is intended to be as human-friendly as possible partly through the following mechanisms: - In order to minimize repetition, any attributes that are common to all server configurations can be specified in the ``server_common_attributes`` stanza even though the stanza itself does not map directly to a deployable resource. - For reference locality, each security group stanza contains its list of rules even though rules are actually created in a separate stage from the groups themselves. In order to make the :class:`Config` object more useful to the program logic, this method performs the following transformations: - Distributes the ``server_common_attributes`` among all the members of the ``servers`` stanza. - Extracts security group rules to a top-level key, and interpolates all source and target values.", "response": "def prepare(self):\n        \"\"\"\n        Reorganizes the data such that the deployment logic can find it all\n        where it expects to be.\n\n        The raw configuration file is intended to be as human-friendly as\n        possible partly through the following mechanisms:\n\n            - In order to minimize repetition, any attributes that are common\n              to all server configurations can be specified in the\n              ``server_common_attributes`` stanza even though the stanza itself\n              does not map directly to a deployable resource.\n            - For reference locality, each security group stanza contains its\n              list of rules even though rules are actually created in a\n              separate stage from the groups themselves.\n\n        In order to make the :class:`Config` object more useful to the program\n        logic, this method performs the following transformations:\n\n            - Distributes the ``server_common_attributes`` among all the\n              members of the ``servers`` stanza.\n            - Extracts security group rules to a top-level key, and\n              interpolates all source and target values.\n\n        \"\"\"\n        # TODO: take server_common_attributes and disperse it among the various\n        # server stanzas\n\n        # First stage - turn all the dicts (SERVER, SECGROUP, DATABASE, LOADBAL)\n        # into lists now they're merged properly\n        for stanza_key, name_key in (\n                (R.SERVERS, A.server.NAME),\n                (R.SERVER_SECURITY_GROUPS, A.secgroup.NAME),\n                (R.LOAD_BALANCERS, A.loadbalancer.NAME),\n                (R.DATABASES, A.database.NAME),\n                (R.BUCKETS, A.NAME),\n                (R.QUEUES, A.NAME)):\n            self[stanza_key] = self._convert_to_list(stanza_key, name_key)\n\n        self._prepare_ssh_keys()\n        self._prepare_secgroups()\n        self._prepare_tags()\n        self._prepare_dbs()\n        self._prepare_servers()\n        self._prepare_load_balancers()\n        self._prepare_ansible()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef autoinc(self):\n        if not self.get('autoinc_version'):\n            return\n\n        oldver = self['version']\n        newver = bump_version_tail(oldver)\n\n        config_path = self.filepath\n        temp_fd, temp_name = tempfile.mkstemp(\n                dir=os.path.dirname(config_path),\n                )\n        with open(config_path) as old:\n            with os.fdopen(temp_fd, 'w') as new:\n                for oldline in old:\n                    if oldline.startswith('version:'):\n                        new.write(\"version: '%s'\\n\" % newver)\n                        continue\n                    new.write(oldline)\n\n        # no need to backup the old file, it's under version control anyway -\n        # right???\n        log.info('Incrementing stack version %s -> %s' % (oldver, newver))\n        os.rename(temp_name, config_path)", "response": "Updates the stack version in the file associated with this config."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setup(name, path='log', enable_debug=False):\n    path_tmpl = os.path.join(path, '{name}_{level}.log')\n    info = path_tmpl.format(name=name, level='info')\n    warn = path_tmpl.format(name=name, level='warn')\n    err = path_tmpl.format(name=name, level='err')\n    crit = path_tmpl.format(name=name, level='crit')\n    # a nested handler setup can be used to configure more complex setups\n    setup = [\n        # make sure we never bubble up to the stderr handler\n        # if we run out of setup handling\n        NullHandler(),\n        # then write messages that are at least info to to a logfile\n        TimedRotatingFileHandler(info, level='INFO', encoding='utf-8',\n                                 date_format='%Y-%m-%d'),\n        # then write messages that are at least warnings to to a logfile\n        TimedRotatingFileHandler(warn, level='WARNING', encoding='utf-8',\n                                 date_format='%Y-%m-%d'),\n        # then write messages that are at least errors to to a logfile\n        TimedRotatingFileHandler(err, level='ERROR', encoding='utf-8',\n                                 date_format='%Y-%m-%d'),\n        # then write messages that are at least critical errors to to a logfile\n        TimedRotatingFileHandler(crit, level='CRITICAL', encoding='utf-8',\n                                 date_format='%Y-%m-%d'),\n    ]\n    if enable_debug:\n        debug = path_tmpl.format(name=name, level='debug')\n        setup.insert(1, TimedRotatingFileHandler(debug, level='DEBUG',\n                     encoding='utf-8', date_format='%Y-%m-%d'))\n    if src_server is not None and smtp_server is not None \\\n            and smtp_port != 0 and len(dest_mails) != 0:\n        mail_tmpl = '{name}_error@{src}'\n        from_mail = mail_tmpl.format(name=name, src=src_server)\n        subject = 'Error in {}'.format(name)\n        # errors should then be delivered by mail and also be kept\n        # in the application log, so we let them bubble up.\n        setup.append(MailHandler(from_mail, dest_mails, subject,\n                                 level='ERROR', bubble=True,\n                                 server_addr=(smtp_server, smtp_port)))\n\n    return NestedSetup(setup)", "response": "Prepare a nested setup for a single channel."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mail_setup(path):\n    global dest_mails\n    global smtp_server\n    global smtp_port\n    global src_server\n    config = configparser.RawConfigParser()\n    config.readfp(path)\n    dest_mails = config.get('mail', 'dest_mail').split(',')\n    smtp_server = config.get('mail', 'smtp_server')\n    smtp_port = config.get('mail', 'smtp_port')\n    src_server = config.get('mail', 'src_server')", "response": "Sets the variables to be able to send emails."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns a subscriber and pass the messages to the logbook setup.", "response": "def run(log_name, path, debug=False, mail=None, timeout=0):\n    \"\"\"\n    Run a subscriber and pass the messages to the logbook setup.\n    Stays alive as long as the pubsub instance listen to something.\n\n    :param log_name: the channel to listen to\n    :param path: the path where the log files will be written\n    :param debug: True if you want to save the debug messages too\n    :param mail: Path to the config file for the mails\n\n    \"\"\"\n    global pubsub\n    global channel\n    channel = log_name\n    if use_tcp_socket:\n        r = redis.StrictRedis(host=hostname, port=port)\n    else:\n        r = redis.StrictRedis(unix_socket_path=unix_socket)\n    pubsub = r.pubsub()\n    pubsub.psubscribe(channel + '.*')\n\n    if timeout != 0:\n        deadline = time.time() + timeout\n\n    logger = Logger(channel)\n    if mail is not None:\n        mail_setup(mail)\n    if os.path.exists(path) and not os.path.isdir(path):\n        raise Exception(\"The path you want to use to save the file is invalid (not a directory).\")\n    if not os.path.exists(path):\n        os.mkdir(path)\n    with setup(channel, path, debug):\n        while True:\n            msg = pubsub.get_message()\n            if msg:\n                if msg['type'] == 'pmessage':\n                    level = msg['channel'].decode('utf-8').split('.')[1]\n                    message = msg['data']\n                    try:\n                        message = message.decode('utf-8')\n                    except:\n                        pass\n                    logger.log(level, message)\n            time.sleep(0.01)\n            if timeout > 0:\n                if time.time() >= deadline:\n                    break"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npass options through to this plugin.", "response": "def parse_options(cls, options):\n    \"\"\"Pass options through to this plugin.\"\"\"\n    cls.ignore_decorators = options.ignore_decorators\n    cls.exclude_from_doctest = options.exclude_from_doctest\n    if not isinstance(cls.exclude_from_doctest, list):\n      cls.exclude_from_doctest = [cls.exclude_from_doctest]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nuses directly check ( api from pydocstyle.", "response": "def run(self):\n    \"\"\"Use directly check() api from pydocstyle.\"\"\"\n    if self.exclude_from_doctest:\n      for pattern in self.exclude_from_doctest:\n        if fnmatch.fnmatch(self.filename, pattern):\n          return\n\n    checked_codes = pep257.conventions.pep257 | {'D998', 'D999'}\n    for error in self._check_source():\n      if isinstance(error, pep257.Error) and error.code in checked_codes:\n        # NOTE(sigmavirus24): Fixes GitLab#3\n        message = '%s %s' % (error.code, error.short_desc)\n        yield (error.line, 0, message, type(self))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the source for the specified file.", "response": "def load_source(self):\n    \"\"\"Load the source for the specified file.\"\"\"\n    if self.filename in self.STDIN_NAMES:\n      self.filename = 'stdin'\n      self.source = pycodestyle.stdin_get_value()\n    else:\n      with pep257.tokenize_open(self.filename) as fd:\n        self.source = fd.read()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef join_params(self, params, suppress_null=True):\n\t\t''' \n\t\tCustom alternative to urllib.urlencode that keeps URL length\n\t\tdown by not escaping certain special characters that Factual\n\t\tcan tolerate unescaped. This is especially useful for the \n\t\tJSON special chars {}[],:. \n\n\t\tThe full list of usually-escaped-but-ok-for-factual characters is:\n\n\t\t    / { } ' $ : , [ ]\n\n\t\tThe API used to tolerate doublequotes, but this seems to have \n\t\tchanged. \n\n\t\tsuppress_null removes parametrs which are set to None.\n\t\t'''\n\t\t# ensure all params and values are properly urlencoded\n\t\t# since we may have numbers, etc. here, cast to unicode and encode back to utf-8\n\t\treturn \"&\".join([\n\t\t\t\t\t(\"%s=%s\" \\\n\t\t\t\t\t\t% (\n\t\t\t\t\t\t\turllib.quote_plus(unicode(k).encode('utf-8'), '/{}\\'$:,[]'),\n\t\t\t\t\t\t\turllib.quote_plus(unicode(v).encode('utf-8'), '/{}\\'$:,[]')\n\t\t\t\t\t\t)\n\t\t\t\t\t) \n\t\t\t\t\tfor k,v \n\t\t\t\t\tin params.iteritems()\n\t\t\t\t\tif not suppress_null or v != None\n\t\t\t\t])", "response": "Join the params of a single object into a URL string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepare(self, data_source):\n        dataframe = self.__get_dataframe(data_source, use_target=True)\n        self.__config.get_data_model().set_features_types_from_dataframe(dataframe)\n        dataframe = self.__cleaner.prepare(dataframe)\n        return self.__transformer.prepare(dataframe)", "response": "Called with the training data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall with the predict data.", "response": "def apply(self, data_source):\n        \"\"\"\n        Called with the predict data (new information).\n        @param data_source: Either a pandas.DataFrame or a file-like object.\n        \"\"\"\n        dataframe = self.__get_dataframe(data_source, use_target=False)\n        dataframe = self.__cleaner.apply(dataframe)\n        dataframe = self.__transformer.apply(dataframe)\n        return dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef exploreISA(pathToISATABFile, verbose=True):\n    try:\n        isa_tab_record = isatab.load(pathToISATABFile, skip_load_tables=True)\n        if verbose:\n            print('In this ISATAB file you have:')\n            for idx,st in enumerate(isa_tab_record.studies):\n                print('Study: '+str(idx+1))\n                print('\\tStudy Identifier: '+st.identifier+', Study ID: '+st.id+', Study Filename: '+st.filename+', Study Title: '+st.title)\n                print('\\tThis Study has the following Assays:')\n                for ix,a in enumerate(st.assays):\n                    print('\\tAssay: '+str(ix+1))\n                    print('\\t\\tAssay Filename: '+a.filename+', Assay technology type: '+a.technology_type.term)\n    except FileNotFoundError as err:\n        raise err", "response": "This function loops through the ISATAB file and lists its Studies and their associated Assays."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getISAAssay(assayNum, studyNum, pathToISATABFile):\n    from isatools import isatab\n    import copy\n    try:\n        isa = isatab.load(pathToISATABFile, skip_load_tables=True)\n        std = isa.studies[studyNum - 1]\n        return copy.deepcopy(std.assays[assayNum - 1])\n    except FileNotFoundError as err:\n        raise err", "response": "This function returns an Assay object given the assay and study numbers in an ISA file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef appendStudytoISA(study, pathToISATABFile):\n    from isatools import isatab\n    import os\n    try:\n        isa = isatab.load(pathToISATABFile, skip_load_tables=True)\n        lngth = len(isa.studies)\n        base = os.path.basename(study.filename)\n        fname = os.path.splitext(base)[0]\n        fname = fname + str(lngth)\n        ext = os.path.splitext(base)[1]\n        fname = fname + ext\n        study.filename = fname\n        isa.studies.append(study)\n        isatab.dump(isa_obj=isa, output_path=pathToISATABFile)\n    except FileNotFoundError as err:\n        raise err", "response": "This function appends a Study object to an ISA file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef appendAssayToStudy(assay, studyNum, pathToISATABFile):\n    from isatools import isatab\n    try:\n        isa = isatab.load(pathToISATABFile, skip_load_tables=True)\n        std = isa.studies[studyNum - 1]\n        lngth = len(std.assays)\n        base  = os.path.basename(assay.filename)\n        fname = os.path.splitext(base)[0]\n        fname = fname + str(lngth)\n        ext   = os.path.splitext(base)[1]\n        fname = fname + ext\n        assay.filename = fname\n        isa.studies[studyNum - 1].assays.append(assay)\n        isatab.dump(isa_obj=isa, output_path=pathToISATABFile)\n    except FileNotFoundError as err:\n        raise err", "response": "This function appends an assay object to a study in an ISA file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nask the user for a question in y / n form and return True or False.", "response": "def ask(question, default=True, exact=False):\n    \"\"\"Ask the question in y/n form and return True/False.\n\n    If you don't want a default 'yes', set default to None (or to False if you\n    want a default 'no').\n\n    With exact=True, we want to get a literal 'yes' or 'no', at least\n    when it does not match the default.\n\n    \"\"\"\n    if AUTO_RESPONSE:\n        if default is None:\n            msg = (\"The question '%s' requires a manual answer, but \" +\n                   \"we're running in --no-input mode.\")\n            msg = msg % question\n            raise RuntimeError(msg)\n        logger.debug(\"Auto-responding '%s' to the question below.\" % (\n            default and \"yes\" or \"no\"))\n        logger.debug(question)\n        return default\n    while True:\n        yn = 'y/n'\n        if default is True:\n            yn = 'Y/n'\n        if default is False:\n            yn = 'y/N'\n        q = question + \" (%s)? \" % yn\n        answer = input(q)\n        if answer:\n            answer = answer\n        else:\n            answer = ''\n        if not answer and default is not None:\n            return default\n        if exact and answer.lower() not in ('yes', 'no'):\n            print(\"Please explicitly answer yes/no in full \"\n                  \"(or accept the default)\")\n            continue\n        if answer:\n            answer = answer[0].lower()\n            if answer == 'y':\n                return True\n            if answer == 'n':\n                return False\n        # We really want an answer.\n        print('Please explicitly answer y/n')\n        continue"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncommand - > output", "response": "def system(command, answer=''):\n    \"\"\"commands.getoutput() replacement that also works on windows\"\"\"\n    p = subprocess.Popen(command,\n                         shell=True,\n                         stdin=subprocess.PIPE,\n                         stdout=subprocess.PIPE,\n                         stderr=subprocess.PIPE,\n                         close_fds=MUST_CLOSE_FDS)\n    i, o, e = (p.stdin, p.stdout, p.stderr)\n    if answer:\n        i.write(answer)\n    i.close()\n    result = o.read() + e.read()\n    o.close()\n    e.close()\n    return result.decode('utf8')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fix_rst_heading(heading, below):\n    if len(below) == 0:\n        return below\n    first = below[0]\n    if first not in '-=`~':\n        return below\n    if not len(below) == len([char for char in below\n                              if char == first]):\n        # The line is not uniformly the same character\n        return below\n    below = first * len(heading)\n    return below", "response": "Given a heading line give it the correct length."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract the headings from a list of history lines.", "response": "def extract_headings_from_history(history_lines):\n    \"\"\"Return list of dicts with version-like headers.\n\n    We check for patterns like '2.10 (unreleased)', so with either\n    'unreleased' or a date between parenthesis as that's the format we're\n    using. Just fix up your first heading and you should be set.\n\n    As an alternative, we support an alternative format used by some\n    zope/plone paster templates: '2.10 - unreleased' or '2.10 ~ unreleased'\n\n    Note that new headers that zest.releaser sets are in our preferred\n    form (so 'version (date)').\n    \"\"\"\n    pattern = re.compile(r\"\"\"\n    (?P<version>.+)  # Version string\n    \\(               # Opening (\n    (?P<date>.+)     # Date\n    \\)               # Closing )\n    \\W*$             # Possible whitespace at end of line.\n    \"\"\", re.VERBOSE)\n    alt_pattern = re.compile(r\"\"\"\n    ^                # Start of line\n    (?P<version>.+)  # Version string\n    \\ [-~]\\          # space dash/twiggle space\n    (?P<date>.+)     # Date\n    \\W*$             # Possible whitespace at end of line.\n    \"\"\", re.VERBOSE)\n    headings = []\n    line_number = 0\n    for line in history_lines:\n        match = pattern.search(line)\n        alt_match = alt_pattern.search(line)\n        if match:\n            result = {'line': line_number,\n                      'version': match.group('version').strip(),\n                      'date': match.group('date'.strip())}\n            headings.append(result)\n            logger.debug(\"Found heading: %r\", result)\n        if alt_match:\n            result = {'line': line_number,\n                      'version': alt_match.group('version').strip(),\n                      'date': alt_match.group('date'.strip())}\n            headings.append(result)\n            logger.debug(\"Found alternative heading: %r\", result)\n        line_number += 1\n    return headings"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts the headings from the changelog file that were modified by zope. releaser.", "response": "def extract_headings_from_history_modified(changelog):\n    \"\"\"Return list of dicts with version-like headers.\n\n    We check for patterns like '2.10 (unreleased)', so with either\n    'unreleased' or a date between parenthesis as that's the format we're\n    using. Just fix up your first heading and you should be set.\n\n    As an alternative, we support an alternative format used by some\n    zope/plone paster templates: '2.10 - unreleased' or '2.10 ~ unreleased'\n\n    Note that new headers that zest.releaser sets are in our preferred\n    form (so 'version (date)').\n    \"\"\"\n    pattern = re.compile(r\"\"\"\n    (?P<version>.+)  # Version string\n    \\(               # Opening (\n    (?P<date>.+)     # Date\n    \\)               # Closing )\n    \\W*$             # Possible whitespace at end of line.\n    \"\"\", re.VERBOSE)\n    alt_pattern = re.compile(r\"\"\"\n    ^                # Start of line\n    (?P<version>.+)  # Version string\n    \\ [-~]\\          # space dash/twiggle space\n    (?P<date>.+)     # Date\n    \\W*$             # Possible whitespace at end of line.\n    \"\"\", re.VERBOSE)\n    headings = []\n    line_number = 0\n    with open(changelog, 'r') as f:\n        for line in f:\n            match = pattern.search(line)\n            alt_match = alt_pattern.search(line)\n            if match:\n                result = {'line': line_number,\n                          'version': match.group('version').strip(),\n                          'date': match.group('date'.strip())}\n                headings.append(result)\n                logger.debug(\"Found heading: %r\", result)\n            if alt_match:\n                result = {'line': line_number,\n                          'version': alt_match.group('version').strip(),\n                          'date': alt_match.group('date'.strip())}\n                headings.append(result)\n                logger.debug(\"Found alternative heading: %r\", result)\n            line_number += 1\n    return headings"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndoing sanity check before making changes", "response": "def sanity_check(vcs):\n    \"\"\"Do sanity check before making changes\n\n    Check that we are not on a tag and/or do not have local changes.\n\n    Returns True when all is fine.\n    \"\"\"\n    if not vcs.is_clean_checkout():\n        q = (\"This is NOT a clean checkout. You are on a tag or you have \"\n             \"local changes.\\n\"\n             \"Are you sure you want to continue?\")\n        if not ask(q, default=False):\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_recommended_files(data, vcs):\n    main_files = os.listdir(data['workingdir'])\n    if not 'setup.py' in main_files and not 'setup.cfg' in main_files:\n        # Not a python package.  We have no recommendations.\n        return True\n    if not 'MANIFEST.in' in main_files and not 'MANIFEST' in main_files:\n        q = (\"This package is missing a MANIFEST.in file. This file is \"\n             \"recommended. \"\n             \"See http://docs.python.org/distutils/sourcedist.html\"\n             \" for more info. Sample contents:\"\n             \"\\n\"\n             \"recursive-include main_directory *\"\n             \"recursive-include docs *\"\n             \"include *\"\n             \"global-exclude *.pyc\"\n             \"\\n\"\n             \"You may want to quit and fix this.\")\n\n        if not vcs.is_setuptools_helper_package_installed():\n            q += \"Installing %s may help too.\\n\" % \\\n                vcs.setuptools_helper_package\n        # We could ask, but simply printing it is nicer.  Well, okay,\n        # let's avoid some broken eggs on PyPI, per\n        # https://github.com/zestsoftware/zest.releaser/issues/10\n        q += \"Do you want to continue with the release?\"\n        if not ask(q, default=False):\n            return False\n        print(q)\n    return True", "response": "Check if the current directory is a python package and if so ask user if it is OK."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the version looks like a development version.", "response": "def cleanup_version(version):\n    \"\"\"Check if the version looks like a development version.\"\"\"\n    for w in WRONG_IN_VERSION:\n        if version.find(w) != -1:\n            logger.debug(\"Version indicates development: %s.\", version)\n            version = version[:version.find(w)].strip()\n            logger.debug(\"Removing debug indicators: %r\", version)\n        version = version.rstrip('.')  # 1.0.dev0 -> 1.0. -> 1.0\n    return version"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pad(lines, delim):\n\t\"\"\"\n\tPopulates text into chunks. If the delim was & then\n\t['12 & 344', '344 & 8', '8 & 88'] would be stored in chunks as\n\t[['12', '344', '8'], ['344', '8', '88']]\n\t\"\"\"\n\tchunks = []\n\tfor i in range(len(lines)):\n\t\tline = lines[i]\n\t\tsections = line.split(delim)\n\t\tfor j in range(len(sections)):\n\t\t\tif len(chunks) <= j:\n\t\t\t\tchunks.append([])\n\t\t\tchunks[j].append(sections[j])\n\n\t\"\"\"\n\tCalculates & Stores the max length of chunks\n\t\"\"\"\n\tmax_lengths = []\n\tfor i in range(len(chunks)):\n\t\t_max = max([len(j) for j in chunks[i]])\n\t\tmax_lengths.append(_max)\n\n\t\"\"\"\n\tPads the children of chunks according to the chunk's max length\" \\\n\t\"\"\"\n\tfor i in range(len(chunks)):\n\t\tfor j in range(len(chunks[i])):\n\t\t\tchunks[i][j] += (max_lengths[i] - len(chunks[i][j])) * ' '\n\tnew_lines = ['' for i in range(len(lines))]\n\n\tfor i in range(len(chunks)):\n\t\tfor j in range(len(chunks[i])):\n\t\t\tnew_lines[j] += chunks[i][j]\n\treturn new_lines", "response": "This function pads text into chunks and returns a new string."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npasses output through pager.", "response": "def pager(__text: str, *, pager: Optional[str] = 'less'):\n    \"\"\"Pass output through pager.\n\n    See :manpage:`less(1)`, if you wish to configure the default pager.  For\n    example, you may wish to check ``FRSX`` options.\n\n    Args:\n        __text: Text to page\n        pager: Pager to use\n    \"\"\"\n    if pager:\n        run([pager, ], input=__text.encode())\n    else:\n        print(__text)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mdprint(*values, plain=None, **options):\n    print(*[mdrender(x, plain=plain) for x in values], **options)", "response": "Convert HTML to VTML and then print it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef listen(self, **kwargs: Any) -> Server:\n        loop = cast(asyncio.AbstractEventLoop, self._loop)\n        return (yield from loop.create_server(\n            lambda: self._protocol(\n                loop=loop,\n                handle=self._handle,\n                requset_charset=self.requset_charset,\n                response_charset=self.response_charset,\n            ),\n            **kwargs,\n        ))", "response": "Listen for new requests."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self, host: str = \"0.0.0.0\", port: int = 5000) -> None:\n        loop = cast(asyncio.AbstractEventLoop, self._loop)\n        listen = self.listen(host=host, port=port)\n        server = loop.run_until_complete(listen)\n\n        def close() -> None:\n            \"\"\"\n            \u5173\u95ed\u56de\u8c03\n            \"\"\"\n            server.close()\n            loop.stop()\n        # print(type(server))\n        loop.add_signal_handler(SIGTERM, close)\n        loop.add_signal_handler(SIGINT, close)\n        loop.run_forever()", "response": "debug run\n        :param host: the hostname to listen on, default is ``'0.0.0.0'``\n        :param port: the port of the server, default id ``5000``"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_server(\n            self,\n            loop: asyncio.AbstractEventLoop,\n            sock: Any,\n            ssl: SSLContext,\n    ) -> TypeGenerator[Any, None, Server]:\n        \"\"\"\n        \u63d0\u4f9b\u7ed9 Worker \u4f7f\u7528\u7684\u8c03\u7528\n        \"\"\"\n        if loop is not None and self._loop is not loop:\n            self._loop = loop\n        return (yield from self.listen(\n            sock=sock,\n            ssl=ssl,\n        ))", "response": "Create a new server."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _next_middleware(\n            self,\n            middlewares: Iterator[MIDDLEWARE_TYPE],\n            ctx: Context,\n    ) -> NEXT_CALL_TYPE:\n        \"\"\"\n        \u751f\u6210 next_call \u7684\u8c03\u7528\n        \u4f7f\u7528\u8fed\u4ee3\u5668\uff0c\u8fd9\u4e2a\u65b9\u6cd5\u6bcf\u8c03\u7528\u4e00\u6b21\u90fd\u4f1a\u6307\u5411\u4e0b\u4e00\u4e2a\u4e2d\u95f4\u4ef6\u3002\n        \"\"\"\n        @asyncio.coroutine\n        def next_call() -> NEXT_CALL_RES_TYPE:\n            \"\"\"\n            \u8c03\u7528\u4e0b\u4e00\u4e2a\u4e2d\u95f4\u4ef6\n            \"\"\"\n            yield from self._middleware_call(middlewares, ctx, next_call)\n        return next_call", "response": "Returns a coroutine that yields the next middleware."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _handle(self, request: Request, response: Response) -> TypeGenerator[Any, None, None]:\n        # request.start_time = datetime.now().timestamp()\n        # \u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u4f1a\u8bdd\u4e0a\u4e0b\u6587\n        ctx = self._context(\n            cast(asyncio.AbstractEventLoop, self._loop),\n            request,\n            response,\n            self,\n        )\n        request.app = self\n        response.app = self\n        request.ctx = ctx\n        response.ctx = ctx\n        request.response = response\n        response.request = request\n\n        # \u628a\u5f53\u524d\u6ce8\u518c\u7684\u4e2d\u95f4\u4ef6\u8f6c\u4e3a\u8fed\u4ee3\u5668\n        middleware_iter = iter(self._middleware)\n        # \u901a\u8fc7\u8fed\u4ee3\u5668\u7684\u6a21\u5f0f\u751f\u6210\u4e00\u4e2a\u6267\u884c\u4e0b\u4e00\u4e2a\u4e2d\u95f4\u7684\u8c03\u7528\u65b9\u6cd5\n        next_call = self._next_middleware(middleware_iter, ctx)\n        # \u987a\u5e8f\u6267\u884c\u4e2d\u95f4\u4ef6\n        yield from self._middleware_call(middleware_iter, ctx, next_call)\n        # \u8bbe\u7f6e cookies\n        cookies_headers = ctx.cookies.headers()\n        if cookies_headers is not None:\n            ctx.response.set(\"Set-Cookie\", cookies_headers)\n        # \u5199\u51fa headers\n        ctx.response.flush_headers()\n        # \u5199\u51fa body\n        ctx.response.flush_body()", "response": "request \u89e3\u6790\u540e\u7684\u56de\u8c03\uff0c\u8c03\u7528\u4e2d\u95f4\u4ef6\uff0c\u5e76\u5904\u7406 headers, body \u53d1\u9001\u3002"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generic_key_facets(self, request):\n\n        excluded_apps = Q(app_label__in=EXCLUDED_APPS_FROM_FACETS)\n        excluded_models = Q()\n        for app_label, model in EXCLUDED_MODELS_FROM_FACETS:\n            excluded_models = excluded_models | Q(app_label=app_label,\n                    model=model)\n        values = \"model\", \"app_label\", \"id\"\n        content_types = ContentType.objects.values_list(*values) \\\n                .exclude(excluded_apps | excluded_models)\n        return JsonResponse(dict([(str(a), {\"app_label\": str(b), \"id\": str(c)})\n                for a, b, c in content_types]))", "response": "Find all available facets and models for VisualSearch"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generic_key_modelsearch(self, request, app_label, model_name):\n        content_type = ContentType.objects.get(app_label=app_label,\n                model=model_name)\n\n        model = content_type.model_class()\n        model_admin = self._registry[model].__class__(model, self)\n        model_admin.change_list_template = \"admin/hatband/change_list.json\"\n        return model_admin.changelist_view(request)", "response": "Generic key model search."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn JSON for an individual Model instance", "response": "def type_and_model_to_query(self, request):\n        \"\"\"\n        Return JSON for an individual Model instance\n\n        If the required parameters are wrong, return 400 Bad Request\n        If the parameters are correct but there is no data, return empty JSON\n\n        \"\"\"\n        try:\n            content_type_id = request.GET[\"content_type_id\"]\n            object_id = request.GET[\"object_id\"]\n        except KeyError:\n            return HttpResponseBadRequest()\n\n        try:\n            content_type = ContentType.objects.get(pk=content_type_id)\n            model = content_type.model_class()\n            result = model.objects.get(pk=object_id)\n        except ObjectDoesNotExist:\n            data = \"\"\n        else:\n            data = '%s: \"%d: %s\"' % (content_type.model, result.pk, result)\n\n        return JsonResponse({\"query\": data})"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the given CLI arguments to get a run configuration derived from the given CLI arguments.", "response": "def _parse_args(args: List[str]) -> _UpdateArgumentsRunConfig:\n    \"\"\"\n    Parses the given CLI arguments to get a run configuration.\n    :param args: CLI arguments\n    :return: run configuration derived from the given CLI arguments\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        prog=\"gitlab-update-variables\", description=\"Tool for setting a GitLab project's build variables\")\n    add_common_arguments(parser)\n    parser.add_argument(\"config_location\", type=str, help=\"Location of the configuration file\")\n    parser.add_argument(\"--setting-repository\", dest=\"setting_repository\", nargs=\"+\", type=str,\n                        help=\"Directory from which variable settings groups may be sourced\")\n    parser.add_argument(\"--default-setting-extension\", dest=\"default_setting_extensions\",nargs=\"+\", type=str,\n                        help=\"Extensions to try adding to the variable to source location if it does not exist\")\n\n    arguments = parser.parse_args(args)\n    return _UpdateArgumentsRunConfig(\n        arguments.config_location, arguments.setting_repository, arguments.default_setting_extensions,\n        url=arguments.url, token=arguments.token, debug=arguments.debug)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload data from a set of configuration files.", "response": "def load(self, paths, params=None):\n        \"\"\" Load data from configuration files.\n\n        Configuration values are read from a sequence of one or more YAML\n        files. Files are read in the given order, and a duplicate value will\n        overwrite the existing value.\n\n        The optional 'params' argument is a dict-like object to use for\n        parameter substitution in the config files. Any text matching \"%key;\"\n        will be replaced with the value for 'key' in params.\n\n        \"\"\"\n        def replace(match):\n            \"\"\" Callback for re.sub to do parameter replacement. \"\"\"\n            # This allows for multi-pattern substitution in a single pass.\n            return params[match.group(0)]\n\n        params = {r\"%{:s};\".format(key): val for (key, val)\n                  in params.iteritems()} if params else {}\n        regex = compile(\"|\".join(params) or r\"^(?!)\")\n        for path in paths:\n            with open(path, \"r\") as stream:\n                # Global text substitution is used for parameter replacement.\n                # Two drawbacks of this are 1) the entire config file has to be\n                # read into memory first; 2) it might be nice if comments were\n                # excluded from replacement. A more elegant (but complex)\n                # approach would be to use PyYAML's various hooks to do the\n                # substitution as the file is parsed.\n                logger.info(\"reading config data from {:s}\".format(path))\n                yaml = regex.sub(replace, stream.read())\n            try:\n                self.update(load(yaml))\n            except TypeError:  # load() returned None\n                logger.warn(\"config file '{:s}' is empty\".format(yaml))\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a unicode object from given string.", "response": "def u(s, errors='ignore'):\n    \"\"\"\n    Automatically detects given string's encoding and returns its unicode form.\n    Decoding errors are handled according to the `errors` argument, see `unicode()`\n    documentation for more details.\n\n    :param s: string to decode.\n    :type s: str\n    :param errors: decoding error handling behaviour.\n    :type errors: str\n    :return: decoded string\n    :rtype: unicode\n    \"\"\"\n    try:\n        return s.decode('utf-8', errors=errors)\n    except UnicodeDecodeError:\n        encoding = chardet.detect(s)['encoding']\n        return unicode(s, encoding=encoding, errors=errors)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_repositories(path):\n    return [get_repository(os.path.join(path, subdir))\n            for subdir in os.listdir(path)\n            if os.path.isdir(\n            os.path.join(path, subdir, '.git'))]", "response": "Returns a list of tuples with the name and path for\n    repositories found in a directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an array of the path name for repositories found in a directory.", "response": "def get_repository_names(path):\n    \"\"\"\n    Return an array of the path name for\n    repositories found in a directory.\n\n    :param str path:\n        The path to find repositories in\n    :returns: array\n    \"\"\"\n    return [subdir\n            for subdir in os.listdir(path)\n            if os.path.isdir(os.path.join(path, subdir, '.git'))]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_schemas(repo):\n    schema_files = glob.glob(\n        os.path.join(repo.working_dir, '_schemas', '*.avsc'))\n    schemas = {}\n    for schema_file in schema_files:\n        with open(schema_file, 'r') as fp:\n            schema = json.load(fp)\n            schemas['%(namespace)s.%(name)s' % schema] = schema\n    return schemas", "response": "Return a list of parsed avro schemas as dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_content_types(repo):\n    schema_files = glob.glob(\n        os.path.join(repo.working_dir, '_schemas', '*.avsc'))\n    return [os.path.splitext(os.path.basename(schema_file))[0]\n            for schema_file in schema_files]", "response": "Return a list of content types in a git repository."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_schema(repo, content_type):\n    try:\n        with open(\n                os.path.join(repo.working_dir,\n                             '_schemas',\n                             '%s.avsc' % (content_type,)), 'r') as fp:\n            data = fp.read()\n            return avro.schema.parse(data)\n    except IOError:  # pragma: no cover\n        raise NotFound('Schema does not exist.')", "response": "Returns a schema for a content type in a git repository."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an ES mapping for a content type in a git repository.", "response": "def get_mapping(repo, content_type):\n    \"\"\"\n    Return an ES mapping for a content type in a repository.\n\n    :param Repo repo:\n        This git repository.\n    :returns: dict\n    \"\"\"\n    try:\n        with open(\n            os.path.join(repo.working_dir,\n                         '_mappings',\n                         '%s.json' % (content_type,)), 'r') as fp:\n            return json.load(fp)\n    except IOError:\n        raise NotFound('Mapping does not exist.')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary representing the repository that is relevant to the current branch.", "response": "def format_repo(repo):\n    \"\"\"\n    Return a dictionary representing the repository\n\n    It returns ``None`` for things we do not support or are not\n    relevant.\n\n    :param str repo_name:\n        The name of the repository.\n    :param git.Repo repo:\n        The repository object.\n    :param str base_url:\n        The base URL for the repository's links.\n    :returns: dict\n\n    \"\"\"\n    commit = repo.commit()\n    return {\n        'name': os.path.basename(repo.working_dir),\n        'branch': repo.active_branch.name,\n        'commit': commit.hexsha,\n        'timestamp': datetime.fromtimestamp(\n            commit.committed_date).isoformat(),\n        'author': '%s <%s>' % (commit.author.name, commit.author.email),\n        'schemas': list_schemas(repo)\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a generator that returns a JSON formattable representation of a DiffIndex.", "response": "def format_diffindex(diff_index):\n    \"\"\"\n    Return a JSON formattable representation of a DiffIndex.\n\n    Returns a generator that returns dictionaries representing the changes.\n\n    .. code::\n        [\n            {\n                'type': 'A',\n                'path': 'path/to/added/file.txt',\n            },\n            {\n                'type': 'D',\n                'path': 'path/to/deleted/file.txt',\n            },\n            {\n                'type': 'M',\n                'path': 'path/to/modified/file.txt',\n            },\n            {\n                'type': 'R',\n                'rename_from': 'original/path/to/file.txt',\n                'rename_to': 'new/path/to/file.txt',\n            },\n        ]\n\n    :returns: generator\n\n    \"\"\"\n    for diff in diff_index:\n        if diff.new_file:\n            yield format_diff_A(diff)\n        elif diff.deleted_file:\n            yield format_diff_D(diff)\n        elif diff.renamed:\n            yield format_diff_R(diff)\n        elif diff.a_blob and diff.b_blob and diff.a_blob != diff.b_blob:\n            yield format_diff_M(diff)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_content_type(repo, content_type):\n    storage_manager = StorageManager(repo)\n    model_class = load_model_class(repo, content_type)\n    return [dict(model_obj)\n            for model_obj in storage_manager.iterate(model_class)]", "response": "Returns a list of all content objects for a given content type in a given git repository."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef format_content_type_object(repo, content_type, uuid):\n    try:\n        storage_manager = StorageManager(repo)\n        model_class = load_model_class(repo, content_type)\n        return dict(storage_manager.get(model_class, uuid))\n    except GitCommandError:\n        raise NotFound('Object does not exist.')", "response": "Return a content object from a repository for a given content type and uuid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary representing the repository status", "response": "def format_repo_status(repo):\n    \"\"\"\n    Return a dictionary representing the repository status\n\n    It returns ``None`` for things we do not support or are not\n    relevant.\n\n    :param str repo_name:\n        The name of the repository.\n    :returns: dict\n\n    \"\"\"\n    commit = repo.commit()\n    return {\n        'name': os.path.basename(repo.working_dir),\n        'commit': commit.hexsha,\n        'timestamp': datetime.fromtimestamp(\n            commit.committed_date).isoformat(),\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsaving an object as a certain content type.", "response": "def save_content_type_object(repo, schema, uuid, data):\n    \"\"\"\n    Save an object as a certain content type\n    \"\"\"\n    storage_manager = StorageManager(repo)\n    model_class = deserialize(schema,\n                              module_name=schema['namespace'])\n    model = model_class(data)\n    commit = storage_manager.store(model, 'Updated via PUT request.')\n    return commit, model"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting an object of a certain content type", "response": "def delete_content_type_object(repo, content_type, uuid):\n    \"\"\"\n    Delete an object of a certain content type\n    \"\"\"\n    storage_manager = StorageManager(repo)\n    model_class = load_model_class(repo, content_type)\n    model = storage_manager.get(model_class, uuid)\n    commit = storage_manager.delete(model, 'Deleted via DELETE request.')\n    return commit, model"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_model_class(repo, content_type):\n    schema = get_schema(repo, content_type).to_json()\n    return deserialize(schema, module_name=schema['namespace'])", "response": "Load a model class for a content type in a git repository."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_list(self, section, option):\n        value = self.get(section, option)\n        return list(filter(None, (x.strip() for x in value.splitlines())))", "response": "Returns a list of the values of the option in section."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dictionary of the configuration of the specified section and option.", "response": "def get_dict(self, section, option):\n        \"\"\"\n        This allows for loading of Pyramid dictionary style configuration\n        options:\n\n        [foo]\n        bar =\n            baz=qux\n            zap=paz\n\n        ``get_dict('foo', 'bar')`` returns ``{'baz': 'qux', 'zap': 'paz'}``\n\n        :param str section:\n            The section to read.\n        :param str option:\n            The option to read from the section.\n        :returns: dict\n        \"\"\"\n        return dict(re.split('\\s*=\\s*', value)\n                    for value in self.get_list(section, option))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_alive(self) -> Generator[Any, None, None]:\n        if self.loop is None:\n            return\n        pid = os.getpid()\n        try:\n            while self.alive:  # type: ignore\n                self.notify()\n\n                if pid == os.getpid() and self.ppid != os.getppid():\n                    self.alive = False\n                    self.log.info(\"Parent changed, shutting down: %s\", self)\n                else:\n                    yield from asyncio.sleep(1.0, loop=self.loop)\n        except (Exception, BaseException, GeneratorExit, KeyboardInterrupt):\n            pass\n        yield from self.close()", "response": "Check if the process is alive."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate server and add it to self. servers.", "response": "def _run(self) -> Generator[Any, None, None]:\n        \"\"\"\n        \u521b\u5efa Server\n        \"\"\"\n        ssl_context = self._create_ssl_context()\n        # access_logger = self.log.access_log if self.cfg.accesslog else None\n        for sock in self.sockets:\n            # max_fields_size = self.cfg.limit_request_fields * self.cfg.limit_request_field_size\n            # h11_max_incomplete_size = self.cfg.limit_request_line + max_fields_size\n            server = yield from self.wsgi.create_server(self.loop, sock=sock.sock, ssl=ssl_context)\n            self.servers.append(server)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclose all open servers and wait for all servers to be closed.", "response": "def close(self) -> Generator[Any, None, None]:\n        \"\"\"\n        \u5173\u95ed\u56de\u8c03\n        \"\"\"\n        for server in self.servers:\n            server.close()\n            yield from server.wait_closed()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nquoting query with sign (", "response": "def quote(query):\n    '''Quote query with sign(')'''\n    if query.startswith('\\'') is not True:\n        query = '\\'' + query\n\n    if query.endswith('\\'') is not True:\n        query = query + '\\''\n\n    return query"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search(self, query, search_type, payload=None):\n        '''Search implementation'''\n        url = self.url + search_type\n        headers = {'User-Agent': self.user_agent}\n\n        if payload is not None:\n           payload['Query'] = quote(query)\n        else:\n            payload = {'Query': quote(query)}\n\n        request = requests.get(url, auth=self.auth, params=payload, headers=headers)\n        return request", "response": "Search implementation of the search API."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search_composite(self, query, source, payload=None):\n        '''Shortcut search with composite source'''\n        source = '+'.join(source)\n\n        if payload is None:\n            payload = dict(Sources=quote(source))\n        else:\n            payload['Sources'] = quote(source)\n\n        return self.search(query, 'Composite', payload)", "response": "Shortcut search with composite source"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef key_of(d):\n    if len(d) > 1 and not type(d) == dict():\n        raise ValueError('key_of(d) may only except single element dict')\n    else:\n        return keys_of(d)[0]", "response": "Returns the key of a single element dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nopen a grindstone file and populates the grindstone with its contents. Returns an empty grindstone json object if a file does not exist.", "response": "def open_grindstone(self):\n        \"\"\"\n        Opens a grindstone file and populates the grindstone with it's\n        contents.\n        Returns an empty grindstone json object if a file does not exist.\n        \"\"\"\n        try:\n            with open(self.grindstone_path, 'r') as f:\n                # Try opening the file\n                return json.loads(f.read())\n        # If the file is empty\n        except json.decoder.JSONDecodeError:\n            # Default return empty object with empty tasks list\n            return {'tasks': []}\n        # The file does not yet exist\n        except FileNotFoundError:\n            # Default return empty object with empty tasks list\n            return {'tasks': []}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_task(self, name=None, desc=None):\n        # A name is required to create a task\n        for k in self.get_tasks():\n            if name in keys_of(k):\n                raise ValueError('Task already exists')\n\n        if name is not None:\n            # desc can be None, so we can just append whatever we have\n            self.grindstone['tasks'].append( {name: desc} )\n        else:\n            # Raising errors is good, and makes tests easy.\n            raise ValueError('Tasks `name` cannot be None')", "response": "Adds a task to the list of tasks in the grindstone."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_task(self, task=None):\n        # Iterate over the list of tasks\n        for t in self.grindstone['tasks']:\n            # If they key of the task matches the task given\n            if key_of(t) == task:\n                # Remove that task\n                self.grindstone['tasks'].remove(t)\n                # Return True because something did happen\n                return True\n        # Return false because nothing happened\n        return False", "response": "Deletes a given task by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites the GRIndstone to self. grindstone_path.", "response": "def write_grindstone(self):\n        \"\"\"\n        Writes self.gs to self.grindstone_path.\n        \"\"\"\n        with open(self.grindstone_path, 'w') as f:\n            # Write the JSON dump of the file\n            f.write(json.dumps(self.grindstone))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a tuple for a given task", "response": "def get_task(self, task=None):\n        \"\"\"\n        Returns a (task, description) tuple for a given task\n        \"\"\"\n        # Iterate over the grindstone tasks\n        for t in self.grindstone['tasks']:\n            # if they key matches the task\n            if key_of(t) == task:\n                # Return this task\n                return t\n        # Otherwise return nothing\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_app_loggers(log_level, apps, handlers=None):\n\n    # Use 'default' handler provided by DEFAULT_LOGGING config if\n    # not supplied.\n    if handlers is None:\n        handlers = ['default']\n\n    # The log config expects the handlers value to be a list, so let's\n    # make sure of that here.\n    if not isinstance(handlers, list):\n        handlers = list(handlers)\n\n    app_loggers = {}\n    for app in apps:\n        app_loggers[app] = {\n            'level': log_level,\n            'handlers': handlers,\n            'propagate': False,\n        }\n\n    return app_loggers", "response": "Build a logger dict for the given log level and apps list."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _build_logging_config(level, apps_list, verbose, filename=None):\n    config = copy.deepcopy(DEFAULT_LOGGING)\n\n    # Swap out default stream handler for a file handler, if\n    # a filename is given\n    if filename:\n        config['handlers']['default'].update(\n            {\n                'class': 'logging.handlers.WatchedFileHandler',\n                'filename': filename,\n            }\n        )\n\n    if verbose:\n        config['handlers']['default']['formatter'] = 'verbose'\n\n    config['loggers'] = build_app_loggers(level, apps_list)\n\n    return config", "response": "Build the logging config with installed application\n    loggers at the given log level."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild and enables a logger with a list of the top - level list of the installed apps plus any additional app modules passed in.", "response": "def configure_installed_apps_logger(level, verbose=False,\n                                    additional_packages=None, filename=None):\n    \"\"\"Builds and enables a logger with a logger list of the top-level list of\n    installed app modules (based on package name) plus any additional\n    application packages passed in - for example, a user may want to log a\n    dependent package of one the installed apps.  The logger will write either\n    to the console or to a file based on the presence of the filename parameter.\n    Check that the LOGGING_CONFIG setting is None before we configure the logger\n    in order to prevent maintaining Django's list of log handlers.\"\"\"\n    if settings.LOGGING_CONFIG:\n        raise ImproperlyConfigured(LOGGING_CONFIG_ERROR_MSG)\n\n    app_set = _normalize_apps(settings.INSTALLED_APPS)\n    # Add any additional app modules to the set of apps we want to configure\n    if additional_packages:\n        # Make sure we're dealing with a list of additional apps before we\n        # convert to a set\n        if not isinstance(additional_packages, list):\n            additional_packages = list(additional_packages)\n        # Update the app set with these additional app modules\n        app_set.update(set(additional_packages))\n\n    config = _build_logging_config(\n        level, app_set, verbose, filename)\n\n    logging.config.dictConfig(config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ut12frame(treq, ind, ut1_unix):\n    if treq is None:  # have to do this since interp1 will return last index otherwise\n        return\n\n    treq = atleast_1d(treq)\n# %% handle human specified string scalar case\n    if treq.size == 1:\n        treq = datetime2unix(treq[0])\n# %% handle time range case\n    elif treq.size == 2:\n        tstartreq = datetime2unix(treq[0])\n        tendreq = datetime2unix(treq[1])\n        treq = ut1_unix[(ut1_unix > tstartreq) & (ut1_unix < tendreq)]\n    else:  # otherwise, it's a vector of requested values\n        treq = datetime2unix(treq)\n# %% get indices\n    \"\"\"\n    We use nearest neighbor interpolation to pick a frame index for each requested time.\n    \"\"\"\n    f = interp1d(ut1_unix, ind, kind='nearest', bounds_error=True,\n                 assume_sorted=True)  # it won't output nan for int case in Numpy 1.10 and other versions too\n    framereq = f(treq).astype(int64)\n    framereq = framereq[framereq >= 0]  # discard outside time limits\n    return framereq", "response": "Given treq output index to extract via rawDMCreader\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef datetime2unix(T):\n    T = atleast_1d(T)\n\n    ut1_unix = empty(T.shape, dtype=float)\n    for i, t in enumerate(T):\n        if isinstance(t, (datetime, datetime64)):\n            pass\n        elif isinstance(t, str):\n            try:\n                ut1_unix[i] = float(t)  # it was ut1_unix in a string\n                continue\n            except ValueError:\n                t = parse(t)  # datetime in a string\n        elif isinstance(t, (float, int)):  # assuming ALL are ut1_unix already\n            return T\n        else:\n            raise TypeError('I only accept datetime or parseable date string')\n\n        # ut1 seconds since unix epoch, need [] for error case\n        ut1_unix[i] = forceutc(t).timestamp()\n\n    return ut1_unix", "response": "converts datetime to UT1 unix epoch time\n    converts datetime to UT1 unix epoch time\n    converts datetime to UT1 unix epoch time\n    converts datetime to UT1 unix epoch time\n    converts datetime to datetime"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nensuring that a value is iterable and not some sort of string", "response": "def _is_iterable(val):\n    \"\"\"Ensure that a value is iterable and not some sort of string\"\"\"\n    try:\n        iter(val)\n    except (ValueError, TypeError):\n        return False\n    else:\n        return not isinstance(val, basestring)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download_url(url, destination, retries=None, retry_delay=None, runner=None):\n    runner = runner if runner is not None else FabRunner()\n    return try_repeatedly(\n        lambda: runner.run(\"wget --quiet --output-document '{0}' '{1}'\".format(destination, url)),\n        max_retries=retries,\n        delay=retry_delay\n    )", "response": "Download the given URL to the provided path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_install_sources(self):\n        if not self._sources:\n            return ''\n        parts = ['--no-index']\n        for source in self._sources:\n            parts.append(\"--find-links '{0}'\".format(source))\n        return ' '.join(parts)", "response": "Construct arguments to use alternative package indexes if there were sources supplied empty string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef install(self, release_id, upgrade=False):\n        release_path = os.path.join(self._releases, release_id)\n        if not self._runner.exists(release_path):\n            self._runner.run(\"{0} '{1}'\".format(self._venv_path, release_path))\n\n        cmd = [os.path.join(release_path, 'bin', 'pip'), 'install']\n        if upgrade:\n            cmd.append('--upgrade')\n\n        sources = self._get_install_sources()\n        if sources:\n            cmd.append(sources)\n\n        cmd.extend(\"'{0}'\".format(package) for package in self._packages)\n        return self._runner.run(' '.join(cmd))", "response": "Install target packages into a virtual environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninstalling the contents of the local directory into a release directory.", "response": "def install(self, release_id):\n        \"\"\"Install the contents of the local directory into a release directory.\n\n        If the directory for the given release ID does not exist on the remote\n        system, it will be created. The directory will be created according to\n        the standard Tunic directory structure (see :doc:`design`).\n\n        Note that the name and path of the local directory is irrelevant, only\n        the contents of the specified directory will be transferred to the remote\n        server. The contents will end up as children of the release directory on\n        the remote server.\n\n        :param str release_id: Timestamp-based identifier for this\n            deployment. If this ID corresponds to a directory that already\n            exists, contents of the local directory will be copied into\n            this directory.\n        :return: The results of the ``put`` command using Fabric. This return\n            value is an iterable of the paths of all files uploaded on the remote\n            server.\n        \"\"\"\n        release_path = os.path.join(self._releases, release_id)\n        if not self._runner.exists(release_path):\n            self._runner.run(\"mkdir -p '{0}'\".format(release_path))\n\n        # Make sure to remove any user supplied globs or trailing slashes\n        # so that we can ensure exactly the glob behavior we want from the\n        # put command.\n        local_path = self._local_path.strip('*').strip(os.path.sep)\n        return self._runner.put(os.path.join(local_path, '*'), release_path)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninstalling the local artifact into the remote release directory optionally with a different name than the artifact had locally.", "response": "def install(self, release_id):\n        \"\"\"Install the local artifact into the remote release directory, optionally\n        with a different name than the artifact had locally.\n\n        If the directory for the given release ID does not exist on the remote\n        system, it will be created. The directory will be created according to\n        the standard Tunic directory structure (see :doc:`design`).\n\n        :param str release_id: Timestamp-based identifier for this deployment.\n        :param int retries: Max number of times to retry downloads after a failure\n        :param float retry_delay: Number of seconds between download retries\n        :return: The results of the ``put`` command using Fabric. This return\n            value is an iterable of the paths of all files uploaded on the remote\n            server.\n        \"\"\"\n        release_path = os.path.join(self._releases, release_id)\n        if not self._runner.exists(release_path):\n            self._runner.run(\"mkdir -p '{0}'\".format(release_path))\n\n        # The artifact can optionally be renamed when being uploaded to\n        # remote server. Useful for when we need a consistent name for\n        # each deploy on the remote server but the local artifact includes\n        # version numbers or something.\n        if self._remote_name is not None:\n            destination = os.path.join(release_path, self._remote_name)\n        else:\n            destination = release_path\n\n        return self._runner.put(self._local_file, destination, mirror_local_mode=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the filename part of the path component from a URL.", "response": "def _get_file_from_url(url):\n        \"\"\"Get the filename part of the path component from a URL.\"\"\"\n        path = urlparse(url).path\n        if not path:\n            raise ValueError(\"Could not extract path from URL '{0}'\".format(url))\n        name = os.path.basename(path)\n        if not name:\n            raise ValueError(\"Could not extract file name from path '{0}'\".format(path))\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading and install an artifact into the remote release directory.", "response": "def install(self, release_id):\n        \"\"\"Download and install an artifact into the remote release directory,\n        optionally with a different name the the artifact had.\n\n        If the directory for the given release ID does not exist on the remote\n        system, it will be created. The directory will be created according to\n        the standard Tunic directory structure (see :doc:`design`).\n\n        :param str release_id: Timestamp-based identifier for this deployment.\n        :return: The results of the download function being run. This return value\n            should be the result of running a command with Fabric. By default\n            this will be the result of running ``wget``.\n        \"\"\"\n        release_path = os.path.join(self._releases, release_id)\n        if not self._runner.exists(release_path):\n            self._runner.run(\"mkdir -p '{0}'\".format(release_path))\n\n        # The artifact can optionally be renamed to something specific when\n        # downloaded on the remote server. In that case use the provided name\n        # in the download path. Otherwise, just use the last component of\n        # of the URL we're downloading.\n        if self._remote_name is not None:\n            destination = os.path.join(release_path, self._remote_name)\n        else:\n            destination = os.path.join(release_path, self._get_file_from_url(self._artifact_url))\n\n        # Note that although the default implementation of a download method\n        # accepts a FabRunner instance, we aren't passing our instance here.\n        # The reason being, that's only needed for testing the download_url\n        # method. If we were testing class, we'd mock out the download method\n        # anyway. So, it's not part of the public API of the download interface\n        # and we don't deal with it here.\n        return self._downloader(\n            self._artifact_url,\n            destination,\n            retries=self._retries,\n            retry_delay=self._retry_delay\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply a function to each element in an iterable and return a result list.", "response": "def pool_process(func, iterable, process_name='Pool processing', cpus=cpu_count()):\n    \"\"\"\n    Apply a function to each element in an iterable and return a result list.\n\n    :param func: A function that returns a value\n    :param iterable: A list or set of elements to be passed to the func as the singular parameter\n    :param process_name: Name of the process, for printing purposes only\n    :param cpus: Number of CPUs\n    :return: Result list\n    \"\"\"\n    with Timer('\\t{0} ({1}) completed in'.format(process_name, str(func))):\n        pool = Pool(cpus)\n        vals = pool.map(func, iterable)\n        pool.close()\n    return vals"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remover(file_path):\n    if os.path.isfile(file_path):\n        os.remove(file_path)\n        return True\n    elif os.path.isdir(file_path):\n        shutil.rmtree(file_path)\n        return True\n    else:\n        return False", "response": "Delete a file or directory path only if it exists."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve a file s creation date.", "response": "def creation_date(path_to_file, return_datetime=True):\n    \"\"\"\n    Retrieve a file's creation date.\n\n    Try to get the date that a file was created, falling back to when it was\n    last modified if that isn't possible.\n\n    See http://stackoverflow.com/a/39501288/1709587 for explanation.\n\n    :param path_to_file: File path\n    :param return_datetime: Bool, returns value in Datetime format\n    :return: Creation date\n    \"\"\"\n    if platform.system() == 'Windows':\n        created_at = os.path.getctime(path_to_file)\n    else:\n        stat = os.stat(path_to_file)\n        try:\n            created_at = stat.st_birthtime\n        except AttributeError:\n            # We're probably on Linux. No easy way to get creation dates here,\n            # so we'll settle for when its content was last modified.\n            created_at = stat.st_mtime\n\n    if return_datetime:\n        return datetime.fromtimestamp(created_at)\n    else:\n        return created_at"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfilters list of file paths to remove non - included remove excluded files and concatenate full paths.", "response": "def _get_filepaths(self):\n        \"\"\"Filters list of file paths to remove non-included, remove excluded files and concatenate full paths.\"\"\"\n        self._printer(str(self.__len__()) + \" file paths have been parsed in \" + str(self.timer.end))\n        if self._hash_files:\n            return pool_hash(self.filepaths)\n        else:\n            return self.filepaths"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef creation_dates(self, sort=True):\n        if not sort:\n            return pool_creation_date(self.filepaths)\n        else:\n            pcd = pool_creation_date(self.filepaths)\n            pcd.sort(key=itemgetter(1), reverse=True)\n            return pcd", "response": "Return a list of tuples created from list of walked paths."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef walk(self):\n        if self.parallelize:\n            self.filepaths = Sprinter(self.directory, self.filters, self.full_paths, self.pool_size, self._printer).sprinter()\n        else:\n            self.filepaths = Crawler(self.directory, self.filters, self.full_paths, self.topdown, self._printer).crawler()\n        return self._get_filepaths()", "response": "Walks the directory and returns a list of file paths."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef files(self):\n        self._printer('\\tFiles Walk')\n        for directory in self.directory:\n            for path in os.listdir(directory):\n                full_path = os.path.join(directory, path)\n                if os.path.isfile(full_path):\n                    if not path.startswith('.'):\n                        self.filepaths.append(full_path)\n        return self._get_filepaths()", "response": "Return list of files in root directory"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns list of folders in root directory", "response": "def folders(self):\n        \"\"\"Return list of folders in root directory\"\"\"\n        for directory in self.directory:\n            for path in os.listdir(directory):\n                full_path = os.path.join(directory, path)\n                if os.path.isdir(full_path):\n                    if not path.startswith('.'):\n                        self.filepaths.append(full_path)\n        return self._get_filepaths()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate path dirs files tuple for each path in directory. Executes filters and returns a dictionary of the tree_dict.", "response": "def get(self):\n        \"\"\"\n        Generate path, dirs, files tuple for each path in directory.  Executes filters if branches are not None\n        :return:\n        \"\"\"\n        for path, dirs, files in os.walk(self.directory):\n            folders = path[self.start:].split(os.sep)\n            if self.branches:\n                if self._filter(folders, 'folders'):\n                    files = dict.fromkeys(files)\n                    parent = reduce(dict.get, folders[:-1], self.tree_dict)\n                    parent[folders[-1]] = files\n            else:\n                files = dict.fromkeys(files)\n                parent = reduce(dict.get, folders[:-1], self.tree_dict)\n                parent[folders[-1]] = files\n        return self.tree_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a url pattern to the url manager.", "response": "def add_url(self, pattern, method=None, call=None):\n        \"\"\"Add a url pattern.\n\n        Args:\n            pattern (:obj:`str`): URL pattern to add. This is usually '/'\n                separated path. Parts of the URL can be parameterised using\n                curly braces.\n                Examples: \"/\", \"/path/to/resource\", \"/resoures/{param}\"\n            method (:obj:`str`, :obj:`list` of :obj:`str`, optional): HTTP\n                methods for the path specied. By default, GET method is added.\n                Value can be either a single method, by passing a string, or\n                multiple methods, by passing a list of strings.\n            call (callable): Callable corresponding to the url pattern and the\n                HTTP method specified.\n\n        Note:\n            A trailing '/' is always assumed in the pattern.\n\n        See Also:\n            :func:`drongo.managers.url.UrlManager.add`\n        \"\"\"\n        self._url_manager.add(pattern, method, call)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts other format to png", "response": "def convert_other_format(filename, format):\n    \"\"\"\n    \u8f6c\u6362\u4e3apng\u56fe\u7247\n    :param filename: \u56fe\u7247\u6587\u4ef6\u540d\n    :return:\n    \"\"\"\n    img = Image.open(filename)\n    rp = ReParser()\n    c_filename = rp.replace(r'\\..*$', format, filename)\n    img.save(c_filename)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving interference line from an image", "response": "def remove_interference_line(img):\n    \"\"\"\n    \u53bb\u9664\u5e72\u6270\u7ebf\n    :param img:\n    :return:\n    \"\"\"\n    pixdata = img.load()\n    w,h = img.size\n    for y in range(1,h-1):\n        for x in range(1,w-1):\n            count = 0\n            if pixdata[x,y-1] > 245:\n                count = count + 1\n            if pixdata[x,y+1] > 245:\n                count = count + 1\n            if pixdata[x-1,y] > 245:\n                count = count + 1\n            if pixdata[x+1,y] > 245:\n                count = count + 1\n            if count > 2:\n                pixdata[x,y] = 255\n    return img"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a thumbnail of the image.", "response": "def create_thumbnail(img, width, height):\n    \"\"\"\n    \u521b\u5efa\u7f29\u7565\u56fe\n    \u7f29\u7565\u56fe\u7684\u610f\u601d\u5c31\u662f\u7f29\u5c0f\n    :param img: \u56fe\u7247\u5bf9\u8c61\n    :param width: \u5bbd\n    :param height: \u9ad8\n    :return:\n    \"\"\"\n    size = (width, height)\n    img.thumbnail(size)\n    return img"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cut(img, left, above, right, down):\n    box = (left, above, right, down)\n    region = img.crop(box)\n    return region", "response": "Cuts the image to the specified bounds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npaste image in a new region", "response": "def paste(region, img, left, above, right, down):\n    \"\"\"\n    \u5c06\u6263\u7684\u56fe\u7c98\u8d34\u5230\u5236\u5b9a\u56fe\u7247\u4e0a\n    \u5f53\u4f60\u7c98\u8d34\u77e9\u5f62\u9009\u533a\u7684\u65f6\u5019\u5fc5\u987b\u4fdd\u8bc1\u5c3a\u5bf8\u4e00\u81f4\u3002\u6b64\u5916\uff0c\u77e9\u5f62\u9009\u533a\u4e0d\u80fd\u5728\u56fe\u50cf\u5916\u3002\u7136\u800c\u4f60\u4e0d\u5fc5\u4fdd\u8bc1\u77e9\u5f62\u9009\u533a\u548c\u539f\u56fe\u7684\u989c\u8272\u6a21\u5f0f\u4e00\u81f4\uff0c\n    \u56e0\u4e3a\u77e9\u5f62\u9009\u533a\u4f1a\u88ab\u81ea\u52a8\u8f6c\u6362\u989c\u8272\uff0c\u9057\u61be\u7684\u662f\uff0c\u53ea\u80fd\u6263\u77e9\u5f62\u56fe\u3002\n\n    :param region: \u6263\u51fa\u7684\u56fe\n    :param img: \u6307\u5b9a\u56fe\u7247\n    :param left: \u5de6\n    :param above: \u4e0a\n    :param right: \u53f3\n    :param down: \u4e0b\n    :return: \u88ab\u4fee\u6539\u8fc7\u7684\u56fe\u7247\u5bf9\u8c61\uff0c\u8fd8\u5728\u5185\u5b58\u4e2d\uff0c\u672a\u4fdd\u5b58\u3002\n    \"\"\"\n    region = region.transpose(Image.ROTATE_180)\n    box = (left, above, right, down)\n    img.paste(region, box)\n    return img"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resize(img, width, height):\n    return img.resize((width, height), Image.ANTIALIAS)", "response": "Resizes an image to a given width and height."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_exif_data(self, image):\n        exif_data = {}\n        info = image._getexif()\n        if info:\n            for tag, value in info.items():\n                decoded = TAGS.get(tag, tag)\n                if decoded == \"GPSInfo\":\n                    gps_data = {}\n                    for t in value:\n                        sub_decoded = GPSTAGS.get(t, t)\n                        gps_data[sub_decoded] = value[t]\n\n                    exif_data[decoded] = gps_data\n                else:\n                    exif_data[decoded] = value\n\n        return exif_data", "response": "Returns a dictionary from the exif data of an PIL Image item. Also converts the GPS Tags to the exif data of the PIL Image item."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the latitude and longitude of the current image from the exif data if available.", "response": "def get_lat_lon(self, exif_data):\n        \"\"\"Returns the latitude and longitude, if available, from the provided exif_data (obtained through get_exif_data above)\"\"\"\n        lat = None\n        lon = None\n\n        if \"GPSInfo\" in exif_data:\n            gps_info = exif_data[\"GPSInfo\"]\n\n            gps_latitude = self._get_if_exist(gps_info, \"GPSLatitude\")\n            gps_latitude_ref = self._get_if_exist(gps_info, 'GPSLatitudeRef')\n            gps_longitude = self._get_if_exist(gps_info, 'GPSLongitude')\n            gps_longitude_ref = self._get_if_exist(gps_info, 'GPSLongitudeRef')\n\n            if gps_latitude and gps_latitude_ref and gps_longitude and gps_longitude_ref:\n                lat = self._convert_to_degress(gps_latitude)\n                if gps_latitude_ref != \"N\":\n                    lat = 0 - lat\n\n                lon = self._convert_to_degress(gps_longitude)\n                if gps_longitude_ref != \"E\":\n                    lon = 0 - lon\n\n        return lat, lon"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the GPS coordinates of an image", "response": "def get_gps(self, image):\n        \"\"\"\u83b7\u53d6\u7ecf\u5ea6\uff0c\u7eac\u5ea6\"\"\"\n        exif_data = self.get_exif_data(image)\n        return self.get_lat_lon(exif_data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_reader(\n            self,\n            fd: IFileLike,\n            callback: typing.Callable[[IFileLike], typing.Any],\n    ) -> None:\n        \"\"\"Add a file descriptor to the processor and wait for READ.\n\n        Args:\n            fd (IFileLike): Any obect that exposes a 'fileno' method that\n                returns a valid file descriptor integer.\n            callback (typing.Callable[[IFileLike], typing.Any]): A function\n                that consumes the IFileLike object whenever the READ event is\n                fired.\n        \"\"\"\n        raise NotImplementedError()", "response": "Add a file descriptor to the processor and wait for READ event."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads the configuration data from a file.", "response": "def _load(self, path='config', filetype=None, relaxed=False, ignore=False):\n        \"\"\" load key value pairs from a file\n\n            Parameters:\n                path     - path to configuration data (see Note 1)\n                filetype - type component of dot-delimited path\n                relaxed  - if True, define keys on the fly (see Note 2)\n                ignore   - if True, ignore undefined keys in path\n\n            Return:\n                self\n\n            Notes:\n\n                1. The path can be:\n                    * an open file object with a readlines method\n                    * a dot delimited path to a file (see normalize_path)\n                    * an os-specific path to a file (relative to cwd)\n                    * an iterable of key=value strings\n\n                2. Normally keys read from the file must conform to keys\n                   previously defined for the Config. If the relaxed flag\n                   is True, any keys found in the file will be accepted.\n                   If the ignore flag is True, and kyes found in the file\n                   that are not previously defined are ignored.\n        \"\"\"\n        for num, line in enumerate(\n                    un_comment(load_lines_from_path(path, filetype)),\n                    start=1,\n                ):\n            if not line:\n                continue\n            try:\n                key, val = line.split('=', 1)\n                key = key.strip()\n                val = val.strip()\n                if relaxed:\n                    self._define(key)\n                try:\n                    level, itemname = self.__lookup(key)\n                except KeyError:\n                    if ignore:\n                        continue\n                    raise\n                item = level.get(itemname)\n                if item is None:\n                    raise KeyError(itemname)\n                item.load(val)\n            except Exception as e:\n                args = e.args or ('',)\n                msg = 'line {} of config: {}'. format(num, args[0])\n                e.args = (msg,) + args[1:]\n                raise\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nenforcing env > value when loading from file", "response": "def load(self, value):\n        \"\"\" enforce env > value when loading from file \"\"\"\n        self.reset(\n            value,\n            validator=self.__dict__.get('validator'),\n            env=self.__dict__.get('env'),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_img_path(instance, filename):\n    upload_path = '/'.join(\n        ['img', instance._meta.app_label, str(now.year), str(now.month), filename]\n    )\n    return upload_path", "response": "Sets upload_to dynamically\n    Sets upload_to dynamically\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save(self, *args, **kwargs):\n        self.text = clean_text(self.text)\n        self.text_formatted = format_text(self.text)\n        super(BaseUserContentModel, self).save(*args, **kwargs)", "response": "Clean text and save formatted version."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave the content image.", "response": "def save(self, *args, **kwargs):\n        \"\"\"\n        We want to do dimension checks and/or resizing BEFORE the original image is saved.\n        Note that if we can't get image dimensions, it's considered an invalid image\n        and we return without saving.\n        If the image has changed, sets self.thumb to None, triggering post_save thumbnailer.\n        \"\"\"\n        img = self.image\n        # Check if this is an already existing photo\n        try:\n            old_self = self.__class__.objects.get(id=self.id)\n        except ObjectDoesNotExist:\n            old_self = None\n        #  Run on new and changed images:\n        if self.id is None or self.thumb is None or (old_self.image != img):\n            try:\n                height = img.height\n                width = img.width\n            except Exception as error:\n                # We aren't dealing with a reliable image, so....\n                #print(\"Error getting image height or width: {}\".format(error))\n                return\n            # If image is vertical or square (treated as vertical)...\n            if height >= width:\n                self.is_vertical = True\n            if width > 900 or height > 1200:\n                \"\"\"\n                The image is larger than we want.\n                We're going to downsize it BEFORE it is saved,\n                using PIL on the InMemoryUploadedFile.\n                \"\"\"\n                image = Image.open(img)\n                image.resize((900, 1200), Image.ANTIALIAS)\n                image.save(img.path)\n            try:\n                ezthumb_field = get_thumbnailer(self.image)\n                self.thumb = ezthumb_field.get_thumbnail({\n                    'size': (80, 80),\n                    'crop': ',-10'\n                }).url.replace(\"\\\\\", \"/\")\n            except Exception as error:\n                print(\"Error thumbnailing {}: {}\".format(self.id, error))\n        super(ContentImage, self).save(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_script(create=None):  # noqa: E501\n    if connexion.request.is_json:\n        create = Create.from_dict(connexion.request.get_json())  # noqa: E501\n\n    if(not hasAccess()):\n        return redirectUnauthorized()\n\n    driver = LoadedDrivers.getDefaultDriver()\n    driver.saveScript(create.script.name, create.script.content)\n    return Response(status=200, body={'file-name': create.script.name})", "response": "Create a new script"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_script(delete=None):  # noqa: E501\n    if connexion.request.is_json:\n        delete = Delete.from_dict(connexion.request.get_json())  # noqa: E501\n\n    if(not hasAccess()):\n        return redirectUnauthorized()\n\n    driver = LoadedDrivers.getDefaultDriver()\n    driver.deleteScript(delete.script.name)\n    return Response(status=200, body={})", "response": "Delete a script from the node"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rename_script(rename=None):  # noqa: E501\n    if connexion.request.is_json:\n        rename = Rename.from_dict(connexion.request.get_json())  # noqa: E501\n\n    if(not hasAccess()):\n        return redirectUnauthorized()\n\n    driver = LoadedDrivers.getDefaultDriver()\n    if (not driver.renameScript(rename.original.name, rename.new.name)):\n        return ErrorResponse(status=500, message='Cannot rename to an existing file.')\n    return Response(status=200, body={'file-name': rename.new.name})", "response": "Rename a script in a node"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_script(save=None):  # noqa: E501\n    if connexion.request.is_json:\n        save = Save.from_dict(connexion.request.get_json())  # noqa: E501\n\n    if(not hasAccess()):\n        return redirectUnauthorized()\n\n    driver = LoadedDrivers.getDefaultDriver()\n    driver.saveScript(save.script.name, save.script.content)\n    return Response(status=200, body={'file-name': save.script.name})", "response": "Save a script\n\n    Save a script # noqa: E501\n\n    :param Scripts: The data needed to save this script\n    :type Scripts: dict | bytes\n\n    :rtype: Response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_headline_from_description(sender, instance, *args, **kwargs):\n    '''\n    Auto generate the headline of the node from the first lines of the description.\n    '''\n    lines = instance.description.split('\\n')\n    headline = truncatewords(lines[0], 20)\n    if headline[:-3] == '...':\n        headline = truncatechars(headline.replace(' ...', ''), 250)  # Just in case the words exceed char limit.\n    else:\n        headline = truncatechars(headline, 250)\n    instance.headline = headline", "response": "Auto generate the headline of the node from the first lines of the description."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef story_root_for_new_outline(sender, instance, created, *args, **kwargs):\n    '''\n    If a new instance of a Outline is created, also create\n    the root node of the story tree.\n    '''\n    if created and isinstance(instance, Outline):\n        streeroot = StoryElementNode.add_root(outline=instance, story_element_type='root')\n        streeroot.save()\n        instance.refresh_from_db()", "response": "Create a story root node for a new outline."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall when an arc element is added to a story element node and any missing elements or locations are added to any missing elements or locations.", "response": "def story_node_add_arc_element_update_characters_locations(sender, instance, created, *args, **kwargs):\n    '''\n    If an arc element is added to a story element node, add any missing elements or locations.\n    '''\n    arc_node = ArcElementNode.objects.get(pk=instance.pk)\n    logger.debug('Scanning arc_node %s' % arc_node)\n    if arc_node.arc_element_type == 'root':\n        logger.debug(\"root node. skipping...\")\n    else:\n        logger.debug('Checking arc node for story element relationship...')\n        if arc_node.story_element_node:\n            logger.debug('Found a story element node for arc element...')\n            # This change was initiated by the arc element node as opposed to the story node.\n            story_node = arc_node.story_element_node\n            if arc_node.assoc_characters.count() > 0:\n                logger.debug('Found %d characters to add...' % arc_node.assoc_characters.count())\n                for character in arc_node.assoc_characters.all():\n                    story_node.assoc_characters.add(character)\n            if arc_node.assoc_locations.count() > 0:\n                logger.debug('Found %d locations to add...' % arc_node.assoc_locations.count())\n                for location in arc_node.assoc_locations.all():\n                    story_node.assoc_locations.add(location)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nevaluating attempts to link an arc to a story node from another outline.", "response": "def validate_arc_links_same_outline(sender, instance, *args, **kwargs):\n    '''\n    Evaluates attempts to link an arc to a story node from another outline.\n    '''\n    if instance.story_element_node:\n        if instance.story_element_node.outline != instance.parent_outline:\n            raise IntegrityError(_('An arc cannot be associated with an story element from another outline.'))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_character_instance_valid_for_arc(sender, instance, action, reverse, pk_set, *args, **kwargs):\n    '''\n    Evaluate attempts to assign a character instance to ensure it is from same\n    outline.\n    '''\n    if action == 'pre_add':\n        if reverse:\n            # Fetch arc definition through link.\n            for apk in pk_set:\n                arc_node = ArcElementNode.objects.get(pk=apk)\n                if arc_node.parent_outline != instance.outline:\n                    raise IntegrityError(_('Character Instance and Arc Element must be from same outline.'))\n        else:\n            for cpk in pk_set:\n                char_instance = CharacterInstance.objects.get(pk=cpk)\n                if char_instance.outline != instance.parent_outline:\n                    raise IntegrityError(_('Character Instance and Arc Element must be from the same outline.'))", "response": "Validate that a character instance is from same ArcElement or from same ArcElement outline."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate that the location instance is from same outline as the arc element.", "response": "def validate_location_instance_valid_for_arc(sender, instance, action, reverse, pk_set, *args, **kwargs):\n    '''\n    Evaluates attempts to add location instances to arc, ensuring they are from same outline.\n    '''\n    if action == 'pre_add':\n        if reverse:\n            # Fetch arc definition through link.\n            for apk in pk_set:\n                arc_node = ArcElementNode.objects.get(pk=apk)\n                if arc_node.parent_outline != instance.outline:\n                    raise IntegrityError(_('Location instance must be from same outline as arc element.'))\n        else:\n            for lpk in pk_set:\n                loc_instance = LocationInstance.objects.get(pk=lpk)\n                if loc_instance.outline != instance.parent_outline:\n                    raise IntegrityError(_('Location Instance must be from the same outline as arc element.'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates that a character is from the same outline as the story node.", "response": "def validate_character_for_story_element(sender, instance, action, reverse, pk_set, *args, **kwargs):\n    '''\n    Validates that character is from the same outline as the story node.\n    '''\n    if action == 'pre_add':\n        if reverse:\n            for spk in pk_set:\n                story_node = StoryElementNode.objects.get(pk=spk)\n                if instance.outline != story_node.outline:\n                    raise IntegrityError(_('Character Instance must be from the same outline as story node.'))\n        else:\n            for cpk in pk_set:\n                char_instance = CharacterInstance.objects.get(pk=cpk)\n                if char_instance.outline != instance.outline:\n                    raise IntegrityError(_('Character Instance must be from the same outline as story node.'))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating that the location is from same outline as story node.", "response": "def validate_location_for_story_element(sender, instance, action, reverse, pk_set, *args, **kwargs):\n    '''\n    Validates that location is from same outline as story node.\n    '''\n    if action == 'pre_add':\n        if reverse:\n            for spk in pk_set:\n                story_node = StoryElementNode.objects.get(pk=spk)\n                if instance.outline != story_node.outline:\n                    raise IntegrityError(_('Location must be from same outline as story node.'))\n        else:\n            for lpk in pk_set:\n                loc_instance = LocationInstance.objects.get(pk=lpk)\n                if instance.outline != loc_instance.outline:\n                    raise IntegrityError(_('Location must be from the same outline as story node.'))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate the generation of story elements.", "response": "def validate_generations_for_story_elements(\n        sender,\n        instance,\n        action,\n        target_node_type=None,\n        target_node=None,\n        pos=None,\n        *args,\n        **kwargs\n):\n    '''\n    Unlike arc nodes, for which we just warn about structure, the story tree\n    allowed parent/child rules must be strictly enforced.\n    '''\n    if action == 'add_child':\n        if instance.story_element_type not in STORY_NODE_ELEMENT_DEFINITIONS[target_node_type]['allowed_parents']:\n            raise IntegrityError(_('%s is not an allowed child of %s' % (target_node_type,\n                                                                         instance.story_element_type)))\n    if action == 'update':\n        parent = instance.get_parent()\n        children = instance.get_children()\n        if parent.story_element_type not in STORY_NODE_ELEMENT_DEFINITIONS[target_node_type]['allowed_parents']:\n            raise IntegrityError(_('%s is not an allowed child of %s' % (target_node_type, parent.story_element_type)))\n        if children:\n            for child in children:\n                if target_node_type not in STORY_NODE_ELEMENT_DEFINITIONS[child.story_element_type]['allowed_parents']:\n                    raise IntegrityError(_('%s is not permitted to be a parent of %s' % (\n                        target_node_type, child.story_element_type)))\n    if action == 'add_sibling':\n        parent = instance.get_parent()\n        if parent.story_element_type not in STORY_NODE_ELEMENT_DEFINITIONS[target_node_type]['allowed_parents']:\n            raise IntegrityError(_('%s is not an allowed child of %s' % (target_node_type, parent.story_element_type)))\n    if action == 'move':\n        if not pos or 'sibling' in pos or 'right' in pos or 'left' in pos:\n            parent = target_node.get_parent()\n            if (parent.story_element_type not in\n                STORY_NODE_ELEMENT_DEFINITIONS[instance.story_element_type]['allowed_parents']):\n                raise IntegrityError(_('%s is not an allowed child of %s' % (\n                    instance.story_element_type,\n                    parent.story_element_type\n                )))\n        if 'child' in pos:\n            if (target_node.story_element_type not in\n                STORY_NODE_ELEMENT_DEFINITIONS[instance.story_element_type]['allowed_parents']):\n                raise IntegrityError(_('%s is not an allowed child of %s' % (\n                    instance.story_element_type,\n                    target_node.story_element_type\n                )))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef options(self, request, *args, **kwargs):\n        response = HttpResponse()\n        response['Allow'] = ', '.join(self.allowed_methods)\n        response['Content-Length'] = 0\n        return response", "response": "Handles responding to requests for the OPTIONS HTTP verb"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_redirect_url(self, request, **kwargs):\n        if self.url:\n            url = self.url % kwargs\n            args = request.META.get('QUERY_STRING', '')\n            if args and self.query_string:\n                url = \"%s?%s\" % (url, args)\n            return url\n        else:\n            return None", "response": "Returns the URL to redirect to."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the given possible_identifier can be used as an an identifier in Python 2.", "response": "def is_python2_identifier(possible_identifier):\n    \"\"\"\n    Returns `True` if the given `possible_identifier` can be used as an\n    identifier in Python 2.\n    \"\"\"\n    match = _python2_identifier_re.match(possible_identifier)\n    return bool(match) and not iskeyword(possible_identifier)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if the given possible_identifier can be used as an an identifier in Python 3.", "response": "def is_python3_identifier(possible_identifier):\n    \"\"\"\n    Returns `True` if the given `possible_identifier` can be used as an\n    identifier in Python 3.\n    \"\"\"\n    possible_identifier = unicodedata.normalize('NFKC', possible_identifier)\n    return (\n        bool(possible_identifier) and\n        _is_in_id_start(possible_identifier[0]) and\n        all(map(_is_in_id_continue, possible_identifier[1:]))\n    ) and not iskeyword(possible_identifier)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unique(iterable):\n    seen = set()\n    for obj in iterable:\n        if obj not in seen:\n            yield obj\n            seen.add(obj)", "response": "Returns an iterator that yields the first occurence of a hashable item in\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef contains(self, x, y) -> bool:\n        if x < self._left or x > self._right or y < self._top or y > self._bottom:\n            return False\n        return True", "response": "Checks if the given x y position is within the area of this region."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_in_bounds(self, width, height) -> bool:\n        if self._top < 0 \\\n                or self._bottom > height \\\n                or self._left < 0 \\\n                or self._right > width:\n            return False\n        return True", "response": "Check if this region is contained within the bounds of a given stage size."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef canvas_resize(self, scale):\n        self._top *= scale\n        self._bottom *= scale\n        self._left *= scale\n        self._right *= scale\n        self._calibrate_to_rect()", "response": "Resize this region against the entire axis space."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the distance between the x and y of the two regions.", "response": "def distance(r1: 'Region', r2: 'Region'):\n        \"\"\" Calculate distance between the x and y of the two regions.\"\"\"\n        return math.sqrt((r2.x - r1.x) ** 2 + (r2.y - r1.y) ** 2)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fast_distance(r1: 'Region', r2: 'Region'):\n        return abs(r1.x - r2.x) + abs(r1.y - r2.y)", "response": "A quicker way of calculating approximate distance. Lower accuracy but faster results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrooting Mean Square\" Arguments: x (seq of float): A sequence of numerical values Returns: The square root of the average of the squares of the values math.sqrt(sum(x_i**2 for x_i in x) / len(x)) or return (np.array(x) ** 2).mean() ** 0.5 >>> rms([0, 2, 4, 4]) 3.0", "response": "def rms(x):\n    \"\"\"\"Root Mean Square\"\n\n    Arguments:\n        x (seq of float): A sequence of numerical values\n\n    Returns:\n        The square root of the average of the squares of the values\n\n        math.sqrt(sum(x_i**2 for x_i in x) / len(x))\n\n        or\n\n        return (np.array(x) ** 2).mean() ** 0.5\n\n    >>> rms([0, 2, 4, 4])\n    3.0\n    \"\"\"\n    try:\n        return (np.array(x) ** 2).mean() ** 0.5\n    except:\n        x = np.array(dropna(x))\n        invN = 1.0 / len(x)\n        return (sum(invN * (x_i ** 2) for x_i in x)) ** .5"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rmse(target, prediction, relative=False, percent=False):\n    relative = relative or percent\n    prediction = pd.np.array(prediction)\n    target = np.array(target)\n    err = prediction - target\n    if relative:\n        denom = target\n        # Avoid ZeroDivisionError: divide by prediction rather than target where target==0\n        denom[denom == 0] = prediction[denom == 0]\n        # If the prediction and target are both 0, then the error is 0 and should be included in the RMSE\n        # Otherwise, the np.isinf() below would remove all these zero-error predictions from the array.\n        denom[(denom == 0) & (target == 0)] = 1\n        err = (err / denom)\n        err = err[(~ np.isnan(err)) & (~ np.isinf(err))]\n    return 100 * rms(err) if percent else rms(err)", "response": "Root Mean Square Error for a single base - set of classes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean_dataframe(df):\n    df = df.fillna(method='ffill')\n    df = df.fillna(0.0)\n    return df", "response": "Fill NaNs with the previous value the next value then 1. 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clean_dataframes(dfs):\n    if isinstance(dfs, (list)):\n        for df in dfs:\n            df = clean_dataframe(df)\n        return dfs\n    else:\n        return [clean_dataframe(dfs)]", "response": "Removes NaNs from the previous value and next value of the next value of the previous value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_symbols_from_list(list_name):\n    try:\n        # quant software toolkit has a method for retrieving lists of symbols like S&P500 for 2012 with 'sp5002012'\n        import QSTK.qstkutil.DataAccess as da\n        dataobj = da.DataAccess('Yahoo')\n    except ImportError:\n        raise\n    except:\n        return []\n    try:\n        return dataobj.get_symbols_from_list(list_name)\n    except:\n        raise", "response": "Retrieve a named list of strings ( symbols ) that are members of the S&P 500 in 2012"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_symbols(symbols, *args):\n    if (hasattr(symbols, '__iter__') and not any(symbols)) \\\n            or (isinstance(symbols, (list, tuple, Mapping)) and not symbols):\n        return []\n    if isinstance(symbols, basestring):\n        # # FIXME: find a direct API for listing all possible symbols\n        # try:\n        #     return list(set(dataobj.get_symbols_from_list(symbols)))\n        # except:\n        return [s.upper().strip() for s in (symbols.split(',') + list(str(a) for a in args))]\n    else:\n        ans = []\n        for sym in (list(symbols) + list(args)):\n            tmp = make_symbols(sym)\n            ans = ans + tmp\n        return list(set(ans))", "response": "Return a list of uppercase strings like GOOG AAPL XOM..."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_time_series(x, t=pd.Timestamp(datetime.datetime(1970, 1, 1)), freq=None):\n    if isinstance(x, pd.DataFrame):\n        x = pd.Series(x[x.columns[0]])\n    elif not isinstance(x, pd.Series) and (not isinstance(t, (pd.Series, pd.Index, list, tuple)) or not len(t)):\n        #warnings.warn(\"Coercing a non-Series\")\n        if len(x) == 2:\n            t, x = listify(x[0]), listify(x[1])\n        elif len(x) >= 2:\n            try:\n                t, x = zip(*x)\n            except (ValueError, IndexError, TypeError):\n                pass\n        x = pd.Series(x)\n    else:\n        if isinstance(t, (datetime.datetime, pd.Timestamp)):\n            t = pd.Timestamp(t)\n        else:\n            x = pd.Series(listify(x), index=listify(t))\n    if not isinstance(x, pd.Series):\n        raise TypeError(\"`pug.invest.util.make_time_series(x, t)` expects x to be a type that\"\n                        \" can be coerced to a Series object, but it's type is: {0}\"\n                        .format(type(x)))\n    # By this point x must be a Series, only question is whether its index needs to be converted to a DatetimeIndex\n    if x.index[0] != 0 and isinstance(x.index[0], (datetime.date, datetime.datetime, pd.Timestamp,\n                                      basestring, float, np.int64, int)):\n        t = x.index\n    elif isinstance(t, (datetime.date, datetime.datetime, pd.Timestamp, basestring, float, np.int64, int)):\n        if not freq:\n            freq = '15min'\n            warnings.warn('Assumed time series freq to be {0} though no freq argument was provided!'\n                          .format(freq), RuntimeWarning)\n        t = pd.date_range(t, periods=len(x), freq=freq)\n    x = pd.Series(x, index=t)\n    if isinstance(x, pd.Series):\n        x.index = pd.DatetimeIndex(x.index.values)\n    return x", "response": "Convert a 2 - D array of time pairs or pair of time vectors into a pd. Series time - series\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate numpy 2 - D meshgrid from 3 + columns in a Pandas DataFrame", "response": "def pandas_mesh(df):\n    \"\"\"Create numpy 2-D \"meshgrid\" from 3+ columns in a Pandas DataFrame\n\n    Arguments:\n      df (DataFrame): Must have 3 or 4 columns of numerical data\n\n    Returns:\n      OrderedDict: column labels from the data frame are the keys, values are 2-D matrices\n        All matrices have shape NxM, where N = len(set(df.iloc[:,0])) and M = len(set(df.iloc[:,1]))\n\n    >>> pandas_mesh(pd.DataFrame(np.arange(18).reshape(3,6),\n    ...                          columns=list('ABCDEF'))).values()  # doctest: +NORMALIZE_WHITESPACE\n    [array([[ 0,  6, 12],\n            [ 0,  6, 12],\n            [ 0,  6, 12]]),\n     array([[ 1,  1,  1],\n            [ 7,  7,  7],\n            [13, 13, 13]]),\n     array([[  2.,  nan,  nan],\n            [ nan,   8.,  nan],\n            [ nan,  nan,  14.]]),\n     array([[  3.,  nan,  nan],\n            [ nan,   9.,  nan],\n            [ nan,  nan,  15.]]),\n     array([[  4.,  nan,  nan],\n            [ nan,  10.,  nan],\n            [ nan,  nan,  16.]]),\n     array([[  5.,  nan,  nan],\n            [ nan,  11.,  nan],\n            [ nan,  nan,  17.]])]\n    \"\"\"\n    xyz = [df[c].values for c in df.columns]\n    index = pd.MultiIndex.from_tuples(zip(xyz[0], xyz[1]), names=['x', 'y'])\n    # print(index)\n    series = [pd.Series(values, index=index) for values in xyz[2:]]\n    # print(series)\n    X, Y = np.meshgrid(sorted(list(set(xyz[0]))), sorted(list(set(xyz[1]))))\n    N, M = X.shape\n    Zs = []\n    # print(Zs)\n    for k, s in enumerate(series):\n        Z = np.empty(X.shape)\n        Z[:] = np.nan\n        for i, j in itertools.product(range(N), range(M)):\n            Z[i, j] = s.get((X[i, j], Y[i, j]), np.NAN)\n        Zs += [Z]\n    return OrderedDict((df.columns[i], m) for i, m in enumerate([X, Y] + Zs))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef integrated_change(ts, integrator=integrate.trapz, clip_floor=None, clip_ceil=float('inf')):\n    integrator = get_integrator(integrator)\n    if clip_floor is None:\n        clip_floor = ts[0]\n    if clip_ceil < clip_floor:\n        polarity = -1\n        offset, clip_floor, clip_ceil, = clip_ceil, clip_ceil, clip_floor\n    else:\n        polarity, offset = 1, clip_floor\n    clipped_values = np.clip(ts.values - offset, clip_floor, clip_ceil)\n    print(polarity, offset, clip_floor, clip_ceil)\n    print(clipped_values)\n    integrator_types = set(['trapz', 'cumtrapz', 'simps', 'romb'])\n    if integrator in integrator_types:\n        integrator = getattr(integrate, integrator)\n    integrator = integrator or integrate.trapz\n    # datetime units converted to seconds (since 1/1/1970)\n    return integrator(clipped_values, ts.index.astype(np.int64) / 10 ** 9)", "response": "Integrate a time series to a new value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef insert_crossings(ts, thresh):\n    # import time\n    # tic0 = time.clock(); tic = tic0\n\n    # int64 for fast processing, pandas.DatetimeIndex is 5-10x slower, 0.3 ms\n    index = ts.index\n    index_type = type(index)\n    ts.index = ts.index.astype(np.int64)\n    # toc = time.clock();\n    # print((toc-tic)*1000); tic = time.clock()\n\n    # value immediately before an upward thresh crossing, 6 ms\n    preup = ts[(ts < thresh) & (ts.shift(-1) > thresh)]\n    # toc = time.clock();\n    # print((toc-tic)*1000); tic = time.clock()\n\n    # values immediately after an upward thresh crossing, 4 ms\\\n    postup = ts[(ts.shift(1) < thresh) & (ts > thresh)]\n    # toc = time.clock();\n    # print((toc-tic)*1000); tic = time.clock()\n\n    # value immediately after a downward thresh crossing, 1.8 ms\n    postdown = ts[(ts < thresh) & (ts.shift(1) > thresh)]\n    # toc = time.clock();\n    # print((toc-tic)*1000); tic = time.clock()\n\n    # value immediately before an upward thresh crossing, 1.9 ms\n    predown = ts[(ts.shift(-1) < thresh) & (ts > thresh)]\n    # toc = time.clock();\n    # print((toc-tic)*1000); tic = time.clock()\n\n    # upward slope (always positive) between preup and postup in units of\n    # \"value\" per nanosecond (timestamps convert to floats as nanoseconds), 0.04 ms\n    slopeup = (postup.values - preup.values) / (postup.index.values - preup.index.values).astype(np.float64)\n    # toc = time.clock();\n    # print((toc-tic)*1000); tic = time.clock()\n\n    # upward crossing point index/time, 0.04 ms\n    tup = preup.index.values + ((thresh - preup.values) / slopeup).astype(np.int64)\n    # toc = time.clock();\n    # print((toc-tic)*1000); tic = time.clock()\n\n    # downward slope (always negative) between predown and postdown in units of\n    # \"value\" per nanosecond (timestamps convert to floats as nanoseconds), 0.03 ms\n    slopedown = (postdown.values - predown.values) / \\\n                (postdown.index.values - predown.index.values).astype(np.float64)\n    # toc = time.clock();\n    # print((toc-tic)*1000); tic = time.clock()\n\n    # upward crossing point index/time, 0.02 ms\n    tdown = predown.index.values + ((thresh - predown.values) / slopedown).astype(np.int64)\n    # toc = time.clock();\n    # print((toc-tic)*1000); tic = time.clock()\n\n    # insert crossing points into time-series (if it had a regular sample period before, it won't now!), 2.0 ms\n    ts.index = index  # pd.DatetimeIndex(ts.index)\n    # toc = time.clock();\n    # print((toc-tic)*1000); tic = time.clock()\n\n    # insert crossing points into time-series (if it had a regular sample period before, it won't now!), 2.0 ms\n    ts = ts.append(pd.Series(thresh * np.ones(len(tup)), index=index_type(tup.astype(np.int64))))\n    # toc = time.clock();\n    # print((toc-tic)*1000); tic = time.clock()\n\n    # insert crossing points into time-series (if it had a regular sample period before, it won't now!), 1.9 ms\n    ts = ts.append(pd.Series(thresh * np.ones(len(tdown)), index=index_type(tdown.astype(np.int64))))\n    # toc = time.clock();\n    # print((toc-tic)*1000); tic = time.clock()\n\n    # if you don't `sort_index()`, numerical integrators in `scipy.integrate` will give the wrong answer, 0.1 ms\n    ts = ts.sort_index()\n    # toc = time.clock();\n    # if you don't `sort_index()`, numerical integrators in `scipy.integrate` will give the wrong answer\n    # print((toc-tic)*1000); tic = time.clock()\n    # print((toc-tic0)*1000);\n    return ts", "response": "Insert or append threshold crossings into a timeseries."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the scipy. integrator indicated by an index name or integrator_function tuple or raises AttributeError if integrator is not a scipy. integrator", "response": "def get_integrator(integrator):\n    \"\"\"Return the scipy.integrator indicated by an index, name, or integrator_function\n\n    >> get_integrator(0)\n    \"\"\"\n    integrator_types = set(['trapz', 'cumtrapz', 'simps', 'romb'])\n    integrator_funcs = [integrate.trapz, integrate.cumtrapz, integrate.simps, integrate.romb]\n\n    if isinstance(integrator, int) and 0 <= integrator < len(integrator_types):\n        integrator = integrator_types[integrator]\n    if isinstance(integrator, basestring) and integrator in integrator_types:\n        return getattr(integrate, integrator)\n    elif integrator in integrator_funcs:\n        return integrator\n    else:\n        print('Unsupported integration rule: {0}'.format(integrator))\n        print('Expecting one of these sample-based integration rules: %s' % (str(list(integrator_types))))\n        raise AttributeError\n    return integrator"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nclips the tops off at a given threshold within a TimeSeries.", "response": "def clipped_area(ts, thresh=0, integrator=integrate.trapz):\n    \"\"\"Total value * time above the starting value within a TimeSeries\n\n    Arguments:\n      ts (pandas.Series): Time series to be integrated.\n      thresh (float): Value to clip the tops off at (crossings will be interpolated)\n\n    References:\n      http://nbviewer.ipython.org/gist/kermit666/5720498\n\n    >>> t = ['2014-12-09T00:00', '2014-12-09T00:15', '2014-12-09T00:30', '2014-12-09T00:45',\n    ...      '2014-12-09T01:00', '2014-12-09T01:15', '2014-12-09T01:30', '2014-12-09T01:45']\n    >>> import pandas as pd\n    >>> ts = pd.Series([217, 234, 235, 231, 219, 219, 231, 232], index=pd.to_datetime(t))\n    >>> clipped_area(ts, thresh=230)  # doctest: +ELLIPSIS\n    8598.52941...\n    >>> clipped_area(ts, thresh=234)  # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE\n    562.5\n    >>> clipped_area(pd.Series(ts.values, index=ts.index.values.astype(pd.np.int64)),\n    ...              thresh=234)  # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE\n    562.5\n    \"\"\"\n    integrator = get_integrator(integrator or 0)\n    ts = insert_crossings(ts, thresh) - thresh\n    ts = ts[ts >= 0]\n    # timestamp is in nanoseconds (since 1/1/1970) but this converts it to seconds (SI units)\n    return integrator(ts, ts.index.astype(np.int64)) / 1.0e9"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clipping_params(ts, capacity=100, rate_limit=float('inf'), method=None, max_attempts=100):\n    VALID_METHODS = ['L-BFGS-B', 'TNC', 'SLSQP', 'COBYLA']\n    # print('in clipping params for ts.index={0} and method={1}'.format(ts.index[0], method))\n    ts.index = ts.index.astype(np.int64)\n    costs = []\n\n    def cost_fun(x, *args):\n        thresh = x[0]\n        ts, capacity, bounds = args\n        integral = clipped_area(ts, thresh=thresh)\n        terms = np.array([(10. * (integral - capacity) / capacity) ** 2,\n                        2. / 0.1**((bounds[0] - thresh) * capacity / bounds[0]),\n                        2. / 0.1**((thresh - bounds[1]) * capacity / bounds[1]),\n                        1.2 ** (integral / capacity)])\n        return sum(terms)\n\n    bounds = (ts.min(), ts.max())\n    done, attempts = 0, 0\n    thresh0 = bounds[0] + 0.5 * (bounds[1] - bounds[0])\n    if not method or not method in VALID_METHODS:\n        while attempts < max_attempts and not done:\n            for optimizer_method in VALID_METHODS:\n                optimum = minimize(fun=cost_fun, x0=[thresh0], bounds=[bounds], args=(ts, capacity, bounds), method=optimizer_method)\n                if optimum.success:\n                    done = True\n                    break\n            if done:\n                break\n            attempts += 1\n            thresh0 = bounds[0] + random.random() * (bounds[1] - bounds[0])\n    else:\n        optimum = minimize(fun=cost_fun, x0=[thresh0], bounds=[bounds], args=(ts, capacity, bounds), method=method)\n    thresh = optimum.x[0]\n    integral = clipped_area(ts, thresh=thresh)\n    params = dict(optimum)\n    params.update({'costs': costs, 'threshold': thresh, 'initial_guess': thresh0, 'attempts': attempts,\n                   'integral': integral, 'method': method})\n    return params", "response": "This function takes a time series and attempts to clip to a maximum value of a time series."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the start end and threshold that clips the value of a time series.", "response": "def discrete_clipping_params(ts, capacity=100, rate_limit=float('inf')):\n    \"\"\"Start, end, and threshold that clips the value of a time series the most, given a limitted \"capacity\" and \"rate\"\n\n    Assumes that the integrated maximum includes the peak (instantaneous maximum).\n    Assumes that the threshold can only set to one of the values of the Series.\n\n    Arguments:\n      ts (TimeSeries): Time series to attempt to clip to as low a max value as possible\n      capacity (float): Total \"funds\" or \"energy\" available for clipping (integrated area under time series)\n\n    TODO:\n      Bisection search for the optimal threshold.\n\n    Returns:\n      2-tuple: Timestamp of the start and end of the period of the maximum clipped integrated increase\n\n    >> t = ['2014-12-09T00:00', '2014-12-09T00:15', '2014-12-09T00:30', '2014-12-09T00:45',\n    .. '2014-12-09T01:00', '2014-12-09T01:15', '2014-12-09T01:30', '2014-12-09T01:45']\n    >> ts = pd.Series([217, 234, 235, 231, 219, 219, 231, 232], index=pd.to_datetime(t))\n    >> (discrete_clipping_params(ts, capacity=60000) ==\n    .. {'integral': 54555.882352942499, 't0': pd.Timestamp('2014-12-09 00:15:00'),\n    ..  't1': pd.Timestamp('2014-12-09 01:45:00'),\n    .. 'threshold': 219})\n    True\n    >> (discrete_clipping_params(ts, capacity=30000) ==\n    .. {'integral': 5638.2352941179997, 't0': pd.Timestamp('2014-12-09 00:15:00'),\n    .. 't1': pd.Timestamp('2014-12-09 01:45:00'),\n    .. 'threshold': 231})\n    True\n    \"\"\"\n    raise NotImplementedError(\"Doesn't work. Returns incorrect, overly conservative threshold values.\")\n    #index_type = ts.index.dtype\n    #ts2 = ts.copy()\n    ts.index = ts.index.astype(np.int64)\n    ts_sorted = ts.order(ascending=False)\n    # default is to clip right at the peak (no clipping at all)\n    i, t0, t1, integral, thresh = 1, ts_sorted.index[0], ts_sorted.index[0], 0, ts_sorted.iloc[0]\n    params = {'t0': t0, 't1': t1, 'integral': 0, 'threshold': thresh}\n    while i < len(ts_sorted) and integral <= capacity and (ts_sorted.iloc[0] - ts_sorted.iloc[i]) < rate_limit:\n        params = {'t0': pd.Timestamp(t0), 't1': pd.Timestamp(t1), 'threshold': thresh, 'integral': integral}\n        i += 1\n        times = ts_sorted.index[:i]\n        # print(times)\n        t0 = times.min()\n        t1 = times.max()\n        # print(ts_sorted.index[:3])\n        thresh = min(ts_sorted.iloc[:i])\n        integral = clipped_area(ts, thresh=thresh)\n    if integral <= capacity:\n        return {'t0': pd.Timestamp(t0), 't1': pd.Timestamp(t1), 'threshold': thresh, 'integral': integral}\n    return params"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef square_off(series, time_delta=None, transition_seconds=1):\n    if time_delta:\n        # int, float means delta is in seconds (not years!)\n        if isinstance(time_delta, (int, float)):\n            time_delta = datetime.timedelta(0, time_delta)\n        new_times = series.index + time_delta\n    else:\n        diff = np.diff(series.index)\n        time_delta = np.append(diff, [diff[-1]])\n        new_times = series.index + time_delta\n        new_times = pd.DatetimeIndex(new_times) - datetime.timedelta(0, transition_seconds)\n    return pd.concat([series, pd.Series(series.values, index=new_times)]).sort_index()", "response": "Insert samples in regularly sampled data to produce stairsteps from ramps when plotted."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef join_time_series(serieses, ignore_year=False, T_s=None, aggregator='mean'):\n    if ignore_year:\n        df = pd.DataFrame()\n        for name, ts in serieses.iteritems():\n            # FIXME: deal with leap years\n            sod = np.array(map(lambda x: (x.hour * 3600 + x.minute * 60 + x.second),\n                           ts.index.time))\n            # Coerce soy to an integer so that merge/join operations identify same values\n            # (floats don't equal!?)\n            soy = (ts.index.dayofyear + 366 * (ts.index.year - ts.index.year[0])) * 3600 * 24 + sod\n            ts2 = pd.Series(ts.values, index=soy)\n            ts2 = ts2.dropna()\n            ts2 = ts2.sort_index()\n            df2 = pd.DataFrame({name: ts2.values}, index=soy)\n            df = df.join(df2, how='outer')\n        if T_s and aggregator:\n            df = df.groupby(lambda x: int(x /\n                            float(T_s))).aggregate(dict((name, aggregator) for name in df.columns))\n    else:\n        df = pd.DataFrame(serieses)\n        if T_s and aggregator:\n            x0 = df.index[0]\n            df = df.groupby(lambda x: int((x - x0).total_seconds() /\n                            float(T_s))).aggregate(dict((name, aggregator) for name in df.columns))\n            # FIXME: convert seconds since begninning of first year back into Timestamp instances\n    return df", "response": "Combine a dict of pd. Series objects into a single pd. DataFrame with optional downsampling."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsimulate a random signal with seasonal and quadratic trend RW IRW and RRW.", "response": "def simulate(t=1000, poly=(0.,), sinusoids=None, sigma=0, rw=0, irw=0, rrw=0):\n    \"\"\"Simulate a random signal with seasonal (sinusoids), linear and quadratic trend, RW, IRW, and RRW\n\n    Arguments:\n      t (int or list of float): number of samples or time vector, default = 1000\n      poly (list of float): polynomial coefficients (in decreasing \"order\") passed to `numpy.polyval`\n         i.e. poly[0]*x**(N-1) + ... + poly[N-1]\n      sinusoids (list of list): [[period], [amplitude, period], or [ampl., period, phase]]\n\n    >>> len(simulate(poly=(0,),rrw=1))\n    1000\n    >>> simulate(t=range(3), poly=(1,2))  # doctest: +NORMALIZE_WHITESPACE\n    0    2\n    1    3\n    2    4\n    dtype: float64\n    >>> all(simulate(t=50, sinusoids=((1,2,3),)) == simulate(t=range(50), sinusoids=((1,2,3),)))\n    True\n    >>> any(simulate(t=100))\n    False\n    >>> abs(simulate(sinusoids=42.42).values[1] + simulate(sinusoids=42.42).values[-1]) < 1e-10\n    True\n    >>> simulate(t=17,sinusoids=[42, 16]).min()\n    -42.0\n    >>> all((simulate(t=range(10), sinusoids=(1, 9, 4.5))+simulate(t=10, sinusoids=(1,9))).abs() < 1e-10)\n    True\n    \"\"\"\n    if t and isinstance(t, int):\n        t = np.arange(t, dtype=np.float64)\n    else:\n        t = np.array(t, dtype=np.float64)\n    N = len(t)\n    poly = poly or (0.,)\n    poly = listify(poly)\n    y = np.polyval(poly, t)\n    sinusoids = listify(sinusoids or [])\n    if any(isinstance(ATP, (int, float)) for ATP in sinusoids):\n        sinusoids = [sinusoids]\n    for ATP in sinusoids:\n        # default period is 1 more than the length of the simulated series (no values of the cycle are repeated)\n        T = (t[-1] - t[0]) * N / (N - 1.)\n        # default amplitude is 1 and phase is 0\n        A, P = 1., 0\n        try:\n            A, T, P = ATP\n        except (TypeError, ValueError):\n            try:\n                A, T = ATP\n            except (TypeError, ValueError):\n                # default period is 1 more than the length of the simulated series\n                # (no values of the cycle are repeated)\n                A = ATP[0]\n        # print(A, T, P)\n        # print(t[1] - t[0])\n        y += A * np.sin(2 * np.pi * (t - P) / T)\n    if sigma:\n        y += np.random.normal(0.0, float(sigma), N)\n    if rw:\n        y += np.random.normal(0.0, float(rw), N).cumsum()\n    if irw:\n        y += np.random.normal(0.0, float(irw), N).cumsum().cumsum()\n    if rrw:\n        y += np.random.normal(0.0, float(rrw), N).cumsum().cumsum().cumsum()\n    return pd.Series(y, index=t)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef normalize_symbols(symbols, *args, **kwargs):\n    postprocess = kwargs.get('postprocess', None) or str.upper\n    if (      (hasattr(symbols, '__iter__') and not any(symbols))\n        or (isinstance(symbols, (list, tuple, Mapping)) and (not symbols or not any(symbols)))):\n        return []\n    args = normalize_symbols(args, postprocess=postprocess)\n    if isinstance(symbols, basestring):\n        try:\n            return list(set(get_symbols_from_list(symbols))) + args\n        except:\n            return [postprocess(s.strip()) for s in symbols.split(',')] + args\n    else:\n        ans = []\n        for sym in list(symbols):\n            ans += normalize_symbols(sym, postprocess=postprocess)\n        return list(set(ans))", "response": "Coerce into a list of uppercase strings like GOOG AAPL XOM or GOOGL."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef smooth(x, window_len=11, window='hanning', fill='reflect'):\n\n    # force window_len to be an odd integer so it can be symmetrically applied\n    window_len = int(window_len)\n    window_len += int(not (window_len % 2))\n    half_len = (window_len - 1) / 2\n\n    if x.ndim != 1:\n        raise ValueError(\"smooth only accepts 1 dimension arrays.\")\n    if x.size < window_len:\n        raise ValueError(\"Input vector needs to be bigger than window size.\")\n    if window_len < 3:\n        return x\n    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n        raise ValueError(\"The window arg ({}) should be 'flat', 'hanning', 'hamming', 'bartlett', or 'blackman'\"\n                         .format(window))\n\n    s = np.r_[x[window_len - 1:0:-1], x, x[-1:-window_len:-1]]\n\n    window = window.strip().lower()\n    if window is None or window == 'flat':\n        w = np.ones(window_len, 'd')\n    else:\n        w = getattr(np, window)(window_len)\n\n    y = np.convolve(w / w.sum(), s, mode='valid')\n\n    return y[half_len + 1:-half_len]", "response": "smooth the data using a normalized window with requested size"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef estimate_shift(x, y, smoother=None, w=None, index_and_value=False, ignore_edge=1/3.,\n                   method='valid'):\n    \"\"\"Estimate the time shift between two signals based on their cross correlation\n\n    Arguements:\n      smoother:  Smoothing function applied to correlation values before finding peak\n      w:         Window. Sequence of values between 0 and 1 for wind centered on 0-shift\n                 to weight correlation by before finding peak. Zero-padded to match width of\n                 larger of x and y. Default = hanning(max(len(x, y)))\n\n    Returns:\n      int: number to subtract from an x index to compute a corresponding y index\n    >>> x, y = np.asarray(np.matrix([[0.5, 0.01], [0.01, 1.0]]) * np.random.randn(50,2).T)\n    >>> x[:30-8] = y[8:30]\n\n    >> estimate_shift(x, y, 'full')\n    -8\n    >> estimate_shift(x, y, 'valid')\n    -8\n    >> estimate_shift(y, x, 'full') in [8, 9]\n    True\n    >> estimate_shift(y, x, 'full') in [8, 9]\n    True\n    >> estimate_shift(y, x, 'full') in [8, 9]\n    True\n    \"\"\"\n    return NotImplementedError(\"On Line 965, FIXME: TypeError: object of type 'NoneType' has no len()\")\n    method = method or 'valid'\n    try:\n        x = x.dropna()\n        x = x.values\n    except:\n        pass\n    try:\n        y = y.dropna()\n        y = y.values\n    except:\n        pass\n\n    if len(x) < len(y):\n        swap, x, y = -1, y, x\n    else:\n        swap = +1\n\n    Nx, Ny = len(x), len(y)\n    if ignore_edge > 0:\n        yi0 = int(max(Ny * ignore_edge, 1))\n        yi1 = max(Ny - yi0 - 1, 0)\n        # ignore a large portion of the data in the shorter vector\n        y = y[yi0:yi1]\n\n    x, y = x - x.mean(), y - y.mean()\n    x, y = x / x.std(),  y / y.std()\n\n    c = np.correlate(x, y, mode=method)\n    print(len(x))\n    print(len(y))\n    print(len(w))\n    print(len(c))\n    if w is not None:\n        wc = int(np.ceil(len(w) / 2.)) - 1\n        cc = int(np.ceil(len(c) / 2.)) - 1\n        w0 = cc - wc\n        print(w0)\n        if w0 > 0:\n            c[:w0], c[-w0:] = 0, 0\n            c[w0:-w0] = w[:len(c[w0:-w0])] * c[w0:-w0]\n        elif w0 == 0:\n            if len(w) < len(c):\n                w = np.append(w, 0)\n            c = c * w[:len(c)]\n        elif w0 < 0:\n            w0 = abs(w0)\n            w = w[w0:-w0]\n            c[w0:-w0] = w[:len(c[w0:-w0])] * c[w0:-w0]\n    try:\n        c = smoother(c)\n    except:\n        pass\n\n    offset = imax = c.argmax()\n    offset = offset - yi0\n    if method == 'full':\n        offset = imax - Nx + 1\n    # elif method == 'valid':\n    #     offset = imax - yi0\n    elif method == 'same':\n        raise NotImplementedError(\"Unsure what index value to report for a correlation maximum at i = {}\"\n                                  .format(imax))\n    offset *= swap\n\n    if index_and_value:\n        return offset, c[imax]\n    else:\n        return offset", "response": "Estimate the time shift between two signals based on their cross correlation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fuzzy_index_match(possiblities, label, **kwargs):\n    possibilities = list(possiblities)\n    if isinstance(label, basestring):\n        return fuzzy_get(possibilities, label, **kwargs)\n    if isinstance(label, int):\n        return possibilities[label]\n    if isinstance(label, list):\n        return [fuzzy_get(possibilities, lbl) for lbl in label]", "response": "Find the closest matching column label key or integer indexed value in a sequence of immutable objects corresponding to best matches to each object in label\n              Returns the object in the list of possibilities corresponding to each object in label\n              Returns None if no match was found"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the column labels from any DataFrame or QuerySet - like table object.", "response": "def get_column_labels(obj):\n    \"\"\"Retrieve the column labels/keys from any DataFrame or QuerySet-like table object\n\n    >>> from collections import OrderedDict\n    >>> get_column_labels(OrderedDict(zip('ABC', pd.np.arange(12).reshape((3,4)))))\n    ['A', 'B', 'C']\n    \"\"\"\n    if not isinstance(obj, (list, tuple, pd.np.ndarray)):\n        try:\n            labels = [f.name for f in obj.model._meta.fields]\n        except:\n            try:\n                labels = obj.keys()\n            except:\n                try:\n                    labels = dir(obj)\n                except:\n                    labels = None\n    elif all(isinstance(heading, basestring) for heading in obj[0]):\n        labels = list(obj[0])\n        # if obj isn't a reference to a mutable (dict, DataFrame, list, etc), this won't work\n        del obj[0]\n    return labels"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncoerce an iterable list or rows dict of columns etc into a Pandas DataFrame", "response": "def make_dataframe(obj, columns=None, exclude=None, limit=1e8):\n    \"\"\"Coerce an iterable, queryset, list or rows, dict of columns, etc into a Pandas DataFrame\"\"\"\n    try:\n        obj = obj.objects.all()[:limit]\n    except:\n        pass\n    if isinstance(obj, (pd.Series, list, tuple)):\n        return make_dataframe(pd.DataFrame(obj), columns, exclude, limit)\n    # if the obj is a named tuple, DataFrame, dict of columns, django QuerySet, sql alchemy query result\n    # retrieve the \"include\"d field/column names from its keys/fields/attributes\n    if columns is None:\n        columns = get_column_labels(obj)\n    if exclude is not None and columns is not None and columns and exclude:\n        columns = [i for i in columns if i not in exclude]\n    try:\n        return pd.DataFrame(list(obj.values(*columns)[:limit]))\n    except:\n        pass\n    try:\n        return pd.DataFrame(obj)[fuzzy_get(obj, columns)]\n    except:\n        pass\n    return pd.DataFrame(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplot discrete PDFs of a single object.", "response": "def hist(table, field=-1, class_column=None,\n         title='', verbosity=2, **kwargs):\n    \"\"\"Plot discrete PDFs\n\n    >>> df = pd.DataFrame(pd.np.random.randn(99,3), columns=list('ABC'))\n    >>> df['Class'] = pd.np.array((pd.np.matrix([1,1,1])*pd.np.matrix(df).T).T > 0)\n    >>> len(hist(df, verbosity=0, class_column='Class'))\n    3\n    \"\"\"\n    field = fuzzy_index_match(table, field)\n    if not isinstance(table, (pd.DataFrame, basestring)):\n        try:\n            table = make_dataframe(table.objects.filter(**{field + '__isnull': False}))\n        except:\n            table = table\n    # labels = get_column_labels(table)\n    try:\n        table = table[pd.notnull(table[field])]\n    except:\n        pass\n\n    series_labels = []\n    if class_column is not None:\n        series_labels = sorted(set(table[class_column]))\n    labels = [str(c) for c in series_labels] + ['all']\n\n    default_kwargs = {\n        'normed': False,\n        'histtype': 'bar',\n        'color': seaborn.color_palette(),\n        'label': labels,\n        'log': True,\n        'bins': 10,\n        }\n    default_kwargs.update(kwargs)\n    num_colors = len(default_kwargs['color'])\n    num_labels = len(default_kwargs['label'])\n    default_kwargs['color'] = [default_kwargs['color'][i % num_colors] for i in range(num_labels)]\n\n    if not title:\n        title = '{} vs. {}'.format(titlecase(str(field).replace('_', ' ')),\n                                   titlecase(str(class_column).replace('_', ' ')))\n    if verbosity > 0:\n        print('Plotting histogram titled: {}'.format(title))\n    if verbosity > 1:\n        print('histogram configuration: {}'.format(default_kwargs))\n    x = [table[(table[class_column].isnull() if pd.isnull(c) else table[class_column] == c)]\n         [field].values for c in series_labels]\n    x += [table[field].values]\n    if not default_kwargs['normed']:\n        default_kwargs['weights'] = [pd.np.ones_like(x_c) / float(len(x_c)) for x_c in x]\n    elif isinstance(default_kwargs['normed'], int) and default_kwargs['normed'] < 0:\n        default_kwargs['normed'] = 0\n\n    bins = default_kwargs['bins']\n    # FIXME: x log scaling doesn't work\n    if False and default_kwargs['log'] and isinstance(bins, int):\n        max_x = max(pd.np.max(x_c) for x_c in x)\n        min_x = min(pd.np.min(x_c) for x_c in x)\n        if pd.isnull(min_x) or not(min_x):\n            min_x = max_x / 10.\n        default_kwargs['bins'] = pd.np.logspace(min_x, max_x, bins)\n\n    fig, ax = plt.subplots()\n    ans = plt.hist(x, **default_kwargs)\n    # FIXME: x log scaling doesn't work\n    if False and default_kwargs['log'] and isinstance(bins, int):\n        ax.set_xscale('log')\n    if verbosity > 1:\n        plt.legend(default_kwargs['label'])\n        try:\n            plt.show(block=False)\n        except:\n            plt.show()\n\n    plt.title(title)\n    plt.xlabel(titlecase(field.replace('_', ' ')))\n    if 'weights' in default_kwargs:\n        plt.ylabel('Normalized Frequency or Probability')\n    elif default_kwargs['normed']:\n        plt.ylabel('Normalized Count')\n    else:\n        plt.ylabel('Count')\n    if verbosity > 2:\n        plt.savefig(make_timestamp() + '--' + title.replace(' ', '-') + '.png', transparent=True)\n    return ans"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a QuerySet containing only the related content objects that match the given conditions.", "response": "def filter(self, destination_object=None, source_object=None, **kwargs):\n        \"\"\"\n        See ``QuerySet.filter`` for full documentation\n\n        This adds support for ``destination_object`` and ``source_object``\n        as kwargs.  This converts those objects into the values necessary\n        to handle the ``GenericForeignKey`` fields.\n        \"\"\"\n        if destination_object:\n            kwargs.update({\n                \"destination_id\": destination_object.pk,\n                \"destination_type\": get_for_model(destination_object),\n            })\n        if source_object:\n            kwargs.update({\n                \"source_id\": source_object.pk,\n                \"source_type\": get_for_model(source_object),\n            })\n        return super(RelatedContentQuerySet, self).filter(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntricks sphinx into displaying the desired module in these objects s documentation.", "response": "def _set_module_names_for_sphinx(modules: List, new_name: str):\n    \"\"\" Trick sphinx into displaying the desired module in these objects' documentation. \"\"\"\n    for obj in modules:\n        obj.__module__ = new_name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating kinds of the internal model managers to delegations", "response": "def update_kinds(apps, schema_editor):\n    \"\"\"\n    Downgrade FR special committees to delegations\n    \"\"\"\n\n    # Get model managers\n    Group = apps.get_model(\"representatives\", \"Group\")\n\n    qs = Group.objects.filter(\n        models.Q(name__iregex=ur'^commission d\\'enqu\u00eate') |\n        models.Q(name__iregex=ur'^commission sp\u00e9ciale')\n    )\n\n    for g in qs:\n        g.kind = 'delegation'\n        g.save()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_abbreviations(apps, schema_editor):\n\n    # Get model managers\n    Group = apps.get_model(\"representatives\", \"Group\")\n\n    # Abbreviation mapping\n    amap = {\n        u'SenComCult': u'Culture',\n        u'SenComEco': u'\u00c9conomie',\n        u'SenComDef': u'D\u00e9fense',\n        u'SenComEU': u'Europe',\n        u'SenComSoc': u'Social',\n        u'SenComFin': u'Finances',\n        u'SenComLois': u'Lois',\n        u'SenComDevD': u'',\n        u'SenComAppL': u'',\n        u'AnComCult': u'Culture',\n        u'AnComEco': u'\u00c9conomie',\n        u'AnComEtrg': u'\u00c9tranger',\n        u'AnComDef': u'D\u00e9fense',\n        u'AnComEU': u'Europe',\n        u'AnComSoc': u'Social',\n        u'AnComFin': u'Finances',\n        u'AnComLois': u'Lois',\n        u'AnComDevD': u'',\n        u'AnComImmu': u'',\n    }\n\n    for old, new in amap.iteritems():\n        for g in Group.objects.filter(abbreviation=old):\n            g.abbreviation = new\n            g.save()", "response": "Migrate to new FR committee abbreviations\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild API object identifier from an existing user object.", "response": "def build_api_object(uo=None, api_key=None, uo_id=None, uo_type=None):\n        \"\"\"\n        Builds API object identifier\n        :return:\n        \"\"\"\n        if uo is not None:\n            api_key = uo.resolve_api_key() if uo.resolve_api_key() is not None else api_key\n            uo_id = uo.uo_id if uo.uo_id is not None else uo_id\n            uo_type = uo.uo_type if uo.uo_type is not None else uo_type\n\n        if uo_type is None or uo_type == EBConsts.INVALID_KEY_TYPE:\n            uo_type = 0\n\n        return \"%s%010x%010x\" % (api_key, uo_id, uo_type)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing the request type string for ProcessData packet from the UOtype of UO object.", "response": "def get_request_type(type_in):\n        \"\"\"\n        Constructs request type string for ProcessData packet from the UOtype of UO object\n        :param type_in:\n        :return:\n        \"\"\"\n        uo_type = None\n        if isinstance(type_in, (int, long)):\n            uo_type = int(type_in)\n        elif isinstance(type_in, UO):\n            uo_type = type_in.uo_type\n        return EBConsts.REQUEST_TYPES.get(uo_type, 'PROCESS')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge(final, update, path=None):\n        if final is None:\n            return None\n        if update is None:\n            return final\n        if path is None:\n            path = []\n\n        for key in update:\n            if key in final:\n                if isinstance(final[key], dict) and isinstance(update[key], dict):\n                    EBUtils.merge(final[key], update[key], path + [str(key)])\n                elif final[key] == update[key]:\n                    pass  # same leaf value\n                else:\n                    raise ValueError('Conflict at %s' % '.'.join(path + [str(key)]))\n            else:\n                final[key] = update[key]\n        return final", "response": "Deep merges dictionary object b into dictionary object a."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading and executes tasks from a given skeleton file and returns a new skeleton file that is ready to be used for the build process.", "response": "def run_skeleton(skeleton_path, tasks, watch=True):\n    \"\"\"loads and executes tasks from a given skeleton file\n\n        skeleton_path:\n            path to the skeleton file\n\n        tasks:\n            a list of string identifiers of tasks to be executed\n\n        watch:\n            boolean flag of if the skeleton should be watched for changes and\n            automatically updated\n    \"\"\"\n\n    build_context = load_context_from_skeleton(skeleton_path);\n\n    # for t in build_context.tasks:\n    #     print t, str(build_context.tasks[t])\n\n    for task in tasks:\n        build_context.build_task(task)\n\n\n    # print json.dumps(\n    #     dict((name,\n    #          str(task.value)[0:100] + \"...\"\n    #          if 100 < len(str(task.value))\n    #          else str(task.value))\n\n    #          for name, task in build_context.tasks.iteritems()),\n    #     indent=2)\n\n    if watch:\n        print\n        print \"resolving watch targets\"\n\n        # establish watchers\n        observer = Observer()\n        buildcontexteventhandler = BuildContextFsEventHandler(build_context)\n        built_tasks = ((taskname, task) \n                       for taskname, task in build_context.tasks.iteritems()\n                       if task.last_build_time > 0)\n        for taskname, task in built_tasks:\n            for f in task.task.file_watch_targets:\n                if os.path.isdir(f):\n                    print \"%s: watching %s\" % (taskname, f)\n                    observer.schedule(\n                        buildcontexteventhandler,\n                        f,\n                        recursive=True)\n                else:\n                    print \"%s: watching %s for %s\" % (taskname, os.path.dirname(f),\n                                                      os.path.basename(f))\n                    dirname = os.path.dirname(f)\n                    observer.schedule(\n                        buildcontexteventhandler,\n                        dirname if dirname != \"\" else \".\",\n                        recursive=True)\n\n        print\n        print \"watching for changes\"\n\n        observer.start()\n        try:\n            while True:\n                sleep(0.5)\n        except KeyboardInterrupt:\n            observer.stop()\n        observer.join()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_fresh_content(top=4, additional=10, featured=False):\n    from articles.models import Article\n    from photos.models import Gallery\n    from video.models import Video\n\n    articles = Article.published.only('title', 'summary', 'slug', 'created')\n    galleries = Gallery.published.only('title', 'summary', 'slug', 'created')\n    videos = Video.published.only('title', 'summary', 'slug', 'created')\n\n    if featured:\n        articles = articles.filter(featured=True)\n        galleries = galleries.filter(featured=True)\n        videos = videos.filter(featured=True)\n\n    # now slice to maximum possible for each group\n    # and go ahead and make them lists for chaining\n    max_total = top + additional\n    articles = list(articles[:max_total])\n    galleries = list(galleries[:max_total])\n    videos = list(videos[:max_total])\n\n    # chain the lists now\n    content = chain(articles, galleries, videos)\n    content = sorted(content, key=lambda instance: instance.created)\n    content.reverse()\n\n    top_content = content[:top]\n    additional_content = content[top:max_total]\n    return {\n        'top_content': top_content,\n        'additional_content': additional_content,\n        'MEDIA_URL': settings.MEDIA_URL,\n    }", "response": "Get the most recent published content for a given top item type and additional content type."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a string that can be used as a markdown filter.", "response": "def markdown(value, arg=''):\n    \"\"\"\n    Runs Markdown over a given value, optionally using various\n    extensions python-markdown supports.\n\n    Derived from django.contrib.markdown, which was deprecated from django.\n\n    ALWAYS CLEAN INPUT BEFORE TRUSTING IT.\n\n    Syntax::\n\n        {{ value|markdown:\"extension1_name,extension2_name...\" }}\n\n    To enable safe mode, which strips raw HTML and only returns HTML\n    generated by actual Markdown syntax, pass \"safe\" as the first\n    extension in the list.\n\n    If the version of Markdown in use does not support extensions,\n    they will be silently ignored.\n\n    \"\"\"\n    import warnings\n    warnings.warn('The markdown filter has been deprecated',\n                  category=DeprecationWarning)\n    try:\n        import markdown\n    except ImportError:\n        if settings.DEBUG:\n            raise template.TemplateSyntaxError(\n                \"Error in 'markdown' filter: The Python markdown library isn't installed.\"\n            )\n        return force_text(value)\n    else:\n        markdown_vers = getattr(markdown, \"version_info\", 0)\n        if markdown_vers < (2, 1):\n            if settings.DEBUG:\n                raise template.TemplateSyntaxError(\n                    \"\"\"\n                    Error in 'markdown' filter:\n                    Django does not support versions of the Python markdown library < 2.1.\n                    \"\"\"\n                )\n            return force_text(value)\n        else:\n            extensions = [e for e in arg.split(\",\") if e]\n            if extensions and extensions[0] == \"safe\":\n                extensions = extensions[1:]\n                return mark_safe(markdown.markdown(\n                    force_text(value), extensions, safe_mode=True, enable_attributes=False))\n            else:\n                return mark_safe(markdown.markdown(\n                    force_text(value), extensions, safe_mode=False))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef file_path(self):\n        return os.path.join(keyring.util.platform.data_root(), self.filename)", "response": "The path to the file where passwords are stored."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_password(self, service, username):\n        service = escape_for_ini(service)\n        username = escape_for_ini(username)\n\n        # load the passwords from the file\n        config = configparser.RawConfigParser()\n        if os.path.exists(self.file_path):\n            config.read(self.file_path, encoding='utf-8')\n\n        # fetch the password\n        try:\n            password = config.get(service, username)\n        except (configparser.NoOptionError, configparser.NoSectionError):\n            password = None\n        \n        return password", "response": "Read the password from the file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite the password in the file.", "response": "def set_password(self, service, username, password):\n        \"\"\"Write the password in the file.\n        \"\"\"\n        service = escape_for_ini(service)\n        username = escape_for_ini(username)\n\n        # ensure the file exists\n        self._ensure_file_path()\n\n        # load the keyring from the disk\n        config = configparser.RawConfigParser()\n        config.read(self.file_path)\n\n        # update the keyring with the password\n        if not config.has_section(service):\n            config.add_section(service)\n        config.set(service, username, password)\n\n        # save the keyring back to the file\n        config_file = codecs.open(self.file_path, 'w', 'utf-8')\n        try:\n            config.write(config_file)\n        finally:\n            config_file.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef account(self, account=None):\n        ''' Fetches account information and stores the\n        result in a class variable. Returns that variable\n        if the account has not changed.\n        '''\n        for num_of_retries in range(default.max_retry):\n            if account is None:\n                account = self.mainaccount\n            if account == self.checkedaccount:\n                return self.accountinfo\n            self.checkedaccount = account\n            try:\n                self.accountinfo = self.steem_instance().get_account(account)\n            except Exception as e:\n                self.util.retry((\"COULD NOT GET ACCOUNT INFO FOR \" + str(account)), \n                    e, num_of_retries, default.wait_time)\n                self.s = None\n            else:\n                if self.accountinfo is None:\n                    self.msg.error_message(\"COULD NOT FIND ACCOUNT: \" + str(account))\n                    return False\n                else:\n                    return self.accountinfo", "response": "Fetches the account information and stores the\n        result in a class variable. Returns that variable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the steem instance if it already exists otherwise returns None.", "response": "def steem_instance(self):\n        ''' Returns the steem instance if it already exists\n        otherwise uses the goodnode method to fetch a node\n        and instantiate the Steem class.\n        '''\n        if self.s:\n            return self.s\n        for num_of_retries in range(default.max_retry):\n            node = self.util.goodnode(self.nodes)\n            try:\n                self.s = Steem(keys=self.keys, \n                    nodes=[node])\n            except Exception as e:\n                self.util.retry(\"COULD NOT GET STEEM INSTANCE\", \n                    e, num_of_retries, default.wait_time)\n                self.s = None\n            else:\n                return self.s\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef verify_key (self, acctname=None, tokenkey=None):\n        ''' This can be used to verify either a private\n        posting key or to verify a steemconnect refresh\n        token and retreive the access token.\n        '''\n        if (re.match( r'^[A-Za-z0-9]+$', tokenkey)\n                        and tokenkey is not None\n                        and len(tokenkey) <= 64\n                        and len(tokenkey) >= 16):\n            pubkey = PrivateKey(tokenkey).pubkey or 0\n            pubkey2 = self.account(acctname)\n            if (str(pubkey) \n                    == str(pubkey2['posting']['key_auths'][0][0])):\n                self.privatekey = tokenkey\n                self.refreshtoken = None\n                self.accesstoken = None\n                return True\n            else:\n                return False\n        elif (re.match( r'^[A-Za-z0-9\\-\\_\\.]+$', tokenkey)\n                        and tokenkey is not None\n                        and len(tokenkey) > 64):\n            self.privatekey = None\n            self.accesstoken = self.connect.get_token(tokenkey)\n            if self.accesstoken:\n                self.username = self.connect.username\n                self.refreshtoken = self.connect.refresh_token\n                return True\n            else:\n                return False\n        else:\n            return False", "response": "This method is used to verify a private key and a steemconnect refresh token and retreive the access token."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfetches and returns the 3 values needed to calculate the reward pool and other associated values such as rshares and rshares. Returns the reward balance all recent claims and the current price of steem.", "response": "def reward_pool_balances(self):\n        ''' Fetches and returns the 3 values\n        needed to calculate the reward pool\n        and other associated values such as rshares.\n        Returns the reward balance, all recent claims\n        and the current price of steem.\n        '''\n        if self.reward_balance > 0:\n            return self.reward_balance\n        else:\n            reward_fund = self.steem_instance().get_reward_fund()\n            self.reward_balance = Amount(\n                reward_fund[\"reward_balance\"]).amount\n            self.recent_claims = float(reward_fund[\"recent_claims\"])\n            self.base = Amount(\n                self.steem_instance(\n                ).get_current_median_history_price()[\"base\"]\n                ).amount\n        return [self.reward_balance, self.recent_claims, self.base]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the rshares to steem.", "response": "def rshares_to_steem (self, rshares):\n        ''' Gets the reward pool balances\n        then calculates rshares to steem\n        '''\n        self.reward_pool_balances()\n        return round(\n            rshares \n            * self.reward_balance \n            / self.recent_claims \n            * self.base, 4)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve the global properties of the class that contains the steem_instance and stores them in self. util. info.", "response": "def global_props(self):\n        ''' Retrieves the global properties\n        used to determine rates used for calculations\n        in converting steempower to vests etc.\n        Stores these in the Utilities class as that\n        is where the conversions take place, however\n        SimpleSteem is the class that contains\n        steem_instance, so to to preserve heirarchy \n        and to avoid \"spaghetti code\", this method\n        exists in this class.\n        '''\n        if self.util.info is None:\n            self.util.info = self.steem_instance().get_dynamic_global_properties()\n            self.util.total_vesting_fund_steem = Amount(self.util.info[\"total_vesting_fund_steem\"]).amount\n            self.util.total_vesting_shares = Amount(self.util.info[\"total_vesting_shares\"]).amount\n            self.util.vote_power_reserve_rate = self.util.info[\"vote_power_reserve_rate\"]\n        return self.util.info"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef current_vote_value(self, **kwargs):\n        ''' Ensures the needed variables are\n        created and set to defaults although\n        a variable number of variables are given.\n        '''\n        try:\n            kwargs.items()\n        except:\n            pass\n        else:\n            for key, value in kwargs.items():\n                setattr(self, key, value)\n        try:\n            self.lastvotetime\n        except:\n            self.lastvotetime=None\n        try:\n            self.steempower\n        except:\n            self.steempower=0\n        try:\n            self.voteweight\n        except:\n            self.voteweight=100\n        try:\n            self.votepoweroverride\n        except:\n            self.votepoweroverride=0\n        try:\n            self.accountname\n        except:\n            self.accountname=None              \n        if self.accountname is None:\n            self.accountname = self.mainaccount   \n        if self.check_balances(self.accountname) is not False:\n            if self.voteweight > 0 and self.voteweight < 101:\n                self.voteweight = self.util.scale_vote(self.voteweight)\n            if self.votepoweroverride > 0 and self.votepoweroverride < 101:\n                self.votepoweroverride = self.util.scale_vote(self.votepoweroverride) \n            else:\n                self.votepoweroverride = (self.votepower \n                                + self.util.calc_regenerated(\n                                self.lastvotetime))\n            self.vpow = round(self.votepoweroverride / 100, 2)\n            self.global_props()\n            self.rshares = self.util.sp_to_rshares(self.steempower, \n                                            self.votepoweroverride, \n                                            self.voteweight)\n            self.votevalue = self.rshares_to_steem(self.rshares)\n            return self.votevalue\n        return None", "response": "Returns the current vote value for the current vouchers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfetching an account balance and makes necessary conversions", "response": "def check_balances(self, account=None):\n        ''' Fetches an account balance and makes\n        necessary conversions\n        '''\n        a = self.account(account)\n        if a is not False and a is not None:\n            self.sbdbal = Amount(a['sbd_balance']).amount\n            self.steembal = Amount(a['balance']).amount\n            self.votepower = a['voting_power']\n            self.lastvotetime = a['last_vote_time']\n            vs = Amount(a['vesting_shares']).amount\n            dvests = Amount(a['delegated_vesting_shares']).amount\n            rvests = Amount(a['received_vesting_shares']).amount\n            vests = (float(vs) - float(dvests)) + float(rvests)\n            try:\n                self.global_props()\n                self.steempower_delegated = self.util.vests_to_sp(dvests)\n                self.steempower_raw = self.util.vests_to_sp(vs)\n                self.steempower = self.util.vests_to_sp(vests)\n            except Exception as e:\n                self.msg.error_message(e)\n            else:\n                return [self.sbdbal, self.steembal, self.steempower, \n                        self.votepower, self.lastvotetime]\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransfer funds from the given account to the given account", "response": "def transfer_funds(self, to, amount, denom, msg):\n        ''' Transfer SBD or STEEM to the given account\n        '''\n        try:\n            self.steem_instance().commit.transfer(to, \n                float(amount), denom, msg, self.mainaccount)\n        except Exception as e:\n            self.msg.error_message(e)\n            return False\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfetch the account history from the most recent back", "response": "def get_my_history(self, account=None, limit=10000):\n        ''' Fetches the account history from\n        most recent back\n        '''\n        if not account:\n            account = self.mainaccount\n        try:\n            h = self.steem_instance().get_account_history(\n                account, -1, limit)\n        except Exception as e:\n            self.msg.error_message(e)\n            return False\n        else:\n            return h"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuses for creating a main post to an account s blog.", "response": "def post(self, title, body, permlink, tags):\n        ''' Used for creating a main post\n        to an account's blog. Waits 20 seconds\n        after posting as that is the required \n        amount of time between posting.\n        '''\n        for num_of_retries in range(default.max_retry):\n            try:\n                self.msg.message(\"Attempting to post \" + permlink)\n                self.steem_instance().post(title, \n                                            body, \n                                            self.mainaccount, \n                                            permlink, \n                                            None, None, None, None, \n                                            tags, None, False)   \n            except Exception as e:\n                self.util.retry(\"COULD NOT POST '\" + title + \"'\", \n                    e, num_of_retries, 10)\n                self.s = None\n            else:\n                self.msg.message(\"Post seems successful. Wating 60 seconds before verifying...\")\n                self.s = None\n                time.sleep(60)\n                checkident = self.recent_post()\n                ident = self.util.identifier(self.mainaccount, permlink)\n                if checkident == ident:\n                    return True\n                else:\n                    self.util.retry('A POST JUST CREATED WAS NOT FOUND IN THE '\n                                    + 'BLOCKCHAIN {}'''.format(title), \n                                    \"Identifiers do not match\", \n                                    num_of_retries, default.wait_time)\n                    self.s = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nusing for creating a reply to a single entry in the database.", "response": "def reply(self, permlink, msgbody):\n        ''' Used for creating a reply to a \n        post. Waits 20 seconds\n        after posting as that is the required \n        amount of time between posting.\n        '''\n        for num_of_retries in range(default.max_retry): \n            try:\n                self.steem_instance().post(\"message\", \n                                            msgbody, \n                                            self.mainaccount, \n                                            None, \n                                            permlink, \n                                            None, None, \"\", \n                                            None, None, False)\n            except Exception as e:\n                self.util.retry(\"COULD NOT REPLY TO \" + permlink, \n                    e, num_of_retries, default.wait_time)\n                self.s = None\n            else:\n                self.msg.message(\"Replied to \" + permlink)\n                time.sleep(20)\n                return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfollowing the given account", "response": "def follow(self, author):\n        ''' Follows the given account\n        '''\n        try:\n            self.steem_instance().commit.follow(author, \n                ['blog'], self.mainaccount)\n        except Exception as e:\n            self.msg.error_message(e)\n            return False\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a list of all the followers of a given account.", "response": "def following(self, account=None, limit=100):\n        ''' Gets a list of all the followers\n        of a given account. If no account is given\n        the followers of the mainaccount are\n        returned.\n        '''\n        if not account:\n            account = self.mainaccount\n        followingnames = []\n        try:\n            self.followed = self.steem_instance().get_following(account, \n                '', 'blog', limit)\n        except Exception as e:\n            self.msg.error_message(e)\n            return False\n        else:\n            for a in self.followed:\n                followingnames.append(a['following'])\n            return followingnames"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the most recent post for the given author.", "response": "def recent_post(self, author=None, daysback=0, flag=0):\n        ''' Returns the most recent post from the account\n        given. If the days back is greater than zero\n        then the most recent post is returned for that\n        day. For instance if daysback is set to 2\n        then it will be the most recent post from 2 days\n        ago (48 hours).\n        '''\n        if not author:\n            author = self.mainaccount\n        for num_of_retries in range(default.max_retry):\n            try:\n                self.blog = self.steem_instance().get_blog(author, 0, 30)\n            except Exception as e:\n                self.util.retry('COULD NOT GET THE '\n                                + 'MOST RECENT POST FOR '\n                                + '{}'.format(author), \n                                e, num_of_retries, default.wait_time)\n                self.s = None\n            else:\n                i = 0\n                for p in self.blog:\n                    if p['comment']['author'] == author:\n                        self.blognumber = i\n                        ageinminutes = self.util.minutes_back(p['comment']['created'])\n                        ageindays = (ageinminutes / 60) / 24\n                        if (int(ageindays) == daysback):\n                            if flag == 1 and ageinminutes < 15:\n                                return None\n                            else:\n                                return self.util.identifier(\n                                    p['comment']['author'],\n                                    p['comment']['permlink'])\n                        else:\n                            return None\n                    i += 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef vote_history(self, permlink, author=None):\n        ''' Returns the raw vote history of a\n        given post from a given account\n        '''\n        if author is None:\n            author = self.mainaccount\n        return self.steem_instance().get_active_votes(author, permlink)", "response": "Returns the raw vote history of a\n        given post from a given account\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nattempt to vote the given object on the given object. Returns True if successful False otherwise.", "response": "def vote(self, identifier, weight=100.0):\n        ''' Waits 5 seconds as that is the required amount \n        of time between votes.\n        '''\n        for num_of_retries in range(default.max_retry):\n            try:\n                self.steem_instance().vote(identifier, \n                    weight, self.mainaccount)\n                self.msg.message(\"voted for \" + identifier)\n                time.sleep(5)\n            except Exception as e:\n                if re.search(r'You have already voted in a similar way', str(e)):\n                    self.msg.error_message('''Already voted on \n                                        {}'''.format(identifier))\n                    return \"already voted\"\n                else:\n                    self.util.retry('''COULD NOT VOTE ON \n                                    {}'''.format(identifier), \n                                    e, num_of_retries, default.wait_time)\n                    self.s = None\n            else:\n                return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwaiting 20 seconds as that is the required amount of time between resteems", "response": "def resteem(self, identifier):\n        ''' Waits 20 seconds as that is the required \n        amount of time between resteems\n        '''\n        for num_of_retries in range(default.max_retry):\n            try:\n                self.steem_instance().resteem(\n                    identifier, self.mainaccount)\n                self.msg.message(\"resteemed \" + identifier)\n                time.sleep(10)\n            except Exception as e:\n                self.util.retry('''COULD NOT RESTEEM \n                                {}'''.format(identifier), \n                                e, num_of_retries, default.wait_time)\n                self.s = None\n            else:\n                return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dex_ticker(self):\n        ''' Simply grabs the ticker using the \n        steem_instance method and adds it\n        to a class variable.\n        '''\n        self.dex = Dex(self.steem_instance())\n        self.ticker = self.dex.get_ticker();\n        return self.ticker", "response": "Grabs the ticker using the \n        steem_instance method and adds it\n        to a class variable."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuses the ticker to get the highest bid and moves the steem at that price.", "response": "def steem_to_sbd(self, steemamt=0, price=0, account=None):\n        ''' Uses the ticker to get the highest bid\n        and moves the steem at that price.\n        '''\n        if not account:\n            account = self.mainaccount\n        if self.check_balances(account):\n            if steemamt == 0:\n                steemamt = self.steembal\n            elif steemamt > self.steembal:\n                self.msg.error_message(\"INSUFFICIENT FUNDS. CURRENT STEEM BAL: \" \n                                        + str(self.steembal))\n                return False\n            if price == 0:\n                price = self.dex_ticker()['highest_bid']\n            try:\n                self.dex.sell(steemamt, \"STEEM\", price, account=account)\n            except Exception as e:\n                self.msg.error_message(\"COULD NOT SELL STEEM FOR SBD: \" + str(e))\n                return False\n            else:\n                self.msg.message(\"TRANSFERED \" \n                                    + str(steemamt) \n                                    + \" STEEM TO SBD AT THE PRICE OF: $\"\n                                    + str(price))\n                return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nuse the ticker to get the lowest ask and moves the sbd at that price.", "response": "def sbd_to_steem(self, sbd=0, price=0, account=None):\n        ''' Uses the ticker to get the lowest ask\n        and moves the sbd at that price.\n        '''\n        if not account:\n            account = self.mainaccount\n        if self.check_balances(account):\n            if sbd == 0:\n                sbd = self.sbdbal\n            elif sbd > self.sbdbal:\n                self.msg.error_message(\"INSUFFICIENT FUNDS. CURRENT SBD BAL: \" \n                                        + str(self.sbdbal))\n                return False\n            if price == 0:\n                price = 1 / self.dex_ticker()['lowest_ask']\n            try:\n                self.dex.sell(sbd, \"SBD\", price, account=account)\n            except Exception as e:\n                self.msg.error_message(\"COULD NOT SELL SBD FOR STEEM: \" + str(e))\n                return False\n            else:\n                self.msg.message(\"TRANSFERED \" \n                                    + str(sbd) \n                                    + \" SBD TO STEEM AT THE PRICE OF: $\"\n                                    + str(price))\n                return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nuse the steem_instance method to decide if a witness is available on a given account.", "response": "def vote_witness(self, witness, account=None):\n        ''' Uses the steem_instance method to\n        vote on a witness.\n        '''\n        if not account:\n            account = self.mainaccount\n        try:\n            self.steem_instance().approve_witness(witness, account=account)\n        except Exception as e:\n            self.msg.error_message(\"COULD NOT VOTE \" \n                                    + witness + \" AS WITNESS: \" + e)\n            return False\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unvote_witness(self, witness, account=None):\n        ''' Uses the steem_instance method to\n        unvote a witness.\n        '''\n        if not account:\n            account = self.mainaccount\n        try:\n            self.steem_instance().disapprove_witness(witness, account=account)\n        except Exception as e:\n            self.msg.error_message(\"COULD NOT UNVOTE \" \n                                    + witness + \" AS WITNESS: \" + e)\n            return False\n        else:\n            return True", "response": "Uses the steem_instance method to\n        unvote a witness."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef voted_me_witness(self, account=None, limit=100):\n        ''' Fetches all those a given account is\n        following and sees if they have voted that\n        account as witness.\n        '''\n        if not account:\n            account = self.mainaccount\n        self.has_voted = []\n        self.has_not_voted = []\n        following = self.following(account, limit)\n        for f in following:\n            wv = self.account(f)['witness_votes']\n            voted = False\n            for w in wv:\n                if w == account:\n                    self.has_voted.append(f)\n                    voted = True\n            if not voted:\n                self.has_not_voted.append(f)\n        return self.has_voted", "response": "Fetches all those a given account is\n            following and sees if they have voted that account as witness. Returns a list of all the entries in the order they ve been voted."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfetches all those a given account is following and sees if they have muted that account. Returns True if all of the entries in the account are muted False otherwise.", "response": "def muted_me(self, account=None, limit=100):\n        ''' Fetches all those a given account is\n        following and sees if they have muted that\n        account.\n        '''\n        self.has_muted = []\n        if account is None:\n            account = self.mainaccount\n        following = self.following(account, limit)\n        if following is False:\n            self.msg.error_message(\"COULD NOT GET FOLLOWING FOR MUTED\")\n            return False\n        for f in following:\n            h = self.get_my_history(f)\n            for a in h:\n                if a[1]['op'][0] == \"custom_json\":\n                    j = a[1]['op'][1]['json']\n                    d = json.loads(j)\n                    try:\n                        d[1]\n                    except:\n                        pass\n                    else:\n                        for i in d[1]:\n                            if i == \"what\":\n                                if len(d[1]['what']) > 0:\n                                    if d[1]['what'][0] == \"ignore\":\n                                        if d[1]['follower'] == account:\n                                            self.msg.message(\"MUTED BY \" + f)\n                                            self.has_muted.append(f)\n        return self.has_muted"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delegate(self, to, steempower):\n        ''' Delegates based on Steem Power rather\n        than by vests.\n        '''\n        self.global_props()\n        vests = self.util.sp_to_vests(steempower)\n        strvests = str(vests)\n        strvests = strvests + \" VESTS\"\n        try:\n            self.steem_instance().commit.delegate_vesting_shares(to, \n                                                                strvests, \n                                                                account=self.mainaccount)\n        except Exception as e:\n            self.msg.error_message(\"COULD NOT DELEGATE \" \n                                    + str(steempower) + \" SP TO \" \n                                    + to + \": \" + str(e))\n            return False\n        else:\n            self.msg.message(\"DELEGATED \" + str(steempower) + \" STEEM POWER TO \" + str(to))\n            return True", "response": "Delegates based on Steem Power rather\n        than by vests."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start_logging(gconfig, logpath):\n    '''Turn on logging and set up the global config.\n\n    This expects the :mod:`yakonfig` global configuration to be unset,\n    and establishes it.  It starts the log system via the :mod:`dblogger`\n    setup.  In addition to :mod:`dblogger`'s defaults, if `logpath` is\n    provided, a :class:`logging.handlers.RotatingFileHandler` is set to\n    write log messages to that file.\n\n    This should not be called if the target worker is\n    :class:`rejester.workers.ForkWorker`, since that manages logging on\n    its own.\n\n    :param dict gconfig: the :mod:`yakonfig` global configuration\n    :param str logpath: optional location to write a log file\n\n    '''\n    yakonfig.set_default_config([rejester, dblogger], config=gconfig)\n    if logpath:\n        formatter = dblogger.FixedWidthFormatter()\n        # TODO: do we want byte-size RotatingFileHandler or TimedRotatingFileHandler?\n        handler = logging.handlers.RotatingFileHandler(\n            logpath, maxBytes=10000000, backupCount=3)\n        handler.setFormatter(formatter)\n        logging.getLogger('').addHandler(handler)", "response": "Turn on logging and set up the global configuration."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstarting some worker class.", "response": "def start_worker(which_worker, config={}):\n    '''Start some worker class.\n\n    :param str which_worker: name of the worker\n    :param dict config: ``rejester`` config block\n\n    '''\n    if which_worker == 'multi_worker':\n        cls = MultiWorker\n    elif which_worker == 'fork_worker':\n        cls = ForkWorker\n    else:\n        # Don't complain too hard, just fall back\n        cls = ForkWorker\n    return run_worker(cls, config)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fork_worker(gconfig, args):\n    '''Run the worker as a daemon process.\n\n    This uses :mod:`daemon` to run the standard double-fork, so it can\n    return immediately and successfully in the parent process having forked.\n\n    :param dict gconfig: the :mod:`yakonfig` global configuration\n    :param args: command-line arguments\n\n    '''\n    if args.pidfile:\n        pidfile_lock = lockfile.FileLock(args.pidfile)\n    else:\n        pidfile_lock = None\n    with daemon.DaemonContext(pidfile=pidfile_lock, detach_process=True):\n        try:\n            if args.pidfile:\n                with open(args.pidfile, 'w') as f:\n                    f.write(str(os.getpid()))\n            go(gconfig, args)\n        except Exception, exc:\n            logp = logpath or os.path.join('/tmp', 'rejester-failure.log')\n            open(logp, 'a').write(traceback.format_exc(exc))\n            raise", "response": "Run the worker as a daemon process."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding transients (service, topic, etc) named in add_names if they are not exposed in resolved_dict and removes transients named in remove_names if they are exposed in resolved_dict This method can be used to force exposing/withholding any transient, bypassing other mechanisms. No extra check is made here regarding regex or system status to try to guess if it should be added/removed. This is left ot the caller. :param add_names: the names of the transients to add :param remove_names: the names of the transients to remove :param class_build_args: the args to pass to the resolved transient constructor :param class_build_kwargs: the kwargs to pass to the resolved transient constructor :return: the list of transients exposed", "response": "def update_transients(self, add_names, remove_names, *class_build_args, **class_build_kwargs):\n        \"\"\"\n        Adds transients (service, topic, etc) named in add_names if they are not exposed in resolved_dict\n        and removes transients named in remove_names if they are exposed in resolved_dict\n\n        This method can be used to force exposing/withholding any transient, bypassing other mechanisms.\n        No extra check is made here regarding regex or system status to try to guess if it should be added/removed.\n        This is left ot the caller.\n\n        :param add_names: the names of the transients to add\n        :param remove_names: the names of the transients to remove\n        :param class_build_args: the args to pass to the resolved transient constructor\n        :param class_build_kwargs: the kwargs to pass to the resolved transient constructor\n        :return: the list of transients exposed\n        \"\"\"\n        # Important : no effect if names is empty list. only return empty. functional style.\n\n        added = []\n        removed = []\n        for tst_name in [tst for tst in add_names if tst not in self.transients.keys()]:\n            try:\n                ttype = self.transient_type_resolver(tst_name)  # should return None if error - TODO : handle (and reraise) exception !!\n                if ttype is not None:  # transient can be resolved\n                    self.transients[tst_name] = self.TransientMaker(tst_name, ttype, *class_build_args, **class_build_kwargs)\n                    added += [tst_name]\n                    logging.info(\"[{name}] Interfacing with {desc} {transient}\".format(name=__name__, desc=self.transients_desc, transient=tst_name))\n                else:\n                    logging.warning(\"[{name}] Type of {desc} {transient} unknown. Giving up trying to interface.\".format(name=__name__, desc=self.transients_desc,\n                                                                              transient=tst_name))\n            except Exception as e:\n                logging.warn(\"[{name}] Cannot interface with {desc} {transient} : {exc}\".format(name=__name__, desc=self.transients_desc, transient=tst_name, exc=e))\n                exc_info = sys.exc_info()\n                six.reraise(exc_info[0], exc_info[1], exc_info[2])\n\n        for tst_name in [tst for tst in remove_names if tst in self.transients.keys()]:\n            if tst_name in self.transients:  # we make sure the transient is still exposed\n                # because we might have modified resolved_dict after building the list to loop on\n                logging.info(\"[{name}] Removing {desc} {transient}\".format(name=__name__, desc=self.transients_desc, transient=tst_name))\n                self.TransientCleaner(self.transients[tst_name])  # calling the cleanup function in case we need to do something\n                self.transients.pop(tst_name, None)\n                removed += [tst_name]\n\n        return DiffTuple(added, removed)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef expose_transients_regex(self, regexes, *class_build_args, **class_build_kwargs):\n        # Important : no effect if names is empty list. only return empty diff. functional style.\n\n        # look through the new service names received by reconfigure, and add\n        # those services which are not in the existing service args\n        for tst_regex in [r for r in regexes if not r in self.transients_args]:\n            self.transients_args.add(tst_regex)\n            logging.info('[{name}] Exposing {desc} regex : {regex}'.format(name=__name__, desc=self.transients_desc, regex=tst_regex))\n            # TODO : check here for bugs & add test : what if we add multiple regexes ? wont we miss some add_names ?\n\n        # look through the current service args and delete those values which\n        # will not be valid when the args are replaced with the new ones. run on\n        # a copy so that we will remove from the original without crashing\n        for tst_regex in [r for r in self.transients_args if not r in regexes]:\n            logging.info('[{name}] Withholding {desc} regex : {regex}'.format(name=__name__, desc=self.transients_desc, regex=tst_regex))\n            self.transients_args.remove(tst_regex)\n\n        return self.transient_change_detect(\n            *class_build_args,\n            **class_build_kwargs\n         )", "response": "Exposes a list of transients matching the given regex."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transient_change_diff(self, transient_appeared, transient_gone, *class_build_args, **class_build_kwargs):\n\n        to_add = set(regexes_match_sublist(self.transients_args, transient_appeared))\n        lost_matches = {n for n in self.transients if find_first_regex_match(n, self.transients_args) is None}\n        to_remove = set(transient_gone) | lost_matches  # we stop interfacing with lost transient OR lost matches\n\n        return self.update_transients(\n            add_names=to_add,\n            remove_names=to_remove,\n            *class_build_args,\n            **class_build_kwargs\n        )", "response": "This function is called when we want to update the status of a transient entry. It is called when we want to update the status of a transient entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mock(self, tst_name, tst_type):\n        print(\" -> Mock {tst_name} appear\".format(**locals()))\n        # Service appears\n        self.available[tst_name] = tst_type\n        yield\n        # Service disappear\n        self.available.pop(tst_name)\n        print(\" -> Mock {tst_name} disappear\".format(**locals()))", "response": "Mocks appearance and disappearance of a service"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsearch for a given search term.", "response": "def search(self, search_term, num_results, **kwargs):\n        \"\"\"Gets x number of Google image result urls for\n        a given search term.\n        Arguments\n        search_term: str\n            tearm to search for\n        num_results: int\n            number of url results to return\n        return ['url','url']\n        \"\"\"\n        results = []\n        count = 1\n        try:\n            while len(results) <= num_results:\n                search_results = self.service.cse().list(\n                    q=search_term,\n                    cx=self.cse_id,\n                    searchType=\"image\",\n                    fileType=self.file_type,\n                    start=count,\n                    **kwargs).execute()\n                results.extend(\n                    [r['link'] for r in search_results['items']])\n                count += len(search_results)\n            results = results[:num_results]\n        except KeyError as e:\n            logger.warning('Exception: %s', e)\n        if len(results) == 0:\n            raise ZeroResultsException(\"No images found\")\n        return(results)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _doc_object(obj, obj_type, nest=None, config=default_config):\n    doc = inspect.getdoc(obj)\n\n    if not doc and not nest:\n        return None\n\n    result = {\n        'type': obj_type,\n        'name': obj.__name__,\n        'doc': doc\n    }\n\n    if nest:\n        result['nest'] = nest\n\n    return result", "response": "Return a dict with type name doc and nested doc ( if any."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_function_doc(function, config=default_config):\n    if config.exclude_function:\n        for ex in config.exclude_function:\n            if ex.match(function.__name__):\n                return None\n\n    return _doc_object(function, 'function', config=config)", "response": "Return doc for a function."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns doc for a class.", "response": "def get_class_doc(klass, config=default_config):\n    \"\"\"Return doc for a class.\"\"\"\n    if config.exclude_class:\n        for ex in config.exclude_class:\n            if ex.match(klass.__name__):\n                return None\n\n    nested_doc = []\n    class_dict = klass.__dict__\n\n    for item in dir(klass):\n        if item in class_dict.keys():\n            appended = None\n            if isinstance(class_dict[item], type) and config.nested_class:\n                appended = get_class_doc(class_dict[item], config)\n            elif isinstance(class_dict[item], types.FunctionType):\n                appended = get_function_doc(class_dict[item], config)\n            if appended is not None:\n                nested_doc.append(appended)\n\n    return _doc_object(klass, 'class', nested_doc, config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_module_doc(module, config=default_config, already_met=None):\n    # Avoid recursion loops (init)\n    if already_met is None:\n        already_met = set()\n\n    if config.exclude_module:\n        for ex in config.exclude_module:\n            if ex.match(module.__name__):\n                return None\n\n    # Force load submodules into module's dict\n    if hasattr(module, '__path__'):\n        subm = [\n            modname for importer, modname, ispkg\n            in pkgutil.iter_modules(module.__path__)\n        ]\n        __import__(module.__name__, fromlist=subm)\n\n    # We don't want to include imported items,\n    # so we parse the code to blacklist them.\n\n    # Be sure to parse .py and not .pyc file on Python 2.X\n    if hasattr(module, '__file__'):\n        module_file = module.__file__\n    else:\n        module_file = inspect.getsourcefile(module)\n    path, ext = os.path.splitext(module_file)\n    if ext == '.pyc':\n        module_file = path + '.py'\n\n    try:\n        code = open(module_file).read()\n        body = ast.parse(code).body\n    except SyntaxError:\n        code = open(module_file).read().encode('utf-8')\n        body = ast.parse(code).body\n\n    imported = []\n    for node in body:\n        if isinstance(node, (ast.Import, ast.ImportFrom)):\n            imported.extend([n.name for n in node.names])\n\n    nested_doc = []\n    module_dict = module.__dict__\n\n    for item in dir(module):\n        if item not in imported and item in module_dict.keys():\n            # Avoid recursion loops\n            if id(item) in already_met:\n                continue\n            already_met.add(id(item))\n\n            appended = None\n            if isinstance(module_dict[item], types.ModuleType):\n                appended = get_module_doc(module_dict[item], config, already_met)  # noqa\n            elif isinstance(module_dict[item], type):\n                appended = get_class_doc(module_dict[item], config)\n            elif isinstance(module_dict[item], types.FunctionType):\n                appended = get_function_doc(module_dict[item], config)\n            if appended is not None:\n                nested_doc.append(appended)\n\n    return _doc_object(module, 'module', nested_doc, config)", "response": "Return doc for a module."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if given name matches the current entry.", "response": "def match(self, name):\n        \"\"\"\n        Check if given name matches.\n\n        Args:\n            name (str): name to check.\n\n        Returns:\n            bool: matches name.\n        \"\"\"\n        if self.method == Ex.Method.PREFIX:\n            return name.startswith(self.value)\n        elif self.method == Ex.Method.SUFFIX:\n            return name.endswith(self.value)\n        elif self.method == Ex.Method.CONTAINS:\n            return self.value in name\n        elif self.method == Ex.Method.EXACT:\n            return self.value == name\n        elif self.method == Ex.Method.REGEX:\n            return re.search(self.value, name)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms the action of the current file.", "response": "def do_action(self, target, dry_run=False):\n        \"\"\"\n        :param target: Full path and filename\n        :param dry_run: True - don't actually perform action. False: perform action. No effect for this rule.\n        :return: filename: Full path and filename after action completes\n        \"\"\"\n        if dry_run is False:\n            try:\n                filename = os.path.basename(target)\n                size = os.path.getsize(target)\n                print(\"{0}\\t{1}\".format(filename, size))\n            except OSError:\n                self.logger.error(\"Error getting size for file: {0}\".format(target))\n\n        return target"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_geometry(geometry):\n    if not geometry:\n        return None, None\n    if callable(geometry):\n        geometry = geometry()\n    geometry = str(geometry).split('x')\n    if len(geometry) == 1 or (len(geometry) > 1 and not geometry[1]):\n        width = int(geometry[0])\n        height = None\n    else:\n        w = geometry[0]\n        width = int(w) if w else None\n        height = int(geometry[1])\n    return (width, height)", "response": "Parse a geometry string and returns a width height tuple"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning shorter version as string.", "response": "def get_version():\n    \"\"\"\n    Returns shorter version (digit parts only) as string.\n    \"\"\"\n    version = '.'.join((str(each) for each in VERSION[:3]))\n    if len(VERSION) > 3:\n        version += VERSION[3]\n    return version"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef as_unicode(obj, encoding=convert.LOCALE, pretty=False):\n\n    return convert.convert(obj, encoding, 0 if pretty else None)", "response": "Converts any object to unicode string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert any object to str string or bytes string.", "response": "def as_str(obj, encoding=convert.LOCALE, pretty=False):\n    \"\"\"\n    Representing any object to <str> string (python2.7) or <bytes> string (python3.0).\n\n    :param obj: any object\n    :type encoding: str\n    :param encoding: codec for encoding unicode strings\n                     (locale.getpreferredencoding() by default)\n    :type pretty: bool\n    :param pretty: pretty print\n\n    :rtype: str\n    :return: any object as string\n    \"\"\"\n\n    return as_unicode(obj, encoding, pretty).encode(encoding)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef autocommand(func):\n    name = func.__name__\n    title, desc = command.parse_docstring(func)\n    if not title:\n        title = 'Auto command for: %s' % name\n    if not desc:\n        # Prevent Command from using docstring of AutoCommand\n        desc = ' '\n    return AutoCommand(title=title, desc=desc, name=name, func=func)", "response": "A simplified decorator for making a single function a Command\n    instance."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self, args):\n        args = vars(args)\n        positionals = []\n        keywords = {}\n        for action in self.argparser._actions:\n            if not hasattr(action, 'label'):\n                continue\n            if action.label == 'positional':\n                positionals.append(args[action.dest])\n            elif action.label == 'varargs':\n                positionals.extend(args[action.dest])\n            elif action.label == 'keyword':\n                keywords[action.dest] = args[action.dest]\n            elif action.label == 'varkwargs':\n                kwpairs = iter(args[action.dest] or [])\n                for key in kwpairs:\n                    try:\n                        key, value = key.split('=', 1)\n                    except ValueError:\n                        value = next(kwpairs)\n                        key = key.strip('-')\n                    keywords[key] = value\n        return self.func(*positionals, **keywords)", "response": "Convert the unordered args into function arguments."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef submit(self, task):\n        if self.api_url == 'http://STUB_URL':\n            logging.info(u'STARTER CLIENT DEV MODE \u0417\u0430\u0434\u0430\u0447\u0430 \u0443\u0441\u043b\u043e\u0432\u043d\u043e \u043f\u043e\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u0430')\n            return\n\n        url = self.api_url + '/services/' + task.serviceId + '/tasks'\n        last_e = None\n        for idx in range(self.max_retries):\n            try:\n                resp = requests.post(\n                    url=url,\n                    data=json.dumps(task.__dict__),\n                    headers=self.headers,\n                    timeout=15\n                )\n                try:\n                    return json.loads(resp.text)\n                except:\n                    raise IOError(\"Starter response read error: \" + resp.text)\n            except (requests.exceptions.ConnectionError, requests.exceptions.Timeout) as e:\n                # \u041f\u0440\u0438 \u043e\u0448\u0438\u0431\u043a\u0430\u0445 \u043f\u043e\u0434\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u044f \u043f\u044b\u0442\u0430\u0435\u043c\u0441\u044f \u0435\u0449\u0435 \u0440\u0430\u0437\n                last_e = e\n                sleep(3)\n        raise last_e", "response": "Submit a task to the Arlo Asterisk API."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave the image for testing.", "response": "def _save_to(self, im, path, format=None):\n        \"\"\"Save the image for testing.\n        \"\"\"\n        format = format or im.format\n        if not format:\n            _, format = splitext(path)\n            format = format[1:]\n        im.format = format.lower()\n        im.save(filename=path)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef debug(self, message, *args, **kwargs):\n        self._log(logging.DEBUG, message, *args, **kwargs)", "response": "Log a debug message"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlog an info message", "response": "def info(self, message, *args, **kwargs):\n        \"\"\"More important level : default for print and save\n        \"\"\"\n        self._log(logging.INFO, message, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends an email and syslog warning to the log file.", "response": "def warn(self, message, *args, **kwargs):\n        \"\"\"Send email and syslog by default ...\n        \"\"\"\n        self._log(logging.WARNING, message, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef warning(self, message, *args, **kwargs):\n        self._log(logging.WARNING, message, *args, **kwargs)", "response": "Log a warning message with the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef error(self, message, *args, **kwargs):\n        self._log(logging.ERROR, message, *args, **kwargs)", "response": "Log an error message with the specified arguments."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlog a critical level message with optional arguments", "response": "def critical(self, message, *args, **kwargs):\n        \"\"\"Highest level\n        \"\"\"\n        self._log(logging.CRITICAL, message, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles exception in the log.", "response": "def exception(self, message, *args, **kwargs):\n        \"\"\"Handle exception\n        \"\"\"\n        self.logger.exception(message, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef init_logger(self):\n        # All logs are comming to this logger\n        self.logger.setLevel(logging.DEBUG)\n        self.logger.propagate = False\n\n        # Logging to console\n        if self.min_log_level_to_print:\n            level = self.min_log_level_to_print\n            handler_class = logging.StreamHandler\n            self._create_handler(handler_class, level)\n\n        # Logging to file\n        if self.min_log_level_to_save:\n            level = self.min_log_level_to_save\n            handler_class = logging.handlers.TimedRotatingFileHandler\n            self._create_handler(handler_class, level)\n\n        # Logging to syslog\n        if self.min_log_level_to_syslog:\n            level = self.min_log_level_to_syslog\n            handler_class = logging.handlers.SysLogHandler\n            self._create_handler(handler_class, level)\n\n        # Logging to email\n        if self.min_log_level_to_mail:\n            level = self.min_log_level_to_mail\n            handler_class = AlkiviEmailHandler\n            self._create_handler(handler_class, level)\n\n        return", "response": "Create configuration for the root logger."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef new_iteration(self, prefix):\n        # Flush data for the current iteration\n        self.flush()\n\n        # Fix prefix\n        self.prefix[-1] = prefix\n        self.reset_formatter()", "response": "When inside a loop logger created a new iteration containing the current iteration."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reset_formatter(self):\n        for handler in self.handlers:\n            formatter = self.get_formatter(handler)\n            handler.setFormatter(formatter)", "response": "Rebuild formatter for all handlers."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_min_level_to_print(self, level):\n        self.min_log_level_to_print = level\n        handler_class = logging.StreamHandler\n        self._set_min_level(handler_class, level)", "response": "Allow to change print level after creation\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nallows to change save level after creation", "response": "def set_min_level_to_save(self, level):\n        \"\"\"Allow to change save level after creation\n        \"\"\"\n        self.min_log_level_to_save = level\n        handler_class = logging.handlers.TimedRotatingFileHandler\n        self._set_min_level(handler_class, level)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nallowing to change mail level after creation", "response": "def set_min_level_to_mail(self, level):\n        \"\"\"Allow to change mail level after creation\n        \"\"\"\n        self.min_log_level_to_mail = level\n        handler_class = AlkiviEmailHandler\n        self._set_min_level(handler_class, level)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_min_level_to_syslog(self, level):\n        self.min_log_level_to_syslog = level\n        handler_class = logging.handlers.SysLogHandler\n        self._set_min_level(handler_class, level)", "response": "Allow to change syslog level after creation\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_handler(self, handler_class):\n        element = None\n        for handler in self.handlers:\n            if isinstance(handler, handler_class):\n                element = handler\n                break\n        return element", "response": "Return an existing class of handler."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a specific handler from our logger.", "response": "def _delete_handler(self, handler_class):\n        \"\"\"Delete a specific handler from our logger.\"\"\"\n        to_remove = self._get_handler(handler_class)\n        if not to_remove:\n            logging.warning('Error we should have an element to remove')\n        else:\n            self.handlers.remove(to_remove)\n            self.logger.removeHandler(to_remove)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the level of an handler.", "response": "def _update_handler(self, handler_class, level):\n        \"\"\"Update the level of an handler.\"\"\"\n        handler = self._get_handler(handler_class)\n        handler.setLevel(level)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_handler(self, handler_class, level):\n        if handler_class == logging.StreamHandler:\n            handler = handler_class()\n            handler.setLevel(level)\n        elif handler_class == logging.handlers.SysLogHandler:\n            handler = handler_class(address='/dev/log')\n            handler.setLevel(level)\n        elif handler_class == logging.handlers.TimedRotatingFileHandler:\n            handler = handler_class(self.filename, when='midnight')\n            handler.setLevel(level)\n        elif handler_class == AlkiviEmailHandler:\n            handler = handler_class(mailhost='127.0.0.1',\n                                    fromaddr=\"%s@%s\" % (USER, HOST),\n                                    toaddrs=self.emails,\n                                    level=self.min_log_level_to_mail)\n            # Needed, we want all logs to go there\n            handler.setLevel(0)\n\n        formatter = self.get_formatter(handler)\n        handler.setFormatter(formatter)\n        self.handlers.append(handler)\n        self.logger.addHandler(handler)", "response": "Create an handler for at specific level."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a logging. Formatter according to the given handler.", "response": "def get_formatter(self, handler):\n        \"\"\"\n        Return formatters according to handler.\n\n        All handlers are the same format, except syslog.\n        We omit time when syslogging.\n        \"\"\"\n        if isinstance(handler, logging.handlers.SysLogHandler):\n            formatter = '[%(levelname)-9s]'\n        else:\n            formatter = '[%(asctime)s] [%(levelname)-9s]'\n\n        for p in self.prefix:\n            formatter += ' [%s]' % (p)\n        formatter = formatter + ' %(message)s'\n        return logging.Formatter(formatter)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef version_control():\n    curdir_contents = os.listdir('.')\n    if '.hg' in curdir_contents:\n        return hg.Hg()\n    elif '.git' in curdir_contents:\n        return git.Git()\n    else:\n        logger.critical('No version control system detected.')\n        sys.exit(1)", "response": "Return an object that provides the version control interface based\n    on the detected version control system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking whether the package is registered on pypi", "response": "def package_in_pypi(package):\n    \"\"\"Check whether the package is registered on pypi\"\"\"\n    url = 'http://pypi.python.org/simple/%s' % package\n    try:\n        urllib.request.urlopen(url)\n        return True\n    except urllib.error.HTTPError as e:\n        logger.debug(\"Package not found on pypi: %s\", e)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the version to a non - development version.", "response": "def _grab_version(self):\n        \"\"\"Set the version to a non-development version.\"\"\"\n        original_version = self.vcs.version\n        logger.debug(\"Extracted version: %s\", original_version)\n        if original_version is None:\n            logger.critical('No version found.')\n            sys.exit(1)\n        suggestion = utils.cleanup_version(original_version)\n        new_version = utils.ask_version(\"Enter version\", default=suggestion)\n        if not new_version:\n            new_version = suggestion\n        self.data['original_version'] = original_version\n        self.data['new_version'] = new_version"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngrab the needed history and change the version of the current version.", "response": "def _grab_history(self):\n        \"\"\"Calculate the needed history/changelog changes\n\n        Every history heading looks like '1.0 b4 (1972-12-25)'. Extract them,\n        check if the first one matches the version and whether it has a the\n        current date.\n        \"\"\"\n        default_location = None\n        config = self.setup_cfg.config\n        if config and config.has_option('zest.releaser', 'history_file'):\n            default_location = config.get('zest.releaser', 'history_file')\n        history_file = self.vcs.history_file(location=default_location)\n        if not history_file:\n            logger.warn(\"No history file found\")\n            self.data['history_lines'] = None\n            self.data['history_file'] = None\n            return\n        logger.debug(\"Checking %s\", history_file)\n        history_lines = open(history_file).read().split('\\n')\n        # ^^^ TODO: .readlines()?\n        headings = utils.extract_headings_from_history(history_lines)\n        if not len(headings):\n            logger.error(\"No detectable version heading in the history \"\n                         \"file %s\", history_file)\n            sys.exit()\n        good_heading = self.data['history_header'] % self.data\n        # ^^^ history_header is a string with %(abc)s replacements.\n        line = headings[0]['line']\n        previous = history_lines[line]\n        history_lines[line] = good_heading\n        logger.debug(\"Set heading from %r to %r.\", previous, good_heading)\n        history_lines[line + 1] = utils.fix_rst_heading(\n            heading=good_heading,\n            below=history_lines[line + 1])\n        logger.debug(\"Set line below heading to %r\",\n                     history_lines[line + 1])\n        self.data['history_lines'] = history_lines\n        self.data['history_file'] = history_file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _write_history(self):\n        if self.data['history_file'] is None:\n            return\n        contents = '\\n'.join(self.data['history_lines'])\n        history = self.data['history_file']\n        open(history, 'w').write(contents)\n        logger.info(\"History file %s updated.\", history)", "response": "Write previously calculated history lines back to the file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_if_tag_already_exists(self):\n        version = self.data['new_version']\n        if self.vcs.tag_exists(version):\n            return True\n        else:\n            return False", "response": "Check if tag already exists and show the difference if so"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _release(self):\n\n        pypiconfig = pypi.PypiConfig()\n\n        # Does the user normally want a real release?  We are\n        # interested in getting a sane default answer here, so you can\n        # override it in the exceptional case but just hit Enter in\n        # the usual case.\n        main_files = os.listdir(self.data['workingdir'])\n        if 'setup.py' not in main_files and 'setup.cfg' not in main_files:\n            # Neither setup.py nor setup.cfg, so this is no python\n            # package, so at least a pypi release is not useful.\n            # Expected case: this is a buildout directory.\n            default_answer = False\n        else:\n            default_answer = pypiconfig.want_release()\n\n        if not utils.ask(\"Check out the tag (for tweaks or pypi/distutils \"\n                         \"server upload)\", default=default_answer):\n            return\n\n        package = self.vcs.name\n        version = self.data['new_version']\n        logger.info(\"Doing a checkout...\")\n        self.vcs.checkout_from_tag(version)\n        self.data['tagdir'] = os.path.realpath(os.getcwd())\n        logger.info(\"Tag checkout placed in %s\", self.data['tagdir'])\n\n        # Possibly fix setup.cfg.\n        if self.setup_cfg.has_bad_commands():\n            logger.info(\"This is not advisable for a release.\")\n            if utils.ask(\"Fix %s (and commit to tag if possible)\" %\n                         self.setup_cfg.config_filename, default=True):\n                # Fix the setup.cfg in the current working directory\n                # so the current release works well.\n                self.setup_cfg.fix_config()\n\n        sdist_options = self._sdist_options()\n\n        if 'setup.py' in os.listdir(self.data['tagdir']):\n            self._upload_distributions(package, sdist_options, pypiconfig)\n\n        # Make sure we are in the expected directory again.\n        os.chdir(self.vcs.workingdir)", "response": "Upload the release when desired"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _update_version(self):\n        #current = self.vcs.version\n        current = self.data['new_version']\n\n        # Clean it up to a non-development version.\n        current = utils.cleanup_version(current)\n        # Try to make sure that the suggestion for next version after\n        # 1.1.19 is not 1.1.110, but 1.1.20.\n        current_split = current.split('.')\n        major = '.'.join(current_split[:-1])\n        minor = current_split[-1]\n        try:\n            minor = int(minor) + 1\n            suggestion = '.'.join([major, str(minor)])\n        except ValueError:\n            # Fall back on simply updating the last character when it is\n            # an integer.\n            try:\n                last = int(current[-1]) + 1\n                suggestion = current[:-1] + str(last)\n            except ValueError:\n                logger.warn(\"Version does not end with a number, so we can't \"\n                            \"calculate a suggestion for a next version.\")\n                suggestion = None\n        print(\"Current version is %r\" % current)\n        q = \"Enter new development version ('.dev0' will be appended)\"\n        version = utils.ask_version(q, default=suggestion)\n        if not version:\n            version = suggestion\n        if not version:\n            logger.error(\"No version entered.\")\n            sys.exit()\n\n        self.data['new_version'] = version\n        dev_version = self.data['dev_version_template'] % self.data\n        self.data['dev_version'] = dev_version\n        logger.info(\"New version string is %r\",\n                    dev_version)\n\n        self.vcs.version = self.data['dev_version']", "response": "Ask for and store a new development version string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the history file with the new version.", "response": "def _update_history(self):\n        \"\"\"Update the history file\"\"\"\n        version = self.data['new_version']\n        history = self.vcs.history_file()\n        if not history:\n            logger.warn(\"No history file found\")\n            return\n        history_lines = open(history).read().split('\\n')\n        headings = utils.extract_headings_from_history(history_lines)\n        if not len(headings):\n            logger.warn(\"No detectable existing version headings in the \"\n                        \"history file.\")\n            inject_location = 0\n            underline_char = '-'\n        else:\n            first = headings[0]\n            inject_location = first['line']\n            underline_line = first['line'] + 1\n            try:\n                underline_char = history_lines[underline_line][0]\n            except IndexError:\n                logger.debug(\"No character on line below header.\")\n                underline_char = '-'\n        header = '%s (unreleased)' % version\n        inject = [header,\n                  underline_char * len(header),\n                  '',\n                  self.data['nothing_changed_yet'],\n                  '',\n                  '']\n        history_lines[inject_location:inject_location] = inject\n        contents = '\\n'.join(history_lines)\n        open(history, 'w').write(contents)\n        logger.info(\"Injected new section into the history: %r\", header)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\noffer to push changes if needed.", "response": "def _push(self):\n        \"\"\"Offer to push changes, if needed.\"\"\"\n\n        push_cmds = self.vcs.push_commands()\n        if not push_cmds:\n            return\n        if utils.ask(\"OK to push commits to the server?\"):\n            for push_cmd in push_cmds:\n                output = utils.system(push_cmd)\n                logger.info(output)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete a user Delete a user # noqa: E501 :param user: Delete user with this name :type user: str :param driver: The driver to use for the request. ie. github :type driver: str :param user_delete: The data needed to delete this user :type user_delete: dict | bytes :rtype: Response", "response": "def delete_user(user, driver, user_delete=None):  # noqa: E501\n    \"\"\"Delete a user\n\n    Delete a user # noqa: E501\n\n    :param user: Delete user with this name\n    :type user: str\n    :param driver: The driver to use for the request. ie. github\n    :type driver: str\n    :param user_delete: The data needed to delete this user\n    :type user_delete: dict | bytes\n\n    :rtype: Response\n    \"\"\"\n    if connexion.request.is_json:\n        user_delete = UserDelete.from_dict(connexion.request.get_json())  # noqa: E501\n\n    response = errorIfUnauthorized(role='admin')\n    if response:\n        return response\n    else:\n        response = ApitaxResponse()\n\n    driver: Driver = LoadedDrivers.getDriver(driver)\n\n    if driver.deleteApitaxUser(User(username=user)):\n        return Response(status=200, body=response.getResponseBody())\n\n    return ErrorResponse(status=500, message='Failed to create user')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_user(user, driver):  # noqa: E501\n\n    response = ApitaxResponse()\n\n    driver: Driver = LoadedDrivers.getDriver(driver)\n    user: User = driver.getApitaxUser(User(username=user))\n    response.body.add({'user': {'username': user.username, 'role': user.role}})\n\n    return Response(status=200, body=response.getResponseBody())", "response": "Retrieve a user with this name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main(path_dir, requirements_name):\n    click.echo(\"\\nWARNING: Uninstall libs it's at your own risk!\")\n    click.echo('\\nREMINDER: After uninstall libs, update your requirements '\n               'file.\\nUse the `pip freeze > requirements.txt` command.')\n\n    click.echo('\\n\\nList of installed libs and your dependencies added on '\n               'project\\nrequirements that are not being used:\\n')\n\n    check(path_dir, requirements_name)", "response": "Console script for imports."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef now(utc=False):\n    if utc:\n        return datetime.datetime.utcnow().replace(tzinfo=dateutil.tz.tzutc())\n    else:\n        return datetime.datetime.now()", "response": "Returns the current time."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsplits a \"%s:%d\" string and returns the string and number.", "response": "def parse_scale(x):\n    \"\"\"Splits a \"%s:%d\" string and returns the string and number.\n\n    :return: A ``(string, int)`` pair extracted from ``x``.\n\n    :raise ValueError: the string ``x`` does not respect the input format.\n    \"\"\"\n    match = re.match(r'^(.+?):(\\d+)$', x)\n    if not match:\n        raise ValueError('Invalid scale \"%s\".' % x)\n    return match.group(1), int(match.group(2))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmerging the values in one or more dictionaries into a single dict.", "response": "def merge_envs(*args):\n    \"\"\"Union of one or more dictionaries.\n\n    In case of duplicate keys, the values in the right-most arguments will\n    squash (overwrite) the value provided by any dict preceding it.\n\n    :param args: Sequence of ``dict`` objects that should be merged.\n    :return: A ``dict`` containing the union of keys in all input dicts.\n\n    \"\"\"\n    env = {}\n    for arg in args:\n        if not arg:\n            continue\n        env.update(arg)\n    return env"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_once(name, cmd, env, shutdown, loop=None, utc=False):\n\n    # Get the default event loop if necessary.\n    loop = loop or asyncio.get_event_loop()\n\n    # Launch the command into a child process.\n    if isinstance(cmd, str):\n        cmd = shlex.split(cmd)\n    process = yield from asyncio.create_subprocess_exec(\n        *cmd,\n        env=env,\n        stdin=asyncio.subprocess.PIPE,\n        stdout=asyncio.subprocess.PIPE,\n        stderr=asyncio.subprocess.STDOUT,\n    )\n    print('%s [strawboss] %s(%d) spawned.' % (\n        now(utc).isoformat(), name, process.pid\n    ))\n\n    # Exhaust the child's standard output stream.\n    #\n    # TODO: close stdin for new process.\n    # TODO: terminate the process after the grace period.\n    ready = asyncio.ensure_future(process.wait())\n    pending = {\n        shutdown,\n        ready,\n        asyncio.ensure_future(process.stdout.readline()),\n    }\n    while not ready.done():\n        done, pending = yield from asyncio.wait(\n            pending,\n            return_when=asyncio.FIRST_COMPLETED,\n        )\n        for future in done:\n            # React to a request to shutdown the process.\n            #\n            # NOTE: shutdown is asynchronous unless the process completion\n            #       notification is \"in flight\".  We forward the request to\n            #       shutdown and then wait until the child process completes.\n            if future is shutdown:\n                try:\n                    process.kill()\n                except ProcessLookupError:\n                    pass\n                else:\n                    print('%s [strawboss] %s(%d) killed.' % (\n                        now(utc).isoformat(), name, process.pid\n                    ))\n                continue\n            # React to process death (natural, killed or terminated).\n            if future is ready:\n                exit_code = yield from future\n                print('%s [strawboss] %s(%d) completed with exit status %d.' % (\n                    now(utc).isoformat(), name, process.pid, exit_code\n                ))\n                continue\n            # React to stdout having a full line of text.\n            data = yield from future\n            if not data:\n                print('%s [strawboss] EOF from %s(%d).' % (\n                    now(utc).isoformat(), name, process.pid,\n                ))\n                continue\n            data = data.decode('utf-8').strip()\n            print('%s [%s] %s' % (\n                now(utc).isoformat(), name, data\n            ))\n            pending.add(asyncio.ensure_future(process.stdout.readline()))\n    # Cancel any remaining tasks (e.g. readline).\n    for future in pending:\n        if future is shutdown:\n            continue\n        future.cancel()\n    # Pass the exit code back to the caller.\n    return exit_code", "response": "Starts a child process and waits for its completion."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart a child process and re - spawns it every time it completes.", "response": "def run_and_respawn(shutdown, loop=None, **kwds):\n    \"\"\"Starts a child process and re-spawns it every time it completes.\n\n    .. note:: This function is a coroutine.\n\n    :param shutdown: Future that the caller will fulfill to indicate that the\n       process should not be re-spawned.  It is also passed to ``run_once()``\n       to indicate that the currently running process should be killed early.\n    :param loop: Event loop to use.  Defaults to the\n       ``asyncio.get_event_loop()``.\n    :param kwds: Arguments to forward to :py:func:`run_once`.\n    :return: A future that will be completed when the process has stopped\n       re-spawning and has completed.  The future has no result.\n\n    \"\"\"\n\n    # Get the default event loop if necessary.\n    loop = loop or asyncio.get_event_loop()\n\n    while not shutdown.done():\n        t = loop.create_task(run_once(shutdown=shutdown, loop=loop, **kwds))\n        yield from t"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main(arguments=None):\n\n    # Parse command-line arguments.\n    if arguments is None:\n        arguments = sys.argv[1:]\n    arguments = cli.parse_args(arguments)\n\n    # Read the procfile.\n    try:\n        process_types = procfile.loadfile(arguments.procfile)\n    except FileNotFoundError:\n        sys.stderr.write('Procfile not found at \"%s\".' % arguments.procfile)\n        sys.exit(2)\n\n    # Read the env file(s).\n    env = {}\n    if arguments.use_env:\n        for path in arguments.envfiles:\n            try:\n                env.update(dotenvfile.loadfile(path))\n            except FileNotFoundError:\n                sys.stderr.write(\n                    'Warning: environment file \"%s\" not found.\\n' % path\n                )\n\n    # Determine how many processes of each type we need.\n    effective_scale = {}\n    requested_scale = dict(arguments.scale)\n    for label in process_types:\n        effective_scale[label] = requested_scale.get(\n            label,\n            requested_scale['*'],\n        )\n\n    # Start the event loop.\n    loop = asyncio.get_event_loop()\n\n    # Register for shutdown events (idempotent, trap once only).\n    shutdown = asyncio.Future()\n    def stop_respawning():\n        if shutdown.done():\n            return\n        shutdown.set_result(None)\n        loop.remove_signal_handler(signal.SIGINT)\n    loop.add_signal_handler(signal.SIGINT, stop_respawning)\n\n    # Spawn tasks.\n    tasks = []\n    for label, count in effective_scale.items():\n        process_type = process_types[label]\n        the_cmd = shlex.split(process_type['cmd'])\n        the_env = merge_envs(os.environ, env, process_type['env'])\n        for i in range(count):\n            task = loop.create_task(run_and_respawn(\n                name='%s.%i' % (label, i),\n                cmd=the_cmd,\n                env=the_env,\n                loop=loop,\n                shutdown=shutdown,\n                utc=arguments.use_utc,\n            ))\n            tasks.append(task)\n\n    if not tasks:\n        sys.stderr.write('Nothing to run.\\n')\n        sys.exit(2)\n\n    # Wait for all tasks to complete.\n    loop.run_until_complete(asyncio.wait(tasks))\n    loop.close()", "response": "This function is the main function of the command - line interface."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlogging an exception to stdout.", "response": "def logexception(self, logger=None):\n        '''\n        calls exception method on a loger and prints the log to stdout\n        logger is set in the cfg\n        #Todo more details here on the cfg etc\n        :param logger:\n        :return:\n        '''\n        traceback.print_exc()\n        if logger: \n            logger.exception('Unexpected runtime Error...')\n        else:\n            self.logger.exception('Unexpected runtime Error...')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef upload_logs(self, release_singleton=True):\n        '''\n        uploads a log to a server using the method and gui specifed\n        in self.pcfg\n        singleton mode can be disabled so a new version can be restarted whille uploading oges\n        on typicallin in the case of uploadnig after a crash or sys exit\n        set self.cfg log_upload_interface to gui/cli/or background\n        '''\n        if release_singleton:\n            self.release_singleton()\n\n        def _upload():\n            for log in self.get_logs():\n                new_name = self._uniquename(log)\n                self._upload(log, new_name)\n                # Todo: keep log around for a few days\n                self.delete_log(log)\n\n        if self.pcfg['log_server_interface'] == 'gui':\n            raise NotImplementedError\n            threading.Thread(target=threadme)\n            gui_uploader(threadme)\n        elif self.pcfg['log_server_interface'] == 'cli':\n            raise NotImplementedError\n        elif self.pcfg['log_server_interface'] == 'background':\n            _upload()", "response": "Uploads a log to a server using the GUI specifed\n        singleton mode."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_log(self, log):\n        '''check we don't delte anythin unintended'''\n        if os.path.splitext(log)[-1] != '.log':\n            raise Exception('File without .log was passed in for deletoin')\n        with suppress(Exception):\n            os.remove(log)", "response": "delete a log file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_logs(self):\n        '''returns logs from disk, requires .log extenstion'''\n        folder = os.path.dirname(self.pcfg['log_file'])\n        for path, dir, files in os.walk(folder):\n            for file in files:\n                if os.path.splitext(file)[-1] == '.log':\n                    yield os.path.join(path, file)", "response": "returns logs from disk requires. log extenstion"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _uniquename(self, log):\n        '''\n        renames the log to ensure we get no clashes on the server\n        subclass this to change the path etc'''\n        return '{hostname} - {time}.log'.format(\n                                hostname=os.getenv('USERNAME'),\n                                time=strftime(\"%a, %d %b %Y %H-%M-%S\", gmtime()))", "response": "renames the log to ensure we get no clashes on the server\n        subclass this is not a real object"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse out command line arguments", "response": "def parser(description=None, usage=None):\n    \"\"\"Parse out command line arguments\"\"\"\n\n    class ArgNamespace(object):\n        def __init__(self, result):\n            self._result = result\n\n        def __getattr__(self, name):\n            try:\n                super(ArgNamespace, self).__getattr__(name)\n            except AttributeError:\n                return getattr(self._result, name)\n\n        def arg_strings(self, name=None):\n            if not self._result:\n                return None\n            return extract_strings(self._result.__dict__, name)\n\n    class ArgParser(object):\n\n        def __init__(self, argument_parser):\n            self.parser = argument_parser\n            self.parse = self.parse_args\n            self._parsed = None\n\n            self.arg = self.parser.add_argument\n            self.opt = self.true = partial(self.arg, action='store_true')\n            self.int = partial(self.arg, type=int)\n\n        def parse_args(self):\n            return ArgNamespace(self.parser.parse_args())\n\n        def sub(self, name, help=''):\n            self.arg(name, metavar=name, help=help, type=str)\n\n        def args(self, name, help='', many='*'):\n            self.arg(name, metavar=name, help=help, type=str, nargs=many)\n\n        def answer(self, answers=None):\n            yes_no = {\n                'n': ('-n', '--no', 'Answer no'),\n                'y': ('-y', '--yes', 'Answer yes'),\n            }\n            options = yes_no\n            options.update(answers)\n            [self.true(options[o]) for o in options]\n\n    lines = description.splitlines()\n    if not usage:\n        if len(lines) > 1 and not lines[1]:\n            usage, epilog = lines[0], '\\n\\n'.join(lines[2:])\n    else:\n        usage = description = lines[0]\n        epilog = None\n    return ArgParser(\n        argparse.ArgumentParser(usage=description))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef next_event(self, canceller=None):\n        d = defer.Deferred(canceller)\n        \n        def cb(value):\n            self.remove_callback(d.callback)\n            return value\n        d.addBoth(cb)\n        \n        self.add_callback(d.callback)\n        return d", "response": "Returns a Deferred that will be called back\nAttributeNames with the value of the next event."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef derive(self, modifier):\n        def forward(value):\n            changed_value = modifier(value)\n            derived.fire(changed_value)\n        \n        derived = Event()\n        self.add_callback(forward)\n        return derived", "response": "Derives an event from this one."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a file in the given directory with a valid module name populated with the given txt.", "response": "def create_module_file(txt, directory):\n    \"\"\"Create a file in the given directory with\n    a valid module name populated with the given txt.\n\n    Returns:\n        A path to the file\"\"\"\n    name = nonpresent_module_filename()\n    path = os.path.join(directory, name)\n    with open(path, 'w') as fh:\n        fh.write(txt)\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nonpresent_module_filename():\n    while True:\n        module_name = get_random_name()\n        loader = pkgutil.find_loader(module_name)\n        if loader is not None:\n            continue\n        importlib.invalidate_caches()\n        return \"{}.py\".format(module_name)", "response": "Return a random module name that doesn t already exist"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_random_name():\n    char_seq = []\n    name_source = random.randint(1, 2**8-1)\n    current_value = name_source\n    while current_value > 0:\n        char_offset = current_value % 26\n        current_value = current_value - random.randint(1, 26)\n        char_seq.append(chr(char_offset + ord('a')))\n    name = ''.join(char_seq)\n    assert re.match(VALID_PACKAGE_RE, name)\n    return name", "response": "Return random lowercase name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dictionary of the Cache - Control headers that are present in the response", "response": "def get_header_dict(response, header):\n    \"\"\" returns a dictionary of the cache control headers\n        the same as is used by django.utils.cache.patch_cache_control\n        if there are no Cache-Control headers returns and empty dict\n    \"\"\"\n    def dictitem(s):\n        t = s.split('=', 1)\n        if len(t) > 1:\n            return (t[0].lower(), t[1])\n        else:\n            return (t[0].lower(), True)\n\n    if response.has_header(header):\n        hd = dict([dictitem(el) for el in cc_delim_re.split(response[header])])\n    else:\n        hd= {}\n    return hd"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats and sets a header dict in a response inververs of get_header_dict.", "response": "def set_header_dict(response, header, header_dict):\n    \"\"\"Formats and sets a header dict in a response, inververs of get_header_dict.\"\"\"\n    def dictvalue(t):\n        if t[1] is True:\n            return t[0]\n        return t[0] + '=' + smart_str(t[1])\n\n    response[header] = ', '.join([dictvalue(el) for el in header_dict.items()])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a path smart_import will import the module and return the attr reffered to.", "response": "def smart_import(mpath):\n    \"\"\"Given a path smart_import will import the module and return the attr reffered to.\"\"\"\n    try:\n        rest = __import__(mpath)\n    except ImportError:\n        split = mpath.split('.')\n        rest = smart_import('.'.join(split[:-1]))\n        rest = getattr(rest, split[-1])\n    return rest"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef strip_wsgi(request):\n\n    meta = copy(request.META)\n    for key in meta:\n        if key[:4] == 'wsgi':\n            meta[key] = None\n    return meta", "response": "Strip WSGI data out of the request META data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the headers we want for caching.", "response": "def patch_headers(self, response):\n        \"\"\"Set the headers we want for caching.\"\"\"\n\n        # Remove Vary:Cookie if we want to cache non-anonymous\n        if not getattr(settings, 'BETTERCACHE_ANONYMOUS_ONLY', False):\n            vdict = get_header_dict(response, 'Vary')\n            try:\n                vdict.pop('cookie')\n            except KeyError:\n                pass\n            else:\n                set_header_dict(response, 'Vary', vdict)\n\n        #  Set max-age, post-check and pre-check\n        cc_headers = get_header_dict(response, 'Cache-Control')\n        try:\n            timeout = cc_headers['max-age']\n        except KeyError:\n            timeout = settings.BETTERCACHE_CACHE_MAXAGE\n            cc_headers['max-age'] = timeout\n        # This should never happen but let's be safe\n        if timeout is 0:\n            return response\n        if not 'pre-check' in cc_headers:\n           cc_headers['pre-check'] = timeout\n        if not 'post-check' in cc_headers:\n           cc_headers['post-check'] = int(timeout * settings.BETTERCACHE_EDGE_POSTCHECK_RATIO)\n        set_header_dict(response, 'Cache-Control', cc_headers)\n        # this should be the main/first place we're setting edge control so we can just set what we want\n        ec_dict = {'cache-maxage' : settings.BETTERCACHE_EDGE_MAXAGE}\n        set_header_dict(response, 'Edge-Control', ec_dict)\n        response['Last-Modified'] = http_date()\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives the request and response return True if the request should be cached False otherwise", "response": "def should_cache(self, request, response):\n        \"\"\" Given the request and response should it be cached \"\"\"\n\n        if not getattr(request, '_cache_update_cache', False):\n            return False\n        if not response.status_code in getattr(settings, 'BETTERCACHE_CACHEABLE_STATUS', CACHEABLE_STATUS):\n            return False\n        if getattr(settings, 'BETTERCACHE_ANONYMOUS_ONLY', False) and self.session_accessed and request.user.is_authenticated:\n            return False\n        if self.has_uncacheable_headers(response):\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if this page was originally generated less than LOCAL_POSTCHECK seconds ago", "response": "def should_regenerate(self, response):\n        \"\"\" Check if this page was originally generated less than LOCAL_POSTCHECK seconds ago \"\"\"\n\n        if response.has_header('Last-Modified'):\n            last_modified = parse_http_date(response['Last-Modified'])\n            next_regen = last_modified + settings.BETTERCACHE_LOCAL_POSTCHECK\n            return time.time() > next_regen"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef has_uncacheable_headers(self, response):\n\n        cc_dict = get_header_dict(response, 'Cache-Control')\n        if cc_dict:\n            if 'max-age' in cc_dict and cc_dict['max-age'] == '0':\n                return True\n            if 'no-cache' in cc_dict:\n                return True\n            if 'private' in cc_dict:\n                return True\n        if response.has_header('Expires'):\n            if parse_http_date(response['Expires']) < time.time():\n                return True\n        return False", "response": "Returns True if the response contains uncacheable headers."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncaches the response supresses and logs exceptions", "response": "def set_cache(self, request, response):\n        \"\"\" caches the response supresses and logs exceptions\"\"\"\n\n        try:\n            cache_key = self.cache_key(request)\n            #presumably this is to deal with requests with attr functions that won't pickle\n            if hasattr(response, 'render') and callable(response.render):\n                response.add_post_render_callback(lambda r: cache.set(cache_key, (r, time.time(),), settings.BETTERCACHE_LOCAL_MAXAGE))\n            else:\n                cache.set(cache_key, (response, time.time(),) , settings.BETTERCACHE_LOCAL_MAXAGE)\n        except:\n            logger.error(\"failed to cache to %s\" %cache_key)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nattempt to get a response from cache returns a tuple of the response and whether it s expired", "response": "def get_cache(self, request):\n        \"\"\" Attempts to get a response from cache, returns a tuple of the response and whether it's expired\n            If there is no cached response return (None, None,)\n        \"\"\"\n\n        # try and get the cached GET response\n        cache_key = self.cache_key(request)\n        cached_response = cache.get(cache_key, None)\n        # if it wasn't found and we are looking for a HEAD, try looking for a corresponding GET\n        if cached_response is None and request.method == 'HEAD':\n            cache_key = self.cache_key(request, 'GET')\n            cached_response = cache.get(cache_key, None)\n        if cached_response is None:\n            return None, None\n        if cached_response[1] < time.time() - settings.BETTERCACHE_LOCAL_POSTCHECK:\n            return cached_response[0], True\n        return cached_response[0], False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_task(self, request, response):\n\n        # TODO is this too messy?\n        from bettercache.tasks import GeneratePage\n        try:\n            GeneratePage.apply_async((strip_wsgi(request),))\n        except:\n            logger.error(\"failed to send celery task\")\n        self.set_cache(request, response)", "response": "send off a celery task for the current page and recache"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef entity_to_unicode(string):\n    # Selected character replacements that have been seen\n    replacements = []\n    replacements.append((r\"&alpha;\", u\"\\u03b1\"))\n    replacements.append((r\"&beta;\", u\"\\u03b2\"))\n    replacements.append((r\"&gamma;\", u\"\\u03b3\"))\n    replacements.append((r\"&delta;\", u\"\\u03b4\"))\n    replacements.append((r\"&epsilon;\", u\"\\u03b5\"))\n    replacements.append((r\"&ordm;\", u\"\\u00ba\"))\n    replacements.append((r\"&iuml;\", u\"\\u00cf\"))\n    replacements.append((r\"&ldquo;\", '\"'))\n    replacements.append((r\"&rdquo;\", '\"'))\n\n    # First, replace numeric entities with unicode\n    string = re.sub(r\"&#x(....);\", repl, string)\n    # Second, replace some specific entities specified in the list\n    for entity, replacement in replacements:\n        string = re.sub(entity, replacement, string)\n    return string", "response": "Quick convert unicode HTML entities to unicode characters using a regular expression replacement\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving a tag from a string", "response": "def remove_tag(tag_name, string):\n    \"\"\"\n    Remove open and close tags - the tags themselves only - using\n    a non-greedy angle bracket pattern match\n    \"\"\"\n    if not string:\n        return string\n    pattern = re.compile('</?' + tag_name + '.*?>')\n    string = pattern.sub('', string)\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreplaces tags such as i to italic", "response": "def replace_tags(string, from_tag='i', to_tag='italic'):\n    \"\"\"\n    Replace tags such as <i> to <italic>\n    <sup> and <sub> are allowed and do not need to be replaced\n    This does not validate markup\n    \"\"\"\n    string = string.replace('<' + from_tag + '>', '<' + to_tag + '>')\n    string = string.replace('</' + from_tag + '>', '</' + to_tag + '>')\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef version_from_xml_filename(filename):\n    \"extract the numeric version from the xml filename\"\n    try:\n        filename_parts = filename.split(os.sep)[-1].split('-')\n    except AttributeError:\n        return None\n    if len(filename_parts) == 3:\n        try:\n            return int(filename_parts[-1].lstrip('v').rstrip('.xml'))\n        except ValueError:\n            return None\n    else:\n        return None", "response": "extract the numeric version from the xml filename"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the last commit to the master branch.", "response": "def get_last_commit_to_master(repo_path=\".\"):\n    \"\"\"\n    returns the last commit on the master branch. It would be more ideal to get the commit\n    from the branch we are currently on, but as this is a check mostly to help\n    with production issues, returning the commit from master will be sufficient.\n    \"\"\"\n    last_commit = None\n    repo = None\n    try:\n        repo = Repo(repo_path)\n    except (InvalidGitRepositoryError, NoSuchPathError):\n        repo = None\n    if repo:\n        try:\n            last_commit = repo.commits()[0]\n        except AttributeError:\n            # Optimised for version 0.3.2.RC1\n            last_commit = repo.head.commit\n    return str(last_commit)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the journal volume value based on the pub date and year", "response": "def calculate_journal_volume(pub_date, year):\n    \"\"\"\n    volume value is based on the pub date year\n    pub_date is a python time object\n    \"\"\"\n    try:\n        volume = str(pub_date.tm_year - year + 1)\n    except TypeError:\n        volume = None\n    except AttributeError:\n        volume = None\n    return volume"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconcatenates an author name from json data", "response": "def author_name_from_json(author_json):\n    \"concatenate an author name from json data\"\n    author_name = None\n    if author_json.get('type'):\n        if author_json.get('type') == 'group' and author_json.get('name'):\n            author_name = author_json.get('name')\n        elif author_json.get('type') == 'person' and author_json.get('name'):\n            if author_json.get('name').get('preferred'):\n                author_name = author_json.get('name').get('preferred')\n    return author_name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nformatting an author affiliation from details", "response": "def text_from_affiliation_elements(department, institution, city, country):\n    \"format an author affiliation from details\"\n    return ', '.join(element for element in [department, institution, city, country] if element)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef select(self, table, args='*', condition=None, control=None):\n        sql = 'select {} from {}'.format(args, table)\n        sql += self.parse_condition(condition) + (' {};'.format(control) if control else ';')\n        return super(PGWrapper, self).execute(sql, result=True).results", "response": "Select all the records in a table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the record in the specified table.", "response": "def update(self, table, kwargs, condition=None):\n        \"\"\".. :py:method:: update\n\n            All module update can user this function.\n            condition only support string and dictionary.\n\n        Usage::\n\n            >>> update('dept', {'name': 'design', 'quantity': 3}, {'id': 'we4d'})\n            update dept set name='design', quantity=3 where id='we4d';\n\n            >>> update('dept', {'name': 'design', 'quantity': 3}, 'introduction is null')\n            update dept set name='design', quantity=3 where introduction is null;\n\n            >>> update('physician', {'$inc': {'status': -10}, 'present': 0}, {'id': 'someid'})\n            update physician set status=status+-10, present=0 where id='someid';\n\n        \"\"\"\n        sql = \"update {} set {}\"\n        equations = []\n        values = []\n        for k, v in kwargs.iteritems():\n            if k == '$inc' and isinstance(v, dict):\n                for ik, iv in v.iteritems():\n                    equations.append(\"{field}={field}+{value}\".format(field=ik, value=iv))\n            else:\n                equations.append(\"{}=%s\".format(k))\n                values.append(v)\n\n        sql = sql.format(table, ', '.join(equations))\n        sql += self.parse_condition(condition) + \";\"\n        super(PGWrapper, self).execute(sql, values, result=False)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting all entries from a table.", "response": "def delete(self, table, condition):\n        \"\"\".. :py:method::\n\n        Usage::\n\n            >>> delete('hospital', {'id': '12de3wrv'})\n            delete from hospital where id='12de3wrv';\n\n        \"\"\"\n        sql = \"delete from {}\".format(table)\n        sql += self.parse_condition(condition) + \";\"\n        super(PGWrapper, self).execute(sql, result=False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef insert_inexistence(self, table, kwargs, condition):\n        sql = \"insert into \" + table + \" ({}) \"\n        select = \"select {} \"\n        condition = \"where not exists (select 1 from \" + table + \"{} limit 1);\".format( self.parse_condition(condition) )\n        keys, values = [], []\n        [ (keys.append(k), values.append(v)) for k, v in kwargs.iteritems() ]\n        sql = sql.format(', '.join(keys)) + select.format( ', '.join(['%s']*len(values)) ) + condition\n        super(PGWrapper, self).execute(sql, values, result=False)", "response": "Insert inexistence of a record in the specified table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the condition string and dictonary", "response": "def parse_condition(self, condition):\n        \"\"\".. :py:method::\n\n            parse the condition, support string and dictonary\n        \"\"\"\n        if isinstance(condition, bytes):\n            sql = \" where {}\".format(condition)\n        elif isinstance(condition, dict):\n            conditions = []\n            for k, v in condition.iteritems():\n                if isinstance(v, unicode):\n                    v = v.encode('utf-8')\n                s = \"{}='{}'\".format(k, v) if isinstance(v, bytes) else \"{}={}\".format(k, v)\n                conditions.append(s)\n            sql = \" where {}\".format(', '.join(conditions))\n        else:\n            sql = \"\"\n        return sql"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nselecting the entries from a table join another table.", "response": "def select_join(self, table, field, join_table, join_field):\n        \"\"\".. :py:method::\n\n        Usage::\n\n            >>> select_join('hospital', 'id', 'department', 'hospid')\n            select hospital.id from hospital left join department on hospital.id=department.hospid where department.hospid is null;\n\n        \"\"\"\n        sql = \"select {table}.{field} from {table} left join {join_table} \"\\\n              \"on {table}.{field}={join_table}.{join_field} \"\\\n              \"where {join_table}.{join_field} is null;\".format(table=table,\n                                                                field=field,\n                                                                join_table=join_table,\n                                                                join_field=join_field)\n        return super(PGWrapper, self).execute(sql, result=True).results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_variants(fns, remove=['DBSNP'], keep_only=True,\n                  min_tumor_f=0.1, min_tumor_cov=14,\n                  min_normal_cov=8):\n    \"\"\"Read muTect results from the list of files fns\n\n    Parameters\n    ----------\n    fns : list\n        List of MuTect output files.\n\n    Returns\n    -------\n    variants : pandas.DataFrame\n        Pandas DataFrame summarizing variant calling results.\n\n    remove : list\n        List of site types for column \"dbsnp_site\" to remove.\n\n    keep_only : boolean\n        If True, only keep variants with 'KEEP' in \"judgement\" column.\n        Otherwise, keep all variants.\n\n    min_tumor_f : float between 0 and 1\n        Minimum tumor allelic fraction.\n\n    min_tumor_cov : int > 0\n        Minimum coverage of the variant in the tumor.\n\n    min_normal_cov : int > 0\n        Minimum coverage of the variant in the normal.\n\n    \"\"\"\n    variants = []\n    for i, f in enumerate(fns):\n        # If keep_only, use awk to only grab those lines for big speedup.\n        if keep_only:\n            from numpy import dtype\n            import subprocess\n            res = subprocess.check_output(\n                'awk \\'$35 == \"KEEP\"\\' {}'.format(f), shell=True)\n            if res.strip() != '': \n                columns = [u'contig', u'position', u'context', u'ref_allele',\n                           u'alt_allele', u'tumor_name', u'normal_name',\n                           u'score', u'dbsnp_site', u'covered', u'power',\n                           u'tumor_power', u'normal_power', u'total_pairs',\n                           u'improper_pairs', u'map_Q0_reads', u't_lod_fstar',\n                           u'tumor_f', u'contaminant_fraction',\n                           u'contaminant_lod', u't_ref_count', u't_alt_count',\n                           u't_ref_sum', u't_alt_sum', u't_ref_max_mapq',\n                           u't_alt_max_mapq', u't_ins_count', u't_del_count',\n                           u'normal_best_gt', u'init_n_lod', u'n_ref_count',\n                           u'n_alt_count', u'n_ref_sum', u'n_alt_sum',\n                           u'judgement']\n                tdf = pd.DataFrame(\n                    [x.split('\\t') for x in res.strip().split('\\n')],\n                    columns=columns)\n                tdf = tdf.convert_objects(convert_numeric=True)\n            else:\n                tdf = pd.DataFrame(columns=columns)\n            tdf['contig'] = tdf.contig.astype(object)\n\n        else:\n            tdf = pd.read_table(f, index_col=None, header=0, skiprows=1,\n                                low_memory=False, \n                                dtype={'contig':object})\n        for t in remove:\n            tdf = tdf[tdf.dbsnp_site != t]\n        tdf = tdf[tdf.tumor_f > min_tumor_f]\n        tdf = tdf[tdf.t_ref_count + tdf.t_alt_count > min_tumor_cov]\n        tdf = tdf[tdf.n_ref_count + tdf.n_alt_count > min_normal_cov]\n        variants.append(tdf)\n    variants = pd.concat(variants)\n    variants.index = range(variants.shape[0])\n    return variants", "response": "Read muTect output files and return a pandas DataFrame summarizing the variants."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mutect_to_bed(df):\n    s = (df.contig.astype(str) + '\\t' + \n         (df.position - 1).astype(int).astype(str) + '\\t' + \n         df.position.astype(int).astype(str) + '\\t' + \n         df.tumor_name)\n    s = '\\n'.join(s.values) + '\\n'\n    bt = pbt.BedTool(s, from_string=True)\n    return bt", "response": "Convert MuTect results to BedTool object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compile_ip_v4(rule):\n    if isinstance(rule.value, ipranges.Range):\n        return rule\n    return IPV4Rule(ipranges.from_str_v4(rule.value))", "response": "Compile a rule into a ISA - IPV4 rule."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compile_ip_v6(rule):\n    if isinstance(rule.value, ipranges.Range):\n        return rule\n    return IPV6Rule(ipranges.from_str_v6(rule.value))", "response": "Compile a rule into an object representing a valid IPv6 address."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compile_datetime(rule):\n    if isinstance(rule.value, datetime.datetime):\n        return rule\n    try:\n        # Try numeric type\n        return DatetimeRule(datetime.datetime.fromtimestamp(float(rule.value)))\n    except (TypeError, ValueError):\n        pass\n    # Try RFC3339 timestamp string\n    res = TIMESTAMP_RE.match(str(rule.value))\n    if res is not None:\n        year, month, day, hour, minute, second = (int(n or 0) for n in res.group(*range(1, 7)))\n        us_str = (res.group(7) or \"0\")[:6].ljust(6, \"0\")\n        us_int = int(us_str)\n        zonestr = res.group(8)\n        zonespl = (0, 0) if zonestr in ['z', 'Z'] else [int(i) for i in zonestr.split(\":\")]\n        zonediff = datetime.timedelta(minutes = zonespl[0]*60+zonespl[1])\n        return DatetimeRule(datetime.datetime(year, month, day, hour, minute, second, us_int) - zonediff)\n    raise ValueError(\"Wrong datetime format '{}'\".format(rule.value))", "response": "Compile a date rule into a datetime object representing the current node s datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compile_timedelta(rule):\n    if isinstance(rule.value, datetime.timedelta):\n        return rule\n    try:\n        # Try numeric type\n        return TimedeltaRule(datetime.timedelta(seconds = int(rule.value)))\n    except:\n        pass\n    # Try RFC3339 timestamp string\n    res = DURATION_RE.match(str(rule.value))\n    if res is not None:\n        days, hours, minutes, seconds = (int(n or 0) for n in res.group('days','hrs','mins','secs'))\n        return TimedeltaRule(datetime.timedelta(days = days, hours = hours, minutes = minutes, seconds = seconds))\n    raise ValueError(\"Wrong timedelta format '{}'\".format(rule.value))", "response": "Compile a timedelta rule into a TimedeltaRule object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compile_timeoper(rule):\n    if isinstance(rule.value, (datetime.datetime, datetime.timedelta)):\n        return rule\n    if isinstance(rule, NumberRule):\n        return compile_timedelta(rule)\n    if isinstance(rule, ConstantRule):\n        try:\n            return compile_datetime(rule)\n        except ValueError:\n            pass\n        try:\n            return compile_timedelta(rule)\n        except ValueError:\n            pass\n    raise ValueError(\"Wrong time operation constant '{}'\".format(rule))", "response": "Compile a timeoper rule into a sequence of datetime or timedelta objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef traverse(self, traverser, **kwargs):\n        result = self.rule.traverse(traverser, **kwargs)\n        return self.conversion(result)", "response": "This method traverses the whole rule tree and returns the result of the conversion."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_variable_compilation(self, path, compilation_cbk, listclass):\n        self.compilations_variable[path] = {\n            'callback':  compilation_cbk,\n            'listclass': listclass\n        }", "response": "Register given compilation method for given variable on given path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register_function_compilation(self, func, compilation_cbk, listclass):\n        self.compilations_function[func] = {\n            'callback':  compilation_cbk,\n            'listclass': listclass\n        }", "response": "Register given function to be called for given function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompile given operation rule when possible for given compination of operation operands.", "response": "def _compile_operation_rule(self, rule, left, right, result_class):\n        \"\"\"\n        Compile given operation rule, when possible for given compination of\n        operation operands.\n        \"\"\"\n\n        # Make sure variables always have constant with correct datatype on the\n        # opposite side of operation.\n        if isinstance(left, VariableRule) and isinstance(right, (ConstantRule, ListRule)):\n            return self._cor_compile(\n                rule,\n                left,\n                right,\n                result_class,\n                clean_variable(left.value),\n                self.compilations_variable\n            )\n        if isinstance(right, VariableRule) and isinstance(left, (ConstantRule, ListRule)):\n            return self._cor_compile(\n                rule,\n                right,\n                left,\n                result_class,\n                clean_variable(right.value),\n                self.compilations_variable\n            )\n\n        # Make sure functions always have constant with correct datatype on the\n        # opposite side of operation.\n        if isinstance(left, FunctionRule) and isinstance(right, (ConstantRule, ListRule)):\n            return self._cor_compile(\n                rule,\n                left,\n                right,\n                result_class,\n                left.function,\n                self.compilations_function\n            )\n        if isinstance(right, FunctionRule) and isinstance(left, (ConstantRule, ListRule)):\n            return self._cor_compile(\n                rule,\n                right,\n                left,\n                result_class,\n                right.function,\n                self.compilations_function\n            )\n\n        # In all other cases just keep things the way they are.\n        return result_class(rule.operation, left, right)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms compilation of given math operation by actually calculating given math expression.", "response": "def _calculate_operation_math(self, rule, left, right):\n        \"\"\"\n        Perform compilation of given math operation by actually calculating given\n        math expression.\n        \"\"\"\n\n        # Attempt to keep integer data type for the result, when possible.\n        if isinstance(left, IntegerRule) and isinstance(right, IntegerRule):\n            result = self.evaluate_binop_math(rule.operation, left.value, right.value)\n            if isinstance(result, list):\n                return ListRule([IntegerRule(r) for r in result])\n            return IntegerRule(result)\n\n        # Otherwise the result is float.\n        if isinstance(left, NumberRule) and isinstance(right, NumberRule):\n            result = self.evaluate_binop_math(rule.operation, left.value, right.value)\n            if isinstance(result, list):\n                return ListRule([FloatRule(r) for r in result])\n            return FloatRule(result)\n\n        # This point should never be reached.\n        raise Exception()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a LogicalBinOpRule for the given rule.", "response": "def binary_operation_logical(self, rule, left, right, **kwargs):\n        \"\"\"\n        Implementation of :py:func:`pynspect.traversers.RuleTreeTraverser.binary_operation_logical` interface.\n        \"\"\"\n        return LogicalBinOpRule(rule.operation, left, right)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef binary_operation_comparison(self, rule, left, right, **kwargs):\n        return self._compile_operation_rule(\n            rule,\n            left,\n            right,\n            ComparisonBinOpRule\n        )", "response": "Compile the binary operation comparison rule."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef binary_operation_math(self, rule, left, right, **kwargs):\n        if isinstance(left, NumberRule) and isinstance(right, NumberRule):\n            return self._calculate_operation_math(rule, left, right)\n        return self._compile_operation_rule(\n            rule,\n            left,\n            right,\n            MathBinOpRule\n        )", "response": "Implementation of pynspect. traversers. RuleTreeTraverser. binary_operation_math."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a database from a directory.", "response": "def get_db(directory, engine=None):\n    \"\"\"Get a database\n\n    :param directory: The root data directory\n    :param engine: a pre-created SQLAlchemy engine (default: in-memory SQLite)\n    \"\"\"\n    if engine is None:\n        engine = create_engine('sqlite://')\n    tables.metadata.create_all(engine)\n    Session = sessionmaker(bind=engine)\n    db = Session()\n    if directory is not None:\n        load_from_directory(db, directory)\n    return db"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_from_dict(db, data, metadata):\n    # The ORM overhead is too high for this kind of bulk load,\n    # so drop down to SQLAlchemy Core.\n    # This tries to do minimize the number of SQL commands by loading entire\n    # tables at once\n\n    if metadata['version'] != 2:\n        raise ValueError('Can only load version 2')\n\n    try:\n        bind = db.get_bind(tables.Event)\n    except (ValueError, AttributeError):\n        pass\n    else:\n        if bind.dialect.name == 'sqlite':\n            db.execute('PRAGMA foreign_keys = ON')\n\n    with bulk_inserter(db) as insert:\n\n        # Load speakers\n\n        speaker_slugs = set()\n\n        for series_slug, series in data['series'].items():\n            for event_slug, event in series['events'].items():\n                for talk in event.get('talks'):\n                    for speaker in talk.get('speakers', ()):\n                        if speaker not in speaker_slugs:\n                            speaker_slugs.add(speaker)\n                            insert(tables.Speaker, {\n                                'slug': speaker,\n                                'name': speaker,\n                            })\n\n        venue_ids = {}\n\n        # Load cities, and their venues\n\n        for city_slug, city in data['cities'].items():\n            city_data = city['city']\n            insert(tables.City, {\n                'slug': city_slug,\n                'name': city_data['name'],\n                'latitude': city_data['location']['latitude'],\n                'longitude': city_data['location']['longitude'],\n                '_source': city_data['_source'],\n            })\n\n            for venue_slug, venue in city.get('venues', {}).items():\n                venue_ids[city_slug, venue_slug] = insert(tables.Venue, {\n                    'city_slug': city_slug,\n                    'slug': venue_slug,\n                    'name': venue['name'],\n                    'address': venue.get('address'),\n                    'latitude': venue['location']['latitude'],\n                    'longitude': venue['location']['longitude'],\n                    'notes': venue.get('notes'),\n                })\n\n\n        # Load series, their events, and everything underneath\n\n        for series_slug, series_dir in data['series'].items():\n\n            series = series_dir['series']\n            recurrence = series.get('recurrence')\n            if recurrence:\n                rrule_str = recurrence['rrule']\n                rrule.rrulestr(rrule_str)  # check rrule syntax\n                recurrence_attrs = {\n                    'recurrence_rule': rrule_str,\n                    'recurrence_scheme': recurrence['scheme'],\n                    'recurrence_description_cs': recurrence['description']['cs'],\n                    'recurrence_description_en': recurrence['description']['en'],\n                }\n            else:\n                recurrence_attrs = {\n                    'recurrence_rule': None,\n                    'recurrence_scheme': None,\n                    'recurrence_description_cs': None,\n                    'recurrence_description_en': None,\n                }\n            insert(tables.Series, {\n                'slug': series_slug,\n                'name': series['name'],\n                'home_city_slug': series.get('city'),\n                'description_cs': series['description']['cs'],\n                'description_en': series['description']['en'],\n                'organizer_info': json.dumps(series.get('organizer-info', ())),\n                **recurrence_attrs,\n            })\n\n            for event_slug, event in series_dir['events'].items():\n                venue_slug = event.get('venue')\n                city_slug = event['city']\n                if venue_slug:\n                    venue_id = venue_ids[city_slug, venue_slug]\n                else:\n                    venue_id = None\n\n                start = make_full_datetime(event['start'])\n                end = event.get('end')\n                if end is None:\n                    end = start.replace(hour=23, minute=59, second=59)\n                event_id = insert(tables.Event, {\n                    'name': event['name'],\n                    'number': event.get('number'),\n                    'topic': event.get('topic'),\n                    'description': event.get('description'),\n                    'date': start.date(),\n                    'start_time': start.time(),\n                    'end': end,\n                    'all_day': event.get('all_day', False),\n                    'series_slug': series_slug,\n                    'city_slug': city_slug,\n                    'venue_id': venue_id,\n                    '_source': event['_source']\n                })\n\n                for i, talk in enumerate(event.get('talks', ())):\n                    talk_id = insert(tables.Talk, {\n                        'event_id': event_id,\n                        'index': i,\n                        'title': talk['title'],\n                        'description': talk.get('description'),\n                        'is_lightning': talk.get('lightning', False),\n                    })\n\n                    for i, speaker in enumerate(talk.get('speakers', ())):\n                        assert speaker in speaker_slugs\n                        insert(tables.TalkSpeaker, {\n                            'talk_id': talk_id,\n                            'index': i,\n                            'speaker_slug': speaker,\n                        })\n\n                    for i, link in enumerate([\n                            *({'talk': u} for u in talk.get('urls', ())),\n                            *talk.get('coverage', {})]):\n                        for kind, url in link.items():\n                            insert(tables.TalkLink, {\n                                'talk_id': talk_id,\n                                'index': i,\n                                'url': url,\n                                'kind': kind,\n                            })\n\n                for i, url in enumerate(event.get('urls', ())):\n                    insert(tables.EventLink, {\n                        'event_id': event_id,\n                        'index': i,\n                        'url': url,\n                    })", "response": "Load data from a dict into a database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates listening sockets bound to the given port and address.", "response": "def bind_sockets(port, address=None, family=socket.AF_UNSPEC,\n                 backlog=_DEFAULT_BACKLOG, flags=None, reuse_port=False):\n    \"\"\"Creates listening sockets bound to the given port and address.\n\n    Returns a list of socket objects (multiple sockets are returned if\n    the given address maps to multiple IP addresses, which is most common\n    for mixed IPv4 and IPv6 use).\n\n    Address may be either an IP address or hostname.  If it's a hostname,\n    the server will listen on all IP addresses associated with the\n    name.  Address may be an empty string or None to listen on all\n    available interfaces.  Family may be set to either `socket.AF_INET`\n    or `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise\n    both will be used if available.\n\n    The ``backlog`` argument has the same meaning as for\n    `socket.listen() <socket.socket.listen>`.\n\n    ``flags`` is a bitmask of AI_* flags to `~socket.getaddrinfo`, like\n    ``socket.AI_PASSIVE | socket.AI_NUMERICHOST``.\n\n    ``reuse_port`` option sets ``SO_REUSEPORT`` option for every socket\n    in the list. If your platform doesn't support this option ValueError will\n    be raised.\n    \"\"\"\n    if reuse_port and not hasattr(socket, 'SO_REUSEPORT'):\n        raise ValueError('the platform does not support SO_REUSEPORT')\n\n    sockets = []\n    if not address:\n        address = None\n    if not socket.has_ipv6 and family == socket.AF_UNSPEC:\n        # Python can be compiled with --disable-ipv6, which causes\n        # operations on AF_INET6 sockets to fail, but does not\n        # automatically exclude those results from getaddrinfo\n        # results.\n        # http://bugs.python.org/issue16208\n        family = socket.AF_INET\n    if flags is None:\n        flags = socket.AI_PASSIVE\n    bound_port = None\n    for res in set(socket.getaddrinfo(address, port, family, socket.SOCK_STREAM,\n                                      0, flags)):\n        af, socktype, proto, canonname, sockaddr = res\n        if (sys.platform == 'darwin' and address == 'localhost' and\n                af == socket.AF_INET6 and sockaddr[3] != 0):\n            # Mac OS X includes a link-local address fe80::1%lo0 in the\n            # getaddrinfo results for 'localhost'.  However, the firewall\n            # doesn't understand that this is a local address and will\n            # prompt for access (often repeatedly, due to an apparent\n            # bug in its ability to remember granting access to an\n            # application). Skip these addresses.\n            continue\n        try:\n            sock = socket.socket(af, socktype, proto)\n        except socket.error as e:\n            if e.errno == errno.EAFNOSUPPORT:\n                continue\n            raise\n        if os.name != 'nt':\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        if reuse_port:\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)\n        if af == socket.AF_INET6:\n            # On linux, ipv6 sockets accept ipv4 too by default,\n            # but this makes it impossible to bind to both\n            # 0.0.0.0 in ipv4 and :: in ipv6.  On other systems,\n            # separate sockets *must* be used to listen for both ipv4\n            # and ipv6.  For consistency, always disable ipv4 on our\n            # ipv6 sockets and use a separate ipv4 socket when needed.\n            #\n            # Python 2.x on windows doesn't have IPPROTO_IPV6.\n            if hasattr(socket, \"IPPROTO_IPV6\"):\n                sock.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_V6ONLY, 1)\n\n        # automatic port allocation with port=None\n        # should bind on the same port on IPv4 and IPv6\n        host, requested_port = sockaddr[:2]\n        if requested_port == 0 and bound_port is not None:\n            sockaddr = tuple([host, bound_port] + list(sockaddr[2:]))\n\n        sock.setblocking(0)\n        sock.bind(sockaddr)\n        bound_port = sock.getsockname()[1]\n        sock.listen(backlog)\n        sockets.append(sock)\n    return sockets"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a listening unix socket.", "response": "def bind_unix_socket(file_, mode=0o600, backlog=_DEFAULT_BACKLOG):\n    \"\"\"Creates a listening unix socket.\n\n    If a socket with the given name already exists, it will be deleted.\n    If any other file with that name exists, an exception will be\n    raised.\n\n    Returns a socket object (not a list of socket objects like\n    `bind_sockets`)\n    \"\"\"\n    sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n    sock.setblocking(0)\n    try:\n        st = os.stat(file_)\n    except OSError as err:\n        if err.errno != errno.ENOENT:\n            raise\n    else:\n        if stat.S_ISSOCK(st.st_mode):\n            os.remove(file_)\n        else:\n            raise ValueError('File %s exists and is not a socket', file_)\n    sock.bind(file_)\n    os.chmod(file_, mode)\n    sock.listen(backlog)\n    return sock"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a new random hash for the first time step.", "response": "def firsthash(frame, removedupes=False):\n    '''\n    Hashes the first time step. Only will work as long as\n    the hash can fit in a uint64.\n\n    Parameters:\n    -----------\n      frame : first frame.\n\n    Keywords:\n    ---------\n      removedups: specify duplicates for the given frame.\n    \n    Returns a dictionary of everything needed\n    to generate hashes from the genhash function.\n    \n    '''\n    #hashes must have i8 available\n    #overwise, we'll have overflow\n    def avgdiff(d):\n        d=np.sort(d);\n        d = d[1:] - d[:-1]\n        ret = np.average(d[np.nonzero(d)]);\n        if np.isnan(ret):\n            return 1.0;\n        return ret;\n    def hasextent(l,eps=1e-10):\n        #will I one day make pic sims on the pm scale??\n        dim = frame['data'][l];\n        return np.abs(dim.max()-dim.min()) > eps;\n    fields = list(frame['data'].dtype.names);\n    dims = [ i for i in ['xi','yi','zi']\n             if i in fields and hasextent(i) ];\n    ip = np.array([ frame['data'][l]\n                    for l in dims ]).T;\n    avgdiffs = np.array([avgdiff(a) for a in ip.T]);\n    mins  = ip.min(axis=0);\n    ips = (((ip - mins)/avgdiffs).round().astype('uint64'))\n    pws  = np.floor(np.log10(ips.max(axis=0))).astype('uint64')+1\n    pws = list(pws);\n    pw = [0]+[ ipw+jpw for ipw,jpw in\n               zip([0]+pws[:-1],pws[:-1]) ];\n    pw = 10**np.array(pw);#.astype('int64');\n    #the dictionary used for hashing\n    d=dict(dims=dims, mins=mins, avgdiffs=avgdiffs, pw=pw);\n    hashes = genhash(frame,removedupes=False,**d);\n    if removedupes:\n        #consider if the negation of this is faster for genhash\n        uni,counts = np.unique(hashes,return_counts=True);\n        d['dupes']=uni[counts>1]\n        dupei = np.in1d(hashes, d['dupes']);\n        hashes[dupei] = -1;\n        d['removedupes']=True;\n    return hashes,d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate the hashes for a given frame.", "response": "def genhash(frame,**kw):\n    '''\n    Generate the hashes for the given frame for a specification\n    given in the dictionary d returned from firsthash.\n\n    Parameters:\n    -----------\n      frame :  frame to hash.\n\n    Keywords:\n    ---------\n      d         : hash specification generated from firsthash.\n      new       : use new hashing, which isn't really hashing.\n      removedups: put -1 in duplicates,\n      dims      : specify dims. Supercedes the setting in `d'.\n      dupes     : array of hashes known to be dupes.\n      ftype     : type of floats. defaults to 'f'.\n\n    -- old keywords from old hashing --\n      mins      : minima of each axis\n      avgdifs   : average differences\n      pw        : powers of each axis\n\n    Returns an array of the shape of the frames with hashes.\n    '''\n    getkw = mk_getkw(kw,genhash_defaults,prefer_passed=True);\n    dims = getkw('dims');\n    dupes= getkw('dupes');\n    if not getkw('new'):\n        ip = np.array([frame['data'][l] for l in dims]).T;\n        scaled = ((ip - getkw('mins'))/getkw('avgdiffs')).round().astype('int64');\n        hashes = (scaled*getkw('pw')).sum(axis=1).astype('int64');\n    else:\n        hashes = np.array([\n            struct.pack('{}{}'.format(len(dims),getkw('ftype')), *[p[l] for l in dims])\n            for p in frame['data']]);\n    if getkw('removedupes'):\n        #marking duplicated particles\n        if not getkw('dupes'):\n            hashes =  np.unique(hashes);\n        else:\n            dupei = np.in1d(hashes, getkw('dupes'));\n            hashes[dupei] = -1\n    return hashes;"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addhash(frame,**kw):\n    '''\n    helper function to add hashes to the given frame\n    given in the dictionary d returned from firsthash.\n\n    Parameters:\n    -----------\n      frame :  frame to hash.\n\n    Keywords:\n    ---------\n      same as genhash\n    \n    Returns frame with added hashes, although it will be added in\n    place.\n    '''\n    hashes = genhash(frame,**kw);\n    frame['data'] = rfn.rec_append_fields(\n        frame['data'],'hash',hashes);\n    return frame;", "response": "helper function to add hashes to the given frame"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sortframe(frame):\n    '''\n    sorts particles for a frame\n    '''\n    d = frame['data'];\n    sortedargs = np.lexsort([d['xi'],d['yi'],d['zi']])\n    d = d[sortedargs];\n    frame['data']=d;\n    return frame;", "response": "Sort a frame by the particles in the sequence of x y zi."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads and addhash each frame.", "response": "def read_and_hash(fname, **kw):\n    '''\n    Read and and addhash each frame.\n    '''\n    return [addhash(frame, **kw) for frame in read(fname, **kw)];"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nobtaining good hashes from a. p4 file with the dict hashd and a function that returns good hashes.", "response": "def filter_hashes_from_file(fname, f, **kw):\n    '''\n    Obtain good hashes from a .p4 file with the dict hashd and a\n    function that returns good hashes. Any keywords will be\n    sent to read_and_hash.\n\n    Parameters:\n    -----------\n\n    fname -- filename of file.\n    f     -- function that returns a list of good hashes.\n    '''\n    return np.concatenate([\n        frame['data']['hash'][f(frame)]\n        for frame in read_and_hash(fname, **kw)\n    ]);"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreplace the string re_text with replace_str.", "response": "def replace(self, re_text, replace_str, text):\n        \"\"\"\n        \u6b63\u5219\u8868\u8fbe\u5f0f\u66ff\u6362\n        :param re_text: \u6b63\u5219\u8868\u8fbe\u5f0f\n        :param replace_str: \u66ff\u6362\u5b57\u7b26\u4e32\n        :param text: \u641c\u7d22\u6587\u6863\n        :return: \u66ff\u6362\u540e\u7684\u5b57\u7b26\u4e32\n        \"\"\"\n        return re.sub(re_text, replace_str, text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_match(self, step) -> list:\n        args = []\n        match = super().check_match(step)\n        if match is None:\n            return None\n\n        for arg in match:\n            args.append(model.Argument.from_argument(arg))\n\n        for arg in self.context_params:\n            args.append(model.Argument(0, 0, \"\", None, name=arg, implicit=True))\n\n        return args", "response": "Like matchers. CFParseMatcher. check_match but\n            adds implicit parameters from the context_params list"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the goat step string to CFParse String", "response": "def convert(self, pattern: str) -> str:\n        \"\"\"Convert the goat step string to CFParse String\"\"\"\n        parameters = OrderedDict()\n        for parameter in self.signature.parameters.values():\n            annotation = self.convert_type_to_parse_type(parameter)\n            parameters[parameter.name] = \"{%s:%s}\" % (parameter.name, annotation)\n\n        formatter = GoatFormatter()\n\n        # We have to use vformat here to ensure that kwargs will be OrderedDict\n        values = parameters.values()\n        parameter_list = list(values)\n        converted_pattern = formatter.vformat(pattern, parameter_list, parameters)\n\n        self.context_params = formatter.unused_args\n        return converted_pattern"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef xml_to_json(root, tag_prefix=None, on_tag={}):\n    '''\n    Parses a XML element to JSON format.\n\n    This is a relatively generic function parsing a XML element\n    to JSON format. It does not guarantee any specific formal\n    behaviour but is empirically known to \"work well\" with respect\n    to the author's needs. External verification of the returned\n    results by the user is therefore instrumental.\n\n    For bigger XML elements the whole procedure may take a while,\n    so the philosophy should be to save the laboriously mapped\n    JSON data structure to a file once you have it. This of course\n    also means that this functions is probably of little value\n    when you have to constantly JSONify big XMLs. In summary,\n    this function is mostly useful for one-time parsing of XML to\n    JSON for subsequent use of the resulting JSON data instead of\n    the XML-formated data.\n\n    Args:\n        root: A XML element\n        tag_prefix: A tag prefix which will be cut from the keys\n        on_tag: User-defined parsing for elements identified by tag\n\n    Returns:\n        A Python data structure corresponding to the JSON mapping\n        of the supplied XML element\n    '''\n\n    def get_key(tag):\n        if tag_prefix is not None:\n            return tag.split(tag_prefix)[1]\n        return tag\n\n    def parse_element(elmt):\n        key = get_key(elmt.tag)\n\n        if key in on_tag:\n            return on_tag[key](elmt)\n\n        items = dict(elmt.items())\n        if len(elmt) == 0:\n            if items:\n                return { **items, **{key : elmt.text} }\n            else:\n                return elmt.text\n        else:\n            tags = {child.tag for child in elmt}\n            max_children = max({len(child) for child in elmt})\n            if len(tags) == 1:\n                value_list = [parse_element(child) for child in elmt]\n                if items:\n                    return { **items, **{key : value_list} }\n                else:\n                    return value_list\n            elif len(tags) > 1:\n                tag2children = {tag: [] for tag in tags}\n                for child in elmt:\n                    tag2children[child.tag].append(child)\n\n                if max_children == 0:\n                    value_dict = {get_key(tag) : [child.text for child in children] if len(children) > 1\n                                                 else children[0].text\n                                                 for tag, children in tag2children.items()}\n                else:\n                    value_dict = {get_key(tag) : [parse_element(child) for child in children] if len(children) > 1\n                                                 else parse_element(children[0])\n                                                 for tag, children in tag2children.items()}\n                if items:\n                    return { **items, **value_dict }\n                else:\n                    return value_dict\n\n    # ---\n    return parse_element(root)", "response": "Parses a XML element to JSON format."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntest if the output device can handle the desired strings.", "response": "def beststr(*strings):\n    \"\"\" Test if the output device can handle the desired strings. The options\n    should be sorted by preference. Eg. beststr(unicode, ascii). \"\"\"\n    for x in strings:\n        try:\n            x.encode(sys.stdout.encoding)\n        except UnicodeEncodeError:\n            pass\n        else:\n            return x\n    raise ValueError('No valid strings found')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds slice to the list if it doesn t already exist.", "response": "def _add_slice(seq, slc):\n    \"\"\" Our textwrap routine deals in slices.  This function will concat\n    contiguous slices as an optimization so lookup performance is faster.\n    It expects a sequence (probably a list) to add slice to or will extend\n    the last slice of the sequence if it ends where the new slice begins. \"\"\"\n    if seq and seq[-1].stop == slc.start:\n        seq[-1] = slice(seq[-1].start, slc.stop)\n    else:\n        seq.append(slc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _textwrap_slices(text, width, strip_leading_indent=False):\n    if not isinstance(text, str):\n        raise TypeError(\"Expected `str` type\")\n    chunks = (x for x in _textwrap_word_break.split(text) if x)\n    remaining = width\n    buf = []\n    lines = [buf]\n    whitespace = []\n    whitespace_len = 0\n    pos = 0\n    try:\n        chunk = next(chunks)\n    except StopIteration:\n        chunk = ''\n    if not strip_leading_indent and is_whitespace(chunk):\n        # Add leading indent for first line, but only up to one lines worth.\n        chunk_len = len(chunk)\n        if chunk_len >= width:\n            _add_slice(buf, slice(0, width))\n            buf = []\n            lines.append(buf)\n        else:\n            _add_slice(buf, slice(0, chunk_len))\n            remaining -= chunk_len\n        pos = chunk_len\n        try:\n            chunk = next(chunks)\n        except StopIteration:\n            chunk = ''\n    while True:\n        avail_len = remaining - whitespace_len\n        chunk_len = len(chunk)\n        if chunk == '\\n':\n            buf = []\n            lines.append(buf)\n            whitespace = []\n            whitespace_len = 0\n            remaining = width\n        elif is_whitespace(chunk):\n            if buf:\n                _add_slice(whitespace, slice(pos, pos + chunk_len))\n                whitespace_len += chunk_len\n        elif len(chunk) > avail_len:\n            if not buf:\n                # Must hard split the chunk.\n                for x in whitespace:\n                    _add_slice(buf, x)\n                _add_slice(buf, slice(pos, pos + avail_len))\n                chunk = chunk[avail_len:]\n                pos += avail_len\n            # Bump to next line without fetching the next chunk.\n            buf = []\n            lines.append(buf)\n            whitespace = []\n            whitespace_len = 0\n            remaining = width\n            continue\n        else:\n            if buf:\n                remaining -= whitespace_len\n                for x in whitespace:\n                    _add_slice(buf, x)\n            whitespace = []\n            whitespace_len = 0\n            _add_slice(buf, slice(pos, pos + chunk_len))\n            remaining -= chunk_len\n        pos += chunk_len\n        try:\n            chunk = next(chunks)\n        except StopIteration:\n            break\n    return lines", "response": "A utility function that returns a list of slices that can be used to extract the text from the text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef vtmlrender(vtmarkup, plain=None, strict=False, vtmlparser=VTMLParser()):\n    if isinstance(vtmarkup, VTMLBuffer):\n        return vtmarkup.plain() if plain else vtmarkup\n    try:\n        vtmlparser.feed(vtmarkup)\n        vtmlparser.close()\n    except:\n        if strict:\n            raise\n        buf = VTMLBuffer()\n        buf.append_str(str(vtmarkup))\n        return buf\n    else:\n        buf = vtmlparser.getvalue()\n        return buf.plain() if plain else buf\n    finally:\n        vtmlparser.reset()", "response": "Look for vt100 markup and render vt opcodes into a VTMLBuffer."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfollow normal print method signature but look for vt100 codes for richer output.", "response": "def vtmlprint(*values, plain=None, strict=None, **options):\n    \"\"\" Follow normal print() signature but look for vt100 codes for richer\n    output. \"\"\"\n    print(*[vtmlrender(x, plain=plain, strict=strict) for x in values],\n          **options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfeeds the data into the state machine.", "response": "def feed(self, data):\n        \"\"\" We need to prevent insertion of some special HTML characters\n        (entity refs and maybe more).  It's hard to prevent the state machine\n        from blowing up with them in the data, so we temporarily replacing\n        them with a reserved unicode value based on the PAU private space. \"\"\"\n        assert not self.closed\n        for mark, special in self.escape_map:\n            assert mark not in data\n            data = data.replace(special, mark)\n        super().feed(data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting any constraints or keys across one or more columns.", "response": "def get_constraints(self, cursor, table_name):\n        \"\"\"\n        Retrieves any constraints or keys (unique, pk, fk, check, index) across one or more columns.\n        \"\"\"\n        constraints = {}\n        # Loop over the key table, collecting things as constraints\n        # This will get PKs, FKs, and uniques, but not CHECK\n        cursor.execute(\"\"\"\n            SELECT\n                kc.constraint_name,\n                kc.column_name,\n                c.constraint_type,\n                array(SELECT table_name::text || '.' || column_name::text\n                      FROM information_schema.constraint_column_usage\n                      WHERE constraint_name = kc.constraint_name\n                        AND constraint_schema = kc.constraint_schema)\n            FROM information_schema.key_column_usage AS kc\n            JOIN information_schema.table_constraints AS c ON\n                kc.table_schema = c.table_schema AND\n                kc.table_name = c.table_name AND\n                kc.constraint_name = c.constraint_name\n            WHERE\n                kc.table_schema = %s AND\n                kc.table_name = %s\n            ORDER BY kc.ordinal_position ASC\n        \"\"\", [self.connection.schema, table_name])\n        for constraint, column, kind, used_cols in cursor.fetchall():\n            # If we're the first column, make the record\n            if constraint not in constraints:\n                constraints[constraint] = {\n                    \"columns\": [],\n                    \"primary_key\": kind.lower() == \"primary key\",\n                    \"unique\": kind.lower() in [\"primary key\", \"unique\"],\n                    \"foreign_key\": tuple(used_cols[0].split(\".\", 1)) if kind.lower() == \"foreign key\" else None,\n                    \"check\": False,\n                    \"index\": False,\n                }\n            # Record the details\n            constraints[constraint]['columns'].append(column)\n        # Now get CHECK constraint columns\n        cursor.execute(\"\"\"\n            SELECT kc.constraint_name, kc.column_name\n            FROM information_schema.constraint_column_usage AS kc\n            JOIN information_schema.table_constraints AS c ON\n                kc.table_schema = c.table_schema AND\n                kc.table_name = c.table_name AND\n                kc.constraint_name = c.constraint_name\n            WHERE\n                c.constraint_type = 'CHECK' AND\n                kc.table_schema = %s AND\n                kc.table_name = %s\n        \"\"\", [self.connection.schema, table_name])\n        for constraint, column in cursor.fetchall():\n            # If we're the first column, make the record\n            if constraint not in constraints:\n                constraints[constraint] = {\n                    \"columns\": [],\n                    \"primary_key\": False,\n                    \"unique\": False,\n                    \"foreign_key\": None,\n                    \"check\": True,\n                    \"index\": False,\n                }\n            # Record the details\n            constraints[constraint]['columns'].append(column)\n        # Now get indexes\n        cursor.execute(\"\"\"\n            SELECT\n                c2.relname,\n                ARRAY(\n                    SELECT (SELECT attname FROM pg_catalog.pg_attribute WHERE attnum = i AND attrelid = c.oid)\n                    FROM unnest(idx.indkey) i\n                ),\n                idx.indisunique,\n                idx.indisprimary\n            FROM pg_catalog.pg_class c, pg_catalog.pg_class c2,\n                pg_catalog.pg_index idx, pg_catalog.pg_namespace n\n            WHERE c.oid = idx.indrelid\n                AND idx.indexrelid = c2.oid\n                AND c.relnamespace = n.oid\n                AND n.nspname = %s\n                AND c.relname = %s\n        \"\"\", [self.connection.schema, table_name])\n        for index, columns, unique, primary in cursor.fetchall():\n            if index not in constraints:\n                constraints[index] = {\n                    \"columns\": list(columns),\n                    \"primary_key\": primary,\n                    \"unique\": unique,\n                    \"foreign_key\": None,\n                    \"check\": False,\n                    \"index\": True,\n                }\n        return constraints"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean_text(value, topic=False):\n    for x in PROFANITY_REPLACEMENTS:\n        value = value.replace(x[0], x[1])\n\n    for bbset in BBCODE_REPLACEMENTS:\n        p = re.compile(bbset[0], re.DOTALL)\n        value = p.sub(bbset[1], value)\n\n    bleached = bleach.clean(value, tags=ALLOWED_TAGS, attributes=ALLOWED_ATTRIBUTES, strip=True)\n\n    # We want to retain markdown quotes and we'll be running bleach again in format_post.\n    bleached = bleached.replace('&gt;', '>').replace('&amp;', '&')\n    return bleached", "response": "Cleans the given text into a single HTML page."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if value looks like an email address.", "response": "def is_email_simple(value):\n        \"\"\"Return True if value looks like an email address.\"\"\"\n        # An @ must be in the middle of the value.\n        if '@' not in value or value.startswith('@') or value.endswith('@'):\n            return False\n        try:\n            p1, p2 = value.split('@')\n        except ValueError:\n            # value contains more than one @.\n            return False\n        # Dot must be in p2 (e.g. example.com)\n        if '.' not in p2 or p2.startswith('.'):\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts links in text to HTML.", "response": "def convert_links(text, trim_url_limit=None, nofollow=False, autoescape=False):\n    \"\"\"\n    Finds URLs in text and attempts to handle correctly.\n    Heavily based on django.utils.html.urlize\n    With the additions of attempting to embed media links, particularly images.\n\n    Works on http://, https://, www. links, and also on links ending in one of\n    the original seven gTLDs (.com, .edu, .gov, .int, .mil, .net, and .org).\n\n    Links can have trailing punctuation (periods, commas, close-parens) and\n    leading punctuation (opening parens) and it'll still do the right thing.\n    \n    TO-DO: refactor to better leverage existing django.utils.html\n\n    \"\"\"\n\n    safe_input = isinstance(text, SafeData)\n    words = word_split_re.split(force_text(text))\n    for i, word in enumerate(words):\n        if '.' in word or ':' in word:\n            # Deal with punctuation.\n            lead, middle, trail = '', word, ''\n            stripped = middle.rstrip(TRAILING_PUNCTUATION_CHARS)\n            if middle != stripped:\n                trail = middle[len(stripped):] + trail\n                middle = stripped\n            for opening, closing in WRAPPING_PUNCTUATION:\n                if middle.startswith(opening):\n                    middle = middle[len(opening):]\n                    lead = lead + opening\n                # Keep parentheses at the end only if they're balanced.\n                if (middle.endswith(closing)\n                    and middle.count(closing) == middle.count(opening) + 1):\n                    middle = middle[:-len(closing)]\n                    trail = closing + trail\n\n            # Make URL we want to point to.\n            url = None\n            if simple_url_re.match(middle):\n                url = smart_urlquote(middle)\n            elif simple_url_2_re.match(middle):\n                url = smart_urlquote('http://%s' % middle)\n            elif ':' not in middle and is_email_simple(middle):\n                local, domain = middle.rsplit('@', 1)\n                try:\n                    domain = domain.encode('idna').decode('ascii')\n                except UnicodeError:\n                    continue\n            if url:\n                u = url.lower()\n                if autoescape and not safe_input:\n                    lead, trail = escape(lead), escape(trail)\n                    url = escape(url)\n\n                # Photos\n                if u.endswith('.jpg') or u.endswith('.gif') or u.endswith('.png'):\n                    middle = '<img src=\"%s\">' % url\n\n                # Youtube\n                #'https://www.youtube.com/watch?v=gkqXgaUuxZg'\n                elif 'youtube.com/watch' in url:\n                    parsed = urlparse.urlsplit(url)\n                    query  = urlparse.parse_qs(parsed.query)\n                    token  = query.get('v')\n                    if token and len(token) > 0:\n                        middle = '<iframe src=\"http://www.youtube.com/embed/%s\" height=\"320\" width=\"100%%\"></iframe>' % token[0]\n                    else:\n                        middle = url\n                elif 'youtu.be/' in url:\n                    try:\n                        token = url.rsplit('/', 1)[1]\n                        middle = '<iframe src=\"http://www.youtube.com/embed/%s\" height=\"320\" width=\"100%%\"></iframe>' % token\n                    except IndexError:\n                        middle = six.u(url)\n\n                words[i] = mark_safe('%s%s%s' % (lead, middle, trail))\n            else:\n                if safe_input:\n                    words[i] = mark_safe(word)\n                elif autoescape:\n                    words[i] = escape(word)\n        elif safe_input:\n            words[i] = mark_safe(word)\n        elif autoescape:\n            words[i] = escape(word)\n    return ''.join(words)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_text(value):\n    # convert media links\n    value = convert_links(value)\n    value = urlizetrunc(value, 30)\n\n    for x in EMOTICON_REPLACEMENTS:\n        value = value.replace(x[0], '<span class=\"emoticon-{}\"></span>'.format(x[1]))\n\n    markedup = markdown.markdown(value).replace('</p>\\n<p>', '</p><p>')\n    with_linebreaks = markedup.replace('\\n* ', '<br>* ')\n    bleached = bleach.clean(with_linebreaks, tags=ALLOWED_TAGS, attributes=ALLOWED_ATTRIBUTES, strip=True)\n    return mark_safe(bleached)", "response": "Takes cleaned text and creates HTML - formatted web - friendly version of it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef loadSettings(self):\n        self.settings.beginGroup('rampviewer')\n        geometry = self.settings.value('geometry').toByteArray()\n        self.settings.endGroup()\n\n        self.restoreGeometry(geometry)", "response": "Load window state from self. settings"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef saveSettings(self):\n        self.settings.beginGroup('rampviewer')\n        self.settings.setValue('geometry', self.saveGeometry())\n        self.settings.endGroup()", "response": "Save window state to self. settings."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap for multiprocessing. Pool. map", "response": "def pool_process(func, iterable, cpus=cpu_count(), return_vals=False, cpu_reduction=0, progress_bar=False):\n    \"\"\"\n    Multiprocessing helper function for performing looped operation using multiple processors.\n\n    :param func: Function to call\n    :param iterable: Iterable object to perform each function on\n    :param cpus: Number of cpu cores, defaults to system's cpu count\n    :param return_vals: Bool, returns output values when True\n    :param cpu_reduction: Number of cpu core's to not use\n    :param progress_bar: Display text based progress bar\n    :return:\n    \"\"\"\n    with Pool(cpus - abs(cpu_reduction)) as pool:\n        # Return values returned by 'func'\n        if return_vals:\n            # Show progress bar\n            if progress_bar:\n                vals = [v for v in tqdm(pool.imap_unordered(func, iterable), total=len(iterable))]\n\n            # No progress bar\n            else:\n                vals = pool.map(func, iterable)\n\n            # Close pool and return values\n            pool.close()\n            # pool.join()\n            return vals\n\n        # Don't capture values returned by 'func'\n        else:\n            pool.map(func, iterable)\n            pool.close()\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef map(self):\n        with Pool(self.cpu_count) as pool:\n            pool.map(self._func, self._iterable)\n            pool.close()\n        return True", "response": "Perform a function on every item in an iterable."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform a function on every item and return a list of yield values.", "response": "def map_return(self):\n        \"\"\"Perform a function on every item and return a list of yield values.\"\"\"\n        with Pool(self.cpu_count) as pool:\n            vals = pool.map(self._func, self._iterable)\n            pool.close()\n            return vals"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform a function on every item while displaying a progress bar.", "response": "def map_tqdm(self):\n        \"\"\"\n        Perform a function on every item while displaying a progress bar.\n\n        :return: A list of yielded values\n        \"\"\"\n        with Pool(self.cpu_count) as pool:\n            vals = [v for v in tqdm(pool.imap_unordered(self._func, self._iterable), total=len(self._iterable))]\n            pool.close()\n            return vals"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clone(self, d):\n        return Desinence(d.grq(), d.morphoNum(), d.numRad(), self)", "response": "Clones a Desinence object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsplits the given content into a list of items that were separated by newlines.", "response": "def split_by_line(content):\n    \"\"\"Split the given content into a list of items by newline.\n\n    Both \\r\\n and \\n are supported. This is done since it seems\n    that TTY devices on POSIX systems use \\r\\n for newlines in\n    some instances.\n\n    If the given content is an empty string or a string of only\n    whitespace, an empty list will be returned. If the given\n    content does not contain any newlines, it will be returned\n    as the only element in a single item list.\n\n    Leading and trailing whitespace is remove from all elements\n    returned.\n\n    :param str content: Content to split by newlines\n    :return: List of items that were separated by newlines.\n    :rtype: list\n    \"\"\"\n    # Make sure we don't end up splitting a string with\n    # just a single trailing \\n or \\r\\n into multiple parts.\n    stripped = content.strip()\n\n    if not stripped:\n        return []\n    if '\\r\\n' in stripped:\n        return _strip_all(stripped.split('\\r\\n'))\n    if '\\n' in stripped:\n        return _strip_all(stripped.split('\\n'))\n    return _strip_all([stripped])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_release_id(version=None):\n    # pylint: disable=invalid-name\n    ts = datetime.utcnow().strftime(RELEASE_DATE_FMT)\n\n    if version is None:\n        return ts\n    return '{0}-{1}'.format(ts, version)", "response": "Get a unique time - based identifier for a deployment\n    that also includes some sort of version number\n    or release."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef try_repeatedly(method, max_retries=None, delay=None):\n    max_retries = max_retries if max_retries is not None else 1\n    delay = delay if delay is not None else 0\n    tries = 0\n\n    with warn_only():\n        while tries < max_retries:\n            res = method()\n            if not res.failed:\n                return res\n\n            tries += 1\n            time.sleep(delay)\n    # final try outside the warn_only block so that if it\n    # fails it'll just blow up or do whatever it was going to\n    # do anyway.\n    return method()", "response": "Execute a given method in a single thread."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the release ID of the current deployment.", "response": "def get_current_release(self):\n        \"\"\"Get the release ID of the \"current\" deployment, None if\n        there is no current deployment.\n\n        This method performs one network operation.\n\n        :return: Get the current release ID\n        :rtype: str\n        \"\"\"\n        current = self._runner.run(\"readlink '{0}'\".format(self._current))\n        if current.failed:\n            return None\n        return os.path.basename(current.strip())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the release ID of the deployment immediately after the current release.", "response": "def get_previous_release(self):\n        \"\"\"Get the release ID of the deployment immediately\n        before the \"current\" deployment, ``None`` if no previous\n        release could be determined.\n\n        This method performs two network operations.\n\n        :return: The release ID of the release previous to the\n            \"current\" release.\n        :rtype: str\n        \"\"\"\n        releases = self.get_releases()\n        if not releases:\n            return None\n\n        current = self.get_current_release()\n        if not current:\n            return None\n\n        try:\n            current_idx = releases.index(current)\n        except ValueError:\n            return None\n\n        try:\n            return releases[current_idx + 1]\n        except IndexError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cleanup(self, keep=5):\n        releases = self.get_releases()\n        current_version = self.get_current_release()\n        to_delete = [version for version in releases[keep:] if version != current_version]\n\n        for release in to_delete:\n            self._runner.run(\"rm -rf '{0}'\".format(os.path.join(self._releases, release)))", "response": "Remove all but the keep most recent releases."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates the minimal required directories for deploying multiple releases of a project.", "response": "def setup_directories(self, use_sudo=True):\n        \"\"\"Create the minimal required directories for deploying multiple\n        releases of a project.\n\n        By default, creation of directories is done with the Fabric\n        ``sudo`` function but can optionally use the ``run`` function.\n\n        This method performs one network operation.\n\n        :param bool use_sudo: If ``True``, use ``sudo()`` to create required\n            directories. If ``False`` try to create directories using the\n            ``run()`` command.\n        \"\"\"\n        runner = self._runner.sudo if use_sudo else self._runner.run\n        runner(\"mkdir -p '{0}'\".format(self._releases))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the owner and permissions of the code deploy.", "response": "def set_permissions(\n            self, owner, file_perms=PERMS_FILE_DEFAULT,\n            dir_perms=PERMS_DIR_DEFAULT, use_sudo=True):\n        \"\"\"Set the owner and permissions of the code deploy.\n\n        The owner will be set recursively for the entire code deploy.\n\n        The directory permissions will be set on only the base of the\n        code deploy and the releases directory. The file permissions\n        will be set recursively for the entire code deploy.\n\n        If not specified default values will be used for file or directory\n        permissions.\n\n        By default the Fabric ``sudo`` function will be used for changing\n        the owner and permissions of the code deploy. Optionally, you can\n        pass the ``use_sudo=False`` argument to skip trying to change the\n        owner of the code deploy and to use the ``run`` function to change\n        permissions.\n\n        This method performs between three and four network operations\n        depending on if ``use_sudo`` is false or true, respectively.\n\n        :param str owner: User and group in the form 'owner:group' to\n            set for the code deploy.\n        :param str file_perms: Permissions to set for all files in the\n            code deploy in the form 'u+perms,g+perms,o+perms'. Default\n            is ``u+rw,g+rw,o+r``.\n        :param str dir_perms: Permissions to set for the base and releases\n            directories in the form 'u+perms,g+perms,o+perms'. Default\n            is ``u+rwx,g+rws,o+rx``.\n        :param bool use_sudo: If ``True``, use ``sudo()`` to change ownership\n            and permissions of the code deploy. If ``False`` try to change\n            permissions using the ``run()`` command, do not change ownership.\n\n        .. versionchanged:: 0.2.0\n            ``use_sudo=False`` will no longer attempt to change ownership of\n            the code deploy since this will just be a no-op or fail.\n\n        \"\"\"\n        runner = self._runner.sudo if use_sudo else self._runner.run\n\n        if use_sudo:\n            runner(\"chown -R '{0}' '{1}'\".format(owner, self._base))\n\n        for path in (self._base, self._releases):\n            runner(\"chmod '{0}' '{1}'\".format(dir_perms, path))\n\n        runner(\"chmod -R '{0}' '{1}'\".format(file_perms, self._base))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates pending tasks in a dict on self. result with task string as key. It will also create a list on self. tasks that is used to make sure the serialization of the results is correctly ordered.", "response": "def create_pending_tasks(self):\n        \"\"\"\n        Creates pending task results in a dict on self.result with task string as key. It will also\n        create a list on self.tasks that is used to make sure the serialization of the results\n        creates a correctly ordered list.\n        \"\"\"\n        for task in self.settings.services:\n            task = self.create_service_command(task)\n            self.service_tasks.append(task)\n            self.service_results[task] = Result(task)\n\n        for task in self.settings.tasks['setup']:\n            self.setup_tasks.append(task)\n            self.setup_results[task] = Result(task)\n\n        for task in self.settings.tasks['tests']:\n            self.tasks.append(task)\n            self.results[task] = Result(task)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating pending task results in a dict on self. after_result with task string as key.", "response": "def create_pending_after_task(self):\n        \"\"\"\n        Creates pending task results in a dict on self.after_result with task string as key.\n        It will also create a list on self.tasks that is used to make sure the serialization\n        of the results creates a correctly ordered list.\n        \"\"\"\n        for task in self.settings.tasks[self.after_tasks_key]:\n            self.after_tasks.append(task)\n            self.after_results[task] = Result(task)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef arbanglemap(self):\n        '''\n        here's the center angle of each pixel ( + then - to go from biggest to\n        smallest angle)  (e.g. 94.5 deg to 85.5 deg. -- sweeping left to right)\n        '''\n        # raySpacingDeg = self.arbfov / self.nCutPix\n        maxAng = self.boresightEl + self.arbfov / 2\n        minAng = self.boresightEl - self.arbfov / 2\n        angles = np.linspace(maxAng, minAng, num=self.ncutpix, endpoint=True)\n        assert np.isclose(angles[0], maxAng) & np.isclose(angles[-1], minAng)\n        return angles", "response": "return the arbanglemap of the image"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nnote we need to retrieve values in case no modifications are done. (since we'd get a closed h5py handle)", "response": "def doorient(self):\n        \"\"\"\n        NOTE: we need to retrieve values in case no modifications are done.\n        (since we'd get a closed h5py handle)\n        \"\"\"\n        assert self.cal1Dfn.is_file(\n        ), 'please specify filename for each camera under [cam]/cal1Dname: in .ini file  {}'.format(self.cal1Dfn)\n\n        with h5py.File(self.cal1Dfn, 'r') as f:\n            az = f['az'][()]\n            el = f['el'][()]\n            ra = f['ra'][()]\n            dec = f['dec'][()]\n\n        assert az.ndim == el.ndim == 2\n        assert az.shape == el.shape\n\n        if self.transpose:\n            logging.debug(\n                'tranposing cam #{} az/el/ra/dec data. '.format(self.name))\n            az = az.T\n            el = el.T\n            ra = ra.T\n            dec = dec.T\n        if self.fliplr:\n            logging.debug(\n                'flipping horizontally cam #{} az/el/ra/dec data.'.format(self.name))\n            az = np.fliplr(az)\n            el = np.fliplr(el)\n            ra = np.fliplr(ra)\n            dec = np.fliplr(dec)\n        if self.flipud:\n            logging.debug(\n                'flipping vertically cam #{} az/el/ra/dec data.'.format(self.name))\n            az = np.flipud(az)\n            el = np.flipud(el)\n            ra = np.flipud(ra)\n            dec = np.flipud(dec)\n        if self.rotccw != 0:\n            logging.debug(\n                'rotating cam #{} az/el/ra/dec data.'.format(self.name))\n            az = np.rot90(az, self.rotccw)\n            el = np.rot90(el, self.rotccw)\n            ra = np.rot90(ra, self.rotccw)\n            dec = np.rot90(dec, self.rotccw)\n\n        self.az = az\n        self.el = el\n        self.ra = ra\n        self.dec = dec"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef show_news_line(slug=None, limit=3, **kwargs):\n\n    if slug is None:\n        section = None\n        q = News.objects.published()\n    else:\n        section = Section.objects.get(slug=slug)\n        q = News.objects.published().filter(sections__slug=slug)\n\n    models = q.prefetch_related('sections').order_by('-date', '-id').all()[:limit]\n\n    return {'models': models, 'section': section, 'data': kwargs}", "response": "Show the news line."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries loading config file from a default directory", "response": "def load_config():\n    '''try loading config file from a default directory'''\n    cfg_path = '/usr/local/etc/freelan'\n    cfg_file = 'freelan.cfg'\n\n    if not os.path.isdir(cfg_path):\n        print(\"Can not find default freelan config directory.\")\n        return\n\n    cfg_file_path = os.path.join(cfg_path,cfg_file)\n\n    if not os.path.isfile( cfg_file_path ):\n        print(\"Can not find default freelan config file.\")\n        return\n\n    return _load_config(cfg_file_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_config(cfg):\n    '''try writing config file to a default directory'''\n    cfg_path = '/usr/local/etc/freelan'\n    cfg_file = 'freelan_TEST.cfg'\n\n    cfg_lines = []\n\n    if not isinstance(cfg, FreelanCFG):\n        if not isinstance(cfg, (list, tuple)):\n            print(\"Freelan write input can not be processed.\")\n            return\n        cfg_lines = cfg\n    else:\n        cfg_lines = cfg.build()\n\n    if not os.path.isdir(cfg_path):\n        print(\"Can not find default freelan config directory.\")\n        return\n\n    cfg_file_path = os.path.join(cfg_path,cfg_file)\n\n    if os.path.isfile( cfg_file_path ):\n        print(\"freelan config file already exists - moving to not replace content.\")\n        ts = time.time()\n        backup_file = cfg_file_path+'.ORG-'+datetime.datetime.fromtimestamp(ts).strftime('%y-%m-%d-%H-%M-%S')\n        shutil.move(cfg_file_path, backup_file)\n\n    cfg_lines = [cfg_line+'\\n' for cfg_line in cfg_lines]\n\n    with open(cfg_file_path, 'w') as cfg_f:\n        cfg_f.writelines(cfg_lines)", "response": "try writing config file to a default directory"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef poke_array(self, store, name, elemtype, elements, container, visited, _stack):\n        raise NotImplementedError", "response": "abstract method to store array data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cfgdump(path, config):\n    dump = yaml_dump(config)\n    if not os.path.exists(path):\n        os.makedirs(path)\n    with open(os.path.join(path, 'config.yaml'), 'w') as outf:\n        outf.write(dump)\n    print(dump)", "response": "Create output directory path and output there the config. yaml file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating metadata for video records.", "response": "def videometadata(ctx, city, date, outpath):\n    \"\"\"Generate metadata for video records.\n\n    city: The meetup series.\n\n    \\b\n    date: The date. May be:\n        - YYYY-MM-DD or YY-MM-DD (e.g. 2015-08-27)\n        - YYYY-MM or YY-MM (e.g. 2015-08)\n        - MM (e.g. 08): the given month in the current year\n        - pN (e.g. p1): show the N-th last meetup\n    \"\"\"\n    db = ctx.obj['db']\n    today = ctx.obj['now'].date()\n\n    event = cliutil.get_event(db, city, date, today)\n\n    data = event.as_dict()\n    cliutil.handle_raw_output(ctx, data)\n\n    evdir = \"{}-{}\".format(event.city.name, event.slug)\n\n    config = OrderedDict()\n    config['speaker'] = ''\n    config['title'] = ''\n    config['lightning'] = True\n    config['speaker_only'] = False\n    config['widescreen'] = False\n    config['speaker_vid'] = \"*.MTS\"\n    config['screen_vid'] = \"*.ts\"\n    config['event'] = event.name\n    if event.number:\n        config['event'] += \" #{}\".format(event.number)\n    config['date'] = event.date.strftime(\"%Y-%m-%d\")\n    config['url'] = \"https://pyvo.cz/{}/{}/\".format(event.series_slug,\n                                                    event.slug)\n\n    print(evdir)\n    cfgdump(os.path.join(outpath, evdir), config)\n\n    if event.talks:\n        for talknum, talk in enumerate(event.talks, start=1):\n            config['speaker'] = ', '.join(s.name for s in talk.speakers)\n            config['title'] = talk.title\n            config['lightning'] = talk.is_lightning\n            talkdir = \"{:02d}-{}\".format(talknum, slugify(talk.title))\n            print(talkdir)\n            cfgdump(os.path.join(outpath, evdir, talkdir), config)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the value of the attribute from the user s meta and base class.", "response": "def get_value(self, meta, base_model_meta, mcs_args: McsArgs):\n        \"\"\"\n        :param meta: the class Meta (if any) from the user's model (NOTE:\n            this will be a plain object, NOT an instance of ModelMetaOptions)\n        :param base_model_meta: the ModelMetaOptions (if any) from the\n            base class of the user's model\n        :param mcs_args: the McsArgs for the user's model class\n        \"\"\"\n        value = self.default\n        if self.inherit and base_model_meta is not None:\n            value = getattr(base_model_meta, self.name, value)\n        if meta is not None:\n            value = getattr(meta, self.name, value)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef split_data(data, subset, splits):\n  '''Returns the data for a given protocol\n  '''\n\n  return dict([(k, data[k][splits[subset]]) for k in data])", "response": "Returns the data for a given subset"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(protocol, subset, classes=CLASSES, variables=VARIABLES):\n  '''Returns the data subset given a particular protocol\n\n\n  Parameters\n\n    protocol (string): one of the valid protocols supported by this interface\n\n    subset (string): one of 'train' or 'test'\n\n    classes (list of string): a list of strings containing the names of the\n      classes from which you want to have the data from\n\n    variables (list of strings): a list of strings containg the names of the\n      variables (features) you want to have data from\n\n\n  Returns:\n\n    data (numpy.ndarray): The data for all the classes and variables nicely\n      packed into one numpy 3D array. One depth represents the data for one\n      class, one row is one example, one column a given feature.\n\n  '''\n\n  retval = split_data(bob.db.iris.data(), subset, PROTOCOLS[protocol])\n\n  # filter variables (features)\n  varindex = [VARIABLES.index(k) for k in variables]\n\n  # filter class names and variable indexes at the same time\n  retval = dict([(k, retval[k][:,varindex]) for k in classes])\n\n  # squash the data\n  return numpy.array([retval[k] for k in classes])", "response": "Returns the data subset given a particular protocol and subset"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef silent_parse_args(self, command, args):\n        args_ns = argparse.Namespace()\n        stderr_save = argparse._sys.stderr\n        stdout_save = argparse._sys.stdout\n        argparse._sys.stderr = os.devnull\n        argparse._sys.stdout = os.devnull\n        try:\n            command.argparser.parse_known_args(args, args_ns)\n        except BaseException:\n            pass\n        finally:\n            argparse._sys.stderr = stderr_save\n            argparse._sys.stdout = stdout_save\n        return args_ns", "response": "Silently parse the arguments and return the args namespace."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the nargs and set the max_args and min_args attributes.", "response": "def parse_nargs(self, nargs):\n        \"\"\" Nargs is essentially a multi-type encoding.  We have to parse it\n        to understand how many values this action may consume. \"\"\"\n        self.max_args = self.min_args = 0\n        if nargs is None:\n            self.max_args = self.min_args = 1\n        elif nargs == argparse.OPTIONAL:\n            self.max_args = 1\n        elif nargs == argparse.ZERO_OR_MORE:\n            self.max_args = None\n        elif nargs in (argparse.ONE_OR_MORE, argparse.REMAINDER):\n            self.min_args = 1\n            self.max_args = None\n        elif nargs != argparse.PARSER:\n            self.max_args = self.min_args = nargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconsumes the arguments we support.", "response": "def consume(self, args):\n        \"\"\" Consume the arguments we support.  The args are modified inline.\n        The return value is the number of args eaten. \"\"\"\n        consumable = args[:self.max_args]\n        self.consumed = len(consumable)\n        del args[:self.consumed]\n        return self.consumed"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef file_complete(self, prefix, args):\n        path = os.path.expanduser(prefix)\n        dirname, name = os.path.split(path)\n        if not dirname:\n            dirname = '.'\n        try:\n            dirs = os.listdir(dirname)\n        except FileNotFoundError:\n            return frozenset()\n        choices = []\n        session = self.calling_command.session\n        for f in dirs:\n            try:\n                if (not name or f.startswith(name)) and \\\n                   not f.startswith('.'):\n                    choices.append(f)\n            except PermissionError:\n                pass\n        prevent_pad = session.pad_completion and len(choices) == 1 and \\\n            os.path.isdir(choices[0])\n        names = [os.path.join(dirname, x) for x in choices]\n        if prevent_pad:\n            names.append(names[0] + '/')\n        return frozenset(names)", "response": "Look in the local filesystem for valid file choices."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget data from a single lab from hackerspaces. org.", "response": "def get_single_lab(lab_slug, open_cage_api_key):\n    \"\"\"Gets data from a single lab from hackerspaces.org.\"\"\"\n    wiki = MediaWiki(hackerspaces_org_api_url)\n    wiki_response = wiki.call(\n        {'action': 'query',\n         'titles': lab_slug,\n         'prop': 'revisions',\n         'rvprop': 'content'})\n\n    # If we don't know the pageid...\n    for i in wiki_response[\"query\"][\"pages\"]:\n        content = wiki_response[\"query\"][\"pages\"][i][\"revisions\"][0][\"*\"]\n\n    # Transform the data into a Lab object\n    current_lab = Hackerspace()\n\n    equipment_list = []\n\n    # Parse the Mediawiki code\n    wikicode = mwparserfromhell.parse(content)\n    for k in wikicode.filter_templates():\n        element_name = unicode(k.name)\n        if \"Hackerspace\" in element_name:\n            for j in k.params:\n                current_lab.name = lab_slug\n                j_value = unicode(j.value)\n                j_name = unicode(j.name)\n                # Remove new line in content\n                if j_value[-1:] == \"\\n\" or j_value[:1] == \"\\n\":\n                    j_value = j_value.replace('\\n', '')\n                if j_name == \"logo\":\n                    current_lab.logo = j_value\n                if j_name == \"founding\":\n                    current_lab.founding = j_value\n                if j_name == \"coordinate\":\n                    # Clean the coordinates\n                    j_value = j_value.replace('\"', '')\n                    j_value = j_value.replace('N', '')\n                    j_value = j_value.replace('S', '')\n                    j_value = j_value.replace('W', '')\n                    j_value = j_value.replace('E', '')\n                    j_value = j_value.replace(u'\u00b0', '')\n                    j_value = j_value.replace(' ', '')\n                    # Get the full address with the coordinates\n                    address = get_location(query=j_value, format=\"reverse\", api_key=open_cage_api_key)\n                    current_lab.city = address[\"city\"]\n                    current_lab.county = address[\"county\"]\n                    current_lab.state = address[\"state\"]\n                    current_lab.postal_code = address[\"postal_code\"]\n                    current_lab.address_1 = address[\"address_1\"]\n                    current_lab.country = address[\"country\"]\n                    current_lab.country_code = address[\"country_code\"]\n                    current_lab.continent = address[\"continent\"]\n                    current_lab.latitude = address[\"latitude\"]\n                    current_lab.longitude = address[\"longitude\"]\n                if j_name == \"membercount\":\n                    current_lab.membercount = j_value\n                if j_name == \"fee\":\n                    current_lab.fee = j_value\n                if j_name == \"size\":\n                    current_lab.size = j_value\n                if j_name == \"status\":\n                    current_lab.status = j_value\n                if j_name == \"site\":\n                    current_lab.site = j_value\n                if j_name == \"wiki\":\n                    current_lab.wiki = j_value\n                if j_name == \"irc\":\n                    current_lab.irc = j_value\n                if j_name == \"jabber\":\n                    current_lab.jabber = j_value\n                if j_name == \"phone\":\n                    current_lab.phone = j_value\n                if j_name == \"youtube\":\n                    current_lab.youtube = j_value\n                if j_name == \"eventbrite\":\n                    current_lab.eventbrite = j_value\n                if j_name == \"facebook\":\n                    current_lab.facebook = j_value\n                if j_name == \"ustream\":\n                    current_lab.ustream = j_value\n                if j_name == \"flickr\":\n                    current_lab.flickr = j_value\n                if j_name == \"twitter\":\n                    current_lab.twitter = j_value\n                if j_name == \"googleplus\":\n                    current_lab.googleplus = j_value\n                if j_name == \"email\":\n                    current_lab.email = j_value\n                if j_name == \"maillist\":\n                    current_lab.maillist = j_value\n                if j_name == \"ical\":\n                    current_lab.ical = j_value\n                if j_name == \"forum\":\n                    current_lab.forum = j_value\n        elif \"Equipment\" in element_name:\n            for j in k.params:\n                equipment_list.append(j.replace(\"equipment=\", \"\"))\n\n            current_lab.equipment = equipment_list\n\n    # Load the free text\n    freetext = \"\"\n    for k in wikicode._nodes:\n        try:\n            test_value = k.name\n        except AttributeError:\n            freetext += unicode(k)\n    current_lab.text = freetext\n\n    return current_lab"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exec_command(command, **kwargs):\n\n    shell = kwargs.get('shell', False)\n    stdin = kwargs.get('stdin', None)\n    stdout = kwargs.get('stdout', None)\n    stderr = kwargs.get('stderr', None)\n\n    kwargs.update(shell=shell)\n    kwargs.update(stdin=stdin)\n    kwargs.update(stdout=stdout)\n    kwargs.update(stderr=stderr)\n\n    if not isinstance(command, list):\n        command = shlex.split(command)\n\n    return_value = subprocess.call(command, **kwargs)\n\n    return CommandReturnValue(return_value=return_value,\n                              stdin=stdin,\n                              stdout=stdout,\n                              stderr=stderr)", "response": "Executes a command and sends the output to the console"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute a command and captures the output without any output to the console.", "response": "def observe_command(command, **kwargs):\n    \"\"\"\n    Executes the given command and captures the output without any output to the console\n\n    :param str|list command:\n\n    :kwargs:\n        * `shell`   (``bool`` = False)  --\n        * `timeout` (``int`` = 15)      -- Timeout in seconds\n        * `stdin`   (``*`` = None)      --\n        * `stdout`  (``*`` = None)      --\n        * `stderr`  (``*`` = None)      --\n        * `cwd`     (``string`` = None) --\n\n    :return: CommandReturnValue\n    \"\"\"\n\n    shell = kwargs.get('shell', False)\n    timeout = kwargs.get('timeout', 15)\n    stdin = kwargs.get('stdin', subprocess.PIPE)\n    stdout = kwargs.get('stdout', subprocess.PIPE)\n    stderr = kwargs.get('stderr', subprocess.PIPE)\n    cwd = kwargs.get('cwd', None)\n\n    kwargs.update(shell=shell)\n    kwargs.update(stdin=stdin)\n    kwargs.update(stdout=stdout)\n    kwargs.update(stderr=stderr)\n    kwargs.update(cwd=cwd)\n\n    if not isinstance(command, list):\n        command = shlex.split(command)\n\n    # TODO: implement and process stdin - 1\n    proc = subprocess.Popen(command, **kwargs)\n\n    try:\n        # only Python versions from 3.3 have the 'timeout' argument\n        if sys.version_info[0] >= 3 and sys.version_info[1] >= 3:\n            proc_stdout, proc_stderr = proc.communicate(timeout=timeout)\n\n        else:\n            proc_stdout, proc_stderr = proc.communicate()\n\n    except subprocess.TimeoutExpired:\n        proc.kill()\n        proc_stdout, proc_stderr = proc.communicate()\n\n    # TODO: implement and process stdin - 2\n    # process stdin\n    # try:\n    #     _stdin = proc.stdin.read()\n    # except IOError:\n    #     _stdin = None\n    #\n    # if not _stdin:\n    #     _stdin = None\n\n    # process stdout\n    try:\n        _stdout = proc_stdout.decode('utf-8')\n    except IOError:\n        _stdout = None\n\n    if not _stdout:\n        _stdout = None\n\n    # process stderr\n    try:\n        _stderr = proc_stderr.decode('utf-8')\n    except IOError:\n        _stderr = None\n\n    if not _stderr:\n        _stderr = None\n\n    return CommandReturnValue(return_value=proc.returncode,\n                              stdout=_stdout,\n                              stderr=_stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the fingerprint for an object", "response": "def calculate_hash(obj):\n    \"\"\"\n    Computes fingerprint for an object, this code is duplicated from\n    representatives.models.HashableModel because we don't have access to model\n    methods in a migration scenario.\n    \"\"\"\n\n    hashable_fields = {\n        'Chamber': ['name', 'country', 'abbreviation'],\n        'Constituency': ['name'],\n        'Group': ['name', 'abbreviation', 'kind', 'chamber'],\n        'Mandate': ['group', 'constituency', 'role', 'begin_date', 'end_date',\n            'representative']\n    }\n\n    fingerprint = hashlib.sha1()\n    for field_name in hashable_fields[obj.__class__.__name__]:\n        field = obj._meta.get_field(field_name)\n        if field.is_relation:\n            related = getattr(obj, field_name)\n            if related is None:\n                fingerprint.update(smart_str(related))\n            else:\n                fingerprint.update(related.fingerprint)\n        else:\n            fingerprint.update(smart_str(getattr(obj, field_name)))\n    obj.fingerprint = fingerprint.hexdigest()\n    return obj.fingerprint"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_or_create(cls, **kwargs):\n\n    try:\n        obj = cls.objects.get(**kwargs)\n        created = False\n    except cls.DoesNotExist:\n        obj = cls(**kwargs)\n        created = True\n        calculate_hash(obj)\n        obj.save()\n\n    return (obj, created)", "response": "Implements get_or_create logic for models that inherit from\n    representatives. models. HashableModel"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nenabling a function to work with a decorator with arguments.", "response": "def decorator_with_args(func, return_original=False, target_pos=0):\n    \"\"\"Enable a function to work with a decorator with arguments\n\n    Args:\n\n      func (callable): The input function.\n\n      return_original (bool): Whether the resultant decorator returns\n        the decorating target unchanged. If True, will return the\n        target unchanged. Otherwise, return the returned value from\n        *func*. Default to False. This is useful for converting a\n        non-decorator function to a decorator. See examples below.\n\n    Return:\n\n      callable: a decorator with arguments.\n\n    Examples:\n\n    >>> @decorator_with_args\n    ... def register_plugin(plugin, arg1=1):\n    ...     print('Registering '+plugin.__name__+' with arg1='+str(arg1))\n    ...     return plugin  # note register_plugin is an ordinary decorator\n    >>> @register_plugin(arg1=10)\n    ... def plugin1(): pass\n    Registering plugin1 with arg1=10\n\n    >>> @decorator_with_args(return_original=True)\n    ... def register_plugin_xx(plugin, arg1=1):\n    ...     print('Registering '+plugin.__name__+' with arg1='+str(arg1))\n    ...     # Note register_plugin_xxx does not return plugin, so it cannot\n    ...     # be used as a decorator directly before applying\n    ...     # decorator_with_args. \n    >>> @register_plugin_xx(arg1=10)\n    ... def plugin1(): pass\n    Registering plugin1 with arg1=10\n    >>> plugin1()\n\n    >>> @decorator_with_args(return_original=True)\n    ... def register_plugin_xxx(plugin, arg1=1): pass\n\n    >>> # use result decorator as a function\n    >>> register_plugin_xxx(plugin=plugin1, arg1=10)\n    <function plugin1...>\n\n    >>> @decorator_with_args(return_original=True, target_pos=1)\n    ... def register_plugin_xxxx(arg1, plugin, arg2=10):\n    ...     print('Registering '+plugin.__name__+' with arg1='+str(arg1))\n    >>> @register_plugin_xxxx(100)\n    ... def plugin2(): pass\n    Registering plugin2 with arg1=100\n    \"\"\"\n    if sys.version_info[0] >= 3:\n        target_name = inspect.getfullargspec(func).args[target_pos]\n    else:\n        target_name = inspect.getargspec(func).args[target_pos]\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        if  len(args) > target_pos:\n            res = func(*args, **kwargs)\n            return args[target_pos] if return_original else res\n        elif len(args) <= 0 and target_name in kwargs:\n            res = func(*args, **kwargs)\n            return kwargs[target_name] if return_original else res\n        else:\n            return wrap_with_args(*args, **kwargs)\n\n    def wrap_with_args(*args, **kwargs):\n        def wrapped_with_args(target):\n            kwargs2 = dict()\n            kwargs2[target_name] = target\n            kwargs2.update(kwargs)\n            res = func(*args,  **kwargs2)\n            return target if return_original else res\n        return wrapped_with_args\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking elements for equality", "response": "def elements_equal(first, *others):\n    \"\"\"\n    Check elements for equality\n    \"\"\"\n    f = first\n    lf = list(f)\n    for e in others:\n        le = list(e)\n        if (len(lf) != len(le)\n                or f.tag != e.tag\n                or f.text != e.text\n                or f.tail != e.tail\n                or f.attrib != e.attrib\n                or (not all(map(elements_equal, lf, le)))\n                ):\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_element(text_or_tree_or_element):\n    if isinstance(text_or_tree_or_element, ET.Element):\n        return text_or_tree_or_element\n    elif isinstance(text_or_tree_or_element, ET.ElementTree):\n        return text_or_tree_or_element.getroot()\n    elif isinstance(text_or_tree_or_element, (unicode, bytes)):\n        return ET.fromstring(text_or_tree_or_element)\n    else:\n        return ET.parse(text_or_tree_or_element).getroot()", "response": "Get back an ET. Element for several possible input formats\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _connectToFlickr(self):\n\n        if self.connected_to_flickr:\n            logger.debug(\"Already connected to flickr\")\n            return True\n\n        logger.debug(\"Connecting to flickr\")\n        # Do flickr authentication\n        _flickr = flickrapi.FlickrAPI(api_key, api_secret,format='etree')\n        try:\n            (token, frob) = _flickr.get_token_part_one(perms='delete')\n        except:\n            print(\"Couldn't connect to flickr\")\n            return False\n\n        if not token: raw_input(\"Press ENTER after you authorized this program\")\n        _flickr.get_token_part_two((token, frob))\n\n        self.flickr=_flickr;\n        \n        self.connected_to_flickr=True\n\n        return True", "response": "Establish the actual TCP connection to flickr"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if this is a config file or meta file.", "response": "def _isConfigFile(self,filename):\n        \"\"\"If this is a config file or meta file\n        return true\"\"\"\n        ext=os.path.splitext(filename)[1].lower()\n        if filename in self.FLICKR_CONFIG_FILES:\n            return True\n        elif ext in self.FLICKR_META_EXTENSIONS:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmanaging FLICKR config files", "response": "def _update_config(self,directory,filename):\n        \"\"\"Manages FLICKR config files\"\"\"\n        basefilename=os.path.splitext(filename)[0]\n        ext=os.path.splitext(filename)[1].lower()\n        if filename==LOCATION_FILE:\n            print(\"%s - Updating geotag information\"%(LOCATION_FILE))\n            return self._update_config_location(directory)\n        elif filename==TAG_FILE:\n            print(\"%s - Updating tags\"%(TAG_FILE))\n            return self._update_config_tags(directory)\n        elif filename==SET_FILE:\n            print(\"%s - Updating sets\"%(SET_FILE))\n            return self._update_config_sets(directory)\n        elif filename==MEGAPIXEL_FILE:\n            print(\"%s - Updating photo size\"%(MEGAPIXEL_FILE))\n            return self._upload_media(directory,resize_request=True)\n        elif ext in self.FLICKR_META_EXTENSIONS:\n            return self._update_meta(directory,basefilename)\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _update_meta(self,directory,filename):\n\n        if not self._connectToFlickr():\n            print(\"%s - Couldn't connect to flickr\"%(directory))\n            return False\n\n        db = self._loadDB(directory)\n\n        # Look up photo id for this photo\n        pid=db[filename]['photoid']\n\n        # =========== LOAD TITLE ========\n        fullfile=os.path.join(directory,filename+'.title')\n        try:\n            logger.debug('trying to open [%s]'%(fullfile))\n            _title=(open(fullfile).readline().strip())\n            logger.debug(\"_updatemeta: %s - title is %s\",filename,_title)\n        except:\n            _title=''\n\n        # =========== LOAD DESCRIPTION ========\n        fullfile=os.path.join(directory,filename+'.description')\n        try:\n            _description=(open(fullfile).readline().strip())\n            logger.debug(\"_updatemeta: %s - description is %s\",filename,_description)\n        except:\n            _description=''\n\n        logger.info('%s - updating metadata (title=%s) (description=%s)'\\\n                %(filename,_title,_description))\n        resp=self.flickr.photos_setMeta(photo_id=pid,title=_title,\\\n                description=_description)\n        if resp.attrib['stat']!='ok':\n            logger.error(\"%s - flickr: photos_setTags failed with status: %s\",\\\n                    resp.attrib['stat']);\n            return False\n        else:\n            return True", "response": "Opens up filename. title and filename. description updates on flickr"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _load_tags(self,directory):\n        #FIXME: should check if DB tracking file before using it\n        # --- Read tags out of file\n        _tags=''\n        try:\n            fullfile=os.path.join(directory,TAG_FILE)\n            ltags=open(fullfile).readline().split(',')\n            _tags=''' '''\n\n            for tag in ltags:\n                _tags+='''\"'''+tag.strip()+'''\" '''\n            _tags=_tags.strip()\n        except:\n            logger.info(\"No tags found in %s\"%(directory))\n\n        return _tags", "response": "Loads tags from tag file and return\n        as flickr api compatible string\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a photo set on Flickr", "response": "def _createphotoset(self,myset,primary_photoid):\n        \"\"\"Creates a photo set on Flickr\"\"\"\n        if not self._connectToFlickr():\n            print(\"%s - Couldn't connect to flickr\"%(directory))\n            return False\n        \n        logger.debug('Creating photo set %s with prim photo %s'\\\n                %(myset,primary_photoid))\n        resp=self.flickr.photosets_create(title=myset,\\\n                primary_photo_id=primary_photoid)\n        if resp.attrib['stat']!='ok':\n            logger.error(\"%s - flickr: photos_setTags failed with status: %s\",\\\n                    resp.attrib['stat']);\n            return False\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _update_config_sets(self,directory,files=None):\n        if not self._connectToFlickr():\n            print(\"%s - Couldn't connect to flickr\"%(directory))\n            return False\n\n        # Load sets from SET_FILE\n        _sets=self._load_sets(directory)\n\n        # Connect to flickr and get dicionary of photosets\n        psets=self._getphotosets()\n\n        db = self._loadDB(directory)\n\n        # To create a set, one needs to pass it the primary\n        # photo to use, let's open the DB and load the first\n        # photo\n        primary_pid=db[db.keys()[0]]['photoid']\n\n        # Loop through all sets, create if it doesn't exist\n        for myset in _sets:\n            if myset not in psets:\n                logger.info('set [%s] not in flickr sets, will create set'%(myset))\n                self._createphotoset(myset,primary_pid)\n\n        # Now reaload photosets from flickr\n        psets=self._getphotosets()\n\n        # --- Load DB of photos, and update them all with new tags\n        for fn in db:\n            # --- If file list provided, skip files not in the list\n            if files and fn not in files:\n                continue\n\n            pid=db[fn]['photoid']\n\n            # Get all the photosets this photo belongs to\n            psets_for_photo=self._getphotosets_forphoto(pid)\n\n            for myset in _sets:\n                if myset in psets_for_photo:\n                    logger.debug(\"%s - Already in photoset [%s] - skipping\"%(fn,myset))\n                    continue\n                logger.info(\"%s [flickr] Adding to set [%s]\" %(fn,myset))\n                psid=psets[myset]['id']\n                logger.debug(\"%s - Adding to photoset %s\"%(fn,psid))\n                resp=self.flickr.photosets_addPhoto(photoset_id=psid,photo_id=pid)\n                if resp.attrib['stat']!='ok':\n                    logger.error(\"%s - flickr: photos_addPhoto failed with status: %s\",\\\n                            resp.attrib['stat']);\n                    return False\n\n            # Go through all sets flickr says this photo belongs to and\n            # remove from those sets if they don't appear in SET_FILE\n            for pset in psets_for_photo:\n                if pset not in _sets:\n                    psid=psets[pset]['id']\n                    logger.info(\"%s [flickr] Removing from set [%s]\" %(fn,pset))\n                    logger.debug(\"%s - Removing from photoset %s\"%(fn,psid))\n                    resp=self.flickr.photosets_removePhoto(photoset_id=psid,photo_id=pid)\n                    if resp.attrib['stat']!='ok':\n                        logger.error(\"%s - flickr: photossets_removePhoto failed with status: %s\",\\\n                                resp.attrib['stat']);\n                        return False\n\n        return True", "response": "Load set information from file and updates on flickr and flickr DB and photosets"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nasking flickr which photosets photo with given pid belongs to returns list of availabe photoset names", "response": "def _getphotosets_forphoto(self,pid):\n        \"\"\"Asks flickr which photosets photo with\n        given pid belongs to, returns list of\n        photoset names\"\"\"\n\n        resp=self.flickr.photos_getAllContexts(photo_id=pid)\n        if resp.attrib['stat']!='ok':\n            logger.error(\"%s - flickr: photos_getAllContext failed with status: %s\",\\\n                    resp.attrib['stat']);\n            return None\n\n        lphotosets=[]\n        for element in resp.findall('set'):\n            lphotosets.append(element.attrib['title'])\n\n        logger.debug('%s - belongs to these photosets %s',pid,lphotosets)\n\n        return lphotosets"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nask flickr for photo original size returns tuple with width height", "response": "def _getphoto_originalsize(self,pid):\n        \"\"\"Asks flickr for photo original size\n        returns tuple with width,height\n        \"\"\"\n\n        logger.debug('%s - Getting original size from flickr'%(pid))\n\n        width=None\n        height=None\n\n        resp=self.flickr.photos_getSizes(photo_id=pid)\n        if resp.attrib['stat']!='ok':\n            logger.error(\"%s - flickr: photos_getSizes failed with status: %s\",\\\n                    resp.attrib['stat']);\n            return (None,None)\n        \n        for size in resp.find('sizes').findall('size'):\n            if size.attrib['label']==\"Original\":\n                width=int(size.attrib['width'])\n                height=int(size.attrib['height'])\n                logger.debug('Found pid %s original size of %s,%s'\\\n                    %(pid,width,height))\n                \n        return (width,height)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn URL to photo with specified size", "response": "def _getphoto_url(self,pid,size='n'):\n        \"\"\"Returns URL to photo, optionally can link\n        to different size images\n        Size suffixes according to:\n        http://www.flickr.com/services/api/misc.urls.html\n\n        s   small square 75x75\n        q   large square 150x150\n        t   thumbnail, 100 on longest side\n        m   small, 240 on longest side\n        n   small, 320 on longest side\n        -   medium, 500 on longest side\n        z   medium 640, 640 on longest side\n        c   medium 800, 800 on longest side\n        b   large, 1024 on longest side*\n        o   original image, either a jpg, gif or png, depending on source format\n\n        \"\"\"\n        p=self._getphoto_information(pid)\n        farm=p['farm']\n        server=p['server']\n        secret=p['secret']\n        url=\"http://farm%s.staticflickr.com/%s/%s_%s_%s.jpg\"\\\n            %(farm,server,pid,secret,size)\n\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _update_config_location(self,directory,files=None):\n        if not self._connectToFlickr():\n            print(\"%s - Couldn't connect to flickr\"%(filename))\n            return False\n\n\n        # --- Read location out of file\n        fullfile=os.path.join(directory,LOCATION_FILE)\n        try:\n            location=open(fullfile).readline().strip()\n        except:\n            logger.info('No location information found');\n            return False\n\n        logger.debug('Setting location information : %s'%(location))\n\n        # ---- Now do reverse geocoding\n        try:\n            results = Geocoder.geocode(location)\n        except:\n            logger.error(\"Couldn't find lat/lon for %s\"%(location))\n            return False\n\n        #logger.debug(results.raw)\n        logger.debug('google says location is: %s'%(results[0]))\n        _lat,_lon=results[0].coordinates\n        placename=results[0]\n\n        # --- Load DB of photos, and update them all with new location\n        db = self._loadDB(directory)\n        for fn in db:\n            # --- If file list provided, skip files not in the list\n            if files and fn not in files:\n                continue\n\n            logger.debug('Checking %s for location change'%(fn))\n            exif_lat,exif_lon=pusher_utils.getexif_location(directory,fn)\n            if exif_lat and exif_lon:\n                logger.info(\"%s [flickr] EXIF GPS found (%f,%f) - skipping\"\\\n                        %(fn,exif_lat,exif_lon))\n                continue\n            else:\n                logger.info(\"%s - GPS: no position, using location file\"%(fn))\n\n            logger.info(\"%s [flickr] Updating loc to %f,%f [%s]\"\\\n                    %(fn,_lat,_lon,placename))\n            pid=db[fn]['photoid']\n            resp=self.flickr.photos_geo_setLocation(photo_id=pid,lat=_lat,lon=_lon)\n            if resp.attrib['stat']!='ok':\n                logger.error(\"%s - flickr: geo_setLocation failed with status: %s\",\\\n                        resp.attrib['stat']);\n                return False\n\n        return True", "response": "Loads location and applies to all files in given files list and updates the config location with new location."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves specified files from flickr DB", "response": "def _remove_media(self,directory,files=None):\n        \"\"\"Removes specified files from flickr\"\"\"\n        # Connect if we aren't already\n        if not self._connectToFlickr():\n            logger.error(\"%s - Couldn't connect to flickr\")\n            return False\n\n        db=self._loadDB(directory)\n        # If no files given, use files from DB in dir\n        if not files:\n            files=db.keys()\n\n        #If only one file given, make it a list\n        if isinstance(files,basestring):\n            files=[files]\n\n        for fn in files:\n            print(\"%s - Deleting from flickr [local copy intact]\"%(fn))\n\n            try:\n                pid=db[fn]['photoid']\n            except:\n                logger.debug(\"%s - Was never in flickr DB\"%(fn))\n                continue\n            resp=self.flickr.photos_delete(photo_id=pid,format='etree')\n            if resp.attrib['stat']!='ok':\n                print(\"%s - flickr: delete failed with status: %s\",\\\n                        resp.attrib['stat']);\n                return False\n            else:\n                logger.debug('Removing %s from flickr DB'%(fn))\n                del db[fn]\n                self._saveDB(directory,db)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _upload_or_replace_flickr(self,directory,fn,_tags=None,\\\n            _megapixels=None,resize_request=None):\n        \"\"\"Does the actual upload to flickr.\n        if resize_request, will resize picture only if\n        it already exists and the geometry on flickr doesn't match\n        what we want,\n        returns (status,replaced)\"\"\"\n        # We should check here if \n        db=self._loadDB(directory)\n\n        status=False\n        replaced=False\n\n        if not _megapixels:\n            mpstring=\"original\"\n        else:\n            mpstring=(\"%0.1f MP\"%(_megapixels))\n\n        # If resize request, make tempfile and\n        # resize.\n        if _megapixels:\n            fp = tempfile.NamedTemporaryFile()\n            fullfile_resized=fp.name\n            logger.debug(\"tempfile for resized is %s\"%(fp.name))\n\n        fullfile=os.path.join(directory,fn)\n\n        ext=os.path.splitext(fullfile)[1].lower()\n        # If JPEG, then resize\n        if ext=='.jpg':\n            isJPG=True\n        else:\n            isJPG=False\n            \n\n        # Possibly scale before uploading\n        if fn not in db:\n            # Do we have to resize?\n            if _megapixels and isJPG:\n                if pusher_utils.resize_image(fullfile,fullfile_resized,_megapixels):\n                    logger.debug(\"%s resized to %s successfully\"\\\n                            %(fullfile,fullfile_resized))\n                    fullfile=fullfile_resized\n                else:\n                    logger.warning(\"%s couldn't resize, uploading original\"\\\n                            %(fullfile))\n\n            logger.debug(\"Upload %s to flickr, tags=%s\",fn,_tags)\n\n            print(\"%s - Uploading to flickr, tags[%s] size=%s\"\\\n                    %(fn,_tags,mpstring))\n\n            # Do the actual upload\n            uplxml=self.flickr.upload(filename=fullfile,\\\n                    #title=_title,\\\n                    tags=_tags,\\\n                    format='etree')\n\n            if uplxml.attrib['stat']!='ok':\n                print(\"%s - flickr: upload failed with status: %s\",\\\n                        fn,uplxml.attrib['stat']);\n                status=False\n                replaced=False\n                return status,replaced\n\n            pid=uplxml.find('photoid').text\n            db[fn]={}\n            db[fn]['photoid']=pid\n            logger.debug(\"%s - flickr: uploaded with photoid %s\",fn,pid);\n            status=True\n            replaced=False\n        else:\n            # File already exists, let's replace it.\n            pid=db[fn]['photoid']\n            # If this is an actual resize request,\n            # go check geometry on flickr and resize\n            # if it hasn't been already\n            if resize_request and isJPG:\n                if self._already_resized_on_flickr(fullfile,pid,_megapixels):\n                    status=True\n                    replaced=True\n                    logger.info(\\\n                            '%s - flickr: already correct size - skipping'\\\n                            %(fn))\n                    # File already resized, skip it.\n                    return status,replaced\n\n            # If megapixels given, will resize image\n            if _megapixels and isJPG:\n                if pusher_utils.resize_image(fullfile,fullfile_resized,_megapixels):\n                    logger.debug(\"%s resized to %s successfully\"\\\n                            %(fullfile,fullfile_resized))\n                    fullfile=fullfile_resized\n                else:\n                    logger.warning(\"%s couldn't resize, uploading original\"\\\n                            %(fullfile))\n                    \n            logger.info(\"%s - Replace on flickr pid=%s\",fn,pid)\n            uplxml=self.flickr.replace(filename=fullfile,photo_id=pid)\n            if uplxml.attrib['stat']!='ok':\n                print(\"%s - flickr: replace failed with status: %s\",\\\n                        uplxml.attrib['stat']);\n                status=False\n                replaced=False\n                return status,replaced\n            else:\n                replaced=True\n                status=True\n\n        # We should check here if \n        self._saveDB(directory,db)\n        return status,replaced", "response": "Upload or replace a flickr file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _already_resized_on_flickr(self,fn,pid,_megapixels):\n        logger.debug(\"%s - resize requested\"%(fn))\n        # Get width/height from flickr\n        width_flickr,height_flickr=self._getphoto_originalsize(pid)\n        # Now compute what image will be if we resize it\n        new_width,new_height=pusher_utils.resize_compute_width_height(\\\n                fn,_megapixels)\n        if width_flickr==new_width and height_flickr==new_height:\n            return True\n        # Also return true if image couldn't be resized\n        elif not new_width:\n            return True\n        return False", "response": "Checks if image file with photo_id pid has already been resized on flickr. Returns True if so False if not."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _getphotosets(self):\n        sets={}\n        if not self._connectToFlickr():\n            print(\"Couldn't connect to flickr\")\n            return sets\n\n        psets = self.flickr.photosets_getList(user_id=myid)\n        for myset in psets.find('photosets').findall('photoset'):\n            key=myset.find('title').text\n            sets[key]={}\n            sets[key]['number_photos']=int(myset.attrib['photos'])\n            sets[key]['photo_id']=(myset.attrib['primary'])\n            sets[key]['id']=int(myset.attrib['id'])\n            sets[key]['url']='http://www.flickr.com/photos/%s/sets/%d/'\\\n                    %(myid,sets[key]['id'])\n\n        return sets", "response": "Returns dictionary of photosets retrieved from flickr"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns ( codename name ) for all permissions in the given opts.", "response": "def _get_all_permissions(opts):\n    \"Returns (codename, name) for all permissions in the given opts.\"\n    perms = []\n    for action in settings.DEFAULT_PERMISSIONS:\n        perms.append((_get_permission_codename(action, opts), 'Can %s %s' % (action, opts.verbose_name_raw)))\n    return perms + list(opts.permissions)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_project(self, project_path):\n        shutil.copytree(self.project_path, project_path)\n\n        self.update_file(project_path, 'requirements.txt', {\n            'trionyx_version': trionyx.__version__\n        })\n\n        self.update_file(project_path, 'config/local_settings.py', {\n            'secret_key': utils.random_string(32)\n        })", "response": "Create Trionyx project in given path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_app(self, apps_path, name):\n        app_path = os.path.join(apps_path, name.lower())\n\n        shutil.copytree(self.app_path, app_path)\n\n        self.update_file(app_path, '__init__.py', {\n            'name': name.lower()\n        })\n\n        self.update_file(app_path, 'apps.py', {\n            'name': name.lower(),\n            'verbose_name': name.capitalize()\n        })", "response": "Create Trionyx app in given path"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate given file with given variables", "response": "def update_file(self, project_path, file_path, variables):\n        \"\"\"\n        Update given file with given variables, variables in file must be inclosed with [[]].\n\n        For example you want to replace a variable secret_key, in the file its [[secret_key]].\n\n        :param str project_path:\n        :param str file_path:\n        :param dict variables:\n        \"\"\"\n        update_file = os.path.join(project_path, file_path)\n        with open(update_file, 'rb') as _file:\n            file_content = _file.read().decode('utf-8')\n\n        for key, value in variables.items():\n            file_content = file_content.replace('[[{}]]'.format(key), value)\n\n        with open(update_file, 'w+', encoding='utf-8') as _file:\n            _file.writelines(file_content)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef count(self, query=None, distinct=False, distinct_fields=None):\n        if distinct_fields is None:\n            self.__ensure_columns()\n            if distinct:\n                field = ','.join(self.columns)\n            else:\n                field = '*'\n        else:\n            field = ','.join(distinct_fields)\n\n        if distinct:\n            count_str = 'DISTINCT(%s)' %(field)\n        else:\n            count_str = field\n\n        count_str = 'COUNT(%s)' %(count_str)\n\n        sql = 'SELECT %s FROM %s' %(count_str, self.name)\n\n        if query is not None:\n            query_str = build_query(query)\n            if query_str:\n                sql = sql + ' WHERE ' + query_str\n\n        self.cursor.execute(sql)\n        count = self.cursor.fetchone()[0]\n\n        return count", "response": "Returns the number of rows satisying a criteria."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find(self, filter={}, fields=None, skip=0, limit=None, sort=None):\n        if not fields:\n            self.__ensure_columns()\n            fields = self.columns\n\n        query_obj = Query(source=self.name, filter=filter, fields=fields, skip=skip, limit=limit, sort=sort)\n        return QuerySet(cursor=self.cursor, query=query_obj)", "response": "Searches the table using the provided filters and returns a QuerySet object containing only the user s attributes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef insert(self, data_or_list_of_data):\n        result = None\n\n        def insert_data(data):\n            sql = build_insert(self.name, data)\n            row_count = self.cursor.execute(sql)\n\n            if row_count:\n                return self.cursor.lastrowid\n            else:\n                return None\n\n        value_to_be_inserted = []\n\n        if isinstance(data_or_list_of_data, list):\n            result = []\n            for data in data_or_list_of_data:\n                r = insert_data(data)\n                result.append(r)\n        else:\n            result = insert_data(data_or_list_of_data)\n        \n        return result", "response": "Insert data into the user table."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the data in the table.", "response": "def update(self, query, attributes, upsert=False):\n        \"\"\"\n        Updates data in the table.\n        \n        :Parameters: \n\n        - query(dict), specify the WHERE clause\n        - attributes(dict), specify the SET clause\n        - upsert: boolean. If True, then when there's no row matches the query, insert the values\n\n        :Return: Number of rows updated or inserted\n        \"\"\"\n        if upsert:\n            found_result = self.find_one(query)\n            if not found_result:\n                id = self.insert(attributes)\n                if id > 0:\n                    return 1\n                else:\n                    return 0\n\n        sql = build_update(self.name, query, attributes)\n        return self.cursor.execute(sql)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove(self, filter=None):\n        sql = build_delete(table_name=self.name, condition=filter)\n        return self.cursor.execute(sql)", "response": "Removes rows from the table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget ssh key in s3 bucket with specific name load it in StringIO file", "response": "def get_s3_key(self):\n        \"\"\"\n        get ssh key in s3 bucket with specific name, load it in StringIO file\n        :return:\n        \"\"\"\n        try:\n            c = s3.connect_to_region(self._region,\n                                     aws_access_key_id=self._aws_access_key_id,\n                                     aws_secret_access_key=self._aws_secret_access_key)\n            bucket = c.get_bucket(self._s3_bucket)\n            key = bucket.get_key(self._s3_name)\n            self._key_file = StringIO(unicode(key.get_contents_as_string().decode()))\n            self._key_file.seek(0)\n            key.close()\n        except NoAuthHandlerFound:\n            raise SergentSshException('Boto said that you should check your credentials')\n        except S3ResponseError as e:\n            logger.exception(e)\n            raise SergentSshException('bucket %s or key %s not found' % (self._s3_bucket, self._s3_name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_instances_by_tag(self, tags):\n\n        try:\n            c = ec2.connect_to_region(self._region,\n                                      aws_access_key_id=self._aws_access_key_id,\n                                      aws_secret_access_key=self._aws_secret_access_key)\n\n            # select instance by list of tags (OR used)\n            reservations = c.get_all_reservations(filters=SergentSsh.tags_to_dict(tags))\n            instances = list()\n\n            for r in reservations:\n                # for each instance launched by this reservation\n                for instance in r.instances:\n                    # we need only running instances\n                    if instance.state.lower() == 'running':\n                        instances.append(instance)\n\n            return instances\n        except NoAuthHandlerFound:\n            raise SergentSshException('Boto said that you should check your credentials')", "response": "Get instances by tags"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef upsert(self, events):\n        existing = self.get_existing_keys(events)\n        inserts = [e for e in events if not e[self.key] in existing]\n        updates = [e for e in events if e[self.key] in existing]\n        self.insert(inserts)\n        self.update(updates)", "response": "Inserts or updates the given events into MySQL"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_existing_keys(self, events):\n        data = [e[self.key] for e in events]\n        ss = ','.join(['%s' for _ in data])\n        query = 'SELECT %s FROM %s WHERE %s IN (%s)' % (self.key, self.table, self.key, ss)\n        cursor = self.conn.conn.cursor()\n        cursor.execute(query, data)\n        LOG.info(\"%s (data: %s)\", query, data)\n        existing = [r[0] for r in cursor.fetchall()]\n        LOG.info(\"Existing IDs: %s\" % existing)\n        return set(existing)", "response": "Returns the list of keys from the given event source that are already in the DB"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insert(self, events):\n        if not len(events):\n            return\n        keys = sorted(events[0].keys())\n        ss = ','.join(['%s' for _ in keys])\n        query = 'INSERT INTO %s (%s) VALUES ' % (self.table, ','.join(keys))\n        data = []\n        for event in events:\n            query += '(%s),' % ss\n            data += [event[k] for k in keys]\n        query = query[:-1] + ';'\n        LOG.info(\"%s (data: %s)\", query, data)\n        conn = self.conn.conn\n        cursor = conn.cursor()\n        cursor.execute(query, data)\n        conn.commit()", "response": "Constructs and executes a MySQL insert for the given events."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender datetime value with django formats default is SHORT_DATETIME_FORMAT", "response": "def datetime_value_renderer(value, **options):\n    \"\"\"Render datetime value with django formats, default is SHORT_DATETIME_FORMAT\"\"\"\n    datetime_format = options.get('datetime_format', 'SHORT_DATETIME_FORMAT')\n    return formats.date_format(timezone.localtime(value), datetime_format)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat price value with current locale and CURRENCY in settings", "response": "def price_value_renderer(value, currency=None, **options):\n    \"\"\"Format price value, with current locale and CURRENCY in settings\"\"\"\n    if not currency:\n        currency = getattr(settings, 'CURRENCY', 'USD')\n    return format_currency(value, currency, locale=utils.get_current_locale())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrender a single field.", "response": "def render_field(self, obj, field_name, **options):\n        \"\"\"Render field\"\"\"\n        try:\n            field = obj._meta.get_field(field_name)\n        except FieldDoesNotExist:\n            return getattr(obj, field_name, '')\n\n        if hasattr(field, 'choices') and getattr(field, 'choices'):\n            return getattr(obj, 'get_{}_display'.format(field_name))()\n\n        value = getattr(obj, field_name, '')\n        renderer = self.renderers.get(type(field))\n\n        if renderer:\n            return renderer(value, **options)\n\n        if isinstance(value, models.BaseModel):\n            value = str(value)\n\n        return self.render_value(value, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reduce(self, show_noisy=False):\n        if not show_noisy:\n            for log in self.quiet_logs:\n                yield log['raw'].strip()\n        else:\n            for log in self.noisy_logs:\n                yield log['raw'].strip()", "response": "Yield the reduced log lines that are in the log file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a query to the backend API with a list of observed features in this log file", "response": "def _send_features(self, features):\n        \"\"\"\n        Send a query to the backend api with a list of observed features in this log file\n\n        :param features: Features found in the log file\n        :return: Response text from ThreshingFloor API\n        \"\"\"\n\n        # Hit the auth endpoint with a list of features\n        try:\n            r = requests.post(self.base_uri + self.api_endpoint, json=features, headers={'x-api-key': self.api_key})\n        except requests.exceptions.ConnectionError:\n            raise TFAPIUnavailable(\"The ThreshingFloor API appears to be unavailable.\")\n\n        if r.status_code != 200:\n            sys.stderr.write(\"%s\\n\" % r.text)\n            raise TFAPIUnavailable(\"Request failed and returned a status of: {STATUS_CODE}\"\n                                   .format(STATUS_CODE=r.status_code))\n\n        return json.loads(r.text)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clean_out_dir(directory):\n    if not isinstance(directory, path):\n        directory = path(directory)\n    for file_path in directory.files():\n        file_path.remove()\n    for dir_path in directory.dirs():\n        dir_path.rmtree()", "response": "Delete all the files and subdirectories in a directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the log file size is correct.", "response": "def check_log_file_size(self):\n        \"\"\"\u5982\u679c\u65e5\u5fd7\u6587\u4ef6\u8d85\u8fc7100M\uff0c\u5148\u4fdd\u5b58\u6e90\u6587\u4ef6\uff0c\u518d\u5c06\u539f\u65e5\u5fd7\u6587\u4ef6\u540d\u540e\u52a0\u201c_\u65f6\u95f4\u6233\u201d\u4fdd\u5b58\uff0c\u518d\n        \u91cd\u65b0\u4ee5\u539f\u6587\u4ef6\u540d\u4ee5\u8ffd\u52a0\u6a21\u5f0f\u521b\u5efa\uff0c\u8fd9\u6837\u5c31\u5b9e\u73b0\u4e86\uff0c\u53ea\u8981\u65e5\u5fd7\u6587\u4ef6\u8d85\u8fc7100M\u5c31\u81ea\u52a8\u5907\u4efd\u3002\n        \u4ece\u800c\u5b9e\u73b0\u4e86\u63a7\u5236\u65e5\u5fd7\u6587\u4ef6\u5927\u5c0f\u7684\u6548\u679c\uff0c\u7531\u4e8e\u5728\u591a\u7ebf\u7a0b\u8fdb\u884c\u540c\u4e00\u4e2a\u6587\u4ef6\u5199\u5165\u7684\u65f6\u5019\uff0c\u5982\u679c\n        \u6587\u4ef6\u5927\u5c0f\u8d85\u8fc7\u4e86100m\uff0c\u800c\u8fd9\u4e00\u65f6\u523b\uff0c\u4e5f\u6709\u5f88\u591a\u7ebf\u7a0b\u76d1\u6d4b\u5230\u4e86\u6587\u4ef6\u5927\u5c0f\u8d85\u9650\u5236\uff0c\u6240\u4ee5\u8fd9\u65f6\n        \u90a3\u4e9b\u77e5\u9053\u8d85\u8fc7\u4e86\u9650\u5236\u7684\u7ebf\u7a0b\u5c31\u4f1a\u6539\u540d\u6587\u4ef6\uff0c\u7136\u540e\u4ee5\u8ffd\u52a0\u65b9\u5f0f\u91cd\u65b0\u6253\u5f00\u6587\u4ef6\uff0c\u8fd9\u6837\u5c31\u4f1a\u9020\u6210\n        \u6539\u540d\u540e\u7684\u6587\u4ef6\u7684\u5927\u5c0f\u6709\u7684\u5b57\u8282\u6570\u57280\u5b57\u8282\u8fd9\u4e2a\u8303\u56f4\uff0c\u6240\u4ee5\uff0c\u6211\u5f15\u5165\u4e86\u9501\u6765\u63a7\u5236\u3002\n        \"\"\"\n        with self.lock:\n            if getsize(self.fileName) >= 1024 * 1024 * 1024:\n                # \u5173\u95ed\u6587\u4ef6\n                self.__f.close()\n                # \u6539\u540d\n                rename(self.fileName, self.fileName + '_' + str(get_current_timestamp()))\n                # \u91cd\u65b0\u521b\u5efa\u65e5\u5fd7\n                self.__f = open(self.fileName, 'a')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef log(self, message):\n        theLog = '[\u65e5\u5fd7\u540d:%s] [\u65f6\u95f4:%s] \\n[\u5185\u5bb9:\\n%s]\\n\\n' % (\n                self.startName, timestamp_to_time(get_current_timestamp()),  message)\n        if not self.fileName:\n            print(theLog)\n        else:\n            # \u7531\u4e8e\u8fd9\u91cc\u6709\u5f88\u591a\u7684\u7ebf\u7a0b\u90fd\u8981\u7ecf\u8fc7\u8fd9\u9053\u7ebf\u7a0b\u9501\u7684\u63a7\u5236\uff0c\u6240\u4ee5\u4e0d\u4f1a\u51fa\u73b0\u95ee\u9898\n            self.check_log_file_size()\n            self.__f.write(theLog)", "response": "log message to file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _extract_zip(archive, dest=None, members=None):\n    # Python 2.5 compatibility.\n    dest = dest or os.getcwd()\n    members = members or archive.infolist()\n\n    for member in members:\n        if isinstance(member, basestring):\n            member = archive.getinfo(member)\n\n        _extract_zip_member(archive, member, dest)", "response": "Extract the ZipInfo object to a real file on the path targetpath."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_parser():\n    p = optparse.OptionParser()\n    p.add_option('--prefix', metavar='DIR', help='install SDK in DIR')\n    p.add_option('--bindir', metavar='DIR', help='install tools in DIR')\n    p.add_option('--force', action='store_true', default=False,\n        help='over-write existing installation')\n    p.add_option('--no-bindir', action='store_true', default=False,\n        help='do not install tools on DIR')\n\n    return p", "response": "Returns a new option parser."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_args(argv):\n    parser = make_parser()\n\n    opts, args = parser.parse_args(argv[1:])\n\n    # Use APPENGINEPY_SDK_VERSION if set.\n    if not args and (sdk_version_key in os.environ):\n        args = (os.environ[sdk_version_key],)\n\n    return opts, args", "response": "Returns a tuple of opts and args for arguments."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_version(url=VERSION_URL):\n    for line in get(url):\n        if 'release:' in line:\n            return line.split(':')[-1].strip(' \\'\"\\r\\n')", "response": "Returns the version string for the latest SDK."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a filename or URL for the SDK name.", "response": "def parse_sdk_name(name):\n    \"\"\"Returns a filename or URL for the SDK name.\n\n    The name can be a version string, a remote URL or a local path.\n    \"\"\"\n    # Version like x.y.z, return as-is.\n    if all(part.isdigit() for part in name.split('.', 2)):\n        return DOWNLOAD_URL % name\n\n    # A network location.\n    url = urlparse.urlparse(name)\n    if url.scheme:\n        return name\n\n    # Else must be a filename.\n    return os.path.abspath(name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen the SDK from the URL.", "response": "def open_sdk(url):\n    \"\"\"Open the SDK from the URL, which can be either a network location or\n    a filename path. Returns a file-like object open for reading.\n    \"\"\"\n    if urlparse.urlparse(url).scheme:\n        return _download(url)\n    else:\n        return open(url)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndownload an URL and returns a file - like object open for reading.", "response": "def _download(url):\n    \"\"\"Downloads an URL and returns a file-like object open for reading,\n    compatible with zipping.ZipFile (it has a seek() method).\n    \"\"\"\n    fh = StringIO()\n\n    for line in get(url):\n        fh.write(line)\n\n    fh.seek(0)\n    return fh"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreset the internal state of the message.", "response": "def reset(self):\n        '''Reset stream.'''\n        self._text = None\n        self._markdown = False\n        self._channel = Incoming.DEFAULT_CHANNEL\n        self._attachments = []\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets text content. :param text: text content. :param markdown: is markdown? Defaults to ``False``.", "response": "def with_text(self, text, markdown=None):\n        '''Set text content.\n\n        :param text: text content.\n        :param markdown: is markdown? Defaults to ``False``.\n        '''\n        self._text = text\n        self._markdown = markdown or False\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a message. :raises InvalidPayloadError:", "response": "def build_message(self):\n        '''Build a message.\n\n        :raises InvalidPayloadError:\n        '''\n        if self._text is None:\n            raise InvalidPayloadError('text is required')\n\n        message = {\n            'text': self._text,\n            'markdown': self._markdown\n        }\n\n        if self._channel != Incoming.DEFAULT_CHANNEL:\n            message['channel'] = self._channel\n\n        if self._attachments:\n            message['attachments'] = []\n            for attachment in self._attachments:\n                if 'title' not in attachment and 'text' not in attachment:\n                    raise InvalidPayloadError('title or text is required')\n                message['attachments'].append(attachment)\n\n        return message"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_factory(name, directory, configuration=None):\n    for entry_point in pkg_resources.iter_entry_points(ENTRY_POINT):\n        if entry_point.name == name:\n            factory_class = entry_point.load(require=False)\n            return factory_class(directory, configuration)\n\n    raise KeyError", "response": "Load a factory and have it initialize in a particular directory"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncrop an image to a specified threshold.", "response": "def crop_image(image, threshold):\n    \"\"\"\n    \u041d\u0430\u0439\u0442\u0438 \u043d\u0435\u043f\u0440\u043e\u0437\u0440\u0430\u0447\u043d\u0443\u044e \u043e\u0431\u043b\u0430\u0441\u0442\u044c \u043d\u0430 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0438 \u0438 \u0432\u044b\u0440\u0435\u0437\u0430\u0442\u044c \u0435\u0451\n    :param image: \u0418\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435\n    :param threshold: \u041f\u043e\u0440\u043e\u0433 \u043f\u0440\u043e\u0437\u0440\u0430\u0447\u043d\u043e\u0441\u0442\u0438 \u0434\u043b\u044f \u043e\u0431\u0440\u0435\u0437\u0430\u043d\u0438\u044f\n    :return: cropped_image - \u0432\u044b\u0440\u0435\u0437\u0430\u043d\u043d\u043e\u0435 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435\n             x, y, width, height - \u043a\u043e\u043e\u0440\u0434\u0438\u043d\u0430\u0442\u044b \u0438 \u0440\u0430\u0437\u043c\u0435\u0440 \u0432\u044b\u0440\u0435\u0437\u0430\u043d\u043d\u0433\u043e \u043f\u0440\u044f\u043c\u043e\u0443\u0433\u043e\u043b\u044c\u043d\u0438\u043a\u0430\n    \"\"\"\n    cropper = CropTransparent(image.width(), image.height(), threshold, str(image.constBits()))\n    x = cropper.getCroppedOffsetX()\n    y = cropper.getCroppedOffsetY()\n    width = cropper.getCroppedWidth()\n    height = cropper.getCroppedHeight()\n\n    cropped_image = image.copy(x, y, width, height)\n\n    return cropped_image, x, y, width, height"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _convert_bases_to_mixins(self, mcs_args: McsArgs):\n        def _mixin_name(name):\n            return f'{name}_FSQLAConvertedMixin'\n\n        new_base_names = set()\n        new_bases = []\n        for b in reversed(mcs_args.bases):\n            if b.__name__ not in self._registry:\n                if b not in new_bases:\n                    new_bases.append(b)\n                continue\n\n            _, base_name, base_bases, base_clsdict = \\\n                self._registry[b.__name__][b.__module__]\n\n            for bb in reversed(base_bases):\n                if f'{bb.__module__}.{bb.__name__}' in self._base_model_classes:\n                    if bb not in new_bases:\n                        new_bases.append(bb)\n                elif (bb.__name__ not in new_base_names\n                        and _mixin_name(bb.__name__) not in new_base_names):\n                    new_base_names.add(bb.__name__)\n                    new_bases.append(bb)\n\n            clsdict = {}\n            for attr, value in base_clsdict.items():\n                if attr in {'__name__', '__qualname__'}:\n                    continue\n\n                has_fk = isinstance(value, sa.Column) and value.foreign_keys\n                if has_fk or isinstance(value, MapperProperty):\n                    # programmatically add a method wrapped with declared_attr\n                    # to the new mixin class\n                    exec(f\"\"\"\\\n@declared_attr\ndef {attr}(self):\n    return value\"\"\", {'value': value, 'declared_attr': declared_attr}, clsdict)\n                else:\n                    clsdict[attr] = value\n\n            mixin_name = _mixin_name(base_name)\n            new_bases.append(type(mixin_name, (object,), clsdict))\n            new_base_names.add(mixin_name)\n\n        mcs_args.bases = tuple(reversed(new_bases))", "response": "Convert base classes to mixins."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(self, key, *args, **kwargs):\n        instance = self._class(key, *args, **kwargs)\n        self._events.create.trigger(list=self, instance=instance, key=key, args=args, kwargs=kwargs)\n        return self.insert(instance)", "response": "Creates and inserts an identified object using the specified class."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninsert an already - created identified object of the expected class.", "response": "def insert(self, identified):\n        \"\"\"\n        Inserts an already-created identified object of the expected class.\n        \"\"\"\n\n        if not isinstance(identified, self._class):\n            raise self.Error(\"Passed instance is not of the needed class\",\n                             self.Error.INVALID_INSTANCE_CLASS, instance=identified)\n\n        try:\n            if self._objects[identified.key] != identified:\n                raise self.Error(\"Passes instance's key '%s' is already occupied\" % identified.key,\n                                 self.Error.KEY_EXISTS, key=identified.key, instance=identified)\n        except KeyError:\n            self._objects[identified.key] = identified\n            self._events.insert.trigger(list=self, instance=identified)\n        return identified"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves an already - created identified object from the record.", "response": "def remove(self, identified):\n        \"\"\"\n        Removes an already-created identified object.\n        A key may be passed instead of an identified object.\n        If an object is passed, and its key is held by another\n            object inside the record, an error is triggered.\n        Returns the removed object.\n        \"\"\"\n\n        by_val = isinstance(identified, Identified)\n        if by_val:\n            key = identified.key\n            if not isinstance(identified, self._class):\n                raise self.Error(\"Such instance could never exist here\",\n                                 self.Error.INVALID_INSTANCE_CLASS, instance=identified)\n        else:\n            key = identified\n\n        try:\n            popped = self._objects.pop(key)\n            if by_val and popped != identified:\n                raise self.Error(\"Trying to pop a different object which also has key '%s'\" % popped.key,\n                                 self.Error.NOT_SAME_OBJECT, instance=identified, current=popped)\n            self._events.remove.trigger(list=self, instance=identified, by_val=by_val)\n        except KeyError:\n            raise self.Error(\"No object with key '%s' exists here\",\n                             self.Error.KEY_NOT_EXISTS, key=key, instance=identified if by_val else None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef timeout_deferred(deferred, timeout, error_message=\"Timeout occured\"):\n    \n    timeout_occured = [False]\n    \n    def got_result(result):\n        if not timeout_occured[0]:\n            # Deferred called back before the timeout.\n            delayedCall.cancel()\n            return result\n        else:\n            if isinstance(result, failure.Failure) and result.check(defer.CancelledError):\n                # Got a `CancelledError` after we called  `cancel()`.\n                # Replace it with a `TimeoutError`.\n                raise TimeoutError(error_message)\n            else:\n                # Apparently the given deferred has something else to tell us.\n                # It might be that it completed before the `cancel()` had an effect\n                # (or as a result thereof). It might also be that it triggered an\n                # error. In either case, we want this to be visible down-stream.\n                return result\n    \n    def time_is_up():\n        timeout_occured[0] = True\n        deferred.cancel()\n    delayedCall = reactor.callLater(timeout, time_is_up)\n\n    deferred.addBoth(got_result)\n    return deferred", "response": "Waits a given time for a given deferred to be cancelled."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if valid http auth credentials are found in the request header.", "response": "def http_auth(self):\n        \"\"\"\n        Returns ``True`` if valid http auth credentials are found in the\n        request header.\n\n        \"\"\"\n        if 'HTTP_AUTHORIZATION' in self.request.META.keys():\n            authmeth, auth = self.request.META['HTTP_AUTHORIZATION'].split(\n                ' ', 1)\n            if authmeth.lower() == 'basic':\n                auth = auth.strip().decode('base64')\n                identifier, password = auth.split(':', 1)\n                username = get_username(identifier)\n                user = authenticate(username=username, password=password)\n                if user:\n                    login(self.request, user)\n                    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init(self, db=RDB_DB, host=RDB_HOST, port=RDB_PORT):\n        self.RDB_HOST = host\n        self.RDB_PORT = port\n        self.RDB_DB = db\n\n        from .connection import RethinkDB\n        self.rdb = RethinkDB()\n        self.rdb.init()", "response": "Create the Frink object to store the connection credentials."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_field(source, loc, tokens):\n    name = tokens[0].lower()\n    value = normalize_value(tokens[2])\n    if name == 'author' and ' and ' in value:\n        value = [field.strip() for field in value.split(' and ')]\n    return (name, value)", "response": "Parse a field from the tokens."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_entry(source, loc, tokens):\n    type_ = tokens[1].lower()\n    entry_type = structures.TypeRegistry.get_type(type_)\n    if entry_type is None or not issubclass(entry_type, structures.Entry):\n        raise exceptions.UnsupportedEntryType(\n                \"%s is not a supported entry type\" % type_\n            )\n    new_entry = entry_type()\n    new_entry.name = tokens[3]\n    for key, value in [t for t in tokens[4:-1] if t != ',']:\n        new_entry[key] = value\n    return new_entry", "response": "Parses the tokens of an entry into an Entry instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a Bibliography from a source file.", "response": "def parse_bibliography(source, loc, tokens):\n    \"\"\"\n    Combines the parsed entries into a Bibliography instance.\n    \"\"\"\n    bib = structures.Bibliography()\n    for entry in tokens:\n        bib.add(entry)\n    return bib"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_string(str_, validate=False):\n    result = pattern.parseString(str_)[0]\n    if validate:\n        result.validate()\n    return result", "response": "Tries to parse a given string into a Bibliography instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrying to parse a given filepath or fileobj into a Bibliography instance.", "response": "def parse_file(file_or_path, encoding='utf-8', validate=False):\n    \"\"\"\n    Tries to parse a given filepath or fileobj into a Bibliography instance. If\n    ``validate`` is passed as keyword argument and set to ``True``, the\n    Bibliography will be validated using the standard rules.\n    \"\"\"\n    try:\n        is_string = isinstance(file_or_path, basestring)\n    except NameError:\n        is_string = isinstance(file_or_path, str)\n    if is_string:\n        with codecs.open(file_or_path, 'r', encoding) as file_:\n            result = pattern.parseFile(file_)[0]\n    else:\n        result = pattern.parseFile(file_or_path)[0]\n    if validate:\n        result.validate()\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef connection_made(self, transport: asyncio.transports.Transport):\n        self._transport = transport\n        self._remote_host = self._transport.get_extra_info('peername')\n        self._extra = {\"client\": str(self._remote_host)}\n        self.connections.add(self)\n\n        self._stream_reader = asyncio.StreamReader(loop=self._loop)\n        self._stream_writer = asyncio.StreamWriter(transport, self,\n                                                   self._stream_reader,\n                                                   self._loop)\n        super().connection_made(transport)\n        if self.timeout:\n            self._timeout_handler = self._loop.call_soon(\n                self.timeout_callback)\n        self._handlertask = asyncio.ensure_future(self.query_handler())\n        if self.debug:\n            access_logger.info(\"connected\", extra=self._extra)", "response": "This method is called when a new connection is made."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connection_lost(self, exc: Exception=None):\n        self._handlertask.cancel()\n\n        super().connection_lost(exc)\n        if self._timeout_handler:\n            self._timeout_handler.cancel()\n        self._transport = None\n        for i, task in self.tasks.items():\n            task.cancel()\n        self.connections.discard(self)\n        if self.debug:\n            access_logger.info(\"lost connection\", extra=self._extra)", "response": "Called by the exception handler when the connection is lost."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef timeout_callback(self):\n        # Check if elapsed time since last response exceeds our configured\n        # maximum keep alive timeout value\n        now = time()\n        time_elapsed = now - self._last_response_time\n        if time_elapsed < self.timeout:\n            time_left = self.timeout - time_elapsed\n            self._timeout_handler = (\n                self._loop.call_later(\n                    time_left,\n                    self.timeout_callback\n                )\n            )\n        else:\n            logger.info('KeepAlive Timeout. Closing connection.')\n            responseb = self.encoder({\n                \"MPRPC\": self.VERSION,\n                \"CODE\": 504\n            })\n            self._stream_writer.write(responseb)\n            self.close()", "response": "This is the callback function that is called when the keep alive timeout is reached."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef writer(self, response: Dict[str, Any]):\n        responseb = self.encoder(response)\n        self._stream_writer.write(responseb)\n        if self.debug:\n            access_logger.info(\"write {}\".format(responseb), extra=self._extra)\n        self._last_response_time = time()", "response": "Write a response to the stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a single record from the stream", "response": "async def read(self):\n        \"\"\"\u8bfb\u53d6\u8bf7\u6c42,\u5e76\u8f6c\u5316\u4e3apython\u7684\u5b57\u5178\u7ed3\u6784.\u5982\u679c\u8bfb\u5165\u4e86EOF,\u90a3\u4e48\u89e6\u53d1\u56de\u8c03\u51fd\u6570connection_lost.\"\"\"\n        try:\n            data = await self._stream_reader.readuntil(self.SEPARATOR)\n        except asyncio.IncompleteReadError:\n            self.connection_lost()\n        else:\n            query = self.decoder(data)\n            if self.debug:\n                access_logger.info(\"get query: {}\".format(\n                    query\n                ), extra=self._extra)\n            return query"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nquery the server for new messages.", "response": "async def query_handler(self):\n        \"\"\"\u6839\u636e\u83b7\u53d6\u5230\u7684\u4e0d\u540c\u8bf7\u6c42\u6267\u884c\u4e0d\u540c\u7684\u52a8\u4f5c.\u4f1a\u5728\u5efa\u7acb\u8fde\u63a5\u540e\u88ab\u653e\u5165\u4e8b\u4ef6\u5faa\u73af.\n\n        \u4e3b\u8981\u4e3a3\u79cd\u8bf7\u6c42:\n        + \u9a8c\u8bc1\u8bf7\u6c42\n        + \u5fc3\u8df3\u8bf7\u6c42\n        + \u4efb\u52a1\u8c03\u7528\u8bf7\u6c42\n        \u5982\u679c\u4e2d\u9014\u6709\u6b65\u9aa4\u62a5\u9519\u4e5f\u8d1f\u8d23\u5c06\u5bf9\u5e94\u7684\u9519\u8bef\u8f6c\u5316\u4e3a\u9519\u8bef\u4fe1\u606f\u53d1\u9001\u7ed9\u5ba2\u6237\u7aef.\n\n        \"\"\"\n        while True:\n            request = await self.read()\n            if request is None:\n                break\n            ID = request.get('ID')\n            try:\n                if request.get(\"AUTH\"):\n                    self._check_auth_handler(request)\n                elif request.get(\"HEARTBEAT\"):\n                    response = {\n                        \"MPRPC\": self.VERSION,\n                        \"CODE\": 101,\n                        \"HEARTBEAT\": \"pong\"\n                    }\n                    self.writer(response)\n                elif ID:\n                    fut = asyncio.ensure_future(\n                        self._RPC_handler(request),\n                        loop=self._loop)\n                    if asyncio.isfuture(fut):\n                        self.tasks[ID] = fut\n                        self.__class__.TASKS.append(fut)\n                else:\n                    raise ProtocolSyntaxException(\"Protocol Syntax Error\")\n            except MethodError as se:\n                exinfo = traceback.TracebackException.from_exception(\n                    se).format(chain=True)\n                frames = \"\".join([i + \"/n\" for i in exinfo])\n                response = {\n                    \"MPRPC\": self.VERSION,\n                    \"CODE\": se.status_code,\n                    \"MESSAGE\": {\n                        \"ID\": ID,\n                        'EXCEPTION': str(type(se)),\n                        'MESSAGE': str(se),\n                        \"DATA\": {\n                            'METHOD': request.get(\"METHOD\"),\n                            \"ARGS\": request.get(\"ARGS\"),\n                            \"KWARGS\": request.get(\"KWARGS\"),\n                            'FRAME': frames}\n                    }\n                }\n                self.writer(response)\n            except ServerException as me:\n                response = {\n                    \"MPRPC\": self.VERSION,\n                    \"CODE\": me.status_code,\n\n                }\n                self.writer(response)\n            except Exception as e:\n                if self.debug:\n                    logger.info(\"Unknow Error: {}[{}]\".format(\n                        type(e).__name__, str(e)\n                    ))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_auth_handler(self, request: Dict[str, Any]):\n        a_username = request.get(\"AUTH\").get(\"USERNAME\")\n        a_password = request.get(\"AUTH\").get(\"PASSWORD\")\n        auth_len = len(self.auth)\n        if auth_len == 0:\n            if any([a_username, a_password]):\n                if self.debug:\n                    access_logger.info(\"login failed\", extra=self._extra)\n                raise LoginError(\"login error ,unknown username/password\")\n            else:\n                return True\n        else:\n            for username, password in self.auth:\n                if all([a_username == username, a_password == password]):\n                    response = {\n                        \"MPRPC\": self.VERSION,\n                        \"CODE\": 100,\n                        \"VERSION\": self.method_wrapper.version,\n                        \"DESC\": self.method_wrapper.__doc__,\n                        \"DEBUG\": self.debug,\n                        \"COMPRESER\": self.compreser.__name__ if (\n                            self.compreser) else None,\n                        \"TIMEOUT\": self.timeout,\n                    }\n                    self.writer(response)\n                    if self.debug:\n                        access_logger.info(\"login succeed\", extra=self._extra)\n                    break\n            else:\n                if self.debug:\n                    access_logger.info(\"login failed\", extra=self._extra)\n                raise LoginError(\"login error ,unknown username/password\")\n            return True", "response": "Check if the user is authenticated."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def _RPC_handler(self, request: Dict[str, Any]):\n        ID = request.get(\"ID\")\n        method = request.get(\"METHOD\")\n        with_return = request.get(\"RETURN\")\n        args = request.get(\"ARGS\") or []\n        kwargs = request.get(\"KWARGS\") or {}\n        try:\n            if method is None:\n                raise RequestError(\n                    \"request do not have method\", request.get(\"ID\"))\n            if method == \"system.getresult\":\n                await self._get_result(ID, *args, **kwargs)\n            else:\n                result = await self.method_wrapper.apply(ID, method,\n                                                         *args, **kwargs)\n        except MethodError as se:\n            exinfo = traceback.TracebackException.from_exception(\n                se).format(chain=True)\n            frames = \"\".join([i + \"/n\" for i in exinfo])\n            response = {\n                \"MPRPC\": self.VERSION,\n                \"CODE\": se.status_code,\n                \"MESSAGE\": {\n                    \"ID\": ID,\n                    'EXCEPTION': str(type(se)),\n                    'MESSAGE': str(se),\n                    \"DATA\": {\n                        'METHOD': request.get(\"METHOD\"),\n                        \"ARGS\": request.get(\"ARGS\"),\n                        \"KWARGS\": request.get(\"KWARGS\"),\n                        'FRAME': frames}\n                }\n            }\n            self.writer(response)\n            return False\n        except ServerException as me:\n            response = {\n                \"MPRPC\": self.VERSION,\n                \"CODE\": me.status_code,\n            }\n            self.writer(response)\n            return False\n        except Exception as e:\n            if self.debug is True:\n                raise e\n            else:\n                logger.info(\n                    \"Task[{}]: Unknown Error {}:\\nmessage:{}\".format(\n                        ID, e.__class__.__name__, str(e))\n                )\n        else:\n            if with_return:\n                if inspect.isasyncgen(result):\n                    await self._asyncgen_wrap(result, ID)\n                else:\n                    response = {\n                        \"MPRPC\": self.VERSION,\n                        \"CODE\": 200,\n                        \"MESSAGE\": {\n                            \"ID\": ID,\n                            'RESULT': result\n                        }\n                    }\n                    self.writer(response)\n                    if self.debug:\n                        access_logger.info(\n                            \"Task[{}]: response answered\".format(ID),\n                            extra=self._extra\n                        )\n            return result", "response": "This is the main function that handles the RPC request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nending tracking of attributes changes. Returns the changes that occurred to the attributes.", "response": "def track_end(self):\n        \"\"\"\n        Ends tracking of attributes changes.\n        Returns the changes that occurred to the attributes.\n          Only the final state of each attribute is obtained\n        \"\"\"\n        self.__tracking = False\n        changes = self.__changes\n        self.__changes = {}\n        return changes"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef creationTime(item):\n    forThisItem = _CreationTime.createdItem == item\n    return item.store.findUnique(_CreationTime, forThisItem).timestamp", "response": "Returns the creation time of the given item."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef access_key(root, key, sep='.', default=None):\n    '''\n    Look up a key in a potentially nested object `root` by its `sep`-separated\n    path. Returns `default` if the key is not found.\n\n    Example:\n        access_key({'foo': {'bar': 1}}, 'foo.bar') -> 1\n    '''\n    props = key.split('.')\n    props.reverse()\n    while props and root:\n        prop = props.pop()\n        root = access(root, prop, default=default)\n    return root", "response": "Look up a key in a potentially nested object root by its sep - separated path. Returns default if the key is not found."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setup_parser():\n    '''Set up the command-line options.'''\n    p = argparse.ArgumentParser(description='Create and manage a \\\nSimplyStatic site.')\n    subparsers = p.add_subparsers(help='commands', dest='command')\n\n    # aliases are not supported in 2.7 for add_parser\n    # init command\n    init_cmd_parser = subparsers.add_parser('init',\n                        help=\"Initialize a SimplyStatic directory structure\")\n\n    init_cmd_parser.add_argument('-d', '--dirname', action='store',\n                                 help='Directory to initialize')\n\n    init_cmd_parser.add_argument('-r', '--randomsite', action='store_true',\n                                 help='Add random pages to the site (useful for testing)')\n\n    init_cmd_parser.add_argument('-n', '--numpages', action='store',type=int, default = 20,\n                                 help='Number of random pages to add to the site.')\n\n    # add command\n    add_cmd_parser = subparsers.add_parser('add',\n                                           help='Add a page to the site.')\n    add_cmd_parser.add_argument('title', help=\"Title for the page\",\n                                action='store')\n\n    add_cmd_parser.add_argument('-d', '--dirname',\n        help=\"Directory of site root, or any place under site root.\",\n        action='store')\n\n    generate_cmd_parser = subparsers.add_parser('gen',\n                                           help='Generates the site.')\n    generate_cmd_parser.add_argument('-d', '--dirname',\n        help=\"Directory of site root, or any place under site root.\",\n        action='store')\n\n    # rename command\n    rename_cmd_parser = subparsers.add_parser('rename',\n                                    help='Renames a page in the site.')\n    rename_cmd_parser.add_argument('slug', \n                            help=\"Slug of the page to be renamed\",\n                            action='store')\n    rename_cmd_parser.add_argument('newtitle',\n                help=\"New title in quotes (*NOT* a slug) for the page.\",\n                action='store')\n    rename_cmd_parser.add_argument('-d', '--dirname', \n            help=\"Directory of site root, or any place under site root.\",\n            action='store')\n\n    # servecommand\n\n    serve_cmd_parser = subparsers.add_parser('serve',\n                                    help='Serves the site on localhost.')\n    serve_cmd_parser.add_argument('-p','--port', action='store', type=int, default = 8000,\n                                 help='Port for the server.')\n\n    serve_cmd_parser.add_argument('-i','--ip', action='store', default = '127.0.0.1',\n                                 help='IP address for the server.')\n\n    # ls command\n    ls_cmd_parser = subparsers.add_parser('ls',\n                        help=\"List pages, drafts, or most recently edited page.\")\n\n    ls_cmd_parser.add_argument('-d', '--dirname',\n        help=\"Directory of site root, or any place under site root.\",\n        action='store')\n\n    ls_cmd_parser.add_argument('-f', '--drafts', action='store_true',\n                                   help='List pages whose status is draft.')\n\n    ls_cmd_parser.add_argument('-r', '--recent', action='store_true',\n                                 help='List the most recently edited page.')\n\n\n    return p", "response": "Setup the command - line options."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dispatch(argdict):\n    '''Call the command-specific function, depending on the command.'''\n    cmd = argdict['command']\n    ftc = getattr(THIS_MODULE, 'do_'+cmd)\n    ftc(argdict)", "response": "Call the command - specific function depending on the command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_init(argdict):\n    '''Create the structure of a s2site.'''\n    site = make_site_obj(argdict)\n    try:\n        site.init_structure()\n        print \"Initialized directory.\"\n        if argdict['randomsite']:\n            #all_tags = ['tag1','tag2','tag3','tag4']\n            for i in range(1,argdict['numpages']+1):\n                #ptags = random.sample(all_tags,random.randint(1,len(all_tags)))\n                p = site.random_page()\n                p.set_published()\n                p.write()\n                print \"added page \",p.slug\n    except ValueError: # pragma: no cover\n        print \"Cannot create structure. You're already within an s2 \\\ntree, or the directory is not empty or it is not writeable. \"", "response": "Create the structure of a s2site."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_add(argdict):\n    '''Add a new page to the site.'''\n    site = make_site_obj(argdict)\n    if not site.tree_ready:\n        print \"Cannot add page. You are not within a simplystatic \\\ntree and you didn't specify a directory.\"\n        sys.exit()\n    title = argdict['title']\n    try: \n        new_page = site.add_page(title)\n        new_page.write()\n        print \"Added page '\"+ title + \"'\"\n    except ValueError as e: # pragma: no cover\n        print \"Attempted to create a page which already exists.\"\n        sys.exit()", "response": "Add a new page to the site."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_gen(argdict):\n    '''Generate the whole site.'''\n    site = make_site_obj(argdict)\n    try:\n        st = time.time()\n        site.generate()\n        et = time.time()\n        print \"Generated Site in %f seconds.\"% (et-st)\n    except ValueError as e: # pragma: no cover\n        print \"Cannot generate. You are not within a simplystatic \\\ntree and you didn't specify a directory.\"", "response": "Generate the whole site."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_serve(argdict):\n    '''Serve the site on localhost, for testing/development.'''\n    site = make_site_obj(argdict)\n    os.chdir(site.dirs['www'])\n\n    HandlerClass = SimpleHTTPRequestHandler\n    ServerClass  = BaseHTTPServer.HTTPServer\n    Protocol     = \"HTTP/1.0\"\n    server_address = (argdict['ip'], argdict['port'])\n    HandlerClass.protocol_version = Protocol\n    httpd = ServerClass(server_address, HandlerClass)\n\n    sa = httpd.socket.getsockname()\n    print \"Serving HTTP on\", sa[0], \"port\", sa[1], \"...\"\n    httpd.serve_forever()", "response": "Serve the site on localhost for testing and development."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getbydatatype(data_type, besteffort=True):\n    return _REGISTRY.getbydatatype(data_type=data_type, besteffort=besteffort)", "response": "Get schema class by data type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register(self, schema):\n        result = None\n\n        uuid = schema.uuid\n\n        if uuid in self._schbyuuid:\n            result = self._schbyuuid[uuid]\n\n        if result != schema:\n\n            self._schbyuuid[uuid] = schema\n\n            name = schema.name\n\n            schemas = self._schbyname.setdefault(name, set())\n\n            schemas.add(schema)\n\n            for innername, innerschema in iteritems(schema.getschemas()):\n\n                if innerschema.uuid not in self._schbyuuid:\n                    register(innerschema)\n\n        return result", "response": "Register input schema class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering schema class with associated data types.", "response": "def registercls(self, data_types, schemacls=None):\n        \"\"\"Register schema class with associated data_types.\n\n        Can be used such as a decorator.\n\n        :param list data_types: data types to associate with schema class.\n        :param type schemacls: schema class to register.\n        :return: schemacls.\n        :rtype: type\n        \"\"\"\n        if schemacls is None:\n            return lambda schemacls: self.registercls(\n                data_types=data_types, schemacls=schemacls\n            )\n\n        for data_type in data_types:\n            self._schbytype[data_type] = schemacls\n\n        return schemacls"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unregistercls(self, schemacls=None, data_types=None):\n        if schemacls is not None:\n\n            # clean schemas by data type\n            for data_type in list(self._schbytype):\n                _schemacls = self._schbytype[data_type]\n                if _schemacls is schemacls:\n                    del self._schbytype[data_type]\n\n        if data_types is not None:\n\n            for data_type in data_types:\n                if data_type in self._schbytype:\n                    del self._schbytype[data_type]", "response": "Unregister a schema class or associated data_types."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getbyuuid(self, uuid):\n        if uuid not in self._schbyuuid:\n            raise KeyError('uuid {0} not registered'.format(uuid))\n\n        return self._schbyuuid[uuid]", "response": "Get a schema by uuid."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getbyname(self, name):\n        if name not in self._schbyname:\n            raise KeyError('name {0} not registered'.format(name))\n\n        return self._schbyname[name]", "response": "Get schemas by given name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getbydatatype(self, data_type, besteffort=True):\n        result = None\n\n        if data_type in self._schbytype:\n            result = self._schbytype[data_type]\n\n        elif besteffort:\n            for rdata_type in self._schbytype:\n                if issubclass(data_type, rdata_type):\n                    result = self._schbytype[rdata_type]\n                    break\n\n        return result", "response": "Get schema class by data type."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntruncates the table with the given name.", "response": "def truncate_table(self, tablename):\n        \"\"\"\n        SQLite3 doesn't support direct truncate, so we just use delete here\n        \"\"\"\n        self.get(tablename).remove()\n        self.db.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts logging with this logger.", "response": "def start(self, level=\"WARN\"):\n        \"\"\" Start logging with this logger.\n\n        Until the logger is started, no messages will be emitted. This applies\n        to all loggers with the same name and any child loggers.\n\n        Messages less than the given priority level will be ignored. The\n        default level is 'WARN', which conforms to the *nix convention that a\n        successful run should produce no diagnostic output. Available levels\n        and their suggested meanings:\n\n          DEBUG - output useful for developers\n          INFO - trace normal program flow, especially external interactions\n          WARN - an abnormal condition was detected that might need attention\n          ERROR - an error was detected but execution continued\n          CRITICAL - an error was detected and execution was halted\n\n        \"\"\"\n        if self.active:\n            return\n        handler = StreamHandler()  # stderr\n        handler.setFormatter(Formatter(self.LOGFMT))\n        self.addHandler(handler)\n        self.setLevel(level.upper())\n        self.active = True\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop(self):\n        if not self.active:\n            return\n        self.removeHandler(self.handlers[-1])\n        self.active = False\n        return", "response": "Stop logging with this logger."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a single string as traceback line", "response": "def parse_line(string):\n    \"\"\"Parse a single string as traceback line\"\"\"\n    match = line_regexp().match(string)\n    if match:\n        matches = match.groupdict()\n        line_number = matches['line_number']\n        path_to_python = matches['path_to_python']\n        spaceless_path_to_python = matches['spaceless_path_to_python']\n        if path_to_python:\n            return path_to_python, line_number\n        elif spaceless_path_to_python:\n            return spaceless_path_to_python, line_number"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms the action of the assessment.", "response": "def do_action(self, target, dry_run=False):\n        \"\"\"\n        :param target: Full path and filename\n        :param dry_run: True - don't actually perform action. False: perform action.\n        :return: filename: Full path and filename after action completes\n        \"\"\"\n        # Get full path to the file in the destination directory\n        new_filename = os.path.join(self.destination, os.path.basename(target))\n\n        # If the file exists in the destination directory, append _NNN to the name where NNN is\n        # a zero padded number. Starts at _001\n        while os.path.exists(new_filename):\n            # if filename ends in _NNN, start at that number\n            filename, extension = os.path.splitext(os.path.basename(new_filename))\n            if filename[-4] == '_' and filename[-3:].isdigit():\n                # Split the number off the filename and increment it, handle suffixes longer than 3 numbers\n                current = filename.split('_')[-1]\n                filename_root = filename[0:-len(current)-1]\n                current = int(current) + 1\n                new_filename = os.path.join(self.destination,\n                                            (filename_root +\n                                             \"_{0:03d}\".format(current) +\n                                             extension))\n            else:\n                # No number suffix found in the filename, just start at _001\n                new_filename = os.path.join(self.destination,\n                                            (filename + \"_001\" + extension))\n\n        if dry_run is False:\n            self.logger.debug(\"Moving {0} to {1}\".format(target, new_filename))\n\n            if not os.path.exists(new_filename):\n                try:\n                    shutil.move(target, new_filename)\n                except IOError:\n                    self.logger.error(\"Error moving file {0} to {1}\".format(target, self.destination))\n                    raise IOError\n            else:\n                self.logger.error(\"Destination file already exists: {0}\".format(new_filename))\n                raise IOError\n\n            return new_filename\n\n        else:\n            self.logger.debug(\"Dry run. Skipping move {0} to {1}\".format(target, new_filename))\n            return target"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sftp_upload_window_size_set(srv,file, method_to_call='put'):\n    '''\n    sets config for uploading files with pysftp\n    '''\n    channel = srv.sftp_client.get_channel()\n    channel.lock.acquire()\n    channel.out_window_size += os.stat(file).st_size * 1.1   # bit more bytes incase packet loss\n    channel.out_buffer_cv.notifyAll()\n    channel.lock.release()", "response": "Sets the size of the file to be used for uploading files with pysftp\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plotit(self):\n        '''\n        Produce the plots requested in the Dynac input file.  This makes the same\n        plots as produced by the Dynac ``plotit`` command.\n        '''\n        [self._plot(i) for i in range(len(self.plots))]", "response": "Produce the plots requested in the Dynac input file. This makes the same\n        plots as produced by the plotit command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninput must be hex string, and a valid compressed public key. Check if it's a valid key first, using the validatepubkey() function below, and then verify that the str len is 66.", "response": "def uncompress(pub):\n    '''\n    Input must be hex string, and a valid compressed public key.\n    Check if it's a valid key first, using the validatepubkey()\n    function below, and then verify that the str len is 66.\n    '''\n\n    yp = int(pub[:2],16) - 2\n    x = int(pub[2:],16)\n    a = (pow_mod(x,3,P) + 7) % P\n    y = pow_mod(a, (P+1)//4, P)\n    if y % 2 != yp:\n        y = -y % P\n    x = dechex(x,32)\n    y = dechex(y,32)\n    return '04' + x + y"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compress(pub):\n    '''\n    Input must be hex string, and a valid uncompressed public key.\n    Check if it's a valid key first, using the validatepubkey()\n    function below, and then verify that the str len is 130.\n    '''\n\n    x = pub[2:66]\n    y = pub[66:]\n    if int(y,16) % 2:\n        o = str('03') + str(x)\n    else:\n        o = str('02') + str(x)\n    return o", "response": "Compress a public key into a base - 16 encoded string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef privtopub(priv,outcompressed=True):\n    '''\n    Input must be 64-char hex string\n    '''\n\n    x, y = ecmultiply(Gx,Gy,int(priv,16))\n    x = dechex(x,32)\n    y = dechex(y,32)\n    o = '04' + x + y\n    if outcompressed:\n        return compress(o)\n    else:\n        return o", "response": "Return a private key in the format of a 32 - char hex string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsubtract two private keys from the end of the input string.", "response": "def subtractprivkeys(p1,p2):\n    '''\n    Input must be 64-char hex string\n    '''\n\n    return dechex(((int(p1,16) + (N - int(p2,16))) % N),32)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninputting pubkey must be hex string and valid pubkey. Input privkey must be 64-char hex string. Pubkey input can be compressed or uncompressed, as long as it's a valid key and a hex string. Use the validatepubkey() function to validate the public key first. The compression of the input public key does not do anything or matter in any way.", "response": "def multiplypub(pub,priv,outcompressed=True):\n    '''\n    Input pubkey must be hex string and valid pubkey.\n    Input privkey must be 64-char hex string.\n\n    Pubkey input can be compressed or uncompressed, as long as it's a\n    valid key and a hex string. Use the validatepubkey() function to\n    validate the public key first.  The compression of the input\n    public key does not do anything or matter in any way.\n    '''\n\n    if len(pub) == 66:\n        pub = uncompress(pub)\n    x, y = ecmultiply(int(pub[2:66],16),int(pub[66:],16),int(priv,16))\n    x = dechex(x,32)\n    y = dechex(y,32)\n    o = '04' + x + y\n    if outcompressed:\n        return compress(o)\n    else:\n        return o"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addpubs(p1,p2,outcompressed=True):\n    '''\n    Pubkey inputs can be compressed or uncompressed, as long as\n    they're valid keys and hex strings. Use the validatepubkey()\n    function to validate them first. The compression of the input\n    keys does not do anything or matter in any way. Only the\n    outcompressed bool dictates the compression of the output.\n    '''\n\n    if len(p1) == 66:\n        p1 = uncompress(p1)\n    if len(p2) == 66:\n        p2 = uncompress(p2)\n    x, y = ecadd(int(p1[2:66],16),int(p1[66:],16),\n                 int(p2[2:66],16),int(p2[66:],16))\n    x = dechex(x,32)\n    y = dechex(y,32)\n    o = '04' + x + y\n    if outcompressed:\n        return compress(o)\n    else:\n        return o", "response": "Add pubkeys p1 and p2 to the base36 key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsubtract two public keys from the current key.", "response": "def subtractpubs(p1,p2,outcompressed=True):\n    '''\n    Pubkey inputs can be compressed or uncompressed, as long as\n    they're valid keys and hex strings. Use the validatepubkey()\n    function to validate them first. The compression of the input\n    keys does not do anything or matter in any way. Only the\n    outcompressed bool dictates the compression of the output.\n    '''\n\n    if len(p1) == 66:\n        p1 = uncompress(p1)\n    if len(p2) == 66:\n        p2 = uncompress(p2)\n    x, y = ecsubtract(int(p1[2:66],16),int(p1[66:],16),\n                      int(p2[2:66],16),int(p2[66:],16))\n    x = dechex(x,32)\n    y = dechex(y,32)\n    o = '04' + x + y\n    if outcompressed:\n        return compress(o)\n    else:\n        return o"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validatepubkey(pub):\n    '''\n    Returns input key if it's a valid hex public key, or False\n    otherwise.\n\n    Input must be hex string, not bytes or integer/long or anything\n    else.\n    '''\n\n    try:\n        pub = hexstrlify(unhexlify(pub))\n    except:\n        return False\n    if len(pub) == 130:\n        if pub[:2] != '04':\n            return False\n        if uncompress(compress(pub)) != pub:\n            return False\n    elif len(pub) == 66:\n        if pub[:2] != '02' and pub[:2] != '03':\n            return False\n    else:\n        return False\n    return pub", "response": "Validate a public key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a WIF key to a tuple of 2 - char hex keys.", "response": "def wiftohex(wifkey):\n    '''\n    Returns a tuple of:\n    (64-char hex key, 2-char hex prefix for key, if it was compressed)\n    '''\n\n    iscompressed = False\n    wifkey = normalize_input(wifkey)\n    assert len(wifkey) == 50 or len(wifkey) == 51 or len(wifkey) == 52\n    for c in wifkey:\n        if c not in b58_digits:\n            raise Exception(\"Not WIF\")\n    key = b58d(wifkey)\n    prefix, key = key[:2], key[2:] \n    if len(key) == 66:\n        assert key[-2:] == '01'\n        key = key[:-2]\n        iscompressed = True\n    assert len(key) == 64\n    return key, prefix, iscompressed"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuses for getting unknown input type into a private key. For example, if you ask a user to input a private key, and they may input hex, WIF, integer, etc. Run it through this function to get a standardized format. Function either outputs private key hex string or raises an exception. It's really going to try to make any input into a private key, so make sure that whatever you import is indeed supposed to be a private key. For example, if you put an int in, it will turn that into a key. Make sure you want a key when you use this function!!!", "response": "def privtohex(key):\n    '''\n    Used for getting unknown input type into a private key.\n\n    For example, if you ask a user to input a private key, and they\n    may input hex, WIF, integer, etc. Run it through this function to\n    get a standardized format.\n\n    Function either outputs private key hex string or raises an\n    exception. It's really going to try to make any input into\n    a private key, so make sure that whatever you import is indeed\n    supposed to be a private key. For example, if you put an int in,\n    it will turn that into a key. Make sure you want a key when you\n    use this function!!!\n    '''\n\n    if isitint(key):\n        key = dechex(key,32)\n    else:\n        try:\n            key, z, zz = wiftohex(key)\n            assert len(key) == 64\n        except:\n            try:\n                key = unhexlify(key)\n            except:\n                try:\n                    key1 = hexstrlify(key)\n                    assert len(key1) == 64 or len(key1) == 66 or len(key1) == 68\n                    if len(key1) == 68:\n                        assert key1[-2:] == '01'\n                    key = key1\n                except:\n                    raise Exception(\"Cannot interpret input key.\")\n            else:\n                key = hexstrlify(key)\n    if len(key) == 68:\n        assert key[-2:] == '01'\n        key = key[:-2]\n    if len(key) == 66:\n        key = key[2:]\n    assert len(key) == 64\n    return key"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nnegate the vector part of the quaternion.", "response": "def conjugate_quat(quat):\n    \"\"\"Negate the vector part of the quaternion.\"\"\"\n    return Quat(-quat.x, -quat.y, -quat.z, quat.w)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns linear interpolation of two quaternions.", "response": "def lerp_quat(from_quat, to_quat, percent):\n    \"\"\"Return linear interpolation of two quaternions.\"\"\"\n\n    # Check if signs need to be reversed.\n    if dot_quat(from_quat, to_quat) < 0.0:\n        to_sign = -1\n    else:\n        to_sign = 1\n\n    # Simple linear interpolation\n    percent_from = 1.0 - percent\n    percent_to = percent\n\n    result = Quat(\n        percent_from * from_quat.x + to_sign * percent_to * to_quat.x,\n        percent_from * from_quat.y + to_sign * percent_to * to_quat.y,\n        percent_from * from_quat.z + to_sign * percent_to * to_quat.z,\n        percent_from * from_quat.w + to_sign * percent_to * to_quat.w)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nlerp_quat(from_quat, to_quat, percent):\n\n    result = lerp_quat(from_quat, to_quat, percent)\n    result.normalize()\n    return result", "response": "Return normalized linear interpolation of two quaternions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rotate_vec(self, vec):\n        xyz = Vec3(self.x, self.y, self.z)\n        return add_v3(vec, scale_v3(\n            xyz.cross(xyz.cross(vec) + scale_v3(vec, self.w)), 2.0))", "response": "rotate the vector by the vector vector"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning euler angles for the current species.", "response": "def to_euler_rad(self, dst_euler_vec3=None):\n        \"\"\"Returns euler angles\n\n        dst_euler_vec3 is an optional destination vector.\n        \"\"\"\n\n        euler_vec3 = dst_euler_vec3 or Vec3(0.0, 0.0, 0.0)\n\n        # TODO consolidated duplicated code in this function and to_euler_deg()\n        sqw = self.w * self.w\n        sqx = self.x * self.x\n        sqy = self.y * self.y\n        sqz = self.z * self.z\n\n        euler_vec3.z = math.atan2(2.0 * (self.x * self.y + self.z * self.w),\n                                  (sqx - sqy - sqz + sqw))\n        euler_vec3.x = math.atan2(2.0 * (self.y * self.z + self.x * self.w),\n                                  (-sqx - sqy + sqz + sqw))\n        euler_vec3.y = math.asin(-2.0 * (self.x * self.z - self.y * self.w))\n        return euler_vec3"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_from_matrix44(self, mat):\n\n        # Matrix trace\n        trace = mat.data[0][0] + mat.data[1][1] + mat.data[2][2] + 1.0\n\n        if trace > 0.00000001:\n            # n4 is norm of quaternion multiplied by 4.\n            n4 = math.sqrt(trace) * 2\n            self.x = (mat.data[1][2] - mat.data[2][1]) / n4\n            self.y = (mat.data[2][0] - mat.data[0][2]) / n4\n            self.z = (mat.data[0][1] - mat.data[1][0]) / n4\n            self.w = n4 / 4.0\n            return self\n\n        # TODO: unittests for code below when trace is small.\n\n        # matrix trace <= 0\n        if mat.data[0][0] > mat.data[1][1] and mat.data[0][0] > mat.data[2][2]:\n            s = 2.0 * math.sqrt(1.0 + mat.data[0][0] - mat.data[1][1] -\n                                mat.data[2][2])\n            self.x = s / 4.0\n            self.y = (mat.data[1][0] + mat.data[0][1]) / s\n            self.z = (mat.data[2][0] + mat.data[0][2]) / s\n            self.w = (mat.data[2][1] - mat.data[1][2]) / s\n            return self\n        elif mat.data[1][1] > mat.data[2][2]:\n            s = 2.0 * math.sqrt(1.0 - mat.data[0][0] + mat.data[1][1] -\n                                mat.data[2][2])\n            self.x = (mat.data[1][0] + mat.data[0][1]) / s\n            self.y = s / 4.0\n            self.z = (mat.data[2][1] + mat.data[1][2]) / s\n            self.w = (mat.data[2][0] - mat.data[0][2]) / s\n            return self\n        else:\n            s = 2.0 * math.sqrt(1.0 - mat.data[0][0] - mat.data[1][1] +\n                                mat.data[2][2])\n            self.x = (mat.data[2][0] + mat.data[0][2]) / s\n            self.y = (mat.data[2][1] + mat.data[1][2]) / s\n            self.z = s / 4.0\n            self.w = (mat.data[1][0] - mat.data[0][1]) / s\n            return self", "response": "Create a new Quat from a Matrix44."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef repeat_func(func: Callable[[], Union[T, Awaitable[T]]], times: int=None, *, interval: float=0) -> AsyncIterator[T]:\n    base = stream.repeat.raw((), times, interval=interval)\n    return cast(AsyncIterator[T], stream.starmap.raw(base, func, task_limit=1))", "response": "Repeat a function indefinitely."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef repeat_func_eof(func: Callable[[], Union[T, Awaitable[T]]], eof: Any, *, interval: float=0, use_is: bool=False) -> AsyncIterator[T]:\n    pred = (lambda item: item != eof) if not use_is else (lambda item: (item is not eof))\n    base = repeat_func.raw(func, interval=interval)\n    return cast(AsyncIterator[T], stream.takewhile.raw(base, pred))", "response": "Repeat a function until an EOF item is reached."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an asynchronous iterator that yields items from the given queue until an item equal to the given eof value is encountered.", "response": "def stream_from_queue(queue: asyncio.Queue, eof: Any=__DEFAULT, *, use_is: bool=False) -> AsyncIterator[Any]:\n    \"\"\"\n    Repeatedly gets an item from the given queue, until an item equal to `eof` (using `==` or `is`) is encountered.\n    If no `eof` is given, the stream does not stop.\n    \"\"\"\n    if eof is not __DEFAULT:\n        return cast(AsyncIterator[Any], repeat_func_eof(queue.get, eof, use_is=use_is))\n    else:\n        return cast(AsyncIterator[Any], repeat_func(queue.get))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _stringlist(*args):\n    return list(itertools.chain.from_iterable(itertools.repeat(x,1) if stringy(x) else x for x in args if x))", "response": "Takes a list of strings or strings and flatten these into\n    a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing an outgoing mail and put it into the OUTBOX.", "response": "def _parse_outgoing_mail(sender, to, msgstring):\n    \"\"\"\n    Parse an outgoing mail and put it into the OUTBOX.\n\n\n    Arguments:\n    - `sender`: str\n    - `to`: str\n    - `msgstring`: str\n\n    Return: None\n    Exceptions: None\n    \"\"\"\n    global OUTBOX\n    OUTBOX.append(email.message_from_string(msgstring))\n    return"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts ourself to a message part of the appropriate MIME type.", "response": "def as_msg(self):\n        \"\"\"\n        Convert ourself to be a message part of the appropriate\n        MIME type.\n\n        Return: MIMEBase\n        Exceptions: None\n        \"\"\"\n        # Based upon http://docs.python.org/2/library/email-examples.html\n        # with minimal tweaking\n\n        # Guess the content type based on the file's extension.  Encoding\n        # will be ignored, although we should check for simple things like\n        # gzip'd or compressed files.\n        ctype, encoding = mimetypes.guess_type(str(self.path))\n        if ctype is None or encoding is not None:\n            # No guess could be made, or the file is encoded (compressed), so\n            # use a generic bag-of-bits type.\n            ctype = 'application/octet-stream'\n        maintype, subtype = ctype.split('/', 1)\n        if maintype == 'text':\n            # Note: we should handle calculating the charset\n            msg = MIMEText(self.path.read(), _subtype=subtype)\n        elif maintype == 'image':\n            fp = self.path.open('rb')\n            msg = MIMEImage(fp.read(), _subtype=subtype)\n            fp.close()\n        elif maintype == 'audio':\n            fp = self.path.open('rb')\n            msg = MIMEAudio(fp.read(), _subtype=subtype)\n            fp.close()\n        else:\n            fp = self.path.open('rb')\n            msg = MIMEBase(maintype, subtype)\n            msg.set_payload(fp.read())\n            fp.close()\n            # Encode the payload using Base64\n            encoders.encode_base64(msg)\n\n        filename = str(self.path[-1])\n        msg.add_header('Content-Disposition', 'attachment', filename=filename)\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of unicoded strings", "response": "def tolist(self, to):\n        \"\"\"\n        Make sure that our addressees are a unicoded list\n\n        Arguments:\n        - `to`: str or list\n\n        Return: [u, ...]\n        Exceptions: None\n        \"\"\"\n        return ', '.join(isinstance(to, list) and [u(x) for x in to] or [u(to)])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sanity_check(self, sender, to, subject, plain=None, html=None, cc=None, bcc=None):\n        if not plain and not html:\n            raise NoContentError()", "response": "Sanity check the message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send(self, sender, to, subject, plain=None, html=None, cc=None, bcc=None,\n             replyto=None, attach=None):\n        \"\"\"\n        Send the message.\n\n        If we have PLAIN and HTML versions, send a multipart alternative\n        MIME message, else send whichever we do have.\n\n        If we have neither, raise NoContentError\n\n        Arguments:\n        - `sender`: str\n        - `to`: list\n        - `subject`: str\n        - `plain`: str\n        - `html`: str\n        - `cc`: str or [str]\n        - `bcc`: str or [str]\n        - `replyto`: str\n        - `attach`: str or [str]\n\n        Return: None\n        Exceptions: NoContentError\n        \"\"\"\n        self.sanity_check(sender, to, subject, plain=plain, html=html)\n        # Create message container - the correct MIME type is multipart/alternative.\n        msg = MIMEMultipart('mixed')\n        msg['Subject'] = u(subject)\n        msg['From']    = u(sender)\n        msg['To']      = self.tolist(to)\n        if cc:\n            msg['Cc']      = self.tolist(cc)\n\n        recipients = _stringlist(to, cc, bcc)\n\n        if replyto:\n            msg.add_header('reply-to', replyto)\n\n        # Attach parts into message container.\n        # According to RFC 2046, the last part of a multipart message, in this case\n        # the HTML message, is best and preferred.\n        if plain:\n            msg.attach(MIMEText(u(plain), 'plain'))\n        if html:\n            msg.attach(MIMEText(u(html), 'html'))\n\n        # Deal with attachments.\n        if attach:\n            for p in _stringlist(attach):\n                msg.attach(Attachment(p).as_msg())\n\n        self.deliver(msg, recipients)", "response": "Sends a message to the list of recipients."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deliver(self, message, to):\n        # Send the message via local SMTP server.\n        s = smtplib.SMTP(self.host, self.port)\n        # sendmail function takes 3 arguments: sender's address, recipient's address\n        # and message to send - here it is sent as one string.\n        s.sendmail(message['From'], to, message.as_string())\n        s.quit()\n        return", "response": "Deliver a message to the local server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deliver(self, message, to):\n        # Send the message via local SMTP server.\n        s = smtplib.SMTP(self.host, self.port)\n        s.ehlo()\n        s.starttls()\n        s.login(self.user, self.pw)\n        # sendmail function takes 3 arguments: sender's address, recipient's address\n        # and message to send - here it is sent as one string.\n        s.sendmail(message['From'], to, message.as_string())\n        s.quit()\n        return", "response": "Deliver a message to the local server."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend the message. If we have PLAIN and HTML versions, send a multipart alternative MIME message, else send whichever we do have. If we have neither, raise NoContentError Arguments: - `sender`: str - `to`: list - `subject`: str - `plain`: str - `html`: str - `attach`: str or iterable of str - `replyto`: str Return: None Exceptions: NoContentError", "response": "def send(self, sender, to, subject, plain=None, html=None, cc=None, bcc=None,\n             attach=None, replyto=None):\n        \"\"\"\n        Send the message.\n\n        If we have PLAIN and HTML versions, send a multipart alternative\n        MIME message, else send whichever we do have.\n\n        If we have neither, raise NoContentError\n\n        Arguments:\n        - `sender`: str\n        - `to`: list\n        - `subject`: str\n        - `plain`: str\n        - `html`: str\n        - `attach`: str or iterable of str\n        - `replyto`: str\n\n        Return: None\n        Exceptions: NoContentError\n        \"\"\"\n        headers = {}\n        if attach:\n            raise NotImplementedError('Attachments not implemented for Django yet!')\n        if replyto:\n            headers['Reply-To'] = replyto\n\n        self.sanity_check(sender, to, subject, plain=plain, html=html,\n                          cc=cc, bcc=bcc)\n\n        if not cc:\n            cc = []\n        if not bcc:\n            bcc = []\n\n        # This comes straight from the docs at\n        # https://docs.djangoproject.com/en/dev/topics/email/\n        from django.core.mail import EmailMultiAlternatives\n\n        if not plain:\n            plain = ''\n\n        msg = EmailMultiAlternatives(u(subject), u(plain), u(sender), _stringlist(to),\n                                     bcc=bcc, cc=cc, headers=headers)\n\n        if html:\n            msg.attach_alternative(ensure_unicode(html), \"text/html\")\n\n        msg.send()\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind a Template in the list of templates that have the given name and extension.", "response": "def _find_tpl(self, name, extension='.jinja2'):\n        \"\"\"\n        Return a Path object representing the Template we're after,\n        searching SELF.tpls or None\n\n        Arguments:\n        - `name`: str\n\n        Return: Path or None\n        Exceptions: None\n        \"\"\"\n        found = None\n        for loc in self.tpls:\n            if not loc:\n                continue\n            contents = [f for f in loc.ls() if f.find(name) != -1 and f.endswith(extension)]\n            if contents:\n                found = contents[0]\n                break\n            exact = loc + (name + extension)\n            if exact.is_file:\n                found = exact\n        return found"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn plain html templates for NAME", "response": "def _find_tpls(self, name):\n        \"\"\"\n        Return plain, html templates for NAME\n\n        Arguments:\n        - `name`: str\n\n        Return: tuple\n        Exceptions: None\n        \"\"\"\n        return self._find_tpl(name, extension='.txt'), self._find_tpl(name, extension='.html')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _send(self, sender, to, subject, message, cc=None, bcc=None, attach=None, replyto=None):\n        self.mailer.send(sender, to, subject, plain=message, cc=cc, bcc=bcc, attach=attach, replyto=replyto)\n        return", "response": "Send a Letter ( MESSAGE from SENDER to TO with the subject SUBJECT and the message."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a Letter from SENDER to TO, with the subject SUBJECT. Use the current template, with KWARGS as the context. Arguments: - `sender`: unicode - `to`: unicode - `subject`: unicode - `cc`: str or [str] - `bcc`: str or [str] - `replyto`: str - `**kwargs`: objects Return: None Exceptions: None", "response": "def _sendtpl(self, sender, to, subject, cc=None, bcc=None, attach=None, replyto=None, **kwargs):\n        \"\"\"\n        Send a Letter from SENDER to TO, with the subject SUBJECT.\n        Use the current template, with KWARGS as the context.\n\n        Arguments:\n        - `sender`: unicode\n        - `to`: unicode\n        - `subject`: unicode\n        - `cc`: str or [str]\n        - `bcc`: str or [str]\n        - `replyto`: str\n        - `**kwargs`: objects\n\n        Return: None\n        Exceptions: None\n        \"\"\"\n        plain, html = self.body(**kwargs)\n        self.mailer.send(sender, to, subject, plain=plain, html=html, cc=cc, bcc=bcc,\n                         replyto=replyto, attach=attach)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef body(self, **kwargs):\n        text_content, html_content = None, None\n        if self.plain:\n            text_content = mold.cast(self.plain, **kwargs)\n        if self.html:\n            html_content = mold.cast(self.html, **kwargs)\n        return text_content, html_content", "response": "Return the plain and html versions of our contents."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets an active template to use with our Postman.", "response": "def template(self, name):\n        \"\"\"\n        Set an active template to use with our Postman.\n\n        This changes the call signature of send.\n\n        Arguments:\n        - `name`: str\n\n        Return: None\n        Exceptions: None\n        \"\"\"\n        self.plain, self.html = self._find_tpls(name)\n        if not self.plain:\n            self.plain = self._find_tpl(name)\n        try:\n            self.send = self._sendtpl\n            yield\n        finally:\n            self.plain, self.html = None, None\n            self.send = self._send"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef environment(self):\n        '''Get raw data about this worker.\n\n        This is recorded in the :meth:`heartbeat` info, and can be\n        retrieved by :meth:`TaskMaster.get_heartbeat`.  The dictionary\n        includes keys ``worker_id``, ``host``, ``fqdn``, ``version``,\n        ``working_set``, and ``memory``.\n\n        '''\n        hostname = socket.gethostname()\n        aliases = ()\n        ipaddrs = ()\n\n        # This sequence isn't 100% reliable.  We might try a socket()\n        # sequence like RedisBase._ipaddress(), or just decide that\n        # socket.fqdn() and/or socket.gethostname() is good enough.\n        try:\n            ip = socket.gethostbyname(hostname)\n        except socket.herror:\n            # If you're here, then $(hostname) doesn't resolve.\n            ip = None\n\n        try:\n            if ip is not None:\n                hostname, aliases, ipaddrs = socket.gethostbyaddr(ip)\n        except socket.herror:\n            # If you're here, then $(hostname) resolves, but the IP\n            # address that results in doesn't reverse-resolve.  This\n            # has been observed on OSX at least.\n            ipaddrs = (ip,)\n\n        env = dict(\n            worker_id=self.worker_id,\n            parent=self.parent,\n            hostname=hostname,\n            aliases=tuple(aliases),\n            ipaddrs=tuple(ipaddrs),\n            fqdn=socket.getfqdn(),\n            version=pkg_resources.get_distribution(\"rejester\").version, # pylint: disable=E1103\n            working_set=[(dist.key, dist.version) for dist in pkg_resources.WorkingSet()], # pylint: disable=E1103\n            # config_hash=self.config['config_hash'],\n            # config_json = self.config['config_json'],\n            memory=psutil.virtual_memory(),\n            pid=os.getpid(),\n        )\n        return env", "response": "Get raw data about this worker."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register(self, parent=None):\n        '''Record the availability of this worker and get a unique identifer.\n\n        This sets :attr:`worker_id` and calls :meth:`heartbeat`.  This\n        cannot be called multiple times without calling\n        :meth:`unregister` in between.\n\n        '''\n        if self.worker_id:\n            raise ProgrammerError('Worker.register cannot be called again without first calling unregister; it is not idempotent')\n        self.parent = parent\n        self.worker_id = nice_identifier()\n        self.task_master.worker_id = self.worker_id\n        self.heartbeat()\n        return self.worker_id", "response": "Record the availability of this worker and get a unique identifer."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves this worker from the list of available workers.", "response": "def unregister(self):\n        '''Remove this worker from the list of available workers.\n\n        This requires the worker to already have been :meth:`register()`.\n\n        ''' \n        self.task_master.worker_unregister(self.worker_id)\n        self.task_master.worker_id = None\n        self.worker_id = None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef heartbeat(self):\n        '''Record the current worker state in the registry.\n\n        This records the worker's current mode, plus the contents of\n        :meth:`environment`, in the data store for inspection by others.\n\n        :returns mode: Current mode, as :meth:`TaskMaster.get_mode`\n\n        '''\n        mode = self.task_master.get_mode()\n        self.task_master.worker_heartbeat(self.worker_id, mode,\n                                          self.lifetime, self.environment(),\n                                          parent=self.parent)\n        return mode", "response": "Record the current worker state in the registry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef spec(self):\n        '''Actual work spec.\n\n        This is retrieved from the database on first use, and in some\n        cases a worker can be mildly more efficient if it avoids using\n        this.\n\n        '''\n        if self._spec_cache is None:\n            self._spec_cache = self.registry.get(\n                WORK_SPECS, self.work_spec_name)\n        return self._spec_cache", "response": "Actual work spec.\n        This is retrieved from the database on first use and then stored in the cache on first use."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef module(self):\n        '''Python module to run the job.\n\n        This is used by :func:`run` and the standard worker system.\n        If the work spec contains keys ``module``, ``run_function``,\n        and ``terminate_function``, then this contains the Python\n        module object named as ``module``; otherwise this contains\n        :const:`None`.\n\n        '''\n        if self._module_cache is None:\n            funclist = filter(None, (self.spec.get('run_function'),\n                                     self.spec.get('terminate_function')))\n            if funclist:\n                try:\n                    self._module_cache = __import__(\n                        self.spec['module'], globals(), (), funclist, -1)\n                except Exception:\n                    logger.error('failed to load spec[\"module\"] = %r',\n                                 self.spec['module'], exc_info=True)\n                    raise\n        return self._module_cache", "response": "Python module to run the job."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self):\n        '''Actually runs the work unit.\n\n        This is called by the standard worker system, generally\n        once per work unit.  It requires the work spec to contain\n        keys ``module``, ``run_function``, and ``terminate_function``.\n        It looks up ``run_function`` in :attr:`module` and calls that\n        function with :const:`self` as its only parameter.\n\n        '''\n        try:\n            logger.info('running work unit {0}'.format(self.key))\n            run_function = getattr(self.module, self.spec['run_function'])\n            ret_val = run_function(self)\n            self.update()\n            logger.info('completed work unit {0}'.format(self.key))\n            return ret_val\n        except LostLease:\n            logger.warning('work unit {0} timed out'.format(self.key))\n            raise\n        except Exception:\n            logger.error('work unit {0} failed'.format(self.key),\n                         exc_info=True)\n            raise", "response": "Actually runs the work unit."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nterminates the work unit.", "response": "def terminate(self):\n        '''Kills the work unit.\n\n        This is called by the standard worker system, but only in\n        response to an operating system signal.  If the job does setup\n        such as creating a child process, its terminate function\n        should kill that child process.  More specifically, this\n        function requires the work spec to contain the keys\n        ``module``, ``run_function``, and ``terminate_function``, and\n        calls ``terminate_function`` in :attr:`module` containing\n        :const:`self` as its only parameter.\n\n        '''\n        terminate_function_name = self.spec.get('terminate_function')\n        if not terminate_function_name:\n            logger.error('tried to terminate WorkUnit(%r) but no '\n                         'function name', self.key)\n            return None\n        terminate_function = getattr(self.module,\n                                     self.spec['terminate_function'])\n        if not terminate_function:\n            logger.error('tried to terminate WorkUnit(%r) but no '\n                         'function %s in module %r',\n                         self.key, terminate_function_name,\n                         self.module.__name__)\n            return None\n        logger.info('calling terminate function for work unit {0}'\n                    .format(self.key))\n        ret_val = terminate_function(self)\n        self.update(lease_time=-10)\n        return ret_val"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, lease_time=None):\n        '''Refresh this task's expiration time.\n\n        This tries to set the task's expiration time to the current\n        time, plus `lease_time` seconds.  It requires the job to not\n        already be complete.  If `lease_time` is negative, makes the\n        job immediately be available for other workers to run.\n\n        :param int lease_time: time to extend job lease beyond now\n        :raises rejester.exceptions.LostLease: if the lease has already\n          expired\n\n        '''\n        if lease_time is None:\n            lease_time = self.default_lifetime\n        with self.registry.lock(identifier=self.worker_id) as session:\n            self._refresh(session)\n            try:\n                self.expires = time.time() + lease_time\n                session.update(\n                    WORK_UNITS_ + self.work_spec_name,\n                    {self.key: self.data}, \n                    priorities={self.key: self.expires},\n                    locks={self.key: self.worker_id})\n\n            except EnvironmentError, exc:\n                raise LostLease(exc)", "response": "Refresh this task s expiration time. This attempts to set the task s expiration time to the current one plus the given time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmoving this work unit to a finished state.", "response": "def finish(self):\n        '''Move this work unit to a finished state.\n\n        In the standard worker system, the worker calls this on the job's\n        behalf when :meth:`run_function` returns successfully.\n\n        :raises rejester.exceptions.LostLease: if the lease has already\n          expired\n\n        '''\n        with self.registry.lock(identifier=self.worker_id) as session:\n            self._refresh(session, stopping=True)\n            if self.finished or self.failed:\n                return\n            session.move(\n                WORK_UNITS_ + self.work_spec_name,\n                WORK_UNITS_ + self.work_spec_name + _FINISHED,\n                {self.key: self.data})\n            session.popmany(\n                WORK_UNITS_ + self.work_spec_name + '_locks',\n                self.key, self.worker_id)\n            blocks = session.get(\n                WORK_UNITS_ + self.work_spec_name + _BLOCKS,\n                self.key)\n            if blocks is not None:\n                for block in blocks:\n                    spec = block[0]\n                    unit = block[1]\n                    # hard = block[2]\n                    depends = session.get(WORK_UNITS_ + spec + _DEPENDS,\n                                          unit)\n                    if depends is None:\n                        continue\n                    depends.remove([self.work_spec_name, self.key])\n                    if len(depends) == 0:\n                        session.popmany(WORK_UNITS_ + spec + _DEPENDS, unit)\n                        unitdef = session.get(WORK_UNITS_ + spec + _BLOCKED,\n                                              unit)\n                        session.move(WORK_UNITS_ + spec + _BLOCKED,\n                                     WORK_UNITS_ + spec,\n                                     {unit: unitdef})\n                    else:\n                        session.set(WORK_UNITS_ + spec + _DEPENDS, unit,\n                                    depends)\n            self.finished = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fail(self, exc=None):\n        '''Move this work unit to a failed state.\n\n        In the standard worker system, the worker calls this on the job's\n        behalf when :meth:`run_function` ends with any exception:\n\n        .. code-block:: python\n\n            try:\n                work_unit.run()\n                work_unit.finish()\n            except Exception, e:\n                work_unit.fail(e)\n\n        A ``traceback`` property is recorded with a formatted version\n        of `exc`, if any.\n\n        :param exc: Exception that caused the failure, or :const:`None`\n        :raises rejester.exceptions.LostLease: if the lease has already\n          expired\n\n        '''\n        with self.registry.lock(identifier=self.worker_id) as session:\n            self._refresh(session, stopping=True)\n            if self.finished or self.failed:\n                return\n            if exc:\n                self.data['traceback'] = traceback.format_exc(exc)\n            else:\n                self.data['traceback'] = None\n            session.move(\n                WORK_UNITS_ + self.work_spec_name,\n                WORK_UNITS_ + self.work_spec_name + _FAILED,\n                {self.key: self.data})\n            session.popmany(\n                WORK_UNITS_ + self.work_spec_name + '_locks',\n                self.key, self.worker_id)\n            blocks = session.get(WORK_UNITS_ + self.work_spec_name + _BLOCKS,\n                                 self.key)\n            if blocks is not None:\n                for block in blocks:\n                    spec = block[0]\n                    unit = block[1]\n                    hard = block[2]\n                    if hard:\n                        session.popmany(WORK_UNITS_ + spec + _DEPENDS, unit)\n                        unitdef = session.get(WORK_UNITS_ + spec + _BLOCKED,\n                                              unit)\n                        if unitdef is not None:\n                            session.move(WORK_UNITS_ + spec + _BLOCKED,\n                                         WORK_UNITS_ + spec + _FAILED,\n                                         {unit: unitdef})\n                    else:\n                        depends = session.get(WORK_UNITS_ + spec + _DEPENDS,\n                                              unit)\n                        if depends is None:\n                            continue\n                        depends.remove([self.work_spec_name, self.key])\n                        if len(depends) == 0:\n                            session.popmany(WORK_UNITS_ + spec + _DEPENDS, unit)\n                            unitdef = session.get(WORK_UNITS_ + spec + _BLOCKED,\n                                                  unit)\n                            if unitdef is not None:\n                                session.move(WORK_UNITS_ + spec + _BLOCKED,\n                                             WORK_UNITS_ + spec,\n                                             {unit: unitdef})\n                        else:\n                            session.set(WORK_UNITS_ + spec + _DEPENDS, unit,\n                                        depends)\n        self.failed = True", "response": "Move this work unit to a failed state."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the global mode of the rejester system.", "response": "def set_mode(self, mode):\n        '''Set the global mode of the rejester system.\n\n        This must be one of the constants :attr:`TERMINATE`,\n        :attr:`RUN`, or :attr:`IDLE`.  :attr:`TERMINATE` instructs any\n        running workers to do an orderly shutdown, completing current\n        jobs then exiting.  :attr:`IDLE` instructs workers to stay\n        running but not start new jobs.  :attr:`RUN` tells workers to\n        do actual work.\n\n        :param str mode: new rejester mode\n        :raise rejester.exceptions.ProgrammerError: on invalid `mode`\n\n        '''\n        if mode not in [self.TERMINATE, self.RUN, self.IDLE]:\n            raise ProgrammerError('mode=%r is not recognized' % mode)\n        with self.registry.lock(identifier=self.worker_id) as session:\n            session.set('modes', 'mode', mode)\n        logger.info('set mode to %s', mode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef idle_all_workers(self):\n        '''Set the global mode to :attr:`IDLE` and wait for workers to stop.\n\n        This can wait arbitrarily long before returning.  The worst\n        case in \"normal\" usage involves waiting five minutes for a\n        \"lost\" job to expire; a well-behaved but very-long-running job\n        can extend its own lease further, and this function will not\n        return until that job finishes (if ever).\n\n        .. deprecated:: 0.4.5\n            There isn't an obvious use case for this function, and its\n            \"maybe wait forever for something out of my control\" nature\n            makes it hard to use in real code.  Polling all of the work\n            specs and their :meth:`num_pending` in application code if\n            you really needed this operation would have the same\n            semantics and database load.\n\n        '''\n        self.set_mode(self.IDLE)\n        while 1:\n            num_pending = dict()\n            for work_spec_name in self.registry.pull(NICE_LEVELS).keys():\n                num_pending[work_spec_name] = self.num_pending(work_spec_name)\n            if sum(num_pending.values()) == 0:\n                break\n            logger.warn('waiting for pending work_units: %r', num_pending)\n            time.sleep(1)", "response": "Set the global mode to IDLE and wait for all workers to stop."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mode_counts(self):\n        '''Get the number of workers in each mode.\n\n        This returns a dictionary where the keys are mode constants\n        and the values are a simple integer count of the number of\n        workers in that mode.\n\n        '''\n        modes = {self.RUN: 0, self.IDLE: 0, self.TERMINATE: 0}\n        for worker_id, mode in self.workers().items():\n            modes[mode] += 1\n        return modes", "response": "Get the number of workers in each mode. This returns a dictionary where the keys are mode constants\n        and the values are simple integer count of the number of workers in that mode."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef workers(self, alive=True):\n        '''Get a listing of all workers.\n\n        This returns a dictionary mapping worker ID to the mode\n        constant for their last observed mode.\n\n        :param bool alive: if true (default), only include workers\n          that have called :meth:`Worker.heartbeat` sufficiently recently\n\n        '''\n        return self.registry.filter(\n            WORKER_OBSERVED_MODE,\n            priority_min=alive and time.time() or '-inf')", "response": "Get a listing of all workers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dump(self):\n        '''Print the entire contents of this to debug log messages.\n\n        This is really only intended for debugging.  It could produce\n        a lot of data.\n\n        '''\n        with self.registry.lock(identifier=self.worker_id) as session:\n            for work_spec_name in self.registry.pull(NICE_LEVELS).iterkeys():\n                def scan(sfx):\n                    v = self.registry.pull(WORK_UNITS_ + work_spec_name + sfx)\n                    if v is None:\n                        return []\n                    return v.keys()\n                for key in scan(''):\n                    logger.debug('spec {0} unit {1} available or pending'\n                                 .format(work_spec_name, key))\n                for key in scan(_BLOCKED):\n                    blocked_on = session.get(\n                        WORK_UNITS_ + work_spec_name + _DEPENDS, key)\n                    logger.debug('spec {0} unit {1} blocked on {2!r}'\n                                 .format(work_spec_name, key, blocked_on))\n                for key in scan(_FINISHED):\n                    logger.debug('spec {0} unit {1} finished'\n                                 .format(work_spec_name, key))\n                for key in scan(_FAILED):\n                    logger.debug('spec {0} unit {1} failed'\n                                 .format(work_spec_name, key))", "response": "Print the entire contents of this to debug log messages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_work_spec(cls, work_spec):\n        '''Check that `work_spec` is valid.\n\n        It must at the very minimum contain a ``name`` and ``min_gb``.\n\n        :raise rejester.exceptions.ProgrammerError: if it isn't valid\n\n        '''\n        if 'name' not in work_spec:\n            raise ProgrammerError('work_spec lacks \"name\"')\n        if 'min_gb' not in work_spec or \\\n                not isinstance(work_spec['min_gb'], (float, int, long)):\n            raise ProgrammerError('work_spec[\"min_gb\"] must be a number')", "response": "Check that the work_spec is valid."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the number of available work units for some work spec.", "response": "def num_available(self, work_spec_name):\n        '''Get the number of available work units for some work spec.\n\n        These are work units that could be returned by :meth:`get_work`:\n        they are not complete, not currently executing, and not blocked\n        on some other work unit.\n\n        '''\n        return self.registry.len(WORK_UNITS_ + work_spec_name,\n                                 priority_max=time.time())"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the number of pending work units for some work spec.", "response": "def num_pending(self, work_spec_name):\n        '''Get the number of pending work units for some work spec.\n\n        These are work units that some worker is currently working on\n        (hopefully; it could include work units assigned to workers that\n        died and that have not yet expired).\n\n        '''\n        return self.registry.len(WORK_UNITS_ + work_spec_name,\n                                 priority_min=time.time())"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the total number of work units for some work spec.", "response": "def num_tasks(self, work_spec_name):\n        '''Get the total number of work units for some work spec.'''\n        return self.num_finished(work_spec_name) + \\\n               self.num_failed(work_spec_name) + \\\n               self.registry.len(WORK_UNITS_ + work_spec_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a summary dictionary for some work spec.", "response": "def status(self, work_spec_name):\n        '''Get a summary dictionary for some work spec.\n\n        The keys are the strings :meth:`num_available`, :meth:`num_pending`,\n        :meth:`num_blocked`, :meth:`num_finished`, :meth:`num_failed`,\n        and :meth:`num_tasks`, and the values are the values returned\n        from those functions.\n\n        '''\n        return dict(\n            num_available=self.num_available(work_spec_name),\n            num_pending=self.num_pending(work_spec_name),\n            num_blocked=self.num_blocked(work_spec_name),\n            num_finished=self.num_finished(work_spec_name),\n            num_failed=self.num_failed(work_spec_name),\n            num_tasks=self.num_tasks(work_spec_name),\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef iter_work_specs(self, limit=None, start=None):\n        '''\n        yield work spec dicts\n        '''\n        count = 0\n        ws_list, start = self.list_work_specs(limit, start)\n        while True:\n            for name_spec in ws_list:\n                yield name_spec[1]\n                count += 1\n                if (limit is not None) and (count >= limit):\n                    break\n            if not start:\n                break\n            if limit is not None:\n                limit -= count\n            ws_list, start = self.list_work_specs(limit, start)", "response": "Iterate over work specs in order of name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_work_spec(self, work_spec_name):\n        '''Get the dictionary defining some work spec.'''\n        with self.registry.lock(identifier=self.worker_id) as session:\n            return session.get(WORK_SPECS, work_spec_name)", "response": "Get the dictionary defining some work spec."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_work_units(self, work_spec_name, work_unit_keys=None,\n                       state=None, limit=None, start=None):\n        '''Get (key, value) pairs for work units.\n\n        If `state` is not :const:`None`, then it should be one of\n        the string state constants, and this function will return\n        a list of pairs of work unit key and value for work units\n        in that state.  If `start` is not :const:`None`, then this\n        many work units are skipped; if `limit` is not :const:`None`\n        then at most this many work units will be returned.\n\n        If `state` is :const:`None` then all work units in all\n        states will be returned.\n\n        :param str work_spec_name: name of work spec to query\n        :param str state: string state constant, or :const:`None`\n          for all work units in all states\n        :param int limit: maximum number of items to return\n        :param int start: skip this many items before returning any\n        :return: list of pairs of (work unit key, work unit data)\n\n        '''\n        if work_unit_keys is not None:\n            raise NotImplementedError(\"get_work_units(by work_unit_keys)\")\n        if start is None:\n            start = 0\n        if state is not None:\n            if state == AVAILABLE:\n                return self.list_available_work_units(\n                    work_spec_name, start=start, limit=limit).items()\n            if state == PENDING:\n                return self.list_pending_work_units(\n                    work_spec_name, start=start, limit=limit).items()\n            if state == BLOCKED:\n                return self.list_blocked_work_units(\n                    work_spec_name, start=start, limit=limit).items()\n            if state == FINISHED:\n                return self.list_finished_work_units(\n                    work_spec_name, start=start, limit=limit).items()\n            if state == FAILED:\n                return self.list_failed_work_units(\n                    work_spec_name, start=start, limit=limit).items()\n            raise ProgrammerError(\"unknown state {0!r}\".format(state))\n        # TODO: correctly handle start/limit for the case where\n        # we're trying to list everything (unqualified)...this is\n        # actually kind of limited utility\n        work_units = {}\n        work_units.update(self.list_work_units(work_spec_name))\n        work_units.update(self.list_blocked_work_units(work_spec_name))\n        work_units.update(self.list_finished_work_units(work_spec_name))\n        work_units.update(self.list_failed_work_units(work_spec_name))\n        return work_units.items()", "response": "Get a list of work units in a specific state."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a dictionary of work units for some work spec.", "response": "def list_work_units(self, work_spec_name, start=0, limit=None):\n        \"\"\"Get a dictionary of work units for some work spec.\n\n        The dictionary is from work unit name to work unit definiton.\n        Only work units that have not been completed (\"available\" or\n        \"pending\" work units) are included.\n\n        \"\"\"\n        return self.registry.filter(WORK_UNITS_ + work_spec_name,\n                                    start=start, limit=limit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_available_work_units(self, work_spec_name, start=0, limit=None):\n        return self.registry.filter(WORK_UNITS_ + work_spec_name,\n                                    priority_max=time.time(),\n                                    start=start, limit=limit)", "response": "Get a dictionary of available work units for some work spec."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_pending_work_units(self, work_spec_name, start=0, limit=None):\n        return self.registry.filter(WORK_UNITS_ + work_spec_name,\n                                    priority_min=time.time(),\n                                    start=start, limit=limit)", "response": "Get a dictionary of in - progress work units for some work spec."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_blocked_work_units(self, work_spec_name, start=0, limit=None):\n        return self.registry.filter(WORK_UNITS_ + work_spec_name + _BLOCKED,\n                                    start=start, limit=limit)", "response": "Get a dictionary of blocked work units for some work spec."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_finished_work_units(self, work_spec_name, start=0, limit=None):\n        return self.registry.filter(WORK_UNITS_ + work_spec_name + _FINISHED,\n                                    start=start, limit=limit)", "response": "Get a dictionary of finished work units for some work spec."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a dictionary of failed work units for some work spec.", "response": "def list_failed_work_units(self, work_spec_name, start=0, limit=None):\n        \"\"\"Get a dictionary of failed work units for some work spec.\n\n        The dictionary is from work unit name to work unit definiton.\n        Only work units that have completed unsuccessfully are included.\n\n        \"\"\"\n        return self.registry.filter(WORK_UNITS_ + work_spec_name + _FAILED,\n                                    start=start, limit=limit)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove some units from somewhere.", "response": "def _remove_some_work_units(self, work_spec_name, work_unit_names,\n                                suffix='', priority_min='-inf',\n                                priority_max='+inf'):\n        '''Remove some units from somewhere.'''\n        now = time.time()\n        if work_unit_names is None:\n            count = 0\n            while True:\n                with self.registry.lock(identifier=self.worker_id) as session:\n                    names = session.filter(\n                        WORK_UNITS_ + work_spec_name + suffix,\n                        priority_min=priority_min, priority_max=priority_max,\n                        limit=1000)\n                    if not names: break\n                    count += session.popmany(\n                        WORK_UNITS_ + work_spec_name + suffix, *names)\n        else:\n            # TODO: This needs to honor priority_min/priority_max,\n            # otherwise it gets the wrong answer for \"available\"/\n            # \"pending\" (it will get both states).\n            with self.registry.lock(identifier=self.worker_id) as session:\n                count = session.popmany(WORK_UNITS_ + work_spec_name + suffix,\n                                        *work_unit_names)\n        return count"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting work units from a work spec.", "response": "def del_work_units(self, work_spec_name, work_unit_keys=None,\n                       state=None, all=False):\n        '''Delete work units from a work spec.\n\n        The parameters are considered in order as follows:\n\n        * If `all` is :const:`True`, then all work units in\n          `work_spec_name` are deleted; otherwise\n        * If `state` is not :const:`None`, then all work units\n          in the named state are deleted; otherwise\n        * If `work_unit_keys` are specified, then those specific\n          work units are deleted; otherwise\n        * Nothing is deleted.\n\n        :param str work_spec_name: name of the work spec\n        :param list work_unit_keys: if not :const:`None`, only delete\n          these specific keys\n        :param str state: only delete work units in this state\n        :param bool all: if true, delete all work units\n        :return: number of work units deleted\n\n        '''\n        count = 0\n        if (state is None) or (state == AVAILABLE):\n            count += self.remove_available_work_units(work_spec_name, work_unit_keys)\n        if (state is None) or (state == PENDING):\n            count += self.remove_pending_work_units(work_spec_name, work_unit_keys)\n        if (state is None) or (state == BLOCKED):\n            count += self.remove_blocked_work_units(work_spec_name, work_unit_keys)\n        if (state is None) or (state == FAILED):\n            count += self.remove_failed_work_units(work_spec_name, work_unit_keys)\n        if (state is None) or (state == FINISHED):\n            count += self.remove_finished_work_units(work_spec_name, work_unit_keys)\n        return count"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving some work units in the available queue.", "response": "def remove_available_work_units(self, work_spec_name, work_unit_names):\n        '''Remove some work units in the available queue.\n\n        If `work_unit_names` is :const:`None` (which must be passed\n        explicitly), all available work units in `work_spec_name` are\n        removed; otherwise only the specific named work units will be.\n\n        :param str work_spec_name: name of the work spec\n        :param list work_unit_names: names of the work units, or\n          :const:`None` for all in `work_spec_name`\n        :return: number of work units removed\n\n        '''\n        return self._remove_some_work_units(\n            work_spec_name, work_unit_names, priority_max=time.time())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves some work units in the pending list.", "response": "def remove_pending_work_units(self, work_spec_name, work_unit_names):\n        '''Remove some work units in the pending list.\n\n        If `work_unit_names` is :const:`None` (which must be passed\n        explicitly), all pending work units in `work_spec_name` are\n        removed; otherwise only the specific named work units will be.\n\n        Note that this function has the potential to confuse workers\n        if they are actually working on the work units in question.  If\n        you have ensured that the workers are dead and you would be\n        otherwise waiting for the leases to expire before calling\n        :meth:`remove_available_work_units`, then this is a useful\n        shortcut.\n\n        :param str work_spec_name: name of the work spec\n        :param list work_unit_names: names of the work units, or\n          :const:`None` for all in `work_spec_name`\n        :return: number of work units removed\n\n        '''\n        return self._remove_some_work_units(\n            work_spec_name, work_unit_names, priority_min=time.time())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving some work units in the blocked list.", "response": "def remove_blocked_work_units(self, work_spec_name, work_unit_names):\n        '''Remove some work units in the blocked list.\n\n        If `work_unit_names` is :const:`None` (which must be passed\n        explicitly), all pending work units in `work_spec_name` are\n        removed; otherwise only the specific named work units will be.\n\n        Note that none of the \"remove\" functions will restart blocked\n        work units, so if you have called\n        e.g. :meth:`remove_available_work_units` for a predecessor\n        job, you may need to also call this method for its successor.\n\n        :param str work_spec_name: name of the work spec\n        :param list work_unit_names: names of the work units, or\n          :const:`None` for all in `work_spec_name`\n        :return: number of work units removed\n\n        '''\n        return self._remove_some_work_units(\n            work_spec_name, work_unit_names, suffix=_BLOCKED)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_failed_work_units(self, work_spec_name, work_unit_names):\n        '''Remove some failed work units.\n\n        If `work_unit_names` is :const:`None` (which must be passed\n        explicitly), all failed work units in `work_spec_name` are\n        removed; otherwise only the specific named work units will be.\n\n        Also consider :meth:`retry` to move failed work units back into\n        the available queue.\n\n        :param str work_spec_name: name of the work spec\n        :param list work_unit_names: names of the work units, or\n          :const:`None` for all in `work_spec_name`\n        :return: number of work units removed\n\n        '''\n        return self._remove_some_work_units(\n            work_spec_name, work_unit_names, suffix=_FAILED)", "response": "Remove some failed work units from the available queue."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving some finished work units in a specific work spec.", "response": "def remove_finished_work_units(self, work_spec_name, work_unit_names):\n        '''Remove some finished work units.\n\n        If `work_unit_names` is :const:`None` (which must be passed\n        explicitly), all finished work units in `work_spec_name` are\n        removed; otherwise only the specific named work units will be.\n\n        :param str work_spec_name: name of the work spec\n        :param list work_unit_names: names of the work units, or\n          :const:`None` for all in `work_spec_name`\n        :return: number of work units removed\n\n        '''\n        return self._remove_some_work_units(\n            work_spec_name, work_unit_names, suffix=_FINISHED)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_work_unit_status(self, work_spec_name, work_unit_key):\n        '''Get a high-level status for some work unit.\n\n        The return value is a dictionary.  The only required key is\n        ``status``, which could be any of:\n\n        ``missing``\n          The work unit does not exist anywhere\n        ``available``\n          The work unit is available for new workers; additional\n          keys include ``expiration`` (may be 0)\n        ``pending``\n          The work unit is being worked on; additional keys include\n          ``expiration`` and ``worker_id`` (usually)\n        ``blocked``\n          The work unit is waiting for some other work units to finish;\n          additional keys include ``depends_on``\n        ``finished``\n          The work unit has completed\n        ``failed``\n          The work unit failed; additional keys include ``traceback``\n\n        :param str work_spec_name: name of the work spec\n        :param str work_unit_name: name of the work unit\n        :return: dictionary description of summary status\n        '''\n        with self.registry.lock(identifier=self.worker_id) as session:\n            # In the available list?\n            (unit,priority) = session.get(WORK_UNITS_ + work_spec_name,\n                                          work_unit_key, include_priority=True)\n            if unit:\n                result = {}\n                if priority < time.time():\n                    result['status'] = 'available'\n                else:\n                    result['status'] = 'pending'\n                result['expiration'] = priority\n                # ...is anyone working on it?\n                worker = session.get(WORK_UNITS_ + work_spec_name + \"_locks\",\n                                     work_unit_key)\n                if worker:\n                    result['worker_id'] = worker\n                return result\n\n            # In the finished list?\n            unit = session.get(WORK_UNITS_ + work_spec_name + _FINISHED,\n                               work_unit_key)\n            if unit:\n                return { 'status': 'finished' }\n\n            # In the failed list?\n            unit = session.get(WORK_UNITS_ + work_spec_name + _FAILED,\n                               work_unit_key)\n            if unit:\n                result = { 'status': 'failed' }\n                if 'traceback' in unit:\n                    result['traceback'] = unit['traceback']\n                return result\n\n            # In the blocked list?\n            unit = session.get(WORK_UNITS_ + work_spec_name + _BLOCKED,\n                               work_unit_key)\n            if unit:\n                # This should always have *something*, right?\n                deps = session.get(WORK_UNITS_ + work_spec_name + _DEPENDS,\n                                   work_unit_key, default=[])\n                result = { 'status': 'blocked',\n                           'depends_on': deps }\n                return result\n\n        return { 'status': 'missing' }", "response": "Get a high - level status for some work unit."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the data for some work unit.", "response": "def inspect_work_unit(self, work_spec_name, work_unit_key):\n        '''Get the data for some work unit.\n\n        Returns the data for that work unit, or `None` if it really\n        can't be found.\n\n        :param str work_spec_name: name of the work spec\n        :param str work_unit_key: name of the work unit\n        :return: definition of the work unit, or `None`\n        '''\n        with self.registry.lock(identifier=self.worker_id) as session:\n            work_unit_data = session.get(\n                WORK_UNITS_ + work_spec_name, work_unit_key)\n            if not work_unit_data:\n                work_unit_data = session.get(\n                    WORK_UNITS_ + work_spec_name + _BLOCKED, work_unit_key)\n            if not work_unit_data:\n                work_unit_data = session.get(\n                    WORK_UNITS_ + work_spec_name + _FINISHED, work_unit_key)\n            if not work_unit_data:\n                work_unit_data = session.get(\n                    WORK_UNITS_ + work_spec_name + _FAILED, work_unit_key)\n            return work_unit_data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reset_all(self, work_spec_name):\n        '''Restart a work spec.\n\n        This calls :meth:`idle_all_workers`, then moves all finished\n        jobs back into the available queue.\n\n        .. deprecated:: 0.4.5\n            See :meth:`idle_all_workers` for problems with that method.\n            This also ignores failed jobs and work unit dependencies.\n            In practice, whatever generated a set of work units\n            initially can recreate them easily enough.\n\n        '''\n        self.idle_all_workers()\n        with self.registry.lock(identifier=self.worker_id) as session:\n            session.move_all(WORK_UNITS_ + work_spec_name + _FINISHED,\n                             WORK_UNITS_ + work_spec_name)\n            session.reset_priorities(WORK_UNITS_ + work_spec_name, 0)", "response": "Restarts a work spec."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_bundle(self, work_spec, work_units, nice=0):\n        '''Load a work spec and some work units into the task list.\n        \n        update the work_spec and work_units.  Overwrites any existing\n        work spec with the same ``work_spec['name']`` and similarly\n        overwrites any WorkUnit with the same ``work_unit.key``\n\n        :param dict work_spec: Work spec dictionary\n        :param work_units: Keys are used as :attr:`WorkUnit.key`, values\n          are used as :attr:`WorkUnit.data`\n        :type work_units: dict of dict\n        :param int nice: Niceness of `work_spec`, higher value is lower\n          priority\n\n        '''\n        self.validate_work_spec(work_spec)\n        \n        work_spec_name = work_spec['name']\n        with self.registry.lock(identifier=self.worker_id) as session:\n            session.update(NICE_LEVELS, {work_spec_name: nice})\n            session.update(WORK_SPECS,  {work_spec_name: work_spec})\n            \n            ## redis chokes on lua scripts with \n            work_units = work_units.items()\n            window_size = 10**4\n            for i in xrange(0, len(work_units), window_size):\n                self.registry.re_acquire_lock()\n                session.update(WORK_UNITS_ + work_spec_name, \n                               dict(work_units[i: i + window_size]))", "response": "Load a work spec and some work units into the task list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the work spec for this worker.", "response": "def set_work_spec(self, work_spec):\n        '''\n        work_spec is a dict()\n        work_spec['name'] is used as work_spec_name in other API calls\n        work_spec['nice'] is used for prioritization, if set.\n        '''\n        self.validate_work_spec(work_spec)\n\n        nice = int(work_spec.get('nice', 0))\n        work_spec_name = work_spec['name']\n        with self.registry.lock(identifier=self.worker_id) as session:\n            session.update(NICE_LEVELS, {work_spec_name: nice})\n            session.update(WORK_SPECS,  {work_spec_name: work_spec})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_work_units(self, work_spec_name, work_unit_key_vals):\n        '''\n        work_unit_key_vals list of (work_unit_key, work_unit_data)\n        '''\n        with self.registry.lock(identifier=self.worker_id) as session:\n            window_size = 10**4\n            for i in xrange(0, len(work_unit_key_vals), window_size):\n                self.registry.re_acquire_lock()\n                session.update(WORK_UNITS_ + work_spec_name,\n                               dict(work_unit_key_vals[i: i + window_size]))", "response": "Adds a list of work units to the work_units list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_dependent_work_units(self, work_unit, depends_on, hard=True):\n        # There's no good, not-confusing terminology here.\n        # I'll call work_unit \"later\" and depends_on \"earlier\"\n        # consistently, because that at least makes the time flow\n        # correct.\n        later_spec, later_unit, later_unitdef = work_unit\n        earlier_spec, earlier_unit, earlier_unitdef = depends_on\n        with self.registry.lock(identifier=self.worker_id) as session:\n            # Bail if either work spec doesn't already exist\n            if session.get(WORK_SPECS, later_spec) is None:\n                raise NoSuchWorkSpecError(later_spec)\n            if session.get(WORK_SPECS, earlier_spec) is None:\n                raise NoSuchWorkSpecError(earlier_spec)\n            \n            # Cause both work units to exist (if possible)\n            # Note that if \"earlier\" is already finished, we may be\n            # able to make \"later\" available immediately\n            earlier_done = False\n            earlier_successful = False\n            if earlier_unitdef is not None:\n                session.update(WORK_UNITS_ + earlier_spec,\n                               { earlier_unit: earlier_unitdef })\n            else:\n                earlier_unitdef = session.get(\n                    WORK_UNITS_ + earlier_spec, earlier_unit)\n                if earlier_unitdef is None:\n                    earlier_unitdef = session.get(\n                        WORK_UNITS_ + earlier_spec + _BLOCKED, earlier_unit)\n                if earlier_unitdef is None:\n                    earlier_unitdef = session.get(\n                        WORK_UNITS_ + earlier_spec + _FINISHED, earlier_unit)\n                    if earlier_unitdef is not None:\n                        earlier_done = True\n                        earlier_successful = True\n                if earlier_unitdef is None:\n                    earlier_unitdef = session.get(\n                        WORK_UNITS_ + earlier_spec + _FAILED, earlier_unit)\n                    if earlier_unitdef is not None:\n                        earlier_done = True\n\n            later_failed = earlier_done and hard and not earlier_successful\n            later_unblocked = ((earlier_done and not later_failed) or\n                               (earlier_unitdef is None))\n            if later_failed:\n                later_destination = WORK_UNITS_ + later_spec + _FAILED\n            elif later_unblocked:\n                later_destination = WORK_UNITS_ + later_spec\n            else:\n                later_destination = WORK_UNITS_ + later_spec + _BLOCKED\n\n            if later_unitdef is not None:\n                for suffix in ['', _FINISHED, _FAILED, _BLOCKED]:\n                    k = WORK_UNITS_ + later_spec + suffix\n                    if k != later_destination:\n                        session.popmany(k, later_unit)\n                session.update(later_destination,\n                               { later_unit: later_unitdef })\n            elif earlier_unitdef is not None:\n                later_unitdef = session.get(\n                    WORK_UNITS_ + later_spec, later_unit)\n                if later_unitdef is not None:\n                    session.move(\n                        WORK_UNITS_ + later_spec,\n                        WORK_UNITS_ + later_spec + _BLOCKED,\n                        { later_unit: later_unitdef })\n                else:\n                    later_unitdef = session.get(\n                        WORK_UNITS_ + later_spec + _BLOCKED, later_unit)\n\n            if later_unitdef is None or earlier_unitdef is None:\n                return False\n\n            # Now both units exist and are in the right place;\n            # record the dependency\n            blocks = session.get(WORK_UNITS_ + earlier_spec + _BLOCKS,\n                                 earlier_unit)\n            if blocks is None: blocks = []\n            blocks.append([later_spec, later_unit, hard])\n            session.set(WORK_UNITS_ + earlier_spec + _BLOCKS,\n                        earlier_unit, blocks)\n\n            depends = session.get(WORK_UNITS_ + later_spec + _DEPENDS,\n                                  later_unit)\n            if depends is None: depends = []\n            depends.append([earlier_spec, earlier_unit])\n            session.set(WORK_UNITS_ + later_spec + _DEPENDS,\n                        later_unit, depends)\n\n            return True", "response": "Add dependent work units to the master s namespace."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef retry(self, work_spec_name, *work_unit_names):\n        '''Move failed work unit(s) back into the \"pending\" queue.\n\n        The work unit will be available to execute immediately.  If\n        other tasks had depended on it, those dependencies will not\n        be recreated.\n\n        :param str work_spec_name: name of the (existing) work spec\n        :param str work_unit_names: name(s) of the (failed) work unit(s)\n        :raise rejester.NoSuchWorkSpecError: if `work_spec_name` is\n          invalid\n        :raise rejester.NoSuchWorkUnitError: if `work_spec_name` is\n          valid but any of the `work_unit_names` are not a failed work unit\n        :raise rejester.LockError: if the registry lock could not be\n          obtained\n        \n        '''\n        with self.registry.lock(identifier=self.worker_id) as session:\n            # This sequence is safe even if this system dies\n            units = {}\n            for work_unit_name in work_unit_names:\n                unit = session.get(WORK_UNITS_ + work_spec_name + _FAILED,\n                                   work_unit_name)\n                if unit is None:\n                    spec = session.get(WORK_SPECS, work_spec_name)\n                    if spec is None:\n                        raise NoSuchWorkSpecError(work_spec_name)\n                    else:\n                        raise NoSuchWorkUnitError(work_unit_name)\n                if 'traceback' in unit:\n                    del unit['traceback']\n                units[work_unit_name] = unit\n            session.move(WORK_UNITS_ + work_spec_name + _FAILED,\n                         WORK_UNITS_ + work_spec_name,\n                         units,\n                         priority=0)", "response": "Move failed work units back into the pending queue."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef nice(self, work_spec_name, nice):\n        '''Change the priority of an existing work spec.'''\n        with self.registry.lock(identifier=self.worker_id) as session:\n            session.update(NICE_LEVELS, dict(work_spec_name=nice))", "response": "Change the priority of an existing work spec."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_work(self, worker_id, available_gb=None, lease_time=None, work_spec_names=None, max_jobs=None):\n        '''obtain a WorkUnit instance based on available memory for the\n        worker process.  \n        \n        :param worker_id: unique identifier string for a worker to\n          which a WorkUnit will be assigned, if available.\n        :param available_gb: number of gigabytes of RAM available to\n          this worker\n        :param lease_time: how many seconds to lease a WorkUnit\n        :param int max_jobs: maximum number of work units to return (default 1)\n        :param work_spec_names: limit to queue from one work_spec. NOT IMPLEMENTD. this implementation will return work from any work spec.\n\n        '''\n\n        if not isinstance(available_gb, (int, float)):\n            raise ProgrammerError('must specify available_gb')\n\n        if (max_jobs is not None) and (max_jobs != 1):\n            logger.error('redis rejester does not support max_jobs. ignoring and getting 1')\n\n        if lease_time is None:\n            lease_time = self.default_lifetime\n        work_unit = None\n\n        try: \n            with self.registry.lock(identifier=self.worker_id) as session:\n                ## use the simple niceness algorithm described in\n                ## http://en.wikipedia.org/wiki/Nice_(Unix)\n                ## where each job gets a (20-niceness) share\n                nice_levels = session.pull(NICE_LEVELS)\n                for work_spec_name, nice in nice_levels.iteritems():\n                    nice = min(19, nice)\n                    nice = max(-19, nice)\n                    nice = 20 - nice\n                    nice_levels[work_spec_name] = nice\n\n                while nice_levels:\n                    total_nice = sum(nice_levels.values())\n                    score = random.randrange(total_nice)\n                    work_spec_name = None\n                    total_score = 0\n                    for wsn, nice in nice_levels.iteritems():\n                        total_score += nice\n                        if total_score > score:\n                            work_spec_name = wsn\n                            break\n                    assert work_spec_name is not None\n                    nice_levels.pop(work_spec_name)\n                    \n                    ## verify sufficient memory\n                    work_spec = session.get(WORK_SPECS, work_spec_name)\n                    if available_gb < work_spec['min_gb']:\n                        if self.enough_memory:\n                            logger.info('Not enough memory to run work '\n                                        'spec %s (need %.1f GiB, have '\n                                        '%.1f GiB) but running anyways',\n                                        work_spec_name,\n                                        work_spec['min_gb'],\n                                        available_gb)\n                        else:\n                            logger.info('Not enough memory to run work '\n                                        'spec %s (need %.1f GiB, have '\n                                        '%.1f GiB)',\n                                        work_spec_name,\n                                        work_spec['min_gb'],\n                                        available_gb)\n                            continue\n\n                    ## try to get a task\n                    wu_expires = time.time() + lease_time\n                    _work_unit = session.getitem_reset(\n                        WORK_UNITS_ + work_spec_name,\n                        priority_max=time.time(),\n                        new_priority=wu_expires,\n                        lock=worker_id,\n                    )\n\n                    if _work_unit:\n                        logger.info('work unit %r', _work_unit)\n                        work_unit = WorkUnit(\n                            self.registry, work_spec_name,\n                            _work_unit[0], _work_unit[1],\n                            worker_id=worker_id,\n                            expires=wu_expires,\n                            default_lifetime=self.default_lifetime,\n                        )\n                        break\n\n        except (LockError, EnvironmentError):\n            logger.error('took to long to get work', exc_info=True)\n\n        logger.debug('get_work %r', work_unit)\n        return work_unit", "response": "obtain a WorkUnit instance based on the available memory for a worker process."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a specific WorkUnit that has already been assigned to a particular worker_id", "response": "def get_assigned_work_unit(self, worker_id, work_spec_name,\n                               work_unit_key):\n        '''get a specific WorkUnit that has already been assigned to a\n        particular worker_id\n        '''\n        with self.registry.lock(identifier=self.worker_id) as session:\n            assigned_work_unit_key = session.get(\n                WORK_UNITS_ + work_spec_name + '_locks', worker_id)\n            if not assigned_work_unit_key == work_unit_key:\n                # raise LostLease instead of EnvironmentError, so\n                # users of TaskMaster can have a single type of\n                # expected exception, rather than two\n                raise LostLease(\n                    'assigned_work_unit_key=%r != %r'\n                    % (assigned_work_unit_key, work_unit_key))\n            # could trap EnvironmentError and raise LostLease instead\n            work_unit_data = session.get(WORK_UNITS_ + work_spec_name,\n                                         work_unit_key)\n            return WorkUnit(\n                self.registry, work_spec_name,\n                work_unit_key, work_unit_data,\n                worker_id=worker_id,\n                default_lifetime=self.default_lifetime,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_child_work_units(self, worker_id):\n        '''Get work units assigned to a worker's children.\n\n        Returns a dictionary mapping worker ID to :class:`WorkUnit`.\n        If a child exists but is idle, that worker ID will map to\n        :const:`None`.  The work unit may already be expired or\n        assigned to a different worker; this will be reflected in\n        the returned :class:`WorkUnit`.\n\n        This may write back to the underlying data store to clean up\n        stale children that have not unregistered themselves but\n        no longer exist in any form.\n\n        '''\n        result = {}\n        with self.registry.lock(identifier=worker_id) as session:\n            all_children = session.pull(WORKER_CHILDREN_ + worker_id)\n            # The data stored in Redis isn't actually conducive to\n            # this specific query; we will need to scan each work spec\n            # for each work unit\n            work_specs = session.pull(WORK_SPECS)\n            for child in all_children.iterkeys():\n                work_spec_name = None\n                for spec in work_specs.iterkeys():\n                    work_unit_key = session.get(\n                        WORK_UNITS_ + spec + '_locks', child)\n                    if work_unit_key:\n                        work_spec_name = spec\n                        break\n\n                if work_spec_name:\n                    assigned = session.get(\n                        WORK_UNITS_ + work_spec_name + '_locks',\n                        work_unit_key)\n                    (data, expires) = session.get(\n                        WORK_UNITS_ + work_spec_name, work_unit_key,\n                        include_priority=True)\n                    if data is None:\n                        # The work unit is probably already finished\n                        result[child] = None\n                    else:\n                        result[child] = WorkUnit(\n                            self.registry, work_spec_name, work_unit_key,\n                            data, expires=expires, worker_id=assigned)\n                else:\n                    # The child isn't doing anything.  Does it still\n                    # exist?\n                    heartbeat = session.get(WORKER_OBSERVED_MODE, child)\n                    if heartbeat:\n                        result[child] = None\n                    else:\n                        session.popmany(WORKER_CHILDREN_ + worker_id,\n                                        child)\n        return result", "response": "Get work units assigned to a worker s children."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot the entire image in a single figure.", "response": "def plotPlainImg(sim, cam, rawdata, t, odir):\n    \"\"\"\n    No subplots, just a plan\n\n    http://stackoverflow.com/questions/22408237/named-colors-in-matplotlib\n    \"\"\"\n    for R, C in zip(rawdata, cam):\n        fg = figure()\n        ax = fg.gca()\n        ax.set_axis_off()  # no ticks\n        ax.imshow(R[t, :, :],\n                  origin='lower',\n                  vmin=max(C.clim[0], 1), vmax=C.clim[1],\n                  cmap='gray')\n        ax.text(0.05, 0.075, datetime.utcfromtimestamp(C.tKeo[t]).strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3],\n                ha='left',\n                va='top',\n                transform=ax.transAxes,\n                color='limegreen',\n                # weight='bold',\n                size=24\n                )\n\n        writeplots(fg, 'cam{}rawFrame'.format(C.name), t, odir)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plotRealImg(sim, cam, rawdata, t: int, odir: Path=None, fg=None):\n    ncols = len(cam)\n    #  print('using {} cameras'.format(ncols))\n    T = nans(ncols, dtype=datetime)\n\n#    if asi is not None:\n#        ncols=3\n#        if isinstance(asi,(tuple,list)):\n#            pass\n#        elif isinstance(asi,(str,Path)):\n#            asi = Path(asi).expanduser()\n#            if asi.is_dir():\n#                asi=list(asi.glob('*.FITS'))\n    if fg is None:\n        doclose = True\n        fg, axs = subplots(nrows=1, ncols=ncols, figsize=(\n            15, 12), dpi=DPI, facecolor='black')\n        axs = atleast_1d(axs)  # in case only 1\n        # fg.set_size_inches(15,5) #clips off\n    else:  # maintain original figure handle for anim.writer\n        doclose = False\n        fg.clf()\n        axs = [fg.add_subplot(1, ncols, i + 1) for i in range(ncols)]\n\n    for i, C in enumerate(cam):\n        if C.usecam:  # HiST cameras\n            # print('frame {}'.format(t))\n            # hold times for all cameras at this time step\n            T[i] = updateframe(t, rawdata[i], None, cam[i], axs[i], fg)\n        elif C.name == 'asi':  # ASI\n            dasc = dio.load(C.fn, treq=T[sim.useCamBool][0])\n            C.tKeo = dasc.time\n\n            updateframe(0, dasc.values, dasc.wavelength, C,\n                        axs[i], fg)  # FIXME may need API update\n            try:\n                overlayrowcol(axs[i], C.hlrows, C.hlcols)\n            except AttributeError:\n                pass  # az/el were not registered\n        else:\n            logging.error(f'unknown camera {C.name} index {i}')\n\n        if i == 0:\n            axs[0].set_ylabel(datetime.strftime(\n                T[0], '%x')).set_color('limegreen')\n\n            # NOTE: commented out due to Matplotlib 1.x bugs\n            # fg.suptitle(datetime.strftime(T[0],'%x')) #makes giant margins that tight_layout doesn't help, bug\n            # fg.text(0.5,0.15,datetime.strftime(T[0],'%x'))#, va='top',ha='center') #bug too\n            # fg.tight_layout()\n            # fg.subplots_adjust(top=0.95)\n\n    # TODO: T[0] is fastest cam now, but needs generalization\n    writeplots(fg, 'rawFrame', T[0], odir=odir,\n               dpi=sim.dpi, facecolor='k', doclose=doclose)", "response": "plot real image for all cameras in the cluster"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef updateframe(t, raw, wavelen, cam, ax, fg):\n    showcb = False\n\n    ttxt = f'Cam {cam.name}: '\n\n    if raw.ndim == 3:\n        frame = raw[t, ...]\n    elif raw.ndim == 2:\n        frame = raw\n    elif raw.ndim == 1:  # GeoData\n        frame = raw.reshape((sqrt(raw.size), -1))\n    else:\n        raise ValueError('ndim==3 or 2')\n# %% filtering (optional) # FIXME provide noise estimate\n    \"\"\"\n    http://scikit-image.org/docs/dev/api/skimage.restoration.html?highlight=denoise\n    \"\"\"\n    if 'wiener' in cam.cp:\n        # psf = ones((cam.wiener, cam.wiener)) / cam.wiener**2\n        frame = wiener(frame, cam.cp['wiener'])\n\n    if 'medfilt2d' in cam.cp:\n        frame = medfilt2d(frame.astype(float), cam.cp['medfilt2d'])\n\n    if 'denoise_bilateral' in cam.cp:\n        frame = skres.denoise_bilateral(((frame - cam.clim[0]) / (cam.clim[1] - cam.clim[0])).clip(0., 1.),\n                                        sigma_color=0.05, sigma_spatial=15, multichannel=False)\n    if 'denoise_tv_chambolle' in cam.cp:\n        frame = skres.denoise_tv_chambolle(((frame - cam.clim[0]) / (cam.clim[1] - cam.clim[0])).clip(0., 1.),\n                                           )\n# %% plotting raw uint16 data\n    if False:\n        v = vis.HistEqStretch(frame)\n        NORM = ImageNormalize(stretch=v)\n\n    NORM = None\n    #  NORM = LogNorm()\n    # NORM = ImageNormalize(stretch=vis.LogStretch())\n\n    hi = ax.imshow(frame,\n                   origin='lower', interpolation='none',\n                   # aspect='equal',\n                   # extent=(0,C.superx,0,C.supery),\n                   vmin=cam.clim[0], vmax=cam.clim[1],\n                   cmap='gray', norm=NORM)\n\n    # autoscale(False) for case where we put plots on top of image\n    # yet still reduces blank space between subplots\n    ax.autoscale(False)\n\n    if showcb:  # showing the colorbar makes the plotting go 5-10x more slowly\n        hc = fg.colorbar(hi, ax=ax)  # not cax!\n        hc.set_label(f'{raw.dtype} data numbers')\n\n    dtframe = datetime.utcfromtimestamp(cam.tKeo[t])\n\n    if cam.name == 'asi':\n        dtstr = datetime.strftime(dtframe, '%H:%M:%S')\n        if int(wavelen[t]) == 428:\n            tcolor = 'blue'\n        elif int(wavelen[t]) == 557:\n            tcolor = 'limegreen'\n        elif int(wavelen[t]) == 630:\n            tcolor = 'red'\n        else:\n            tcolor = 'limegreen'\n        ttxt += f'{dtstr} $\\lambda$ {wavelen[t]:.1f}'\n    else:\n        dtstr = datetime.strftime(dtframe, '%H:%M:%S.%f')[:-3]  # millisecond\n        tcolor = 'limegreen'\n        ttxt += f'{dtstr}'\n\n    ax.set_title(ttxt, color=tcolor)\n\n    ax.set_axis_off()  # no ticks\n\n    if False:\n        ax.set_xlabel('x-pixel')\n        if cam.name == 0:\n            ax.set_ylabel('y-pixel')\n# %% plotting 1D cut line\n    try:\n        ax.plot(cam.cutcol[cam.Lcind], cam.cutrow[cam.Lcind],\n                marker='.', linestyle='none', color='blue', markersize=1, alpha=0.5)\n        # plot magnetic zenith\n        ax.scatter(x=cam.cutcol[cam.angleMagzenind],\n                   y=cam.cutrow[cam.angleMagzenind],\n                   marker='o', facecolors='none', color='red', s=500, linewidth=2, alpha=0.5)\n    except AttributeError:  # asi\n        pass\n# %% plot cleanup\n    ax.grid(False)  # in case Seaborn is used\n    return dtframe", "response": "update the frame with the new data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns info for all Nodes", "response": "def get_nodes(api_url=None, verify=False, cert=list()):\n    \"\"\"\n    Returns info for all Nodes\n\n    :param api_url: Base PuppetDB API url\n\n    \"\"\"\n    return utils._make_api_request(api_url, '/nodes', verify, cert)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_node(api_url=None, node_name=None, verify=False, cert=list()):\n    return utils._make_api_request(api_url, '/nodes/{0}'.format(node_name), verify, cert)", "response": "Returns info for a node"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_node_fact_by_name(api_url=None, node_name=None, fact_name=None, verify=False, cert=list()):\n    return utils._make_api_request(api_url, '/nodes/{0}/facts/{1}'.format(node_name,\n        fact_name), verify, cert)", "response": "Returns specified fact for a Node"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_node_resource_by_type(api_url=None, node_name=None,\n    type_name=None, verify=False, cert=list()):\n    \"\"\"\n    Returns specified resource for a Node\n\n    :param api_url: Base PuppetDB API url\n    :param node_name: Name of node\n    :param type_name: Type of resource\n\n    \"\"\"\n    return utils._make_api_request(api_url, '/nodes/{0}/resources/{1}'.format(node_name,\n        type_name), verify, cert)", "response": "Returns a resource for a node by type"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef call(self, request=None, *args, **kwargs):\n        if request is not None:\n            self.request = request\n\n        retry = self.request.configuration.retry\n        if not isinstance(retry, SimpleRetry):\n            raise Error('Currently only the fast retry strategy is supported')\n\n        last_exception = None\n        for i in range(0, retry.max_retry):\n            try:\n                if i > 0:\n                    retry.sleep_jitter()\n\n                self.call_once()\n                return self.response\n\n            except Exception as ex:\n                last_exception = RequestFailed(message='Request failed', cause=ex)\n                logger.debug(\"Request %d failed, exception: %s\" % (i, ex))\n\n                # Last exception - throw it here to have a stack\n                if i+1 == retry.max_retry:\n                    raise last_exception\n\n        raise last_exception", "response": "Calls multiple time - with retry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert given value to long if possible otherwise None is returned.", "response": "def field_to_long(value):\n        \"\"\"\n        Converts given value to long if possible, otherwise None is returned.\n\n        :param value:\n        :return:\n        \"\"\"\n        if isinstance(value, (int, long)):\n            return long(value)\n        elif isinstance(value, basestring):\n            return bytes_to_long(from_hex(value))\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_url(self):\n        url = \"%s/1.0/%s/%s/%s\" % (\n            self.request.endpoint.get_url(),\n            self.request.api_object,\n            self.request.api_method,\n            to_hex(self.request.nonce)\n        )\n        return url", "response": "Construct URL for the current object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform one API request.", "response": "def call_once(self, request=None, *args, **kwargs):\n        \"\"\"\n        Performs one API request.\n        Raises exception on failure.\n\n        :param request:\n        :param args:\n        :param kwargs:\n        :return: response\n        \"\"\"\n        if request is not None:\n            self.request = request\n\n        config = self.request.configuration\n        if config.http_method != EBConsts.HTTP_METHOD_POST or config.method != EBConsts.METHOD_REST:\n            raise Error('Not implemented yet, only REST POST method is allowed')\n\n        url = self.request.url if self.request.url is not None else self.build_url()\n        logger.debug(\"URL to call: %s\", url)\n\n        # Do the request\n        resp = requests.post(url, json=self.request.body, timeout=config.timeout, headers=self.request.headers)\n        self.last_resp = resp\n        return self.check_response(resp)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking the response code of the response and raises an exception if it is not OK", "response": "def check_response(self, resp):\n        \"\"\"\n        Checks response after request was made.\n        Checks status of the response, mainly\n\n        :param resp:\n        :return:\n        \"\"\"\n\n        # For successful API call, response code will be 200 (OK)\n        if resp.ok:\n            json = resp.json()\n            self.response = ResponseHolder()\n            self.response.response = json\n\n            # Check the code\n            if 'status' not in json:\n                raise InvalidResponse('No status field')\n\n            self.response.status = self.field_to_long(json['status'])\n            if self.response.status != EBConsts.STATUS_OK:\n                txt_status = self.get_text_status(json)\n                raise InvalidStatus('Status is %s (%04X)'\n                                    % (txt_status if txt_status is not None else \"\", self.response.status))\n\n            if self.response_checker is not None:\n                self.response_checker(self.response)\n\n            return self.response\n\n        else:\n            # If response code is not ok (200), print the resulting http error code with description\n            resp.raise_for_status()\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an email message object which implements the email. message. Message interface.", "response": "def create_email(filepaths, collection_name):\n    \"\"\"Create an email message object which implements the\n    email.message.Message interface and which has the files to be shared\n    uploaded to min.us and links placed in the message body.\n\n    \"\"\"\n    gallery = minus.CreateGallery()\n\n    if collection_name is not None:\n        gallery.SaveGallery(collection_name)\n\n    interface = TerminalInterface()\n    interface.new_section()\n    interface.message(\\\n        'Uploading files to http://min.us/m%s...' % (gallery.reader_id,))\n\n    item_map = { }\n    for path in filepaths:\n        interface.message('Uploading %s...' % (os.path.basename(path),))\n        interface.start_progress()\n        item = minus.UploadItem(path, gallery,\n                os.path.basename(path), interface.update_progress)\n        interface.end_progress()\n        item_map[item.id] = os.path.basename(path)\n\n    msg_str = ''\n    msg_str += \"I've shared some files with you. They are viewable as a \"\n    msg_str += \"gallery at the following link:\\n\\n - http://min.us/m%s\\n\\n\" %\\\n            (gallery.reader_id,)\n    msg_str += \"The individual files can be downloaded from the following \"\n    msg_str += \"links:\\n\\n\"\n\n    for item, name in item_map.items():\n        msg_str += ' - http://i.min.us/j%s%s %s\\n' % \\\n                (item, os.path.splitext(name)[1], name)\n\n    msg = MIMEText(msg_str)\n    msg.add_header('Format', 'Flowed')\n    \n    return msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef account_overview(object):\n    return Layout(\n        Container(\n            Row(\n                Column2(\n                    Panel(\n                        'Avatar',\n                        Img(src=\"{}{}\".format(settings.MEDIA_URL, object.avatar)),\n                        collapse=True,\n                    ),\n                ),\n                Column10(\n                    Panel(\n                        'Account information',\n                        DescriptionList(\n                            'email',\n                            'first_name',\n                            'last_name',\n                        ),\n                    )\n                ),\n            )\n        )\n    )", "response": "Create layout for user profile"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of public methods of the object.", "response": "def list_public_methods(obj: Any):\n    \"\"\"\u627e\u51fa\u5bf9\u8c61\u4e2d\u7684\u51fd\u6570.\n\n    Parameters:\n\n        obj (Any): - \u8981\u6267\u884c\u7684\u5bf9\u8c61\n\n    Returns:\n\n        (List[str]): - \u6240\u6709\u5bf9\u8c61\u4e2d\u7684\u516c\u5f00\u7684\u65b9\u6cd5\u540d\n\n    \"\"\"\n    return [member for member in dir(obj)\n            if not member.startswith('_') and\n            callable(getattr(obj, member))]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef merge(iterable1, *args):\n\n    result_list = list(iterable1) if not isinstance(iterable1, dict) else eval('list(iterable1.items())')\n\n    for i, other in enumerate(args, start=1):\n        if not isinstance(other, type(iterable1)):\n            raise TypeError('the parameter type of index {} not equals type of index 0'.format(i))\n        if not isinstance(other, dict):\n            result_list[len(result_list):len(result_list)] = list(other)\n        else:\n            result_list[len(result_list):len(result_list)] = list(other.items())\n\n    if isinstance(iterable1, str):\n        return ''.join(result_list)\n    elif isinstance(iterable1, tuple):\n        return tuple(result_list)\n    elif isinstance(iterable1, dict):\n        return dict(result_list)\n    else:\n        return result_list", "response": "Returns an type of iterable1 value which merged after iterable1 used *args\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transpose_list(list_of_dicts):\n    res = {}\n    for d in list_of_dicts:\n        for k, v in d.items():\n            if k in res:\n                res[k].append(v)\n            else:\n                res[k] = [v]\n    return res", "response": "Transpose a list of dicts to a dict of lists\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_enter(__msg: Optional[Union[Callable, str]] = None) -> Callable:\n    # pylint: disable=missing-docstring\n    def decorator(__func):\n        @wraps(__func)\n        def wrapper(*args, **kwargs):\n            if __msg:\n                print(__msg)\n            else:\n                print('Entering {!r}({!r})'.format(__func.__name__, __func))\n            return __func(*args, **kwargs)\n        return wrapper\n    if callable(__msg):\n        return on_enter()(__msg)\n    return decorator", "response": "Decorator to display a message when entering a function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write(self, __text: str) -> None:\n        if __text == os.linesep:\n            self.handle.write(__text)\n        else:\n            frame = inspect.currentframe()\n            if frame is None:\n                filename = 'unknown'\n                lineno = 0\n            else:\n                outer = frame.f_back\n                filename = outer.f_code.co_filename.split(os.sep)[-1]\n                lineno = outer.f_lineno\n            self.handle.write('[{:>15s}:{:03d}] {}'.format(filename[-15:],\n                                                           lineno, __text))", "response": "Write text to the debug stream."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef enable() -> None:\n        if not isinstance(sys.stdout, DebugPrint):\n            sys.stdout = DebugPrint(sys.stdout)", "response": "Patch sys. stdout to use DebugPrint."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef starting(self):\n        ident = self.ident()\n        print('{} starting & consuming \"{}\".'.format(ident, self.to_consume))\n\n        if self.max_tasks:\n            print('{} will die after {} tasks.'.format(ident, self.max_tasks))\n        else:\n            print('{} will never die.'.format(ident))", "response": "Prints a startup message to stdout."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint an interrupt message to stdout.", "response": "def interrupt(self):\n        \"\"\"\n        Prints an interrupt message to stdout.\n        \"\"\"\n        ident = self.ident()\n        print('{} for \"{}\" saw interrupt. Finishing in-progress task.'.format(\n            ident,\n            self.to_consume\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stopping(self):\n        ident = self.ident()\n        print('{} for \"{}\" shutting down. Consumed {} tasks.'.format(\n            ident,\n            self.to_consume,\n            self.tasks_complete\n        ))", "response": "Prints a shutdown message to stdout."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_forever(self):\n        self.starting()\n        self.keep_running = True\n\n        def handle(signum, frame):\n            self.interrupt()\n            self.keep_running = False\n\n        signal.signal(signal.SIGINT, handle)\n\n        while self.keep_running:\n            if self.max_tasks and self.tasks_complete >= self.max_tasks:\n                self.stopping()\n\n            if self.gator.len():\n                result = self.gator.pop()\n                self.tasks_complete += 1\n                self.result(result)\n\n            if self.nap_time >= 0:\n                time.sleep(self.nap_time)\n\n        return 0", "response": "Runs the worker forever until the max_tasks is reached."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchanging the working directory to path for the duration of this context manager.", "response": "def chdir(path):\n    \"\"\"Change the working directory to `path` for the duration of this context\n    manager.\n\n    :param str path: The path to change to\n    \"\"\"\n    cur_cwd = os.getcwd()\n    os.chdir(path)\n    try:\n        yield\n    finally:\n        os.chdir(cur_cwd)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a temporary file for the duration of this context manager and delete it afterwards.", "response": "def temp_file():\n    \"\"\"Create a temporary file for the duration of this context manager,\n    deleting it afterwards.\n\n    Yields:\n        str - path to the file\n    \"\"\"\n    fd, path = tempfile.mkstemp()\n    os.close(fd)\n    try:\n        yield path\n    finally:\n        os.remove(path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef skip_pickle_inject(app, what, name, obj, skip, options):\n    if name.endswith('._raw_slave'):\n        return True\n    return None", "response": "skip the inject function for pickle"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the signature of the slave", "response": "def wraplet_signature(app, what, name, obj, options, signature, return_annotation):\n    \"\"\"have wrapplets use the signature of the slave\"\"\"\n    try:\n        wrapped = obj._raw_slave\n    except AttributeError:\n        return None\n    else:\n        slave_argspec = autodoc.getargspec(wrapped)\n        slave_signature = autodoc.formatargspec(obj, *slave_argspec)\n        return (slave_signature, return_annotation)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_users(path=settings.LOGIN_FILE):\n    if not os.path.exists(path):\n        return {}\n\n    data = \"\"\n    with open(path) as f:\n        data = f.read().splitlines()\n\n    users = {}\n    cnt = 1\n    for line in data:\n        line = line.split(\":\")\n\n        assert len(line) == 7, \"Bad number of fields in '%s', at line %d!\" % (\n            path,\n            cnt\n        )\n\n        users[line[0]] = {\n            \"pass_hash\": line[1],\n            \"uid\": line[2],\n            \"gid\": line[3],\n            \"full_name\": line[4],\n            \"home\": line[5],\n            \"shell\": line[6]\n        }\n\n        cnt += 1\n\n    return users", "response": "Read passwd file and return dict with users and all their settings."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave dictionary with user data to passwd file.", "response": "def save_users(users, path=settings.LOGIN_FILE):\n    \"\"\"\n    Save dictionary with user data to passwd file (default\n    :attr:`ftp.settings.LOGIN_FILE`).\n\n    Args:\n        users (dict): dictionary with user data. For details look at dict\n                      returned from :func:`load_users`.\n        path (str, default settings.LOGIN_FILE): path of the file, where the\n             data will be stored (default :attr:`ftp.settings.LOGIN_FILE`).\n    \"\"\"\n    with open(path, \"w\") as fh:\n        for username, data in users.items():\n            pass_line = username + \":\" + \":\".join([\n                data[\"pass_hash\"],\n                data[\"uid\"],\n                data[\"gid\"],\n                data[\"full_name\"],\n                data[\"home\"],\n                data[\"shell\"]\n            ])\n\n            fh.write(pass_line + \"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_permissions(filename, uid=None, gid=None, mode=0775):\n    if uid is None:\n        uid = get_ftp_uid()\n\n    if gid is None:\n        gid = -1\n\n    os.chown(filename, uid, gid)\n    os.chmod(filename, mode)", "response": "Set the permissions of a file or directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecode string to configuration dict.", "response": "def _decode_config(conf_str):\n    \"\"\"\n    Decode string to configuration dict.\n\n    Only values defined in settings._ALLOWED_MERGES can be redefined.\n    \"\"\"\n    conf_str = conf_str.strip()\n\n    # convert \"tttff\" -> [True, True, True, False, False]\n    conf = map(\n        lambda x: True if x.upper() == \"T\" else False,\n        list(conf_str)\n    )\n\n    return dict(zip(settings._ALLOWED_MERGES, conf))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nencodes conf_dict to string.", "response": "def _encode_config(conf_dict):\n    \"\"\"Encode `conf_dict` to string.\"\"\"\n    out = []\n\n    # get variables in order defined in settings._ALLOWED_MERGES\n    for var in settings._ALLOWED_MERGES:\n        out.append(conf_dict[var])\n\n    # convert bools to chars\n    out = map(\n        lambda x: \"t\" if x else \"f\",\n        out\n    )\n\n    return \"\".join(out)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_user_config(username, path=settings.LOGIN_FILE):\n    return _decode_config(load_users(path=path)[username][\"full_name\"])", "response": "Read user s configuration from otherwise unused field full_name in\n    passwd file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_user_config(username, conf_dict, path=settings.LOGIN_FILE):\n    users = load_users(path=path)\n    users[username][\"full_name\"] = _encode_config(conf_dict)\n    save_users(users, path=path)", "response": "Save user s configuration to otherwise unused field full_name in passwd\n    file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_ecdsap256_key_pair():\n    pub  = ECDSAP256PublicKey()\n    priv = ECDSAP256PrivateKey()\n    rc = _lib.xtt_crypto_create_ecdsap256_key_pair(pub.native, priv.native)\n    if rc == RC.SUCCESS:\n        return (pub, priv)\n    else:\n        raise error_from_code(rc)", "response": "Create a new ECDSAP256 key pair."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving an optparse. Option returns a two - tuple of the option s variable name and default value.", "response": "def get_option_default(option):\n    \"\"\"\n    Given an optparse.Option, returns a two-tuple of the option's variable name\n    and default value.\n    \n    \"\"\"\n    return (\n        option.dest, \n        None if option.default is optparse.NO_DEFAULT else option.default,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_command_class_from_apps(name, apps, exclude_packages=None, exclude_command_class=None):\n    if exclude_packages is None:\n        exclude_packages = []\n    for app in reversed(\n        [app for app in apps if not issubpackage(app, exclude_packages)]):\n        try:\n            command_class = import_module(\n                \"{app:s}.management.commands.{name:s}\".format(\n                    app=app, name=name)).Command\n        except (ImportError, AttributeError):\n            pass\n        else:\n            if exclude_command_class is None or \\\n                not issubclass(command_class, exclude_command_class):\n                return command_class\n    return None", "response": "Returns the last command class that matches the given name in the given apps."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the command class for the given name.", "response": "def get_command_class(name, exclude_packages=None, exclude_command_class=None):\n    \"\"\"\n    Searches \"django.core\" and the apps in settings.INSTALLED_APPS to find the\n    named command class, optionally skipping packages or a particular\n    command class.\n    \n    \"\"\"\n    from django.conf import settings\n    return get_command_class_from_apps(\n        name, \n        settings.INSTALLED_APPS \\\n            if \"django.core\" in settings.INSTALLED_APPS \\\n            else (\"django.core\",) + tuple(settings.INSTALLED_APPS),\n        exclude_packages=exclude_packages,\n        exclude_command_class=exclude_command_class)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch django. core and django. apps to find the command class and returns the command and its default options dictionary.", "response": "def get_command_and_defaults(name, exclude_packages=None, exclude_command_class=None):\n    \"\"\"\n    Searches \"django.core\" and the apps in settings.INSTALLED_APPS to find the\n    named command class, optionally skipping packages or a particular command\n    class. Gathers the command's default options and returns the command and\n    options dictionary as a two-tuple: (command, options). Returns (None, {})\n    if the command class could not be found.\n    \n    \"\"\"\n    command = get_command_class(name,\n        exclude_packages=exclude_packages,\n        exclude_command_class=exclude_command_class)\n    defaults = {}\n    if command is not None:\n        command = command()\n        defaults = command.get_option_defaults() \\\n            if isinstance(command, Command) \\\n            else get_option_defaults(command)\n    return (command, defaults)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if a command exists in the database.", "response": "def check_command(self, name, exclude_packages=None, exclude_command_class=None):\n    \"\"\"\n    Uses get_command_class() to check for the presence of a command.\n    \n    \"\"\"\n    return get_command_class(\n        name, \n        exclude_packages=exclude_packages,\n        exclude_command_class=exclude_command_class) is not None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if a named program is available on the shell PATH.", "response": "def check_program(name):\n    \"\"\"\n    Uses the shell program \"which\" to determine whether the named program\n    is available on the shell PATH.\n    \n    \"\"\"\n    with open(os.devnull, \"w\") as null:\n        try:\n            subprocess.check_call((\"which\", name), stdout=null, stderr=null)\n        except subprocess.CalledProcessError as e:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_option_lists(self):\n        return [self.get_option_list()] + \\\n            [option_list\n                for name, description, option_list\n                in self.get_option_groups()]", "response": "A hook to override the option lists used to generate option names\n        and defaults."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_options(self):\n        return reduce(\n            list.__add__,\n            [list(option_list) for option_list in self.get_option_lists()],\n            [])", "response": "A hook to override the flattened list of all options used to generate\n        option names and defaults."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a parser for the option groups.", "response": "def create_parser(self, prog_name, subcommand):\n        \"\"\"\n        Customize the parser to include option groups.\n        \n        \"\"\"\n        parser = optparse.OptionParser(\n            prog=prog_name,\n            usage=self.usage(subcommand),\n            version=self.get_version(),\n            option_list=self.get_option_list())\n        for name, description, option_list in self.get_option_groups():\n            group = optparse.OptionGroup(parser, name, description);\n            list(map(group.add_option, option_list))\n            parser.add_option_group(group)\n        return parser"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform any required parsing on the options from optparse.", "response": "def parse_options(self, options):\n        \"\"\"\n        Perform any required parsing on the option values from optparse.\n        Attempts to call a parse_option_<name> method for each option name\n        returned by self.get_option_names().\n        \n        \"\"\"\n        for name in self.get_option_names():\n            parse = getattr(self, \"parse_option_{name:s}\".format(\n                name=name), None)\n            if parse is not None and isinstance(parse, collections.Callable):\n                options[name] = parse()\n        return options"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle(self, *arguments, **options):\n        self.arguments = arguments\n        self.options = options\n        self.arguments = self.parse_arguments(arguments)\n        self.options = self.parse_options(options)\n        \n        for name in self.get_actions():\n            validate = getattr(self, \"validate_{name:s}\".format(\n                name=name), None)\n            if validate is not None and isinstance(validate, collections.Callable):\n                validate(*arguments, **options)\n        for name in self.get_actions():\n            handle = getattr(self, \"handle_{name:s}\".format(\n                name=name), None)\n            if handle is not None and isinstance(handle, collections.Callable):\n                handle(*self.arguments, **self.options)", "response": "Runs validate_<action > and handle_<action > for each action named by self. get_actions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking whether the given Django management command exists excluding the given Django management command from the search.", "response": "def check_command(self, name):\n        \"\"\"\n        Checks whether the given Django management command exists, excluding\n        this command from the search.\n        \n        \"\"\"\n        if not check_command(\n            name, \n            exclude_packages=self.get_exclude_packages(),\n            exclude_command_class=self.__class__):\n            raise management.CommandError(\n                \"The management command \\\"{name:s}\\\" is not available. \"\n                \"Please ensure that you've added the application with \"\n                \"the \\\"{name:s}\\\" command to your INSTALLED_APPS \"\n                \"setting\".format(\n                    name=name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks whether a program is available on the shell PATH.", "response": "def check_program(self, name):\n        \"\"\"\n        Checks whether a program is available on the shell PATH.\n        \n        \"\"\"\n        if not check_program(name):\n            raise management.CommandError(\n                \"The program \\\"{name:s}\\\" is not available in the shell. \"\n                \"Please ensure that \\\"{name:s}\\\" is installed and reachable \"\n                \"through your PATH environment variable.\".format(\n                    name=name))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef call_command(self, name, *arguments, **options):\n        command, defaults = get_command_and_defaults(\n            name,\n            exclude_packages=self.get_exclude_packages(),\n            exclude_command_class=self.__class__)\n        if command is None:\n            raise management.CommandError(\n                \"Unknown command: {name:s}\".format(\n                    name=name))\n        defaults.update(options)\n        return command.execute(*arguments, **defaults)", "response": "Calls the given Django management command and returns the result."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling the shell program with the given arguments.", "response": "def call_program(self, name, *arguments):\n        \"\"\"\n        Calls the shell program on the PATH with the given arguments.\n        \n        \"\"\"\n        verbosity = self.options.get(\"verbosity\", 1)\n        with self.devnull as null:\n            try:\n                subprocess.check_call((name,) + tuple(arguments), \n                    stdout=null if verbosity == 0 else self.stdout,\n                    stderr=null if verbosity == 0 else self.stderr)\n            except subprocess.CalledProcessError as error:\n                raise management.CommandError(\n                    \"{name:s} failed with exit code {code:d}\".format(\n                        name=name, code=error.returncode))\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing version from module without importing or evaluating the code.", "response": "def version(modfile):\n    '''\n    Parse version from module without importing or evaluating the code.\n    The module should define a __version__ variable like __version__ = '2.0.1'.\n    '''\n    import re\n    with open(modfile) as fh:\n        for line in fh:\n            m = re.search(r\"^__version__ = '([^']+)'$\", line)\n            if m:\n                return m.group(1)\n    raise Exception('No __version__ string found in {fn}'.format(fn=modfile))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_score(self):\n\n        if not self.subject_token:\n            return\n\n        vote_score = 0\n        replies_score = 0\n        for msg in self.message_set.all():\n            # Calculate replies_score\n            replies_score += self._get_score(300, msg.received_time)\n\n            # Calculate vote_score\n            for vote in msg.vote_set.all():\n                vote_score += self._get_score(100, vote.created)\n\n        # Calculate page_view_score\n        page_view_score = self.hits * 10\n\n        self.score = (page_view_score + vote_score + replies_score) // 10\n        self.save()", "response": "Update the score of this thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef url(self):\n        return reverse('archives:thread_view',\n                       args=[self.mailinglist.name,\n                             self.thread.subject_token])", "response": "Shortcut to get thread url"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_config():  # pragma: no cover\n    description = \"\"\"\\\n        Print the deployment settings for a Pyramid application.  Example:\n        'psettings deployment.ini'\n    \"\"\"\n    parser = argparse.ArgumentParser(\n        description=textwrap.dedent(description)\n    )\n    parser.add_argument(\n        'config_uri', type=str, help='an integer for the accumulator'\n    )\n    parser.add_argument(\n        '-k', '--key',\n        dest='key',\n        metavar='PREFIX',\n        type=str,\n        action='store',\n        help=(\n            \"Tells script to print only specified\"\n            \" config tree provided by dotted name\"\n        )\n    )\n    args = parser.parse_args(sys.argv[1:])\n\n    config_uri = args.config_uri\n    env = bootstrap(config_uri)\n    config, closer = env['registry']['config'], env['closer']\n\n    try:\n        print(printer(slice_config(config, args.key)))\n    except KeyError:\n        print(\n            'Sorry, but the key path {0}, does not exists in Your config!'\n            .format(args.key)\n        )\n    finally:\n        closer()", "response": "Print the deployment settings for a Pyramid application."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef printer(data, depth=0):\n    indent = _INDENT * depth\n    config_string = '' if not depth else ':\\n'\n    if isinstance(data, dict):\n        for key, val in data.items():\n            line = '{0}{1}'.format(indent, key)\n            values = printer(val, depth + 1)\n            if not values.count('\\n'):\n                values = ': {0}'.format(values.lstrip())\n\n            line = '{line}{values}'.format(line=line, values=values)\n            config_string += '{0}\\n'.format(line)\n\n    elif isinstance(data, list):\n        for elem in data:\n            config_string += '{0} - {1}\\n'.format(indent, elem)\n    else:\n        config_string = '{0}{1} ({2})'.format(\n            indent, data, data.__class__.__name__\n        )\n\n    return config_string.rstrip('\\n')", "response": "Returns a string with formatted version of the data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef slice_config(config, key):\n    if key:\n        keys = key.split('.')\n        for k in keys:\n            config = config[k]\n\n    return config", "response": "Slice config for printing as defined in key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsplit the file size into several chunks.", "response": "def split_size(size):\n    '''Split the file size into several chunks.'''\n    rem = size % CHUNK_SIZE\n    if rem == 0:\n        cnt = size // CHUNK_SIZE\n    else:\n        cnt = size // CHUNK_SIZE + 1\n\n    chunks = []\n    for i in range(cnt):\n        pos = i * CHUNK_SIZE\n        if i == cnt - 1:\n            disp = size - pos\n        else:\n            disp = CHUNK_SIZE\n        chunks.append((pos, disp))\n    return chunks"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreverse the content of inf write to outf.", "response": "def reverse_fd(inf, outf):\n    '''Reverse the content of inf, write to outf.\n    Both inf and outf are file objects.\n    inf must be seekable.\n    '''\n    inf.seek(0, 2)\n    size = inf.tell()\n    if not size:\n        return\n\n    chunks = split_size(size)\n    for chunk in reversed(chunks):\n        inf.seek(chunk[0], 0)\n        data = inf.read(chunk[1])\n        if len(data) != chunk[1]:\n            raise IOError('incomplete I/O operation')\n        outf.write(data[::-1])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreverses the content of infile write to outfile. Both infile and outfile are filenames or filepaths.", "response": "def reverse_file(infile, outfile):\n    '''Reverse the content of infile, write to outfile.\n    Both infile and outfile are filenames or filepaths.\n    '''\n    with open(infile, 'rb') as inf:\n        with open(outfile, 'wb') as outf:\n            reverse_fd(inf, outf)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef imp_print(self, text, end):\n\t\tPRINT(text, end=end, file=win_unicode_console.streams.stdout_text_transcoded)", "response": "Use win_unicode_console to print text to stdout."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef imp_print(self, text, end):\n\t\tsys.stdout.write((text + end).encode(\"utf-8\"))", "response": "Directly send utf8 bytes to stdout"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cascade(sequence, full=False):\n    if len(sequence) == 1:\n        return sequence[0]\n    \n    left = sequence[0]\n    if full:\n        intermed = []\n    for cdiff in sequence[1:]:\n        right = restore(cdiff, left)\n        if full:\n            intermed.append(right)\n        left = right\n\n    return left", "response": "Cascade a sequence of string entries into a single entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrestoring the full text of either the edited text or the edited version using the cdiff dictionary returned by the ArcGIS.", "response": "def restore(cdiff, a):\n    \"\"\"Restores the full text of either the edited text using the\n    compressed diff.\n\n    Args:\n        cdiff (dict): compressed diff returned by\n          :func:`~acorn.logging.diff.compress`. \n        a (str or list): *original* string or list of strings to use as a\n          reference to restore the edited version.\n    \"\"\"\n    left = a.splitlines(1) if isinstance(a, string_types) else a\n    lrest = []\n    iline = 0\n    \n    for i, line in enumerate(left):\n        if iline not in cdiff:\n            lrest.append(\"  \" + line)\n            iline += 1\n        else:\n            cs = [l[0] for l in cdiff[iline]]\n            add = cs.count('+') - cs.count('-')\n            lrest.extend(cdiff[iline])\n            iline += add + 1\n            \n    for i in sorted(cdiff.keys()):\n        if i >= len(left):\n            lrest.extend(cdiff[i])\n\n    from difflib import restore\n    return list(restore(lrest, 2))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform the *compressed* diff of `a` and `b` such that the original contents of the :func:`difflib.ndiff` call can be reconstructed using :func:`~acorn.logging.diff.restore`. Args: a (str or list): *original* string or list of strings to diff. b (str or list): *edited* string or list of strings to diff.", "response": "def compress(a, b):\n    \"\"\"Performs the *compressed* diff of `a` and `b` such that the original\n    contents of the :func:`difflib.ndiff` call can be reconstructed using\n    :func:`~acorn.logging.diff.restore`.\n\n    Args:\n        a (str or list): *original* string or list of strings to diff.\n        b (str or list): *edited* string or list of strings to diff.\n    \"\"\"\n    from difflib import ndiff\n    left = a.splitlines(1) if isinstance(a, string_types) else a\n    right = b.splitlines(1) if isinstance(b, string_types) else b\n    ldiff = list(ndiff(left, right))\n    \n    result = {}\n    latest = None   \n    combo = None\n    icombo = 0\n    iorig = 0\n    \n    for i, line in enumerate(ldiff):\n        cs = [l[0] for l in ldiff[i:min((i+4, len(ldiff)))]]\n        if cs[0] != ' ':\n            #Initialize a new entry in the diff list.\n            if latest is None:\n                latest = iorig\n                result[latest] = []\n                \n            #We have to be careful. At a minimum, there may be a '-' or a '+' when the lines are \n            #completely added or deleted. When they are *altered*, then we also expect one or\n            #more '?' lines showing the differences.\n            if combo is None:\n                if cs[0] == '-':\n                    #Check whether the next lines have one of these combinations:\n                    if (len(cs) >=3 and cs[1] == '+' and cs[2] == '?'):\n                        combo = 3\n                    elif (len(cs) >= 4 and cs[1] == '?' and cs[2] == '+'\n                          and cs[3] == '?'):\n                        combo = 4\n                    else:\n                        #This is a stand-alone deletion.\n                        combo = 1\n                elif cs[0] == '+':\n                    #This is for the stand-alone addition.\n                    combo = 1\n                \n            if icombo < combo:\n                result[latest].append(line)\n                icombo += 1\n            \n            if icombo == combo:\n                if combo > 1:\n                    latest = None\n                combo = None\n                icombo = 0\n                if cs[0] != '+':\n                    iorig += 1\n        else:\n            latest = None\n            iorig += 1\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_url(width, height, color=True):\n    d = dict(width=width, height=height)\n    return URL % d", "response": "Get the URL for a placekitten image."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a global IOLoop instance.", "response": "def instance():\n        \"\"\"Returns a global `IOLoop` instance.\n\n        Most applications have a single, global `IOLoop` running on the\n        main thread.  Use this method to get this instance from\n        another thread.  To get the current thread's `IOLoop`, use `current()`.\n        \"\"\"\n        if not hasattr(IOLoop, \"_instance\"):\n            with IOLoop._instance_lock:\n                if not hasattr(IOLoop, \"_instance\"):\n                    # New instance after double check\n                    IOLoop._instance = IOLoop()\n        return IOLoop._instance"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_paste(self, content):\n        r = requests.post(\n            self.endpoint + '/pastes',\n            data={'content': content},\n            allow_redirects=False)\n\n        if r.status_code == 302:\n            return r.headers['Location']\n\n        if r.status_code == 413:\n            raise MaxLengthExceeded('%d bytes' % len(content))\n\n        try:\n            error_message = r.json()['error']\n        except Exception:\n            error_message = r.text\n\n        raise UnexpectedError(error_message)", "response": "Create a raw paste of the given content."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes a comma - separated string of key ids or fingerprints and returns a list of key ids", "response": "def match_keys(inp, p=False):\n    \"\"\"Takes a comma-separated string of key ids or fingerprints and returns a list of key ids\"\"\"\n    _keys = []\n    ssh_keys = DO.get_ssh_keys()\n    for k in inp.split(\",\"):\n        done = False\n        if k.isdigit():\n            for _ in [s for s in ssh_keys if s[\"id\"] == int(k)]:\n                done = True\n                _keys.append(_[\"fingerprint\"])\n        else:\n            for _ in [s for s in ssh_keys if s[\"fingerprint\"] == k]:\n                done = True\n                _keys.append(_[\"fingerprint\"])\n        if p and not done:\n            print(\"Could not find a match for '{}', skipping\".format(k), file=sys.stderr)\n    return _keys"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cd(cd_path, create=False):\n    oricwd = os.getcwd()\n    if create:\n        mkdir(cd_path)\n    try:\n        os.chdir(cd_path)\n        yield\n    finally:\n        os.chdir(oricwd)", "response": "cd to target dir when running in this block\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes a generator like cd but use it for function Taxonomy", "response": "def cd_to(path, mkdir=False):\n    \"\"\"make a generator like cd, but use it for function\n\n    Usage::\n\n        >>> @cd_to(\"/\")\n        ... def say_where():\n        ...     print(os.getcwd())\n        ...\n        >>> say_where()\n        /\n\n    \"\"\"\n    def cd_to_decorator(func):\n        @functools.wraps(func)\n        def _cd_and_exec(*args, **kwargs):\n            with cd(path, mkdir):\n                return func(*args, **kwargs)\n        return _cd_and_exec\n    return cd_to_decorator"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting file or dir", "response": "def rm(path, isdir=False):\n    \"\"\"delete file or dir\n    returns True if deleted, if file/dir not exists, return False\n\n    :param path: path to delete\n    :param isdir: set True if you want to delete dir\n    \"\"\"\n    if isdir:\n        deleted = os.path.isdir(path)\n        shutil.rmtree(path, ignore_errors=True)\n    elif os.path.isfile(path) or os.path.islink(path):\n        deleted = True\n        os.remove(path)\n    else:\n        deleted = False\n    return deleted"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef require_python(minimum):\n    if sys.hexversion < minimum:\n        hversion = hex(minimum)[2:]\n        if len(hversion) % 2 != 0:\n            hversion = '0' + hversion\n        split = list(hversion)\n        parts = []\n        while split:\n            parts.append(int(''.join((split.pop(0), split.pop(0))), 16))\n        major, minor, micro, release = parts\n        if release == 0xf0:\n            print('Python {0}.{1}.{2} or better is required'.format(\n                major, minor, micro))\n        else:\n            print('Python {0}.{1}.{2} ({3}) or better is required'.format(\n                major, minor, micro, hex(release)[2:]))\n        sys.exit(1)", "response": "Require at least a minimum Python version."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_version(filename, pattern=None):\n    if pattern is None:\n        cre = DEFAULT_VERSION_RE\n    else:\n        cre = re.compile(pattern)\n    with open(filename) as fp:\n        for line in fp:\n            if line.startswith('__version__'):\n                mo = cre.search(line)\n                assert mo, 'No valid __version__ string found'\n                return mo.group('version')\n    raise AssertionError('No __version__ assignment found')", "response": "Extract the version number from a file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nproviding a long description.", "response": "def long_description(*filenames):\n    \"\"\"Provide a long description.\"\"\"\n    res = ['']\n    for filename in filenames:\n        with open(filename) as fp:\n            for line in fp:\n                res.append('   ' + line)\n            res.append('')\n        res.append('\\n')\n    return EMPTYSTRING.join(res)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprovides a short description.", "response": "def description(filename):\n    \"\"\"Provide a short description.\"\"\"\n    # This ends up in the Summary header for PKG-INFO and it should be a\n    # one-liner.  It will get rendered on the package page just below the\n    # package version header but above the long_description, which ironically\n    # gets stuff into the Description header.  It should not include reST, so\n    # pick out the first single line after the double header.\n    with open(filename) as fp:\n        for lineno, line in enumerate(fp):\n            if lineno < 3:\n                continue\n            line = line.strip()\n            if len(line) > 0:\n                return line"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncleaning all build artifacts", "response": "def clean(docs=False, bytecode=False, extra=''):\n    '''Cleanup all build artifacts'''\n    patterns = ['build', 'dist', 'cover', 'docs/_build', '**/*.pyc', '*.egg-info', '.tox', '**/__pycache__']\n    for pattern in patterns:\n        print('Removing {0}'.format(pattern))\n        lrun('rm -rf {0}'.format(pattern))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfetching Houses from the Plum cloud servers.", "response": "async def fetch_houses(self):\n        \"\"\"Lookup details for devices on the plum servers\"\"\"\n        try:\n            async with self._websession.get(\"https://production.plum.technology/v2/getHouses\", headers=self.headers) as response:\n                return await response.json()\n\n        except IOError:\n            print(\"Unable to login to Plum cloud servers.\")\n            sys.exit(5)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def fetch_house(self, house_id):\n        url = \"https://production.plum.technology/v2/getHouse\"\n        data = {\"hid\": house_id}\n        return await self.__post(url, data)", "response": "Fetch details for a given house id"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def fetch_room(self, room_id):\n        url = \"https://production.plum.technology/v2/getRoom\"\n        data = {\"rid\": room_id}\n        return await self.__post(url, data)", "response": "Get details for a given room id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget details for a given logical load", "response": "async def fetch_logical_load(self, llid):\n        \"\"\"Lookup details for a given logical load\"\"\"\n        url = \"https://production.plum.technology/v2/getLogicalLoad\"\n        data = {\"llid\": llid}\n        return await self.__post(url, data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget details for a given lightpad", "response": "async def fetch_lightpad(self, lpid):\n        \"\"\"Lookup details for a given lightpad\"\"\"\n        url = \"https://production.plum.technology/v2/getLightpad\"\n        data = {\"lpid\": lpid}\n        return await self.__post(url, data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the houses of the plum server.", "response": "async def update_houses(self):\n        \"\"\"Lookup details for devices on the plum servers\"\"\"\n        houses = await self.fetch_houses()\n        for house_id in houses:\n            asyncio.Task(self.update_house(house_id))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_bytes(s, encoding=\"utf-8\"):\n    if isinstance(s, six.binary_type):\n        return s\n    else:\n        return six.text_type(s).encode(encoding)", "response": "Converts the string to a bytes type if not already."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_text(s, encoding=\"utf-8\"):\n    if isinstance(s, six.text_type):\n        return s\n    else:\n        return six.binary_type(s).decode(encoding)", "response": "Converts the bytes to a text type if not already."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nraise an exception if the two values do not have the same length.", "response": "def _check_len(a, b):\n    \"\"\"\n    Raises an exception if the two values do not have the same\n    length. This is useful for validating preconditions.\n\n    :a: the first value\n    :b: the second value\n    :raises ValueError: if the sizes do not match\n    \"\"\"\n    if len(a) != len(b):\n        msg = \"Length must be {}. Got {}\".format(len(a), len(b))\n        raise ValueError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncompares two strictly monotonous increasing 1d arrays return a similarity index > 0 = identical", "response": "def similarity1DdiffShapedArrays(arr1, arr2, normalize=False):\n    \"\"\"\n    compare two strictly monotonous increasing 1d arrays\n    of same or different size\n    return a similarity index-> 0=identical\n    \"\"\"\n    # assign longer and shorter here, because jit cannot do it\n    if len(arr1) < len(arr2):\n        arr1, arr2 = arr2, arr1\n    if not len(arr2):\n        out = sum(arr1)\n    else:\n        out = _calc(arr1, arr2)\n\n    if normalize:\n        if not len(arr2):\n            mn = arr1[0]\n            mx = arr1[-1]\n        else:\n            mn = min(arr1[0], arr2[0])\n            mx = max(arr1[-1], arr2[-1])\n        out = out/ (mx - mn)\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_instance(\n    model, method=\"file\",\n    img_dir=None, data_dir=None,\n    bucket=None\n):\n    \"\"\"Return an instance of ConsumeStore.\"\"\"\n    global _instances\n    if not isinstance(model, ConsumeModel):\n        raise TypeError(\n            \"get_instance() expects a parker.ConsumeModel derivative.\"\n        )\n\n    if method == \"file\":\n        my_store = store.get_filestore_instance(\n            img_dir=img_dir,\n            data_dir=data_dir\n        )\n    elif method == \"s3\":\n        my_store = store.get_s3store_instance(\n            bucket=bucket\n        )\n    else:\n        raise ValueError(\"Unexpected method value, '%s'.\" % method)\n\n    key = \"%s:%s\" % (repr(model), repr(my_store))\n\n    try:\n        instance = _instances[key]\n    except KeyError:\n        instance = ConsumeStore(model, my_store)\n        _instances[key] = instance\n\n    return instance", "response": "Return an instance of ConsumeStore."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_media(self):\n        chunk_path = fileops.get_chunk_path_from_string(\n            self.model.unique_field\n        )\n\n        for i, mediafile in enumerate(self.model.media_list):\n            filename = os.path.join(\n                self._get_prefix(),\n                chunk_path,\n                \"%s_%d\" % (self.model.unique_field, i)\n            )\n            self.store.store_media(filename, mediafile)", "response": "Store any media within model. media_list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_data(self):\n        filename = os.path.join(\n            self._get_prefix(),\n            self.model.site\n        )\n        self.store.store_json(\n            filename,\n            self.model.get_dict()\n        )", "response": "Store data as a JSON dump."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining if the specified member of _ast contains any for or while loops in its body definition.", "response": "def findloop(m):\n    \"\"\"Determines if the specified member of `_ast` contains any for or while loops\n    in its body definition.\n    \"\"\"\n    from _ast import For, While, FunctionDef, ClassDef, ListComp    \n    from _ast import DictComp\n    if isinstance(m, (FunctionDef, ClassDef)):\n        return False\n    elif isinstance(m, (For, While, ListComp, DictComp)):\n        return True\n    elif hasattr(m, \"value\"):\n        return findloop(m.value)\n    elif hasattr(m, \"__iter__\"):\n        for sm in m:\n            present = findloop(sm)\n            if present:\n                break\n        else:\n            present = False\n        return present\n    elif hasattr(m, \"body\") or hasattr(m, \"orelse\"):\n        body = hasattr(m, \"body\") and findloop(m.body)\n        orelse = hasattr(m, \"orelse\") and findloop(m.orelse)\n        return body or orelse\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef record_markdown(text, cellid):\n    from acorn.logging.database import record\n    from time import time\n    ekey = \"nb-{}\".format(cellid)\n    \n    global _cellid_map\n    if cellid not in _cellid_map:\n        from acorn.logging.database import active_db\n        from difflib import SequenceMatcher\n        from acorn.logging.diff import cascade\n        taskdb = active_db()\n        \n        if ekey not in taskdb.entities:\n            #Compute a new ekey if possible with the most similar markdown cell\n            #in the database.\n            possible = [k for k in taskdb.entities if k[0:3] == \"nb-\"]\n            maxkey, maxvalue = None, 0.\n            for pkey in possible:\n                sequence = [e[\"c\"] for e in taskdb.entities[pkey]]\n                state = ''.join(cascade(sequence))\n                matcher = SequenceMatcher(a=state, b=text)\n                ratio = matcher.quick_ratio()\n                if ratio > maxvalue and ratio > 0.5:\n                    maxkey, maxvalue = pkey, ratio\n\n            #We expect the similarity to be at least 0.5; otherwise we decide\n            #that it is a new cell.\n            if maxkey is not None:\n                ekey = pkey\n                            \n        _cellid_map[cellid] = ekey\n        \n    ekey = _cellid_map[cellid]        \n    entry = {\n        \"m\": \"md\",\n        \"a\": None,\n        \"s\": time(),\n        \"r\": None,\n        \"c\": text,\n    }\n    record(ekey, entry, diff=True)", "response": "Records the specified markdown text into the acorn database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_ipython_extension(ip):\n    decor = InteractiveDecorator(ip)\n    ip.events.register('post_run_cell', decor.post_run_cell)\n\n    #Unfortunately, the built-in \"pre-execute\" and \"pre-run\" methods are\n    #triggered *before* the input from the cell has been stored to\n    #history. Thus, we don't have access to the actual code that is about to be\n    #executed. Instead, we use our own :class:`HistoryManager` that overrides\n    #the :meth:`store_inputs` so we can handle the loop detection.\n    newhist = AcornHistoryManager(ip.history_manager, decor)\n    ip.history_manager = newhist", "response": "Loads the interacting decorator that ships with acorn into the ipython\n    interactive shell."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef store_inputs(self, line_num, source, source_raw=None):\n        self.old.store_inputs(line_num, source, source_raw)\n        #Now that the input has been stored correctly, intercept the\n        #pre-execution and create logs accordingly.\n        self.decorator.pre_run_cell(line_num, source)", "response": "Store source and raw input in history and create input cache\n        variables _i *"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of the objects that need to be decorated in the current user namespace based on their type.", "response": "def _get_decoratables(self, atype):\n        \"\"\"Returns a list of the objects that need to be decorated in the\n        current user namespace based on their type.\n\n        Args:\n            atype (str): one of the values in :attr:`atypes`. Specifies the type of\n              object to search.\n        \"\"\"\n        result = []\n        defmsg = \"Skipping {}; not decoratable or already decorated.\"\n        for varname in self.shell.run_line_magic(\"who_ls\", atype):\n            varobj = self.shell.user_ns.get(varname, None)\n            decorate = False\n            \n            if varobj is None: # Nothing useful can be done.\n                continue\n            \n            if atype in [\"classobj\", \"type\"]:\n                #Classes are only relevant if they have no __file__\n                #attribute; all other classes should be decorated by the\n                #full acorn machinery.\n                if (not hasattr(varobj, \"__acorn__\") and\n                    hasattr(varobj, \"__module__\") and\n                    varobj.__module__ == \"__main__\" and\n                    not hasattr(varobj, \"__file__\")):\n                    decorate = True\n                else:\n                    msg.std(defmsg.format(varname), 3)\n                    \n            elif atype in [\"function\", \"staticmethod\"]:\n                # %who_ls will only return functions from the *user*\n                # namespace, so we don't have a lot to worry about here.\n                func = None\n                if atype == \"staticmethod\" and hasattr(varobj, \"__func__\"):\n                    func = varobj.__func__\n                elif atype == \"function\":\n                    func = varobj\n\n                if (func is not None and\n                    not hasattr(func, \"__acorn__\") and\n                    hasattr(func, \"__code__\") and\n                    \"<ipython-input\" in func.__code__.co_filename):\n                    decorate = True\n                else:\n                    msg.std(defmsg.format(varname), 3)\n                    \n            if decorate:\n                self.entities[atype][varname] = varobj\n                result.append((varname, varobj))\n                \n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlog the definition of the object that was just auto - decorated inside the IPython notebook.", "response": "def _logdef(self, n, o, otype):\n        \"\"\"Logs the definition of the object that was just auto-decorated inside\n        the `ipython` notebook.\n        \"\"\"\n        import re\n        try:\n            #The latest input cell will be the one that this got executed\n            #from. TODO: actually, if acorn got imported after the fact, then\n            #the import would have caused all the undecorated functions to be\n            #decorated as soon as acorn imported. I suppose we just won't have\n            #any code for that case.\n            if otype == \"classes\":\n                cellno = max([int(k[2:]) for k in self.shell.user_ns.keys()\n                              if re.match(\"_i\\d+\", k)])\n            elif otype == \"functions\":\n                cellno = int(o.__code__.co_filename.strip(\"<>\").split('-')[2])\n        except:\n            #This must not have been an ipython notebook declaration, so we\n            #don't store the code.\n            cellno = None\n            pass\n        \n        code = \"\"\n        if cellno is not None:\n            cellstr = \"_i{0:d}\".format(cellno)\n            if cellstr in self.shell.user_ns:\n                cellcode = self.shell.user_ns[cellstr]\n                import ast\n                astm = ast.parse(cellcode)\n                ab = astm.body\n                parts = {ab[i].name: (ab[i].lineno, None if i+1 >= len(ab)\n                                      else ab[i+1].lineno) \n                         for i, d in enumerate(ab)}\n                if n in parts:\n                    celllines = cellcode.split('\\n')\n                    start, end = parts[n]\n                    if end is not None:\n                        code = celllines[start-1:end-1]\n                    else:\n                        code = celllines[start-1:]\n\n        #Now, we actually create the entry. Since the execution for function\n        #definitions is almost instantaneous, we just log the pre and post\n        #events at the same time.\n        from time import time\n        from acorn.logging.database import record\n        entry = {\n            \"m\": \"def\",\n            \"a\": None,\n            \"s\": time(),\n            \"r\": None,\n            \"c\": code,\n        }\n        from acorn import msg\n        record(\"__main__.{}\".format(n), entry, diff=True)\n        msg.info(entry, 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _decorate(self, atype, n, o):\n        typemap = {\"function\": \"functions\",\n                   \"classobj\": \"classes\",\n                   \"staticmethod\": \"methods\",\n                   \"type\": \"classes\"}\n        from acorn.logging.decoration import decorate_obj\n        try:\n            otype = typemap[atype]\n            decorate_obj(self.shell.user_ns, n, o, otype)\n            #Also create a log in the database for this execution; this allows a\n            #user to track the changes they make in prototyping function and\n            #class definitions.\n            self._logdef(n, o, otype)\n            msg.okay(\"Auto-decorated {}: {}.\".format(n, o))\n        except:\n            msg.err(\"Error auto-decorating {}: {}.\".format(n, o))\n            raise", "response": "Decorates the specified object for automatic logging with acorn."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines the most similar cell to the specified code.", "response": "def _find_cellid(self, code):\n        \"\"\"Determines the most similar cell (if any) to the specified code. It\n        must have at least 50% overlap ratio and have been a loop-intercepted\n        cell previously.\n\n        Args:\n            code (str): contents of the code cell that were executed.\n        \"\"\"\n        from difflib import SequenceMatcher\n        maxvalue = 0.\n        maxid = None\n        \n        for cellid, c in self.cellids.items():\n            matcher = SequenceMatcher(a=c, b=code)\n            ratio = matcher.quick_ratio()\n            if ratio > maxvalue and ratio > 0.5:\n                maxid, maxvalue = cellid, ratio\n\n        return maxid"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _log_images(self):\n        from time import time\n        from acorn.logging.database import record        \n        entry = {\n            \"m\": \"plot\",\n            \"a\": None,\n            \"s\": time(),\n            \"r\": thumb_uuid,\n        }\n        \n        #See if we can match the executed cell's code up with one that we\n        #intercepted in the past..\n        code = self.shell.user_ns.get(\"i_{0:d}\".format(self.cellid))\n        cellid = self._find_cellid(code)\n        if cellid is None:\n            cellid = self.cellid\n        #Store the contents of the cell so they are up to date for next time.\n        self.cellids[cellid] = code\n\n        from acorn import msg\n        record(\"__main__.{}\".format(cellid), entry)\n        msg.info(entry, 1)", "response": "Creates database logs for all the image file names in the global\n        variable."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning after the user - entered code in a cell has been executed.", "response": "def post_run_cell(self):\n        \"\"\"Runs after the user-entered code in a cell has been executed. It\n        detects any new, decoratable objects that haven't been decorated yet and\n        then decorates them.\n        \"\"\"\n        #We just want to detect any new, decoratable objects that haven't been\n        #decorated yet.\n        decorlist = {k: [] for k in self.atypes}\n        for atype in self.atypes:\n            for n, o in self._get_decoratables(atype):\n                self._decorate(atype, n, o)\n\n        #Next, check whether we have an outstanding \"loop intercept\" that we\n        #\"wrapped\" with respect to acorn by enabling streamlining.\n        if self.pre is not None:\n            #Re-enable the acorn logging systems so that it gets back to normal.\n            from acorn.logging.decoration import set_streamlining\n            set_streamlining(False)\n\n            from acorn import msg\n            from acorn.logging.database import record\n            from time import time\n\n            #Determine the elapsed time for the execution of the entire cell.\n            entry = self.pre\n            entry[\"e\"] = time() - entry[\"s\"]\n            #See if we can match the executed cell's code up with one that we\n            #intercepted in the past..\n            cellid = self._find_cellid(entry[\"c\"])\n            if cellid is None:\n                cellid = self.cellid\n\n            #Store the contents of the cell *before* they get overwritten by a\n            #diff.\n            self.cellids[cellid] = entry[\"c\"]\n                        \n            record(\"__main__.{0:d}\".format(cellid), entry, diff=True)\n            msg.info(entry, 1)\n\n            self.pre = None\n\n        #Finally, check whether any new variables have shown up, or have had\n        #their values changed.\n        from acorn.logging.database import tracker, active_db, Instance\n        varchange = self._var_changes()\n        taskdb = active_db()\n        for n, o in varchange:\n            otrack = tracker(o)\n            if isinstance(otrack, Instance):\n                taskdb.log_uuid(otrack.uuid)\n\n        global thumb_uuid\n        if thumb_uuid is not None:\n            self._log_images()\n            #Reset the image tracker list so that we don't save these images\n            #again next cell execution.\n            thumb_uuid = None\n            \n        self.cellid = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetermine the list of variables whose values have changed since the last cell execution.", "response": "def _var_changes(self):\n        \"\"\"Determines the list of variables whose values have changed since the\n        last cell execution.\n        \"\"\"       \n        result = []\n        variables = self.shell.run_line_magic(\"who_ls\", \"\")\n        if variables is None:\n            return result\n\n        import inspect\n        for varname in variables:\n            varobj = self.shell.user_ns.get(varname, None)\n            if varobj is None:\n                continue\n\n            #We need to make sure that the objects have types that make\n            #sense. We auto-decorate all classes and functions; also modules and\n            #other programming constructs are not variables.\n            keep = False\n            for ifunc in inspectors:\n                if getattr(inspect, ifunc)(varobj):\n                    break\n            else:\n                keep = True    \n\n            if keep:\n                whoid = id(varobj)\n                if varname not in self.who or self.who[varname] != whoid:\n                    result.append((varname, varobj))\n                    self.who[varname] = whoid\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes before the user - entered code in IPython is run.", "response": "def pre_run_cell(self, cellno, code):\n        \"\"\"Executes before the user-entered code in `ipython` is run. This\n        intercepts loops and other problematic code that would produce lots of\n        database entries and streamlines it to produce only a single entry.\n\n        Args:\n            cellno (int): the cell number that is about to be executed.\n            code (str): python source code that is about to be executed.\n        \"\"\"\n        #First, we look for loops and list/dict comprehensions in the code. Find\n        #the id of the latest cell that was executed.\n        self.cellid = cellno\n        \n        #If there is a loop somewhere in the code, it could generate millions of\n        #database entries and make the notebook unusable.\n        import ast\n        if findloop(ast.parse(code)):\n            #Disable the acorn logging systems so that we don't pollute the\n            #database.\n            from acorn.logging.decoration import set_streamlining\n            set_streamlining(True)\n\n            #Create the pre-execute entry for the database.\n            from time import time\n            self.pre = {\n                \"m\": \"loop\",\n                \"a\": None,\n                \"s\": time(),\n                \"r\": None,\n                \"c\": code,\n            }"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsamples data from given histogram and min max values within range", "response": "def inverseHistogram(hist, bin_range):\n    \"\"\"sample data from given histogram and min, max values within range\n\n    Returns:\n        np.array: data that would create the same histogram as given\n    \"\"\"\n    data = hist.astype(float) / np.min(hist[np.nonzero(hist)])\n    new_data = np.empty(shape=np.sum(data, dtype=int))\n    i = 0\n    xvals = np.linspace(bin_range[0], bin_range[1], len(data))\n    for d, x in zip(data, xvals):\n        new_data[i:i + d] = x\n        i += int(d)\n    return new_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a watermark image to an instance of a PIL Image.", "response": "def watermark_image(image, wtrmrk_path, corner=2):\n    '''Adds a watermark image to an instance of a PIL Image.\n\n    If the provided watermark image (wtrmrk_path) is\n    larger than the provided base image (image), then\n    the watermark image will be automatically resized to \n    roughly 1/8 the size of the base image.\n\n    Args:\n        image: An instance of a PIL Image. This is the base image.\n        wtrmrk_path: Path to the watermark image to use.\n        corner: An integer between 0 and 3 representing the corner\n            where the watermark image should be placed on top of the\n            base image. 0 is top left, 1 is top right, 2 is bottom\n            right and 3 is bottom left. NOTE: Right now, this is \n            permanently set to 2 (bottom right) but this can be \n            changed in the future by either creating a new cmd-line\n            flag or putting this in the config file.\n\n    Returns: The watermarked image\n    '''\n    padding = 2\n    wtrmrk_img = Image.open(wtrmrk_path)\n\n    #Need to perform size check in here rather than in options.py because this is\n    # the only place where we know the size of the image that the watermark is\n    # being placed onto\n    if wtrmrk_img.width > (image.width - padding * 2) or wtrmrk_img.height > (\n            image.height - padding * 2):\n        res = (int(image.width / 8.0), int(image.height / 8.0))\n        resize_in_place(wtrmrk_img, res)\n\n    pos = get_pos(corner, image.size, wtrmrk_img.size, padding)\n\n    was_P = image.mode == 'P'\n    was_L = image.mode == 'L'\n\n    # Fix PIL palette issue by converting palette images to RGBA\n    if image.mode not in ['RGB', 'RGBA']:\n        if image.format in ['JPG', 'JPEG']:\n            image = image.convert('RGB')\n        else:\n            image = image.convert('RGBA')\n\n    image.paste(wtrmrk_img.convert('RGBA'), pos, wtrmrk_img.convert('RGBA'))\n\n    if was_P:\n        image = image.convert('P', palette=Image.ADAPTIVE, colors=256)\n    elif was_L:\n        image = image.convert('L')\n\n    return image"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a text watermark to an instance of a PIL Image.", "response": "def watermark_text(image, text, corner=2):\n    '''Adds a text watermark to an instance of a PIL Image.\n\n    The text will be sized so that the height of the text is\n    roughly 1/20th the height of the base image. The text will \n    be white with a thin black outline.\n\n    Args:\n        image: An instance of a PIL Image. This is the base image.\n        text: Text to use as a watermark.\n        corner: An integer between 0 and 3 representing the corner\n            where the watermark image should be placed on top of the\n            base image. 0 is top left, 1 is top right, 2 is bottom\n            right and 3 is bottom left. NOTE: Right now, this is \n            permanently set to 2 (bottom right) but this can be \n            changed in the future by either creating a new cmd-line\n            flag or putting this in the config file.\n\n    Returns: The watermarked image\n    '''\n\n    # Load Font\n    FONT_PATH = ''\n    if resource_exists(__name__, 'resources/fonts/SourceSansPro-Regular.ttf'):\n        FONT_PATH = resource_filename(\n            __name__, 'resources/fonts/SourceSansPro-Regular.ttf')\n\n    padding = 5\n\n    was_P = image.mode == 'P'\n    was_L = image.mode == 'L'\n\n    # Fix PIL palette issue by converting palette images to RGBA\n    if image.mode not in ['RGB', 'RGBA']:\n        if image.format in ['JPG', 'JPEG']:\n            image = image.convert('RGB')\n        else:\n            image = image.convert('RGBA')\n\n    # Get drawable image\n    img_draw = ImageDraw.Draw(image)\n\n    fontsize = 1  # starting font size\n\n    # portion of image width you want text height to be.\n    # default font size will have a height that is ~1/20\n    # the height of the base image.\n    img_fraction = 0.05\n\n    # attempt to use Aperture default font. If that fails, use ImageFont default\n    try:\n        font = ImageFont.truetype(font=FONT_PATH, size=fontsize)\n        was_over = False\n        inc = 2\n        while True:\n            if font.getsize(text)[1] > img_fraction * image.height:\n                if not was_over:\n                    was_over = True\n                    inc = -1\n            else:\n                if was_over:\n                    break\n            # iterate until the text size is just larger than the criteria\n            fontsize += inc\n            font = ImageFont.truetype(font=FONT_PATH, size=fontsize)\n        fontsize -= 1\n        font = ImageFont.truetype(font=FONT_PATH, size=fontsize)\n    except:\n        # replace with log message\n        print('Failed to load Aperture font. Using default font instead.')\n        font = ImageFont.load_default()  # Bad because default is suuuuper small\n\n    # get position of text\n    pos = get_pos(corner, image.size, font.getsize(text), padding)\n\n    # draw a thin black border\n    img_draw.text((pos[0] - 1, pos[1]), text, font=font, fill='black')\n    img_draw.text((pos[0] + 1, pos[1]), text, font=font, fill='black')\n    img_draw.text((pos[0], pos[1] - 1), text, font=font, fill='black')\n    img_draw.text((pos[0], pos[1] + 1), text, font=font, fill='black')\n\n    # draw the actual text\n    img_draw.text(pos, text, font=font, fill='white')\n\n    # Remove cached font file\n    cleanup_resources()\n    del img_draw\n\n    if was_P:\n        image = image.convert('P', palette=Image.ADAPTIVE, colors=256)\n    elif was_L:\n        image = image.convert('L')\n\n    return image"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints out a log message.", "response": "def log(msg, *args, **kwargs):\n    \"\"\"\n    Print out a log message.\n    \"\"\"\n    if len(args) == 0 and len(kwargs) == 0:\n        print(msg)\n    else:\n        print(msg.format(*args, **kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef logv(msg, *args, **kwargs):\n    if settings.VERBOSE:\n        log(msg, *args, **kwargs)", "response": "Print out a log message only if verbose mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntries to resolve the given absolute or relative path using the given relative_prefix and possible_extensions. If that fails returns None.", "response": "def resolve_possible_paths(path, relative_prefix, possible_extensions=None, leading_underscore=False):\n    \"\"\"\n    Attempts to resolve the given absolute or relative ``path``. If it\n    doesn't exist as is, tries to create an absolute path using the\n    ``relative_prefix``. If that fails, tries relative/absolute versions\n    with each of ``possible_extensions``.\n\n    :returns: The absolute path, or ``None`` if no such file can be found.\n    \"\"\"\n    possible_extensions = [''] + list(possible_extensions) if possible_extensions else ['']\n    possible_paths = [path + e if os.path.isabs(path + e) else os.path.join(relative_prefix, path + e)\n                      for e in possible_extensions]\n\n    if leading_underscore and not os.path.basename(path).startswith('_'):\n        extra_paths = [os.path.join(os.path.dirname(p), '_' + os.path.basename(p))\n                       for p in possible_paths]\n        possible_paths = possible_paths + extra_paths\n\n    for p in possible_paths:\n        p = os.path.normpath(p)\n        if os.path.isfile(p):\n            return p\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_html_urls(file_name, html_data):\n    '''\n    Returns a list of tuples in the form (url, file_name, line_number)\n    '''\n    try:\n        html = lxml.html.fromstring(html_data)\n        anchor_tags = html.cssselect('a')\n\n        for a in anchor_tags:\n            # A link was started but not finished, href with nothing set!\n            if not 'href' in a.attrib or a.attrib['href'] == '':\n                BROKEN_URLS.append(('None', file_name, a.sourceline))\n\n            url = clean_url(a.attrib['href'])\n\n            if is_valid_url(url):\n                if url not in URL_CACHE:\n                    URL_CACHE.add(url)\n\n                    yield (url, file_name, a.sourceline)\n\n    except SyntaxError:\n        pass", "response": "Parses the HTML file and returns a list of tuples in the form url file_name line_number"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck the format of urls is list of tuples i. e. url file name source line number", "response": "def check_urls(urls):\n    '''\n    expected format of urls is list of tuples (url, file name, source line) i.e. (\"google.com\", \"index.html\", 32)\n    '''\n    threads = list()\n    progress_bar = None\n    progress_counter = 0\n\n    if SHOW_PROGRESS_BAR and len(urls) > 0:\n\n        widgets = [SimpleProgress()]\n        progress_bar = ProgressBar(widgets=widgets, maxval=len(urls)).start()\n\n    for u in urls:\n        t = Thread(target=async_check_url, args=(u[0], u[1], u[2]))\n        t.start()\n        threads.append(t)\n\n    for thread in threads:\n        if SHOW_PROGRESS_BAR and len(urls) > 0:\n            progress_counter = progress_counter + 1\n            progress_bar.update(progress_counter)\n\n        thread.join()\n\n    if SHOW_PROGRESS_BAR and len(urls) > 0:\n        progress_bar.finish()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _csv_to_nodes_dict(nodes_csv):\n\n    data = []\n\n    for row in csv.reader(nodes_csv):\n        node = {\n            \"pm_user\": row[2],\n            \"pm_addr\": row[1],\n            \"pm_password\": row[3],\n            \"pm_type\": row[0],\n            \"mac\": [\n                row[4]\n            ]\n        }\n        data.append(node)\n\n    return data", "response": "Convert a CSV file into a list of dicts formatted for os_cloud_config\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef assign(A, attr, B, lock=False):\n    '''Assigns B to A.attr, yields, and then assigns A.attr back to its\n    original value.\n    '''\n    class NoAttr(object): pass\n\n    context = threading.Lock if lock else null_context\n    with context():\n        if not hasattr(A, attr):\n            tmp = NoAttr\n        else:\n            tmp = getattr(A, attr)\n\n        setattr(A, attr, B)\n\n        try:\n            yield B\n\n        finally:\n            if tmp is NoAttr:\n                delattr(A, attr)\n            else:\n                setattr(A, attr, tmp)", "response": "Assigns B to A. attr yields and then assigns A. attr back to its\n    original value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(*args):\n    '''For using then deleting objects.'''\n    from syn.base_utils import this_module\n    mod = this_module(npop=3)\n    yield\n    for arg in args:\n        name = arg\n        if not isinstance(name, STR):\n            name = arg.__name__\n        delattr(mod, name)", "response": "For using then deleting objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dictionary representing the job.", "response": "def serialize_job(job):\n    \"\"\"Return a dictionary representing the job.\"\"\"\n    d = dict(\n        id=job.get_id(),\n        uri=url_for('jobs.get_job', job_id=job.get_id(), _external=True),\n        status=job.get_status(),\n        result=job.result\n    )\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resolve_pattern(pattern):\n    '''Resolve a glob pattern into a filelist'''\n    if os.path.exists(pattern) and os.path.isdir(pattern):\n        pattern = os.path.join(pattern, '**/*.bench.py')\n    return recursive_glob(pattern)", "response": "Resolve a glob pattern into a filelist"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload JSON from the request body and store them in self. request. arguments.", "response": "def load_json(self):\n        \"\"\"Load JSON from the request body and store them in\n        self.request.arguments, like Tornado does by default for POSTed form\n        parameters.\n\n        If JSON cannot be decoded\n\n        :raises ValueError: JSON Could not be decoded\n        \"\"\"\n        try:\n            self.request.arguments = json.loads(self.request.body)\n        except ValueError:\n            msg = \"Could not decode JSON: %s\" % self.request.body\n            self.logger.debug(msg)\n            self.raise_error(400, msg)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind and return the value of the json key with key name from the request data. Similar to Tornado s get_argument method.", "response": "def get_json_argument(self, name, default=None):\n        \"\"\"Find and return the argument with key 'name'\n        from JSON request data. Similar to Tornado's get_argument() method.\n\n        :param str name: The name of the json key you want to get the value for\n        :param bool default: The default value if nothing is found\n        :returns: value of the argument name request\n        \"\"\"\n\n        if default is None:\n            default = self._ARG_DEFAULT\n        if not self.request.arguments:\n            self.load_json()\n        if name not in self.request.arguments:\n            if default is self._ARG_DEFAULT:\n                msg = \"Missing argument '%s'\" % name\n                self.logger.debug(msg)\n                self.raise_error(400, msg)\n            self.logger.debug(\"Returning default argument %s, as we couldn't \"\n                              \"find '%s' in %s\" % (default, name,\n                                                   self.request.arguments))\n            return default\n        arg = self.request.arguments[name]\n        return arg"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a dictionary of all key - value pairs in the handler paths query string and returns it", "response": "def get_dict_of_all_args(self):\n        \"\"\"Generates a dictionary from a handler paths query string and returns it\n\n        :returns: Dictionary of all key/values in arguments list\n        :rtype: dict\n        \"\"\"\n        dictionary = {}\n        for arg in [arg for arg in self.request.arguments if arg not in self.settings.get(\"reserved_query_string_params\", [])]:\n            val =  self.get_argument(arg, default=None)\n            if val:\n                dictionary[arg] = val\n        return dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_arg_value_as_type(self, key, default=None, convert_int=False):\n\n        val = self.get_query_argument(key, default)\n\n        if isinstance(val, int):\n            return val\n\n        if val.lower() in ['true', 'yes']:\n            return True\n\n        if val.lower() in ['false', 'no']:\n            return False\n\n        return val", "response": "Allow users to pass through truthy type values like true yes no and get to a typed variable in your code\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_mongo_query_from_arguments(self, reserved_attributes=[]):\n\n        query = {}\n        for arg in self.request.arguments:\n            if arg not in reserved_attributes:\n                if len(self.request.arguments.get(arg)) > 1:\n                    query[\"$or\"] = []\n                    for val in self.request.arguments.get(arg):\n                        query[\"$or\"].append({arg: self.get_arg_value_as_type(val)})\n                else:\n                    query[arg] = self.get_arg_value_as_type(self.request.arguments.get(arg)[0])\n\n        return query", "response": "Generate a mongo query from the given URL query parameters handles OR query via multiples\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles conversion of pymongo cursor into a JSON object formatted for UI consumption", "response": "def obj_cursor_to_json(self, cursor):\n        \"\"\"Handle conversion of pymongo cursor into a JSON object formatted for UI consumption\n\n        :param Cursor cursor: A motor client database cursor\n        \"\"\"\n        json_object = json.loads(json_util.dumps(cursor))\n\n        if \"_id\" in json_object:\n            json_object['id'] = str(json_object['_id']['$oid'])\n            del json_object['_id']\n\n        return json_object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate the meta data dictionary for a revision", "response": "def _get_meta_data(self):\n        \"\"\"Creates the meta data dictionary for a revision\"\"\"\n        return {\n            \"comment\": self.request.headers.get(\"comment\", \"\"),\n            \"author\": self.get_current_user() or self.settings.get('annonymous_user')\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef json_obj_to_cursor(self, json):\n        cursor = json_util.loads(json)\n        if \"id\" in json:\n            cursor[\"_id\"] = ObjectId(cursor[\"id\"])\n            del cursor[\"id\"]\n\n        return cursor", "response": "Convert a JSON object to a mongo db cursor"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nturning an argument into an array based on the splitChar", "response": "def arg_as_array(self, arg, split_char=\"|\"):\n        \"\"\"Turns an argument into an array, split by the splitChar\n\n        :param str arg: The name of the query param you want to turn into an array based on the value\n        :param str split_char: The character the value should be split on.\n        :returns: A list of values\n        :rtype: list\n        \"\"\"\n        valuesString = self.get_argument(arg, default=None)\n        if valuesString:\n            valuesArray = valuesString.split(split_char)\n            return valuesArray\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting an error status and returns a message to the user in JSON format", "response": "def raise_error(self, status=500, message=\"Generic server error.  Out of luck...\"):\n        \"\"\"\n        Sets an error status and returns a message to the user in JSON format\n\n        :param int status: The status code to use\n        :param str message: The message to return in the JSON response\n        \"\"\"\n        self.set_status(status)\n        self.write({\"message\" : message,\n                    \"status\" : status})"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef return_resource(self, resource, status=200, statusMessage=\"OK\"):\n        self.set_status(status, statusMessage)\n        self.write(json.loads(json_util.dumps(resource)))", "response": "Return a resource response from the server"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef group_objects_by(self, list, attr, valueLabel=\"value\", childrenLabel=\"children\"):\n\n        groups = []\n        for obj in list:\n            val = obj.get(attr)\n            if not val:\n                pass\n\n            newGroup = {\"attribute\": attr, valueLabel: val, childrenLabel: [obj]}\n\n            found = False\n            for i in range(0,len(groups)):\n                if val == groups[i].get(valueLabel):\n                    found = True\n                    groups[i][childrenLabel].append(obj)\n                    pass\n\n            if not found:\n                groups.append(newGroup)\n\n\n        return groups", "response": "This method creates a list of objects based on the attribute value on of the given attr valueLabel and childrenLabel."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite a hyper media response object to the resource store.", "response": "def write_hyper_response(self, links=[], meta={}, entity_name=None, entity=None, notifications=[], actions=[]):\n        \"\"\"Writes a hyper media response object\n\n        :param list links: A list of links to the resources\n        :param dict meta: The meta data for this response\n        :param str entity_name: The entity name\n        :param object entity: The Entity itself\n        :param list notifications: List of notifications\n        :param list actions: List of actions\n        \"\"\"\n        assert entity_name is not None\n        assert entity is not None\n\n        meta.update({\n            \"status\": self.get_status()\n        })\n\n        self.write({\n            \"links\": links,\n            \"meta\": meta,\n            entity_name: entity,\n            \"notifications\": notifications,\n            \"actions\": actions\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, id):\n        try:\n            if self.request.headers.get(\"Id\"):\n                object_ = yield self.client.find_one({self.request.headers.get(\"Id\"): id})\n            else:\n                object_ = yield self.client.find_one_by_id(id)\n\n            if object_:\n                self.write(object_)\n                return\n\n            self.raise_error(404, \"%s/%s not found\" % (self.object_name, id))\n\n        except InvalidId as ex:\n            self.raise_error(400, message=\"Your ID is malformed: %s\" % id)\n        except Exception as ex:\n            self.logger.error(ex)\n            self.raise_error()", "response": "Get an object by unique identifier"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates a resource by bson ObjectId", "response": "def put(self, id):\n        \"\"\"\n        Update a resource by bson ObjectId\n\n        :returns: json string representation\n        :rtype: JSON\n        \"\"\"\n        try:\n            #Async update flow\n            object_ = json_util.loads(self.request.body)\n\n            toa = self.request.headers.get(\"Caesium-TOA\", None)\n\n            obj_check = yield self.client.find_one_by_id(id)\n            if not obj_check:\n                self.raise_error(404, \"Resource not found: %s\" % id)\n                self.finish()\n                return\n\n            if toa:\n\n                stack = AsyncSchedulableDocumentRevisionStack(self.client.collection_name, self.settings, master_id=id)\n                revision_id = yield stack.push(object_, int(toa), meta=self._get_meta_data())\n\n                if isinstance(revision_id, str):\n                    self.set_header(\"Caesium-TOA\", toa)\n\n                    #We add the id of the original request, because we don't want to infer this\n                    #On the client side, as the state of the client code could change easily\n                    #We want this request to return with the originating ID as well.\n                    object_[\"id\"] = id\n                    self.return_resource(object_)\n                else:\n                    self.raise_error(404, \"Revision not scheduled for object: %s\" % id)\n\n            else:\n                if object_.get(\"_id\"):\n                    del object_[\"_id\"]\n\n                response = yield self.client.update(id, object_)\n\n                if response.get(\"updatedExisting\"):\n                    object_ = yield self.client.find_one_by_id(id)\n                    self.return_resource(object_)\n                else:\n                    self.raise_error(404, \"Resource not found: %s\" % id)\n\n        except ValidationError as vex:\n            self.logger.error(\"%s validation error\" % self.object_name, vex)\n            self.raise_error(400, \"Your %s cannot be updated because it is missing required fields, see docs\" % self.object_name)\n        except ValueError as ex:\n            self.raise_error(400, \"Invalid JSON Body, check formatting. %s\" % ex[0])\n        except InvalidId as ex:\n            self.raise_error(message=\"Your ID is malformed: %s\" % id)\n        except Exception as ex:\n            self.logger.error(ex)\n            self.raise_error()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef post(self, id=None):\n        try:\n\n            try:\n                base_object = json_util.loads(self.request.body)\n            except TypeError:\n                base_object = json_util.loads(self.request.body.decode())\n\n            #assert not hasattr(base_object, \"_id\")\n\n            toa = self.request.headers.get(\"Caesium-TOA\", None)\n\n            if toa:\n                # Async create flow\n                stack = AsyncSchedulableDocumentRevisionStack(self.client.collection_name, self.settings)\n\n                revision_id = yield stack.push(base_object, toa=int(toa), meta=self._get_meta_data())\n                resource = yield stack.preview(revision_id)\n\n                if isinstance(revision_id, str):\n                    self.set_header(\"Caesium-TOA\", toa)\n                    self.return_resource(resource.get(\"snapshot\"))\n                else:\n                    self.raise_error(404, \"Revision not scheduled for object: %s\" % id)\n\n            else:\n\n                id = yield self.client.insert(base_object)\n                base_object = yield self.client.find_one_by_id(id)\n\n                self.return_resource(base_object)\n\n        except ValidationError as vex:\n            self.logger.error(\"%s validation error\" % self.object_name, vex)\n            self.raise_error(400, \"Your %s cannot be created because it is missing required fields, see docs\" % self.object_name)\n        except ValueError as ex:\n            self.raise_error(400, \"Invalid JSON Body, check formatting. %s\" % ex[0])\n        except Exception as ex:\n            self.logger.error(ex)\n            self.raise_error()", "response": "Create a new object in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a resource by bson id", "response": "def delete(self, id):\n        \"\"\"\n        Delete a resource by bson id\n        :raises: 404 Not Found\n        :raises: 400 Bad request\n        :raises: 500 Server Error\n        \"\"\"\n        try:\n            response = yield self.client.delete(id)\n\n            if response.get(\"n\") > 0:\n                self.write({\"message\": \"Deleted %s object: %s\" % (self.object_name, id) })\n                return\n\n            self.raise_error(404, \"Resource not found\")\n\n        except InvalidId as ex:\n            self.raise_error(400, message=\"Your ID is malformed: %s\" % id)\n        except:\n            self.raise_error()\n\n        self.finish()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef initialize(self):\n\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self.client = None", "response": "Initialize the object attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __lazy_migration(self, master_id):\n        collection_name = self.request.headers.get(\"collection\")\n\n        if collection_name:\n            stack = AsyncSchedulableDocumentRevisionStack(collection_name,\n                                                          self.settings,\n                                                          master_id=master_id,\n                                                          )\n            objects = yield stack._lazy_migration(meta=self._get_meta_data())\n            raise Return(objects)\n\n        self.raise_error(500, \"This object %s/%s didn't exist as a revision, \"\n                         \"we tried to create it but we failed... Sorry. \"\n                         \"Please check this object\" % (collection_name,\n                                                       master_id))\n        raise Return(None)", "response": "Create a revision for a master id that didn t previously have it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a list of revisions by master ID.", "response": "def get(self, master_id):\n        \"\"\"\n        Get a list of revisions by master ID\n\n        :param master_id:\n        :return:\n        \"\"\"\n        collection_name = self.request.headers.get(\"collection\")\n        self.client = BaseAsyncMotorDocument(\"%s_revisions\" % collection_name)\n\n        limit = self.get_query_argument(\"limit\", 2)\n        add_current_revision = self.get_arg_value_as_type(\"addCurrent\",\n                                                          \"false\")\n        show_history = self.get_arg_value_as_type(\"showHistory\", \"false\")\n\n        objects_processed = []\n\n        if isinstance(limit, unicode):\n            limit = int(limit)\n\n        objects = yield self.client.find({\"master_id\": master_id,\n                                          \"processed\": False},\n                                         orderby=\"toa\",\n                                         order_by_direction=1,\n                                         page=0,\n                                         limit=20)\n\n        # If this is a document that should have a revision and doesn't we\n        # orchestratioin creation of the first one\n        if len(objects) == 0:\n\n            new_revision = yield self.__lazy_migration(master_id)\n            if not new_revision:\n                return\n\n        if show_history:\n            objects_processed = yield self.client.find({\"master_id\": master_id,\n                                                        \"processed\": True},\n                                                       orderby=\"toa\",\n                                                       order_by_direction=-1,\n                                                       page=0,\n                                                       limit=limit)\n\n        elif add_current_revision:\n            objects_processed = yield self.client.find({\"master_id\": master_id,\n                                                        \"processed\": True},\n                                                       orderby=\"toa\",\n                                                       order_by_direction=-1,\n                                                       page=0,\n                                                       limit=1)\n\n        if len(objects_processed) > 0:\n            objects_processed = objects_processed[::-1]\n            objects_processed[-1][\"current\"] = True\n            objects = objects_processed + objects\n\n        self.write({\n            \"count\": len(objects),\n            \"results\": objects\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating a revision by ID", "response": "def put(self, id):\n        \"\"\"\n        Update a revision by ID\n\n        :param id: BSON id\n        :return:\n        \"\"\"\n\n        collection_name = self.request.headers.get(\"collection\")\n\n        if not collection_name:\n            self.raise_error(400, \"Missing a collection name header\")\n\n        self.client = BaseAsyncMotorDocument(\"%s_revisions\" % collection_name)\n\n        super(self.__class__, self).put(id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the revision based on the stack preview algorithm", "response": "def get(self, id):\n        \"\"\"\n        Get revision based on the stack preview algorithm\n\n        :param id: BSON id\n        :return: JSON\n        \"\"\"\n        collection_name = self.request.headers.get(\"collection\")\n\n        if not collection_name:\n            self.raise_error(400, \"Missing a collection name for stack\")\n\n        self.stack = AsyncSchedulableDocumentRevisionStack(collection_name, self.settings)\n\n        revision = yield self.stack.preview(id)\n        self.write(revision)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a set of resources of any type", "response": "def get(self):\n\n        \"\"\"\n        Standard search end point for a resource of any type, override this get method as necessary\n        in any specifc sub class.  This is mostly here as a convenience for basic querying functionality\n        on attribute\n\n        example URL::\n\n            foo?attr1=foo&attr2=true\n\n        will create a query of::\n\n            {\n                \"attr1\": \"foo\",\n                \"attr2\": true\n            }\n\n\n        \"\"\"\n        objects = yield self.client.find(self.get_mongo_query_from_arguments())\n\n        self.write({\n            \"count\" : len(objects),\n            \"results\": objects\n        })\n        self.finish()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef put(self, id=None):\n\n        toa = self.request.headers.get(\"Caesium-TOA\")\n\n        if not toa:\n            self.raise_error(400, \"Caesium-TOA header is required, none found\")\n            self.finish(self.request.headers.get(\"Caesium-TOA\"))\n\n        meta = self._get_meta_data()\n        meta[\"bulk_id\"] = uuid.uuid4().get_hex()\n        ids = self.get_json_argument(\"ids\")\n        patch = self.get_json_argument(\"patch\")\n\n        self.get_json_argument(\"ids\", [])\n        for id in ids:\n            stack = AsyncSchedulableDocumentRevisionStack(self.client.collection_name, self.settings, master_id=id)\n            stack.push(patch, toa=toa, meta=meta)\n\n        self.write({\n            \"count\": len(ids),\n            \"result\": {\n                \"ids\": ids,\n                \"toa\": toa,\n                \"patch\": patch,\n            }\n        })\n        self.finish()", "response": "Update many objects with a single PUT."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete a single object from the collection", "response": "def delete(self, bulk_id):\n        \"\"\"Update many objects with a single toa\n\n        :param str bulk_id: The bulk id for the job you want to delete\n        \"\"\"\n\n        collection_name = self.request.headers.get(\"collection\")\n\n        if not collection_name:\n            self.raise_error(400, \"Missing a collection name header\")\n\n        self.revisions = BaseAsyncMotorDocument(\"%s_revisions\" % collection_name)\n\n        self.logger.info(\"Deleting revisions with bulk_id %s\" % (bulk_id))\n\n        result = yield self.revisions.collection.remove({\"meta.bulk_id\": bulk_id})\n\n        self.write(result)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef author_from_git(self):\n        self.author = None\n        try:\n            encoding = locale.getdefaultlocale()[1]\n            # launch git command and get answer\n            cmd = Popen([\"git\", \"config\", \"--get\", \"user.name\"], stdout=PIPE)\n            stdoutdata = cmd.communicate().decode(encoding)\n            if (stdoutdata[0]):\n                import ipdb;ipdb.set_trace()\n                author = stdoutdata[0].rstrip(os.linesep)\n                self.author = author#.decode('utf8')\n        except ImportError:\n            pass\n        except CalledProcessError:\n            pass\n        except OSError:\n            pass\n\n        return self.author", "response": "Get the author name from git information."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the specified epoch time or current time if None is provided as an ISO 8601 string in zulu time.", "response": "def zulu(ts=None, ms=True):\n  '''\n  Returns the specified epoch time (or current time if None or not\n  provided) as an ISO 8601 string in zulu time (with millisecond\n  precision), e.g. zulu(1362187446.553) => '2013-03-02T01:24:06.553Z'.\n  If `ms` is True (the default), milliseconds will be included, otherwise\n  truncated.\n  '''\n  if ts is None:\n    ts = time.time()\n  ms = '.%03dZ' % (ts * 1000 % 1000,) if ms else 'Z'\n  return time.strftime('%Y-%m-%dT%H:%M:%S', time.gmtime(ts)) + ms"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lru_cache(maxsize=100, typed=False):\n\t# Users should only access the lru_cache through its public API:\n\t#     cache_info, cache_clear, and f.__wrapped__\n\t# The internals of the lru_cache are encapsulated for thread safety and\n\t# to allow the implementation to change (including a possible C version).\n\n\tdef decorating_function(user_function, **kwargs):\n\t\ttuple = kwargs.get('tuple', builtins.tuple)\n\t\tsorted = kwargs.get('sorted', builtins.sorted)\n\t\tmap = kwargs.get('map', builtins.map)\n\t\tlen = kwargs.get('len', builtins.len)\n\t\ttype = kwargs.get('type', builtins.type)\n\t\tKeyError = kwargs.get('KeyError', builtins.KeyError)\n\n\t\thits = [0]\n\t\tmisses = [0]\n\t\tkwd_mark = (object(),)\t\t\t# separates positional and keyword args\n\t\tlock = Lock()\t\t\t\t\t# needed because OrderedDict isn't threadsafe\n\n\t\tif maxsize is None:\n\t\t\tcache = dict()\t\t\t\t# simple cache without ordering or size limit\n\n\t\t\t@wraps(user_function)\n\t\t\tdef wrapper(*args, **kwds):\n\t\t\t\t# nonlocal hits, misses\n\t\t\t\tkey = args\n\t\t\t\tif kwds:\n\t\t\t\t\tsorted_items = tuple(sorted(kwds.items()))\n\t\t\t\t\tkey += kwd_mark + sorted_items\n\t\t\t\tif typed:\n\t\t\t\t\tkey += tuple(map(type, args))\n\t\t\t\t\tif kwds:\n\t\t\t\t\t\tkey += tuple(type(v) for k, v in sorted_items)\n\t\t\t\ttry:\n\t\t\t\t\tresult = cache[key]\n\t\t\t\t\thits[0] += 1\n\t\t\t\t\treturn result\n\t\t\t\texcept KeyError:\n\t\t\t\t\tpass\n\t\t\t\tresult = user_function(*args, **kwds)\n\t\t\t\tcache[key] = result\n\t\t\t\tmisses[0] += 1\n\t\t\t\treturn result\n\t\telse:\n\t\t\tcache = OrderedDict()\t\t\t# ordered least recent to most recent\n\t\t\tcache_popitem = cache.popitem\n\t\t\t# use the move_to_end method if available, otherwise fallback to\n\t\t\t#  the function.\n\t\t\tcache_renew = getattr(\n\t\t\t\tcache, 'move_to_end',\n\t\t\t\tfunctools.partial(_move_to_end, cache))\n\n\t\t\t@wraps(user_function)\n\t\t\tdef wrapper(*args, **kwds):\n\t\t\t\t# nonlocal hits, misses\n\t\t\t\tkey = args\n\t\t\t\tif kwds:\n\t\t\t\t\tsorted_items = tuple(sorted(kwds.items()))\n\t\t\t\t\tkey += kwd_mark + sorted_items\n\t\t\t\tif typed:\n\t\t\t\t\tkey += tuple(map(type, args))\n\t\t\t\t\tif kwds:\n\t\t\t\t\t\tkey += tuple(type(v) for k, v in sorted_items)\n\t\t\t\twith lock:\n\t\t\t\t\ttry:\n\t\t\t\t\t\tresult = cache[key]\n\t\t\t\t\t\tcache_renew(key)  # record recent use of this key\n\t\t\t\t\t\thits[0] += 1\n\t\t\t\t\t\treturn result\n\t\t\t\t\texcept KeyError:\n\t\t\t\t\t\tpass\n\t\t\t\tresult = user_function(*args, **kwds)\n\t\t\t\twith lock:\n\t\t\t\t\tcache[key] = result\t\t# record recent use of this key\n\t\t\t\t\tmisses[0] += 1\n\t\t\t\t\tif len(cache) > maxsize:\n\t\t\t\t\t\tcache_popitem(0)  # purge least recently used cache entry\n\t\t\t\treturn result\n\n\t\tdef cache_info():\n\t\t\t\"\"\"Report cache statistics\"\"\"\n\t\t\twith lock:\n\t\t\t\treturn _CacheInfo(hits[0], misses[0], maxsize, len(cache))\n\n\t\tdef cache_clear():\n\t\t\t\"\"\"Clear the cache and cache statistics\"\"\"\n\t\t\t# nonlocal hits, misses\n\t\t\twith lock:\n\t\t\t\tcache.clear()\n\t\t\t\thits[0] = misses[0] = 0\n\n\t\twrapper.cache_info = cache_info\n\t\twrapper.cache_clear = cache_clear\n\t\treturn wrapper\n\n\treturn decorating_function", "response": "A function decorator that returns a function that caches the results of a user function."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates our providers from either an ICatalog subclass or a mapping.", "response": "def update(self, arg, allow_overwrite=False):\n        \"\"\"\n        Update our providers from either an ICatalog subclass/instance or a mapping.\n\n        If arg is an ICatalog, we update from it's ._providers attribute.\n\n        :param arg: Di/Catalog/Mapping to update from.\n        :type arg: ICatalog or collections.Mapping\n        :param allow_overwrite: If True, allow overwriting existing keys\n        :type allow_overwrite: bool\n        \"\"\"\n        # If arg happens to be an ICatalog subclass\n        if inspect.isclass(arg) and issubclass(arg, ICatalog) or isinstance(arg, ICatalog):\n            arg = arg._providers\n        if not allow_overwrite:\n            for key in arg:\n                if key in self._providers:\n                    raise KeyError(\"Key %s already exists\" % key)\n        super(ProviderMapping, self).update(arg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load(force=False):\n\n    if GRAFTS and not force:\n        return GRAFTS\n\n    # insert missing paths\n    # this could be a configurated item\n    userpath = settings.userpath\n    if os.path.isdir(userpath) and userpath not in __path__:\n        __path__.append(userpath)\n\n    def notify_error(name):\n        logging.error('unable to load %s package' % name)\n\n    # autoload decorated functions\n    walker = walk_packages(__path__, '%s.' % __name__, onerror=notify_error)\n    for module_finder, name, ispkg in walker:\n        loader = module_finder.find_module(name)\n        mod = loader.load_module(name)\n        for func in mod.__dict__.values():\n            if is_graft(func):\n                GRAFTS.append(func)\n\n    # append setuptools modules\n    for entry_point in iter_entry_points(group=settings.entry_point):\n        try:\n            func = entry_point.load()\n            if is_graft(func):\n                GRAFTS.append(func)\n            else:\n                notify_error(entry_point.name)\n        except Exception as error:\n            logging.exception(error)\n            notify_error(entry_point.name)\n\n    return GRAFTS", "response": "Magical loading of all grafted functions."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _write_buildproc_yaml(build_data, env, user, cmd, volumes, app_folder):\n\n    buildproc = ProcData({\n        'app_folder': str(app_folder),\n        'app_name': build_data.app_name,\n        'app_repo_url': '',\n        'app_repo_type': '',\n        'buildpack_url': '',\n        'buildpack_version': '',\n        'config_name': 'build',\n        'env': env,\n        'host': '',\n        'port': 0,\n        'version': build_data.version,\n        'release_hash': '',\n        'settings': {},\n        'user': user,\n        'cmd': cmd,\n        'volumes': volumes,\n        'proc_name': 'build',\n        'image_name': build_data.image_name,\n        'image_url': build_data.image_url,\n        'image_md5': build_data.image_md5,\n    })\n\n    # write a proc.yaml for the container.\n    with open('buildproc.yaml', 'w') as f:\n        f.write(buildproc.as_yaml())\n    return get_container_path(buildproc)", "response": "Write a proc. yaml for the container and return the container path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nasserting that the compile script is finished.", "response": "def assert_compile_finished(app_folder):\n    \"\"\"\n    Once builder.sh has invoked the compile script, it should return and we\n    should set a flag to the script returned. If that flag is missing, then\n    it is an indication that the container crashed, and we generate an error.\n\n    This function will clean up the flag after the check is performed, so only\n    call this function once. See issue #141.\n    \"\"\"\n    fpath = os.path.join(app_folder, '.postbuild.flag')\n    if not os.path.isfile(fpath):\n        msg = ('No postbuild flag set, LXC container may have crashed while '\n               'building. Check compile logs for build.')\n        raise AssertionError(msg)\n    try:\n        os.remove(fpath)\n    except OSError:\n        # It doesn't matter if it fails.\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives the path to an app folder that was just built return the data emitted from running the buildpack s release. yaml file.", "response": "def recover_release_data(app_folder):\n    \"\"\"\n    Given the path to an app folder where an app was just built, return a\n    dictionary containing the data emitted from running the buildpack's release\n    script.\n\n    Relies on the builder.sh script storing the release data in ./.release.yaml\n    inside the app folder.\n    \"\"\"\n    with open(os.path.join(app_folder, '.release.yaml'), 'rb') as f:\n        return yaml.safe_load(f)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef recover_buildpack(app_folder):\n    filepath = os.path.join(app_folder, '.buildpack')\n    with open(filepath) as f:\n        buildpack_picked = f.read()\n    buildpack_picked = buildpack_picked.lstrip('/')\n    buildpack_picked = buildpack_picked.rstrip('\\n')\n    buildpack_picked = os.path.join(os.getcwd(), buildpack_picked)\n    return BuildPack(buildpack_picked)", "response": "Given a path to an app folder returns a BuildPack object pointing to the dir where the buildpack used during the build."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pull_buildpack(url):\n    defrag = _defrag(urllib.parse.urldefrag(url))\n    with lock_or_wait(defrag.url):\n        bp = update_buildpack(url)\n        dest = bp.basename + '-' + hash_text(defrag.url)\n        shutil.copytree(bp.folder, dest)\n    # Make the buildpack dir writable, per\n    # https://bitbucket.org/yougov/velociraptor/issues/178\n    path.Path(dest).chmod('a+wx')\n    return dest", "response": "Update a buildpack in its shared location then make a copy into the\n    current directory using an md5 of the url."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_tarball(self, app_folder, build_data):\n        # slugignore\n        clean_slug_dir(app_folder)\n\n        # tar up the result\n        with tarfile.open('build.tar.gz', 'w:gz') as tar:\n            tar.add(app_folder, arcname='')\n        build_data.build_md5 = file_md5('build.tar.gz')\n\n        tardest = os.path.join(self.outfolder, 'build.tar.gz')\n        shutil.move('build.tar.gz', tardest)\n\n        build_data_path = os.path.join(self.outfolder, 'build_result.yaml')\n        print(\"Writing\", build_data_path)\n        with open(build_data_path, 'w') as f:\n            f.write(build_data.as_yaml())", "response": "Create a tarball and build result."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_request(self, request):\n        ''' \n        checks if the host domain is one of the site objects\n        and sets request.site_id\n        '''\n        site_id = 0\n        domain = request.get_host().lower()\n        if hasattr(settings, 'SITE_ID'):\n            site_id = settings.SITE_ID\n        try:\n            site = Site.objects.get(domain__iexact=domain)\n            site_id = site.id\n        except Site.DoesNotExist:\n            pass\n        request.site_id = site_id", "response": "Checks if the host domain is one of the site objects\n        and sets request. site_id accordingly."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef signable(self, request, authheaders, bodyhash=None):\n        method = request.method.upper()\n        host = request.get_header(\"host\")\n        path = request.url.canonical_path()\n        query = request.url.encoded_query()\n\n        timestamp = request.get_header(\"x-authorization-timestamp\")\n        auth_headers = self.unroll_auth_headers(authheaders, exclude_signature=True, sep='&', quote=False)\n        base = '{0}\\n{1}\\n{2}\\n{3}\\n{4}'.format(method, host, path, query, auth_headers)\n\n        cheaders = []\n        cheaders_sign = '\\n'\n        if \"headers\" in authheaders and authheaders[\"headers\"] != \"\":\n            cheaders = authheaders[\"headers\"].split(\";\")\n        cheaders.sort()\n        for cheader in cheaders:\n            cheaders_sign += '{0}: {1}\\n'.format(cheader.lower(), request.get_header(cheader))\n        base += cheaders_sign\n        base += '{0}'.format(timestamp)\n\n        if bodyhash is not None:\n            base += '\\n{0}\\n{1}'.format(request.get_header('content-type'), bodyhash)\n\n        return base", "response": "Creates the signable string for a request and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_auth_headers(self, authorization):\n        matches = re.findall(r'(\\w+)=\"(.*?)\"', authorization)\n        return dict(matches)", "response": "Parses the authorization headers from the request and returns a dict that is accepted by all other API functions which expect the authorization headers in a dict format."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the v2 signature appropriate for the request.", "response": "def sign(self, request, authheaders, secret):\n        \"\"\"Returns the v2 signature appropriate for the request. The request is not changed by this function.\n\n        Keyword arguments:\n        request -- A request object which can be consumed by this API.\n        authheaders -- A string-indexable object which contains the headers appropriate for this signature version.\n        secret -- The base64-encoded secret key for the HMAC authorization.\n        \"\"\"\n        if \"id\" not in authheaders or authheaders[\"id\"] == '':\n            raise KeyError(\"id required in authorization headers.\")\n        if \"nonce\" not in authheaders or authheaders[\"nonce\"] == '':\n            raise KeyError(\"nonce required in authorization headers.\")\n        if \"realm\" not in authheaders or authheaders[\"realm\"] == '':\n            raise KeyError(\"realm required in authorization headers.\")\n        if request.get_header('x-authorization-timestamp') == '':\n            raise KeyError(\"X-Authorization-Timestamp is required.\")\n        bodyhash = None\n        if request.body is not None and request.body != b'':\n            sha256 = hashlib.sha256()\n            sha256.update(request.body)\n            bodyhash = base64.b64encode(sha256.digest()).decode('utf-8')\n\n        try:\n            mac = hmac.HMAC(base64.b64decode(secret.encode('utf-8'), validate=True), digestmod=self.digest)\n        except TypeError:\n            s = secret.encode('utf-8')\n            if not re.match(b'^[A-Za-z0-9+/]*={0,2}$', s):\n                raise binascii.Error('Non-base64 digit found')\n            mac = hmac.HMAC(base64.b64decode(s), digestmod=self.digest)\n        mac.update(self.signable(request, authheaders, bodyhash).encode('utf-8'))\n        digest = mac.digest()\n        return base64.b64encode(digest).decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_response_signer(self):\n        if not hasattr(self, \"response_signer\"):\n            self.response_signer = V2ResponseSigner(self.digest, orig=self)\n        return self.response_signer", "response": "Returns the response signer for this version of the signature."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nverify whether or not the request is an authorization appropriate and valid for this version of the signature.", "response": "def check(self, request, secret):\n        \"\"\"Verifies whether or not the request bears an authorization appropriate and valid for this version of the signature.\n        This verifies every element of the signature, including the timestamp's value.\n        Does not alter the request.\n\n        Keyword arguments:\n        request -- A request object which can be consumed by this API.\n        secret -- The base64-encoded secret key for the HMAC authorization.\n        \"\"\"\n        if request.get_header(\"Authorization\") == \"\":\n            return False\n        ah = self.parse_auth_headers(request.get_header(\"Authorization\"))\n        if \"signature\" not in ah:\n            return False\n        if request.get_header('x-authorization-timestamp') == '':\n            raise KeyError(\"X-Authorization-Timestamp is required.\")\n        timestamp = int(float(request.get_header('x-authorization-timestamp')))\n        if timestamp == 0:\n            raise ValueError(\"X-Authorization-Timestamp must be a valid, non-zero timestamp.\")\n        if self.preset_time is None:\n            curr_time = time.time()\n        else:\n            curr_time = self.preset_time\n        if timestamp > curr_time + 900:\n            raise ValueError(\"X-Authorization-Timestamp is too far in the future.\")\n        if timestamp < curr_time - 900:\n            raise ValueError(\"X-Authorization-Timestamp is too far in the past.\")\n        if request.body is not None and request.body != b'':\n            content_hash = request.get_header(\"x-authorization-content-sha256\")\n            if content_hash == '':\n                raise KeyError(\"X-Authorization-Content-SHA256 is required for requests with a request body.\")\n            sha256 = hashlib.sha256()\n            sha256.update(request.body)\n            if content_hash != base64.b64encode(sha256.digest()).decode('utf-8'):\n                raise ValueError(\"X-Authorization-Content-SHA256 must match the SHA-256 hash of the request body.\")\n        return ah[\"signature\"] == self.sign(request, ah, secret)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unroll_auth_headers(self, authheaders, exclude_signature=False, sep=\",\", quote=True):\n        res = \"\"\n        ordered = collections.OrderedDict(sorted(authheaders.items()))\n        form = '{0}=\\\"{1}\\\"' if quote else '{0}={1}'\n        if exclude_signature:\n            return sep.join([form.format(k, urlquote(str(v), safe='')) for k, v in ordered.items() if k != 'signature'])\n        else:\n            return sep.join([form.format(k, urlquote(str(v), safe='') if k != 'signature' else str(v)) for k, v in ordered.items()])", "response": "Converts an authorization header dict - like object into a string representing the authorization."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sign_direct(self, request, authheaders, secret):\n        if request.get_header('x-authorization-timestamp') == '':\n            request.with_header(\"X-Authorization-Timestamp\", str(time.time()))\n        if request.body is not None and request.body != b'':\n            if request.get_header(\"x-authorization-content-sha256\") == '':\n                sha256 = hashlib.sha256()\n                sha256.update(request.body)\n                request.with_header(\"X-Authorization-Content-SHA256\", base64.b64encode(sha256.digest()).decode('utf-8'))\n        sig = self.sign(request, authheaders, secret)\n        authheaders[\"signature\"] = sig\n        return request.with_header(\"Authorization\", \"acquia-http-hmac {0}\".format(self.unroll_auth_headers(authheaders)))", "response": "Signs a request directly with a v2 signature."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking the response for the appropriate signature. Returns True if the signature matches the expected value.", "response": "def check(self, request, response, secret):\n        \"\"\"Checks the response for the appropriate signature. Returns True if the signature matches the expected value.\n\n        Keyword arguments:\n        request -- A request object which can be consumed by this API.\n        response -- A requests response object or compatible signed response object.\n        secret -- The base64-encoded secret key for the HMAC authorization.\n        \"\"\"\n        auth = request.get_header('Authorization')\n        if auth == '':\n            raise KeyError('Authorization header is required for the request.')\n        ah = self.orig.parse_auth_headers(auth)\n        act = response.headers['X-Server-Authorization-HMAC-SHA256']\n        if act == '':\n            raise KeyError('Response is missing the signature header X-Server-Authorization-HMAC-SHA256.')\n        sig = self.sign(request, ah, response.text, secret)\n        return sig == act"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate the signable string for a response and returns it.", "response": "def signable(self, request, authheaders, response_body):\n        \"\"\"Creates the signable string for a response and returns it.\n\n        Keyword arguments:\n        request -- A request object which can be consumed by this API.\n        authheaders -- A string-indexable object which contains the headers appropriate for this signature version.\n        response_body -- A string or bytes-like object which represents the body of the response.\n        \"\"\"\n        nonce = authheaders[\"nonce\"]\n        timestamp = request.get_header(\"x-authorization-timestamp\")\n        try:\n            body_str = response_body.decode('utf-8')\n        except:\n            body_str = response_body\n        return '{0}\\n{1}\\n{2}'.format(nonce, timestamp, body_str)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sign(self, request, authheaders, response_body, secret):\n        if \"nonce\" not in authheaders or authheaders[\"nonce\"] == '':\n            raise KeyError(\"nonce required in authorization headers.\")\n        if request.get_header('x-authorization-timestamp') == '':\n            raise KeyError(\"X-Authorization-Timestamp is required.\")\n\n        try:\n            mac = hmac.HMAC(base64.b64decode(secret.encode('utf-8'), validate=True), digestmod=self.digest)\n        except TypeError:\n            s = secret.encode('utf-8')\n            if not re.match(b'^[A-Za-z0-9+/]*={0,2}$', s):\n                raise binascii.Error('Non-base64 digit found')\n            mac = hmac.HMAC(base64.b64decode(s), digestmod=self.digest)\n        mac.update(self.signable(request, authheaders, response_body).encode('utf-8'))\n        digest = mac.digest()\n        return base64.b64encode(digest).decode('utf-8')", "response": "Returns the response signature for the request."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_items_from_response(self, response):\n        for item in response.get('items', []):\n            id = item.get('id')\n            task = Task(id, taskqueue=self.taskqueue)\n            task._set_properties(item)\n            yield task", "response": "Yields all items from a response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntesting if the taskqueue exists.", "response": "def exists(self, client=None):\n        \"\"\"API call:  test for the existence of the taskqueue via a GET request\n\n        See\n        https://cloud.google.com/appengine/docs/python/taskqueue/rest/taskqueues/get\n\n        :type client: :class:`taskqueue.client.Client` or ``NoneType``\n        :param client: the client to use.  If not passed, falls back to the\n                       ``client`` stored on the current taskqueue.\n        \"\"\"\n        client = self._require_client(client)\n        try:\n            response = client.connection.api_request(method='GET', path=self.path)\n        except NotFound:\n            return False\n        else:\n            # projectname gets prefixed, this retrieves correct path with prefixed project name\n            # see https://code.google.com/p/googleappengine/issues/detail?id=10199\n            if os.path.split(response.get(\"id\"))[-1] == self.id:\n                self.full_name = response.get(\"id\")\n                return True\n            else:\n                return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a task from the current task queue.", "response": "def delete_task(self, id, client=None):\n        \"\"\"Deletes a task from the current task queue.\n\n        If the task isn't found (backend 404), raises a\n        :class:`gcloud.exceptions.NotFound`.\n\n        :type id: string\n        :param id: A task name to delete.\n\n        :type client: :class:`gcloud.taskqueue.client.Client` or ``NoneType``\n        :param client: Optional. The client to use.  If not passed, falls back\n                       to the ``client`` stored on the current taskqueue.\n\n        :raises: :class:`gcloud.exceptions.NotFound`\n        \"\"\"\n        client = self._require_client(client)\n        task = Task(taskqueue=self, id=id)\n\n        # We intentionally pass `_target_object=None` since a DELETE\n        # request has no response value (whether in a standard request or\n        # in a batch request).\n        client.connection.api_request(method='DELETE', path=task.path, _target_object=None)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_task(self, id, client=None):\n        client = self._require_client(client)\n        task = Task(taskqueue=self, id=id)\n        try:\n            response = client.connection.api_request(method='GET', path=task.path, _target_object=task)\n            task._set_properties(response)\n            return task\n        except NotFound:\n            return None", "response": "Gets a named task from taskqueue."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nacquires a lease on the topmost N unowned tasks in the specified queue.", "response": "def lease(self, lease_time, num_tasks, group_by_tag=False, tag=None, client=None):\n        \"\"\" Acquires a lease on the topmost N unowned tasks in the specified queue.\n\n        :type lease_time: int\n        :param lease_time: How long to lease this task, in seconds.\n\n        :type num_tasks: int\n        :param num_tasks: The number of tasks to lease.\n\n        :type group_by_tag: bool\n        :param group_by_tag: Optional. When True, returns tasks of the same tag. Specify which tag by using the\n        tag parameter. If tag is not specified, returns tasks of the same tag as the oldest task in the queue.\n\n        :type tag: string\n        :param tag: Optional. Only specify tag if groupByTag is true. If groupByTag is true and tag is not specified,\n        the tag is assumed to be that of the oldest task by ETA. I.e., the first available tag.\n\n        :type client: :class:`gcloud.taskqueue.client.Client` or ``NoneType``\n        :param client: Optional. The client to use.  If not passed, falls back\n                       to the ``client`` stored on the task's taskqueue.\n\n        :rtype: :class:`_TaskIterator`.\n        :returns: An iterator of tasks.\n        \"\"\"\n        client = self._require_client(client)\n\n        if group_by_tag:\n            query_params = {\"leaseSecs\": lease_time, \"numTasks\": num_tasks, \"groupByTag\": group_by_tag, \"tag\": tag}\n        else:\n            query_params = {\"leaseSecs\": lease_time, \"numTasks\": num_tasks}\n        response = client.connection.api_request(method='POST', path=self.path + \"/tasks/lease\",\n                                                 query_params=query_params)\n\n        for item in response.get('items', []):\n            id = item.get('id')\n            task = Task(id, taskqueue=self)\n            task._set_properties(item)\n            yield task"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_task(self, id, new_lease_time, client=None):\n        client = self._require_client(client)\n        task = Task(taskqueue=self, id=id)\n        try:\n            response = client.connection.api_request(method='POST', path=self.path + \"/tasks/\" + id,\n                                                     query_params={\"newLeaseSeconds\": new_lease_time},\n                                                     _target_object=task)\n            task._set_properties(response)\n            return task\n        except NotFound:\n            return None", "response": "Updates the duration of a task in the taskqueue."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninserting a new task into the task queue.", "response": "def insert_task(self, description, tag=None, client=None):\n        \"\"\" Insert task in task queue.\n\n        If the task isn't found (backend 404), raises a\n        :class:`gcloud.exceptions.NotFound`.\n\n        :type description: string\n        :param description: Description of task to perform\n\n        :type tag: string\n        :param tag: Optional. The tag for this task, allows leasing tasks with a specific tag\n\n        :type client: :class:`gcloud.taskqueue.client.Client` or ``NoneType``\n        :param client: Optional. The client to use.  If not passed, falls back\n                       to the ``client`` stored on the task's taskqueue.\n\n        :rtype: :class:`_Task`.\n        :returns: a task\n        :raises: :class:`gcloud.exceptions.NotFound`\n        \"\"\"\n        client = self._require_client(client)\n\n        new_task = {\n            \"queueName\": self.full_name,\n            \"payloadBase64\": base64.b64encode(description).decode('ascii'),\n            \"tag\": tag\n        }\n\n        response = client.connection.api_request(method='POST', path=self.path + \"/tasks/\", data=new_task)\n        task = Task(taskqueue=self, id=response.get('id'))\n        task._set_properties(response)\n        return task"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds the class to the container.", "response": "def add_to(self, container):\n        '''\n        Add the class to @container.\n        '''\n        if self.container:\n            self.remove_from(self.container)\n        container.add(self)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndrawing all widgets and sub - containers to the surface.", "response": "def draw(self, surf):\n        '''\n        Draw all widgets and sub-containers to @surf.\n        '''\n        if self.shown:\n            for w in self.widgets:\n                surf.blit(w.image, self.convert_rect(w.rect))\n            for c in self.containers:\n                c.draw(surf)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves the class from its container contained items and sub - widgets.", "response": "def kill(self):\n        '''\n        Remove the class from its container, contained items and sub-widgets. \n        Runs automatically when the class is garbage collected.\n        '''\n        Base.kill(self)\n        \n        for c in self.containers:\n            c.remove_internal(self)\n        for w in self.widgets:\n            w.remove_internal(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add(self, *widgets):\n        '''\n        Place @widgets under the blitting hand of the Container(). Each arg \n        must be a Widget(), a fellow Container(), or an iterable. Else, things \n        get ugly...\n        '''\n        for w in widgets:\n            if is_widget(w):\n                if w not in self.widgets:\n                    self.widgets.add(w)\n                    w.add_internal(self)\n            elif is_container(w):\n                if w not in self.containers:\n                    self.containers.add(w)\n                    w.add_internal(self)\n            else:\n                # If it isn't an iterable, we'll get an error here.\n                # Desired effect.\n                self.add(*w)", "response": "Add widgets to the set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving widgets from the blitting hand of the Container.", "response": "def remove(self, *widgets):\n        '''\n        Remove @widgets from the blitting hand of the Container(). Each arg \n        must be a Widget(), a fellow Container(), or an iterable. Else, things \n        get ugly...\n        '''\n        for w in widgets:\n            if w in self.widgets:\n                self.widgets.remove(w)\n                w.remove_internal(self)\n            elif w in self.containers:\n                self.containers.remove(w)\n                w.remove_internal(self)\n            else:\n                # If it isn't an iterable, we'll get an error here.\n                # Desired effect.\n                self.remove(*w)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_point(self, point):\n        '''\n        Converts the relative position of @point into an absolute position. To \n        be used for event considerations, blitting is handled directly by the \n        Container().\n        '''\n        return self.container.convert_point(Vector(point) + self.pos)", "response": "Converts the relative position of point into an absolute position."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_rect(self, rect):\n        '''\n        Converts the relative position of @rect into an absolute position.To be \n        used for event considerations, blitting is handled directly by the \n        Container().\n        '''\n        return self.container.convert_rect(rect.move(self.pos))", "response": "Converts the relative position of rect into an absolute position."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbind a callback to the related object.", "response": "def bind(self, func, etype):\n        '''\n        Wraps around container.bind().\n        '''\n        if func not in self._event_cbs:\n            wrapped = self._WrapCB(self, func)\n            self._event_cbs[func] = wrapped\n        else:\n            wrapped = self._event_cbs[func]\n        self.container.bind(wrapped, etype)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unbind(self, func, etype):\n        '''\n        Wraps around container.unbind().\n        '''\n        wrapped = self.event_cbs[func]\n        self.container.unbind(self, wrapped, etype)", "response": "Unbinds a handler from the event handler func."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nscrolls the x - coordinate of the current mouse button.", "response": "def scroll_x(self, pixels, relative=True):\n        '''\n        Negative values for @pixels scroll left, positive values scroll right;\n        @relative determines whether to set the scroll-x value or change as \n        above.\n        '''\n        if relative:\n            self.offset.x += int(pixels)\n        else:\n            self.offset.x = int(pixels)\n        self._update()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nscroll the y - axis of the log - table.", "response": "def scroll_y(self, pixels, relative=True):\n        '''\n        Negative values for @pixels scroll up, positive values scroll down;\n        @relative determines whether to set the scroll-y value or change as \n        above.\n        '''\n        if relative:\n            self.offset.y += int(pixels)\n        else:\n            self.offset.y = int(pixels)\n        self._update()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_rect(self, rect):\n        '''\n        Same as Container().convert_rect(), but adds scrolling.\n        '''\n        return Container.convert_rect(self, rect).move(-self.offset)", "response": "Same as Container. convert_rect but adds scrolling."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving the character before the cursor.", "response": "def bspace(self):\n        '''\n        Remove the character before the cursor.\n        '''\n        try:\n            self.text.pop(self.cursor_loc - 1)\n            self.cursor_loc -= 1\n        except IndexError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninserts string @s at the current cursor location.", "response": "def insert(self, s):\n        '''\n        Insert string @s at the current cursor location.\n        '''\n        for c in s:\n            self.text.insert(self.cursor_loc, c)\n            self.cursor_loc += 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the image before drawing.", "response": "def update(self):\n        '''\n        Update the image before drawing.\n        '''\n        self.image = self.blank.copy()\n        vcenter_blit(self.image, \n                self.font.render(self.get(), True, self.color), \n                self.margin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy(self):\n        '''\n        Copy the text in the Entry() and place it on the clipboard.\n        '''\n        try:\n            pygame.scrap.put(SCRAP_TEXT, self.get())\n            return True\n        except:\n            # pygame.scrap is experimental, allow for changes\n            return False", "response": "Copy the text in the Entry and place it on the clipboard."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npastes text from the clipboard at the cursor. Returns True if the clipboard is valid False otherwise.", "response": "def paste(self):\n        '''\n        Insert text from the clipboard at the cursor.\n        '''\n        try:\n            t = pygame.scrap.get(SCRAP_TEXT)\n            if t:\n                self.insert(t)\n                return True\n        except:\n            # pygame.scrap is experimental, allow for changes\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the image before drawing.", "response": "def update(self):\n        '''\n        Update the image before drawing.\n        '''\n        self.image = self.blank.copy()\n        \n        bf = self.font.render(''.join(self.text[:self.cursor_loc]), \n                True, self.color)\n        br = bf.get_rect().move(self.margin)\n        \n        af = self.font.render(''.join(self.text[self.cursor_loc:]), \n                True, self.color)\n        \n        cr = self.cursor.get_rect()\n        cvec = Vector(br.w - cr.w, 0) + self.margin\n        \n        scroll = Vector()\n        \n        if cvec.x > self.rect.w:\n            scroll.x = self.rect.w - cvec.x - self.font.size(' ')[0]\n        \n        vcenter_blit(self.image, bf, scroll + br)\n        vcenter_blit(self.image, af, scroll + br.topright)\n        \n        if self.cursor_shown and self.focus and pygame.key.get_focused():\n            vcenter_blit(self.image, self.cursor, scroll + cvec)\n        \n        if self.blink_frames != None:\n            self.blinker += 1\n            self.blinker %= self.blink_frames\n            if not self.blinker:\n                self.cursor_shown = not self.cursor_shown"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef configure(self, config):\n        self._name = config.get_as_string_with_default(\"name\", self._name)\n        self._name = config.get_as_string_with_default(\"info.name\", self._name)\n\n        self._description = config.get_as_string_with_default(\"description\", self._description)\n        self._description = config.get_as_string_with_default(\"info.description\", self._description)\n\n        self._properties = config.get_section(\"properties\")", "response": "Configures the component by passing configuration parameters."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_from_env(key, default=\"\"):\n    try:\n        val = os.environ.get(key, default)\n        return val.split(',')\n    except (KeyError, ValueError):\n        return []", "response": "Returns a list of strings from the environment variable key."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of lists from the environment variable key.", "response": "def lists_from_env(key, default=\"\"):\n    \"\"\"\n    Splits a string in the format \"a,b:c,d,e:f\" into\n    [('a', 'b'), ('c', 'd', 'e'), ('f', )]\n    \"\"\"\n    try:\n        val = os.environ.get(key, default)\n        lists = val.split(\":\")\n        return [i.split(',') for i in lists]\n    except (KeyError, ValueError):\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint out the animation cycle to stdout. This function is for use with synchronous functions and must be run in a thread. Args: animation_ (generator): A generator that produces strings for the animation. Should be endless. step (float): Seconds between each animation frame.", "response": "def animate_cli(animation_, step, event):\n    \"\"\"Print out the animation cycle to stdout. This function is for use with\n    synchronous functions and must be run in a thread.\n\n    Args:\n        animation_ (generator): A generator that produces strings for the\n        animation. Should be endless.\n        step (float): Seconds between each animation frame.\n    \"\"\"\n    while True:  # run at least once, important for tests!\n        time.sleep(step)\n        frame = next(animation_)\n        sys.stdout.write(frame)\n        sys.stdout.flush()\n        if event.is_set():\n            break\n    sys.stdout.write(animation_.get_erase_frame())\n    sys.stdout.flush()\n    animation_.reset()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef configuration_ES(t0: date, t1: Optional[date] = None, \n                     steps_per_day: int = None) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Get the positions and velocities of the earth and sun from date t0 to t1.\n    Returned as a tuple q, v\n    q: Nx3 array of positions (x, y, z) in the J2000.0 coordinate frame.\n    \"\"\"\n    # Default steps_per_day = 1\n    if steps_per_day is None:\n        steps_per_day = 1\n        \n    # Time step dt is 1.0 over steps per day\n    dt: float = 1.0 / float(steps_per_day)\n\n    # Default t1 to one day after t0\n    if t1 is not None:\n        # Convert t to a julian day\n        jd0: int = julian_day(t0)\n        jd1: int = julian_day(t1)\n    else:\n        jd0: int = julian_day(t0)\n        jd1: int = jd0 + dt\n    # Pass the times as an array of julian days\n    jd: np.ndarray = np.arange(jd0, jd1, dt)\n\n    # Position and velocity of the sun as arrays of length 3\n    sun_id: int = jpl_body_id['sun']\n    pos_sun, vel_sun = jpl_kernel[0, sun_id].compute_and_differentiate(jd)\n\n    # Position and velocity of the earth as arrays of length 3\n    earth_id: int = jpl_body_id['earth']\n    pos_earth, vel_earth = jpl_kernel[0, earth_id].compute_and_differentiate(jd)\n\n    # Convert positions from km to meters (multiply by km2m)\n    q = np.vstack([pos_sun, pos_earth]).T * km2m\n    # Convert velocities from km / day to meters / sec (multiply by km2m, divide by day2sec)\n    v = np.vstack([vel_sun, vel_earth]).T * (km2m / day2sec)\n\n    # Return tuple of Tx6 arrays for position q and velocity v\n    return q, v", "response": "Compute the Earth and Sun configuration for a given time range."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nplot the earth - sun orbits.", "response": "def plot_ES(q: np.ndarray, sim_name: str, fname: Optional[str] = None):\n    \"\"\"\n    Plot the earth-sun orbits.\n    q is a Tx6 array.  T indexes time points.  6 columns are sun (x, y, z) and earth (x, y, z)\n    \"\"\"\n    # Convert all distances from meters to astronomical units (AU)\n    # Unpack sun (x, y) in au; z not used in plots\n    sun_x = q[:,0] / au2m\n    sun_y = q[:,1] / au2m\n    # Unpack earth (x, y); z not used in plots\n    earth_x = q[:,3] / au2m\n    earth_y = q[:,4] / au2m\n    \n    # Set up chart title and scale\n    fig, ax = plt.subplots(figsize=[12,12])\n    ax.set_title(f'Orbit of Earth in 2018; Weekly from {sim_name}')\n    ax.set_xlabel('x in J2000.0 Frame; Astronomical Units (au)')\n    ax.set_ylabel('y in J2000.0 Frame; Astronomical Units (au)')\n    a = 1.2\n    ticks = np.arange(-a, a+0.2, 0.2)\n    ax.set_xlim(-a, a)\n    ax.set_ylim(-a, a)\n    ax.set_xticks(ticks)\n    ax.set_yticks(ticks)\n\n    # Set marker sizes proportional to size of bodies    \n    radius_earth = radius_tbl['earth']\n    markersize_earth = 8.0\n    markersize_sun = cbrt(radius_tbl['sun'] / radius_earth) * markersize_earth\n    \n    # Orbit of the Sun (it moves a little in barycentric coordinates)\n    ax.plot(sun_x, sun_y, label='Sun', color='orange', linewidth=0, markersize = markersize_sun, marker='o')\n    # Orbit of the Earth\n    ax.plot(earth_x, earth_y, label='Earth', color='b', linewidth=0, markersize = markersize_earth, marker='o')\n    \n    # Legend and grid\n    ax.legend()\n    ax.grid()\n\n    # Save plot if a filename was provided\n    if fname is not None:\n        fig.savefig(fname, bbox_inches='tight')\n\n    # Display plot\n    plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef accel_ES(q: np.ndarray):\n\n    # Number of celestial bodies\n    num_bodies: int = 2\n    # Number of dimensions in arrays; 3 spatial dimensions times the number of bodies\n    dims = 3 * num_bodies\n\n    # Body 0 is the sun; Body 1 is the earth\n    m0 = mass[0]\n    m1 = mass[1]\n\n    # Extract position of the sun and earth as 3-vectors\n    pos_0 = q[slices[0]]\n    pos_1 = q[slices[1]]\n\n    # Displacement vector from sun to earth\n    dv_01: np.ndarray = pos_1 - pos_0\n\n    # Distance from sun to earth\n    r_01: float = np.linalg.norm(dv_01)\n    \n    # Unit vector pointing from sun to earth\n    udv_01 = dv_01 / r_01\n\n    # The force between these has magnitude G*m0*m1 / r^2\n    f_01: float = (G * m0 * m1) / (r_01 ** 2)\n    \n    # Initialize acceleration as 6x1 array\n    a: np.ndarray = np.zeros(dims)\n    \n    # The force vectors are attractive\n    a[slices[0]] += f_01 * udv_01 / m0\n    a[slices[1]] -= f_01 * udv_01 / m1\n\n    # Return the acceleration vector\n    return a", "response": "Compute the gravitational accelerations in the earth - sun system."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the kinetic and potential energy of the earth sun system", "response": "def energy_ES(q, v):\n    \"\"\"Compute the kinetic and potential energy of the earth sun system\"\"\"\n    # Body 0 is the sun, Body 1 is the earth\n    m0 = mass[0]\n    m1 = mass[1]\n\n    # Positions of sun and earth\n    q0: np.ndarray = q[:, slices[0]]\n    q1: np.ndarray = q[:, slices[1]]\n\n    # Velocities of sun and earth\n    v0: np.ndarray = v[:, slices[0]]\n    v1: np.ndarray = v[:, slices[1]]\n\n    # Kinetic energy is 1/2 mv^2\n    T0: np.ndarray = 0.5 * m0 * np.sum(v0 * v0, axis=1)\n    T1: np.ndarray = 0.5 * m1 * np.sum(v1 * v1, axis=1)\n    T: np.ndarray = T0 + T1\n    \n    # Potential energy is -G m1 m2  / r\n    dv_01 = q1 - q0\n    r_01 = np.linalg.norm(dv_01, axis=1)\n    U_01: np.ndarray = -G * m0 * m1 / r_01\n    U: np.ndarray = U_01\n    \n    # Total energy H = T + U\n    H = T + U\n    \n    return H, T, U"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a force function that will be applied to the potential energy fluxion of the earth - sun sytem.", "response": "def make_force_ES(q_vars, mass):\n    \"\"\"Fluxion with the potential energy of the earth-sun sytem\"\"\"\n    # Build the potential energy fluxion; just one pair of bodies\n    U =  U_ij(q_vars, mass, 0, 1)\n    # Varname arrays for both the coordinate system and U\n    vn_q = np.array([q.var_name for q in q_vars])\n    vn_fl = np.array(sorted(U.var_names))\n    # Permutation array for putting variables in q in the order expected by U (alphabetical)\n    q2fl = np.array([np.argmax((vn_q == v)) for v in vn_fl])\n    # Permutation array for putting results of U.diff() in order of q_vars\n    fl2q = np.array([np.argmax((vn_fl == v)) for v in vn_q])\n    # Return a force function from this potential\n    force_func = lambda q: -U.diff(q[q2fl]).squeeze()[fl2q]\n    return force_func"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _gen_s3_path(self, model, props):\n\n        now = '%.5f' % time.time()\n\n        return '%s/%s/%s/%s.%s' % (model.rtype, model.rid_value,\n                                   self._s3_rtype, now, props['file-ext'])", "response": "Generate the path to upload the resource ID and file - extension"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_post(self, req, resp, rid):\n\n        signals.pre_req.send(self.model)\n        signals.pre_req_upload.send(self.model)\n\n        props = req.deserialize(self.mimetypes)\n        model = find(self.model, rid)\n\n        signals.pre_upload.send(self.model, model=model)\n\n        try:\n            conn = s3_connect(self.key, self.secret)\n            path = self._gen_s3_path(model, props)\n            s3_url = s3_upload(self.acl, self.bucket, conn, props['content'],\n                               props['content-type'], path)\n        except IOError:\n            abort(ServiceUnavailable(**{\n                'detail': 'The upload attempt failed unexpectedly',\n            }))\n        else:\n            signals.post_upload.send(self.model, model=model, url=s3_url)\n\n            resp.location = s3_url\n            resp.status = falcon.HTTP_201\n\n            resp.serialize({'data': {'url': s3_url}})\n\n            signals.post_req.send(self.model)\n            signals.post_req_upload.send(self.model)", "response": "Handle the HTTP POST request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun f before the decorated function.", "response": "def before(f, chain=False):\n    \"\"\"Runs f before the decorated function.\"\"\"\n    def decorator(g):\n        @wraps(g)\n        def h(*args, **kargs):\n            if chain:\n                return g(f(*args, **kargs))\n            else:\n                f(*args, **kargs)\n                return g(*args, **kargs)\n        return h\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning f with the result of the decorated function.", "response": "def after(f, chain=False):\n    \"\"\"Runs f with the result of the decorated function.\"\"\"\n    def decorator(g):\n        @wraps(g)\n        def h(*args, **kargs):\n            if chain:\n                return f(g(*args, **kargs))\n            else:\n                r = g(*args, **kargs)\n                f(*args, **kargs)\n                return r\n        return h\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef during(f):\n    def decorator(g):\n        @wraps(g)\n        def h(*args, **kargs):\n            tf = Thread(target=f, args=args, kwargs=kargs)\n            tf.start()\n            r = g(*args, **kargs)\n            tf.join()\n            return r\n        return h\n    return decorator", "response": "Runs f in a separate thread."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _delete(self, _file_path, _method_title, _record_key):\r\n\r\n        '''\r\n            a helper method for non-blocking deletion of files\r\n            \r\n        :param _file_path: string with path to file to remove \r\n        :param _method_title: string with name of method calling _delete\r\n        :param _record_key: string with name of record key to delete\r\n        :return: None\r\n        '''\r\n\r\n        import os\r\n        from time import sleep\r\n\r\n        current_dir = os.path.split(_file_path)[0]\r\n        count = 0\r\n        retry_count = 10\r\n        while True:\r\n            try:\r\n                os.remove(_file_path)\r\n                while current_dir != self.collection_folder:\r\n                    if not os.listdir(current_dir):\r\n                        os.rmdir(current_dir)\r\n                        current_dir = os.path.split(current_dir)[0]\r\n                    else:\r\n                        break\r\n                break\r\n            except PermissionError:\r\n                sleep(.05)\r\n                count += 1\r\n                if count > retry_count:\r\n                    raise Exception('%s failed to delete %s' % (_method_title, _record_key))\r\n\r\n        os._exit(0)", "response": "a helper method for non - blocking deletion of files\r\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save(self, record_key, record_data, overwrite=True, secret_key=''):\r\n\r\n        ''' \r\n            a method to create a record in the collection folder\r\n\r\n        :param record_key: string with name to assign to record (see NOTES below)\r\n        :param record_data: byte data for record body\r\n        :param overwrite: [optional] boolean to overwrite records with same name\r\n        :param secret_key: [optional] string with key to encrypt data\r\n        :return: string with name of record\r\n\r\n        NOTE:   record_key may only contain alphanumeric, /, _, . or -\r\n                characters and may not begin with the . or / character.\r\n\r\n        NOTE:   using one or more / characters splits the key into\r\n                separate segments. these segments will appear as a\r\n                sub directories inside the record collection and each\r\n                segment is used as a separate index for that record\r\n                when using the list method\r\n                eg. lab/unittests/1473719695.2165067.json is indexed:\r\n                [ 'lab', 'unittests', '1473719695.2165067', '.json' ]\r\n        '''\r\n\r\n        title = '%s.save' % self.__class__.__name__\r\n            \r\n    # validate inputs\r\n        input_fields = {\r\n            'record_key': record_key,\r\n            'secret_key': secret_key\r\n        }\r\n        for key, value in input_fields.items():\r\n            if value:\r\n                object_title = '%s(%s=%s)' % (title, key, str(value))\r\n                self.fields.validate(value, '.%s' % key, object_title)\r\n    \r\n    # validate byte data\r\n        if not isinstance(record_data, bytes):\r\n            raise ValueError('%s(record_data=b\"...\") must be byte data.' % title)\r\n        \r\n    # construct and validate file path\r\n        file_path = os.path.join(self.collection_folder, record_key)\r\n        file_path = self.fields.validate(file_path, '.record_key_path')\r\n        file_root, file_name = os.path.split(file_path)\r\n        self.fields.validate(file_name, '.record_key_comp')\r\n        while file_root != self.collection_folder:\r\n            file_root, path_node = os.path.split(file_root)\r\n            self.fields.validate(path_node, '.record_key_comp')\r\n\r\n    # check overwrite exception\r\n        from os import path, makedirs\r\n        if not overwrite:\r\n            if path.exists(file_path):\r\n                raise Exception('%s(record_key=\"%s\") already exists. To overwrite, set overwrite=True' % (title, record_key))\r\n\r\n    # create directories in path to file\r\n        file_root, file_node = path.split(file_path)\r\n        if file_root:\r\n            if not path.exists(file_root):\r\n                makedirs(file_root)\r\n            \r\n    # encrypt data\r\n        if secret_key:\r\n            from labpack.encryption import cryptolab\r\n            record_data, secret_key = cryptolab.encrypt(record_data, secret_key)\r\n    \r\n    # save file\r\n        with open(file_path, 'wb') as f:\r\n            f.write(record_data)\r\n            f.close()\r\n    \r\n    # erase file date from drep files\r\n        import re\r\n        if re.search('\\\\.drep$', file_name):\r\n            from os import utime\r\n            file_time = 1\r\n            utime(file_path, times=(file_time, file_time))\r\n\r\n        return record_key", "response": "a method to create a record in the collection folder\r\n guilds related data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list(self, prefix='', delimiter='', filter_function=None, max_results=1, reverse_search=True, previous_key=''):\r\n\r\n        ''' \r\n            a method to list keys in the collection\r\n\r\n        :param prefix: string with prefix value to filter results\r\n        :param delimiter: string with value which results must not contain (after prefix)\r\n        :param filter_function: (positional arguments) function used to filter results\r\n        :param max_results: integer with maximum number of results to return\r\n        :param reverse_search: boolean to search keys in reverse alphanumeric order\r\n        :param previous_key: string with key in collection to begin search after\r\n        :return: list of key strings\r\n\r\n            NOTE:   each key string can be divided into one or more segments\r\n                    based upon the / characters which occur in the key string as\r\n                    well as its file extension type. if the key string represents\r\n                    a file path, then each directory in the path, the file name\r\n                    and the file extension are all separate indexed values.\r\n\r\n                    eg. lab/unittests/1473719695.2165067.json is indexed:\r\n                    [ 'lab', 'unittests', '1473719695.2165067', '.json' ]\r\n\r\n                    it is possible to filter the records in the collection according\r\n                    to one or more of these path segments using a filter_function.\r\n\r\n            NOTE:   the filter_function must be able to accept an array of positional\r\n                    arguments and return a value that can evaluate to true or false.\r\n                    while searching the records, list produces an array of strings\r\n                    which represent the directory structure in relative path of each\r\n                    key string. if a filter_function is provided, this list of strings\r\n                    is fed to the filter function. if the function evaluates this input\r\n                    and returns a true value the file will be included in the list\r\n                    results.\r\n        '''\r\n\r\n        title = '%s.list' % self.__class__.__name__\r\n\r\n    # validate input\r\n        input_fields = {\r\n            'prefix': prefix,\r\n            'delimiter': delimiter,\r\n            'max_results': max_results,\r\n            'record_key': previous_key\r\n        }\r\n        for key, value in input_fields.items():\r\n            if value:\r\n                object_title = '%s(%s=%s)' % (title, key, str(value))\r\n                self.fields.validate(value, '.%s' % key, object_title)\r\n\r\n    # validate filter function\r\n        if filter_function:\r\n            try:\r\n                path_segments = [ 'lab', 'unittests', '1473719695.2165067', '.json' ]\r\n                filter_function(*path_segments)\r\n            except:\r\n                err_msg = '%s(filter_function=%s)' % (title, filter_function.__class__.__name__)\r\n                raise TypeError('%s must accept positional arguments.' % err_msg)\r\n\r\n    # construct empty results list\r\n        results_list = []\r\n        root_segments = self.collection_folder.split(os.sep)\r\n        if previous_key:\r\n            previous_key = os.path.join(self.collection_folder, previous_key)\r\n\r\n    # determine root path\r\n        root_path = self.collection_folder\r\n        if prefix:\r\n            from os import path\r\n            file_root, file_name = path.split(prefix)\r\n            root_path = path.join(root_path, file_root)\r\n            \r\n    # walk collection folder to find files\r\n        for file_path in self.localhost.walk(root_path, reverse_search, previous_key):\r\n            path_segments = file_path.split(os.sep)\r\n            for i in range(len(root_segments)):\r\n                del path_segments[0]\r\n            record_key = os.path.join(*path_segments)\r\n            record_key = record_key.replace('\\\\','/')\r\n\r\n    # apply prefix filter\r\n            partial_key = record_key\r\n            if prefix:\r\n                if record_key.find(prefix) == 0:\r\n                    partial_key = record_key[len(prefix):]\r\n                else:\r\n                    continue\r\n    \r\n    # apply delimiter filter\r\n            if delimiter:\r\n                if partial_key.find(delimiter) > -1:\r\n                    continue\r\n    \r\n    # apply filter function\r\n            if filter_function:\r\n                if filter_function(*path_segments):\r\n                    results_list.append(record_key)\r\n            else:\r\n                results_list.append(record_key)\r\n\r\n    # return results list\r\n            if len(results_list) == max_results:\r\n                return results_list\r\n\r\n        return results_list", "response": "a method to list the keys in the collection"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove(self):\r\n\r\n        ''' \r\n            a method to remove collection and all records in the collection\r\n\r\n        :return: string with confirmation of deletion\r\n        '''\r\n\r\n        _title = '%s.remove' % self.__class__.__name__\r\n\r\n    # TODO  error handling is turned off to avoid system blocking\r\n    #       fix potential to create artifacts in the system\r\n\r\n    # remove collection tree\r\n        try:\r\n            import shutil\r\n            shutil.rmtree(self.collection_folder, ignore_errors=True)\r\n        except:\r\n            raise Exception('%s failed to remove %s collection from app data.' % (_title, self.collection_folder))\r\n\r\n        exit_msg = '%s collection has been removed from app data.' % self.collection_folder\r\n        return exit_msg", "response": "a method to remove collection and all records in the collection and all records in the collection"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef export(self, storage_client, overwrite=True):\r\n        \r\n        '''\r\n            a method to export all the records in collection to another platform\r\n            \r\n        :param storage_client: class object with storage client methods\r\n        :return: string with exit message\r\n        '''\r\n        \r\n        title = '%s.export' % self.__class__.__name__\r\n        \r\n    # validate storage client\r\n        method_list = [ 'save', 'load', 'list', 'export', 'delete', 'remove', '_import', 'collection_name' ]\r\n        for method in method_list:\r\n            if not getattr(storage_client, method, None):\r\n                from labpack.parsing.grammar import join_words\r\n                raise ValueError('%s(storage_client=...) must be a client object with %s methods.' % (title, join_words(method_list)))\r\n            \r\n    # walk collection folder to find files\r\n        import os\r\n        root_segments = self.collection_folder.split(os.sep)\r\n        count = 0\r\n        skipped = 0\r\n        for file_path in self.localhost.walk(self.collection_folder):\r\n            path_segments = file_path.split(os.sep)\r\n            for i in range(len(root_segments)):\r\n                del path_segments[0]\r\n            record_key = os.path.join(*path_segments)\r\n            record_key = record_key.replace('\\\\','/')\r\n            \r\n    # read and save files\r\n            record_data = open(file_path, 'rb').read()\r\n            last_modified = os.path.getmtime(file_path)\r\n            outcome = storage_client._import(record_key, record_data, overwrite=overwrite, last_modified=last_modified)\r\n            if outcome:\r\n                count += 1\r\n            else:\r\n                skipped += 1\r\n            \r\n    # report outcome\r\n        plural = ''\r\n        skip_insert = ''\r\n        new_folder = storage_client.collection_name\r\n        if count != 1:\r\n            plural = 's'\r\n        if skipped > 0:\r\n            skip_plural = ''\r\n            if skipped > 1:\r\n                skip_plural = 's'\r\n            skip_insert = ' %s record%s skipped to avoid overwrite.' % (str(skipped), skip_plural)\r\n        exit_msg = '%s record%s exported to %s.%s' % (str(count), plural, new_folder, skip_insert)\r\n        return exit_msg", "response": "a method to export all the records in collection to another platform\r\n            a method to export all the records in collection to another platform\r\n            a method to export all the records in collection to another platform\r\n            a method to export all the records in collection to another platform\r\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef current_frame(raw=False):\n        '''\n        Gives the current execution frame.\n\n        :returns:\n            The current execution frame that is actually executing this.\n        '''\n\n        # `import sys` is important here, because the `sys` module is special\n        # and we will end up with the class frame instead of the `current` one.\n\n        if NATIVE:\n            import sys\n\n            frame = sys._getframe()\n        else:\n            frame = _getframe()\n\n        frame = frame.f_back\n\n        if not raw:\n            frame = Frame(frame)\n\n        return frame", "response": "Returns the current execution frame."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlocate a specific element in a frame by criteria.", "response": "def locate(callback, root_frame=None, include_root=False, raw=False):\n        '''\n        Locates a frame by criteria.\n\n        :param callback:\n            One argument function to check the frame against. The frame we are\n            curretly on, is given as that argument.\n        :param root_frame:\n            The root frame to start the search from. Can be a callback taking\n            no arguments.\n        :param include_root:\n            `True` if the search should start from the `root_frame` or the one\n            beneath it. Defaults to `False`.\n        :param raw:\n            whether to use raw frames or wrap them in our own object. Defaults to\n            `False`.\n        :raises RuntimeError:\n            When no matching frame is found.\n        :returns:\n            The first frame which responds to the `callback`.\n        '''\n\n        def get_from(maybe_callable):\n            if callable(maybe_callable):\n                return maybe_callable()\n\n            return maybe_callable\n\n        # Creates new frames, whether raw or not.\n        new = lambda frame: frame if raw else Frame(frame)\n\n        current_frame = get_from(root_frame or Frame.current_frame(raw=True))\n        current_frame = new(current_frame)\n\n        if not include_root:\n            current_frame = new(current_frame.f_back)\n\n        # The search will stop, because at some point the frame will be falsy.\n        while current_frame:\n            found = callback(current_frame)\n\n            if found:\n                return current_frame\n\n            current_frame = new(current_frame.f_back)\n\n        raise Frame.NotFound('No matching frame found')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_call(self, func, *args, **kwargs):\n        self.func = func\n        self.func_args = args\n        self.func_kwargs = kwargs", "response": "Set the function & its arguments to be called when the task is processed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nserialize the Task object into a JSON strong representation.", "response": "def serialize(self):\n        \"\"\"\n        Serializes the ``Task`` data for storing in the queue.\n\n        All data must be JSON-serializable in order to be stored properly.\n\n        :returns: A JSON strong of the task data.\n        \"\"\"\n        data = {\n            'task_id': self.task_id,\n            'retries': self.retries,\n            'async': self.async,\n            'module': determine_module(self.func),\n            'callable': determine_name(self.func),\n            'args': self.func_args,\n            'kwargs': self.func_kwargs,\n            'options': {},\n        }\n\n        if self.on_start:\n            data['options']['on_start'] = {\n                'module': determine_module(self.on_start),\n                'callable': determine_name(self.on_start),\n            }\n\n        if self.on_success:\n            data['options']['on_success'] = {\n                'module': determine_module(self.on_success),\n                'callable': determine_name(self.on_success),\n            }\n\n        if self.on_error:\n            data['options']['on_error'] = {\n                'module': determine_module(self.on_error),\n                'callable': determine_name(self.on_error),\n            }\n\n        return json.dumps(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deserialize(cls, data):\n        data = json.loads(data)\n        options = data.get('options', {})\n\n        task = cls(\n            task_id=data['task_id'],\n            retries=data['retries'],\n            async=data['async']\n        )\n\n        func = import_attr(data['module'], data['callable'])\n        task.to_call(func, *data.get('args', []), **data.get('kwargs', {}))\n\n        if options.get('on_start'):\n            task.on_start = import_attr(\n                options['on_start']['module'],\n                options['on_start']['callable']\n            )\n\n        if options.get('on_success'):\n            task.on_success = import_attr(\n                options['on_success']['module'],\n                options['on_success']['callable']\n            )\n\n        if options.get('on_error'):\n            task.on_error = import_attr(\n                options['on_error']['module'],\n                options['on_error']['callable']\n            )\n\n        return task", "response": "Given some data from the queue creates a new Task instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self):\n        if self.on_start:\n            self.on_start(self)\n\n        try:\n            result = self.func(*self.func_args, **self.func_kwargs)\n        except Exception as err:\n            self.to_failed()\n\n            if self.on_error:\n                self.on_error(self, err)\n\n            raise\n\n        self.to_success()\n\n        if self.on_success:\n            self.on_success(self, result)\n\n        return result", "response": "Runs the task.\n\n        This fires the ``on_start`` hook function first (if present), passing\n        the task itself.\n\n        Then it runs the target function supplied via ``Task.to_call`` with\n        its arguments & stores the result.\n\n        If the target function succeeded, the ``on_success`` hook function is\n        called, passing both the task & the result to it.\n\n        If the target function failed (threw an exception), the ``on_error``\n        hook function is called, passing both the task & the exception to it.\n        Then the exception is re-raised.\n\n        Finally, the result is returned."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_typecode_list(ofwhat, tcname):\n    '''Check a list of typecodes for compliance with Struct\n    requirements.'''\n    for o in ofwhat:\n        if callable(o): #skip if _Mirage\n            continue\n        if not isinstance(o, TypeCode):\n            raise TypeError(\n                tcname + ' ofwhat outside the TypeCode hierarchy, ' +\n                str(o.__class__))\n        if o.pname is None and not isinstance(o, AnyElement):\n            raise TypeError(tcname + ' element ' + str(o) + ' has no name')", "response": "Check a list of typecodes for compliance with Struct\n    requirements."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning typecode or substitute type for wildcard or derived type. For serialization only.", "response": "def _get_type_or_substitute(typecode, pyobj, sw, elt):\n    '''return typecode or substitute type for wildcard or\n    derived type.  For serialization only.\n    '''\n    sub = getattr(pyobj, 'typecode', typecode)\n    if sub is typecode or sub is None:\n        return typecode\n\n    # Element WildCard\n    if isinstance(typecode, AnyElement):\n        return sub\n \n    # Global Element Declaration\n    if isinstance(sub, ElementDeclaration):\n        if (typecode.nspname,typecode.pname) == (sub.nspname,sub.pname):\n            raise TypeError(\\\n                'bad usage, failed to serialize element reference (%s, %s), in: %s' %\n                 (typecode.nspname, typecode.pname, sw.Backtrace(elt),))\n\n        # check substitutionGroup \n        if _is_substitute_element(typecode, sub):\n            return sub\n\n        raise TypeError(\\\n            'failed to serialize (%s, %s) illegal sub GED (%s,%s): %s' %\n             (typecode.nspname, typecode.pname, sub.nspname, sub.pname,\n              sw.Backtrace(elt),))\n\n    # Local Element\n    if not isinstance(typecode, AnyType) and not isinstance(sub, typecode.__class__):\n        raise TypeError(\\\n            'failed to serialize substitute %s for %s,  not derivation: %s' %\n             (sub, typecode, sw.Backtrace(elt),))\n\n    # Make our substitution type match the elements facets,\n    # since typecode is created for a single existing pyobj\n    # some facets are irrelevant.\n    sub = _copy(sub)\n    sub.nspname = typecode.nspname\n    sub.pname = typecode.pname\n    sub.aname = typecode.aname\n    sub.minOccurs = sub.maxOccurs = 1\n    return sub"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a StrictRedis connection instance.", "response": "def get_connection(self, host, port, db):\n        \"\"\"\n        Returns a ``StrictRedis`` connection instance.\n        \"\"\"\n        return redis.StrictRedis(\n            host=host,\n            port=port,\n            db=db,\n            decode_responses=True\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndrop all the task in the specified queue.", "response": "def drop_all(self, queue_name):\n        \"\"\"\n        Drops all the task in the queue.\n\n        :param queue_name: The name of the queue. Usually handled by the\n            ``Gator`` instance.\n        :type queue_name: string\n        \"\"\"\n        task_ids = self.conn.lrange(queue_name, 0, -1)\n\n        for task_id in task_ids:\n            self.conn.delete(task_id)\n\n        self.conn.delete(queue_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef push(self, queue_name, task_id, data):\n        self.conn.lpush(queue_name, task_id)\n        self.conn.set(task_id, data)\n        return task_id", "response": "Pushes a task onto the queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pop(self, queue_name):\n        task_id = self.conn.lpop(queue_name)\n        data = self.conn.get(task_id)\n        self.conn.delete(task_id)\n        return data", "response": "Pops a task off the queue."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, queue_name, task_id):\n        self.conn.lrem(queue_name, 1, task_id)\n        data = self.conn.get(task_id)\n\n        if data:\n            self.conn.delete(task_id)\n            return data", "response": "Pops a specific task off the queue by identifier. Returns the data for the task."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef contains_non_repeat_actions(self):\n        '''\n        Because repeating repeat actions can get ugly real fast\n        '''\n        for action in self.actions:\n            if not isinstance(action, (int, dynamic.RepeatCommand)):\n                return True\n        return False", "response": "Returns True if there are any non - repeat actions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _all_correct_list(array):\n    if type(array) not in _ITERABLE_TYPES:\n        return False\n\n    for item in array:\n        if not type(item) in _ITERABLE_TYPES:\n            return False\n\n        if len(item) != 2:\n            return False\n\n    return True", "response": "Make sure that all items in array have good type and size."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting data to dictionary.", "response": "def _convert_to_dict(data):\n    \"\"\"\n    Convert `data` to dictionary.\n\n    Tries to get sense in multidimensional arrays.\n\n    Args:\n        data: List/dict/tuple of variable dimension.\n\n    Returns:\n        dict: If the data can be converted to dictionary.\n\n    Raises:\n        MetaParsingException: When the data are unconvertible to dict.\n    \"\"\"\n    if isinstance(data, dict):\n        return data\n\n    if isinstance(data, list) or isinstance(data, tuple):\n        if _all_correct_list(data):\n            return dict(data)\n        else:\n            data = zip(data[::2], data[1::2])\n            return dict(data)\n    else:\n        raise MetaParsingException(\n            \"Can't decode provided metadata - unknown structure.\"\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_structure(data):\n    if not isinstance(data, dict):\n        try:\n            data = _convert_to_dict(data)\n        except MetaParsingException:\n            raise\n        except:\n            raise MetaParsingException(\n                \"Metadata format has invalid strucure (dict is expected).\"\n            )\n\n    for key, val in data.iteritems():\n        if type(key) not in _ALLOWED_TYPES:\n            raise MetaParsingException(\n                \"Can't decode the meta file - invalid type of keyword '\" +\n                str(key) +\n                \"'!\"\n            )\n        if type(val) not in _ALLOWED_TYPES:\n            raise MetaParsingException(\n                \"Can't decode the meta file - invalid type of keyword '\" +\n                str(key) +\n                \"'!\"\n            )\n\n    return data", "response": "Checks whether the data is a flat dictionary. If not try to convert it to dictionary. If not raise MetaParsingException."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck whether the key matches the keyword. If so set the value to value.", "response": "def check(self, key, value):\n        \"\"\"\n        Check whether `key` matchs the :attr:`keyword`. If so, set the\n        :attr:`value` to `value`.\n\n        Args:\n            key (str): Key which will be matched with :attr:`keyword`.\n            value (str): Value which will be assigned to :attr:`value` if keys\n                         matches.\n\n        Returns:\n            True/False: Whether the key matched :attr:`keyword`.\n        \"\"\"\n        key = key.lower().strip()\n\n        # try unicode conversion\n        try:\n            key = key.decode(\"utf-8\")\n        except UnicodeEncodeError:\n            pass\n\n        key = self._remove_accents(key)\n\n        if self.keyword in key.split():\n            self.value = value\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving accent from a unicode string.", "response": "def _remove_accents(self, input_str):\n        \"\"\"\n        Convert unicode string to ASCII.\n\n        Credit: http://stackoverflow.com/a/517974\n        \"\"\"\n        nkfd_form = unicodedata.normalize('NFKD', input_str)\n        return u\"\".join([c for c in nkfd_form if not unicodedata.combining(c)])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses a key in all required and optional fields.", "response": "def process(self, key, val):\n        \"\"\"\n        Try to look for `key` in all required and optional fields. If found,\n        set the `val`.\n        \"\"\"\n        for field in self.fields:\n            if field.check(key, val):\n                return\n\n        for field in self.optional:\n            if field.check(key, val):\n                return"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a structure when the object is valid.", "response": "def get_epublication(self):\n        \"\"\"\n        Returns:\n            EPublication: Structure when the object :meth:`is_valid`.\n\n        Raises:\n            MetaParsingException: When the object is not valid.\n        \"\"\"\n        if not self.is_valid():\n            bad_fields = filter(lambda x: not x.is_valid(), self.fields)\n            bad_fields = map(\n                lambda x: \"Keyword '%s' (%s) not found.\" % (x.keyword, x.descr),\n                bad_fields\n            )\n\n            raise MetaParsingException(\n                \"Missing field(s):\\n\\t\" + \"\\n\\t\".join(bad_fields)\n            )\n\n        relevant_fields = self.fields\n        relevant_fields += filter(lambda x: x.is_valid(), self.optional)\n\n        epub_dict = dict(map(lambda x: (x.epub, x.value), relevant_fields))\n\n        # make sure, that all fields present in EPublication has values also\n        # in epub_dict\n        for epublication_part in EPublication._fields:\n            if epublication_part not in epub_dict:\n                epub_dict[epublication_part] = None\n\n        if not is_valid_isbn(epub_dict[\"ISBN\"]):\n            raise MetaParsingException(\n                \"ISBN '%s' is not valid!\" % epub_dict[\"ISBN\"]\n            )\n\n        return EPublication(**epub_dict)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_size(cls):\n        return sum([getattr(cls, name).length\n                    for name in cls.get_fields_names()])", "response": "Returns the total byte size of the fields in this structure"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenders a template with optional context or request.", "response": "def template_render(template, context=None, request=None):\n    \"\"\"\n    Passing Context or RequestContext to Template.render is deprecated in 1.9+,\n    see https://github.com/django/django/pull/3883 and\n    https://github.com/django/django/blob/1.9rc1/django/template/backends/django.py#L82-L84\n\n    :param template: Template instance\n    :param context: dict\n    :param request: Request instance\n    :return: rendered template as SafeText instance\n    \"\"\"\n    if django.VERSION < (1, 8) or isinstance(template, Template):\n        if request:\n            context = RequestContext(request, context)\n        else:\n            context = Context(context)\n        return template.render(context)\n    # backends template, e.g. django.template.backends.django.Template\n    else:\n        return template.render(context, request=request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_all_related_many_to_many_objects(opts):\n    if django.VERSION < (1, 9):\n        return opts.get_all_related_many_to_many_objects()\n    else:\n        return [r for r in opts.related_objects if r.field.many_to_many]", "response": "Get all related objects in the order they are to be many - to - many"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nformat an image. Args: path (str): Path to the image file. options (dict): Options to apply to the image. Returns: (list) A list of PIL images. The list will always be of length 1 unless resolutions for resizing are provided in the options.", "response": "def format_image(path, options):\n    '''Formats an image.\n\n    Args:\n        path (str): Path to the image file.\n        options (dict): Options to apply to the image.\n\n    Returns:\n        (list) A list of PIL images. The list will always be of length\n        1 unless resolutions for resizing are provided in the options. \n    '''\n    image = Image.open(path)\n    image_pipeline_results = __pipeline_image(image, options)\n    return image_pipeline_results"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __pipeline_image(image, options):\n    '''Sends an image through a processing pipeline.\n    Applies all (relevant) provided options to a given image.\n    Args:\n        image: An instance of a PIL Image.\n        options: Options to apply to the image (i.e. resolutions).\n    Returns:\n        A list containing instances of PIL Images. This list will always be length\n        1 if no options exist that require multiple copies to be created for a single\n        image (i.e resolutions).\n    '''\n    results = []\n\n    # Begin pipline\n\n    # 1. Create image copies for each resolution\n    if 'resolutions' in options:\n        resolutions = options['resolutions']  # List of resolution tuples\n        for res in resolutions:\n            img_rs = resize(image, res)  # Resized image\n\n            # Add image to result set. This result set will be pulled from\n            # throughout the pipelining process to perform more processing (watermarking).\n            results.append(img_rs)\n\n    # 2. Apply watermark to each image copy\n    if 'wmark-img' in options:\n        wtrmk_path = options['wmark-img']\n        if wtrmk_path:\n            if len(results) == 0:\n                image = watermark_image(image, wtrmk_path)  #watermark actual image?\n            else:\n                for i in range(0, len(results)):\n                    results[i] = watermark_image(\n                        results[i], wtrmk_path)  #watermark actual image\n\n    if 'wmark-txt' in options:\n        wtrmk_txt = options['wmark-txt']\n        if wtrmk_txt:\n            if len(results) == 0:\n                image = watermark_text(image, wtrmk_txt)  #watermark actual image?\n            else:\n                for i in range(0, len(results)):\n                    results[i] = watermark_text(results[i],\n                                                wtrmk_txt)  #watermark actual image\n\n    # Fallback: Nothing was done to the image\n    if len(results) == 0:\n        results.append(image)\n    \n    return results", "response": "Sends an image through a processing pipeline."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_instance(key, expire=None):\n    global _instances\n    try:\n        instance = _instances[key]\n    except KeyError:\n        instance = RedisSet(\n            key,\n            _redis,\n            expire=expire\n        )\n        _instances[key] = instance\n\n    return instance", "response": "Return an instance of RedisSet."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add(self, value):\n        added = self.redis.sadd(\n            self.key,\n            value\n        )\n\n        if self.redis.scard(self.key) < 2:\n            self.redis.expire(self.key, self.expire)\n\n        return added", "response": "Add value to set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write(name, keyword, domain, citation, author, description, species, version, contact, licenses, values,\n          functions, output, value_prefix):\n    \"\"\"Build a namespace from items.\"\"\"\n    write_namespace(\n        name, keyword, domain, author, citation, values,\n        namespace_description=description,\n        namespace_species=species,\n        namespace_version=version,\n        author_contact=contact,\n        author_copyright=licenses,\n        functions=functions,\n        file=output,\n        value_prefix=value_prefix\n    )", "response": "Build a namespace from items."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhashing all versions on Artifactory.", "response": "def history(namespace_module):\n    \"\"\"Hash all versions on Artifactory.\"\"\"\n    for path in get_namespace_history(namespace_module):\n        h = get_bel_resource_hash(path.as_posix())\n        click.echo('{}\\t{}'.format(path, h))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_to_annotation(file, output):\n    resource = parse_bel_resource(file)\n\n    write_annotation(\n        keyword=resource['Namespace']['Keyword'],\n        values={k: '' for k in resource['Values']},\n        citation_name=resource['Citation']['NameString'],\n        description=resource['Namespace']['DescriptionString'],\n        file=output\n    )", "response": "Convert a namespace file to an annotation file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noutputting the hashes for the annotation resources versions.", "response": "def history(annotation_module):\n    \"\"\"Output the hashes for the annotation resources' versions.\"\"\"\n    for path in get_annotation_history(annotation_module):\n        h = get_bel_resource_hash(path.as_posix())\n        click.echo('{}\\t{}'.format(path, h))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts an annotation file to a namespace file.", "response": "def convert_to_namespace(file, output, keyword):\n    \"\"\"Convert an annotation file to a namespace file.\"\"\"\n    resource = parse_bel_resource(file)\n    write_namespace(\n        namespace_keyword=(keyword or resource['AnnotationDefinition']['Keyword']),\n        namespace_name=resource['AnnotationDefinition']['Keyword'],\n        namespace_description=resource['AnnotationDefinition']['DescriptionString'],\n        author_name='Charles Tapley Hoyt',\n        namespace_domain=NAMESPACE_DOMAIN_OTHER,\n        values=resource['Values'],\n        citation_name=resource['Citation']['NameString'],\n        file=output\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_proxy():\n    proxies = _config['proxies']\n\n    return proxies[\n        random.randint(0, len(proxies) - 1)\n    ] if len(proxies) > 0 else None", "response": "Return a random proxy from proxy config."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an instance of Client.", "response": "def get_instance():\n    \"\"\"Return an instance of Client.\"\"\"\n    global _instances\n    user_agents = _config['user-agents']\n\n    user_agent = user_agents[\n        random.randint(0, len(user_agents) - 1)\n    ] if len(user_agents) > 0 else DEFAULT_UA\n\n    instance_key = user_agent\n\n    try:\n        instance = _instances[instance_key]\n    except KeyError:\n        instance = Client(user_agent, get_proxy)\n        _instances[instance_key] = instance\n\n    return instance"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, uri, disable_proxy=False, stream=False):\n        response = requests.get(\n            uri,\n            headers=self.headers,\n            allow_redirects=True,\n            cookies={},\n            stream=stream,\n            proxies=self.proxy if not disable_proxy else False\n        )\n\n        if response.status_code in _PERMITTED_STATUS_CODES:\n            self.response_headers = response.headers\n            return response.content if not stream else response.iter_content()\n        else:\n            raise requests.exceptions.HTTPError(\n                \"HTTP response did not have a permitted status code.\"\n            )", "response": "Return Requests response to GET request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_content(self, uri, disable_proxy=False):\n        return self.get(uri=uri, disable_proxy=disable_proxy)", "response": "Return content from URI if Response status is good."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_iter_content(self, uri, disable_proxy=False):\n        return self.get(uri=uri, disable_proxy=disable_proxy, stream=True)", "response": "Return iterable content from URI if Response status is good."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dict of keys that differ with another config object.", "response": "def dict_diff(first, second):\n    \"\"\" Return a dict of keys that differ with another config object.\n    If a value is not found in one fo the configs, it will be represented\n    by KEYNOTFOUND.\n    @param first:   Fist dictionary to diff.\n    @param second:  Second dicationary to diff.\n    @return diff:   Dict of Key => (first.val, second.val)\n    \"\"\"\n    diff = {}\n    # Check all keys in first dict\n    for key in first:\n        if key not in second:\n            diff[key] = (first[key], None)\n        elif (first[key] != second[key]):\n            diff[key] = (first[key], second[key])\n    # Check all keys in second dict to find missing\n    for key in second:\n        if key not in first:\n            diff[key] = (None, second[key])\n    return diff"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a new word to the WordList and assigns it an id.", "response": "def add(self, word, id=None):\n        \"\"\"\n        Adds a new word to the WordList and assigns it an id.  If id is set,\n        :param word: The word token\n        :param id: (Optional) The token id can be set, but bypasses the automatic id assignment.  Only specify the id\n          if you plan to specify it on all add calls.\n        :return: None\n        \"\"\"\n        word_id = id if id is not None else self.get_next_id()\n        self[word] = word_id\n        self.id2word[word_id] = word"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprocesses a file and return the filename.", "response": "def process_file(self, path, dryrun):\n        \"\"\"\n        Concat files and return filename.\n        \"\"\"\n        # special case - skip output file so we won't include it in result\n        if path == self._output_path:\n            return None\n\n        # if dryrun skip and return file\n        if dryrun:\n            return path\n\n        # concat file with output file\n        with open(path, \"rb\") as infile:\n            data = infile.read()\n            self._output_file.write(data)\n\n        # return processed file path\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetects whether a sequence of elements leads to a fork of streams", "response": "def _chain_forks(elements):\n        \"\"\"Detect whether a sequence of elements leads to a fork of streams\"\"\"\n        # we are only interested in the result, so unwind from the end\n        for element in reversed(elements):\n            if element.chain_fork:\n                return True\n            elif element.chain_join:\n                return False\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a scene release string and return a dictionary of parsed values.", "response": "def parse(filename):\n    \"\"\" parse a scene release string and return a dictionary of parsed values.\"\"\"\n    screensize = re.compile('720p|1080p', re.I)\n    source = re.compile(\n        '\\.(AHDTV|MBluRay|MDVDR|CAM|TS|TELESYNC|DVDSCR|DVD9|BDSCR|DDC|R5LINE|R5|DVDRip|HDRip|BRRip|BDRip|WEBRip|WEB-?HD|HDtv|PDTV|WEBDL|BluRay)', re.I)\n    year = re.compile('(1|2)\\d{3}')\n    series = re.compile('s\\d{1,3}e\\d{1,3}', re.I)\n    group = re.compile('[A-Za-z0-9]+$', re.I)\n    video = re.compile('DVDR|Xvid|MP4|NTSC|PAL|[xh][\\.\\s]?264', re.I)\n    audio = re.compile('AAC2[\\.\\s]0|AAC|AC3|DTS|DD5', re.I)\n    edition = re.compile(\n        '\\.(UNRATED|DC|(Directors|EXTENDED)[\\.\\s](CUT|EDITION)|EXTENDED|3D|2D|\\bNF\\b)',\n        re.I)\n    tags = re.compile(\n        '\\.(COMPLETE|LiMiTED|DL|DUAL|iNTERNAL|UNCUT|FS|FESTIVAL|DOKU|DOCU|DUBBED|SUBBED|WS)', re.I)\n    release = re.compile(\n        'REAL[\\.\\s]PROPER|REMASTERED|PROPER|REPACK|READNFO|READ[\\.\\s]NFO|DiRFiX|NFOFiX', re.I)\n    subtitles = re.compile(\n        '\\.(MULTi(SUBS)?|FiNNiSH|NORDiC|DANiSH|SWEDiSH|NORWEGiAN|iTALiAN|SPANiSH|SWESUB)', re.I)\n    language = re.compile('\\.(German|ITALIAN|Chinese|CZECH|RUSSIAN|FRENCH|TRUEFRENCH)', re.I)\n\n    title = filename\n    attrs = {'screenSize': screensize,\n             'source': source,\n             'year': year,\n             'series': series,\n             'release_group': group,\n             'video': video,\n             'audio': audio,\n             'edition': edition,\n             'tags': tags,\n             'release': release,\n             'subtitles': subtitles,\n             'language': language\n             }\n    data = {}\n    for attr in attrs:\n        match = methodcaller('search', filename)(attrs[attr])\n        if match:\n            matched = methodcaller('group')(match)\n            data[attr] = matched.strip('.')\n            title = re.sub(matched, '', title)\n    if 'series' in data:\n        s, e = re.split('e|E', data['series'])\n        # use lstrip to remove leading zeros\n        data['season'] = s[1:].lstrip('0')\n        data['episode'] = e.lstrip('0')\n        data['series'] = True\n    temptitle = title.replace('.', ' ').strip('-').strip()\n    data['title'] = re.sub('\\s{2,}', ' ', temptitle)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a new server certificate signed by the provided root.", "response": "def generate_ecdsap256_server_certificate(server_id, server_pub_key, expiry,\n                                        root_id, root_priv_key):\n    \"\"\"\n    Creates a new server certificate signed by the provided root.\n\n    :param Identity server_id: the identity for the certificate\n    :param ECDSAP256PublicKey server_pub_key: the public key for the certificate\n    :param CertificateExpiry expiry: the expiry date for the certificate\n    :param CertificateRootId root_id: the root identity to sign this certificate\n    :param ECDSAP256PrivateKey root_priv_key: the root private key to sign this\n                                            certificate\n    \"\"\"\n    cert = ECDSAP256ServerCertificate()\n    rc = _lib.xtt_generate_server_certificate_ecdsap256(cert.native,\n                                                        server_id.native,\n                                                        server_pub_key.native,\n                                                        expiry.native,\n                                                        root_id.native,\n                                                        root_priv_key.native)\n    if rc == RC.SUCCESS:\n        return cert\n    else:\n        raise error_from_code(rc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef project(self, win_width, win_height, fov, viewer_distance):\n        factor = fov / (viewer_distance + self.z)\n        x = self.x * factor + win_width // 2\n        y = -self.y * factor + win_height // 2\n        return Point3D(x, y, 1)", "response": "Transforms this 3D point to 2D using a perspective projection."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef can_create(self, locator):\n        if locator == None:\n            raise Exception(\"Locator cannot be null\")\n        \n        # Iterate from the latest factories\n        for factory in reversed(self._factories):\n            locator = factory.can_create(locator)\n            if locator != None:\n                return locator\n        \n        return None", "response": "Checks if this factory can create a component by given locator."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read(cls, iprot):\n        '''\n        Read a new object from the given input protocol and return the object.\n\n        :type iprot: thryft.protocol._input_protocol._InputProtocol\n        :rtype: pastpy.gen.database.impl.dbf.objects_dbf_record.ObjectsDbfRecord\n        '''\n\n        init_kwds = {}\n\n        iprot.read_struct_begin()\n        while True:\n            ifield_name, ifield_type, _ifield_id = iprot.read_field_begin()\n            if ifield_type == 0:  # STOP\n                break\n            elif ifield_name == 'accessno':\n                try:\n                    init_kwds['accessno'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'accessory':\n                try:\n                    init_kwds['accessory'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'acqvalue':\n                try:\n                    init_kwds['acqvalue'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'age':\n                try:\n                    init_kwds['age'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'appnotes':\n                try:\n                    init_kwds['appnotes'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'appraisor':\n                try:\n                    init_kwds['appraisor'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'assemzone':\n                try:\n                    init_kwds['assemzone'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'bagno':\n                try:\n                    init_kwds['bagno'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'boxno':\n                try:\n                    init_kwds['boxno'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'caption':\n                try:\n                    init_kwds['caption'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'cat':\n                try:\n                    init_kwds['cat'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'catby':\n                try:\n                    init_kwds['catby'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'catdate':\n                try:\n                    init_kwds['catdate'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'cattype':\n                try:\n                    init_kwds['cattype'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'chemcomp':\n                try:\n                    init_kwds['chemcomp'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'circum':\n                try:\n                    init_kwds['circum'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'circumft':\n                try:\n                    init_kwds['circumft'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'circumin':\n                try:\n                    init_kwds['circumin'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'classes':\n                try:\n                    init_kwds['classes'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'colldate':\n                try:\n                    init_kwds['colldate'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'collection':\n                try:\n                    init_kwds['collection'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'collector':\n                try:\n                    init_kwds['collector'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'conddate':\n                try:\n                    init_kwds['conddate'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'condexam':\n                try:\n                    init_kwds['condexam'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'condition':\n                try:\n                    init_kwds['condition'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'condnotes':\n                try:\n                    init_kwds['condnotes'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'count':\n                try:\n                    init_kwds['count'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'creator':\n                try:\n                    init_kwds['creator'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'creator2':\n                try:\n                    init_kwds['creator2'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'creator3':\n                try:\n                    init_kwds['creator3'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'credit':\n                try:\n                    init_kwds['credit'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'crystal':\n                try:\n                    init_kwds['crystal'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'culture':\n                try:\n                    init_kwds['culture'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'curvalmax':\n                try:\n                    init_kwds['curvalmax'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'curvalue':\n                try:\n                    init_kwds['curvalue'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'dataset':\n                try:\n                    init_kwds['dataset'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'date':\n                try:\n                    init_kwds['date'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'datingmeth':\n                try:\n                    init_kwds['datingmeth'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'datum':\n                try:\n                    init_kwds['datum'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'depth':\n                try:\n                    init_kwds['depth'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'depthft':\n                try:\n                    init_kwds['depthft'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'depthin':\n                try:\n                    init_kwds['depthin'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'descrip':\n                try:\n                    init_kwds['descrip'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'diameter':\n                try:\n                    init_kwds['diameter'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'diameterft':\n                try:\n                    init_kwds['diameterft'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'diameterin':\n                try:\n                    init_kwds['diameterin'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'dimnotes':\n                try:\n                    init_kwds['dimnotes'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'dimtype':\n                try:\n                    init_kwds['dimtype'] = iprot.read_i32()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'dispvalue':\n                try:\n                    init_kwds['dispvalue'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'earlydate':\n                try:\n                    init_kwds['earlydate'] = iprot.read_i32()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'elements':\n                try:\n                    init_kwds['elements'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'epoch':\n                try:\n                    init_kwds['epoch'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'era':\n                try:\n                    init_kwds['era'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'event':\n                try:\n                    init_kwds['event'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'ew':\n                try:\n                    init_kwds['ew'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'excavadate':\n                try:\n                    init_kwds['excavadate'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'excavateby':\n                try:\n                    init_kwds['excavateby'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'exhibitid':\n                try:\n                    init_kwds['exhibitid'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'exhibitno':\n                try:\n                    init_kwds['exhibitno'] = iprot.read_i32()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'exhlabel1':\n                try:\n                    init_kwds['exhlabel1'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'exhlabel2':\n                try:\n                    init_kwds['exhlabel2'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'exhlabel3':\n                try:\n                    init_kwds['exhlabel3'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'exhlabel4':\n                try:\n                    init_kwds['exhlabel4'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'exhstart':\n                try:\n                    init_kwds['exhstart'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'family':\n                try:\n                    init_kwds['family'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'feature':\n                try:\n                    init_kwds['feature'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'flagdate':\n                try:\n                    init_kwds['flagdate'] = iprot.read_date_time()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'flagnotes':\n                try:\n                    init_kwds['flagnotes'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'flagreason':\n                try:\n                    init_kwds['flagreason'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'formation':\n                try:\n                    init_kwds['formation'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'fossils':\n                try:\n                    init_kwds['fossils'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'found':\n                try:\n                    init_kwds['found'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'fracture':\n                try:\n                    init_kwds['fracture'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'frame':\n                try:\n                    init_kwds['frame'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'framesize':\n                try:\n                    init_kwds['framesize'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'genus':\n                try:\n                    init_kwds['genus'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'gparent':\n                try:\n                    init_kwds['gparent'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'grainsize':\n                try:\n                    init_kwds['grainsize'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'habitat':\n                try:\n                    init_kwds['habitat'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'hardness':\n                try:\n                    init_kwds['hardness'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'height':\n                try:\n                    init_kwds['height'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'heightft':\n                try:\n                    init_kwds['heightft'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'heightin':\n                try:\n                    init_kwds['heightin'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'homeloc':\n                try:\n                    init_kwds['homeloc'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'idby':\n                try:\n                    init_kwds['idby'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'iddate':\n                try:\n                    init_kwds['iddate'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'imagefile':\n                try:\n                    init_kwds['imagefile'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'imageno':\n                try:\n                    init_kwds['imageno'] = iprot.read_i32()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'imagesize':\n                try:\n                    init_kwds['imagesize'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'inscomp':\n                try:\n                    init_kwds['inscomp'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'inscrlang':\n                try:\n                    init_kwds['inscrlang'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'inscrpos':\n                try:\n                    init_kwds['inscrpos'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'inscrtech':\n                try:\n                    init_kwds['inscrtech'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'inscrtext':\n                try:\n                    init_kwds['inscrtext'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'inscrtrans':\n                try:\n                    init_kwds['inscrtrans'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'inscrtype':\n                try:\n                    init_kwds['inscrtype'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'insdate':\n                try:\n                    init_kwds['insdate'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'insphone':\n                try:\n                    init_kwds['insphone'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'inspremium':\n                try:\n                    init_kwds['inspremium'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'insrep':\n                try:\n                    init_kwds['insrep'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'insvalue':\n                try:\n                    init_kwds['insvalue'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'invnby':\n                try:\n                    init_kwds['invnby'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'invndate':\n                try:\n                    init_kwds['invndate'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'kingdom':\n                try:\n                    init_kwds['kingdom'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'latdeg':\n                try:\n                    init_kwds['latdeg'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'latedate':\n                try:\n                    init_kwds['latedate'] = iprot.read_i32()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'legal':\n                try:\n                    init_kwds['legal'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'length':\n                try:\n                    init_kwds['length'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'lengthft':\n                try:\n                    init_kwds['lengthft'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'lengthin':\n                try:\n                    init_kwds['lengthin'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'level':\n                try:\n                    init_kwds['level'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'lithofacie':\n                try:\n                    init_kwds['lithofacie'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'loancond':\n                try:\n                    init_kwds['loancond'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'loandue':\n                try:\n                    init_kwds['loandue'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'loanid':\n                try:\n                    init_kwds['loanid'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'loaninno':\n                try:\n                    init_kwds['loaninno'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'loanno':\n                try:\n                    init_kwds['loanno'] = iprot.read_i32()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'loanrenew':\n                try:\n                    init_kwds['loanrenew'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'locfield1':\n                try:\n                    init_kwds['locfield1'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'locfield2':\n                try:\n                    init_kwds['locfield2'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'locfield3':\n                try:\n                    init_kwds['locfield3'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'locfield4':\n                try:\n                    init_kwds['locfield4'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'locfield5':\n                try:\n                    init_kwds['locfield5'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'locfield6':\n                try:\n                    init_kwds['locfield6'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'longdeg':\n                try:\n                    init_kwds['longdeg'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'luster':\n                try:\n                    init_kwds['luster'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'made':\n                try:\n                    init_kwds['made'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'maintcycle':\n                try:\n                    init_kwds['maintcycle'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'maintdate':\n                try:\n                    init_kwds['maintdate'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'maintnote':\n                try:\n                    init_kwds['maintnote'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'material':\n                try:\n                    init_kwds['material'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'medium':\n                try:\n                    init_kwds['medium'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'member':\n                try:\n                    init_kwds['member'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'mmark':\n                try:\n                    init_kwds['mmark'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'nhclass':\n                try:\n                    init_kwds['nhclass'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'nhorder':\n                try:\n                    init_kwds['nhorder'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'notes':\n                try:\n                    init_kwds['notes'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'ns':\n                try:\n                    init_kwds['ns'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'objectid':\n                try:\n                    init_kwds['objectid'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'objname':\n                try:\n                    init_kwds['objname'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'objname2':\n                try:\n                    init_kwds['objname2'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'objname3':\n                try:\n                    init_kwds['objname3'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'objnames':\n                try:\n                    init_kwds['objnames'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'occurrence':\n                try:\n                    init_kwds['occurrence'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'oldno':\n                try:\n                    init_kwds['oldno'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'origin':\n                try:\n                    init_kwds['origin'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'othername':\n                try:\n                    init_kwds['othername'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'otherno':\n                try:\n                    init_kwds['otherno'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'outdate':\n                try:\n                    init_kwds['outdate'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'owned':\n                try:\n                    init_kwds['owned'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'parent':\n                try:\n                    init_kwds['parent'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'people':\n                try:\n                    init_kwds['people'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'period':\n                try:\n                    init_kwds['period'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'phylum':\n                try:\n                    init_kwds['phylum'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'policyno':\n                try:\n                    init_kwds['policyno'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'ppid':\n                try:\n                    init_kwds['ppid'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'preparator':\n                try:\n                    init_kwds['preparator'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'prepdate':\n                try:\n                    init_kwds['prepdate'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'preserve':\n                try:\n                    init_kwds['preserve'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'pressure':\n                try:\n                    init_kwds['pressure'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'provenance':\n                try:\n                    init_kwds['provenance'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'pubnotes':\n                try:\n                    init_kwds['pubnotes'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'qrurl':\n                try:\n                    init_kwds['qrurl'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'recas':\n                try:\n                    init_kwds['recas'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'recdate':\n                try:\n                    init_kwds['recdate'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'recfrom':\n                try:\n                    init_kwds['recfrom'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'relation':\n                try:\n                    init_kwds['relation'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'relnotes':\n                try:\n                    init_kwds['relnotes'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'renewuntil':\n                try:\n                    init_kwds['renewuntil'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'repatby':\n                try:\n                    init_kwds['repatby'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'repatclaim':\n                try:\n                    init_kwds['repatclaim'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'repatdate':\n                try:\n                    init_kwds['repatdate'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'repatdisp':\n                try:\n                    init_kwds['repatdisp'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'repathand':\n                try:\n                    init_kwds['repathand'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'repatnotes':\n                try:\n                    init_kwds['repatnotes'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'repatnotic':\n                try:\n                    init_kwds['repatnotic'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'repattype':\n                try:\n                    init_kwds['repattype'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'rockclass':\n                try:\n                    init_kwds['rockclass'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'rockcolor':\n                try:\n                    init_kwds['rockcolor'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'rockorigin':\n                try:\n                    init_kwds['rockorigin'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'rocktype':\n                try:\n                    init_kwds['rocktype'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'role':\n                try:\n                    init_kwds['role'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'role2':\n                try:\n                    init_kwds['role2'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'role3':\n                try:\n                    init_kwds['role3'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'school':\n                try:\n                    init_kwds['school'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'sex':\n                try:\n                    init_kwds['sex'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'sgflag':\n                try:\n                    init_kwds['sgflag'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'signedname':\n                try:\n                    init_kwds['signedname'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'signloc':\n                try:\n                    init_kwds['signloc'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'site':\n                try:\n                    init_kwds['site'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'siteno':\n                try:\n                    init_kwds['siteno'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'specgrav':\n                try:\n                    init_kwds['specgrav'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'species':\n                try:\n                    init_kwds['species'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'sprocess':\n                try:\n                    init_kwds['sprocess'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'stage':\n                try:\n                    init_kwds['stage'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'status':\n                try:\n                    init_kwds['status'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'statusby':\n                try:\n                    init_kwds['statusby'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'statusdate':\n                try:\n                    init_kwds['statusdate'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'sterms':\n                try:\n                    init_kwds['sterms'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'stratum':\n                try:\n                    init_kwds['stratum'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'streak':\n                try:\n                    init_kwds['streak'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'subfamily':\n                try:\n                    init_kwds['subfamily'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'subjects':\n                try:\n                    init_kwds['subjects'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'subspecies':\n                try:\n                    init_kwds['subspecies'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'technique':\n                try:\n                    init_kwds['technique'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'tempauthor':\n                try:\n                    init_kwds['tempauthor'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'tempby':\n                try:\n                    init_kwds['tempby'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'tempdate':\n                try:\n                    init_kwds['tempdate'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'temperatur':\n                try:\n                    init_kwds['temperatur'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'temploc':\n                try:\n                    init_kwds['temploc'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'tempnotes':\n                try:\n                    init_kwds['tempnotes'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'tempreason':\n                try:\n                    init_kwds['tempreason'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'tempuntil':\n                try:\n                    init_kwds['tempuntil'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'texture':\n                try:\n                    init_kwds['texture'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'title':\n                try:\n                    init_kwds['title'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'tlocfield1':\n                try:\n                    init_kwds['tlocfield1'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'tlocfield2':\n                try:\n                    init_kwds['tlocfield2'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'tlocfield3':\n                try:\n                    init_kwds['tlocfield3'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'tlocfield4':\n                try:\n                    init_kwds['tlocfield4'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'tlocfield5':\n                try:\n                    init_kwds['tlocfield5'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'tlocfield6':\n                try:\n                    init_kwds['tlocfield6'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'udf1':\n                try:\n                    init_kwds['udf1'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'udf10':\n                try:\n                    init_kwds['udf10'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'udf11':\n                try:\n                    init_kwds['udf11'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'udf12':\n                try:\n                    init_kwds['udf12'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'udf13':\n                try:\n                    init_kwds['udf13'] = iprot.read_i32()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'udf14':\n                try:\n                    init_kwds['udf14'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'udf15':\n                try:\n                    init_kwds['udf15'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'udf16':\n                try:\n                    init_kwds['udf16'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'udf17':\n                try:\n                    init_kwds['udf17'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'udf18':\n                try:\n                    init_kwds['udf18'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'udf19':\n                try:\n                    init_kwds['udf19'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'udf2':\n                try:\n                    init_kwds['udf2'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'udf20':\n                try:\n                    init_kwds['udf20'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'udf21':\n                try:\n                    init_kwds['udf21'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'udf22':\n                try:\n                    init_kwds['udf22'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'udf3':\n                try:\n                    init_kwds['udf3'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'udf4':\n                try:\n                    init_kwds['udf4'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'udf5':\n                try:\n                    init_kwds['udf5'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'udf6':\n                try:\n                    init_kwds['udf6'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'udf7':\n                try:\n                    init_kwds['udf7'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'udf8':\n                try:\n                    init_kwds['udf8'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'udf9':\n                try:\n                    init_kwds['udf9'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'unit':\n                try:\n                    init_kwds['unit'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'updated':\n                try:\n                    init_kwds['updated'] = iprot.read_date_time()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'updatedby':\n                try:\n                    init_kwds['updatedby'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'used':\n                try:\n                    init_kwds['used'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'valuedate':\n                try:\n                    init_kwds['valuedate'] = iprot.read_date()\n                except (TypeError,):\n                    pass\n            elif ifield_name == 'varieties':\n                try:\n                    init_kwds['varieties'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'vexhtml':\n                try:\n                    init_kwds['vexhtml'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'vexlabel1':\n                try:\n                    init_kwds['vexlabel1'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'vexlabel2':\n                try:\n                    init_kwds['vexlabel2'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'vexlabel3':\n                try:\n                    init_kwds['vexlabel3'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'vexlabel4':\n                try:\n                    init_kwds['vexlabel4'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'webinclude':\n                try:\n                    init_kwds['webinclude'] = iprot.read_bool()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'weight':\n                try:\n                    init_kwds['weight'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'weightin':\n                try:\n                    init_kwds['weightin'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'weightlb':\n                try:\n                    init_kwds['weightlb'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'width':\n                try:\n                    init_kwds['width'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'widthft':\n                try:\n                    init_kwds['widthft'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'widthin':\n                try:\n                    init_kwds['widthin'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'xcord':\n                try:\n                    init_kwds['xcord'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'ycord':\n                try:\n                    init_kwds['ycord'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'zcord':\n                try:\n                    init_kwds['zcord'] = iprot.read_decimal()\n                except (decimal.InvalidOperation, TypeError,):\n                    pass\n            elif ifield_name == 'zsorter':\n                try:\n                    init_kwds['zsorter'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            elif ifield_name == 'zsorterx':\n                try:\n                    init_kwds['zsorterx'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            iprot.read_field_end()\n        iprot.read_struct_end()\n\n        return cls(**init_kwds)", "response": "Reads a new object from the given input protocol and returns the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(self, oprot):\n        '''\n        Write this object to the given output protocol and return self.\n\n        :type oprot: thryft.protocol._output_protocol._OutputProtocol\n        :rtype: pastpy.gen.database.impl.dbf.objects_dbf_record.ObjectsDbfRecord\n        '''\n\n        oprot.write_struct_begin('ObjectsDbfRecord')\n\n        if self.accessno is not None:\n            oprot.write_field_begin(name='accessno', type=11, id=None)\n            oprot.write_string(self.accessno)\n            oprot.write_field_end()\n\n        if self.accessory is not None:\n            oprot.write_field_begin(name='accessory', type=11, id=None)\n            oprot.write_string(self.accessory)\n            oprot.write_field_end()\n\n        if self.acqvalue is not None:\n            oprot.write_field_begin(name='acqvalue', type=11, id=None)\n            oprot.write_decimal(self.acqvalue)\n            oprot.write_field_end()\n\n        if self.age is not None:\n            oprot.write_field_begin(name='age', type=11, id=None)\n            oprot.write_string(self.age)\n            oprot.write_field_end()\n\n        if self.appnotes is not None:\n            oprot.write_field_begin(name='appnotes', type=11, id=None)\n            oprot.write_string(self.appnotes)\n            oprot.write_field_end()\n\n        if self.appraisor is not None:\n            oprot.write_field_begin(name='appraisor', type=11, id=None)\n            oprot.write_string(self.appraisor)\n            oprot.write_field_end()\n\n        if self.assemzone is not None:\n            oprot.write_field_begin(name='assemzone', type=11, id=None)\n            oprot.write_string(self.assemzone)\n            oprot.write_field_end()\n\n        if self.bagno is not None:\n            oprot.write_field_begin(name='bagno', type=11, id=None)\n            oprot.write_string(self.bagno)\n            oprot.write_field_end()\n\n        if self.boxno is not None:\n            oprot.write_field_begin(name='boxno', type=11, id=None)\n            oprot.write_string(self.boxno)\n            oprot.write_field_end()\n\n        if self.caption is not None:\n            oprot.write_field_begin(name='caption', type=11, id=None)\n            oprot.write_string(self.caption)\n            oprot.write_field_end()\n\n        if self.cat is not None:\n            oprot.write_field_begin(name='cat', type=11, id=None)\n            oprot.write_string(self.cat)\n            oprot.write_field_end()\n\n        if self.catby is not None:\n            oprot.write_field_begin(name='catby', type=11, id=None)\n            oprot.write_string(self.catby)\n            oprot.write_field_end()\n\n        if self.catdate is not None:\n            oprot.write_field_begin(name='catdate', type=10, id=None)\n            oprot.write_date(self.catdate)\n            oprot.write_field_end()\n\n        if self.cattype is not None:\n            oprot.write_field_begin(name='cattype', type=11, id=None)\n            oprot.write_string(self.cattype)\n            oprot.write_field_end()\n\n        if self.chemcomp is not None:\n            oprot.write_field_begin(name='chemcomp', type=11, id=None)\n            oprot.write_string(self.chemcomp)\n            oprot.write_field_end()\n\n        if self.circum is not None:\n            oprot.write_field_begin(name='circum', type=11, id=None)\n            oprot.write_decimal(self.circum)\n            oprot.write_field_end()\n\n        if self.circumft is not None:\n            oprot.write_field_begin(name='circumft', type=11, id=None)\n            oprot.write_decimal(self.circumft)\n            oprot.write_field_end()\n\n        if self.circumin is not None:\n            oprot.write_field_begin(name='circumin', type=11, id=None)\n            oprot.write_decimal(self.circumin)\n            oprot.write_field_end()\n\n        if self.classes is not None:\n            oprot.write_field_begin(name='classes', type=11, id=None)\n            oprot.write_string(self.classes)\n            oprot.write_field_end()\n\n        if self.colldate is not None:\n            oprot.write_field_begin(name='colldate', type=10, id=None)\n            oprot.write_date(self.colldate)\n            oprot.write_field_end()\n\n        if self.collection is not None:\n            oprot.write_field_begin(name='collection', type=11, id=None)\n            oprot.write_string(self.collection)\n            oprot.write_field_end()\n\n        if self.collector is not None:\n            oprot.write_field_begin(name='collector', type=11, id=None)\n            oprot.write_string(self.collector)\n            oprot.write_field_end()\n\n        if self.conddate is not None:\n            oprot.write_field_begin(name='conddate', type=10, id=None)\n            oprot.write_date(self.conddate)\n            oprot.write_field_end()\n\n        if self.condexam is not None:\n            oprot.write_field_begin(name='condexam', type=11, id=None)\n            oprot.write_string(self.condexam)\n            oprot.write_field_end()\n\n        if self.condition is not None:\n            oprot.write_field_begin(name='condition', type=11, id=None)\n            oprot.write_string(self.condition)\n            oprot.write_field_end()\n\n        if self.condnotes is not None:\n            oprot.write_field_begin(name='condnotes', type=11, id=None)\n            oprot.write_string(self.condnotes)\n            oprot.write_field_end()\n\n        if self.count is not None:\n            oprot.write_field_begin(name='count', type=11, id=None)\n            oprot.write_string(self.count)\n            oprot.write_field_end()\n\n        if self.creator is not None:\n            oprot.write_field_begin(name='creator', type=11, id=None)\n            oprot.write_string(self.creator)\n            oprot.write_field_end()\n\n        if self.creator2 is not None:\n            oprot.write_field_begin(name='creator2', type=11, id=None)\n            oprot.write_string(self.creator2)\n            oprot.write_field_end()\n\n        if self.creator3 is not None:\n            oprot.write_field_begin(name='creator3', type=11, id=None)\n            oprot.write_string(self.creator3)\n            oprot.write_field_end()\n\n        if self.credit is not None:\n            oprot.write_field_begin(name='credit', type=11, id=None)\n            oprot.write_string(self.credit)\n            oprot.write_field_end()\n\n        if self.crystal is not None:\n            oprot.write_field_begin(name='crystal', type=11, id=None)\n            oprot.write_string(self.crystal)\n            oprot.write_field_end()\n\n        if self.culture is not None:\n            oprot.write_field_begin(name='culture', type=11, id=None)\n            oprot.write_string(self.culture)\n            oprot.write_field_end()\n\n        if self.curvalmax is not None:\n            oprot.write_field_begin(name='curvalmax', type=11, id=None)\n            oprot.write_decimal(self.curvalmax)\n            oprot.write_field_end()\n\n        if self.curvalue is not None:\n            oprot.write_field_begin(name='curvalue', type=11, id=None)\n            oprot.write_decimal(self.curvalue)\n            oprot.write_field_end()\n\n        if self.dataset is not None:\n            oprot.write_field_begin(name='dataset', type=11, id=None)\n            oprot.write_string(self.dataset)\n            oprot.write_field_end()\n\n        if self.date is not None:\n            oprot.write_field_begin(name='date', type=11, id=None)\n            oprot.write_string(self.date)\n            oprot.write_field_end()\n\n        if self.datingmeth is not None:\n            oprot.write_field_begin(name='datingmeth', type=11, id=None)\n            oprot.write_string(self.datingmeth)\n            oprot.write_field_end()\n\n        if self.datum is not None:\n            oprot.write_field_begin(name='datum', type=11, id=None)\n            oprot.write_string(self.datum)\n            oprot.write_field_end()\n\n        if self.depth is not None:\n            oprot.write_field_begin(name='depth', type=11, id=None)\n            oprot.write_decimal(self.depth)\n            oprot.write_field_end()\n\n        if self.depthft is not None:\n            oprot.write_field_begin(name='depthft', type=11, id=None)\n            oprot.write_decimal(self.depthft)\n            oprot.write_field_end()\n\n        if self.depthin is not None:\n            oprot.write_field_begin(name='depthin', type=11, id=None)\n            oprot.write_decimal(self.depthin)\n            oprot.write_field_end()\n\n        if self.descrip is not None:\n            oprot.write_field_begin(name='descrip', type=11, id=None)\n            oprot.write_string(self.descrip)\n            oprot.write_field_end()\n\n        if self.diameter is not None:\n            oprot.write_field_begin(name='diameter', type=11, id=None)\n            oprot.write_decimal(self.diameter)\n            oprot.write_field_end()\n\n        if self.diameterft is not None:\n            oprot.write_field_begin(name='diameterft', type=11, id=None)\n            oprot.write_decimal(self.diameterft)\n            oprot.write_field_end()\n\n        if self.diameterin is not None:\n            oprot.write_field_begin(name='diameterin', type=11, id=None)\n            oprot.write_decimal(self.diameterin)\n            oprot.write_field_end()\n\n        if self.dimnotes is not None:\n            oprot.write_field_begin(name='dimnotes', type=11, id=None)\n            oprot.write_string(self.dimnotes)\n            oprot.write_field_end()\n\n        if self.dimtype is not None:\n            oprot.write_field_begin(name='dimtype', type=8, id=None)\n            oprot.write_i32(self.dimtype)\n            oprot.write_field_end()\n\n        if self.dispvalue is not None:\n            oprot.write_field_begin(name='dispvalue', type=11, id=None)\n            oprot.write_string(self.dispvalue)\n            oprot.write_field_end()\n\n        if self.earlydate is not None:\n            oprot.write_field_begin(name='earlydate', type=8, id=None)\n            oprot.write_i32(self.earlydate)\n            oprot.write_field_end()\n\n        if self.elements is not None:\n            oprot.write_field_begin(name='elements', type=11, id=None)\n            oprot.write_string(self.elements)\n            oprot.write_field_end()\n\n        if self.epoch is not None:\n            oprot.write_field_begin(name='epoch', type=11, id=None)\n            oprot.write_string(self.epoch)\n            oprot.write_field_end()\n\n        if self.era is not None:\n            oprot.write_field_begin(name='era', type=11, id=None)\n            oprot.write_string(self.era)\n            oprot.write_field_end()\n\n        if self.event is not None:\n            oprot.write_field_begin(name='event', type=11, id=None)\n            oprot.write_string(self.event)\n            oprot.write_field_end()\n\n        if self.ew is not None:\n            oprot.write_field_begin(name='ew', type=11, id=None)\n            oprot.write_string(self.ew)\n            oprot.write_field_end()\n\n        if self.excavadate is not None:\n            oprot.write_field_begin(name='excavadate', type=10, id=None)\n            oprot.write_date(self.excavadate)\n            oprot.write_field_end()\n\n        if self.excavateby is not None:\n            oprot.write_field_begin(name='excavateby', type=11, id=None)\n            oprot.write_string(self.excavateby)\n            oprot.write_field_end()\n\n        if self.exhibitid is not None:\n            oprot.write_field_begin(name='exhibitid', type=11, id=None)\n            oprot.write_string(self.exhibitid)\n            oprot.write_field_end()\n\n        if self.exhibitno is not None:\n            oprot.write_field_begin(name='exhibitno', type=8, id=None)\n            oprot.write_i32(self.exhibitno)\n            oprot.write_field_end()\n\n        if self.exhlabel1 is not None:\n            oprot.write_field_begin(name='exhlabel1', type=11, id=None)\n            oprot.write_string(self.exhlabel1)\n            oprot.write_field_end()\n\n        if self.exhlabel2 is not None:\n            oprot.write_field_begin(name='exhlabel2', type=11, id=None)\n            oprot.write_string(self.exhlabel2)\n            oprot.write_field_end()\n\n        if self.exhlabel3 is not None:\n            oprot.write_field_begin(name='exhlabel3', type=11, id=None)\n            oprot.write_string(self.exhlabel3)\n            oprot.write_field_end()\n\n        if self.exhlabel4 is not None:\n            oprot.write_field_begin(name='exhlabel4', type=11, id=None)\n            oprot.write_string(self.exhlabel4)\n            oprot.write_field_end()\n\n        if self.exhstart is not None:\n            oprot.write_field_begin(name='exhstart', type=10, id=None)\n            oprot.write_date(self.exhstart)\n            oprot.write_field_end()\n\n        if self.family is not None:\n            oprot.write_field_begin(name='family', type=11, id=None)\n            oprot.write_string(self.family)\n            oprot.write_field_end()\n\n        if self.feature is not None:\n            oprot.write_field_begin(name='feature', type=11, id=None)\n            oprot.write_string(self.feature)\n            oprot.write_field_end()\n\n        if self.flagdate is not None:\n            oprot.write_field_begin(name='flagdate', type=10, id=None)\n            oprot.write_date_time(self.flagdate)\n            oprot.write_field_end()\n\n        if self.flagnotes is not None:\n            oprot.write_field_begin(name='flagnotes', type=11, id=None)\n            oprot.write_string(self.flagnotes)\n            oprot.write_field_end()\n\n        if self.flagreason is not None:\n            oprot.write_field_begin(name='flagreason', type=11, id=None)\n            oprot.write_string(self.flagreason)\n            oprot.write_field_end()\n\n        if self.formation is not None:\n            oprot.write_field_begin(name='formation', type=11, id=None)\n            oprot.write_string(self.formation)\n            oprot.write_field_end()\n\n        if self.fossils is not None:\n            oprot.write_field_begin(name='fossils', type=11, id=None)\n            oprot.write_string(self.fossils)\n            oprot.write_field_end()\n\n        if self.found is not None:\n            oprot.write_field_begin(name='found', type=11, id=None)\n            oprot.write_string(self.found)\n            oprot.write_field_end()\n\n        if self.fracture is not None:\n            oprot.write_field_begin(name='fracture', type=11, id=None)\n            oprot.write_string(self.fracture)\n            oprot.write_field_end()\n\n        if self.frame is not None:\n            oprot.write_field_begin(name='frame', type=11, id=None)\n            oprot.write_string(self.frame)\n            oprot.write_field_end()\n\n        if self.framesize is not None:\n            oprot.write_field_begin(name='framesize', type=11, id=None)\n            oprot.write_string(self.framesize)\n            oprot.write_field_end()\n\n        if self.genus is not None:\n            oprot.write_field_begin(name='genus', type=11, id=None)\n            oprot.write_string(self.genus)\n            oprot.write_field_end()\n\n        if self.gparent is not None:\n            oprot.write_field_begin(name='gparent', type=11, id=None)\n            oprot.write_string(self.gparent)\n            oprot.write_field_end()\n\n        if self.grainsize is not None:\n            oprot.write_field_begin(name='grainsize', type=11, id=None)\n            oprot.write_string(self.grainsize)\n            oprot.write_field_end()\n\n        if self.habitat is not None:\n            oprot.write_field_begin(name='habitat', type=11, id=None)\n            oprot.write_string(self.habitat)\n            oprot.write_field_end()\n\n        if self.hardness is not None:\n            oprot.write_field_begin(name='hardness', type=11, id=None)\n            oprot.write_string(self.hardness)\n            oprot.write_field_end()\n\n        if self.height is not None:\n            oprot.write_field_begin(name='height', type=11, id=None)\n            oprot.write_decimal(self.height)\n            oprot.write_field_end()\n\n        if self.heightft is not None:\n            oprot.write_field_begin(name='heightft', type=11, id=None)\n            oprot.write_decimal(self.heightft)\n            oprot.write_field_end()\n\n        if self.heightin is not None:\n            oprot.write_field_begin(name='heightin', type=11, id=None)\n            oprot.write_decimal(self.heightin)\n            oprot.write_field_end()\n\n        if self.homeloc is not None:\n            oprot.write_field_begin(name='homeloc', type=11, id=None)\n            oprot.write_string(self.homeloc)\n            oprot.write_field_end()\n\n        if self.idby is not None:\n            oprot.write_field_begin(name='idby', type=11, id=None)\n            oprot.write_string(self.idby)\n            oprot.write_field_end()\n\n        if self.iddate is not None:\n            oprot.write_field_begin(name='iddate', type=10, id=None)\n            oprot.write_date(self.iddate)\n            oprot.write_field_end()\n\n        if self.imagefile is not None:\n            oprot.write_field_begin(name='imagefile', type=11, id=None)\n            oprot.write_string(self.imagefile)\n            oprot.write_field_end()\n\n        if self.imageno is not None:\n            oprot.write_field_begin(name='imageno', type=8, id=None)\n            oprot.write_i32(self.imageno)\n            oprot.write_field_end()\n\n        if self.imagesize is not None:\n            oprot.write_field_begin(name='imagesize', type=11, id=None)\n            oprot.write_string(self.imagesize)\n            oprot.write_field_end()\n\n        if self.inscomp is not None:\n            oprot.write_field_begin(name='inscomp', type=11, id=None)\n            oprot.write_string(self.inscomp)\n            oprot.write_field_end()\n\n        if self.inscrlang is not None:\n            oprot.write_field_begin(name='inscrlang', type=11, id=None)\n            oprot.write_string(self.inscrlang)\n            oprot.write_field_end()\n\n        if self.inscrpos is not None:\n            oprot.write_field_begin(name='inscrpos', type=11, id=None)\n            oprot.write_string(self.inscrpos)\n            oprot.write_field_end()\n\n        if self.inscrtech is not None:\n            oprot.write_field_begin(name='inscrtech', type=11, id=None)\n            oprot.write_string(self.inscrtech)\n            oprot.write_field_end()\n\n        if self.inscrtext is not None:\n            oprot.write_field_begin(name='inscrtext', type=11, id=None)\n            oprot.write_string(self.inscrtext)\n            oprot.write_field_end()\n\n        if self.inscrtrans is not None:\n            oprot.write_field_begin(name='inscrtrans', type=11, id=None)\n            oprot.write_string(self.inscrtrans)\n            oprot.write_field_end()\n\n        if self.inscrtype is not None:\n            oprot.write_field_begin(name='inscrtype', type=11, id=None)\n            oprot.write_string(self.inscrtype)\n            oprot.write_field_end()\n\n        if self.insdate is not None:\n            oprot.write_field_begin(name='insdate', type=10, id=None)\n            oprot.write_date(self.insdate)\n            oprot.write_field_end()\n\n        if self.insphone is not None:\n            oprot.write_field_begin(name='insphone', type=11, id=None)\n            oprot.write_string(self.insphone)\n            oprot.write_field_end()\n\n        if self.inspremium is not None:\n            oprot.write_field_begin(name='inspremium', type=11, id=None)\n            oprot.write_string(self.inspremium)\n            oprot.write_field_end()\n\n        if self.insrep is not None:\n            oprot.write_field_begin(name='insrep', type=11, id=None)\n            oprot.write_string(self.insrep)\n            oprot.write_field_end()\n\n        if self.insvalue is not None:\n            oprot.write_field_begin(name='insvalue', type=11, id=None)\n            oprot.write_decimal(self.insvalue)\n            oprot.write_field_end()\n\n        if self.invnby is not None:\n            oprot.write_field_begin(name='invnby', type=11, id=None)\n            oprot.write_string(self.invnby)\n            oprot.write_field_end()\n\n        if self.invndate is not None:\n            oprot.write_field_begin(name='invndate', type=10, id=None)\n            oprot.write_date(self.invndate)\n            oprot.write_field_end()\n\n        if self.kingdom is not None:\n            oprot.write_field_begin(name='kingdom', type=11, id=None)\n            oprot.write_string(self.kingdom)\n            oprot.write_field_end()\n\n        if self.latdeg is not None:\n            oprot.write_field_begin(name='latdeg', type=11, id=None)\n            oprot.write_decimal(self.latdeg)\n            oprot.write_field_end()\n\n        if self.latedate is not None:\n            oprot.write_field_begin(name='latedate', type=8, id=None)\n            oprot.write_i32(self.latedate)\n            oprot.write_field_end()\n\n        if self.legal is not None:\n            oprot.write_field_begin(name='legal', type=11, id=None)\n            oprot.write_string(self.legal)\n            oprot.write_field_end()\n\n        if self.length is not None:\n            oprot.write_field_begin(name='length', type=11, id=None)\n            oprot.write_decimal(self.length)\n            oprot.write_field_end()\n\n        if self.lengthft is not None:\n            oprot.write_field_begin(name='lengthft', type=11, id=None)\n            oprot.write_decimal(self.lengthft)\n            oprot.write_field_end()\n\n        if self.lengthin is not None:\n            oprot.write_field_begin(name='lengthin', type=11, id=None)\n            oprot.write_decimal(self.lengthin)\n            oprot.write_field_end()\n\n        if self.level is not None:\n            oprot.write_field_begin(name='level', type=11, id=None)\n            oprot.write_string(self.level)\n            oprot.write_field_end()\n\n        if self.lithofacie is not None:\n            oprot.write_field_begin(name='lithofacie', type=11, id=None)\n            oprot.write_string(self.lithofacie)\n            oprot.write_field_end()\n\n        if self.loancond is not None:\n            oprot.write_field_begin(name='loancond', type=11, id=None)\n            oprot.write_string(self.loancond)\n            oprot.write_field_end()\n\n        if self.loandue is not None:\n            oprot.write_field_begin(name='loandue', type=10, id=None)\n            oprot.write_date(self.loandue)\n            oprot.write_field_end()\n\n        if self.loanid is not None:\n            oprot.write_field_begin(name='loanid', type=11, id=None)\n            oprot.write_string(self.loanid)\n            oprot.write_field_end()\n\n        if self.loaninno is not None:\n            oprot.write_field_begin(name='loaninno', type=11, id=None)\n            oprot.write_string(self.loaninno)\n            oprot.write_field_end()\n\n        if self.loanno is not None:\n            oprot.write_field_begin(name='loanno', type=8, id=None)\n            oprot.write_i32(self.loanno)\n            oprot.write_field_end()\n\n        if self.loanrenew is not None:\n            oprot.write_field_begin(name='loanrenew', type=10, id=None)\n            oprot.write_date(self.loanrenew)\n            oprot.write_field_end()\n\n        if self.locfield1 is not None:\n            oprot.write_field_begin(name='locfield1', type=11, id=None)\n            oprot.write_string(self.locfield1)\n            oprot.write_field_end()\n\n        if self.locfield2 is not None:\n            oprot.write_field_begin(name='locfield2', type=11, id=None)\n            oprot.write_string(self.locfield2)\n            oprot.write_field_end()\n\n        if self.locfield3 is not None:\n            oprot.write_field_begin(name='locfield3', type=11, id=None)\n            oprot.write_string(self.locfield3)\n            oprot.write_field_end()\n\n        if self.locfield4 is not None:\n            oprot.write_field_begin(name='locfield4', type=11, id=None)\n            oprot.write_string(self.locfield4)\n            oprot.write_field_end()\n\n        if self.locfield5 is not None:\n            oprot.write_field_begin(name='locfield5', type=11, id=None)\n            oprot.write_string(self.locfield5)\n            oprot.write_field_end()\n\n        if self.locfield6 is not None:\n            oprot.write_field_begin(name='locfield6', type=11, id=None)\n            oprot.write_string(self.locfield6)\n            oprot.write_field_end()\n\n        if self.longdeg is not None:\n            oprot.write_field_begin(name='longdeg', type=11, id=None)\n            oprot.write_decimal(self.longdeg)\n            oprot.write_field_end()\n\n        if self.luster is not None:\n            oprot.write_field_begin(name='luster', type=11, id=None)\n            oprot.write_string(self.luster)\n            oprot.write_field_end()\n\n        if self.made is not None:\n            oprot.write_field_begin(name='made', type=11, id=None)\n            oprot.write_string(self.made)\n            oprot.write_field_end()\n\n        if self.maintcycle is not None:\n            oprot.write_field_begin(name='maintcycle', type=11, id=None)\n            oprot.write_string(self.maintcycle)\n            oprot.write_field_end()\n\n        if self.maintdate is not None:\n            oprot.write_field_begin(name='maintdate', type=10, id=None)\n            oprot.write_date(self.maintdate)\n            oprot.write_field_end()\n\n        if self.maintnote is not None:\n            oprot.write_field_begin(name='maintnote', type=11, id=None)\n            oprot.write_string(self.maintnote)\n            oprot.write_field_end()\n\n        if self.material is not None:\n            oprot.write_field_begin(name='material', type=11, id=None)\n            oprot.write_string(self.material)\n            oprot.write_field_end()\n\n        if self.medium is not None:\n            oprot.write_field_begin(name='medium', type=11, id=None)\n            oprot.write_string(self.medium)\n            oprot.write_field_end()\n\n        if self.member is not None:\n            oprot.write_field_begin(name='member', type=11, id=None)\n            oprot.write_string(self.member)\n            oprot.write_field_end()\n\n        if self.mmark is not None:\n            oprot.write_field_begin(name='mmark', type=11, id=None)\n            oprot.write_string(self.mmark)\n            oprot.write_field_end()\n\n        if self.nhclass is not None:\n            oprot.write_field_begin(name='nhclass', type=11, id=None)\n            oprot.write_string(self.nhclass)\n            oprot.write_field_end()\n\n        if self.nhorder is not None:\n            oprot.write_field_begin(name='nhorder', type=11, id=None)\n            oprot.write_string(self.nhorder)\n            oprot.write_field_end()\n\n        if self.notes is not None:\n            oprot.write_field_begin(name='notes', type=11, id=None)\n            oprot.write_string(self.notes)\n            oprot.write_field_end()\n\n        if self.ns is not None:\n            oprot.write_field_begin(name='ns', type=11, id=None)\n            oprot.write_string(self.ns)\n            oprot.write_field_end()\n\n        if self.objectid is not None:\n            oprot.write_field_begin(name='objectid', type=11, id=None)\n            oprot.write_string(self.objectid)\n            oprot.write_field_end()\n\n        if self.objname is not None:\n            oprot.write_field_begin(name='objname', type=11, id=None)\n            oprot.write_string(self.objname)\n            oprot.write_field_end()\n\n        if self.objname2 is not None:\n            oprot.write_field_begin(name='objname2', type=11, id=None)\n            oprot.write_string(self.objname2)\n            oprot.write_field_end()\n\n        if self.objname3 is not None:\n            oprot.write_field_begin(name='objname3', type=11, id=None)\n            oprot.write_string(self.objname3)\n            oprot.write_field_end()\n\n        if self.objnames is not None:\n            oprot.write_field_begin(name='objnames', type=11, id=None)\n            oprot.write_string(self.objnames)\n            oprot.write_field_end()\n\n        if self.occurrence is not None:\n            oprot.write_field_begin(name='occurrence', type=11, id=None)\n            oprot.write_string(self.occurrence)\n            oprot.write_field_end()\n\n        if self.oldno is not None:\n            oprot.write_field_begin(name='oldno', type=11, id=None)\n            oprot.write_string(self.oldno)\n            oprot.write_field_end()\n\n        if self.origin is not None:\n            oprot.write_field_begin(name='origin', type=11, id=None)\n            oprot.write_string(self.origin)\n            oprot.write_field_end()\n\n        if self.othername is not None:\n            oprot.write_field_begin(name='othername', type=11, id=None)\n            oprot.write_string(self.othername)\n            oprot.write_field_end()\n\n        if self.otherno is not None:\n            oprot.write_field_begin(name='otherno', type=11, id=None)\n            oprot.write_string(self.otherno)\n            oprot.write_field_end()\n\n        if self.outdate is not None:\n            oprot.write_field_begin(name='outdate', type=10, id=None)\n            oprot.write_date(self.outdate)\n            oprot.write_field_end()\n\n        if self.owned is not None:\n            oprot.write_field_begin(name='owned', type=11, id=None)\n            oprot.write_string(self.owned)\n            oprot.write_field_end()\n\n        if self.parent is not None:\n            oprot.write_field_begin(name='parent', type=11, id=None)\n            oprot.write_string(self.parent)\n            oprot.write_field_end()\n\n        if self.people is not None:\n            oprot.write_field_begin(name='people', type=11, id=None)\n            oprot.write_string(self.people)\n            oprot.write_field_end()\n\n        if self.period is not None:\n            oprot.write_field_begin(name='period', type=11, id=None)\n            oprot.write_string(self.period)\n            oprot.write_field_end()\n\n        if self.phylum is not None:\n            oprot.write_field_begin(name='phylum', type=11, id=None)\n            oprot.write_string(self.phylum)\n            oprot.write_field_end()\n\n        if self.policyno is not None:\n            oprot.write_field_begin(name='policyno', type=11, id=None)\n            oprot.write_string(self.policyno)\n            oprot.write_field_end()\n\n        if self.ppid is not None:\n            oprot.write_field_begin(name='ppid', type=11, id=None)\n            oprot.write_string(self.ppid)\n            oprot.write_field_end()\n\n        if self.preparator is not None:\n            oprot.write_field_begin(name='preparator', type=11, id=None)\n            oprot.write_string(self.preparator)\n            oprot.write_field_end()\n\n        if self.prepdate is not None:\n            oprot.write_field_begin(name='prepdate', type=10, id=None)\n            oprot.write_date(self.prepdate)\n            oprot.write_field_end()\n\n        if self.preserve is not None:\n            oprot.write_field_begin(name='preserve', type=11, id=None)\n            oprot.write_string(self.preserve)\n            oprot.write_field_end()\n\n        if self.pressure is not None:\n            oprot.write_field_begin(name='pressure', type=11, id=None)\n            oprot.write_string(self.pressure)\n            oprot.write_field_end()\n\n        if self.provenance is not None:\n            oprot.write_field_begin(name='provenance', type=11, id=None)\n            oprot.write_string(self.provenance)\n            oprot.write_field_end()\n\n        if self.pubnotes is not None:\n            oprot.write_field_begin(name='pubnotes', type=11, id=None)\n            oprot.write_string(self.pubnotes)\n            oprot.write_field_end()\n\n        if self.qrurl is not None:\n            oprot.write_field_begin(name='qrurl', type=11, id=None)\n            oprot.write_string(self.qrurl)\n            oprot.write_field_end()\n\n        if self.recas is not None:\n            oprot.write_field_begin(name='recas', type=11, id=None)\n            oprot.write_string(self.recas)\n            oprot.write_field_end()\n\n        if self.recdate is not None:\n            oprot.write_field_begin(name='recdate', type=11, id=None)\n            oprot.write_string(self.recdate)\n            oprot.write_field_end()\n\n        if self.recfrom is not None:\n            oprot.write_field_begin(name='recfrom', type=11, id=None)\n            oprot.write_string(self.recfrom)\n            oprot.write_field_end()\n\n        if self.relation is not None:\n            oprot.write_field_begin(name='relation', type=11, id=None)\n            oprot.write_string(self.relation)\n            oprot.write_field_end()\n\n        if self.relnotes is not None:\n            oprot.write_field_begin(name='relnotes', type=11, id=None)\n            oprot.write_string(self.relnotes)\n            oprot.write_field_end()\n\n        if self.renewuntil is not None:\n            oprot.write_field_begin(name='renewuntil', type=10, id=None)\n            oprot.write_date(self.renewuntil)\n            oprot.write_field_end()\n\n        if self.repatby is not None:\n            oprot.write_field_begin(name='repatby', type=11, id=None)\n            oprot.write_string(self.repatby)\n            oprot.write_field_end()\n\n        if self.repatclaim is not None:\n            oprot.write_field_begin(name='repatclaim', type=11, id=None)\n            oprot.write_string(self.repatclaim)\n            oprot.write_field_end()\n\n        if self.repatdate is not None:\n            oprot.write_field_begin(name='repatdate', type=10, id=None)\n            oprot.write_date(self.repatdate)\n            oprot.write_field_end()\n\n        if self.repatdisp is not None:\n            oprot.write_field_begin(name='repatdisp', type=11, id=None)\n            oprot.write_string(self.repatdisp)\n            oprot.write_field_end()\n\n        if self.repathand is not None:\n            oprot.write_field_begin(name='repathand', type=11, id=None)\n            oprot.write_string(self.repathand)\n            oprot.write_field_end()\n\n        if self.repatnotes is not None:\n            oprot.write_field_begin(name='repatnotes', type=11, id=None)\n            oprot.write_string(self.repatnotes)\n            oprot.write_field_end()\n\n        if self.repatnotic is not None:\n            oprot.write_field_begin(name='repatnotic', type=10, id=None)\n            oprot.write_date(self.repatnotic)\n            oprot.write_field_end()\n\n        if self.repattype is not None:\n            oprot.write_field_begin(name='repattype', type=11, id=None)\n            oprot.write_string(self.repattype)\n            oprot.write_field_end()\n\n        if self.rockclass is not None:\n            oprot.write_field_begin(name='rockclass', type=11, id=None)\n            oprot.write_string(self.rockclass)\n            oprot.write_field_end()\n\n        if self.rockcolor is not None:\n            oprot.write_field_begin(name='rockcolor', type=11, id=None)\n            oprot.write_string(self.rockcolor)\n            oprot.write_field_end()\n\n        if self.rockorigin is not None:\n            oprot.write_field_begin(name='rockorigin', type=11, id=None)\n            oprot.write_string(self.rockorigin)\n            oprot.write_field_end()\n\n        if self.rocktype is not None:\n            oprot.write_field_begin(name='rocktype', type=11, id=None)\n            oprot.write_string(self.rocktype)\n            oprot.write_field_end()\n\n        if self.role is not None:\n            oprot.write_field_begin(name='role', type=11, id=None)\n            oprot.write_string(self.role)\n            oprot.write_field_end()\n\n        if self.role2 is not None:\n            oprot.write_field_begin(name='role2', type=11, id=None)\n            oprot.write_string(self.role2)\n            oprot.write_field_end()\n\n        if self.role3 is not None:\n            oprot.write_field_begin(name='role3', type=11, id=None)\n            oprot.write_string(self.role3)\n            oprot.write_field_end()\n\n        if self.school is not None:\n            oprot.write_field_begin(name='school', type=11, id=None)\n            oprot.write_string(self.school)\n            oprot.write_field_end()\n\n        if self.sex is not None:\n            oprot.write_field_begin(name='sex', type=11, id=None)\n            oprot.write_string(self.sex)\n            oprot.write_field_end()\n\n        if self.sgflag is not None:\n            oprot.write_field_begin(name='sgflag', type=11, id=None)\n            oprot.write_string(self.sgflag)\n            oprot.write_field_end()\n\n        if self.signedname is not None:\n            oprot.write_field_begin(name='signedname', type=11, id=None)\n            oprot.write_string(self.signedname)\n            oprot.write_field_end()\n\n        if self.signloc is not None:\n            oprot.write_field_begin(name='signloc', type=11, id=None)\n            oprot.write_string(self.signloc)\n            oprot.write_field_end()\n\n        if self.site is not None:\n            oprot.write_field_begin(name='site', type=11, id=None)\n            oprot.write_string(self.site)\n            oprot.write_field_end()\n\n        if self.siteno is not None:\n            oprot.write_field_begin(name='siteno', type=11, id=None)\n            oprot.write_string(self.siteno)\n            oprot.write_field_end()\n\n        if self.specgrav is not None:\n            oprot.write_field_begin(name='specgrav', type=11, id=None)\n            oprot.write_string(self.specgrav)\n            oprot.write_field_end()\n\n        if self.species is not None:\n            oprot.write_field_begin(name='species', type=11, id=None)\n            oprot.write_string(self.species)\n            oprot.write_field_end()\n\n        if self.sprocess is not None:\n            oprot.write_field_begin(name='sprocess', type=11, id=None)\n            oprot.write_string(self.sprocess)\n            oprot.write_field_end()\n\n        if self.stage is not None:\n            oprot.write_field_begin(name='stage', type=11, id=None)\n            oprot.write_string(self.stage)\n            oprot.write_field_end()\n\n        if self.status is not None:\n            oprot.write_field_begin(name='status', type=11, id=None)\n            oprot.write_string(self.status)\n            oprot.write_field_end()\n\n        if self.statusby is not None:\n            oprot.write_field_begin(name='statusby', type=11, id=None)\n            oprot.write_string(self.statusby)\n            oprot.write_field_end()\n\n        if self.statusdate is not None:\n            oprot.write_field_begin(name='statusdate', type=10, id=None)\n            oprot.write_date(self.statusdate)\n            oprot.write_field_end()\n\n        if self.sterms is not None:\n            oprot.write_field_begin(name='sterms', type=11, id=None)\n            oprot.write_string(self.sterms)\n            oprot.write_field_end()\n\n        if self.stratum is not None:\n            oprot.write_field_begin(name='stratum', type=11, id=None)\n            oprot.write_string(self.stratum)\n            oprot.write_field_end()\n\n        if self.streak is not None:\n            oprot.write_field_begin(name='streak', type=11, id=None)\n            oprot.write_string(self.streak)\n            oprot.write_field_end()\n\n        if self.subfamily is not None:\n            oprot.write_field_begin(name='subfamily', type=11, id=None)\n            oprot.write_string(self.subfamily)\n            oprot.write_field_end()\n\n        if self.subjects is not None:\n            oprot.write_field_begin(name='subjects', type=11, id=None)\n            oprot.write_string(self.subjects)\n            oprot.write_field_end()\n\n        if self.subspecies is not None:\n            oprot.write_field_begin(name='subspecies', type=11, id=None)\n            oprot.write_string(self.subspecies)\n            oprot.write_field_end()\n\n        if self.technique is not None:\n            oprot.write_field_begin(name='technique', type=11, id=None)\n            oprot.write_string(self.technique)\n            oprot.write_field_end()\n\n        if self.tempauthor is not None:\n            oprot.write_field_begin(name='tempauthor', type=11, id=None)\n            oprot.write_string(self.tempauthor)\n            oprot.write_field_end()\n\n        if self.tempby is not None:\n            oprot.write_field_begin(name='tempby', type=11, id=None)\n            oprot.write_string(self.tempby)\n            oprot.write_field_end()\n\n        if self.tempdate is not None:\n            oprot.write_field_begin(name='tempdate', type=10, id=None)\n            oprot.write_date(self.tempdate)\n            oprot.write_field_end()\n\n        if self.temperatur is not None:\n            oprot.write_field_begin(name='temperatur', type=11, id=None)\n            oprot.write_string(self.temperatur)\n            oprot.write_field_end()\n\n        if self.temploc is not None:\n            oprot.write_field_begin(name='temploc', type=11, id=None)\n            oprot.write_string(self.temploc)\n            oprot.write_field_end()\n\n        if self.tempnotes is not None:\n            oprot.write_field_begin(name='tempnotes', type=11, id=None)\n            oprot.write_string(self.tempnotes)\n            oprot.write_field_end()\n\n        if self.tempreason is not None:\n            oprot.write_field_begin(name='tempreason', type=11, id=None)\n            oprot.write_string(self.tempreason)\n            oprot.write_field_end()\n\n        if self.tempuntil is not None:\n            oprot.write_field_begin(name='tempuntil', type=11, id=None)\n            oprot.write_string(self.tempuntil)\n            oprot.write_field_end()\n\n        if self.texture is not None:\n            oprot.write_field_begin(name='texture', type=11, id=None)\n            oprot.write_string(self.texture)\n            oprot.write_field_end()\n\n        if self.title is not None:\n            oprot.write_field_begin(name='title', type=11, id=None)\n            oprot.write_string(self.title)\n            oprot.write_field_end()\n\n        if self.tlocfield1 is not None:\n            oprot.write_field_begin(name='tlocfield1', type=11, id=None)\n            oprot.write_string(self.tlocfield1)\n            oprot.write_field_end()\n\n        if self.tlocfield2 is not None:\n            oprot.write_field_begin(name='tlocfield2', type=11, id=None)\n            oprot.write_string(self.tlocfield2)\n            oprot.write_field_end()\n\n        if self.tlocfield3 is not None:\n            oprot.write_field_begin(name='tlocfield3', type=11, id=None)\n            oprot.write_string(self.tlocfield3)\n            oprot.write_field_end()\n\n        if self.tlocfield4 is not None:\n            oprot.write_field_begin(name='tlocfield4', type=11, id=None)\n            oprot.write_string(self.tlocfield4)\n            oprot.write_field_end()\n\n        if self.tlocfield5 is not None:\n            oprot.write_field_begin(name='tlocfield5', type=11, id=None)\n            oprot.write_string(self.tlocfield5)\n            oprot.write_field_end()\n\n        if self.tlocfield6 is not None:\n            oprot.write_field_begin(name='tlocfield6', type=11, id=None)\n            oprot.write_string(self.tlocfield6)\n            oprot.write_field_end()\n\n        if self.udf1 is not None:\n            oprot.write_field_begin(name='udf1', type=11, id=None)\n            oprot.write_string(self.udf1)\n            oprot.write_field_end()\n\n        if self.udf10 is not None:\n            oprot.write_field_begin(name='udf10', type=11, id=None)\n            oprot.write_string(self.udf10)\n            oprot.write_field_end()\n\n        if self.udf11 is not None:\n            oprot.write_field_begin(name='udf11', type=11, id=None)\n            oprot.write_string(self.udf11)\n            oprot.write_field_end()\n\n        if self.udf12 is not None:\n            oprot.write_field_begin(name='udf12', type=11, id=None)\n            oprot.write_string(self.udf12)\n            oprot.write_field_end()\n\n        if self.udf13 is not None:\n            oprot.write_field_begin(name='udf13', type=8, id=None)\n            oprot.write_i32(self.udf13)\n            oprot.write_field_end()\n\n        if self.udf14 is not None:\n            oprot.write_field_begin(name='udf14', type=11, id=None)\n            oprot.write_decimal(self.udf14)\n            oprot.write_field_end()\n\n        if self.udf15 is not None:\n            oprot.write_field_begin(name='udf15', type=11, id=None)\n            oprot.write_decimal(self.udf15)\n            oprot.write_field_end()\n\n        if self.udf16 is not None:\n            oprot.write_field_begin(name='udf16', type=11, id=None)\n            oprot.write_decimal(self.udf16)\n            oprot.write_field_end()\n\n        if self.udf17 is not None:\n            oprot.write_field_begin(name='udf17', type=11, id=None)\n            oprot.write_decimal(self.udf17)\n            oprot.write_field_end()\n\n        if self.udf18 is not None:\n            oprot.write_field_begin(name='udf18', type=10, id=None)\n            oprot.write_date(self.udf18)\n            oprot.write_field_end()\n\n        if self.udf19 is not None:\n            oprot.write_field_begin(name='udf19', type=10, id=None)\n            oprot.write_date(self.udf19)\n            oprot.write_field_end()\n\n        if self.udf2 is not None:\n            oprot.write_field_begin(name='udf2', type=11, id=None)\n            oprot.write_string(self.udf2)\n            oprot.write_field_end()\n\n        if self.udf20 is not None:\n            oprot.write_field_begin(name='udf20', type=10, id=None)\n            oprot.write_date(self.udf20)\n            oprot.write_field_end()\n\n        if self.udf21 is not None:\n            oprot.write_field_begin(name='udf21', type=11, id=None)\n            oprot.write_string(self.udf21)\n            oprot.write_field_end()\n\n        if self.udf22 is not None:\n            oprot.write_field_begin(name='udf22', type=11, id=None)\n            oprot.write_string(self.udf22)\n            oprot.write_field_end()\n\n        if self.udf3 is not None:\n            oprot.write_field_begin(name='udf3', type=11, id=None)\n            oprot.write_string(self.udf3)\n            oprot.write_field_end()\n\n        if self.udf4 is not None:\n            oprot.write_field_begin(name='udf4', type=11, id=None)\n            oprot.write_string(self.udf4)\n            oprot.write_field_end()\n\n        if self.udf5 is not None:\n            oprot.write_field_begin(name='udf5', type=11, id=None)\n            oprot.write_string(self.udf5)\n            oprot.write_field_end()\n\n        if self.udf6 is not None:\n            oprot.write_field_begin(name='udf6', type=11, id=None)\n            oprot.write_string(self.udf6)\n            oprot.write_field_end()\n\n        if self.udf7 is not None:\n            oprot.write_field_begin(name='udf7', type=11, id=None)\n            oprot.write_string(self.udf7)\n            oprot.write_field_end()\n\n        if self.udf8 is not None:\n            oprot.write_field_begin(name='udf8', type=11, id=None)\n            oprot.write_string(self.udf8)\n            oprot.write_field_end()\n\n        if self.udf9 is not None:\n            oprot.write_field_begin(name='udf9', type=11, id=None)\n            oprot.write_string(self.udf9)\n            oprot.write_field_end()\n\n        if self.unit is not None:\n            oprot.write_field_begin(name='unit', type=11, id=None)\n            oprot.write_string(self.unit)\n            oprot.write_field_end()\n\n        if self.updated is not None:\n            oprot.write_field_begin(name='updated', type=10, id=None)\n            oprot.write_date_time(self.updated)\n            oprot.write_field_end()\n\n        if self.updatedby is not None:\n            oprot.write_field_begin(name='updatedby', type=11, id=None)\n            oprot.write_string(self.updatedby)\n            oprot.write_field_end()\n\n        if self.used is not None:\n            oprot.write_field_begin(name='used', type=11, id=None)\n            oprot.write_string(self.used)\n            oprot.write_field_end()\n\n        if self.valuedate is not None:\n            oprot.write_field_begin(name='valuedate', type=10, id=None)\n            oprot.write_date(self.valuedate)\n            oprot.write_field_end()\n\n        if self.varieties is not None:\n            oprot.write_field_begin(name='varieties', type=11, id=None)\n            oprot.write_string(self.varieties)\n            oprot.write_field_end()\n\n        if self.vexhtml is not None:\n            oprot.write_field_begin(name='vexhtml', type=11, id=None)\n            oprot.write_string(self.vexhtml)\n            oprot.write_field_end()\n\n        if self.vexlabel1 is not None:\n            oprot.write_field_begin(name='vexlabel1', type=11, id=None)\n            oprot.write_string(self.vexlabel1)\n            oprot.write_field_end()\n\n        if self.vexlabel2 is not None:\n            oprot.write_field_begin(name='vexlabel2', type=11, id=None)\n            oprot.write_string(self.vexlabel2)\n            oprot.write_field_end()\n\n        if self.vexlabel3 is not None:\n            oprot.write_field_begin(name='vexlabel3', type=11, id=None)\n            oprot.write_string(self.vexlabel3)\n            oprot.write_field_end()\n\n        if self.vexlabel4 is not None:\n            oprot.write_field_begin(name='vexlabel4', type=11, id=None)\n            oprot.write_string(self.vexlabel4)\n            oprot.write_field_end()\n\n        if self.webinclude is not None:\n            oprot.write_field_begin(name='webinclude', type=2, id=None)\n            oprot.write_bool(self.webinclude)\n            oprot.write_field_end()\n\n        if self.weight is not None:\n            oprot.write_field_begin(name='weight', type=11, id=None)\n            oprot.write_decimal(self.weight)\n            oprot.write_field_end()\n\n        if self.weightin is not None:\n            oprot.write_field_begin(name='weightin', type=11, id=None)\n            oprot.write_decimal(self.weightin)\n            oprot.write_field_end()\n\n        if self.weightlb is not None:\n            oprot.write_field_begin(name='weightlb', type=11, id=None)\n            oprot.write_decimal(self.weightlb)\n            oprot.write_field_end()\n\n        if self.width is not None:\n            oprot.write_field_begin(name='width', type=11, id=None)\n            oprot.write_decimal(self.width)\n            oprot.write_field_end()\n\n        if self.widthft is not None:\n            oprot.write_field_begin(name='widthft', type=11, id=None)\n            oprot.write_decimal(self.widthft)\n            oprot.write_field_end()\n\n        if self.widthin is not None:\n            oprot.write_field_begin(name='widthin', type=11, id=None)\n            oprot.write_decimal(self.widthin)\n            oprot.write_field_end()\n\n        if self.xcord is not None:\n            oprot.write_field_begin(name='xcord', type=11, id=None)\n            oprot.write_decimal(self.xcord)\n            oprot.write_field_end()\n\n        if self.ycord is not None:\n            oprot.write_field_begin(name='ycord', type=11, id=None)\n            oprot.write_decimal(self.ycord)\n            oprot.write_field_end()\n\n        if self.zcord is not None:\n            oprot.write_field_begin(name='zcord', type=11, id=None)\n            oprot.write_decimal(self.zcord)\n            oprot.write_field_end()\n\n        if self.zsorter is not None:\n            oprot.write_field_begin(name='zsorter', type=11, id=None)\n            oprot.write_string(self.zsorter)\n            oprot.write_field_end()\n\n        if self.zsorterx is not None:\n            oprot.write_field_begin(name='zsorterx', type=11, id=None)\n            oprot.write_string(self.zsorterx)\n            oprot.write_field_end()\n\n        oprot.write_field_stop()\n\n        oprot.write_struct_end()\n\n        return self", "response": "Writes the object to the given protocol and returns the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads data from file matched with given glob pattern.", "response": "def load(pathname, using=None, unite=False, basecolumn=0,\n         relative=False, baseline=None,\n         parser=None, loader=None,\n         with_filename=False, recursive=False, natsort=True, **kwargs):\n    \"\"\"\n    Load data from file matched with given glob pattern.\n\n    Return value will be a list of data unless :attr:`unite` is `True`.\n    If :attr:`unite` is `True` then all data will be united into a single data.\n\n    Parameters\n    ----------\n    pathname : string or list\n        A glob pattern or a list of glob pattern which will be used to load\n        data.\n    using : integer list or slice instance, optional\n        A list of index or slice instance which will be used to slice data\n        columns.\n    unite : boolean, optional:\n        If it is `True` then dataset will be united into a single numpy\n        array. See usage for more detail.\n    basecolumn : integer, optional\n        An index of base column. all data will be trimmed based on the order\n        of this column when the number of samples are different among the\n        dataset.\n        It only affect when :attr:`unite` is specified as `True`.\n    relative : boolean, optional\n        Make the dataset relative to the first data by using\n        :func:`maidenhair.filters.relative.relative` function.\n    baseline : function, None, optional\n        A function which will take data columns and return regulated data\n        columns.\n        It is useful to regulate baseline of each data in dataset.\n    parser : instance, string, None, optional\n        An instance or registered name of parser class.\n        If it is not specified, default parser specified with\n        :func:`maidenhair.functions.set_default_parser` will be used instead.\n    loader : instance, string, None, optional\n        An instance or registered name of loader class.\n        If it is not specified, default loader specified with\n        :func:`maidenhair.functions.set_default_loader` will be used instead.\n    with_filename : boolean, optional\n        If it is `True`, returning dataset will contain filename in the\n        first column.\n        It is cannot be used with :attr:`unite = True`\n    recursive : boolean, optional\n        Recursively find pattern in the directory\n    natsort : boolean\n        Naturally sort found files.\n\n    Returns\n    -------\n    list\n        A list of numpy array\n\n    Examples\n    --------\n    Assume that there are five independent experimental data for three types\n    of samples, namely there are fifteen data.\n    Each data file would have two direction (X and Y) and 100 data points.\n    Its filenames would be formatted as\n    `<type number>.<experimental number>.txt`\n    and save in `tests/fixtures` directory.\n\n    Then the loading code will be\n\n    >>> import maidenhair\n    >>> dataset = []\n    >>> dataset += maidenhair.load('tests/fixtures/1.*.txt',\n    ...                             unite=True, using=(0, 1))\n    >>> dataset += maidenhair.load('tests/fixtures/2.*.txt',\n    ...                             unite=True, using=(0, 1))\n    >>> dataset += maidenhair.load('tests/fixtures/3.*.txt',\n    ...                             unite=True, using=(0, 1))\n    >>> len(dataset)            # number of samples\n    3\n    >>> len(dataset[0])         # number of axis (X and Y)\n    2\n    >>> len(dataset[0][0])      # number of data points\n    100\n    >>> len(dataset[0][0][0])   # number of columns\n    5\n\n    Without using `unite=True`, the dataset will be\n\n    >>> import numpy as np\n    >>> import maidenhair\n    >>> dataset = []\n    >>> dataset += maidenhair.load('tests/fixtures/1.*.txt', using=(0, 1))\n    >>> dataset += maidenhair.load('tests/fixtures/2.*.txt', using=(0, 1))\n    >>> dataset += maidenhair.load('tests/fixtures/3.*.txt', using=(0, 1))\n    >>> len(dataset)            # number of samples\n    15\n    >>> len(dataset[0])         # number of axis (X and Y)\n    2\n    >>> len(dataset[0][0])      # number of data points\n    100\n    >>> isinstance(dataset[0][0][0], np.float64)\n    True\n\n    \"\"\"\n    parser = parser or get_default_parser()\n    loader = loader or get_default_loader()\n    # make sure the pathname is a list\n    if not isinstance(pathname, (list, tuple)):\n        pathname = [pathname]\n    dataset = []\n    for _pathname in pathname:\n        dataset += loader.glob(_pathname,\n                using=using, parser=parser,\n                unite=unite, basecolumn=basecolumn,\n                with_filename=with_filename,\n                recursive=recursive,\n                natsort=natsort,\n                **kwargs)\n    if relative:\n        from maidenhair.filters import relative\n        dataset = relative(dataset)\n    if baseline is not None:\n        for i, data in enumerate(dataset):\n            dataset[i] = baseline(data)\n    return dataset"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_default_parser(parser):\n    if isinstance(parser, basestring):\n        parser = registry.find(parser)()\n    if not isinstance(parser, BaseParser):\n        parser = parser()\n    global _parser\n    _parser = parser", "response": "Set default parser instance"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting default loader instance", "response": "def set_default_loader(loader):\n    \"\"\"\n    Set defaulr loader instance\n\n    Parameters\n    ----------\n    loader : instance or string\n        An instance or registered name of loader class.\n        The specified loader instance will be used when user did not specified\n        :attr:`loader` in :func:`maidenhair.functions.load` function.\n\n    See also\n    --------\n    :func:`maidenhair.utils.plugins.Registry.register` : Register new class\n\n    \"\"\"\n    if isinstance(loader, basestring):\n        loader = registry.find(loader)()\n    if not isinstance(loader, BaseLoader):\n        loader = loader()\n    global _loader\n    _loader = loader"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching a set of metadata to find all relations rel", "response": "def _values(metadata, rel):\n    \"\"\"Searches a set <metadata> to find all relations <rel>\n    Returns a list of the values of those relations\n    (A list, because a rel can occur more than once)\"\"\"\n    result = []\n    for r in metadata:\n        if(r[REL] == rel):\n            result.append(r[VAL])\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake a string and converts it into an internal hypercat object with some checking", "response": "def loads(inputStr):\n    \"\"\"Takes a string and converts it into an internal hypercat object, with some checking\"\"\"\n    inCat = json.loads(inputStr)\n    assert CATALOGUE_TYPE in _values(inCat[CATALOGUE_METADATA], ISCONTENTTYPE_RELATION)\n    # Manually copy mandatory fields, to check that they are they, and exclude other garbage\n    desc = _values(inCat[CATALOGUE_METADATA], DESCRIPTION_RELATION)[0]  # TODO: We are ASSUMING just one description, which may not be true\n    outCat = Hypercat(desc)\n    for i in inCat[ITEMS]:\n        href = i[HREF]\n        contentType = _values(i[ITEM_METADATA], ISCONTENTTYPE_RELATION) [0]\n        desc = _values(i[ITEM_METADATA], DESCRIPTION_RELATION) [0]\n        if contentType == CATALOGUE_TYPE:\n            r = Hypercat(desc)\n        else:\n            r = Resource(desc, contentType)\n        outCat.addItem(r, href)\n\n    return outCat"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rels(self):\n        r = []\n        for i in self.metadata:\n            r = r + i[REL]\n        return []", "response": "Returns a LIST of all the metadata relations"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn hypercat formatted prettily", "response": "def prettyprint(self):\n        \"\"\"Return hypercat formatted prettily\"\"\"\n        return json.dumps(self.asJSON(), sort_keys=True, indent=4, separators=(',', ': '))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef addItem(self, child, href):\n        assert isinstance(child, Base), \"child must be a hypercat Catalogue or Resource\"\n        child.setHref(href)\n        for item in self.items:\n            assert item.href != href, \"All items in a catalogue must have unique hrefs : \"+href\n        self.items += [child]           # Add new\n        return", "response": "Add a new item as a child of this catalogue."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing an existing child item by matching the href. Guarantees not to change the order of items.", "response": "def replaceItem(self, child, href):\n        \"\"\"Replace an existing child (by matching the href). Guarantees not to change the order of items[]\"\"\"\n        assert isinstance(child, Base), \"child item must be a hypercat Catalogue or Resource\"\n        for i in range(len(self.items)):\n            if(self.items[i].href == href):\n                self.items[i] = child   # Replace existing\n                return\n        assert False, \"No such child item to replace as \"+href"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef findByPath(self, rel, path):\n        if((path==\"\") or (path==\"/\")):\n            return(self)\n        (front,dummy,rest) = path.lstrip(\"/\").partition(\"/\")\n        for child in self.items:\n            if front in child.values(rel):\n                return child.findByPath(rel, rest)\n        return None", "response": "Traverses children building a path based on relation <rel > until given path is found."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef recurse(self, fn, *args):\n        fn(self, *args)\n        for i in self.items:\n            if isinstance(i, Hypercat):\n                self.recurse(i, *args)", "response": "Calls fn on a hypercat and all its child hypercats ( not resources"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tailf(\n    filepath,\n    lastn=0,\n    timeout=60,\n    stopon=None,\n    encoding=\"utf8\",\n    delay=0.1\n):\n    \"\"\"provide a `tail -f` like function\n\n    :param filepath: file to tail -f, absolute path or relative path\n    :param lastn: lastn line will also be yield\n    :param timeout: (optional)\n        stop tail -f when time's up [timeout <= 10min, default = 1min]\n    :param stopon: (optional) stops when the stopon(output) returns True\n    :param encoding: (optional) default encoding utf8\n    :param delay: (optional) sleep if no data is available, default is 0.1s\n\n    Usage::\n        >>> for line in tailf('/tmp/foo'):\n        ...     print(line)\n        ...\n        \"bar\"\n        \"barz\"\n    \"\"\"\n    if not os.path.isfile(filepath):\n        raise ShCmdError(\"[{0}] not exists\".format(filepath))\n\n    if consts.TIMEOUT_MAX > timeout:\n        timeout = consts.TIMEOUT_DEFAULT\n\n    delay = delay if consts.DELAY_MAX > delay > 0 else consts.DELAY_DEFAULT\n    if isinstance(stopon, types.FunctionType) is False:\n        stopon = always_false\n\n    logger.info(\"tail -f {0} begin\".format(filepath))\n\n    with open(filepath, \"rt\", encoding=encoding) as file_obj:\n        lastn_filter = deque(maxlen=lastn)\n        logger.debug(\"tail last {0} lines\".format(lastn))\n\n        for line in file_obj:\n            lastn_filter.append(line.rstrip())\n        for line in lastn_filter:\n            yield line\n\n        start = time.time()\n        while timeout < 0 or (time.time() - start) < timeout:\n            line = file_obj.readline()\n            where = file_obj.tell()\n            if line:\n                logger.debug(\"found line: [{0}]\".format(line))\n                yield line\n                if stopon(line):\n                    break\n            else:\n                file_obj.seek(0, os.SEEK_END)\n                if file_obj.tell() < where:\n                    logger.info(\"file [{0}] rewinded!\".format(filepath))\n                    file_obj.seek(0)\n                else:\n                    logger.debug(\"no data, waiting for [{0}]s\".format(delay))\n                    time.sleep(delay)\n\n    logger.info(\"tail -f {0} end\".format(filepath))", "response": "tail - f generator for a single file"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes a file and return the result.", "response": "def _execfile(filename, globals, locals=None):\n    \"\"\"\n    Python 3 implementation of execfile.\n    \"\"\"\n    mode = 'rb'\n    # Python 2.6 compile requires LF for newlines, so use deprecated\n    #  Universal newlines support.\n    if sys.version_info < (2, 7):\n        mode += 'U'\n    with open(filename, mode) as stream:\n        script = stream.read()\n    if locals is None:\n        locals = globals\n    code = compile(script, filename, 'exec')\n    exec(code, globals, locals)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a single value to this element for processing", "response": "def send(self, value=None):\n        \"\"\"Send a single value to this element for processing\"\"\"\n        if self.chain_fork:\n            return self._send_fork(value)\n        return self._send_flat(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_interfaces(path: str) -> Interfaces:\n\twith open(path, encoding='utf-8') as f:\n\t\treturn json.load(f)", "response": "Reads an Interfaces JSON file at the given path and returns it as a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a set of strings to be used as Slots with Pabianas default Clock.", "response": "def multiple(layer: int, limit: int) -> Set[str]:\n\t\"\"\"Returns a set of strings to be used as Slots with Pabianas default Clock.\n\n\tArgs:\n\t\tlayer: The layer in the hierarchy this Area is placed in.\n\t\t\tTechnically, the number specifies how many of the Clocks signals are relevant to the Area.\n\t\t\tBetween 1 and limit.\n\t\tlimit: The number of layers of the hierarchy.\n\t\"\"\"\n\treturn {str(x).zfill(2) for x in [2**x for x in range(limit)] if x % 2**(layer - 1) == 0}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef catch_boto_400(self, message, heading=None, document=None, **info):\n        try:\n            yield\n        except ClientError as error:\n            if str(error.response[\"ResponseMetadata\"][\"HTTPStatusCode\"]).startswith(\"4\"):\n                if heading or document:\n                    print(\"=\" * 80)\n                    if heading:\n                        print(heading)\n                    print(document)\n                    print(\"=\" * 80)\n                error_message = error.response[\"Error\"][\"Message\"]\n                raise BadAmazon(message, error_message=error_message, error_code=error.response[\"ResponseMetadata\"][\"HTTPStatusCode\"], **info)\n            else:\n                raise", "response": "Catch a BotoServerError 400 into a BadAmazon"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint out a change", "response": "def print_change(self, symbol, typ, changes=None, document=None, **kwargs):\n        \"\"\"Print out a change\"\"\"\n        values = \", \".join(\"{0}={1}\".format(key, val) for key, val in sorted(kwargs.items()))\n        print(\"{0} {1}({2})\".format(symbol, typ, values))\n        if changes:\n            for change in changes:\n                print(\"\\n\".join(\"\\t{0}\".format(line) for line in change.split('\\n')))\n        elif document:\n            print(\"\\n\".join(\"\\t{0}\".format(line) for line in document.split('\\n')))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef change(self, symbol, typ, **kwargs):\n        self.print_change(symbol, typ, **kwargs)\n        if not self.dry_run:\n            try:\n                yield\n            except:\n                raise\n            else:\n                self.amazon.changes = True", "response": "Print out a change and then do the change if not doing a dry run"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef urlopen(url, timeout=20, redirects=None):\n    scheme, host, path, params, query, frag = urlparse(url)\n\n    if not scheme in ('http', 'https'):\n        return urllib.urlopen(url)\n    if params: path = '%s;%s' % (path, params)\n    if query:  path = '%s?%s' % (path, query)\n    if frag:   path = '%s#%s' % (path, frag)\n\n    if scheme == 'https':\n        # If ssl is not compiled into Python, you will not get an exception\n        # until a conn.endheaders() call.   We need to know sooner, so use\n        # getattr.\n        try:\n            import M2Crypto\n        except ImportError:\n            if not hasattr(socket, 'ssl'):\n                raise RuntimeError, 'no built-in SSL Support'\n\n            conn = TimeoutHTTPS(host, None, timeout)\n        else:\n            ctx = M2Crypto.SSL.Context()\n            ctx.set_session_timeout(timeout)\n            conn = M2Crypto.httpslib.HTTPSConnection(host, ssl_context=ctx)\n            conn.set_debuglevel(1)\n\n    else:\n        conn = TimeoutHTTP(host, None, timeout)\n\n    conn.putrequest('GET', path)\n    conn.putheader('Connection', 'close')\n    conn.endheaders()\n    response = None\n    while 1:\n        response = conn.getresponse()\n        if response.status != 100:\n            break\n        conn._HTTPConnection__state = httplib._CS_REQ_SENT\n        conn._HTTPConnection__response = None\n\n    status = response.status\n\n    # If we get an HTTP redirect, we will follow it automatically.\n    if status >= 300 and status < 400:\n        location = response.msg.getheader('location')\n        if location is not None:\n            response.close()\n            if redirects is not None and redirects.has_key(location):\n                raise RecursionError(\n                    'Circular HTTP redirection detected.'\n                    )\n            if redirects is None:\n                redirects = {}\n            redirects[location] = 1\n            return urlopen(location, timeout, redirects)\n        raise HTTPResponse(response)\n\n    if not (status >= 200 and status < 300):\n        raise HTTPResponse(response)\n\n    body = StringIO(response.read())\n    response.close()\n    return body", "response": "A minimal urlopen replacement hack that supports timeouts for http."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the SOAP version related to an envelope uri.", "response": "def SOAPUriToVersion(self, uri):\n        \"\"\"Return the SOAP version related to an envelope uri.\"\"\"\n        value = self._soap_uri_mapping.get(uri)\n        if value is not None:\n            return value\n        raise ValueError(\n            'Unsupported SOAP envelope uri: %s' % uri\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GetSOAPEnvUri(self, version):\n        attrname = 'NS_SOAP_ENV_%s' % join(split(version, '.'), '_')\n        value = getattr(self, attrname, None)\n        if value is not None:\n            return value\n        raise ValueError(\n            'Unsupported SOAP version: %s' % version\n            )", "response": "Returns the appropriate SOAP envelope uri for a given SOAP version string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef WSDLUriToVersion(self, uri):\n        value = self._wsdl_uri_mapping.get(uri)\n        if value is not None:\n            return value\n        raise ValueError(\n            'Unsupported SOAP envelope uri: %s' % uri\n            )", "response": "Return the WSDL version related to a WSDL namespace uri."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef isElement(self, node, name, nsuri=None):\n        if node.nodeType != node.ELEMENT_NODE:\n            return 0\n        return node.localName == name and \\\n               (nsuri is None or self.nsUriMatch(node.namespaceURI, nsuri))", "response": "Return true if the given node is an element with the given name and optional namespace uri."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the first child of node with a matching name and namespace uri or the default if one is provided.", "response": "def getElement(self, node, name, nsuri=None, default=join):\n        \"\"\"Return the first child of node with a matching name and\n           namespace uri, or the default if one is provided.\"\"\"\n        nsmatch = self.nsUriMatch\n        ELEMENT_NODE = node.ELEMENT_NODE\n        for child in node.childNodes:\n            if child.nodeType == ELEMENT_NODE:\n                if ((child.localName == name or name is None) and\n                    (nsuri is None or nsmatch(child.namespaceURI, nsuri))\n                    ):\n                    return child\n        if default is not join:\n            return default\n        raise KeyError, name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the first child of node matching an id reference.", "response": "def getElementById(self, node, id, default=join):\n        \"\"\"Return the first child of node matching an id reference.\"\"\"\n        attrget = self.getAttr\n        ELEMENT_NODE = node.ELEMENT_NODE\n        for child in node.childNodes:\n            if child.nodeType == ELEMENT_NODE:\n                if attrget(child, 'id') == id:\n                    return child\n        if default is not join:\n            return default\n        raise KeyError, name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an id - > element mapping of those elements within a document that define an id attribute.", "response": "def getMappingById(self, document, depth=None, element=None,\n                       mapping=None, level=1):\n        \"\"\"Create an id -> element mapping of those elements within a\n           document that define an id attribute. The depth of the search\n           may be controlled by using the (1-based) depth argument.\"\"\"\n        if document is not None:\n            element = document.documentElement\n            mapping = {}\n        attr = element._attrs.get('id', None)\n        if attr is not None:\n            mapping[attr.value] = element\n        if depth is None or depth > level:\n            level = level + 1\n            ELEMENT_NODE = element.ELEMENT_NODE\n            for child in element.childNodes:\n                if child.nodeType == ELEMENT_NODE:\n                    self.getMappingById(None, depth, child, mapping, level)\n        return mapping"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getElements(self, node, name, nsuri=None):\n        nsmatch = self.nsUriMatch\n        result = []\n        ELEMENT_NODE = node.ELEMENT_NODE\n        for child in node.childNodes:\n            if child.nodeType == ELEMENT_NODE:\n                if ((child.localName == name or name is None) and (\n                    (nsuri is None) or nsmatch(child.namespaceURI, nsuri))):\n                    result.append(child)\n        return result", "response": "Return a sequence of the child elements of the given node that that\n           match the given name and optional namespace uri."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hasAttr(self, node, name, nsuri=None):\n        if nsuri is None:\n            if node.hasAttribute(name):\n                return True\n            return False\n        return node.hasAttributeNS(nsuri, name)", "response": "Return true if the given node has the given name and nsuri."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the value of the attribute named name with the optional nsuri or the default if one is specified.", "response": "def getAttr(self, node, name, nsuri=None, default=join):\n        \"\"\"Return the value of the attribute named 'name' with the\n           optional nsuri, or the default if one is specified. If\n           nsuri is not specified, an attribute that matches the\n           given name will be returned regardless of namespace.\"\"\"\n        if nsuri is None:\n            result = node._attrs.get(name, None)\n            if result is None:\n                for item in node._attrsNS.keys():\n                    if item[1] == name:\n                        result = node._attrsNS[item]\n                        break\n        else:\n            result = node._attrsNS.get((nsuri, name), None)\n        if result is not None:\n            return result.value\n        if default is not join:\n            return default\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a Collection of all attributes", "response": "def getAttrs(self, node):\n        \"\"\"Return a Collection of all attributes \n        \"\"\"\n        attrs = {}\n        for k,v in node._attrs.items():\n            attrs[k] = v.value\n        return attrs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the text value of an xml element node. Leading and trailing whitespace is stripped from the value unless the preserve_ws flag is passed with a true value.", "response": "def getElementText(self, node, preserve_ws=None):\n        \"\"\"Return the text value of an xml element node. Leading and trailing\n           whitespace is stripped from the value unless the preserve_ws flag\n           is passed with a true value.\"\"\"\n        result = []\n        for child in node.childNodes:\n            nodetype = child.nodeType\n            if nodetype == child.TEXT_NODE or \\\n               nodetype == child.CDATA_SECTION_NODE:\n                result.append(child.nodeValue)\n        value = join(result, '')\n        if preserve_ws is None:\n            value = strip(value)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef findNamespaceURI(self, prefix, node):\n        attrkey = (self.NS_XMLNS, prefix)\n        DOCUMENT_NODE = node.DOCUMENT_NODE\n        ELEMENT_NODE = node.ELEMENT_NODE\n        while 1:\n            if node is None:\n                raise DOMException('Value for prefix %s not found.' % prefix)\n            if node.nodeType != ELEMENT_NODE:\n                node = node.parentNode\n                continue\n            result = node._attrsNS.get(attrkey, None)\n            if result is not None:\n                return result.value\n            if hasattr(node, '__imported__'):\n                raise DOMException('Value for prefix %s not found.' % prefix)\n            node = node.parentNode\n            if node.nodeType == DOCUMENT_NODE:\n                raise DOMException('Value for prefix %s not found.' % prefix)", "response": "Find a namespace uri given a prefix and a context node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef findTargetNS(self, node):\n        attrget = self.getAttr\n        attrkey = (self.NS_XMLNS, 'xmlns')\n        DOCUMENT_NODE = node.DOCUMENT_NODE\n        ELEMENT_NODE = node.ELEMENT_NODE\n        while 1:\n            if node.nodeType != ELEMENT_NODE:\n                node = node.parentNode\n                continue\n            result = attrget(node, 'targetNamespace', default=None)\n            if result is not None:\n                return result\n            node = node.parentNode\n            if node.nodeType == DOCUMENT_NODE:\n                raise DOMException('Cannot determine target namespace.')", "response": "Find the defined target namespace uri for the given node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the namespace URI and name of a type attribue of the given element or None if the element does not have a type attribute.", "response": "def getTypeRef(self, element):\n        \"\"\"Return (namespaceURI, name) for a type attribue of the given\n           element, or None if the element does not have a type attribute.\"\"\"\n        typeattr = self.getAttr(element, 'type', default=None)\n        if typeattr is None:\n            return None\n        parts = typeattr.split(':', 1)\n        if len(parts) == 2:\n            nsuri = self.findNamespaceURI(parts[0], element)\n        else:\n            nsuri = self.findDefaultNS(element)\n        return (nsuri, parts[1])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef importNode(self, document, node, deep=0):\n        nodetype = node.nodeType\n        if nodetype in (node.DOCUMENT_NODE, node.DOCUMENT_TYPE_NODE):\n            raise DOMException('Illegal node type for importNode')\n        if nodetype == node.ENTITY_REFERENCE_NODE:\n            deep = 0\n        clone = node.cloneNode(deep)\n        self._setOwnerDoc(document, clone)\n        clone.__imported__ = 1\n        return clone", "response": "Implements ( well enough for our purposes ) DOM node import."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nsUriMatch(self, value, wanted, strict=0, tt=type(())):\n        if value == wanted or (type(wanted) is tt) and value in wanted:\n            return 1\n        if not strict and value is not None:\n            wanted = type(wanted) is tt and wanted or (wanted,)\n            value = value[-1:] != '/' and value or value[:-1]\n            for item in wanted:\n                if item == value or item[:-1] == value:\n                    return 1\n        return 0", "response": "Return a true value if two namespace uri values match."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a writable DOM document object.", "response": "def createDocument(self, nsuri, qname, doctype=None):\n        \"\"\"Create a new writable DOM document object.\"\"\"\n        impl = xml.dom.minidom.getDOMImplementation()\n        return impl.createDocument(nsuri, qname, doctype)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload an xml file from a URL and return a DOM document.", "response": "def loadFromURL(self, url):\n        \"\"\"Load an xml file from a URL and return a DOM document.\"\"\"\n        if isfile(url) is True:\n            file = open(url, 'r')\n        else:\n            file = urlopen(url)\n\n        try:     \n            result = self.loadDocument(file)\n        except Exception, ex:\n            file.close()\n            raise ParseError(('Failed to load document %s' %url,) + ex.args)\n        else:\n            file.close()\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nevaluate the given expression and returns a list of ElementProxy objects.", "response": "def evaluate(self, expression, processorNss=None):\n        '''expression -- XPath compiled expression\n        '''\n        from Ft.Xml import XPath\n        if not processorNss:\n            context = XPath.Context.Context(self.node, processorNss=self.processorNss)\n        else:\n            context = XPath.Context.Context(self.node, processorNss=processorNss)\n        nodes = expression.evaluate(context)\n        return map(lambda node: ElementProxy(self.sw,node), nodes)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef checkNode(self, namespaceURI=None, localName=None):\n        '''\n            namespaceURI -- namespace of element\n            localName -- local name of element\n        '''\n        namespaceURI = namespaceURI or self.namespaceURI\n        localName = localName or self.name\n        check = False\n        if localName and self.node:\n            check = self._dom.isElement(self.node, localName, namespaceURI)\n        if not check:\n            raise NamespaceError, 'unexpected node type %s, expecting %s' %(self.node, localName)", "response": "Check that the node is an element of the specified namespaceURI and localName."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _getUniquePrefix(self):\n        '''I guess we need to resolve all potential prefixes\n        because when the current node is attached it copies the \n        namespaces into the parent node.\n        '''\n        while 1:\n            self._indx += 1\n            prefix = 'ns%d' %self._indx\n            try:\n                self._dom.findNamespaceURI(prefix, self._getNode())\n            except DOMException, ex:\n                break\n        return prefix", "response": "I guess we need to resolve all potential prefixes\n            because we need to find the unique prefix for the current node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _getPrefix(self, node, nsuri):\n        '''\n        Keyword arguments:\n            node -- DOM Element Node\n            nsuri -- namespace of attribute value\n        '''\n        try:\n            if node and (node.nodeType == node.ELEMENT_NODE) and \\\n                (nsuri == self._dom.findDefaultNS(node)):\n                return None\n        except DOMException, ex:\n            pass\n        if nsuri == XMLNS.XML:\n            return self._xml_prefix\n        if node.nodeType == Node.ELEMENT_NODE:\n            for attr in node.attributes.values():\n                if attr.namespaceURI == XMLNS.BASE \\\n                   and nsuri == attr.value:\n                        return attr.localName\n            else:\n                if node.parentNode:\n                    return self._getPrefix(node.parentNode, nsuri)\n        raise NamespaceError, 'namespaceURI \"%s\" is not defined' %nsuri", "response": "Returns the prefix of the node with the given namespace."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new XML document.", "response": "def createDocument(self, namespaceURI, localName, doctype=None):\n        '''If specified must be a SOAP envelope, else may contruct an empty document.\n        '''\n        prefix = self._soap_env_prefix\n\n        if namespaceURI == self.reserved_ns[prefix]:\n            qualifiedName = '%s:%s' %(prefix,localName)\n        elif namespaceURI is localName is None:\n            self.node = self._dom.createDocument(None,None,None)\n            return\n        else:\n            raise KeyError, 'only support creation of document in %s' %self.reserved_ns[prefix]\n\n        document = self._dom.createDocument(nsuri=namespaceURI, qname=qualifiedName, doctype=doctype)\n        self.node = document.childNodes[0]\n\n        #set up reserved namespace attributes\n        for prefix,nsuri in self.reserved_ns.items():\n            self._setAttributeNS(namespaceURI=self._xmlns_nsuri, \n                qualifiedName='%s:%s' %(self._xmlns_prefix,prefix), \n                value=nsuri)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset xsi : type", "response": "def setAttributeType(self, namespaceURI, localName):\n        '''set xsi:type\n        Keyword arguments:\n            namespaceURI -- namespace of attribute value\n            localName -- name of new attribute value\n\n        '''\n        self.logger.debug('setAttributeType: (%s,%s)', namespaceURI, localName)\n        value = localName\n        if namespaceURI:\n            value = '%s:%s' %(self.getPrefix(namespaceURI),localName)\n\n        xsi_prefix = self.getPrefix(self._xsi_nsuri)\n        self._setAttributeNS(self._xsi_nsuri, '%s:type' %xsi_prefix, value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setAttributeNS(self, namespaceURI, localName, value):\n        '''\n        Keyword arguments:\n            namespaceURI -- namespace of attribute to create, None is for\n                attributes in no namespace.\n            localName -- local name of new attribute\n            value -- value of new attribute\n        ''' \n        prefix = None\n        if namespaceURI:\n            try:\n                prefix = self.getPrefix(namespaceURI)\n            except KeyError, ex:\n                prefix = 'ns2'\n                self.setNamespaceAttribute(prefix, namespaceURI)\n        qualifiedName = localName\n        if prefix:\n            qualifiedName = '%s:%s' %(prefix, localName)\n        self._setAttributeNS(namespaceURI, qualifiedName, value)", "response": "Sets the value of an attribute in the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setNamespaceAttribute(self, prefix, namespaceURI):\n        '''\n        Keyword arguments:\n            prefix -- xmlns prefix\n            namespaceURI -- value of prefix\n        '''\n        self._setAttributeNS(XMLNS.BASE, 'xmlns:%s' %prefix, namespaceURI)", "response": "Sets the namespace attribute of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef createElementNS(self, namespace, qname):\n        '''\n        Keyword arguments:\n            namespace -- namespace of element to create\n            qname -- qualified name of new element\n        '''\n        document = self._getOwnerDocument()\n        node = document.createElementNS(namespace, qname)\n        return ElementProxy(self.sw, node)", "response": "Create a new element in the specified namespace and qualified name."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new element ( namespaceURI localName prefix ) append it to current node then set it to be the current node.", "response": "def createAppendSetElement(self, namespaceURI, localName, prefix=None):\n        '''Create a new element (namespaceURI,name), append it\n           to current node, then set it to be the current node.\n        Keyword arguments:\n            namespaceURI -- namespace of element to create\n            localName -- local name of new element\n            prefix -- if namespaceURI is not defined, declare prefix.  defaults\n                to 'ns1' if left unspecified.\n        '''\n        node = self.createAppendElement(namespaceURI, localName, prefix=None)\n        node=node._getNode()\n        self._setNode(node._getNode())"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new element with namespaceURI localName and prefix and append it to current node and return the newly created node.", "response": "def createAppendElement(self, namespaceURI, localName, prefix=None):\n        '''Create a new element (namespaceURI,name), append it\n           to current node, and return the newly created node.\n        Keyword arguments:\n            namespaceURI -- namespace of element to create\n            localName -- local name of new element\n            prefix -- if namespaceURI is not defined, declare prefix.  defaults\n                to 'ns1' if left unspecified.\n        '''\n        declare = False\n        qualifiedName = localName\n        if namespaceURI:\n            try:\n                prefix = self.getPrefix(namespaceURI)\n            except:\n                declare = True\n                prefix = prefix or self._getUniquePrefix()\n            if prefix: \n                qualifiedName = '%s:%s' %(prefix, localName)\n        node = self.createElementNS(namespaceURI, qualifiedName)\n        if declare:\n            node._setAttributeNS(XMLNS.BASE, 'xmlns:%s' %prefix, namespaceURI)\n        self._appendChild(node=node._getNode())\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getElement(self, namespaceURI, localName):\n        '''\n        Keyword arguments:\n            namespaceURI -- namespace of element\n            localName -- local name of element\n        '''\n        node = self._dom.getElement(self.node, localName, namespaceURI, default=None)\n        if node:\n            return ElementProxy(self.sw, node)\n        return None", "response": "Returns the element with the specified namespaceURI and localName."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getAttributeValue(self, namespaceURI, localName):\n        '''\n        Keyword arguments:\n            namespaceURI -- namespace of attribute\n            localName -- local name of attribute\n        '''\n        if self.hasAttribute(namespaceURI, localName):\n            attr = self.node.getAttributeNodeNS(namespaceURI,localName)\n            return attr.value\n        return None", "response": "Returns the value of the attribute with the specified namespaceURI and localName."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds faces and energy in an image and returns a CropInfo object", "response": "def face_and_energy_detector(image_path, detect_faces=True):\n    \"\"\"\n    Finds faces and energy in an image\n    \"\"\"\n    source = Image.open(image_path)\n    work_width = 800\n    if source.mode != 'RGB' or source.bits != 8:\n        source24 = source.convert('RGB')\n    else:\n        source24 = source.copy()\n\n    grayscaleRMY = source24.convert('L', (0.5, 0.419, 0.081, 0))\n    w = min(grayscaleRMY.size[0], work_width)\n    h = w * grayscaleRMY.size[1] / grayscaleRMY.size[0]\n    b = grayscaleRMY.resize((w, h), Image.BICUBIC)\n    # b.save('step2.jpg')\n    if detect_faces:\n        info = do_face_detection(image_path)\n        if info:\n            return CropInfo(gravity=info)\n    b = b.filter(ImageFilter.GaussianBlur(7))\n    # b.save('step3.jpg')\n    sobelXfilter = ImageFilter.Kernel((3, 3), (1, 0, -1, 2, 0, -2, 1, 0, -1), -.5)\n    sobelYfilter = ImageFilter.Kernel((3, 3), (1, 2, 1, 0, 0, 0, -1, -2, -1), -.5)\n    b = ImageChops.lighter(b.filter(sobelXfilter), b.filter(sobelYfilter))\n    b = b.filter(ImageFilter.FIND_EDGES)\n    # b.save('step4.jpg')\n    ec = energy_center(b)\n    return CropInfo(gravity=ec)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_crop_size(crop_w, crop_h, image_w, image_h):\n    scale1 = float(crop_w) / float(image_w)\n    scale2 = float(crop_h) / float(image_h)\n    scale1_w = crop_w  # int(round(img_w * scale1))\n    scale1_h = int(round(image_h * scale1))\n    scale2_w = int(round(image_w * scale2))\n    scale2_h = crop_h  # int(round(img_h * scale2))\n\n    if scale1_h > crop_h:  # scale1_w == crop_w\n        # crop on vertical\n        return (scale1_w, scale1_h)\n    else:  # scale2_h == crop_h and scale2_w > crop_w\n        #crop on horizontal\n        return (scale2_w, scale2_h)", "response": "Determines the correct scale size for the image based on the crop_w and crop_h parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the start and stop points that are sub_amount distance apart and contain weight.", "response": "def calc_subrange(range_max, sub_amount, weight):\n    \"\"\"\n    return the start and stop points that are sub_amount distance apart and\n    contain weight, without going outside the provided range\n    \"\"\"\n    if weight > range_max or sub_amount > range_max:\n        raise ValueError(\"sub_amount and weight must be less than range_max. range_max %s, sub_amount %s, weight %s\" % (range_max, sub_amount, weight))\n    half_amount = sub_amount / 2\n    bottom = weight - half_amount\n    top = bottom + sub_amount\n    if top <= range_max and bottom >= 0:\n        return (bottom, top)\n    elif weight > range_max / 2:\n        # weight is on the upper half, start at the max and go down\n        return (range_max - sub_amount, range_max)\n    else:\n        # weight is on the lower have, start at 0 and go up\n        return (0, sub_amount)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef smart_crop(crop_w, crop_h, image_path):\n    cropping = face_and_energy_detector(image_path)\n    img = Image.open(image_path)\n    w, h = img.size\n    scaled_size = get_crop_size(crop_w, crop_h, *img.size)\n    gravity_x = int(round(scaled_size[0] * cropping.gravity[0]))\n    gravity_y = int(round(scaled_size[1] * cropping.gravity[1]))\n    if scaled_size[0] == crop_w:\n        # find the top and bottom crops\n        crop_top, crop_bot = calc_subrange(scaled_size[1], crop_h, gravity_y)\n        return scaled_size, Rect(left=0, top=crop_top, right=crop_w, bottom=crop_bot)\n    else:\n        # find the right and left crops\n        crop_left, crop_right = calc_subrange(scaled_size[0], crop_w, gravity_x)\n        return scaled_size, Rect(left=crop_left, top=0, right=crop_right, bottom=crop_h)", "response": "Return the scaled image size and crop rectangle"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting last failed access attempt of Client .", "response": "def get_last_failed_access_attempt(cls, **kwargs):\n        \"\"\"\n        Return Failed access attempt of Client\n        :param ip_adress: String\n        :return:\n        \"\"\"\n        try:\n            lockout = cls.objects.get(\n                **kwargs\n            )\n        except cls.DoesNotExist:\n            lockout = None\n\n        if lockout:\n            time_remaining = lockout.expiration_time\n            if time_remaining and time_remaining <= 0:\n                lockout.is_expired = True\n                lockout.save()\n                return None\n\n        return lockout"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef expiration_time(self):\n        logging_forgotten_time = configuration.behavior.login_forgotten_seconds\n\n        if logging_forgotten_time <= 0:\n            return None\n\n        now = timezone.now()\n        delta = now - self.modified\n        time_remaining = logging_forgotten_time - delta.seconds\n\n        return time_remaining", "response": "Returns the time until this access attempt is forgotten."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validate_extension(self, file_name, extension_map, method_title, argument_title):\r\n\r\n    ''' \r\n        a method to extract (and test) the extension type of a file\r\n\r\n    :param file_name: string with name of file\r\n    :param extension_map: dictionary with regex patterns, extensions and mimetypes\r\n    :param method_title: string with title of feeder method\r\n    :param argument_title: string with title of argument key from feeder method\r\n    :return: dictionary with mimetype and extension details\r\n    '''\r\n\r\n    title = 'validate_extension'\r\n    ext_arg = '%s(extension_map={...})' % title\r\n\r\n# validate inputs\r\n    input_fields = {\r\n        'file_name': file_name,\r\n        'method_title': method_title,\r\n        'argument_title': argument_title\r\n    }\r\n    for key, value in input_fields.items():\r\n        if not isinstance(value, str):\r\n            raise ValueError('%s(%s=\"...\") must be a string' % (title, key))\r\n    if not isinstance(extension_map, dict):\r\n        raise ValueError('%s must be a dictionary.' % ext_arg)\r\n\r\n# import dependencies\r\n    import re\r\n\r\n# construct default response\r\n    file_details = {\r\n        'mimetype': '',\r\n        'extension': ''\r\n    }\r\n\r\n# test file name against regex\r\n    type_list = []\r\n    for key, value in extension_map.items():\r\n        if not isinstance(value, dict):\r\n            raise ValueError('%s %s key must be a dictionary.' % (ext_arg, key))\r\n        elif not 'extension' in value.keys():\r\n            raise ValueError('%s %s dict must have an \"extension\" key.' % (ext_arg, key))\r\n        type_list.append(value['extension'])\r\n        regex_pattern = re.compile(key)\r\n        if regex_pattern.findall(file_name):\r\n            file_details.update(**value)\r\n\r\n# validate extension\r\n    if not file_details['extension']:\r\n        raise ValueError(\r\n            '%s(%s=%s) must be one of %s extension types.' % (method_title, argument_title, file_name, type_list))\r\n\r\n    return file_details", "response": "a method to extract the mimetype and extension of a file\r\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if dict1 equals dict2", "response": "def compare_dicts(dict1, dict2):\n    \"\"\"\n    Checks if dict1 equals dict2\n    \"\"\"\n    for k, v in dict2.items():\n        if v != dict1[k]:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getItalianAccentedVocal(vocal, acc_type=\"g\"):\n    vocals = {'a': {'g': u'\\xe0', 'a': u'\\xe1'},\n              'e': {'g': u'\\xe8', 'a': u'\\xe9'},\n              'i': {'g': u'\\xec', 'a': u'\\xed'},\n              'o': {'g': u'\\xf2', 'a': u'\\xf3'},\n              'u': {'g': u'\\xf9', 'a': u'\\xfa'}}\n    return vocals[vocal][acc_type]", "response": "It returns given vocal with grave or acute accent\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_certificates(self):\n\n        '''\n            a method to retrieve a list of server certificates\n\n        :return: list with certificate name strings\n        '''\n\n        title = '%s.list_certificates' % self.__class__.__name__\n\n    # send request for list of certificates\n        self.printer('Querying AWS for server certificates.')\n        try:\n            response = self.connection.list_server_certificates()\n        except:\n            raise AWSConnectionError(title)\n\n    # construct certificate list from response\n        cert_list = []\n        if 'ServerCertificateMetadataList' in response.keys():\n            for certificate in response['ServerCertificateMetadataList']:\n                cert_list.append(certificate['ServerCertificateName'])\n\n    # report results and return list\n        if cert_list:\n            print_out = 'Found server certificate'\n            if len(cert_list) > 1:\n                print_out += 's'\n            from labpack.parsing.grammar import join_words\n            print_out += ' %s.' % join_words(cert_list)\n            self.printer(print_out)\n        else:\n            self.printer('No server certificates found.')\n\n        self.certificate_list = cert_list\n        \n        return self.certificate_list", "response": "a method to retrieve a list of server certificates with the specified names"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_certificate(self, certificate_name):\n\n        '''\n            a method to retrieve the details about a server certificate\n\n        :param certificate_name: string with name of server certificate\n        :return: dictionary with certificate details\n        '''\n\n        title = '%s.read_certificate' % self.__class__.__name__\n\n    # validate inputs\n        input_fields = {\n            'certificate_name': certificate_name\n        }\n        for key, value in input_fields.items():\n            object_title = '%s(%s=%s)' % (title, key, str(value))\n            self.fields.validate(value, '.%s' % key, object_title)\n\n    # verify existence of server certificate\n        if not certificate_name in self.certificate_list:\n            self.printer_on = False\n            self.list_certificates()\n            self.printer_on = True\n            if not certificate_name in self.certificate_list:\n                raise Exception('\\nServer certificate %s does not exist.' % certificate_name)\n\n    # send request for certificate details\n        try:\n            cert_kwargs = { 'ServerCertificateName': certificate_name }\n            response = self.connection.get_server_certificate(**cert_kwargs)\n        except:\n            raise AWSConnectionError(title)\n\n    # construct certificate details from response\n        from labpack.records.time import labDT\n        from labpack.parsing.conversion import camelcase_to_lowercase\n        cert_dict = response['ServerCertificate']\n        cert_details = camelcase_to_lowercase(cert_dict)\n        for key, value in cert_details['server_certificate_metadata'].item():\n            cert_details.update(**{key:value})\n        del cert_details['server_certificate_metadata']\n        date_time = cert_details['expiration']\n        epoch_time = labDT(date_time).epoch()\n        cert_details['expiration'] = epoch_time\n\n        return cert_details", "response": "a method to retrieve the details about a server certificate"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting with a beautiful color.", "response": "def text_in_color(self, message, color_code):\n        \"\"\" Print with a beautiful color. See codes at the top of this file. \"\"\"\n        return self.term.color(color_code) + message + self.term.normal"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns set of files that will be added to tar file later should be tuple list or generator that returns strings", "response": "def files(self):\n        \"\"\"files that will be add to tar file later\n        should be tuple, list or generator that returns strings\n        \"\"\"\n        ios_names = [info.name for info in self._ios_to_add.keys()]\n        return set(self.files_to_add + ios_names)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd file like object to archive later", "response": "def add_fileobj(self, fname, fcontent):\n        \"\"\"add file like object, it will be add to tar file later\n\n        :param fname: name in tar file\n        :param fcontent: content. bytes, string, BytesIO or StringIO\n        \"\"\"\n        tar_info = tarfile.TarInfo(fname)\n        if isinstance(fcontent, io.BytesIO):\n            tar_info.size = len(fcontent.getvalue())\n        elif isinstance(fcontent, io.StringIO):\n            tar_info.size = len(fcontent.getvalue())\n            fcontent = io.BytesIO(fcontent.getvalue().encode(\"utf8\"))\n        else:\n            if hasattr(fcontent, \"readable\"):\n                fcontent = fcontent\n            tar_info.size = len(fcontent)\n            if isinstance(fcontent, str):\n                fcontent = fcontent.encode(\"utf8\")\n            fcontent = io.BytesIO(fcontent)\n        self._ios_to_add[tar_info] = fcontent"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate(self):\n        if self._tar_buffer.tell():\n            self._tar_buffer.seek(0, 0)\n            yield self._tar_buffer.read()\n\n        for fname in self._files_to_add:\n            last = self._tar_buffer.tell()\n            self._tar_obj.add(fname)\n            self._tar_buffer.seek(last, os.SEEK_SET)\n            data = self._tar_buffer.read()\n            yield data\n\n        for info, content in self._ios_to_add.items():\n            last = self._tar_buffer.tell()\n            self._tar_obj.addfile(info, content)\n            self._tar_buffer.seek(last, os.SEEK_SET)\n            data = self._tar_buffer.read()\n            yield data\n\n        self._tar_obj.close()\n        yield self._tar_buffer.read()\n        self._generated = True", "response": "generate tar file\n\n        ..Usage::\n\n            >>> tarfile = b\"\".join(data for data in tg.generate())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tar(self):\n        if not self.generated:\n            for data in self.generate():\n                pass\n        return self._tar_buffer.getvalue()", "response": "tar in bytes format"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_thesaurus_response(word, client):\n    response = client.getThesaurus(word)\n    print(\"SYNONYMS: \")\n    \"\"\"if \"noun\" in response:\n        print(\"\\nNouns:\\n%s\" % \" \".join(response[\"noun\"][\"syn\"]))\n    if \"verb\" in response:\n        print(\"Verbs:\\n%s\" % \" \".join(response[\"verb\"][\"syn\"]))\"\"\"\n    try:\n        print(\",\".join(response[\"words\"]))\n    except TypeError:\n        pass", "response": "Print the response of a thesaurus word."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the Thesaurus for a given word", "response": "def getThesaurus(self, word):\n        \"\"\"response = requests.get(\"http://words.bighugelabs.com/api/2/%s/%s/json\"\n                            % (self.tkey, word)).json()\n        return response\"\"\"\n        response = requests.get(\n            \"http://api.wordnik.com:80/v4/word.json/%s/relatedWords?\"\n            \"useCanonical=false&relationshipTypes=synonym&limitPer\"\n            \"RelationshipType=15&api_key=%s\" % (word, key)).json()\n        try:\n            return response[0]\n        except IndexError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connect(self):\n        self.client = MongoClient(self.mongo_uri)\n        self.db = self.client[self.db_name]", "response": "Starts the mongodb connection."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find(self, collection, query):\n        obj = getattr(self.db, collection)\n        result = obj.find(query)\n        return result", "response": "Search a collection for the query provided. Just a raw interface to\n            mongo to do any query you want."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_all(self, collection):\n        obj = getattr(self.db, collection)\n        result = obj.find()\n        return result", "response": "Search a collection for all available items."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_one(self, collection, query):\n        obj = getattr(self.db, collection)\n        result = obj.find_one(query)\n        return result", "response": "Search a collection for the query provided and return one result. Just\n            is a raw interface to mongo to do any query you want."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_distinct(self, collection, key):\n        obj = getattr(self.db, collection)\n        result = obj.distinct(key)\n        return result", "response": "Search a collection for the distinct key values provided."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds an embedded campaign to the TLO.", "response": "def add_embedded_campaign(self, id, collection, campaign, confidence,\n                              analyst, date, description):\n        \"\"\"\n        Adds an embedded campaign to the TLO.\n\n        Args:\n            id: the CRITs object id of the TLO\n            collection: The db collection. See main class documentation.\n            campaign: The campaign to assign.\n            confidence: The campaign confidence\n            analyst: The analyst making the assignment\n            date: The date of the assignment\n            description: A description\n        Returns:\n            The resulting mongo object\n        \"\"\"\n        if type(id) is not ObjectId:\n            id = ObjectId(id)\n        # TODO: Make sure the object does not already have the campaign\n        # Return if it does. Add it if it doesn't\n        obj = getattr(self.db, collection)\n        result = obj.find({'_id': id, 'campaign.name': campaign})\n        if result.count() > 0:\n            return\n        else:\n            log.debug('Adding campaign to set: {}'.format(campaign))\n            campaign_obj = {\n                'analyst': analyst,\n                'confidence': confidence,\n                'date': date,\n                'description': description,\n                'name': campaign\n            }\n            result = obj.update(\n                {'_id': id},\n                {'$push': {'campaign': campaign_obj}}\n            )\n            return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_bucket_list_item(self, id, collection, item):\n        if type(id) is not ObjectId:\n            id = ObjectId(id)\n        obj = getattr(self.db, collection)\n        result = obj.update(\n            {'_id': id},\n            {'$pull': {'bucket_list': item}}\n        )\n        return result", "response": "Removes an item from the bucket list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_campaign_name_list(self):\n        campaigns = self.find('campaigns', {})\n        campaign_names = []\n        for campaign in campaigns:\n            if 'name' in campaign:\n                campaign_names.append(campaign['name'])\n        return campaign_names", "response": "Returns a list of all valid campaign names"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninvoke the RFC 7159 spec compliant parser :return: the parsed & vetted request body", "response": "def deserialize(self):\n        \"\"\" Invoke the RFC 7159 spec compliant parser\n\n        :return:\n            the parsed & vetted request body\n        \"\"\"\n\n        super(Deserializer, self).deserialize()\n\n        try:\n            return json.loads(self.req.get_body())\n        except TypeError:\n            link = 'tools.ietf.org/html/rfc7159'\n            self.fail('Typically, this error is due to a missing JSON '\n                      'payload in your request when one was required. '\n                      'Otherwise, it could be a bug in our API.', link)\n        except UnicodeDecodeError:\n            link = 'tools.ietf.org/html/rfc7159#section-8.1'\n            self.fail('We failed to process your JSON payload & it is '\n                      'most likely due to non UTF-8 encoded characters '\n                      'in your JSON.', link)\n        except ValueError as exc:\n            link = 'tools.ietf.org/html/rfc7159'\n            self.fail('The JSON payload appears to be malformed & we '\n                      'failed to process it. The error with line & column '\n                      'numbers is: %s' % exc.message, link)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts an integer to two bytes.", "response": "def int_to_bin(i):\n    \"\"\" Integer to two bytes \"\"\"\n    # devide in two parts (bytes)\n    i1 = i % 256\n    i2 = int(i / 256)\n    # make string (little endian)\n    return chr(i1) + chr(i2)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite an animated gif from the specified images.", "response": "def write_gif(filename, images, duration=0.1, repeat=True, dither=False,\n                nq=0, sub_rectangles=True, dispose=None):\n    \"\"\" write_gif(filename, images, duration=0.1, repeat=True, dither=False,\n                    nq=0, sub_rectangles=True, dispose=None)\n\n    Write an animated gif from the specified images.\n\n    Parameters\n    ----------\n    filename : string\n        The name of the file to write the image to.\n    images : list\n        Should be a list consisting of PIL images or numpy arrays.\n        The latter should be between 0 and 255 for integer types, and\n        between 0 and 1 for float types.\n    duration : scalar or list of scalars\n        The duration for all frames, or (if a list) for each frame.\n    repeat : bool or integer\n        The amount of loops. If True, loops infinitetely.\n    dither : bool\n        Whether to apply dithering\n    nq : integer\n        If nonzero, applies the NeuQuant quantization algorithm to create\n        the color palette. This algorithm is superior, but slower than\n        the standard PIL algorithm. The value of nq is the quality\n        parameter. 1 represents the best quality. 10 is in general a\n        good tradeoff between quality and speed. When using this option,\n        better results are usually obtained when sub_rectangles is False.\n    sub_rectangles : False, True, or a list of 2-element tuples\n        Whether to use sub-rectangles. If True, the minimal rectangle that\n        is required to update each frame is automatically detected. This\n        can give significant reductions in file size, particularly if only\n        a part of the image changes. One can also give a list of x-y\n        coordinates if you want to do the cropping yourself. The default\n        is True.\n    dispose : int\n        How to dispose each frame. 1 means that each frame is to be left\n        in place. 2 means the background color should be restored after\n        each frame. 3 means the decoder should restore the previous frame.\n        If sub_rectangles==False, the default is 2, otherwise it is 1.\n\n    \"\"\"\n\n    # Check PIL\n    if PIL is None:\n        raise RuntimeError(\"Need PIL to write animated gif files.\")\n\n    # Check images\n    images = check_images(images)\n\n    # Instantiate writer object\n    gif_writer = GifWriter()\n    gif_writer.transparency = False  # init transparency flag used in GifWriter functions\n\n    # Check loops\n    if repeat is False:\n        loops = 1\n    elif repeat is True:\n        loops = 0  # zero means infinite\n    else:\n        loops = int(repeat)\n\n    # Check duration\n    if hasattr(duration, '__len__'):\n        if len(duration) == len(images):\n            duration = [d for d in duration]\n        else:\n            raise ValueError(\"len(duration) doesn't match amount of images.\")\n    else:\n        duration = [duration for im in images]\n\n    # Check subrectangles\n    if sub_rectangles:\n        images, xy, images_info = gif_writer.handle_sub_rectangles(images, sub_rectangles)\n        default_dispose = 1  # Leave image in place\n    else:\n        # Normal mode\n        xy = [(0, 0) for im in images]\n        default_dispose = 2  # Restore to background color.\n\n    # Check dispose\n    if dispose is None:\n        dispose = default_dispose\n    if hasattr(dispose, '__len__'):\n        if len(dispose) != len(images):\n            raise ValueError(\"len(xy) doesn't match amount of images.\")\n    else:\n        dispose = [dispose for im in images]\n\n    # Make images in a format that we can write easy\n    images = gif_writer.convert_images_to_pil(images, dither, nq)\n\n    # Write\n    if isinstance(filename, basestring):\n        fp = open(filename, 'wb')\n    elif hasattr(filename, 'write'):\n        fp = filename\n    else:\n        return\n    try:\n        gif_writer.write_gif_to_file(fp, images, duration, loops, xy, dispose)\n    finally:\n        fp.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_header_anim(self, im):\n        bb = \"GIF89a\"\n        bb += int_to_bin(im.size[0])\n        bb += int_to_bin(im.size[1])\n        bb += \"\\x87\\x00\\x00\"\n        return bb", "response": "Get animation header. To replace PILs getheader ( im ) [ 0 ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the image descriptor.", "response": "def get_image_descriptor(self, im, xy=None):\n        \"\"\" get_image_descriptor(im, xy=None)\n\n        Used for the local color table properties per image.\n        Otherwise global color table applies to all frames irrespective of\n        whether additional colors comes in play that require a redefined\n        palette. Still a maximum of 256 color per frame, obviously.\n\n        Written by Ant1 on 2010-08-22\n        Modified by Alex Robinson in Janurari 2011 to implement subrectangles.\n\n        \"\"\"\n\n        # Defaule use full image and place at upper left\n        if xy is None:\n            xy = (0, 0)\n\n        # Image separator,\n        bb = '\\x2C'\n\n        # Image position and size\n        bb += int_to_bin(xy[0])  # Left position\n        bb += int_to_bin(xy[1])  # Top position\n        bb += int_to_bin(im.size[0])  # image width\n        bb += int_to_bin(im.size[1])  # image height\n\n        # packed field: local color table flag1, interlace0, sorted table0,\n        # reserved00, lct size111=7=2^(7+1)=256.\n        bb += '\\x87'\n\n        # LZW minimum size code now comes later, begining of [image data] blocks\n        return bb"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_graphics_control_ext(self, duration=0.1, dispose=2, transparent_flag=0, transparency_index=0):\n\n        bb = '\\x21\\xF9\\x04'\n        bb += chr(((dispose & 3) << 2) | (transparent_flag & 1))  # low bit 1 == transparency,\n        # 2nd bit 1 == user input , next 3 bits, the low two of which are used,\n        # are dispose.\n        bb += int_to_bin(int(duration * 100))  # in 100th of seconds\n        bb += chr(transparency_index)  # transparency index\n        bb += '\\x00'  # end\n        return bb", "response": "This function returns the string that represents the graphics control extension of the image."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef handle_sub_rectangles(self, images, sub_rectangles):\n        image_info = [im.info for im in images]\n        if isinstance(sub_rectangles, (tuple, list)):\n            # xy given directly\n\n            # Check xy\n            xy = sub_rectangles\n            if xy is None:\n                xy = (0, 0)\n            if hasattr(xy, '__len__'):\n                if len(xy) == len(images):\n                    xy = [xxyy for xxyy in xy]\n                else:\n                    raise ValueError(\"len(xy) doesn't match amount of images.\")\n            else:\n                xy = [xy for im in images]\n            xy[0] = (0, 0)\n\n        else:\n            # Calculate xy using some basic image processing\n\n            # Check Numpy\n            if np is None:\n                raise RuntimeError(\"Need Numpy to use auto-sub_rectangles.\")\n\n            # First make numpy arrays if required\n            for i in range(len(images)):\n                im = images[i]\n                if isinstance(im, Image.Image):\n                    tmp = im.convert()  # Make without palette\n                    a = np.asarray(tmp)\n                    if len(a.shape) == 0:\n                        raise MemoryError(\"Too little memory to convert PIL image to array\")\n                    images[i] = a\n\n            # Determine the sub rectangles\n            images, xy = self.get_sub_rectangles(images)\n\n        # Done\n        return images, xy, image_info", "response": "Handle the sub - rectangles."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_sub_rectangles(self, ims):\n\n        # Check image count\n        if len(ims) < 2:\n            return ims, [(0, 0) for i in ims]\n\n        # We need numpy\n        if np is None:\n            raise RuntimeError(\"Need Numpy to calculate sub-rectangles. \")\n\n        # Prepare\n        ims2 = [ims[0]]\n        xy = [(0, 0)]\n\n        # Iterate over images\n        prev = ims[0]\n        for im in ims[1:]:\n\n            # Get difference, sum over colors\n            diff = np.abs(im - prev)\n            if diff.ndim == 3:\n                diff = diff.sum(2)\n            # Get begin and end for both dimensions\n            x = np.argwhere(diff.sum(0))\n            y = np.argwhere(diff.sum(1))\n            # Get rect coordinates\n            if x.size and y.size:\n                x0, x1 = x[0], x[-1] + 1\n                y0, y1 = y[0], y[-1] + 1\n            else:  # No change ... make it minimal\n                x0, x1 = 0, 2\n                y0, y1 = 0, 2\n\n            # Cut out and store\n            im2 = im[y0:y1, x0:x1]\n            prev = im\n            ims2.append(im2)\n            xy.append((x0, y0))\n\n        return ims2, xy", "response": "Get the minimal rectangles that need updating each frame."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts images to Paletted PIL images which can then be ArcGIS images.", "response": "def convert_images_to_pil(self, images, dither, nq=0, images_info=None):\n        \"\"\" convert_images_to_pil(images, nq=0)\n\n        Convert images to Paletted PIL images, which can then be\n        written to a single animaged GIF.\n\n        \"\"\"\n\n        # Convert to PIL images\n        images2 = []\n        for im in images:\n            if isinstance(im, Image.Image):\n                images2.append(im)\n            elif np and isinstance(im, np.ndarray):\n                if im.ndim == 3 and im.shape[2] == 3:\n                    im = Image.fromarray(im, 'RGB')\n                elif im.ndim == 3 and im.shape[2] == 4:\n                    # im = Image.fromarray(im[:,:,:3],'RGB')\n                    self.transparency = True\n                    im = Image.fromarray(im[:, :, :4], 'RGBA')\n                elif im.ndim == 2:\n                    im = Image.fromarray(im, 'L')\n                images2.append(im)\n\n        # Convert to paletted PIL images\n        images, images2 = images2, []\n        if nq >= 1:\n            # NeuQuant algorithm\n            for im in images:\n                im = im.convert(\"RGBA\")  # NQ assumes RGBA\n                nq_instance = NeuQuant(im, int(nq))  # Learn colors from image\n                if dither:\n                    im = im.convert(\"RGB\").quantize(palette=nq_instance.palette_image(), colors=255)\n                else:\n                    im = nq_instance.quantize(im, colors=255)  # Use to quantize the image itself\n\n                self.transparency = True  # since NQ assumes transparency\n                if self.transparency:\n                    alpha = im.split()[3]\n                    mask = Image.eval(alpha, lambda a: 255 if a <= 128 else 0)\n                    im.paste(255, mask=mask)\n                images2.append(im)\n        else:\n            # for index,im in enumerate(images):\n            for i in range(len(images)):\n                im = images[i].convert('RGB').convert('P', palette=Image.ADAPTIVE, dither=dither, colors=255)\n                if self.transparency:\n                    alpha = images[i].split()[3]\n                    mask = Image.eval(alpha, lambda a: 255 if a <= 128 else 0)\n                    im.paste(255, mask=mask)\n                images2.append(im)\n\n        # Done\n        return images2"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites the bytes to the specified file.", "response": "def write_gif_to_file(self, fp, images, durations, loops, xys, disposes):\n        \"\"\" write_gif_to_file(fp, images, durations, loops, xys, disposes)\n\n        Given a set of images writes the bytes to the specified stream.\n\n        \"\"\"\n\n        # Obtain palette for all images and count each occurance\n        palettes, occur = [], []\n        for im in images:\n            palettes.append(getheader(im)[1])\n        for palette in palettes:\n            occur.append(palettes.count(palette))\n\n        # Select most-used palette as the global one (or first in case no max)\n        print palettes, occur\n        global_palette = palettes[occur.index(max(occur))]\n\n        # Init\n        frames = 0\n        first_frame = True\n\n        for im, palette in zip(images, palettes):\n\n            if first_frame:\n                # Write header\n\n                # Gather info\n                header = self.get_header_anim(im)\n                appext = self.get_app_ext(loops)\n\n                # Write\n                fp.write(header)\n                fp.write(global_palette)\n                fp.write(appext)\n\n                # Next frame is not the first\n                first_frame = False\n\n            if True:\n                # Write palette and image data\n\n                # Gather info\n                data = getdata(im)\n                imdes, data = data[0], data[1:]\n\n                transparent_flag = 0\n                if self.transparency:\n                    transparent_flag = 1\n\n                graphext = self.get_graphics_control_ext(\n                    durations[frames],\n                    disposes[frames],\n                    transparent_flag=transparent_flag,\n                    transparency_index=255)\n\n                # Make image descriptor suitable for using 256 local color palette\n                lid = self.get_image_descriptor(im, xys[frames])\n\n                # Write local header\n                if (palette != global_palette) or (disposes[frames] != 2):\n                    # Use local color palette\n                    fp.write(graphext)\n                    fp.write(lid)  # write suitable image descriptor\n                    fp.write(palette)  # write local color table\n                    fp.write('\\x08')  # LZW minimum size code\n                else:\n                    # Use global color palette\n                    fp.write(graphext)\n                    fp.write(imdes)  # write suitable image descriptor\n\n                # Write image data\n                for d in data:\n                    fp.write(d)\n\n            # Prepare for next round\n            frames = frames + 1\n\n        fp.write(\";\")  # end gif\n        return frames"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef palette_image(self):\n        if self.pimage is None:\n            palette = []\n            for i in range(self.NETSIZE):\n                palette.extend(self.colormap[i][:3])\n\n            palette.extend([0] * (256 - self.NETSIZE) * 3)\n\n            # a palette image to use for quant\n            self.pimage = Image.new(\"P\", (1, 1), 0)\n            self.pimage.putpalette(palette)\n        return self.pimage", "response": "Create a paletted image which contains the palette of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_installed_extjs_apps():\n    installed_apps = []\n    checked = set()\n    for app in settings.INSTALLED_APPS:\n        if not app.startswith('django.') and not app in checked:\n            checked.add(app)\n            try:\n                installed_apps.append(get_appinfo(app))\n            except LookupError, e:\n                pass\n    return installed_apps", "response": "Get all installed extjs apps."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates JSB config file using sencha create jsb.", "response": "def createJsbConfig(self):\n        \"\"\"\n        Create JSB config file using ``sencha create jsb``.\n\n        :return: The created jsb3 config as a string.\n        \"\"\"\n        tempdir = mkdtemp()\n        tempfile = join(tempdir, 'app.jsb3')\n        cmd = ['sencha', 'create', 'jsb', '-a', self.url, '-p', tempfile]\n        log.debug('Running: %s', ' '.join(cmd))\n        call(cmd)\n        jsb3 = open(tempfile).read()\n        rmtree(tempdir)\n        return jsb3"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cleanJsbConfig(self, jsbconfig):\n        config = json.loads(jsbconfig)\n        self._cleanJsbAllClassesSection(config)\n        self._cleanJsbAppAllSection(config)\n        return json.dumps(config, indent=4)", "response": "Clean up the JSB config."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a clean JSB with the current set of attributes and return the result.", "response": "def createCleanJsbConfig(self):\n        \"\"\"\n        Run :meth:`createJsbConfig`, clean up the JSB with\n        :meth:`cleanJsbConfig` and return the result.\n        \"\"\"\n        jsb = self.createJsbConfig()\n        log.debug('sencha generated JSB config: %s', jsb)\n        jsb = self.cleanJsbConfig(jsb)\n        log.debug('cleaned JSB config: %s', jsb)\n        return jsb"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclean all classes section in the sencha created JSB.", "response": "def _cleanJsbAllClassesSection(self, config):\n        \"\"\"\n        Fixes two issues with the sencha created JSB:\n\n            - All extjs urls are prefixed by ``../static`` instead of\n              ``/static`` (no idea why).\n            - We assume static files are served at ``/static``, but collectstatic may\n              not build files in ``static/``. Therefore, we replace ``/static`` with\n              the relative path to ``settings.STATIC_ROOT``.\n        \"\"\"\n        allclasses = config['builds'][0]\n        for fileinfo in allclasses['files']:\n            path = fileinfo['path']\n            if path.startswith('..'):\n                path = path[2:]\n            path = path.replace('/static', self.static_root)\n            fileinfo['path'] = path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding the current locale from the given JSB string.", "response": "def buildFromJsbString(self, jsb, nocompressjs=False):\n        \"\"\"\n        Build from the given config file using ``sencha build``.\n\n        :param jsb: The JSB config as a string.\n        :param nocompressjs: Compress the javascript? If ``True``, run ``sencha build --nocompress``.\n        \"\"\"\n        tempconffile = 'temp-app.jsb3'\n        cmd = ['sencha', 'build', '-p', tempconffile, '-d', self.outdir]\n        if nocompressjs:\n            cmd.append('--nocompress')\n        open(tempconffile, 'w').write(jsb)\n        log.info('Running: %s', ' '.join(cmd))\n        try:\n            call(cmd)\n        finally:\n            remove(tempconffile)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef configureAndBuild(self, nocompressjs=False):\n        jsb = self.createCleanJsbConfig()\n        self.buildFromJsbString(jsb, nocompressjs)", "response": "Run createCleanJsbConfig and build."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef determine_actions(self, request, view):\n        actions = {}\n        for method in {'PUT', 'POST'} & set(view.allowed_methods):\n            view.request = clone_request(request, method)\n            try:\n                # Test global permissions\n                if hasattr(view, 'check_permissions'):\n                    view.check_permissions(view.request)\n                # Test object permissions\n                if method == 'PUT' and hasattr(view, 'get_object'):\n                    view.get_object()\n            except (exceptions.APIException, PermissionDenied, Http404):\n                pass\n            else:\n                # If user has appropriate permissions for the view, include\n                # appropriate metadata about the fields that should be supplied.\n                serializer = view.get_serializer()\n                actions[method] = self.get_serializer_info(serializer)\n            finally:\n                view.request = request\n\n        return actions", "response": "Returns a dictionary of the actions that should be performed for the given request and view."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive an instance of a serializer return a dictionary of metadata about its fields.", "response": "def get_serializer_info(self, serializer):\n        \"\"\"\n        Given an instance of a serializer, return a dictionary of metadata\n        about its fields.\n        \"\"\"\n        if hasattr(serializer, 'child'):\n            # If this is a `ListSerializer` then we want to examine the\n            # underlying child serializer instance instead.\n            serializer = serializer.child\n        return OrderedDict([\n            (field_name, self.get_field_info(field))\n            for field_name, field in serializer.fields.items()\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_field_info(self, field):\n        field_info = OrderedDict()\n        field_info['type'] = self.label_lookup[field]\n        field_info['required'] = getattr(field, 'required', False)\n\n        attrs = [\n            'read_only', 'label', 'help_text',\n            'min_length', 'max_length',\n            'min_value', 'max_value'\n        ]\n\n        for attr in attrs:\n            value = getattr(field, attr, None)\n            if value is not None and value != '':\n                field_info[attr] = force_text(value, strings_only=True)\n\n        if getattr(field, 'child', None):\n            field_info['child'] = self.get_field_info(field.child)\n        elif getattr(field, 'fields', None):\n            field_info['children'] = self.get_serializer_info(field)\n\n        if not field_info.get('read_only') and hasattr(field, 'choices'):\n            field_info['choices'] = [\n                {\n                    'value': choice_value,\n                    'display_name': force_text(choice_name, strings_only=True)\n                }\n                for choice_value, choice_name in field.choices.items()\n            ]\n\n        return field_info", "response": "Returns a dictionary of metadata about a serializer field."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_request(self, endpoint, entitiy_type, query, params=None):\n        if params is None:\n            params = {}\n\n        params['entitytype'] = entitiy_type\n        params['query'] = query\n        params['country'] = 'US'\n        params['language'] = 'en'\n\n        return super(SearchApi, self).make_request('%s/search' % endpoint,\n                                                   params)", "response": "Make the request to the API."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches the music database for a given query", "response": "def music_search(self, entitiy_type, query, **kwargs):\n        \"\"\"\n        Search the music database\n\n        Where ``entitiy_type`` is a comma separated list of:\n\n        ``song``\n            songs\n\n        ``album``\n            albums\n\n        ``composition``\n            compositions\n\n        ``artist``\n            people working in music\n        \"\"\"\n        return self.make_request('music', entitiy_type, query, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef amg_video_search(self, entitiy_type, query, **kwargs):\n        return self.make_request('amgvideo', entitiy_type, query, kwargs)", "response": "Search the Movies and TV for a given entitiy type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef video_search(self, entitiy_type, query, **kwargs):\n        return self.make_request('video', entitiy_type, query, kwargs)", "response": "Search the TV schedule database for a specific entitiy type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef structureOutput(fileUrl, fileName, searchFiles, format=True, space=40):\n\t#First, remove the filename\n\tif format:\n\t\tsplitUrls = fileUrl[1:].split('/')\n\t\tfileUrl = \"\"\n\t\tfor splitUrl in splitUrls:\n\t\t\t# This is a gimmicky fix to make formatting consistent\n\t\t\t# Cemetech doesn't have /pub/ at the front of it's repo paths\n\t\t\t# Also, Omnimaga has a /files/ we need to get rid of similarly\n\t\t\t# This probably *should* be repo-dependent, but oh well\n\t\t\tif splitUrl != \"\" and (not \".\" in splitUrl) and (splitUrl != \"pub\" and splitUrl != \"files\"):\n\t\t\t\tfileUrl += splitUrl + '/'\n\t\t\telif \".\" in splitUrl:\n\t\t\t\tarchiveName = splitUrl\n\n\t#Now, format the output\n\tif searchFiles:\n\t\tfileName = archiveName\n\tpause = (space - len(fileUrl))\n\toutput = fileUrl\n\toutput += (\" \" * pause)\n\toutput += fileName\n\treturn output", "response": "Formats the output of a list of packages"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef count(self, searchString, category=\"\", math=False, game=False, searchFiles=False, extension=\"\"):\n\t\tfileData = {}\n\t\tnameData = {}\n\t\t\n\t\t#Search the index\n\t\tif searchFiles:\n\t\t\tfileData = self.searchNamesIndex(self.fileIndex, fileData, searchString, category, math, game, extension)\n\t\telse:\n\t\t\tnameData = self.searchNamesIndex(self.nameIndex, nameData, searchString)\n\t\t\t\n\t\t#Now search the other index\n\t\tif searchFiles:\n\t\t\tnameData, fileData = self.searchFilesIndex(fileData, nameData, self.nameIndex, searchString)\n\t\telse:\n\t\t\tfileData, nameData = self.searchFilesIndex(nameData, fileData, self.fileIndex, searchString, category, math, game, extension)\n\n\t\t# Bail out if we failed to do either of those things.\n\t\tif fileData is None or nameData is None:\n\t\t\tself.repo.printd(\"Error: failed to load one or more of the index files for this repo. Exiting.\")\n\t\t\tself.repo.printd(\"Please run 'calcpkg update' and retry this command.\")\n\t\t\tsys.exit(1)\n\n\t\t#Now obtain a count (exclude \"none\" elements)\n\t\tcount = 0\n\t\tfor element in nameData:\n\t\t\tif not nameData[element] is None:\n\t\t\t\tcount += 1\n\n\t\tself.repo.printd(\"Search for '\" + searchString + \"' returned \" + str(count) + \" result(s) in \" + self.repo.name)\n\t\treturn count", "response": "Counts the number of files containing some search term doesn t return them"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncoring function to search directory structure for child files and folders of a parent", "response": "def searchHierarchy(self, fparent):\n\t\t\"\"\"Core function to search directory structure for child files and folders of a parent\"\"\"\n\t\tdata = []\n\t\treturnData = []\n\t\tparentslashes = fparent.count('/') \n\t\tfilecount = 0\n\t\tfoldercount = 0\n\n\t\t#open files for folder searching\n\t\ttry:\n\t\t\tdirFile = open(self.dirIndex, 'rt')\n\t\texcept IOError:\n\t\t\tself.repo.printd(\"Error: Unable to read index file \" + self.dirIndex)\n\t\t\treturn\n\n\t\t#search for folders\n\t\tfor fldr in dirFile:\n\t\t\tfldr = fldr.split('|')\n\t\t\tfldr = fldr[0]\n\t\t\tif fparent in fldr and parentslashes+1 == fldr.count('/'):\n\t\t\t\treturnData.append([fldr, fldr[fldr.rfind('/',1,-1):-1], ResultType.FOLDER])\n\t\t\t\tfoldercount += 1\n\n\t\tdirFile.close()\n\n\t\t#open files for file searching\n\t\ttry:\n\t\t\tfileFile = open(self.fileIndex, 'rt')\n\t\texcept IOError:\n\t\t\tself.repo.printd(\"Error: Unable to read index file \" + self.fileIndex)\n\t\t\treturn\n\n\t\ttry:\n\t\t\tnameFile = open(self.nameIndex, 'rt')\n\t\texcept IOError:\n\t\t\tself.repo.printd(\"Error: Unable to read index file \" + self.nameIndex)\n\t\t\treturn\n\n\t\t#search for files\n\t\tfor (path,name) in zip(fileFile,nameFile):\n\t\t\tif fparent in path and parentslashes == path.count('/'):\n\t\t\t\treturnData.append([path.strip(), name, ResultType.FILE])\n\t\t\t\tfilecount += 1\n\n\t\tfileFile.close()\n\t\tnameFile.close()\n\n\t\treturn [returnData, foldercount, filecount]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches the index and return the data", "response": "def search(self, searchString, category=\"\", math=False, game=False, searchFiles=False, extension=\"\"):\n\t\t\"\"\"Core function to search the indexes and return data\"\"\"\n\t\tdata = []\n\t\tnameData = {}\n\t\tfileData = {}\n\t\t\n\t\t#Search the name index\n\t\tif searchFiles:\n\t\t\tfileData = self.searchNamesIndex(self.fileIndex, fileData, searchString, category, math, game, extension, searchFiles)\n\t\telse:\n\t\t\tnameData = self.searchNamesIndex(self.nameIndex, nameData, searchString)\n\t\t\t\n\t\t#Now search the file index\n\t\tif searchFiles:\n\t\t\tnameData, fileData = self.searchFilesIndex(fileData, nameData, self.nameIndex, searchString)\n\t\telse:\n\t\t\tfileData, nameData = self.searchFilesIndex(nameData, fileData, self.fileIndex, searchString, category, math, game, extension)\n\t\t\t\n\t\t# Bail out if we failed to do either of those things.\n\t\tif fileData is None or nameData is None:\n\t\t\tself.repo.printd(\"Error: failed to load one or more of the index files for this repo. Exiting.\")\n\t\t\tself.repo.printd(\"Please run 'calcpkg update' and retry this command.\")\n\t\t\tsys.exit(1)\n\t\t\t\n\t\t# Prepare output to parse\n\t\tspace = 0\n\t\tlongestFile = len(\"File Name:\")\n\t\tfor key, value in nameData.iteritems():\n\t\t\tfileValue = fileData[key]\n\t\t\tdata.append([fileValue, value])\n\t\t\tif not fileValue is None:\n\t\t\t\tfolder = fileValue.rpartition(\"/\")[0]\n\t\t\t\tif space < len(folder):\n\t\t\t\t\tspace = len(folder)\n\t\t\tif not value is None:\n\t\t\t\tif longestFile < len(value):\n\t\t\t\t\tlongestFile = len(value)\n\n\t\t#Print output\n\t\tspace += 5\n\t\tif len(data) != 0:\n\t\t\tself.repo.printd(\"Results for repo: \" + self.repo.name)\n\t\t\tself.repo.printd(structureOutput(\"File Category:\", \"File Name:\", False, False, space))\n\t\t\tself.repo.printd(\"-\" * (space + longestFile))\n\t\telse:\n\t\t\tself.repo.printd(\"No packages found\")\n\t\treturnData = []\n\t\tfor datum in data:\n\t\t\ttry:\n\t\t\t\tself.repo.printd(structureOutput(datum[0], datum[1], searchFiles, True, space))\n\t\t\t\treturnData.append([datum[0], datum[1]])\n\t\t\texcept:\n\t\t\t\tpass\n\t\tself.repo.printd(\" \")\n\t\t\n\t\t#Return data\n\t\treturn returnData"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches the files index using the namedata and returns the filedata", "response": "def searchFilesIndex(self, nameData, fileData, fileIndex, searchString, category=\"\", math=False, game=False, extension=\"\"):\n\t\t\"\"\"Search the files index using the namedata and returns the filedata\"\"\"\n\t\ttry:\n\t\t\tfileFile = open(fileIndex, 'rt')\n\t\texcept IOError:\n\t\t\tself.repo.printd(\"Error: Unable to read index file \" + self.fileIndex)\n\t\t\treturn None, None\n\t\t\t\n\t\tcount = 1\n\t\tfor line in fileFile:\n\t\t\tcount += 1\n\t\t\ttry:\n\t\t\t\tif nameData[count] != None:\n\t\t\t\t\t#category argument\n\t\t\t\t\tif category in line:\n\t\t\t\t\t\tfileData[count] = line[:len(line) - 1]\n\t\t\t\t\telse:\n\t\t\t\t\t\tnameData[count] = None\n\t\t\t\t\t\tfileData[count] = None\n\t\t\t\t\t#extension argument\n\t\t\t\t\tif extension in line:\n\t\t\t\t\t\tfileData[count] = line[:len(line) - 1]\n\t\t\t\t\telse:\n\t\t\t\t\t\tnameData[count] = None\n\t\t\t\t\t\tfileData[count] = None\n\t\t\t\t\t#Both game and math\n\t\t\t\t\tif (game and math):\n\t\t\t\t\t\tif (\"/games/\" in line or \"/math/\" in line or \"/science\" in line):\n\t\t\t\t\t\t\tnameData[count] = line[:len(line) - 1]\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tnameData[count] = None\n\t\t\t\t\t#game option switch\n\t\t\t\t\telif game:\n\t\t\t\t\t\tif \"/games/\" in line:\n\t\t\t\t\t\t\tfileData[count] = line[:len(line) - 1]\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tnameData[count] = None\n\t\t\t\t\t\t\tfileData[count] = None\n\t\t\t\t\t#math option switch\n\t\t\t\t\telif math:\n\t\t\t\t\t\tif (\"/math/\" in line or \"/science/\" in line):\n\t\t\t\t\t\t\tfileData[count] = line[:len(line) - 1]\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tnameData[count] = None\n\t\t\t\t\t\t\tfileData[count] = None\n\t\t\texcept:\n\t\t\t\tpass\n\t\t\t\t\n\t\t#Close the file and return\n\t\tfileFile.close()\n\t\treturn fileData, nameData"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch the names index for a string and returns the namedata", "response": "def searchNamesIndex(self, nameIndex, nameData, searchString, category=\"\", math=False, game=False, extension=\"\", searchFiles=False):\n\t\t\"\"\"Search the names index for a string and returns the namedata\"\"\"\n\t\tnameData = {}\n\t\ttry:\n\t\t\tnameFile = open(nameIndex, 'rt')\n\t\texcept IOError:\n\t\t\tself.repo.printd(\"Error: Unable to read index file \" + self.fileIndex)\n\t\t\treturn None\n\t\t\t\n\t\tcount = 1\n\t\tfor line in nameFile:\n\t\t\tcount += 1\n\t\t\tif searchString.lower() in line.lower():\n\t\t\t\t#Extension argument\n\t\t\t\tif extension in line:\n\t\t\t\t\tnameData[count] = line[:len(line) - 1]\n\t\t\t\telse:\n\t\t\t\t\tnameData[count] = None\n\t\t\t\t#category arg\n\t\t\t\tif category in line and extension in line:\n\t\t\t\t\tnameData[count] = line[:len(line) - 1]\n\t\t\t\telse:\n\t\t\t\t\tnameData[count] = None\n\t\t\t\t#Both game and math\n\t\t\t\tif (game and math):\n\t\t\t\t\tif (\"/games/\" in line or \"/math/\" in line or \"/science\" in line):\n\t\t\t\t\t\tnameData[count] = line[:len(line) - 1]\n\t\t\t\t\telse:\n\t\t\t\t\t\tnameData[count] = None\n\t\t\t\t#Game option switch\n\t\t\t\telif game:\n\t\t\t\t\tif \"/games/\" in line:\n\t\t\t\t\t\tnameData[count] = line[:len(line) - 1]\n\t\t\t\t\telse:\n\t\t\t\t\t\tnameData[count] = None\n\t\t\t\t#Math option switch\n\t\t\t\telif math:\n\t\t\t\t\tif (\"/math/\" in line or \"/science/\" in line):\n\t\t\t\t\t\tnameData[count] = line[:len(line) - 1]\n\t\t\t\t\telse:\n\t\t\t\t\t\tnameData[count] = None\n\n\t\t#Close the name index and return\n\t\tnameFile.close()\n\t\treturn nameData"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a list of parsers and a media type return the appropriate parser to handle the incoming request.", "response": "def select_parser(self, request, parsers):\n        \"\"\"\n        Given a list of parsers and a media type, return the appropriate\n        parser to handle the incoming request.\n        \"\"\"\n        for parser in parsers:\n            if media_type_matches(parser.media_type, request.content_type):\n                return parser\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a request and a list of renderers return a two - tuple of renderer and media type.", "response": "def select_renderer(self, request, renderers, format_suffix=None):\n        \"\"\"\n        Given a request and a list of renderers, return a two-tuple of:\n        (renderer, media type).\n        \"\"\"\n        # Allow URL style format override.  eg. \"?format=json\n        format_query_param = self.settings.URL_FORMAT_OVERRIDE\n        format = format_suffix or request.query_params.get(format_query_param)\n\n        if format:\n            renderers = self.filter_renderers(renderers, format)\n\n        accepts = self.get_accept_list(request)\n\n        # Check the acceptable media types against each renderer,\n        # attempting more specific media types first\n        # NB. The inner loop here isn't as bad as it first looks :)\n        #     Worst case is we're looping over len(accept_list) * len(self.renderers)\n        for media_type_set in order_by_precedence(accepts):\n            for renderer in renderers:\n                for media_type in media_type_set:\n                    if media_type_matches(renderer.media_type, media_type):\n                        # Return the most specific media type as accepted.\n                        media_type_wrapper = _MediaType(media_type)\n                        if (\n                            _MediaType(renderer.media_type).precedence >\n                            media_type_wrapper.precedence\n                        ):\n                            # Eg client requests '*/*'\n                            # Accepted media type is 'application/json'\n                            full_media_type = ';'.join(\n                                (renderer.media_type,) +\n                                tuple('{0}={1}'.format(\n                                    key, value.decode(HTTP_HEADER_ENCODING))\n                                    for key, value in media_type_wrapper.params.items()))\n                            return renderer, full_media_type\n                        else:\n                            # Eg client requests 'application/json; indent=8'\n                            # Accepted media type is 'application/json; indent=8'\n                            return renderer, media_type\n\n        raise exceptions.NotAcceptable(available_renderers=renderers)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfilter the renderers that are not in the given format.", "response": "def filter_renderers(self, renderers, format):\n        \"\"\"\n        If there is a '.json' style format suffix, filter the renderers\n        so that we only negotiation against those that accept that format.\n        \"\"\"\n        renderers = [renderer for renderer in renderers\n                     if renderer.format == format]\n        if not renderers:\n            raise Http404\n        return renderers"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives the incoming request return a tokenised list of media type strings.", "response": "def get_accept_list(self, request):\n        \"\"\"\n        Given the incoming request, return a tokenised list of media\n        type strings.\n        \"\"\"\n        header = request.META.get('HTTP_ACCEPT', '*/*')\n        return [token.strip() for token in header.split(',')]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndoing linear regression [n_iter] times successive removing [outliers] return result of normal linregress", "response": "def linregressIgnoringOutliers(x, y, n_iter=3, nstd=2):\n    \"\"\"\n    do linear regression [n_iter] times\n    successive removing [outliers]\n    return result of normal linregress\n    \"\"\"\n    for _ in range(n_iter):\n        m, n = linregress(x, y)[:2]\n        y_fit = x * m + n\n        dy = y - y_fit\n        std = (dy**2).mean()**0.5\n        inliers = abs(dy) < nstd * std\n        if inliers.sum() > 2:\n            x = x[inliers]\n            y = y[inliers]\n        else:\n            break\n    return linregress(x, y)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntranslate a unit position as Vec2 into a known parking spot.", "response": "def unit_pos_to_spot(unit_pos) -> ParkingSpot:\n    \"\"\"\n    Translates a unit position to a known parking spot\n\n    Args:\n        unit_pos: unit position as Vec2\n\n    Returns: ParkingSpot object\n\n    \"\"\"\n    min_ = 50\n    res = None\n    for airport in parkings:\n        for spot in parkings[airport]:  # type: ignore\n            spot_pos = parkings[airport][spot]  # type: ignore\n            dist = math.hypot(unit_pos[0] - spot_pos[0], unit_pos[1] - spot_pos[1])\n            if dist < min_:\n                min_ = dist  # type: ignore\n                res = ParkingSpot(airport=airport, spot=spot)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef collect(self):\n        class_functions = []\n        for key in self.__class__.__dict__.keys():\n            func = self.__class__.__dict__[key]\n            if (inspect.isfunction(func)):\n                class_functions.append(func)\n\n        functions = sorted(class_functions, key=lambda func: func.__name__)\n        for function in functions:\n            value = function(self)\n            if value:\n                return value", "response": "Collect the best suited data of all available in the subclasses."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef init(self):\n        self.y = {\"version\": int(time.time())}\n        recipient_email = raw_input(\"Enter Email ID: \")\n        self.import_key(emailid=recipient_email)\n        self.encrypt(emailid_list=[recipient_email])", "response": "Initialize a new password db store"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_users(self):\n        crypt = self._decrypt_file()\n\n        self.logger.info(crypt.stderr)\n        raw_userlist = crypt.stderr.split('\\n')\n        userlist = list()\n        for index, line in enumerate(raw_userlist):\n            if 'gpg: encrypted' in line:\n                m = re.search('ID (\\w+)', line)\n                keyid = m.group(1).strip()\n                userline = raw_userlist[index+1].strip()\n                userlist.append((keyid, userline))\n        return userlist", "response": "Get user list from the encrypted passdb file"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd user to encryption", "response": "def add_user(self, recipient_email):\n        \"\"\"\n        Add user to encryption\n        \"\"\"\n        self.import_key(emailid=recipient_email)\n        emailid_list = self.list_user_emails()\n        self.y = self.decrypt()\n        emailid_list.append(recipient_email)\n        self.encrypt(emailid_list=emailid_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves user from encryption", "response": "def delete_user(self, recipient_email):\n        \"\"\"\n        Remove user from encryption\n        \"\"\"\n        emailid_list = self.list_user_emails()\n        if recipient_email not in emailid_list:\n            raise Exception(\"User {0} not present!\".format(recipient_email))\n        else:\n            emailid_list.remove(recipient_email)\n            self.y = self.decrypt()\n            self.encrypt(emailid_list=emailid_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_meta(filename, data):\n    if \".\" not in filename:\n        raise MetaParsingException(\n            \"Can't recognize type of your metadata ('%s')!\" % filename\n        )\n\n    suffix = filename.rsplit(\".\", 1)[1].lower()\n\n    if suffix not in SUPPORTED_FILES:\n        raise MetaParsingException(\"Can't parse file of type '%s'!\" % suffix)\n\n    fp = validator.FieldParser()\n    for key, val in SUPPORTED_FILES[suffix](data).items():\n        fp.process(key, val)\n\n    return fp.get_epublication()", "response": "Parse metadata file into EPublication object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_instance(page_to_consume):\n    global _instances\n    if isinstance(page_to_consume, basestring):\n        uri = page_to_consume\n        page_to_consume = consumepage.get_instance(uri)\n    elif isinstance(page_to_consume, consumepage.ConsumePage):\n        uri = page_to_consume.uri\n    else:\n        raise TypeError(\n            \"get_instance() expects a parker.ConsumePage \"\n            \"or basestring derivative.\"\n        )\n\n    try:\n        instance = _instances[uri]\n    except KeyError:\n        instance = ConsumeModel(page_to_consume)\n        _instances[uri] = instance\n\n    return instance", "response": "Return an instance of ConsumeModel."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_from_config(self, config):\n        self.site = config.get(\"id\", False)\n        self.classification = config.get(\"class\", False)\n        self.tags = config.get(\"tags\", False)\n        self._load_key_value(\n            config.get(\"key_value_data\", False)\n        )\n        self._load_data(\n            config.get(\"specific_data\", False)\n        )\n        self._load_crumb(\n            config.get(\"crumbs\", False)\n        )\n        self._load_media_list(\n            config.get(\"media\", False)\n        )\n        self.unique_field = self.data_dict.get(\n            config.get(\"unique_field\", False),\n            False\n        )", "response": "Load model from passed configuration."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary of the object primed for dumping.", "response": "def get_dict(self):\n        \"\"\"Return a dictionary of the object primed for dumping.\"\"\"\n        data = self.data_dict.copy()\n\n        data.update({\n            \"class\": self.classification,\n            \"tags\": self.tags,\n            \"key_value_data\": self.key_value_dict,\n            \"crumbs\": self.crumb_list if len(self.crumb_list) > 0 else None,\n            \"media\": [\n                mediafile.filename\n                if mediafile.filename is not None\n                else mediafile.uri\n                for mediafile in self.media_list\n            ] if len(self.media_list) > 0 else None,\n            \"uri\": self.uri,\n            \"dumped\": datetime.utcnow().isoformat(),\n        })\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(self, name, redirect_uri=None):\n\n        data = dict(name=name)\n        if redirect_uri:\n            data['redirect_uri'] = redirect_uri\n\n        auth_request_resource = self.resource.create(data)\n\n        return (auth_request_resource.attributes['metadata']['device_token'],\n                auth_request_resource.attributes['mfa_uri'])", "response": "Create a new Device object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhook to add global options to an argparse. ArgumentParser object.", "response": "def build_option_parser(parser):\n    \"\"\"Hook to add global options\n\n    Called from openstackclient.shell.OpenStackShell.__init__()\n    after the builtin parser has been initialized.  This is\n    where a plugin can add global options such as an API version setting.\n\n    :param argparse.ArgumentParser parser: The parser object that has been\n        initialized by OpenStackShell.\n    \"\"\"\n    parser.add_argument(\n        '--os-rdomanager-oscplugin-api-version',\n        metavar='<rdomanager-oscplugin-api-version>',\n        default=utils.env(\n            'OS_RDOMANAGER_OSCPLUGIN_API_VERSION',\n            default=DEFAULT_RDOMANAGER_OSCPLUGIN_API_VERSION),\n        help='RDO Manager OSC Plugin API version, default=' +\n             DEFAULT_RDOMANAGER_OSCPLUGIN_API_VERSION +\n             ' (Env: OS_RDOMANAGER_OSCPLUGIN_API_VERSION)')\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef baremetal(self):\n\n        # TODO(d0ugal): When the ironicclient has it's own OSC plugin, the\n        # following client handling code should be removed in favor of the\n        # upstream version.\n\n        if self._baremetal is not None:\n            return self._baremetal\n\n        endpoint = self._instance.get_endpoint_for_service_type(\n            \"baremetal\",\n            region_name=self._instance._region_name,\n        )\n\n        token = self._instance.auth.get_token(self._instance.session)\n\n        self._baremetal = ironic_client.get_client(\n            1, os_auth_token=token, ironic_url=endpoint,\n            ca_file=self._instance._cli_options.os_cacert)\n\n        return self._baremetal", "response": "Returns an ironic client for the baremetal service client"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an orchestration service client", "response": "def orchestration(self):\n        \"\"\"Returns an orchestration service client\"\"\"\n\n        # TODO(d0ugal): This code is based on the upstream WIP implementation\n        # and should be removed when it lands:\n        # https://review.openstack.org/#/c/111786\n\n        if self._orchestration is not None:\n            return self._orchestration\n\n        API_VERSIONS = {\n            '1': 'heatclient.v1.client.Client',\n        }\n\n        heat_client = utils.get_client_class(\n            API_NAME,\n            self._instance._api_version[API_NAME],\n            API_VERSIONS)\n        LOG.debug('Instantiating orchestration client: %s', heat_client)\n\n        endpoint = self._instance.get_endpoint_for_service_type(\n            'orchestration')\n        token = self._instance.auth.get_token(self._instance.session)\n\n        client = heat_client(\n            endpoint=endpoint,\n            auth_url=self._instance._auth_url,\n            token=token,\n            username=self._instance._username,\n            password=self._instance._password,\n            region_name=self._instance._region_name,\n            insecure=self._instance._insecure,\n            ca_file=self._instance._cli_options.os_cacert,\n        )\n\n        self._orchestration = client\n        return self._orchestration"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef management(self):\n\n        endpoint = self._instance.get_endpoint_for_service_type(\n            \"management\",\n            region_name=self._instance._region_name,\n        )\n\n        token = self._instance.auth.get_token(self._instance.session)\n\n        self._management = tuskar_client.get_client(\n            2, os_auth_token=token, tuskar_url=endpoint)\n\n        return self._management", "response": "Returns an management service client"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if the media type in the first argument is less than or equal to the media type in the second argument.", "response": "def media_type_matches(lhs, rhs):\n    \"\"\"\n    Returns ``True`` if the media type in the first argument <= the\n    media type in the second argument.  The media types are strings\n    as described by the HTTP spec.\n\n    Valid media type strings include:\n\n    'application/json; indent=4'\n    'application/json'\n    'text/*'\n    '*/*'\n    \"\"\"\n    lhs = _MediaType(lhs)\n    rhs = _MediaType(rhs)\n    return lhs.match(rhs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of sets of media types ordered by precedence.", "response": "def order_by_precedence(media_type_lst):\n    \"\"\"\n    Returns a list of sets of media type strings, ordered by precedence.\n    Precedence is determined by how specific a media type is:\n\n    3. 'type/subtype; param=val'\n    2. 'type/subtype'\n    1. 'type/*'\n    0. '*/*'\n    \"\"\"\n    ret = [set(), set(), set(), set()]\n    for media_type in media_type_lst:\n        precedence = _MediaType(media_type).precedence\n        ret[3 - precedence].add(media_type)\n    return [media_types for media_types in ret if media_types]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the closest ancestor to cls in bases.", "response": "def nearest_base(cls, bases):\n    '''Returns the closest ancestor to cls in bases.\n    '''\n    if cls in bases:\n        return cls\n\n    dists = {base: index(mro(cls), base) for base in bases}\n    dists2 = {dist: base for base, dist in dists.items() if dist is not None}\n    if not dists2:\n        return None\n    return dists2[min(dists2)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_typename(x):\n    '''Returns the name of the type of x, if x is an object.  Otherwise, returns the name of x.\n    '''\n    if isinstance(x, type):\n        ret = x.__name__\n    else:\n        ret = x.__class__.__name__\n    return ret", "response": "Returns the name of the type of x."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True iff o1 and o2 are of the same class lineage.", "response": "def same_lineage(o1, o2):\n    '''Returns True iff o1 and o2 are of the same class lineage (that is, a direct line of descent, without branches).'''\n    def comp(x, y):\n        return issubclass(x, y) or issubclass(y, x)\n\n    if isinstance(o1, type) and isinstance(o2, type):\n        return comp(o1, o2)\n    elif not (isinstance(o1, type) or isinstance(o2, type)):\n        return comp(type(o1), type(o2))\n    raise TypeError(\"Cannot compare type and object\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getfunc(obj, name=''):\n    '''Get the function corresponding to name from obj, not the method.'''\n    if name:\n        obj = getattr(obj, name)\n    return getattr(obj, '__func__', obj)", "response": "Get the function corresponding to name from obj not the method."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the first key mapping to value as encountered via iteritems. If use_id is True returns the first key mapping to value otherwise default.", "response": "def getkey(mapping, value, default=None, use_id=False):\n    '''Returns the first key mapping to value, as encountered via iteritems(), otherwise default.  Obviously, works best for injective maps.\n    '''\n    if use_id:\n        for key, val in mapping.items():\n            if val is value:\n                return key\n    else:\n        for key, val in mapping.items():\n            if val == value:\n                return key\n    return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the string identifying the module that cls is defined in.", "response": "def get_mod(cls):\n\n    '''Returns the string identifying the module that cls is defined in.\n    '''\n    if isinstance(cls, (type, types.FunctionType)):\n        ret = cls.__module__\n    else:\n        ret = cls.__class__.__module__\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef this_module(npop=1):\n    '''Returns the module object of the module this function is called from\n    '''\n    stack = inspect.stack()\n    st = stack[npop]\n    frame = st[0]\n    return inspect.getmodule(frame)", "response": "Returns the module object of the module this function is called from\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nasserting that o1 and o2 are distinct yet equivalent objects", "response": "def assert_equivalent(o1, o2):\n    '''Asserts that o1 and o2 are distinct, yet equivalent objects\n    '''\n    if not (isinstance(o1, type) and isinstance(o2, type)):\n        assert o1 is not o2\n    assert o1 == o2\n    assert o2 == o1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef assert_inequivalent(o1, o2):\n    '''Asserts that o1 and o2 are distinct and inequivalent objects\n    '''\n    if not (isinstance(o1, type) and isinstance(o2, type)):\n        assert o1 is not o2\n    assert not o1 == o2 and o1 != o2\n    assert not o2 == o1 and o2 != o1", "response": "Asserts that o1 and o2 are distinct and inequivalent objects\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nasserting that o1 and o2 are distinct yet equivalent objects of the same type.", "response": "def assert_type_equivalent(o1, o2):\n    '''Asserts that o1 and o2 are distinct, yet equivalent objects of the same type\n    '''\n    assert o1 == o2\n    assert o2 == o1\n    assert type(o1) is type(o2)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nasserting that obj does not change (w. r. t. == ) under repeated deepcopies", "response": "def assert_deepcopy_idempotent(obj):\n    '''Assert that obj does not change (w.r.t. ==) under repeated deepcopies\n    '''\n    from copy import deepcopy\n    obj1 = deepcopy(obj)\n    obj2 = deepcopy(obj1)\n    obj3 = deepcopy(obj2)\n    assert_equivalent(obj, obj1)\n    assert_equivalent(obj, obj2)\n    assert_equivalent(obj, obj3)\n    assert type(obj) is type(obj3)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nassert that obj does not change (w. r. t == ) under repeated picklings", "response": "def assert_pickle_idempotent(obj):\n    '''Assert that obj does not change (w.r.t. ==) under repeated picklings\n    '''\n    from six.moves.cPickle import dumps, loads\n    obj1 = loads(dumps(obj))\n    obj2 = loads(dumps(obj1))\n    obj3 = loads(dumps(obj2))\n    assert_equivalent(obj, obj1)\n    assert_equivalent(obj, obj2)\n    assert_equivalent(obj, obj3)\n    assert type(obj) is type(obj3)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the charset of the message", "response": "def get_charset(message, default='ASCII'):\n    \"\"\"Get the message charset\"\"\"\n\n    charset = message.get_content_charset()\n\n    if not charset:\n        charset = message.get_charset()\n\n    if not charset:\n        charset = default\n\n    try:\n        codecs.lookup(charset)\n    except LookupError:\n        charset = default\n\n    return charset"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the body of the email message", "response": "def get_body(self):\n        \"\"\"Get the body of the email message\"\"\"\n\n        if self.is_multipart():\n            # get the plain text version only\n            text_parts = [part\n                          for part in typed_subpart_iterator(self,\n                                                             'text',\n                                                             'plain')]\n            body = []\n            for part in text_parts:\n                charset = get_charset(part, get_charset(self))\n                body.append(unicode(part.get_payload(decode=True),\n                                    charset,\n                                    \"replace\"))\n\n            return u\"\\n\".join(body).strip()\n\n        else:   # if it is not multipart, the payload will be a string\n                # representing the message body\n            body = unicode(self.get_payload(decode=True),\n                           get_charset(self),\n                           \"replace\")\n            return body.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_some_expensive_things(number):\n    result = yield batch_accumulate(1000, expensive(number))\n    total = reduce(add, result, 0)\n    log.msg(\"first for {}: {}\".format(number, total))\n\n    result = yield batch_accumulate(1000, expensive(int(total/1e9)))\n    total = reduce(add, result, 0)\n    log.msg(\"second for {}: {}\".format(number, total))\n    defer.returnValue(total)", "response": "Perform one expensive computation cooperatively with any\n     other iterator passed into twisted s cooperate then use it s result to pass into the second computation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nblock call on widgets.", "response": "def listen(self):\n        \"\"\"Blocking call on widgets.\n\n        \"\"\"\n        while self._listen:\n            key = u''\n            key = self.term.inkey(timeout=0.2)\n            try:\n                if key.code == KEY_ENTER:\n                    self.on_enter(key=key)\n                elif key.code in (KEY_DOWN, KEY_UP):\n                    self.on_key_arrow(key=key)\n                elif key.code == KEY_ESCAPE or key == chr(3):\n                    self.on_exit(key=key)\n                elif key != '':\n                    self.on_key(key=key)\n            except KeyboardInterrupt:\n                self.on_exit(key=key)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninserting new element. Usage: window.add(widget, **{ 'prop1': val, 'prop2': val2 })", "response": "def add(self, widget, *args, **kwargs):\n        \"\"\"Insert new element.\n\n        Usage:\n            window.add(widget, **{\n                'prop1': val,\n                'prop2': val2\n            })\n\n        \"\"\"\n        ins_widget = widget(*args, **kwargs)\n        self.__iadd__(ins_widget)\n        return ins_widget"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake a search string and parses it into a list of keywords and phrases.", "response": "def search_terms(q):\n    '''Takes a search string and parses it into a list of keywords and\n    phrases.'''\n    tokens = parse_search_terms(q)\n    # iterate through all the tokens and make a list of token values\n    # (which are the actual words and phrases)\n    values = []\n    for t in tokens:\n        # word/phrase\n        if t[0] is None:\n            values.append(t[1])\n        # incomplete field\n        elif t[1] is None:\n            values.append('%s:' % t[0])\n        # anything else must be a field, value pair\n        # - if value includes whitespace, wrap in quotes\n        elif re.search('\\s', t[1]):\n            values.append('%s:\"%s\"' % t)\n        # otherwise, leave unquoted\n        else:\n            values.append('%s:%s' % t)\n    return values"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pages_to_show(paginator, page, page_labels=None):\n    show_pages = {}  # FIXME; do we need OrderedDict here ?\n    if page_labels is None:\n        page_labels = {}\n\n    def get_page_label(index):\n        if index in page_labels:\n            return page_labels[index]\n        else:\n            return unicode(index)\n\n    if page != 1:\n        before = 3      # default number of pages to show before the current page\n        if page >= (paginator.num_pages - 3):   # current page is within 3 of end\n            # increase number to show before current page based on distance to end\n            before += (3 - (paginator.num_pages - page))\n        for i in range(before, 0, -1):    # add pages from before away up to current page\n            if (page - i) >= 1:\n                # if there is a page label available, use that as dictionary value\n                show_pages[page - i] = get_page_label(page - i)\n\n    # show up to 3 to 7 numbers after the current number, depending on\n    # how many we already have\n    for i in range(7 - len(show_pages)):\n        if (page + i) <= paginator.num_pages:\n            # if there is a page label available, use that as dictionary value\n            show_pages[page + i] = get_page_label(page + i)\n\n    return show_pages", "response": "Generate a dictionary of pages to show around the current page."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nzipping into db_backups_dir and uploads to bucket_name/s3_folder fab -f ./fabfile.py backup_dbs", "response": "def backup():\n    \"\"\"\n    zips into db_backups_dir and uploads to bucket_name/s3_folder\n    fab -f ./fabfile.py backup_dbs\n    \"\"\"\n\n    args = parser.parse_args()\n\n    s3_backup_dir(\n        args.datadir,\n        args.aws_access_key_id,\n        args.aws_secret_access_key,\n        args.bucket_name,\n        args.zip_backups_dir, args.backup_aging_time, args.s3_folder, args.project)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nindent a block of text.", "response": "def Indentation( logical_line,\n                 previous_logical,\n                 indent_level,\n                 previous_indent_level ):\n  \"\"\"Use two spaces per indentation level.\"\"\"\n  comment = '' if logical_line else ' (comment)'\n  if indent_level % 2:\n    code = 'YCM111' if logical_line else 'YCM114'\n    message = ' indentation is not a multiple of two spaces' + comment\n    yield 0, code + message\n  if ( previous_logical.endswith( ':' ) and\n       ( indent_level - previous_indent_level != 2 ) ):\n    code = 'YCM112' if logical_line else 'YCM115'\n    message = ' expected an indented block of {} spaces{}'.format(\n      previous_indent_level + 2, comment )\n    yield 0, code + message"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef SpacesInsideBrackets( logical_line, tokens ):\n  for index in range( len( tokens ) ):\n    _, prev_text, _, prev_end, _ = ( tokens[ index - 1 ] if index - 1 >= 0 else\n                                     ( None, None, None, None, None ) )\n    token_type, text, start, end, _ = tokens[ index ]\n    next_token_type, next_text, next_start, _, _ = (\n      tokens[ index + 1 ] if index + 1 < len( tokens ) else\n      ( None, None, None, None, None ) )\n    if text in LEFT_BRACKETS:\n      if ( next_text == CORRESPONDING_BRACKET[ text ] and\n           next_start != end ):\n        code = 'YCM204'\n        message = ( ' no spaces between {} and {}'\n                    ' for empty content'.format( text, next_text ) )\n        yield end, code + message\n      if ( next_token_type not in [ tokenize.NL, tokenize.NEWLINE ] and\n           next_text != CORRESPONDING_BRACKET[ text ] and\n           next_start and\n           next_start[ 0 ] == start[ 0 ] and\n           next_start[ 1 ] - start[ 1 ] != 2 ):\n        code = 'YCM201'\n        message = ' exactly one space required after {}'.format( text )\n        yield end, code + message\n    if text in RIGHT_BRACKETS:\n      if ( prev_text != CORRESPONDING_BRACKET[ text ] and\n           prev_end and\n           prev_end[ 0 ] == end[ 0 ] and\n           end[ 1 ] - prev_end[ 1 ] != 2 ):\n        code = 'YCM202'\n        message = ' exactly one space required before {}'.format( text )\n        yield start, code + message", "response": "Require spaces inside parentheses square brackets and braces for\n non - empty content."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuying a player at the specified cost", "response": "def buy(self, player, cost):\n        \"\"\"\n        indicate that the player was bought at the specified cost\n\n        :param Player player: player to buy\n        :param int cost: cost to pay\n\n        :raises InsufficientFundsError: if owner doesn't have the money\n        :raises NoValidRosterSlotError: if owner doesn't have a slot this player could fill\n        :raises AlreadyPurchasedError: if owner already bought this player\n        \"\"\"\n        if cost > self.max_bid():\n            raise InsufficientFundsError()\n        elif not any(roster_slot.accepts(player) and roster_slot.occupant is None for roster_slot in self.roster):\n            raise NoValidRosterSlotError()\n        elif self.owns(player):\n            raise AlreadyPurchasedError()\n\n        self.money -= cost\n        self._remaining_picks -= 1\n        self._owned_player_ids.add(player.player_id)\n        self._slot_in(player, cost)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nkeeps running this thread until it's stopped", "response": "def run(self):\n        \"\"\"Keep running this thread until it's stopped\"\"\"\n        while not self._finished.isSet():\n            self._func(self._reference)\n            self._finished.wait(self._func._interval / 1000.0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subscribe(self, clock_name: str=None, clock_slots: Iterable[str]=None, subscriptions: Dict[str, Any]={}):\n\t\tfor area in subscriptions:  # type: str\n\t\t\tinit_full(self, area, subscriptions[area])\n\t\t\tsubscriptions[area] = {'slots': subscriptions[area]}\n\n\t\tif clock_name is not None:\n\t\t\tself.clock_name = clock_name\n\t\t\tself.clock_slots = clock_slots\n\t\t\tsubscriptions[clock_name] = {'slots': clock_slots, 'buffer-length': 1}\n\t\tself.setup(puller=True, subscriptions=subscriptions)", "response": "Subscribes this Area to the given Areas and optionally given Slots."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds a module logger.", "response": "def logger(ref=0):\n    \"\"\"Finds a module logger.\n\n    If the argument passed is a module, find the logger for that module using\n    the modules' name; if it's a string, finds a logger of that name; if an\n    integer, walks the stack to the module at that height.\n\n    The logger is always extended with a ``.configure()`` method allowing\n    its log levels for syslog and stderr to be adjusted or automatically\n    initialized as per the documentation for `configure()` below.\n    \"\"\"\n    if inspect.ismodule(ref):\n        return extend(logging.getLogger(ref.__name__))\n    if isinstance(ref, basestring):\n        return extend(logging.getLogger(ref))\n    return extend(logging.getLogger(stackclimber(ref+1)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconfiguring a logger according to the specified options.", "response": "def configure(logger=None, **kwargs):\n    \"\"\"Configures a logger, according to the following rules:\n\n    * With no options set, enables ``INFO`` level on stderr if stderr is a TTY;\n      otherwise enables ``INFO`` level to Syslog.\n\n    * With ``syslog=`` and/or ``stderr=``, configures as specified.\n\n    * With ``level=``, enables either Syslog or stderr logging according to\n      whether or not stderr is a TTY, but uses the level specified.\n    \"\"\"\n    configuration = Configuration.auto(**kwargs)\n    if logger is None:\n        logger = logging.getLogger()\n    configuration(logger)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef auto(cls, syslog=None, stderr=None, level=None, extended=None,\n             server=None):\n        \"\"\"Tries to guess a sound logging configuration.\n        \"\"\"\n        level = norm_level(level) or logging.INFO\n        if syslog is None and stderr is None:\n            if sys.stderr.isatty() or syslog_path() is None:\n                log.info('Defaulting to STDERR logging.')\n                syslog, stderr = None, level\n                if extended is None:\n                    extended = (stderr or 0) <= logging.DEBUG\n            else:\n                log.info('Defaulting to logging with Syslog.')\n                syslog, stderr = level, None\n        return cls(syslog=syslog, stderr=stderr, extended=extended,\n                   server=server)", "response": "Tries to guess a sound logging configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef format(self, rec):\n        t = self.formatTime(rec, self.datefmt)\n        func = '' if rec.funcName == '<module>' else ' %s()' % rec.funcName\n        left_header_data = (t, rec.msecs, rec.name, func, rec.lineno)\n        left_header = '%s.%03d %s%s @ %d' % left_header_data\n        right_header = rec.levelname.lower()\n        spacer = 79 - 4 - len(left_header) - len(right_header)\n        top_line = left_header + ' -' + spacer * '-' + '- ' + right_header\n        lines = [_ for __ in textwrap.dedent(rec.getMessage()).splitlines()\n                 for _ in self.wrapper.wrap(__)]\n\n        # This is more or less the logic in logging.Formatter.format() for\n        # exception logging, though greatly condensed.\n        if rec.exc_info:\n            exc_text = super(Formatter, self).formatException(rec.exc_info)\n            exc_lines = exc_text.splitlines()\n            # if len(exc_lines) > 4:\n            #     exc_lines = exc_lines[:2] + ['...'] + exc_lines[-2:]\n            lines += [''] + ['  ' + l for l in exc_lines]\n\n        return top_line + '\\n' + '\\n'.join(l for l in lines)", "response": "Formats a log record into a string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_file(fd, filename=None, size=None, timestamp=None, ctype=None,\n              charset=CHARSET, attachment=False, wrapper=DEFAULT_WRAPPER):\n    \"\"\" Send a file represented by file object\n\n    This function constcuts a HTTPResponse object that uses a file descriptor\n    as response body. The file descriptor is suppled as ``fd`` argument and it\n    must have a ``read()`` method. ``ValueError`` is raised when this is not\n    the case. It supports `byte serving`_ using Range header, and makes the\n    best effort to set all appropriate headers. It also supports HEAD queries.\n\n    Because we are dealing with file descriptors and not physical files, the\n    user must also supply the file metadata such as filename, size, and\n    timestamp.\n\n    The ``filename`` argument is an arbitrary filename. It is used to guess the\n    content type, and also to set the content disposition in case of\n    attachments.\n\n    The ``size`` argument is the payload size in bytes. If it is omitted, the\n    content length header is not set, and byte serving does not work.\n\n    The ``timestamp`` argument is the number of seconds since Unix epoch when\n    the file was created or last modified. If this argument is omitted,\n    If-Modified-Since request headers cannot be honored.\n\n    To explicitly specify the content type, the ``ctype`` argument can be used.\n    This should be a valid MIME type of the payload.\n\n    Default encoding (used as charset parameter in Content-Type header) is\n    'UTF-8'. This can be overridden by using the ``charset`` argument.\n\n    The ``attachment`` argumnet can be set to ``True`` to add the\n    Content-Dispositon response header. Value of the header is then set to the\n    filename.\n\n    The ``wrapper`` argument is used to wrap the file descriptor when doing\n    byte serving. The default is to use ``fdsend.rangewrapper.RangeWrapper``\n    class, but there are alternatives as ``fdsend.rangewrapper.range_iter`` and\n    ``bottle._file_iter_range``. The wrappers provided by this package are\n    written to specifically handle file handles that do not have a ``seek()``\n    method. If this is not your case, you may safely use the bottle's wrapper.\n\n    The primary difference between ``fdsend.rangewrapper.RangeWrapper`` and\n    ``fdsend.rangewrapper.range_iter`` is that the former returns a file-like\n    object with ``read()`` method, which may or may not increase performance\n    when used on a WSGI server that supports ``wsgi.file_wrapper`` feature. The\n    latter returns an iterator and the response is returned as is without the\n    use of a ``file_wrapper``. This may have some benefits when it comes to\n    memory usage.\n\n    Benchmarking and profiling is the best way to determine which wrapper you\n    want to use, or you need to implement your own.\n\n    To implement your own wrapper, you need to create a callable or a class\n    that takes the following arguments:\n\n    - file descriptor\n    - offset (in bytes from start of the file)\n    - length (total number of bytes in the range)\n\n    The return value of the wrapper must be either an iterable or file-like\n    object that implements ``read()`` and ``close()`` methods with the usual\n    semantics.\n\n    The code is partly based on ``bottle.static_file``.\n\n    .. _byte serving: https://tools.ietf.org/html/rfc2616#page-138\n    \"\"\"\n    if not hasattr(fd, 'read'):\n        raise ValueError(\"Object '{}' has no read() method\".format(fd))\n\n    headers = {}\n    status = 200\n\n    if not ctype and filename is not None:\n        ctype, enc = mimetypes.guess_type(filename)\n        if enc:\n            headers['Content-Encoding'] = enc\n\n    if ctype:\n        if ctype.startswith('text/'):\n            # We expect and assume all text files are encoded UTF-8. It's\n            # broadcaster's job to ensure this is true.\n            ctype += '; charset=%s' % charset\n        headers['Content-Type'] = ctype\n\n    if size:\n        headers['Content-Length'] = size\n        headers['Accept-Ranges'] = 'bytes'\n\n    if timestamp:\n        headers['Last-Modified'] = format_ts(timestamp)\n\n        # Check if If-Modified-Since header is in request and respond early\n        modsince = request.environ.get('HTTP_IF_MODIFIED_SINCE')\n        print(modsince)\n        modsince = modsince and parse_date(modsince.split(';')[0].strip())\n        if modsince is not None and modsince >= timestamp:\n            headers['Date'] = format_ts()\n            return HTTPResponse(status=304, **headers)\n\n    if attachment and filename:\n        headers['Content-Disposition'] = 'attachment; filename=\"%s\"' % filename\n\n    if request.method == 'HEAD':\n        # Request is a HEAD, so remove any fd body\n        fd = ''\n\n    ranges = request.environ.get('HTTP_RANGE')\n    if size and ranges:\n        ranges = list(parse_range_header(ranges, size))\n        if not ranges:\n            return HTTPError(416, 'Request Range Not Satisfiable')\n        start, end = ranges[0]\n        headers['Content-Range'] = 'bytes %d-%d/%d' % (start, end - 1, size)\n        length = end - start\n        headers['Content-Length'] = str(length)\n        fd = wrapper(fd, start, length)\n        status = 206\n\n    return HTTPResponse(fd, status=status, **headers)", "response": "This function sends a file to the bottle server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert an element to a chainlink", "response": "def convert(self, element):\n        \"\"\"Convert an element to a chainlink\"\"\"\n        if isinstance(element, self.base_link_type):\n            return element\n        for converter in self.converters:\n            link = converter(element)\n            if link is not NotImplemented:\n                return link\n        raise TypeError('%r cannot be converted to a chainlink' % element)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_related_coref_relationships(self, content_id, min_strength=None):\n        '''Follow coreference relationships to get full related graph.\n\n        :rtype: dict mapping related identifier to list of documents\n        coref to that identifier.\n        '''\n        related_labels = self.rel_label_store.get_related(\n            content_id, min_strength=min_strength)\n        related_cids = [rel_label.other(content_id)\n                        for rel_label in related_labels]\n        related_cid_to_idents = {}\n        for cid in related_cids:\n            conn_labels = self.label_store.directly_connected(cid)\n            idents = [label.other(cid) for label in conn_labels]\n            related_cid_to_idents[cid] = idents\n        return related_cid_to_idents", "response": "Follow coreference relationships to get full related graph."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_related_flat(self, content_id, min_strength=None):\n        '''Follow coreference relationships to get full related graph.\n\n        This differs from ``get_related_coref_relationships`` in that\n        it returns a flat list of all identifiers found through the\n        coreference layer of indirection.\n\n        :rtype: list of identifiers\n        '''\n        rel_id_to_idents = self.get_related_coref_relationships(\n            content_id, min_strength=min_strength)\n        flat_list = []\n        for val in rel_id_to_idents.values():\n            flat_list.extend(val)\n        return flat_list", "response": "Follow coreference relationships to get full related graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a view class return a textual name to represent the view.", "response": "def get_view_name(view_cls, suffix=None):\n    \"\"\"\n    Given a view class, return a textual name to represent the view.\n    This name is used in the browsable API, and in OPTIONS responses.\n\n    This function is the default for the `VIEW_NAME_FUNCTION` setting.\n    \"\"\"\n    name = view_cls.__name__\n    name = formatting.remove_trailing_string(name, 'View')\n    name = formatting.remove_trailing_string(name, 'ViewSet')\n    name = formatting.camelcase_to_spaces(name)\n    if suffix:\n        name += ' ' + suffix\n\n    return name"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a view class return a textual description to represent the view.", "response": "def get_view_description(view_cls, html=False):\n    \"\"\"\n    Given a view class, return a textual description to represent the view.\n    This name is used in the browsable API, and in OPTIONS responses.\n\n    This function is the default for the `VIEW_DESCRIPTION_FUNCTION` setting.\n    \"\"\"\n    description = view_cls.__doc__ or ''\n    description = formatting.dedent(smart_text(description))\n    if html:\n        return formatting.markup_description(description)\n    return description"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the response that should be used for any given exception. By default we handle the REST framework `APIException`, and also Django's built-in `Http404` and `PermissionDenied` exceptions. Any unhandled exceptions may return `None`, which will cause a 500 error to be raised.", "response": "def exception_handler(exc, context):\n    \"\"\"\n    Returns the response that should be used for any given exception.\n\n    By default we handle the REST framework `APIException`, and also\n    Django's built-in `Http404` and `PermissionDenied` exceptions.\n\n    Any unhandled exceptions may return `None`, which will cause a 500 error\n    to be raised.\n    \"\"\"\n    if isinstance(exc, exceptions.APIException):\n        headers = {}\n        if getattr(exc, 'auth_header', None):\n            headers['WWW-Authenticate'] = exc.auth_header\n        if getattr(exc, 'wait', None):\n            headers['Retry-After'] = '%d' % exc.wait\n\n        if isinstance(exc.detail, (list, dict)):\n            data = exc.detail\n        else:\n            data = {'message': exc.detail}\n\n        set_rollback()\n        return Response(data, status=exc.status_code, headers=headers)\n\n    elif isinstance(exc, Http404):\n        msg = _('Not found.')\n        data = {'message': six.text_type(msg)}\n\n        set_rollback()\n        return Response(data, status=status.HTTP_404_NOT_FOUND)\n\n    elif isinstance(exc, PermissionDenied):\n        msg = _('Permission denied.')\n        data = {'message': six.text_type(msg)}\n\n        set_rollback()\n        return Response(data, status=status.HTTP_403_FORBIDDEN)\n\n    # Note: Unhandled exceptions will raise a 500 error.\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\noverride as_view to allow us to discover information about the view.", "response": "def as_view(cls, **initkwargs):\n        \"\"\"\n        Store the original class on the view function.\n\n        This allows us to discover information about the view when we do URL\n        reverse lookups.  Used for breadcrumb generation.\n        \"\"\"\n        if isinstance(getattr(cls, 'queryset', None), models.query.QuerySet):\n            def force_evaluation():\n                raise RuntimeError(\n                    'Do not evaluate the `.queryset` attribute directly, '\n                    'as the result will be cached and reused between requests. '\n                    'Use `.all()` or call `.get_queryset()` instead.'\n                )\n            cls.queryset._fetch_all = force_evaluation\n            cls.queryset._result_iter = force_evaluation  # Django <= 1.5\n\n        view = super(RestView, cls).as_view(**initkwargs)\n        view.cls = cls\n\n        # Note: session based authentication is explicitly CSRF validated,\n        # all other authentication is CSRF exempt.\n        return csrf_exempt(view)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef permission_denied(self, request, message=None):\n        if not request.successful_authenticator:\n            raise exceptions.NotAuthenticated()\n        raise exceptions.PermissionDenied(detail=message)", "response": "Raises an exception if the request is not permitted."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the view name as used in OPTIONS responses and in the browsable API.", "response": "def get_view_name(self):\n        \"\"\"\n        Return the view name, as used in OPTIONS responses and in the\n        browsable API.\n        \"\"\"\n        func = self.settings.VIEW_NAME_FUNCTION\n        return func(self.__class__, getattr(self, 'suffix', None))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn some descriptive text for the view.", "response": "def get_view_description(self, html=False):\n        \"\"\"\n        Return some descriptive text for the view, as used in OPTIONS responses\n        and in the browsable API.\n        \"\"\"\n        func = self.settings.VIEW_DESCRIPTION_FUNCTION\n        return func(self.__class__, html)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetermine if the request includes a. json style format suffix.", "response": "def get_format_suffix(self, **kwargs):\n        \"\"\"\n        Determine if the request includes a '.json' style format suffix\n        \"\"\"\n        if self.settings.FORMAT_SUFFIX_KWARG:\n            return kwargs.get(self.settings.FORMAT_SUFFIX_KWARG)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming content negotiation on the content negotiation.", "response": "def perform_content_negotiation(self, request, force=False):\n        \"\"\"\n        Determine which renderer and media type to use render the response.\n        \"\"\"\n        renderers = self.get_renderers()\n        conneg = self.get_content_negotiator()\n\n        try:\n            return conneg.select_renderer(request, renderers, self.format_kwarg)\n        except Exception:\n            if force:\n                return (renderers[0], renderers[0].media_type)\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_throttles(self, request):\n        for throttle in self.get_throttles():\n            if not throttle.allow_request(request, self):\n                self.throttled(request, throttle.wait())", "response": "Checks if the request should be throttled. Raises an appropriate exception if the request should be throttled."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining the API version for the current request.", "response": "def determine_version(self, request, *args, **kwargs):\n        \"\"\"\n        If versioning is being used, then determine any API version for the\n        incoming request. Returns a two-tuple of (version, versioning_scheme)\n        \"\"\"\n        if self.versioning_class is None:\n            return (None, None)\n        scheme = self.versioning_class()\n        return (scheme.determine_version(request, *args, **kwargs), scheme)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initialize_request(self, request, *args, **kwargs):\n        parser_context = self.get_parser_context(request)\n\n        return Request(\n            request,\n            parsers=self.get_parsers(),\n            authenticators=self.get_authenticators(),\n            negotiator=self.get_content_negotiator(),\n            parser_context=parser_context\n        )", "response": "Initializes the request object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initial(self, request, *args, **kwargs):\n        self.format_kwarg = self.get_format_suffix(**kwargs)\n\n        # Ensure that the incoming request is permitted\n        self.perform_authentication(request)\n        self.check_permissions(request)\n        self.check_throttles(request)\n\n        # Perform content negotiation and store the accepted info on the request\n        neg = self.perform_content_negotiation(request)\n        request.accepted_renderer, request.accepted_media_type = neg\n\n        # Determine the API version, if versioning is in use.\n        version, scheme = self.determine_version(request, *args, **kwargs)\n        request.version, request.versioning_scheme = version, scheme", "response": "Runs everything that needs to occur prior to calling the method handler."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef finalize_response(self, request, response, *args, **kwargs):\n        # Make the error obvious if a proper response is not returned\n        assert isinstance(response, HttpResponseBase), (\n            'Expected a `Response`, `HttpResponse` or `HttpStreamingResponse` '\n            'to be returned from the view, but received a `%s`'\n            % type(response)\n        )\n\n        if isinstance(response, Response):\n            if not getattr(request, 'accepted_renderer', None):\n                neg = self.perform_content_negotiation(request, force=True)\n                request.accepted_renderer, request.accepted_media_type = neg\n\n            response.accepted_renderer = request.accepted_renderer\n            response.accepted_media_type = request.accepted_media_type\n            response.renderer_context = self.get_renderer_context()\n\n        for key, value in self.headers.items():\n            response[key] = value\n\n        return response", "response": "Finalizes the response object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle_exception(self, exc):\n        if isinstance(exc, (exceptions.NotAuthenticated,\n                            exceptions.AuthenticationFailed)):\n            # WWW-Authenticate header for 401 responses, else coerce to 403\n            auth_header = self.get_authenticate_header(self.request)\n\n            if auth_header:\n                exc.auth_header = auth_header\n            else:\n                exc.status_code = status.HTTP_403_FORBIDDEN\n\n        exception_handler = self.settings.EXCEPTION_HANDLER\n\n        context = self.get_exception_handler_context()\n        response = exception_handler(exc, context)\n\n        if response is None:\n            raise\n\n        response.exception = True\n        return response", "response": "Handle any exception that occurs by returning an appropriate response."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef options(self, request, *args, **kwargs):\n        if self.metadata_class is None:\n            return self.http_method_not_allowed(request, *args, **kwargs)\n        data = self.metadata_class().determine_metadata(request, self)\n        return Response(data, status=status.HTTP_200_OK)", "response": "Handle HTTP OPTIONS requests."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_subkey(self,name,value=None):\n        self.sam |= KEY_CREATE_SUB_KEY\n        subkey = Key(name,self)\n        try:\n            subkey = self.get_subkey(name)\n        except AttributeError:\n            _winreg.CreateKey(self.hkey,name)\n            subkey = self.get_subkey(name)\n        if value is None:\n            pass\n        elif issubclass(type(value),type) and issubclass(value,Key):\n            pass\n        elif isinstance(value,Key):\n            for v in value.values():\n                subkey[v.name] = v\n            for k in value.subkeys():\n                subkey.set_subkey(k.name,k)\n        elif isinstance(value,dict):\n            for (nm,val) in value.items():\n                if isinstance(val,dict):\n                    subkey.set_subkey(nm,val)\n                elif isinstance(val,Key):\n                    subkey.set_subkey(nm,val)\n                elif issubclass(type(val),type) and issubclass(val,Key):\n                    subkey.set_subkey(nm,val)\n                else:\n                    subkey[nm] = val\n        else:\n            if not isinstance(value,Value):\n                value = Value(value)\n            subkey[value.name] = value", "response": "Create the named subkey and set its value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete the named subkey and any values or keys it contains.", "response": "def del_subkey(self,name):\n        \"\"\"Delete the named subkey, and any values or keys it contains.\"\"\"\n        self.sam |= KEY_WRITE\n        subkey = self.get_subkey(name)\n        subkey.clear()\n        _winreg.DeleteKey(subkey.parent.hkey,subkey.name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clear(self):\n        self.sam |= KEY_WRITE\n        for v in list(self.values()):\n            del self[v.name]\n        for k in list(self.subkeys()):\n            self.del_subkey(k.name)", "response": "Remove all subkeys and values from this key."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef publish(self):\n\n        try:\n             for collection in self.settings.get(\"scheduler\").get(\"collections\"):\n                yield self.publish_for_collection(collection)\n        except Exception as ex:\n            self.logger.error(ex)", "response": "Iterate over the scheduler collections and apply any actions found\n ZMQ."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset all revisions found to in process so that other threads will not pick them up.", "response": "def set_all_revisions_to_in_process(self, ids):\n        \"\"\"\n        Set all revisions found to in process, so that other threads will not pick them up.\n\n        :param list ids:\n        \"\"\"\n\n        predicate = {\n            \"_id\" : {\n                \"$in\" : [ ObjectId(id) for id in ids ]\n            }\n        }\n\n        set = {\"$set\": { \"inProcess\": True }}\n\n        yield self.revisions.collection.update(predicate, set, multi=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all the pending revisions after the current time", "response": "def __get_pending_revisions(self):\n        \"\"\"\n        Get all the pending revisions after the current time\n\n        :return: A list of revisions\n        :rtype: list\n\n        \"\"\"\n        dttime = time.mktime(datetime.datetime.now().timetuple())\n        changes = yield self.revisions.find({\n            \"toa\" : {\n                \"$lt\" : dttime,\n            },\n            \"processed\": False,\n            \"inProcess\": None\n        })\n        if len(changes) > 0:\n            yield self.set_all_revisions_to_in_process([change.get(\"id\") for change in changes])\n\n        raise Return(changes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef publish_for_collection(self, collection_name):\n        self.revisions = BaseAsyncMotorDocument(\"%s_revisions\" % collection_name, self.settings)\n\n        changes = yield self.__get_pending_revisions()\n\n        if len(changes) > 0:\n\n            self.logger.info(\"%s revisions will be actioned\" % len(changes))\n\n            for change in changes:\n                try:\n                    self.logger.info(\"Applying %s action %s - %s to document: %s/%s\" % (change.get(\"action\"), change.get(\"id\"), change.get(\"meta\",{}).get(\"comment\", \"No Comment\"), change.get(\"collection\"), change.get(\"master_id\")))\n\n                    stack = AsyncSchedulableDocumentRevisionStack(\n                        change.get(\"collection\"),\n                        self.settings,\n                        master_id=change.get(\"master_id\")\n                    )\n\n                    revision = yield stack.pop()\n\n                    self.logger.debug(revision)\n\n                except Exception as ex:\n                    self.logger.error(ex)", "response": "Run the publishing operations for a given collection"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating a master document and revision history document", "response": "def __update_action(self, revision):\n        \"\"\"Update a master document and revision history document\n\n        :param dict revision: The revision dictionary\n        \"\"\"\n\n        patch = revision.get(\"patch\")\n        if patch.get(\"_id\"):\n            del patch[\"_id\"]\n\n        update_response = yield self.collection.patch(revision.get(\"master_id\"), self.__make_storeable_patch_patchable(patch))\n\n        if update_response.get(\"n\") == 0:\n            raise RevisionNotFoundException()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling the insert action type.", "response": "def __insert_action(self, revision):\n        \"\"\"\n        Handle the insert action type.\n\n        Creates new document to be created in this collection.\n        This allows you to stage a creation of an object\n\n        :param dict revision: The revision dictionary\n\n        \"\"\"\n\n        revision[\"patch\"][\"_id\"] = ObjectId(revision.get(\"master_id\"))\n\n        insert_response = yield self.collection.insert(revision.get(\"patch\"))\n\n        if not isinstance(insert_response, str):\n            raise DocumentRevisionInsertFailed()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __delete_action(self, revision):\n        delete_response = yield self.collection.delete(revision.get(\"master_id\"))\n        if delete_response.get(\"n\") == 0:\n            raise DocumentRevisionDeleteFailed()", "response": "Handle a delete action to a partiular master id via the revision."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pop(self):\n        revisions = yield self.list()\n\n        if len(revisions) > 0:\n            revision = revisions[0]\n\n            # Update type action\n            if revision.get(\"action\") == self.UPDATE_ACTION:\n                try:\n                    yield self.__update_action(revision)\n                except Exception as ex:\n                    self.logger.error(ex)\n\n            # Insert type update\n            if revision.get(\"action\") == self.INSERT_ACTION:\n                try:\n                    yield self.__insert_action(revision)\n                except Exception as ex:\n                    self.logger.error(ex)\n\n            #Get the updated object for attachment to the snapshot\n            snapshot_object = yield self.collection.find_one_by_id(revision.get(\"master_id\"))\n\n            #Handle delete action here\n            if revision.get(\"action\") == self.DELETE_ACTION:\n                try:\n                    yield self.__delete_action(revision)\n                except Exception as ex:\n                    self.logger.error(ex)\n\n                snapshot_object = None\n\n            #Update the revision to be in a post-process state including snapshot\n            revision_update_response = yield self.revisions.patch(revision.get(\"id\"),\n                {\n                    \"processed\" : True,\n                    \"snapshot\" : snapshot_object,\n                    \"inProcess\": False\n                }\n            )\n\n            if revision_update_response.get(\"n\") == 0:\n                raise RevisionUpdateFailed(msg=\"revision document update failed\")\n\n            revision = yield self.revisions.find_one_by_id(revision.get(\"id\"))\n\n            #TODO: Make this callback method something that can be passed in.  This was used in\n            #the original implementation to send back to the client via websocket\n            #revision_success.send('revision_success', type=\"RevisionSuccess\", data=revision)\n\n            raise Return(revision)\n\n        raise Return(None)", "response": "Pop the top revision off the stack. This method applies the action. This method will return the revision object that was created and updated."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __make_patch_storeable(self, patch):\n        new_patch = {}\n        for key in patch:\n            new_patch[key.replace(\".\", \"|\")] = patch[key]\n\n        return new_patch", "response": "Make a patch that can be applied to the future\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __make_storeable_patch_patchable(self, patch):\n\n        new_patch = {}\n        for key in patch:\n            new_patch[key.replace(\"|\", \".\")] = patch[key]\n\n        return new_patch", "response": "Make a patch that can be applied to a namespace path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef push(self, patch=None, toa=None, meta=None):\n\n        if not meta:\n            meta = {}\n\n        if not toa:\n            toa = time.mktime(datetime.datetime.now().timetuple())\n\n        if not isinstance(toa, int):\n            toa = int(toa)\n\n        #Documents should be stored in bson formats\n        if isinstance(patch, dict):\n            patch = self.revisions._dictionary_to_cursor(patch)\n\n        action = None\n\n        if isinstance(patch, type(None)):\n            action = self.DELETE_ACTION\n        elif self.master_id and isinstance(patch, dict):\n            action = self.UPDATE_ACTION\n            patch = self.__make_patch_storeable(patch)\n            yield self._lazy_migration(meta=copy.deepcopy(meta), toa=toa-1)\n\n        elif not self.master_id and isinstance(patch, dict):\n            #Scheduled inserts will not have an object ID and one should be generated\n            action = self.INSERT_ACTION\n            patch[\"_id\"] = ObjectId()\n            self.master_id = patch[\"_id\"].__str__()\n\n        elif not action:\n            raise RevisionActionNotValid()\n\n        # We shall never store the _id to a patch dictionary\n        if patch and patch.get(\"_id\"):\n            del patch[\"_id\"]\n\n        change = {\n            \"toa\": toa,\n            \"processed\": False,\n            \"collection\": self.collection_name,\n            \"master_id\": self.master_id,\n            \"action\": action,\n            \"patch\" : None if action == self.DELETE_ACTION else self.collection._dictionary_to_cursor(patch),\n            \"meta\": meta\n        }\n\n        jsonschema.validate(change, self.SCHEMA)\n\n        id = yield self.revisions.insert(change)\n\n        raise Return(id)", "response": "Push a change on to the revision stack."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning all revisions for this stack.", "response": "def list(self, toa=None, show_history=False):\n        \"\"\"Return all revisions for this stack\n\n        :param int toa: The time of action as a UTC timestamp\n        :param bool show_history: Whether to show historical revisions\n        \"\"\"\n        if not toa:\n            toa = time.mktime(datetime.datetime.now().timetuple())\n\n        query = {\n            \"$query\": {\n                \"master_id\": self.master_id,\n                \"processed\": show_history,\n                \"toa\" : {\"$lte\" : toa}\n            },\n            \"$orderby\": {\n                \"toa\": 1\n            }\n        }\n\n        revisions = yield self.revisions.find(query)\n\n        raise Return(revisions)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle when a revision scheduling is turned onto a collection that was previously not scheduleable. This method will create the first revision for each object before its every used in the context of scheduling. :param dict patch: The patch that should be used :param dict meta: Meta data for this action :param int toa: The time of action :return: A legacy revision for a document that was previously :rtype: list", "response": "def _lazy_migration(self, patch=None, meta=None, toa=None):\n        \"\"\"\n        Handle when a revision scheduling is turned onto a collection that was previously not scheduleable.\n        This method will create the first revision for each object before its every used in the context of scheduling.\n\n        :param dict patch: The patch that should be used\n        :param dict meta: Meta data for this action\n        :param int toa: The time of action\n        :return: A legacy revision for a document that was previously\n        :rtype: list\n        \"\"\"\n        objects = yield self.revisions.find({\"master_id\": self.master_id}, limit=1)\n\n        if len(objects) > 0:\n            raise Return(objects)\n\n        if not patch:\n            patch = yield self.collection.find_one_by_id(self.master_id)\n\n        if not toa:\n             toa = long(time.mktime(datetime.datetime.now().timetuple()))\n\n        meta[\"comment\"] = \"This document was migrated automatically.\"\n\n        if isinstance(patch, dict) and patch.get(\"id\"):\n            del patch[\"id\"]\n\n        if isinstance(patch, dict) and patch.get(\"_id\"):\n            del patch[\"_id\"]\n\n        #Here we separate patch and snapshot, and make sure that the snapshot looks like the master document\n        snapshot = copy.deepcopy(patch)\n        snapshot[\"id\"] = self.master_id\n        snapshot[\"published\"] = self.settings.get(\"scheduler\", {}).get(\"lazy_migrated_published_by_default\", False)\n\n        #If no objects are returned, this is some legacy object that needs a first revision\n        #Create it here\n        legacy_revision = {\n            \"toa\": toa,\n            \"processed\": True,\n            \"collection\": self.collection_name,\n            \"master_id\": self.master_id,\n            \"action\": self.INSERT_ACTION,\n            \"patch\": self.collection._dictionary_to_cursor(patch),\n            \"snapshot\": snapshot,\n            \"meta\": meta,\n        }\n\n        response = yield self.revisions.insert(legacy_revision)\n        if isinstance(response, str):\n            raise Return([legacy_revision])\n\n        raise Return(None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a preview object base for a given dictionary.", "response": "def __create_preview_object_base(self, dct):\n        \"\"\"\n        The starting point for a preview of a future object.\n        This is the object which will have future revisions iterated and applied to.\n\n        :param dict dct: The starting object dictionary\n        :return: The preview object id\n        :rtype: str\n\n        \"\"\"\n        if dct.get(\"_id\"):\n            del dct[\"_id\"]\n\n        preview_object_id = yield self.previews.insert(dct)\n\n        raise Return(preview_object_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget an ephemeral preview of a revision with all revisions applied between it and the current state.", "response": "def preview(self, revision_id):\n        \"\"\"Get an ephemeral preview of a revision with all revisions applied between it and the current state\n\n        :param str revision_id: The ID of the revision state you want to preview the master id at.\n        :return: A snapshot of a future state of the object\n        :rtype: dict\n        \"\"\"\n\n        target_revision = yield self.revisions.find_one_by_id(revision_id)\n\n        if isinstance(target_revision.get(\"snapshot\"), dict):\n            raise Return(target_revision)\n\n        preview_object = None\n\n        if not isinstance(target_revision, dict):\n            raise RevisionNotFound()\n\n        revision_collection_client = BaseAsyncMotorDocument(target_revision.get(\"collection\"), self.settings)\n\n        self.master_id = target_revision.get(\"master_id\")\n\n        action = target_revision.get(\"action\")\n\n        if action == self.DELETE_ACTION:\n            raise Return(preview_object)\n\n        if action in [self.INSERT_ACTION, self.UPDATE_ACTION]:\n\n            revisions = yield self.list(toa=target_revision.get(\"toa\"))\n\n            if len(revisions) == 0:\n                raise NoRevisionsAvailable()\n\n            first_revision = revisions[0]\n            current_document = None\n\n\n            if first_revision.get(\"action\") == self.UPDATE_ACTION:\n                current_document = yield revision_collection_client.find_one_by_id(target_revision.get(\"master_id\"))\n\n            elif first_revision.get(\"action\") == self.INSERT_ACTION:\n                # If we are doing an insert, the first revision patch is the current state\n                current_document = first_revision.get(\"patch\")\n\n            if not current_document:\n                raise RevisionNotFound()\n\n            preview_id = yield self.__create_preview_object_base(current_document)\n\n            for revision in revisions:\n                patch = revision.get(\"patch\")\n\n                if patch.get(\"_id\"):\n                    del patch[\"_id\"]\n\n                yield self.previews.patch(preview_id, self.__make_storeable_patch_patchable(patch))\n\n            preview_object = yield self.previews.find_one_by_id(preview_id)\n\n\n            preview_object[\"id\"] = target_revision[\"id\"]\n            target_revision[\"snapshot\"] = self.collection._obj_cursor_to_dictionary(preview_object)\n            target_revision[\"snapshot\"][\"id\"] = target_revision[\"master_id\"]\n\n            # Delete the last preview\n            yield self.previews.delete(preview_id)\n\n        raise Return(target_revision)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef insert(self, dct, toa=None, comment=\"\"):\n        if self.schema:\n            jsonschema.validate(dct, self.schema)\n\n        bson_obj = yield self.collection.insert(dct)\n\n        raise Return(bson_obj.__str__())", "response": "Create a new document with the given dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef upsert(self, _id, dct, attribute=\"_id\"):\n\n        mongo_response = yield self.update(_id, dct, upsert=True, attribute=attribute)\n\n        raise Return(mongo_response)", "response": "Update or Insert a new document with the given id and dictionary dct."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, predicate_value, dct, upsert=False, attribute=\"_id\"):\n        if self.schema:\n            jsonschema.validate(dct, self.schema)\n\n        if attribute==\"_id\" and not isinstance(predicate_value, ObjectId):\n            predicate_value = ObjectId(predicate_value)\n\n        predicate = {attribute: predicate_value}\n\n\n        dct = self._dictionary_to_cursor(dct)\n\n        mongo_response = yield self.collection.update(predicate, dct, upsert)\n\n        raise Return(self._obj_cursor_to_dictionary(mongo_response))", "response": "Update an existing document with the given predicate value and dictionary dct."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef patch(self, predicate_value, attrs, predicate_attribute=\"_id\"):\n\n        if predicate_attribute==\"_id\" and not isinstance(predicate_value, ObjectId):\n            predicate_value = ObjectId(predicate_value)\n\n        predicate = {predicate_attribute: predicate_value}\n\n        dct = self._dictionary_to_cursor(attrs)\n\n        if dct.get(\"_id\"):\n            del dct[\"_id\"]\n\n        set = { \"$set\": dct }\n\n        mongo_response = yield self.collection.update(predicate, set, False)\n\n        raise Return(self._obj_cursor_to_dictionary(mongo_response))", "response": "Update an existing document via a $set query"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting a document or create a DELETE revision", "response": "def delete(self, _id):\n        \"\"\"Delete a document or create a DELETE revision\n\n        :param str _id: The ID of the document to be deleted\n        :returns: JSON Mongo client response including the \"n\" key to show number of objects effected\n        \"\"\"\n        mongo_response = yield self.collection.remove({\"_id\": ObjectId(_id)})\n\n        raise Return(mongo_response)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_one(self, query):\n        mongo_response = yield self.collection.find_one(query)\n        raise Return(self._obj_cursor_to_dictionary(mongo_response))", "response": "Find one wrapper with conversion to dictionary\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds a document by any criteria.", "response": "def find(self, query, orderby=None, order_by_direction=1, page=0, limit=0):\n        \"\"\"Find a document by any criteria\n\n        :param dict query: The query to perform\n        :param str orderby: The attribute to order results by\n        :param int order_by_direction: 1 or -1\n        :param int page: The page to return\n        :param int limit: Number of results per page\n        :returns: A list of results\n        :rtype: list\n\n        \"\"\"\n\n        cursor = self.collection.find(query)\n\n        if orderby:\n            cursor.sort(orderby, order_by_direction)\n\n        cursor.skip(page*limit).limit(limit)\n\n        results = []\n        while (yield cursor.fetch_next):\n            results.append(self._obj_cursor_to_dictionary(cursor.next_object()))\n\n        raise Return(results)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_one_by_id(self, _id):\n        document = (yield self.collection.find_one({\"_id\": ObjectId(_id)}))\n        raise Return(self._obj_cursor_to_dictionary(document))", "response": "Find a single document by id"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an index on a given attribute", "response": "def create_index(self, index, index_type=GEO2D):\n        \"\"\"Create an index on a given attribute\n\n        :param str index: Attribute to set index on\n        :param str index_type: See PyMongo index types for further information, defaults to GEO2D index.\n        \"\"\"\n        self.logger.info(\"Adding %s index to stores on attribute: %s\" % (index_type, index))\n        yield self.collection.create_index([(index, index_type)])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch based on location and other attribute filters", "response": "def location_based_search(self, lng, lat, distance, unit=\"miles\", attribute_map=None, page=0, limit=50):\n        \"\"\"Search based on location and other attribute filters\n\n        :param long lng: Longitude parameter\n        :param long lat: Latitude parameter\n        :param int distance: The radius of the query\n        :param str unit: The unit of measure for the query, defaults to miles\n        :param dict attribute_map: Additional attributes to apply to the location bases query\n        :param int page: The page to return\n        :param int limit: Number of results per page\n        :returns: List of objects\n        :rtype: list\n        \"\"\"\n\n        #Determine what type of radian conversion you want base on a unit of measure\n        if unit == \"miles\":\n            distance = float(distance/69)\n        else:\n            distance = float(distance/111.045)\n\n        #Start with geospatial query\n        query = {\n            \"loc\" : {\n                \"$within\": {\n                    \"$center\" : [[lng, lat], distance]}\n                }\n        }\n\n        #Allow querying additional attributes\n        if attribute_map:\n            query = dict(query.items() + attribute_map.items())\n\n        results = yield self.find(query, page=page, limit=limit)\n\n        raise Return(self._list_cursor_to_json(results))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake a raw dictionary representation and adapt it back to a proper mongo document", "response": "def _dictionary_to_cursor(self, obj):\n        \"\"\"\n        Take a raw dictionary representation and adapt it back to a proper mongo document dictionary\n        :param dict obj: The object to adapt\n        :return: a mongo document with complex types for storage in mongo\n        :rtype: dict\n        \"\"\"\n        if obj.get(\"id\"):\n            obj[\"_id\"] = ObjectId(obj.get(\"id\"))\n            del obj[\"id\"]\n\n        if isinstance(obj.get(\"_id\"), str):\n            obj[\"_id\"] = ObjectId(obj.get(\"_id\"))\n\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _obj_cursor_to_dictionary(self, cursor):\n        if not cursor:\n            return cursor\n\n        cursor = json.loads(json.dumps(cursor, cls=BSONEncoder))\n\n        if cursor.get(\"_id\"):\n            cursor[\"id\"] = cursor.get(\"_id\")\n            del cursor[\"_id\"]\n\n        return cursor", "response": "Handle conversion of pymongo cursor into a JSON object formatted for UI consumption\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef default(self, obj, **kwargs):\n        if isinstance(obj, datetime.datetime):\n            return time.mktime(obj.timetuple())\n\n        if isinstance(obj, Timestamp):\n            return obj.time\n\n        if isinstance(obj, ObjectId):\n            return obj.__str__()\n\n        return JSONEncoder.default(self, obj)", "response": "Handle the adapting of special types from mongo"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets an array of MXRecords associated to the specified domain.", "response": "def get_mx_records(domain):\n        \"\"\"\n        Gets an array of MXRecords associated to the domain specified.\n\n        :param domain:\n        :return: [MXRecord]\n        \"\"\"\n\n        DNS.DiscoverNameServers()\n        request = DNS.Request()\n        response = request.req(name=domain, qtype=DNS.Type.MX)\n\n        mx_records = []\n        for answer in response.answers:\n            mx_records.append(MXRecord(priority=answer['data'][0], exchange=answer['data'][1], domain=domain))\n\n        return sorted(mx_records, key=lambda record: record.priority)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget an array of MXRecords associated to the specified domain.", "response": "def get_mx_records(domain):\n        \"\"\"\n        Gets an array of MXRecords associated to the domain specified.\n\n        :param domain:\n        :return: [MXRecord]\n        \"\"\"\n        import dns.resolver\n\n        response = dns.resolver.query(domain, 'MX')\n\n        mx_records = []\n        for answer in response.answers:\n            mx_records.append(MXRecord(priority=answer.preference, exchange=answer.exchange, domain=domain))\n\n        return sorted(mx_records, key=lambda record: record.priority)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the references to dependent components.", "response": "def set_references(self, references):\n        \"\"\"\n        Sets references to dependent components.\n\n        :param references: references to locate the component dependencies.\n        \"\"\"\n        super(CompositeLogger, self).set_references(references)\n        # descriptor = Descriptor(None, \"logger\", None, None, None)\n        loggers = references.get_optional(Descriptor(None, \"logger\", None, None, None))\n        for logger in loggers:\n            if isinstance(logger, ILogger):\n                self._loggers.append(logger)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _write(self, level, correlation_id, error, message):\n        for logger in self._loggers:\n            logger.log(level, correlation_id, error, message)", "response": "Writes a log message to the destination logger."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _tdec(code: str, unit: str = 'C') -> str:\n    ret = f\"{'-' if code[0] == '1' else ''}{int(code[1:3])}.{code[3]}\"\n    if unit:\n        ret += f'\u00b0{unit}'\n    return ret", "response": "Translate a 4 - digit decimal temperature representation to a 3 - digit decimal temperature representation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pressure_tendency(code: str, unit: str = 'mb') -> str:\n    width, precision = int(code[2:4]), code[4]\n    return ('3-hour pressure difference: +/- '\n            f'{width}.{precision} {unit} - {PRESSURE_TENDENCIES[code[1]]}')", "response": "Translate a 5 - digit pressure outlook code into a 3 - hour pressure difference string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(rmk: str) -> RemarksData:\n    rmkdata = {}\n    for item in rmk.split(' '):\n        if len(item) in [5, 9] and item[0] == 'T' and item[1:].isdigit():\n            rmkdata['temperature_decimal'] = core.make_number(_tdec(item[1:5], None))  # type: ignore\n            rmkdata['dewpoint_decimal'] = core.make_number(_tdec(item[5:], None))  # type: ignore\n    return RemarksData(**rmkdata)", "response": "Parses a remarks resource element into a RemarksData object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntranslates elements in the remarks string into a dictionary of strings.", "response": "def translate(remarks: str) -> typing.Dict[str, str]:  # noqa\n    \"\"\"\n    Translates elements in the remarks string\n    \"\"\"\n    ret = {}\n    # Add and replace static multi-word elements\n    for key in REMARKS_GROUPS:\n        if key in remarks:\n            ret[key.strip()] = REMARKS_GROUPS[key]\n            remarks.replace(key, ' ')\n    # For each remaining element\n    for rmk in remarks.split()[1:]:\n        rlen = len(rmk)\n        # Static single-word elements\n        if rmk in REMARKS_ELEMENTS:\n            ret[rmk] = REMARKS_ELEMENTS[rmk]\n        # Digit-only encoded elements\n        elif rmk.isdigit():\n            if rlen == 5 and rmk[0] in LEN5_DECODE:\n                rmk_ = LEN5_DECODE[rmk[0]](rmk)  # type: ignore\n                ret[rmk] = rmk_\n            # 24-hour min/max temperature\n            elif rlen == 9:\n                ret[rmk] = f'24-hour temperature: max {_tdec(rmk[1:5])} min {_tdec(rmk[5:])}'\n        # Sea level pressure: SLP218\n        elif rmk.startswith('SLP'):\n            ret[rmk] = f'Sea level pressure: 10{rmk[3:5]}.{rmk[5]} hPa'\n        # Temp/Dew with decimal: T02220183\n        elif rlen == 9 and rmk[0] == 'T' and rmk[1:].isdigit():\n            ret[rmk] = f'Temperature {_tdec(rmk[1:5])} and dewpoint {_tdec(rmk[5:])}'\n        # Precipitation amount: P0123\n        elif rlen == 5 and rmk[0] == 'P' and rmk[1:].isdigit():\n            ret[rmk] = f'Hourly precipitation: {int(rmk[1:3])}.{rmk[3:]} in.'\n        # Weather began/ended\n        elif rlen == 5 and rmk[2] in ('B', 'E') and rmk[3:].isdigit() and rmk[:2] in WX_TRANSLATIONS:\n            state = 'began' if rmk[2] == 'B' else 'ended'\n            ret[rmk] = f'{WX_TRANSLATIONS[rmk[:2]]} {state} at :{rmk[3:]}'\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncleaning the cell according to the cell type.", "response": "def clean_cell(self, cell, cell_type):\n        \"\"\"\n        Uses the type of field (from the mapping) to\n        determine how to clean and format the cell.\n        \"\"\"\n        try:\n            # Get rid of non-ASCII characters\n            cell = cell.encode('ascii', 'ignore').decode()\n            if cell_type == 'D':\n                cell = datetime.strptime(cell, '%Y%m%d')\n            elif cell_type == 'I':\n                cell = int(cell)\n            elif cell_type == 'N':\n                cell = Decimal(cell)\n            else:\n                cell = cell.upper()\n\n                if len(cell) > 50:\n                    cell = cell[0:50]\n\n                if not cell or cell in NULL_TERMS:\n                    cell = None\n\n        except:\n            cell = None\n\n        return cell"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_row(self):\n        fields = self.mapping\n        for i, cell in enumerate(self.row[0:len(fields)]):\n            field_name, field_type = fields[str(i)]\n            parsed_cell = self.clean_cell(cell, field_type)\n            self.parsed_row[field_name] = parsed_cell", "response": "Parses a row - by - cell returning a dict of field names\n            to the cleaned field values."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild the mappings for the current object.", "response": "def build_mappings(self):\n        \"\"\"\n        Uses CSV files of field names and positions for\n        different filing types to load mappings into memory,\n        for use in parsing different types of rows.\n        \"\"\"\n        self.mappings = {}\n        for record_type in ('sa', 'sb', 'F8872'):\n            path = os.path.join(\n                os.path.dirname(\n                    os.path.dirname(\n                        os.path.dirname(__file__))),\n                'mappings',\n                '{}.csv'.format(record_type))\n            mapping = {}\n            with open(path, 'r') as csvfile:\n                reader = csv.DictReader(csvfile)\n                for row in reader:\n                    mapping[row['position']] = (\n                        row['model_name'],\n                        row['field_type'])\n\n            self.mappings[record_type] = mapping"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef diff(full, dataset_uri, reference_dataset_uri):\n\n    def echo_header(desc, ds_name, ref_ds_name, prop):\n        click.secho(\"Different {}\".format(desc), fg=\"red\")\n        click.secho(\"ID, {} in '{}', {} in '{}'\".format(\n            prop, ds_name, prop, ref_ds_name))\n\n    def echo_diff(diff):\n        for d in diff:\n            line = \"{}, {}, {}\".format(d[0], d[1], d[2])\n            click.secho(line)\n\n    ds = dtoolcore.DataSet.from_uri(dataset_uri)\n    ref_ds = dtoolcore.DataSet.from_uri(reference_dataset_uri)\n\n    num_items = len(list(ref_ds.identifiers))\n\n    ids_diff = diff_identifiers(ds, ref_ds)\n    if len(ids_diff) > 0:\n        echo_header(\"identifiers\", ds.name, ref_ds.name, \"present\")\n        echo_diff(ids_diff)\n        sys.exit(1)\n\n    with click.progressbar(length=num_items,\n                           label=\"Comparing sizes\") as progressbar:\n        sizes_diff = diff_sizes(ds, ref_ds, progressbar)\n    if len(sizes_diff) > 0:\n        echo_header(\"sizes\", ds.name, ref_ds.name, \"size\")\n        echo_diff(sizes_diff)\n        sys.exit(2)\n\n    if full:\n        with click.progressbar(length=num_items,\n                               label=\"Comparing hashes\") as progressbar:\n            content_diff = diff_content(ds, ref_ds, progressbar)\n        if len(content_diff) > 0:\n            echo_header(\"content\", ds.name, ref_ds.name, \"hash\")\n            echo_diff(content_diff)\n            sys.exit(3)", "response": "Report the difference between two datasets."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlist items in a dataset or a proto dataset.", "response": "def ls(quiet, verbose, uri):\n    \"\"\"List datasets / items in a dataset.\n\n    If the URI is a dataset the items in the dataset will be listed.\n    It is not possible to list the items in a proto dataset.\n\n    If the URI is a location containing datasets the datasets will be listed.\n    Proto datasets are highlighted in red.\n    \"\"\"\n    if dtoolcore._is_dataset(uri, CONFIG_PATH):\n        _list_dataset_items(uri, quiet, verbose)\n    else:\n        _list_datasets(uri, quiet, verbose)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist the item identifiers in the dataset.", "response": "def identifiers(dataset_uri):\n    \"\"\"List the item identifiers in the dataset.\"\"\"\n    dataset = dtoolcore.DataSet.from_uri(dataset_uri)\n    for i in dataset.identifiers:\n        click.secho(i)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreport summary information about a dataset.", "response": "def summary(dataset_uri, format):\n    \"\"\"Report summary information about a dataset.\"\"\"\n    dataset = dtoolcore.DataSet.from_uri(dataset_uri)\n    creator_username = dataset._admin_metadata[\"creator_username\"]\n    frozen_at = dataset._admin_metadata[\"frozen_at\"]\n    num_items = len(dataset.identifiers)\n    tot_size = sum([dataset.item_properties(i)[\"size_in_bytes\"]\n                    for i in dataset.identifiers])\n\n    if format == \"json\":\n        json_lines = [\n            '{',\n            '  \"name\": \"{}\",'.format(dataset.name),\n            '  \"uuid\": \"{}\",'.format(dataset.uuid),\n            '  \"creator_username\": \"{}\",'.format(creator_username),\n            '  \"number_of_items\": {},'.format(num_items),\n            '  \"size_in_bytes\": {},'.format(tot_size),\n            '  \"frozen_at\": {}'.format(frozen_at),\n            '}',\n        ]\n        formatted_json = \"\\n\".join(json_lines)\n        colorful_json = pygments.highlight(\n            formatted_json,\n            pygments.lexers.JsonLexer(),\n            pygments.formatters.TerminalFormatter())\n        click.secho(colorful_json, nl=False)\n\n    else:\n        info = [\n            (\"name\", dataset.name),\n            (\"uuid\", dataset.uuid),\n            (\"creator_username\", creator_username),\n            (\"number_of_items\", str(num_items)),\n            (\"size\", sizeof_fmt(tot_size).strip()),\n            (\"frozen_at\", date_fmt(frozen_at)),\n        ]\n        for key, value in info:\n            click.secho(\"{}: \".format(key), nl=False)\n            click.secho(value, fg=\"green\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns abspath to file with item content.", "response": "def fetch(dataset_uri, item_identifier):\n    \"\"\"Return abspath to file with item content.\n\n    Fetches the file from remote storage if required.\n    \"\"\"\n    dataset = dtoolcore.DataSet.from_uri(dataset_uri)\n    click.secho(dataset.item_content_abspath(item_identifier))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef overlay(overlay_name, dataset_uri, item_identifier):\n    dataset = dtoolcore.DataSet.from_uri(dataset_uri)\n    if overlay_name not in dataset.list_overlay_names():\n        click.secho(\n            \"No such overlay in dataset: {}\".format(overlay_name),\n            fg=\"red\",\n            err=True\n        )\n        sys.exit(4)\n    overlay = dataset.get_overlay(overlay_name)\n\n    try:\n        click.secho(str(overlay[item_identifier]))\n    except KeyError:\n        click.secho(\n            \"No such identifier in overlay: {}\".format(item_identifier),\n            fg=\"red\",\n            err=True\n        )\n        sys.exit(5)", "response": "Return abspath to file with item content."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef relpath(dataset_uri, item_identifier):\n    dataset = dtoolcore.DataSet.from_uri(dataset_uri)\n    try:\n        props = dataset.item_properties(item_identifier)\n    except KeyError:\n        click.secho(\n            \"No such item in dataset: {}\".format(item_identifier),\n            fg=\"red\",\n            err=True\n        )\n        sys.exit(21)\n    click.secho(props[\"relpath\"])", "response": "Return relpath associated with the item."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef verify(full, dataset_uri):\n    dataset = dtoolcore.DataSet.from_uri(dataset_uri)\n    all_okay = True\n\n    generated_manifest = dataset.generate_manifest()\n    generated_identifiers = set(generated_manifest[\"items\"].keys())\n    manifest_identifiers = set(dataset.identifiers)\n\n    for i in generated_identifiers.difference(manifest_identifiers):\n        message = \"Unknown item: {} {}\".format(\n            i,\n            generated_manifest[\"items\"][i][\"relpath\"]\n        )\n        click.secho(message, fg=\"red\")\n        all_okay = False\n\n    for i in manifest_identifiers.difference(generated_identifiers):\n        message = \"Missing item: {} {}\".format(\n            i,\n            dataset.item_properties(i)[\"relpath\"]\n        )\n        click.secho(message, fg=\"red\")\n        all_okay = False\n\n    for i in manifest_identifiers.intersection(generated_identifiers):\n        generated_hash = generated_manifest[\"items\"][i][\"size_in_bytes\"]\n        manifest_hash = dataset.item_properties(i)[\"size_in_bytes\"]\n        if generated_hash != manifest_hash:\n            message = \"Altered item size: {} {}\".format(\n                i,\n                dataset.item_properties(i)[\"relpath\"]\n            )\n            click.secho(message, fg=\"red\")\n            all_okay = False\n\n    if full:\n        for i in manifest_identifiers.intersection(generated_identifiers):\n            generated_hash = generated_manifest[\"items\"][i][\"hash\"]\n            manifest_hash = dataset.item_properties(i)[\"hash\"]\n            if generated_hash != manifest_hash:\n                message = \"Altered item hash: {} {}\".format(\n                    i,\n                    dataset.item_properties(i)[\"relpath\"]\n                )\n                click.secho(message, fg=\"red\")\n                all_okay = False\n\n    if not all_okay:\n        sys.exit(1)\n    else:\n        click.secho(\"All good :)\", fg=\"green\")", "response": "Verify the integrity of a dataset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the UUID of the dataset.", "response": "def uuid(dataset_uri):\n    \"\"\"Return the UUID of the dataset.\"\"\"\n    dataset = dtoolcore.DataSet.from_uri(dataset_uri)\n    click.secho(dataset.uuid)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef merge(self, destination, source):\n        if isinstance(source, dict):\n            for key, value in source.items():\n                if isinstance(value, dict):\n                    # get node or create one\n                    node = destination.setdefault(key, {})\n                    if node is not None:\n                        self.merge(node, value)\n                    else:\n                        destination[key] = value\n                else:\n                    destination[key] = value", "response": "run me with nosetests --with-doctest file.py\n\n        >>> a = { 'first' : { 'all_rows' : { 'pass' : 'dog', 'number' : '1' } } }\n        >>> b = { 'first' : { 'all_rows' : { 'fail' : 'cat', 'number' : '5' } } }\n        >>> merge(a, b) == { 'first' : { 'all_rows' : { 'pass' : 'dog', 'fail' : 'cat', 'number' : '5' } } }"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef split_data(self):\n        this_gene_code = None\n        for seq_record in self.data.seq_records:\n            if this_gene_code is None or this_gene_code != seq_record.gene_code:\n                this_gene_code = seq_record.gene_code\n                self._blocks.append([])\n            list_length = len(self._blocks)\n            self._blocks[list_length - 1].append(seq_record)", "response": "Splits the list of SeqRecordExpanded objects into lists which are\n            kept into a bigger list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_to_string(self, block):\n        if self.partitioning != '1st-2nd, 3rd':\n            return self.make_datablock_by_gene(block)\n        else:\n            if self.format == 'FASTA':\n                return self.make_datablock_considering_codon_positions_as_fasta_format(block)\n            else:\n                return self.make_datablock_by_gene(block)", "response": "Makes a gene_block as str from list of SeqRecordExpanded objects of a gene_code."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_block_dicts_to_string(self, block_1st2nd, block_1st, block_2nd, block_3rd):\n        out = \"\"\n        # We need 1st and 2nd positions\n        if self.codon_positions in ['ALL', '1st-2nd']:\n            for gene_code, seqs in block_1st2nd.items():\n                out += '>{0}_1st-2nd\\n----\\n'.format(gene_code)\n                for seq in seqs:\n                    out += seq\n        elif self.codon_positions == '1st':\n            for gene_code, seqs in block_1st.items():\n                out += '>{0}_1st\\n----\\n'.format(gene_code)\n                for seq in seqs:\n                    out += seq\n        elif self.codon_positions == '2nd':\n            for gene_code, seqs in block_2nd.items():\n                out += '>{0}_2nd\\n----\\n'.format(gene_code)\n                for seq in seqs:\n                    out += seq\n\n        # We also need 3rd positions\n        if self.codon_positions in ['ALL', '3rd']:\n            for gene_code, seqs in block_3rd.items():\n                out += '\\n>{0}_3rd\\n----\\n'.format(gene_code)\n                for seq in seqs:\n                    out += seq\n        return out", "response": "Takes into account whether we need to output all codon positions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_charsets(self):\n        count_start = 1\n        out = ''\n        for gene_code, lengths in self.data.gene_codes_and_lengths.items():\n            count_end = lengths[0] + count_start - 1\n            out += self.format_charset_line(gene_code, count_start, count_end)\n            count_start = count_end + 1\n        return out", "response": "This function generates the character sets for the Phylip dataset."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_slash_number(self):\n        if self.partitioning == 'by codon position' and self.codon_positions == '1st-2nd':\n            return '\\\\2'\n        elif self.partitioning in ['by codon position', '1st-2nd, 3rd'] and self.codon_positions in ['ALL', None]:\n            return '\\\\3'\n        else:\n            return ''", "response": "Returns a backslash number for the charset line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nappend pos1 pos2 etc to the gene_code", "response": "def add_suffixes_to_gene_codes(self):\n        \"\"\"Appends pos1, pos2, etc to the gene_code if needed.\"\"\"\n        out = []\n        for gene_code in self.data.gene_codes:\n            for sufix in self.make_gene_code_suffixes():\n                out.append('{0}{1}'.format(gene_code, sufix))\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_outgroup(self):\n        if self.outgroup is not None:\n            outgroup_taxonomy = ''\n            for i in self.data.seq_records:\n                if self.outgroup == i.voucher_code:\n                    outgroup_taxonomy = '{0}_{1}'.format(i.taxonomy['genus'],\n                                                         i.taxonomy['species'])\n                    break\n            outgroup = '\\noutgroup {0}_{1};'.format(self.outgroup,\n                                                    outgroup_taxonomy)\n        else:\n            outgroup = ''\n        return outgroup", "response": "Generates the outgroup line from the voucher code specified by the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies this datetime to a MIZ object", "response": "def apply_to_miz(self, miz):\n        \"\"\"\n        Applies this datetime to a Miz object (it will be mutated in place)\n\n        Args:\n            miz: MIZ object to mutate\n\n        Returns: True\n\n        \"\"\"\n        miz.mission.day = self.date.day\n        miz.mission.month = self.date.month\n        miz.mission.year = self.date.year\n        miz.mission.mission_start_time = self.mission_start_time\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_string(input_str) -> 'MissionTime':\n        # noinspection SpellCheckingInspection\n        \"\"\"\n        Creates a MissionTime instance from a string\n\n        Format: YYYYMMDDHHMMSS\n\n        Args:\n            input_str: string to parse\n\n        Returns: MissionTime instance\n\n        \"\"\"\n        match = RE_INPUT_STRING.match(input_str)\n        if not match:\n            raise ValueError(f'badly formatted date/time: {input_str}')\n\n        return MissionTime(\n            datetime.datetime(\n                int(match.group('year')),\n                int(match.group('month')),\n                int(match.group('day')),\n                int(match.group('hour')),\n                int(match.group('minute')),\n                int(match.group('second')),\n            )\n        )", "response": "Parses a string into a MissionTime instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates the report to the given output.", "response": "def run(self, output):\n        '''Generate the report to the given output.\n\n        :param output: writable file-like object or file path\n        '''\n        # Ensure folder exists.\n        if self.folder_id not in self.folders.folders(self.user):\n            print(\"E: folder not found: %s\" % self.folder_name,\n                  file=sys.stderr)\n            return\n\n        # Create workbook.\n        wb = self.workbook = xlsxwriter.Workbook(output)\n\n        # Create the different styles used by this report generator.\n        self.formats['title'] = wb.add_format({'font_size': '18',\n                                               'bold': True})\n\n        self.formats['default'] = wb.add_format({'align': 'top'})\n        self.formats['bold'] = wb.add_format({'bold': True})\n\n        self.formats['header'] = wb.add_format({\n            'bold': True,\n            'align': 'center',\n            'valign': 'top',\n            'font_size': '14',\n            'font_color': '#506050',\n            'bg_color': '#f5f5f5',\n            'right': 1,\n            'border_color': 'white'})\n\n        self.formats['pre'] = wb.add_format({'font_name': 'Courier',\n                                             'valign': 'top'})\n\n        self.formats['link'] = wb.add_format({'valign': 'top',\n                                              'font_color': 'blue',\n                                              'underline': True})\n\n        self.formats['type_text'] = wb.add_format({\n            'font_color': '#BF8645',\n            'valign': 'top',\n            'align': 'center'})\n\n        self.formats['type_image'] = wb.add_format({\n            'font_color': '#84BF45',\n            'valign': 'top',\n            'align': 'center'})\n\n        # Generate report for a specific subfolder or *all* subfolders of\n        # self.folder .\n        if self.subfolder_id is None:\n            self._generate_report_all()\n        else:\n            self._generate_report_single(self.subfolder_id)\n\n        # done and outta here\n        self.workbook.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _generate_report_all(self):\n        '''Generate report for all subfolders contained by self.folder_id.'''\n        assert self.workbook is not None\n        count = 0\n\n        # Do all subfolders\n        for sid in self.folders.subfolders(self.folder_id, self.user):\n            count += 1\n            self._generate_for_subfolder(sid)\n\n        if count == 0:\n            print(\"I: empty workbook created: no subfolders found\")", "response": "Generate report for all subfolders contained by self. folder_id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a single report for a subfolder given by sid.", "response": "def _generate_report_single(self, sid):\n        '''Generate report for subfolder given by sid .\n\n        The main purpose of this method is to make sure the subfolder given by\n        sid does indeed exist.  All real work is delegated to\n        _generate_for_subfolder.\n\n        :param sid: The subfolder id\n\n        Private method.\n        '''\n        assert self.workbook is not None\n        assert sid is not None\n\n        # Ensure subfolder exists\n        if not sid in self.folders.subfolders(self.folder_id, self.user):\n            subfolder = Folders.id_to_name(sid)\n            print(\"E: subfolder not found: %s\" % subfolder, file=sys.stderr)\n            return\n\n        self._generate_for_subfolder(sid)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _generate_for_subfolder(self, sid):\n        ''' Generate report for a subfolder.\n\n        :param sid: The subfolder id; assumed valid\n        '''\n        # TODO: the following assumes subfolder names can be constructed from a\n        # subfolder id, which might not be the case in the future.\n        name = self._sanitise_sheetname(uni(Folders.id_to_name(sid)))\n        ws = self.workbook.add_worksheet(name)\n        fmt = self.formats\n        ws.write(\"A1\", \"Dossier report\", fmt['title'])\n        ws.write(\"A2\", \"%s | %s\" % (uni(self.folder_name), name))\n\n        # Column dimensions\n        ws.set_column('A:A', 37)\n        ws.set_column('B:B', 37)\n        ws.set_column('C:C', 37)\n        ws.set_column('D:D', 8)\n        ws.set_column('E:E', 30)\n        ws.set_column('F:F', 37)\n\n        # Header\n        ws.write(\"A4\", \"Id\", fmt['header'])\n        ws.write(\"B4\", \"URL\", fmt['header'])\n        ws.write(\"C4\", \"Subtopic Id\", fmt['header'])\n        ws.write(\"D4\", \"Type\", fmt['header'])\n        ws.write(\"E4\", \"Content\", fmt['header'])\n        ws.write(\"F4\", \"Image URL\", fmt['header'])\n\n        # TODO: we probably want to wrap the following in a try-catch block, in\n        # case the call to folders.subtopics fails.\n        row = 4\n        for i in subtopics(self.store, self.folders, self.folder_id, sid, self.user):\n            Item.construct(self, i).generate_to(ws, row)\n            row += 1", "response": "Generate a report for a subfolder."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef construct(generator, subtopic):\n        '''Method constructor of Item-derived classes.\n\n        Given a subtopic tuple, this method attempts to construct an\n        Item-derived class, currently either ItemText or ItemImage, from the\n        subtopic's type, found in its 4th element.\n\n        :param generator: Reference to the owning ReportGenerator instance\n        :param subtopic: Tuple containing content_id, meta_url, subtopic_id,\n        type and type-specific data.\n\n        :returns An instantiated Item-derived class.\n\n        '''\n        type = subtopic[3]\n        if type not in Item.constructors:\n            raise LookupError(type)   # perhaps customise this exception?\n\n        return Item.constructors[type](generator, subtopic)", "response": "Method to construct an Item - derived class from a subtopic tuple."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_to(self, worksheet, row):\n        '''Generate row report.\n\n        Generates a row report of the item represented by this instance and\n        inserts it into a given worksheet at a specified row number.\n\n        :param worksheet: Reference to a worksheet in which to insert row\n        report.\n\n        :param row: Row number.\n        '''\n        super(ItemImage, self).generate_to(worksheet, row)\n\n        embedded = False\n        fmt = self.generator.formats\n        worksheet.write(row, 3, \"image\", fmt['type_image'])\n        worksheet.write_url(row, 5, self.data[0], fmt['link'])\n\n        try:\n            if self.data:\n                image = self.resize_image(StringIO(self.data[1]))\n                worksheet.insert_image(row, 4, 'image',\n                                       {'image_data': image})\n                embedded = True\n        except:\n            # We probably wrongly ignoring the exception.  Should really at\n            # least log it somewhere.\n            pass\n\n        # Attempt to retrieve image data from the image URL if image data not\n        # present already above or something failed whilst recreating image\n        # from base64 encoding.\n        if not embedded:\n            url = self.data[0]\n            if url:\n                image = self.resize_image(BytesIO(urlopen(url).read()))\n                worksheet.insert_image(row, 4, url, {'image_data': image})\n                embedded = True\n            else:\n                worksheet.write(row, 4, '<unavailable>')\n\n        if embedded:\n            worksheet.set_row(row, 40)", "response": "Generate a row report."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a row report.", "response": "def generate_to(self, worksheet, row):\n        '''Generate row report.\n\n        Generates a row report of the item represented by this instance and\n        inserts it into a given worksheet at a specified row number.\n\n        :param worksheet: Reference to a worksheet in which to insert row\n        report.\n\n        :param row: Row number.\n\n        '''\n        super(ItemText, self).generate_to(worksheet, row)\n\n        fmt = self.generator.formats\n        worksheet.write(row, 3, \"text\", fmt['type_text'])\n        worksheet.write(row, 4, uni(self.data), fmt['default'])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npopulate the list with the list of entries from the soup.", "response": "def _populate(self, soup):\n        \"\"\"\n        Populate the list, assuming ``soup`` is a ``BeautifulSoup`` object.\n        \"\"\"\n        tables = soup.select('table[rules=all]')\n        if not tables:\n            return\n        trs = tables[0].select('tr')[1:]\n\n        if len(trs[0]) == 5:\n            # M1\n            self._populate_small_table(trs)\n        else:\n            # M2\n            self._populate_large_table(trs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npopulate the list with the Course objects from a small table.", "response": "def _populate_small_table(self, trs):\n        \"\"\"\n        Populate the list, given that ``trs`` is a ``BeautifulSoup`` elements\n        list from a large table (5 columns).\n        \"\"\"\n        for tr in trs:\n            tds = tr.select('td')\n            cs = Course(\n                title=text(tds[0]),\n                followed=parsebool(tds[1]),\n            )\n\n            followed = cs['followed']\n            cs['result'] = parsefloat(tds[2]) if followed else None\n            cs['jury'] = parsefloat(tds[3]) if followed else None\n            cs['session'] = text(tds[4]) if followed else None\n\n            self.append(cs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _populate_large_table(self, trs):\n        for tr in trs:\n            tds = tr.select('td')\n            cs = Course(\n                code=coursecode(tds[0]),\n                title=text(tds[1]),\n                semester=parseint(tds[2]),\n                status=text(tds[3]),\n                ects=parsefloat(tds[4]),\n                followed=parsebool(tds[5]),\n            )\n\n            followed = cs['followed']\n            cs['session'] = text(tds[7]) if followed else None\n            cs['result'] = parseresult(tds[6]) if followed else None\n\n            self.append(cs)", "response": "Populate the list with the contents of the large table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter(self, criteria):\n        if isinstance(criteria, str) or isinstance(criteria, unicode):\n            _criteria = criteria\n            criteria = lambda x: x.get(_criteria)\n\n        return CoursesList(filter(criteria, self))", "response": "Return a filtered version of this list following the given criteria."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading setup. py to string", "response": "def setup_py_source(self):  # type: () -> Optional[str]\n        \"\"\"\n        Read setup.py to string\n        :return:\n        \"\"\"\n        if not self.setup_source:\n            self.setup_source = self._read_file(\"setup.py\")\n        if not self.setup_source:\n            self.setup_source = self._read_file(\"setup\")  # rare case\n        return self.setup_source"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract the package_dir dictionary from source file.", "response": "def extract_package_dir(self):  # type: () -> Optional[str]\n        \"\"\"\n        Get the package_dir dictionary from source\n        :return:\n        \"\"\"\n        # package_dir={'': 'lib'},\n        source = self.setup_py_source()\n        if not source:\n            # this happens when the setup.py file is missing\n            return None\n\n        # sometime\n        # 'package_dir'      : {'': 'src'},\n        # sometimes\n        # package_dir={...}\n        if \"package_dir=\" in source:\n            line = source.replace(\"\\n\", \"\")\n            line = line.split(\"package_dir\")[1]\n            fixed = \"\"\n            for char in line:\n                fixed += char\n                if char == \"}\":\n                    break\n            line = fixed\n\n            simplified_line = line.strip(\" ,\").replace(\"'\", '\"')\n\n            parts = simplified_line.split(\"=\")\n\n            dict_src = parts[1].strip(\" \\t\")\n            if not dict_src.endswith(\"}\"):\n                raise JiggleVersionException(\n                    \"Either this is hard to parse or we have 2+ src foldrs\"\n                )\n            try:\n                paths_dict = ast.literal_eval(dict_src)\n            except ValueError as ve:\n                logger.error(source + \": \" + dict_src)\n                return \"\"\n\n            if \"\" in paths_dict:\n                candidate = paths_dict[\"\"]\n                if os.path.isdir(candidate):\n                    return unicode(candidate)\n            if len(paths_dict) == 1:\n                candidate = first_value_in_dict(paths_dict)\n                if os.path.isdir(candidate):\n                    return unicode(candidate)\n            else:\n                raise JiggleVersionException(\n                    \"Have path_dict, but has more than one path.\"\n                )\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef via_find_packages(self):  # type: () -> List[str]\n        packages = []  # type: List[str]\n        source = self.setup_py_source()\n        if not source:\n            return packages\n        find_package_args = \"\"\n        for row in source.split(\"\\n\"):\n            if \"find_packages\" in row:\n                logger.debug(row)\n                if \"find_packages()\" in row:\n                    packages = find_packages()\n                else:\n                    try:\n\n                        find_package_args_source = row.split(\"(\")[1].split(\")\")[0]\n                        find_package_args = ast.literal_eval(find_package_args_source)\n                        logger.debug(packages)\n                    except:\n                        logger.debug(source)\n                        # raise\n        if not find_package_args:\n            packages = find_packages()\n        else:\n            try:\n                # signature find(cls, where='.', exclude=(), include=('*',)):\n                packages = find_packages(find_package_args)\n            except:\n                packages = find_packages()\n\n        return packages", "response": "Use find_packages code to find modules. Can find LOTS of modules."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding top - level modules along side setup. py or in current folder.", "response": "def find_top_level_modules_by_dunder_init(self):  # type: () -> List[str]\n        \"\"\"\n        Find modules along side setup.py (or in current folder)\n\n        Recreates what find_packages does.\n        :return:\n        \"\"\"\n        # TODO: use package_dirs\n        packaged_dirs = \"\"\n        try:\n            # Right now only returns 1st.\n            packaged_dirs = self.extract_package_dir()\n        except:\n            pass\n        likely_src_folders = [\".\", \"src\", \"lib\"]\n        if packaged_dirs and packaged_dirs not in likely_src_folders:\n            likely_src_folders.append(packaged_dirs)\n\n        candidates = []\n        for likely_src in likely_src_folders:\n            if not os.path.isdir(likely_src):\n                continue\n            folders = [\n                f\n                for f in os.listdir(likely_src)\n                if os.path.isdir(os.path.join(likely_src, f))\n            ]\n\n            for folder in folders:\n                if os.path.isfile(os.path.join(likely_src, folder, \"__init__.py\")):\n                    # dunder_source = self.file_opener.read_file(folder + \"/__init__.py\")\n                    candidates.append(folder)\n\n        return list(set([x for x in candidates if x]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds a single file project.", "response": "def find_single_file_project(self):  # type: () -> List[str]\n        \"\"\"\n        Take first non-setup.py python file. What a mess.\n        :return:\n        \"\"\"\n        # TODO: use package_dirs\n        packaged_dirs = \"\"\n        try:\n            # Right now only returns 1st.\n            packaged_dirs = self.extract_package_dir()\n        except:\n            pass\n        likely_src_folders = [\".\", \"src/\"]\n        if packaged_dirs:\n            likely_src_folders.append(packaged_dirs)\n\n        candidates = []\n        for likely_src in likely_src_folders:\n            if not os.path.isdir(likely_src):\n                continue\n            files = [f for f in os.listdir(likely_src) if os.path.isfile(f)]\n\n            # BUG: doesn't deal with src/foo/bar.py\n            for file in files:\n                if file.endswith(\"setup.py\") or file == \"setup\":\n                    continue  # duh\n                if file.endswith(\".py\"):\n                    candidate = file.replace(\".py\", \"\")\n                    if candidate != \"setup\":\n                        candidates.append(candidate)\n                else:\n                    if self.file_opener.is_python_inside(file):\n                        candidates.append(file)\n        return candidates"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the host name or IP address.", "response": "def get_host(self):\n        \"\"\"\n        Gets the host name or IP address.\n\n        :return: the host name or IP address.\n        \"\"\"\n        host = self.get_as_nullable_string(\"host\")\n        host = host if host != None else self.get_as_nullable_string(\"ip\")\n        return host"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef query_icao(icao: str):\n        params = {\n            'dataSource': 'metars',\n            'requestType': 'retrieve',\n            'format': 'csv',\n            'hoursBeforeNow': 24,\n        }\n        AWC._validate_icao(icao)\n        params['stationString'] = icao\n        try:\n            return AWC._query(params)\n        except RequestsConnectionError:\n            raise AWCRequestFailed('failed to obtain requested data from AWC')", "response": "Queries AWC for the METAR of a given station ID as a four letters - digits ICAO code and returns the response."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(self, asset_content, friendly_name, tags='', optimize=False):\n\n        return self._create_asset({\n            'asset': b64encode(asset_content),\n            'friendly-name': friendly_name,\n            'tags': tags,\n            'optimize': optimize,\n            'type': 'base64'\n        })", "response": "Create an asset on the server"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an asset at a specific URL path on the server.", "response": "def create_at_path(self, asset_content, url_path, tags=''):\n        \"\"\"\n        Create asset at a specific URL path on the server\n        \"\"\"\n\n        return self._create_asset({\n            'asset': b64encode(asset_content),\n            'url-path': url_path,\n            'tags': tags,\n            'type': 'base64'\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive an array xarr of values smoothly return the max and min", "response": "def _extalg(xarr, alpha=100, axis=None):\n    '''Given an array xarr of values, smoothly return the max/min'''\n    return (np.sum(xarr * np.exp(alpha*xarr), axis=axis, keepdims=True)/\n                np.sum(np.exp(alpha*xarr), axis=axis, keepdims=True))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _extgrad(xarr, alpha=100, axis=None):\n    '''Given an array xarr of values, return the gradient of the smooth min/max\n    swith respect to each entry in the array'''\n    term1 = (np.exp(alpha*xarr)/\n                np.sum(np.exp(alpha*xarr), axis=axis, keepdims=True))\n    term2 = 1 + alpha*(xarr - _extalg(xarr, alpha, axis=axis))\n\n    return term1*term2", "response": "Given an array xarr of values return the gradient of the smooth min max or smooth max"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the dp metric for a single horsetail curve at a given value of the epistemic uncertainties", "response": "def _matrix_integration(q, h, t):\n    ''' Returns the dp metric for a single horsetail\n    curve at a given value of the epistemic uncertainties'''\n\n    N = len(q)\n\n    # correction if CDF has gone out of trapezium range\n    if h[-1] < 0.9: h[-1] = 1.0\n\n    W = np.zeros([N, N])\n    for i in range(N):\n        W[i, i] = 0.5*(h[min(i+1, N-1)] - h[max(i-1, 0)])\n\n    dp = (q - t).T.dot(W).dot(q - t)\n\n    return dp"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _matrix_grad(q, h, h_dx, t, t_prime):\n    ''' Returns the gradient with respect to a single variable'''\n\n    N = len(q)\n    W = np.zeros([N, N])\n    Wprime = np.zeros([N, N])\n    for i in range(N):\n        W[i, i] = 0.5*(h[min(i+1, N-1)] - h[max(i-1, 0)])\n        Wprime[i, i] = \\\n            0.5*(h_dx[min(i+1, N-1)] - h_dx[max(i-1, 0)])\n\n    tgrad = np.array([t_prime[i]*h_dx[i] for i in np.arange(N)])\n\n    grad = 2.0*(q - t).T.dot(W).dot(-1.0*tgrad) \\\n            + (q - t).T.dot(Wprime).dot(q - t)\n\n    return grad", "response": "Returns the gradient with respect to a single variable"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nevaluates the samples at the given values of the design variables and return the evaluated q_samples and grad_samples.", "response": "def evalSamples(self, x):\n        '''Evalautes the samples of quantity of interest and its gradient\n        (if supplied) at the given values of the design variables\n\n        :param iterable x: values of the design variables, this is passed as\n            the first argument to the function fqoi\n\n        :return: (values of the quantity of interest, values of the gradient)\n        :rtype: Tuple\n        '''\n\n        # Make sure dimensions are correct\n#        u_sample_dimensions = self._processDimensions()\n\n        self._N_dv = len(_makeIter(x))\n\n        if self.verbose:\n            print('Evaluating surrogate')\n        if self.surrogate is None:\n            def fqoi(u):\n                return self.fqoi(x, u)\n            def fgrad(u):\n                return self.jac(x, u)\n            jac = self.jac\n        else:\n            fqoi, fgrad, surr_jac = self._makeSurrogates(x)\n            jac = surr_jac\n\n        u_samples = self._getParameterSamples()\n\n        if self.verbose:\n            print('Evaluating quantity of interest at samples')\n        q_samples, grad_samples = self._evalSamples(u_samples, fqoi, fgrad, jac)\n\n        return q_samples, grad_samples"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef evalMetric(self, x, method=None):\n        '''Evaluates the horsetail matching metric at given values of the\n        design variables.\n\n        :param iterable x: values of the design variables, this is passed as\n            the first argument to the function fqoi\n        :param str method: method to use to evaluate the metric ('empirical' or\n            'kernel')\n\n        :return: metric_value - value of the metric evaluated at the design\n            point given by x\n\n        :rtype: float\n\n        *Example Usage*::\n\n            >>> def myFunc(x, u): return x[0]*x[1] + u\n            >>> u1 = UniformParameter()\n            >>> theHM = HorsetailMatching(myFunc, u)\n            >>> x0 = [1, 2]\n            >>> theHM.evalMetric(x0)\n\n        '''\n        # Make sure dimensions are correct\n#        u_sample_dimensions = self._processDimensions()\n\n        if self.verbose:\n            print('----------')\n            print('At design: ' + str(x))\n\n        q_samples, grad_samples = self.evalSamples(x)\n\n        if self.verbose:\n            print('Evaluating metric')\n\n        return self.evalMetricFromSamples(q_samples, grad_samples, method)", "response": "Evaluates the horsetail matching metric at given values of the design variables."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef evalMetricFromSamples(self, q_samples, grad_samples=None, method=None):\n        '''Evaluates the horsetail matching metric from given samples of the quantity\n        of interest and gradient instead of evaluating them at a design.\n\n        :param np.ndarray q_samples: samples of the quantity of interest,\n            size (M_int, M_prob)\n        :param np.ndarray grad_samples: samples of the gradien,\n            size (M_int, M_prob, n_x)\n\n        :return: metric_value - value of the metric\n\n        :rtype: float\n\n        '''\n        # Make sure dimensions are correct\n#        u_sample_dimensions = self._processDimensions()\n\n        q_samples = np.array(q_samples)\n        if not (q_samples.shape[0] == self.samples_int and\n                q_samples.shape[1] == self.samples_prob):\n            raise ValueError('Shape of q_samples should be [M_int, M_prob]')\n\n        if grad_samples is not None:\n            grad_samples = np.array(grad_samples)\n            if not (grad_samples.shape[0] == self.samples_int and\n                    grad_samples.shape[1] == self.samples_prob):\n                raise ValueError('''Shape of grad_samples\n                        should be [M_int, M_prob, n_dv]''')\n\n        if method is None:\n            method = self.method\n\n        if method.lower() == 'empirical':\n            return self._evalMetricEmpirical(q_samples, grad_samples)\n        elif method.lower() == 'kernel':\n            return self._evalMetricKernel(q_samples, grad_samples)\n        else:\n            raise ValueError('Unsupported metric evalation method')", "response": "Evaluates the horsetail matching metric from given samples of the quantity of interest and gradient of the horsetail matching metric at a design."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning that gets vectors of the horsetail plot at the last design evaluated.", "response": "def getHorsetail(self):\n        '''Function that gets vectors of the horsetail plot at the last design\n        evaluated.\n\n        :return: upper_curve, lower_curve, CDFs - returns three parameters,\n            the first two are tuples containing pairs of x/y vectors of the\n            upper and lower bounds on the CDFs (the horsetail plot). The\n            third parameter is a list of x/y tuples for individual CDFs\n            propagated at each sampled value of the interval uncertainties\n\n        *Example Usage*::\n\n            >>> def myFunc(x, u): return x[0]*x[1] + u\n            >>> u = UniformParameter()\n            >>> theHM = HorsetailMatching(myFunc, u)\n            >>> (x1, y1, t1), (x2, y2, t2), CDFs = theHM.getHorsetail()\n            >>> matplotlib.pyplot(x1, y1, 'b')\n            >>> matplotlib.pyplot(x2, y2, 'b')\n            >>> for (x, y) in CDFs:\n            ...     matplotlib.pyplot(x, y, 'k:')\n            >>> matplotlib.pyplot.show()\n\n        '''\n\n        if hasattr(self, '_ql'):\n\n            ql, qu, hl, hu = self._ql, self._qu, self._hl, self._hu\n            qh, hh = self._qh, self._hh\n\n            if self._qis is not None:\n                ql, hl = _appendPlotArrays(ql, hl, self._qis)\n                qu, hu = _appendPlotArrays(qu, hu, self._qis)\n\n            CDFs = []\n            for qi, hi in zip(qh, hh):\n                CDFs.append((qi, hi))\n\n            upper_target = [self._ftarg_u(h) for h in hu]\n            upper_curve = (qu, hu, upper_target)\n            lower_target = [self._ftarg_l(h) for h in hl]\n            lower_curve = (ql, hl, lower_target)\n            return upper_curve, lower_curve, CDFs\n\n        else:\n            raise ValueError('''The metric has not been evaluated at any\n                    design point so the horsetail does not exist''')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_queryset(self):\n        '''\n        If MultiTenantMiddleware is used, filter queryset by request.site_id\n        '''\n        queryset = super(PageList, self).get_queryset()\n        if hasattr(self.request, 'site_id'):\n            queryset = queryset.filter(site_id=self.request.site_id)\n        return queryset", "response": "Filter queryset by request. site_id."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_context_data(self, **kwargs):\n        '''\n        Adds a 'base_template' attribute to context for the page_detail to \n        extend from\n        '''\n        context = super(PageList, self).get_context_data(**kwargs)\n        page_base_template = \"nupages/base.html\"\n        # if MultiTenantMiddleware is used, use a base template specific to \n        # the tenants SITE_ID\n        if hasattr(self.request, 'site_id'):\n            page_base_template = select_template(\n                [\"nupages/tenants/{}/base.html\".format(self.request.site_id), \n                page_base_template])\n        context['base_template'] = page_base_template\n        print page_base_template\n        return context", "response": "Adds a base_template attribute to the context for the page_detail to \n        extend from\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_template_names(self):\n        '''\n        Looks for a custom_template value and prepends it to template_names \n        if it exists otherwise 'nupages/page_detail.html' is used\n        '''\n        template_names = super(PageDetail, self).get_template_names()\n        if self.get_object().custom_template:\n            # there is a custom template, insert it before 'template_name'\n            template_names.insert(0, self.get_object().custom_template)\n        return template_names", "response": "Returns a list of template names for this page detail."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a base_template attribute to the context for the page_detail to extend from", "response": "def get_context_data(self, **kwargs):\n        '''\n        Adds a 'base_template' attribute to context for the page_detail to \n        extend from\n        '''\n        context = super(PageDetail, self).get_context_data(**kwargs)\n        page_base_template = \"nupages/base.html\"\n        # if MultiTenantMiddleware is used, use a base template specific to \n        # the tenants SITE_ID\n        if hasattr(self.request, 'site_id'):\n            page_base_template = select_template(\n                [\"nupages/tenants/{}/base.html\".format(self.request.site_id), \n                page_base_template])\n        context['base_template'] = page_base_template\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve a TAF string from an online database", "response": "def retrieve_taf(station_icao) -> typing.Tuple[typing.Union[str, None], typing.Union[str, None]]:\n    \"\"\"\n    Retrieves a TAF string from an online database\n\n    Args:\n        station_icao: ICAO of the station\n\n    Returns:\n        tuple of error, metar_str\n    \"\"\"\n    url = _BASE_TAF_URL.format(station=station_icao)\n    with requests.get(url) as resp:\n        if not resp.ok:\n            return f'unable to obtain TAF for station {station_icao}\\n' \\\n                   f'Got to \"http://tgftp.nws.noaa.gov/data/observations/metar/stations\" ' \\\n                   f'for a list of valid stations', None\n        return None, resp.content.decode().split('\\n')[1]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef retrieve_metar(station_icao) -> typing.Tuple[typing.Optional[str], typing.Optional[str]]:\n    url = _BASE_METAR_URL.format(station=station_icao)\n    with requests.get(url) as resp:\n        if not resp.ok:\n            return f'unable to obtain METAR for station {station_icao}\\n' \\\n                   f'Got to \"http://tgftp.nws.noaa.gov/data/observations/metar/stations\" ' \\\n                   f'for a list of valid stations', None\n        return None, resp.content.decode().split('\\n')[1]", "response": "Retrieves a METAR string from an online database"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef value(self, units=None):\n        if units is None:\n            return self._value\n\n        if not units.upper() in CustomPressure.legal_units:\n            raise UnitsError(\"unrecognized pressure unit: '\" + units + \"'\")\n        units = units.upper()\n        if units == self._units:\n            return self._value\n        if self._units == \"IN\":\n            mb_value = self._value * 33.86398\n        elif self._units == \"MM\":\n            mb_value = self._value * 1.3332239\n        else:\n            mb_value = self._value\n        if units in (\"MB\", \"HPA\"):\n            return mb_value\n        if units == \"IN\":\n            return mb_value / 33.86398\n        if units == \"MM\":\n            return mb_value / 1.3332239\n\n        raise UnitsError(\"unrecognized pressure unit: '\" + units + \"'\")", "response": "Return the pressure in the specified units."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef string(self, units: typing.Optional[str] = None) -> str:\n        if not units:\n            _units: str = self._units\n        else:\n            if not units.upper() in CustomPressure.legal_units:\n                raise UnitsError(\"unrecognized pressure unit: '\" + units + \"'\")\n            _units = units.upper()\n        val = self.value(units)\n        if _units == \"MB\":\n            return \"%.0f mb\" % val\n        if _units == \"HPA\":\n            return \"%.0f hPa\" % val\n        if _units == \"IN\":\n            return \"%.2f inches\" % val\n        if _units == \"MM\":\n            return \"%.0f mmHg\" % val\n\n        raise ValueError(_units)", "response": "Return a string representation of the pressure using the given units."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vectorAngle(vec1,vec2):\n    '''\n    vector (x,y,z) or vector field of shape (3,x,y)\n    '''\n    if vec1.ndim == 1:\n        assert vec2.ndim == 3\n        vec1 = vectorToField(vec1, vec2.shape[:2])\n\n    if vec2.ndim == 1:\n        assert vec1.ndim == 3\n        vec2 = vectorToField(vec2, vec1.shape[1:])\n    a = np.arccos(\n                np.einsum('ijk,ijk->jk', vec1,vec2)\n                /( norm(vec1,axis=0) * norm(vec2,axis=0) ) )\n    #take smaller of both possible angles:\n    ab = np.abs(np.pi-a)\n    with np.errstate(invalid='ignore'):\n        i = a>ab\n    a[i] = ab[i]\n    return a", "response": "calculate the angle between two vectors"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef determine_name(func):\n    if hasattr(func, '__name__'):\n        return func.__name__\n    elif hasattr(func, '__class__'):\n        return func.__class__.__name__\n\n    # This shouldn't be possible, but blow up if so.\n    raise AttributeError(\"Provided callable '{}' has no name.\".format(\n        func\n    ))", "response": "Given a function returns the name of the function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef import_module(module_name):\n    try:\n        return importlib.import_module(module_name)\n    except ImportError as err:\n        raise UnknownModuleError(str(err))", "response": "Imports a module named module_name and returns the module."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef import_attr(module_name, attr_name):\n    module = import_module(module_name)\n\n    try:\n        return getattr(module, attr_name)\n    except AttributeError as err:\n        raise UnknownCallableError(str(err))", "response": "Imports the module & returns the attribute."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload and return site configuration as a dict.", "response": "def load_site_config(name):\n    \"\"\"Load and return site configuration as a dict.\"\"\"\n    return _load_config_json(\n        os.path.join(\n            CONFIG_PATH,\n            CONFIG_SITES_PATH,\n            name + CONFIG_EXT\n        )\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_charsets(self):\n        count_start = 1\n        out = ''\n        for gene_code, lengths in self.data.gene_codes_and_lengths.items():\n            count_end = lengths[0] + count_start - 1\n            formatted_line = self.format_charset_line(gene_code, count_start, count_end)\n            converted_line = formatted_line.replace('    charset', 'DNA,').replace(';', '')\n            out += converted_line\n            count_start = count_end + 1\n        return out", "response": "Creates a string of the character sets for the Phylip dataset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_date(cls, date):\n        try:\n            date = date.date()\n        except AttributeError:\n            pass\n        return cls(date.year, date.month)", "response": "Returns a Month instance from the given datetime. date object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking that every element of kwargs is a valid type in this tree.", "response": "def _check_search_kwarg_types(self, kwargs):\n        '''Checks that every element of kwargs is a valid type in this tree.'''\n        for key in kwargs:\n            if key not in self.node_types:\n                raise TypeError(\"Invalid search type: {}\".format(key))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef average(x):\n    if x.ndim > 1 and len(x[0]) > 1:\n        return np.average(x, axis=1)\n    return x", "response": "Returns a numpy array of column average."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a numpy array of column mean.", "response": "def mean(x):\n    \"\"\"\n    Return a numpy array of column mean.\n    It does not affect if the array is one dimension\n\n    Parameters\n    ----------\n    x : ndarray\n        A numpy array instance\n\n    Returns\n    -------\n    ndarray\n        A 1 x n numpy array instance of column mean\n\n    Examples\n    --------\n    >>> a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    >>> np.array_equal(mean(a), [2, 5, 8])\n    True\n    >>> a = np.array([1, 2, 3])\n    >>> np.array_equal(mean(a), [1, 2, 3])\n    True\n\n    \"\"\"\n    if x.ndim > 1 and len(x[0]) > 1:\n        return np.mean(x, axis=1)\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a numpy array of column median.", "response": "def median(x):\n    \"\"\"\n    Return a numpy array of column median.\n    It does not affect if the array is one dimension\n\n    Parameters\n    ----------\n    x : ndarray\n        A numpy array instance\n\n    Returns\n    -------\n    ndarray\n        A 1 x n numpy array instance of column median\n\n    Examples\n    --------\n    >>> a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    >>> np.array_equal(median(a), [2, 5, 8])\n    True\n    >>> a = np.array([1, 2, 3])\n    >>> np.array_equal(median(a), [1, 2, 3])\n    True\n\n    \"\"\"\n    if x.ndim > 1 and len(x[0]) > 1:\n        return np.median(x, axis=1)\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a numpy array of column variance", "response": "def variance(x):\n    \"\"\"\n    Return a numpy array of column variance\n\n    Parameters\n    ----------\n    x : ndarray\n        A numpy array instance\n\n    Returns\n    -------\n    ndarray\n        A 1 x n numpy array instance of column variance\n\n    Examples\n    --------\n    >>> a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    >>> np.testing.assert_array_almost_equal(\n    ...     variance(a),\n    ...     [0.666666, 0.666666, 0.666666])\n    >>> a = np.array([1, 2, 3])\n    >>> np.testing.assert_array_almost_equal(\n    ...     variance(a),\n    ...     0.666666)\n\n    \"\"\"\n    if x.ndim > 1 and len(x[0]) > 1:\n        return np.var(x, axis=1)\n    return np.var(x)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a numpy array of column standard deviation for the given array x.", "response": "def standard_deviation(x):\n    \"\"\"\n    Return a numpy array of column standard deviation\n\n    Parameters\n    ----------\n    x : ndarray\n        A numpy array instance\n\n    Returns\n    -------\n    ndarray\n        A 1 x n numpy array instance of column standard deviation\n\n    Examples\n    --------\n    >>> a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n    >>> np.testing.assert_array_almost_equal(\n    ...     standard_deviation(a),\n    ...     [0.816496, 0.816496, 0.816496])\n    >>> a = np.array([1, 2, 3])\n    >>> np.testing.assert_array_almost_equal(\n    ...     standard_deviation(a),\n    ...     0.816496)\n\n    \"\"\"\n    if x.ndim > 1 and len(x[0]) > 1:\n        return np.std(x, axis=1)\n    return np.std(x)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef confidential_interval(x, alpha=0.98):\n    from scipy.stats import t\n    if x.ndim == 1:\n        df = len(x) - 1\n        # calculate positive critical value of student's T distribution\n        cv = t.interval(alpha, df)\n        # calculate sample standard distribution\n        std = np.std(x)\n    else:\n        # calculate degree of freedom\n        df = len(x[0]) - 1\n        # calculate positive critical value of student's T distribution\n        cv = t.interval(alpha, df)[1]\n        # calculate sample standard distribution\n        std = np.std(x, axis=1)\n    # calculate positive difference from\n    # sample average to confidential interval\n    return std * cv / np.sqrt(df)", "response": "Returns a numpy array of column confidential interval"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a simple moving matrix.", "response": "def simple_moving_matrix(x, n=10):\n    \"\"\"\n    Create simple moving matrix.\n\n    Parameters\n    ----------\n    x : ndarray\n        A numpy array\n    n : integer\n        The number of sample points used to make average\n\n    Returns\n    -------\n    ndarray\n        A n x n numpy array which will be useful for calculating confidentail\n        interval of simple moving average\n\n    \"\"\"\n    if x.ndim > 1 and len(x[0]) > 1:\n        x = np.average(x, axis=1)\n    h = n / 2\n    o = 0 if h * 2 == n else 1\n    xx = []\n    for i in range(h, len(x) - h):\n        xx.append(x[i-h:i+h+o])\n    return np.array(xx)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the simple moving average of the array x.", "response": "def simple_moving_average(x, n=10):\n    \"\"\"\n    Calculate simple moving average\n\n    Parameters\n    ----------\n    x : ndarray\n        A numpy array\n    n : integer\n        The number of sample points used to make average\n\n    Returns\n    -------\n    ndarray\n        A 1 x n numpy array instance\n    \"\"\"\n    if x.ndim > 1 and len(x[0]) > 1:\n        x = np.average(x, axis=1)\n    a = np.ones(n) / float(n)\n    return np.convolve(x, a, 'valid')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_available_port():\n    s = socket.socket()\n    s.bind(('localhost', 0))\n    _address, port = s.getsockname()\n    s.close()\n    return port", "response": "Find an available port."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ldif_encode(attr, value):\n    if isinstance(value, bytes):\n        return '%s:: %s' % (attr, base64.b64encode(value).decode('ascii'))\n    elif any(c not in _BASE_LDIF for c in value):\n        return '%s:: %s' % (attr, base64.b64encode(value.encode('utf-8')).decode('ascii'))\n    else:\n        return '%s: %s' % (attr, value)", "response": "Encode a value pair for the LDIF format."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds the first directory containing a given candidate file.", "response": "def _find_file(self, needle, candidates):\n        \"\"\"Find the first directory containing a given candidate file.\"\"\"\n        for candidate in candidates:\n            fullpath = os.path.join(candidate, needle)\n            if os.path.isfile(fullpath):\n                return fullpath\n        raise PathError(\"Unable to locate file %s; tried %s\" % (needle, candidates))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _locate_schemas(self, schemas, skip_missing_schemas):\n        for schema in schemas:\n            if schema == os.path.abspath(schema):\n                schema_file = schema\n            else:\n                schema_file = os.path.join(self.paths.schemas, schema)\n\n            if os.path.isfile(schema_file):\n                # Absolute path: use it.\n                yield schema_file\n            elif skip_missing_schemas:\n                logger.warning(\"Unable to locate schema %s at %s\", schema, schema_file)\n            else:\n                raise PathError(\"Unable to locate schema %s at %s\" % (schema, schema_file))", "response": "Locate all schemas in the given list of schemas."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npopulate a * running* server with initial data.", "response": "def _populate(self):\n        \"\"\"Populate a *running* server with initial data.\"\"\"\n        self.add(self._core_data)\n        if self.initial_data:\n            self.add(self.initial_data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npolls the slapd port until available.", "response": "def _poll_slapd(self, timeout=DEFAULT_STARTUP_DELAY):\n        \"\"\"Poll slapd port until available.\"\"\"\n\n        begin = time.time()\n        time.sleep(0.5)\n        while time.time() < begin + timeout:\n            if self._process.poll() is not None:\n                raise RuntimeError(\"LDAP server has exited before starting listen.\")\n\n            s = socket.socket()\n            try:\n                s.connect(('localhost', self.port))\n            except socket.error:\n                # Not ready yet, sleep\n                time.sleep(0.5)\n            else:\n                return\n            finally:\n                s.close()\n\n        raise RuntimeError(\"LDAP server not responding within %s seconds.\" % timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake a list of SeqRecordExpanded objects corresponding to a gene_code and produces the gene_block as string.", "response": "def convert_to_string(self, block):\n        \"\"\"\n        Takes a list of SeqRecordExpanded objects corresponding to a gene_code\n        and produces the gene_block as string.\n\n        :param block:\n        :return: str.\n        \"\"\"\n        out = \"\"\n        for seq_record in block:\n            taxon_id = \">{0}_{1}_{2} [org={0} {1}] [Specimen-voucher={2}] \" \\\n                       \"[note={3} gene, partial cds.] [Lineage={4}]\".format(\n                seq_record.taxonomy['genus'],\n                seq_record.taxonomy['species'],\n                seq_record.voucher_code,\n                seq_record.gene_code,\n                seq_record.lineage,\n            )\n            sequence = get_seq(seq_record, self.codon_positions, self.aminoacids,\n                               self.degenerate)\n            seq = sequence.seq\n            if sequence.warning:\n                self.warnings.append(sequence.warning)\n\n            n = 60\n            seq = [seq[i:i + n] for i in range(0, len(seq), n)]\n            out += '{0}\\n{1}\\n'.format(taxon_id, \"\\n\".join(seq))\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_view(self, query_criteria=None, uid='_all_users'):\n    \n        '''\n            a method to add a view to a design document of a uid \n            \n        :param query_criteria: dictionary with valid jsonmodel query criteria \n        :param uid: [optional] string with uid of design document to update\n        :return: integer with status of operation\n\n        an example of how to construct the query_criteria argument:\n\n        query_criteria = {\n            '.path.to.number': {\n                'min_value': 4.5\n            },\n            '.path.to.string': {\n                'discrete_values': [ 'pond', 'lake', 'stream', 'brook' ]\n            }\n        }\n        \n        NOTE:   only fields specified in the document schema at class initialization\n                can be used as fields in query_criteria. otherwise, an error will be thrown.\n                uid is automatically added to all document schemas at initialization\n                \n        NOTE:   the full list of all criteria are found in the reference page for the\n                jsonmodel module as well as the query-rules.json file included in the\n                module. \n                http://collectiveacuity.github.io/jsonModel/reference/#query-criteria\n        '''\n        \n        # https://developer.couchbase.com/documentation/mobile/1.5/references/sync-gateway/admin-rest-api/index.html#/query/put__db___design__ddoc_\n        # https://developer.couchbase.com/documentation/server/3.x/admin/Views/views-writing.html\n    \n        title = '%s.create_view' % self.__class__.__name__\n    \n    # validate inputs\n        input_fields = {\n            'uid': uid\n        }\n        for key, value in input_fields.items():\n            if value:\n                object_title = '%s(%s=%s)' % (title, key, str(value))\n                self.fields.validate(value, '.%s' % key, object_title)\n\n    # validate inputs\n        if query_criteria:\n            if not self.model:\n                raise ValueError('%s(query_criteria={...} requires a document_schema.' % title)\n            self.model.query(query_criteria)\n        else:\n            query_criteria = {}\n        if uid != '_all_users' and self.public:\n            raise ValueError('%s(uid=\"%s\") user ids are not applicable for a public bucket. % title')\n            \n    # catch missing args\n        if not query_criteria and not uid:\n            raise IndexError('%s requires either a uid or query_criteria argument.' % title)\n    \n    # create a view of all user documents\n        else:\n            \n        # retrieve the design document for the uid\n            url = self.bucket_url + '/_design/%s' % uid\n            design_details = {\n                'views': {}\n            }\n            response = requests.get(url)\n            if response.status_code in (200, 201):\n                design_details = response.json()\n                design_details['views'] = self._clean_views(design_details['views'])\n        \n        # create a view of all docs for the uid\n            if not query_criteria:\n                if uid == '_all_users':\n                    return response.status_code\n                else:\n                    function_string = 'function(doc, meta) { if (doc.uid == \"%s\") { emit(null, null); } }' % uid\n                    design_details['views']['_all_docs'] = { 'map': function_string }\n            \n        # construct a view for a query criteria\n            else:\n                \n            # determine hashed key for criteria\n                import hashlib\n                import json\n                from collections import OrderedDict\n                ordered_criteria = OrderedDict(**query_criteria)\n                hashed_criteria = hashlib.md5(json.dumps(query_criteria, sort_keys=True).encode('utf-8')).hexdigest()\n            \n            # determine function string for criteria\n                uid_insert = 'emit();'\n                if uid != '_all_users':\n                    uid_insert = 'if (doc.uid == \"%s\") { emit(); }' % uid\n                function_string = 'function(doc, meta) { %s }' % uid_insert\n                emit_insert = 'emit(null, ['\n                count = 0\n                for key in ordered_criteria.keys():\n                    if count:\n                        emit_insert += ','\n                    emit_insert += 'doc%s' % key\n                emit_insert += ']);'\n                function_string = function_string.replace('emit();', emit_insert)\n            \n            # construct updated design details\n                design_details['views'][hashed_criteria] = { 'map': function_string }\n\n        # send update of design document\n            response = requests.put(url, json=design_details)\n        \n        return response.status_code", "response": "a method to add a view to a design document of a uid \n            "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_view(self, query_criteria=None, uid='_all_users'):\n    \n        '''\n            a method to delete a view associated with a user design doc\n        \n        :param query_criteria: [optional] dictionary with valid jsonmodel query criteria\n        :param uid: [optional] string with uid of design document to update\n        :return: integer with status of operation\n                \n        an example of how to construct the query_criteria argument:\n\n        query_criteria = {\n            '.path.to.number': {\n                'min_value': 4.5\n            },\n            '.path.to.string': {\n                'discrete_values': [ 'pond', 'lake', 'stream', 'brook' ]\n            }\n        }\n        \n        NOTE:   only fields specified in the document schema at class initialization\n                can be used as fields in query_criteria. otherwise, an error will be thrown.\n                uid is automatically added to all document schemas at initialization\n                \n        NOTE:   the full list of all criteria are found in the reference page for the\n                jsonmodel module as well as the query-rules.json file included in the\n                module. \n                http://collectiveacuity.github.io/jsonModel/reference/#query-criteria\n\n        NOTE:   if a query_criteria is not specified, then the entire user design doc is removed\n                otherwise, the existing design document is updated. \n        '''\n        \n    # https://developer.couchbase.com/documentation/mobile/1.5/references/sync-gateway/admin-rest-api/index.html#/query/delete__db___design__ddoc_\n    \n        title = '%s.delete_view' % self.__class__.__name__\n    \n    # validate inputs\n        input_fields = {\n            'uid': uid\n        }\n        for key, value in input_fields.items():\n            if value:\n                object_title = '%s(%s=%s)' % (title, key, str(value))\n                self.fields.validate(value, '.%s' % key, object_title)\n\n    # validate inputs\n        if query_criteria:\n            if not self.model:\n                raise ValueError('%s(query_criteria={...} requires a document_schema.' % title)\n            self.model.query(query_criteria)\n        else:\n            query_criteria = {}\n        if uid != '_all_users' and self.public:\n            raise ValueError('%s(uid=\"%s\") user ids are not applicable for a public bucket. % title')\n            \n    # handle deleting user design doc\n        if not query_criteria:\n            url = self.bucket_url + '/_design/%s' % uid\n            response = requests.delete(url)\n    \n    # catch missing args\n        elif not uid:\n            raise IndexError('%s requires either a uid or query_criteria argument.' % title)\n    \n    # handle removing a view from a design doc\n        else:\n            \n    # determine hash of query criteria\n            import hashlib\n            import json\n            hashed_criteria = hashlib.md5(json.dumps(query_criteria, sort_key=True).encode('utf-8')).hexdigest()\n\n    # determine design document to update\n            url = self.bucket_url + '/_design/%s' % uid\n    \n    # remove view from design document and update\n            response = requests.get(url)\n            if response.status_code in (200, 201):\n                design_details = response.json()\n                design_details['views'] = self._clean_views(design_details['views'])\n                if hashed_criteria in design_details['views'].keys():\n                    del design_details['views'][hashed_criteria]\n                if design_details['views']:\n                    response = requests.put(url, json=design_details)\n                else:\n                    response = requests.delete(url)\n\n        return response.status_code", "response": "a method to delete a view associated with a user design document"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_user(self, uid, user_password, user_email='', user_channels=None, user_roles=None, user_views=None, disable_account=False):\n\n        '''\n            a method to add or update an authorized user to the bucket\n            \n        :param uid: string with id to assign to user\n        :param user_password: string with password to assign to user\n        :param user_email: [optional] string with email of user for future lookup\n        :param user_channels: [optional] list of strings with channels to subscribe to user\n        :param user_roles: [optional] list of strings with roles to assign to user\n        :param user_views: [optional] list of query criteria to create as views for user\n        :param disable_account: boolean to disable access to records by user\n        :return: integer with status code of user account creation\n        '''\n\n    # https://developer.couchbase.com/documentation/mobile/1.5/references/sync-gateway/admin-rest-api/index.html#/user/put__db___user__name_\n    # https://developer.couchbase.com/documentation/mobile/1.5/guides/sync-gateway/authorizing-users/index.html\n    \n        title = '%s.save_user' % self.__class__.__name__\n        \n    # validate inputs\n        input_fields = {\n            'uid': uid,\n            'user_password': user_password,\n            'user_email': user_email,\n            'user_channels': user_channels,\n            'user_roles': user_roles\n        }\n        for key, value in input_fields.items():\n            if value:\n                object_title = '%s(%s=%s)' % (title, key, str(value))\n                self.fields.validate(value, '.%s' % key, object_title)\n    \n    # construct url\n        url = self.bucket_url + '/_user/%s' % uid\n\n    # create default settings\n        json_data = {\n            'admin_channels': [ uid ],\n            'admin_roles': [ uid ],\n            'name': uid,\n            'password': user_password,\n            'disabled': disable_account\n        }\n    \n    # add optional additional channels and roles\n        if user_email:\n            json_data['email'] = user_email\n        if user_channels:\n            json_data['admin_channels'].extend(user_channels)\n        if user_roles:\n            json_data['admin_roles'].extend(user_roles)\n\n    # send request\n        response = requests.put(url, json=json_data)\n\n    # create indices\n        if response.status_code in (200, 201) and not self.public:\n            self.create_view(uid=uid)\n            if user_views:\n                for criteria in user_views:\n                    self.create_view(query_criteria=criteria, uid=uid)\n\n    # report outcome\n        self.printer('User \"%s\" updated in bucket \"%s\"' % (uid, self.bucket_name))\n        \n        return response.status_code", "response": "a method to add or update an authorized user to the bucket"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_user(self, uid):\n    \n        '''\n            a method to retrieve the account details of a user in the bucket\n            \n        :param uid: string with id of user in bucket \n        :return: dictionary with account fields for user\n        '''\n    \n        title = '%s.load_user' % self.__class__.__name__\n        \n    # validate inputs\n        input_fields = {\n            'uid': uid\n        }\n        for key, value in input_fields.items():\n            if value:\n                object_title = '%s(%s=%s)' % (title, key, str(value))\n                self.fields.validate(value, '.%s' % key, object_title)\n    \n    # construct url\n        url = self.bucket_url + '/_user/%s' % uid\n        \n    # send request and unwrap response\n        response = requests.get(url)\n        response = response.json()\n    \n        return response", "response": "a method to retrieve the account details of a user in the bucket \n"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_user(self, uid, delete_views=True):\n        \n        '''\n            a method to retrieve the account details of a user in the bucket\n            \n        :param uid: string with id of user in bucket\n        :param delete_views: boolean to remove indices attached to user\n        :return: integer with status of delete operation\n        '''\n    \n        title = '%s.delete_user' % self.__class__.__name__\n        \n    # validate inputs\n        input_fields = {\n            'uid': uid\n        }\n        for key, value in input_fields.items():\n            if value:\n                object_title = '%s(%s=%s)' % (title, key, str(value))\n                self.fields.validate(value, '.%s' % key, object_title)\n    \n    # delete any existing sessions\n        self.delete_sessions(uid)\n    \n    # delete any existing views\n        if delete_views:\n            self.delete_view(uid=uid)\n            \n    # construct url\n        url = self.bucket_url + '/_user/%s' % uid\n\n    # send request\n        response = requests.delete(url)\n    \n    # report outcome\n        self.printer('User \"%s\" removed from bucket \"%s\"' % (uid, self.bucket_name))\n        \n        return response.status_code", "response": "a method to retrieve the account details of a user in the bucket and delete any existing sessions and views"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_session(self, uid, duration=0):\n\n        '''\n            a method to create a session token for the user\n            \n        :param uid: string with id of user in bucket\n        :param duration: integer with number of seconds to last (default: 24hrs) \n        :return: dictionary with account fields for user\n        '''\n    \n        title = '%s.create_session' % self.__class__.__name__\n        \n    # validate inputs\n        input_fields = {\n            'uid': uid,\n            'duration': duration\n        }\n        for key, value in input_fields.items():\n            if value:\n                object_title = '%s(%s=%s)' % (title, key, str(value))\n                self.fields.validate(value, '.%s' % key, object_title)\n        \n    # construct request fields\n        url = self.bucket_url + '/_session'\n        json_data = {\n            'name': uid\n        }\n        if duration:\n            json_data['ttl'] = duration\n    \n    # send request and unwrap response\n        response = requests.post(url, json=json_data)\n        response = response.json()\n    \n        return response", "response": "a method to create a session token for the user in bucket"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef exists(self, doc_id, rev_id=''):\n        \n        '''\n            a method to determine if document exists\n            \n        :param doc_id: string with id of document in bucket \n        :param rev_id: [optional] string with revision id of document in bucket\n        :return: boolean indicating existence of document\n        '''\n\n        title = '%s.exists' % self.__class__.__name__\n\n    # validate inputs\n        input_fields = {\n            'doc_id': doc_id,\n            'rev_id': rev_id\n        }\n        for key, value in input_fields.items():\n            if value:\n                object_title = '%s(%s=%s)' % (title, key, str(value))\n                self.fields.validate(value, '.%s' % key, object_title)\n    \n    # send request and construct response\n        url = self.bucket_url + '/%s' % doc_id\n        params = None\n        if rev_id:\n            params = { 'rev': rev_id }\n        response = requests.get(url, params=params)\n        if not 'error' in response.json():\n            return True\n        return False", "response": "a method to determine if a document in a bucket contains a specific entry in the database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list(self, query_criteria=None, uid='_all_users', all_versions=False, previous_id='', purge_deleted=False):\n    \n        '''\n            a generator method for retrieving documents from the bucket \n            \n        :param query_criteria: [optional] dictionary with valid jsonmodel query criteria \n        :param uid: [optional] string with uid of design document to update\n        :param all_versions: boolean to include previous revisions in query\n        :param previous_id: [optional] string with id of the last doc in a previous query\n        :param purge_deleted: boolean to purge any files in results which have been deleted\n        :return: dictionary with document fields\n\n        NOTE:   to efficiently use the query architecture of couchbase, it is important\n                to first create a view for any query criteria you wish to use. if a\n                specific query criteria is not previously created or no query criteria\n                is included, then list will scan all documents based upon the uid field\n                and return the appropriate matching results\n\n        an example of how to construct the query_criteria argument:\n\n        query_criteria = {\n            '.path.to.number': {\n                'min_value': 4.5\n            },\n            '.path.to.string': {\n                'discrete_values': [ 'pond', 'lake', 'stream', 'brook' ]\n            }\n        }\n        \n        NOTE:   only fields specified in the document schema at class initialization\n                can be used as fields in query_criteria. otherwise, an error will be thrown.\n                uid is automatically added to all document schemas at initialization\n                \n        NOTE:   the full list of all criteria are found in the reference page for the\n                jsonmodel module as well as the query-rules.json file included in the\n                module. \n                http://collectiveacuity.github.io/jsonModel/reference/#query-criteria \n        '''\n\n        title = '%s.list' % self.__class__.__name__\n    \n    # validate inputs\n        input_fields = {\n            'uid': uid,\n            'previous_id': previous_id\n        }\n        for key, value in input_fields.items():\n            if value:\n                object_title = '%s(%s=%s)' % (title, key, str(value))\n                self.fields.validate(value, '.%s' % key, object_title)\n\n    # validate inputs\n        if query_criteria:\n            if not self.model:\n                raise ValueError('%s(query_criteria={...} requires a document_schema.' % title)\n            self.model.query(query_criteria)\n        else:\n            query_criteria = {}\n        if uid != '_all_users' and self.public:\n            raise ValueError('%s(uid=\"%s\") user ids are not applicable for a public bucket. % title')\n\n    # define url for all documents\n        hashed_criteria = ''\n        ordered_criteria = None\n        if not query_criteria and uid == '_all_users':\n            url = self.bucket_url + '/_all_docs'\n    \n    # define url for sub-set of documents\n        else:\n                \n        # define error message\n            error_message = '%s(uid=\"%s\") does  not exist. Try: %s.create_view(uid=\"%s\")' % (title, uid, self.__class__.__name__, uid)\n        \n        # establish all users if no uid\n            if not uid:\n                raise Exception('%s(uid=\"\") is a required field.' % title)\n            \n        # retrieve design document\n            design_url = self.bucket_url + '/_design/%s' % uid\n            response = requests.get(design_url)\n            response = response.json()\n            if 'error' in response.keys():\n                raise Exception(error_message)\n        \n        # validate existence of view\n            if not query_criteria:\n                if not '_all_docs' in response['views'].keys():\n                    raise Exception(error_message)\n                url = self.bucket_url + '/_design/%s/_view/_all_docs' % uid\n            else:\n        \n            # determine hashed key for criteria\n                import hashlib\n                import json\n                from collections import OrderedDict\n                ordered_criteria = OrderedDict(**query_criteria)\n                hashed_criteria = hashlib.md5(json.dumps(query_criteria, sort_keys=True).encode('utf-8')).hexdigest()\n    \n            # define url based upon existence of hashed key and uid\n                if hashed_criteria in response['views'].keys():\n                    url = self.bucket_url + '/_design/%s/_view/%s' % (uid, hashed_criteria)\n                elif uid == '_all_users':\n                    hashed_criteria = ''\n                    url = self.bucket_url + '/_all_docs'\n                else:\n                    hashed_criteria = ''\n                    url = self.bucket_url + '/_design/%s/_view/_all_docs' % uid\n\n    # determine query params\n        params = {\n            'limit': 101,\n            'revs': all_versions\n        }\n        if previous_id:\n            params['startkey'] = previous_id\n        break_off = False\n\n    # send request\n        while True:\n            response = requests.get(url, params=params)\n\n        # report records\n            response_details = response.json()\n\n        # break off if reached end of records\n            if not 'rows' in response_details.keys():\n                break\n            elif not response_details['rows']:\n                break\n        \n        # evaluate each row of view results\n            else:\n                for i in range(len(response_details['rows'])):\n    \n                # skip previous key\n                    if not 'startkey' in params.keys() or i:\n                        row = response_details['rows'][i]\n                        params['startkey'] = row['id']\n\n                    # evaluate query criteria in view\n                        if hashed_criteria and row['value']:\n\n                            from labpack.mapping.data import reconstruct_dict\n                            dot_paths = []\n                            for key in ordered_criteria.keys():\n                                dot_paths.append(key)\n                            record_dict = reconstruct_dict(dot_paths, row['value'])\n                            if self.model.query(query_criteria, record_dict):\n                                doc_details = self.read(row['id'])\n                                if not doc_details:\n                                    if purge_deleted:\n                                        self.purge(row['id']) # eliminate stranded records\n                                else:\n                                    yield doc_details\n\n                    # else scan documents\n                        else:\n                            doc_details = self.read(row['id'])\n\n                        # filter results with query criteria\n                            if not doc_details:\n                                if purge_deleted:\n                                    self.purge(row['id']) # eliminate stranded records\n                            else:\n                                if query_criteria:\n                                    if self.model.query(query_criteria, doc_details):\n                                        yield doc_details\n                                else:\n                                    yield doc_details\n\n                # end if no more results\n                    elif len(response_details['rows']) == 1:\n                        break_off = True\n                        break\n\n            if break_off:\n                break", "response": "a generator method for retrieving documents from the bucket \n            "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(self, doc_details):\n\n        '''\n            a method to create a new document in the collection\n\n        :param doc_details: dictionary with document details and user id value\n        :return: dictionary with document details and _id and _rev values\n        '''\n        \n        # https://developer.couchbase.com/documentation/mobile/1.5/references/sync-gateway/admin-rest-api/index.html#/document/post__db___doc_\n\n        title = '%s.create' % self.__class__.__name__\n\n    # validate input\n        if self.model:\n            doc_details = self.model.validate(doc_details, path_to_root='', object_title='%s(doc_details={...}' % title)\n\n    # define request fields\n        from copy import deepcopy\n        new_record = deepcopy(doc_details)\n        url = self.bucket_url + '/'\n\n    # send request and construct output\n        response = requests.post(url, json=new_record)\n        if response.status_code not in (200, 201):\n            response = response.json()\n            raise Exception('%s() error: %s' % (title, response))\n        response = response.json()\n        new_record['_id'] = response['id']\n        new_record['_rev'] = response['rev']\n    \n        return new_record", "response": "a method to create a new document in the collection"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove(self):\n\n        '''\n            a method to remove the entire bucket from the database \n\n        :return: string with confirmation message \n        '''\n\n        # https://developer.couchbase.com/documentation/mobile/1.5/references/sync-gateway/admin-rest-api/index.html#/database/delete__db__\n\n        title = '%s.remove' % self.__class__.__name__\n\n    # validate admin access\n        if not self.admin_access:\n            raise Exception('%s requires admin access.' % title)\n\n    # flush files on server\n        if self.configs['server'].find('http:') > -1:\n            flush_url = self.configs['server'] + '/pools/%s/buckets/%s/controller/doFlush' % (self.configs['pool'], self.bucket_name)\n            response = requests.post(flush_url)\n            try:\n                print(response.json())\n            except:\n                print(response.status_code)\n    \n    # else (in dev) iterate over files and users and purge \n        elif self.configs['server'].find('walrus') > -1:\n            for doc in self.list(purge_deleted=True):\n                self.purge(doc['_id'])\n            user_list = self.list_users()\n            for uid in user_list:\n                self.delete_user(uid)\n            self.delete_view()\n\n    # delete bucket from configs\n        delete_url = self.bucket_url + '/'\n        requests.delete(delete_url)\n        \n    # report outcome\n        exit_msg = 'Bucket \"%s\" removed from database.' % self.bucket_name\n        self.printer(exit_msg)\n        \n        return exit_msg", "response": "a method to remove the entire bucket from the database \n\n "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_chart(self):\n        encoding, properties = {}, {}\n\n        if self.orientation == \"horizontal\":\n            # Set the axis\n            encoding[\"x\"] = alt.X(\n                \"hex\",\n                axis=None,\n                scale=alt.Scale(zero=False, padding=0)\n            )\n\n            # Set the rectangle size.\n            properties[\"width\"] = len(self.df)*self.square_size\n            properties[\"height\"] = self.square_size\n\n        elif self.orientation == \"vertical\":\n            # Set the axis\n            encoding[\"y\"] = alt.Y(\n                \"hex\",\n                axis=None,\n                scale=alt.Scale(zero=False, padding=0)\n            )\n\n            # Set the rectangle size.\n            properties[\"height\"] = len(self.df)*self.square_size\n            properties[\"width\"] = self.square_size\n\n        # Build a chart.\n        tooltip = list(self.df.columns)\n        chart = alt.Chart(self.df).mark_rect().encode(\n            color=alt.Color(\"hex\", legend=None, scale=alt.Scale(range=self.colors)),\n            tooltip=tooltip,\n            **encoding\n        ).properties(\n            **properties\n        )\n        return chart", "response": "Write color palette to Altair Chart."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _repr_mimebundle_(self, *args, **kwargs):\n        chart = self.to_chart()\n        dct = chart.to_dict()\n        return alt.renderers.get()(dct)", "response": "Return a MIME bundle for display in Jupyter frontends."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_request(self, req, resp):\n\n        key = req.env['REMOTE_PORT'] + req.env['REMOTE_ADDR']\n        val = self.cache.get(key, 0)\n\n        if val == self.count:\n            abort(exceptions.TooManyRequests(headers=self._error_headers))\n        else:\n            self.cache[key] = val + 1", "response": "Process the request before routing it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _enter_newline(self):\n\n        last_text_idx = self._last_text_idx\n        if last_text_idx >= 0:\n            buf = self._buffer\n            buf[last_text_idx] = buf[last_text_idx].rstrip()\n\n        self._remove_begining_ws = True", "response": "Remove trailing spaces in the current line and mark that leading spaces of the next line need to be removed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove comment except IE conditional comment. .. seealso:: `About conditional comments <http://msdn.microsoft.com/en-us/library/ms537512.ASPX>`_", "response": "def handle_comment(self, comment):\n        \"\"\"\n        Remove comment except IE conditional comment.\n\n        .. seealso::\n           `About conditional comments\n            <http://msdn.microsoft.com/en-us/library/ms537512.ASPX>`_\n        \"\"\"\n\n        match = _COND_COMMENT_PATTERN.match(comment)\n        if match is not None:\n            cond = match.group(1)\n            content = match.group(2)\n\n            self._buffer.append(_COND_COMMENT_START_FORMAT % cond)\n            self._push_status()\n            self.feed(content)\n            self._pop_status()\n            self._buffer.append(_COND_COMMENT_END_FORMAT)\n        elif not self.remove_comments:\n            self._buffer.append(_COMMENT_FORMAT % comment)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle the start tag of the tag.", "response": "def handle_startendtag(self, tag, attrs):\n        \"\"\"\n        Normalize the tag with trailing '/' character (such as `<img ... />`).\n\n        The trailing '/' character has no effect on void elements, but on\n        foreign elements it marks the start tag as self-closing.\n\n        .. seealso::\n           `HTML5 - Start tags\n            <http://www.w3.org/TR/html5-author/syntax.html#syntax-start-tag>`_\n        \"\"\"\n        is_foreign = tag not in _VOID_ELEMENTS\n        self._append_tag(tag, attrs, closing=is_foreign)\n        if tag in _BLOCK_ELEMENTS:\n            self._enter_newline()\n        elif tag not in _HIDDEN_ELEMENTS:\n            self._reset_newline_status()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handle_data(self, data):\n\n        tag_stack = self._tag_stack\n        if tag_stack and tag_stack[-1] in _RM_WS_ELEMENTS:\n            # just ignore the content of this element\n            assert data.strip() == ''\n            return\n\n        if self._preserve == 0:\n            if self._remove_begining_ws:\n                data = data.lstrip()\n                if not data:\n                    return\n\n                self._remove_begining_ws = False\n\n            self._last_text_idx = len(self._buffer)\n\n            data = _WS_PATTERN.sub(' ', data)\n            if data and data[-1] == ' ':\n                # immediately followed spaces will be collapsed\n                self._remove_begining_ws = True\n        else:\n            # the content cannot be stripped\n            self._reset_newline_status()\n\n        self._buffer.append(data)", "response": "Handle the data from the internal buffer."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nedits the credentials used by the secure. secure class.", "response": "def edit_credentials(self, credential=None, already_set=True):\n        \"\"\"\n        Edit the credentials used by the :py:class:`~pypersonalassistant.secure.secure` class.\n        \n        .. note :: User input is required.\n\n        By default, unset credentials will be displayed.\n        \n        :param string credential: A specific credential to edit.\n        :param bool already_set: If `False` will show all credentials, whether set or unset.\n        \"\"\"\n        # get user input of credentials\n        # save and reload credentials.json\n        credentials_required = self._CREDENTIALS_REQUIRED\n        if credential:\n            credentials_required = [credential]\n        \n        for cred in credentials_required:\n            # If credential is already set, decide whether to continue\n            if (cred in self._credentials) and ((already_set is False) and (credential is None)):\n                continue\n            else:\n                current_encrypted_value = ''\n                try:\n                    current_encrypted_value = self._credentials_encrypted[cred]\n                except KeyError:\n                    None\n                \n                prompt = '\\nCredential: {0}\\nCurrent (encrypted) value: {1}\\nEnter new value, or press enter to skip: '.format(cred, current_encrypted_value)\n                input_value = confirm_input(prompt)      \n                if input_value == '':\n                    logging.info('{0} skipped'.format(cred))\n                else:\n                    self._credentials.update({cred: input_value})\n                    logging.info('{0} updated: {1}'.format(cred, input_value))\n        self._save_credentials()\n        self._load_credentials()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef twilio_SMS(self, from_, to, body):\n        logging.debug('Texting from Twilio')\n        client = TwilioRestClient(self._credentials['TWILIO_ACCOUNT_SID'], self._credentials['TWILIO_AUTH_TOKEN']) \n        response = client.messages.create(\n            to=to, \n            from_=from_, \n            body=body,  \n        )\n        logging.debug('Response from Twilio: {0}'.format(response))\n        return response", "response": "Send an SMS message from your twilio account."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef SMS(self, to, body):\n        logging.debug('Texting someone')\n        return self.twilio_SMS(self._credentials['TWILIO_PHONE_NUMBER'], to, body)", "response": "Send an SMS message from a default number."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef SMS_me(self, body):\n        logging.debug('Texting myself')\n        return self.text(self._credentials['PERSONAL_PHONE_NUMBER'], body)", "response": "Quickly send an SMS to yourself."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend an email from Gmail.", "response": "def gmail_email(self, from_, to, msg):\n        \"\"\"\n        Send an email from your `gmail`_ account.\n        \n        .. _gmail: https://mail.google.com/\n        \n        msg can either be:\n        \n        * A string, in which case:\n        \n            * At the first newline (\\\\n) the string will be split into subject and body\n            * If no newline is present, the entire string will be body.\n        \n        * An `email.message.Message`_ object\n        \n        .. _email.message.Message: https://docs.python.org/3/library/email.message.html\n        \n        Login will be performed using stored credentials.\n        \n        * *stored credential name: GMAIL_EMAIL*\n        * *stored credential name: GMAIL_EMAIL_PASSWORD*\n        \n        :param string from_: The phone number in your twilio account to send the SMS message from. Full international format.        \n        :param string to: The email address to send the email to.\n        :param body: The content of the email. See above. \n        \"\"\"\n        logging.debug('Emailing from Gmail')\n        smtpConn = smtplib.SMTP('smtp.gmail.com', 587)\n        smtpConn.ehlo()\n        smtpConn.starttls()\n        login_response = smtpConn.login(self._credentials['GMAIL_EMAIL'], self._credentials['GMAIL_EMAIL_PASSWORD'])\n        \n        # if email is of type email.message.Message, flatten and send\n        # if anything else, convert to string and try and send\n        if isinstance(msg, email.message.Message):\n            logging.debug('Flattening MIME to string')\n            # If From is already set, overwrite\n            msg['From'] = from_\n            # If To is string, convert to list and add each to header\n            if isinstance(to, str):\n                to = [to]\n            for x in to:\n                msg['To'] = x\n            msg = msg.as_string()\n        else:\n            msg = str(msg)\n        \n        logging.debug(msg.replace('\\n', ' '))\n        response = smtpConn.sendmail(from_, to, msg)\n        logging.info('Response from Gmail: {0}'.format(response))\n        smtpConn.quit()\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef email(self, to, msg):\n        logging.debug('Emailing someone')\n        return self.gmail_email(self._credentials['GMAIL_EMAIL'], to, msg)", "response": "Sends an email from a default address."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef configure(self, config):\n        credentials = CredentialParams.many_from_config(config)\n        for credential in credentials:\n            self._credentials.append(credential)", "response": "Configures the component by passing configuration parameters."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _req(self, op, uri, payload = None):\n\t\t'''HTTP  reequest wrapper with data packaging fucntionality\n\t\tArgs:\n\t\t\top \t\t\thttp verb in str\n\t\t\turi \t\taddress of the request\n\t\t\tpayload\t\tdata to be sent in dict format (default: None) \n\t\t\t\t\t\tIf not provided no data is sent\n\t\t\treturn \t\tcode and req response dict (single or list)'''\n\t\tif DEBUG:\n\t\t\tprint(('uri', uri))\n\n\t\treq_fp, content_type = self._get_req_fp(op)\n\t\t\n\t\tif payload:\n\t\t\tif content_type:\n\t\t\t\tr = req_fp(uri, payload, auth = self.api_auth, headers = content_type)\n\t\t\telse:\n\t\t\t\tr = req_fp(uri, payload, auth = self.api_auth)\n\t\telse:\n\t\t\tr = req_fp(uri, auth = self.api_auth)\n\t\t\n\t\tif r.status_code == requests.codes.ok:\n\t\t\tdata = r.json()\n\t\telse:\n\t\t\tdata = None\n\t\t\tpass\n\t\t#keep for debugging \n\n\t\t#in case there's an error and we're debugging\n\t\tself._parse_req(r)\n\n\t\treturn r.status_code, data", "response": "HTTP request wrapper with data packaging fucntionality"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_req(self, req):\n\t\t'''Parses a request object for relevant debugging information. Only works\n\t\tif DEBUG is enabled.\n\t\tArgs:\n\t\t\treq \t\t\trequests req object\n\t\t'''\n\t\tif DEBUG:\n\t\t\tif req.status_code != requests.codes.ok:\n\t\t\t\tprint((\"code: {}\".format(req.status_code)))\n\t\t\t\tprint((\"response {}\".format(req.json())))\n\t\t\t\tprint((\"req headers {}\".format(req.request.headers)))\n\t\t\t\tprint((\"req body {}\".format(req.request.body)))", "response": "Parses a request object for relevant debugging information. Only works\n\tif DEBUG is enabled."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting user information from the server and update the attribute if", "response": "def get_user(self, key = None):\n\t\t'''Get user information from the server and update the attribute\n\t\tArgs:\n\t\t\tkey\t\t\tuser key (default: me)\n\t\t\treturn\t\t(status code for the get request, dict user data)\n\t\t''' \t\n\t\tif key:\n\t\t\turi = self.api_uri + \"/users/\" + key\n\t\telse:\n\t\t\turi = self.api_uri + \"/users/me\"\n\n\t\treturn self._req('get', uri)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes a pipeline specified by the key.", "response": "def delete_pipeline(self, pipeline_key):\n\t\t'''Deletes the pipeline specified by the key\n\t\tArgs:\n\t\t\treturns \t(status code for the DELETE request, success message dict)\n\t\t\t\t\t\texpect (200 , {'success': 'true'}) for successful execution}\n\t\t'''\n\t\tif pipeline_key:\n\t\t\turi = '/'.join([\n\t\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\t\tself.pipelines_suffix,\n\t\t\t\t\t\t\tpipeline_key\n\t\t\t\t\t\t\t])\n\t\t\treturn self._req('delete', uri)\n\t\telse:\n\t\t\treturn requests.codes.bad_request, None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_all_pipelines(self):\n\t\t'''Deletes all pipelines\n\t\tArgs:\n\t\t\treturns\t\tOK for overall success or last error code, resp data.\n\t\t'''\n\t\tcode, data = self.get_pipeline()\n\t\tif code == requests.codes.ok:\n\t\t\tfor pl_data in data:\n\t\t\t\tc, d = self.delete_pipeline(pl_data['pipelineKey'])\n\t\t\t\tif c != requests.codes.ok:\n\t\t\t\t\tcode = c\n\t\t\t\t\tdata = d\n\t\treturn code, data", "response": "Deletes all pipelines in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new pipeline with the provided attributes.", "response": "def create_pipeline(self, name, description, **kwargs):\n\t\t'''Creates a pipeline with the provided attributes.\n\t\tArgs:\n\t\t\tname\trequired name string\n\t\t\tkwargs\t{name, description, orgWide, aclEntries} user \n\t\t\tspecifiable ones only\n\t\t\treturn\t(status code, pipeline_dict) (as created)\n\t\t'''\n\t\t#req sanity check\n\t\tif not (name and description):\n\t\t\treturn requests.codes.bad_request, None\n\n\t\tkwargs.update({'name':name, 'description':description})\n\n\t\tnew_pl = StreakPipeline(**kwargs)\n\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\tself.pipelines_suffix\n\t\t\t\t\t\t])\n\t\tcode, r_data = self._req('put', uri, new_pl.to_dict())\n\t\t\n\t\treturn code, r_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates a pipeline with the provided attributes.", "response": "def update_pipeline(self, pipeline):\n\t\t'''Updates a pipeline with the provided attributes.\n\t\tArgs:\n\t\t\tkey\t\t\trequired identifier for the pipeline\n\t\t\tpipeline\tStreakPipeline object\n\t\t\treturn\t\t(status code, pipeline_dict)\n\t\t'''\n\t\t#req sanity check\n\t\tpayload = None\n\t\tif  type(pipeline) is not StreakPipeline:\n\t\t\treturn requests.codes.bad_request, None\n\n\t\tpayload = pipeline.to_dict(rw = True)\n\n\t\ttry:\n\t\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\tself.pipelines_suffix,\n\t\t\t\t\t\tpipeline.attributes['pipelineKey']\n\t\t\t\t\t\t])\n\t\texcept KeyError:\n\t\t\treturn requests.codes.bad_request, None\n\t\n\t\tcode, r_data = self._req('post', uri , json.dumps(payload))\n\n\t\treturn code, r_data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a list of one or all box objects. Performs a single GET.", "response": "def get_box(self, box_key = None, sort_by = None):\n\t\t'''Gets a list of one/all box objects. Performs a single GET.\n\t\tTo go deeper individual boxes need to be polled for their contents.\n\t\tThis is a directory for what we could ask for.\n\t\tArgs:\n\t\t\tbox_key\t\tkey for the target box (default: None i.e. ALL)\n\t\t\tsort_by\t\tin desc order by 'creationTimestamp' or 'lastUpdatedTimestamp'\n\t\t\treturns \t(status code for the GET request, dict of box or a list thereof) \n\t\t'''\n\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\tself.boxes_suffix\n\t\t\t\t\t\t])\n\t\tif box_key:\n\t\t\turi = '/'.join([\n\t\t\t\t\t\t\turi,\n\t\t\t\t\t\t\tbox_key\n\t\t\t\t\t\t\t])\n\t\tif sort_by:\n\t\t\t\tif sort_by in ['creationTimestamp', 'lastUpdatedTimestamp']:\n\t\t\t\t\turi += self.sort_by_postfix + sort_by\n\t\t\t\telse:\t\t\n\t\t\t\t\treturn requests.codes.bad_request, {'success' : 'False', \n\t\t\t\t\t\t\t\t\t\t\t\t'error': 'sortBy needs to be \\'creationTimestamp\\', or \\'lastUpdatedTimestamp\\''}\n\t\treturn self._req('get', uri)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a list of all boxes in a pipeline.", "response": "def get_pipeline_boxes(self, pipeline_key, sort_by = None):\n\t\t'''Gets a list of all box objects in a pipeline. Performs a single GET.\n\t\tArgs:\n\t\t\tpipeline_key\tkey for pipeline\n\t\t\tsort_by\t\t\tin desc order by 'creationTimestamp' or 'lastUpdatedTimestamp'\n\t\t\t\t\t\t\tNot sure if it is supported\n\t\t\treturns \t\t(status code for the GET request, dict of boxes) \n\t\t'''\n\t\tif not pipeline_key:\n\t\t\treturn requests.codes.bad_request, None\n\n\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\tself.pipelines_suffix,\n\t\t\t\t\t\tpipeline_key\n\t\t\t\t\t\t])\n\t\t\n\t\tif sort_by:\n\t\t\t\tif sort_by in ['creationTimestamp', 'lastUpdatedTimestamp']:\n\t\t\t\t\turi += self.sort_by_postfix + sort_by\n\t\t\t\telse:\t\t\n\t\t\t\t\treturn requests.codes.bad_request, {'success' : 'False', \n\t\t\t\t\t\t\t\t\t\t\t\t'error': 'sortBy needs to be \\'creationTimestamp\\', or \\'lastUpdatedTimestamp\\''}\n\t\t\n\t\treturn self._req('get', uri)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete the box specified by the key.", "response": "def delete_box(self, key):\n\t\t'''Deletes the box specified by the key\n\t\tArgs:\n\t\t\treturns \t(status code for the DELETE request, success message dict)\n\t\t'''\n\t\tif key:\n\t\t\turi = self.box_root_uri + '/' + key\n\t\t\treturn self._req('delete', uri)\n\t\telse:\n\t\t\treturn requests.codes.bad_request, None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_pipeline_box(self, pipeline_key, name, **kwargs):\n\t\t'''Creates a box int the pipeline specified with the provided attributes.\n\t\tArgs:\n\t\t\tname\trequired name string\n\t\t\tkwargs\t{...} see StreakBox object for details\n\t\t\treturn\t(status code, box dict)\n\t\t'''\n\t\t#req sanity check\n\t\tif not (pipeline_key and name):\n\t\t\treturn requests.codes.bad_request, None\n\n\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\tself.pipelines_suffix,\n\t\t\t\t\t\tpipeline_key,\n\t\t\t\t\t\tself.boxes_suffix\n\t\t\t\t\t\t]) \n\n\t\tkwargs.update({'name':name})\n\n\t\tnew_box = StreakBox(**kwargs)\n\t\t\n\t\tcode, data = self._req('put', uri, new_box.to_dict(rw = True))\n\t\t\n\t\treturn code, data", "response": "Creates a new box int in the pipeline with the provided attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate a box with the provided attributes.", "response": "def update_box(self, box):\n\t\t'''Updates a box with the provided attributes.\n\t\tArgs:\n\t\t\tbox \tStreakBox object with updated info\n\t\t\treturn\t(status code, box in dict form)\n\t\t'''\n\t\t#req sanity check\n\t\tpayload = None\n\t\tif  type(box) is not StreakBox:\n\t\t\treturn requests.codes.bad_request, None\n\n\t\tpayload = box.to_dict(rw = True)\n\n\t\ttry:\n\t\t\turi = self.box_root_uri + '/' + box.attributes['boxKey']\n\t\texcept KeyError:\n\t\t\treturn requests.codes.bad_request, None\n\t\n\t\tcode, data = self._req('post', uri , json.dumps(payload))\n\n\t\treturn code, data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch for a keyword and returns the search results.", "response": "def search(self, kw):\n\t\t'''Takes a keyword and returns the search results.\n\t\tWorks for boxes only?\n\t\tArgs:\n\t\t\tkw\t\tkeyword (str) to search for.\n\t\t\treturn\t(code, list(dicts))\n\t\t'''\n\t\tif not kw:\n\t\t\treturn requests.codes.bad_request, None\n\n\t\tcode, data = self._req('get', self.search_uri + kw)\n\n\t\treturn code, data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_snippet(self, snippet_key = None):\n\t\t'''Get all/one specific snippet by its key\n\t\tArgs:\n\t\t\tkey\t\t\tsnippet key (default: None i.e. ALL)\n\t\t\treturn\t\t(status code, snippet dict or list thereof)\n\t\t'''\n\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\tself.snippets_suffix\n\t\t\t\t\t\t])\n\t\tif snippet_key:\n\t\t\turi = '/'.join([\n\t\t\t\t\t\t\turi,\n\t\t\t\t\t\t\tsnippet_key\n\t\t\t\t\t\t\t])\n\n\t\tcode, data =  self._req('get', uri)\n\t\t\n\t\treturn code, data", "response": "Get all specific snippet by its key"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a list of one or all stages in a pipeline.", "response": "def get_pipeline_stage(self, pipeline_key, stage_key = None, sort_by = None):\n\t\t'''Gets a list of one/all stage objects in a pipeline. Performs a single GET.\n\t\tArgs:\n\t\t\tpipeline_key\tkey for pipeline\n\t\t\tstage_key \t\tkey for stage (default: None i.e. ALL)\n\t\t\tsort_by\t\t\tin desc order by 'creationTimestamp' or 'lastUpdatedTimestamp'\n\t\t\t\t\t\t\tmay or may not be supported\n\t\t\treturns \t\t(status code for the GET request, dict of stages)\n\t\t\t\t\t\t\tIt is not a list hence the .values() before return\n\t\t'''\n\t\tif not pipeline_key:\n\t\t\treturn requests.codes.bad_request, None\n\n\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\tself.pipelines_suffix,\n\t\t\t\t\t\tpipeline_key,\n\t\t\t\t\t\tself.stages_suffix\n\t\t\t\t\t\t])\n\t\tif stage_key:\n\t\t\turi = '/'.join([\n\t\t\t\t\t\t\turi,\n\t\t\t\t\t\t\tstage_key\n\t\t\t\t\t\t\t])\n\t\t\n\t\tif sort_by:\n\t\t\t\tif sort_by in ['creationTimestamp', 'lastUpdatedTimestamp']:\n\t\t\t\t\turi += self.sort_by_postfix + sort_by\n\t\t\t\telse:\t\t\n\t\t\t\t\treturn requests.codes.bad_request, {'success' : 'False', \n\t\t\t\t\t\t\t\t\t\t\t\t'error': 'sortBy needs to be \\'creationTimestamp\\', or \\'lastUpdatedTimestamp\\''}\n\n\t\tcode, data = self._req('get', uri)\n\t\t\n\t\t#format is ambigious so we need to rely on user input\n\t\tif stage_key:\n\t\t\tdata = list(data.values())\n\t\t\n\t\treturn code, data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_pipeline_stage(self, pipeline_key, name, **kwargs):\n\t\t'''Creates a pipeline stage with the provided attributes.\n\t\tArgs:\n\t\t\tname\trequired name string\n\t\t\tkwargs\t{..} see StreakStage object for details\n\t\t\treturn\t(status code, stage dict)\n\t\t'''\n\t\t#req sanity check\n\t\tif not (pipeline_key and name):\n\t\t\treturn requests.codes.bad_request, None\n\n\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\tself.pipelines_suffix,\n\t\t\t\t\t\tpipeline_key,\n\t\t\t\t\t\tself.stages_suffix])\n\t\t\n\t\tkwargs.update({'name':name})\n\n\t\tnew_box = StreakStage(**kwargs)\n\t\t\n\t\tcode, data = self._req('put', uri, new_box.to_dict(rw = True))\n\t\t\n\t\treturn code, data", "response": "Create a new pipeline stage."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_pipeline_stage(self, pipeline_key, stage_key, sort_by = None):\n\t\t'''Deletes a stage in the pipeline by stage key and pipeline key\n\t\tArgs:\n\t\t\tpipeline_key\tkey for pipeline\n\t\t\tstage_key\t\tkey for stage\n\t\t\tsort_by\t\t\tin desc order by 'creationTimestamp' or 'lastUpdatedTimestamp'\n\t\t\treturns \t\t(status code for the GET request, dict of op report) \n\t\t'''\n\t\tif not (pipeline_key and stage_key):\n\t\t\treturn requests.codes.bad_request, None\n\n\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\tself.pipelines_suffix,\n\t\t\t\t\t\tpipeline_key,\n\t\t\t\t\t\tself.stages_suffix,\n\t\t\t\t\t\tstage_key\n\t\t\t\t\t\t])\n\t\t\n\t\tcode, data = self._req('delete', uri)\n\t\t\n\t\treturn code, data", "response": "Delete a stage in a pipeline"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_pipeline_stage(self, stage):\n\t\t'''Updates a box with the provided attributes.\n\t\tArgs:\n\t\t\tpipeline_key\treqiured identifier for the pipeline\n\t\t\tstage\t\t\tStreakStage object\n\t\t\tkwargs\t\t\t{name}\n\t\t\treturn\t\t\t(status code, stage dict)\n\t\t'''\n\t\t#req sanity check\n\t\tpayload = None\n\t\tif  type(stage) is not StreakStage:\n\t\t\treturn requests.codes.bad_request, None\n\n\t\tpayload = stage.to_dict(rw = True)\n\t\n\t\t#print(new_pl.attributes)\n\t\t#print(new_pl.to_dict())\n\t\t#raw_input()\n\t\ttry:\n\t\t\turi = '/'.join([self.api_uri,\n\t\t\t\t\t\t\tself.pipelines_suffix,\n\t\t\t\t\t\t\tstage.attributes['pipelineKey'],\n\t\t\t\t\t\t\tself.stages_suffix,\n\t\t\t\t\t\t\tstage.attributes['key']\n\t\t\t\t\t\t\t])\n\t\texcept KeyError:\n\t\t\treturn requests.codes.bad_request, None\n\t\n\t\tcode, data = self._req('post', uri , json.dumps(payload))\n\t\t\n\t\treturn code, data", "response": "Updates a box with the provided attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new StreakField object.", "response": "def _create_field(self, uri , name, field_type, **kwargs):\n\t\t'''Creates a field with the provided attributes.\n\t\tArgs:\n\t\t\turi\t\tbase uri for the field (pipeline or box uri)\n\t\t\tname\trequired name string\n\t\t\tfield_type\trequired type string [TEXT_INPUT, DATE or PERSON]\n\t\t\tkwargs\t{}\n\t\t\treturn\t(status code, field dict)\n\t\t'''\n\t\t#req sanity check\n\t\tif not (name and (field_type in ['TEXT_INPUT', 'DATE', 'PERSON'])):\n\t\t\treturn requests.codes.bad_request, {'success' : 'False', \n\t\t\t\t\t\t\t\t\t\t\t\t'error': 'name needs to be provided and field_type needs to be \\'TEXT_INPUT\\', \\'DATE\\' or \\'PERSON\\''}\n\n\t\tkwargs.update({'name':name, 'type':field_type})\n\n\t\tnew_box = StreakField(**kwargs)\n\t\t#print(new_pl.attributes)\n\t\t#print(new_pl.to_dict())\n\t\t#raw_input()\n\t\tcode, data = self._req('put', uri, new_box.to_dict(rw = True))\n\t\t\n\t\treturn code, data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate a field with the provided attributes.", "response": "def _update_field(self, uri, field):\n\t\t'''Updates a field with the provided attributes.\n\t\tArgs:\n\t\t\tkey\treqiured identifier for the pipeline or box\n\t\t\tfield\t\t\tStreakField object\n\t\t\tkwargs\t\t\t{name, type} see StreakField for details\n\t\t\treturn\t\t\t(status code, field dict)\n\t\t'''\n\t\t#req sanity check\n\t\tpayload = None\n\t\tif  type(field) is not StreakField:\n\t\t\treturn requests.codes.bad_request, None\n\n\t\tpayload = field.to_dict(rw = True)\n\t\n\t\t#print(new_pl.attributes)\n\t\t#print(new_pl.to_dict())\n\t\t#raw_input()\n\t\ttry:\n\t\t\turi = '/'.join([\n\t\t\t\t\t\t\turi, \n\t\t\t\t\t\t\tfield.attributes['key']\n\t\t\t\t\t\t\t])\n\t\texcept KeyError:\n\t\t\treturn requests.codes.bad_request, None\n\t\n\t\tcode, data = self._req('post', uri , json.dumps(payload))\n\t\t\n\t\treturn code, data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_pipeline_field(self, pipeline_key, field_key = None):\n\t\t'''Gets one/all field in a pipeline\n\t\tArgs:\n\t\t\tpipeline_key \t\tkey for pipeline\n\t\t\tfield_key \t\t\tkey for field (default: None i.e. ALL)\n\t\t\treturns\t\t\t\tstatus code, field dict or list thereof\n\t\t'''\n\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri, \n\t\t\t\t\t\tself.pipelines_suffix, \n\t\t\t\t\t\tpipeline_key, \n\t\t\t\t\t\tself.fields_suffix\n\t\t\t\t\t\t])\n\t\tif field_key:\n\t\t\turi = '/'.join([uri, field_key])\n\n\t\treturn self._req('get', uri)", "response": "Gets one or all fields in a pipeline"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_pipeline_field(self, pipeline_key, name, field_type, **kwargs):\n\t\t'''Creates a pipeline field with the provided attributes.\n\t\tArgs:\n\t\t\tpipeline_key\tspecifying the pipeline to add the field to\n\t\t\tname\t\t\trequired name string\n\t\t\tfield_type\t\trequired type string [TEXT_INPUT, DATE or PERSON]\n\t\t\tkwargs\t\t\t{}\n\t\t\treturn\t\t\t(status code, field dict)\n\t\t'''\n\n\t\turi = '/'.join([self.api_uri,\n\t\t\t\t\t\tself.pipelines_suffix,\n\t\t\t\t\t\tpipeline_key,\n\t\t\t\t\t\tself.fields_suffix\n\t\t\t\t\t\t])\n\t\t\n\t\tcode, data = self._create_field(uri, name, field_type, **kwargs)\n\t\t\n\t\treturn code, data", "response": "Creates a new pipeline field with the provided attributes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the pipeline field with the given key.", "response": "def update_pipeline_field(self, pipeline_key, field):\n\t\t'''Upates pipeline field as specified\n\t\tArgs:\n\t\t\tpipeline_key\t\tkey for pipeline where the fields lives\n\t\t\tfield \t\t\t\tStreakField object with fresh data\n\t\t\treturns\t\t\t\t(status code, updated field dict)\n\t\t'''\n\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\tself.pipelines_suffix,\n\t\t\t\t\t\tpipeline_key,\n\t\t\t\t\t\tself.fields_suffix\n\t\t\t\t\t\t])\n\t\treturn self._update_field(uri, field)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_box_field(self, box_key, field_key = None):\n\t\t'''Gets one/all field in a box\n\t\tArgs:\n\t\t\tbox_key \t\tkey for pipeline\n\t\t\tfield_key \t\t\tkey for field (default: None i.e. ALL)\n\t\t\treturns\t\t\t\tstatus code, field dict or list thereof\n\t\t'''\n\t\t#does not work\n\t\tself._raise_unimplemented_error()\n\t\t\n\t\turi = '/'.join([self.api_uri,\n\t\t\t\t\t\tself.boxes_suffix,\n\t\t\t\t\t\tbox_key,\n\t\t\t\t\t\tself.fields_suffix\n\t\t\t\t\t\t])\n\t\tif field_key:\n\t\t\turi = '/'.join([uri, field_key])\n\n\t\treturn self._req('get', uri)", "response": "Get one or all field in a box."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a box field with the provided attributes.", "response": "def create_box_field(self, box_key, name, field_type, **kwargs):\n\t\t'''Creates a box field with the provided attributes.\n\t\tArgs:\n\t\t\tbox_key\t\t\tspecifying the box to add the field to\n\t\t\tname\t\t\trequired name string\n\t\t\tfield_type\t\trequired type string [TEXT_INPUT, DATE or PERSON]\n\t\t\tkwargs\t\t\t{}\n\t\t\treturn\t\t\t(status code, field dict)\n\t\t'''\n\t\t#does not work\n\t\tself._raise_unimplemented_error()\n\t\t\n\t\turi = '/'.join([self.api_uri,\n\t\t\t\t\t\tself.boxes_suffix, \n\t\t\t\t\t\tbox_key,\n\t\t\t\t\t\tself.fields_suffix\n\t\t\t\t\t\t])\n\t\t\n\t\tcode, data = self._create_field(uri, name, field_type, **kwargs)\n\t\t\n\t\treturn code, data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_box_field(self, box_key, field):\n\t\t'''Upates box field as specified\n\t\tArgs:\n\t\t\tbox_key\t\tkey for pipeline where the fields lives\n\t\t\tfield \t\t\t\tStreakField object with fresh data\n\t\t\treturns\t\t\t\t(status code, updated field dict)\n\t\t'''\n\t\t#does not work\n\t\tself._raise_unimplemented_error()\n\t\t\n\t\turi = '/'.join([self.api_uri,\n\t\t\t\t\t\tself.boxes_suffix,\n\t\t\t\t\t\tbox_key,\n\t\t\t\t\t\tself.fields_suffix\n\t\t\t\t\t\t])\n\t\treturn self._update_field(uri, field)", "response": "Updates the field of a box."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfunction to get newsfeeds for a pipeline", "response": "def get_pipeline_newsfeeds(self, pipeline_key, detail_level = None):\n\t\t'''Function to get newsfeed for a pipeline\n\t\tArgs:\n\t\t\tpipeline_key\tpipeline key\n\t\t\tdetail_level \targuments for req str ['ALL', 'CONDENSED']\n\t\t\treturn \t\t\tlist of feed dicts parse at your convenience\n\t\t'''\n\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\tself.pipelines_suffix,\n\t\t\t\t\t\tpipeline_key,\n\t\t\t\t\t\tself.newsfeed_suffix\n\t\t\t\t\t\t])\n\t\treturn self._get_newsfeeds(uri, detail_level)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions to get newsfeeds for a given box", "response": "def get_box_newsfeeds(self, box_key, detail_level = None):\n\t\t'''Function to get newsfeed for a pipeline\n\t\tArgs:\n\t\t\tbox \t\t\tpipeline key\n\t\t\tdetail_level \targuments for req str ['ALL', 'CONDENSED']\n\t\t\treturn \t\t\tlist of feed dicts parse at your convenience\n\t\t'''\n\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\tself.boxes_suffix,\n\t\t\t\t\t\tbox_key,\n\t\t\t\t\t\tself.newsfeed_suffix\n\t\t\t\t\t\t])\n\t\treturn self._get_newsfeeds(uri, detail_level)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_thread(self, thread_key):\n\t\t'''Gets a thread specified by thread_key\n\t\tArgs:\n\t\t\tthread_key \t\tthread to get\n\t\t\treturns \t\ta thread dict\n\t\t'''\n\t\turi = '/'.join([self.api_uri,\n\t\t\t\t\t\tself.threads_suffix,\n\t\t\t\t\t\tthread_key\n\t\t\t\t\t\t])\n\t\treturn self._req('get', uri)", "response": "Get a thread by thread_key"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn all threads in a specified box", "response": "def get_box_threads(self, box_key):\n\t\t'''Gets all threads in a specified box\n\t\tArgs:\n\t\t\tbox_key \t\tbox to look in\n\t\t\treturns \t\ta list of thread dicts\n\t\t'''\n\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\tself.boxes_suffix,\n\t\t\t\t\t\tbox_key,\n\t\t\t\t\t\tself.threads_suffix\n\t\t\t\t\t\t])\n\t\treturn self._req('get', uri)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a comment in a box.", "response": "def create_box_comments(self, box_key, message, **kwargs):\n\t\t'''Creates a comments in a box with the provided attributes.\n\t\tArgs:\n\t\t\tbox_key\t\t\tkey for box\n\t\t\tmessage\t\t\tmessage string\n\t\t\tkwargs\t\t\t{} see StreakComment object for more information\n\t\t\treturn\t\t\t(status code, comment dict)\n\t\t'''\n\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\tself.boxes_suffix,\n\t\t\t\t\t\tbox_key,\n\t\t\t\t\t\tself.comments_suffix\n\t\t\t\t\t\t])\n\n\t\tif not (box_key and message):\n\t\t\treturn requests.codes.bad_request, None\n\n\t\tkwargs.update({'message':message})\n\n\t\tnew_cmt = StreakComment(**kwargs)\n\t\t#print(new_pl.attributes)\n\t\t#print(new_pl.to_dict())\n\t\t#raw_input()\n\t\tcode, r_data = self._req('put', uri, new_cmt.to_dict())\n\t\t\n\t\treturn code, r_data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_box_comments(self, box_key):\n\t\t'''Gets comments in a box with the provided attributes.\n\t\tArgs:\n\t\t\tbox_key\t\t\tkey for box\n\t\t\treturn\t\t\t(status code, list of comment dicts)\n\t\t'''\n\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\tself.boxes_suffix,\n\t\t\t\t\t\tbox_key,\n\t\t\t\t\t\tself.comments_suffix\n\t\t\t\t\t\t])\n\t\treturn self._req('get', uri)", "response": "Get comments in a box with the provided attributes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_box_comment(self, box_key, comment_key):\n\t\t'''Deletes comment in a box with the comment_key\n\t\tArgs:\n\t\t\tbox_key\t\t\tkey for box\n\t\t\treturn\t\t\t(status code, list of comment dicts)\n\t\t'''\n\t\t#does not work\n\t\tself._raise_unimplemented_error()\n\n\t\turi = '/'.join([self.api_uri,\n\t\t\t\t\t\tself.boxes_suffix,\n\t\t\t\t\t\tbox_key,\n\t\t\t\t\t\tself.comments_suffix,\n\t\t\t\t\t\tcomment_key\n\t\t\t\t\t\t])\n\t\treturn self._req('delete', uri)", "response": "Delete a comment in a box with the comment_key"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a reminder with the provided message and date and optional arguments.", "response": "def create_box_reminder(self, box_key, message, remind_date, remind_follwers, **kwargs):\n\t\t'''Creates a reminder with the provided attributes.\n\t\tArgs:\n\t\t\tbox_key \t\t\tspecifying the box to add the field to\n\t\t\tmessage\t\t\t\tmessage for the reminder\n\t\t\tremind_date\t\t\tdate to remind on in ticks.\n\t\t\tremind_followers\ttrue/false\n\t\t\tkwargs\t\t\t\t{..} see StreakReminder object for details\n\t\t\treturn\t\t\t\t(status code, reminder dict)\n\t\t'''\n\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\tself.boxes_suffix, \n\t\t\t\t\t\tbox_key,\n\t\t\t\t\t\tself.reminders_suffix\n\t\t\t\t\t\t])\n\t\tkwargs.update({\t'message':message, \n\t\t\t\t\t\t'remindDate':remind_date, \n\t\t\t\t\t\t'remindFollowers': remind_follwers})\n\n\t\tnew_rem = StreakReminder(**kwargs)\n\t\t\n\t\tcode, data = self._req('put', uri, new_rem.to_dict(rw = True))\n\t\t\n\t\treturn code, data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_reminder(self, reminder):\n\t\t'''Creates a reminder with the provided attributes.\n\t\tArgs:\n\t\t\treminder\t\tupdated reminder of StreakReminder type\n\t\t\treturn\t\t\t(status code, reminder dict)\n\t\t'''\n\t\turi = '/'.join([self.api_uri,\n\t\t\t\t\t\tself.reminders_suffix,\n\t\t\t\t\t\t])\n\t\t#req sanity check\n\t\tpayload = None\n\t\tif  type(reminder) is not StreakReminder:\n\t\t\treturn requests.codes.bad_request, None\n\n\t\tpayload = reminder.to_dict(rw = True)\n\t\n\t\ttry:\n\t\t\turi = '/'.join([uri, reminder.attributes['key']])\n\t\texcept KeyError:\n\t\t\treturn requests.codes.bad_request, None\n\t\n\t\tcode, data = self._req('post', uri , json.dumps(payload))\n\t\t\n\t\treturn code, data", "response": "This method creates a reminder with the provided attributes and returns the updated reminder."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all reminders for a given box", "response": "def get_box_reminders(self, box_key):\n\t\t'''Gets all reminders for a box\n\t\tArgs:\n\t\t\treminder\t\tupdated reminder of StreakReminder type\n\t\t\treturn\t\t\t(status code, reminder dict)\n\t\t'''\n\t\t#required sanity check\n\t\tif box_key:\n\t\t\treturn requests.codes.bad_request, None\n\n\t\turi = '/'.join([self.api_uri,\n\t\t\t\t\t\tself.boxes_suffix, \n\t\t\t\t\t\tbox_key,\n\t\t\t\t\t\tself.reminders_suffix\n\t\t\t\t\t\t])\n\n\t\treturn self._req('get', uri)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget one reminder Args: reminder_key key for the reminder to get return (status code, reminder dict)", "response": "def get_reminder(self, reminder_key):\n\t\t'''Gets one reminder\n\t\tArgs:\n\t\t\treminder_key\tkey for the reminder to get\n\t\t\treturn\t\t\t(status code, reminder dict)\n\t\t'''\n\t\t#required sanity check\n\t\tif reminder_key:\n\t\t\treturn requests.codes.bad_request, None\n\t\t\n\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\tself.reminders_suffix,\n\t\t\t\t\t\treminder_key\n\t\t\t\t\t\t])\n\n\t\treturn self._req('get', uri)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets file information Args: file_key key for the file to get return (status code, dict of file info)", "response": "def get_file(self, file_key):\n\t\t'''Gets file information\n\t\tArgs:\n\t\t\tfile_key\t\tkey for the file to get\n\t\t\treturn\t\t\t(status code, dict of file info)\n\t\t'''\n\t\turi = '/'.join([\n\t\t\t\t\t\tself.api_uri,\n\t\t\t\t\t\tself.files_suffix,\n\t\t\t\t\t\tfile_key\n\t\t\t\t\t\t])\n\n\t\treturn self._req('get', uri)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the contents of a file.", "response": "def get_file_contents(self, file_key):\n\t\t'''Gets file contents\n\t\tArgs:\n\t\t\tfile_key\t\tkey for the file \n\t\t\treturn\t\t\t(status code, ?)\n\t\t'''\n\t\t#does not work\n\t\tself._raise_unimplemented_error()\n\t\t\n\t\turi = '/'.join([self.api_uri,\n\t\t\t\t\t\tself.files_suffix,\n\t\t\t\t\t\tfile_key,\n\t\t\t\t\t\tself.file_contents_suffix,\n\t\t\t\t\t\t])\n\t\treturn self._req('get', uri)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_file_link(self, file_key):\n\t\t'''Gets link to file\n\t\tArgs:\n\t\t\tfile_key\t\tkey for the file \n\t\t\treturn\t\t\t(status code, ?)\n\t\t'''\n\t\t#does not work\n\t\tself._raise_unimplemented_error()\n\n\t\turi = '/'.join([self.api_uri,\n\t\t\t\t\t\tself.files_suffix,\n\t\t\t\t\t\tfile_key,\n\t\t\t\t\t\tself.file_link_suffix,\n\t\t\t\t\t\t])\n\t\treturn self._req('get', uri)", "response": "Get link to a file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_box_files(self, box_key):\n\t\t'''Gets to file infos in a single box.\n\t\tArgs:\n\t\t\tbox_key\t\tkey for the file \n\t\t\treturn\t\t(status code, list of file info dicts)\n\t\t'''\n\t\turi = '/'.join([self.api_uri,\n\t\t\t\t\t\tself.boxes_suffix,\n\t\t\t\t\t\tbox_key,\n\t\t\t\t\t\tself.files_suffix\n\t\t\t\t\t\t])\n\n\t\treturn self._req('get', uri)", "response": "Get to file infos in a single box."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_string(self, key):\n\n        # Massive hack, lol\n        if key.startswith(\"lambda.\"):\n            key = \"lambda.items.{0}\".format(key[7:])\n        if key.startswith(\"apigateway.\"):\n            key = \"apigateway.items.{0}\".format(key[11:])\n\n        # Make sure key is in all_options\n        if key not in self.all_options:\n            kwargs = {}\n            if len(self.chain) > 1:\n                kwargs['source'] = Meta(self.all_options, self.chain[-2]).source\n            raise BadOptionFormat(\"Can't find key in options\", key=key, chain=self.chain, **kwargs)\n\n        return super(MergedOptionStringFormatter, self).get_string(key)", "response": "Get a string from all_options"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef special_get_field(self, value, args, kwargs, format_spec=None):\n        if value in self.chain:\n            raise BadOptionFormat(\"Recursive option\", chain=self.chain + [value])", "response": "This is a special get_field method that checks if the value is a valid entry in the chain."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_page_from_path(self, path):\n        from feincms.module.page.models import Page\n        try:\n            return Page.objects.best_match_for_path(path)\n        except Page.DoesNotExist:\n            return None", "response": "Gets the FeinCMS Page object that the path points to."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the FeinCMS resource s access state following any INHERITed values.", "response": "def _get_resource_access_state(self, request):\n        \"\"\"\n        Returns the FeinCMS resource's access_state, following any INHERITed values.\n\n        Will return None if the resource has an access state that should never be\n        protected. It should not be possible to protect a resource with an access_state\n        of STATE_ALL_ALLOWED, or an access_state of STATE_INHERIT and no parent.\n\n        Will also return None if the accessed URL doesn't contain a Page.\n        \"\"\"\n        feincms_page = self._get_page_from_path(request.path_info.lstrip('/'))\n        if not feincms_page:\n            return None\n\n        # Chase inherited values up the tree of inheritance.\n        INHERIT = AccessState.STATE_INHERIT\n        while feincms_page.access_state == INHERIT and feincms_page.parent:\n            feincms_page = feincms_page.parent\n\n        # Resources with STATE_ALL_ALLOWED or STATE_INHERIT and no parent should never be\n        # access-restricted. This code is here rather than in is_resource_protected to\n        # emphasise its importance and help avoid accidentally overriding it.\n        never_restricted = (INHERIT, AccessState.STATE_ALL_ALLOWED)\n        if feincms_page.access_state in never_restricted:\n            return None\n\n        # Return the found value.\n        return feincms_page.access_state"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine if a resource should be protected.", "response": "def is_resource_protected(self, request, **kwargs):\n        \"\"\"\n        Determines if a resource should be protected.\n\n        Returns true if and only if the resource's access_state matches an entry in\n        the return value of get_protected_states().\n        \"\"\"\n        access_state = self._get_resource_access_state(request)\n        protected_states = self.get_protected_states()\n        return access_state in protected_states"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbumping version of the current version of the current version of the current version of the current version of the current version.", "response": "def bump_version(project, source, force_init):  # type: (str, str, bool, bool) ->int\n    \"\"\"\n    Entry point\n    :return:\n    \"\"\"\n    file_opener = FileOpener()\n    # logger.debug(\"Starting version jiggler...\")\n    jiggler = JiggleVersion(project, source, file_opener, force_init)\n\n    logger.debug(\n        \"Current, next : {0} -> {1} : {2}\".format(\n            jiggler.current_version, jiggler.version, jiggler.schema\n        )\n    )\n    if not jiggler.version_finder.validate_current_versions():\n\n        logger.debug(unicode(jiggler.version_finder.all_current_versions()))\n        logger.error(\"Versions not in sync, won't continue\")\n        die(-1, \"Versions not in sync, won't continue\")\n    changed = jiggler.jiggle_all()\n    logger.debug(\"Changed {0} files\".format(changed))\n    return changed"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compare_two_documents(kls, doc1, doc2):\n        first = doc1\n        if isinstance(doc1, string_types):\n            try:\n                first = json.loads(doc1)\n            except (ValueError, TypeError) as error:\n                log.warning(\"Failed to convert doc into a json object\\terror=%s\", error)\n                yield error.args[0]\n                return\n\n        second = doc2\n        if isinstance(doc2, string_types):\n            try:\n                second = json.loads(doc2)\n            except (ValueError, TypeError) as error:\n                log.warning(\"Failed to convert doc into a json object\\terror=%s\", error)\n                yield error.args[0]\n                return\n\n        # Ordering the principals because the ordering amazon gives me hates me\n        def sort_statement(statement):\n            for principal in (statement.get(\"Principal\", None), statement.get(\"NotPrincipal\", None)):\n                if principal:\n                    for principal_type in (\"AWS\", \"Federated\", \"Service\"):\n                        if principal_type in principal and type(principal[principal_type]) is list:\n                            principal[principal_type] = sorted(principal[principal_type])\n        def sort_key(statement, key):\n            if key in statement and type(statement[key]) is list:\n                statement[key] = sorted(statement[key])\n        for document in (first, second):\n            if \"Statement\" in document:\n                if type(document[\"Statement\"]) is dict:\n                    sort_statement(document[\"Statement\"])\n                    sort_key(document[\"Statement\"], \"Action\")\n                    sort_key(document[\"Statement\"], \"NotAction\")\n                    sort_key(document[\"Statement\"], \"Resource\")\n                    sort_key(document[\"Statement\"], \"NotResource\")\n                else:\n                    for statement in document[\"Statement\"]:\n                        sort_statement(statement)\n                        sort_key(statement, \"Action\")\n                        sort_key(statement, \"NotAction\")\n                        sort_key(statement, \"Resource\")\n                        sort_key(statement, \"NotResource\")\n\n        difference = diff(first, second, fromfile=\"current\", tofile=\"new\").stringify()\n        if difference:\n            lines = difference.split('\\n')\n            if not first or not second or first != second:\n                for line in lines:\n                    yield line", "response": "Compare two documents by converting them into json objects and back to strings and compare"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning data from facter.", "response": "def facter_info():\n    \"\"\"Returns data from facter.\n    \"\"\"\n\n    with suppress(FileNotFoundError):  # facter may not be installed\n        proc = subprocess.Popen(['facter', '--yaml'],\n                                stdout=subprocess.PIPE,\n                                stderr=subprocess.PIPE)\n        stdout, stderr = proc.communicate()\n        if not proc.returncode:\n            data = serializer.load(stdout)\n            return {'facter': data}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the color of the classroom.", "response": "def get_color(index):\n    \"\"\"Dips the brush in paint.\n\n    Arguments:\n        index - an integer between 0 and 7, inclusive. Tells the bot which color you want.\n    \"\"\"\n    if index in range(0, 8):\n        # Send the turtle to the top-left corner of the window to imitate the position of the WCB's brush.\n        state['turtle'].goto(-WCB_WIDTH / 2, -WCB_HEIGHT / 2)\n\n        _make_cnc_request(\"tool.color./\" + str(index))\n\n        # This is the order of the colors in the palette in our classroom's bot; yours may vary!\n        colors = [\"black\", \"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"purple\", \"brown\"]\n\n        state['turtle'].color(colors[index])\n        state['distance_traveled'] = 0\n\n    else:\n        print(\"Color indexes must be between 0 and 7, but you gave me: \" + index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef move_to(x, y):\n    _make_cnc_request(\"coord/{0}/{1}\".format(x, y))\n    state['turtle'].goto(x, y)", "response": "Moves the brush to a particular position."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nturning the brush s turtle to the left.", "response": "def turn_left(relative_angle):\n    \"\"\"Turns the brush's \"turtle\" to the left.\n\n    Arguments:\n        relative_angle - a number like 10.\n            A bigger number makes the turtle turn farther to the left.\n    \"\"\"\n    assert int(relative_angle) == relative_angle, \"turn_left() only accepts integers, but you gave it \" + str(relative_angle)\n\n    _make_cnc_request(\"move.left./\" + str(relative_angle))\n    state['turtle'].left(relative_angle)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nturn the brush s turtle to the right.", "response": "def turn_right(relative_angle):\n    \"\"\"Turns the brush's \"turtle\" to the right.\n\n    Arguments:\n        relative_angle - a number like 10.\n            A bigger number makes the turtle turn farther to the right.\n    \"\"\"\n    assert int(relative_angle) == relative_angle, \"turn_right() only accepts integers, but you gave it \" + str(relative_angle)\n\n    _make_cnc_request(\"move.right./\" + str(relative_angle))\n    state['turtle'].right(relative_angle)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndescribe the object using developer - specified attributes specific to the main object type.", "response": "def describe(o):\n    \"\"\"Describes the object using developer-specified attributes specific to\n    each main object type.\n\n    Returns:\n        dict: keys are specific attributes tailored to the specific object type,\n        though `fqdn` is common to all descriptions; values are the corresponding\n        attribute values which are *simple* types that can easily be serialized to\n        JSON.\n    \"\"\"\n    #First, we need to determine the fqdn, so that we can lookup the format for\n    #this object in the config file for the package.\n    from inspect import getmodule\n    from acorn.logging.decoration import _fqdn\n    fqdn = _fqdn(o, False)\n    if fqdn is None:\n        #This should not have happened; if the FQDN couldn't be determined, then\n        #we should have never logged it.\n        return json_describe(o, str(type(o)))\n    package = fqdn.split('.')[0]\n\n    global _package_desc\n    if package not in _package_desc:\n        from acorn.config import descriptors\n        spack = descriptors(package)\n        if spack is None:\n            _package_desc[package] = None\n            return json_describe(o, fqdn)\n        else:\n            _package_desc[package] = spack\n    \n    if _package_desc[package] is None:\n        return json_describe(o, fqdn)\n    elif fqdn in _package_desc[package]:\n        return json_describe(o, fqdn, _package_desc[package][fqdn])\n    else:\n        return json_describe(o, fqdn)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the attribute specified by the fqdn list from obj.", "response": "def _obj_getattr(obj, fqdn, start=1):\n    \"\"\"Returns the attribute specified by the fqdn list from obj.\n    \"\"\"\n    node = obj\n    for chain in fqdn.split('.')[start:]:\n        if hasattr(node, chain):\n            node = getattr(node, chain)\n        else:\n            node = None\n            break\n    return node"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _package_transform(package, fqdn, start=1, *args, **kwargs):\n    #Our only difficulty here is that package names can be chained. We ignore\n    #the first item since that was already checked for us by the calling\n    #method.\n    node = _obj_getattr(package, fqdn, start)\n    \n    #By the time this loop is finished, we should have a function to apply if\n    #the developer setting up the config did a good job.\n    if node is not None and hasattr(node, \"__call__\"):\n        return node(*args, **kwargs)\n    else:\n        return args", "response": "Applies the specified package transform with fqdn to the package object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply an instance method with name fqdn to o.", "response": "def _instance_transform(fqdn, o, *args, **kwargs):\n    \"\"\"Applies an instance method with name `fqdn` to `o`.\n\n    Args:\n        fqdn (str): fully-qualified domain name of the object.\n        o: object to apply instance method to.\n    \"\"\"\n    return _package_transform(o, fqdn, start=0, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the specified value to a list if it is a numpy. ndarray ; otherwise it is just returned as is.", "response": "def _array_convert(a):\n    \"\"\"Converts the specified value to a list if it is a :class:`numpy.ndarray`;\n    otherwise it is just returned as is.\n    \"\"\"\n    from numpy import ndarray\n    if isinstance(a, ndarray):\n        larr = a.tolist()\n        if len(larr) == 1:\n            return larr[0]\n        else:\n            return larr\n    else:\n        return a"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef json_describe(o, fqdn, descriptor=None):\n    if descriptor is None or not isinstance(descriptor, dict):\n        return {\"fqdn\": fqdn}\n    else:\n        result = {\"fqdn\": fqdn}\n        for attr, desc in descriptor.items():\n            if attr == \"instance\":\n                #For instance methods, we repeatedly call instance methods on\n                #`value`, assuming that the methods belong to `value`.\n                value = o\n            else:\n                if '.' in attr:\n                    #We get the chain of attribute values.\n                    value = o\n                    for cattr in attr.split('.'):\n                        if hasattr(value, cattr):\n                            value = getattr(value, cattr, \"\")\n                        else:\n                            break\n                else:\n                    #There is just a one-level getattr.    \n                    value = getattr(o, attr, \"\")\n                \n            if \"transform\" in desc:\n                for transform in desc[\"transform\"]:\n                    if \"numpy\" == transform[0:len(\"numpy\")]:\n                        value = _numpy_transform(transform, value)\n                    elif \"scipy\" == transform[0:len(\"scipy\")]:\n                        value = _scipy_transform(transform, value)\n                    elif \"math\" == transform[0:len(\"math\")]:\n                        value = _math_transform(transform, value)\n                    elif \"self\" in transform:\n                        args = desc[\"args\"] if \"args\" in desc else []\n                        kwds = desc[\"kwargs\"] if \"kwargs\" in desc else {}\n                        method = transform[len(\"self.\"):]\n                        value = _instance_transform(method, value, *args,**kwds)\n                        \n            if \"slice\" in desc:\n                for si, sl in enumerate(desc[\"slice\"]):\n                    if ':' in sl:\n                        name, slice = sl.split(':')\n                    else:\n                        name, slice = str(si), sl\n\n                    slvalue = value\n                    for i in map(int, slice.split(',')):\n                        slvalue = slvalue[i]\n                        \n                    result[name] = _array_convert(slvalue)\n            else:\n                if \"rename\" in desc:\n                    result[desc[\"rename\"]] = _array_convert(value)\n                else:\n                    result[attr] = _array_convert(value)\n                \n    return result", "response": "Describes the object o using the specified descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract database name from connection string", "response": "def get_database_name(self):\n        \"\"\"\n        extract database from connection string\n        \"\"\"\n        uri_dict = uri_parser.parse_uri(self.host)\n        database = uri_dict.get('database', None)\n        if not database:\n            raise \"database name is missing\"\n        return database"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding by creation date using start and end dates as range", "response": "def find(self, start, end, limit=50, *args, **kwargs):\n        \"\"\"\n        find by creation date, using start and end dates as range\n        \"\"\"\n        # check if spec has been specified, build on top of it\n        fc = kwargs.get('spec', dict())\n\n        # filter _id on start and end dates\n        fc['_id'] = {'$gte': ObjectId.from_datetime(start),\n                     '$lte': ObjectId.from_datetime(end)}\n\n        if not self.collection:\n            collection_name = kwargs.get('collection_name',\n                             MONGODB_DEFAULT_COLLECTION)\n            self.set_collection(collection_name)\n\n        return self.collection.find(fc, limit=limit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save(self, data, *args, **kwargs):\n        try:\n            collection_name = kwargs.get('collection_name',\n                                         MONGODB_DEFAULT_COLLECTION)\n            w = kwargs.get('w', 0)\n\n            if not self.collection:\n                self.set_collection(collection_name)\n\n            self.collection.insert(data, w)\n        except (ConnectionFailure, AutoReconnect, InvalidURI), e:\n            # fail silently - just log and die ...\n            if ADD_LOG_FAILURES:\n                logging.exception(\n                    'Error connection to %s, unable to insert %s' % (\n                        MONGODB_URI, data))", "response": "Save data into the database"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle a database exception and return a meaningful .", "response": "def handle_exc(exc):\n    \"\"\" Given a database exception determine how to fail\n\n    Attempt to lookup a known error & abort on a meaningful\n    error. Otherwise issue a generic DatabaseUnavailable exception.\n\n    :param exc: psycopg2 exception\n    \"\"\"\n\n    err = ERRORS_TABLE.get(exc.pgcode)\n\n    if err:\n        abort(exceptions.InvalidQueryParams(**{\n            'detail': err,\n            'parameter': 'filter',\n        }))\n\n    abort(exceptions.DatabaseUnavailable)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dirty_vals(model):\n\n        vals = []\n\n        for field in model.dirty_fields:\n            vals.append('%({0})s'.format(field))\n\n        vals = ', '.join(vals)\n\n        return vals or None", "response": "Get the dirty values in a friendly SQL format"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef field_cols(model):\n\n        to_many = model.to_many\n        cols = [f for f in model.all_fields if f not in to_many]\n        cols = ', '.join(cols)\n\n        return cols or None", "response": "Get the models columns in a friendly SQL format"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nturning the tuple of filters into SQL WHERE statements The key (column name) & operator have already been vetted so they can be trusted but the value could still be evil so it MUST be a parameterized input! That is done by creating a param dict where they key name & val look like: '{}_{}'.format(key, oper): val The key is constructed the way it is to ensure uniqueness, if we just used the key name then it could get clobbered. Ultimately the WHERE statement will look something like: age >= {age_gte} where age_gte is the key name in the param dict with a value of the evil user input. In the end, a string statement & dict param are returned as a tuple if any filters were provided otherwise None. :return: tuple (string, dict)", "response": "def filters_query(filters):\n        \"\"\" Turn the tuple of filters into SQL WHERE statements\n\n        The key (column name) & operator have already been vetted\n        so they can be trusted but the value could still be evil\n        so it MUST be a parameterized input!\n\n        That is done by creating a param dict where they key name\n        & val look like:\n\n            '{}_{}'.format(key, oper): val\n\n        The key is constructed the way it is to ensure uniqueness,\n        if we just used the key name then it could get clobbered.\n\n        Ultimately the WHERE statement will look something like:\n\n            age >= {age_gte}\n\n        where age_gte is the key name in the param dict with a\n        value of the evil user input. In the end, a string\n        statement & dict param are returned as a tuple if any\n        filters were provided otherwise None.\n\n        :return: tuple (string, dict)\n        \"\"\"\n\n        def _cast_val(filtr):\n            \"\"\" Perform any needed casting on the filter value\n\n            This could be tasks like including '%' signs at\n            certain anchor points based on the filter or\n            even wrapping it in certain functions.\n            \"\"\"\n\n            val = filtr.val\n\n            if filtr.oper in ('contains', 'icontains'):\n                val = '%' + filtr.val + '%'\n            elif filtr.oper == 'endswith':\n                val = '%' + filtr.val\n            elif filtr.oper == 'startswith':\n                val = filtr.val + '%'\n\n            return val\n\n        def _filter(filtr):\n            \"\"\" Process each individual Filter object \"\"\"\n\n            oper = FILTER_TABLE[filtr.oper]\n            prop = '{field}_{oper}'.format(\n                field=filtr.field.replace('.', '_'),\n                oper=filtr.oper,\n            )\n\n            if isinstance(filtr, FilterRel):\n                stmt = _filter_rel(filtr, oper, prop)\n            else:\n                stmt = '{field} {oper} %({prop})s'.format(\n                    field=filtr.field,\n                    oper=oper,\n                    prop=prop,\n                )\n\n            return stmt, {prop: _cast_val(filtr)}\n\n        def _filter_or(filters):\n            \"\"\" Given a FilterOr object return a SQL query \"\"\"\n\n            param = {}\n            stmts = []\n\n            for filtr in filters:\n                vals = _filter(filtr)\n\n                param.update(vals[1])\n                stmts.append(vals[0])\n\n            stmt = ' OR '.join(stmts)\n            stmt = '({})'.format(stmt)\n\n            return stmt, param\n\n        def _filter_rel(rel, oper, prop):\n            \"\"\" Given a FilterRel object return a SQL sub query \"\"\"\n\n            stmt = \"\"\"\n                   {field} IN (SELECT {foreign_field} FROM {foreign_rtype}\n                               WHERE {foreign_filter} {oper} %({prop})s)\n                   \"\"\"\n\n            return stmt.format(\n                field=rel.local_field,\n                foreign_field=rel.foreign_field,\n                foreign_filter=rel.foreign_filter,\n                foreign_rtype=rel.foreign_rtype,\n                oper=oper,\n                prop=prop,\n            )\n\n        param = {}\n        stmts = []\n\n        for filtr in filters:\n            if isinstance(filtr, FilterOr):\n                vals = _filter_or(filtr)\n            else:\n                vals = _filter(filtr)\n\n            param.update(vals[1])\n            stmts.append(vals[0])\n\n        if stmts:\n            stmt = ' AND '.join(stmts)\n            stmt = ' WHERE ' + stmt\n\n        return stmt, param"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nturn the Sortables into a SQL ORDER BY query", "response": "def sorts_query(sortables):\n        \"\"\" Turn the Sortables into a SQL ORDER BY query \"\"\"\n\n        stmts = []\n\n        for sortable in sortables:\n            if sortable.desc:\n                stmts.append('{} DESC'.format(sortable.field))\n            else:\n                stmts.append('{} ASC'.format(sortable.field))\n\n        return ' ORDER BY {}'.format(', '.join(stmts))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a model object instance create it", "response": "def create(self, model):\n        \"\"\" Given a model object instance create it \"\"\"\n\n        signals.pre_create.send(model.__class__, model=model)\n        signals.pre_save.send(model.__class__, model=model)\n\n        param = self.to_pg(model)\n        query = \"\"\"\n                INSERT INTO {table} ({dirty_cols})\n                VALUES ({dirty_vals})\n                RETURNING {cols};\n                \"\"\"\n\n        query = query.format(\n            cols=self.field_cols(model),\n            dirty_cols=self.dirty_cols(model),\n            dirty_vals=self.dirty_vals(model),\n            table=model.rtype,\n        )\n\n        result = self.query(query, param=param)\n\n        signals.post_create.send(model.__class__, model=model)\n        signals.post_save.send(model.__class__, model=model)\n\n        return model.merge(result[0], clean=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a model object instance delete it", "response": "def delete(self, model):\n        \"\"\" Given a model object instance delete it \"\"\"\n\n        signals.pre_delete.send(model.__class__, model=model)\n\n        param = {'rid_value': self.to_pg(model)[model.rid_field]}\n        query = \"\"\"\n                DELETE FROM {table}\n                WHERE {rid_field} = %(rid_value)s\n                RETURNING {cols};\n                \"\"\"\n\n        query = query.format(\n            cols=self.field_cols(model),\n            rid_field=model.rid_field,\n            table=model.rtype,\n        )\n\n        result = self.query(query, param=param)\n\n        signals.post_delete.send(model.__class__, model=model)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find(self, rtype, key, val):\n\n        model = rtype_to_model(rtype)\n        param = {'key': key, 'val': val}\n        query = \"\"\"\n                SELECT {cols} FROM {table}\n                WHERE {key} = %(val)s;\n                \"\"\"\n\n        query = query.format(\n            cols=self.field_cols(model),\n            key=key,\n            table=rtype,\n        )\n\n        signals.pre_find.send(model.__class__, model=model)\n\n        result = self.query(query, param=param)\n        if result:\n            result = model(result[0])\n            signals.post_find.send(model.__class__, model=result)\n\n        return result or None", "response": "Given a resource type and a single key and val find the model object that matches the given key and val."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform a SQL based query on the database and return the result.", "response": "def query(self, query, param=None):\n        \"\"\" Perform a SQL based query\n\n        This will abort on a failure to communicate with\n        the database.\n\n        :query: string query\n        :params: parameters for the query\n        :return: RecordList from psycopg2\n        \"\"\"\n\n        with self.conn.cursor() as curs:\n            print 'XXX QUERY', curs.mogrify(query, param)\n            try:\n                curs.execute(query, param)\n            except BaseException as exc:\n                msg = 'query: {}, param: {}, exc: {}'.format(query, param, exc)\n\n                if hasattr(exc, 'pgcode'):\n                    msg = '{}, exc code: {}'.format(msg, exc.pgcode)\n\n                print msg\n                handle_exc(exc)\n\n            result = curs.fetchall()\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search(self, rtype, **kwargs):\n\n        model = rtype_to_model(rtype)\n        param = {}\n        pages = self.pages_query(kwargs.get('pages'))\n        sorts = self.sorts_query(kwargs.get(\n            'sorts', [Sortable(goldman.config.SORT)]\n        ))\n\n        query = \"\"\"\n                SELECT {cols}, count(*) OVER() as _count\n                FROM {table}\n                \"\"\"\n        query = query.format(\n            cols=self.field_cols(model),\n            table=rtype,\n        )\n\n        filters = kwargs.get('filters', [])\n        filters += getattr(model, 'search_filters', []) or []\n\n        if filters:\n            where, param = self.filters_query(filters)\n            query += where\n\n        model_query = getattr(model, 'search_query', '') or ''\n        if filters and model_query:\n            model_query = ' AND ' + model_query\n        elif model_query:\n            model_query = ' WHERE ' + model_query\n\n        query += model_query\n        query += sorts\n        query += pages\n\n        signals.pre_search.send(model.__class__, model=model)\n\n        result = self.query(query, param=param)\n        models = [model(res) for res in result]\n\n        if models:\n            signals.post_search.send(model.__class__, models=result)\n\n        pages = kwargs.get('pages')\n        if pages and result:\n            pages.total = result[0]['_count']\n\n        return models", "response": "Search for the model by assorted criteria"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, model):\n\n        signals.pre_update.send(model.__class__, model=model)\n        signals.pre_save.send(model.__class__, model=model)\n\n        param = self.to_pg(model)\n        param['rid_value'] = param[model.rid_field]\n\n        query = \"\"\"\n                UPDATE {table}\n                SET ({dirty_cols}) = ({dirty_vals})\n                WHERE {rid_field} = %(rid_value)s\n                RETURNING {cols};\n                \"\"\"\n\n        query = query.format(\n            cols=self.field_cols(model),\n            dirty_cols=self.dirty_cols(model),\n            dirty_vals=self.dirty_vals(model),\n            rid_field=model.rid_field,\n            table=model.rtype,\n        )\n\n        result = self.query(query, param=param)\n\n        signals.post_update.send(model.__class__, model=model)\n        signals.post_save.send(model.__class__, model=model)\n\n        return model.merge(result[0], clean=True)", "response": "Given a model object instance update it"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites a log message to the logger destination.", "response": "def _write(self, level, correlation_id, ex, message):\n        \"\"\"\n        Writes a log message to the logger destination.\n\n        :param level: a log level.\n\n        :param correlation_id: (optional) transaction id to trace execution through call chain.\n\n        :param ex: an error object associated with this message.\n\n        :param message: a human-readable message to log.\n        \"\"\"\n        error = ErrorDescriptionFactory.create(ex) if ex != None else None\n        source = socket.gethostname() # Todo: add process/module name\n        log_message = LogMessage(level, source, correlation_id, error, message)\n        \n        self._lock.acquire()\n        try:\n            self._cache.append(log_message)\n        finally:\n            self._lock.release()\n\n        self._update()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nclearing all cached log messages.", "response": "def clear(self):\n        \"\"\"\n        Clears (removes) all cached log messages.\n        \"\"\"\n        self._lock.acquire()\n        try:\n            self._cache = []\n            self._updated = False\n        finally:\n            self._lock.release()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a regex that matches the given range of the log entries", "response": "def regex_for_range(min_, max_):\n    \"\"\"\n    > regex_for_range(12, 345)\n    '1[2-9]|[2-9]\\d|[1-2]\\d{2}|3[0-3]\\d|34[0-5]'\n    \"\"\"\n    positive_subpatterns = []\n    negative_subpatterns = []\n    max_ -= 1\n    if min_ < 0:\n        min__ = 1\n        if max_ < 0:\n            min__ = abs(max_)\n        max__ = abs(min_)\n\n        negative_subpatterns = split_to_patterns(min__, max__)\n        min_ = 0\n\n    if max_ >= 0:\n        positive_subpatterns = split_to_patterns(min_, max_)    \n\n    negative_only_subpatterns = ['-' + val for val in negative_subpatterns if val not in positive_subpatterns]\n    positive_only_subpatterns = [val for val in positive_subpatterns if val not in negative_subpatterns]\n    intersected_subpatterns = ['-?' + val for val in negative_subpatterns if val in positive_subpatterns]\n\n    subpatterns = negative_only_subpatterns + intersected_subpatterns + positive_only_subpatterns\n    return '|'.join(subpatterns)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the path from the WSGI environment", "response": "def get_path(environ):\n    \"\"\"\n    Get the path\n    \"\"\"\n    from wsgiref import util\n    request_uri = environ.get('REQUEST_URI', environ.get('RAW_URI', ''))\n    if request_uri == '':\n        uri = util.request_uri(environ)\n        host = environ.get('HTTP_HOST', '')\n        scheme = util.guess_scheme(environ)\n        prefix = \"{scheme}://{host}\".format(scheme=scheme, host=host)\n        request_uri = uri.replace(prefix, '')\n    return request_uri"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle a PURGE request.", "response": "def handle_purge(environ, start_response):\n    \"\"\"\n    Handle a PURGE request.\n    \"\"\"\n    from utils import is_valid_security, get_cached_files\n    from settings import DEBUG\n    server = environ['SERVER_NAME']\n    try:\n        request_uri = get_path(environ)\n        path_and_query = request_uri.lstrip(\"/\")\n        query_string = environ.get('QUERY_STRING', '')\n        if is_valid_security('PURGE', query_string):\n            cached_files = get_cached_files(path_and_query, server)\n            for i in cached_files:\n                try:\n                    os.remove(i)\n                except OSError as e:\n                    return do_500(environ, start_response, e.message)\n            start_response(\"204 No Content\", [])\n            return []\n        else:\n            return do_405(environ, start_response)\n    except Http404 as e:\n        return do_404(environ, start_response, e.message, DEBUG)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndropping all the task in the specified queue.", "response": "def drop_all(self, queue_name):\n        \"\"\"\n        Drops all the task in the queue.\n\n        :param queue_name: The name of the queue. Usually handled by the\n            ``Gator`` instance.\n        :type queue_name: string\n        \"\"\"\n        cls = self.__class__\n\n        for task_id in cls.queues.get(queue_name, []):\n            cls.task_data.pop(task_id, None)\n\n        cls.queues[queue_name] = []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef push(self, queue_name, task_id, data):\n        cls = self.__class__\n        cls.queues.setdefault(queue_name, [])\n        cls.queues[queue_name].append(task_id)\n        cls.task_data[task_id] = data\n        return task_id", "response": "Pushes a task onto the queue."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npop a task off the queue.", "response": "def pop(self, queue_name):\n        \"\"\"\n        Pops a task off the queue.\n\n        :param queue_name: The name of the queue. Usually handled by the\n            ``Gator`` instance.\n        :type queue_name: string\n\n        :returns: The data for the task.\n        :rtype: string\n        \"\"\"\n        cls = self.__class__\n        queue = cls.queues.get(queue_name, [])\n\n        if queue:\n            task_id = queue.pop(0)\n            return cls.task_data.pop(task_id, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, queue_name, task_id):\n        # This method is *very* non-thread-safe.\n        cls = self.__class__\n        queue = cls.queues.get(queue_name, [])\n\n        if queue:\n            try:\n                offset = queue.index(task_id)\n            except ValueError:\n                return None\n\n            queue.pop(offset)\n            return cls.task_data.pop(task_id, None)", "response": "Pops a specific task off the queue by identifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an instance of CrawlModel.", "response": "def get_instance(page_to_crawl):\n    \"\"\"Return an instance of CrawlModel.\"\"\"\n    global _instances\n    if isinstance(page_to_crawl, basestring):\n        uri = page_to_crawl\n        page_to_crawl = crawlpage.get_instance(uri)\n    elif isinstance(page_to_crawl, crawlpage.CrawlPage):\n        uri = page_to_crawl.uri\n    else:\n        raise TypeError(\n            \"get_instance() expects a parker.CrawlPage \"\n            \"or basestring derivative.\"\n        )\n\n    try:\n        instance = _instances[uri]\n    except KeyError:\n        instance = CrawlModel(page_to_crawl)\n        _instances[uri] = instance\n\n    return instance"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_from_config(self, config):\n        self.site = config.get(\"id\", False)\n        self.uri_base = config.get(\"uri_base\", False)\n        self.uris_to_crawl = self.crawlpage.get_uris(\n            base_uri=self.uri_base,\n            filter_list=config.get(\"crawl_uri_filters\", None)\n        )\n        self.is_consume_page = self.crawlpage.has_selector(\n            config.get(\"consume_selector\", False)\n        )", "response": "Load model from passed configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts s3://bucketname / path / to file. txt to bucketname object_key", "response": "def _parse_s3_file(original_file):\n    \"\"\"\n    Convert `s3://bucketname/path/to/file.txt` to ('bucketname', 'path/to/file.txt')\n    \"\"\"\n    bits = original_file.replace('s3://', '').split(\"/\")\n    bucket = bits[0]\n    object_key = \"/\".join(bits[1:])\n    return bucket, object_key"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates the original file exists in the S3 bucket", "response": "def file_exists(original_file):\n    \"\"\"\n    Validate the original file is in the S3 bucket\n    \"\"\"\n    s3 = boto3.resource('s3')\n    bucket_name, object_key = _parse_s3_file(original_file)\n    bucket = s3.Bucket(bucket_name)\n    bucket_iterator = bucket.objects.filter(Prefix=object_key)\n    bucket_list = [x for x in bucket_iterator]\n    logger.debug(\"Bucket List: {0}\".format(\", \".join([x.key for x in bucket_list])))\n    logger.debug(\"bucket_list length: {0}\".format(len(bucket_list)))\n    return len(bucket_list) == 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads the file from s3", "response": "def get_file(original_file):\n    \"\"\"\n    original file should be s3://bucketname/path/to/file.txt\n\n    returns a Buffer with the file in it\n    \"\"\"\n    import cStringIO\n    import boto3\n    s3 = boto3.resource('s3')\n    bucket_name, object_key = _parse_s3_file(original_file)\n    logger.debug(\"Downloading {0} from {1}\".format(object_key, bucket_name))\n    bucket = s3.Bucket(bucket_name)\n    output = cStringIO.StringIO()\n    bucket.download_fileobj(object_key, output)\n    output.reset()\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites the buffer to modified_file", "response": "def put_file(buffer, modified_file):\n    \"\"\"\n    write the buffer to modified_file.\n\n    modified_file should be in the format 's3://bucketname/path/to/file.txt'\n    \"\"\"\n    import mimetypes\n    import boto3\n    file_type, _ = mimetypes.guess_type(modified_file)\n\n    s3 = boto3.resource('s3')\n    bucket_name, object_key = _parse_s3_file(modified_file)\n    extra_args = {\n        'ACL': 'public-read',\n        'ContentType': file_type\n    }\n    bucket = s3.Bucket(bucket_name)\n    logger.info(\"Uploading {0} to {1}\".format(object_key, bucket_name))\n    bucket.upload_fileobj(buffer, object_key, ExtraArgs=extra_args)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef assignFtypeToPyFile(extension, args=(), mimetype=None, showTerminal=True):\r\n    # WINDOWS\r\n    if os.name == 'nt':\r\n        if not isAdmin():\r\n            raise Exception(\r\n                'need to have admin rights to connect a file extension to program')\r\n\r\n        if getattr(sys, 'frozen', False):\r\n            # in case we run from an executable e.g. created with pyinstaller:\r\n            py_exec = sys.executable\r\n        else:\r\n            py_exec = sys.exec_prefix\r\n            if showTerminal:\r\n                py_exec += '\\\\python.exe'\r\n            else:\r\n                py_exec += '\\\\pythonw.exe'\r\n\r\n        # associate extension witrh MIME type:\r\n        os.system(\"assoc .%s=%s\" % (extension, mimetype))\r\n\r\n        if type(args) not in (tuple, list):\r\n            args = (args,)\r\n        if len(args) == 1:\r\n            str_args = ''' \"%s\"''' % args[0]\r\n        else:\r\n            str_args = \"\"\r\n            for a in args:\r\n                str_args += ''' \"%s\"''' % a\r\n        # open MIME type with pyFile:\r\n        os.system(\r\n            \"\"\"ftype %s=\"%s\" %s\"\"\" %\r\n            (mimetype, py_exec, str_args) + \"\"\" \"%1\" %*\"\"\")\r\n    # LINUX\r\n    # check the os to setup further procedures\r\n    # elif os.name == 'posix': #for linux-systems\r\n    #    self.__class__ = _LinuxOpenExtensionWith\r\n\r\n    # MAC\r\n    else:\r\n        raise OSError(\r\n            'creating start menu entries is not implemented for this OS at the moment')", "response": "Connect a file extension to a python script and assign a MIMETYPE name to the file extension"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_data_files(*include_dirs):\n    'called from setup.py in skeleton projects'\n    data_files = []\n    for include_dir in include_dirs:\n        for root, directories, filenames in os.walk(include_dir):\n            include_files = []\n            for filename in filenames:\n                # do not bring along certain files\n                if filename.endswith('.local'):\n                    continue\n                include_files.append(os.path.join(root, filename))\n            if include_files:\n                data_files.append((root, include_files))\n    return data_files", "response": "called from setup. py in skeleton projects"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a dictionary of HTML lists into a list of lists.", "response": "def parse_html_list(dictionary, prefix=''):\n    \"\"\"\n    Used to suport list values in HTML forms.\n    Supports lists of primitives and/or dictionaries.\n\n    * List of primitives.\n\n    {\n        '[0]': 'abc',\n        '[1]': 'def',\n        '[2]': 'hij'\n    }\n        -->\n    [\n        'abc',\n        'def',\n        'hij'\n    ]\n\n    * List of dictionaries.\n\n    {\n        '[0]foo': 'abc',\n        '[0]bar': 'def',\n        '[1]foo': 'hij',\n        '[1]bar': 'klm',\n    }\n        -->\n    [\n        {'foo': 'abc', 'bar': 'def'},\n        {'foo': 'hij', 'bar': 'klm'}\n    ]\n    \"\"\"\n    ret = {}\n    regex = re.compile(r'^%s\\[([0-9]+)\\](.*)$' % re.escape(prefix))\n    for field, value in dictionary.items():\n        match = regex.match(field)\n        if not match:\n            continue\n        index, key = match.groups()\n        index = int(index)\n        if not key:\n            ret[index] = value\n        elif isinstance(ret.get(index), dict):\n            ret[index][key] = value\n        else:\n            ret[index] = MultiValueDict({key: [value]})\n    return [ret[item] for item in sorted(ret.keys())]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_html_dict(dictionary, prefix=''):\n    ret = MultiValueDict()\n    regex = re.compile(r'^%s\\.(.+)$' % re.escape(prefix))\n    for field, value in dictionary.items():\n        match = regex.match(field)\n        if not match:\n            continue\n        key = match.groups()[0]\n        ret[key] = value\n    return ret", "response": "Parses a dictionary of values in HTML forms."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind the version of a string in the library file.", "response": "def find_version_by_string_lib(line):  # type: (str)->Optional[str]\n    \"\"\"\n    No regex parsing. Or at least, mostly, not regex.\n    \"\"\"\n    if not line:\n        return None\n    simplified_line = simplify_line(line)\n    version = None\n    if simplified_line.startswith(\"version=\"):\n        if '\"' not in simplified_line:\n            pass\n            # logger.debug(\"Weird version string, no double quote : \" + unicode((full_path, line, simplified_line)))\n        else:\n            if \"=\" in simplified_line:\n                post_equals = simplified_line.split(\"=\")[0]\n                if '\"' in post_equals:\n                    parts = post_equals.split('\"')\n\n                    if len(parts) != 3:\n                        # logger.debug(\"Weird string, more than 3 parts : \" + unicode((full_path, line, simplified_line)))\n                        version = parts[0]\n    return version"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding a version in a line.", "response": "def find_in_line(line):  # type: (str) -> Optional[str]\n    \"\"\"\n    Find a version in a line.\n    :param line:\n    :return:\n    \"\"\"\n    if not line:\n        return None\n\n    for method in [find_by_ast, find_version_by_string_lib, find_version_by_regex]:\n        by = method(line)\n        by = validate_string(by)\n        if by:\n            return by\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef meta(self):\n        mount_points = []\n        for overlay in self.overlays:\n            mount_points.append(overlay.mount_point)\n        return [self.end_dir, self.start_dir, mount_points]", "response": "Data for loading later"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget format for log level.", "response": "def get_level_fmt(self, level):\n        \"\"\"Get format for log level.\"\"\"\n        key = None\n        if level == logging.DEBUG:\n            key = 'debug'\n        elif level == logging.INFO:\n            key = 'info'\n        elif level == logging.WARNING:\n            key = 'warning'\n        elif level == logging.ERROR:\n            key = 'error'\n        elif level == logging.CRITICAL:\n            key = 'critical'\n        return self.overwrites.get(key, self.fmt)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start_simple_server():\r\n\t\"A simple mail server that sends a simple response\"\r\n\targs = _get_args()\r\n\taddr = ('', args.port)\r\n\tDebuggingServer(addr, None)\r\n\tasyncore.loop()", "response": "A simple mail server that sends a simple response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if obj matches the current object.", "response": "def match(self, obj):\n        \"\"\"\n        Returns\n            bool: it matches\n        \"\"\"\n        path, frag = [], obj\n        for part in self.parts:\n            path.append(part)\n            if isinstance(frag, dict):\n                try:\n                    frag = frag[part]\n                except KeyError:\n                    return False\n            elif isinstance(frag, (list, tuple)):\n                frag = part in frag\n            elif isinstance(frag, str):\n                frag = frag == part\n            elif isinstance(frag, int):\n                frag = frag == int(part)\n            else:\n                return False\n        return True if frag else False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the object from the database.", "response": "def read(self, obj):\n        \"\"\"\n        Returns\n            object: fragment\n        \"\"\"\n        path, frag = [], obj\n        for part in self.parts:\n            path.append(part)\n            if isinstance(frag, dict):\n                try:\n                    frag = frag[part]\n                except KeyError as error:\n                    raise NotFound(':'.join(path)) from error\n            elif isinstance(frag, (list, tuple)):\n                try:\n                    frag = frag[int(part)]\n                except IndexError as error:\n                    raise NotFound(':'.join(path)) from error\n                except ValueError as error:\n                    raise WrongType(':'.join(path)) from error\n            elif isinstance(frag, (str, int)):\n                raise WrongType(':'.join(path))\n            else:\n                raise NotFound(':'.join(path))\n        return frag"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write(self, obj, value, merge=False):\n        full = deepcopy(obj)\n        frag = full\n\n        parts, last = self.parts[:-1], self.parts[-1]\n        for part in parts:\n            if isinstance(frag, dict):\n                frag = frag[part]\n            elif isinstance(frag, (list, tuple)):\n                frag = frag[int(part)]\n\n        if isinstance(frag, dict):\n            if last in frag and merge:\n                frag[last].update(value)\n            else:\n                frag[last] = value\n        elif isinstance(frag, list):\n            if last == '-':\n                frag.append(value)\n            else:\n                frag[int(last)] = value\n\n        return full", "response": "Writes the value into the obj\nAttributeNames dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete an object from the set.", "response": "def delete(self, obj):\n        \"\"\"\n        Returns\n            object: full copy of new obj\n        \"\"\"\n        full = deepcopy(obj)\n        frag = full\n        parts, last = self.parts[:-1], self.parts[-1]\n        for part in parts:\n            if isinstance(frag, dict):\n                frag = frag[part]\n            elif isinstance(frag, (list, tuple)):\n                frag = frag[int(part)]\n\n        if isinstance(frag, dict):\n            frag.pop(last)\n        elif isinstance(frag, list):\n            if last == '-':\n                frag.pop()\n            else:\n                frag.pop(int(last))\n\n        return full"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates the revocation request for the current user and update the status of the response.", "response": "def on_post(self, req, resp):\n        \"\"\" Validate the token revocation request for spec compliance\n\n        The spec also dictates the JSON based error response\n        on failure & is handled in this responder.\n        \"\"\"\n\n        token = req.get_param('token')\n        token_type_hint = req.get_param('token_type_hint')\n\n        # errors or not, disable client caching along the way\n        # per the spec\n        resp.disable_caching()\n\n        if not token:\n            resp.status = falcon.HTTP_400\n            resp.serialize({\n                'error': 'invalid_request',\n                'error_description': 'A token parameter is required during '\n                                     'revocation according to RFC 7009.',\n                'error_uri': 'tools.ietf.org/html/rfc7009#section-2.1',\n            })\n        elif token_type_hint == 'refresh_token':\n            resp.status = falcon.HTTP_400\n            resp.serialize({\n                'error': 'unsupported_token_type',\n                'error_description': 'Currently only access_token types can '\n                                     'be revoked, NOT refresh_token types.',\n                'error_uri': 'tools.ietf.org/html/rfc7009#section-2.2.1',\n            })\n        else:\n            # ignore return code per section 2.2\n            self.revoke_token(token)\n            resp.status = falcon.HTTP_200"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nemulates a seek on an object that does not support it.", "response": "def emulate_seek(fd, offset, chunk=CHUNK):\n    \"\"\" Emulates a seek on an object that does not support it\n\n    The seek is emulated by reading and discarding bytes until specified offset\n    is reached.\n\n    The ``offset`` argument is in bytes from start of file. The ``chunk``\n    argument can be used to adjust the size of the chunks in which read\n    operation is performed. Larger chunks will reach the offset in less reads\n    and cost less CPU but use more memory. Conversely, smaller chunks will be\n    more memory efficient, but cause more read operations and more CPU usage.\n\n    If chunk is set to None, then the ``offset`` amount of bytes is read at\n    once. This is fastest but depending on the offset size, may use a lot of\n    memory.\n\n    Default chunk size is controlled by the ``fsend.rangewrapper.CHUNK``\n    constant, which is 8KB by default.\n\n    This function has no return value.\n    \"\"\"\n    while chunk and offset > CHUNK:\n        fd.read(chunk)\n        offset -= chunk\n    fd.read(offset)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nforcing adjustment of read cursort to specified offset", "response": "def force_seek(fd, offset, chunk=CHUNK):\n    \"\"\" Force adjustment of read cursort to specified offset\n\n    This function takes a file descriptor ``fd`` and tries to seek to position\n    specified by ``offset`` argument. If the descriptor does not support the\n    ``seek()`` method, it will fall back to ``emulate_seek()``.\n\n    The optional ``chunk`` argument can be used to adjust the chunk size for\n    ``emulate_seek()``.\n    \"\"\"\n    try:\n        fd.seek(offset)\n    except (AttributeError, io.UnsupportedOperation):\n        # This file handle probably has no seek()\n        emulate_seek(fd, offset, chunk)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a specified number of bytes from the file descriptor returning them as a string.", "response": "def read(self, size=None):\n        \"\"\" Read a specified number of bytes from the file descriptor\n\n        This method emulates the normal file descriptor's ``read()`` method and\n        restricts the total number of bytes readable.\n\n        If file descriptor is not present (e.g., ``close()`` method had been\n        called), ``ValueError`` is raised.\n\n        If ``size`` is omitted, or ``None``, or any other falsy value, read\n        will be done up to the remaining length (constructor's ``length``\n        argument minus the bytes that have been read previously).\n\n        This method internally invokes the file descriptor's ``read()`` method,\n        and the method must accept a single integer positional argument.\n        \"\"\"\n        if not self.fd:\n            raise ValueError('I/O on closed file')\n        if not size:\n            size = self.remaining\n        size = min([self.remaining, size])\n        if not size:\n            return ''\n        data = self.fd.read(size)\n        self.remaining -= size\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef placeholdit(\n    width,\n    height,\n    background_color=\"cccccc\",\n    text_color=\"969696\",\n    text=None,\n    random_background_color=False\n):\n    \"\"\"\n    Creates a placeholder image using placehold.it\n\n    Usage format:\n\n      {% placeholdit [width] [height] [background_color] [text_color] [text] %}\n\n    Example usage:\n\n        Default image at 250 square\n        {% placeholdit 250 %}\n\n        100 wide and 200 high\n        {% placeholdit 100 200 %}\n\n        Custom background and text colors\n        {% placeholdit 100 200 background_color='fff' text_color=000' %}\n\n        Custom text\n        {% placeholdit 100 200 text='Hello LA' %}\n    \"\"\"\n    url = get_placeholdit_url(\n        width,\n        height,\n        background_color=background_color,\n        text_color=text_color,\n        text=text,\n    )\n    return format_html('<img src=\"{}\"/>', url)", "response": "Returns a placeholdit image using placehold. it\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pangram(language='en'):\n    try:\n        pangram = get_pangram(language)\n    except KeyError:\n        raise template.TemplateSyntaxError(\n            \"Could not find a pangram for %r abbreviation\" % language\n        )\n    return get_pangram_html(pangram)", "response": "Print a pangram in the specified language."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sync_one(self, aws_syncr, amazon, role):\n        trust_document = role.trust.document\n        attached_policies = role.attached_policies\n        permission_document = role.permission.document\n        policy_name = \"syncr_policy_{0}\".format(role.name.replace('/', '__'))\n\n        role_info = amazon.iam.role_info(role.name)\n        if not role_info:\n            amazon.iam.create_role(role.name, trust_document, policies={policy_name: permission_document}, attached_policies=attached_policies)\n        else:\n            amazon.iam.modify_role(role_info, role.name, trust_document, policies={policy_name: permission_document}, attached_policies=attached_policies)\n\n        if role.make_instance_profile:\n            amazon.iam.make_instance_profile(role.name)", "response": "Make sure this role exists and has only what policies we want it to have"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the result of the query", "response": "def _get_result(self):\n        \"\"\"\n        get the result\n        \"\"\"\n        info = {}\n\n        self.options2attr = {\n            'email': self._email,\n            'telephone': self._telephone,\n            'QQ' : self._QQ,\n            'wechat': self._wechat,\n            'url': self._url,\n            'emoji': self._emoji,\n            'tex': self._tex,\n            'blur': self._blur,\n            'message': self.m,\n        }\n\n        for item in self.option:\n            info[item] = self.options2attr[item]\n        return info"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _clear(self):\n        self._email = []\n        self._telephone = []\n        self._QQ = []\n        self._wechat = []\n        self._url = []\n        self._emoji = []\n        self._tex = []\n        self._blur = []", "response": "clear all the attributes"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts info specified in option", "response": "def extract(self, m):\n        \"\"\"\n        extract info specified in option\n        \"\"\"\n        self._clear()\n        self.m = m\n        # self._preprocess()\n\n        if self.option != []:\n            self._url_filter()\n            self._email_filter()\n            if 'tex' in self.option:\n                self._tex_filter()\n            # if 'email' in self.option:\n            #     self._email_filter()\n            if 'telephone' in self.option:\n                self._telephone_filter()\n            if 'QQ' in self.option:\n                self._QQ_filter()\n            if 'emoji' in self.option:\n                self._emoji_filter()\n            if 'wechat' in self.option:\n                self._wechat_filter()\n        self._filter()\n        if 'blur' in self.option:\n            self._blur = get_number(self.m, self._limit)\n\n        return self._get_result()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _filter(self):\n        pattern = u\"[\\s+\\.\\!\\-\\/_,$%^*(+\\\"\\']+|[+\u2014\u2014\uff01\u3011\u3010\uff0c\u3002\uff1f?:\u3001\uff1a~@#\uffe5%\u2026\u2026&*\u201c\u201d\uff08\uff09]+\"\n        self.m = re.sub(pattern, \"\", self.m)", "response": "Remove punctuation from the beginning of the string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nenabling or disables logs to be written to files", "response": "def set_log_rotate_handler(self, set_file):\n        '''Enables/disables logs to be written to files\n\n        Arguments:\n            set_file (:obj:`bool`): False disables, True enables\n\n        '''\n        if hasattr(self, 'debug_handler'):\n            if set_file:\n                self.log.addHandler(self.debug_handler)\n                self.log.addHandler(self.error_handler)\n            else:\n                try:\n                    self.log.removeHandler(self.error_handler)\n                    self.log.removeHandler(self.debug_handler)\n                except Exception:\n                    pass\n        else:\n            self.log.debug('The file log handlers were not created. It is not\\\n                           possible to write to the log files.')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_log_level(self, log_level):\n        '''Configures class log level\n\n        Arguments:\n            log_level (:obj:`str`): log level ('NOTSET','DEBUG','INFO' 'WARNING',\n                'ERROR', 'CRITICAL')\n\n        '''\n        if log_level == 'DEBUG':\n            self.log.setLevel(logging.DEBUG)\n            self.log.debug(\"Changing log level to \"+log_level)\n        elif log_level == 'INFO':\n            self.log.setLevel(logging.INFO)\n            self.log.info(\"Changing log level to \"+log_level)\n        elif log_level == 'WARNING':\n            self.log.setLevel(logging.WARNING)\n            self.log.warning(\"Changing log level to \"+log_level)\n        elif log_level == 'ERROR':\n            self.log.setLevel(logging.ERROR)\n            self.log.error(\"Changing log level to \"+log_level)\n        elif log_level == 'CRITICAL':\n            self.log.setLevel(logging.CRITICAL)\n            self.log.critical(\"Changing log level to \"+log_level)\n        elif log_level == 'NOTSET':\n            self.log.setLevel(logging.NOTSET)\n        else:\n            raise NotImplementedError('Not implemented log level '+str(log_level))", "response": "Configures class log level"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_log_format(self, log_type, log_format):\n        '''Configures log format\n\n        Arguments:\n            log_type (:obj:`str`): log type (error, debug or stream)\n            log_format (:obj:`str`): log format (ex:\"Log: %(message)s | Log level:%(levelname)s |\n                Date:%(asctime)s',datefmt='%m/%d/%Y %I:%M:%S\")\n\n        '''\n        if not (log_type == 'error' or log_type == 'stream' or log_type == 'debug'):\n            self.log.debug('Log type must be error, stream, or debug')\n        else:\n            self.default_formatter = logging.Formatter(log_format)\n            if log_type == 'error':\n                self.error_handler.setFormatter(self.default_formatter)\n            elif log_type == 'debug':\n                self.debug_handler.setFormatter(self.default_formatter)\n            elif log_type == 'stream':\n                self.stream_handler.setFormatter(self.default_formatter)", "response": "Configures log format\n\n        Arguments:\n            log_type (:obj:`str`): log type (error, debug or stream)\n            log_format (:obj:`str`): log format (ex:\"Log: %(message)s | Log level:%(levelname)s |\n                Date:%(asctime)s',datefmt='%m/%d/%Y %I:%M:%S\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd question answer set to DB.", "response": "def add_document(self, question, answer):\n        \"\"\"Add question answer set to DB.\n\n        :param question: A question to an answer\n        :type question: :class:`str`\n\n        :param answer: An answer to a question\n        :type answer: :class:`str`\n\n        \"\"\"\n        question = question.strip()\n        answer = answer.strip()\n\n        session = self.Session()\n\n        if session.query(Document) \\\n                .filter_by(text=question, answer=answer).count():\n            logger.info('Already here: {0} -> {1}'.format(question, answer))\n            return\n        logger.info('add document: {0} -> {1}'.format(question, answer))\n\n        grams = self._get_grams(session, question, make=True)\n\n        doc = Document(question, answer)\n        doc.grams = list(grams)\n        self._recalc_idfs(session, grams)\n\n        session.add(doc)\n        session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the best answer to a question.", "response": "def get_best_answer(self, query):\n        \"\"\"Get best answer to a question.\n\n        :param query: A question to get an answer\n        :type query: :class:`str`\n\n        :returns: An answer to a question\n        :rtype: :class:`str`\n\n        :raises: :class:`NoAnswerError` when can not found answer to a question\n\n        \"\"\"\n        query = to_unicode(query)\n        session = self.Session()\n\n        grams = self._get_grams(session, query)\n        if not grams:\n            raise NoAnswerError('Can not found answer')\n\n        documents = set([doc for gram in grams for doc in gram.documents])\n\n        self._recalc_idfs(session, grams)\n\n        idfs = dict((gram.gram, gram.idf) for gram in grams)\n\n        docs = dict(\n            (doc.answer, _cosine_measure(idfs, self._get_tf_idfs(doc)))\n            for doc in documents)\n        docs = dict((key, val) for (key, val) in docs.items() if val)\n\n        session.commit()\n\n        try:\n            max_ratio = max(docs.values())\n            answers = [answer for answer in docs.keys()\n                       if docs.get(answer) == max_ratio]\n\n            answer = random.choice(answers)\n            logger.debug('{0} -> {1} ({2})'.format(query, answer, max_ratio))\n            return (answer, max_ratio)\n        except ValueError:\n            raise NoAnswerError('Can not found answer')\n        finally:\n            session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef recreate_grams(self):\n\n        session = self.Session()\n\n        for document in session.query(Document).all():\n            logger.info(document.text)\n            grams = self._get_grams(session, document.text, make=True)\n            document.grams = list(grams)\n\n        broken_links = session.query(Gram) \\\n            .filter(~Gram.documents.any()).all()\n        for gram in broken_links:\n            session.delete(gram)\n\n        session.commit()", "response": "Re - create grams for database."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts an active generator to a generatorLink.", "response": "def link_generator(element):\n    \"\"\"\n    Convert active generators to a :py:class:`~.GeneratorLink` instance\n\n    This converter automatically constructs a :py:class:`~.GeneratorLink`\n    from any :term:`generator iterator` (not a :term:`generator function <generator>`).\n    The following two lines produce the same chain:\n\n    .. code:: python\n\n        a >> generator >> e\n        a >> GeneratorLink(generator) >> e\n\n    Note that the source of the generator is inconsequential.\n    For example, a :term:`generator expression` can be used to provide values:\n\n    .. code:: python\n\n        ((value, value**2) for value in range(500)) >> printlet(flatten=True)\n\n    The :term:`generator iterator` is *not* primed when binding.\n    This makes it suitable for producing values, but not for transforming values.\n    \"\"\"\n    if isinstance(element, types.GeneratorType):\n        return GeneratorLink(element, prime=False)\n    return NotImplemented"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nraises exception in generator.", "response": "def throw(self, typ, val=None, tb=None):  # pylint:disable=method-hidden,invalid-name\n        \"\"\"\n        throw(typ[,val[,tb]]) -> raise exception in generator,\n        return next yielded value or raise StopIteration.\n        \"\"\"\n        self._materialize()\n        self._generator.throw(typ, val, tb)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef throw(self, type, value=None, traceback=None):  # pylint: disable=redefined-builtin\n        return self.__wrapped__.throw(type, value, traceback)", "response": "Raise an exception in this element"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enumeratelet(iterable=None, start=0):\n    # shortcut directly to chain enumeration\n    if iterable is None:\n        return _enumeratelet(start=start)\n    try:\n        iterator = iter(iterable)\n    except TypeError:\n        if start != 0:\n            raise  # first arg is not iterable but start is explicitly set\n        return _enumeratelet(start=iterable)  # first arg is not iterable, try short notation\n    else:\n        return iterlet(enumerate(iterator, start=start))", "response": "r Enumerates chunks of data from an iterable or a chainable sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfilters chunks of data from an iterable or a chain of data.", "response": "def filterlet(function=bool, iterable=None):\n    \"\"\"\n    Filter chunks of data from an iterable or a chain\n\n    :param function: callable selecting valid elements\n    :type function: callable\n    :param iterable: object providing chunks via iteration\n    :type iterable: iterable or None\n\n    For any chunk in ``iterable`` or the chain, it is passed on only if\n    ``function(chunk)`` returns true.\n\n    .. code::\n\n        chain = iterlet(range(10)) >> filterlet(lambda chunk: chunk % 2 == 0)\n        for value in chain:\n            print(value)  # prints 0, 2, 4, 6, 8\n    \"\"\"\n    if iterable is None:\n        return _filterlet(function=function)\n    else:\n        return iterlet(elem for elem in iterable if function(elem))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef printlet(flatten=False, **kwargs):\n    chunk = yield\n    if flatten:\n        while True:\n            print(*chunk, **kwargs)\n            chunk = yield chunk\n    else:\n        while True:\n            print(chunk, **kwargs)\n            chunk = yield chunk", "response": "Print chunks of data from a chain."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes sure this function exists and has only attributes we want it to have", "response": "def sync_one(self, aws_syncr, amazon, function):\n        \"\"\"Make sure this function exists and has only attributes we want it to have\"\"\"\n        function_info = amazon.lambdas.function_info(function.name, function.location)\n        if not function_info:\n            amazon.lambdas.create_function(function.name, function.description, function.location, function.runtime, function.role, function.handler, function.timeout, function.memory_size, function.code)\n        else:\n            amazon.lambdas.modify_function(function_info, function.name, function.description, function.location, function.runtime, function.role, function.handler, function.timeout, function.memory_size, function.code)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a version string and returns a version object and the next version.", "response": "def version_object_and_next(string, retries=0):  # type: (str, int) -> VersionThing\n    \"\"\"\n    Try three parsing strategies, favoring semver, then pep440, then whatev.\n    :param string:\n    :return:\n    \"\"\"\n    if retries > 2:\n        raise JiggleVersionException(\n            \"Can't parse, ran out of retries: \" + unicode(string)\n        )\n    if string == \"\" or string is None:\n        raise JiggleVersionException(\"No version string, can only use default logic.\")\n\n    if string[0] == \"v\":\n        string = string[1:]\n\n    try:\n        version = semantic_version.Version(string)\n        next_version = version.next_patch()\n        _ = semantic_version.Version(unicode(string))\n        return version, next_version, \"semantic_version\"\n    except:\n        logger.debug(\"Not sem_ver:\" + unicode(string))\n        try:\n            version = parver.Version.parse(string)\n            next_version = version.bump_dev()\n            _ = parver.Version.parse(unicode(next_version))\n            return version, next_version, \"pep440 (parver)\"\n        except:\n            try:\n                logger.debug(\"Not par_ver:\" + unicode(string))\n                # Version.supported_version_schemes = [Pep440VersionScheme, Simple4VersionScheme]\n                version = versio_version.Version(string, scheme=Simple4VersionScheme)\n                version.bump()\n                return (\n                    versio_version.Version(string, scheme=Simple4VersionScheme),\n                    version,\n                    \"simple-4 part (versio)\",\n                )\n            except:\n                # let above libs try first before we do primitive clean up work\n                retries += 1\n                if \"a\" in string:\n                    return version_object_and_next(string.replace(\"a\", \".a\"), retries)\n                elif \"b\" in string:\n                    return version_object_and_next(string.replace(\"b\", \".b\"), retries)\n                elif len(string.split(\".\")) == 1:\n                    # convert 2 part to 3 part.\n                    return version_object_and_next(string + \".0.0\", retries)\n                elif len(string.split(\".\")) == 2:\n                    # convert 2 part to 3 part, e.g. 1.1 -> 1.1.0\n                    return version_object_and_next(string + \".0\", retries)\n                elif string.isnumeric() and \".\" not in string:\n                    # e.g. \"21\" -> \"21.0.0\"\n                    return version_object_and_next(string + \".0.0\", retries)\n                else:\n                    logger.debug(\"Not versio:\" + unicode(string))\n                    # versio only does pep440 by default\n                    # print(versio.version.Version.supported_version_schemes)\n                    raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the difference of all values in self and the union of all values in args.", "response": "def complement(self, *args):\n        '''Returns the difference of the union of all values and the union of the values in *args.\n        '''\n        universe = self.union()\n        to_diff = self.union(*args)\n        return universe.difference(to_diff)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef intersection(self, *args):\n        '''Returns the intersection of the values whose keys are in *args.  If *args is blank, returns the intersection of all values.\n        '''\n        values = self.values()\n        if args:\n            values = [val for key,val in self.items() if key in args]\n        return set(reduce(set.intersection, values))", "response": "Returns the intersection of the values whose keys are in args."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npreserving order if given an assoc list.", "response": "def update(self, *args, **kwargs):\n        '''Preserves order if given an assoc list.\n        '''\n        arg = dict_arg(*args, **kwargs)\n        if isinstance(arg, list):\n          for key, val in arg:\n              self[key] = val\n        else:\n            super(AssocDict, self).update(arg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the URL path for a live doo list.", "response": "def _get_url_path(list_name):\n    \"\"\"\n    Live Dao requires RESTCLIENTS_MAILMAN_KEY in the settings.py\n    \"\"\"\n    access_key = getattr(settings,\n                         \"RESTCLIENTS_MAILMAN_KEY\",\n                         \"__mock_key__\")\n    return URL.format(key=access_key, uwnetid=list_name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_signature(cls, function):\n        '''Parses the signature of a method and its annotations to swagger.\n\n        Return a dictionary {arg_name: info}.\n        '''\n        annotations = function.__annotations__.copy()\n        del annotations['return']\n        result = []\n        for param_name, (param_type, param_obj) in annotations.items():\n            sig_param = function.signature.parameters[param_name]\n            param_description = {\n                'paramType': param_type,\n                'name': param_name,\n                'required': sig_param.default is inspect.Parameter.empty}\n            param_description.update(param_obj.describe())\n            result.append(param_description)\n        return result", "response": "Parses the signature of a method and its annotations to swagger.\n        Return a dictionary { arg_name : info."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_swagger_fragment(cls):\n        '''Return the swagger-formatted fragment for the Resource Listing.'''\n        if cls.__swagger_fragment:\n            return cls.__swagger_fragment\n        cls.__swagger_fragment = {\n            'path': cls.endpoint_path.replace('<', '{').replace('>', '}'),\n            'description': cls.description,\n            'operations': cls.get_resource_operations(),\n        }\n        return cls.__swagger_fragment", "response": "Return the swagger - formatted fragment for the Resource Listing."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_resource_operations(cls):\n        '''Return the swagger-formatted method descriptions'''\n        operations = []\n        for http, callback in cls.implemented_methods.items():\n            # Parse docstring\n            summary, notes = utils.parse_docstring(callback)\n            # Parse return annotations\n            responses = utils.parse_return_annotation(callback)\n            ok_result_model = responses[200]['responseModel']\n            operations.append({\n                'method': http,\n                'nickname': callback.__name__,\n                'type': ok_result_model,\n                'parameters': cls.parse_signature(callback),\n                'summary': summary.strip(),\n                'notes': notes.strip(),\n                'responseMessages': list(responses.values())\n            })\n        return operations", "response": "Return the swagger - formatted method descriptions"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_routing_tuples(cls):\n        '''A generator of (rule, callback) tuples.'''\n        for callback in cls.callbacks:\n            ep_name = '{}.{}'.format(cls.api.__name__, callback.__name__)\n            yield (Rule(cls.endpoint_path,\n                        endpoint=ep_name,\n                        methods=callback.swagger_ops),\n                   callback)", "response": "A generator of ( rule callback ) tuples."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn all the methods that are actually a request callback.", "response": "def callbacks(cls):\n        '''Return all the methods that are actually a request callback.'''\n        if cls.__callbacks is not None:\n            return cls.__callbacks\n        cls.__callbacks = []\n        for mname in dir(cls):\n            # Avoid recursion by excluding all methods of this prototype class\n            if mname in dir(Resource):\n                continue\n            callback = getattr(cls, mname)\n            if not hasattr(callback, 'swagger_ops'):\n                continue\n            cls.__callbacks.append(callback)\n        return cls.__callbacks"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a mapping of implemented HTTP methods vs. their callbacks.", "response": "def implemented_methods(cls):\n        '''Return a mapping of implemented HTTP methods vs. their callbacks.'''\n        if cls.__implemented_methods:\n            return cls.__implemented_methods\n        cls.__implemented_methods = {}\n        for method in cls.callbacks:\n            for op in getattr(method, 'swagger_ops'):\n                cls.__implemented_methods[op] = method\n        return cls.__implemented_methods"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfits a 2d array to a 2d function", "response": "def fit2dArrayToFn(arr, fn, mask=None, down_scale_factor=None,\n                   output_shape=None, guess=None,\n                   outgrid=None):\n    \"\"\"Fit a 2d array to a 2d function\n\n    USE ONLY MASKED VALUES\n    \n    * [down_scale_factor] map to speed up fitting procedure, set value smaller than 1\n    * [output_shape] shape of the output array\n    * [guess] must be scaled using [scale_factor]\n\n    Returns:\n        Fitted map, fitting params (scaled), error\n    \"\"\"\n    if mask is None:\n        #assert outgrid is not None\n        mask = np.ones(shape=arr.shape, dtype=bool)\n\n    if down_scale_factor is None:\n        if mask.sum() > 1000:\n            down_scale_factor = 0.3\n        else:\n            down_scale_factor = 1\n\n    if down_scale_factor != 1:\n        # SCALE TO DECREASE AMOUNT OF POINTS TO FIT:\n        arr2 = zoom(arr, down_scale_factor)\n        mask = zoom(mask, down_scale_factor, output=bool)\n    else:\n        arr2 = arr\n    # USE ONLY VALID POINTS:\n    x, y = np.where(mask)\n    z = arr2[mask]\n    # FIT:\n    parameters, cov_matrix = curve_fit(fn, (x, y), z, p0=guess)\n    # ERROR:\n    perr = np.sqrt(np.diag(cov_matrix))\n\n    if outgrid is not None:\n        yy,xx = outgrid\n        rebuilt = fn((yy,xx), *parameters)\n    else:\n        if output_shape is None:\n            output_shape = arr.shape\n    \n        fx = arr2.shape[0] / output_shape[0]\n        fy = arr2.shape[1] / output_shape[1]\n    \n        rebuilt = np.fromfunction(lambda x, y: fn((x * fx, y * fy),\n                                                  *parameters), output_shape)\n\n    return rebuilt, parameters, perr"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _validate_auth_scheme(self, req):\n\n        if not req.auth:\n            raise AuthRequired(**{\n                'detail': 'You must first login to access the requested '\n                          'resource(s). Please retry your request using '\n                          'OAuth 2.0 Bearer Token Authentication as '\n                          'documented in RFC 6750. If you do not have an '\n                          'access_token then request one at the token '\n                          'endpdoint of: %s' % self.token_endpoint,\n                'headers': self._error_headers,\n                'links': 'tools.ietf.org/html/rfc6750#section-2.1',\n            })\n        elif req.auth_scheme != 'bearer':\n            raise AuthRequired(**{\n                'detail': 'Your Authorization header is using an unsupported '\n                          'authentication scheme. Please modify your scheme '\n                          'to be a string of: \"Bearer\".',\n                'headers': self._error_headers,\n                'links': 'tools.ietf.org/html/rfc6750#section-2.1',\n            })", "response": "Checks if the request has an auth & the proper scheme and raises an exception if not."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_token(self, req):\n\n        self._validate_auth_scheme(req)\n\n        try:\n            return naked(req.auth.split(' ')[1])\n        except IndexError:\n            desc = 'You are using the Bearer Authentication scheme as ' \\\n                   'required to login but your Authorization header is ' \\\n                   'completely missing the access_token.'\n\n            raise InvalidAuthSyntax(**{\n                'detail': desc,\n                'headers': self._get_invalid_token_headers(desc),\n                'links': 'tools.ietf.org/html/rfc6750#section-2.1',\n            })", "response": "Get the token from the Authorization header."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_request(self, req, resp):  # pylint: disable=unused-argument\n\n        if req.path in (self.revoke_endpoint, self.token_endpoint):\n            return\n\n        try:\n            token = self._get_token(req)\n            self.auth_token(token)\n        except (AuthRequired, InvalidAuthSyntax) as exc:\n            if not self.optional:\n                abort(exc)\n        except AuthRejected as exc:\n            if not self.optional:\n                exc.headers = self._get_invalid_token_headers(exc.detail)\n                abort(exc)", "response": "Process the request before routing it."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start(self):\n\n        if self._timer:\n            self._timer.cancel()\n\n        self._timer = Timer(self._timeout, self._fire)\n        self._timer.start()", "response": "Starts the delayed execution"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tmpfile(root=TEMPS_DIR, prefix=TEMPS_PREFIX, suffix=TEMPS_SUFFIX):\n    '''\n    For use in a with statement, this function returns a context manager that\n    yields a path directly under root guaranteed to be unique by using the uuid\n    module.  This path is not created.  However if the path is an existing file\n    when the with statement is exited, the file will be removed.\n\n    This function is useful if you want to use a file temporarily but do not\n    want to write boilerplate to make sure it is removed when you are done with\n    it.\n\n    Example:\n\n        with temps.tmpfile() as path:\n            do_stuff(path)\n    '''\n    path = tmppath(root, prefix, suffix)\n    try:\n        yield path\n    finally:\n        if os.path.isfile(path):\n            # try to delete the file\n            os.unlink(path)", "response": "A context manager that returns a temporary file under root."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tmpdir(root=TEMPS_DIR, prefix=TEMPS_PREFIX, suffix=TEMPS_SUFFIX,\n             mode=TEMPS_MODE, use_umask=True):\n    '''\n    use_umask: if False, the mode of the created directory will be explicitly\n    set to `mode` using os.chmod.  By default, `mode` is altered by the current\n    umask.\n\n    For use in a with statement, this function returns a context manager that\n    makes and a directory directly under root with the given mode that is\n    guaranteed to be uniquely named by using the uuid module.  Then it yields\n    the directory path.  When the context is exited the directory and\n    everything under it will be removed.\n\n    This function is useful if you need an isolated place to do some temporary\n    work with files and dirs without worrying about naming conflicts and\n    without having to write boilerplate and error handling to make sure the\n    directory is cleaned up.\n\n    Example:\n\n        with temps.tmpdir() as workingdir:\n            do_this(workingdir)\n            do_that(workingdir)\n    '''\n    path = tmppath(root, prefix, suffix)\n    os.makedirs(path, mode=mode)\n    if not use_umask:\n        os.chmod(path, mode)\n\n    try:\n        yield path\n    finally:\n        shutil.rmtree(path)", "response": "A context manager that creates a temporary directory under root."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a path to a temporary file under root.", "response": "def tmppath(root=TEMPS_DIR, prefix=TEMPS_PREFIX, suffix=TEMPS_SUFFIX):\n    '''\n    Returns a path directly under root that is guaranteed to be unique by\n    using the uuid module.\n    '''\n    return os.path.join(root, prefix + uuid.uuid4().hex + suffix)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the last uploaded directory backup", "response": "def s3_get_dir_backup(aws_access_key_id, aws_secret_access_key, bucket_name, s3_folder, zip_backups_dir, project):\n    \"\"\"\n    get last uploaded directory backup\n    :param aws_access_key_id:\n    :param aws_secret_access_key:\n    :param bucket_name:\n    :param s3_folder:\n    :param zip_backups_dir:\n    :param project:\n    :return:\n    \"\"\"\n\n    matches = []\n    pat = dir_zip_pat % project\n    print('looking for pat \"%s\" in bucket %s' % (pat, bucket_name))\n    bucket = s3_bucket(aws_access_key_id, aws_secret_access_key, bucket_name)\n    bucketlist = bucket.list()\n    for f in bucketlist:\n        \n        if re.search(pat + '$', f.name):\n            print('%s matches' % f.name)\n            bk_date = dt.strptime(f.name.replace(s3_folder + '/', '')[0:19], TIMESTAMP_FORMAT)\n            matches.append({\n                'key': f,\n                'file': f.name,\n                'date': bk_date\n            })\n    if matches:\n        last_bk = sorted(matches, key=operator.itemgetter('date'))[0]\n        dest = os.path.join(zip_backups_dir, last_bk['file'].replace(s3_folder + '/', ''))\n        if not os.path.exists(dest):\n            last_bk['key'].get_contents_to_filename(dest)\n            print('Downloaded %s to %s' % (f.name, dest))\n        else:\n            print('Last backup %s already exists' % dest)\n    else:\n        print('no matches')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef backup(\n        datadir,\n        aws_access_key_id,\n        aws_secret_access_key,\n        bucket_name,\n        zip_backups_dir, backup_aging_time, s3_folder, project):\n    \"\"\"\n    zips dir into /backups, uploads to s3, deletes backups older than backup_aging_time.\n    fab -f ./fabfile.py backup_dbs\n    :param datadir:\n    :param aws_access_key_id:\n    :param aws_secret_access_key:\n    :param bucket_name:\n    :param zip_backups_dir:\n    :param backup_aging_time:\n    :param s3_folder:\n    :param project:\n    :return:\n    \"\"\"\n\n    #  Connect to the bucket\n\n    bucket = s3_bucket(aws_access_key_id, aws_secret_access_key, bucket_name)\n    key = boto.s3.key.Key(bucket)\n\n    bucketlist = bucket.list()\n\n    pat = dir_zip_pat % project\n\n    zip_file = '%s-%s.zip' % (dt.now().strftime(TIMESTAMP_FORMAT), project)\n    print 'Zipping datadir %s to %s' % (zip_backups_dir, zip_file)\n    zip_full_target = os.path.join(zip_backups_dir, zip_file)\n    os.system('zip -r %s %s' % (zip_full_target, datadir))\n\n    zip_local_full_target = zip_full_target\n    # append '.zip'\n    key.key = '%s/%s' % (s3_folder, zip_file)\n    print 'STARTING upload of %s to %s: %s' % (zip_file, key.key, dt.now())\n    try:\n        key.set_contents_from_filename(zip_full_target)\n        print 'Upload of %s FINISHED: %s' % (zip_local_full_target, dt.now())\n    finally:\n        delete_expired_backups_in_bucket(bucket, bucketlist, pat, backup_aging_time=backup_aging_time)\n        delete_local_zip_backups(pat, zip_backups_dir, backup_aging_time)", "response": "This function creates a backup of the current version of the current version of the current version of the current version of the current version of the current version of the version of the current version of the version of the current version of the version of the current version of the version."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrotate the given polygon around the origin or to the center of mass of mass of mass of mass", "response": "def rotatePolygon(polygon, theta, origin=None):\r\n    \"\"\"Rotates the given polygon around the origin or if not given it's center of mass\r\n\r\n    polygon: np.array( (x1,y1), (...))\r\n    theta: rotation clockwise in RADIAN\r\n    origin = [x,y] - if not given set to center of gravity\r\n\r\n    returns: None\r\n    \"\"\"\r\n    if origin is None:\r\n        origin = np.mean(polygon, axis=0, dtype=polygon.dtype)\r\n    #polygon = polygon.copy()\r\n    polygon -= origin\r\n    for n, corner in enumerate(polygon):\r\n        polygon[n] = corner[0] * np.cos(theta) - corner[1] * np.sin(theta), corner[\r\n            0] * np.sin(theta) + corner[1] * np.cos(theta)\r\n    polygon += origin\r\n    return polygon"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef updateFromArchivePage(self, archiveRoot, names, files, parent = \"/\", verbose=False):\n\t\troot = archiveRoot + parent\n\t\tarchive = urllib.urlopen(root)\n\t\tarchiveText = archive.read()\n\t\tarchive.close()\n\t\t\t\t\n\t\t# Recursively call this function on all subdirectories\n\t\tworking = archiveText\n\t\tfolderString = 'solid #aaa;\"><a href=\"index.php?mode=folder&path='\n\t\twhile folderString in working:\n\t\t\tindex = working.find(folderString) + len(folderString)\n\t\t\tfolder = working[index:]\n\t\t\tfolder = folder[:folder.find('>') - 1]\n\t\t\tworking = working[index + len(folder):]\n\t\t\tif folder != \"\" and folder.count(\"/\") > parent.count(\"/\"):\n\t\t\t\tif verbose:\n\t\t\t\t\tself.printd(\"  Caching \" + folder)\n\t\t\t\tself.updateFromArchivePage(archiveRoot, names, files, folder, verbose)\n\t\t\t\t\n\t\t# Now, step through all files and write them to the names and files objects\n\t\tworking = archiveText\n\t\tfileString = \"../scripts/countdown.php?\" #/73/basic/games/aod73.zip&path=archives\"\n\t\twhile fileString in working:\n\t\t\t# Get the filename and path of the file\n\t\t\tindex = working.find(fileString) + len(fileString)\n\t\t\tfileData = working[index:]\n\t\t\tfileData = fileData[:fileData.find(\"&path=archives\")]\n\t\t\t\n\t\t\t# Get the proper name (title) of the file\n\t\t\tworking = working[index:]\n\t\t\tnameData = working[working.find('1.25em;\"><b>') + len('1.25em;\"><b>'):]\n\t\t\tnameData = nameData[:nameData.find('</B>')]\n\t\t\t\n\t\t\t# Write files to index objects\n\t\t\tfiles.write(fileData + \"\\n\")\n\t\t\tnames.write(nameData + \"\\n\")", "response": "This function works recursively over Cemetech file category directory pages and writes the files to the index file and the names and files objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getSimpleFileData(self, fileInfo, data):\n\t\tresult = fileInfo[fileInfo.find(data + \"</td>\"):]\n\t\tresult = result[:result.find(\"</A></td>\")]\n\t\tresult = result[result.rfind(\">\") + 1:]\n\t\treturn result", "response": "Function to initialize the simple data for file info"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning to initialize the slightly more complicated data for file info", "response": "def getComplexFileData(self, fileInfo, data):\n\t\t\"\"\"Function to initialize the slightly more complicated data for file info\"\"\"\n\t\tresult = fileInfo[fileInfo.find(data + \"</td>\") + len(data + \"</td>\"):]\n\t\tresult = result[:result.find(\"</td>\")]\n\t\tresult = result[result.rfind(\">\") + 1:]\n\t\treturn result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning to get the description of a file.", "response": "def getFileDescription(self, fileInfo):\n\t\t\"\"\"Function to get the description of a file.\"\"\"\n\t\tdata = 'Description'\n\t\tresult = fileInfo[fileInfo.find(data + \"</td>\") + len(data + \"</td>\"):]\n\t\tresult.lstrip()\n\t\tresult = result[:result.find(\"</td>\")]\n\t\tresult = result[result.rfind(\"<\"):]\n\t\tif \"<td\" in result:\n\t\t\tresult = result[result.find(\">\") + 1:]\n\t\treturn result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef two_numbers(\n            cls, request,\n            operation: (Ptypes.path,\n                        String('One of the 4 arithmetic operations.',\n                                enum=['add', 'sub', 'mul', 'div'])),\n            first: (Ptypes.path,\n                    Float('The first operand.')),\n            second: (Ptypes.path,\n                     Float('The second operand.'))) -> [\n            (200, 'Ok', Float),\n            (400, 'Wrong number format or invalid operation'),\n            (422, 'NaN')]:\n        '''Any of the four arithmetic operation on two numbers.'''\n        log.info('Performing {} on {} and {}'.format(operation, first, second))\n        try:\n            first = float(first)\n            second = float(second)\n        except ValueError:\n            Respond(400)\n        if operation == 'add':\n            Respond(200, first + second)\n        elif operation == 'sub':\n            Respond(200, first - second)\n        elif operation == 'mul':\n            Respond(200, first * second)\n        elif operation == 'div':\n            if second == 0:\n                Respond(422)\n            Respond(200, first / second)\n        else:\n            Respond(400)", "response": "Any of the four arithmetic operations on two numbers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the modulo of a vector.", "response": "def length(\n            cls, request,\n            vector: (Ptypes.body,\n                     Vector('The vector to analyse.'))) -> [\n            (200, 'Ok', Float),\n            (400, 'Wrong vector format')]:\n        '''Return the modulo of a vector.'''\n        log.info('Computing the length of vector {}'.format(vector))\n        try:\n            Respond(200, sqrt(vector['x'] ** 2 +\n                              vector['y'] ** 2 +\n                              vector.get('z', 0) ** 2))\n        except ValueError:\n            Respond(400)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef place(slot_name, dttime):\n\tdttime = datetime.strptime(dttime, '%Y-%m-%d %H:%M:%S')\n\tdttime = dttime.replace(second=0, microsecond=0)\n\ttry:\n\t\tarea.context['timers'][dttime].add(slot_name)\n\texcept KeyError:\n\t\tarea.context['timers'][dttime] = {slot_name}\n\tarea.publish({'status': 'placed'}, slot=slot_name)", "response": "place a timer at the specified time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_size():\n    current_os = platform.system()\n    tuple_xy = None\n    if current_os == 'Windows':\n        tuple_xy = _get_terminal_size_windows()\n        if tuple_xy is None:\n            tuple_xy = _get_terminal_size_tput()\n            # needed for window's python in cygwin's xterm!\n    if current_os in ['Linux', 'Darwin'] or current_os.startswith('CYGWIN'):\n        tuple_xy = _get_terminal_size_linux()\n    if tuple_xy is None:\n        logger.debug(\"Cannot determine terminal size, use default\")\n        tuple_xy = (80, 25)      # default value\n    return dict(cols = tuple_xy[0], rows = tuple_xy[1])", "response": "Get width and height of console window"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_image_dimension(self, url):\n        w_h = (None, None)\n        try:\n            if url.startswith('//'):\n                url = 'http:' + url\n            data = requests.get(url).content\n            im = Image.open(BytesIO(data))\n\n            w_h = im.size\n        except Exception:\n            logger.warning(\"Error getting image size {}\".format(url), exc_info=True)\n\n        return w_h", "response": "Get the image size from a url and return a tuple that contains ( width height )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef screenshot(self, save_path, element=None, delay=0):\n        if save_path is None:\n            logger.error(\"save_path cannot be None\")\n            return None\n\n        save_location = cutil.norm_path(save_path)\n        cutil.create_path(save_location)\n        logger.info(\"Taking screenshot: {filename}\".format(filename=save_location))\n\n        if not self.driver_type.startswith('selenium'):\n            logger.debug(\"Create tmp phantomjs web driver for screenshot\")\n            # Create a tmp phantom driver to take the screenshot for us\n            from web_wrapper import DriverSeleniumPhantomJS\n            headers = self.get_headers()  # Get headers to pass to the driver\n            proxy = self.get_proxy()  # Get the current proxy being used if any\n            # TODO: ^ Do the same thing for cookies\n            screenshot_web = DriverSeleniumPhantomJS(headers=headers, proxy=proxy)\n            screenshot_web.get_site(self.url, page_format='raw')\n            screenshot_driver = screenshot_web.driver\n        else:\n            screenshot_driver = self.driver\n\n        # If a background color does need to be set\n        # self.driver.execute_script('document.body.style.background = \"{}\"'.format('white'))\n\n        # Take screenshot\n        # Give the page some extra time to load\n        time.sleep(delay)\n        if self.driver_type == 'selenium_chrome':\n            # Need to do this for chrome to get a fullpage screenshot\n            self.chrome_fullpage_screenshot(save_location, delay)\n        else:\n            screenshot_driver.get_screenshot_as_file(save_location)\n\n        # Use .png extenstion for users save file\n        if not save_location.endswith('.png'):\n            save_location += '.png'\n\n        # If an element was passed, just get that element so crop the screenshot\n        if element is not None:\n            logger.debug(\"Crop screenshot\")\n            # Crop the image\n            el_location = element.location\n            el_size = element.size\n            try:\n                cutil.crop_image(save_location,\n                                 output_file=save_location,\n                                 width=int(el_size['width']),\n                                 height=int(el_size['height']),\n                                 x=int(el_location['x']),\n                                 y=int(el_location['y']),\n                                 )\n            except Exception as e:\n                raise e.with_traceback(sys.exc_info()[2])\n\n        if not self.driver_type.startswith('selenium'):\n            # Quit the tmp driver created to take the screenshot\n            screenshot_web.quit()\n\n        return save_location", "response": "Take screenshot of the current page"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_site(self, url, cookies={}, page_format='html', return_on_error=[], retry_enabled=True,\n                 num_tries=0, num_apikey_tries=0, headers={}, api=False, track_stat=True, timeout=30,\n                 force_requests=False, driver_args=(), driver_kwargs={}, parser='beautifulsoup',\n                 custom_source_checks=[]):\n        \"\"\"\n        headers & cookies - Will update to the current headers/cookies and just be for this request\n        driver_args & driver_kwargs - Gets passed and expanded out to the driver\n        \"\"\"\n        self._reset_response()\n\n        num_tries += 1\n        # Save args and kwargs so they can be used for trying the function again\n        tmp_args = locals().copy()\n        get_site_args = [tmp_args['url']]\n        # Remove keys that dont belong to the keywords passed in\n        del tmp_args['url']\n        del tmp_args['self']\n        get_site_kwargs = tmp_args\n\n        # Check driver_kwargs for anything that we already set\n        kwargs_cannot_be = ['headers', 'cookies', 'timeout']\n        for key_name in kwargs_cannot_be:\n            if driver_kwargs.get(key_name) is not None:\n                del driver_kwargs[key_name]\n                logger.warning(\"Cannot pass `{key}` in driver_kwargs to get_site(). `{key}` is already set by default\"\n                               .format(key=key_name))\n\n        # Check if a url is being passed in\n        if url is None:\n            logger.error(\"Url cannot be None\")\n            return None\n\n        ##\n        # url must start with http....\n        ##\n        prepend = ''\n        if url.startswith('//'):\n            prepend = 'http:'\n\n        elif not url.startswith('http'):\n            prepend = 'http://'\n\n        url = prepend + url\n\n        ##\n        # Try and get the page\n        ##\n        rdata = None\n        try:\n            source_text = self._get_site(url, headers, cookies, timeout, driver_args, driver_kwargs)\n            if custom_source_checks:\n                # Check if there are any custom check to run\n                for re_text, status_code in custom_source_checks:\n                    if re.search(re_text, source_text):\n                        if self.response is None:\n                            # This is needed when using selenium and we still need to pass in the 'response'\n                            self.response = type('', (), {})()\n                        self.response.status_code = status_code\n                        self.status_code = status_code\n                        raise requests.exceptions.HTTPError(\"Custom matched status code\", response=self.response)\n\n            rdata = self.parse_source(source_text, page_format, parser)\n\n        ##\n        # Exceptions from Selenium\n        ##\n        # Nothing yet\n\n        ##\n        # Exceptions from Requests\n        ##\n        except (requests.exceptions.ConnectionError, requests.exceptions.Timeout) as e:\n            \"\"\"\n            Try again with a new profile (do not get new apikey)\n            Wait n seconds before trying again\n            \"\"\"\n            e_name = type(e).__name__\n            if num_tries < self._num_retries and retry_enabled is True:\n                logger.info(\"{} [get_site]: try #{} on {} Error {}\".format(e_name, num_tries, url, e))\n                time.sleep(2)\n                self.new_profile()\n                return self.get_site(*get_site_args, **get_site_kwargs)\n\n            else:\n                logger.error(\"{} [get_site]: try #{} on{}\".format(e_name, num_tries, url))\n\n        except requests.exceptions.TooManyRedirects as e:\n            logger.exception(\"TooManyRedirects [get_site]: {}\".format(url))\n\n        ##\n        # Exceptions shared by Selenium and Requests\n        ##\n        except (requests.exceptions.HTTPError, SeleniumHTTPError) as e:\n            \"\"\"\n            Check the status code returned to see what should be done\n            \"\"\"\n            status_code = str(e.response.status_code)\n            # If the client wants to handle the error send it to them\n            if int(status_code) in return_on_error:\n                raise e.with_traceback(sys.exc_info()[2])\n\n            try_again = self._get_site_status_code(url, status_code, api, num_tries, num_apikey_tries)\n            if try_again is True and retry_enabled is True:\n                # If True then try request again\n                return self.get_site(*get_site_args, **get_site_kwargs)\n\n        # Every other exceptions that were not caught\n        except Exception:\n            logger.exception(\"Unknown Exception [get_site]: {url}\".format(url=url))\n\n        return rdata", "response": "Get the site from the given url."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_site_status_code(self, url, status_code, api, num_tries, num_apikey_tries):\n        # Make status code an int\n        try:\n            status_code = int(status_code)\n        except ValueError:\n            logger.exception(\"Incorrect status code passed in\")\n            return None\n        # TODO: Try with the same api key 3 times, then try with with a new apikey the same way for 3 times as well\n        # try_profile_again = False\n        # if api is True and num_apikey_tries < self._num_retries:\n        #     # Try with the same apikey/profile again after a short wait\n        #     try_profile_again = True\n\n        # Retry for any status code in the 400's or greater\n        if status_code >= 400 and num_tries < self._num_retries:\n            # Fail after 3 tries\n            logger.info(\"HTTP error, try #{}, Status: {} on url: {}\".format(num_tries, status_code, url),\n                        extra={'status_code': status_code,\n                               'num_tries': num_tries,\n                               'url': url})\n            time.sleep(.5)\n            self.new_profile()\n            return True\n\n        else:\n            logger.warning(\"HTTPError [get_site]\\n\\t# of Tries: {}\\n\\tCode: {} - {}\"\n                           .format(num_tries, status_code, url),\n                           extra={'status_code': status_code,\n                                  'num_tries': num_tries,\n                                  'url': url})\n\n        return None", "response": "Get the site status code from the status code and return the status code or None if the status code is not valid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndownload the file from url to save_path.", "response": "def download(self, url, save_path, header={}, redownload=False):\n        \"\"\"\n        Currently does not use the proxied driver\n        TODO: Be able to use cookies just like headers is used here\n        :return: the path of the file that was saved\n        \"\"\"\n        if save_path is None:\n            logger.error(\"save_path cannot be None\")\n            return None\n\n        # Get headers of current web driver\n        header = self.get_headers()\n        if len(header) > 0:\n            # Add more headers if needed\n            header.update(header)\n\n        logger.debug(\"Download {url} to {save_path}\".format(url=url, save_path=save_path))\n\n        save_location = cutil.norm_path(save_path)\n        if redownload is False:\n            # See if we already have the file\n            if os.path.isfile(save_location):\n                logger.debug(\"File {save_location} already exists\".format(save_location=save_location))\n                return save_location\n\n        # Create the dir path on disk\n        cutil.create_path(save_location)\n\n        if url.startswith('//'):\n            url = \"http:\" + url\n        try:\n            with urllib.request.urlopen(urllib.request.Request(url, headers=header)) as response,\\\n            open(save_location, 'wb') as out_file:\n                data = response.read()\n                out_file.write(data)\n\n        except urllib.error.HTTPError as e:\n            save_location = None\n            # We do not need to show the user 404 errors\n            if e.code != 404:\n                logger.exception(\"Download Http Error {url}\".format(url=url))\n\n        except Exception:\n            save_location = None\n            logger.exception(\"Download Error: {url}\".format(url=url))\n\n        return save_location"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_table(table_name):\n    return db.engine.dialect.has_table(\n        db.engine.connect(),\n        table_name\n    )", "response": "Return True if table exists False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an alembic migration context.", "response": "def create_migration_ctx(**kwargs):\n    \"\"\"Create an alembic migration context.\"\"\"\n    env = EnvironmentContext(Config(), None)\n    env.configure(\n        connection=db.engine.connect(),\n        sqlalchemy_module_prefix='db.',\n        **kwargs\n    )\n    return env.get_context()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_operations(ctx=None, **kwargs):\n    if ctx is None:\n        ctx = create_migration_ctx(**kwargs)\n    operations = Operations(ctx)\n    operations.has_table = has_table\n    return operations", "response": "Create an alembic operations object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef produce_upgrade_operations(\n        ctx=None, metadata=None, include_symbol=None, include_object=None,\n        **kwargs):\n    \"\"\"Produce a list of upgrade statements.\"\"\"\n    if metadata is None:\n        # Note, all SQLAlchemy models must have been loaded to produce\n        # accurate results.\n        metadata = db.metadata\n    if ctx is None:\n        ctx = create_migration_ctx(target_metadata=metadata, **kwargs)\n\n    template_args = {}\n    imports = set()\n\n    _produce_migration_diffs(\n        ctx, template_args, imports,\n        include_object=include_object,\n        include_symbol=include_symbol,\n        **kwargs\n    )\n\n    return template_args", "response": "Produce a list of upgrade statements."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handleArgs(self, event):\n        # settings resolution order:\n        # command line > cfg file > environ\n        if self.djsettings:\n            os.environ['DJANGO_SETTINGS_MODULE'] = self.djsettings\n        if self.djconfig:\n            os.environ['DJANGO_CONFIGURATION'] = self.djconfig\n        # test for django-configurations package\n        try:\n            from configurations import importer\n            importer.install()\n        except ImportError:\n            pass\n        from django.conf import settings\n\n        try:\n            from south.management.commands import patch_for_test_db_setup\n            patch_for_test_db_setup()\n        except ImportError:\n            pass", "response": "Hook for handling the command line args"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_signature(signature, private_key, full_path, payload):\n    if isinstance(private_key, bytes):\n        private_key = private_key.decode(\"ascii\")\n\n    if isinstance(payload, bytes):\n        payload = payload.decode()\n\n    url_to_check = _strip_signature_from_url(signature, full_path)\n    computed_signature = apysigner.get_signature(private_key, url_to_check, payload)\n    return constant_time_compare(signature, computed_signature)", "response": "Checks signature received and verifies that we are able to re - create a new object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef constant_time_compare(val1, val2):  # noqa: C901\n    if len(val1) != len(val2):\n        return False\n\n    if isinstance(val1, bytes):\n        val1 = val1.decode(\"ascii\")\n    if isinstance(val2, bytes):\n        val2 = val2.decode(\"ascii\")\n\n    result = 0\n    for x, y in zip(val1, val2):\n        result |= ord(x) ^ ord(y)\n    return result == 0", "response": "Compare two strings in constant time."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_param(key):\n\n    regex = re.compile(r'filter\\[([A-Za-z0-9_./]+)\\]')\n    match = regex.match(key)\n\n    if match:\n        field_and_oper = match.groups()[0].split('__')\n\n        if len(field_and_oper) == 1:\n            return field_and_oper[0], 'eq'\n        elif len(field_and_oper) == 2:\n            return tuple(field_and_oper)\n        else:\n            raise InvalidQueryParams(**{\n                'detail': 'The filter query param of \"%s\" is not '\n                          'supported. Multiple filter operators are '\n                          'not allowed in a single expression.' % key,\n                'links': LINK,\n                'parameter': PARAM,\n            })", "response": "Parses the query parameter looking for filters\nystal and returns the field name & operator to filter on"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nensures the field exists on the model", "response": "def _validate_field(param, fields):\n    \"\"\" Ensure the field exists on the model \"\"\"\n\n    if '/' not in param.field and param.field not in fields:\n        raise InvalidQueryParams(**{\n            'detail': 'The filter query param of \"%s\" is not possible. The '\n                      'resource requested does not have a \"%s\" field. Please '\n                      'modify your request & retry.' % (param, param.field),\n            'links': LINK,\n            'parameter': PARAM,\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _validate_rel(param, rels):\n\n    if param.field.count('/') > 1:\n        raise InvalidQueryParams(**{\n            'detail': 'The filter query param of \"%s\" is attempting to '\n                      'filter on a nested relationship which is not '\n                      'currently supported.' % param,\n            'links': LINK,\n            'parameter': PARAM,\n        })\n    elif '/' in param.field:\n        model_field = param.field.split('/')[0]\n\n        if model_field not in rels:\n            raise InvalidQueryParams(**{\n                'detail': 'The filter query param of \"%s\" is attempting to '\n                          'filter on a relationship but the \"%s\" field is '\n                          'NOT a relationship field.' % (param, model_field),\n                'links': LINK,\n                'parameter': PARAM,\n            })", "response": "Validate the relationship based filters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate the parameter value.", "response": "def _validate_param(param):  # pylint: disable=too-many-branches\n    \"\"\" Ensure the filter cast properly according to the operator \"\"\"\n\n    detail = None\n\n    if param.oper not in goldman.config.QUERY_FILTERS:\n        detail = 'The query filter {} is not a supported ' \\\n                 'operator. Please change {} & retry your ' \\\n                 'request'.format(param.oper, param)\n\n    elif param.oper in goldman.config.GEO_FILTERS:\n        try:\n            if not isinstance(param.val, list) or len(param.val) <= 2:\n                raise ValueError\n            else:\n                param.val = [float(i) for i in param.val]\n        except ValueError:\n            detail = 'The query filter {} requires a list ' \\\n                     'of floats for geo evaluation. Please ' \\\n                     'modify your request & retry'.format(param)\n\n    elif param.oper in goldman.config.ENUM_FILTERS:\n        if not isinstance(param.val, list):\n            param.val = [param.val]\n\n        param.val = tuple(param.val)\n\n    elif isinstance(param.val, list):\n        detail = 'The query filter {} should not be specified more ' \\\n                 'than once or have multiple values. Please modify ' \\\n                 'your request & retry'.format(param)\n\n    elif param.oper in goldman.config.BOOL_FILTERS:\n        try:\n            param.val = str_to_bool(param.val)\n        except ValueError:\n            detail = 'The query filter {} requires a boolean ' \\\n                     'for evaluation. Please modify your ' \\\n                     'request & retry'.format(param)\n\n    elif param.oper in goldman.config.DATE_FILTERS:\n        try:\n            param.val = str_to_dt(param.val)\n        except ValueError:\n            detail = 'The query filter {} supports only an ' \\\n                     'epoch or ISO 8601 timestamp. Please ' \\\n                     'modify your request & retry'.format(param)\n\n    elif param.oper in goldman.config.NUM_FILTERS:\n        try:\n            param.val = int(param.val)\n        except ValueError:\n            detail = 'The query filter {} requires a number ' \\\n                     'for evaluation. Please modify your ' \\\n                     'request & retry'.format(param)\n\n    if detail:\n        raise InvalidQueryParams(**{\n            'detail': detail,\n            'links': LINK,\n            'parameter': PARAM,\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef init(req, model):\n\n    fields = model.all_fields\n    rels = model.relationships\n    params = []\n\n    for key, val in req.params.items():\n        try:\n            field, oper = _parse_param(key)\n        except (TypeError, ValueError):\n            continue\n\n        try:\n            local_field, foreign_filter = field.split('/')\n            field_type = getattr(model, local_field)\n\n            foreign_field = field_type.field\n            foreign_rtype = field_type.rtype\n\n            if hasattr(field_type, 'local_field'):\n                local_field = field_type.local_field\n\n            param = FilterRel(foreign_field, foreign_filter, foreign_rtype,\n                              local_field, field, oper, val)\n        except AttributeError:\n            raise InvalidQueryParams(**{\n                'detail': 'The filter query param \"%s\" specified a filter '\n                          'containing a \".\" indicating a relationship filter '\n                          'but a relationship by that name does not exist '\n                          'on the requested resource.' % key,\n                'links': LINK,\n                'parameter': PARAM,\n            })\n        except ValueError:\n            param = Filter(field, oper, val)\n\n        _validate_param(param)\n        _validate_rel(param, rels)\n        _validate_field(param, fields)\n        params.append(param)\n\n    return params", "response": "Initialize a list of Filter objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef other_dependancies(server, environment):\n    server = server.lower()\n    # Pillow is not on TestPyPI\n    if server is \"local\":\n        pass\n    elif server in [\"testpypi\", \"pypitest\"]:\n        print(\"  **Install Pillow**\")\n        subprocess.call([environment + '\\\\Scripts\\\\pip.exe', 'install', 'Pillow'], shell=True)\n    elif server is \"pypi\":\n        pass\n    else:\n        print(\"  **Nothing more to install**\")", "response": "Installs things that need to be in place before installing the main package"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks for uncomitted changes", "response": "def git_check():\n    \"\"\"Check for uncomitted changes\"\"\"\n    git_status = subprocess.check_output(['git', 'status', '--porcelain'])\n    if len(git_status) is 0:\n        print(Fore.GREEN + 'All changes committed' + Style.RESET_ALL)\n    else:\n        exit(Fore.RED + 'Please commit all files to continue')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_version_number(update_level='patch'):\n\n    \"\"\"Find current version\"\"\"\n    temp_file = version_file().parent / (\"~\" + version_file().name)\n    with open(str(temp_file), 'w') as g:\n        with open(str(version_file()), 'r') as f:\n            for line in f:\n                version_matches = bare_version_re.match(line)\n                if version_matches:\n                    bare_version_str = version_matches.groups(0)[0]\n                    if semantic_version.validate(bare_version_str):\n                        current_version = Version(bare_version_str)\n                        print(\"{}Current version is {}\".format(\" \"*4, current_version))\n                    else:\n                        current_version = Version.coerce(bare_version_str)\n                        if not text.query_yes_quit(\"{}I think the version is {}. Use it?\".format(\" \"*4, current_version), default=\"yes\"):\n                            exit(Fore.RED + 'Please set an initial version number to continue')\n\n                    \"\"\"Determine new version number\"\"\"\n                    if update_level is 'major':\n                        current_version = current_version.next_major()\n                    elif update_level is 'minor':\n                        current_version = current_version.next_minor()\n                    elif update_level is 'patch':\n                        current_version = current_version.next_patch()\n                    elif update_level is 'prerelease':\n                        if not current_version.prerelease:\n                            current_version = current_version.next_patch()\n                            current_version.prerelease = ('dev', )\n                    else:\n                        exit(Fore.RED + 'Cannot update version in {} mode'.format(update_level))\n\n                    print(\"{}New version is     {}\".format(\" \"*4, current_version))\n\n                    \"\"\"Update version number\"\"\"\n                    line = '__version__ = \"{}\"'.format(current_version)\n                print(line, file=g, end=\"\")\n        print('', file=g)  # add a blank line at the end of the file\n    shutil.copyfile(str(temp_file), str(version_file()))\n    os.remove(str(temp_file))\n    return(current_version)", "response": "Update version number of the current version of the current version."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a release line at the top of the first list it finds", "response": "def add_release_to_changelog(version):\n    \"\"\"Add release line at the top of the first list it finds\n\n    Assumes your changelog in managed with `releases`\"\"\"\n    temp_file = changelog_file().parent / (\"~\" + changelog_file().name)\n    now = datetime.today()\n    release_added = False\n    with open(str(temp_file), 'w') as g:\n        with open(str(changelog_file()), 'r') as f:\n            for line in f:\n                list_match = list_match_re.match(line)\n                if list_match and not release_added:\n                    release_line = \"{}{} :release:`{} <{}-{:02}-{:02}>`\".format(\n                                        list_match.group(\"leading\"),\n                                        list_match.group(\"mark\"),\n                                        version, now.year, now.month, now.day)\n                    print(release_line, file=g)\n                    release_added = True\n                print(line, file=g, end=\"\")\n            if not release_added:\n                release_line = \"{}{} :release:`{} <{}-{:02}-{:02}>`\".format(\n                                \" \", \"-\", version, now.year, now.month, now.day)\n                print(release_line, file=g)\n        print('', file=g)  # add a blank line at the end of the file\n    shutil.copyfile(str(temp_file), str(changelog_file()))\n    os.remove(str(temp_file))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun Sphinx via it s make html command", "response": "def run_sphinx():\n    \"\"\"Runs Sphinx via it's `make html` command\"\"\"\n    old_dir = here_directory()\n    os.chdir(str(doc_directory()))\n    doc_status = subprocess.check_call(['make', 'html'], shell=True)\n    os.chdir(str(old_dir))  # go back to former working directory\n    if doc_status is not 0:\n        exit(Fore.RED + 'Something broke generating your documentation...')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of all the projects and tasks available in the acorn database directory.", "response": "def list_tasks(target=None):\n    \"\"\"Returns a list of all the projects and tasks available in the `acorn`\n    database directory.\n\n    Args:\n        target (str): directory to list the projects for. Defaults to the configured\n          database directory.    \n\n    Returns:\n        dict: keys are project names; values are lists of tasks associated with the\n          project.\n    \"\"\"\n    from os import getcwd, chdir\n    from glob import glob\n    original = getcwd()\n    if target is None:# pragma: no cover\n        target = _dbdir()\n        \n    chdir(target)\n    result = {}\n    for filename in glob(\"*.*.json\"):\n        project, task = filename.split('.')[0:2]\n        if project not in result:\n            result[project] = []\n        result[project].append(task)\n\n    #Set the working directory back to what it was.\n    chdir(original)\n        \n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_task(project_, task_):\n    global project, task\n    project = project_\n    task = task_\n    msg.okay(\"Set project name to {}.{}\".format(project, task), 2)", "response": "Sets the active project and task name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cleanup():\n    failed = {}\n    success = []\n    for dbname, db in dbs.items():\n        try:\n            #Force the database save, even if the time hasn't elapsed yet.\n            db.save(True)\n            success.append(dbname)\n        except: # pragma: no cover\n            import sys, traceback\n            xcls, xerr = sys.exc_info()[0:2]\n            failed[dbname] = traceback.format_tb(sys.exc_info()[2])\n\n    for sdb in success:\n        if writeable:\n            msg.okay(\"Project {0}.{1} saved successfully.\".format(*sdb), 0)\n    for fdb, tb in failed.items(): # pragma: no cover\n        msg.err(\"Project {1}.{2} save failed:\\n{0}\".format(tb, *fdb),\n                prefix=False)", "response": "Saves all the open databases to JSON so that the kernel can be shut down without losing in - memory collections."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the Instance of the specified object.", "response": "def tracker(obj):\n    \"\"\"Returns the :class:`Instance` of the specified object if it is one that\n    we track by default.\n\n    Args:\n        obj (object): any python object passed as an argument to a method.\n\n    Returns:\n        Instance: if the object is trackable, the Instance instance of\n          that object; else None.\n    \"\"\"\n    import types as typ\n    global oids, uuids\n    import six\n    from inspect import isclass\n    untracked = (six.string_types, six.integer_types, float,\n                 complex, six.text_type)\n\n    semitrack = (list, dict, set, tuple)\n    if six.PY3: # pragma: no cover\n        semitrack = semitrack + (range, filter, map)\n        \n    if (isinstance(obj, semitrack) and\n        all([isinstance(t, untracked) for t in obj])):\n        if len(obj) > 0:\n            semiform = \"{0} len={1:d} min={2} max={3}\"\n            return semiform.format(type(obj), len(obj), min(obj), max(obj))\n        else:\n            semiform = \"{0} len={1:d}\"\n            return semiform.format(type(obj), len(obj))\n    elif isinstance(obj, semitrack):\n        #We have to run the tracker on each of the elements in the list, set,\n        #dict or tuple; this is necessary so that we can keep track of\n        #subsequent calls made with unpacked parts of the tuple.\n        result = []\n\n        #If we get a list of 10K tuples (like plot points in matplotlib), then\n        #this pollutes the database. So, we restrict the maximum size of complex\n        #lists to be 5; we track the first 5 objects and then store a summary of\n        #the remaining information.\n        for o in obj[0:min((len(obj), 5))]:\n            track = tracker(o)\n            if isinstance(track, Instance):\n                result.append(track.uuid)\n            else:\n                result.append(track)\n\n        if len(obj) > 5:\n            result.append(\"... ({0:d} items)\".format(len(obj)))\n            \n        return tuple(result)\n    elif isinstance(obj, slice):\n        return \"slice({}, {}, {})\".format(obj.start, obj.stop, obj.step)\n    elif type(obj) is type:\n        return obj.__name__\n    elif type(obj) is typ.LambdaType:\n        if hasattr(obj, \"__fqdn__\"):\n            #We need to get the actual fqdn of the object *before* it was\n            #decorated.\n            return obj.__fqdn__\n        else:\n            if six.PY2:\n                _code = obj.func_code\n            else: # pragma: no cover\n                _code = obj.__code__\n            return \"lambda ({})\".format(', '.join(_code.co_varnames))\n    elif type(obj) in [typ.FunctionType, typ.MethodType]: # pragma: no cover\n        return obj.__name__\n    elif not isinstance(obj, untracked):\n        #For many of the numpy/scipy methods, the result is a tuple of numpy\n        #arrays. In that case, we should maintain the tuple structure for\n        #descriptive purposes, but still return a tracker.\n        oid = id(obj)\n        if oid in oids:\n            result = oids[oid]\n        else:\n            result = Instance(oid, obj)\n            oids[oid] = result\n            uuids[result.uuid] = result\n        return result\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _dbdir():\n    global dbdir\n    from os import mkdir, path, getcwd, chdir\n    \n    if dbdir is None:\n        from acorn.config import settings\n        config = settings(\"acorn\")\n        if (config.has_section(\"database\") and\n            config.has_option(\"database\", \"folder\")):\n            dbdir = config.get(\"database\", \"folder\")\n        else: # pragma: no cover\n            raise ValueError(\"The folder to save DBs in must be configured\"\n                             \"  in 'acorn.cfg'\")\n\n    #It is possible to specify the database path relative to the repository\n    #root. path.abspath will map it correctly if we are in the root directory.\n    from acorn.utility import abspath\n    if not path.isabs(dbdir):\n        #We want absolute paths to make it easier to port this to other OS.\n        dbdir = abspath(dbdir)\n        \n    if not path.isdir(dbdir): # pragma: no cover\n        mkdir(dbdir)\n        \n    return dbdir", "response": "Returns the path to the directory where acorn DBs are stored."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclean the specified python dictionary by converting any tuple keys to strings so that they can be serialized by JSON.", "response": "def _json_clean(d):\n    \"\"\"Cleans the specified python `dict` by converting any tuple keys to\n    strings so that they can be serialized by JSON.\n\n    Args:\n        d (dict): python dictionary to clean up.\n\n    Returns:\n        dict: cleaned-up dictionary.\n    \"\"\"\n    result = {}\n    compkeys = {}\n    for k, v in d.items():\n        if not isinstance(k, tuple):\n            result[k] = v\n        else:\n            #v is a list of entries for instance methods/constructors on the\n            #UUID of the key. Instead of using the composite tuple keys, we\n            #switch them for a string using the \n            key = \"c.{}\".format(id(k))\n            result[key] = v\n            compkeys[key] = k\n\n    return (result, compkeys)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_image(byteio, imgfmt):\n    from os import path, mkdir\n    ptdir = \"{}.{}\".format(project, task)\n    uuid = str(uuid4())\n\n    #Save the image within the project/task specific folder.\n    idir = path.join(dbdir, ptdir)\n    if not path.isdir(idir):\n        mkdir(idir)\n        \n    ipath = path.join(idir, \"{}.{}\".format(uuid, imgfmt))\n    with open(ipath, 'wb') as f:\n        f.write(byteio)\n\n    return uuid", "response": "Saves the specified image to disk."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the active : class : TaskDB for the current project and task.", "response": "def active_db():\n    \"\"\"Returns the active :class:`TaskDB` for the current project and task.\n    \"\"\"\n    global dbs\n    # The task database is encapsulated in a class for easier serialization to\n    # JSON. Get the DB for the (project, task) combination.\n    dbkey = (project, task)\n    if dbkey in dbs:\n        taskdb = dbs[dbkey]\n    else:\n        taskdb = TaskDB()\n        dbs[dbkey] = taskdb\n        msg.okay(\"Initialized JSON database for {}.{}\".format(*dbkey), 2)\n\n    return taskdb"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef record(ekey, entry, diff=False):\n    taskdb = active_db()\n    taskdb.record(ekey, entry, diff)\n    # The task database save method makes sure that we only save as often as\n    # specified in the configuration file.\n    taskdb.save()", "response": "Records the specified entry to the key - value store under the specified entity key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef log_uuid(self, uuid):\n        #We only need to try and describe an object once; if it is already in\n        #our database, then just move along.\n        if uuid not in self.uuids and uuid in uuids:\n            self.uuids[uuid] = uuids[uuid].describe()", "response": "Logs the object with the specified uuid to self. uuids."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrecords the specified entry to the key - value store under the specified entity key.", "response": "def record(self, ekey, entry, diff=False):\n        \"\"\"Records the specified entry to the key-value store under the specified\n        entity key.\n\n        Args:\n            ekey (str): fqdn/uuid of the method/object to store the entry for.\n            entry (dict): attributes and values gleaned from the execution.\n            diff (bool): when True, the \"c\" element of `entry` will be diffed\n              against previous entries under the same `ekey` if their method\n              (attribute \"m\") matches.\n        \"\"\"\n        if ekey not in self.entities:\n            self.entities[ekey] = []\n            \n        #See if we need to diff the code to compress it.\n        if diff and len(self.entities[ekey]) > 0:\n            #Compress the code element of the current entry that we are saving.\n            from acorn.logging.diff import cascade, compress\n            sequence = [e[\"c\"] for e in self.entities[ekey]\n                        if e[\"m\"] == entry[\"m\"]]\n            original = cascade(sequence)\n            difference = compress(original, entry[\"c\"])\n            #Now, overwrite the entry with the compressed version.\n            entry[\"c\"] = difference\n\n        self.entities[ekey].append(entry)\n\n        #We also need to make sure we have uuids and origin information stored\n        #for any uuids present in the parameter string.\n        from uuid import UUID\n        uid = None\n        if entry[\"r\"] is not None:\n            uid = entry[\"r\"]\n        elif isinstance(ekey, str):\n            #For many methods we don't duplicate the UUID in the returns part\n            #because it wastes space. In those cases, the ekey is a UUID.\n            try:\n                uid = str(UUID(ekey))\n            except ValueError: # pragma: no cover\n                pass\n\n        if uid is not None and isinstance(uid, str):\n            self.log_uuid(uid)\n\n        #For the markdown and function definitions, we don't have any arguments,\n        #so we set that to None to save space.\n        if entry[\"a\"] is None:\n            return\n                    \n        for larg in entry[\"a\"][\"_\"]:\n            #We use the constructor to determine if the format of the argument\n            #is a valid UUID; if it isn't then we catch the error and keep\n            #going.\n            if not isinstance(larg, str):\n                continue\n            \n            try:\n                uid = str(UUID(larg))\n                self.log_uuid(uid)\n            except ValueError:\n                #This was obviously not a UUID, we don't need to worry about it,\n                #it has a user-readable string instead.\n                pass\n\n        #We also need to handle the keyword arguments; these are keyed by name.\n        for key, karg in entry[\"a\"].items():\n            if key == \"_\" or not isinstance(karg, str):\n                #Skip the positional arguments since we already handled them.\n                continue\n            try:\n                uid = str(UUID(karg))\n                self.log_uuid(uid)\n            except ValueError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_option(option, default=None, cast=None):\n        from acorn.config import settings\n        config = settings(\"acorn\")\n        if (config.has_section(\"database\") and\n            config.has_option(\"database\", option)):\n            result = config.get(\"database\", option)\n            if cast is not None:\n                result = cast(result)        \n        else:\n            result = default\n\n        return result", "response": "Returns the option value for the specified acorn database option."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load(self):\n        #We load the database even when it is not configured to be\n        #writable. After all, the user may decide part-way through a session to\n        #begin writing again, and then we would want a history up to that point\n        #to be valid.\n        from os import path\n        if path.isfile(self.dbpath):\n            import json\n            with open(self.dbpath) as f:\n                jdb = json.load(f)\n                self.entities = jdb[\"entities\"]\n                self.uuids = jdb[\"uuids\"]", "response": "Deserializes the database from disk."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nserializes the database file to disk.", "response": "def save(self, force=False):\n        \"\"\"Serializes the database file to disk.\n\n        Args:\n            force (bool): when True, the elapsed time since last save is ignored\n                and the database is saved anyway (subject to global\n                :data:`writeable` setting).\n        \"\"\"\n        from time import time\n\n        # Since the DBs can get rather large, we don't want to save them every\n        # single time a method is called. Instead, we only save them at the\n        # frequency specified in the global settings file.\n        from datetime import datetime\n        savefreq = TaskDB.get_option(\"savefreq\", 2, int)\n        \n        if self.lastsave is not None:\n            delta = (datetime.fromtimestamp(time()) -\n                     datetime.fromtimestamp(self.lastsave)) \n            elapsed = int(delta.total_seconds()/60)\n        else:\n            elapsed = savefreq + 1\n\n        if elapsed > savefreq or force:\n            if not writeable:\n                #We still overwrite the lastsave value so that this message doesn't\n                #keep getting output for every :meth:`record` call.\n                self.lastsave = time()\n                msg.std(\"Skipping database write to disk by setting.\", 2)\n                return\n\n            import json\n            try:\n                entities, compkeys = _json_clean(self.entities)\n                jdb = {\"entities\": entities,\n                       \"compkeys\": compkeys,\n                       \"uuids\": self.uuids}\n                with open(self.dbpath, 'w') as f:\n                    json.dump(jdb, f)\n            except: # pragma: no cover\n                from acorn.msg import err\n                import sys\n                raise\n                err(\"{}: {}\".format(*sys.exc_info()[0:2]))\n\n            self.lastsave = time()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef describe(self):\n        result = {}\n        #Because we created an Instance object, we already know that this object\n        #is not one of the regular built-in types (except, perhaps, for list,\n        #dict and set objects that can have their tracking turned on).\n\n        #For objects that are instantiated by the user in __main__, we will\n        #already have a paper trail that shows exactly how it was done; but for\n        #these, we have to rely on human-specified descriptions.\n        from acorn.logging.descriptors import describe\n        return describe(self.obj)", "response": "Returns a dictionary describing the object based on its type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload a module into name given its filename", "response": "def load_module(name, filename):\n    '''Load a module into name given its filename'''\n    if sys.version_info < (3, 5):\n        import imp\n        import warnings\n        with warnings.catch_warnings():  # Required for Python 2.7\n            warnings.simplefilter(\"ignore\", RuntimeWarning)\n            return imp.load_source(name, filename)\n    else:\n        from importlib.machinery import SourceFileLoader\n        loader = SourceFileLoader(name, filename)\n        return loader.load_module()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef function_arguments(func):\n    if getattr(inspect, 'signature', None) is None:\n        return list(inspect.getargspec(func).args)\n    else:\n        return list(inspect.signature(func).parameters.keys())", "response": "This returns a list of all arguments for the function"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef function_defaults(func):\n    if getattr(inspect, 'signature',None) is None:\n        return inspect.getargspec(func)[-1] or []\n    else:\n        return [v.default for k,v in list(\n            inspect.signature(func).parameters.items())\n                if v.default is not inspect._empty]", "response": "This returns a list of the default arguments of the object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef function_doc(function_index=1, function_name=None):\n    frm = func_frame(function_index + 1, function_name)\n    try:\n        func = getattr(frm.f_locals['self'], frm.f_code.co_name)\n    except:\n        func = frm.f_globals[frm.f_code.co_name]\n    return func.__doc__", "response": "This will return the doc of the calling function\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef function_path(func):\n    if getattr(func, 'func_code', None):\n        return func.__code__.co_filename.replace('\\\\', '/')\n    else:\n        return func.__code__.co_filename.replace('\\\\', '/')", "response": "This will return the path to the calling function\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef file_code(function_index=1, function_name=None):\n    info = function_info(function_index + 1, function_name)\n    with open(info['file'], 'r') as fn:\n        return fn.read()", "response": "This will return the code of the calling function\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef function_info(function_index=1, function_name=None, line_number=None):\n    frm = func_frame(function_index + 1, function_name)\n\n    file_ = os.path.abspath(frm.f_code.co_filename)\n    class_name = frm.f_locals.get('self', None)\n    if class_name is not None: # and not skip_class:\n        class_name = str(type(class_name)).split('.',1)[-1].split(\"'\")[0]\n        # try:\n        #     class_name = str(class_name).split(None, 1)[1]\n        #     class_name = class_name.split('.')[-1].replace(')', '')\n        # except:\n        #     class_name = repr(class_name).split()[0].split('.')[-1]\n        # if 'object at' in str(class_name):\n        #     class_name = str(class_name).split(' object at')[0].split('.')[-1]\n\n    args, _, _, kwargs = inspect.getargvalues(frm)\n    line_number = line_number or frm.f_lineno\n    return {'class_name': class_name or '',\n            'function_name': frm.f_code.co_name,\n            'file': file_,\n            'path': os.path.split(file_)[0],\n            'basename': os.path.basename(file_).split('.')[0],\n            'line_number': line_number or frm.f_lineno,\n            'globals': frm.f_globals,\n            'locals': frm.f_locals,\n            'arguments': args,\n            'kwargs': kwargs,\n            'frame': frm}", "response": "This function returns the class_name function_name and line_number of the function traced back two functions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef function_history():\n    ret = []\n    frm = inspect.currentframe()\n    for i in range(100):\n        try:\n            if frm.f_code.co_name != 'run_code':  # this is pycharm debugger\n                                                  # inserting middleware\n                ret.append(frm.f_code.co_name)\n            frm = frm.f_back\n        except Exception as e:\n            break\n    return ret", "response": "This will return a list of all function calls going back to the beginning of the current module"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef function_linenumber(function_index=1, function_name=None, width=5):\n    frm = func_frame(function_index + 1, function_name)\n    if width is None:\n        return frm._f_lineno\n    return str(frm.f_lineno).ljust(width)", "response": "This will return the line number of the function in the stack"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_feature(fc):\n    '''Builds a new `StringCounter` from the many `StringCounters` in the\n    input `fc`.  This StringCounter will define one of the targets for\n    the `MultinomialNB` classifier.\n\n    This crucial function decides the relative importance of features\n    extracted by the ETL pipeline.  This is essentially a form of\n    domain fitting that allows us to tune the extraction to the fields\n    that are important to a domain.  However, if the NER for a domain\n    is inadequate, then the primary purpose of these relative\n    weightings is to remove bogus NER extractions.\n\n    '''\n    feat = StringCounter()\n    rejects = set()\n    keepers = set()\n    #keepers_keys = ['GPE', 'PERSON', 'ORGANIZATION', 'usernames']\n    keepers_keys = ['phone', 'email'] #['usernames', 'phone', 'email', 'ORGANIZATION', 'PERSON']\n    rejects_keys = ['keywords', 'usernames', 'ORGANIZATION', 'PERSON']\n    # The features used to pull the keys for the classifier\n    for f, strength in [('keywords', 10**4), ('GPE', 1), ('bow', 1), ('bowNP_sip', 10**8),\n                        ('phone', 10**12), ('email', 10**12),\n                        ('bowNP', 10**3), ('PERSON', 10**8), ('ORGANIZATION', 10**6), ('usernames', 10**12)]:\n        if strength == 1:\n            feat += fc[f]\n        else:\n            feat += StringCounter({key: strength * count\n                                   for key, count in fc[f].items()})\n        if f in rejects_keys:\n            map(rejects.add, fc[f])\n        if f in keepers_keys:\n            map(keepers.add, fc[f])\n        if u'' in feat: feat.pop(u'')\n    return feat, rejects, keepers", "response": "Builds a new StringCounter from the many StringCounters in the\n    input fc."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexpects a coordinate WorkUnit for DragNet and runs the following steps: 1. scans all dossiers at the *folder* level and assembles feature vectors for each folder -- see `make_feature` 2. trains a multinomial naive Bayes classifier that treats each *folder* as a classifier target. 3. sample the corpus by scanning up to `max_sample` and applying the classifier to each item to get an approx \"size\" of the Folder 4. Bootstrap by treating those classifier predictions as truth data and extract the learned features that are predictive as new query strings. 5. Put the data in kvlayer for webservice end point to return to polling client -- see dossier.models.routes", "response": "def worker(work_unit, max_sample=1000):\n    '''Expects a coordinate WorkUnit for DragNet and runs the following\n    steps:\n\n    1. scans all dossiers at the *folder* level and assembles feature\n    vectors for each folder -- see `make_feature`\n\n    2. trains a multinomial naive Bayes classifier that treats each\n    *folder* as a classifier target.\n\n    3. sample the corpus by scanning up to `max_sample` and applying\n    the classifier to each item to get an approx \"size\" of the Folder\n\n    4. Bootstrap by treating those classifier predictions as truth\n    data and extract the learned features that are predictive as new\n    query strings.\n\n    5. Put the data in kvlayer for webservice end point to return to\n    polling client -- see dossier.models.routes\n\n    '''\n    if 'config' not in work_unit.spec:\n        raise coordinate.exceptions.ProgrammerError(\n            'could not run dragnet without global config')\n\n    web_conf = Config()\n    unitconf = work_unit.spec['config']\n    with yakonfig.defaulted_config([coordinate, kvlayer, dblogger, web_conf],\n                                   config=unitconf):\n\n        labels = []\n        D = list()\n\n        label2fid = dict()\n\n        rejects = set()\n        keepers = set()\n\n        # 1. make a classifier target for each *folder*, ignoring\n        # subfolder structure\n        FT = Folders(web_conf.kvlclient)\n        for idx, fid in enumerate(FT.folders()):\n            label2fid[idx] = fid\n            for sid in FT.subfolders(fid):\n                for cid, subtopic_id in FT.items(fid, sid):\n                    fc = web_conf.store.get(cid)\n                    if fc:\n                        # NB: first call to make_feature\n                        feat, _rejects, _keepers = make_feature(fc)\n                    else:\n                        _rejects = {}\n                        _keepers = {}\n                    D.append(feat)\n                    labels.append(idx)\n                    rejects.update(_rejects)\n                    keepers.update(_keepers)\n                    logger.info('fid=%r, observation: %r', fid, cid)\n\n        # 2. Convert the StringCounters into an sklearn format and\n        # train MultinomialNB\n        logger.info('transforming...')\n        v = DictVectorizer(sparse=False)\n        X = v.fit_transform(D)\n        logger.info('transform fit done.')\n\n        labels = np.array(labels)\n\n        # Fit the sklearn Bernoulli Naive Bayes classifer\n        clf = MultinomialNB()\n        clf.fit(X, labels)\n        logger.info('fit MultinomialNB')\n\n        # 3. Scan the corpus up to max_sample putting the items into\n        # each target to get an approx \"size\" of the Folder\n        counts = Counter()\n        for cid, fc in islice(web_conf.store.scan(), max_sample):\n            # build the same feature vector as the training process\n            feat, _rejects, _keepers = make_feature(fc)\n            X = v.transform([feat])\n            # predict which folder it belongs in\n            target = clf.predict(X[0])[0]\n            # count the effective size of that folder in this sample\n            counts[label2fid[target]] += 1\n\n        logger.info('counts done')\n\n        ## 4. Bootstrap by treating those classifier predictions as\n        ## truth data and extract the learned features that are\n        ## predictive as new query strings.\n        clusters = []\n        for idx in sorted(set(labels)):\n            logger.debug('considering cluster: %d', idx)\n            try:\n                all_features = v.inverse_transform(clf.feature_log_prob_[idx])[0]\n            except:\n                logger.warn('beyond edge on cluster %d', idx)\n                continue\n            words = Counter(all_features)\n            ordered = sorted(words.items(),\n                             key=operator.itemgetter(1), reverse=True)\n            filtered = []\n            for it in ordered:\n                if is_bad_token(it[0]): continue\n\n                if is_username(it[0]):\n                    logger.debug('%r is_username', it[0])\n                #else:\n                #    continue\n                filtered.append(it)\n                if len(filtered) > 100: # hard cutoff\n                    break\n\n            # normalize cluster size exponentially\n            biggest = exp(filtered[0][1])\n            # rescale all by biggest\n            filtered = [(key, int(round(counts[label2fid[idx]] * exp(w) / biggest))) for key, w in filtered]\n            # describe what we just figured out\n            logger.info('%s --> %r', label2fid[idx], ['%s: %d' % it for it in filtered[:10]])\n\n            # return build the JSON-serializable format for the\n            # DragNet UI embedded inside SortingDesk\n            cluster = []\n            cluster.append({'caption': label2fid[idx],\n                            'weight': counts[label2fid[idx]],\n                            'folder_id': None,\n                            })\n            cluster += [{'caption': caption, 'weight': weight, 'folder_id': label2fid[idx]} for caption, weight in filtered if weight > 0]\n            clusters.append(cluster)\n\n        # 5. Put the data in kvlayer for webservice end point to\n        # return to polling client\n        web_conf.kvlclient.setup_namespace({'dragnet': (str,)})\n        web_conf.kvlclient.put('dragnet', (('dragnet',), json.dumps({'clusters': clusters})))\n        return dict(counts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rx_int_extra(rxmatch):\n\n    rxmatch = re.search(\"\\d+\", rxmatch.group(0))\n    return int(rxmatch.group(0))", "response": "Return the int that we don t just match an int but the int is what we need."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nencrypting byte data with the given secret key.", "response": "def encrypt(byte_data, secret_key=''):\r\n\r\n    '''\r\n        uses cryptography module to encrypt byte data\r\n        cipher: AES (128 bit block_size)\r\n        hash: sha512\r\n        key size: 256 bit (first 32 bytes of secret key hash)\r\n        vector size: 128 bit (next 16 bytes of secret key hash)\r\n        padding: PKCS7\r\n        cipher mode: CBC\r\n        backend: openssl 1.0.2a\r\n\r\n        NOTE:   if secret_key is left blank,\r\n                method generates a 32 byte hexadecimal string\r\n\r\n    :param byte_data: bytes with data to encrypt\r\n    :param secret_key: [optional] string used to encrypt data\r\n    :return: encrypted byte data, secret key hex string\r\n    '''\r\n\r\n# validate input\r\n    if not isinstance(byte_data, bytes):\r\n        raise TypeError('\\nbyte data input must be a byte datatype.')\r\n\r\n# validate secret key or create secret key\r\n    if secret_key:\r\n        if not isinstance(secret_key, str):\r\n            raise TypeError('\\nsecret key input must be a utf-8 encoded string.')\r\n    else:\r\n        from os import urandom\r\n        from binascii import hexlify\r\n        secret_key = hexlify(urandom(32)).decode()\r\n\r\n# retrieve cipher key and initialization vector from sha256 hash of secret key\r\n    key_bytes = hashlib.sha512(secret_key.encode('utf-8')).digest()\r\n    cipher_key = key_bytes[0:32]\r\n    cipher_vector = key_bytes[32:48]\r\n\r\n# construct encryptor\r\n    cipher_kwargs = {\r\n        'algorithm': algorithms.AES(cipher_key),\r\n        'mode': modes.CBC(cipher_vector),\r\n        'backend': openssl.backend\r\n    }\r\n    cipher = Cipher(**cipher_kwargs)\r\n    encryptor = cipher.encryptor()\r\n\r\n# encrypt and add padding\r\n    padder = padding.PKCS7(128).padder()\r\n    padded_data = padder.update(byte_data)\r\n    padded_data += padder.finalize()\r\n    encrypted_data = encryptor.update(padded_data) + encryptor.finalize()\r\n\r\n    return encrypted_data, secret_key"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decrypt(encrypted_data, secret_key):\r\n\r\n    '''\r\n        uses cryptography module to decrypt byte data\r\n        cipher: AES (128 bit block_size)\r\n        hash: sha512\r\n        key size: 256 bit (first 32 bytes of secret key hash)\r\n        vector size: 128 bit (next 16 bytes of secret key hash)\r\n        padding: PKCS7\r\n        cipher mode: CBC\r\n        backend: openssl 1.0.2a\r\n    :param encrypted_data: bytes with data to decrypt\r\n    :param secret_key: [optional] string used to decrypt data\r\n    :return: encrypted byte data, secret key hex string\r\n    '''\r\n\r\n# validate input\r\n    if not isinstance(encrypted_data, bytes):\r\n        raise TypeError('\\nbyte data input must be byte datatype.')\r\n    elif not isinstance(secret_key, str):\r\n        raise TypeError('\\nsecret key input must be a utf-8 encoded string.')\r\n\r\n# retrieve cipher key and initialization vector from sha256 hash of secret key\r\n    key_bytes = hashlib.sha512(secret_key.encode('utf-8')).digest()\r\n    cipher_key = key_bytes[0:32]\r\n    cipher_vector = key_bytes[32:48]\r\n\r\n# construct decryptor\r\n    cipher_kwargs = {\r\n        'algorithm': algorithms.AES(cipher_key),\r\n        'mode': modes.CBC(cipher_vector),\r\n        'backend': openssl.backend\r\n    }\r\n    cipher = Cipher(**cipher_kwargs)\r\n    decryptor = cipher.decryptor()\r\n\r\n# decrypt and remove padding\r\n    padded_data = decryptor.update(encrypted_data) + decryptor.finalize()\r\n    unpadder = padding.PKCS7(128).unpadder()\r\n    byte_data = unpadder.update(padded_data) + unpadder.finalize()\r\n\r\n    return byte_data", "response": "Decrypts the data of the given byte data using the given secret key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prepare_filename_decorator(fn):\n    @wraps(fn)\n    def inner(self, normalized_url, request):\n        ext = settings.ROUGHPAGES_TEMPLATE_FILE_EXT\n        if not normalized_url:\n            normalized_url = settings.ROUGHPAGES_INDEX_FILENAME\n        filenames = fn(self, normalized_url, request)\n        filenames = [x + ext for x in filenames if x]\n        return filenames\n    return inner", "response": "A decorator that can be used to prepare_filename for a base class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\noutput current GET query string with additions appended.", "response": "def smart_query_string(parser, token):\n    \"\"\"\n    Outputs current GET query string with additions appended.\n    Additions are provided in token pairs. \n    \"\"\"\n    args = token.split_contents()\n    additions = args[1:]\n   \n    addition_pairs = []\n    while additions:\n        addition_pairs.append(additions[0:2])\n        additions = additions[2:]\n\n    return SmartQueryStringNode(addition_pairs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_task(self, target, args=(), kwargs=None, priority=None):\n\n        if self._stop:\n            raise RuntimeError(\"Can't add new task, the MaxThreads object is in closing/closed state\")\n\n        new_thread = None\n\n        if (self.threads_active() < self._max_threads or not self._limit) \\\n            and (self._threads_waiting == 0 and self._queue.qsize() > 0):\n            # The number of active threads is less than maximum number of threads\n            # OR there is no limit on the maximum number of threads\n            # AND there are no threads in waiting state\n            # i.e. start a new thread\n            new_thread = self._start_loop_thread()\n\n        self._queue.put(\n            SetPrio(target=target,\n                    args=args,\n                    kwargs=kwargs or {},\n                    priority=priority or 0)\n        )\n\n        return new_thread", "response": "Adds a new task to the queue of active threads."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting a new thread.", "response": "def start_thread(self, target, args=(), kwargs=None, priority=0):\n        \"\"\" To make sure applications work with the old name\n        \"\"\"\n        return self.add_task(target, args, kwargs, priority)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stop(self, block=True):\n        self._stop = True\n\n        # Removing tasks in queue\n        self.empty_queue()\n\n        # All active threads\n        # With the DoNothing function\n        # Because self._stop is True each thread will process at most one of the DoNothing functions\n        # Hence it is ensured that all .get calls are triggered\n        for _ in range(self.threads_active()):\n            self._queue.put(SetPrio(target=DoNothing))\n\n        if block:\n            # Blocking until all threads are closed\n            self.join()\n\n            # Removing any leftover DoNothing functions (Can only be reliably done when all threads are closed)\n            self.empty_queue()", "response": "Stops all active threads and rejects new tasks to be added to the queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists all folders or all subfolders of a specific folder.", "response": "def list_projects(folders, folder = None, user = None):\n    '''List all folders or all subfolders of a folder.\n\n    If folder is provided, this method will output a list of subfolders\n    contained by it.  Otherwise, a list of all top-level folders is produced.\n\n    :param folders: reference to folder.Folders instance\n    :param folder: folder name or None\n    :param user: optional user name\n\n    '''\n    fid = None if folder is None else Folders.name_to_id(folder)\n\n    # List all folders if none provided.\n    if fid is None:\n        for f in folders.folders(user):\n            print(Folders.id_to_name(f))\n\n        return\n\n    # List subfolders of a specific folder\n    try:\n        for sid in folders.subfolders(fid, user):\n            print(Folders.id_to_name(sid))\n    except KeyError:\n        print(\"E: folder not found: %s\" %folder, file=sys.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_supervisor(func: types.AnyFunction) -> types.Supervisor:\n    if not callable(func):\n        raise TypeError(\"func is not callable\")\n    if asyncio.iscoroutinefunction(func):\n        supervisor = _async_supervisor\n    else:\n        supervisor = _sync_supervisor\n    return functools.partial(supervisor, func)", "response": "Get the appropriate supervisor to use and pre - apply the function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef concatechain(*generators: types.FrameGenerator, separator: str = ''):\n    while True:\n        try:\n            next_ = [next(gen) for gen in generators]\n            yield separator.join(next_)\n        except StopIteration as exc:\n            return exc.value", "response": "Return a generator that yields one value from each of the supplied generators joins them together with the specified separator and yields the result."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compare(self, control_result, experimental_result):\n        _compare = getattr(self, '_compare', lambda x, y: x == y)\n        \"\"\"\n        Return true if the results match.\n        \"\"\"\n        return (\n            # Mismatch if only one of the results returned an error, or if\n            # different types of errors were returned.\n            type(control_result.error) is type(experimental_result.error) and\n            _compare(control_result.value, experimental_result.value)\n        )", "response": "Compare the control and experimental results."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_create_list_email(**kargs):\n    to = kargs.get('user', None)\n    if not to:\n        return\n\n    to = [to.email]\n    from_email = settings.COLAB_FROM_ADDRESS\n    subject = _('Created list {}.'.format(kargs.get('listname', '')))\n    msg_tmpl = loader.get_template('emails/create_list_confirmation.txt')\n    message = msg_tmpl.render(Context(kargs))\n    return mail.send_mail(subject, message, from_email, to)", "response": "Send the notification mail\n    kargs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_member_profile(self, brief_details, profile_details):\r\n\r\n        ''' a method to update user profile details on meetup\r\n\r\n        :param brief_details: dictionary with member brief details with updated values\r\n        :param profile_details: dictionary with member profile details with updated values\r\n        :return: dictionary with partial profile details inside [json] key\r\n        '''\r\n\r\n        # https://www.meetup.com/meetup_api/docs/members/:member_id/#edit\r\n\r\n        title = '%s.update_member_profile' % self.__class__.__name__\r\n\r\n        # validate permissions\r\n        if not 'profile_edit' in self.service_scope:\r\n            raise ValueError('%s requires group_join as part of oauth2 service_scope permissions.' % title)\r\n\r\n            # validate inputs\r\n        brief_details = self.objects.profile_brief.validate(brief_details)\r\n        profile_details = self.objects.profile.validate(profile_details)\r\n\r\n        # construct request fields\r\n        url = '%s/members/%s' % (self.endpoint, str(profile_details['id']))\r\n        params = {\r\n            'bio': profile_details['bio'],\r\n            'bio_privacy': profile_details['privacy']['bio'],\r\n            'fields': 'gender,birthday,last_event,messaging_pref,next_event,other_services,privacy,self,stats',\r\n            'gender': profile_details['gender'],\r\n            'groups_privacy': profile_details['privacy']['groups'],\r\n            'lang': brief_details['lang'].replace('_', '-'),\r\n            'lat': str(profile_details['lat']),\r\n            'lon': str(profile_details['lon']),\r\n            'messaging_pref': profile_details['messaging_pref'],\r\n            'name': profile_details['name'],\r\n            'photo_id': profile_details['photo']['id'],\r\n            'sync_photo': True,\r\n            'topics_privacy': profile_details['privacy']['topics'],\r\n            'zip': brief_details['zip']\r\n        }\r\n        if profile_details['privacy']['facebook']:\r\n            params['facebook_privacy'] = profile_details['privacy']['facebook']\r\n        birthday_value = False\r\n        for key, value in profile_details['birthday'].items():\r\n            if value:\r\n                birthday_value = True\r\n                break\r\n        if not birthday_value:\r\n            params['birthday'] = '-1'\r\n        else:\r\n            birthday_string = ''\r\n            b_day = profile_details['birthday']\r\n            if b_day['day'] and b_day['month']:\r\n                if b_day['month'] < 10:\r\n                    birthday_string += '0'\r\n                birthday_string += str(b_day['month'])\r\n                if b_day['day'] < 10:\r\n                    birthday_string += '0'\r\n                birthday_string += str(b_day['day'])\r\n            birthday_string += str(b_day['year'])\r\n            params['birthday'] = birthday_string\r\n\r\n            # send requests\r\n        profile_details = self._patch_request(url, params=params)\r\n\r\n        return profile_details", "response": "a method to update user profile details on meetup"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_member_events(self, upcoming=True):\r\n\r\n        ''' a method to retrieve a list of events member attended or will attend\r\n\r\n        :param upcoming: [optional] boolean to filter list to only future events\r\n        :return: dictionary with list of event details inside [json] key\r\n\r\n        event_details = self._reconstruct_event({})\r\n        '''\r\n\r\n    # https://www.meetup.com/meetup_api/docs/self/events/\r\n\r\n    # construct request fields\r\n        url = '%s/self/events' % self.endpoint\r\n        params = {\r\n            'status': 'past',\r\n            'fields': 'comment_count,event_hosts,rsvp_rules,short_link,survey_questions,rsvpable'\r\n        }\r\n        if upcoming:\r\n            params['status'] = 'upcoming'\r\n\r\n    # send requests\r\n        response_details = self._get_request(url, params=params)\r\n\r\n    # construct method output\r\n        member_events = {\r\n            'json': []\r\n        }\r\n        for key, value in response_details.items():\r\n            if key != 'json':\r\n                member_events[key] = value\r\n        for event in response_details['json']:\r\n            member_events['json'].append(self._reconstruct_event(event))\r\n\r\n        return member_events", "response": "a method to retrieve a list of events member attended or will attend\r\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_member_calendar(self, max_results=0):\r\n\r\n        ''' a method to retrieve the upcoming events for all groups member belongs to\r\n\r\n        :param max_results: [optional] integer with number of events to include\r\n        :return: dictionary with list of event details inside [json] key\r\n\r\n        event_details = self._reconstruct_event({})\r\n        '''\r\n\r\n    # https://www.meetup.com/meetup_api/docs/self/calendar/#list\r\n\r\n        title = '%s.get_member_calendar' % self.__class__.__name__\r\n\r\n    # validate inputs\r\n        input_fields = {\r\n            'max_results': max_results\r\n        }\r\n        for key, value in input_fields.items():\r\n            if value:\r\n                object_title = '%s(%s=%s)' % (title, key, str(value))\r\n                self.fields.validate(value, '.%s' % key, object_title)\r\n\r\n    # construct request fields\r\n        url = '%s/self/calendar' % self.endpoint\r\n        params = {\r\n            'fields': 'comment_count,event_hosts,rsvp_rules,short_link,survey_questions,rsvpable'\r\n        }\r\n        if max_results:\r\n            params['page'] = str(max_results)\r\n\r\n    # send requests\r\n        response_details = self._get_request(url, params=params)\r\n\r\n    # construct method output\r\n        member_calendar = {\r\n            'json': []\r\n        }\r\n        for key, value in response_details.items():\r\n            if key != 'json':\r\n                member_calendar[key] = value\r\n        for event in response_details['json']:\r\n            member_calendar['json'].append(self._reconstruct_event(event))\r\n\r\n        return member_calendar", "response": "a method to retrieve the upcoming events for all groups member belongs to\r\n\r\nMimeType"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_groups(self, topics=None, categories=None, text='', country_code='', latitude=0.0, longitude=0.0, location='', radius=0.0, zip_code='', max_results=0, member_groups=True):\r\n\r\n        ''' a method to find meetup groups based upon a number of filters\r\n\r\n        :param topics: [optional] list of integer meetup ids for topics\r\n        :param text: [optional] string with words in groups to search\r\n        :param country_code: [optional] string with two character country code\r\n        :param latitude: [optional] float with latitude coordinate at center of geo search\r\n        :param longitude: [optional] float with longitude coordinate at center of geo search\r\n        :param location: [optional] string with meetup location name fields to search\r\n        :param radius: [optional] float with distance from center of geographic search\r\n        :param zip_code: [optional] string with zip code of geographic search\r\n        :param max_results: [optional] integer with number of groups to include\r\n        :param member_groups: [optional] boolean to include groups member belongs to\r\n        :return: dictionary with list of group details inside [json] key\r\n\r\n        group_details = self._reconstruct_group(**{})\r\n        '''\r\n\r\n    # https://www.meetup.com/meetup_api/docs/find/groups/\r\n\r\n        title = '%s.list_groups' % self.__class__.__name__\r\n\r\n    # validate inputs\r\n        input_fields = {\r\n            'categories': categories,\r\n            'topics': topics,\r\n            'text': text,\r\n            'country_code': country_code,\r\n            'latitude': latitude,\r\n            'longitude': longitude,\r\n            'location': location,\r\n            'radius': radius,\r\n            'zip_code': zip_code,\r\n            'max_results': max_results\r\n        }\r\n        for key, value in input_fields.items():\r\n            if value:\r\n                object_title = '%s(%s=%s)' % (title, key, str(value))\r\n                self.fields.validate(value, '.%s' % key, object_title)\r\n\r\n    # construct request fields\r\n        url = '%s/find/groups' % self.endpoint\r\n        params = {\r\n            'fields': 'last_event,next_event,join_info',\r\n            'self_groups': 'include'\r\n        }\r\n        if not member_groups:\r\n            params['self_groups'] = 'exclude'\r\n        if max_results:\r\n            params['page'] = str(max_results)\r\n        if categories:\r\n            params['category'] = ','.join(str(item) for item in categories)\r\n        if topics:\r\n            params['topic_id'] = ','.join(str(item) for item in categories)\r\n        if text:\r\n            params['text'] = text\r\n        if country_code:\r\n            params['country'] = country_code.lower()\r\n        if latitude:\r\n            params['lat'] = str(latitude)\r\n        if longitude:\r\n            params['lon'] = str(longitude)\r\n        if location:\r\n            params['location'] = location\r\n        if radius:\r\n            params['radius'] = str(radius)\r\n        if zip_code:\r\n            params['zip'] = zip_code\r\n\r\n    # send request\r\n        response_details = self._get_request(url, params=params)\r\n\r\n    # construct method output\r\n        meetup_groups = {\r\n            'json': []\r\n        }\r\n        for key, value in response_details.items():\r\n            if key != 'json':\r\n                meetup_groups[key] = value\r\n        for group in response_details['json']:\r\n            meetup_groups['json'].append(self._reconstruct_group(group))\r\n\r\n        return meetup_groups", "response": "a method to find meetup groups based upon a number of filters\r\nApps"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_group_details(self, group_url='', group_id=0):\r\n\r\n        ''' a method to retrieve details about a meetup group\r\n\r\n        :param group_url: string with meetup urlname of group\r\n        :param group_id: int with meetup id for group\r\n        :return: dictionary with group details inside [json] key\r\n\r\n        group_details = self._reconstruct_group(**{})\r\n        '''\r\n\r\n    # https://www.meetup.com/meetup_api/docs/:urlname/#get\r\n\r\n        title = '%s.get_group_details' % self.__class__.__name__\r\n\r\n    # validate inputs\r\n        input_fields = {\r\n            'group_url': group_url,\r\n            'group_id': group_id\r\n        }\r\n        for key, value in input_fields.items():\r\n            if value:\r\n                object_title = '%s(%s=%s)' % (title, key, str(value))\r\n                self.fields.validate(value, '.%s' % key, object_title)\r\n        if not group_url and not group_id:\r\n            raise IndexError('%s requires either a group_url or group_id argument.' % title)\r\n\r\n    # construct request fields\r\n        if group_id:\r\n            url = '%s/2/groups?fields=last_event,next_event,join_info&group_id=%s' % (self.endpoint, group_id)\r\n        else:\r\n            url = '%s/%s?fields=last_event,next_event,join_info' % (self.endpoint, group_url)\r\n\r\n    # send request\r\n        group_details = self._get_request(url)\r\n\r\n    # cosntruct method output\r\n        if group_id:\r\n            if 'results' in group_details['json'].keys():\r\n                if group_details['json']['results']:\r\n                    group_details['json'] = self._reconstruct_group(group_details['json']['results'][0])\r\n        else:\r\n            group_details['json'] = self._reconstruct_group(group_details['json'])\r\n\r\n        return group_details", "response": "a method to retrieve details about a meetup group"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_group_members(self, group_url, max_results=0):\r\n\r\n        ''' a method to retrieve a list of members for a meetup group\r\n\r\n        :param group_url: string with meetup urlname for group\r\n        :param max_results: [optional] integer with number of members to include\r\n        :return: dictionary with list of member details inside [json] key\r\n\r\n        member_details = self._reconstruct_member({})\r\n        '''\r\n\r\n    # https://www.meetup.com/meetup_api/docs/:urlname/members/#list\r\n\r\n        title = '%s.list_group_members' % self.__class__.__name__\r\n\r\n    # validate inputs\r\n        input_fields = {\r\n            'group_url': group_url,\r\n            'max_results': max_results\r\n        }\r\n        for key, value in input_fields.items():\r\n            if value:\r\n                object_title = '%s(%s=%s)' % (title, key, str(value))\r\n                self.fields.validate(value, '.%s' % key, object_title)\r\n\r\n    # construct request fields\r\n        url = '%s/%s/members' % (self.endpoint, group_url)\r\n        params = {\r\n            'fields': 'gender,birthday,last_event,messaging_pref,next_event,other_services,privacy,self,stats'\r\n        }\r\n        if max_results:\r\n            params['page'] = str(max_results)\r\n\r\n    # send request\r\n        response_details = self._get_request(url, params=params)\r\n\r\n    # reconstruct method output\r\n        group_members = {\r\n            'json': []\r\n        }\r\n        for key, value in response_details.items():\r\n            if key != 'json':\r\n                group_members[key] = value\r\n        for member in response_details['json']:\r\n            group_members['json'].append(self._reconstruct_member(member))\r\n\r\n        return group_members", "response": "a method to retrieve a list of members for a meetup group"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_venue_details(self, venue_id):\r\n\r\n        ''' a method to retrieve venue details from meetup api\r\n\r\n        :param venue_id: integer for meetup id for venue\r\n        :return: dictionary with venue details inside [json] key\r\n\r\n        venue_details = self.objects.venue.schema\r\n        '''\r\n\r\n        title = '%s.get_venue_details' % self.__class__.__name__\r\n\r\n    # validate inputs\r\n        input_fields = {\r\n            'venue_id': venue_id\r\n        }\r\n        for key, value in input_fields.items():\r\n            if value:\r\n                object_title = '%s(%s=%s)' % (title, key, str(value))\r\n                self.fields.validate(value, '.%s' % key, object_title)\r\n\r\n    # construct request fields\r\n        url = '%s/2/venues' % self.endpoint\r\n        params = {\r\n            'venue_id': str(venue_id)\r\n        }\r\n\r\n    # send request\r\n        venue_details = self._get_request(url, params=params)\r\n\r\n    # reconstruct method output\r\n        if venue_details['json']:\r\n            if 'results' in venue_details['json'].keys():\r\n                if venue_details['json']['results']:\r\n                    details = venue_details['json']['results'][0]\r\n                    venue_details['json'] = self.objects.venue.ingest(**details)\r\n\r\n        return venue_details", "response": "a method to retrieve venue details from meetup api"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_locations(self, latitude=0.0, longitude=0.0, zip_code='', city_name='', max_results=0):\r\n\r\n        ''' a method to retrieve location address details based upon search parameters\r\n\r\n        :param latitude: [optional] float with latitude coordinate at center of geo search\r\n        :param longitude: [optional] float with longitude coordinate at center of geo search\r\n        :param city_name: [optional] string with name of city for search\r\n        :param zip_code: [optional] string with zip code of geographic search\r\n        :param max_results: [optional] integer with number of groups to include\r\n        :return: dictionary with list of location details inside [json] key\r\n\r\n        location_details = self.objects.location.schema\r\n        '''\r\n\r\n        # https://www.meetup.com/meetup_api/docs/find/locations/\r\n\r\n        title = '%s.list_locations' % self.__class__.__name__\r\n\r\n    # validate inputs\r\n        input_fields = {\r\n            'latitude': latitude,\r\n            'longitude': longitude,\r\n            'zip_code': zip_code,\r\n            'city_name': city_name,\r\n            'max_results': max_results\r\n        }\r\n        for key, value in input_fields.items():\r\n            if value:\r\n                object_title = '%s(%s=%s)' % (title, key, str(value))\r\n                self.fields.validate(value, '.%s' % key, object_title)\r\n\r\n    # validate requirements\r\n        if latitude or longitude:\r\n            if not latitude or not longitude:\r\n                raise IndexError('%s coordinate search requires both latitude and longitude arguments.' % title)\r\n\r\n                # construct request fields\r\n        url = '%s/find/locations' % self.endpoint\r\n        params = {}\r\n        if max_results:\r\n            params['page'] = str(max_results)\r\n        if latitude:\r\n            params['lat'] = str(latitude)\r\n        if longitude:\r\n            params['lon'] = str(longitude)\r\n        elif zip_code:\r\n            params['query'] = zip_code\r\n        elif city_name:\r\n            params['query'] = city_name\r\n\r\n            # send request\r\n        response_details = self._get_request(url, params=params)\r\n\r\n        # construct method output\r\n        meetup_locations = {\r\n            'json': []\r\n        }\r\n        for key, value in response_details.items():\r\n            if key != 'json':\r\n                meetup_locations[key] = value\r\n        for location in response_details['json']:\r\n            meetup_locations['json'].append(location)\r\n\r\n        return meetup_locations", "response": "a method to retrieve location details based upon search parameters\r\n            uses the API endpoint\r\n           . location. schema\r\n           . location. schema\r\n           . location. schema\r\n           . max_results returns a dictionary with the location details as keys and the location details as values"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef join_topics(self, member_id, topics):\r\n\r\n        ''' a method to add topics to member profile details on meetup\r\n\r\n        :param member_id: integer with member id from member profile\r\n        :param topics: list of integer meetup ids for topics\r\n        :return: dictionary with list of topic details inside [json] key\r\n\r\n        topic_details = self.objects.topic.schema\r\n        '''\r\n\r\n    # https://www.meetup.com/meetup_api/docs/members/:member_id/#edit\r\n\r\n        title = '%s.join_topics' % self.__class__.__name__\r\n\r\n    # validate permissions\r\n        if not 'profile_edit' in self.service_scope:\r\n            raise ValueError('%s requires group_join as part of oauth2 service_scope permissions.' % title)\r\n\r\n    # validate inputs\r\n        input_fields = {\r\n            'member_id': member_id,\r\n            'topics': topics\r\n        }\r\n        for key, value in input_fields.items():\r\n            if value:\r\n                object_title = '%s(%s=%s)' % (title, key, str(value))\r\n                self.fields.validate(value, '.%s' % key, object_title)\r\n\r\n    # construct request fields\r\n        url = '%s/members/%s' % (self.endpoint, member_id)\r\n        params = {\r\n            'add_topics': ','.join(str(x) for x in topics),\r\n            'fields': 'topics'\r\n        }\r\n\r\n    # send requests\r\n        response_details = self._patch_request(url, params=params)\r\n\r\n    # construct method output dictionary\r\n        member_topics = {\r\n            'json': []\r\n        }\r\n        for key, value in response_details.items():\r\n            if not key == 'json':\r\n                member_topics[key] = value\r\n\r\n    # parse response\r\n        if response_details['json']:\r\n            if 'topics' in response_details['json'].keys():\r\n                for topic in response_details['json']['topics']:\r\n                    member_topics['json'].append(self.objects.topic.ingest(**topic))\r\n\r\n        return member_topics", "response": "a method to add topics to member profile details on meetup"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch_inst_id(self):\n        try:\n            for d in msgpack.unpack(urllib2.urlopen(\n                    \"%s/list/institutes?format=msgpack\" % self.url)):\n                if d['name'] == 'Radboud Universiteit Nijmegen':\n                    return d['id']\n        except IOError, e: # urllib2 exceptions are a subclass of IOError\n            raise RuusterError(e)\n        assert False", "response": "Fetches the institute id of the RU"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfetch the ids of the rooms with the given names", "response": "def fetch_room_ids(self, names):\n        \"\"\" Fetches the ids of the rooms with the given names \"\"\"\n        ret = {}\n        names_set = set(names)\n        try:\n            for d in msgpack.unpack(urllib2.urlopen(\n                    \"%s/list/locations?format=msgpack\" % self.url)):\n                name = d['name'].upper() # normalize: Hg -> HG\n                if name in names_set:\n                    ret[name] = d['id']\n        except urllib2.HTTPError, e:\n            raise RuusterError(e)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfetching the schedules for the given rooms.", "response": "def fetch_todays_schedule(self, rooms):\n        \"\"\" Fetch the schedules for the given rooms. \"\"\"\n        room_ids = self.fetch_room_ids(rooms)\n        inst_id = self.fetch_inst_id()\n        ret = {}\n        now = datetime.datetime.now()\n        day = DAYS[now.isoweekday() - 1]\n        for room_name in room_ids:\n            ret[room_name] = []\n            try:\n                events = msgpack.unpack(urllib2.urlopen(\n                    \"%s/snapshot/head/%s/location/%s?format=msgpack\" % (\n                        self.url, inst_id, room_ids[room_name])))['events']\n            except urllib2.HTTPError, e:\n                raise RuusterError(e)\n            for event in events:\n                starttime = datetime.datetime.strptime(\n                        event['starttime'], '%H:%M:%S').time()\n                endtime = datetime.datetime.strptime(\n                        event['endtime'], '%H:%M:%S').time()\n                if event['day'] != day:\n                    continue\n                ok = False\n                for period in event['eventperiods']:\n                    startdate = datetime.datetime.strptime(\n                            period['startdate'], '%Y-%m-%d %H:%M:%SZ').date()\n                    enddate = datetime.datetime.strptime(\n                            period['enddate'], '%Y-%m-%d %H:%M:%SZ').date()\n                    if (startdate <= now.date() and now.date() <= enddate):\n                        ok = True\n                        break\n                if not ok:\n                    continue\n                name = event['course']['name']\n                if name == 'Reserveringen' and 'comment' in event:\n                    name = event['comment']\n                ret[room_name].append((starttime, endtime,\n                        normalize_event_name(name)))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_ip(source='aws'):\n    \n    ''' a method to get current public ip address of machine '''\n    \n    if source == 'aws':\n        source_url = 'http://checkip.amazonaws.com/'\n    else:\n        raise Exception('get_ip currently only supports queries to aws')\n    \n    import requests\n    try:\n        response = requests.get(url=source_url)\n    except Exception as err:\n        from labpack.handlers.requests import handle_requests\n        from requests import Request\n        request_object = Request(method='GET', url=source_url)\n        request_details = handle_requests(request_object)\n        raise Exception(request_details['error'])\n    current_ip = response.content.decode()\n    current_ip = current_ip.strip()\n    \n    return current_ip", "response": "a method to get current public ip address of machine"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef describe_ip(ip_address, source='whatismyip'):\n\n    ''' a method to get the details associated with an ip address '''\n    \n# determine url\n    if source == 'nekudo':\n        source_url = 'https://geoip.nekudo.com/api/%s' % ip_address\n    elif source == 'geoip':\n        source_url = 'https://freegeoip.net/json/%s' % ip_address\n    elif source == 'whatismyip':\n        # http://whatismyipaddress.com/ip-lookup\n        source_url = 'https://whatismyipaddress.com/ip/%s' % ip_address\n    else:\n        raise Exception('describe_ip currently only supports queries to nekudo')\n\n    # TODO incorporate geoip module and c dependencies with local database\n    # http://tech.marksblogg.com/ip-address-lookups-in-python.html\n\n# send request\n    ip_details = {\n        'accuracy_radius': 0,\n        'asn': '',\n        'assignment': '',\n        'city': '',\n        'continent': '',\n        'country': '',\n        'hostname': '',\n        'ip': '',\n        'isp': '',\n        'latitude': 0.0,\n        'longitude': 0.0,\n        'organization': '',\n        'postal_code': '',\n        'region': '',\n        'timezone': '',\n        'type': ''\n    }\n    import requests\n    try:\n        response = requests.get(url=source_url)\n    except Exception as err:\n        from labpack.handlers.requests import handle_requests\n        from requests import Request\n        request_object = Request(method='GET', url=source_url)\n        request_details = handle_requests(request_object)\n        raise Exception(request_details['error'])\n\n# extract response\n    if source == 'whatismyip':\n        import re\n        response_text = response.content.decode()\n        table_regex = re.compile('<table>\\n<tr><th>IP.*?</table>\\n<span\\sstyle', re.S)\n        table_search = table_regex.findall(response_text)\n        if table_search:\n            table_text = table_search[0]\n            field_list = [ 'IP', 'Hostname', 'ISP', 'Organization', 'Type', 'ASN', 'Assignment', 'Continent', 'Country', 'State/Region', 'City', 'Latitude', 'Longitude', 'Postal Code']\n            for field in field_list:\n                field_regex = re.compile('<tr><th>%s:</th><td>(.*?)</td>' % field, re.S)\n                field_search = field_regex.findall(table_text)\n                if field_search:\n                    ip_details[field.lower().replace(' ','_')] = field_search[0]\n        for field in ('longitude', 'latitude'):\n            if field in ip_details.keys():\n                coord_regex = re.compile('\\-?\\d+\\.\\d+')\n                coord_search = coord_regex.findall(ip_details[field])\n                if coord_search:\n                    ip_details[field] = float(coord_search[0])\n        if 'country' in ip_details.keys():\n            country_regex = re.compile('([\\w\\s]+?)($|\\s<img)')\n            country_search = country_regex.findall(ip_details['country'])\n            if country_search:\n                ip_details['country'] = country_search[0][0]\n        for field in ('type', 'assignment'):\n            if field in ip_details.keys():\n                link_regex = re.compile('>(.*?)<')\n                link_search = link_regex.findall(ip_details[field])\n                if link_search:\n                    ip_details[field] = link_search[0]\n        if 'state/region' in ip_details.keys():\n            ip_details['region'] = ip_details['state/region']\n            del ip_details['state/region']\n    elif source == 'nekudo':\n        response_details = response.json()\n        ip_details['country'] = response_details['country']['name']\n        ip_details['latitude'] = response_details['location']['latitude']\n        ip_details['longitude'] = response_details['location']['longitude']\n        ip_details['accuracy_radius'] = response_details['location']['accuracy_radius']\n        if response_details['city']:\n            ip_details['city'] = response_details['city']\n        ip_details['ip'] = response_details['ip']\n        for key in response_details.keys():\n            if key not in ip_details.keys() and key != 'location':\n                ip_details[key] = response_details[key]\n    else:\n        response_details = response.json()\n        for field in ('city', 'ip', 'latitude', 'longitude'):\n            ip_details[field] = response_details[field]\n        ip_details['country'] = response_details['country_name']\n        ip_details['region'] = response_details['region_name']\n        ip_details['postal_code'] = response_details['zip_code']\n        ip_details['timezone'] = response_details['time_zone']\n    \n    return ip_details", "response": "a method to get the details associated with an ip address"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the HTK parameter file.", "response": "def load_parameter(input_filename, only_header=False):\n    \"\"\"Load HTK parameter/feature file.\n\n    :param input_filename:\n    :param only_header: only load the metadata\n    :return: a named tuple representing the HTK parmeter file\n    \"\"\"\n\n    with open(input_filename, 'rb') as f:\n        meta = _parse_parameter_meta(f)\n        if only_header:\n            return meta\n\n        return _parse_parameter_samples(f, meta)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_parameter(samples, sample_period):\n\n    parm_kind_str = 'USER'\n    parm_kind = _htk_str_to_param(parm_kind_str)\n    parm_kind_base, parm_kind_opts = _htk_str_to_param(parm_kind_str)\n\n    meta = ParameterMeta(n_samples=len(samples),\n                         samp_period=sample_period,\n                         samp_size=len(samples[0]) * 4,  # size in bytes\n                         parm_kind_str=parm_kind_str,\n                         parm_kind=parm_kind,\n                         parm_kind_base=parm_kind_base,\n                         parm_kind_opts=parm_kind_opts)\n    return Parameter(meta=meta,\n                     samples=np.array(samples))", "response": "Create a HTK Parameter object from an array of samples and a sample_period."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload an HTK Master Label File.", "response": "def load_mlf(filename, utf8_normalization=None):\n    \"\"\"Load an HTK Master Label File.\n\n    :param filename: The filename of the MLF file.\n    :param utf8_normalization: None\n    \"\"\"\n    with codecs.open(filename, 'r', 'string_escape') as f:\n        data = f.read().decode('utf8')\n        if utf8_normalization:\n            data = unicodedata.normalize(utf8_normalization, data)\n\n    mlfs = {}\n    for mlf_object in HTK_MLF_RE.finditer(data):\n        mlfs[mlf_object.group('file')] = [[Label(**mo.groupdict())\n                                           for mo\n                                           in HTK_HYPOTHESIS_RE.finditer(recognition_data)]\n                                          for recognition_data\n                                          in re.split(r'\\n///\\n', mlf_object.group('hypotheses'))]\n\n    return mlfs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_mlf(mlf, output_filename):\n    with codecs.open(output_filename, 'w', 'utf-8') as f:\n        f.write(u'#!MLF!#\\n')\n        for k, v in mlf.items():\n            f.write(u'\"{}\"\\n'.format(k))\n            for labels in v:\n                for label in labels:\n                    line = u'{start} {end} {symbol} ' \\\n                           u'{loglikelihood} {word}'.format(start=label.start or '',\n                                                            end=label.end or '',\n                                                            symbol=label.symbol or '',\n                                                            loglikelihood=label.log_likelihood or '',\n                                                            word=label.word or '')\n                    f.write(u'{}\\n'.format(line.strip()))\n\n                f.write(u'.\\n')", "response": "Save an MLF file containing a mapping from file to list of annotations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntesting code called from commandline", "response": "def main():\n    \"\"\"Test code called from commandline\"\"\"\n    model = load_model('../data/hmmdefs')\n    hmm = model.hmms['r-We']\n    for state_name in hmm.state_names:\n        print(state_name)\n        state = model.states[state_name]\n        print(state.means_)\n    print(model)\n    model2 = load_model('../data/prior.hmm1mixSI.rate32')\n    print(model2)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_lower(cls):  # NOQA\n\n        email = cls.get_fields_by_class(EmailType)\n        lower = cls.get_fields_by_prop('lower', True) + email\n\n        return list(set(email + lower))", "response": "Return a list of all the fields that should be lowercased by the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of field names matching a field class", "response": "def get_fields_by_class(cls, field_class):\n        \"\"\" Return a list of field names matching a field class\n\n        :param field_class: field class object\n        :return: list\n        \"\"\"\n\n        ret = []\n\n        for key, val in getattr(cls, '_fields').items():\n            if isinstance(val, field_class):\n                ret.append(key)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of field names matching a prop key and value", "response": "def get_fields_by_prop(cls, prop_key, prop_val):\n        \"\"\" Return a list of field names matching a prop key/val\n\n        :param prop_key: key name\n        :param prop_val: value\n        :return: list\n        \"\"\"\n\n        ret = []\n\n        for key, val in cls.get_fields_with_prop(prop_key):\n            if val == prop_val:\n                ret.append(key)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_fields_with_prop(cls, prop_key):\n\n        ret = []\n\n        for key, val in getattr(cls, '_fields').items():\n            if hasattr(val, prop_key):\n                ret.append((key, getattr(val, prop_key)))\n        return ret", "response": "Return a list of fields with a prop key defined\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting the native schematics validation errors into a ValidationFailure exc s list", "response": "def to_exceptions(cls, errors):\n        \"\"\" Convert the validation errors into ValidationFailure exc's\n\n        Transform native schematics validation errors into a\n        goldman ValidationFailure exception.\n\n        :param errors:\n            dict of errors in schematics format\n        :return:\n            list of ValidationFailure exception objects\n        \"\"\"\n\n        ret = []\n\n        for key, val in errors.items():\n            if key in cls.relationships:\n                attr = '/data/relationships/%s' % key\n            else:\n                attr = '/data/attributes/%s' % key\n\n            for error in val:\n                ret.append(ValidationFailure(attr, detail=error))\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dirty_fields(self):\n\n        dirty_fields = []\n\n        for field in self.all_fields:\n            if field not in self._original:\n                dirty_fields.append(field)\n            elif self._original[field] != getattr(self, field):\n                dirty_fields.append(field)\n        return dirty_fields", "response": "Return an array of field names that are dirty"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef merge(self, data, clean=False, validate=False):\n\n        try:\n            model = self.__class__(data)\n        except ConversionError as errors:\n            abort(self.to_exceptions(errors.messages))\n\n        for key, val in model.to_native().items():\n            if key in data:\n                setattr(self, key, val)\n\n        if validate:\n            try:\n                self.validate()\n            except ModelValidationError as errors:\n                abort(self.to_exceptions(errors.messages))\n\n        if clean:\n            self._original = self.to_native()", "response": "This method merges a dict with the model instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\noverride the schematics native to_primitive method loads relationships and returns the data as a dict.", "response": "def to_primitive(self, load_rels=None, sparse_fields=None, *args,\n                     **kwargs):\n        \"\"\" Override the schematics native to_primitive method\n\n        :param loads_rels:\n            List of field names that are relationships that should\n            be loaded for the serialization process. This needs\n            to be run before the native schematics to_primitive is\n            run so the proper data is serialized.\n\n        :param sparse_fields:\n            List of field names that can be provided which limits\n            the serialization to ONLY those field names. A whitelist\n            effectively.\n        \"\"\"\n\n        if load_rels:\n            for rel in load_rels:\n                getattr(self, rel).load()\n\n        data = super(Model, self).to_primitive(*args, **kwargs)\n\n        if sparse_fields:\n            for key in data.keys():\n                if key not in sparse_fields:\n                    del data[key]\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stash_split(fqdn, result, *argl, **argd):\n    global _splits\n    if fqdn == \"sklearn.cross_validation.train_test_split\":\n        key = id(result[1])\n        _splits[key] = result\n\n    #We don't actually want to return anything for the analysis; we are using it\n    #as a hook to save pointers to the dataset split so that we can easily\n    #analyze performance later on.\n    return None", "response": "Stashes the split between training and testing sets so that it can be used later for automatic scoring of models in the log."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the FQDN of the given learning machine.", "response": "def _machine_fqdn(machine):\n    \"\"\"Returns the FQDN of the given learning machine.\n    \"\"\"\n    from acorn.logging.decoration import _fqdn\n    if hasattr(machine, \"__class__\"):\n        return _fqdn(machine.__class__, False)\n    else: # pragma: no cover\n        #See what FQDN can get out of the class instance.\n        return _fqdn(machine)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fit(fqdn, result, *argl, **argd):\n    #Check the arguments to see what kind of data we are working with, then\n    #choose the appropriate function below to return the analysis dictionary.\n    #The first positional argument will be the instance of the machine that was\n    #used. Check its name against a list.\n    global _machines\n    out = None\n    if len(argl) > 0:\n        machine = argl[0]\n        #We save pointers to the machine that was just fit so that we can figure\n        #out later what training data was used for analysis purposes.\n        key = id(machine)\n        _machines[key] = (machine, argl[0], argl[1])\n        \n        if isclassifier(machine):\n            out = classify_fit(fqdn, result, *argl, **argd)\n        elif isregressor(machine):\n            out = regress_fit(fqdn, result, *argl, **argd)\n        \n    return out", "response": "Analyzes the result of a generic fit operation performed by sklearn."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nanalyzes the result of a generic predict operation performed by sklearn.", "response": "def predict(fqdn, result, *argl, **argd):\n    \"\"\"Analyzes the result of a generic predict operation performed by\n    `sklearn`.\n\n    Args:\n        fqdn (str): full-qualified name of the method that was called.\n        result: result of calling the method with `fqdn`.\n        argl (tuple): positional arguments passed to the method call.\n        argd (dict): keyword arguments passed to the method call.\n    \"\"\"\n    #Check the arguments to see what kind of data we are working with, then\n    #choose the appropriate function below to return the analysis dictionary.\n    out = None\n    if len(argl) > 0:\n        machine = argl[0]\n        if isclassifier(machine):\n            out = classify_predict(fqdn, result, None, *argl, **argd)\n        elif isregressor(machine):\n            out = regress_predict(fqdn, result, None, *argl, **argd)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform an automatic prediction for the specified machine and returns the predicted values.", "response": "def _do_auto_predict(machine, X, *args):\n    \"\"\"Performs an automatic prediction for the specified machine and returns\n    the predicted values.\n    \"\"\"\n    if auto_predict and hasattr(machine, \"predict\"):\n        return machine.predict(X)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _generic_fit(fqdn, result, scorer, yP=None, *argl, **argd):\n    out = None\n    if len(argl) > 0:\n        machine = argl[0]\n        out = {}\n        if hasattr(machine, \"best_score_\"):\n            out[\"score\"] = machine.best_score_\n            \n        #With fitting it is often useful to know how well the fitting set was\n        #matched (by trying to predict a score on it). We can do this\n        #automatically and show the result to the user.\n        yL = _do_auto_predict(*argl[0:2])\n        yscore = scorer(fqdn, yL, yP, *argl, **argd)\n        if yscore is not None:\n            out.update(yscore)\n\n    return out", "response": "Performs the generic fit tests that are common to both classifier and the training set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef classify_fit(fqdn, result, *argl, **argd):\n    if len(argl) > 2:\n        #Usually fit is called with fit(machine, Xtrain, ytrain).\n        yP = argl[2]\n    out = _generic_fit(fqdn, result, classify_predict, yP, *argl, **argd)\n    return out", "response": "Analyzes the result of a classification algorithm s fitting."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the percent match for the specified prediction call.", "response": "def _percent_match(result, out, yP=None, *argl):\n    \"\"\"Returns the percent match for the specified prediction call; requires\n    that the data was split before using an analyzed method.\n\n    Args:\n        out (dict): output dictionary to save the result to.\n    \"\"\"\n    if len(argl) > 1:\n        if yP is None:\n            Xt = argl[1]\n            key = id(Xt)\n            if key in _splits:\n                yP = _splits[key][3]\n                \n        if yP is not None:\n            import math\n            out[\"%\"] = round(1.-sum(abs(yP - result))/float(len(result)), 3)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nanalyze the result of a classification algorithm s prediction.", "response": "def classify_predict(fqdn, result, yP=None, *argl, **argd):\n    \"\"\"Analyzes the result of a classification algorithm's prediction. See also\n    :func:`predict` for explanation of arguments.\n\n    .. todo: update the metric to be useful.\n\n    \"\"\"\n    #For now, just to make sure the machinery works correctly, let's return the\n    #percentage correct. This is a terrible metric in practice.\n    out = {}\n    _percent_match(result, out, yP, *argl)\n\n    if auto_print:\n        msg.okay(out, -1)\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nanalyzing the result of a regression algorithm s fitting.", "response": "def regress_fit(fqdn, result, *argl, **argd):\n    \"\"\"Analyzes the result of a regression algorithm's fitting. See also\n    :func:`fit` for explanation of arguments.\n    \"\"\"\n    if len(argl) > 2:\n        yP = argl[2]\n    out = _generic_fit(fqdn, result, regress_predict, yP, *argl, **argd)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef path(self):\n        if not self.id:\n            raise ValueError('Cannot determine path without a task id.')\n\n        return self.path_helper(self.taskqueue.path, self.id)", "response": "Getter property for the URL path to this Task."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(self, client=None):\n        return self.taskqueue.delete_task(self.id, client=client)", "response": "Deletes a task from Task Queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self, new_lease_time, client=None):\n        return self.taskqueue.update_task(self.id, new_lease_time=new_lease_time, client=client)", "response": "Update the duration of a task lease."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef description(self):\n        if self._description is None:\n            if 'payloadBase64' not in self._properties:\n                self._properties = self.taskqueue.get_task(id=self.id)._properties\n            self._description = base64.b64decode(self._properties.get('payloadBase64', b'')).decode(\"ascii\")\n        return self._description", "response": "Returns the description of this task."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef time_enqueued(self):\n        value = self._properties.get('enqueueTimestamp')\n        if value is not None:\n            return _datetime_from_microseconds(int(value))", "response": "Retrieve the timestamp at which the task was enqueued."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve the timestamp at which the task lease will expire.", "response": "def leaseTimestamp(self):\n        \"\"\"Retrieve the timestamp at which the task lease will expire. If this task has never been leased,\n        it will be None. If this this task has been previously leased\n        and the lease has expired, this value will be < Now().\n\n        See: https://cloud.google.com/appengine/docs/python/taskqueue/rest/tasks\n\n        :rtype: :class:`datetime.datetime` or ``NoneType``\n        :returns: Datetime object parsed from microsecond timestamp, or\n                  ``None`` if the property is not set locally. If the task has\n                  not been leased, this will never be set.\n        \"\"\"\n        value = self._properties.get('leaseTimestamp')\n        if value is not None:\n            return _datetime_from_microseconds(int(value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes a 2 - D convolution given 4 - D input and filter tensors.", "response": "def conv2d(self, x_in: Connection, w_in: Connection, receptive_field_size, filters_number, stride=1, padding=1,\n               name=\"\"):\n        \"\"\"\n        Computes a 2-D convolution given 4-D input and filter tensors.\n        \"\"\"\n        x_cols = self.tensor_3d_to_cols(x_in, receptive_field_size, stride=stride, padding=padding)\n        mul = self.transpose(self.matrix_multiply(x_cols, w_in), 0, 2, 1)\n\n        #output_width = self.sum(self.div(self.sum(self.sum(self.shape(x_in, 2), self.constant(-1 * receptive_field_size)),\n        #                        self.constant(2 * padding)), self.constant(stride)), self.constant(1))\n        # output_height = (h - f + 2 * p) / s + 1\n\n        output = self.reshape(mul, (-1, filters_number, receptive_field_size, receptive_field_size))\n\n        output.name = name\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nappends a new entry to the container.", "response": "def append(self, hcont, value, score = None):\n        \"\"\" If sort_field is specified, score must be None.\n            If sort_field is not specified, score is mandatory. \"\"\"\n        assert (score is None) != (self.field.sort_field is None)\n        if score is None:\n            score = getattr(value, self.field.sort_field.name)\n        ContainerFieldWriter.append(self, hcont, value, score)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncopy file to bucket s3_folder", "response": "def copy_file(aws_access_key_id, aws_secret_access_key, bucket_name, file, s3_folder):\n    \"\"\"\n    copies file to bucket s3_folder\n    \"\"\"\n\n    #  Connect to the bucket\n\n    bucket = s3_bucket(aws_access_key_id, aws_secret_access_key, bucket_name)\n    key = boto.s3.key.Key(bucket)\n\n    if s3_folder:\n        target_name = '%s/%s' % (s3_folder, os.path.basename(file))\n    else:\n        target_name = os.path.basename(file)\n\n    key.key = target_name\n    print('Uploading %s to %s' % (file, target_name))\n    key.set_contents_from_filename(file)\n    print('Upload %s FINISHED: %s' % (file, dt.now()))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread a new object from the given input protocol and returns the object.", "response": "def read(cls, iprot):\n        '''\n        Read a new object from the given input protocol and return the object.\n\n        :type iprot: thryft.protocol._input_protocol._InputProtocol\n        :rtype: pastpy.gen.database.impl.online.online_database_objects_list_item.OnlineDatabaseObjectsListItem\n        '''\n\n        init_kwds = {}\n\n        iprot.read_struct_begin()\n        while True:\n            ifield_name, ifield_type, _ifield_id = iprot.read_field_begin()\n            if ifield_type == 0:  # STOP\n                break\n            elif ifield_name == 'detail_href':\n                init_kwds['detail_href'] = iprot.read_string()\n            elif ifield_name == 'record_type':\n                init_kwds['record_type'] = iprot.read_string()\n            elif ifield_name == 'title':\n                init_kwds['title'] = iprot.read_string()\n            elif ifield_name == 'thumbnail_url':\n                try:\n                    init_kwds['thumbnail_url'] = iprot.read_string()\n                except (TypeError, ValueError,):\n                    pass\n            iprot.read_field_end()\n        iprot.read_struct_end()\n\n        return cls(**init_kwds)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, oprot):\n        '''\n        Write this object to the given output protocol and return self.\n\n        :type oprot: thryft.protocol._output_protocol._OutputProtocol\n        :rtype: pastpy.gen.database.impl.online.online_database_objects_list_item.OnlineDatabaseObjectsListItem\n        '''\n\n        oprot.write_struct_begin('OnlineDatabaseObjectsListItem')\n\n        oprot.write_field_begin(name='detail_href', type=11, id=None)\n        oprot.write_string(self.detail_href)\n        oprot.write_field_end()\n\n        oprot.write_field_begin(name='record_type', type=11, id=None)\n        oprot.write_string(self.record_type)\n        oprot.write_field_end()\n\n        oprot.write_field_begin(name='title', type=11, id=None)\n        oprot.write_string(self.title)\n        oprot.write_field_end()\n\n        if self.thumbnail_url is not None:\n            oprot.write_field_begin(name='thumbnail_url', type=11, id=None)\n            oprot.write_string(self.thumbnail_url)\n            oprot.write_field_end()\n\n        oprot.write_field_stop()\n\n        oprot.write_struct_end()\n\n        return self", "response": "Writes the object to the given output protocol."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pairplot(dataset, vars, filename, bins=60):\n    n = len(vars)\n\n    fig, axes = plt.subplots(nrows=n, ncols=n)\n    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n\n    for i, x in enumerate(vars):\n        for j, y in enumerate(vars):\n            print(((x, y), (i, j)))\n            ax = axes[j,i]\n            if j < i:\n                ax.axis('off')\n                continue\n            elif i == j:\n                P = posterior.oneD(dataset+'.h5', x, limits=limits(x), bins=bins)\n                P.plot(ax)\n                ax.set_xlim(limits(x))\n                ax.spines['right'].set_visible(False)\n                ax.spines['top'].set_visible(False)\n                ax.xaxis.set_ticks_position('bottom')\n                ax.set_yticks([])\n            else:\n                P = posterior.twoD(dataset+'.h5', x, y,\n                        xlimits=limits(x), ylimits=limits(y), xbins=bins, ybins=bins)\n\n                # apply some gaussian smoothing to make the contours slightly smoother\n                sigmas = (np.diff(P.ycenters)[0], np.diff(P.xcenters)[0])\n                P.pdf = gaussian_filter(P.pdf, sigmas, mode='nearest')\n                P.plot(ax, levels=np.linspace(0.9, 0.1, 9))\n                ax.set_xlim(limits(x))\n                ax.set_ylim(limits(y))\n\n            # now we clean up labels, ticks and such\n            leftmostcol = i == 0\n            bottomrow = j == n-1\n            ax.set_xlabel(labels(x) if bottomrow else '')\n            ax.set_ylabel(labels(y) if leftmostcol else '')\n\n            if not leftmostcol:\n                ax.set_yticklabels([])\n            if not bottomrow:\n                ax.set_xticklabels([])\n\n    fig.set_size_inches(n*4,n*4)\n    fig.savefig(filename, dpi=200, bbox_inches='tight')\n    plt.close(fig)", "response": "Plot a matrix of the specified variables with all the 2D pdfs and 1D pdfs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot 2D marginalised posteriors of the vars vs the dark matter mass.", "response": "def plot_vs_mass(dataset, vars, filename, bins=60):\n    \"\"\" Plot 2D marginalised posteriors of the 'vars' vs the dark matter mass.\n    We plot the one sigma, and two sigma filled contours. More contours can be plotted\n    which produces something more akin to a heatmap.\n\n    If one require more complicated plotting, it is recommended to write a custom\n    plotting function by extending the default plot() method.\n    \"\"\"\n\n    n = len(vars)\n\n    fig, axes = plt.subplots(nrows=n,\n                             ncols=1,\n                             sharex='col',\n                             sharey=False)\n    plt.subplots_adjust(wspace=0, hspace=0)\n\n    m = 'log(m_{\\chi})'\n\n    for i, y in enumerate(vars):\n        ax = axes[i]\n        P = posterior.twoD(dataset+'.h5', m, y,\n                           xlimits=limits(m), ylimits=limits(y), xbins=bins, ybins=bins)\n\n        # apply some gaussian smoothing to make the contours slightly smoother\n        sigmas = (np.diff(P.ycenters)[0], np.diff(P.xcenters)[0])\n        P.pdf = gaussian_filter(P.pdf, sigmas, mode='nearest')\n\n        P.plot(ax, levels=np.linspace(0.9, 0.1, 9))\n        ax.set_xlabel(labels('log(m_{\\chi})'))\n        ax.set_ylabel(labels(y))\n\n    fig.set_size_inches(4,n*3)\n    fig.savefig(filename, dpi=200, bbox_inches='tight')\n    plt.close(fig)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_oneD(dataset, vars, filename, bins=60):\n    n = len(vars)\n\n    fig, axes = plt.subplots(nrows=n,\n                             ncols=1,\n                             sharex=False,\n                             sharey=False)\n\n    for i, x in enumerate(vars):\n        ax = axes[i]\n        P = posterior.oneD(dataset+'.h5', x, limits=limits(x), bins=bins)\n        P.plot(ax)\n        ax.set_xlabel(labels(x))\n        ax.set_yticklabels([])\n\n    fig.set_size_inches(4, 4*n)\n    fig.savefig(filename, dpi=200, bbox_inches='tight')\n    plt.close(fig)", "response": "Plot 1D marginalised posteriors for the vars of interest."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstarting the root logger and configures extra loggers.", "response": "def start_logger(self):\n        \"\"\"\n        Enables the root logger and configures extra loggers.\n        \"\"\"\n        level = self.real_level(self.level)\n        logging.basicConfig(level=level)\n        self.set_logger(self.name, self.level)\n        config.dictConfig(self.config)\n        self.logger = logging.getLogger(self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_logger(self, logger_name, level, handler=None):\n        if 'loggers' not in self.config:\n            self.config['loggers'] = {}\n        real_level = self.real_level(level)\n        self.config['loggers'][logger_name] = {'level': real_level}\n        if handler:\n            self.config['loggers'][logger_name]['handlers'] = [handler]", "response": "Sets the level of a logger"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering an event to the log.", "response": "def register_event(self, event_name, event_level, message):\n        \"\"\"\n        Registers an event so that it can be logged later.\n        \"\"\"\n        self.events[event_name] = (event_level, message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninvokes callback that should return a ( request response tuple. representing the SOAP request and response respectively.", "response": "def processRequest(cls, ps, **kw):\n        \"\"\"invokes callback that should return a (request,response) tuple.\n        representing the SOAP request and response respectively.\n        ps -- ParsedSoap instance representing HTTP Body.\n        request -- twisted.web.server.Request\n        \"\"\"\n        resource = kw['resource']\n        request = kw['request']\n        method =  getattr(resource, 'soap_%s' %\n                           _get_element_nsuri_name(ps.body_root)[-1])\n                                              \n        try:\n            req_pyobj,rsp_pyobj = method(ps, request=request)\n        except TypeError, ex:\n            log.err(\n                'ERROR: service %s is broken, method MUST return request, response'\\\n                    % cls.__name__\n            )\n            raise\n        except Exception, ex:\n            log.err('failure when calling bound method')\n            raise\n        \n        return rsp_pyobj"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _writeResponse(self, response, request, status=200):\n        request.setResponseCode(status)\n        if self.encoding is not None:\n            mimeType = 'text/xml; charset=\"%s\"' % self.encoding\n        else:\n            mimeType = \"text/xml\"\n\n        request.setHeader(\"Content-Type\", mimeType)\n        request.setHeader(\"Content-Length\", str(len(response)))\n        request.write(response)\n        request.finish()", "response": "Write the response to the HTTP response."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _writeFault(self, fail, request):\n        response = fault.FaultFromException(fail.value, False, fail.tb).AsSOAP() \n        self._writeResponse(response, request, status=500)", "response": "Write fault to the client"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render_POST(self, request):\n        from twisted.internet.defer import maybeDeferred\n        \n        chain = self.factory.newInstance()\n        data = request.content.read()\n        \n        d = maybeDeferred(chain.processRequest, data, request=request, resource=self)\n        d.addCallback(chain.processResponse, request=request, resource=self)\n        d.addCallback(self._writeResponse, request)\n        d.addErrback(self._writeFault, request)\n        \n        return NOT_DONE_YET", "response": "Dispatch method called by twisted render creates a \n        request and returns a response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_iso8601(dt, tz=None):\n    if tz is not None:\n        dt = dt.replace(tzinfo=tz)\n    iso8601 = dt.isoformat()\n\n    # Naive datetime objects usually don't have info about timezone.\n    # Let's assume it's UTC and add Z to the end.\n    if re.match(r'.*(Z|[+-]\\d{2}:\\d{2})$', iso8601) is None:\n        iso8601 += 'Z'\n\n    return iso8601", "response": "Returns an ISO - 8601 representation of a given datetime instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _is_dst(dt):\n        # we can't use `dt.timestamp()` here since it requires a `utcoffset`\n        # and we don't want to get into a recursive loop\n        localtime = time.localtime(time.mktime((\n            dt.year,\n            dt.month,\n            dt.day,\n            dt.hour,\n            dt.minute,\n            dt.second,\n            dt.weekday(),\n            0,              # day of the year\n            -1              # dst\n        )))\n        return localtime.tm_isdst > 0", "response": "Returns True if a given datetime object represents a time with\n        DST shift."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dst(self, dt):\n        if not self._is_dst(dt):\n            return datetime.timedelta(0)\n\n        offset = time.timezone - time.altzone\n        return datetime.timedelta(seconds=-offset)", "response": "Returns a difference in seconds between standard offset and dst offset."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef camelcase_to_lowercase(camelcase_input, python_input=None):\n    \n    '''\n        a function to recursively convert data with camelcase key names into lowercase keys \n        \n    :param camelcase_input: list or dictionary with camelcase keys \n    :param python_input: [optional] list or dictionary with default lowercase keys in output\n    :return: dictionary with lowercase key names\n    '''\n    \n    if python_input:\n        if camelcase_input.__class__ != python_input.__class__:\n            raise ValueError('python_input type %s does not match camelcase_input type %s' % (python_input.__class__, camelcase_input.__class__))\n    if isinstance(camelcase_input, dict):\n        return _to_python_dict(camelcase_input, python_input)\n    elif isinstance(camelcase_input, list):\n        return _ingest_list(camelcase_input, _to_python_dict, python_input)\n    else:\n        return camelcase_input", "response": "a function to recursively convert a camelcase key names into lowercase keys"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lowercase_to_camelcase(python_input, camelcase_input=None):\n    \n    '''\n        a function to recursively convert data with lowercase key names into camelcase keys \n        \n    :param camelcase_input: list or dictionary with lowercase keys \n    :param python_input: [optional] list or dictionary with default camelcase keys in output\n    :return: dictionary with camelcase key names\n    '''\n    \n    if camelcase_input:\n        if python_input.__class__ != camelcase_input.__class__:\n            raise ValueError('camelcase_input type %s does not match python_input type %s' % (camelcase_input.__class__, python_input.__class__))\n    if isinstance(python_input, dict):\n        return _to_camelcase_dict(python_input, camelcase_input)\n    elif isinstance(python_input, list):\n        return _ingest_list(python_input, _to_camelcase_dict, camelcase_input)\n    else:\n        return python_input", "response": "a function to recursively convert data with lowercase key names into camelcase keys \n "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(self, callback_url):\n        resource = self.resource.create({'subscribed_to': 'address',\n                                         'callback_url': callback_url})\n        subscription = self.wrap(resource)\n        self.add(subscription)\n        return subscription", "response": "Register a new Subscription on this collection s parent object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates through all possible sequences.", "response": "def enumerate(self, **kwargs):\n        '''Iterate through all possible sequences (lists).  By default, will\n        stop after 50 items have been yielded. This value can be\n        change by supplying a different value via the max_enumerate kwarg.\n        '''\n        for item in self.set.enumerate(**kwargs):\n            yield flattened(item)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of the matched objects. If the schema matches seq returns a list of the matched objects. Otherwise returns MatchFailure instance.", "response": "def match(self, seq, **kwargs):\n        '''If the schema matches seq, returns a list of the matched objects.\n        Otherwise, returns MatchFailure instance.\n        '''\n        strict = kwargs.get('strict', False)\n        top_level = kwargs.get('top_level', True)\n        match = kwargs.get('match', list())\n\n        if top_level:\n            kwargs['top_level'] = False\n            kwargs['match'] = match\n\n            try:\n                seq = IterableList(seq)\n                self.match(seq, **kwargs)\n\n                if strict:\n                    if not seq.empty():\n                        raise MatchFailed('Sequence is too long', seq)\n\n            except MatchFailed as e:\n                return e.failure()\n\n            return Match(*match)\n\n        for elem in self.elems:\n            elem.match(seq, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef downloads_per_year(collection, code, raw=False):\n\n    tc = ThriftClient()\n\n    body = {\"query\": {\"filtered\": {}}}\n\n    fltr = {}\n\n    query = {\n        \"query\": {\n            \"bool\": {\n                \"must\": [\n                    {\n                        \"match\": {\n                            \"collection\": collection\n                        }\n                    }\n                ]\n            }\n        }\n    }\n\n    aggs = {\n        \"aggs\": {\n            \"access_year\": {\n                \"terms\": {\n                    \"field\": \"access_year\",\n                    \"size\": 0,\n                    \"order\": {\n                        \"_term\": \"asc\"\n                    }\n                },\n                \"aggs\": {\n                    \"access_total\": {\n                        \"sum\": {\n                            \"field\": \"access_total\"\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    body['query']['filtered'].update(fltr)\n    body['query']['filtered'].update(query)\n    body.update(aggs)\n\n    code_type = _code_type(code)\n\n    if code_type:\n        query[\"query\"][\"bool\"][\"must\"].append({\n            \"match\": {\n                code_type: code\n            }\n        })\n\n    query_parameters = [\n        ('size', '0')\n    ]\n\n    query_result = tc.search(json.dumps(body), query_parameters)\n\n    return query_result if raw is True else _compute_downloads_per_year(query_result)", "response": "This method retrieve the total of downloads per year."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef speak(self, text):\n        if not self.is_valid_string(text):\n            raise Exception(\"%s is not ISO-8859-1 compatible.\" % (text))\n\n        # Maximum allowable 1023 characters per message\n        if len(text) > 1023:\n            lines = self.word_wrap(text, width=1023)\n            for line in lines:\n                self.queue.put(\"S%s\" % (line))\n        else:\n            self.queue.put(\"S%s\" % (text))", "response": "This function is used to convert text into speech."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the language used for TTS.", "response": "def set_language(self, language, dialect=None):\n        \"\"\"\n        Set the language used for TTS.\n        en: English\n        es: Spanish | [ lan: latino or ca: castilian ]\n        \"\"\"\n        self.currentAction = 'setting language'\n        l = 0\n        if language == 'en':\n            l = 0\n        elif language == 'es':\n            l = 1\n\n            if dialect == 'ca':\n                l = 2\n\n        self.queue.put('l%s' % (l))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_site(self, url, headers, cookies, timeout, driver_args, driver_kwargs):\n        try:\n            # **TODO**: Find what exception this will throw and catch it and call\n            #   self.driver.execute_script(\"window.stop()\")\n            # Then still try and get the source from the page\n            self.driver.set_page_load_timeout(timeout)\n\n            self.driver.get(url)\n            header_data = self.get_selenium_header()\n            status_code = header_data['status-code']\n\n            # Set data to access from script\n            self.status_code = status_code\n            self.url = self.driver.current_url\n\n        except TimeoutException:\n            logger.warning(\"Page timeout: {}\".format(url))\n            try:\n                scraper_monitor.failed_url(url, 'Timeout')\n            except (NameError, AttributeError):\n                # Happens when scraper_monitor is not being used/setup\n                pass\n            except Exception:\n                logger.exception(\"Unknown problem with scraper_monitor sending a failed url\")\n\n        except Exception as e:\n            raise e.with_traceback(sys.exc_info()[2])\n\n        else:\n            # If an exception was not thrown then check the http status code\n            if status_code < 400:\n                # If the http status code is not an error\n                return self.driver.page_source\n            else:\n                # If http status code is 400 or greater\n                raise SeleniumHTTPError(\"Status code >= 400\", status_code=status_code)", "response": "Try and return the page content using selenium\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nscrolls the page to the bottom of the page.", "response": "def scroll_to_bottom(self):\n        \"\"\"\n        Scoll to the very bottom of the page\n        TODO: add increment & delay options to scoll slowly down the whole page to let each section load in\n        \"\"\"\n        if self.driver.selenium is not None:\n            try:\n                self.driver.selenium.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n            except WebDriverException:\n                self.driver.selenium.execute_script(\"window.scrollTo(0, 50000);\")\n            except Exception:\n                logger.exception(\"Unknown error scrolling page\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef chrome_fullpage_screenshot(self, file, delay=0):\n        total_width = self.driver.execute_script(\"return document.body.offsetWidth\")\n        total_height = self.driver.execute_script(\"return document.body.parentNode.scrollHeight\")\n        viewport_width = self.driver.execute_script(\"return document.body.clientWidth\")\n        viewport_height = self.driver.execute_script(\"return window.innerHeight\")\n        logger.info(\"Starting chrome full page screenshot workaround. Total: ({0}, {1}), Viewport: ({2},{3})\"\n                    .format(total_width, total_height, viewport_width, viewport_height))\n        rectangles = []\n\n        i = 0\n        while i < total_height:\n            ii = 0\n            top_height = i + viewport_height\n\n            if top_height > total_height:\n                top_height = total_height\n\n            while ii < total_width:\n                top_width = ii + viewport_width\n\n                if top_width > total_width:\n                    top_width = total_width\n\n                logger.debug(\"Appending rectangle ({0},{1},{2},{3})\".format(ii, i, top_width, top_height))\n                rectangles.append((ii, i, top_width, top_height))\n\n                ii = ii + viewport_width\n\n            i = i + viewport_height\n\n        stitched_image = Image.new('RGB', (total_width, total_height))\n        previous = None\n        part = 0\n\n        for rectangle in rectangles:\n            if previous is not None:\n                self.driver.execute_script(\"window.scrollTo({0}, {1})\".format(rectangle[0], rectangle[1]))\n                logger.debug(\"Scrolled To ({0},{1})\".format(rectangle[0], rectangle[1]))\n                time.sleep(delay)\n\n            file_name = \"part_{0}.png\".format(part)\n            logger.debug(\"Capturing {0} ...\".format(file_name))\n\n            self.driver.get_screenshot_as_file(file_name)\n            screenshot = Image.open(file_name)\n\n            if rectangle[1] + viewport_height > total_height:\n                offset = (rectangle[0], total_height - viewport_height)\n            else:\n                offset = (rectangle[0], rectangle[1])\n\n            logger.debug(\"Adding to stitched image with offset ({0}, {1})\".format(offset[0], offset[1]))\n            stitched_image.paste(screenshot, offset)\n\n            del screenshot\n            os.remove(file_name)\n            part = part + 1\n            previous = rectangle\n\n        stitched_image.save(file)\n        logger.info(\"Finishing chrome full page screenshot workaround...\")\n        return True", "response": "This function runs a fullscreen screenshot of the current page."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unset(self, key):\n\n    try:\n      try:\n        self.bucket.delete(key)\n      except couchbase.exception.MemcachedError, inst: \n        if str(inst) == \"Memcached error #1:  Not found\":\n          # for some reason the py cb client raises an error when\n          # a key isnt found, instead we just want a none value.\n          return\n        else:\n          raise\n      except:\n        raise\n    except:\n      raise", "response": "Delete object indexed by key"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, key):\n    \n    \"\"\"\n    Retrieve object indexed by <key>\n    \"\"\"\n\n    try:\n      try:\n        obj = self.bucket.get(key)\n      except couchbase.exception.MemcachedError, inst: \n        if str(inst) == \"Memcached error #1:  Not found\":\n          # for some reason the py cb client raises an error when\n          # a key isnt found, instead we just want a none value.\n          obj = None\n        else:\n          raise\n      except:\n        raise\n      \n      if obj:\n        return json.loads(obj[2])\n      else:\n        return None\n\n    except:\n      raise", "response": "Retrieve object indexed by key"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set(self, key, data, retry=0):\n    \n    \"\"\"\n    Store data <data> index by key <key>\n\n    Args\n\n    key <string> couchbase document id\n    data <dict> data to store\n    \"\"\"\n    \n    try:\n\n      if type(data) != dict:\n        raise Exception(\"data needs to be of type <dict>\")\n\n      self.bucket.set(key, 0, 0, json.dumps(data))\n\n    except:\n      raise", "response": "Store data in the object identified by key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dump(self, key):\n    \n    \"\"\"\n    Retrieve object indexed by <key> and return it serialized\n    \"\"\"\n\n    try:\n      \n      obj = self.get(key)\n      if obj:\n        return json.dumps(obj)\n      else:\n        return None\n\n    except:\n      raise", "response": "Dump the object indexed by key and return it serialized"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes sure this key is as defined", "response": "def sync_one(self, aws_syncr, amazon, key):\n        \"\"\"Make sure this key is as defined\"\"\"\n        key_info = amazon.kms.key_info(key.name, key.location)\n        if not key_info:\n            amazon.kms.create_key(key.name, key.description, key.location, key.grant, key.policy.document)\n        else:\n            amazon.kms.modify_key(key_info, key.name, key.description, key.location, key.grant, key.policy.document)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _import(self, record_key, record_data, overwrite=True, last_modified=0.0, **kwargs):\r\n        \r\n        '''\r\n            a helper method for other storage clients to import into appdata\r\n            \r\n        :param record_key: string with key for record\r\n        :param record_data: byte data for body of record\r\n        :param overwrite: [optional] boolean to overwrite existing records\r\n        :param last_modified: [optional] float to record last modified date\r\n        :param kwargs: [optional] keyword arguments from other import methods \r\n        :return: boolean indicating whether record was imported\r\n        '''\r\n        \r\n        title = '%s._import' % self.__class__.__name__\r\n    \r\n    # check overwrite\r\n        if not overwrite:\r\n            if self.exists(record_key):\r\n                return False\r\n    \r\n    # check max size\r\n        import sys\r\n        record_max = self.fields.metadata['record_max_bytes']\r\n        record_size = sys.getsizeof(record_data)\r\n        error_prefix = '%s(record_key=\"%s\", record_data=b\"...\")' % (title, record_key)\r\n        if record_size > record_max:\r\n            raise ValueError('%s exceeds maximum record data size of %s bytes.' % (error_prefix, record_max))\r\n    \r\n    # TODO: apply session upload for files greater than record_max\r\n            \r\n    # construct upload kwargs\r\n        upload_kwargs = {\r\n            'f': record_data,\r\n            'path': '/%s' % record_key,\r\n            'mute': True,\r\n            'mode': self.objects.WriteMode.overwrite\r\n        }\r\n    \r\n    # modify file time\r\n        import re\r\n        if re.search('\\\\.drep$', record_key):\r\n            from labpack.records.time import labDT\r\n            drep_time = labDT.fromEpoch(1)\r\n            upload_kwargs['client_modified'] = drep_time\r\n        elif last_modified:\r\n            from labpack.records.time import labDT\r\n            mod_time = labDT.fromEpoch(last_modified)\r\n            upload_kwargs['client_modified'] = mod_time\r\n    \r\n    # send upload request\r\n        try:\r\n            self.dropbox.files_upload(**upload_kwargs)\r\n        except:\r\n            raise DropboxConnectionError(title)\r\n        \r\n        return True", "response": "a helper method for other storage clients to import into appdata"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _walk(self, root_path=''):\r\n        ''' an iterator method which walks the file structure of the dropbox collection '''\r\n        title = '%s._walk' % self.__class__.__name__\r\n        if root_path:\r\n            root_path = '/%s' % root_path\r\n        try:\r\n            response = self.dropbox.files_list_folder(path=root_path, recursive=True)\r\n            for record in response.entries:\r\n                if not isinstance(record, self.objects.FileMetadata):\r\n                    continue\r\n                yield record.path_display[1:]\r\n            if response.has_more:\r\n                while response.has_more:\r\n                    response = self.dropbox.files_list_folder_continue(response.cursor)\r\n                    for record in response.entries:\r\n                        if not isinstance(record, self.objects.FileMetadata):\r\n                            continue\r\n                        yield record.path_display[1:]\r\n        except:\r\n            raise DropboxConnectionError(title)", "response": "an iterator method which walks the file structure of the dropbox collection"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save(self, record_key, record_data, overwrite=True, secret_key=''):\r\n\r\n        ''' \r\n            a method to create a record in the collection folder\r\n\r\n        :param record_key: string with name to assign to record (see NOTES below)\r\n        :param record_data: byte data for record body\r\n        :param overwrite: [optional] boolean to overwrite records with same name\r\n        :param secret_key: [optional] string with key to encrypt data\r\n        :return: string with name of record\r\n\r\n        NOTE:   record_key may only contain alphanumeric, /, _, . or -\r\n                characters and may not begin with the . or / character.\r\n\r\n        NOTE:   using one or more / characters splits the key into\r\n                separate segments. these segments will appear as a\r\n                sub directories inside the record collection and each\r\n                segment is used as a separate index for that record\r\n                when using the list method\r\n                eg. lab/unittests/1473719695.2165067.json is indexed:\r\n                [ 'lab', 'unittests', '1473719695.2165067', '.json' ]\r\n        '''\r\n\r\n        title = '%s.save' % self.__class__.__name__\r\n            \r\n    # validate inputs\r\n        input_fields = {\r\n            'record_key': record_key,\r\n            'secret_key': secret_key\r\n        }\r\n        for key, value in input_fields.items():\r\n            if value:\r\n                object_title = '%s(%s=%s)' % (title, key, str(value))\r\n                self.fields.validate(value, '.%s' % key, object_title)\r\n    \r\n    # validate byte data\r\n        if not isinstance(record_data, bytes):\r\n            raise ValueError('%s(record_data=b\"...\") must be byte data.' % title)\r\n        \r\n    # construct and validate file path\r\n        file_root, file_name = os.path.split(record_key)\r\n        self.fields.validate(file_name, '.record_key_comp')\r\n        while file_root:\r\n            file_root, path_node = os.path.split(file_root)\r\n            self.fields.validate(path_node, '.record_key_comp')\r\n\r\n    # check overwrite exception\r\n        if not overwrite:\r\n            if self.exists(record_key):\r\n                raise Exception('%s(record_key=\"%s\") already exists. To overwrite, set overwrite=True' % (title, record_key))\r\n    \r\n    # check size of file\r\n        import sys\r\n        record_optimal = self.fields.metadata['record_optimal_bytes']\r\n        record_max = self.fields.metadata['record_max_bytes']\r\n        record_size = sys.getsizeof(record_data)\r\n        error_prefix = '%s(record_key=\"%s\", record_data=b\"...\")' % (title, record_key)\r\n        if record_size > record_max:\r\n            raise ValueError('%s exceeds maximum record data size of %s bytes.' % (error_prefix, record_max))\r\n        elif record_size > record_optimal:\r\n            print('[WARNING] %s exceeds optimal record data size of %s bytes.' % (error_prefix, record_optimal))\r\n    \r\n    # TODO add upload session for support of files over 150MB\r\n    # http://dropbox-sdk-python.readthedocs.io/en/latest/moduledoc.html#dropbox.dropbox.Dropbox.files_upload_session_start\r\n            \r\n    # encrypt data\r\n        if secret_key:\r\n            from labpack.encryption import cryptolab\r\n            record_data, secret_key = cryptolab.encrypt(record_data, secret_key)\r\n    \r\n    # construct upload kwargs\r\n        upload_kwargs = {\r\n            'f': record_data,\r\n            'path': '/%s' % record_key,\r\n            'mute': True,\r\n            'mode': self.objects.WriteMode.overwrite\r\n        }\r\n    \r\n    # modify file time\r\n        import re\r\n        if re.search('\\\\.drep$', file_name):\r\n            from labpack.records.time import labDT\r\n            drep_time = labDT.fromEpoch(1)\r\n            upload_kwargs['client_modified'] = drep_time\r\n    \r\n    # send upload request\r\n        try:\r\n            self.dropbox.files_upload(**upload_kwargs)\r\n        except:\r\n            raise DropboxConnectionError(title)\r\n        \r\n        return record_key", "response": "a method to create a record in the collection"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove(self):\r\n        \r\n        ''' \r\n            a method to remove all records in the collection\r\n\r\n        NOTE:   this method removes all the files in the collection, but the\r\n                collection folder itself created by oauth2 cannot be removed.\r\n                only the user can remove the app folder\r\n                \r\n        :return: string with confirmation of deletion\r\n        '''\r\n\r\n        title = '%s.remove' % self.__class__.__name__\r\n    \r\n    # get contents in root\r\n        try:\r\n            response = self.dropbox.files_list_folder(path='')\r\n        except:\r\n            raise DropboxConnectionError(title)\r\n\r\n    # populate delete list\r\n        delete_list = []\r\n        for file in response.entries:\r\n            delete_list.append(self.objects.DeleteArg(path=file.path_display))\r\n\r\n    # continue retrieval if folder is large\r\n        if response.has_more:\r\n            try:\r\n                while response.has_more:\r\n                    response = self.dropbox.files_list_folder_continue(response.cursor)\r\n                    for file in response.entries:\r\n                        delete_list.append(self.objects.DeleteArg(path=file.path_display))\r\n            except:\r\n                raise DropboxConnectionError(title)\r\n\r\n    # send batch delete request\r\n        try:\r\n            self.dropbox.files_delete_batch(delete_list)\r\n        except:\r\n            raise DropboxConnectionError(title)\r\n    \r\n    # return outcome\r\n        insert = 'collection'\r\n        if self.collection_name:\r\n            insert = self.collection_name\r\n        exit_msg = 'Contents of %s will been removed from Dropbox.' % insert\r\n        return exit_msg", "response": "a method to remove all records in the collection"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _read_stdin():\n    line = sys.stdin.readline()\n    while line:\n        yield line\n        line = sys.stdin.readline()", "response": "Generator for reading from standard input in nonblocking mode."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_line(line):\n    line, timestamp = line.rsplit(\",\", 1)\n    line, command = line.rsplit(\",\", 1)\n    path, username = line.rsplit(\",\", 1)\n\n    return {\n        \"timestamp\": timestamp.strip(),\n        \"command\": command.strip(),\n        \"username\": username.strip(),\n        \"path\": path,\n    }", "response": "Convert one line from the extended log to dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process_log(file_iterator):\n    for line in file_iterator:\n        if \",\" not in line:\n            continue\n\n        parsed = _parse_line(line)\n\n        if not parsed[\"command\"].upper() in [\"DELE\", \"DEL\"]:\n            continue\n\n        # don't react to anything else, than trigger in form of deleted\n        # \"lock\" file\n        if os.path.basename(parsed[\"path\"]) != settings.LOCK_FILENAME:\n            continue\n\n        # react only to lock file in in home directory\n        dir_name = os.path.dirname(parsed[\"path\"])\n        if settings.LOCK_ONLY_IN_HOME:\n            if dir_name != settings.DATA_PATH + parsed[\"username\"]:\n                continue\n\n        # deleted user\n        if not os.path.exists(os.path.dirname(parsed[\"path\"])):\n            continue\n\n        # old record, which doesn't need to be parsed again\n        if os.path.exists(parsed[\"path\"]):\n            continue\n\n        logger.info(\n            \"Request for processing from user '%s'.\" % parsed[\"username\"]\n        )\n\n        yield process_import_request(\n            username=parsed[\"username\"],\n            path=os.path.dirname(parsed[\"path\"]),\n            timestamp=parsed[\"timestamp\"],\n            logger_handler=logger\n        )", "response": "Process the extended ProFTPD log."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening `filename` and start processing it line by line. If `filename` is none, process lines from `stdin`.", "response": "def main(filename):\n    \"\"\"\n    Open `filename` and start processing it line by line. If `filename` is\n    none, process lines from `stdin`.\n    \"\"\"\n    if filename:\n        if not os.path.exists(filename):\n            logger.error(\"'%s' doesn't exists!\" % filename)\n            sys.stderr.write(\"'%s' doesn't exists!\\n\" % filename)\n            sys.exit(1)\n\n        logger.info(\"Processing '%s'\" % filename)\n        for ir in process_log(sh.tail(\"-f\", filename, _iter=True)):\n            print ir\n    else:\n        logger.info(\"Processing stdin.\")\n        for ir in process_log(_read_stdin()):\n            print ir"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninvoke the serializer These are common things for all serializers. Mostly, stuff to do with managing headers. The data passed in may not be reliable for much of anything. Conditionally, set the Content-Type header unless it has already been set.", "response": "def serialize(self, data):\n        \"\"\" Invoke the serializer\n\n        These are common things for all serializers. Mostly,\n        stuff to do with managing headers. The data passed\n        in may not be reliable for much of anything.\n\n        Conditionally, set the Content-Type header unless it\n        has already been set.\n        \"\"\"\n\n        if not self.resp.content_type:\n            self.resp.set_header('Content-Type', getattr(self, 'MIMETYPE'))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef many_init(cls, *args, **kwargs):\n        list_kwargs = {'child_relation': cls(*args, **kwargs)}\n        for key in kwargs.keys():\n            if key in MANY_RELATION_KWARGS:\n                list_kwargs[key] = kwargs[key]\n        return ManyRelatedField(**list_kwargs)", "response": "This method handles creating a parent ManyRelatedField when the many = True keyword argument is passed."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the object corresponding to a matched URL.", "response": "def get_object(self, view_name, view_args, view_kwargs):\n        \"\"\"\n        Return the object corresponding to a matched URL.\n\n        Takes the matched URL conf arguments, and should return an\n        object instance, or raise an `ObjectDoesNotExist` exception.\n        \"\"\"\n        lookup_value = view_kwargs[self.lookup_url_kwarg]\n        lookup_kwargs = {self.lookup_field: lookup_value}\n        return self.get_queryset().get(**lookup_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_url(self, obj, view_name, request, format):\n        # Unsaved objects will not yet have a valid URL.\n        if hasattr(obj, 'pk') and obj.pk is None:\n            return None\n\n        lookup_value = getattr(obj, self.lookup_field)\n        kwargs = {self.lookup_url_kwarg: lookup_value}\n        return self.reverse(view_name, kwargs=kwargs, request=request, format=format)", "response": "Given an object return the URL that hyperlinks to the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint all the file data to the output", "response": "def printData(self, output = sys.stdout):\n\t\t\"\"\"Output all the file data to be written to any writable output\"\"\"\n\t\tself.printDatum(\"Name          : \", self.fileName, output)\n\t\tself.printDatum(\"Author        : \", self.author, output)\n\t\tself.printDatum(\"Repository    : \", self.repository, output)\n\t\tself.printDatum(\"Category      : \", self.category, output)\n\t\tself.printDatum(\"Downloads     : \", self.downloads, output)\n\t\tself.printDatum(\"Date Uploaded : \", self.fileDate, output)\n\t\tself.printDatum(\"File Size     : \", self.fileSize, output)\n\t\tself.printDatum(\"Documentation : \", self.documentation, output)\n\t\tself.printDatum(\"Source Code   : \", self.sourceCode, output)\n\t\tself.printDatum(\"Description   : \", self.description, output)\n#\t\tprint(\"\\n\", output)\n\t\tprint >> output, \"\\n\\n\""}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nraises an error if the nested serializer does not support writable nested fields.", "response": "def raise_errors_on_nested_writes(method_name, serializer, validated_data):\n    \"\"\"\n    Give explicit errors when users attempt to pass writable nested data.\n\n    If we don't do this explicitly they'd get a less helpful error when\n    calling `.save()` on the serializer.\n\n    We don't *automatically* support these sorts of nested writes because\n    there are too many ambiguities to define a default behavior.\n\n    Eg. Suppose we have a `UserSerializer` with a nested profile. How should\n    we handle the case of an update, where the `profile` relationship does\n    not exist? Any of the following might be valid:\n\n    * Raise an application error.\n    * Silently ignore the nested part of the update.\n    * Automatically create a profile instance.\n    \"\"\"\n\n    # Ensure we don't have a writable nested field. For example:\n    #\n    # class UserSerializer(ModelSerializer):\n    #     ...\n    #     profile = ProfileSerializer()\n    assert not any(\n        isinstance(field, BaseSerializer) and\n        (key in validated_data) and\n        isinstance(validated_data[key], (list, dict))\n        for key, field in serializer.fields.items()\n    ), (\n        'The `.{method_name}()` method does not support writable nested'\n        'fields by default.\\nWrite an explicit `.{method_name}()` method for '\n        'serializer `{module}.{class_name}`, or set `read_only=True` on '\n        'nested serializer fields.'.format(\n            method_name=method_name,\n            module=serializer.__class__.__module__,\n            class_name=serializer.__class__.__name__\n        )\n    )\n\n    # Ensure we don't have a writable dotted-source field. For example:\n    #\n    # class UserSerializer(ModelSerializer):\n    #     ...\n    #     address = serializer.CharField('profile.address')\n    assert not any(\n        '.' in field.source and\n        (key in validated_data) and\n        isinstance(validated_data[key], (list, dict))\n        for key, field in serializer.fields.items()\n    ), (\n        'The `.{method_name}()` method does not support writable dotted-source '\n        'fields by default.\\nWrite an explicit `.{method_name}()` method for '\n        'serializer `{module}.{class_name}`, or set `read_only=True` on '\n        'dotted-source serializer fields.'.format(\n            method_name=method_name,\n            module=serializer.__class__.__module__,\n            class_name=serializer.__class__.__name__\n        )\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef many_init(cls, *args, **kwargs):\n        allow_empty = kwargs.pop('allow_empty', None)\n        child_serializer = cls(*args, **kwargs)\n        list_kwargs = {\n            'child': child_serializer,\n        }\n        if allow_empty is not None:\n            list_kwargs['allow_empty'] = allow_empty\n        list_kwargs.update({\n            key: value for key, value in kwargs.items()\n            if key in LIST_SERIALIZER_KWARGS\n        })\n        meta = getattr(cls, 'Meta', None)\n        list_serializer_class = getattr(meta, 'list_serializer_class', ListSerializer)\n        return list_serializer_class(*args, **list_kwargs)", "response": "This method is used to customize the creation of a ListSerializer class when many = True is used."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_value(self, dictionary):\n        # We override the default field access in order to support\n        # lists in HTML forms.\n        if html.is_html_input(dictionary):\n            return html.parse_html_list(dictionary, prefix=self.field_name)\n        return dictionary.get(self.field_name, empty)", "response": "Given the input dictionary return the field value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_validation(self, data=empty):\n        (is_empty_value, data) = self.validate_empty_values(data)\n        if is_empty_value:\n            return data\n\n        value = self.to_internal_value(data)\n        try:\n            self.run_validators(value)\n            value = self.validate(value)\n            assert value is not None, '.validate() should return the validated data'\n        except (ValidationError, DjangoValidationError) as exc:\n            raise ValidationError(detail=get_validation_error_detail(exc))\n\n        return value", "response": "Run the validation on the data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_internal_value(self, data):\n        if html.is_html_input(data):\n            data = html.parse_html_list(data)\n\n        if not isinstance(data, list):\n            message = self.error_messages['not_a_list'].format(\n                input_type=type(data).__name__\n            )\n            raise ValidationError({\n                api_settings.NON_FIELD_ERRORS_KEY: [message]\n            })\n\n        if not self.allow_empty and len(data) == 0:\n            message = self.error_messages['empty']\n            raise ValidationError({\n                api_settings.NON_FIELD_ERRORS_KEY: [message]\n            })\n\n        ret = []\n        errors = []\n\n        for item in data:\n            try:\n                validated = self.child.run_validation(item)\n            except ValidationError as exc:\n                errors.append(exc.detail)\n            else:\n                ret.append(validated)\n                errors.append({})\n\n        if any(errors):\n            raise ValidationError(errors)\n\n        return ret", "response": "Converts a list of data into a list of internal values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave and return a list of object instances.", "response": "def save(self, **kwargs):\n        \"\"\"\n        Save and return a list of object instances.\n        \"\"\"\n        # Guard against incorrect use of `serializer.save(commit=False)`\n        assert 'commit' not in kwargs, (\n            \"'commit' is not a valid keyword argument to the 'save()' method. \"\n            \"If you need to access data before committing to the database then \"\n            \"inspect 'serializer.validated_data' instead. \"\n            \"You can also pass additional keyword arguments to 'save()' if you \"\n            \"need to set extra attributes on the saved model instance. \"\n            \"For example: 'serializer.save(owner=request.user)'.'\"\n        )\n\n        validated_data = [\n            dict(list(attrs.items()) + list(kwargs.items()))\n            for attrs in self.validated_data\n        ]\n\n        if self.instance is not None:\n            self.instance = self.update(self.instance, validated_data)\n            assert self.instance is not None, (\n                '`update()` did not return an object instance.'\n            )\n        else:\n            self.instance = self.create(validated_data)\n            assert self.instance is not None, (\n                '`create()` did not return an object instance.'\n            )\n\n        return self.instance"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_field_names(self, declared_fields, info):\n        fields = getattr(self.Meta, 'fields', None)\n        exclude = getattr(self.Meta, 'exclude', None)\n\n        if fields and fields != ALL_FIELDS and not isinstance(fields, (list, tuple)):\n            raise TypeError(\n                'The `fields` option must be a list or tuple or \"__all__\". '\n                'Got %s.' % type(fields).__name__\n            )\n\n        if exclude and not isinstance(exclude, (list, tuple)):\n            raise TypeError(\n                'The `exclude` option must be a list or tuple. Got %s.' %\n                type(exclude).__name__\n            )\n\n        assert not (fields and exclude), (\n            \"Cannot set both 'fields' and 'exclude' options on \"\n            \"serializer {serializer_class}.\".format(\n                serializer_class=self.__class__.__name__\n            )\n        )\n\n        if fields is None and exclude is None:\n            warnings.warn(\n                \"Creating a ModelSerializer without either the 'fields' \"\n                \"attribute or the 'exclude' attribute is pending deprecation \"\n                \"since 3.3.0. Add an explicit fields = '__all__' to the \"\n                \"{serializer_class} serializer.\".format(\n                    serializer_class=self.__class__.__name__\n                ),\n                PendingDeprecationWarning\n            )\n\n        if fields == ALL_FIELDS:\n            fields = None\n\n        if fields is not None:\n            # Ensure that all declared fields have also been included in the\n            # `Meta.fields` option.\n\n            # Do not require any fields that are declared a parent class,\n            # in order to allow serializer subclasses to only include\n            # a subset of fields.\n            required_field_names = set(declared_fields)\n            for cls in self.__class__.__bases__:\n                required_field_names -= set(getattr(cls, '_declared_fields', []))\n\n            for field_name in required_field_names:\n                assert field_name in fields, (\n                    \"The field '{field_name}' was declared on serializer \"\n                    \"{serializer_class}, but has not been included in the \"\n                    \"'fields' option.\".format(\n                        field_name=field_name,\n                        serializer_class=self.__class__.__name__\n                    )\n                )\n            return fields\n\n        # Use the default set of field names if `Meta.fields` is not specified.\n        fields = self.get_default_field_names(declared_fields, info)\n\n        if exclude is not None:\n            # If `Meta.exclude` is included, then remove those fields.\n            for field_name in exclude:\n                assert field_name in fields, (\n                    \"The field '{field_name}' was included on serializer \"\n                    \"{serializer_class} in the 'exclude' option, but does \"\n                    \"not match any model field.\".format(\n                        field_name=field_name,\n                        serializer_class=self.__class__.__name__\n                    )\n                )\n                fields.remove(field_name)\n\n        return fields", "response": "Returns the list of all field names that should be created when instantiating this serializer class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_default_field_names(self, declared_fields, model_info):\n        return (\n            [model_info.pk.name] +\n            list(declared_fields.keys()) +\n            list(model_info.fields.keys()) +\n            list(model_info.forward_relations.keys())\n        )", "response": "Return the default list of field names that will be used if Meta. fields option is not specified."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a serializer field with the given name.", "response": "def build_field(self, field_name, info, model_class, nested_depth):\n        \"\"\"\n        Return a two tuple of (cls, kwargs) to build a serializer field with.\n        \"\"\"\n        if field_name in info.fields_and_pk:\n            model_field = info.fields_and_pk[field_name]\n            return self.build_standard_field(field_name, model_field)\n\n        elif field_name in info.relations:\n            relation_info = info.relations[field_name]\n            if not nested_depth:\n                return self.build_relational_field(field_name, relation_info)\n            else:\n                return self.build_nested_field(field_name, relation_info, nested_depth)\n\n        elif hasattr(model_class, field_name):\n            return self.build_property_field(field_name, model_class)\n\n        elif field_name == self.url_field_name:\n            return self.build_url_field(field_name, model_class)\n\n        return self.build_unknown_field(field_name, model_class)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_standard_field(self, field_name, model_field):\n        field_mapping = ClassLookupDict(self.serializer_field_mapping)\n\n        field_class = field_mapping[model_field]\n        field_kwargs = get_field_kwargs(field_name, model_field)\n\n        if 'choices' in field_kwargs:\n            # Fields with choices get coerced into `ChoiceField`\n            # instead of using their regular typed field.\n            field_class = self.serializer_choice_field\n            # Some model fields may introduce kwargs that would not be valid\n            # for the choice field. We need to strip these out.\n            # Eg. models.DecimalField(max_digits=3, decimal_places=1, choices=DECIMAL_CHOICES)\n            valid_kwargs = set((\n                'read_only', 'write_only',\n                'required', 'default', 'initial', 'source',\n                'label', 'help_text', 'style',\n                'error_messages', 'validators', 'allow_null', 'allow_blank',\n                'choices'\n            ))\n            for key in list(field_kwargs.keys()):\n                if key not in valid_kwargs:\n                    field_kwargs.pop(key)\n\n        if not issubclass(field_class, ModelField):\n            # `model_field` is only valid for the fallback case of\n            # `ModelField`, which is used when no other typed field\n            # matched to the model field.\n            field_kwargs.pop('model_field', None)\n\n        if not issubclass(field_class, CharField) and not issubclass(field_class, ChoiceField):\n            # `allow_blank` is only valid for textual fields.\n            field_kwargs.pop('allow_blank', None)\n\n        if postgres_fields and isinstance(model_field, postgres_fields.ArrayField):\n            # Populate the `child` argument on `ListField` instances generated\n            # for the PostgrSQL specfic `ArrayField`.\n            child_model_field = model_field.base_field\n            child_field_class, child_field_kwargs = self.build_standard_field(\n                'child', child_model_field\n            )\n            field_kwargs['child'] = child_field_class(**child_field_kwargs)\n\n        return field_class, field_kwargs", "response": "Builds a standard field for the given field_name and model_field."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_relational_field(self, field_name, relation_info):\n        field_class = self.serializer_related_field\n        field_kwargs = get_relation_kwargs(field_name, relation_info)\n\n        to_field = field_kwargs.pop('to_field', None)\n        if to_field and not relation_info.related_model._meta.get_field(to_field).primary_key:\n            field_kwargs['slug_field'] = to_field\n            field_class = self.serializer_related_to_field\n\n        # `view_name` is only valid for hyperlinked relationships.\n        if not issubclass(field_class, HyperlinkedRelatedField):\n            field_kwargs.pop('view_name', None)\n\n        return field_class, field_kwargs", "response": "Build the relational field for forward and reverse relationships."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_url_field(self, field_name, model_class):\n        field_class = self.serializer_url_field\n        field_kwargs = get_url_kwargs(model_class)\n\n        return field_class, field_kwargs", "response": "Create a field representing the object s own URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nincludes any extra keyword arguments that have been included for this field.", "response": "def include_extra_kwargs(self, kwargs, extra_kwargs):\n        \"\"\"\n        Include any 'extra_kwargs' that have been included for this field,\n        possibly removing any incompatible existing keyword arguments.\n        \"\"\"\n        if extra_kwargs.get('read_only', False):\n            for attr in [\n                'required', 'default', 'allow_blank', 'allow_null',\n                'min_length', 'max_length', 'min_value', 'max_value',\n                'validators', 'queryset'\n            ]:\n                kwargs.pop(attr, None)\n\n        if extra_kwargs.get('default') and kwargs.get('required') is False:\n            kwargs.pop('required')\n\n        if extra_kwargs.get('read_only', kwargs.get('read_only', False)):\n            extra_kwargs.pop('required', None)  # Read only fields should always omit the 'required' argument.\n\n        kwargs.update(extra_kwargs)\n\n        return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_extra_kwargs(self):\n        extra_kwargs = getattr(self.Meta, 'extra_kwargs', {})\n\n        read_only_fields = getattr(self.Meta, 'read_only_fields', None)\n        if read_only_fields is not None:\n            for field_name in read_only_fields:\n                kwargs = extra_kwargs.get(field_name, {})\n                kwargs['read_only'] = True\n                extra_kwargs[field_name] = kwargs\n\n        return extra_kwargs", "response": "Return a dictionary mapping field names to a dictionary of additional keyword arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns any extra keyword arguments that need to be included as a tuple of extra keyword arguments for uniqueness constraints on the model.", "response": "def get_uniqueness_extra_kwargs(self, field_names, declared_fields, extra_kwargs):\n        \"\"\"\n        Return any additional field options that need to be included as a\n        result of uniqueness constraints on the model. This is returned as\n        a two-tuple of:\n\n        ('dict of updated extra kwargs', 'mapping of hidden fields')\n        \"\"\"\n        model = getattr(self.Meta, 'model')\n        model_fields = self._get_model_fields(\n            field_names, declared_fields, extra_kwargs\n        )\n\n        # Determine if we need any additional `HiddenField` or extra keyword\n        # arguments to deal with `unique_for` dates that are required to\n        # be in the input data in order to validate it.\n        unique_constraint_names = set()\n\n        for model_field in model_fields.values():\n            # Include each of the `unique_for_*` field names.\n            unique_constraint_names |= {model_field.unique_for_date, model_field.unique_for_month,\n                                        model_field.unique_for_year}\n\n        unique_constraint_names -= {None}\n\n        # Include each of the `unique_together` field names,\n        # so long as all the field names are included on the serializer.\n        for parent_class in [model] + list(model._meta.parents.keys()):\n            for unique_together_list in parent_class._meta.unique_together:\n                if set(field_names).issuperset(set(unique_together_list)):\n                    unique_constraint_names |= set(unique_together_list)\n\n        # Now we have all the field names that have uniqueness constraints\n        # applied, we can add the extra 'required=...' or 'default=...'\n        # arguments that are appropriate to these fields, or add a `HiddenField` for it.\n        hidden_fields = {}\n        uniqueness_extra_kwargs = {}\n\n        for unique_constraint_name in unique_constraint_names:\n            # Get the model field that is referred too.\n            unique_constraint_field = model._meta.get_field(unique_constraint_name)\n\n            if getattr(unique_constraint_field, 'auto_now_add', None):\n                default = CreateOnlyDefault(timezone.now)\n            elif getattr(unique_constraint_field, 'auto_now', None):\n                default = timezone.now\n            elif unique_constraint_field.has_default():\n                default = unique_constraint_field.default\n            else:\n                default = empty\n\n            if unique_constraint_name in model_fields:\n                # The corresponding field is present in the serializer\n                if default is empty:\n                    uniqueness_extra_kwargs[unique_constraint_name] = {'required': True}\n                else:\n                    uniqueness_extra_kwargs[unique_constraint_name] = {'default': default}\n            elif default is not empty:\n                # The corresponding field is not present in the,\n                # serializer. We have a default to use for it, so\n                # add in a hidden field that populates it.\n                hidden_fields[unique_constraint_name] = HiddenField(default=default)\n\n        # Update `extra_kwargs` with any new options.\n        for key, value in uniqueness_extra_kwargs.items():\n            if key in extra_kwargs:\n                extra_kwargs[key].update(value)\n            else:\n                extra_kwargs[key] = value\n\n        return extra_kwargs, hidden_fields"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn all the model fields that are being mapped to by fields on the serializer class.", "response": "def _get_model_fields(self, field_names, declared_fields, extra_kwargs):\n        \"\"\"\n        Returns all the model fields that are being mapped to by fields\n        on the serializer class.\n        Returned as a dict of 'model field name' -> 'model field'.\n        Used internally by `get_uniqueness_field_options`.\n        \"\"\"\n        model = getattr(self.Meta, 'model')\n        model_fields = {}\n\n        for field_name in field_names:\n            if field_name in declared_fields:\n                # If the field is declared on the serializer\n                field = declared_fields[field_name]\n                source = field.source or field_name\n            else:\n                try:\n                    source = extra_kwargs[field_name]['source']\n                except KeyError:\n                    source = field_name\n\n            if '.' in source or source == '*':\n                # Model fields will always have a simple source mapping,\n                # they can't be nested attribute lookups.\n                continue\n\n            try:\n                field = model._meta.get_field(source)\n                if isinstance(field, DjangoModelField):\n                    model_fields[source] = field\n            except FieldDoesNotExist:\n                pass\n\n        return model_fields"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_validators(self):\n        # If the validators have been declared explicitly then use that.\n        validators = getattr(getattr(self, 'Meta', None), 'validators', None)\n        if validators is not None:\n            return validators[:]\n\n        # Otherwise use the default set of validators.\n        return (\n            self.get_unique_together_validators() +\n            self.get_unique_for_date_validators()\n        )", "response": "Determines the set of validators to use when instantiating serializer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_unique_together_validators(self):\n        model_class_inheritance_tree = (\n            [self.Meta.model] +\n            list(self.Meta.model._meta.parents.keys())\n        )\n\n        # The field names we're passing though here only include fields\n        # which may map onto a model field. Any dotted field name lookups\n        # cannot map to a field, and must be a traversal, so we're not\n        # including those.\n        field_names = {\n            field.source for field in self.fields.values()\n            if (field.source != '*') and ('.' not in field.source)\n        }\n\n        # Note that we make sure to check `unique_together` both on the\n        # base model class, but also on any parent classes.\n        validators = []\n        for parent_class in model_class_inheritance_tree:\n            for unique_together in parent_class._meta.unique_together:\n                if field_names.issuperset(set(unique_together)):\n                    validator = UniqueTogetherValidator(\n                        queryset=parent_class._default_manager,\n                        fields=unique_together\n                    )\n                    validators.append(validator)\n        return validators", "response": "Determine a default set of validators for any unique_together contraints."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_unique_for_date_validators(self):\n        info = model_meta.get_field_info(self.Meta.model)\n        default_manager = self.Meta.model._default_manager\n        field_names = [field.source for field in self.fields.values()]\n\n        validators = []\n\n        for field_name, field in info.fields_and_pk.items():\n            if field.unique_for_date and field_name in field_names:\n                validator = UniqueForDateValidator(\n                    queryset=default_manager,\n                    field=field_name,\n                    date_field=field.unique_for_date\n                )\n                validators.append(validator)\n\n            if field.unique_for_month and field_name in field_names:\n                validator = UniqueForMonthValidator(\n                    queryset=default_manager,\n                    field=field_name,\n                    date_field=field.unique_for_month\n                )\n                validators.append(validator)\n\n            if field.unique_for_year and field_name in field_names:\n                validator = UniqueForYearValidator(\n                    queryset=default_manager,\n                    field=field_name,\n                    date_field=field.unique_for_year\n                )\n                validators.append(validator)\n\n        return validators", "response": "Determines a set of validators that can be used to validate the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the default list of field names that will be used if Meta. fields option is not specified.", "response": "def get_default_field_names(self, declared_fields, model_info):\n        \"\"\"\n        Return the default list of field names that will be used if the\n        `Meta.fields` option is not specified.\n        \"\"\"\n        return (\n            [self.url_field_name] +\n            list(declared_fields.keys()) +\n            list(model_info.fields.keys()) +\n            list(model_info.forward_relations.keys())\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_nested_field(self, field_name, relation_info, nested_depth):\n        class NestedSerializer(HyperlinkedModelSerializer):\n            class Meta:\n                model = relation_info.related_model\n                depth = nested_depth - 1\n\n        field_class = NestedSerializer\n        field_kwargs = get_nested_relation_kwargs(relation_info)\n\n        return field_class, field_kwargs", "response": "Create nested fields for forward and reverse relationships."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget an absolute URL from a given one.", "response": "def get_url(self, url):\n        \"\"\"\n        Get an absolute URL from a given one.\n        \"\"\"\n        if url.startswith('/'):\n            url = '%s%s' % (self.base_url, url)\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_soup(self, *args, **kwargs):\n        return BeautifulSoup(self.get(*args, **kwargs).text)", "response": "Shortcut for get which returns a BeautifulSoup element"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_year(self, year):\n        self.year = YEARS.get(year, year)\n        data = {'idCursus': self.year}\n        soup = self.post_soup('/~etudiant/login.php', data=data)\n        return bool(soup.select('ul.rMenu-hor'))", "response": "Set the user s year."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_upgrade(self):\n        sql = text('delete from upgrade where upgrade = :upgrade')\n        db.engine.execute(\n            sct(ql, upgrade='invenio_upgrader_2015_11_12_innodb_removal'))", "response": "Implement your upgrades here."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns pre - upgrade checks.", "response": "def pre_upgrade(self):\n        \"\"\"Run pre-upgrade checks (optional).\"\"\"\n        sql = text('select 1 from upgrade where upgrade = :upgrade')\n        if not db.engine.execute(\n            sql, upgrade='invenio_upgrader_2015_11_12_innodb_removal'\n           ).fetchall():\n            warnings.warn(\"Upgrade '{}' was not applied.\".format(\n                'invenio_upgrader_2015_11_12_innodb_removal'))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding an IntEnum containing all the XTT return codes.", "response": "def _build_return_code_enum():\n    \"\"\"\n    Creates an IntEnum containing all the XTT return codes.\n\n    Finds all return codes by scanning the FFI for items whose names match\n    the pattern \"XTT_RETURN_<X>\".  The name of the result enum value is the\n    suffix \"<X>\".\n    \"\"\"\n    prefix = 'XTT_RETURN_'\n    codes = {k[len(prefix):]:v for (k, v) in vars(_lib).items() if k.startswith(prefix)}\n    return IntEnum('ReturnCode', codes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new database client", "response": "def Client(engine=\"couchbase\", host=\"\", auth=\"\", database=\"\", logger=None, verbose=True):\n  \n  \"\"\"\n  Return new database client\n\n  Arguments\n\n  engine <str> defines which engine to use, currently supports \"couchdb\" and \"couchbase\"\n  host <str|couchdb.Server> host url, when using couchdb this can also be a server instance\n  auth <str> bucket_auth for couchbase, auth for couchdb\n  database <str> database name for couchdb\n  logger <Logger> python logger instance\n  \"\"\"\n\n  if engine == \"couchbase\":\n    from twentyc.database.couchbase.client import CouchbaseClient\n    return CouchbaseClient(\n      host, bucket_auth=auth, logger=logger\n    )\n  elif engine == \"couchdb\":\n    from twentyc.database.couchdb.client import CouchDBClient\n    return CouchDBClient(\n      host, database, auth=auth, logger=logger, verbose=verbose\n    )\n  elif engine == \"dummydb\":\n    from twentyc.database.dummydb.client import DummyDBClient\n    return DummyDBClient()\n  else:\n    raise InvalidEngineException(engine)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ClientFromConfig(engine, config, database, logger=None, verbose=True):\n\n  if type(config) == list:\n    config = dict(config)\n\n  if engine == \"couchbase\":\n    return Client(\n      engine=engine,\n      host=config.get(\"host\"),\n      auth=config.get(\"bucket_%s\" % database),\n      logger=logger,\n      verbose=verbose\n    )\n  elif engine == \"couchdb\":\n   \n    if config.get(\"admin_user\") and config.get(\"admin_password\"):\n      auth = \"%s:%s\" % (config.get(\"admin_user\"), config.get(\"admin_password\"))\n    elif config.get(\"user\") and config.get(\"password\"):\n      auth = \"%s:%s\" % (config.get(\"user\"), config.get(\"password\"))\n    else:\n      auth = None\n\n    return Client(\n      engine=engine,\n      host=config.get(\"host\"),\n      auth=auth,\n      database=config.get(\"db_%s\" % database),\n      logger=logger,\n      verbose=verbose\n    )\n  elif engine == \"dummydb\":\n    return Client(\n      engine=engine\n    )\n  else:\n    raise InvalidEngineException(engine)", "response": "Return a new database client from a valid config section."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetermine & invoke the proper serializer method is used to serialize the data.", "response": "def serialize(self, data):\n        \"\"\" Determine & invoke the proper serializer method\n\n        If data is a list then the serialize_datas method will\n        be run otherwise serialize_data.\n        \"\"\"\n\n        super(Serializer, self).serialize(data)\n\n        body = {\n            'jsonapi': {\n                'version': goldman.config.JSONAPI_VERSION,\n            },\n            'links': {\n                'self': self.req.path,\n            },\n            'meta': {\n                'included_count': 0,\n                'primary_count': 0,\n                'total_primary': self.req.pages.total,\n            },\n        }\n\n        included = data['included']\n        if included:\n            body['included'] = self._serialize_datas(included)\n            body['meta']['included_count'] = len(included)\n\n        _data = data['data']\n        if isinstance(_data, list):\n            body.update({'data': self._serialize_datas(_data)})\n            body.update({'links': self._serialize_pages()})\n            body['meta']['primary_count'] = len(_data)\n        elif _data:\n            body.update({'data': self._serialize_data(_data)})\n            body['meta']['primary_count'] = 1\n        else:\n            body.update({'data': None})\n\n        self.resp.body = json.dumps(body)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _serialize_data(self, data):\n\n        rels = {}\n        rlink = rid_url(data['rtype'], data['rid'])\n\n        doc = {\n            'id': data.pop('rid'),\n            'type': data.pop('rtype'),\n            'links': {\n                'self': rlink,\n            },\n        }\n\n        for key, val in data['to_many'].items():\n            rels.update(self._serialize_to_many(key, val, rlink))\n        del data['to_many']\n\n        for key, val in data['to_one'].items():\n            rels.update(self._serialize_to_one(key, val, rlink))\n        del data['to_one']\n\n        if data:\n            doc['attributes'] = data\n        if rels:\n            doc['relationships'] = rels\n\n        return doc", "response": "Turn the data into a JSON API compliant resource object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a JSON API compliant pagination links section containing the pages used for pagination.", "response": "def _serialize_pages(self):\n        \"\"\" Return a JSON API compliant pagination links section\n\n        If the paginator has a value for a given link then this\n        method will also add the same links to the response\n        objects `link` header according to the guidance of\n        RFC 5988.\n\n        Falcon has a native add_link helper for forming the\n        `link` header according to RFC 5988.\n\n        :return:\n            dict of links used for pagination\n        \"\"\"\n\n        pages = self.req.pages.to_dict()\n        links = {}\n\n        for key, val in pages.items():\n            if val:\n                params = self.req.params\n                params.update(val)\n                links[key] = '%s?%s' % (self.req.path, urlencode(params))\n                self.resp.add_link(links[key], key)\n            else:\n                links[key] = val\n        return links"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake a to_many JSON API compliant :spec: jsonapi.org/format/#document-resource-object-relationships :param key: the string name of the relationship field :param vals: array of dict's containing `rid` & `rtype` keys for the to_many, empty array if no values, & None if the to_manys values are unknown :return: dict as documented in the spec link", "response": "def _serialize_to_many(self, key, vals, rlink):\n        \"\"\" Make a to_many JSON API compliant\n\n        :spec:\n            jsonapi.org/format/#document-resource-object-relationships\n        :param key:\n            the string name of the relationship field\n        :param vals:\n            array of dict's containing `rid` & `rtype` keys for the\n            to_many, empty array if no values, & None if the to_manys\n            values are unknown\n        :return:\n            dict as documented in the spec link\n        \"\"\"\n\n        rel = {\n            key: {\n                'data': [],\n                'links': {\n                    'related': rlink + '/' + key\n                }\n            }\n        }\n\n        try:\n            for val in vals:\n                rel[key]['data'].append({\n                    'id': val['rid'],\n                    'type': val['rtype'],\n                })\n        except TypeError:\n            del rel[key]['data']\n\n        return rel"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nserializing a to_one relationship field into a dict", "response": "def _serialize_to_one(self, key, val, rlink):\n        \"\"\" Make a to_one JSON API compliant\n\n        :spec:\n            jsonapi.org/format/#document-resource-object-relationships\n        :param key:\n            the string name of the relationship field\n        :param val:\n            dict containing `rid` & `rtype` keys for the to_one &\n            None if the to_one is null\n        :return:\n            dict as documented in the spec link\n        \"\"\"\n\n        data = None\n        if val and val['rid']:\n            data = {'id': val['rid'], 'type': val['rtype']}\n\n        return {\n            key: {\n                'data': data,\n                'links': {\n                    'related': rlink + '/' + key\n                }\n            }\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates that value is an integer.", "response": "def validate_int(value):\n    \"\"\" Integer validator \"\"\"\n\n    if value and not isinstance(value, int):\n        try:\n            int(str(value))\n        except (TypeError, ValueError):\n            raise ValidationError('not a valid number')\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_uuid(value):\n\n    if value and not isinstance(value, UUID):\n        try:\n            return UUID(str(value), version=4)\n        except (AttributeError, ValueError):\n            raise ValidationError('not a valid UUID')\n    return value", "response": "Validate that value is a valid UUID."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_namespace_url(module, version):\n    module = module.strip('/')\n\n    return '{module}/{name}'.format(\n        module=get_namespace_module_url(module),\n        name=get_namespace_file_name(module, version),\n    )", "response": "Get a BEL namespace file from Artifactory given the name and version."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_annotation_url(module, version):\n    module = module.strip('/')\n\n    return '{module}/{name}'.format(\n        module=get_annotation_module_url(module),\n        name=get_annotation_file_name(module, version),\n    )", "response": "Get a BEL annotation file from artifactory given the name and version."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a BEL knowledge file from Artifactory given the name and version.", "response": "def get_knowledge_url(module, version):\n    \"\"\"Get a BEL knowledge file from Artifactory given the name and version.\n\n    :param str module:\n    :param str version:\n    :rtype: str\n    \"\"\"\n    module = module.strip('/')\n\n    return '{module}/{name}'.format(\n        module=get_knowledge_module_url(module),\n        name=get_knowledge_file_name(module, version),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef local_path(path):\n    current = os.path.dirname(__file__)\n    root = current\n    return os.path.abspath(os.path.join(root, path))", "response": "Return the absolute path relative to the root of this project\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering all Apis Resources and Models with the application.", "response": "def _register_resources(self, api_dirs, do_checks):\n        '''Register all Apis, Resources and Models with the application.'''\n        msg = 'Looking-up for APIs in the following directories: {}'\n        log.debug(msg.format(api_dirs))\n        if do_checks:\n            check_and_load(api_dirs)\n        else:\n            msg = 'Loading module \"{}\" from directory \"{}\"'\n            for loader, mname, _ in pkgutil.walk_packages(api_dirs):\n                sys.path.append(os.path.abspath(loader.path))\n                log.debug(msg.format(mname, loader.path))\n                import_module(mname)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _mount_resources(self):\n        '''Mount all registered resources onto the application.'''\n        rules = []\n        self.callback_map = {}\n        for ep in Resource:\n            for rule, callback in ep.get_routing_tuples():\n                log.debug('Path \"{}\" mapped to \"{}\"'.format(\n                    rule.rule, rule.endpoint))\n                rules.append(rule)\n                self.callback_map[rule.endpoint] = callback\n        self.url_map = Map(rules)", "response": "Mount all registered resources onto the application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrying to dispapch the request and get the matching coroutine.", "response": "def _get_coroutine(self, request, start_response):\n        '''Try to dispapch the request and get the matching coroutine.'''\n        adapter = self.url_map.bind_to_environ(request.environ)\n        resource, kwargs = adapter.match()\n        callback = self.callback_map[resource]\n        inject_extra_args(callback, request, kwargs)\n        return callback(request, start_response, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef SetAuth(self, style, user=None, password=None):\n        '''Change auth style, return object to user.\n        '''\n        self.auth_style, self.auth_user, self.auth_pass = \\\n            style, user, password\n        return self", "response": "Change auth style return object to user.\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef AddHeader(self, header, value):\n        '''Add a header to send.\n        '''\n        self.user_headers.append((header, value))\n        return self", "response": "Add a header to send.\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __addcookies(self):\n        '''Add cookies from self.cookies to request in self.h\n        '''\n        for cname, morsel in self.cookies.items():\n            attrs = []\n            value = morsel.get('version', '')\n            if value != '' and value != '0':\n                attrs.append('$Version=%s' % value)\n            attrs.append('%s=%s' % (cname, morsel.coded_value))\n            value = morsel.get('path')\n            if value:\n                attrs.append('$Path=%s' % value)\n            value = morsel.get('domain')\n            if value:\n                attrs.append('$Domain=%s' % value)\n            self.h.putheader('Cookie', \"; \".join(attrs))", "response": "Add cookies from self. cookies to request in self. h\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a request and return the reply.", "response": "def RPC(self, url, opname, obj, replytype=None, **kw):\n        '''Send a request, return the reply.  See Send() and Recieve()\n        docstrings for details.\n        '''\n        self.Send(url, opname, obj, **kw)\n        return self.Receive(replytype, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a message to the specified URL.", "response": "def Send(self, url, opname, obj, nsdict={}, soapaction=None, wsaction=None, \n             endPointReference=None, soapheaders=(), **kw):\n        '''Send a message.  If url is None, use the value from the\n        constructor (else error). obj is the object (data) to send.\n        Data may be described with a requesttypecode keyword, the default \n        is the class's typecode (if there is one), else Any.\n\n        Try to serialize as a Struct, if this is not possible serialize an Array.  If \n        data is a sequence of built-in python data types, it will be serialized as an\n        Array, unless requesttypecode is specified.\n\n        arguments:\n            url -- \n            opname -- struct wrapper\n            obj -- python instance\n\n        key word arguments:\n            nsdict -- \n            soapaction --\n            wsaction -- WS-Address Action, goes in SOAP Header.\n            endPointReference --  set by calling party, must be an \n                EndPointReference type instance.\n            soapheaders -- list of pyobj, typically w/typecode attribute.\n                serialized in the SOAP:Header.\n            requesttypecode -- \n\n        '''\n        url = url or self.url\n        endPointReference = endPointReference or self.endPointReference\n\n        # Serialize the object.\n        d = {}\n        d.update(self.nsdict)\n        d.update(nsdict)\n\n        sw = SoapWriter(nsdict=d, header=True, outputclass=self.writerclass, \n                 encodingStyle=kw.get('encodingStyle'),)\n        \n        requesttypecode = kw.get('requesttypecode')\n        if kw.has_key('_args'): #NamedParamBinding\n            tc = requesttypecode or TC.Any(pname=opname, aslist=False)\n            sw.serialize(kw['_args'], tc)\n        elif not requesttypecode:\n            tc = getattr(obj, 'typecode', None) or TC.Any(pname=opname, aslist=False)\n            try:\n                if type(obj) in _seqtypes:\n                    obj = dict(map(lambda i: (i.typecode.pname,i), obj))\n            except AttributeError:\n                # can't do anything but serialize this in a SOAP:Array\n                tc = TC.Any(pname=opname, aslist=True)\n            else:\n                tc = TC.Any(pname=opname, aslist=False)\n\n            sw.serialize(obj, tc)\n        else:\n            sw.serialize(obj, requesttypecode)\n            \n        for i in soapheaders:\n           sw.serialize_header(i) \n            \n        # \n        # Determine the SOAP auth element.  SOAP:Header element\n        if self.auth_style & AUTH.zsibasic:\n            sw.serialize_header(_AuthHeader(self.auth_user, self.auth_pass),\n                _AuthHeader.typecode)\n\n        # \n        # Serialize WS-Address\n        if self.wsAddressURI is not None:\n            if self.soapaction and wsaction.strip('\\'\"') != self.soapaction:\n                raise WSActionException, 'soapAction(%s) and WS-Action(%s) must match'\\\n                    %(self.soapaction,wsaction)\n\n            self.address = Address(url, self.wsAddressURI)\n            self.address.setRequest(endPointReference, wsaction)\n            self.address.serialize(sw)\n\n        # \n        # WS-Security Signature Handler\n        if self.sig_handler is not None:\n            self.sig_handler.sign(sw)\n\n        scheme,netloc,path,nil,nil,nil = urlparse.urlparse(url)\n        transport = self.transport\n        if transport is None and url is not None:\n            if scheme == 'https':\n                transport = self.defaultHttpsTransport\n            elif scheme == 'http':\n                transport = self.defaultHttpTransport\n            else:\n                raise RuntimeError, 'must specify transport or url startswith https/http'\n\n        # Send the request.\n        if issubclass(transport, httplib.HTTPConnection) is False:\n            raise TypeError, 'transport must be a HTTPConnection'\n\n        soapdata = str(sw)\n        self.h = transport(netloc, None, **self.transdict)\n        self.h.connect()\n        self.SendSOAPData(soapdata, url, soapaction, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef SendSOAPDataHTTPDigestAuth(self, response, soapdata, url, request_uri, soapaction, **kw):\n        '''Resend the initial request w/http digest authorization headers.\n        The SOAP server has requested authorization.  Fetch the challenge, \n        generate the authdict for building a response.\n        '''\n        if self.trace:\n            print >>self.trace, \"------ Digest Auth Header\"\n        url = url or self.url\n        if response.status != 401:\n            raise RuntimeError, 'Expecting HTTP 401 response.'\n        if self.auth_style != AUTH.httpdigest:\n            raise RuntimeError,\\\n                'Auth style(%d) does not support requested digest authorization.' %self.auth_style\n\n        from pyremotevbox.ZSI.digest_auth import fetch_challenge,\\\n            generate_response,\\\n            build_authorization_arg,\\\n            dict_fetch\n\n        chaldict = fetch_challenge( response.getheader('www-authenticate') )\n        if dict_fetch(chaldict,'challenge','').lower() == 'digest' and \\\n            dict_fetch(chaldict,'nonce',None) and \\\n            dict_fetch(chaldict,'realm',None) and \\\n            dict_fetch(chaldict,'qop',None):\n            authdict = generate_response(chaldict,\n                request_uri, self.auth_user, self.auth_pass, method='POST')\n            headers = {\\\n                'Authorization':build_authorization_arg(authdict),\n                'Expect':'100-continue',\n            }\n            self.SendSOAPData(soapdata, url, soapaction, headers, **kw)\n            return\n\n        raise RuntimeError,\\\n            'Client expecting digest authorization challenge.'", "response": "Send the SOAP data w/ http digest authorization headers."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ReceiveRaw(self, **kw):\n        '''Read a server reply, unconverted to any format and return it.\n        '''\n        if self.data: return self.data\n        trace = self.trace\n        while 1:\n            response = self.h.getresponse()\n            self.reply_code, self.reply_msg, self.reply_headers, self.data = \\\n                response.status, response.reason, response.msg, response.read()\n            if trace:\n                print >>trace, \"_\" * 33, time.ctime(time.time()), \"RESPONSE:\"\n                for i in (self.reply_code, self.reply_msg,):\n                    print >>trace, str(i)\n                print >>trace, \"-------\"\n                print >>trace, str(self.reply_headers)\n                print >>trace, self.data\n            saved = None\n            for d in response.msg.getallmatchingheaders('set-cookie'):\n                if d[0] in [ ' ', '\\t' ]:\n                    saved += d.strip()\n                else:\n                    if saved: self.cookies.load(saved)\n                    saved = d.strip()\n            if saved: self.cookies.load(saved)\n            if response.status == 401:\n                if not callable(self.http_callbacks.get(response.status,None)):\n                    raise RuntimeError, 'HTTP Digest Authorization Failed'\n                self.http_callbacks[response.status](response)\n                continue\n            if response.status != 100: break\n\n            # The httplib doesn't understand the HTTP continuation header.\n            # Horrible internals hack to patch things up.\n            self.h._HTTPConnection__state = httplib._CS_REQ_SENT\n            self.h._HTTPConnection__response = None\n        return self.data", "response": "Read a server reply unconverted to any format and return it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ReceiveSOAP(self, readerclass=None, **kw):\n        '''Get back a SOAP message.\n        '''\n        if self.ps: return self.ps\n        if not self.IsSOAP():\n            raise TypeError(\n                'Response is \"%s\", not \"text/xml\"' % self.reply_headers.type)\n        if len(self.data) == 0:\n            raise TypeError('Received empty response')\n\n        self.ps = ParsedSoap(self.data, \n                        readerclass=readerclass or self.readerclass, \n                        encodingStyle=kw.get('encodingStyle'))\n\n        if self.sig_handler is not None:\n            self.sig_handler.verify(self.ps)\n\n        return self.ps", "response": "Get back a SOAP message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse incoming message as a fault. Raise TypeError if no fault found.", "response": "def ReceiveFault(self, **kw):\n        '''Parse incoming message as a fault. Raise TypeError if no\n        fault found.\n        '''\n        self.ReceiveSOAP(**kw)\n        if not self.ps.IsAFault():\n            raise TypeError(\"Expected SOAP Fault not found\")\n        return FaultFromFaultMessage(self.ps)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse message create Python object.", "response": "def Receive(self, replytype, **kw):\n        '''Parse message, create Python object.\n\n        KeyWord data:\n            faults   -- list of WSDL operation.fault typecodes\n            wsaction -- If using WS-Address, must specify Action value we expect to\n                receive.\n        '''\n        self.ReceiveSOAP(**kw)\n        if self.ps.IsAFault():\n            msg = FaultFromFaultMessage(self.ps)\n            raise FaultException(msg)\n\n        tc = replytype\n        if hasattr(replytype, 'typecode'):\n            tc = replytype.typecode\n\n        reply = self.ps.Parse(tc)\n        if self.address is not None:\n            self.address.checkResponse(self.ps, kw.get('wsaction'))\n        return reply"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Receive(self, replytype, **kw):\n        '''Parse message, create Python object.\n\n        KeyWord data:\n            faults   -- list of WSDL operation.fault typecodes\n            wsaction -- If using WS-Address, must specify Action value we expect to\n                receive.\n        ''' \n        self.ReceiveSOAP(**kw)\n        ps = self.ps\n        tp = _find_type(ps.body_root)\n        isarray = ((type(tp) in (tuple,list) and tp[1] == 'Array') or _find_arraytype(ps.body_root))\n        if self.typesmodule is None or isarray:\n            return _Binding.Receive(self, replytype, **kw)\n\n        if ps.IsAFault():\n            msg = FaultFromFaultMessage(ps)\n            raise FaultException(msg)\n\n        tc = replytype\n        if hasattr(replytype, 'typecode'):\n            tc = replytype.typecode\n\n        #Ignore response wrapper\n        reply = {}\n        for elt in _child_elements(ps.body_root):\n            name = str(elt.localName)\n            reply[name] = self.__parse_child(elt)\n\n        if self.address is not None:\n            self.address.checkResponse(ps, kw.get('wsaction'))\n\n        return reply", "response": "Parse message create Python object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_creds(self, req):\n\n        self._validate_auth_scheme(req)\n\n        try:\n            creds = naked(req.auth.split(' ')[1])\n            creds = b64decode(creds)\n\n            username, password = creds.split(':')\n            return username, password\n        except IndexError:\n            raise InvalidAuthSyntax(**{\n                'detail': 'You are using the Basic Authentication scheme as '\n                          'required to login but your Authorization header is '\n                          'completely missing the login credentials.',\n                'links': 'tools.ietf.org/html/rfc2617#section-2',\n            })\n        except TypeError:\n            raise InvalidAuthSyntax(**{\n                'detail': 'Our API failed to base64 decode your Basic '\n                          'Authentication login credentials in the '\n                          'Authorization header. They seem to be malformed.',\n                'links': 'tools.ietf.org/html/rfc2617#section-2',\n            })\n        except ValueError:\n            raise InvalidAuthSyntax(**{\n                'detail': 'Our API failed to identify a username & password '\n                          'in your Basic Authentication Authorization header '\n                          'after decoding them. The username or password is '\n                          'either missing or not separated by a \":\" per the '\n                          'spec. Either way the credentials are malformed.',\n                'links': 'tools.ietf.org/html/rfc2617#section-2',\n            })", "response": "Get the username & password from the Basic Authentication header."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_request(self, req, resp):  # pylint: disable=unused-argument\n\n        try:\n            creds = self._get_creds(req)\n            self.auth_creds(*creds)\n        except (AuthRejected, AuthRequired, InvalidAuthSyntax) as exc:\n            exc.headers = self._error_headers\n            if not self.optional:\n                abort(exc)", "response": "Process the request before routing it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating list of available labels.", "response": "def _update_labels(self):\n        \"\"\"Updates list of available labels.\"\"\"\n        labels = set()\n        for page in self.get_pages():\n            for label in page.labels:\n                labels.add(label)\n        to_delete = self._labels - labels\n        for label in labels:\n            self._labels.add(label)\n        for label in to_delete:\n            self._labels.discard(label)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_pages(self, label=None):\n        return (\n            page for page in sorted(\n                self._pages.values(), key=lambda i: i.created, reverse=True\n            ) if ((not label or label in page.labels) and page.visible)\n        )", "response": "Returns list of pages with specified label."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef access_token(self):\n\n        ''' a method to acquire an oauth access token '''\n\n        title = '%s.access_token' % self.__class__.__name__\n    \n    # import dependencies\n        from time import time\n        import requests\n\n    # construct request kwargs\n        request_kwargs = {\n            'url': self.token_endpoint,\n            'data': {\n                'client_id': self.client_id,\n                'client_secret': self.client_secret,\n                'grant_type': 'client_credentials'\n            }\n        }\n\n    # send request\n        try:\n            current_time = time()\n            response = requests.post(**request_kwargs)\n        except Exception:\n            if self.requests_handler:\n                request_kwargs['method'] = 'POST'\n                request_object = requests.Request(**request_kwargs)\n                return self.requests_handler(request_object)\n            else:\n                raise\n\n        response_details = self.response_handler.handle(response)\n\n        if response_details['json']:\n            self._access_token = response_details['json']['access_token']\n            expires_in = response_details['json']['expires_in']\n            self.expires_at = current_time + expires_in\n            \n        return self._access_token", "response": "a method to acquire an oauth access token"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef account_application(self, customer_ip, first_name, last_name, tax_id, date_of_birth, address_line_1, city_name, state_code, postal_code, phone_number, email_address, citizenship_country, employment_status, product_id, funding_amount, account_number, routing_number, backup_withholding=False, phone_type='mobile', accept_tcpa=False, accept_terms=True, address_line_2='', middle_name='', tax_id_type='SSN', secondary_citizenship_country='', job_title='', annual_income=0, cd_term='', funding_type='fundach', account_owner='primary', secondary_application=None):\n\n        '''\n            a method to submit application for new account\n            \n        :param customer_ip: string with ip address of applicant\n        :param first_name: string with first name of applicant\n        :param last_name: string with last name of applicant\n        :param tax_id: string with tax id number of applicant\n        :param date_of_birth: string with ISO format of date of birth of applicant\n        :param address_line_1: string with first line of street address of applicant\n        :param city_name: string with name of city of address of applicant\n        :param state_code: string with code for the state of address of applicant\n        :param postal_code: string with postal code of address of applicant\n        :param phone_number: string with phone number and area code of applicant\n        :param email_address: string with email address of applicant\n        :param citizenship_country: string with ISO 3166 alpha-3 country code of citizenship of applicant\n        :param employment_status: string with employment status of applicant\n        :param product_id: integer with id of account product to apply for\n        :param funding_amount: float with amount of dollars to initially fund account\n        :param account_number: string with pre-existing bank account number of applicant\n        :param routing_number: string with aba routing number for bank of pre-existing account of applicant\n        :param backup_withholding: [optional] boolean to indicate backup withholding on accounts of applicant\n        :param phone_type: [optional] string with type of phone of applicant\n        :param accept_tcpa: boolean to accept to be contacted by citizen one marketing on their phone number \n        :param accept_terms: boolean to accept the terms and conditions associated with new account\n        :param address_line_2: [optional] string with second line of address of applicant\n        :param middle_name: [optional] string with middle name of applicant\n        :param tax_id_type: string with type of tax id of applicant\n        :param secondary_citizenship_country: [optional] string with ISO 3166 alpha-3 country code of secondary citizenship\n        :param job_title: [optional] string with job title of applicant\n        :param annual_income: [optional] integer with dollar value of annual income of applicant \n        :param cd_term: [optional] string with term for the cd account product to apply for\n        :param funding_type: string with funding method selected by the applicant to fund new account\n        :param account_owner: string with role of applicant who owns pre-existing bank account\n        :param secondary_application: dictionary with applicant fields of secondary account holder\n        :return: dictionary with successful response details in ['json'] key\n\n        response details:\n        { \n            \"error\": \"\",\n            \"code\": 200,\n            \"method\": \"GET\",\n            \"url\": \"https://...\",\n            \"headers\": { \n                \"Location\": \"https://www.capitalone.com\"\n            },\n            \"json\": { \n                \"applicationId\": \"adfasdf812381asdf\",\n                \"applicationStatus\": \"Approved\",\n                \"applicationStatusDescription\": \"The application is approved and account is created\",\n                \"bankABANumber\": \"031176110\",\n                \"accountNumber\": \"12345678909876\"\n            }\n        }\n        '''\n    \n        title = '%s.account_application' % self.__class__.__name__\n        \n        from copy import deepcopy\n        \n    # validate general inputs\n        input_fields = {\n            'customer_ip': customer_ip,\n            'product_id': product_id,\n            'cd_term': cd_term,\n            'funding_type': funding_type,\n            'funding_amount': funding_amount,\n            'account_number': account_number,\n            'routing_number': routing_number,\n            'account_owner': account_owner,\n            'accept_terms': accept_terms,\n            'accept_tcpa': accept_tcpa,\n            'secondary_application': secondary_application\n        }\n        for key, value in input_fields.items():\n            object_title = '%s(%s=%s)' % (title, key, str(value))\n            self.fields.validate(value, '.%s' % key, object_title)\n\n    # validate applicant fields\n        app_fields = {\n            'address_line_1': address_line_1,\n            'address_line_2': address_line_2,\n            'city_name': city_name,\n            'state_code': state_code,\n            'postal_code': postal_code,\n            'first_name': first_name,\n            'middle_name': middle_name,\n            'last_name': last_name,\n            'tax_id_type': tax_id_type,\n            'tax_id': tax_id,\n            'date_of_birth': date_of_birth,\n            'email_address': email_address,\n            'backup_withholding': backup_withholding,\n            'citizenship_country': citizenship_country,\n            'secondary_citizenship_country': secondary_citizenship_country,\n            'employment_status': employment_status,\n            'job_title': job_title,\n            'annual_income': annual_income,\n            'phone_number': phone_number,\n            'phone_type': phone_type\n        }\n        for key, value in app_fields.items():\n            object_title = '%s(%s=%s)' % (title, key, str(value))\n            self.fields.validate(value, '.%s' % key, object_title)\n    \n    # construct url\n        url = self.deposits_endpoint + 'account-application'\n    \n    # construct method specific errors\n        error_map = { \n            404: 'Not Found. No products found for the provided productId.',\n            409: 'The application could not be processed due to a business error. Currently, this status is only returned when an existing Capital One customer attempts to open a new account using this API.'\n        }\n\n    # construct headers\n        headers_kwargs = {\n            'Customer-IP-Address': customer_ip\n        }\n\n    # construct applicant list\n        applicant_list = []\n        applicants = [ 'primary' ]\n        if secondary_application:\n            applicants.append('secondary')\n    \n    # iterate over applicants\n        for applicant in applicants:\n        \n        # substitute in secondary application fields\n            if applicant == 'secondary':\n                app_fields = secondary_application\n                for key, value in app_fields.items():\n                    object_title = '%s(%s=%s)' % (title, key, str(value))\n                    self.fields.validate(value, '.%s' % key, object_title)  \n\n        # construct applicant kwargs\n            applicant_kwargs = {\n                'applicantRole': applicant,\n                'firstName': app_fields['first_name'],\n                'lastName': app_fields['last_name'],\n                'homeAddress': {\n                    'addressLine1': app_fields['address_line_1'],\n                    'city': app_fields['city_name'],\n                    'postalCode': app_fields['postal_code']\n                },\n                'taxIdType': app_fields['tax_id_type'],\n                'emailAddress': app_fields['email_address'],\n                'backupWithholding': app_fields['backup_withholding'],\n                'employmentStatus': app_fields['employment_status']\n            }\n\n        # add optional middle name and second address\n            if app_fields['middle_name']:\n                applicant_kwargs['middleName'] = app_fields['middle_name']\n        \n        # add state code\n            from labpack.datasets.iso_3166_2_US import compile_map as map_3166_2\n            state_codes = map_3166_2()\n            if not app_fields['state_code'] in state_codes.keys():\n                raise ValueError('%s(state_code=%s) must be a valid 3 letter country code.' % (title, app_fields['state_code']))\n            applicant_kwargs['homeAddress']['stateCode'] = app_fields['state_code']\n        \n        # add tax id\n            if len(app_fields['tax_id']) < 10:\n                tax_id_temp = app_fields['tax_id']\n                tax_string = tax_id_temp[0:3] + '-' + tax_id[3:5] + '-' + tax_id[5:]\n            else:\n                tax_string = tax_id\n            applicant_kwargs['taxId'] = tax_string\n        \n        # add date of birth\n            if not '-' in app_fields['date_of_birth']:\n                dob_temp = app_fields['date_of_birth']\n                app_fields['date_of_birth'] = dob_temp[0:4] + '-' + dob_temp[4:6] + '-' + dob_temp[6:8]\n            if not len(app_fields['date_of_birth']) == 10:\n                raise ValueError('%s(date_of_birth=%s) must be in ISO format YYYY-MM-DD or YYYYMMDD' % (title, app_fields['date_of_birth']))\n            applicant_kwargs['dateOfBirth'] = app_fields['date_of_birth']\n        \n        # add citizenship country\n            from labpack.datasets.iso_3166 import compile_map as map_3166\n            country_codes = map_3166()\n            if not app_fields['citizenship_country'] in country_codes.keys():\n                raise ValueError('%s(citizenship_country=%s) must be a valid 3 letter country code.' % (title, app_fields['citizenship_country']))\n            applicant_kwargs['citizenshipCountry'] = app_fields['citizenship_country']\n        \n        # add secondary citizenship country\n            if app_fields['secondary_citizenship_country']:\n                if not app_fields['secondary_citizenship_country'] in country_codes.keys():\n                    raise ValueError('%s(secondary_citizenship_country=%s) must be a valid 3 letter country code.' % (title, app_fields['secondary_citizenship_country']))\n                applicant_kwargs['secondaryCitizenshipCountry'] = app_fields['secondary_citizenship_country']\n        \n        # add job title\n            if app_fields['job_title']:\n                applicant_kwargs['jobTitle'] = app_fields['job_title']\n                \n        # add annual income field\n            if app_fields['annual_income']:\n                income_category = 250000\n                income_list = [ { 50000: 25000 }, { 100000: 75000 }, { 150000: 125000 }, { 250000: 200000 } ]\n                for level in income_list:\n                    key, value = next(iter(level.items()))\n                    if app_fields['annual_income'] > int(key):\n                        continue\n                    elif int(key) != 25000:\n                        income_category = int(value)\n                        break\n                applicant_kwargs['annualIncome'] = income_category\n    \n        # add phone number fields\n            phone_kwargs = {\n                'phoneNumber': app_fields['phone_number'],\n                'acceptedTcpa': app_fields['accept_tcpa']\n            }\n            if phone_type == 'mobile':\n                applicant_kwargs['mobilePhoneNumber'] = phone_kwargs\n            elif phone_type == 'home':\n                applicant_kwargs['homePhoneNumber'] = phone_kwargs\n            elif phone_type == 'work':\n                applicant_kwargs['workPhoneNumber'] = phone_kwargs\n\n        # add applicant fields to data kwargs\n            applicant_copy = deepcopy(applicant_kwargs)\n            applicant_list.append(applicant_copy)\n    \n    # construct data fields\n        data_kwargs = {\n            'applicants': applicant_list,\n            'productId': str(product_id)\n        }\n        \n    # add cd term\n        if product_id == '3500':\n            if not cd_term:\n                raise IndexError('%s(cd_term=0) must not be empty if product_id=3500')\n            else:\n    # TODO validate cd terms in account product \n                data_kwargs['cdTerm'] = cd_term\n        \n    # add funding details\n        funding_details = {\n            'fundingType': funding_type,\n            'fundingAmount': funding_amount,\n            'externalAccountDetails': {\n                'accountNumber': account_number,\n                'bankABANumber': routing_number,\n                'accountOwnership': account_owner\n            }\n        }\n        data_kwargs['fundingDetails'] = funding_details\n    \n    # add terms and conditions\n        term_details = {\n            'acceptAccountDisclosures': accept_terms,\n            'acceptPaperlessAgreement': accept_terms,\n            'acceptFraudProtection': accept_terms\n        }\n        data_kwargs['termsAndConditions'] = term_details\n        \n    # send request\n        details = self._requests(url, method='POST', headers=headers_kwargs, data=data_kwargs, errors=error_map)\n\n        return details", "response": "This method is used to submit an application for a specific account."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a list of JSON objects into a list of model instances.", "response": "def parse_list(cls, api, json_list):\n        \"\"\"\n            Parse a list of JSON objects into\n            a result set of model instances.\n        \"\"\"\n        results = []\n        for json_obj in json_list:\n            if json_obj:\n                obj = cls.parse(api, json_obj)\n                results.append(obj)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_instructor_term_list_name(instructor_netid, year, quarter):\n    return \"{uwnetid}_{quarter}{year}\".format(\n        uwnetid=instructor_netid,\n        quarter=quarter.lower()[:2],\n        year=str(year)[-2:])", "response": "Returns the list name of UW instructor email list for the given year and quarter"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the path to the template file for the current locale.", "response": "def get_template_path(self, meta=None, **kwargs):\r\n        \"\"\"\r\n        Formats template_name_path_pattern with kwargs given.\r\n        \"\"\"\r\n        if 'template_name_suffix' not in kwargs or kwargs.get('template_name_suffix') is None:\r\n            kwargs['template_name_suffix'] = self.get_template_name_suffix()\r\n        return self.template_name_path_pattern.format(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_template_name(self, template_name_suffix=None):\r\n        if isinstance(self.object, models.Model):\r\n            meta = self.object._meta\r\n            return self.get_template_path(meta, app_label=meta.app_label, object_name=meta.object_name, template_name_suffix=template_name_suffix)\r\n        elif hasattr(self, 'model') and self.model is not None and issubclass(self.model, models.Model):\r\n            meta = self.model._meta\r\n            return self.get_template_path(meta, app_label=meta.app_label, object_name=meta.object_name, template_name_suffix=template_name_suffix)", "response": "Generates a template path name based on model and app."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_template_name(self, template_name_suffix=None):\r\n        if hasattr(self.object_list, 'model'):\r\n            meta = self.object_list.model._meta\r\n            return self.get_template_path(meta, app_label=meta.app_label, object_name=meta.object_name, template_name_suffix=template_name_suffix)", "response": "Generates a template path name based on model and app."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef threenum(h5file, var, post_col='mult'):\n    f = h5py.File(h5file, 'r')\n    d = f[var]\n    w = f[post_col]\n    s = d.chunks[0]\n\n    n = d.shape[0]\n    maxval = -np.abs(d[0])\n    minval = np.abs(d[0])\n    total = 0\n    wsum = 0\n\n    for x in range(0, n, s):\n\n        aN = ~np.logical_or(np.isnan(d[x:x+s]), np.isinf(d[x:x+s]))\n\n        d_c = d[x:x+s][aN]\n        w_c = w[x:x+s][aN]\n\n        chunk_max = np.max(d_c)\n        chunk_min = np.min(d_c)\n\n        maxval = chunk_max if chunk_max > maxval else maxval\n        minval = chunk_min if chunk_min < minval else minval\n\n        total += np.sum(w_c*d_c)\n        wsum  += np.sum(w_c)\n    f.close()\n\n    mean = total/float(wsum)\n\n    return (minval, maxval, mean)", "response": "Calculates the three number summary for a variable in a H5 file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filechunk(f, chunksize):\n    while True:\n        chunk = tuple(itertools.islice(f, chunksize))\n        if not chunk:\n            return\n        yield np.loadtxt(iter(chunk), dtype=np.float64)", "response": "Iterator that allows for piecemeal processing of a file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a list of files in plain text format into HDF5 format.", "response": "def convert_chain(\n        txtfiles,\n        headers,\n        h5file,\n        chunksize):\n    \"\"\"Converts chain in plain text format into HDF5 format.\n\n    Keyword arguments:\n    txtfiles -- list of paths to the plain text chains.\n    headers -- name of each column.\n    h5file -- where to put the resulting HDF5 file.\n    chunksize -- how large the HDF5 chunk, i.e. number of rows.\n\n    Chunking - How to pick a chunksize\n    TODO Optimal chunk size unknown, our usage make caching irrelevant, and\n    we use all read variable. Larger size should make compression more efficient,\n    and less require less IO reads. Measurements needed.\n    \"\"\"\n\n    h5 = h5py.File(h5file, 'w')\n\n    for h in headers:\n        h5.create_dataset(h,\n                          shape=(0,),\n                          maxshape=(None,),\n                          dtype=np.float64,\n                          chunks=(chunksize,),\n                          compression='gzip',\n                          shuffle=True)\n\n    for txtfile in txtfiles:\n\n        d = np.loadtxt(txtfile, dtype=np.float64)\n\n        if len(d.shape) == 1:\n            d = np.array([d])\n\n        dnrows = d.shape[0]\n\n        for pos, h in enumerate(headers):\n            x = h5[h]\n            xnrows = x.shape[0]\n            x.resize(dnrows+xnrows, axis=0)\n            x[xnrows:] = d[:,pos]\n\n    h5.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getAvailableClassesInModule(prooveModule):\n    l = tuple(x[1] for x in inspect.getmembers(prooveModule, inspect.isclass))\n    l = [x for x in l if x.__name__[0] != \"_\"]\n    return l", "response": "returns a list of all classes in the given module that do not begin with _"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of all classes in the given package", "response": "def getAvailableClassesInPackage(package):\n    \"\"\"\n    return a list of all classes in the given package\n    whose modules dont begin with '_'\n    \"\"\"\n    l = list(x[1] for x in inspect.getmembers(package, inspect.isclass))\n\n    modules = list(x[1] for x in inspect.getmembers(package, inspect.ismodule))\n    for m in modules:\n        l.extend(list(x[1] for x in inspect.getmembers(m, inspect.isclass)))\n    l = [x for x in l if x.__name__[0] != \"_\"]\n    n = 0\n    while n < len(l):\n        cls = l[n]\n        if not cls.__module__.startswith(package.__name__):\n            l.pop(n)\n            n -= 1\n        n += 1\n    return l"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getClassInPackageFromName(className, pkg):\n    # TODO: more efficiency!\n    n = getAvClassNamesInPackage(pkg)\n    i = n.index(className)\n    c = getAvailableClassesInPackage(pkg)\n    return c[i]", "response": "get a class from name within a package"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a class from name within a module", "response": "def getClassInModuleFromName(className, module):\n    \"\"\"\n    get a class from name within a module\n    \"\"\"\n    n = getAvClassNamesInModule(module)\n    i = n.index(className)\n    c = getAvailableClassesInModule(module)\n    return c[i]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_prototype(sample_dimension,\n                     parameter_kind_base='user',\n                     parameter_kind_options=[],\n                     state_stay_probabilities=[0.6, 0.6, 0.7]):\n    \"\"\"Create a prototype HTK model file using a feature file.\n    \"\"\"\n    parameter_kind = create_parameter_kind(base=parameter_kind_base,\n                                           options=parameter_kind_options)\n\n    transition = create_transition(state_stay_probabilities)\n\n    state_count = len(state_stay_probabilities)\n\n    states = []\n    for i in range(state_count):\n        state = create_gmm(np.zeros(sample_dimension),\n                           np.ones(sample_dimension),\n                           weights=None,\n                           gconsts=None)\n\n        states.append(state)\n\n    hmms = [create_hmm(states, transition)]\n    macros = [create_options(vector_size=sample_dimension,\n                             parameter_kind=parameter_kind)]\n\n    model = create_model(macros, hmms)\n\n    return model", "response": "Create a prototype HTK model file using a feature file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef map_hmms(input_model, mapping):\n\n    output_model = copy.copy(input_model)\n\n    o_hmms = []\n    for i_hmm in input_model['hmms']:\n        i_hmm_name = i_hmm['name']\n        o_hmm_names = mapping.get(i_hmm_name, [i_hmm_name])\n\n        for o_hmm_name in o_hmm_names:\n            o_hmm = copy.copy(i_hmm)\n            o_hmm['name'] = o_hmm_name\n\n            o_hmms.append(o_hmm)\n\n    output_model['hmms'] = o_hmms\n\n    return output_model", "response": "Create a new HTK HMM model given a dictionary mapping from string to list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a decorator written for a function view into a mixin for a class - based view.", "response": "def DecoratorMixin(decorator):\n    \"\"\"\n    Converts a decorator written for a function view into a mixin for a\n    class-based view.\n\n    ::\n\n        LoginRequiredMixin = DecoratorMixin(login_required)\n\n        class MyView(LoginRequiredMixin):\n            pass\n\n        class SomeView(DecoratorMixin(some_decorator),\n                       DecoratorMixin(something_else)):\n            pass\n\n    \"\"\"\n\n    class Mixin(object):\n        __doc__ = decorator.__doc__\n\n        @classmethod\n        def as_view(cls, *args, **kwargs):\n            view = super(Mixin, cls).as_view(*args, **kwargs)\n            return decorator(view)\n\n    Mixin.__name__ = str('DecoratorMixin(%s)' % decorator.__name__)\n    return Mixin"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef seq_list_nested(b, d, x=0, top_level=True):\n    '''\n    Create a nested list of iteratively increasing values.\n\n    b: branching factor\n    d: max depth\n    x: starting value (default = 0)\n    '''\n    x += 1\n\n    if d == 0:\n        ret = [x]\n    else:\n        val = x\n        ret = []\n        for i in range(b):\n            lst, x = seq_list_nested(b, d-1, x, False)\n            ret.extend(lst)\n        ret = [val, ret]\n            \n    if top_level:\n        return ret\n    else:\n        return ret, x", "response": "Create a nested list of iteratively increasing values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Opaque(uri, tc, ps, **keywords):\n    '''Resolve a URI and return its content as a string.\n    '''\n    source = urllib.urlopen(uri, **keywords)\n    enc = source.info().getencoding()\n    if enc in ['7bit', '8bit', 'binary']: return source.read()\n\n    data = StringIO.StringIO()\n    mimetools.decode(source, data, enc)\n    return data.getvalue()", "response": "Resolve a URI and return its content as a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nresolves a URI and return its content as an XML DOM.", "response": "def XML(uri, tc, ps, **keywords):\n    '''Resolve a URI and return its content as an XML DOM.\n    '''\n    source = urllib.urlopen(uri, **keywords)\n    enc = source.info().getencoding()\n    if enc in ['7bit', '8bit', 'binary']:\n        data = source\n    else:\n        data = StringIO.StringIO()\n        mimetools.decode(source, data, enc)\n        data.seek(0)\n    dom = ps.readerclass().fromStream(data)\n    return _child_elements(dom)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetSOAPPart(self):\n        '''Get the SOAP body part.\n        '''\n        head, part = self.parts[0]\n        return StringIO.StringIO(part.getvalue())", "response": "Get the SOAP body part."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the content for the bodypart identified by the uri.", "response": "def get(self, uri):\n        '''Get the content for the bodypart identified by the uri.\n        '''\n        if uri.startswith('cid:'):\n            # Content-ID, so raise exception if not found.\n            head, part = self.id_dict[uri[4:]]\n            return StringIO.StringIO(part.getvalue())\n        if self.loc_dict.has_key(uri):\n            head, part = self.loc_dict[uri]\n            return StringIO.StringIO(part.getvalue())\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads the meta data given a file_path or empty meta data", "response": "def load_from_file(cls, file_path):\n        \"\"\"Load the meta data given a file_path or empty meta data\"\"\"\n        data = None\n        if os.path.exists(file_path):\n            metadata_file = open(file_path)\n            data = json.loads(metadata_file.read())\n        return cls(initial=data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbinding metadata to an LXC and saves it", "response": "def bind_and_save(self, lxc):\n        \"\"\"Binds metadata to an LXC and saves it\"\"\"\n        bound_meta = self.bind(lxc)\n        bound_meta.save()\n        return bound_meta"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the internal list with the items from the given report.", "response": "def update(self, report):\n        \"\"\"\n        Add the items from the given report.\n        \"\"\"\n        self.tp.extend(pack_boxes(report.tp, self.title))\n        self.fp.extend(pack_boxes(report.fp, self.title))\n        self.fn.extend(pack_boxes(report.fn, self.title))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new scale report from a gold number precision recall and title.", "response": "def from_scale(cls, gold_number, precision, recall, title):\n        \"\"\"\n        deprecated, for backward compactbility\n        try to use from_score\n        \"\"\"\n        tp_count = get_numerator(recall, gold_number)\n        positive_count = get_denominator(precision, tp_count)\n        fp_count = positive_count - tp_count\n        fn_count = gold_number - tp_count\n        scale_report = cls(['tp'] * tp_count,\n                           ['fp'] * fp_count,\n                           ['fn'] * fn_count,\n                           title)\n        return scale_report"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef worker(work_unit):\n    '''Expects a WorkUnit from coordinated, obtains a config, and runs\n    traverse_extract_fetch\n\n    '''\n    if 'config' not in work_unit.spec:\n        raise coordinate.exceptions.ProgrammerError(\n            'could not run extraction without global config')\n\n    web_conf = Config()\n    unitconf = work_unit.spec['config']\n    #logger.info(unitconf)\n    with yakonfig.defaulted_config([coordinate, kvlayer, dblogger, web_conf],\n                                   config=unitconf):\n        traverse_extract_fetch(web_conf, work_unit.key)", "response": "Expects a WorkUnit from coordinated obtains a config and runs\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a config and a wukey traverse the a folders to generate queries issue them to Google fetch them and ingest them.", "response": "def traverse_extract_fetch(config, wukey, stop_after_extraction=False):\n    '''Given a config and a\n    `wukey=cbor.dumps((folder_name,subfolder_name))`, traverse the\n    folders to generate queries, issue them to Google, fetch the\n    results, and ingest them.\n\n    '''\n\n    config.kvlclient.setup_namespace({'openquery': (str,)})\n    try:\n        data = list(config.kvlclient.get('openquery', (wukey,)))\n        if data:\n            if data[0][1]:\n                logger.info('found existing query results: %r', data)\n                return\n            else:\n                config.kvlclient.delete('openquery', (wukey,))\n    except:\n        logger.error('failed to get data from existing table', exc_info=True)\n\n    fid, sid = cbor.loads(wukey)\n    tfidf = config.tfidf\n    folders = Folders(config.kvlclient)\n    fetcher = Fetcher()\n\n    ## To disable the keyword extractor model, you can uncomment out\n    ## the next three lines (`get_subfolder_queries`) and comment out\n    ## the following two lines (`extract_keyword_queries`).\n    #keyword_feature_keys = []\n    #queries = get_subfolder_queries(\n    #    config.store, config.label_store, folders, fid, sid)\n\n    queries, keyword_feature_keys, has_observations = extract_keyword_queries(\n        config.store, config.label_store, folders, fid, sid)\n\n    logger.info('Model found %d queries: %r', len(queries), queries)\n\n    if stop_after_extraction:\n        return\n\n    keywords = set()\n    for key in keyword_feature_keys:\n        ckey = cleanse(key.decode('utf8'))\n        keywords.add(ckey)\n        for part in ckey.split():\n            keywords.add(part)\n\n    #link2queries = defaultdict(set)\n    links = set()\n    logger.info('searching google for: %r', queries)\n    for q in queries:\n        for result in config.google.web_search_with_paging(q, limit=10):\n            links.add(result['link'])\n            #map(link2queries[result['link']].add, cleanse(q.decode('utf8')).split())\n            logger.info('discovered %r', result['link'])\n\n    result = None\n\n    #logger.info('got %d URLs from %d queries', len(link2queries), len(queries))\n    logger.info('got %d URLs from %d queries', len(links), len(queries))\n\n    # content_ids gets modified within the 'callback' closure\n    content_ids = []\n    #for link, queries in link2queries.items():\n\n    def callback(si, link):\n        if si is None: return\n        cid_url = hashlib.md5(str(link)).hexdigest()\n        cid = etl.interface.mk_content_id(cid_url)\n        content_ids.append(cid)\n\n        # hack alert!\n        # We currently use FCs to store subtopic text data, which\n        # means we cannot overwrite existing FCs with reckless\n        # abandon. So we adopt a heuristic: check if an FC already\n        # exists, and if it does, check if it is being used to store\n        # user data. If so, don't overwrite it and move on.\n        fc = config.store.get(cid)\n        if fc is not None and any(k.startswith('subtopic|')\n                                  for k in fc.iterkeys()):\n            logger.info('skipping ingest for %r (abs url: %r) because '\n                        'an FC with user data already exists.',\n                        cid, link)\n            return\n\n        other_features = {\n            u'keywords': StringCounter(keywords), #list(queries)),\n        }\n\n        try:\n            fc = etl.create_fc_from_html(\n                link, si.body.raw,\n                encoding=si.body.encoding or 'utf-8', tfidf=tfidf,\n                other_features=other_features,\n            )\n            if not fc:\n                logger.info('failed to get an FC, moving on')\n                return\n            logger.info('created FC for %r (abs url: %r)',\n                        cid, link)\n            config.store.put([(cid, fc)])\n        except Exception:\n            logger.info('trapped ingest failure on %r (abs url: %r)',\n                        cid, link, exc_info=True)\n\n    logger.info('FETCHING using ASYNC')\n    fetcher.get_async(islice(links, None), callback)\n\n    data = json.dumps({'content_ids': content_ids})\n    logger.info('saving %d content_ids in %d bytes on wukey %r',\n                len(content_ids), len(data), wukey)\n    config.kvlclient.put('openquery', ((wukey,), data))\n    logger.info('done saving for %r', wukey)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of queries that can be passed on to other subfolder search engines.", "response": "def get_subfolder_queries(store, label_store, folders, fid, sid):\n    '''Returns [unicode].\n\n    This returns a list of queries that can be passed on to \"other\"\n    search engines. The list of queries is derived from the subfolder\n    identified by ``fid/sid``.\n    '''\n    queries = []\n\n    for cid, subid, url, stype, data in subtopics(store, folders, fid, sid):\n        if stype in ('text', 'manual'):\n            queries.append(data)\n    return queries"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract_keyword_queries(store, label_store, folders, fid, sid, include_original=False):\n    '''Transforms a folder structure into positive and negative examples\n    to feed to ``linker.model.extract``.  This transforms SortingDesk's\n    foldering structure into *supervision* data for the extractor.\n\n    This works best if folder name (``fid``) is the ``name`` of an entity\n    in question or, more generally, a query that a user might have\n    issued to a search engine.  In particular, this approach makes\n    sense for the annotated version of this task, which is what\n    SortingDesk enables.\n\n    This returns five queries with the original_query name:\n\n      0. if `include_original`, then original name; the model will\n         eliminate if bad but it seems like it's a mistake to omit\n\n      1. plus the most predictive keyword\n\n      2. minus the least predictive keyword\n\n      3. minus the most predictive keyword for the negative class\n\n      4. plus the least predictive keyword for the negative class\n\n    Additionally, if any of these words are the name, we skip to the\n    next keyword in the list.\n\n    Returns a three tuple of ([unicode], [unicode], bool) where the\n    first list is query strings to send to a search engine, and the\n    second list is feature strings to put in a StringCounter.\n\n    '''\n    keyword_feature_keys = []\n\n    query_names = fid.split('_')\n    ## quotes added so that google treats the name as one token\n    name1 = ' '.join(query_names)\n    #keyword_feature_keys.append(name1)\n    original_query = '\\\"' + name1  + '\\\"'\n    logger.info('the original query was %s', original_query)\n\n    queries = []\n\n    ## 0. original name\n    if include_original:\n        logger.info('query 0: including the original: %r', original_query)\n        queries.append(original_query)\n\n    if sid:\n        name2 = ' '.join(sid.split('_'))\n        keyword_feature_keys.append(name2)\n        queries.append( '\\\"' + name2 + '\\\"' )\n\n    ## generate positive and negative examples by traversing folders\n    try:\n        ids = map(itemgetter(0), folders.items(fid, sid))\n    except KeyError:\n        logger.info('Folder traversal failed to find ids, so no '\n                    'training data; giving up on model-based queries')\n        # third return value of `False` means no observations\n        return queries, keyword_feature_keys, False\n\n    positive_fcs = map(itemgetter(1), store.get_many(ids))\n    negative_ids = imap(itemgetter(0),\n                        negative_subfolder_ids(label_store, folders, fid, sid))\n    negative_fcs = map(itemgetter(1), store.get_many(negative_ids))\n\n    ## These features were selected by manual inspection of current\n    ## FOSS NER output.\n    pos_words, neg_words = extract(positive_fcs, negative_fcs,\n                                   features=['GPE', 'PERSON', 'ORGANIZATION'])\n\n    ## 1. plus the most predictive keyword\n    query_plus_pred = original_query + ' ' + \\\n                                name_filter(pos_words, query_names)\n    logger.info('query 1: + most predictive: %r', query_plus_pred)\n    queries.append(query_plus_pred)\n\n    ## 2. minus the least predictive keyword\n    query_min_least = original_query + ' -' + \\\n                                name_filter(reversed(pos_words), query_names)\n    logger.info('query 2: - least predictive: %r', query_min_least)\n    queries.append(query_min_least)\n\n    ## 3. minus the most predictive keyword for the negative class\n    query_min_most_neg = original_query + ' -' + \\\n                                name_filter(neg_words, query_names)\n    logger.info('query 3: - most predictive for neg: %r', query_min_most_neg)\n    queries.append(query_min_most_neg)\n\n    ## 4. plus the least predictive keyword for the negative class\n    query_plus_least_neg = original_query + ' ' + \\\n                                name_filter(reversed(neg_words), query_names)\n    logger.info('query 4: + least predictive for neg: %r', query_plus_least_neg)\n    queries.append(query_plus_least_neg)\n\n    ## for debugging\n    # logger.info('length %d', len(positive_fcs))\n\n    # for fc in positive_fcs:\n    #     logger.info('pos fc %r', fc['title'])\n\n\n    # logger.info('pos fc %r', positive_fcs[3]['GPE'])\n\n    # logger.info('pos fc %r', positive_fcs[3].keys())\n    # logger.info('pos fc %r', positive_fcs[3]['PERSON'])\n\n    # logger.info('positive keywords: %r', pos_words)\n    # logger.info('negative keywords: %r', neg_words)\n\n    # logger.info('most positive keyword: %r', pos_words[0])\n\n    return queries, keyword_feature_keys, True", "response": "Extracts the keyword queries from a folder structure into positive and negative examples\n    to feed to the classifier."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef name_filter(keywords, names):\n    '''\n    Returns the first keyword from the list, unless\n    that keyword is one of the names in names, in which case\n    it continues to the next keyword.\n\n    Since keywords consists of tuples, it just returns the first\n    element of the tuple, the keyword. It also adds double\n    quotes around the keywords, as is appropriate for google queries.\n\n    Input Arguments:\n    keywords -- a list of (keyword, strength) tuples\n    names -- a list of names to be skipped\n    '''\n    name_set = set(name.lower() for name in names)\n\n    for key_tuple in keywords:\n        if not key_tuple[0] in name_set:\n            return '\\\"' + key_tuple[0] +'\\\"'\n\n    ## returns empty string if we run out, which we shouldn't\n    return ''", "response": "Returns the first keyword from the list unless that keyword is one of the names in names."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds the attribute of the log object E", "response": "def _find_attrNS(E, namespaceURI, localName):\n    '''namespaceURI\n       localName\n    '''\n    try:\n        v = E.getAttributeNS(namespaceURI, localName)\n        if v: return v\n    except: pass\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _find_attrNodeNS(E, namespaceURI, localName):\n    '''Must grab the attribute Node to distinquish between\n    an unspecified attribute(None) and one set to empty string(\"\").\n       namespaceURI\n       localName\n    '''\n    attr = E.getAttributeNodeNS(namespaceURI, localName)\n    if attr is None: return None\n    try:\n        return attr.value\n    except: pass\n    return E.getAttributeNS(namespaceURI, localName)", "response": "Must grab the attribute Node to distinquish between an unspecified attribute and an unspecified attribute"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _resolve_prefix(celt, prefix):\n    '''resolve prefix to a namespaceURI.  If None or \n    empty str, return default namespace or None.\n\n    Parameters:\n      celt -- element node\n      prefix -- xmlns:prefix, or empty str or None\n    '''\n    namespace = None\n    while _is_element(celt):\n        if prefix:\n            namespaceURI = _find_xmlns_prefix(celt, prefix)\n        else:\n            namespaceURI = _find_default_namespace(celt)\n        if namespaceURI: break\n        celt = celt.parentNode\n    else:\n        if prefix:  \n            raise EvaluateException, 'cant resolve xmlns:%s' %prefix\n    return namespaceURI", "response": "resolve prefix to a namespaceURI. If None or \n    empty str return default namespace or None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndo this node have a valid encoding?", "response": "def _valid_encoding(elt):\n    '''Does this node have a valid encoding?\n    '''\n    enc = _find_encstyle(elt)\n    if not enc or enc == _SOAP.ENC: return 1\n    for e in enc.split():\n        if e.startswith(_SOAP.ENC):\n            # XXX Is this correct?  Once we find a Sec5 compatible\n            # XXX encoding, should we check that all the rest are from\n            # XXX that same base?  Perhaps.  But since the if test above\n            # XXX will surely get 99% of the cases, leave it for now.\n            return 1\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a backtrace from the given element to the DOM root in XPath syntax.", "response": "def _backtrace(elt, dom):\n    '''Return a \"backtrace\" from the given element to the DOM root,\n    in XPath syntax.\n    '''\n    s = ''\n    while elt != dom:\n        name, parent = elt.nodeName, elt.parentNode\n        if parent is None: break\n        matches = [ c for c in _child_elements(parent) \n                        if c.nodeName == name ]\n        if len(matches) == 1:\n            s = '/' + name + s\n        else:\n            i = matches.index(elt) + 1\n            s = ('/%s[%d]' % (name, i)) + s\n        elt = parent\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the post value for the given URL.", "response": "def _get_postvalue_from_absoluteURI(url):\n    \"\"\"Bug [ 1513000 ] POST Request-URI not limited to \"abs_path\"\n    Request-URI = \"*\" | absoluteURI | abs_path | authority\n    \n    Not a complete solution, but it seems to work with all known\n    implementations.  ValueError thrown if bad uri.\n    \"\"\"\n    cache = _get_postvalue_from_absoluteURI.cache\n    path = cache.get(url, '')\n    if not path:\n        scheme,authpath = url.split('://')\n        s = authpath.split('/', 1)\n        if len(s) == 2: path = '/%s' %s[1]\n        if len(cache) > _get_postvalue_from_absoluteURI.MAXLEN:cache.clear()\n        cache[url] = path\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconnect to the IRC server and waits for events to be received.", "response": "def connect(self):\n        '''\n        Connects to the IRC server with the options defined in `config`\n        '''\n        self._connect()\n\n        try:\n            self._listen()\n        except (KeyboardInterrupt, SystemExit):\n            pass\n        finally:\n            self.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _listen(self):\n        while True:\n            self._inbuffer = self._inbuffer + self.socket.recv(1024)\n            # Some IRC servers disregard the RFC and split lines by \\n rather than \\r\\n.\n\n            temp = self._inbuffer.split(\"\\n\")\n            self._inbuffer = temp.pop()\n\n            for line in temp:\n                # Strip \\r from \\r\\n for RFC-compliant IRC servers.\n                line = line.rstrip('\\r')\n                if self.config['verbose']: print line\n                self._run_listeners(line)", "response": "A thread that listens to the input from the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun all listeners that match the given line.", "response": "def _run_listeners(self, line):\n        \"\"\"\n        Each listener's associated regular expression is matched against raw IRC\n        input. If there is a match, the listener's associated function is called\n        with all the regular expression's matched subgroups.\n        \"\"\"\n        for regex, callbacks in self.listeners.iteritems():\n            match = regex.match(line)\n\n            if not match:\n                continue\n\n            for callback in callbacks:\n                callback(*match.groups())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstripping the bot s nick and set symbol from the message.", "response": "def _strip_prefix(self, message):\n        \"\"\"\n        Checks if the bot was called by a user.\n        Returns the suffix if so.\n\n        Prefixes include the bot's nick as well as a set symbol.\n        \"\"\"\n\n        if not hasattr(self, \"name_regex\"):\n            \"\"\"\n            regex example:\n            ^(((BotA|BotB)[,:]?\\s+)|%)(.+)$\n            \n            names = [BotA, BotB]\n            prefix = %\n            \"\"\"\n\n            names = self.config['names']\n            prefix = self.config['prefix']\n\n            name_regex_str = r'^(?:(?:(%s)[,:]?\\s+)|%s)(.+)$' % (re.escape(\"|\".join(names)), prefix)\n            self.name_regex = re.compile(name_regex_str, re.IGNORECASE)\n\n        search = self.name_regex.search(message)\n        if search:\n            return search.groups()[1]\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconnecting a socket to the server using options defined in config.", "response": "def _connect(self):\n        \"Connects a socket to the server using options defined in `config`.\"\n        self.socket = socket.socket()\n        self.socket.connect((self.config['host'], self.config['port']))\n        self.cmd(\"NICK %s\" % self.config['nick'])\n        self.cmd(\"USER %s %s bla :%s\" %\n                (self.config['ident'], self.config['host'], self.config['realname']))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a string serialization of boolean data as yes or no.", "response": "def parse_yes_no_str(bool_str):\n    \"\"\"Parse a string serialization of boolean data as yes (Y) or no (N).\n\n    Prase a string serialization of boolean data where True is \"Y\" and False is\n    \"N\" case-insensitive.\n\n    @param bool_str: The string to parse.\n    @type bool_str: str\n    @return: The interpreted string.\n    @rtype: bool\n    @raise ValueError: Raised if the passed string is not equal to 'N' or 'Y'\n        case insensitive.\n    \"\"\"\n    lower_bool_str = bool_str.lower()\n    if lower_bool_str == 'n':\n        return False\n    elif lower_bool_str == 'y':\n        return True\n    else:\n        raise ValueError('%s not a valid boolean string.' % bool_str)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef interpret_contribution_entry(entry):\n    try:\n        new_contribution_amount = float(entry['ContributionAmount'])\n        entry['AmountsInterpreted'] = True\n        entry['ContributionAmount'] = new_contribution_amount\n    except ValueError:\n        entry['AmountsInterpreted'] = False\n    except TypeError:\n        entry['AmountsInterpreted'] = False\n    except AttributeError:\n        entry['AmountsInterpreted'] = False\n\n    try:\n        contribution_date = parse_iso_str(entry['ContributionDate'])\n        filed_date = parse_iso_str(entry['FiledDate'])\n        entry['DatesInterpreted'] = True\n        entry['ContributionDate'] = contribution_date\n        entry['FiledDate'] = filed_date\n    except ValueError:\n        entry['DatesInterpreted'] = False\n    except TypeError:\n        entry['DatesInterpreted'] = False\n    except AttributeError:\n        entry['DatesInterpreted'] = False\n\n    try: \n        amended = parse_yes_no_str(entry['Amended'])\n        amendment = parse_yes_no_str(entry['Amendment'])\n        entry['BooleanFieldsInterpreted'] = True\n        entry['Amended'] = amended\n        entry['Amendment'] = amendment\n    except ValueError:\n        entry['BooleanFieldsInterpreted'] = False\n    except TypeError:\n        entry['BooleanFieldsInterpreted'] = False\n    except AttributeError:\n        entry['BooleanFieldsInterpreted'] = False\n\n    return entry", "response": "Interprets the data fields within a CO - TRACER contributions report."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef interpret_expenditure_entry(entry):\n    try:\n        expenditure_amount = float(entry['ExpenditureAmount'])\n        entry['AmountsInterpreted'] = True\n        entry['ExpenditureAmount'] = expenditure_amount\n    except ValueError:\n        entry['AmountsInterpreted'] = False\n\n    try:\n        expenditure_date = parse_iso_str(entry['ExpenditureDate'])\n        filed_date = parse_iso_str(entry['FiledDate'])\n        entry['DatesInterpreted'] = True\n        entry['ExpenditureDate'] = expenditure_date\n        entry['FiledDate'] = filed_date\n    except ValueError:\n        entry['DatesInterpreted'] = False\n\n    try:\n        amended = parse_yes_no_str(entry['Amended'])\n        amendment = parse_yes_no_str(entry['Amendment'])\n        entry['BooleanFieldsInterpreted'] = True\n        entry['Amended'] = amended\n        entry['Amendment'] = amendment\n    except ValueError:\n        entry['BooleanFieldsInterpreted'] = False\n\n    return entry", "response": "Interprets the Expenditure report data fields within a CO - TRACER expediture report."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninterpreting the data fields within a CO - TRACER loan report.", "response": "def interpret_loan_entry(entry):\n    \"\"\"Interpret data fields within a CO-TRACER loan report.\n\n    Interpret the payment amount, loan amount, interest rate, interest payment,\n    loan balance, payment date, filed date, loan date, amended, and amendment\n    fields of the provided entry. All dates (payment, filed, and loan) are\n    interpreted together and, if any fails, all will retain their original\n    value. Likewise, amended and amendment are interpreted together and\n    if one is malformed, both will retain their original value. Finally,\n    the payment amount, loan amount, interest rate, interest payment, and\n    loan balance will be interpreted transactionally and, if any fail, all\n    will retain their original value.\n\n    Entry may be edited in place and side-effects are possible in coupled code.\n    However, client code should use the return value to guard against future\n    changes.\n\n    A value with the key 'AmountsInterpreted' will be set to True or False in\n    the returned entry if floating point values are successfully interpreted\n    or not respectively.\n\n    A value with the key 'DatesInterpreted' will be set to True or False in\n    the returned entry if ISO 8601 strings are successfully interpreted\n    or not respectively.\n\n    A value with the key 'BooleanFieldsInterpreted' will be set to True or\n    False in the returned entry if boolean strings are successfully interpreted\n    or not respectively.\n\n    @param entry: The loan report data to manipulate / interpret.\n    @type entry: dict\n    @return: The entry passed \n    @raise ValueError: Raised if any expected field cannot be found in entry.\n    \"\"\"\n    try:\n        payment_amount = float(entry['PaymentAmount'])\n        loan_amount = float(entry['LoanAmount'])\n        interest_rate = float(entry['InterestRate'])\n        interest_payment = float(entry['InterestPayment'])\n        loan_balance = float(entry['LoanBalance'])\n        entry['AmountsInterpreted'] = True\n        entry['PaymentAmount'] = payment_amount\n        entry['LoanAmount'] = loan_amount\n        entry['InterestRate'] = interest_rate\n        entry['InterestPayment'] = interest_payment\n        entry['LoanBalance'] = loan_balance\n    except ValueError:\n        entry['AmountsInterpreted'] = False\n\n    try:\n        payment_date = parse_iso_str(entry['PaymentDate'])\n        filed_date = parse_iso_str(entry['FiledDate'])\n        loan_date = parse_iso_str(entry['LoanDate'])\n        entry['DatesInterpreted'] = True\n        entry['PaymentDate'] = payment_date\n        entry['FiledDate'] = filed_date\n        entry['LoanDate'] = loan_date\n    except ValueError:\n        entry['DatesInterpreted'] = False\n\n    try:\n        amended = parse_yes_no_str(entry['Amended'])\n        amendment = parse_yes_no_str(entry['Amendment'])\n        entry['BooleanFieldsInterpreted'] = True\n        entry['Amended'] = amended\n        entry['Amendment'] = amendment\n    except ValueError:\n        entry['BooleanFieldsInterpreted'] = False\n\n    return entry"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses a file and return the path of the processed file.", "response": "def process_file(self, path, dryrun):\n        \"\"\"\n        Add header to all files.\n        \"\"\"\n        if dryrun:\n            return path\n\n        # get file's current header\n        with open(path, \"r\") as infile:\n            head = infile.read(len(self.__header))\n\n        # normalize line breaks\n        if self.__normalize_br:\n            head = head.replace(\"\\r\\n\", \"\\n\")\n\n        # already contain header? skip\n        if head == self.__header:\n            return path\n\n        # add header to file\n        self.push_header(path)\n\n        # return processed file\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npushes the header to a given file", "response": "def push_header(self, filename):\n        \"\"\"\n        Push the header to a given filename\n        :param filename: the file path to push into.\n        \"\"\"\n        # open file and read it all\n        with open(filename, \"r\") as infile:\n            content = infile.read()\n\n        # push header\n        content = self.__header + content\n\n        # re-write file with the header\n        with open(filename, \"w\") as outfile:\n            outfile.write(content)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a comma - separated list of models optionaly with a link.", "response": "def csv_list(models, attr, link=False, separator=\", \"):\n    \"\"\"Return a comma-separated list of models, optionaly with a link.\"\"\"\n    values = []\n    for model in models:\n        value = getattr(model, attr)\n        if link and hasattr(model, \"get_admin_url\") and callable(model.get_admin_url):\n            value = get_admin_html_link(model, label=value)\n        values.append(value)\n    return separator.join(values)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the URL to admin pages for this object.", "response": "def get_admin_url(obj, page=None):\n    \"\"\"Return the URL to admin pages for this object.\"\"\"\n    if obj is None:\n        return None\n\n    if page is None:\n        page = \"change\"\n    if page not in ADMIN_ALL_PAGES:\n        raise ValueError(\"Invalid page name '{}'. Available pages are: {}.\".format(page, ADMIN_ALL_PAGES))\n\n    app_label = obj.__class__._meta.app_label\n    object_name = obj.__class__._meta.object_name.lower()\n\n    if page in ADMIN_GLOBAL_PAGES:\n        url_name = page\n    else:\n        url_name = \"{}_{}_{}\".format(app_label, object_name, page)\n\n    if page == \"app_list\":\n        url_args = (app_label,)\n    elif page == \"view_on_site\":\n        content_type = ContentType.objects.get_for_model(obj.__class__)\n        url_args = (content_type, obj._get_pk_val())\n    elif page in ADMIN_DETAIL_PAGES:\n        url_args = (obj._get_pk_val(),)\n    else:\n        url_args = None\n\n    return reverse(\"admin:{}\".format(url_name), args=url_args)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the index of a fieldset in the original fieldsets list.", "response": "def get_fieldset_index(fieldsets, index_or_name):\n    \"\"\"\n    Return the index of a fieldset in the ``fieldsets`` list.\n\n    Args:\n        fieldsets (list): The original ``fieldsets`` list.\n        index_or_name (int or str): The value of the reference element, or directly its numeric index.\n\n    Returns:\n        (int) The index of the fieldset in the ``fieldsets`` list.\n    \"\"\"\n    if isinstance(index_or_name, six.integer_types):\n        return index_or_name\n\n    for key, value in enumerate(fieldsets):\n        if value[0] == index_or_name:\n            return key\n\n    raise KeyError(\"Key not found: '{}'.\".format(index_or_name))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the index of an element in the list.", "response": "def get_list_index(lst, index_or_name):\n    \"\"\"\n    Return the index of an element in the list.\n\n    Args:\n        lst (list): The list.\n        index_or_name (int or str): The value of the reference element, or directly its numeric index.\n\n    Returns:\n        (int) The index of the element in the list.\n    \"\"\"\n    if isinstance(index_or_name, six.integer_types):\n        return index_or_name\n\n    return lst.index(index_or_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef insert_fields_in_fieldsets(fieldsets, fieldset_index_or_name, new_fields, field_index_or_name=None, after=True):\n    fieldset_index = get_fieldset_index(fieldsets, fieldset_index_or_name)\n    fieldset_fields = fieldsets[fieldset_index][1][\"fields\"]\n\n    try:\n        field_index = get_list_index(fieldset_fields, field_index_or_name)\n    except ValueError:\n        field_index = None\n\n    to_return = deepcopy(fieldsets)\n    to_return[fieldset_index][1][\"fields\"] = list_insert(fieldset_fields, new_fields, field_index, after=after)\n    return to_return", "response": "Insert new fields in the given fieldsets list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_insert(lst, new_elements, index_or_name=None, after=True):\n    if index_or_name is None:\n        index = None\n    else:\n        try:\n            index = get_list_index(lst, index_or_name)\n        except ValueError:\n            index = None\n\n    to_return = lst[:]\n    if index is None:  # Append.\n        to_return += new_elements\n    elif index == 0:  # Prepend.\n        to_return = new_elements + to_return\n    else:\n        if after:\n            index += 1\n        to_return = to_return[:index] + new_elements + to_return[index:]\n    return to_return", "response": "Returns a copy of the original list with the new elements inserted."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting a new value and extends its expiration time.", "response": "def set_value(self, value, timeout):\n        \"\"\"\n        Sets a new value and extends its expiration.\n\n        :param value: a new cached value.\n\n        :param timeout: a expiration timeout in milliseconds.\n        \"\"\"\n        self.value = value\n        self.expiration = time.perf_counter() * 1000 + timeout"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a random password for the", "response": "def _generate_password():\n    \"\"\"Create a random password\n\n    The password is made by taking a uuid and passing it though sha1sum.\n    We may change this in future to gain more entropy.\n\n    This is based on the tripleo command os-make-password\n    \"\"\"\n    uuid_str = six.text_type(uuid.uuid4()).encode(\"UTF-8\")\n    return hashlib.sha1(uuid_str).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_overcloud_passwords(output_file=\"tripleo-overcloud-passwords\"):\n\n    if os.path.isfile(output_file):\n        with open(output_file) as f:\n            return dict(line.split('=') for line in f.read().splitlines())\n\n    password_names = (\n        \"OVERCLOUD_ADMIN_PASSWORD\",\n        \"OVERCLOUD_ADMIN_TOKEN\",\n        \"OVERCLOUD_CEILOMETER_PASSWORD\",\n        \"OVERCLOUD_CEILOMETER_SECRET\",\n        \"OVERCLOUD_CINDER_PASSWORD\",\n        \"OVERCLOUD_DEMO_PASSWORD\",\n        \"OVERCLOUD_GLANCE_PASSWORD\",\n        \"OVERCLOUD_HEAT_PASSWORD\",\n        \"OVERCLOUD_HEAT_STACK_DOMAIN_PASSWORD\",\n        \"OVERCLOUD_NEUTRON_PASSWORD\",\n        \"OVERCLOUD_NOVA_PASSWORD\",\n        \"OVERCLOUD_SWIFT_HASH\",\n        \"OVERCLOUD_SWIFT_PASSWORD\",\n    )\n\n    passwords = dict((p, _generate_password()) for p in password_names)\n\n    with open(output_file, 'w') as f:\n        for name, password in passwords.items():\n            f.write(\"{0}={1}\\n\".format(name, password))\n\n    return passwords", "response": "Create the set of passwords needed by the overcloud."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking the Hypervisor stats meet a minimum value.", "response": "def check_hypervisor_stats(compute_client, nodes=1, memory=0, vcpu=0):\n    \"\"\"Check the Hypervisor stats meet a minimum value\n\n    Check the hypervisor stats match the required counts. This is an\n    implementation of a command in TripleO with the same name.\n\n    :param compute_client: Instance of Nova client\n    :type  compute_client: novaclient.client.v2.Client\n\n    :param nodes: The number of nodes to wait for, defaults to 1.\n    :type  nodes: int\n\n    :param memory: The amount of memory to wait for in MB, defaults to 0.\n    :type  memory: int\n\n    :param vcpu: The number of vcpus to wait for, defaults to 0.\n    :type  vcpu: int\n    \"\"\"\n\n    statistics = compute_client.hypervisors.statistics().to_dict()\n\n    if all([statistics['count'] >= nodes,\n            statistics['memory_mb'] >= memory,\n            statistics['vcpus'] >= vcpu]):\n        return statistics\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wait_for_stack_ready(orchestration_client, stack_name):\n    SUCCESSFUL_MATCH_OUTPUT = \"(CREATE|UPDATE)_COMPLETE\"\n    FAIL_MATCH_OUTPUT = \"(CREATE|UPDATE)_FAILED\"\n\n    while True:\n        stack = orchestration_client.stacks.get(stack_name)\n\n        if not stack:\n            return False\n\n        status = stack.stack_status\n\n        if re.match(SUCCESSFUL_MATCH_OUTPUT, status):\n            return True\n        if re.match(FAIL_MATCH_OUTPUT, status):\n            print(\"Stack failed with status: {}\".format(\n                stack.stack_status_reason, file=sys.stderr))\n            return False\n\n        time.sleep(10)", "response": "Check the status of an orchestration stack and check whether it is complete or failed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwaiting for a given provisioning state in Ironic", "response": "def wait_for_provision_state(baremetal_client, node_uuid, provision_state,\n                             loops=10, sleep=1):\n    \"\"\"Wait for a given Provisioning state in Ironic Discoverd\n\n    Updating the provisioning state is an async operation, we\n    need to wait for it to be completed.\n\n    :param baremetal_client: Instance of Ironic client\n    :type  baremetal_client: ironicclient.v1.client.Client\n\n    :param node_uuid: The Ironic node UUID\n    :type  node_uuid: str\n\n    :param provision_state: The provisioning state name to wait for\n    :type  provision_state: str\n\n    :param loops: How many times to loop\n    :type loops: int\n\n    :param sleep: How long to sleep between loops\n    :type sleep: int\n    \"\"\"\n\n    for _ in range(0, loops):\n\n        node = baremetal_client.node.get(node_uuid)\n\n        if node is None:\n            # The node can't be found in ironic, so we don't need to wait for\n            # the provision state\n            return True\n\n        if node.provision_state == provision_state:\n            return True\n\n        time.sleep(sleep)\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wait_for_node_discovery(discoverd_client, auth_token, discoverd_url,\n                            node_uuids, loops=220, sleep=10):\n    \"\"\"Check the status of Node discovery in Ironic discoverd\n\n    Gets the status and waits for them to complete.\n\n    :param discoverd_client: Ironic Discoverd client\n    :type  discoverd_client: ironic_discoverd.client\n\n    :param auth_token: Authorisation token used by discoverd client\n    :type auth_token: string\n\n    :param discoverd_url: URL used by the discoverd client\n    :type discoverd_url: string\n\n    :param node_uuids: List of Node UUID's to wait for discovery\n    :type node_uuids: [string, ]\n\n    :param loops: How many times to loop\n    :type loops: int\n\n    :param sleep: How long to sleep between loops\n    :type sleep: int\n    \"\"\"\n\n    log = logging.getLogger(__name__ + \".wait_for_node_discovery\")\n    node_uuids = node_uuids[:]\n\n    for _ in range(0, loops):\n\n        for node_uuid in node_uuids:\n\n            status = discoverd_client.get_status(\n                node_uuid,\n                base_url=discoverd_url,\n                auth_token=auth_token)\n\n            if status['finished']:\n                log.debug(\"Discover finished for node {0} (Error: {1})\".format(\n                    node_uuid, status['error']))\n                node_uuids.remove(node_uuid)\n                yield node_uuid, status\n\n        if not len(node_uuids):\n            raise StopIteration\n        time.sleep(sleep)\n\n    if len(node_uuids):\n        log.error(\"Discovery didn't finish for nodes {0}\".format(\n            ','.join(node_uuids)))", "response": "Get the status of the nodes and wait for them to complete"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a heat environment file with the given scale parameters.", "response": "def create_environment_file(path=\"~/overcloud-env.json\",\n                            control_scale=1, compute_scale=1,\n                            ceph_storage_scale=0, block_storage_scale=0,\n                            swift_storage_scale=0):\n    \"\"\"Create a heat environment file\n\n    Create the heat environment file with the scale parameters.\n\n    :param control_scale: Scale value for control roles.\n    :type control_scale: int\n\n    :param compute_scale: Scale value for compute roles.\n    :type compute_scale: int\n\n    :param ceph_storage_scale: Scale value for ceph storage roles.\n    :type ceph_storage_scale: int\n\n    :param block_storage_scale: Scale value for block storage roles.\n    :type block_storage_scale: int\n\n    :param swift_storage_scale: Scale value for swift storage roles.\n    :type swift_storage_scale: int\n    \"\"\"\n\n    env_path = os.path.expanduser(path)\n    with open(env_path, 'w+') as f:\n        f.write(json.dumps({\n            \"parameters\": {\n                \"ControllerCount\": control_scale,\n                \"ComputeCount\": compute_scale,\n                \"CephStorageCount\": ceph_storage_scale,\n                \"BlockStorageCount\": block_storage_scale,\n                \"ObjectStorageCount\": swift_storage_scale}\n        }))\n\n    return env_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_nodes_state(baremetal_client, nodes, transition, target_state,\n                    skipped_states=()):\n    \"\"\"Make all nodes available in the baremetal service for a deployment\n\n    For each node, make it available unless it is already available or active.\n    Available nodes can be used for a deployment and an active node is already\n    in use.\n\n    :param baremetal_client: Instance of Ironic client\n    :type  baremetal_client: ironicclient.v1.client.Client\n\n    :param nodes: List of Baremetal Nodes\n    :type  nodes: [ironicclient.v1.node.Node]\n\n    :param transition: The state to set for a node. The full list of states\n                       can be found in ironic.common.states.\n    :type  transition: string\n\n    :param target_state: The expected result state for a node. For example when\n                         transitioning to 'manage' the result is 'manageable'\n    :type  target_state: string\n\n    :param skipped_states: A set of states to skip, for example 'active' nodes\n                           are already deployed and the state can't always be\n                           changed.\n    :type  skipped_states: iterable of strings\n    \"\"\"\n\n    log = logging.getLogger(__name__ + \".set_nodes_state\")\n\n    for node in nodes:\n\n        if node.provision_state in skipped_states:\n            continue\n\n        log.debug(\n            \"Setting provision state from {0} to '{1} for Node {2}\"\n            .format(node.provision_state, transition, node.uuid))\n\n        baremetal_client.node.set_provision_state(node.uuid, transition)\n\n        if not wait_for_provision_state(baremetal_client, node.uuid,\n                                        target_state):\n            print(\"FAIL: State not updated for Node {0}\".format(\n                  node.uuid, file=sys.stderr))\n        else:\n            yield node.uuid", "response": "Set the state of all nodes in a baremetal service for a deployment"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving a key from the hiera store", "response": "def get_hiera_key(key_name):\n    \"\"\"Retrieve a key from the hiera store\n\n    :param password_name: Name of the key to retrieve\n    :type  password_name: type\n\n    \"\"\"\n    command = [\"hiera\", key_name]\n    p = subprocess.Popen(command, stdout=subprocess.PIPE)\n    out, err = p.communicate()\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_known_hosts(overcloud_ip):\n\n    known_hosts = os.path.expanduser(\"~/.ssh/known_hosts\")\n\n    if os.path.exists(known_hosts):\n        command = ['ssh-keygen', '-R', overcloud_ip, '-f', known_hosts]\n        subprocess.check_call(command)", "response": "For a given IP address remove SSH keys from the known_hosts file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef file_checksum(filepath):\n    checksum = hashlib.md5()\n    with open(filepath, 'rb') as f:\n        for fragment in iter(lambda: f.read(65536), ''):\n            checksum.update(fragment)\n    return checksum.hexdigest()", "response": "Calculate md5 checksum on file\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if there are enough nodes for creating or scaling stack", "response": "def check_nodes_count(baremetal_client, stack, parameters, defaults):\n    \"\"\"Check if there are enough available nodes for creating/scaling stack\"\"\"\n    count = 0\n    if stack:\n        for param in defaults:\n            try:\n                current = int(stack.parameters[param])\n            except KeyError:\n                raise ValueError(\n                    \"Parameter '%s' was not found in existing stack\" % param)\n            count += parameters.get(param, current)\n    else:\n        for param, default in defaults.items():\n            count += parameters.get(param, default)\n\n    available = len(baremetal_client.node.list(associated=False,\n                                               maintenance=False))\n    if count > available:\n        raise exceptions.DeploymentError(\n            \"Not enough nodes - available: {0}, requested: {1}\".format(\n                available, count))\n    else:\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_queues(queues):\n        if not queues:\n            raise ConfigurationException('The queue(s) to use are not defined')\n\n        if isinstance(queues, (list, tuple)):\n            for queue_name in queues:\n                if not isinstance(queue_name, str):\n                    raise ConfigurationException('Queue name \"%s\" is not a (base)string')\n\n        elif isinstance(queues, basestring):\n            queues = str(queues).split(',')\n\n        else:\n            raise ConfigurationException('Invalid format for queues names')\n\n        return list(queues)", "response": "Parse the given parameter and return a list of queues."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_end_signal(self):\n        try:\n            signal.signal(signal.SIGTERM, self.catch_end_signal)\n            signal.signal(signal.SIGINT, self.catch_end_signal)\n        except ValueError:\n            self.log('Signals cannot be caught in a Thread', level='warning')", "response": "Catch some system signals to handle them internaly\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stop_handling_end_signal(self):\n        try:\n            signal.signal(signal.SIGTERM, signal.SIG_DFL)\n            signal.signal(signal.SIGINT, signal.SIG_DFL)\n        except ValueError:\n            self.log('Signals cannot be caught in a Thread', level='warning')", "response": "Stop handling the SIGINT and SIGTERM signals"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprepares the logger using self. logger_name and self. logger_level.", "response": "def set_logger(self):\n        \"\"\"\n        Prepare the logger, using self.logger_name and self.logger_level\n        \"\"\"\n        self.logger = logging.getLogger(self.logger_name)\n        self.logger.setLevel(self.logger_level)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef id(self):\n        if not hasattr(self, '_id'):\n            self._id = str(threading.current_thread().ident + id(self))[-6:]\n        return self._id", "response": "Return an identifier for the worker to use in logging\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef log(self, message, level='info'):\n        getattr(self.logger, level)('[%s] %s' % (self.id, message))", "response": "Log a message to the logger."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef must_stop(self):\n        return bool(self.terminate_gracefuly and self.end_signal_caught\n                 or self.num_loops >= self.max_loops or self.end_forced\n                 or self.wanted_end_date and datetime.utcnow() >= self.wanted_end_date)", "response": "Return True if the worker must stop when the current loop is over."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave the new status and call all callbacks that need to be called when the new status is changed.", "response": "def set_status(self, status):\n        \"\"\"\n        Save the new status and call all defined callbacks\n        \"\"\"\n        self.status = status\n        for callback in self._update_status_callbacks:\n            callback(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wait_for_job(self):\n        blpop_result = self.connection.blpop(self.keys, self.timeout)\n        if blpop_result is None:\n            return None\n        queue_redis_key, job_ident = blpop_result\n        self.set_status('running')\n        return self.get_queue(queue_redis_key), self.get_job(job_ident)", "response": "Wait for a job and return it."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_queue(self, queue_redis_key):\n        try:\n            queue_pk = int(queue_redis_key.split(':')[-2])\n        except:\n            raise DoesNotExist('Unable to get the queue from the key %s' % queue_redis_key)\n        return self.queue_model.get(queue_pk)", "response": "Get a queue based on the redis key used in store the list\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef catch_end_signal(self, signum, frame):\n        if self.end_signal_caught:\n            self.log('Previous signal caught, will end soon')\n            return\n\n        signal_name = dict((getattr(signal, n), n) for n in dir(signal)\n                        if n.startswith('SIG') and '_' not in n).get(signum, signum)\n\n        if self.status == 'running':\n            self.log('Catched %s signal: stopping after current job' % signal_name,\n                     level='critical')\n        else:\n            delay = self.timeout if self.status == 'waiting' else self.fetch_priorities_delay\n            self.log('Catched %s signal: stopping in max %d seconds' % (\n                     signal_name, delay), level='critical')\n\n        self.end_signal_caught = self.end_forced = True", "response": "This method is called when a SIGINT or SIGTERM signal is caught. This method is called when the worker is shutting down."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_keys(self):\n        self.keys = self.queue_model.get_waiting_keys(self.queues)\n\n        if not self.keys:\n            self.log('No queues yet', level='warning')\n        self.last_update_keys = datetime.utcnow()", "response": "Update the redis keys to listen for new jobs priorities."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef elapsed(self):\n        if not self.start_date:\n            return None\n        return (self.end_date or datetime.utcnow()) - self.start_date", "response": "Returns a timedelta representation of the time passed sine the worker\n        was running."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun jobs until must_stop returns True", "response": "def _main_loop(self):\n        \"\"\"\n        Run jobs until must_stop returns True\n        \"\"\"\n        fetch_priorities_delay = timedelta(seconds=self.fetch_priorities_delay)\n        fetch_delayed_delay = timedelta(seconds=self.fetch_delayed_delay)\n\n        while not self.must_stop():\n            self.set_status('waiting')\n\n            if self.last_update_keys + fetch_priorities_delay < datetime.utcnow():\n                self.update_keys()\n\n            if self.last_requeue_delayed + fetch_delayed_delay < datetime.utcnow():\n                self.requeue_delayed_jobs()\n\n            try:\n                queue_and_job = self.wait_for_job()\n                if queue_and_job is None:\n                    # timeout for blpop\n                    continue\n                queue, job = queue_and_job\n            except Exception as e:\n                self.log('Unable to get job: %s\\n%s'\n                    % (str(e), traceback.format_exc()), level='error')\n            else:\n                self.num_loops += 1\n                try:\n                    identifier = 'pk:%s' % job.pk.get()\n                except Exception as e:\n                    identifier = '??'\n                try:\n                    self.set_status('running')\n                    identifier, status = job.hmget('identifier', 'status')\n                     # some cache, don't count on it on subclasses\n                    job._cached_identifier = identifier\n                    job._cached_status = status\n                    queue._cached_name = queue.name.hget()\n\n                    if status == STATUSES.DELAYED:\n                        self.job_delayed(job, queue)\n                    elif status != STATUSES.WAITING:\n                        self.job_skipped(job, queue)\n                    else:\n                        try:\n                            self.job_started(job, queue)\n                            job_result = self.callback(job, queue)\n                        except Exception as e:\n                            trace = None\n                            if self.save_tracebacks:\n                                trace = traceback.format_exc()\n                            self.job_error(job, queue, e, trace)\n                        else:\n                            job._cached_status = job.status.hget()\n                            if job._cached_status == STATUSES.DELAYED:\n                                self.job_delayed(job, queue)\n                            elif job._cached_status == STATUSES.CANCELED:\n                                self.job_skipped(job, queue)\n                            else:\n                                self.job_success(job, queue, job_result)\n                except Exception as e:\n                    self.log('[%s] unexpected error: %s\\n%s'\n                        % (identifier, str(e), traceback.format_exc()), level='error')\n                    try:\n                        queue.errors.rpush(job.ident)\n                    except Exception as e:\n                        self.log('[%s] unable to add the error in the queue: %s\\n%s'\n                            % (identifier, str(e), traceback.format_exc()), level='error')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall when an error occurs during the execute call for a job.", "response": "def job_error(self, job, queue, exception, trace=None):\n        \"\"\"\n        Called when an exception was raised during the execute call for a job.\n        \"\"\"\n        to_be_requeued = not job.must_be_cancelled_on_error and self.requeue_times and self.requeue_times >= int(job.tries.hget() or 0)\n\n        if not to_be_requeued:\n            job.queued.delete()\n\n        job.hmset(end=str(datetime.utcnow()), status=STATUSES.ERROR)\n        queue.errors.rpush(job.ident)\n\n        if self.save_errors:\n            additional_fields = self.additional_error_fields(job, queue, exception)\n            self.error_model.add_error(queue_name=queue._cached_name,\n                                       job=job,\n                                       error=exception,\n                                       trace=trace,\n                                       **additional_fields)\n\n        self.log(self.job_error_message(job, queue, to_be_requeued, exception, trace), level='error')\n\n        if hasattr(job, 'on_error'):\n            job.on_error(queue, exception, trace)\n\n        # requeue the job if needed\n        if to_be_requeued:\n            priority = queue.priority.hget()\n\n            if self.requeue_priority_delta:\n                priority = int(priority) + self.requeue_priority_delta\n\n            self.requeue_job(job, queue, priority, delayed_for=self.requeue_delay_delta)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef requeue_job(self, job, queue, priority, delayed_for=None):\n        job.requeue(queue_name=queue._cached_name,\n                    priority=priority,\n                    delayed_for=delayed_for,\n                    queue_model=self.queue_model)\n\n        if hasattr(job, 'on_requeued'):\n            job.on_requeued(queue)\n\n        self.log(self.job_requeue_message(job, queue))", "response": "Requeue a job in a queue with the given priority."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the message to log when a job raised an error", "response": "def job_error_message(self, job, queue, to_be_requeued, exception, trace=None):\n        \"\"\"\n        Return the message to log when a job raised an error\n        \"\"\"\n        return '[%s|%s|%s] error: %s [%s]' % (queue._cached_name,\n                             job.pk.get(),\n                             job._cached_identifier,\n                             str(exception),\n                             'requeued' if to_be_requeued else 'NOT requeued')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the message to log when a job is requeued.", "response": "def job_requeue_message(self, job, queue):\n        \"\"\"\n        Return the message to log when a job is requeued\n        \"\"\"\n        priority, delayed_until = job.hmget('priority', 'delayed_until')\n\n        msg = '[%s|%s|%s] requeued with priority %s'\n        args = [queue._cached_name, job.pk.get(), job._cached_identifier, priority]\n\n        if delayed_until:\n            msg += ', delayed until %s'\n            args.append(delayed_until)\n\n        return msg % tuple(args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef job_success(self, job, queue, job_result):\n        job.queued.delete()\n        job.hmset(end=str(datetime.utcnow()), status=STATUSES.SUCCESS)\n        queue.success.rpush(job.ident)\n        self.log(self.job_success_message(job, queue, job_result))\n        if hasattr(job, 'on_success'):\n            job.on_success(queue, job_result)", "response": "Called just after an execute call was successful."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the message to log when a job is successful", "response": "def job_success_message(self, job, queue, job_result):\n        \"\"\"\n        Return the message to log when a job is successful\n        \"\"\"\n        return '[%s|%s|%s] success, in %s' % (queue._cached_name, job.pk.get(),\n                                           job._cached_identifier, job.duration)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef job_started(self, job, queue):\n        job.hmset(start=str(datetime.utcnow()), status=STATUSES.RUNNING)\n        job.tries.hincrby(1)\n        self.log(self.job_started_message(job, queue))\n        if hasattr(job, 'on_started'):\n            job.on_started(queue)", "response": "Called just before the execution of the job is started"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef job_started_message(self, job, queue):\n        return '[%s|%s|%s] starting' % (queue._cached_name, job.pk.get(),\n                                        job._cached_identifier)", "response": "Return the message to log just befre the execution of the job"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef job_skipped(self, job, queue):\n        job.queued.delete()\n        self.log(self.job_skipped_message(job, queue), level='warning')\n        if hasattr(job, 'on_skipped'):\n            job.on_skipped(queue)", "response": "Called if a job is being skipped"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef job_skipped_message(self, job, queue):\n        return '[%s|%s|%s] job skipped (current status: %s)' % (\n                queue._cached_name,\n                job.pk.get(),\n                job._cached_identifier,\n                STATUSES.by_value(job._cached_status, 'UNKNOWN'))", "response": "Return the message to log when a job was skipped"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls if a job has the delayed status set to delayed", "response": "def job_delayed(self, job, queue):\n        \"\"\"\n        Called if a job, before trying to run it, has the \"delayed\" status, or,\n        after run, if its status was set to \"delayed\"\n        If delayed_until was not set, or is invalid, set it to 60sec in the future\n        \"\"\"\n        delayed_until = job.delayed_until.hget()\n        if delayed_until:\n            try:\n                delayed_until = compute_delayed_until(delayed_until=parse(delayed_until))\n            except (ValueError, TypeError):\n                delayed_until = None\n\n        if not delayed_until:\n            # by default delay it for 60 seconds\n            delayed_until = compute_delayed_until(delayed_for=60)\n\n        job.enqueue_or_delay(\n            queue_name=queue._cached_name,\n            delayed_until=delayed_until,\n            queue_model=queue.__class__,\n        )\n\n        self.log(self.job_delayed_message(job, queue), level='warning')\n\n        if hasattr(job, 'on_delayed'):\n            job.on_delayed(queue)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef job_delayed_message(self, job, queue):\n        return '[%s|%s|%s] job delayed until %s' % (\n                queue._cached_name,\n                job.pk.get(),\n                job._cached_identifier,\n                job.delayed_until.hget())", "response": "Return the message to log when a job was delayed just before or during\n        its execution\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate and return the OptionParser which will be used to parse the arguments to the worker.", "response": "def create_parser(self):\n        \"\"\"\n        Create and return the ``OptionParser`` which will be used to\n        parse the arguments to the worker.\n\n        \"\"\"\n        return OptionParser(prog=self.prog_name,\n                            usage=self.usage(),\n                            version='%%prog %s' % self.get_version(),\n                            option_list=self.option_list)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef manage_options(self):\n        self.parser = self.create_parser()\n        self.options, self.args = self.parser.parse_args(self.argv)\n\n        self.do_imports()\n\n        if self.options.callback and not callable(self.options.callback):\n            self.parser.error('The callback is not callable')\n\n        self.logger_level = None\n        if self.options.logger_level:\n            if self.options.logger_level.isdigit():\n                self.options.logger_level = int(self.options.logger_level)\n            else:\n                try:\n                    self.options.logger_level = getattr(logging, self.options.logger_level.upper())\n                except:\n                    self.parser.error('Invalid logger-level %s' % self.options.logger_level)\n\n        if self.options.max_loops is not None and self.options.max_loops < 0:\n            self.parser.error('The max-loops argument (%s) must be a <positive></positive> integer' % self.options.max_loops)\n\n        if self.options.max_duration is not None and self.options.max_duration < 0:\n            self.parser.error('The max-duration argument (%s) must be a positive integer' % self.options.max_duration)\n\n        if self.options.timeout is not None and self.options.timeout < 0:\n            self.parser.error('The timeout argument (%s) must be a positive integer (including 0)' % self.options.timeout)\n\n        if self.options.fetch_priorities_delay is not None and self.options.fetch_priorities_delay <= 0:\n            self.parser.error('The fetch-priorities-delay argument (%s) must be a positive integer' % self.options.fetch_priorities_delay)\n\n        if self.options.fetch_delayed_delay is not None and self.options.fetch_delayed_delay <= 0:\n            self.parser.error('The fetch-delayed-delay argument (%s) must be a positive integer' % self.options.fetch_delayed_delay)\n\n        if self.options.requeue_times is not None and self.options.requeue_times < 0:\n            self.parser.error('The requeue-times argument (%s) must be a positive integer (including 0)' % self.options.requeue_times)\n\n        if self.options.requeue_delay_delta is not None and self.options.requeue_delay_delta < 0:\n            self.parser.error('The rrequeue-delay-delta argument (%s) must be a positive integer (including 0)' % self.options.requeue_delay_delta)\n\n        self.database_config = None\n        if self.options.database:\n            host, port, db = self.options.database.split(':')\n            self.database_config = dict(host=host, port=int(port), db=int(db))\n\n        self.update_title = self.options.update_title", "response": "Manage the options for the current programme"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_import(self, name, default):\n        try:\n            option = getattr(self.options, name)\n            if option:\n                klass = import_class(option)\n            else:\n                klass = default\n            setattr(self.options, name, klass)\n        except Exception as e:\n            self.parser.error('Unable to import \"%s\": %s' % (name, e))", "response": "Import the given option"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef do_imports(self):\n        self.do_import('worker_class', Worker)\n        self.do_import('queue_model', self.options.worker_class.queue_model)\n        self.do_import('error_model', self.options.worker_class.error_model)\n        self.do_import('callback', self.options.worker_class.callback)", "response": "Import all importable options"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_options(self):\n        options = []\n\n        print(\"The script is running with the following options:\")\n\n        options.append((\"dry_run\", self.options.dry_run))\n\n        options.append((\"worker_config\", self.__class__))\n\n        database_config = self.database_config or \\\n                          self.options.queue_model.database.connection_settings\n        options.append((\"database\", '%s:%s:%s' % (database_config['host'],\n                                                  database_config['port'],\n                                                  database_config['db'])))\n\n        if self.options.worker_class is not None:\n            options.append((\"worker-class\", self.options.worker_class))\n\n        for name, value in options:\n            print(\" - %s = %s\" % (name.replace('_', '-'), value))\n\n        print(\"The worker will run with the following options:\")\n        for name in self.options.worker_class.parameters:\n            option = getattr(self.worker, name)\n            if name == 'callback' and \\\n                self.options.worker_class.execute == Worker.execute:\n                option = '<jobs \"run\" method>'\n            elif isinstance(option, (list, tuple, set)):\n                option = ','.join(option)\n            print(\" - %s = %s\" % (name.replace('_', '-'), option))", "response": "Print all options parsed by the script\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execute(self):\n        self.prepare_models()\n        self.prepare_worker()\n        if self.options.print_options:\n            self.print_options()\n        self.run()", "response": "Main method to call to run the worker"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prepare_models(self):\n        if self.database_config:\n            for model in (self.options.queue_model, self.options.error_model):\n                model.database.reset(**self.database_config)", "response": "Prepares the models to be used for the queue and error models."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prepare_worker_options(self):\n        worker_options = dict()\n        for option_name in (self.options.worker_class.parameters):\n            option = getattr(self.options, option_name)\n            if option is not None:\n                worker_options[option_name] = option\n        return worker_options", "response": "Prepare and return all options to be passed to the worker"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprepares the worker for the current entry point.", "response": "def prepare_worker(self):\n        \"\"\"\n        Prepare the worker, ready to be launched: prepare options, create a\n        log handler if none, and manage dry_run options\n        \"\"\"\n        worker_options = self.prepare_worker_options()\n        self.worker = self.options.worker_class(**worker_options)\n        if self.update_title:\n            self.worker._add_update_status_callback(self.update_proc_title)\n            self.update_proc_title()\n\n        if not self.worker.logger.handlers:\n            handler = logging.StreamHandler()\n            handler.setFormatter(logging.Formatter(\n                                        ' '.join(['[%(process)d]',\n                                                  # '%(asctime)s,%(msecs).03d',\n                                                  '%(asctime)s',\n                                                  '(%(name)s)',\n                                                  '%(levelname)-8s',\n                                                  '%(message)s',\n                                                 ])\n                                        # , '%y.%m.%d:%H.%M.%S'\n                                    ))\n            self.worker.logger.addHandler(handler)\n\n        if self.options.dry_run:\n            self.worker.end_forced = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates the title for the current process", "response": "def get_proc_title(self):\n        \"\"\"\n        Create the title for the current process (set by `update_proc_title`)\n        \"\"\"\n        has_worker = bool(getattr(self, 'worker', None))\n\n        title_parts = [self.prog_name.replace('.py', ('#%s' % self.worker.id) if has_worker else '')]\n\n        status = 'init'\n        if has_worker and self.worker.status:\n            status = self.worker.status\n            if self.worker.end_forced:\n                status += ' - ending'\n        title_parts.append('[%s]' % status)\n\n        if has_worker and self.worker.queues:\n            title_parts.append('queues=%s' % ','.join(self.worker.queues))\n\n        if has_worker and self.worker.status:\n            # add infos about the main loop\n            title_parts.append('loop=%s/%s' % (self.worker.num_loops, self.worker.max_loops))\n\n            # and about the number of jobs to run\n            title_parts.append('waiting=%s' % self.worker.count_waiting_jobs())\n\n            # and about the number of delayed jobs\n            title_parts.append('delayed=%s' % self.worker.count_delayed_jobs())\n\n            # and about elapsed time\n            if self.worker.start_date:\n                duraiton_message = 'duration=%s'\n                duration_args = (timedelta(seconds=int(round(self.worker.elapsed.total_seconds()))), )\n                if self.worker.max_duration:\n                    duraiton_message += '/%s'\n                    duration_args += (self.worker.max_duration, )\n                title_parts.append(duraiton_message % duration_args)\n\n        return ' '.join(title_parts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef settable_options(doc, argv, ignore, options_first):\n    settable, booleans, repeatable, short_map = set(), set(), set(), dict()\n\n    # Determine which options are settable by docoptcfg and which ones are flags/booleans.\n    options = docopt.parse_defaults(doc)\n    short_map.update((o.short, o.long) for o in options)\n    parsed_argv = docopt.parse_argv(docopt.TokenStream(argv, docopt.DocoptExit), list(options), options_first)\n    overridden = [o.long for o in parsed_argv if hasattr(o, 'long')]\n    for option in options:\n        if option.long in overridden or (option.long in ignore or option.short in ignore):\n            continue\n        if option.argcount == 0:\n            booleans.add(option.long)\n        settable.add(option.long)\n\n    # Determine which options are repeatable.\n    if settable and '...' in doc:\n        pattern = docopt.parse_pattern(docopt.formal_usage(docopt.DocoptExit.usage), options)\n        for option in pattern.fix().flat():\n            if not hasattr(option, 'long'):\n                continue  # Positional argument or sub-command.\n            if getattr(option, 'long') not in settable:\n                continue  # Don't care about this if we can't set it.\n            if getattr(option, 'long') in booleans and getattr(option, 'value') == 0:\n                repeatable.add(getattr(option, 'long'))\n            elif hasattr(getattr(option, 'value'), '__iter__'):\n                repeatable.add(getattr(option, 'long'))\n\n    return settable, booleans, repeatable, short_map", "response": "Determine which options we can set by docoptcfg and which ones are boolean and which ones are repeatable."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_env(key, env_prefix, boolean, repeatable):\n    env_name = '{0}{1}'.format(env_prefix, key[2:].replace('-', '_').upper())\n\n    # Handle repeatable non-boolean options (e.g. --file=file1.txt --file=file2.txt).\n    if repeatable and not boolean:\n        values = list()\n        if env_name in os.environ:  # Optional variable not ending with integer.\n            values.append(os.environ[env_name])\n        for i in range(99):\n            env_name_i = '{0}{1}'.format(env_name, i)  # Loop until variable with integer not found.\n            if env_name_i not in os.environ:\n                break\n            values.append(os.environ[env_name_i])\n        if not values:\n            raise KeyError(env_name)  # Nothing found.\n        return values\n\n    if env_name not in os.environ:\n        raise KeyError(env_name)\n\n    # Handle repeatable booleans.\n    if repeatable and boolean:\n        try:\n            return int(os.environ[env_name])\n        except (TypeError, ValueError):\n            return 0\n\n    # Handle the rest.\n    if boolean:\n        return os.environ[env_name].strip().lower() in ('true', 'yes', 'on', '1')\n    return os.environ[env_name]", "response": "Get one value from environment variable."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all values from environment variables.", "response": "def values_from_env(env_prefix, settable, booleans, repeatable):\n    \"\"\"Get all values from environment variables.\n\n    :param str env_prefix: Argument from docoptcfg().\n    :param iter settable: Option long names available to set by config file.\n    :param iter booleans: Option long names of boolean/flag types.\n    :param iter repeatable: Option long names of repeatable options.\n\n    :return: Settable values.\n    :rtype: dict\n    \"\"\"\n    defaults_env = dict()\n    for key in settable:\n        try:\n            defaults_env[key] = get_env(key, env_prefix, key in booleans, key in repeatable)\n        except KeyError:\n            pass\n    return defaults_env"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets one value from config file.", "response": "def get_opt(key, config, section, booleans, repeatable):\n    \"\"\"Get one value from config file.\n\n    :raise DocoptcfgFileError: If an option is the wrong type.\n\n    :param str key: Option long name (e.g. --config).\n    :param ConfigParser config: ConfigParser instance with config file data already loaded.\n    :param str section: Section in config file to focus on.\n    :param iter booleans: Option long names of boolean/flag types.\n    :param iter repeatable: Option long names of repeatable options.\n\n    :return: Value to set in the defaults dict.\n    \"\"\"\n    # Handle repeatable non-boolean options (e.g. --file=file1.txt --file=file2.txt).\n    if key in repeatable and key not in booleans:\n        return config.get(section, key[2:]).strip('\\n').splitlines()\n\n    # Handle repeatable booleans.\n    if key in repeatable and key in booleans:\n        try:\n            return config.getint(section, key[2:])\n        except ValueError as exc:\n            raise DocoptcfgFileError('Repeatable boolean option \"{0}\" invalid.'.format(key[2:]), str(exc))\n\n    # Handle non-repeatable booleans.\n    if key in booleans:\n        try:\n            return config.getboolean(section, key[2:])\n        except ValueError as exc:\n            raise DocoptcfgFileError('Boolean option \"{0}\" invalid.'.format(key[2:]), str(exc))\n\n    # Handle the rest.\n    return str(config.get(section, key[2:]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse config file and read settable values.", "response": "def values_from_file(docopt_dict, config_option, settable, booleans, repeatable):\n    \"\"\"Parse config file and read settable values.\n\n    Can be overridden by both command line arguments and environment variables.\n\n    :raise DocoptcfgError: If `config_option` isn't found in docstring.\n    :raise DocoptcfgFileError: On any error while trying to read and parse config file.\n\n    :param dict docopt_dict: Dictionary from docopt with environment variable defaults merged in by docoptcfg().\n    :param str config_option: Config option long name with file path as its value.\n    :param iter settable: Option long names available to set by config file.\n    :param iter booleans: Option long names of boolean/flag types.\n    :param iter repeatable: Option long names of repeatable options.\n\n    :return: Settable values.\n    :rtype: dict\n    \"\"\"\n    section = docopt.DocoptExit.usage.split()[1]\n    settable = set(o for o in settable if o != config_option)\n    config = ConfigParser()\n    defaults = dict()\n\n    # Sanity checks.\n    if config_option not in docopt_dict:\n        raise DocoptcfgError\n    if docopt_dict[config_option] is None or not settable:\n        return defaults\n\n    # Read config file.\n    path = DocoptcfgFileError.FILE_PATH = docopt_dict[config_option]\n    try:\n        with open(path) as handle:\n            if hasattr(config, 'read_file'):\n                config.read_file(handle)\n            else:\n                getattr(config, 'readfp')(handle)\n    except Error as exc:\n        raise DocoptcfgFileError('Unable to parse config file.', str(exc))\n    except IOError as exc:\n        raise DocoptcfgFileError('Unable to read config file.', str(exc))\n\n    # Make sure section is in config file.\n    if not config.has_section(section):\n        raise DocoptcfgFileError('Section [{0}] not in config file.'.format(section))\n\n    # Parse config file.\n    for key in settable:\n        if config.has_option(section, key[2:]):\n            defaults[key] = get_opt(key, config, section, booleans, repeatable)\n\n    return defaults"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef docoptcfg(doc, argv=None, env_prefix=None, config_option=None, ignore=None, *args, **kwargs):\n    docopt_dict = docopt.docopt(doc, argv, *args, **kwargs)\n    if env_prefix is None and config_option is None:\n        return docopt_dict  # Nothing to do.\n    if argv is None:\n        argv = sys.argv[1:]\n    if ignore is None:\n        ignore = ('--help', '--version')\n    settable, booleans, repeatable, short_map = settable_options(doc, argv, ignore, kwargs.get('options_first', False))\n    if not settable:\n        return docopt_dict  # Nothing to do.\n\n    # Handle environment variables defaults.\n    if env_prefix is not None:\n        defaults = values_from_env(env_prefix, settable, booleans, repeatable)\n        settable -= set(defaults.keys())  # No longer settable by values_from_file().\n        docopt_dict.update(defaults)\n\n    # Handle config file defaults.\n    if config_option is not None:\n        defaults = values_from_file(\n            docopt_dict,\n            short_map.get(config_option, config_option),\n            settable,\n            booleans,\n            repeatable,\n        )\n        docopt_dict.update(defaults)\n\n    return docopt_dict", "response": "Parse a docstring and return a dictionary of options."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setRepoData(self, searchString, category=\"\", extension=\"\", math=False, game=False, searchFiles=False):\n\t\tself.searchString = searchString\n\t\tself.category = category\n\t\tself.math = math\n\t\tself.game = game\n\t\tself.searchFiles = searchFiles\n\t\tself.extension = extension", "response": "This method sets the values of all the settings that are used for future operations on a repository."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setOutputObject(self, newOutput=output.CalcpkgOutput(True, True)):\n\t\tself.output = newOutput", "response": "Set an object where all output will be redirected to for this repository"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches the index with all the repo s specified parameters", "response": "def searchIndex(self, printData=True):\n\t\t\"\"\"Search the index with all the repo's specified parameters\"\"\"\n\t\tbackupValue = copy.deepcopy(self.output.printData)\n\t\tself.output.printData = printData\n\t\tself.data = self.index.search(self.searchString, self.category, self.math, self.game, self.searchFiles, self.extension)\n\t\tself.output.printData = backupValue\n\t\treturn self.data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef countIndex(self):\n\t\tself.data = self.index.count(self.searchString, self.category, self.math, self.game, self.searchFiles, self.extension)", "response": "A wrapper for the count function in calcrepo. index ; count using specified parameters"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getDownloadUrls(self):\n\t\tdata = self.searchIndex(False)\n\t\tfileUrls = []\n\t\tfor datum in data:\n\t\t\tfileUrl = self.formatDownloadUrl(datum[0])\n\t\t\tfileUrls.append(fileUrl)\n\t\treturn fileUrls", "response": "Return a list of the urls to download from"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of FileInfo objects", "response": "def getFileInfos(self):\n\t\t\"\"\"Return a list of FileInfo objects\"\"\"\n\t\tdata = self.searchIndex(False)\n\t\tself.data = data\n\t\tself.printd(\" \")\n\t\tfileInfos = []\n\t\tfor datum in data:\n\t\t\ttry:\n\t\t\t\tfileInfo = self.getFileInfo(datum[0], datum[1])\n\t\t\t\tfileInfos.append(fileInfo)\n\t\t\texcept NotImplementedError:\n\t\t\t\tself.printd(\"Error: the info command is not supported for \" + self.name + \".\")\n\t\t\t\treturn []\n\t\treturn fileInfos"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef downloadFiles(self, prompt=True, extract=False):\n\t\t#First, get the download urls\n\t\tdata = self.data\n\t\tdownloadUrls = self.getDownloadUrls()\n\t\t\n\t\t#Then, confirm the user wants to do this\n\t\tif prompt:\n\t\t\tconfirm = raw_input(\"Download files [Y/N]? \")\n\t\t\tif confirm.lower() != 'y':\n\t\t\t\tself.printd(\"Operation aborted by user input\")\n\t\t\t\treturn\n\t\t\t\t\n\t\t#Now, if they still do, do all this stuff:\n\t\tcounter = -1\n\t\tfor datum in data:\n\t\t\tcounter += 1\n\t\t\ttry:\n\t\t\t\tdownload = downloadUrls[counter]\n\t\t\texcept:\n\t\t\t\tpass\n\t\t\t\t\n\t\t\t# Download the file; fix our user agent\n\t\t\tself.printd(\"Downloading \" + datum[0] + \" from \" + download)\n\t\t\theaders = { 'User-Agent' : 'calcpkg/2.0' }\n\t\t\trequest = urllib2.Request(download, None, headers)\n\t\t\tfileData = urllib2.urlopen(request).read()\n\t\t\t\n\t\t\t# Now, process the downloaded file\n\t\t\tdowName = datum[0]\n\t\t\t# Use a helper function to remove /pub, /files\n\t\t\tdowName = util.removeRootFromName(dowName)\n\t\t\tdowName = dowName[1:]\n\t\t\tdowName = dowName.replace('/', '-')\n\t\t\tdowName = self.downloadDir + dowName\n\t\t\ttry:\n\t\t\t\tdownloaded = open(dowName, 'wb')\n\t\t\texcept:\n\t\t\t\tos.remove(dowName)\n\t\t\tdownloaded.write(fileData)\n\t\t\tdownloaded.close()\n\t\t\tself.printd(\"Download complete! Wrote file \" + dowName + \"\\n\")\n\n\t\t\t#Extract them if told to do so\n\t\t\tif extract:\n\t\t\t\textractType = \"\"\n\t\t\t\tif '.zip' in dowName:\n\t\t\t\t\textractType = \"zip\"\n\t\t\t\telif '.tar' in dowName:\n\t\t\t\t\textractType = \"tar\"\n\t\t\t\t\tspecType = \"\"\n\t\t\t\t\tif '.bz2' in dowName:\n\t\t\t\t\t\tspecType = \":bz2\"\n\t\t\t\t\telif \".gz\" in dowName:\n\t\t\t\t\t\tspecType = \":gz\"\n\t\t\t\telif \".tgz\" in dowName:\n\t\t\t\t\textractType = \"tar\"\n\t\t\t\t\tspecType = \":gz\"\n\n\t\t\t\tif extractType != \"\":\n\t\t\t\t\tself.printd(\"Extracting file \" + dowName + \", creating directory for extracted files\")\n\t\t\t\t\tdirName, a, ending = dowName.partition('.')\n\t\t\t\t\tdirName = dirName + '-' + ending\n\t\t\t\t\ttry:\n\t\t\t\t\t\tos.mkdir(dirName)\n\t\t\t\t\texcept:\n\t\t\t\t\t\tpass\n\t\t\t\t\tif extractType == \"zip\":\n\t\t\t\t\t\tarchive = zipfile.ZipFile(dowName, 'r')\n\t\t\t\t\telif extractType == \"tar\":\n\t\t\t\t\t\tarchive = tarfile.open(dowName, \"r\" + specType)\n\t\t\t\t\telse:\n\t\t\t\t\t\tself.printd(\"An unknown error has occured!\")\n\t\t\t\t\t\treturn\n\t\t\t\t\tarchive.extractall(dirName)\n\t\t\t\t\tself.printd(\"All files in archive extracted to \" + dirName)\n\t\t\t\t\tos.remove(dowName)\n\t\t\t\t\tself.printd(\"The archive file \" + dowName + \" has been deleted!\\n\")", "response": "Download files from the repository"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a URL download the specified file", "response": "def downloadFileFromUrl(self, url):\n\t\t\"\"\"Given a URL, download the specified file\"\"\"\n\t\tfullurl = self.baseUrl + url\n\t\ttry:\n\t\t\turlobj = urllib2.urlopen(fullurl)\n\t\t\tcontents = urlobj.read()\n\t\texcept urllib2.HTTPError, e:\n\t\t\tself.printd(\"HTTP error:\", e.code, url)\n\t\t\treturn None\n\t\texcept urllib2.URLError, e:\n\t\t\tself.printd(\"URL error:\", e.code, url)\n\t\t\treturn None\n\t\tself.printd(\"Fetched '%s' (size %d bytes)\" % (fullurl, len(contents)))\n\t\treturn contents"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef openIndex(self, filename, description):\n\t\ttry:\n\t\t\tos.remove(filename)\n\t\t\tself.printd(\"  Deleted old \" + description)\n\t\texcept:\n\t\t\tself.printd(\"  No \" + description + \" found\")\n\t\t\t\n\t\t# Now, attempt to open a new index\n\t\ttry:\n\t\t\tfiles = open(filename, 'wt')\n\t\texcept:\n\t\t\tself.printd(\"Error: Unable to create file \" + filename + \" in current folder. Quitting.\")\n\t\t\treturn None\n\t\treturn files", "response": "Attempt to delete and recreate an index returns open file object or None."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading an HTK model from one ore more files.", "response": "def load_model(*args):\n    \"\"\"Load an HTK model from one ore more files.\n\n    :param args: Filenames of the model (e.g. macros hmmdefs)\n    :return: The model as an OrderedDict()\n    \"\"\"\n    text = ''\n    for fnm in args:\n        text += open(fnm).read()\n        text += '\\n'\n\n    parser = htk_model_parser.htk_modelParser()\n    model = HtkModelSemantics()\n    return parser.parse(text,\n                        rule_name='model',\n                        ignorecase=True,\n                        semantics=model,\n                        comments_re=\"\\(\\*.*?\\*\\)\",\n                        trace=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves the HTK model into a file.", "response": "def save_model(model, filename):\n    \"\"\"Save the model into a file.\n\n    :param model: HTK model to be saved\n    :param filename: File where to save the model\n    \"\"\"\n    with open(filename, 'w') as f:\n        f.write(serialize_model(model))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef serialize_model(model):\n\n    result = ''\n\n    # First serialize the macros\n    for macro in model['macros']:\n        if macro.get('options', None):\n            result += '~o '\n            for option in macro['options']['definition']:\n                result += _serialize_option(option)\n\n        elif macro.get('transition', None):\n            result += '~t \"{}\"\\n'.format(macro['transition']['name'])\n            result += _serialize_transp(macro['transition']['definition'])\n\n        elif macro.get('variance', None):\n            result += '~v \"{}\"\\n'.format(macro['variance']['name'])\n            result += _serialize_variance(macro['variance']['definition'])\n\n        elif macro.get('state', None):\n            result += '~s \"{}\"\\n'.format(macro['state']['name'])\n            result += _serialize_stateinfo(macro['state']['definition'])\n\n        elif macro.get('mean', None):\n            result += '~u \"{}\"\\n'.format(macro['mean']['name'])\n            result += _serialize_mean(macro['mean']['definition'])\n\n        elif macro.get('duration', None):\n            result += '~d \"{}\"\\n'.format(macro['duration']['name'])\n            result += _serialize_duration(macro['duration']['definition'])\n\n        else:\n            raise NotImplementedError('Cannot serialize {}'.format(macro))\n\n    for hmm in model['hmms']:\n        if hmm.get('name', None) is not None:\n            result += '~h \"{}\"\\n'.format(hmm['name'])\n\n        result += _serialize_hmm(hmm['definition'])\n\n    return result", "response": "Serialize the HTK model into a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncrop a list of strings to the specified width height", "response": "def _do_crop(self, lines, width, height, x_crop, y_crop):\n        '''Crops a list of strings to the specified width/height\n        '''\n        lines = crop_or_expand(\n            lines, height, default=[self.fillchar * width],\n            scheme=self._schemes[y_crop])\n        for i, line in enumerate(lines):\n            lines[i] = crop_or_expand(\n                line, width, default=self.fillchar,\n                scheme=self._schemes[x_crop])\n        return lines"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading all the native goldman resources.", "response": "def _load_resources(self):\n        \"\"\" Load all the native goldman resources.\n\n        The route or API endpoint will be automatically determined\n        based on the resource object instance passed in.\n\n        INFO: Only our Model based resources are supported when\n              auto-generating API endpoints.\n        \"\"\"\n\n        for resource in self.RESOURCES:\n            if isinstance(resource, goldman.ModelsResource):\n                route = '/%s' % resource.rtype\n            elif isinstance(resource, goldman.ModelResource):\n                route = '/%s/{rid}' % resource.rtype\n            elif isinstance(resource, goldman.RelatedResource):\n                route = '/%s/{rid}/{related}' % resource.rtype\n            else:\n                raise TypeError('unsupported resource type')\n\n            self.add_route(*(route, resource))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _error_serializer(req, exc):  # pylint: disable=unused-argument\n\n        error = {\n            'detail': exc.description,\n            'title': exc.title,\n            'status': exc.status,\n        }\n\n        try:\n            error['links'] = {'about': exc.link['href']}\n        except (TypeError, KeyError):\n            error['links'] = {'about': ''}\n\n        return (\n            goldman.config.JSONAPI_MIMETYPE,\n            json.dumps({'errors': [error]}),\n        )", "response": "Returns a serializer for native falcon HTTPError exceptions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding peakset from the dataset.", "response": "def find_peakset(dataset, basecolumn=-1, method='', where=None):\n    \"\"\"\n    Find peakset from the dataset\n\n    Parameters\n    -----------\n    dataset : list\n        A list of data\n    basecolumn : int\n        An index of column for finding peaks\n    method : str\n        A method name of numpy for finding peaks\n    where : function\n        A function which recieve ``data`` and return numpy indexing list\n\n    Returns\n    -------\n    list\n        A list of peaks of each axis (list)\n    \"\"\"\n    peakset = []\n    where_i = None\n    for data in dataset:\n        base = data[basecolumn]\n        base = maidenhair.statistics.average(base)\n        # limit data points\n        if where:\n            adata = [maidenhair.statistics.average(x) for x in data]\n            where_i = np.where(where(adata))\n            base = base[where_i]\n        # find peak index\n        index = getattr(np, method, np.argmax)(base)\n        # create peakset\n        for a, axis in enumerate(data):\n            if len(peakset) <= a:\n                peakset.append([])\n            if where_i:\n                axis = axis[where_i]\n            peakset[a].append(axis[index])\n    peakset = np.array(peakset)\n    return peakset"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normalise_string(string):\n    string = (string.strip()).lower()\n    return re.sub(r'\\W+', '_', string)", "response": "Strips trailing whitespace from string lowercases it and replaces\n        spaces with underscores"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef json_decode(data):\n    if isinstance(data, six.binary_type):\n        data = data.decode('utf-8')\n\n    return json.loads(data)", "response": "Decodes the given JSON as primitives\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gridLog(**kw):\n    import os\n\n    if not bool( int(os.environ.get('GRIDLOG_ON', 0)) ):\n        return\n\n    url = os.environ.get('GRIDLOG_DEST')\n    if url is None: \n        return\n\n    ## NOTE: urlparse problem w/customized schemes \n    try:\n        scheme = url[:url.find('://')]\n        send = GLRegistry[scheme]\n        send( url, str(GLRecord(**kw)), )\n    except Exception, ex:\n        print >>sys.stderr, \"*** gridLog failed -- %s\" %(str(kw))", "response": "Send GLRecord Distributed Logging Utilities\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite a string to the log file.", "response": "def write(self, *args):\n        '''Write convenience function; writes strings.\n        '''\n        for s in args: self.out.write(s)\n        event = ''.join(*args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves the current counters measurements.", "response": "def _save(self, counters):\n        \"\"\"\n        Saves the current counters measurements.\n\n        :param counters: current counters measurements to be saves.\n        \"\"\"\n        if self._logger == None:\n            return\n        if len(counters) == 0:\n            return\n\n        # Sort counters by name\n        counters = sorted(counters, key=LogCounters._get_counter_name)\n\n        for counter in counters:\n            self._logger.info(\"counters\", self._counter_to_string(counter))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntransforms code conventions to human readable strings", "response": "def humanize(text):\n    '''Transform code conventions to human readable strings'''\n    words = []\n    for part in text.split('_'):\n        for word in RE_CAMEL.findall(part) or [part]:\n            words.append(word.lower())\n    words[0] = words[0].title()\n    return ' '.join(words)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn true if properly visiting the object returns only the object itself.", "response": "def is_visit_primitive(obj):\n    '''Returns true if properly visiting the object returns only the object itself.'''\n    from .base import visit\n    if (isinstance(obj, tuple(PRIMITIVE_TYPES)) and not isinstance(obj, STR)\n        and not isinstance(obj, bytes)):\n        return True\n    if (isinstance(obj, CONTAINERS) and not isinstance(obj, STR) and not\n        isinstance(obj, bytes)):\n        return False\n    if isinstance(obj, STR) or isinstance(obj, bytes):\n        if len(obj) == 1:\n            return True\n        return False\n    return list(visit(obj, max_enum=2)) == [obj]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef configure(self, config):\n        self._timeout = config.get_as_long_with_default(\"options.timeout\", self._default_timeout)\n        self._max_size = config.get_as_long_with_default(\"options.max_size\", self._default_max_size)", "response": "Configures the component by passing configuration parameters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclear the component state.", "response": "def clear(self, correlation_id):\n        \"\"\"\n        Clears component state.\n\n        :param correlation_id: (optional) transaction id to trace execution through call chain.\n        \"\"\"\n        self._lock.acquire()\n        try:\n            self._cache = {}\n        finally:\n            self._lock.release()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rest_verbs(http_method_names=None):\n\n    \"\"\"\n    Decorator that converts a function-based view into an RestView subclass.\n    Takes a list of allowed methods for the view as an argument.\n    \"\"\"\n    http_method_names = ['GET'] if (http_method_names is None) else http_method_names\n\n    def decorator(func):\n\n        WrappedRestView = type(\n            six.PY3 and 'WrappedRestView' or b'WrappedRestView',\n            (RestView,),\n            {'__doc__': func.__doc__}\n        )\n\n        # Note, the above allows us to set the docstring.\n        # It is the equivalent of:\n        #\n        #     class WrappedRestView(RestView):\n        #         pass\n        #     WrappedRestView.__doc__ = func.doc    <--- Not possible to do this\n\n        # api_view applied without (method_names)\n        assert not(isinstance(http_method_names, types.FunctionType)), \\\n            '@api_view missing list of allowed HTTP methods'\n\n        # api_view applied with eg. string instead of list of strings\n        assert isinstance(http_method_names, (list, tuple)), \\\n            '@api_view expected a list of strings, received %s' % type(http_method_names).__name__\n\n        allowed_methods = set(http_method_names) | set(('options',))\n        WrappedRestView.http_method_names = [method.lower() for method in allowed_methods]\n\n        def handler(self, *args, **kwargs):\n            return func(*args, **kwargs)\n\n        for method in http_method_names:\n            setattr(WrappedRestView, method.lower(), handler)\n\n        WrappedRestView.__name__ = func.__name__\n\n        WrappedRestView.renderer_classes = getattr(func, 'renderer_classes',\n                                                  RestView.renderer_classes)\n\n        WrappedRestView.parser_classes = getattr(func, 'parser_classes',\n                                                RestView.parser_classes)\n\n        WrappedRestView.authentication_classes = getattr(func, 'authentication_classes',\n                                                        RestView.authentication_classes)\n\n        WrappedRestView.throttle_classes = getattr(func, 'throttle_classes',\n                                                  RestView.throttle_classes)\n\n        WrappedRestView.permission_classes = getattr(func, 'permission_classes',\n                                                    RestView.permission_classes)\n\n        return WrappedRestView.as_view()\n    return decorator", "response": "Decorator that converts a function - based view into a RestView subclass."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a new object from the given input protocol and returns the object.", "response": "def read(cls, iprot):\n        '''\n        Read a new object from the given input protocol and return the object.\n\n        :type iprot: thryft.protocol._input_protocol._InputProtocol\n        :rtype: pastpy.gen.database.database_configuration.DatabaseConfiguration\n        '''\n\n        init_kwds = {}\n\n        iprot.read_struct_begin()\n        while True:\n            ifield_name, ifield_type, _ifield_id = iprot.read_field_begin()\n            if ifield_type == 0:  # STOP\n                break\n            elif ifield_name == 'dbf':\n                init_kwds['dbf'] = pastpy.gen.database.impl.dbf.dbf_database_configuration.DbfDatabaseConfiguration.read(iprot)\n            elif ifield_name == 'dummy':\n                init_kwds['dummy'] = pastpy.gen.database.impl.dummy.dummy_database_configuration.DummyDatabaseConfiguration.read(iprot)\n            elif ifield_name == 'online':\n                init_kwds['online'] = pastpy.gen.database.impl.online.online_database_configuration.OnlineDatabaseConfiguration.read(iprot)\n            iprot.read_field_end()\n        iprot.read_struct_end()\n\n        return cls(**init_kwds)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write(self, oprot):\n        '''\n        Write this object to the given output protocol and return self.\n\n        :type oprot: thryft.protocol._output_protocol._OutputProtocol\n        :rtype: pastpy.gen.database.database_configuration.DatabaseConfiguration\n        '''\n\n        oprot.write_struct_begin('DatabaseConfiguration')\n\n        if self.dbf is not None:\n            oprot.write_field_begin(name='dbf', type=12, id=None)\n            self.dbf.write(oprot)\n            oprot.write_field_end()\n\n        if self.dummy is not None:\n            oprot.write_field_begin(name='dummy', type=12, id=None)\n            self.dummy.write(oprot)\n            oprot.write_field_end()\n\n        if self.online is not None:\n            oprot.write_field_begin(name='online', type=12, id=None)\n            self.online.write(oprot)\n            oprot.write_field_end()\n\n        oprot.write_field_stop()\n\n        oprot.write_struct_end()\n\n        return self", "response": "Writes the object to the given output protocol and returns self."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of all stations IDs", "response": "def get_stations(self):\n        \"\"\" Return a list of all stations IDs \"\"\"\n        request = requests.get(\"{}/stations\".format(\n            self.base_url))\n        if request.status_code != 200:\n            return None\n        return request.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_station_temperature_datetime(self, station_id):\n        request = requests.get(\n            \"{}/station/{}/parameters/temperature/datetime\".format(\n                self.base_url, station_id))\n        if request.status_code != 200:\n            return None\n        return datetime.strptime(request.json(), \"%Y-%m-%dT%H:%M:%S\")", "response": "Return the temperature measurement datetime for a given station"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_station_temperature_value(self, station_id):\n        request = requests.get(\n            \"{}/station/{}/parameters/temperature/value\".format(\n                self.base_url, station_id))\n        if request.status_code != 200:\n            return None\n        return request.json()", "response": "Get the temperature value for a given station"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if an email might be valid by getting the status from the SMTP server.", "response": "def check_email_status(mx_resolver, recipient_address, sender_address, smtp_timeout=10, helo_hostname=None):\n    \"\"\"\n    Checks if an email might be valid by getting the status from the SMTP server.\n\n    :param mx_resolver: MXResolver\n    :param recipient_address: string\n    :param sender_address: string\n    :param smtp_timeout: integer\n    :param helo_hostname: string\n    :return: dict\n    \"\"\"\n    domain = recipient_address[recipient_address.find('@') + 1:]\n    if helo_hostname is None:\n        helo_hostname = domain\n\n    ret = {'status': 101, 'extended_status': None, 'message': \"The server is unable to connect.\"}\n\n    records = []\n    try:\n        records = mx_resolver.get_mx_records(helo_hostname)\n    except socket.gaierror:\n        ret['status'] = 512\n        ret['extended_status'] = \"5.1.2 Domain name address resolution failed in MX lookup.\"\n\n    smtp = smtplib.SMTP(timeout=smtp_timeout)\n\n    for mx in records:\n        try:\n            connection_status, connection_message = smtp.connect(mx.exchange)\n            if connection_status == 220:\n                smtp.helo(domain)\n                smtp.mail(sender_address)\n                status, message = smtp.rcpt(recipient_address)\n                ret['status'] = status\n\n                pattern = re.compile('(\\d+\\.\\d+\\.\\d+)')\n                matches = re.match(pattern, message)\n                if matches:\n                    ret['extended_status'] = matches.group(1)\n\n                ret['message'] = message\n            smtp.quit()\n            break\n        except smtplib.SMTPConnectError:\n            ret['status'] = 111\n            ret['message'] = \"Connection refused or unable to open an SMTP stream.\"\n        except smtplib.SMTPServerDisconnected:\n            ret['status'] = 111\n            ret['extended_status'] = \"SMTP Server disconnected\"\n        except socket.gaierror:\n            ret['status'] = 512\n            ret['extended_status'] = \"5.1.2 Domain name address resolution failed.\"\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeclares a namespace prefix Use prefix = None to set the default namespace.", "response": "def start_namespace(self, prefix, uri):\n        \"\"\" Declare a namespace prefix\n\n        Use prefix=None to set the default namespace.\n        \"\"\"\n        self._g.startPrefixMapping(prefix, uri)\n        self._ns[prefix] = uri"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resolve_namespace(self, qname):\n        if ':' in qname:\n            prefix, name = qname.split(':', 1)\n            uri = self._ns[prefix]\n        else:\n            name = qname\n            if None in self._ns:\n                uri = self._ns[None]\n            else:\n                uri = None\n        return (uri, name)", "response": "Obtain the uri and name from a qualified name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_colors(n):\n\n    import matplotlib.pyplot as plt\n    from matplotlib.colors import rgb2hex as r2h\n    from numpy import linspace\n\n    cols = linspace(0.05, .95, n)\n    cmap = plt.get_cmap('nipy_spectral')\n    return [r2h(cmap(i)) for i in cols]", "response": "Returns n unique and evenly spaced colors for the backgrounds\n    of the projects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking a color like 0x87c95f and produces a lighter or darker variant.", "response": "def _color_variant(hex_color, brightness_offset=1):\n    \"\"\"Takes a color like #87c95f and produces a lighter or darker variant.\n    Code adapted from method proposed by Chase Seibert at:\n    http://chase-seibert.github.io/blog/2011/07/29/python-calculate-lighterdarker-rgb-colors.html.\n    \n    Args:\n        hex_color (str): The original hex color.\n        brightness_offset (int): The amount to shift the color by.\n\n    Returns:\n        new_color (str): The new hex color variant.\n\n    Raises:\n        Exception: if the len of the hex_color isn't the appropriate length (7).\n    \"\"\"\n    if len(hex_color) != 7:\n        raise Exception(\"Passed %s into color_variant(), needs to be in #87c95f format.\" % hex_color)\n    rgb_hex = [hex_color[x:x+2] for x in [1, 3, 5]]\n    new_rgb_int = [int(hex_value, 16) + brightness_offset for hex_value in rgb_hex]\n    new_rgb_int = [min([255, max([0, i])]) for i in new_rgb_int] # make sure new values are between 0 and 255\n    # hex() produces \"0x88\", we want just \"88\"\n    new_color = \"#\"\n    for i in new_rgb_int:\n        if len(hex(i)[2:]) == 2:\n            new_color += hex(i)[2:]\n        else:\n            new_color += hex(i)[2:] + \"0\"\n\n    return new_color"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of dictionaries in which each project is a key and the list of tasks are stored as a list within that dictionaly element.", "response": "def _make_projcet_list(path):\n    \"\"\"Returns a dictionaries in which each project is a key and the\n    tasks are stored as a list within that dictionaly element.\n    \n    Args:\n        path (str): The path to the folder containing the *.json files.\n    \n    Returns:\n        projects (list of dict): A dictionary in which each project is a key \n          containing a list of it's tasks.\n    \"\"\"\n    from collections import OrderedDict\n    from matplotlib.colors import LinearSegmentedColormap\n    from matplotlib.colors import rgb2hex as r2h\n    from numpy import linspace\n    \n    proj = []\n    projects = OrderedDict()\n    file_list = os.listdir(path)\n    for files in file_list:\n        if files.split(\".\")[0] not in proj and 'json' in files and \"#\" not in files and \"~\" not in files:\n            proj.append(files.split(\".\")[0])\n\n    # get the background color for each project.\n    colors = _get_colors(len(proj))\n    p_c = 0\n\n    for p in proj:\n        tasks = OrderedDict()\n        temp = [x.split(\".\")[1] for x in file_list if p in x and \"#\" not in x and \"~\" not in x]\n        cmspace = linspace(0.95, 0.25, len(temp))\n        cm = LinearSegmentedColormap.from_list(\"acorn.{}\".format(p),\n                                               ['#ffffff', colors[p_c]],\n                                               N=max((len(temp), 25)))\n        hues = [r2h(cm(cmi)) for cmi in cmspace]\n        h_c = 0\n        for t in temp:\n            tasks[t] = [hues[h_c],p+\".\"+t+\".json\"]\n            h_c += 1\n        tasks[\"hex_color\"] = colors[p_c]\n        projects[p] = tasks\n        p_c += 1\n        \n    return projects"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copy_graph(subject, existing_graph):\n    new_graph = rdflib.Graph()\n    for predicate, object_ in existing_graph.predicate_objects():\n        new_graph.add((subject, predicate, object_))\n    return new_graph", "response": "Function takes a subject and an existing graph returns a new graph with all predicate and objects of the existing graph copied to the new graph with\n    subject as the new subject\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize a Flask app object for the extension.", "response": "def init_app(self, app):\n        \"\"\"\n        Initializes a Flask app object for the extension.\n\n        Args:\n            app(Flask): Flask app\n        \"\"\"\n        app.config.setdefault('FEDORA_BASE_URL', 'http://localhost:8080')\n        if hasattr(app, 'teardown_appcontext'):\n            app.teardown_appcontext(self.teardown)\n        else:\n            app.teardown_request(self.teardown)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef connect(self,\n                fedora_url,\n                data=None,\n                method='Get'):\n        \"\"\"Method attempts to connect to REST servers of the Fedora\n        Commons repository using optional data parameter.\n\n        Args:\n            fedora_url(string): Fedora URL\n            data(dict): Data to through to REST endpoint\n            method(str): REST Method, defaults to GET\n\n        Returns:\n            result(string): Response string from Fedora\n\n        \"\"\"\n        if data is None:\n            data = {}\n        if not fedora_url.startswith(\"http\"):\n            fedora_url = urllib.parse.urljoin(self.base_url, fedora_url)\n        request = urllib.request.Request(fedora_url,\n                                         method=method)\n        request.add_header('Accept', 'text/turtle')\n        request.add_header('Content-Type', 'text/turtle')\n        if len(data) > 0:\n            request.data = data\n        try:\n            response = urllib.request.urlopen(request)\n        except urllib.error.URLError as err:\n            if hasattr(err, 'reason'):\n                print(\"failed to reach server at {} with {} method\".format(\n                    fedora_url,\n                    request.method))\n                print(\"Reason: \", err.reason)\n                print(\"Data: \", data)\n            elif hasattr(err, 'code'):\n                print(\"Server error {}\".format(err.code))\n            raise err\n        return response", "response": "Method attempts to connect to the Fedora Commons repository using optional data parameter."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(self, uri=None, graph=None, data=None):\n        if uri is not None:\n            existing_entity = self.__dedup__(rdflib.URIRef(uri), graph)\n            if existing_entity is not None:\n                return # Returns nothing\n        else:\n            default_request = urllib.request.Request(\n                \"/\".join([self.base_url, \"rest\"]),\n                method='POST')\n            uri = urllib.request.urlopen(default_request).read().decode()\n        if graph is not None:\n            new_graph = copy_graph(rdflib.URIRef(uri), graph)\n            create_response = self.connect(\n                uri,\n                data=new_graph.serialize(format='turtle'),\n                method='PUT')\n            raw_response = create_response.read()\n        return uri", "response": "Method creates a new object in Fedora."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef exists(self, uri):\n        ##entity_uri = \"/\".join([self.base_url, entity_id])\n        try:\n            urllib.request.urlopen(uri)\n            return True\n        except urllib.error.HTTPError:\n            return False", "response": "Method returns true is the entity exists in the Repository false otherwise"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef flush(self):\n        base_graph = rdflib.Graph().parse('{}/rest'.format(self.base_url))\n        has_child = rdflib.URIRef(\n            'http://fedora.info/definitions/v4/repository#hasChild')\n        for obj in base_graph.objects(predicate=has_child):\n            self.delete(str(obj))", "response": "Method flushes repository deleting all objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef insert(self,\n               entity_id,\n               property_uri,\n               value):\n        \"\"\"Method inserts a new entity's property in Fedora4 Repository\n\n        Args:\n            entity_id(string): Unique ID of Fedora object\n            property_uri(string): URI of property\n            value: Value of the property, can be literal or URI reference\n\n        Returns:\n            boolean: True if successful changed in Fedora, False otherwise\n        \"\"\"\n        if not entity_id.startswith(\"http\"):\n            entity_uri = urllib.parse.urljoin(self.base_url, entity_id)\n        else:\n            entity_uri = entity_id\n        if entity_uri.endswith(\"/\"):\n            entity_uri = entity_uri[:-1]\n        if not entity_id.endswith(\"fcr:metadata\"):\n            entity_uri = \"/\".join([entity_uri, \"fcr:metadata\"])\n        if not self.exists(entity_id):\n            self.create(entity_id)\n        sparql_template = Template(\"\"\"$prefix\n        INSERT DATA {\n             <$entity> $prop_uri $value_str ;\n        }\"\"\")\n        sparql = sparql_template.substitute(\n            prefix=build_prefixes(self.namespaces),\n            entity=entity_uri,\n            prop_uri=property_uri,\n            value_str=self.__value_format__(value))\n        update_request = urllib.request.Request(\n            entity_uri,\n            data=sparql.encode(),\n            method='PATCH',\n            headers={'Content-Type': 'application/sparql-update'})\n        try:\n            response = urllib.request.urlopen(update_request)\n        except urllib.error.HTTPError:\n            print(\"Error trying patch {}, sparql=\\n{}\".format(entity_uri,\n                sparql))\n            return False\n        if response.code < 400:\n            return True\n        return False", "response": "Method inserts a new property in Fedora4 Repository"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove(self,\n               entity_id,\n               property_uri,\n               value):\n        \"\"\"Method removes a triple for the given/subject.\n\n        Args:\n            entity_id(string): Fedora Object ID, ideally URI of the subject\n            property_uri(string):\n            value(string):\n\n        Return:\n            boolean: True if triple was removed from the object\n        \"\"\"\n        if not entity_id.startswith(\"http\"):\n            entity_uri = urllib.parse.urljoin(self.base_url, entity_id)\n        else:\n            entity_uri = entity_id\n        sparql_template = Template(\"\"\"$prefix\n        DELETE {\n            <$entity> $prop_name $value_str\n        } WHERE {\n            <$entity> $prop_name $value_str\n        }\"\"\")\n        sparql = sparql_template.substitute(\n            prefix=build_prefixes(self.namespaces),\n            entity=entity_uri,\n            prop_name=property_uri,\n            value_str=self.__value_format__(value))\n        delete_property_request = urllib.request.Request(\n            entity_uri,\n            data=sparql.encode(),\n            method='PATCH',\n            headers={'Content-Type': 'application/sparql-update'})\n        response = urllib.request.urlopen(delete_property_request)\n        if response.code < 400:\n            return True\n        return False", "response": "Method removes a triple from the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace(self,\n                entity_id,\n                property_name,\n                old_value,\n                value):\n        \"\"\"Method replaces a triple for the given entity/subject. Property\n        name is from the schema.org vocabulary.\n\n        Args:\n            entity_id(string): Unique ID of Fedora object\n            property_name(string): Prefix and property name i.e. schema:name\n            old_value(string): Literal or URI of old value\n            value(string): Literal or new value\n        \"\"\"\n        if not entity_id.startswith(\"http\"):\n            entity_uri = '/'.join([self.base_url, self.transaction, entity_id])\n        else:\n            entity_uri = entity_id\n        sparql_template = Template(\"\"\"$prefix\n            DELETE {\n             <$entity> $prop_name $old_value\n            } INSERT {\n             <$entity> $prop_name $new_value\n            } WHERE {\n            }\"\"\")\n        sparql = sparql_template.substitute(\n            prefix=build_prefixes(self.namespaces),\n            entity=entity_uri,\n            prop_name=property_name,\n            old_value=self.__value_format__(old_value),\n            new_value=self.__value_format__(value))\n        update_request = urllib.request.Request(\n            entity_uri,\n            data=sparql.encode(),\n            method='PATCH',\n            headers={'Content-Type': 'application/sparql-update'})\n        response = urllib.request.urlopen(update_request)\n        if response.code < 400:\n            return True\n        return False", "response": "Method replaces a triple for the given entity with the given property name and value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndepreciate Method searches Fedora Repository using SPARQL search endpoint and returns a RDF graph of the search results.", "response": "def search(self, query_term):\n        \"\"\"DEPRECIATED\n        Method takes a query term and searches Fedora Repository using SPARQL\n        search endpoint and returns a RDF graph of the search results.\n\n        Args:\n            query_term(str): String to search repository\n\n        Returns:\n            rdflib.Graph()\n        \"\"\"\n        fedora_search_url = \"/\".join([self.base_url, 'rest', 'fcr:search'])\n        fedora_search_url = \"{}?{}\".format(\n            fedora_search_url,\n            urllib.parse.urlencode({\"q\": query_term}))\n        search_request = urllib.request.Request(\n            fedora_search_url,\n            method='GET')\n        search_request.add_header('Accept', 'text/turtle')\n        try:\n            search_response = urllib.request.urlopen(search_request)\n        except urllib.error.URLError as error:\n            raise error\n        fedora_results = rdflib.Graph().parse(\n            data=search_response.read(),\n            format='turtle')\n        return fedora_results"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sparql(self, statement, end_point='fcr:sparql', accept_format='text/csv'):\n        request = urllib.request.Request(\n            '/'.join([self.base_url, 'rest', end_point]),\n            data=statement.encode(),\n            method='POST',\n            headers={\"Context-Type\": \"application/sparql-query\",\n                     \"Accept\": accept_format})\n        result = urllib.request.urlopen(request)\n        return result.read().decode()", "response": "DEPRECIATED\n            Method takes and executes a generic SPARQL statement and returns the result."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the current season based on now and gives a dummy temperature", "response": "def _get_season(_datetime: typing.Optional[date] = None) -> typing.Tuple[str, int]:\n    \"\"\"\n    Finds the current season based on now() and gives a dummy temperature\n\n    Returns: tuple of season name, temperature\n\n    \"\"\"\n    if _datetime is None:\n        _actual_datetime: date = datetime.now().date().replace(year=Y)\n    else:\n        _actual_datetime = _datetime.replace(year=Y)\n    return next((season, temp) for season, temp, (start, end) in SEASONS if start <= _actual_datetime <= end)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _normalize_direction(heading: int) -> int:\n        while heading > 359:\n            heading = int(heading - 359)\n        while heading < 0:\n            heading = int(heading + 359)\n        return heading", "response": "Normalizes the heading to be between 0 and 360."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _gauss(mean: int, sigma: int) -> int:\n        return int(random.gauss(mean, sigma))", "response": "Returns a random value from a base value with a gaussian distribution"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _randomize_speed(base_speed: int, sigma: int = None) -> int:\n        if sigma is None:\n            int_sigma = int(base_speed / 4)\n        else:\n            int_sigma = sigma\n        val = MissionWeather._gauss(base_speed, int_sigma)\n        if val < 0:\n            return 0\n        return min(val, 50)", "response": "Returns a random speed in the wind speed base_speed and sigma value for gaussian variation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _randomize_direction(base_heading, sigma) -> int:\n        val = MissionWeather._gauss(base_heading, sigma)\n        val = MissionWeather._normalize_direction(val)\n        return val", "response": "Returns a randomized direction in the current weather."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef apply_to_miz(self, miz):\n\n        report = ['Building mission with weather:']\n\n        miz.mission.weather.wind_at_ground_level_dir = self.wind_at_ground_level_dir\n        miz.mission.weather.wind_at_ground_level_speed = self.wind_at_ground_level_speed\n        miz.mission.weather.wind_at2000_dir = self._randomize_direction(self.wind_dir, 40)\n        miz.mission.weather.wind_at2000_speed = self._randomize_speed(5 + self.wind_at_ground_level_speed * 2)\n        miz.mission.weather.wind_at8000_dir = self._randomize_direction(self.wind_dir, 80)\n        miz.mission.weather.wind_at8000_speed = self._randomize_speed(10 + self.wind_at_ground_level_speed * 3)\n        miz.mission.weather.turbulence_at_ground_level = self.turbulence\n\n        _ground = f'{miz.mission.weather.wind_at_ground_level_dir}/{miz.mission.weather.wind_at_ground_level_speed}'\n        _at2000 = f'{miz.mission.weather.wind_at2000_dir}/{miz.mission.weather.wind_at2000_speed}'\n        _at8000 = f'{miz.mission.weather.wind_at8000_dir}/{miz.mission.weather.wind_at8000_speed}'\n        _turbulence = f'{miz.mission.weather.turbulence_at_ground_level}'\n\n        wind = f'Wind:' \\\n               f'\\n\\tGround: {_ground}' \\\n               f'\\n\\t2000m: {_at2000}' \\\n               f'\\n\\t8000m: {_at8000}' \\\n               f'\\n\\tTurbulence: {_turbulence}'\n\n        report.append(wind)\n\n        miz.mission.weather.atmosphere_type = 0\n        miz.mission.weather.qnh = self.qnh\n\n        report.append(f'Atmosphere type: {miz.mission.weather.atmosphere_type}')\n        report.append(f'QNH: {miz.mission.weather.qnh}')\n\n        miz.mission.weather.visibility = self.visibility\n        if self.fog_vis:\n            miz.mission.weather.fog_thickness = 1000\n            miz.mission.weather.fog_visibility = self.fog_vis\n            miz.mission.weather.fog_enabled = True\n        else:\n            miz.mission.weather.fog_enabled = False\n            miz.mission.weather.fog_visibility = 0\n            miz.mission.weather.fog_thickness = 0\n\n        visibility = f'Visibility: {miz.mission.weather.visibility}' \\\n                     f'\\n\\tFog: {\"yes\" if miz.mission.weather.fog_enabled else \"no\"}' \\\n                     f'\\n\\tFog thickness: {miz.mission.weather.fog_thickness}' \\\n                     f'\\n\\tFog visibility: {miz.mission.weather.fog_visibility}'\n\n        report.append(visibility)\n\n        miz.mission.weather.temperature = self.temperature\n\n        report.append(f'Temperature: {self.temperature}\u00b0C')\n\n        miz.mission.weather.cloud_density = max(self.force_cloud_density, self.cloud_density)\n        miz.mission.weather.cloud_thickness = self.cloud_thickness\n        miz.mission.weather.cloud_base = self.cloud_base\n        miz.mission.weather.precipitations = self.precipitations\n\n        clouds = f'Clouds:' \\\n                 f'\\n\\tClouds density: {miz.mission.weather.cloud_density}' \\\n                 f'\\n\\tClouds thickness: {miz.mission.weather.cloud_thickness}' \\\n                 f'\\n\\tClouds base: {miz.mission.weather.cloud_base}' \\\n                 f'\\n\\tPrecipitations: {miz.mission.weather.precipitations}'\n\n        report.append(clouds)\n\n        LOGGER.debug('applying weather: %s', report)\n\n        return True", "response": "Applies weather to an opened Miz file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef version_by_pip(package):\n    command = \"pip show {0}\".format(package)\n    result = execute_get_text(command)\n    for line in result.split(\"\\n\"):\n        if line.startswith(\"Version\"):\n            return line.split(\":\")[0]\n    return None", "response": "Get version of pip installed packages"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nguesses the version of a pkg when pip doesn t provide it.", "response": "def guess_version_by_running_live_package(\n    pkg_key, default=\"?\"\n):  # type: (str,str) -> Any\n    \"\"\"Guess the version of a pkg when pip doesn't provide it.\n\n    :param str pkg_key: key of the package\n    :param str default: default version to return if unable to find\n    :returns: version\n    :rtype: string\n\n    \"\"\"\n    try:\n        m = import_module(pkg_key)\n    except ImportError:\n        return default\n    else:\n        return getattr(m, \"__version__\", default)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_api_params(self):\n        result = self.params\n        if type(result) != dict:\n            raise ValueError(\n                '{}.params should return dictionary'.format(\n                    self.__class__.__name__\n                )\n            )\n        return result", "response": "Returns dictionary with available API parameters"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list with required params for API.", "response": "def get_api_required_params(self):\n        \"\"\" List with required params\n\n        :return: Dictionary with API parameters\n        :raises ValueError: If value of __class__.required_params is not list\n        :rtype: list\n        \"\"\"\n        result = self.required_params\n        if type(result) != list:\n            raise ValueError(\n                '{}.required_params should return list'.format(\n                    self.__class__.__name__\n                )\n            )\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds parameters from passed arguments and returns a dictionary with the keys of the API key and the values of the API key.", "response": "def _build_params_from_kwargs(self, **kwargs):\n        \"\"\"Builds parameters from passed arguments\n\n        Search passed parameters in available methods,\n        prepend specified API key, and return dictionary\n        which can be sent directly to API server.\n\n\n        :param kwargs:\n        :type param: dict\n        :raises ValueError: If type of specified parameter doesn't match\n                            the expected type. Also raised if some basic\n                            validation of passed parameter fails.\n        :raises PushalotException: If required parameter not set.\n        :return: Dictionary with params which can be\n                 sent to API server\n        :rtype: dict\n        \"\"\"\n        api_methods = self.get_api_params()\n        required_methods = self.get_api_required_params()\n        ret_kwargs = {}\n        for key, val in kwargs.items():\n            if key not in api_methods:\n                warnings.warn(\n                    'Passed uknown parameter [{}]'.format(key),\n                    Warning\n                )\n                continue\n            if key not in required_methods and val is None:\n                continue\n            if type(val) != api_methods[key]['type']:\n                raise ValueError(\n                    \"Invalid type specified to param: {}\".format(key)\n                )\n            if 'max_len' in api_methods[key]:\n                if len(val) > api_methods[key]['max_len']:\n                    raise ValueError(\n                        \"Lenght of parameter [{}] more than \"\n                        \"allowed length\".format(key)\n                    )\n            ret_kwargs[api_methods[key]['param']] = val\n\n        for item in required_methods:\n            if item not in ret_kwargs:\n                raise pushalot.exc.PushalotException(\n                    \"Parameter [{}] required, but not set\".format(item)\n                )\n\n        return ret_kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries the cache for a specific label.", "response": "def query(self, label):\n        \"\"\"\n        Returns (hit, index) tuple.\n        hit is a boolean, signifying label presence in the cache\n        index is an integer, the instruction index for the label entry\n        \"\"\"\n        try:\n            return True, self.cache[label]\n        except KeyError, e:\n            return False, 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write(self, label, index):\n        if label in self.cache:\n            if self.cache[label] != index:\n                error_message = 'cache_conflict on label: {} with index: {}\\ncache dump: {}'.format(label, index, self.cache)\n                raise RuntimeError(error_message)\n        else:\n            self.cache[label] = index", "response": "Writes a new entry to the cache."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pack_image(filename, max_size, form_field='image'):\n        try:\n            if os.path.getsize(filename) > (max_size * 1024):\n                raise IdeaScalyError('File is too big, must be less than %skb.' % max_size)\n        except os.error as e:\n            raise IdeaScalyError('Unable to access file: %s' % e.strerror)\n\n        # build the mulitpart-formdata body\n        fp = open(filename, 'rb')\n\n        # image must be gif, jpeg, or png\n        file_type = mimetypes.guess_type(filename)\n        if file_type is None:\n            raise IdeaScalyError('Could not determine file type')\n        file_type = file_type[0]\n        if file_type not in ['image/gif', 'image/jpeg', 'image/png']:\n            raise IdeaScalyError('Invalid file type for image: %s' % file_type)\n\n        if isinstance(filename, six.text_type):\n            filename = filename.encode('utf-8')\n\n        BOUNDARY = b'Id34Sc4ly'\n        body = list()\n        body.append(b'--' + BOUNDARY)\n        body.append('content-disposition: form-data; name=\"{0}\";'\n                    ' filename=\"{1}\"'.format(form_field, filename)\n                    .encode('utf-8'))\n        body.append('content-type: {0}'.format(file_type).encode('utf-8'))\n        body.append(b'')\n        body.append(fp.read())\n        body.append(b'--' + BOUNDARY + b'--')\n        body.append(b'')\n        fp.close()\n        body = b'\\r\\n'.join(body)\n        body_length = str(len(body))\n\n        # build headers\n        headers = {\n            'content-type': 'multipart/form-data; boundary={0}'.format(BOUNDARY),\n            'content-length': body_length\n        }\n\n        return headers, body", "response": "Pack an image from file into multipart - formdata post body"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a base class that can be used by a Router or API.", "response": "def create_configuration(name='Base'):\n    \"\"\"Create a configuration base class\n\n    It is built using :class:`ConfigurationMeta`. Subclassing such a base class\n    will register exposed methods\n\n    .. class:: Base\n\n        .. attribute:: configuration\n\n            Configuration dict that can be used by a Router or the API\n\n        .. classmethod:: register(element, action, method)\n\n            Register an element in the :attr:`configuration`\n\n            :param element: the element to register\n            :type element: tuple of (class, method name) or function\n            :param string action: name of the exposed action that will hold the method\n            :param string method: name of the exposed method\n\n    \"\"\"\n    @classmethod\n    def register(cls, element, action, method):\n        if not action in cls.configuration:\n            cls.configuration[action] = {}\n        if method in cls.configuration[action]:\n            raise ValueError('Method %s already defined for action %s' % (method, action))\n        cls.configuration[action][method] = element\n    return ConfigurationMeta(name, (object,), {'configuration': {}, 'register': register})"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmerges configurations together and raise error if a conflict is detected", "response": "def merge_configurations(configurations):\n    \"\"\"Merge configurations together and raise error if a conflict is detected\n\n    :param configurations: configurations to merge together\n    :type configurations: list of :attr:`~pyextdirect.configuration.Base.configuration` dicts\n    :return: merged configurations as a single one\n    :rtype: dict\n\n    \"\"\"\n    configuration = {}\n    for c in configurations:\n        for k, v in c.iteritems():\n            if k in configuration:\n                raise ValueError('%s already in a previous base configuration' % k)\n            configuration[k] = v\n    return configuration"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _Dispatch(ps, modules, SendResponse, SendFault, nsdict={}, typesmodule=None, \n              gettypecode=gettypecode, rpc=False, docstyle=False, **kw):\n    '''Find a handler for the SOAP request in ps; search modules.\n    Call SendResponse or SendFault to send the reply back, appropriately.\n\n    Behaviors:\n        default -- Call \"handler\" method with pyobj representation of body root, and return\n            a self-describing request (w/typecode).  Parsing done via a typecode from \n            typesmodule, or Any.\n\n        docstyle -- Call \"handler\" method with ParsedSoap instance and parse result with an\n          XML typecode (DOM). Behavior, wrap result in a body_root \"Response\" appended message.\n\n        rpc -- Specify RPC wrapper of result. Behavior, ignore body root (RPC Wrapper)\n           of request, parse all \"parts\" of message via individual typecodes.  Expect\n           the handler to return the parts of the message, whether it is a dict, single instance, \n           or a list try to serialize it as a Struct but if this is not possible put it in an Array.\n           Parsing done via a typecode from typesmodule, or Any.\n\n    '''\n    global _client_binding\n    try:\n        what = str(ps.body_root.localName)\n\n        # See what modules have the element name.\n        if modules is None:\n            modules = ( sys.modules['__main__'], )\n\n        handlers = [ getattr(m, what) for m in modules if hasattr(m, what) ]\n        if len(handlers) == 0:\n            raise TypeError(\"Unknown method \" + what)\n\n        # Of those modules, see who's callable.\n        handlers = [ h for h in handlers if callable(h) ]\n        if len(handlers) == 0:\n            raise TypeError(\"Unimplemented method \" + what)\n        if len(handlers) > 1:\n            raise TypeError(\"Multiple implementations found: \" + `handlers`)\n        handler = handlers[0]\n\n        _client_binding = ClientBinding(ps)\n        if docstyle:\n            result = handler(ps.body_root)\n            tc = TC.XML(aslist=1, pname=what+'Response')\n        elif not rpc:\n            try:\n                tc = gettypecode(typesmodule, ps.body_root)\n            except Exception:\n                tc = TC.Any()\n\n            try:\n                arg = tc.parse(ps.body_root, ps)\n            except EvaluateException, ex:\n                SendFault(FaultFromZSIException(ex), **kw)\n                return\n\n            try:\n                result = handler(arg)\n            except Exception,ex:\n                SendFault(FaultFromZSIException(ex), **kw)\n                return\n\n            try:\n                tc = result.typecode\n            except AttributeError,ex:\n                SendFault(FaultFromZSIException(ex), **kw)\n                return\n\n        elif typesmodule is not None:\n            kwargs = {}\n            for e in _child_elements(ps.body_root):\n                try:\n                    tc = gettypecode(typesmodule, e)\n                except Exception:\n                    tc = TC.Any()\n\n                try:\n                    kwargs[str(e.localName)] = tc.parse(e, ps)\n                except EvaluateException, ex:\n                    SendFault(FaultFromZSIException(ex), **kw)\n                    return\n\n            result = handler(**kwargs)\n            aslist = False\n            # make sure data is wrapped, try to make this a Struct\n            if type(result) in _seqtypes:\n                 for o in result:\n                     aslist = hasattr(result, 'typecode')\n                     if aslist: break\n            elif type(result) is not dict:\n                 aslist = not hasattr(result, 'typecode')\n                 result = (result,)\n\n            tc = TC.Any(pname=what+'Response', aslist=aslist)\n        else:\n            # if this is an Array, call handler with list\n            # if this is an Struct, call handler with dict\n            tp = _find_type(ps.body_root)\n            isarray = ((type(tp) in (tuple,list) and tp[1] == 'Array') or _find_arraytype(ps.body_root))\n            data = _child_elements(ps.body_root)\n            tc = TC.Any()\n            if isarray and len(data) == 0:\n                result = handler()\n            elif isarray:\n                try: arg = [ tc.parse(e, ps) for e in data ]\n                except EvaluateException, e:\n                    #SendFault(FaultFromZSIException(e), **kw)\n                    SendFault(RuntimeError(\"THIS IS AN ARRAY: %s\" %isarray))\n                    return\n\n                result = handler(*arg)\n            else:\n                try: kwarg = dict([ (str(e.localName),tc.parse(e, ps)) for e in data ])\n                except EvaluateException, e:\n                    SendFault(FaultFromZSIException(e), **kw)\n                    return\n\n                result = handler(**kwarg)\n\n            # reponse typecode\n            #tc = getattr(result, 'typecode', TC.Any(pname=what+'Response'))\n            tc = TC.Any(pname=what+'Response')\n\n        sw = SoapWriter(nsdict=nsdict)\n        sw.serialize(result, tc)\n        return SendResponse(str(sw), **kw)\n    except Fault, e:\n        return SendFault(e, **kw)\n    except Exception, e:\n        # Something went wrong, send a fault.\n        return SendFault(FaultFromException(e, 0, sys.exc_info()[2]), **kw)", "response": "Dispatch the SOAP request in the given parsedSOAP object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef AsCGI(nsdict={}, typesmodule=None, rpc=False, modules=None):\n    '''Dispatch within a CGI script.\n    '''\n    if os.environ.get('REQUEST_METHOD') != 'POST':\n        _CGISendFault(Fault(Fault.Client, 'Must use POST'))\n        return\n    ct = os.environ['CONTENT_TYPE']\n    try:\n        if ct.startswith('multipart/'):\n            cid = resolvers.MIMEResolver(ct, sys.stdin)\n            xml = cid.GetSOAPPart()\n            ps = ParsedSoap(xml, resolver=cid.Resolve)\n        else:\n            length = int(os.environ['CONTENT_LENGTH'])\n            ps = ParsedSoap(sys.stdin.read(length))\n    except ParseException, e:\n        _CGISendFault(FaultFromZSIException(e))\n        return\n    _Dispatch(ps, modules, _CGISendXML, _CGISendFault, nsdict=nsdict,\n              typesmodule=typesmodule, rpc=rpc)", "response": "Dispatch within a CGI script."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndispatching from within ModPython.", "response": "def AsHandler(request=None, modules=None, **kw):\n    '''Dispatch from within ModPython.'''\n    ps = ParsedSoap(request)\n    kw['request'] = request\n    _Dispatch(ps, modules, _ModPythonSendXML, _ModPythonSendFault, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndispatch within a jonpy CGI script.", "response": "def AsJonPy(request=None, modules=None, **kw):\n    '''Dispatch within a jonpy CGI/FastCGI script.\n    '''\n\n    kw['request'] = request\n    if request.environ.get('REQUEST_METHOD') != 'POST':\n        _JonPySendFault(Fault(Fault.Client, 'Must use POST'), **kw)\n        return\n    ct = request.environ['CONTENT_TYPE']\n    try:\n        if ct.startswith('multipart/'):\n            cid = resolvers.MIMEResolver(ct, request.stdin)\n            xml = cid.GetSOAPPart()\n            ps = ParsedSoap(xml, resolver=cid.Resolve)\n        else:\n            length = int(request.environ['CONTENT_LENGTH'])\n            ps = ParsedSoap(request.stdin.read(length))\n    except ParseException, e:\n        _JonPySendFault(FaultFromZSIException(e), **kw)\n        return\n    _Dispatch(ps, modules, _JonPySendXML, _JonPySendFault, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef punctuate(current_text, new_text, add_punctuation):\n    if add_punctuation and current_text and not current_text[-1] in string.punctuation:\n        current_text += '. '\n    spacer = ' ' if not current_text or (not current_text[-1].isspace() and not new_text[0].isspace()) else ''\n    return current_text + spacer + new_text", "response": "Punctuation is used to add punctuation to the current_text."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ningests the given text for the given topic", "response": "def ingest(topic, text, **kwargs):\n    \"\"\" Ingest the given text for the topic \"\"\"\n    if not text:\n        raise ValueError('No text given to ingest for topic: ' + topic)\n    data = {'topic': topic, 'text': text.strip()}\n    data.update(kwargs)\n    db.markovify.insert(data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating the text for a given topic.", "response": "def generate(topic, add_punctuation, character_count=None):\n    \"\"\" Generate the text for a given topic \"\"\"\n    corpus_cursor = db.markovify.find({'topic': topic})\n    if(corpus_cursor):\n        corpus = ''\n        for text in corpus_cursor:\n            corpus = punctuate(corpus, text['text'], add_punctuation)\n        text_model = markovify.Text(corpus)\n        sentence = text_model.make_short_sentence(character_count) \\\n            if character_count else text_model.make_sentence()\n        if not sentence:\n            raise Exception('There is not enough in the corpus to generate a sentence.')\n        return sentence\n    raise Exception('No text found for topic: ' + topic)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unordered_pair_eq(pair1, pair2):\n    '''Performs pairwise unordered equality.\n\n    ``pair1`` == ``pair2`` if and only if\n    ``frozenset(pair1)`` == ``frozenset(pair2)``.\n    '''\n    (x1, y1), (x2, y2) = pair1, pair2\n    return (x1 == x2 and y1 == y2) or (x1 == y2 and y1 == x2)", "response": "Performs pairwise unordered equality."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef expand_labels(labels, subtopic=False):\n    '''Expand a set of labels that define a connected component.\n\n    ``labels`` must define a *positive* connected component: it is all\n    of the edges that make up the *single* connected component in the\n    :class:`LabelStore`. expand will ignore subtopic assignments, and\n    annotator_id will be an arbitrary one selected from ``labels``.\n\n    Note that this function only returns the expanded labels, which\n    is guaranteed to be disjoint with the given ``labels``. This\n    requirement implies that ``labels`` is held in memory to ensure\n    that no duplicates are returned.\n\n    If ``subtopic`` is ``True``, then it is assumed that ``labels``\n    defines a ``subtopic`` connected component. In this case, subtopics\n    are included in the expanded labels.\n\n    :param labels: iterable of :class:`Label` for the connected component.\n    :rtype: generator of expanded :class:`Label`s only\n    '''\n    labels = list(labels)\n    assert all(lab.value == CorefValue.Positive for lab in labels)\n\n    # Anything to expand?\n    if len(labels) == 0:\n        return\n\n    annotator = labels[0].annotator_id\n\n    data_backed = set()\n    connected_component = set()\n    for label in labels:\n        ident1, ident2 = idents_from_label(label, subtopic=subtopic)\n        data_backed.add(normalize_pair(ident1, ident2))\n        connected_component.add(ident1)\n        connected_component.add(ident2)\n\n    # We do not want to rebuild the Labels we already have,\n    # because they have true annotator_id and subtopic\n    # fields that we may want to preserve.\n    for ident1, ident2 in combinations(connected_component, 2):\n        if normalize_pair(ident1, ident2) not in data_backed:\n            (cid1, subid1), (cid2, subid2) = ident1, ident2\n            yield Label(cid1, cid2, annotator, CorefValue.Positive,\n                        subtopic_id1=subid1, subtopic_id2=subid2)", "response": "Expand a set of labels that define a positive connected component."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsplits a generic identifier. is a tuple of content_id and subtopic_id.", "response": "def normalize_ident(ident):\n    '''Splits a generic identifier.\n\n    If ``ident`` is a tuple, then ``(ident[0], ident[1])`` is returned.\n    Otherwise, ``(ident[0], None)`` is returned.\n    '''\n    if isinstance(ident, tuple) and len(ident) == 2:\n        return ident[0], ident[1]  # content_id, subtopic_id\n    else:\n        return ident, None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the idents of a label.", "response": "def idents_from_label(lab, subtopic=False):\n    '''Returns the \"ident\" of a label.\n\n    If ``subtopic`` is ``True``, then a pair of pairs is returned,\n    where each pair corresponds to the content id and subtopic id in\n    the given label.\n\n    Otherwise, a pair of pairs is returned, but the second element of each\n    pair is always ``None``.\n\n    This is a helper function that is useful for dealing with generic\n    label identifiers.\n    '''\n    if not subtopic:\n        return (lab.content_id1, None), (lab.content_id2, None)\n    else:\n        return (\n            (lab.content_id1, lab.subtopic_id1),\n            (lab.content_id2, lab.subtopic_id2),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a new label to the store.", "response": "def put(self, *labels):\n        '''Add a new label to the store.\n\n        :param label: label\n        :type label: :class:`Label`\n        '''\n        puts = []\n        for label in labels:\n            k1, k2 = self._keys_from_label(label)\n            v = self._value_from_label(label)\n            puts.append((k1, v))\n            puts.append((k2, v))\n        self.kvl.put(self.TABLE, *puts)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _label_from_kvlayer(self, k, v):\n        '''Make a label from a kvlayer row.'''\n        (content_id1, content_id2, subtopic_id1, subtopic_id2,\n         annotator_id, inverted_epoch_ticks) = k\n        epoch_ticks = time_complement(inverted_epoch_ticks)\n\n        (unpacked,) = struct.unpack('B', v[0])\n        value = (unpacked & 15) - 1\n        rating = (unpacked >> 4)\n        meta = None\n        if len(v) > 1:\n            meta = cbor.loads(v[1:])\n\n        return Label(content_id1=content_id1,\n                     content_id2=content_id2,\n                     annotator_id=annotator_id,\n                     value=value,\n                     subtopic_id1=subtopic_id1,\n                     subtopic_id2=subtopic_id2,\n                     epoch_ticks=epoch_ticks,\n                     rating=rating,\n                     meta=meta)", "response": "Make a label from a kvlayer row."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef directly_connected(self, ident):\n        '''Return a generator of labels connected to ``ident``.\n\n        ``ident`` may be a ``content_id`` or a ``(content_id,\n        subtopic_id)``.\n\n        If no labels are defined for ``ident``, then the generator\n        will yield no labels.\n\n        Note that this only returns *directly* connected labels. It\n        will not follow transitive relationships.\n\n        :param ident: content id or (content id and subtopic id)\n        :type ident: ``str`` or ``(str, str)``\n        :rtype: generator of :class:`Label`\n        '''\n        content_id, subtopic_id = normalize_ident(ident)\n        return self.everything(include_deleted=False,\n                               content_id=content_id,\n                               subtopic_id=subtopic_id)", "response": "Return a generator of labels connected to ident."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsplits idents into equivalence classes based on connected_component components.", "response": "def split_by_connected_component(self, idents):\n        '''Split idents into equivalence classes based on connected\n        components.\n        '''\n        idents_remaining = set(idents)\n        connected_components = []\n        for ident in idents:\n            if ident not in idents_remaining:\n                continue\n\n            idents_remaining.remove(ident)\n\n            connected_component = [ident]\n            for label in self.connected_component(ident):\n                cids = label.content_id1, label.content_id2\n                for cid in cids:\n                    if cid in idents_remaining:\n                        connected_component.append(cid)\n                        idents_remaining.remove(cid)\n\n            connected_components.append(sorted(connected_component))\n        return connected_components"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a generator of the connected component label for the given ident.", "response": "def connected_component(self, ident):\n        '''Return a connected component generator for ``ident``.\n\n        ``ident`` may be a ``content_id`` or a ``(content_id,\n        subtopic_id)``.\n\n        Given an ``ident``, return the corresponding connected\n        component by following all positive transitivity relationships.\n\n        For example, if ``(a, b, 1)`` is a label and ``(b, c, 1)`` is\n        a label, then ``connected_component('a')`` will return both\n        labels even though ``a`` and ``c`` are not directly connected.\n\n        (Note that even though this returns a generator, it will still\n        consume memory proportional to the number of labels in the\n        connected component.)\n\n        :param ident: content id or (content id and subtopic id)\n        :type ident: ``str`` or ``(str, str)``\n        :rtype: generator of :class:`Label`\n        '''\n        ident = normalize_ident(ident)\n        done = set()  # set of cids that we've queried with\n        todo = set([ident])  # set of cids to do a query for\n        labels = set()\n        while todo:\n            ident = todo.pop()\n            done.add(ident)\n            for label in self.directly_connected(ident):\n                if label.value != CorefValue.Positive:\n                    continue\n                ident1, ident2 = idents_from_label(\n                    label, subtopic=ident_has_subtopic(ident))\n                if ident1 not in done:\n                    todo.add(ident1)\n                if ident2 not in done:\n                    todo.add(ident2)\n\n                if label not in labels:\n                    labels.add(label)\n                    yield label"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef expand(self, ident):\n        '''Return expanded set of labels from a connected component.\n\n        The connected component is derived from ``ident``. ``ident``\n        may be a ``content_id`` or a ``(content_id, subtopic_id)``.\n        If ``ident`` identifies a subtopic, then expansion is done\n        on a subtopic connected component (and expanded labels retain\n        subtopic information).\n\n        The labels returned by :meth:`LabelStore.connected_component`\n        contains only the :class:`Label` stored in the\n        :class:`LabelStore`, and does not include the labels you can\n        infer from the connected component. This method returns both\n        the data-backed labels and the inferred labels.\n\n        Subtopic assignments of the expanded labels will be empty. The\n        ``annotator_id`` will be an arbitrary ``annotator_id`` within\n        the connected component.\n\n        :param str content_id: content id\n        :param value: coreferent value\n        :type value: :class:`CorefValue`\n        :rtype: ``list`` of :class:`Label`\n        '''\n        subtopic = ident_has_subtopic(normalize_ident(ident))\n        labels = list(self.connected_component(ident))\n        labels.extend(expand_labels(labels, subtopic=subtopic))\n        return labels", "response": "Return expanded set of labels from a connected component."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef negative_inference(self, content_id):\n        '''Return a generator of inferred negative label relationships\n        centered on ``content_id``.\n\n        Negative labels are inferred by getting all other content ids\n        connected to ``content_id`` through a negative label, then\n        running :meth:`LabelStore.negative_label_inference` on those\n        labels. See :meth:`LabelStore.negative_label_inference` for\n        more information.\n        '''\n        neg_labels = ifilter(lambda l: l.value == CorefValue.Negative,\n                             self.directly_connected(content_id))\n        for label in neg_labels:\n            label_inf = self.negative_label_inference(label)\n            for label in label_inf:\n                yield label", "response": "Return a generator of inferred negative label relationships by getting all other content ids that are connected to the given content_id."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef negative_label_inference(self, label):\n        '''Return a generator of inferred negative label relationships.\n\n        Construct ad-hoc negative labels between ``label.content_id1``\n        and the positive connected component of ``label.content_id2``,\n        and ``label.content_id2`` to the connected component of\n        ``label.content_id1``.\n\n        Note this will allocate memory proportional to the size of the\n        connected components of ``label.content_id1`` and\n        ``label.content_id2``.\n        '''\n        assert label.value == CorefValue.Negative\n\n        yield label\n\n        cid2_comp = self.connected_component(label.content_id2)\n        for comp_label in cid2_comp:\n            comp_cids = (comp_label.content_id1,\n                         comp_label.content_id2)\n            for comp_cid in comp_cids:\n                if not comp_cid == label.content_id2:\n                    yield Label(label.content_id1, comp_cid,\n                                'auto', CorefValue.Negative)\n\n        cid1_comp = self.connected_component(label.content_id1)\n        for comp_label in cid1_comp:\n            comp_cids = (comp_label.content_id1,\n                         comp_label.content_id2)\n            for comp_cid in comp_cids:\n                if not comp_cid == label.content_id1:\n                    yield Label(label.content_id2, comp_cid,\n                                'auto', CorefValue.Negative)", "response": "Return a generator of inferred negative label relationships."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfilters out - of - order labels by key tuple.", "response": "def _filter_keys(self, content_id=None, prefix=None, subtopic_id=None):\n        '''Filter out-of-order labels by key tuple.\n\n        :class:`Label` always sorts by `(cid1,cid2,sid1,sid2)`, but\n        for efficient lookups on `cid2` this class also stores in\n        order `(cid2,cid1,sid2,sid1)`.  Filter out things that are\n        in the wrong order.  But, if an original query specified\n        `content_id` or `subtopic_id`, account for the possibility\n        that something might be apparently out-of-order but its\n        dual will not be in the query at all.\n\n        '''\n        def accept(kvp):\n            (content_id1, content_id2, subtopic_id1, subtopic_id2,\n             annotator_id, inverted_epoch_ticks) = kvp[0]\n            # In general we'll accept the label if\n            # it's the natural order; l.content_id1 == cid1\n            is_sorted = (content_id1 < content_id2 or\n                         (content_id1 == content_id2 and\n                          subtopic_id1 <= subtopic_id2))\n            if content_id is not None:\n                # We will only see tuples where content_id1 is the\n                # requested content ID\n                assert content_id1 == content_id\n            elif prefix is not None:\n                assert content_id1.startswith(prefix)\n                # If we'll see both orderings of this record, only\n                # accept the sorted one\n                if content_id2.startswith(prefix) and not is_sorted:\n                    return False\n            elif not is_sorted:\n                # We'll see both orderings of everything, reject the\n                # unsorted ones\n                return False\n\n            # If we're not looking for subtopic IDs, then accept records\n            # matching the content ID that are in natural order\n            if subtopic_id is None:\n                if content_id2 != content_id:\n                    return True  # will never see its dual\n                return subtopic_id1 <= subtopic_id2\n            # The scan range doesn't include subtopic IDs (the key schema\n            # is oriented towards querying content-to-content labels)\n            # so we need to accept records where either part matches\n            # (if both parts match then the record is its own dual)\n            if subtopic_id == subtopic_id1:\n                return True\n            if content_id == content_id2 and subtopic_id == subtopic_id2:\n                return True\n            return False\n        return accept"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef everything(self, include_deleted=False, content_id=None,\n                   subtopic_id=None, prefix=None):\n        '''Returns a generator of all labels in the store.\n\n        If `include_deleted` is :const:`True`, labels that have been\n        overwritten with more recent labels are also included.  If\n        `content_id` is not :const:`None`, only labels for that\n        content ID are retrieved; and then if `subtopic_id` is not\n        :const:`None`, only that subtopic is retrieved, else all\n        subtopics are retrieved.  If `content_id` is :const:`None` but\n        `prefix` is not, then only labels with at least one content ID\n        beginning with `prefix` will be returned.  The returned labels\n        will always be q in sorted order, content IDs first, and with\n        those with the same content, subtopic, and annotator IDs\n        sorted newest first.\n\n        :rtype: generator of :class:`Label`\n\n        '''\n        if content_id is not None:\n            ranges = [((content_id,), (content_id,))]\n        elif prefix is not None:\n            # This is the cheap, easy, and wrong way to do this\n            ranges = [((prefix,), (prefix + b'\\xff',))]\n        else:\n            ranges = []\n        labels = self.kvl.scan(self.TABLE, *ranges)\n        labels = ifilter(self._filter_keys(content_id, prefix, subtopic_id),\n                         labels)\n        labels = imap(lambda p: self._label_from_kvlayer(*p), labels)\n        if not include_deleted:\n            labels = Label.most_recent(labels)\n        return labels", "response": "Returns a generator of all labels in the store."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, *labels):\n        '''Delete `labels` from the store, which involves deleting two\n        records for each :class:`Label`.\n\n        :rtype: None\n        :raises: :exc:`KeyError` if any of the `labels` could not be found.\n\n        '''\n        deletes = []\n        for label in labels:\n            k1, k2 = self._keys_from_label(label)\n            deletes.append(k1)\n            deletes.append(k2)\n        self.kvl.delete(self.TABLE, *deletes)", "response": "Delete labels from the store which involves deleting two\n        records for each label."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply a diff to the label table.", "response": "def apply_diff(self, diff):\n        '''Applies a diff to the label table.\n\n        A ``diff`` is a dictionary with three keys: ``add``, ``delete``\n        and ``change``. Each key should map to a list of labels.\n\n        ``add`` corresponds to the labels that are in ``new`` but not in\n        ``old``.\n\n        ``delete`` corresponds to the labels that are in ``old`` but not\n        in ``new``.\n\n        ``change`` corresponds to the labels that are in both ``old``\n        and ``new`` but have different coref/rating values.\n        '''\n        # add and change are easy---just put the labels.\n        # delete is a little trickier. We need to scrub out the impact of\n        # the previous label without actually deleting it. For this, we\n        # use an unknown coref value.\n        insert = (\n            diff['add'] +\n            diff['change'] +\n            [lab.update(value=CorefValue.Unknown)\n             for lab in diff['delete']]\n        )\n        self.put(*insert)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef file_exists(original_file):\n    if original_file.startswith(\"s3://\"):\n        from filesystem import s3\n        return s3.file_exists(original_file)\n    else:\n        if not os.path.exists(original_file):\n            return False\n        if not os.path.isfile(original_file):\n            return False\n    return True", "response": "Check to make sure the original file exists"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the logging level.", "response": "def set_level(self, level=1):\n        \"\"\"Set the logging level\n\n        Parameters\n        ----------\n        level : `int` or `bool` (optional, default: 1)\n            If False or 0, prints WARNING and higher messages.\n            If True or 1, prints INFO and higher messages.\n            If 2 or higher, prints all messages.\n        \"\"\"\n        if level is True or level == 1:\n            level = logging.INFO\n            level_name = \"INFO\"\n        elif level is False or level <= 0:\n            level = logging.WARNING\n            level_name = \"WARNING\"\n        elif level >= 2:\n            level = logging.DEBUG\n            level_name = \"DEBUG\"\n\n        if not self.logger.handlers:\n            self.logger.tasklogger = self\n            self.logger.propagate = False\n            handler = logging.StreamHandler(\n                stream=stream.RSafeStream(stream=self.stream))\n            handler.setFormatter(logging.Formatter(fmt='%(message)s'))\n            self.logger.addHandler(handler)\n\n        if level != self.logger.level:\n            self.level = level\n            self.logger.setLevel(level)\n            self.debug(\"Set {} logging to {}\".format(\n                self.name, level_name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_timer(self, timer=\"wall\"):\n        if timer == \"wall\":\n            timer = time.time\n        elif timer == \"cpu\":\n            try:\n                timer = time.process_time\n            except AttributeError:\n                raise RuntimeError(\n                    \"Python2.7 on Windows does not offer a CPU time function. \"\n                    \"Please upgrade to Python >= 3.5.\")\n        self.timer = timer\n        return self", "response": "Set the timer function for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlog a message with the specified log_fn.", "response": "def _log(self, log_fn, msg):\n        \"\"\"Log a message\n        \"\"\"\n        if self.indent > 0:\n            msg = len(self.tasks) * self.indent * ' ' + msg\n        return log_fn(msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start_task(self, task):\n        self.info(\"Calculating {}...\".format(task))\n        self.tasks[task] = self.timer()", "response": "Begin logging of a task returning the time lapsed when complete_task is called."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef complete_task(self, task):\n        try:\n            runtime = self.timer() - self.tasks[task]\n            del self.tasks[task]\n            if runtime >= self.min_runtime:\n                self.info(\"Calculated {} in {:.2f} seconds.\".format(\n                    task, runtime))\n            return runtime\n        except KeyError:\n            self.info(\"Calculated {}.\".format(task))", "response": "Complete logging of a task returning the time lapsed since start_task was called\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef edit_miz(  # noqa: C901\n        infile: str,\n        outfile: str = None,\n        metar: typing.Union[str, Metar] = None,\n        time: str = None,\n        min_wind: int = 0,\n        max_wind: int = 40\n) -> str:\n    # noinspection SpellCheckingInspection\n    \"\"\"\n    Edit an opened MIZ file and sets the time and date and the weather\n\n    Args:\n        infile: source file\n        outfile: output file (will default to source file)\n        metar: metar string, ICAO or object to apply\n        time: time string to apply (YYYYMMDDHHMMSS)\n        min_wind: minimum wind\n        max_wind: maximum wind\n\n    Returns:\n        String containing error\n    \"\"\"\n    if outfile is None:\n        LOGGER.debug('editing in place: %s', infile)\n        outfile = infile\n    else:\n        LOGGER.debug('editing miz file: %s -> %s', infile, outfile)\n\n    mission_weather = mission_time = None\n\n    if metar:\n        error, metar = emiz.weather.custom_metar.CustomMetar.get_metar(metar)\n        if error:\n            return error\n\n        mission_weather = emiz.weather.mission_weather.MissionWeather(metar, min_wind=min_wind, max_wind=max_wind)\n\n    if time:\n        try:\n            mission_time = MissionTime.from_string(time)\n        except ValueError:\n            return f'badly formatted time string: {time}'\n\n    if not mission_weather and not mission_time:\n        return 'nothing to do!'\n\n    with Miz(infile) as miz:\n        if mission_weather:\n            LOGGER.debug('applying MissionWeather')\n            if not mission_weather.apply_to_miz(miz):\n                return 'error while applying METAR to mission'\n        if mission_time:\n            LOGGER.debug('applying MissionTime')\n            if not mission_time.apply_to_miz(miz):\n                return 'error while setting time on mission'\n\n        try:\n            miz.zip(outfile)\n            return ''\n        except OSError:\n            return f'permission error: cannot edit \"{outfile}\"; maybe it is in use ?'", "response": "Edit an opened MIZ file and set the time and date of the weather."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_file(self, loader, filename, encoding='utf-8', silent=False):\n        conf = {}\n        try:\n            with open(filename, encoding=encoding) as f:\n                conf = loader(f)\n        except Exception:\n            if not silent:\n                raise\n        self.update(conf)", "response": "Updates the value in the config from a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_json(self, filename, encoding='utf-8', silent=False):\n        self.from_file(json.load, filename, encoding, silent)", "response": "Updates the value in the config from a JSON file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the value in the config from a YAML file.", "response": "def from_yaml(self, filename, encoding='utf-8', silent=False):\n        \"\"\"\n        Updates recursively the value in the the config from a YAML file.\n\n        The method requires the PyYAML to be installed.\n\n        :param filename: (str) a filename of the YAML file\n        :param encoding: (str) an encoding of the filename\n        :param silent: (bool) fails silently if something wrong with yaml file\n\n        .. versionadded:: 0.3.0\n        \"\"\"\n        if not yaml:\n            raise AttributeError(\n                'You need to install PyYAML before using this method!')\n\n        self.from_file(yaml.load, filename, encoding, silent)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the internal dictionary with a given iterable.", "response": "def update(self, iterable={}, **kwargs):\n        \"\"\"\n        Updates recursively a self with a given iterable.\n\n        TODO: rewrite this ugly stuff\n        \"\"\"\n        def _merge(a, *args):\n            for key, value in itertools.chain(*args):\n                if key in a and isinstance(value, (dict, Conf)):\n                    value = _merge(a[key], value.items())\n                a[key] = value\n            return a\n\n        # adopt iterable sequence to unified interface: (key, value)\n        if isinstance(iterable, (dict, Conf)):\n            iterable = iterable.items()\n\n        # iterate and update values\n        _merge(self._data, iterable, kwargs.items())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef baseline(dataset, column=1, fn=None, fail_silently=True):\n    try:\n        if fn is None:\n            fn = lambda columns, column: columns[column][0]\n        for i, data in enumerate(dataset):\n            _baseline = fn(data, column=column)\n            dataset[i][column] -= _baseline\n        return dataset\n    except IndexError, e:\n        if fail_silently:\n            # fail silently\n            return dataset\n        raise e", "response": "Subtract baseline from the dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _dataset_info(dataset):\n    info = {}\n\n    info[\"uri\"] = dataset.uri\n    info[\"uuid\"] = dataset.uuid\n\n    # Computer and human readable size of dataset.\n    tot_size = sum([dataset.item_properties(i)[\"size_in_bytes\"]\n                    for i in dataset.identifiers])\n    info[\"size_int\"] = tot_size\n    info[\"size_str\"] = sizeof_fmt(tot_size)\n\n    info[\"creator\"] = dataset._admin_metadata[\"creator_username\"]\n    info[\"name\"] = dataset._admin_metadata[\"name\"]\n\n    info[\"date\"] = date_fmt(dataset._admin_metadata[\"frozen_at\"])\n\n    info[\"num_items\"] = len(dataset.identifiers)\n\n    info[\"readme_content\"] = dataset.get_readme_content()\n\n    return info", "response": "Return information about dataset as a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef inventory(uri, format):\n    base_uri = dtoolcore.utils.sanitise_uri(uri)\n    info = _base_uri_info(base_uri)\n\n    if format is None:\n        _cmd_line_report(info)\n    elif format == \"csv\":\n        _csv_tsv_report(info, \",\")\n    elif format == \"tsv\":\n        _csv_tsv_report(info, \"\\t\")\n    elif format == \"html\":\n        _html_report(info)", "response": "Generate an inventory of datasets in a base URI."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef analyze(self, file_path='', file_url='', byte_data=None):\r\n\r\n        ''' a method to determine the mimetype and extension of a file from its byte data\r\n\r\n        :param file_path: [optional] string with local path to file\r\n        :param file_url: [optional] string with url of file\r\n        :param byte_data: [optional] byte data from a file\r\n        :return: dictionary with file details\r\n\r\n        {\r\n            'name': 'filename.ext',\r\n            'mimetype': 'type/sub-type',\r\n            'extension': '.ext'\r\n        }\r\n        '''\r\n\r\n        title = '%s.analyze' % self.__class__.__name__\r\n\r\n    # validate inputs\r\n        input_fields = {\r\n            'file_path': file_path,\r\n            'file_url': file_url\r\n        }\r\n        for key, value in input_fields.items():\r\n            if value:\r\n                object_title = '%s(%s=%s)' % (title, key, str(value))\r\n                self.fields.validate(value, '.%s' % key, object_title)\r\n        if byte_data:\r\n            if not isinstance(byte_data, bytes):\r\n                raise ValueError(\"%s(byte_data=b'...') must be byte data\" % title)\r\n\r\n    # construct empty type map\r\n        file_details = {\r\n            'name': '',\r\n            'mimetype': '',\r\n            'extension': ''\r\n        }\r\n        magic_results = None\r\n\r\n    # analyze file\r\n        if file_path:\r\n            import os\r\n            if not os.path.exists(file_path):\r\n                raise ValueError('%s(file_path=%s) is not a valid path.' % (title, file_path))\r\n            split_file = os.path.split(file_path)\r\n            file_details['name'] = split_file[0]\r\n            if len(split_file) > 1:\r\n                file_details['name'] = split_file[1]\r\n            magic_results = self.magic.from_file(file_path)\r\n\r\n    # analyze url\r\n        elif file_url:\r\n            from urllib.parse import urlsplit\r\n            url_path = urlsplit(file_url).path\r\n            path_segments = url_path.split('/')\r\n            file_details['name'] = path_segments[-1]\r\n            import requests\r\n            try:\r\n                response = requests.get(file_url)\r\n            except Exception:\r\n                from labpack.handlers.requests import handle_requests\r\n                response_details = handle_requests(requests.Request(url=file_url))\r\n                raise ValueError('%s(file_url=%s) created this error: %s' % (title, file_url, response_details['error']))\r\n            magic_results = self.magic.from_buffer(response.content)\r\n\r\n    # analyze buffer\r\n        elif byte_data:\r\n            magic_results = self.magic.from_buffer(byte_data)\r\n\r\n        else:\r\n            raise IndexError('%s(...) requires either a file_path, file_url or byte_data argument' % title)\r\n\r\n        if magic_results:\r\n            file_details['mimetype'] = magic_results\r\n            mime_results = self.mimetypes.guess_extension(magic_results)\r\n            if mime_results:\r\n                file_details['extension'] = mime_results\r\n\r\n        return file_details", "response": "a method to determine the mimetype and extension of a file from its byte data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef custom_prompt(msg, delims=\"\", completer=lambda: None):\n    try:\n        orig_delims = readline.get_completer_delims()\n        orig_completer = readline.get_completer()\n\n        readline.set_completer_delims(delims)\n        readline.set_completer(completer)\n\n        try:\n            ret = input(msg)\n        finally:\n            readline.set_completer_delims(orig_delims)\n            readline.set_completer(orig_completer)\n\n        return ret\n    except EOFError:\n        raise UserQuit()", "response": "Start up a prompt that with particular delims and completer"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _pad(self, data):\n        length = 16 - (len(data) % 16)\n        data += chr(length)*length\n        return data", "response": "Pads the data with bytes so it s a multiple of 16."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate and hmac signature for this encrypted data", "response": "def _hash(self, iv, value):\n        \"\"\"\n        Generate and hmac signature for this encrypted data\n        :param key:\n        :param iv:\n        :param value:\n        :return string:\n        \"\"\"\n        return hmac.new(self.key, msg=iv+value, digestmod=hashlib.sha256).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends an email using the SMTP connection.", "response": "def send(self, recipient, subject, message):\n        \"\"\"\n        Sends an email using the SMTP connection.\n\n        :param recipient: <tuple> recipient's email address as the first element and their name as an optional second\n                            element\n        :param subject: <str> mail subject\n        :param message: <str> mail content (as HTML markup)\n        :return: <bool> True if mail was sent successfully, False otherwise\n        \"\"\"\n        if self.configured is False:\n            return False\n\n        # connecting to server\n        try:\n            self.smtp = smtplib.SMTP(\n                self.application.config[\"viper.mail\"][\"host\"],\n                self.application.config[\"viper.mail\"][\"port\"]\n            )\n\n            self.smtp.connect(\n                self.application.config[\"viper.mail\"][\"host\"],\n                self.application.config[\"viper.mail\"][\"port\"]\n            )\n\n            if self.application.config[\"viper.mail\"][\"tls\"]:\n                self.smtp.starttls()\n        except Exception as e:\n            if hasattr(self, \"smtp\") and self.smtp is not None:\n                self.smtp.quit()\n\n            self.log.warn(\n                \"[Viper.Mail] Cannot connect to server. Error: {error}\",\n                error=str(e)\n            )\n            return False\n\n        # performing authentication\n        if len(self.application.config[\"viper.mail\"][\"username\"]) > 0:\n            try:\n                self.smtp.login(\n                    self.application.config[\"viper.mail\"][\"username\"],\n                    self.application.config[\"viper.mail\"][\"password\"]\n                )\n            except Exception as e:\n                if hasattr(self, \"smtp\") and self.smtp is not None:\n                    self.smtp.quit()\n\n                self.log.warn(\n                    \"[Viper.Mail] Cannot authenticate with server. Error: {error}\",\n                    error=str(e)\n                )\n                return False\n\n        # composing message headers\n        messageHeaders = []\n        messageHeaders.append(\"From: {} <{}>\".format(\n            self.application.config[\"viper.mail\"][\"name\"],\n            self.application.config[\"viper.mail\"][\"from\"]\n        ))\n\n        if len(recipient) == 2:\n            messageHeaders.append(\"To: {} <{}>\".format(\n                recipient[1],\n                recipient[0]\n            ))\n        else:\n            messageHeaders.append(\"To: {}\".format(\n                recipient[0]\n            ))\n\n        messageHeaders.append(\"MIME-Version: 1.0\")\n        messageHeaders.append(\"Content-type: text/html\")\n        messageHeaders.append(\"Subject: {}\".format(subject))\n\n        # creating email contents\n        emailContents = \"\"\n        for messageHeaderLine in messageHeaders:\n            if len(emailContents) == 0:\n                emailContents = messageHeaderLine\n            else:\n                emailContents = \"{}\\n{}\".format(\n                    emailContents,\n                    messageHeaderLine\n                )\n        emailContents = \"{}\\n\\n{}\".format(\n            emailContents,\n            message\n        )\n\n        # sending email\n        try:\n            self.smtp.sendmail(\n                self.application.config[\"viper.mail\"][\"from\"],\n                [recipient[0]],\n                emailContents\n            )\n        except smtplib.SMTPRecipientsRefused as e:\n            if hasattr(self, \"smtp\") and self.smtp is not None:\n                self.smtp.quit()\n\n            self.log.warn(\n                \"[Viper.Mail] Server refused mail recipients: \" \\\n                \"{recipients}. Error: {error}\",\n                recipients=recipient,\n                error=str(e)\n            )\n            return False\n        except smtplib.SMTPSenderRefused as e:\n            if hasattr(self, \"smtp\") and self.smtp is not None:\n                self.smtp.quit()\n\n            self.log.warn(\n                \"[Viper.Mail] Server refused mail sender: {sender}. \" \\\n                \"Error: {error}\",\n                sender=self.application.config[\"viper.mail\"][\"from\"],\n                error=str(e)\n            )\n            return False\n        except Exception as e:\n            if hasattr(self, \"smtp\") and self.smtp is not None:\n                self.smtp.quit()\n\n            self.log.warn(\n                \"[Viper.Mail] Server refused to deliver mail. Error: {error}\",\n                error=str(e)\n            )\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds the Merlin venue for a specific language and genre.", "response": "def discover(ctx):\n    '''\n        This is Merlin \n        \n        He is google's dumb cousin who can search for movies\n\n        He is a tad slow, so please be patient with him\n\n        He is dumb too, so while telling him about names of the cast or crew, make sure to avoid spelling mistakes\n\n        For example, you are looking for Arnold Schwarzenegger, you just tell him arnold and he will find him\n\n        If you are looking for Anne Hathaway, you just tell him anne, and so on\n\n        If you will misspell a name he won't be able to find the intended person \n        \n        So, just follow the instructions and let Merlin weave his spell \n    '''\n    if ctx.invoked_subcommand is None:\n        click.echo(\"Hi, I am Merlin, your personal movie recommender\\n\")\n        time.sleep(1)\n        click.echo(\"So,let's find you a Movie\\n\")\n\n        # Get the Language\n        language = 'en'\n        wantLanguage = click.confirm('Do you want to pick the language,default is english')\n        click.echo('\\n')\n        if wantLanguage:\n            justEN = click.confirm('All languages')\n            click.echo('\\n')\n            if justEN:\n               language = '' \n\n        # Get the Genre\n        genre = ''\n        wantGenre = click.confirm('Do you want to a pick a genre ')\n        click.echo('\\n')\n        if wantGenre:\n            for key in sorted(numToGenre.iterkeys()):\n                click.echo(str(key) + '. ' + numToGenre[key].encode('ascii','ignore'))\n            g = click.prompt('\\nPick a Genre(comma separated)')\n            click.echo('\\n')\n            gList = g.split(',')\n            for i in xrange(len(gList)):\n                genre += str(genreDict[numToGenre[int(gList[i])]])\n                genre += ','\n            genre = genre[:-1]\n\n        # Get the year\n        year = ''\n        wantYear = click.confirm('Do you want to pick a year, only movies after this year will be picked')\n        click.echo('\\n')\n        if wantYear:\n            year = click.prompt('Pick a year (YYYY)')\n            click.echo('\\n')\n\n        # Get the Cast\n        cast = ''\n        wantCast = click.confirm('Do you want to specify the cast ')\n        click.echo('\\n')\n        if wantCast:\n            click.echo('Pick the cast, Be as specific as you can and avoid spelling mistakes\\n')\n            while True:\n                search = tmdb.Search()\n                name = click.prompt('Give me a name')\n                click.echo('\\n')\n                result = findPerson(name)\n                if (result):\n                    for key in sorted(result.iterkeys()):\n                        add = click.confirm('Are you looking for ' + key[1].encode('ascii','ignore'))\n                        click.echo('\\n')\n                        if add:\n                            cast += str(result[key])\n                            cast += ','\n                            break;\n                else:\n                    click.echo('Sorry, try again')\n                    click.echo('\\n')\n                 \n                confirm = click.confirm('You want to add more people')\n                click.echo('\\n')\n                if (confirm == False):\n                    break\n            cast = cast[:-1]\n\n        \n        # Get the crew\n        crew = ''\n        wantCrew = click.confirm('Do you want to specify the crew ')\n        click.echo('\\n')\n        if wantCrew:\n            click.echo('Pick the crew, Be as specific as you can and avoid spelling mistakes\\n')\n            while True:\n                search = tmdb.Search()\n                name = click.prompt('Give me a name')\n                click.echo('\\n')\n\n                result = findPerson(name)\n                if (result):\n                    for key in sorted(result.iterkeys()):\n                        add = click.confirm('Are you looking for ' + key[1].encode('ascii','ignore'))\n                        click.echo('\\n')\n                        if add:\n                            crew += str(result[key])\n                            crew += ','\n                            break;\n                else:\n                    click.echo('Sorry, try again')\n                    click.echo('\\n')\n                 \n                confirm = click.confirm('You want to add more people')\n                click.echo('\\n')\n                if (confirm == False):\n                    break\n            crew = crew[:-1]\n\n        # Get results\n        click.echo('Sit back and Relax\\n')\n        page = 1\n\n        castSearch = cast\n        crewSearch = crew\n        tPages = 0\n        tResults = 0\n\n        while True: \n            if page > 1:\n                click.echo('Looking for more results\\n')\n            movies,tPages,tResults = discoverMovie(genre,castSearch,crewSearch,language,year,page)\n            wantQuit = False\n\n            if movies:\n                           \n                page += 1\n\n                wantQuit = displayMovie(movies,wantQuit) \n                click.echo('\\n')\n                if wantQuit == False:\n                    break\n                    \n            else:\n                if tResults == 0:\n                    click.echo('Nothing found\\n')\n                    break \n\n                elif page > tPages:\n                    click.echo('End of the results\\n')\n                    break\n                else:\n                    click.echo('Sorry, try again')\n            \n            #if wantQuit == False:\n            #    break\n        click.echo(\"That's all Folks,Merlin says goodbye\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef primitive_form(obj, **kwargs):\n    '''Return obj, if possible, in a form composed of primitive or builtin objects.'''\n    if isinstance(obj, type):\n        return obj\n    return Type.dispatch(obj).primitive_form(**kwargs)", "response": "Return obj if possible in a form composed of primitive or builtin objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the PDF of the uncertain parameter evaluated at the values provided in u_values.", "response": "def evalPDF(self, u_values):\n        '''Returns the PDF of the uncertain parameter evaluated at the values\n        provided in u_values.\n\n        :param iterable u_values: values of the uncertain parameter at which to\n            evaluate the PDF\n\n        *Example Usage* ::\n\n            >>> u = UniformParameter()\n            >>> X = numpy.linspace(-1, 1, 100)\n            >>> Y = [u.evalPDF(x) for x in X]\n\n        '''\n\n        if isinstance(u_values, np.ndarray):\n            return self._evalPDF(u_values)\n        else:\n            try:\n                iter(u_values)\n                return [self._evalPDF(u) for u in u_values]\n            except:\n                return self._evalPDF(u_values)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a case - insensitive regex for searching terms", "response": "def term_regex(term):\n    \"\"\"\n    Returns a case-insensitive regex for searching terms\n    \"\"\"\n    return re.compile(r'^{0}$'.format(re.escape(term)), re.IGNORECASE)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef show_fact(term):\n    logger.info('Showing fact %s', term)\n    record = db.facts.find_one({'term': term_regex(term)})\n\n    if record is None:\n        return None\n\n    # Fix double spacing in older facts\n    if record['fact']:\n        record['fact'] = record['fact'].replace('  ', ' ')\n\n    # If it isn't authored\n    if not record.get('set_by', ''):\n        return record['fact']\n\n    if 'set_date' not in record:\n        return '{fact} ({set_by})'.format(**record)\n\n    # Otherwise, do normal formatting\n    tz = getattr(settings, 'TIMEZONE', 'US/Eastern')\n    try:\n        timestamp = datetime.fromtimestamp(record['set_date'], tz=pytz.timezone(tz))\n    except TypeError:\n        timestamp = record['set_date'].replace(tzinfo=pytz.timezone(tz))\n    record['fmt_dt'] = datetime.strftime(timestamp, '%m/%d/%Y %I:%M%p')\n\n    return '{fact} ({set_by} on {fmt_dt})'.format(**record)", "response": "Show a fact stored for a given term using a case - insensitive search."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_fact(term, fact, author=''):\n    logger.info('Adding new fact %s: %s', term, fact)\n\n    if not db.facts.find({'term': term_regex(term)}).count():\n        db.facts.insert({\n            'term': term,\n            'fact': fact,\n            'set_by': author,\n            'set_date': time.time()\n        })\n        db.facts.ensure_index('term')", "response": "Records a new fact with a given term. Optionally can set an author."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nforget a fact by removing it from the database", "response": "def forget_fact(term):\n    \"\"\"\n    Forgets a fact by removing it from the database\n    \"\"\"\n    logger.info('Removing fact %s', term)\n    db.facts.remove({'term': term_regex(term)})\n    return random.choice(ACKS)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing an existing fact with a new one.", "response": "def replace_fact(term, fact, author=''):\n    \"\"\"\n    Replaces an existing fact by removing it, then adding the new definition\n    \"\"\"\n    forget_fact(term)\n    add_fact(term, fact, author)\n    return random.choice(ACKS)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef facts(client, channel, nick, message, *args):\n    if len(args) == 2:\n        return facts_command(client, channel, nick, message, *args)\n\n    # Anything else is a match\n    return facts_match(client, channel, nick, message, args[0])", "response": "A function that returns a list of facts for a user."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_module_docstring(app, what, name, obj, options, lines):\n    if what == \"module\" and name == \"clusterpolate\":\n        del lines[:]", "response": "Remove the docstring of the clusterpolate module."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the cardinal direction for a degree direction", "response": "def get_cardinal_direction(direction: int) -> str:  # noqa\n    \"\"\"\n    Returns the cardinal direction (NSEW) for a degree direction\n\n    Wind Direction - Cheat Sheet:\n\n    (360) -- 011/012 -- 033/034 -- (045) -- 056/057 -- 078/079 -- (090)\n\n    (090) -- 101/102 -- 123/124 -- (135) -- 146/147 -- 168/169 -- (180)\n\n    (180) -- 191/192 -- 213/214 -- (225) -- 236/237 -- 258/259 -- (270)\n\n    (270) -- 281/282 -- 303/304 -- (315) -- 326/327 -- 348/349 -- (360)\n    \"\"\"\n    ret = ''\n    if not isinstance(direction, int):\n        direction = int(direction)\n    # Convert to range [0 360]\n    while direction < 0:\n        direction += 360\n    direction = direction % 360\n    if 304 <= direction <= 360 or 0 <= direction <= 56:\n        ret += 'N'\n        if 304 <= direction <= 348:\n            if 327 <= direction <= 348:\n                ret += 'N'\n            ret += 'W'\n        elif 12 <= direction <= 56:\n            if 12 <= direction <= 33:\n                ret += 'N'\n            ret += 'E'\n    elif 124 <= direction <= 236:\n        ret += 'S'\n        if 124 <= direction <= 168:\n            if 147 <= direction <= 168:\n                ret += 'S'\n            ret += 'E'\n        elif 192 <= direction <= 236:\n            if 192 <= direction <= 213:\n                ret += 'S'\n            ret += 'W'\n    elif 57 <= direction <= 123:\n        ret += 'E'\n        if 57 <= direction <= 78:\n            ret += 'NE'\n        elif 102 <= direction <= 123:\n            ret += 'SE'\n    elif 237 <= direction <= 303:\n        ret += 'W'\n        if 237 <= direction <= 258:\n            ret += 'SW'\n        elif 282 <= direction <= 303:\n            ret += 'NW'\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wind(direction: Number,\n         speed: Number,\n         gust: Number,\n         vardir: typing.List[Number] = None,  # type: ignore\n         unit: str = 'kt',\n         cardinals: bool = True,\n         spoken: bool = False) -> str:\n    \"\"\"\n    Format wind elements into a readable sentence\n\n    Returns the translation string\n\n    Ex: NNE-020 (variable 010 to 040) at 14kt gusting to 20kt\n    \"\"\"\n    ret = ''\n    target = 'spoken' if spoken else 'repr'\n    # Wind direction\n    if direction:\n        if direction.repr in WIND_DIR_REPR:\n            ret += WIND_DIR_REPR[direction.repr]\n        elif direction.value is None:\n            ret += direction.repr\n        else:\n            if cardinals:\n                ret += get_cardinal_direction(direction.value) + '-'  # type: ignore\n            ret += getattr(direction, target)\n    # Variable direction\n    if vardir and isinstance(vardir, list):\n        vardir = [getattr(var, target) for var in vardir]\n        ret += ' (variable {} to {})'.format(*vardir)\n    # Speed\n    if speed and speed.value:\n        ret += f' at {speed.value}{unit}'\n    # Gust\n    if gust and gust.value:\n        ret += f' gusting to {gust.value}{unit}'\n    return ret", "response": "Returns a string representation of the wind elements into a readable sentence."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef visibility(vis: Number, unit: str = 'm') -> str:\n    if not (vis and unit in ('m', 'sm')):\n        return ''\n    if vis.repr in VIS_REPR:\n        return VIS_REPR[vis.repr]\n    if unit == 'm':\n        converted = vis.value * 0.000621371\n        converted = str(round(converted, 1)).replace('.0', '') + 'sm'  # type: ignore\n        value = str(round(vis.value / 1000, 1)).replace('.0', '')\n        unit = 'km'\n    elif unit == 'sm':\n        converted = vis.value / 0.621371\n        converted = str(round(converted, 1)).replace('.0', '') + 'km'  # type: ignore\n        value = str(vis.value).replace('.0', '')\n    return f'{value}{unit} ({converted})'", "response": "Formats a visibility element into a string with both km and sm values"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef temperature(temp: Number, unit: str = 'C') -> str:\n    unit = unit.upper()\n    if not (temp and unit in ('C', 'F')):\n        return ''\n    if unit == 'C':\n        converted = temp.value * 1.8 + 32\n        converted = str(int(round(converted))) + '\u00b0F'  # type: ignore\n    elif unit == 'F':\n        converted = (temp.value - 32) / 1.8\n        converted = str(int(round(converted))) + '\u00b0C'  # type: ignore\n    return f'{temp.value}\u00b0{unit} ({converted})'", "response": "Formats a temperature element into a string with both C and F values"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nformats the altimter element into a string with hPa and inHg values.", "response": "def altimeter(alt: Number, unit: str = 'hPa') -> str:\n    \"\"\"\n    Formats the altimter element into a string with hPa and inHg values\n\n    Ex: 30.11 inHg (10.20 hPa)\n    \"\"\"\n    if not (alt and unit in ('hPa', 'inHg')):\n        return ''\n    if unit == 'hPa':\n        value = alt.repr\n        converted = alt.value / 33.8638866667\n        converted = str(round(converted, 2)) + ' inHg'  # type: ignore\n    elif unit == 'inHg':\n        value = alt.repr[:2] + '.' + alt.repr[2:]\n        converted = float(value) * 33.8638866667\n        converted = str(int(round(converted))) + ' hPa'  # type: ignore\n    return f'{value} {unit} ({converted})'"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats a list of clouds into a readable sentence", "response": "def clouds(clds: [Cloud], unit: str = 'ft') -> str:  # type: ignore\n    \"\"\"\n    Format cloud list into a readable sentence\n\n    Returns the translation string\n\n    Ex: Broken layer at 2200ft (Cumulonimbus), Overcast layer at 3600ft - Reported AGL\n    \"\"\"\n    if clds is None:\n        return ''\n    ret = []\n    for cloud in clds:\n        if cloud.altitude is None:\n            continue\n        cloud_str = CLOUD_TRANSLATIONS[cloud.type]\n        if cloud.modifier:\n            cloud_str += f' ({CLOUD_TRANSLATIONS[cloud.modifier]})'\n        ret.append(cloud_str.format(cloud.altitude * 100, unit))\n    if ret:\n        return ', '.join(ret) + ' - Reported AGL'\n    return 'Sky clear'"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wxcode(code: str) -> str:\n    if not code:\n        return ''\n    ret = ''\n    if code[0] == '+':\n        ret = 'Heavy '\n        code = code[1:]\n    elif code[0] == '-':\n        ret = 'Light '\n        code = code[1:]\n    # Return code if code is not a code, ex R03/03002V03\n    if len(code) not in [2, 4, 6]:\n        return code\n    for _ in range(len(code) // 2):\n        if code[:2] in WX_TRANSLATIONS:\n            ret += WX_TRANSLATIONS[code[:2]] + ' '\n        else:\n            ret += code[:2]\n        code = code[2:]\n    return ret.strip()", "response": "Returns a string of variable length weather code"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntranslating wind shear into a readable string", "response": "def wind_shear(shear: str, unit_alt: str = 'ft', unit_wind: str = 'kt', spoken: bool = False) -> str:\n    \"\"\"\n    Translate wind shear into a readable string\n\n    Ex: Wind shear 2000ft from 140 at 30kt\n    \"\"\"\n    if not shear or 'WS' not in shear or '/' not in shear:\n        return ''\n    shear = shear[2:].rstrip(unit_wind.upper()).split('/')  # type: ignore\n    wdir = core.spoken_number(shear[1][:3]) if spoken else shear[1][:3]\n    return f'Wind shear {int(shear[0])*100}{unit_alt} from {wdir} at {shear[1][3:]}{unit_wind}'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntranslating the list of turbulance or icing into a readable sentence", "response": "def turb_ice(turbice: [str], unit: str = 'ft') -> str:  # type: ignore\n    \"\"\"\n    Translate the list of turbulance or icing into a readable sentence\n\n    Ex: Occasional moderate turbulence in clouds from 3000ft to 14000ft\n    \"\"\"\n    if not turbice:\n        return ''\n    # Determine turbulance or icing\n    if turbice[0][0] == '5':\n        conditions = TURBULANCE_CONDITIONS\n    elif turbice[0][0] == '6':\n        conditions = ICING_CONDITIONS\n    else:\n        return ''\n    # Create list of split items (type, floor, height)\n    split = []\n    for item in turbice:\n        if len(item) == 6:\n            split.append([item[1:2], item[2:5], item[5]])\n    # Combine items that cover a layer greater than 9000ft\n    for i in reversed(range(len(split) - 1)):\n        if split[i][2] == '9' and split[i][0] == split[i + 1][0] \\\n                and int(split[i + 1][1]) == (int(split[i][1]) + int(split[i][2]) * 10):\n            split[i][2] = str(int(split[i][2]) + int(split[i + 1][2]))\n            split.pop(i + 1)\n    # Return joined, formatted string from split items\n    return ', '.join(['{conditions} from {low_alt}{unit} to {high_alt}{unit}'.format(\n        conditions=conditions[item[0]], low_alt=int(item[1]) * 100,\n        high_alt=int(item[1]) * 100 + int(item[2]) * 1000, unit=unit) for item in split])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nformats the Min and Max temperature elemets into a readable string", "response": "def min_max_temp(temp: str, unit: str = 'C') -> str:\n    \"\"\"\n    Format the Min and Max temp elemets into a readable string\n\n    Ex: Maximum temperature of 23\u00b0C (73\u00b0F) at 18-15:00Z\n    \"\"\"\n    if not temp or len(temp) < 7:\n        return ''\n    if temp[:2] == 'TX':\n        temp_type = 'Maximum'\n    elif temp[:2] == 'TN':\n        temp_type = 'Minimum'\n    else:\n        return ''\n    temp = temp[2:].replace('M', '-').replace('Z', '').split('/')  # type: ignore\n    if len(temp[1]) > 2:\n        temp[1] = temp[1][:2] + '-' + temp[1][2:]  # type: ignore\n    temp_value = temperature(core.make_number(temp[0]), unit)\n    return f'{temp_type} temperature of {temp_value} at {temp[1]}:00Z'"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dictionary of translations shared between two reports.", "response": "def shared(wxdata: ReportData, units: Units) -> typing.Dict[str, str]:\n    \"\"\"\n    Translate Visibility, Altimeter, Clouds, and Other\n    \"\"\"\n    translations = {}\n    translations['visibility'] = visibility(wxdata.visibility, units.visibility)  # type: ignore\n    translations['altimeter'] = altimeter(wxdata.altimeter, units.altimeter)  # type: ignore\n    translations['clouds'] = clouds(wxdata.clouds, units.altitude)  # type: ignore\n    translations['other'] = other_list(wxdata.other)  # type: ignore\n    return translations"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef metar(wxdata: MetarData, units: Units) -> MetarTrans:\n    translations = shared(wxdata, units)\n    translations['wind'] = wind(wxdata.wind_direction, wxdata.wind_speed,\n                                wxdata.wind_gust, wxdata.wind_variable_direction,\n                                units.wind_speed)\n    translations['temperature'] = temperature(wxdata.temperature, units.temperature)\n    translations['dewpoint'] = temperature(wxdata.dewpoint, units.temperature)\n    translations['remarks'] = remarks.translate(wxdata.remarks)  # type: ignore\n    return MetarTrans(**translations)", "response": "Translate the results of metar. parse\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntranslate the results of taf. parse", "response": "def taf(wxdata: TafData, units: Units) -> TafTrans:\n    \"\"\"\n    Translate the results of taf.parse\n\n    Keys: Forecast, Min-Temp, Max-Temp\n\n    Forecast keys: Wind, Visibility, Clouds, Altimeter, Wind-Shear, Turbulance, Icing, Other\n    \"\"\"\n    translations = {'forecast': []}  # type: ignore\n    for line in wxdata.forecast:\n        trans = shared(line, units)  # type: ignore\n        trans['wind'] = wind(line.wind_direction, line.wind_speed,\n                             line.wind_gust, unit=units.wind_speed)\n        trans['wind_shear'] = wind_shear(line.wind_shear, units.altitude, units.wind_speed)\n        trans['turbulance'] = turb_ice(line.turbulance, units.altitude)\n        trans['icing'] = turb_ice(line.icing, units.altitude)\n        # Remove false 'Sky Clear' if line type is 'BECMG'\n        if line.type == 'BECMG' and trans['clouds'] == 'Sky clear':\n            trans['clouds'] = None  # type: ignore\n        translations['forecast'].append(TafLineTrans(**trans))  # type: ignore\n    translations['min_temp'] = min_max_temp(wxdata.min_temp, units.temperature)  # type: ignore\n    translations['max_temp'] = min_max_temp(wxdata.max_temp, units.temperature)  # type: ignore\n    translations['remarks'] = remarks.translate(wxdata.remarks)\n    return TafTrans(**translations)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_rtype(self, value):\n\n        if not value or value != self.rtype:\n            msg = self.messages['rtype'].format(self.rtype, value)\n            raise ValidationError(msg)\n        return value", "response": "Schematics validator\n\n        The provided rtype must match that of the\n        underlying model.\n\n        :return: str"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the substitution element for the given head element.", "response": "def _get_substitute_element(head, elt, ps):\n    '''if elt matches a member of the head substitutionGroup, return \n    the GED typecode.\n\n    head -- ElementDeclaration typecode, \n    elt -- the DOM element being parsed\n    ps -- ParsedSoap Instance\n    '''\n    if not isinstance(head, ElementDeclaration):\n        return None\n\n    return ElementDeclaration.getSubstitutionElement(head, elt, ps)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _is_substitute_element(head, sub):\n    '''if head and sub are both GEDs, and sub declares \n    head as its substitutionGroup then return True.\n\n    head -- Typecode instance\n    sub  -- Typecode instance\n    '''\n    if not isinstance(head, ElementDeclaration) or not isinstance(sub, ElementDeclaration):\n        return False\n\n    try:\n        group = sub.substitutionGroup \n    except (AttributeError, TypeError):\n        return False\n\n    ged = GED(*group)\n\n    # TODO: better way of representing element references.  Wrap them with\n    # facets, and dereference when needed and delegate to..\n    print (head.nspname == ged.nspname and head.pname == ged.pname)\n    if head is ged or not (head.nspname == ged.nspname and head.pname == ged.pname):\n        return False\n\n    return True", "response": "Returns True if head and sub declares \n    head as its substitutionGroup then return False."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getTypeDefinition(cls, namespaceURI, name, lazy=False):\n        '''Grab a type definition, returns a typecode class definition\n        because the facets (name, minOccurs, maxOccurs) must be provided.\n \n        Parameters:\n           namespaceURI -- \n           name -- \n        '''\n        klass = cls.types.get((namespaceURI, name), None)\n        if lazy and klass is not None:\n            return _Mirage(klass)\n        return klass", "response": "Grab a type definition returns a typecode class definition\n        because the facets name minOccurs and maxOccurs must be provided."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngrabbing an element declaration returns a typecode instance or a typecode class definition.", "response": "def getElementDeclaration(cls, namespaceURI, name, isref=False, lazy=False):\n        '''Grab an element declaration, returns a typecode instance\n        representation or a typecode class definition.  An element \n        reference has its own facets, and is local so it will not be\n        cached.\n\n        Parameters:\n            namespaceURI -- \n            name -- \n            isref -- if element reference, return class definition.\n        '''\n        key = (namespaceURI, name)\n        if isref:\n            klass = cls.elements.get(key,None)\n            if klass is not None and lazy is True:\n                return _Mirage(klass)\n            return klass\n \n        typecode = cls.element_typecode_cache.get(key, None)\n        if typecode is None:\n            tcls = cls.elements.get(key,None)\n            if tcls is not None:\n                typecode = cls.element_typecode_cache[key] = tcls()\n                typecode.typed = False\n            \n        return typecode"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if this typecode is substituted by another typecode.", "response": "def checkSubstitute(self, typecode):\n        '''If this is True, allow typecode to be substituted\n        for \"self\" typecode.\n        '''\n        if not isinstance(typecode, ElementDeclaration): \n            return False\n\n        try:\n            nsuri,ncname = typecode.substitutionGroup\n        except (AttributeError, TypeError):\n            return False\n\n        if (nsuri,ncname) != (self.schema,self.literal):\n            # allow slop with the empty namespace \n            if not nsuri and not self.schema and ncname == self.literal:\n                 return True\n\n            return False\n\n        sub = GED(self.schema, self.literal)\n        if sub is None or sub is not typecode:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getSubstitutionElement(self, elt, ps):\n        '''if elt matches a member of the head substitutionGroup, return \n        the GED typecode representation of the member.\n\n        head -- ElementDeclaration typecode, \n        elt -- the DOM element being parsed\n        ps -- ParsedSoap instance\n        '''\n        nsuri,ncname = _get_element_nsuri_name(elt)\n        typecode = GED(nsuri,ncname)\n        if typecode is None:\n            return\n\n        try:\n            nsuri,ncname = typecode.substitutionGroup\n        except (AttributeError, TypeError):\n            return\n\n        if (ncname == self.pname) and (nsuri == self.nspname or \n           (not nsuri and not self.nspname)):\n             return typecode\n       \n        return", "response": "Return the typecode representation of the element elt."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getSubstituteType(self, elt, ps):\n        '''if xsi:type does not match the instance type attr,\n        check to see if it is a derived type substitution.\n        \n        DONT Return the element's type.\n        \n        Parameters:\n            elt -- the DOM element being parsed\n            ps -- the ParsedSoap object.\n        '''\n        pyclass = SchemaInstanceType.getTypeDefinition(*self.type)\n        if pyclass is None:\n            raise EvaluateException(\n                    'No Type registed for xsi:type=(%s, %s)' %\n                    (self.type[0], self.type[1]), ps.Backtrace(elt))\n            \n        typeName = _find_type(elt)\n        prefix,typeName = SplitQName(typeName)\n        uri = ps.GetElementNSdict(elt).get(prefix)\n        subclass = SchemaInstanceType.getTypeDefinition(uri, typeName)\n        if subclass is None:\n            raise EvaluateException(\n                    'No registered xsi:type=(%s, %s), substitute for xsi:type=(%s, %s)' %\n                    (uri, typeName, self.type[0], self.type[1]), ps.Backtrace(elt))\n                    \n        if not issubclass(subclass, pyclass) and subclass(None) and not issubclass(subclass, pyclass):\n            raise TypeError(\n                    'Substitute Type (%s, %s) is not derived from %s' %\n                    (self.type[0], self.type[1], pyclass), ps.Backtrace(elt))\n\n        return subclass((self.nspname, self.pname))", "response": "Returns the type of the element that is derived from the element s type attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef RegisterBuiltin(cls, arg):\n        '''register a builtin, create a new wrapper.\n        '''\n        if arg in cls.types_dict:\n            raise RuntimeError, '%s already registered' %arg\n        class _Wrapper(arg):\n            'Wrapper for builtin %s\\n%s' %(arg, cls.__doc__)\n        _Wrapper.__name__ = '_%sWrapper' %arg.__name__\n        cls.types_dict[arg] = _Wrapper", "response": "register a builtin create a new wrapper."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef RegisterAnyElement(cls):\n        '''If find registered TypeCode instance, add Wrapper class \n        to TypeCode class serialmap and Re-RegisterType.  Provides\n        Any serialzation of any instances of the Wrapper.\n        '''\n        for k,v in cls.types_dict.items():\n            what = Any.serialmap.get(k)\n            if what is None: continue\n            if v in what.__class__.seriallist: continue\n            what.__class__.seriallist.append(v)\n            RegisterType(what.__class__, clobber=1, **what.__dict__)", "response": "Provides an Any element of TypeCode class serialmap and Re - RegisterType."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef WrapImmutable(cls, pyobj, what):\n        '''return a wrapper for pyobj, with typecode attribute set.\n        Parameters:\n            pyobj -- instance of builtin type (immutable)\n            what -- typecode describing the data\n        '''\n        d = cls.types_dict\n        if type(pyobj) is bool:  \n            pyclass = d[int]\n        elif d.has_key(type(pyobj)) is True:\n            pyclass = d[type(pyobj)]\n        else:\n            raise TypeError,\\\n               'Expecting a built-in type in %s (got %s).' %(\n                d.keys(),type(pyobj))\n\n        newobj = pyclass(pyobj)\n        newobj.typecode = what\n        return newobj", "response": "return a wrapper for pyobj with typecode attribute set."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\noverride this method to customize the documentation page", "response": "def render_doc(self):\n    '''Override this method to customize the documentation page'''\n    if self._doc_view:\n      return self._doc_view()\n    elif not self._doc:\n      self.abort(self.bc_HTTPStatus_NOT_FOUND)\n    res = render_template('swagger-ui.html', title=self.title, specs_url=self.specs_url)\n    res = res.replace(self.complexReplaceString,self.APIDOCSPath)\n\n    regexp=\"\\\"https?:\\/\\/[a-zA-Z0\\-9._]*(:[0-9]*)?\" + self.internal_api_prefix.replace(\"/\",\"\\/\") + \"\\/swagger.json\\\"\"\n    regexp=\"\\\"https?:\\/\\/[a-zA-Z0\\-9._]*(:[0-9]*)?\" + self.internal_apidoc_prefix.replace(\"/\",\"\\/\") + \"\\/swagger.json\\\"\"\n    p = re.compile(regexp)\n    res = p.sub(\"\\\"\" + self.apidocsurl + \"/swagger.json\\\"\", res)\n    '''\n    if (self.overrideAPIDOCSPath()):\n      #print(\"About to replace\")\n      #print(res)\n      res = self.reaplcements(res)\n      #print(\"Replaced\")\n      #print(res)\n      #print(\"End\")\n    '''\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating the dialog layout", "response": "def __createLayout(self):\n        \"\"\"Creates the dialog layout\"\"\"\n        self.resize(450, 150)\n        self.setSizeGripEnabled(True)\n\n        verticalLayout = QVBoxLayout(self)\n\n        whereGroupbox = QGroupBox(self)\n        whereGroupbox.setTitle(\"Garbage collector message destination\")\n        sizePolicy = QSizePolicy(QSizePolicy.Expanding, QSizePolicy.Preferred)\n        sizePolicy.setHorizontalStretch(0)\n        sizePolicy.setVerticalStretch(0)\n        sizePolicy.setHeightForWidth(\n            whereGroupbox.sizePolicy().hasHeightForWidth())\n        whereGroupbox.setSizePolicy(sizePolicy)\n\n        layoutWhere = QVBoxLayout(whereGroupbox)\n        self.__silentRButton = QRadioButton(whereGroupbox)\n        self.__silentRButton.setText(\"Silent\")\n        layoutWhere.addWidget(self.__silentRButton)\n        self.__statusbarRButton = QRadioButton(whereGroupbox)\n        self.__statusbarRButton.setText(\"Status bar\")\n        layoutWhere.addWidget(self.__statusbarRButton)\n        self.__logtabRButton = QRadioButton(whereGroupbox)\n        self.__logtabRButton.setText(\"Log tab\")\n        layoutWhere.addWidget(self.__logtabRButton)\n\n        verticalLayout.addWidget(whereGroupbox)\n\n        buttonBox = QDialogButtonBox(self)\n        buttonBox.setOrientation(Qt.Horizontal)\n        buttonBox.setStandardButtons(QDialogButtonBox.Ok |\n                                     QDialogButtonBox.Cancel)\n        self.__OKButton = buttonBox.button(QDialogButtonBox.Ok)\n        self.__OKButton.setDefault(True)\n        buttonBox.accepted.connect(self.accept)\n        buttonBox.rejected.connect(self.close)\n        verticalLayout.addWidget(buttonBox)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getCheckedOption(self):\n        if self.__silentRButton.isChecked():\n            return GCPluginConfigDialog.SILENT\n        if self.__statusbarRButton.isChecked():\n            return GCPluginConfigDialog.STATUS_BAR\n        return GCPluginConfigDialog.LOG", "response": "Returns what destination is selected"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_request(self, req, resp):\n\n        goldman.sess.req = req\n\n        if goldman.config.STORE:\n            goldman.sess.store = goldman.config.STORE()", "response": "Process the request before routing it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_seq(seq_record, codon_positions, aminoacids=False, degenerate=None):\n    Sequence = namedtuple('Sequence', ['seq', 'warning'])\n\n    if codon_positions not in [None, '1st', '2nd', '3rd', '1st-2nd', 'ALL']:\n        raise WrongParameterFormat(\"`codon_positions` argument should be any of the following\"\n                                   \": 1st, 2nd, 3rd, 1st-2nd or ALL\")\n    if aminoacids:\n        aa = seq_record.translate()\n        if '*' in aa:\n            warning = \"Gene {0}, sequence {1} contains stop codons '*'\".format(seq_record.gene_code,\n                                                                               seq_record.voucher_code)\n        else:\n            warning = None\n        return Sequence(seq=aa, warning=warning)\n\n    if degenerate:\n        return Sequence(seq=seq_record.degenerate(degenerate), warning=None)\n\n    if codon_positions == '1st':\n        return Sequence(seq=seq_record.first_codon_position(), warning=None)\n    elif codon_positions == '2nd':\n        return Sequence(seq=seq_record.second_codon_position(), warning=None)\n    elif codon_positions == '3rd':\n        return Sequence(seq=seq_record.third_codon_position(), warning=None)\n    elif codon_positions == '1st-2nd':\n        return Sequence(seq=seq_record.first_and_second_codon_positions(), warning=None)\n    else:  # None and ALL\n        return Sequence(seq=str(seq_record.seq), warning=None)", "response": "Returns the sequence required by the given codon positions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert nexus format to Phylip and Fasta using Biopython tools.", "response": "def convert_nexus_to_format(dataset_as_nexus, dataset_format):\n    \"\"\"\n    Converts nexus format to Phylip and Fasta using Biopython tools.\n\n    :param dataset_as_nexus:\n    :param dataset_format:\n    :return:\n    \"\"\"\n    fake_handle = StringIO(dataset_as_nexus)\n    nexus_al = AlignIO.parse(fake_handle, 'nexus')\n    tmp_file = make_random_filename()\n    AlignIO.write(nexus_al, tmp_file, dataset_format)\n    dataset_as_fasta = read_and_delete_tmp_file(tmp_file)\n    return dataset_as_fasta"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the dataset header for NEXUS files from data toMATRIX.", "response": "def make_dataset_header(data, file_format, aminoacids):\n    \"\"\"Creates the dataset header for NEXUS files from ``#NEXUS`` to ``MATRIX``.\n\n    Parameters:\n        data (namedtuple):    with necessary info for dataset creation.\n        file_format (str):    TNT, PHYLIP, NEXUS, FASTA\n        aminoacids (boolean): If ``aminoacids is True`` the header will show\n                              ``DATATYPE=PROTEIN`` otherwise it will be ``DNA``.\n    \"\"\"\n    if aminoacids:\n        datatype = 'PROTEIN'\n    else:\n        datatype = 'DNA'\n\n    if file_format in ['NEXUS', 'PHYLIP', 'FASTA']:\n        header = \"\"\"\n#NEXUS\n\nBEGIN DATA;\nDIMENSIONS NTAX={0} NCHAR={1};\nFORMAT INTERLEAVE DATATYPE={2} MISSING=? GAP=-;\nMATRIX\n\"\"\".format(data.number_taxa, data.number_chars, datatype)\n\n    elif file_format == 'MEGA':\n        return \"#MEGA\\n!TITLE title;\"\n\n    else:  # file_format: TNT\n        if aminoacids:\n            molecule_type = \"prot\"\n        else:\n            molecule_type = \"dna\"\n        header = \"\"\"\nnstates {0};\nxread\n{1} {2}\"\"\".format(molecule_type, data.number_chars, data.number_taxa)\n\n    return header.strip()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntruncate a given text to a maximum number of characters.", "response": "def truncate_sentence(text, max_chars, break_words=False, padding=0):\n    \"\"\"Truncates a sentence.\n\n    :param max_chars: The maximum characters of truncated sentence.\n    :param break_words: If you wish to truncate given sentence strictly even\n                        if it breaks a word, set it to ``True``. It defaults\n                        to ``False`` which means truncating given sentence\n                        shorter but never breaking words.\n    :param padding: The padding size for truncating. It is usually used to\n                    keep spaces for some ending characters such as ``\"...\"``.\n    :return: The truncated sentence.\n    \"\"\"\n    if break_words:\n        return text[:-abs(max_chars - len(text)) - padding]\n\n    words = []\n    for word in text.split():\n        predicted_len = (\n            sum(map(len, words)) +  # length of words\n            len(word) +  # length of next word\n            len(words) - 1 +  # length of spaces\n            padding)\n        if predicted_len >= max_chars:\n            break\n        words.append(word)\n    return ' '.join(words)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming an always succeeding task.", "response": "def always_win(cls, request) -> [(200, 'Ok', String)]:\n        '''Perform an always succeeding task.'''\n        task_id = uuid4().hex.upper()[:5]\n        log.info('Starting always OK task {}'.format(task_id))\n        for i in range(randint(0, MAX_LOOP_DURATION)):\n            yield\n        log.info('Finished always OK task {}'.format(task_id))\n        msg = 'I am finally done with task {}!'.format(task_id)\n        Respond(200, msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms an always failing task.", "response": "def always_fail(cls, request) -> [\n            (200, 'Ok', String),\n            (406, 'Not Acceptable', Void)]:\n        '''Perform an always failing task.'''\n        task_id = uuid4().hex.upper()[:5]\n        log.info('Starting always FAILING task {}'.format(task_id))\n        for i in range(randint(0, MAX_LOOP_DURATION)):\n            yield\n        Respond(406)\n        Respond(200, 'Foobar')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a Fibonacci sequence.", "response": "def fibonacci(cls, request,\n                  limit: (Ptypes.path,\n                          Integer('Upper limit of the series'))) -> [\n            (200, 'Ok', FibonacciFragment)]:\n        '''Return Fibonacci sequence whose last number is <= limit.'''\n        def fibonacci_generator():\n            last_two = (0, 1)\n            while last_two[1] <= limit:\n                log.debug('Fibonacci number generated: {}'.format(last_two[1]))\n                yield last_two[1]\n                last_two = last_two[1], sum(last_two)\n        log.info('Starting Fibonacci generation, max: {}'.format(limit))\n        limit = int(limit)\n        Respond(200, fibonacci_generator())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef query_echo(cls, request,\n                   foo: (Ptypes.query, String('A query parameter'))) -> [\n            (200, 'Ok', String)]:\n        '''Echo the query parameter.'''\n        log.info('Echoing query param, value is: {}'.format(foo))\n        for i in range(randint(0, MAX_LOOP_DURATION)):\n            yield\n        msg = 'The value sent was: {}'.format(foo)\n        Respond(200, msg)", "response": "Echo the query parameter."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nechoes the body parameter.", "response": "def body_echo(cls, request,\n                  foo: (Ptypes.body, String('A body parameter'))) -> [\n            (200, 'Ok', String)]:\n        '''Echo the body parameter.'''\n        log.info('Echoing body param, value is: {}'.format(foo))\n        for i in range(randint(0, MAX_LOOP_DURATION)):\n            yield\n        msg = 'The value sent was: {}'.format(foo)\n        Respond(200, msg)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nechoing the header parameter.", "response": "def header_echo(cls, request,\n                    api_key: (Ptypes.header, String('API key'))) -> [\n            (200, 'Ok', String)]:\n        '''Echo the header parameter.'''\n        log.info('Echoing header param, value is: {}'.format(api_key))\n        for i in range(randint(0, MAX_LOOP_DURATION)):\n            yield\n        msg = 'The value sent was: {}'.format(api_key)\n        Respond(200, msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nechoing the form parameter.", "response": "def form_echo(cls, request,\n                  foo: (Ptypes.form, String('A form parameter'))) -> [\n            (200, 'Ok', String)]:\n        '''Echo the form parameter.'''\n        log.info('Echoing form param, value is: {}'.format(foo))\n        for i in range(randint(0, MAX_LOOP_DURATION)):\n            yield\n        msg = 'The value sent was: {}'.format(foo)\n        Respond(200, msg)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the properties for a given data type. This is the main routine where most of the work is done. It converts Nani's data types into properties that can be used to define a new NumPy array and to wrap it into a view object. Use :func:`validate` to check if the input data type is well-formed. Parameters ---------- data_type : nani data type Type of the array elements. name : str Name for the view to be generated for the array. listify_default : bool ``True`` to output the default values with lists in place of tuples. This might cause the output to be incompatible with array creation routines such as ``numpy.array`` but it should still work for element assignment. Returns ------- nani.Nani The properties to use to initalize a NumPy array around the data type. Examples -------- Create a NumPy array where each element represents a color: >>> import numpy >>> import nani >>> color_type = nani.Array( ... element_type=nani.Number(type=numpy.uint8, default=255), ... shape=3, ... view=None) >>> dtype, default, view = nani.resolve(color_type, name='Color') >>> a = numpy.array([default] * element_count, dtype=dtype) >>> v = view(a) >>> type(v) <class 'nani.Color'> >>> for color in v: ... color [255, 255, 255] [255, 255, 255]", "response": "def resolve(data_type, name=None, listify_default=False):\n    \"\"\"Retrieve the properties for a given data type.\n\n    This is the main routine where most of the work is done. It converts\n    Nani's data types into properties that can be used to define a new NumPy\n    array and to wrap it into a view object.\n\n    Use :func:`validate` to check if the input data type is well-formed.\n\n    Parameters\n    ----------\n    data_type : nani data type\n        Type of the array elements.\n    name : str\n        Name for the view to be generated for the array.\n    listify_default : bool\n        ``True`` to output the default values with lists in place of tuples.\n        This might cause the output to be incompatible with array creation\n        routines such as ``numpy.array`` but it should still work for\n        element assignment.\n\n    Returns\n    -------\n    nani.Nani\n        The properties to use to initalize a NumPy array around the data type.\n\n    Examples\n    --------\n    Create a NumPy array where each element represents a color:\n\n    >>> import numpy\n    >>> import nani\n    >>> color_type = nani.Array(\n    ...     element_type=nani.Number(type=numpy.uint8, default=255),\n    ...     shape=3,\n    ...     view=None)\n    >>> dtype, default, view = nani.resolve(color_type, name='Color')\n    >>> a = numpy.array([default] * element_count, dtype=dtype)\n    >>> v = view(a)\n    >>> type(v)\n    <class 'nani.Color'>\n    >>> for color in v:\n    ...     color\n    [255, 255, 255]\n    [255, 255, 255]\n    \"\"\"\n    data_type = _consolidate(data_type)\n    return Nani(\n        dtype=numpy.dtype(_resolve_dtype(data_type)),\n        default=_resolve_default(data_type, listify=listify_default),\n        view=_resolve_view(Array(element_type=data_type, shape=-1, name=name)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _consolidate(data_type):\n    if isinstance(data_type, _ATOMIC):\n        out = data_type\n    elif isinstance(data_type, Array):\n        element_type = _consolidate(data_type.element_type)\n        out = data_type._replace(element_type=element_type)\n    elif isinstance(data_type, Structure):\n        fields = tuple(\n            Field(*(_consolidate(field[i]) if i == _FIELD_TYPE_IDX\n                    else field[i]\n                    for i in _range(len(field))))\n            for field in data_type.fields)\n        out = data_type._replace(fields=fields)\n\n    return out", "response": "Enforce the structure of the data type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the corresponding NumPy s dtype for a given data type.", "response": "def _resolve_dtype(data_type):\n    \"\"\"Retrieve the corresponding NumPy's `dtype` for a given data type.\"\"\"\n    if isinstance(data_type, _FIXED_ATOMIC):\n        out = _get_atomic_dtype(data_type)\n    elif isinstance(data_type, _FLEXIBLE_ATOMIC):\n        out = (_get_atomic_dtype(data_type), data_type.length)\n    elif isinstance(data_type, Array):\n        shape = data_type.shape\n        if isinstance(shape, _SEQUENCE_TYPES) and len(shape) == 1:\n            # Workaround the exception `ValueError: invalid itemsize in\n            # generic type tuple` when an `Array` of shape 0 or (0,) is nested\n            # within another `Array`.\n            shape = shape[0]\n\n        out = (_resolve_dtype(data_type.element_type), shape)\n    elif isinstance(data_type, Structure):\n        out = [(field.name, _resolve_dtype(field.type))\n               for field in data_type.fields]\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the default value for a given data type.", "response": "def _resolve_default(data_type, listify=False):\n    \"\"\"Retrieve the default value for a given data type.\"\"\"\n    if isinstance(data_type, _ATOMIC):\n        # A Python's object type needs to be left as is instead of being\n        # wrapped into a NumPy type.\n        out = (data_type.default if isinstance(data_type, Object)\n               else _get_atomic_dtype(data_type)(data_type.default))\n    elif isinstance(data_type, Array):\n        element_default = _resolve_default(data_type.element_type,\n                                           listify=listify)\n        Sequence = list if listify else tuple\n        shape = ((data_type.shape,) if isinstance(data_type.shape, int)\n                 else data_type.shape)\n        out = element_default\n        for dimension in shape:\n            out = Sequence(copy.deepcopy(out) for _ in _range(dimension))\n    elif isinstance(data_type, Structure):\n        if listify:\n            out = [_resolve_default(field.type, listify=listify)\n                   for field in data_type.fields]\n        else:\n            field_defaults = collections.OrderedDict(\n                (field.name, _resolve_default(field.type, listify=listify))\n                for field in data_type.fields)\n            name = ('StructureDefault_%s' % (data_type.name,)\n                    if data_type.name else 'StructureDefault')\n            struct = collections.namedtuple(name, field_defaults.keys())\n            out = struct(**field_defaults)\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _resolve_view(data_type):\n    view = getattr(data_type, 'view', None)\n    if view is not None:\n        return view\n\n    if isinstance(data_type, _ATOMIC):\n        out = None\n    elif isinstance(data_type, Array):\n        out = _define_array_view(data_type)\n    elif isinstance(data_type, Structure):\n        out = _define_structure_view(data_type)\n\n    return out", "response": "Retrieve the view for a given data type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndefining a new view object for a Array type.", "response": "def _define_array_view(data_type):\n    \"\"\"Define a new view object for a `Array` type.\"\"\"\n    element_type = data_type.element_type\n    element_view = _resolve_view(element_type)\n    if element_view is None:\n        mixins = (_DirectArrayViewMixin,)\n        attributes = _get_mixin_attributes(mixins)\n    elif isinstance(element_type, _ATOMIC):\n        mixins = (_IndirectAtomicArrayViewMixin,)\n        attributes = _get_mixin_attributes(mixins)\n        attributes.update({\n            '_element_view': element_view,\n        })\n    else:\n        mixins = (_IndirectCompositeArrayViewMixin,)\n        attributes = _get_mixin_attributes(mixins)\n        attributes.update({\n            '_element_view': element_view,\n        })\n\n    name = data_type.name if data_type.name else 'ArrayView'\n    return type(name, (), attributes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _define_structure_view(data_type):\n    def define_getter(field_index, field_type, field_view):\n        if field_view is None:\n            def getter(self):\n                return self._data[field_index]\n        elif isinstance(field_type, _ATOMIC):\n            def getter(self):\n                return field_view(self._data, field_index)\n        else:\n            def getter(self):\n                return field_view(self._data[field_index])\n\n        return getter\n\n    def define_setter(field_index, read_only):\n        def setter(self, value):\n            self._data[field_index] = value\n\n        return None if read_only else setter\n\n    field_views = [_resolve_view(field.type) for field in data_type.fields]\n    mixins = (_StructuredViewMixin,)\n    attributes = _get_mixin_attributes(mixins)\n    attributes.update({\n        '_fields': tuple(field.name for field in data_type.fields),\n    })\n    attributes.update({\n        field.name: property(\n            fget=define_getter(i, field.type, field_view),\n            fset=define_setter(i, field.read_only),\n            fdel=None)\n        for i, (field, field_view)\n        in enumerate(zip(data_type.fields, field_views))})\n    name = data_type.name if data_type.name else 'StructureView'\n    return type(name, (), attributes)", "response": "Define a new view object for a Structure type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve the attributes of each mixin class in a set of mixins.", "response": "def _get_mixin_attributes(mixins):\n    \"\"\"Retrieve the attributes for a given set of mixin classes.\n\n    The attributes of each mixin class are being merged into a single\n    dictionary.\n    \"\"\"\n    return {attribute: mixin.__dict__[attribute]\n            for mixin in mixins\n            for attribute in _MIXIN_ATTRIBUTES[mixin]}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the NumPy s dtype for a given atomic data type.", "response": "def _get_atomic_dtype(data_type):\n    \"\"\"Retrieve the NumPy's `dtype` for a given atomic data type.\"\"\"\n    atomic_type = getattr(data_type, 'type', None)\n    if atomic_type is not None:\n        return atomic_type\n\n    return _PREDEFINED_ATOMIC_NUMPY_TYPES[_find_base_type(data_type)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _find_base_type(data_type):\n    bases = type(data_type).__mro__\n    for base in bases:\n        if base in _ALL:\n            return base\n\n    return None", "response": "Find the base type for a given data type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _find_duplicates(seq):\n    seen = set()\n    return [element for element in seq\n            if seq.count(element) > 1\n            and element not in seen and seen.add(element) is None]", "response": "Find the duplicate elements from a sequence."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _format_type(cls):\n    if cls.__module__ == _BUILTIN_MODULE:\n        return cls.__name__\n    else:\n        return '%s.%s' % (cls.__module__, cls.__name__)", "response": "Format a type name for printing."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _format_element(element, count, index, last_separator):\n    return (\"%s'%s'\" % (last_separator, element)\n            if count > 1 and index == count - 1\n            else \"'%s'\" % (element,))", "response": "Format an element from a sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\njoining a sequence into a string.", "response": "def _join_sequence(seq, last_separator=''):\n    \"\"\"Join a sequence into a string.\"\"\"\n    count = len(seq)\n    return ', '.join(_format_element(element, count, i, last_separator)\n                     for i, element in enumerate(seq))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _join_types(seq, last_separator=''):\n    class_names = [_format_type(cls) for cls in seq]\n    return _join_sequence(class_names, last_separator)", "response": "Join class object names into a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef timedelta_to_seconds(value, with_microseconds=False):\n    if value is None:\n        return None\n\n    if not isinstance(value, timedelta):\n        raise TypeError('value must be a datetime.timedelta object')\n\n    microseconds = value.microseconds / MICROSECONDS_IN_SECOND \\\n        if with_microseconds else 0\n\n    return value.days * SECONDS_IN_DAY + value.seconds + microseconds", "response": "Convert a datetime. timedelta object to seconds"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef timedelta_to_str(value, with_microseconds=False):\n    if value is None:\n        return None\n\n    if not isinstance(value, timedelta):\n        raise TypeError('value must be a datetime.timedelta object')\n\n    hours, remainder = divmod(value.seconds, SECONDS_IN_HOUR)\n    hours += value.days * HOURS_IN_DAY\n    minutes, seconds = divmod(remainder, SECONDS_IN_MINUTE)\n\n    if with_microseconds:\n        return '%02d:%02d:%02d.%06d' % (hours, minutes, seconds,\n                                        value.microseconds)\n    else:\n        return '%02d:%02d:%02d' % (hours, minutes, seconds)", "response": "Converts a datetime. timedelta object to a string representation of the ISO - 8601 date and time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a string and returns a datetime. timedelta object", "response": "def parse_timedelta(value):\n    \"\"\"\n    Parses a string and return a datetime.timedelta.\n    :param value: string to parse\n    :type value: str\n    :return: timedelta object or None if value is None\n    :rtype: timedelta/None\n    :raise: TypeError when value is not string\n    :raise: ValueError when value is not proper timedelta string\n    \"\"\"\n    if value is None:\n        return None\n\n    if not isinstance(value, six.string_types):\n        raise TypeError('value must be a string type')\n\n    match = INTERVAL_REGEX.search(value)\n\n    if match:\n        data = match.groupdict()\n        return timedelta(**dict((key, int(data[key] or 0)) for key in data))\n    else:\n        raise ValueError(\"Value '%s' doesn't appear to be a valid timedelta \"\n                         \"string\" % value)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npreparing the roomMap to be JSONified.", "response": "def prepare_roomMap(roomMap):\n    \"\"\" Prepares the roomMap to be JSONified. That is: convert the non\n        JSON serializable objects such as set() \"\"\"\n    ret = {}\n    for room in roomMap:\n        ret[room] = [roomMap[room].name, list(roomMap[room].pcs)]\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprepares the schedule to be JSONified.", "response": "def prepare_schedule(schedule):\n    \"\"\" Prepares the schedule to be JSONified. That is: convert the non\n        JSON serializable objects such as the datetime.time's \"\"\"\n    ret = {}\n    for room in schedule:\n        ret[room] = []\n        for event in schedule[room]:\n            ret[room].append(((event[0].hour,\n                                event[0].minute),\n                             (event[1].hour,\n                              event[1].minute),\n                             event[2]))\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nslices a numpy array to make columns", "response": "def slice_columns(x, using=None):\n    \"\"\"\n    Slice a numpy array to make columns\n\n    Parameters\n    ----------\n    x : ndarray\n        A numpy array instance\n    using : list of integer or slice instance or None, optional\n        A list of index or slice instance\n\n    Returns\n    -------\n    ndarray\n        A list of numpy array columns sliced\n\n    \"\"\"\n    if using is None:\n        using = range(0, len(x[0]))\n    return [x[:,s] for s in using]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unite_dataset(dataset, basecolumn=0):\n    ndata = [None] * len(dataset[0])\n    for pdata in dataset:\n        # select basecolumn\n        bnx = ndata[basecolumn]\n        bpx = pdata[basecolumn]\n        if bnx is not None and bnx.ndim >= 2:\n            bnx = bnx[:,-1]\n        if bpx is not None and bpx.ndim >= 2:\n            bpx = bpx[:,-1]\n        # calculate min and max of this and final data\n        if bnx is not None and len(bnx) != len(bpx):\n            # the number of samples is different, so regulation is required\n            xmin = max(np.min(bnx), np.min(bpx))\n            xmax = min(np.max(bnx), np.max(bpx))\n            # slice the data\n            nindex = np.where((bnx>xmin) & (bnx<xmax))\n            pindex = np.where((bpx>xmin) & (bpx<xmax))\n        else:\n            nindex = None\n            pindex = None\n        for i, (nx, px) in enumerate(itertools.izip(ndata, pdata)):\n            if nindex:\n                nx = nx[nindex]\n            if pindex:\n                px = px[pindex]\n            ndata[i] = px if nx is None else np.c_[nx, px]\n    return [ndata]", "response": "Unite a dataset into a single data list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload data from file using a specified parser.", "response": "def load(self, filename, using=None, parser=None, **kwargs):\n        \"\"\"\n        Load data from file using a specified parser.\n\n        Return value will be separated or sliced into a column list\n\n        Parameters\n        ----------\n        filename : string\n            A data file path\n        using : list of integer, slice instance, or None, optional\n            A list of index or slice instance used to slice data into column\n            If it is not specified, :attr:`using` specified in constructor\n            will be used instead.\n        parser : instance or None, optional\n            An instance or registered name of parser class.\n            If it is not specified, :attr:`parser` specified in constructor\n            will be used instead.\n\n        Returns\n        -------\n        ndarray\n            A list of numpy array\n\n        \"\"\"\n        using = using or self.using\n        parser = parser or self.parser\n        if parser is None:\n            raise AttributeError(\"A parser instance must be specified\")\n        # parse iterator with the specified parser\n        data = parser.load(filename, **kwargs)\n        # slice column by using\n        return slice_columns(data, using)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef glob(self, pathname, using=None,\n             unite=False, basecolumn=0, parser=None,\n             with_filename=False,\n             recursive=False, natsort=True, **kwargs):\n        \"\"\"\n        Load data from file matched with given glob pattern.\n\n        Return value will be a list of data unless :attr:`unite` is `True`.\n        If :attr:`unite` is `True`, all dataset will be united into a single\n        data.\n\n        Parameters\n        ----------\n        pathname : string\n            A glob pattern\n        using : list of integer, slice instance, or None, optional\n            A list of index or slice instance used to slice data into column\n            If it is not specified, :attr:`using` specified in constructor\n            will be used instead.\n        unite : boolean, optional:\n            If it is `True` then dataset will be united into a single numpy\n            array. See usage for more detail.\n        basecolumn : integer, optional\n            An index of base column. all data will be trimmed based on the order\n            of this column when the number of samples are different among the\n            dataset.\n            It only affect when :attr:`unite` is specified as `True`.\n        parser : instance, optional\n            An instance or registered name of parser class.\n            If it is not specified, :attr:`parser` specified in constructor\n            will be used instead.\n        with_filename : boolean, optional\n            If it is `True`, returning dataset will contain filename in the\n            first column.\n            It is cannot be used with :attr:`unite = True`\n        recursive : boolean, optional\n            Recursively find pattern in the directory\n        natsort : boolean\n            Naturally sort found files.\n\n        Returns\n        -------\n        ndarray\n            A list of numpy array\n        \"\"\"\n        # argument check\n        if unite and with_filename:\n            raise AttributeError(\n                    \"`with_filename` attribute cannot be set True when \"\n                    \"`unite` attribute was set True.\")\n        # make sure that the pathname is absolute\n        pathname = os.path.abspath(pathname)\n        if recursive:\n            filelist = rglob(pathname)\n        else:\n            filelist = glob(pathname)\n        if natsort:\n            filelist = natsorted(filelist, number_type=None)\n        # create dataset\n        dataset =[]\n        for filename in filelist:\n            data = self.load(\n                filename=filename,\n                using=using,\n                parser=parser,\n                **kwargs)\n            if with_filename:\n                data = [filename] + data\n            dataset.append(data)\n        # tell the number of files found if verbose is True\n        if kwargs.get('verbose', False):\n            print \"%d files are found with `%s`\" % (\n                    len(dataset),\n                    os.path.relpath(pathname))\n        # warn if nothing have found unless quiet is True\n        if len(dataset) == 0 and not kwargs.get('quiet', False):\n            warnings.warn(\"Nothing found with glob pattern '%s'\" % pathname)\n        # unite dataset if specified\n        if unite and len(dataset) > 0:\n            dataset = unite_dataset(dataset, basecolumn)\n        return dataset", "response": "This function will load data from file matched with given glob pattern."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_by_ast(line, version_token=\"__version__\"):  # type: (str,str) -> Optional[str]\n    if not line:\n        return \"\"\n    # clean up line.\n    simplified_line = simplify_line(line)\n\n    if simplified_line.startswith(version_token):\n        try:\n            tree = ast.parse(simplified_line)  # type: Any\n            if hasattr(tree.body[0].value, \"s\"):\n                return unicode(tree.body[0].value.s)\n            if hasattr(tree.body[0].value, \"elts\"):\n                version_parts = []\n                for elt in tree.body[0].value.elts:\n                    if hasattr(elt, \"n\"):\n                        version_parts.append(unicode(elt.n))\n                    else:\n                        version_parts.append(unicode(elt.s))\n                return \".\".join(version_parts)\n            if hasattr(tree.body[0].value, \"n\"):\n                return unicode(tree.body[0].value.n)\n            # print(tree)\n        except Exception:\n            # raise\n            return None\n\n    return None", "response": "Find a value from an ast line."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsimplifies a single line into a single string.", "response": "def simplify_line(line, keep_comma=False):  # type: (str, bool)->str\n    \"\"\"\n    Change ' to \"\n    Remove tabs and spaces (assume no significant whitespace inside a version string!)\n    \"\"\"\n    if not line:\n        return \"\"\n    if \"#\" in line:\n        parts = line.split(\"#\")\n        simplified_line = parts[0]\n    else:\n        simplified_line = line\n\n    simplified_line = (\n        simplified_line.replace(\" \", \"\")\n        .replace(\"'\", '\"')\n        .replace(\"\\t\", \"\")\n        .replace(\"\\n\", \"\")\n        .replace(\"'''\", '\"')  # version strings shouldn't be split across lines normally\n        .replace('\"\"\"', '\"')\n    )\n    if not keep_comma:\n        simplified_line = simplified_line.strip(\" ,\")\n    return simplified_line"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the version of the file_source that matches version_token.", "response": "def find_version_by_regex(\n    file_source, version_token=\"__version__\"\n):  # type: (str,str)->Optional[str]\n    \"\"\"\n    Regex for dunder version\n    \"\"\"\n    if not file_source:\n        return None\n    version_match = re.search(\n        r\"^\" + version_token + r\" = ['\\\"]([^'\\\"]*)['\\\"]\", file_source, re.M\n    )\n    if version_match:\n        candidate = version_match.group(1)\n        if candidate == \"\" or candidate == \".\":  # yes, it will match to a .\n            return None\n        return candidate\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the version of a node by string lib.", "response": "def find_version_by_string_lib(\n    line, version_token=\"__version__\"\n):  # type: (str,str)->Optional[str]\n    \"\"\"\n    No regex parsing. Or at least, mostly, not regex.\n    \"\"\"\n    if not line:\n        return None\n    simplified_line = simplify_line(line)\n    version = None\n    if simplified_line.strip().startswith(version_token):\n        if '\"' not in simplified_line:\n            pass\n            # logger.debug(\"Weird version string, no double quote : \" + unicode((full_path, line, simplified_line)))\n        else:\n            if \"=\" in simplified_line:\n                post_equals = simplified_line.split(\"=\")[1]\n\n                if post_equals.startswith('\"'):\n                    parts = post_equals.split('\"')\n                    version = parts[0]\n                if not version:\n                    version = None\n    return version"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the first version of a node in a line.", "response": "def find_in_line(line):  # type: (str)->Tuple[Optional[str],Optional[str]]\n    \"\"\"\n    Use three strategies to parse version string\n    :param line:\n    :return:\n    \"\"\"\n    if not line:\n        return None, None\n    for version_token in version_tokens:\n\n        by_ast = find_by_ast(line, version_token)\n        by_ast = validate_string(by_ast)\n        if by_ast:\n            return by_ast, version_token\n\n        by_string_lib = find_version_by_string_lib(line, version_token)\n        by_string_lib = validate_string(by_string_lib)\n        if by_string_lib:\n            return by_string_lib, version_token\n\n        by_regex = find_version_by_regex(line, version_token)\n        by_regex = validate_string(by_regex)\n        if by_regex:\n            return by_regex, version_token\n    return None, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prepare_filenames(self, normalized_url, request):\n        filenames = [normalized_url]\n        if request.user.is_authenticated():\n            filenames.insert(0, normalized_url + \".authenticated\")\n        else:\n            filenames.insert(0, normalized_url + \".anonymous\")\n        return filenames", "response": "Prepares the list of template filenames based on the user s authenticated state."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches this student s courses page and store it in self. courses", "response": "def fetch(self):\n        \"\"\"\n        Fetch this student's courses page. It's recommended to do that when\n        creating the object (this is the default) because the remote sessions\n        are short.\n        \"\"\"\n        soup = self.session.get_results_soup()\n        self.courses = CoursesList(soup)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the WSA action fault attribute.", "response": "def GetWSAActionFault(operation, name):\n    \"\"\"Find wsa:Action attribute, and return value or WSA.FAULT\n       for the default.\n    \"\"\"\n    attr = operation.faults[name].action\n    if attr is not None:\n        return attr\n    return WSA.FAULT"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding wsa : Action attribute and return value or the default.", "response": "def GetWSAActionInput(operation):\n    \"\"\"Find wsa:Action attribute, and return value or the default.\"\"\"\n    attr = operation.input.action\n    if attr is not None:\n        return attr\n    portType = operation.getPortType()\n    targetNamespace = portType.getTargetNamespace()\n    ptName = portType.name\n    msgName = operation.input.name\n    if not msgName:\n        msgName = operation.name + 'Request'\n    if targetNamespace.endswith('/'):\n        return '%s%s/%s' %(targetNamespace, ptName, msgName)\n    return '%s/%s/%s' %(targetNamespace, ptName, msgName)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetWSAActionOutput(operation):\n    attr = operation.output.action\n    if attr is not None:\n        return attr\n    targetNamespace = operation.getPortType().getTargetNamespace()\n    ptName = operation.getPortType().name\n    msgName = operation.output.name\n    if not msgName:\n        msgName = operation.name + 'Response'\n    if targetNamespace.endswith('/'):\n        return '%s%s/%s' %(targetNamespace, ptName, msgName)\n    return '%s/%s/%s' %(targetNamespace, ptName, msgName)", "response": "Find wsa : Action attribute and return value or the default."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef callInfoFromWSDL(port, name):\n    wsdl = port.getService().getWSDL()\n    binding = port.getBinding()\n    portType = binding.getPortType()\n    operation = portType.operations[name]\n    opbinding = binding.operations[name]\n    messages = wsdl.messages\n    callinfo = SOAPCallInfo(name)\n\n    addrbinding = port.getAddressBinding()\n    if not isinstance(addrbinding, SoapAddressBinding):\n        raise ValueError, 'Unsupported binding type.'        \n    callinfo.location = addrbinding.location\n\n    soapbinding = binding.findBinding(SoapBinding)\n    if soapbinding is None:\n        raise ValueError, 'Missing soap:binding element.'\n    callinfo.transport = soapbinding.transport\n    callinfo.style = soapbinding.style or 'document'\n\n    soap_op_binding = opbinding.findBinding(SoapOperationBinding)\n    if soap_op_binding is not None:\n        callinfo.soapAction = soap_op_binding.soapAction\n        callinfo.style = soap_op_binding.style or callinfo.style\n\n    parameterOrder = operation.parameterOrder\n\n    if operation.input is not None:\n        message = messages[operation.input.message]\n        msgrole = opbinding.input\n\n        mime = msgrole.findBinding(MimeMultipartRelatedBinding)\n        if mime is not None:\n            raise ValueError, 'Mime bindings are not supported.'\n        else:\n            for item in msgrole.findBindings(SoapHeaderBinding):\n                part = messages[item.message].parts[item.part]\n                header = callinfo.addInHeaderInfo(\n                    part.name,\n                    part.element or part.type,\n                    item.namespace,\n                    element_type = part.element and 1 or 0\n                    )\n                header.encodingStyle = item.encodingStyle\n\n            body = msgrole.findBinding(SoapBodyBinding)\n            if body is None:\n                raise ValueError, 'Missing soap:body binding.'\n            callinfo.encodingStyle = body.encodingStyle\n            callinfo.namespace = body.namespace\n            callinfo.use = body.use\n\n            if body.parts is not None:\n                parts = []\n                for name in body.parts:\n                    parts.append(message.parts[name])\n            else:\n                parts = message.parts.values()\n\n            for part in parts:\n                callinfo.addInParameter(\n                    part.name,\n                    part.element or part.type,\n                    element_type = part.element and 1 or 0\n                    )\n\n    if operation.output is not None:\n        try:\n            message = messages[operation.output.message]\n        except KeyError:\n            if self.strict:\n                raise RuntimeError(\n                    \"Recieved message not defined in the WSDL schema: %s\" %\n                    operation.output.message)\n            else:\n                message = wsdl.addMessage(operation.output.message)\n                print \"Warning:\", \\\n                      \"Recieved message not defined in the WSDL schema.\", \\\n                      \"Adding it.\"\n                print \"Message:\", operation.output.message\n         \n        msgrole = opbinding.output\n\n        mime = msgrole.findBinding(MimeMultipartRelatedBinding)\n        if mime is not None:\n            raise ValueError, 'Mime bindings are not supported.'\n        else:\n            for item in msgrole.findBindings(SoapHeaderBinding):\n                part = messages[item.message].parts[item.part]\n                header = callinfo.addOutHeaderInfo(\n                    part.name,\n                    part.element or part.type,\n                    item.namespace,\n                    element_type = part.element and 1 or 0\n                    )\n                header.encodingStyle = item.encodingStyle\n\n            body = msgrole.findBinding(SoapBodyBinding)\n            if body is None:\n                raise ValueError, 'Missing soap:body binding.'\n            callinfo.encodingStyle = body.encodingStyle\n            callinfo.namespace = body.namespace\n            callinfo.use = body.use\n\n            if body.parts is not None:\n                parts = []\n                for name in body.parts:\n                    parts.append(message.parts[name])\n            else:\n                parts = message.parts.values()\n\n            if parts:\n                for part in parts:\n                    callinfo.addOutParameter(\n                        part.name,\n                        part.element or part.type,\n                        element_type = part.element and 1 or 0\n                        )\n\n    return callinfo", "response": "Return a SOAPCallInfo given a WSDL port and operation name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a WSDL instance loaded from a stream object.", "response": "def loadFromStream(self, stream, name=None):\n        \"\"\"Return a WSDL instance loaded from a stream object.\"\"\"\n        document = DOM.loadDocument(stream)\n        wsdl = WSDL()\n        if name:\n            wsdl.location = name\n        elif hasattr(stream, 'name'):\n            wsdl.location = stream.name\n        wsdl.load(document)\n        return wsdl"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a WSDL instance loaded from the given url.", "response": "def loadFromURL(self, url):\n        \"\"\"Return a WSDL instance loaded from the given url.\"\"\"\n        document = DOM.loadFromURL(url)\n        wsdl = WSDL()\n        wsdl.location = url\n        wsdl.load(document)\n        return wsdl"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef loadFromFile(self, filename):\n        file = open(filename, 'rb')\n        try:\n            wsdl = self.loadFromStream(file)\n        finally:\n            file.close()\n        return wsdl", "response": "Return a WSDL instance loaded from the given file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef toDom(self):\n        namespaceURI = DOM.GetWSDLUri(self.version)\n        self.document = DOM.createDocument(namespaceURI ,'wsdl:definitions')\n\n        # Set up a couple prefixes for easy reading.\n        child = DOM.getElement(self.document, None)\n        child.setAttributeNS(None, 'targetNamespace', self.targetNamespace)\n        child.setAttributeNS(XMLNS.BASE, 'xmlns:wsdl', namespaceURI)\n        child.setAttributeNS(XMLNS.BASE, 'xmlns:xsd', 'http://www.w3.org/1999/XMLSchema')\n        child.setAttributeNS(XMLNS.BASE, 'xmlns:soap', 'http://schemas.xmlsoap.org/wsdl/soap/')\n        child.setAttributeNS(XMLNS.BASE, 'xmlns:tns', self.targetNamespace)\n        \n        if self.name:\n            child.setAttributeNS(None, 'name', self.name)\n\n        # wsdl:import\n        for item in self.imports: \n            item.toDom()\n        # wsdl:message\n        for item in self.messages:\n            item.toDom()\n        # wsdl:portType\n        for item in self.portTypes:\n            item.toDom()\n        # wsdl:binding\n        for item in self.bindings:\n            item.toDom()\n        # wsdl:service\n        for item in self.services:\n            item.toDom()", "response": "Generate a DOM representation of the WSDL message parts \n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getWSDL(self):\n        parent = self\n        while 1:\n            # skip any collections\n            if isinstance(parent, WSDL):\n                return parent\n            try: parent = parent.parent()\n            except: break\n            \n        return None", "response": "Return the WSDL object that contains this information item."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a DOM representation of the object.", "response": "def toDom(self, node):\n        \"\"\"node -- node representing message\"\"\"\n        wsdl = self.getWSDL()\n        ep = ElementProxy(None, node)\n        epc = ep.createAppendElement(DOM.GetWSDLUri(wsdl.version), 'part')\n        epc.setAttributeNS(None, 'name', self.name)\n\n        if self.element is not None:\n            ns,name = self.element\n            prefix = epc.getPrefix(ns)\n            epc.setAttributeNS(None, 'element', '%s:%s'%(prefix,name))\n        elif self.type is not None:\n            ns,name = self.type\n            prefix = epc.getPrefix(ns)\n            epc.setAttributeNS(None, 'type', '%s:%s'%(prefix,name))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the Binding object that is referenced by this port.", "response": "def getBinding(self):\n        \"\"\"Return the Binding object that is referenced by this port.\"\"\"\n        wsdl = self.getService().getWSDL()\n        return wsdl.bindings[self.binding]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getPortType(self):\n        wsdl = self.getService().getWSDL()\n        binding = wsdl.bindings[self.binding]\n        return wsdl.portTypes[binding.type]", "response": "Return the PortType object that is referenced by this port."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addInParameter(self, name, type, namespace=None, element_type=0):\n        parameter = ParameterInfo(name, type, namespace, element_type)\n        self.inparams.append(parameter)\n        return parameter", "response": "Add an input parameter description to the call info."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addOutParameter(self, name, type, namespace=None, element_type=0):\n        parameter = ParameterInfo(name, type, namespace, element_type)\n        self.outparams.append(parameter)\n        return parameter", "response": "Add an output parameter description to the call info."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setReturnParameter(self, name, type, namespace=None, element_type=0):\n        parameter = ParameterInfo(name, type, namespace, element_type)\n        self.retval = parameter\n        return parameter", "response": "Set the return parameter description for the call info."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds an input SOAP header description to the call info.", "response": "def addInHeaderInfo(self, name, type, namespace, element_type=0,\n                        mustUnderstand=0):\n        \"\"\"Add an input SOAP header description to the call info.\"\"\"\n        headerinfo = HeaderInfo(name, type, namespace, element_type)\n        if mustUnderstand:\n            headerinfo.mustUnderstand = 1\n        self.inheaders.append(headerinfo)\n        return headerinfo"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds an output SOAP header description to the call info.", "response": "def addOutHeaderInfo(self, name, type, namespace, element_type=0,\n                         mustUnderstand=0):\n        \"\"\"Add an output SOAP header description to the call info.\"\"\"\n        headerinfo = HeaderInfo(name, type, namespace, element_type)\n        if mustUnderstand:\n            headerinfo.mustUnderstand = 1\n        self.outheaders.append(headerinfo)\n        return headerinfo"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef assert_bool(dist, attr, value):\n    if bool(value) != value:\n        raise DistutilsSetupError(\n            \"%r must be a boolean value (got %r)\" % (attr,value)\n        )", "response": "Verify that value is a boolean value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_requirements(dist, attr, value):\n    try:\n        list(pkg_resources.parse_requirements(value))\n    except (TypeError,ValueError):\n        raise DistutilsSetupError(\n            \"%r must be a string or list of strings \"\n            \"containing valid project/version requirement specifiers\" % (attr,)\n        )", "response": "Verify that install_requires is a valid requirements list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a context manager that writes records in the cleaned table.", "response": "def store(self):\n        \"\"\" Create a context manager to store records in the cleaned\n        table. \"\"\"\n        output = tempfile.NamedTemporaryFile(suffix='.json')\n        try:\n\n            def write(o):\n                line = json.dumps(o, default=json_default)\n                return output.write(line + '\\n')\n\n            yield write\n\n            output.seek(0)\n            log.info(\"Uploading generated table (%s)...\", self._obj)\n            self.save_file(output.name, destructive=True)\n        finally:\n            try:\n                output.close()\n            except:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef records(self):\n        output = tempfile.NamedTemporaryFile(suffix='.json')\n        try:\n            log.info(\"Loading table from (%s)...\", self._obj)\n            shutil.copyfileobj(self.fh(), output)\n            output.seek(0)\n\n            for line in output.file:\n                yield json.loads(line, object_hook=json_hook)\n\n        finally:\n            try:\n                output.close()\n            except:\n                pass", "response": "Get each record that has been stored in the table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete all NestedOrderedDict that haven t any entries.", "response": "def _cleanRecursive(self, subSelf):\n        \"\"\"\n        Delete all NestedOrderedDict that haven't any entries.\n        \"\"\"\n        for key, item in list(subSelf.items()):\n            if self.isNestedDict(item):\n                if not item:\n                    subSelf.pop(key)\n                else:\n                    self._cleanRecursive(item)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True is an object belongs to a module.", "response": "def belongsToModule(obj, module):\n        \"\"\"Returns True is an object belongs to a module.\"\"\"\n        return obj.__module__ == module.__name__ or obj.__module__.startswith(\n            module.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef buildHirarchy(self, horizontal_operation=None,\n                      vertical_operation=None):\n        \"\"\"Walk through the nested dict structure and executes\n        horizontal_operation(name, callable) resp.\n        vertical_operation(name, callable) if defined.\n        \"\"\"\n        def buildRecursive(pkey, pval):\n            if self.isNestedDict(pval):\n                if vertical_operation:\n                    vertical_operation(pkey, pval)\n                for key, val in list(pval.items()):\n                    # if not isinstance(val, NestedOrderedDict):\n                    buildRecursive(key, val)\n            else:\n                if horizontal_operation:\n                    horizontal_operation(pkey, pval)\n        buildRecursive(self._package.__name__, self)", "response": "Walk through the nested dict structure and executes the horizontal_operation and vertical_operation functions."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses the request after routing.", "response": "def process_resource(self, req, resp, resource):\n        \"\"\" Process the request after routing.\n\n        Deserializer selection needs a resource to determine which\n        deserializers are allowed. If a deserializer is required then\n        it will be initialized & added to the request object for\n        further processing.\n        \"\"\"\n\n        if req.content_required and resource:\n            allowed = resource.deserializer_mimetypes\n\n            if req.content_length in (None, 0):\n                abort(EmptyRequestBody)\n            elif req.content_type not in allowed:\n                abort(ContentTypeUnsupported(allowed))\n            else:\n                deserializer = self._get_deserializer(req.content_type)\n                req.deserializer = deserializer(req, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate the DynamoDB table used by this ObjectStore only if it does not already exist.", "response": "def create_table(self):\n        \"\"\"Create the DynamoDB table used by this ObjectStore, only if it does\n        not already exists.\n        \"\"\"\n\n        all_tables = self.aws_conn.list_tables()['TableNames']\n\n        if self.table_name in all_tables:\n            log.info(\"Table %s already exists\" % self.table_name)\n        else:\n            log.info(\"Table %s does not exist: creating it\" % self.table_name)\n\n            self.table = Table.create(\n                self.table_name,\n                schema=[\n                    HashKey('key')\n                ],\n                throughput={\n                    'read': 10,\n                    'write': 10,\n                },\n                connection=self.aws_conn,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstores the object given as value into the DynamoDB table under key key.", "response": "def put(self, key, value, overwrite=True):\n        \"\"\"Marshall the python object given as 'value' into a string, using the\n        to_string marshalling method passed in the constructor, and store it in\n        the DynamoDB table under key 'key'.\n        \"\"\"\n        self._get_table()\n        s = self.to_string(value)\n        log.debug(\"Storing in key '%s' the object: '%s'\" % (key, s))\n        self.table.put_item(\n            data={\n                'key': key,\n                'value': s,\n            },\n            overwrite=overwrite\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the string representation of the object stored under this key.", "response": "def get(self, key):\n        \"\"\"Get the string representation of the object stored in DynamoDB under this key,\n        convert it back to an object using the 'from_string' unmarshalling method passed\n        in the constructor and return the object. Return None if no object found.\n        \"\"\"\n        self._get_table()\n        s = self.table.get_item(key=key)\n        log.debug(\"Retrieved from key '%s' the object: '%s'\" % (key, s['value']))\n        return self.from_string(s['value'])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(self, key):\n        self._get_table()\n        self.table.delete_item(key=key)\n        log.debug(\"Deleted item at key '%s'\" % (key))", "response": "Delete an item from the cache"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning env var coerced into a type other than string. This function extends the standard os.getenv function to enable the coercion of values into data types other than string (all env vars are strings by default). Args: key: string, the name of the env var to look up Kwargs: default: the default value to return if the env var does not exist. NB the default value is **not** coerced, and is assumed to be of the correct type. coerce: a function that is used to coerce the value returned into another type required: bool, if True, then a RequiredSettingMissing error is raised if the env var does not exist. Returns the env var, passed through the coerce function", "response": "def _get_env(key, default=None, coerce=lambda x: x, required=False):\n    \"\"\"\n    Return env var coerced into a type other than string.\n\n    This function extends the standard os.getenv function to enable\n    the coercion of values into data types other than string (all env\n    vars are strings by default).\n\n    Args:\n        key: string, the name of the env var to look up\n\n    Kwargs:\n        default: the default value to return if the env var does not exist. NB the\n            default value is **not** coerced, and is assumed to be of the correct type.\n        coerce: a function that is used to coerce the value returned into\n            another type\n        required: bool, if True, then a RequiredSettingMissing error is raised\n            if the env var does not exist.\n\n    Returns the env var, passed through the coerce function\n\n    \"\"\"\n    try:\n        value = os.environ[key]\n    except KeyError:\n        if required is True:\n            raise RequiredSettingMissing(key)\n        else:\n            return default\n\n    try:\n        return coerce(value)\n    except Exception:\n        raise CoercianError(key, value, coerce)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_env(key, *default, **kwargs):\n    assert len(default) in (0, 1), \"Too many args supplied.\"\n    func = kwargs.get('coerce', lambda x: x)\n    required = (len(default) == 0)\n    default = default[0] if not required else None\n    return _get_env(key, default=default, coerce=func, required=required)", "response": "Get the environment variable value for the given key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_list(key, *default, **kwargs):\n    separator = kwargs.get('separator', ' ')\n    return get_env(key, *default, coerce=lambda x: x.split(separator))", "response": "Return env var as a list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a FeatureCollection given an HBase artifact row.", "response": "def row_to_content_obj(key_row):\n    '''Returns ``FeatureCollection`` given an HBase artifact row.\n\n    Note that the FC returned has a Unicode feature ``artifact_id``\n    set to the row's key.\n    '''\n    key, row = key_row\n    cid = mk_content_id(key.encode('utf-8'))\n    response = row.get('response', {})\n\n    other_bows = defaultdict(StringCounter)\n    for attr, val in row.get('indices', []):\n        other_bows[attr][val] += 1\n    try:\n        artifact_id = key\n        if isinstance(artifact_id, str):\n            artifact_id = unicode(artifact_id, 'utf-8')\n        fc = html_to_fc(\n            response.get('body', ''),\n            url=row.get('url'), timestamp=row.get('timestamp'),\n            other_features=dict(other_bows, **{'artifact_id': artifact_id}))\n    except:\n        fc = None\n        print('Could not create FC for %s:' % cid, file=sys.stderr)\n        print(traceback.format_exc(), file=sys.stderr)\n    return cid, fc"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a dictionary to a time tuple.", "response": "def _dict_to_tuple(d):\n    '''Convert a dictionary to a time tuple.  Depends on key values in the\n    regexp pattern!\n    '''    \n    # TODO: Adding a ms field to struct_time tuples is problematic \n    # since they don't have this field.  Should use datetime\n    # which has a microseconds field, else no ms..  When mapping struct_time \n    # to gDateTime the last 3 fields are irrelevant, here using dummy values to make\n    # everything happy.\n    # \n\n    retval = _niltime[:]\n    for k,i in ( ('Y', 0), ('M', 1), ('D', 2), ('h', 3), ('m', 4), ):\n        v = d.get(k)\n        if v: retval[i] = int(v)\n        \n    v = d.get('s')\n    if v:\n        msec,sec = _modf(float(v))\n        retval[6],retval[5] = int(round(msec*1000)), int(sec)\n            \n    v = d.get('tz')\n    if v and v != 'Z':\n        h,m = map(int, v.split(':'))\n        # check for time zone offset, if within the same timezone, \n        # ignore offset specific calculations\n        offset=_localtimezone().utcoffset(_datetime.now())\n        local_offset_hour = offset.seconds/3600\n        local_offset_min = (offset.seconds%3600)%60\n        if local_offset_hour > 12: \n            local_offset_hour -= 24\n            \n        if local_offset_hour != h or local_offset_min != m:                \n            if h<0:\n                #TODO: why is this set to server\n                #foff = _fixedoffset(-((abs(h)*60+m)),\"server\")\n                foff = _fixedoffset(-((abs(h)*60+m)))\n            else:\n                #TODO: why is this set to server\n                #foff = _fixedoffset((abs(h)*60+m),\"server\")\n                foff = _fixedoffset((abs(h)*60+m)) \n                \n            dt = _datetime(retval[0],retval[1],retval[2],retval[3],retval[4],\n                           retval[5],0,foff)\n            \n            # update dict with calculated timezone\n            localdt=dt.astimezone(_localtimezone())\n            retval[0] = localdt.year\n            retval[1] = localdt.month\n            retval[2] = localdt.day\n            retval[3] = localdt.hour\n            retval[4] = localdt.minute\n            retval[5] = localdt.second\n            \n    if d.get('neg', 0):\n        retval[0:5] = map(operator.__neg__, retval[0:5])\n    return tuple(retval)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dst(self, dt):\n        tt = _localtime(_mktime((dt.year, dt.month, dt.day,\n                 dt.hour, dt.minute, dt.second, dt.weekday(), 0, -1)))\n        if tt.tm_isdst > 0: return _dstdiff\n        return _zero", "response": "datetime - > DST offset in minutes east of UTC"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting text into typecode specific data.", "response": "def text_to_data(self, text, elt, ps):\n        '''convert text into typecode specific data.\n        '''\n        if text is None:\n            return None\n        m = Duration.lex_pattern.match(text)\n        if m is None:\n            raise EvaluateException('Illegal duration', ps.Backtrace(elt))\n        d = m.groupdict()\n        if d['T'] and (d['h'] is None and d['m'] is None and d['s'] is None):\n            raise EvaluateException('Duration has T without time')\n        try:\n            retval = _dict_to_tuple(d)\n        except ValueError, e:\n            raise EvaluateException(str(e))\n    \n        if self.pyclass is not None:\n            return self.pyclass(retval)\n        return retval"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts text into typecode specific data.", "response": "def text_to_data(self, text, elt, ps):\n        '''convert text into typecode specific data.\n        '''\n        if text is None:\n            return None\n        \n        m = self.lex_pattern.match(text)\n        if not m:\n            raise EvaluateException('Bad Gregorian: %s' %text, ps.Backtrace(elt))\n        try:\n            retval = _dict_to_tuple(m.groupdict())\n        except ValueError, e:\n            #raise EvaluateException(str(e))\n            raise\n        \n        if self.pyclass is not None:\n            return self.pyclass(retval)\n        return retval"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a callback function to a property in an object.", "response": "def add_callback(instance, prop, callback, echo_old=False, priority=0):\n    \"\"\"\n    Attach a callback function to a property in an instance\n\n    Parameters\n    ----------\n    instance\n        The instance to add the callback to\n    prop : str\n        Name of callback property in `instance`\n    callback : func\n        The callback function to add\n    echo_old : bool, optional\n        If `True`, the callback function will be invoked with both the old\n        and new values of the property, as ``func(old, new)``. If `False`\n        (the default), will be invoked as ``func(new)``\n    priority : int, optional\n        This can optionally be used to force a certain order of execution of\n        callbacks (larger values indicate a higher priority).\n\n    Examples\n    --------\n\n    ::\n\n        class Foo:\n            bar = CallbackProperty(0)\n\n        def callback(value):\n            pass\n\n        f = Foo()\n        add_callback(f, 'bar', callback)\n\n    \"\"\"\n    p = getattr(type(instance), prop)\n    if not isinstance(p, CallbackProperty):\n        raise TypeError(\"%s is not a CallbackProperty\" % prop)\n    p.add_callback(instance, callback, echo_old=echo_old, priority=priority)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves a callback function from a property in an instance", "response": "def remove_callback(instance, prop, callback):\n    \"\"\"\n    Remove a callback function from a property in an instance\n\n    Parameters\n    ----------\n    instance\n        The instance to detach the callback from\n    prop : str\n        Name of callback property in `instance`\n    callback : func\n        The callback function to remove\n    \"\"\"\n    p = getattr(type(instance), prop)\n    if not isinstance(p, CallbackProperty):\n        raise TypeError(\"%s is not a CallbackProperty\" % prop)\n    p.remove_callback(instance, callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ignore_callback(instance, *props):\n    for prop in props:\n        p = getattr(type(instance), prop)\n        if not isinstance(p, CallbackProperty):\n            raise TypeError(\"%s is not a CallbackProperty\" % prop)\n        p.disable(instance)\n\n    if isinstance(instance, HasCallbackProperties):\n        instance._ignore_global_callbacks(props)\n\n    yield\n\n    for prop in props:\n        p = getattr(type(instance), prop)\n        assert isinstance(p, CallbackProperty)\n        p.enable(instance)\n\n    if isinstance(instance, HasCallbackProperties):\n        instance._unignore_global_callbacks(props)", "response": "This function is used to ignore any callbacks from one or more callback properties within an instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nnotifies all callbacks that the current value of the current value of the key is old and new.", "response": "def notify(self, instance, old, new):\n        \"\"\"\n        Call all callback functions with the current value\n\n        Each callback will either be called using\n        callback(new) or callback(old, new) depending\n        on whether ``echo_old`` was set to `True` when calling\n        :func:`~echo.add_callback`\n\n        Parameters\n        ----------\n        instance\n            The instance to consider\n        old\n            The old value of the property\n        new\n            The new value of the property\n        \"\"\"\n        if self._disabled.get(instance, False):\n            return\n        for cback in self._callbacks.get(instance, []):\n            cback(new)\n        for cback in self._2arg_callbacks.get(instance, []):\n            cback(old, new)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a callback function to a specific instance that manages this property.", "response": "def add_callback(self, instance, func, echo_old=False, priority=0):\n        \"\"\"\n        Add a callback to a specific instance that manages this property\n\n        Parameters\n        ----------\n        instance\n            The instance to add the callback to\n        func : func\n            The callback function to add\n        echo_old : bool, optional\n            If `True`, the callback function will be invoked with both the old\n            and new values of the property, as ``func(old, new)``. If `False`\n            (the default), will be invoked as ``func(new)``\n        priority : int, optional\n            This can optionally be used to force a certain order of execution of\n            callbacks (larger values indicate a higher priority).\n        \"\"\"\n\n        if echo_old:\n            self._2arg_callbacks.setdefault(instance, CallbackContainer()).append(func, priority=priority)\n        else:\n            self._callbacks.setdefault(instance, CallbackContainer()).append(func, priority=priority)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a previously added callback from an instance.", "response": "def remove_callback(self, instance, func):\n        \"\"\"\n        Remove a previously-added callback\n\n        Parameters\n        ----------\n        instance\n            The instance to detach the callback from\n        func : func\n            The callback function to remove\n        \"\"\"\n        for cb in [self._callbacks, self._2arg_callbacks]:\n            if instance not in cb:\n                continue\n            if func in cb[instance]:\n                cb[instance].remove(func)\n                return\n        else:\n            raise ValueError(\"Callback function not found: %s\" % func)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a callback that gets triggered when a callback property of the class changes.", "response": "def add_callback(self, name, callback, echo_old=False, priority=0):\n        \"\"\"\n        Add a callback that gets triggered when a callback property of the\n        class changes.\n\n        Parameters\n        ----------\n        name : str\n            The instance to add the callback to.\n        callback : func\n            The callback function to add\n        echo_old : bool, optional\n            If `True`, the callback function will be invoked with both the old\n            and new values of the property, as ``callback(old, new)``. If `False`\n            (the default), will be invoked as ``callback(new)``\n        priority : int, optional\n            This can optionally be used to force a certain order of execution of\n            callbacks (larger values indicate a higher priority).\n        \"\"\"\n        if self.is_callback_property(name):\n            prop = getattr(type(self), name)\n            prop.add_callback(self, callback, echo_old=echo_old, priority=priority)\n        else:\n            raise TypeError(\"attribute '{0}' is not a callback property\".format(name))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_callback(self, name, callback):\n\n        if self.is_callback_property(name):\n            prop = getattr(type(self), name)\n            try:\n                prop.remove_callback(self, callback)\n            except ValueError:  # pragma: nocover\n                pass  # Be forgiving if callback was already removed before\n        else:\n            raise TypeError(\"attribute '{0}' is not a callback property\".format(name))", "response": "Removes a previously added callback from the instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\niterating over all callback properties.", "response": "def iter_callback_properties(self):\n        \"\"\"\n        Iterator to loop over all callback properties.\n        \"\"\"\n        for name in dir(self):\n            if self.is_callback_property(name):\n                yield name, getattr(type(self), name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if there are presamples and return True if there are no presamples", "response": "def has_gis(wrapped, instance, args, kwargs):\n    \"\"\"Skip function execution if there are no presamples\"\"\"\n    if gis:\n        return wrapped(*args, **kwargs)\n    else:\n        warn(MISSING_GIS)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sha256(filepath, blocksize=65536):\n    hasher = hashlib.sha256()\n    fo = open(filepath, 'rb')\n    buf = fo.read(blocksize)\n    while len(buf) > 0:\n        hasher.update(buf)\n        buf = fo.read(blocksize)\n    return hasher.hexdigest()", "response": "Generate SHA 256 hash for file at filepath"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_data(self):\n        assert os.path.exists(self.data_fp)\n        if gis:\n            with fiona.drivers():\n                with fiona.open(self.faces_fp) as src:\n                    assert src.meta\n\n        gpkg_hash = json.load(open(self.data_fp))['metadata']['sha256']\n        assert gpkg_hash == sha256(self.faces_fp)", "response": "Check that the data file is present and that the faces file is readable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_definitions(self):\n        self.data = dict(json.load(open(self.data_fp))['data'])\n        self.all_faces = set(self.data.pop(\"__all__\"))\n        self.locations = set(self.data.keys())", "response": "Load mapping of country names to face ids"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef construct_rest_of_world(self, excluded, name=None, fp=None, geom=True):\n        for location in excluded:\n            assert location in self.locations, \"Can't find location {}\".format(location)\n        included = self.all_faces.difference(\n            set().union(*[set(self.data[loc]) for loc in excluded])\n        )\n\n        if not geom:\n            return included\n        elif not gis:\n            warn(MISSING_GIS)\n            return\n\n        geom = _union(included)[1]\n        if fp:\n            self.write_geoms_to_file(fp, [geom], [name] if name else None)\n            return fp\n        else:\n            return geom", "response": "Construct rest - of - world geometry and optionally write to filepath fp."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef construct_rest_of_worlds(self, excluded, fp=None, use_mp=True, simplify=True):\n        geoms = {}\n        raw_data = []\n        for key in sorted(excluded):\n            locations = excluded[key]\n            for location in locations:\n                assert location in self.locations, \"Can't find location {}\".format(location)\n            included = self.all_faces.difference(\n                {face for loc in locations for face in self.data[loc]}\n            )\n            raw_data.append((key, self.faces_fp, included))\n        if use_mp:\n            with Pool(cpu_count() - 1) as pool:\n                results = pool.map(_union, raw_data)\n            geoms = dict(results)\n        else:\n            geoms = dict([_union(row) for row in raw_data])\n        if simplify:\n            geoms = {k: v.simplify(0.05) for k, v in geoms.items()}\n        if fp:\n            labels = sorted(geoms)\n            self.write_geoms_to_file(fp, [geoms[key] for key in labels], labels)\n            return fp\n        else:\n            return geoms", "response": "Construct many rest - of - world geometries and optionally write to filepath fp."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef construct_rest_of_worlds_mapping(self, excluded, fp=None):\n        metadata = {\n            'filename': 'faces.gpkg',\n            'field': 'id',\n            'sha256': sha256(self.faces_fp)\n        }\n        data = []\n        for key, locations in excluded.items():\n            for location in locations:\n                assert location in self.locations, \"Can't find location {}\".format(location)\n            included = self.all_faces.difference(\n                {face for loc in locations for face in self.data[loc]}\n            )\n            data.append((key, sorted(included)))\n        obj = {'data': data, 'metadata': metadata}\n        if fp:\n            with open(fp, \"w\") as f:\n                json.dump(obj, f, indent=2)\n        else:\n            return obj", "response": "Construct topo mapping file for excluded."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef construct_difference(self, parent, excluded, name=None, fp=None):\n        assert parent in self.locations, \"Can't find location {}\".format(parent)\n        for location in excluded:\n            assert location in self.locations, \"Can't find location {}\".format(location)\n        included = set(self.data[parent]).difference(\n            reduce(set.union, [set(self.data[loc]) for loc in excluded])\n        )\n        geom = _union(included)\n        if fp:\n            self.write_geoms_to_file(fp, [geom], [name] if name else None)\n            return fp\n        else:\n            return geom", "response": "Construct geometry from parent without the regions in excluded and optionally write to filepath fp."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite unioned geometries to filepath fp. Optionally use names in name field.", "response": "def write_geoms_to_file(self, fp, geoms, names=None):\n        \"\"\"Write unioned geometries ``geoms`` to filepath ``fp``. Optionally use ``names`` in name field.\"\"\"\n        if fp[-5:] != '.gpkg':\n            fp = fp + '.gpkg'\n        if names is not None:\n            assert len(geoms) == len(names), \"Inconsistent length of geometries and names\"\n        else:\n            names = (\"Merged geometry {}\".format(count) for count in itertools.count())\n        meta = {\n            'crs': {'no_defs': True, 'ellps': 'WGS84', 'datum': 'WGS84', 'proj': 'longlat'},\n            'driver': 'GPKG',\n            'schema': {'geometry': 'MultiPolygon', 'properties': {'name': 'str', 'id': 'int'}}\n        }\n        with fiona.drivers():\n            with fiona.open(fp, 'w', **meta) as sink:\n                for geom, name, count in zip(geoms, names, itertools.count(1)):\n                    sink.write({\n                        'geometry': _to_fiona(geom),\n                        'properties': {'name': name, 'id': count}\n                    })\n        return fp"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving quotes from word.", "response": "def _remove_quotes(word):\n    \"\"\"\n    Remove quotes from `word` if the word starts and ands with quotes (\" or ').\n    \"\"\"\n    if not word or len(word) <= 2:\n        return word\n\n    if word[0] == word[-1] and word[0] in [\"'\", '\"']:\n        return word[1:-1]\n\n    return word"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles decoding of the CSV data.", "response": "def decode(data):\n    \"\"\"\n    Handles decoding of the CSV `data`.\n\n    Args:\n        data (str): Data which will be decoded.\n\n    Returns:\n        dict: Dictionary with decoded data.\n    \"\"\"\n    # try to guess dialect of the csv file\n    dialect = None\n    try:\n        dialect = csv.Sniffer().sniff(data)\n    except Exception:\n        pass\n\n    # parse data with csv parser\n    handler = None\n    try:\n        data = data.splitlines()  # used later\n        handler = csv.reader(data, dialect)\n    except Exception, e:\n        raise MetaParsingException(\"Can't parse your CSV data: %s\" % e.message)\n\n    # make sure, that data are meaningful\n    decoded = []\n    for cnt, line in enumerate(handler):\n        usable_data = filter(lambda x: x.strip(), line)\n\n        if not usable_data:\n            continue\n\n        if len(usable_data) != 2:\n            raise MetaParsingException(\n                \"Bad number of elements - line %d:\\n\\t%s\\n\" % (cnt, data[cnt])\n            )\n\n        # remove trailing spaces, decode to utf-8\n        usable_data = map(lambda x: x.strip().decode(\"utf-8\"), usable_data)\n\n        # remove quotes if the csv.Sniffer failed to decode right `dialect`\n        usable_data = map(lambda x: _remove_quotes(x), usable_data)\n\n        decoded.append(usable_data)\n\n    # apply another checks to data\n    decoded = validator.check_structure(decoded)\n\n    return decoded"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cli(ctx, config, quiet):\n    ctx.obj = {}\n    ctx.obj['config'] = load_config(config.read())  # yaml.load(config.read())\n    ctx.obj['quiet'] = quiet\n    log(ctx, ' * ' + rnd_scotty_quote() + ' * ')", "response": "A CLI for the ECS Docker Deployment Tool"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake an array of Part of Speech labeled tokens and returns a set of tokens where word tokens have been merged into Noun phrases. :param pos_tokens: an array of (token, POS) :returns: returns an array of word and phrase tokens", "response": "def merge_pos_tokens(self, pos_tokens):\n        \"\"\"\n        takes an array of Part of Speech labeled tokens and returns a set of tokens where word tokens have been merged into Noun phrases.\n        :param pos_tokens: an array of (token, POS)\n        :returns: returns an array of word and phrase tokens\n        \"\"\"\n        if pos_tokens is None or len(pos_tokens)<0:\n            return \"\"\n        tokens, pos = zip(*pos_tokens)\n        pos_phrase_ids = self.convert_noun_phrases(tokens, pos)\n        phrase_ids, phrase_pos = zip(*pos_phrase_ids)\n        phrase_text = convert_run_to_text(phrase_ids, phrase_dictionary=self)\n        return zip(phrase_text, phrase_pos)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts any identified phrases in the run into phrase_ids.", "response": "def convert_noun_phrases(self, id_run, pos_run):\n        \"\"\"\n        Converts any identified phrases in the run into phrase_ids.  The dictionary provides all acceptable phrases\n        :param id_run: a run of token ids\n        :param dictionary: a dictionary of acceptable phrases described as there component token ids\n        :return: a run of token and phrase ids.\n        \"\"\"\n        i = 0\n        rv = []\n        while i < len(id_run):\n            phrase_id, offset = PhraseDictionary.return_max_phrase(id_run, i, self)\n            if phrase_id:\n                if pos_run[i] in ('JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS', 'SYM', 'CD', 'VBG', 'FW', 'NP'):\n                    print \"MERGED\", pos_run[i], self.get_phrase(phrase_id)\n                    rv.append((phrase_id,'NP'))\n                    i = offset\n                else:\n                    print \"SKIPPED\", pos_run[i], self.get_phrase(phrase_id)\n                    rv.append((id_run[i], pos_run[i]))\n                    i += 1\n            else:\n                rv.append((id_run[i], pos_run[i]))\n                i += 1\n        return rv"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a new phrase to the dictionary.", "response": "def add(self, phrase, id=None):\n        \"\"\"\n        Adds a new phrase to the dictionary\n        :param phrase: the new phrase as a list of tokens\n        :param phrase_id: optionally the phrase_id can be set on addition.  Beware, if you set one id you should set\n            them all as the auto-generated ids do not take into account phrase_ids set this way.\n        :return: None\n        \"\"\"\n        if len(phrase) > 0 and type(phrase[0]) in (tuple, list):\n            phrase = [token[0] for token in phrase]\n        super(NounPhraseDictionary, self).add(phrase, id)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending the record to Errordite.", "response": "def emit(self, record):\n        \"\"\"\n        Sends exception info to Errordite.\n\n        This handler will ignore the log level, and look for an exception\n        within the record (as recored.exc_info) or current stack frame\n        (sys.exc_info()). If it finds neither, it will simply return without\n        doing anything.\n        \"\"\"\n        if not self.token:\n            raise Exception(\"Missing Errordite service token.\")\n\n        if record.levelname == 'EXCEPTION':\n            exc_info = record.exc_info\n        else:\n            exc_info = sys.exc_info()\n\n        if exc_info == (None, None, None):\n            # we can't find an exception to report on, so just return\n            return\n\n        ex_type, ex_value, ex_tb = exc_info\n        ex_source = traceback.extract_tb(ex_tb)[-1]\n\n        payload = {\n            \"TimestampUtc\": datetime.datetime.utcnow().isoformat(),\n            \"Token\": self.token,\n            \"MachineName\": platform.node(),\n            \"ExceptionInfo\": {\n                \"Message\": record.msg % record.args,\n                \"Source\": '%s: line %s' % (ex_source[0], ex_source[1]),\n                \"ExceptionType\": '%s.%s' % (ex_type.__module__, ex_type.__name__),\n                \"StackTrace\": traceback.format_exc(),\n                \"MethodName\": ex_source[2]\n            }\n        }\n        if hasattr(record, 'version'):\n            payload['Version'] = record.version\n\n        # enrich with additional, non-core information. This may be sub-\n        # classed\n        payload = self.enrich_errordite_payload(payload, record)\n\n        try:\n            requests.post(\n                ERRORDITE_API_URL,\n                data=json.dumps(payload),\n                headers={'content-type': 'application/json'}\n            )\n            # since we already in the logger, logging an error, there's\n            # there's really nothing we can do with the response that adds\n            # any value - so ignore it.\n            return 'ok'\n\n        except:\n            self.handleError(record)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nresolve the variable or return the value passed to it in the first place", "response": "def resolve(var, context):\n    \"\"\"\n    Resolve the variable, or return the value passed to it in the first place\n    \"\"\"\n    try:\n        return var.resolve(context)\n    except template.VariableDoesNotExist:\n        return var.var"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef no_param_shortcut(parser, token):\n    bits = smart_split(token.contents)\n    tagname = bits.next()\n    try:\n        imageurl = bits.next()\n    except StopIteration:\n        raise template.TemplateSyntaxError(\"%r tag requires at least the image url\" % tagname)\n\n    return MogrifyNode(imageurl, [(tagname, ), ])", "response": "Shortcut to transmogrify thumbnail."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the raw data and translations by fetching and parsing the METAR report and then parsing the METAR report. Returns True if a new report is available otherwise False.", "response": "def update(self, report: str = None) -> bool:\n        \"\"\"Updates raw, data, and translations by fetching and parsing the METAR report\n\n        Returns True is a new report is available, else False\n        \"\"\"\n        if report is not None:\n            self.raw = report\n        else:\n            raw = self.service.fetch(self.station)\n            if raw == self.raw:\n                return False\n            self.raw = raw\n        self.data, self.units = metar.parse(self.station, self.raw)\n        self.translations = translate.metar(self.data, self.units)  # type: ignore\n        self.last_updated = datetime.utcnow()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef summary(self) -> str:\n        if not self.translations:\n            self.update()\n        return summary.metar(self.translations)", "response": "Returns the summary of the current instance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the summary of the message.", "response": "def speech(self) -> str:\n        \"\"\"\n        Report summary designed to be read by a text-to-speech program\n        \"\"\"\n        if not self.data:\n            self.update()\n        return speech.metar(self.data, self.units)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of summary for each forecast created from translations", "response": "def summary(self):  # type: ignore\n        \"\"\"\n        Condensed summary for each forecast created from translations\n        \"\"\"\n        if not self.translations:\n            self.update()\n        return [summary.taf(trans) for trans in self.translations.forecast]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the TAF of the report.", "response": "def speech(self) -> str:\n        \"\"\"\n        Report summary designed to be read by a text-to-speech program\n        \"\"\"\n        if not self.data:\n            self.update()\n        return speech.taf(self.data, self.units)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_python_paths(self, args):\n        paths = []\n        do_paths = False\n        for arg in args:\n\n            if arg == '--pythonpath':\n                # space separated\n                do_paths = True\n                continue\n\n            elif arg.startswith('--pythonpath='):\n                # '=' separated\n                do_paths = True\n                arg = arg[13:]\n\n            if do_paths:\n                if arg.startswith('-'):\n                    # stop thinking it's a python path\n                    do_paths = False\n                    continue\n                # ok add the python path\n                if '*' in arg:\n                    paths.extend(glob.glob(arg))\n                else:\n                    paths.append(arg)\n\n        return paths", "response": "This method parses the python paths from the command line. It handles the case where we can t do globbing and we can t do globbing."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start(self):\n        if not self.initialized:\n            raise Exception(\"Consumer not initialized (no Producer).\")\n        producer = self.producer\n        context = zmq._Context()\n        self.pull = context.socket(zmq.PULL)\n        self.push = context.socket(zmq.PUSH)\n        self.pull.connect('tcp://%s:%s' % (producer.host, producer.push_port))\n        self.push.connect('tcp://%s:%s' % (producer.host, producer.pull_port))\n        # TODO: notify the producer that this consumer's ready for work?\n        self.listen()", "response": "Start the consumer. This starts a listen loop on a zmq. PUSH socket and calling self. handle on each incoming request and pushing the response\n        on a zmq. PULL socket."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef listen(self):\n        while True:\n            message = self.pull.recv()\n            logger.debug(\"received message of length %d\" % len(message))\n            uuid, message = message[:32], message[32:]\n            response = uuid + self.handle(message)\n            self.push.send(response)", "response": "Listen forever on the zmq. PULL socket."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_strategy_types():\n    def get_subtypes(type_):\n        subtypes = type_.__subclasses__()\n        for subtype in subtypes:\n            subtypes.extend(get_subtypes(subtype))\n        return subtypes\n    return get_subtypes(Strategy)", "response": "Get a list of all Strategy subclasses."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_file_type_map():\n    file_type_map = {}\n    for strategy_type in get_strategy_types():\n        for ext in strategy_type.file_types:\n            if ext in file_type_map:\n                raise KeyError(\n                    'File type {ext} already registered to {file_type_map[ext]}'\n                    .format(**locals()))\n            file_type_map[ext] = strategy_type\n    return file_type_map", "response": "Map file types to strategy types."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef guess_strategy_type(file_name_or_ext):\n    if '.' not in file_name_or_ext:\n        ext = file_name_or_ext\n    else:\n        name, ext = os.path.splitext(file_name_or_ext)\n    ext = ext.lstrip('.')\n    file_type_map = get_file_type_map()\n    return file_type_map.get(ext, None)", "response": "Guess the strategy type to use for a file by extension."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a file name and section.", "response": "def parse_file_name_and_section(self, file_name, section=None, extender=None,\n                                    extender_section=None):\n        \"\"\"Parse file name and (maybe) section.\n\n        File names can be absolute paths, relative paths, or asset\n        specs::\n\n            /home/user/project/local.cfg\n            local.cfg\n            some.package:local.cfg\n\n        File names can also include a section::\n\n            some.package:local.cfg#dev\n\n        If a ``section`` is passed, it will take precedence over a\n        section parsed out of the file name.\n\n        \"\"\"\n        if '#' in file_name:\n            file_name, parsed_section = file_name.rsplit('#', 1)\n        else:\n            parsed_section = None\n\n        if ':' in file_name:\n            package, path = file_name.split(':', 1)\n            file_name = pkg_resources.resource_filename(package, path)\n\n        if extender:\n            if not file_name:\n                # Extended another section in the same file\n                file_name = extender\n            elif not os.path.isabs(file_name):\n                # Extended by another file in the same directory\n                file_name = os.path.join(os.path.dirname(extender), file_name)\n\n        if section:\n            pass\n        elif parsed_section:\n            section = parsed_section\n        elif extender_section:\n            section = extender_section\n        else:\n            section = self.get_default_section(file_name)\n\n        return file_name, section"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading settings from specified section of config file.", "response": "def read_file(self, file_name, section=None):\n        \"\"\"Read settings from specified ``section`` of config file.\"\"\"\n        file_name, section = self.parse_file_name_and_section(file_name, section)\n        if not os.path.isfile(file_name):\n            raise SettingsFileNotFoundError(file_name)\n        parser = self.make_parser()\n        with open(file_name) as fp:\n            parser.read_file(fp)\n\n        settings = OrderedDict()\n\n        if parser.has_section(section):\n            section_dict = parser[section]\n            self.section_found_while_reading = True\n        else:\n            section_dict = parser.defaults().copy()\n\n        extends = section_dict.get('extends')\n\n        if extends:\n            extends = self.decode_value(extends)\n            extends, extends_section = self.parse_file_name_and_section(\n                extends, extender=file_name, extender_section=section)\n            settings.update(self.read_file(extends, extends_section))\n\n        settings.update(section_dict)\n\n        if not self.section_found_while_reading:\n            raise SettingsFileSectionNotFoundError(section)\n\n        return settings"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning first non - DEFAULT section ; falls back to DEFAULT.", "response": "def get_default_section(self, file_name):\n        \"\"\"Returns first non-DEFAULT section; falls back to DEFAULT.\"\"\"\n        if not os.path.isfile(file_name):\n            return 'DEFAULT'\n        parser = self.make_parser()\n        with open(file_name) as fp:\n            parser.read_file(fp)\n        sections = parser.sections()\n        section = sections[0] if len(sections) > 0 else 'DEFAULT'\n        return section"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _validate_login(self):\r\n        \r\n        ''' a method to validate user can access heroku account '''\r\n        \r\n        title = '%s.validate_login' % self.__class__.__name__\r\n            \r\n    # verbosity\r\n        windows_insert = ' On windows, run in cmd.exe'\r\n        self.printer('Checking heroku credentials ... ', flush=True)\r\n\r\n    # validate netrc exists\r\n        from os import path\r\n        netrc_path = path.join(self.localhost.home, '.netrc')\r\n    # TODO verify path exists on Windows\r\n        if not path.exists(netrc_path):\r\n            error_msg = '.netrc file is missing. Try: heroku login, then heroku auth:token'\r\n            if self.localhost.os.sysname in ('Windows'):\r\n                error_msg += windows_insert\r\n            self.printer('ERROR.')\r\n            raise Exception(error_msg)\r\n\r\n    # replace value in netrc\r\n        netrc_text = self._update_netrc(netrc_path, self.token, self.email)\r\n\r\n    # verify remote access\r\n        def handle_invalid(stdout, proc):\r\n\r\n        # define process closing helper\r\n            def _close_process(_proc):\r\n            # close process\r\n                import psutil\r\n                process = psutil.Process(_proc.pid)\r\n                for proc in process.children(recursive=True):\r\n                    proc.kill()\r\n                process.kill()\r\n            # restore values to netrc\r\n                with open(netrc_path, 'wt') as f:\r\n                    f.write(netrc_text)\r\n                    f.close()\r\n\r\n        # invalid credentials\r\n            if stdout.find('Invalid credentials') > -1:\r\n                _close_process(proc)\r\n                self.printer('ERROR.')\r\n                raise Exception('Permission denied. Heroku auth token is not valid.\\nTry: \"heroku login\", then \"heroku auth:token\"')\r\n\r\n        sys_command = 'heroku apps --json'\r\n        response = self._handle_command(sys_command, interactive=handle_invalid, handle_error=True)\r\n\r\n        if response.find('Warning: heroku update') > -1:\r\n            self.printer('WARNING: heroku update available.')\r\n            self.printer('Try: npm install -g -U heroku\\nor see https://devcenter.heroku.com/articles/heroku-cli#staying-up-to-date')\r\n            self.printer('Checking heroku credentials ... ')\r\n            response_lines = response.splitlines()\r\n            response = '\\n'.join(response_lines[1:])\r\n\r\n    # add list to object\r\n        import json\r\n        try:\r\n            self.apps = json.loads(response)\r\n        except:\r\n            self.printer('ERROR.')\r\n            raise Exception(response)\r\n\r\n        self.printer('done.')\r\n\r\n        return self", "response": "a method to validate user can access heroku account"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deploy_docker(self, dockerfile_path, virtualbox_name='default'):\r\n\r\n        ''' a method to deploy app to heroku using docker '''\r\n\r\n        title = '%s.deploy_docker' % self.__class__.__name__\r\n\r\n    # validate inputs\r\n        input_fields = {\r\n            'dockerfile_path': dockerfile_path,\r\n            'virtualbox_name': virtualbox_name\r\n        }\r\n        for key, value in input_fields.items():\r\n            object_title = '%s(%s=%s)' % (title, key, str(value))\r\n            self.fields.validate(value, '.%s' % key, object_title)\r\n    \r\n    # check app subdomain\r\n        if not self.subdomain:\r\n            raise Exception('You must access a subdomain before you can deploy to heroku. Try: %s.access()' % self.__class__.__name__)\r\n            \r\n    # import dependencies\r\n        from os import path\r\n\r\n    # validate docker client\r\n        from labpack.platforms.docker import dockerClient\r\n        dockerClient(virtualbox_name, self.verbose)\r\n\r\n    # validate dockerfile\r\n        if not path.exists(dockerfile_path):\r\n            raise Exception('%s is not a valid path on local host.' % dockerfile_path)\r\n        dockerfile_root, dockerfile_node = path.split(dockerfile_path)\r\n        if dockerfile_node != 'Dockerfile':\r\n            raise Exception('heroku requires a file called Dockerfile to deploy using Docker.')\r\n\r\n    # validate container plugin\r\n        from os import devnull\r\n        from subprocess import check_output\r\n        self.printer('Checking heroku plugin requirements ... ', flush=True)\r\n        sys_command = 'heroku plugins --core'\r\n        heroku_plugins = check_output(sys_command, shell=True, stderr=open(devnull, 'wb')).decode('utf-8')\r\n        if heroku_plugins.find('heroku-container-registry') == -1 and heroku_plugins.find('container-registry') == -1:\r\n            sys_command = 'heroku plugins'\r\n            heroku_plugins = check_output(sys_command, shell=True, stderr=open(devnull, 'wb')).decode('utf-8')\r\n            if heroku_plugins.find('heroku-container-registry') == -1 and heroku_plugins.find('container-registry') == -1:\r\n                self.printer('ERROR')\r\n                raise Exception(\r\n                    'heroku container registry required. Upgrade heroku-cli.')\r\n        self.printer('done.')\r\n\r\n    # verify container login\r\n        self.printer('Checking heroku container login ... ', flush=True)\r\n        sys_command = 'heroku container:login'\r\n        self._handle_command(sys_command)\r\n        self.printer('done.')\r\n    \r\n    # Old Login Process (pre 2018.02.03)\r\n        # import pexpect\r\n        # try:\r\n        #     child = pexpect.spawn('heroku container:login', timeout=5)\r\n        #     child.expect('Email:\\s?')\r\n        #     child.sendline(self.email)\r\n        #     i = child.expect([pexpect.EOF, pexpect.TIMEOUT])\r\n        #     if i == 0:\r\n        #         child.terminate()\r\n        #     elif i == 1:\r\n        #         child.terminate()\r\n        #         raise Exception('Some unknown issue prevents Heroku from accepting credentials.\\nTry first: heroku login')\r\n        # except Exception as err:\r\n        #     self._check_connectivity(err)\r\n        # self.printer('done.')\r\n        \r\n    # verbosity\r\n        self.printer('Building docker image ...')\r\n    \r\n    # build docker image\r\n        sys_command = 'cd %s; heroku container:push web --app %s' % (dockerfile_root, self.subdomain)\r\n        self._handle_command(sys_command, print_pipe=True)\r\n        sys_command = 'cd %s; heroku container:release web --app %s' % (dockerfile_root, self.subdomain)\r\n        self._handle_command(sys_command, print_pipe=True)\r\n        self.printer('Deployment complete.')\r\n\r\n        return True", "response": "a method to deploy an app to heroku using docker"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deploy_app(self, site_folder, runtime_type=''):\r\n\r\n        ''' a method to deploy a static html page to heroku using php '''\r\n\r\n        title = '%s.deploy_php' % self.__class__.__name__\r\n\r\n    # validate inputs\r\n        input_fields = {\r\n            'site_folder': site_folder,\r\n            'runtime_type': runtime_type\r\n        }\r\n        for key, value in input_fields.items():\r\n            if value:\r\n                object_title = '%s(%s=%s)' % (title, key, str(value))\r\n                self.fields.validate(value, '.%s' % key, object_title)\r\n\r\n    # verify app subdomain\r\n        if not self.subdomain:\r\n            raise Exception('You must access a subdomain before you can deploy to heroku. Try: %s.access()' % self.__class__.__name__)\r\n                    \r\n    # validate existence of site folder\r\n        from os import path\r\n        if not path.exists(site_folder):\r\n            raise ValueError('%s is not a valid path on localhost.' % site_folder)\r\n    \r\n    # validate existence of proper runtime file\r\n        runtime_file = 'index.html'\r\n        static_build = False\r\n        if runtime_type == 'php':\r\n            runtime_file = 'index.php'\r\n        elif runtime_type in ('ruby', 'java', 'python', 'jingo'):\r\n            runtime_file = 'Procfile'\r\n        elif runtime_type == 'node':\r\n            runtime_file = 'package.json'\r\n        else:\r\n            runtime_type = 'html'\r\n            static_build = True\r\n        build_file = path.join(site_folder, runtime_file)\r\n        if not path.exists(build_file):\r\n            raise Exception('%s must contain an %s file to build a %s app.' % (site_folder, runtime_file, runtime_type))\r\n        if runtime_type == 'python':\r\n            req_file = path.join(site_folder, 'requirements.txt')\r\n            if not path.exists(req_file):\r\n                raise Exception('%s must contain a requirements.txt file to build a python app.' % site_folder)\r\n        if runtime_type == 'jingo':\r\n            req_file = path.join(site_folder, 'package.json')\r\n            if not path.exists(req_file):\r\n                raise Exception('%s must contain a package.json file to build a jingo app.' % site_folder)\r\n\r\n    # validate container plugin\r\n        from os import devnull\r\n        from subprocess import check_output\r\n        self.printer('Checking heroku plugin requirements ... ', flush=True)\r\n        sys_command = 'heroku plugins'\r\n        heroku_plugins = check_output(sys_command, shell=True, stderr=open(devnull, 'wb')).decode('utf-8')\r\n        if heroku_plugins.find('heroku-builds') == -1:\r\n            self.printer('ERROR')\r\n            raise Exception(\r\n                'heroku builds plugin required. Try: heroku plugins:install heroku-builds')\r\n        self.printer('done.')\r\n    \r\n    # construct temporary folder\r\n        self.printer('Creating temporary files ... ', flush=True)\r\n        from shutil import copytree, move, ignore_patterns\r\n        from os import makedirs\r\n        from time import time\r\n        from labpack import __module__\r\n        from labpack.storage.appdata import appdataClient\r\n        client_kwargs = {\r\n            'collection_name': 'TempFiles',\r\n            'prod_name': __module__\r\n        }\r\n        tempfiles_client = appdataClient(**client_kwargs)\r\n        temp_folder = path.join(tempfiles_client.collection_folder, 'heroku%s' % time())\r\n    \r\n    # define cleanup function\r\n        def _cleanup_temp():\r\n            self.printer('Cleaning up temporary files ... ', flush=True)\r\n            from shutil import rmtree\r\n            rmtree(temp_folder, ignore_errors=True)\r\n            self.printer('done.')\r\n\r\n    # copy site to temporary folder\r\n        try:\r\n            makedirs(temp_folder)\r\n            site_root, site_name = path.split(path.abspath(site_folder))\r\n            build_path = path.join(temp_folder, site_name)\r\n            copytree(site_folder, build_path, ignore=ignore_patterns('*node_modules/*','*.lab/*'))\r\n            if static_build:\r\n                index_path = path.join(build_path, 'index.html')\r\n                home_path = path.join(build_path, 'home.html')\r\n                compose_path = path.join(build_path, 'compose.json')\r\n                php_path = path.join(build_path, 'index.php')\r\n                with open(compose_path, 'wt') as f:\r\n                    f.write('{}')\r\n                    f.close()\r\n                with open(php_path, 'wt') as f:\r\n                    f.write('<?php include_once(\"home.html\"); ?>')\r\n                    f.close()\r\n                move(index_path, home_path)\r\n        except:\r\n            self.printer('ERROR')\r\n            _cleanup_temp()\r\n            raise\r\n        self.printer('done.')\r\n\r\n    # deploy site to heroku\r\n        self.printer('Deploying %s to heroku ... ' % site_folder, flush=True)\r\n        try:\r\n            sys_command = 'cd %s; heroku builds:create -a %s' % (temp_folder, self.subdomain)\r\n            self._handle_command(sys_command, print_pipe=True)\r\n        except:\r\n            self.printer('ERROR')\r\n            raise\r\n        finally:\r\n            _cleanup_temp()\r\n\r\n        self.printer('Deployment complete.')\r\n        \r\n        return True", "response": "a method to deploy a static html page to heroku using php"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init():\n    '''Initialise a WSGI application to be loaded by uWSGI.'''\n    # Load values from config file\n    config_file = os.path.realpath(os.path.join(os.getcwd(), 'swaggery.ini'))\n    config = configparser.RawConfigParser(allow_no_value=True)\n    config.read(config_file)\n    log_level = config.get('application', 'logging_level').upper()\n    api_dirs = list(config['apis'])\n    do_checks = config.get('application',\n                           'disable_boot_checks').lower() == 'false'\n    # Set logging level\n    log.setLevel(getattr(logging, log_level))\n    log.debug('Log level set to {}'.format(log_level))\n    # Bootstrap application\n    log.debug('Exploring directories: {}'.format(api_dirs))\n    application = Swaggery(api_dirs=api_dirs, do_checks=do_checks)\n    return application", "response": "Initialise a WSGI application to be loaded by uWSGI."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_names(cls):\n        response = subwrap.run(['lxc-ls'])\n        output = response.std_out\n        return map(str.strip, output.splitlines())", "response": "Lists all known LXC names"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the LXC path for the current class", "response": "def lxc_path(cls, *join_paths):\n        \"\"\"Returns the LXC path (default on ubuntu is /var/lib/lxc)\"\"\"\n        response = subwrap.run(['lxc-ls', '-d'])\n        output = response.std_out\n        lxc_path = output.splitlines()[0]\n        lxc_path = lxc_path.strip()\n        return os.path.join(lxc_path, *join_paths)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving and parses info about an LXC", "response": "def info(cls, name, get_state=True, get_pid=True):\n        \"\"\"Retrieves and parses info about an LXC\"\"\"\n        # Run lxc-info quietly\n        command = ['lxc-info', '-n', name]\n        response = subwrap.run(command)\n        lines = map(split_info_line, response.std_out.splitlines())\n        return dict(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the client module name.", "response": "def getClientModuleName(self):\n        \"\"\"client module name.\n        \"\"\"\n        name = GetModuleBaseNameFromWSDL(self._wsdl)\n        if not name:\n            raise WsdlGeneratorError, 'could not determine a service name'\n        \n        if self.client_module_suffix is None:\n            return name\n\n        return '%s%s' %(name, self.client_module_suffix)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getTypesModuleName(self):\n        if self.types_module_name is not None:\n            return self.types_module_name\n\n        name = GetModuleBaseNameFromWSDL(self._wsdl)\n        if not name:\n            raise WsdlGeneratorError, 'could not determine a service name'\n        \n        if self.types_module_suffix is None:\n            return name\n\n        return '%s%s' %(name, self.types_module_suffix)", "response": "returns the types module name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gatherNamespaces(self):\n        '''This method must execute once..  Grab all schemas\n        representing each targetNamespace.\n        '''\n        if self.usedNamespaces is not None:\n            return\n\n        self.logger.debug('gatherNamespaces')\n        self.usedNamespaces = {}\n            \n        # Add all schemas defined in wsdl\n        # to used namespace and to the Alias dict\n        for schema in self._wsdl.types.values():\n            tns = schema.getTargetNamespace()\n            self.logger.debug('Register schema(%s) -- TNS(%s)'\\\n                %(_get_idstr(schema), tns),)\n            if self.usedNamespaces.has_key(tns) is False:\n                self.usedNamespaces[tns] = []\n            self.usedNamespaces[tns].append(schema)\n            NAD.add(tns)\n            \n        # Add all xsd:import schema instances\n        # to used namespace and to the Alias dict\n        for k,v in SchemaReader.namespaceToSchema.items():\n            self.logger.debug('Register schema(%s) -- TNS(%s)'\\\n                %(_get_idstr(v), k),)\n            if self.usedNamespaces.has_key(k) is False:\n                self.usedNamespaces[k] = []\n            self.usedNamespaces[k].append(v)\n            NAD.add(k)", "response": "This method must execute once.. Grab all schemas that are defined in wsdl and add them to the usedNamespaces dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef writeClient(self, fd, sdClass=None, **kw):\n        sdClass = sdClass or ServiceDescription\n        assert issubclass(sdClass, ServiceDescription), \\\n            'parameter sdClass must subclass ServiceDescription'\n\n#        header = '%s \\n# %s.py \\n# generated by %s\\n%s\\n'\\\n#                  %('#'*50, self.getClientModuleName(), self.__module__, '#'*50)\n        print >>fd, '#'*50\n        print >>fd, '# file: %s.py' %self.getClientModuleName()\n        print >>fd, '# '\n        print >>fd, '# client stubs generated by \"%s\"' %self.__class__\n        print >>fd, '#     %s' %' '.join(sys.argv)\n        print >>fd, '# '\n        print >>fd, '#'*50\n\n        self.services = []\n        for service in self._wsdl.services:\n            sd = sdClass(self._addressing, do_extended=self.do_extended, \n                         wsdl=self._wsdl)\n            if len(self._wsdl.types) > 0:\n                sd.setTypesModuleName(self.getTypesModuleName(), \n                                      self.getTypesModulePath())\n#                sd.setMessagesModuleName(self.getMessagesModuleName(), \n#                                         self.getMessagesModulePath())\n\n            self.gatherNamespaces()\n            sd.fromWsdl(service, **kw)\n            sd.write(fd)\n            self.services.append(sd)", "response": "write out the client module to file descriptor fd."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef writeTypes(self, fd):\n        print >>fd, '#'*50\n        print >>fd, '# file: %s.py' %self.getTypesModuleName()\n        print >>fd, '#'\n        print >>fd, '# schema types generated by \"%s\"' %self.__class__\n        print >>fd, '#    %s' %' '.join(sys.argv)\n        print >>fd, '#'\n        print >>fd, '#'*50\n                  \n        print >>fd, TypesHeaderContainer()\n        self.gatherNamespaces()\n        for l in self.usedNamespaces.values():\n            sd = SchemaDescription(do_extended=self.do_extended, \n                                   extPyClasses=self.extPyClasses)\n            for schema in l:\n                sd.fromSchema(schema)\n            sd.write(fd)", "response": "write out types module to file descriptor."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setTypesModuleName(self, name, modulePath=None):\n        self.typesModuleName = '%s' %name\n        if modulePath is not None:\n            self.typesModuleName = '%s.%s' %(modulePath,name)", "response": "Sets the types module name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite out the current state of the module to file descriptor fd. msg_fd = optional file descriptor for messages module.", "response": "def write(self, fd, msg_fd=None):\n        \"\"\"write out module to file descriptor.\n        fd -- file descriptor to write out service description.\n        msg_fd -- optional file descriptor for messages module.\n        \"\"\"\n#        if msg_fd != None:\n#            print >>fd, self.messagesImports\n#            print >>msg_fd, self.imports\n#        else:\n        print >>fd, self.imports\n            \n        print >>fd, self.locator\n        for m in self.bindings:\n            print >>fd, m\n\n#        if msg_fd != None:\n#            for m in self.messages:\n#                print >>msg_fd, m\n#        else:\n        for m in self.messages:\n            print >>fd, m"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fromSchema(self, schema):\n        ''' Can be called multiple times, but will not redefine a\n        previously defined type definition or element declaration.\n        '''  \n        ns = schema.getTargetNamespace()\n        assert self.targetNamespace is None or self.targetNamespace == ns,\\\n            'SchemaDescription instance represents %s, not %s'\\\n            %(self.targetNamespace, ns)\n\n        if self.targetNamespace is None:\n            self.targetNamespace = ns\n \n        self.classHead.ns = self.classFoot.ns = ns\n        for item in [t for t in schema.types if t.getAttributeName() not in self.__types]:\n            self.__types.append(item.getAttributeName())\n            self.items.append(TypeWriter(do_extended=self.do_extended, extPyClasses=self.extPyClasses))\n            self.items[-1].fromSchemaItem(item)\n\n        for item in [e for e in schema.elements if e.getAttributeName() not in self.__elements]:\n            self.__elements.append(item.getAttributeName())\n            self.items.append(ElementWriter(do_extended=self.do_extended))\n            self.items[-1].fromSchemaItem(item)", "response": "Creates a new instance of this object from a schema."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting out to file descriptor.", "response": "def write(self, fd):\n        \"\"\"write out to file descriptor.\n        \"\"\"\n        print >>fd, self.classHead\n        for t in self.items:\n            print >>fd, t\n        print >>fd, self.classFoot"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset up global elements.", "response": "def fromSchemaItem(self, item):\n        \"\"\"set up global elements.\n        \"\"\"\n        if item.isElement() is False or item.isLocal() is True:\n            raise TypeError, 'expecting global element declaration: %s' %item.getItemTrace()\n\n        local = False\n        qName = item.getAttribute('type')\n        if not qName:\n            etp = item.content\n            local = True\n        else:\n            etp = item.getTypeDefinition('type')\n            \n        if etp is None:\n            if local is True: \n                self.content = ElementLocalComplexTypeContainer(do_extended=self.do_extended)\n            else: \n                self.content = ElementSimpleTypeContainer()\n        elif etp.isLocal() is False:\n            self.content = ElementGlobalDefContainer()\n        elif etp.isSimple() is True: \n            self.content = ElementLocalSimpleTypeContainer()\n        elif etp.isComplex():\n            self.content = ElementLocalComplexTypeContainer(do_extended=self.do_extended)\n        else:\n            raise Wsdl2PythonError, \"Unknown element declaration: %s\" %item.getItemTrace()\n\n        self.logger.debug('ElementWriter setUp container \"%r\", Schema Item \"%s\"' %(\n            self.content, item.getItemTrace()))\n        \n        self.content.setUp(item)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nacquiring the lock file.", "response": "def acquire(self):\n        \"\"\"\n        Attempt to acquire the lock every `delay` seconds until the\n        lock is acquired or until `timeout` has expired.\n\n        Raises FileLockTimeout if the timeout is exceeded.\n\n        Errors opening the lock file (other than if it exists) are\n        passed through.\n        \"\"\"\n        self.lock = retry_call(\n            self._attempt,\n            retries=float('inf'),\n            trap=zc.lockfile.LockError,\n            cleanup=functools.partial(self._check_timeout, timing.Stopwatch()),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef release(self):\n        lock = vars(self).pop('lock', missing)\n        lock is not missing and self._release(lock)", "response": "Release the lock and cleanup\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _resolve_view_params(self, request, defaults, *args, **kwargs):\n        params = copy.copy(defaults)\n        params.update(self.params)\n        params.update(kwargs)\n        resolved_params = {}\n        \n        extra_context = {}\n        for key in params:\n            # grab from provided params. \n            value = params[key]\n            \n            # otherwise grab from existing params\n            if value == None:\n                value = self.params[key] if self.params.has_key(key) else None\n            \n            # otherwise grab from class method\n            if value == None:\n                value = getattr(self, 'get_%s' % key)(request, *args, **kwargs) if getattr(self, 'get_%s' % key, None) else None\n\n            if key in defaults:\n                resolved_params[key] = value\n            else:\n                extra_context[key] = value\n        \n        if extra_context:\n            try:\n                resolved_params['extra_context'].update(extra_context)\n            except AttributeError:\n                resolved_params['extra_context'] = extra_context\n\n        return resolved_params", "response": "Resolves view params with least ammount of resistance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle_valid(self, form=None, *args, **kwargs):\n        # Take a chance and try save a subclass of a ModelForm.\n        if hasattr(form, 'save'):\n            form.save()\n        # Also try and call handle_valid method of the form itself.\n        if hasattr(form, 'handle_valid'):\n            form.handle_valid(*args, **kwargs)", "response": "Called after the form has validated."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef evalMetric(self, x, w1=None, w2=None):\n        '''Evaluates the weighted sum metric at given values of the\n        design variables.\n\n        :param iterable x: values of the design variables, this is passed as\n            the first argument to the function fqoi\n\n        :param float w1: value to weight the mean by\n\n        :param float w2: value to weight the std by\n\n        :return: metric_value - value of the metric evaluated at the design\n            point given by x\n\n        :rtype: float\n\n        '''\n        if w1 is None:\n            w1 = self.w1\n        if w2 is None:\n            w2 = self.w2\n\n        if self.verbose:\n            print('----------')\n            print('At design: ' + str(x))\n\n        self._N_dv = len(_makeIter(x))\n\n        if self.verbose:\n            print('Evaluating surrogate')\n        if self.surrogate is None:\n            def fqoi(u):\n                return self.fqoi(x, u)\n\n            def fgrad(u):\n                return self.jac(x, u)\n            jac = self.jac\n        else:\n            fqoi, fgrad, surr_jac = self._makeSurrogates(x)\n            jac = surr_jac\n\n        u_samples = self._getParameterSamples()\n\n        if self.verbose: print('Evaluating quantity of interest at samples')\n        q_samples, grad_samples = self._evalSamples(u_samples, fqoi, fgrad, jac)\n\n        if self.verbose: print('Evaluating metric')\n        return self._evalWeightedSumMetric(q_samples, grad_samples)", "response": "Evaluates the weighted sum metric at given values of the design variables."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd an indicator to the CRITs vocabulary.", "response": "def add_indicator(self,\n                      value,\n                      itype,\n                      source='',\n                      reference='',\n                      method='',\n                      campaign=None,\n                      confidence=None,\n                      bucket_list=[],\n                      ticket='',\n                      add_domain=True,\n                      add_relationship=True,\n                      indicator_confidence='unknown',\n                      indicator_impact='unknown',\n                      threat_type=itt.UNKNOWN,\n                      attack_type=iat.UNKNOWN,\n                      description=''):\n        \"\"\"\n        Add an indicator to CRITs\n\n        Args:\n            value: The indicator itself\n            itype: The overall indicator type. See your CRITs vocabulary\n            source: Source of the information\n            reference: A reference where more information can be found\n            method: The method for adding this indicator\n            campaign: If the indicator has a campaign, add it here\n            confidence: The confidence this indicator belongs to the given\n                        campaign\n            bucket_list: Bucket list items for this indicator\n            ticket: A ticket associated with this indicator\n            add_domain: If the indicator is a domain, it will automatically\n                        add a domain TLO object.\n            add_relationship: If add_domain is True, this will create a\n                        relationship between the indicator and domain TLOs\n            indicator_confidence: The confidence of the indicator\n            indicator_impact: The impact of the indicator\n            threat_type: The threat type of the indicator\n            attack_type: the attack type of the indicator\n            description: A description of this indicator\n        Returns:\n            JSON object for the indicator or None if it failed.\n        \"\"\"\n        # Time to upload these indicators\n        data = {\n            'api_key': self.api_key,\n            'username': self.username,\n            'source': source,\n            'reference': reference,\n            'method': '',\n            'campaign': campaign,\n            'confidence': confidence,\n            'bucket_list': ','.join(bucket_list),\n            'ticket': ticket,\n            'add_domain': True,\n            'add_relationship': True,\n            'indicator_confidence': indicator_confidence,\n            'indicator_impact': indicator_impact,\n            'type': itype,\n            'threat_type': threat_type,\n            'attack_type': attack_type,\n            'value': value,\n            'description': description,\n            }\n\n        r = requests.post(\"{0}/indicators/\".format(self.url), data=data,\n                          verify=self.verify, proxies=self.proxies)\n        if r.status_code == 200:\n            log.debug(\"Indicator uploaded successfully - {}\".format(value))\n            ind = json.loads(r.text)\n            return ind\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_event(self,\n                  source,\n                  reference,\n                  event_title,\n                  event_type,\n                  method='',\n                  description='',\n                  bucket_list=[],\n                  campaign='',\n                  confidence='',\n                  date=None):\n        \"\"\"\n        Adds an event. If the event name already exists, it will return that\n        event instead.\n\n        Args:\n            source: Source of the information\n            reference: A reference where more information can be found\n            event_title: The title of the event\n            event_type: The type of event. See your CRITs vocabulary.\n            method: The method for obtaining the event.\n            description: A text description of the event.\n            bucket_list: A list of bucket list items to add\n            campaign: An associated campaign\n            confidence: The campaign confidence\n            date: A datetime.datetime object of when the event occurred.\n        Returns:\n            A JSON event object or None if there was an error.\n        \"\"\"\n        # Check to see if the event already exists\n        events = self.get_events(event_title)\n        if events is not None:\n            if events['meta']['total_count'] == 1:\n                return events['objects'][0]\n            if events['meta']['total_count'] > 1:\n                log.error('Multiple events found while trying to add the event'\n                          ': {}'.format(event_title))\n                return None\n        # Now we can create the event\n        data = {\n            'api_key': self.api_key,\n            'username': self.username,\n            'source': source,\n            'reference': reference,\n            'method': method,\n            'campaign': campaign,\n            'confidence': confidence,\n            'description': description,\n            'event_type': event_type,\n            'date': date,\n            'title': event_title,\n            'bucket_list': ','.join(bucket_list),\n        }\n\n        r = requests.post('{}/events/'.format(self.url), data=data,\n                          verify=self.verify, proxies=self.proxies)\n        if r.status_code == 200:\n            log.debug('Event created: {}'.format(event_title))\n            json_obj = json.loads(r.text)\n            if 'id' not in json_obj:\n                log.error('Error adding event. id not returned.')\n                return None\n            return json_obj\n        else:\n            log.error('Event creation failed with status code: '\n                      '{}'.format(r.status_code))\n            return None", "response": "Adds an event to the CRITs vocabulary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_sample_file(self,\n                        sample_path,\n                        source,\n                        reference,\n                        method='',\n                        file_format='raw',\n                        file_password='',\n                        sample_name='',\n                        campaign='',\n                        confidence='',\n                        description='',\n                        bucket_list=[]):\n        \"\"\"\n        Adds a file sample. For meta data only use add_sample_meta.\n\n        Args:\n            sample_path: The path on disk of the sample to upload\n            source: Source of the information\n            reference: A reference where more information can be found\n            method: The method for obtaining the sample.\n            file_format: Must be raw, zip, or rar.\n            file_password: The password of a zip or rar archived sample\n            sample_name: Specify a filename for the sample rather than using\n                the name on disk\n            campaign: An associated campaign\n            confidence: The campaign confidence\n            description: A text description of the sample\n            bucket_list: A list of bucket list items to add\n        Returns:\n            A JSON sample object or None if there was an error.\n        \"\"\"\n        if os.path.isfile(sample_path):\n            data = {\n                'api_key': self.api_key,\n                'username': self.username,\n                'source': source,\n                'reference': reference,\n                'method': method,\n                'filetype': file_format,\n                'upload_type': 'file',\n                'campaign': campaign,\n                'confidence': confidence,\n                'description': description,\n                'bucket_list': ','.join(bucket_list),\n            }\n            if sample_name != '':\n                data['filename'] = sample_name\n            with open(sample_path, 'rb') as fdata:\n                if file_password:\n                    data['password'] = file_password\n                r = requests.post('{0}/samples/'.format(self.url),\n                                  data=data,\n                                  files={'filedata': fdata},\n                                  verify=self.verify,\n                                  proxies=self.proxies)\n                if r.status_code == 200:\n                    result_data = json.loads(r.text)\n                    return result_data\n                else:\n                    log.error('Error with status code {0} and message '\n                              '{1}'.format(r.status_code, r.text))\n            return None", "response": "Adds a file sample to the available data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_sample_meta(self,\n                        source,\n                        reference,\n                        method='',\n                        filename='',\n                        md5='',\n                        sha1='',\n                        sha256='',\n                        size='',\n                        mimetype='',\n                        campaign='',\n                        confidence='',\n                        description='',\n                        bucket_list=[]):\n        \"\"\"\n        Adds a metadata sample. To add an actual file, use add_sample_file.\n\n        Args:\n            source: Source of the information\n            reference: A reference where more information can be found\n            method: The method for obtaining the sample.\n            filename: The name of the file.\n            md5: An MD5 hash of the file.\n            sha1: SHA1 hash of the file.\n            sha256: SHA256 hash of the file.\n            size: size of the file.\n            mimetype: The mimetype of the file.\n            campaign: An associated campaign\n            confidence: The campaign confidence\n            bucket_list: A list of bucket list items to add\n            upload_type: Either 'file' or 'meta'\n        Returns:\n            A JSON sample object or None if there was an error.\n        \"\"\"\n        data = {\n            'api_key': self.api_key,\n            'username': self.username,\n            'source': source,\n            'reference': reference,\n            'method': method,\n            'filename': filename,\n            'md5': md5,\n            'sha1': sha1,\n            'sha256': sha256,\n            'size': size,\n            'mimetype': mimetype,\n            'upload_type': 'meta',\n            'campaign': campaign,\n            'confidence': confidence,\n            'bucket_list': ','.join(bucket_list),\n        }\n        r = requests.post('{0}/samples/'.format(self.url),\n                          data=data,\n                          verify=self.verify,\n                          proxies=self.proxies)\n        if r.status_code == 200:\n            result_data = json.loads(r.text)\n            return result_data\n        else:\n            log.error('Error with status code {0} and message '\n                      '{1}'.format(r.status_code, r.text))\n        return None", "response": "Adds a sample to the metadata file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_email(self,\n                  email_path,\n                  source,\n                  reference,\n                  method='',\n                  upload_type='raw',\n                  campaign='',\n                  confidence='',\n                  description='',\n                  bucket_list=[],\n                  password=''):\n        \"\"\"\n        Add an email object to CRITs. Only RAW, MSG, and EML are supported\n        currently.\n\n        Args:\n            email_path: The path on disk of the email.\n            source: Source of the information\n            reference: A reference where more information can be found\n            method: The method for obtaining the email.\n            upload_type: 'raw', 'eml', or 'msg'\n            campaign: An associated campaign\n            confidence: The campaign confidence\n            description: A description of the email\n            bucket_list: A list of bucket list items to add\n            password: A password for a 'msg' type.\n        Returns:\n            A JSON email object from CRITs or None if there was an error.\n        \"\"\"\n        if not os.path.isfile(email_path):\n            log.error('{} is not a file'.format(email_path))\n            return None\n        with open(email_path, 'rb') as fdata:\n            data = {\n                'api_key': self.api_key,\n                'username': self.username,\n                'source': source,\n                'reference': reference,\n                'method': method,\n                'upload_type': upload_type,\n                'campaign': campaign,\n                'confidence': confidence,\n                'bucket_list': bucket_list,\n                'description': description,\n            }\n            if password:\n                data['password'] = password\n            r = requests.post(\"{0}/emails/\".format(self.url),\n                              data=data,\n                              files={'filedata': fdata},\n                              verify=self.verify,\n                              proxies=self.proxies)\n            if r.status_code == 200:\n                result_data = json.loads(r.text)\n                return result_data\n            else:\n                print('Error with status code {0} and message '\n                      '{1}'.format(r.status_code, r.text))\n        return None", "response": "Adds an email to the CRITs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a backdoor object to the CRITs object.", "response": "def add_backdoor(self,\n                     backdoor_name,\n                     source,\n                     reference,\n                     method='',\n                     aliases=[],\n                     version='',\n                     campaign='',\n                     confidence='',\n                     description='',\n                     bucket_list=[]):\n        \"\"\"\n        Add a backdoor object to CRITs.\n\n        Args:\n            backdoor_name: The primary name of the backdoor\n            source: Source of the information\n            reference: A reference where more information can be found\n            method: The method for obtaining the backdoor information.\n            aliases: List of aliases for the backdoor.\n            version: Version\n            campaign: An associated campaign\n            confidence: The campaign confidence\n            description: A description of the email\n            bucket_list: A list of bucket list items to add\n        \"\"\"\n        data = {\n            'api_key': self.api_key,\n            'username': self.username,\n            'source': source,\n            'reference': reference,\n            'method': method,\n            'name': backdoor_name,\n            'aliases': ','.join(aliases),\n            'version': version,\n            'campaign': campaign,\n            'confidence': confidence,\n            'bucket_list': bucket_list,\n            'description': description,\n        }\n        r = requests.post('{0}/backdoors/'.format(self.url),\n                          data=data,\n                          verify=self.verify,\n                          proxies=self.proxies)\n        if r.status_code == 200:\n            result_data = json.loads(r.text)\n            return result_data\n        else:\n            log.error('Error with status code {0} and message '\n                      '{1}'.format(r.status_code, r.text))\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_profile_point(self,\n                          value,\n                          source='',\n                          reference='',\n                          method='',\n                          ticket='',\n                          campaign=None,\n                          confidence=None,\n                          bucket_list=[]):\n        \"\"\"\n        Add an indicator to CRITs\n\n        Args:\n            value: The profile point itself\n            source: Source of the information\n            reference: A reference where more information can be found\n            method: The method for adding this indicator\n            campaign: If the indicator has a campaign, add it here\n            confidence: The confidence this indicator belongs to the given\n                        campaign\n            bucket_list: Bucket list items for this indicator\n            ticket: A ticket associated with this indicator\n        Returns:\n            JSON object for the indicator or None if it failed.\n        \"\"\"\n        # Time to upload these indicators\n        data = {\n            'api_key': self.api_key,\n            'username': self.username,\n            'source': source,\n            'reference': reference,\n            'method': '',\n            'campaign': campaign,\n            'confidence': confidence,\n            'bucket_list': ','.join(bucket_list),\n            'ticket': ticket,\n            'value': value,\n            }\n\n        r = requests.post(\"{0}/profile_points/\".format(self.url), data=data,\n                          verify=self.verify, proxies=self.proxies)\n        if r.status_code == 200:\n            log.debug(\"Profile Point uploaded successfully - {}\".format(value))\n            pp = json.loads(r.text)\n            return pp\n\n        return None", "response": "Adds an indicator to CRITs"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching for events with the provided title and return the JSON object that represents the event.", "response": "def get_events(self, event_title, regex=False):\n        \"\"\"\n        Search for events with the provided title\n\n        Args:\n            event_title: The title of the event\n        Returns:\n            An event JSON object returned from the server with the following:\n                {\n                    \"meta\":{\n                        \"limit\": 20, \"next\": null, \"offset\": 0,\n                        \"previous\": null, \"total_count\": 3\n                    },\n                    \"objects\": [{}, {}, etc]\n                }\n            or None if an error occurred.\n        \"\"\"\n        regex_val = 0\n        if regex:\n            regex_val = 1\n        r = requests.get('{0}/events/?api_key={1}&username={2}&c-title='\n                         '{3}&regex={4}'.format(self.url, self.api_key,\n                                                self.username, event_title,\n                                                regex_val), verify=self.verify)\n        if r.status_code == 200:\n            json_obj = json.loads(r.text)\n            return json_obj\n        else:\n            log.error('Non-200 status code from get_event: '\n                      '{}'.format(r.status_code))\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_samples(self, md5='', sha1='', sha256=''):\n        params = {'api_key': self.api_key, 'username': self.username}\n        if md5:\n            params['c-md5'] = md5\n        if sha1:\n            params['c-sha1'] = sha1\n        if sha256:\n            params['c-sha256'] = sha256\n        r = requests.get('{0}/samples/'.format(self.url),\n                         params=params,\n                         verify=self.verify,\n                         proxies=self.proxies)\n        if r.status_code == 200:\n            result_data = json.loads(r.text)\n            if 'meta' in result_data:\n                if 'total_count' in result_data['meta']:\n                    if result_data['meta']['total_count'] > 0:\n                        return result_data\n        else:\n            log.error('Non-200 status code: {}'.format(r.status_code))\n        return None", "response": "Searches for a sample in CRITs. Currently only hashes allowed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_backdoor(self, name, version=''):\n        params = {}\n        params['or'] = 1\n        params['c-name'] = name\n        params['c-aliases__in'] = name\n        r = requests.get('{0}/backdoors/'.format(self.url),\n                         params=params,\n                         verify=self.verify,\n                         proxies=self.proxies)\n        if r.status_code == 200:\n            result_data = json.loads(r.text)\n            if 'meta' not in result_data:\n                return None\n            if 'total_count' not in result_data['meta']:\n                return None\n            if result_data['meta']['total_count'] <= 0:\n                return None\n            if 'objects' not in result_data:\n                return None\n            for backdoor in result_data['objects']:\n                if 'version' in backdoor:\n                    if backdoor['version'] == version:\n                        return backdoor\n        else:\n            log.error('Non-200 status code: {}'.format(r.status_code))\n        return None", "response": "Searches for the backdoor based on name and version."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_relationship(self, left_id, left_type, right_id, right_type,\n                         rel_type='Related To'):\n        \"\"\"\n        Checks if the two objects are related\n\n        Args:\n            left_id: The CRITs ID of the first indicator\n            left_type: The CRITs TLO type of the first indicator\n            right_id: The CRITs ID of the second indicator\n            right_type: The CRITs TLO type of the second indicator\n            rel_type: The relationships type (\"Related To\", etc)\n        Returns:\n            True or False if the relationship exists or not.\n        \"\"\"\n        data = self.get_object(left_id, left_type)\n        if not data:\n            raise CRITsOperationalError('Crits Object not found with id {}'\n                                        'and type {}'.format(left_id,\n                                                             left_type))\n        if 'relationships' not in data:\n            return False\n        for relationship in data['relationships']:\n            if relationship['relationship'] != rel_type:\n                continue\n            if relationship['value'] != right_id:\n                continue\n            if relationship['type'] != right_type:\n                continue\n            return True\n        return False", "response": "Checks if the two objects are related to the given CRITs object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nforges a relationship between two CRITs TLOs.", "response": "def forge_relationship(self, left_id, left_type, right_id, right_type,\n                           rel_type='Related To', rel_date=None,\n                           rel_confidence='high', rel_reason=''):\n        \"\"\"\n        Forges a relationship between two TLOs.\n\n        Args:\n            left_id: The CRITs ID of the first indicator\n            left_type: The CRITs TLO type of the first indicator\n            right_id: The CRITs ID of the second indicator\n            right_type: The CRITs TLO type of the second indicator\n            rel_type: The relationships type (\"Related To\", etc)\n            rel_date: datetime.datetime object for the date of the\n                relationship. If left blank, it will be datetime.datetime.now()\n            rel_confidence: The relationship confidence (high, medium, low)\n            rel_reason: Reason for the relationship.\n        Returns:\n            True if the relationship was created. False otherwise.\n        \"\"\"\n        if not rel_date:\n            rel_date = datetime.datetime.now()\n        type_trans = self._type_translation(left_type)\n        submit_url = '{}/{}/{}/'.format(self.url, type_trans, left_id)\n\n        params = {\n            'api_key': self.api_key,\n            'username': self.username,\n            }\n\n        data = {\n            'action': 'forge_relationship',\n            'right_type': right_type,\n            'right_id': right_id,\n            'rel_type': rel_type,\n            'rel_date': rel_date,\n            'rel_confidence': rel_confidence,\n            'rel_reason': rel_reason\n        }\n\n        r = requests.patch(submit_url, params=params, data=data,\n                           proxies=self.proxies, verify=self.verify)\n        if r.status_code == 200:\n            log.debug('Relationship built successfully: {0} <-> '\n                      '{1}'.format(left_id, right_id))\n            return True\n        else:\n            log.error('Error with status code {0} and message {1} between '\n                      'these indicators: {2} <-> '\n                      '{3}'.format(r.status_code, r.text, left_id, right_id))\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the status of the TLO.", "response": "def status_update(self, crits_id, crits_type, status):\n        \"\"\"\n        Update the status of the TLO. By default, the options are:\n        - New\n        - In Progress\n        - Analyzed\n        - Deprecated\n\n        Args:\n            crits_id: The object id of the TLO\n            crits_type: The type of TLO. This must be 'Indicator', ''\n            status: The status to change.\n        Returns:\n            True if the status was updated. False otherwise.\n        Raises:\n            CRITsInvalidTypeError\n        \"\"\"\n        obj_type = self._type_translation(crits_type)\n        patch_url = \"{0}/{1}/{2}/\".format(self.url, obj_type, crits_id)\n        params = {\n            'api_key': self.api_key,\n            'username': self.username,\n        }\n\n        data = {\n            'action': 'status_update',\n            'value': status,\n        }\n\n        r = requests.patch(patch_url, params=params, data=data,\n                           verify=self.verify, proxies=self.proxies)\n        if r.status_code == 200:\n            log.debug('Object {} set to {}'.format(crits_id, status))\n            return True\n        else:\n            log.error('Attempted to set object id {} to '\n                      'Informational, but did not receive a '\n                      '200'.format(crits_id))\n            log.error('Error message was: {}'.format(r.text))\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef source_add_update(self, crits_id, crits_type, source,\n                          action_type='add', method='', reference='',\n                          date=None):\n        \"\"\"\n        date must be in the format \"%Y-%m-%d %H:%M:%S.%f\"\n        \"\"\"\n        type_trans = self._type_translation(crits_type)\n        submit_url = '{}/{}/{}/'.format(self.url, type_trans, crits_id)\n\n        if date is None:\n            date = datetime.datetime.now()\n            date = datetime.datetime.strftime(date, '%Y-%m-%d %H:%M:%S.%f')\n\n        params = {\n            'api_key': self.api_key,\n            'username': self.username,\n            }\n\n        data = {\n            'action': 'source_add_update',\n            'action_type': action_type,\n            'source': source,\n            'method': method,\n            'reference': reference,\n            'date': date\n        }\n\n        r = requests.patch(submit_url, params=params, data=json.dumps(data),\n                           proxies=self.proxies, verify=self.verify)\n        if r.status_code == 200:\n            log.debug('Source {0} added successfully to {1} '\n                      '{2}'.format(source, crits_type, crits_id))\n            return True\n        else:\n            log.error('Error with status code {0} and message {1} for '\n                      'type {2} and id {3} and source '\n                      '{4}'.format(r.status_code, r.text, crits_type,\n                                   crits_id, source))\n            return False", "response": "Add or update a source in the cache"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _type_translation(self, str_type):\n        if str_type == 'Indicator':\n            return 'indicators'\n        if str_type == 'Domain':\n            return 'domains'\n        if str_type == 'IP':\n            return 'ips'\n        if str_type == 'Sample':\n            return 'samples'\n        if str_type == 'Event':\n            return 'events'\n        if str_type == 'Actor':\n            return 'actors'\n        if str_type == 'Email':\n            return 'emails'\n        if str_type == 'Backdoor':\n            return 'backdoors'\n\n        raise CRITsInvalidTypeError('Invalid object type specified: '\n                                    '{}'.format(str_type))", "response": "Internal method to translate the named CRITs TLO type to a URL - based string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if line segment line1 and line2 intersects line segment line1 and line2 are not parallel.", "response": "def lineSeqmentsDoIntersect(line1, line2):\r\n    \"\"\"\r\n    Return True if line segment line1 intersects line segment line2 and\r\n    line1 and line2 are not parallel.\r\n    \"\"\"\r\n    (x1, y1), (x2, y2) = line1\r\n    (u1, v1), (u2, v2) = line2\r\n    (a, b), (c, d) = (x2 - x1, u1 - u2), (y2 - y1, v1 - v2)\r\n    e, f = u1 - x1, v1 - y1\r\n    denom = float(a * d - b * c)\r\n    if _near(denom, 0):\r\n        # parallel\r\n        return False\r\n    else:\r\n        t = old_div((e * d - b * f), denom)\r\n        s = old_div((a * f - e * c), denom)\r\n        # When 0<=t<=1 and 0<=s<=1 the point of intersection occurs within the\r\n        # line segments\r\n        return 0 <= t <= 1 and 0 <= s <= 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mf(pred, props=None, value_fn=None, props_on_match=False, priority=None):\n\n    if isinstance(pred, BaseMatcher):\n        ret = pred if props_on_match else pred.props\n\n    if isinstance(pred, basestring) or \\\n       type(pred).__name__ == 'SRE_Pattern':\n        ret = RegexMatcher(pred, props=props, value_fn=value_fn)\n\n    if isinstance(pred, set):\n        return OverlayMatcher(pred, props=props, value_fn=value_fn)\n\n    if isinstance(pred, list):\n        deps = [p for p in pred if isinstance(p, BaseMatcher)]\n        ret = ListMatcher([mf(p, props_on_match=True) for p in pred],\n                          props=props, value_fn=value_fn,\n                          dependencies=deps)\n\n    if priority is not None:\n        ret.priority = priority\n\n    return ret", "response": "Returns a new matcher that matches the given properties."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef offset_overlays(self, text, offset=0, **kw):\n\n        # This may be a bit slower but overlayedtext takes care of\n        # unicode issues.\n        if not isinstance(text, OverlayedText):\n            text = OverlayedText(text)\n\n        for m in self.regex.finditer(unicode(text)[offset:]):\n            yield Overlay(text, (offset + m.start(), offset + m.end()),\n                          props=self.props,\n                          value=self.value(rxmatch=m))", "response": "Generate overlays after offset."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nyielding Overlay objects from the text.", "response": "def fit_overlays(self, text, start=None, end=None, **kw):\n        \"\"\"\n        Get an overlay thet fits the range [start, end).\n        \"\"\"\n\n        _text = text[start or 0:]\n        if end:\n            _text = _text[:end]\n\n        m = self.regex.match(unicode(_text))\n\n        if m:\n            yield Overlay(text, (start + m.start(), start + m.end()),\n                          props=self.props,\n                          value=self.value(rxmatch=m))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an iterator over the overlays that match the given offset.", "response": "def offset_overlays(self, text, offset=0, **kw):\n        \"\"\"\n        Get overlays for the text.\n        :param text: The text to be searched. This is an overlay\n        object.\n        :param offset: Match starting that index. If none just search.\n        :returns: A generator for overlays.\n        \"\"\"\n\n        for ovl in text.overlays:\n            if ovl.match(offset=offset, props=self.props_match):\n                yield ovl.copy(props=self.props,\n                               value=self.value(overlay=ovl))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nyield the overlays that fit the given range.", "response": "def fit_overlays(self, text, start=None, end=None, **kw):\n        \"\"\"\n        Get an overlay thet fits the range [start, end).\n        \"\"\"\n\n        for ovl in text.overlays:\n            if ovl.match(props=self.props_match, rng=(start, end)):\n                yield ovl"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmerges ovls and setup the value and props.", "response": "def _merge_ovls(self, ovls):\n        \"\"\"\n        Merge ovls and also setup the value and props.\n        \"\"\"\n\n        ret = reduce(lambda x, y: x.merge(y), ovls)\n        ret.value = self.value(ovls=ovls)\n        ret.set_props(self.props)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding a list of overlays that start at start.", "response": "def _fit_overlay_lists(self, text, start, matchers, **kw):\n        \"\"\"\n        Return a list of overlays that start at start.\n        \"\"\"\n\n        if matchers:\n            for o in matchers[0].fit_overlays(text, start):\n                for rest in self._fit_overlay_lists(text, o.end, matchers[1:]):\n                    yield [o] + rest\n\n        else:\n            yield []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nyield the overlays of the given text.", "response": "def offset_overlays(self, text, offset=0, run_deps=True, **kw):\n        \"\"\"\n        The heavy lifting is done by fit_overlays. Override just that for\n        alternatie implementation.\n        \"\"\"\n\n        if run_deps and self.dependencies:\n            text.overlay(self.dependencies)\n\n        for ovlf in self.matchers[0].offset_overlays(text,\n                                                     goffset=offset,\n                                                     **kw):\n            for ovll in self._fit_overlay_lists(text, ovlf.end,\n                                                self.matchers[1:]):\n                yield self._merge_ovls([ovlf] + ovll)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\noverlays the matcher list if run_matchers is True.", "response": "def _maybe_run_matchers(self, text, run_matchers):\n        \"\"\"\n        OverlayedText should be smart enough to not run twice the same\n        matchers but this is an extra handle of control over that.\n        \"\"\"\n\n        if run_matchers is True or \\\n           (run_matchers is not False and text not in self._overlayed_already):\n            text.overlay(self.matchers)\n            self._overlayed_already.append(text)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fit_overlays(self, text, run_matchers=None, **kw):\n        self._maybe_run_matchers(text, run_matchers)\n        for i in self._list_match.fit_overlay(text, **kw):\n            yield i", "response": "Yields the overlays of all available resources."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef offset_overlays(self, text, run_matchers=None, **kw):\n\n        self._maybe_run_matchers(text, run_matchers)\n        for i in self._list_match.offset_overlays(text, **kw):\n            yield i", "response": "Yields the overlays of the text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_nodes_by_selector(self, selector, not_selector=None):\n        nodes = self.parsed(selector)\n\n        if not_selector is not None:\n            nodes = nodes.not_(not_selector)\n\n        return nodes", "response": "Return a collection of filtered nodes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_text_from_node(self, node, regex=None, group=1):\n        text = self._get_stripped_text_from_node(node)\n\n        if regex is not None:\n            text = self._filter_by_regex(regex, text, group)\n\n        return text", "response": "Get text from node and filter if necessary."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the text content of the selector.", "response": "def get_filtered_values_by_selector(self, selector, regex=None, group=1):\n        \"\"\"Return the text content of @selector.\n\n        Filter text content by @regex and @group.\n        \"\"\"\n        data = [\n            self.get_text_from_node(node, regex, group)\n            for node in self.get_nodes_by_selector(selector)\n            if self.get_text_from_node(node, regex, group)\n        ]\n\n        return data if len(data) > 1 else data[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the stripped text content of a node.", "response": "def _get_stripped_text_from_node(self, node):\n        \"\"\"Return the stripped text content of a node.\"\"\"\n        return (\n            node.text_content()\n            .replace(u\"\\u00A0\", \" \")\n            .replace(\"\\t\", \"\")\n            .replace(\"\\n\", \"\")\n            .strip()\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfilter text by regex.", "response": "def _filter_by_regex(self, regex, text, group=1):\n        \"\"\"Filter @text by @regex.\"\"\"\n        match = re.search(\n            regex,\n            text,\n            re.MULTILINE\n        )\n\n        return match.group(group).strip() if (\n            match and match.groups()\n        ) else text"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a local settings file.", "response": "def make_local_settings(argv=None):\n    \"\"\"Generate a local settings file.\n\n    The most common usage is:\n\n        make-local-settings <env>\n\n    where env is replaced with and environment name such as stage or\n    prod. For example:\n\n        make-local-settings prod\n\n    This will create a local settings file named local.prod.cfg with\n    a prod section if local.prod.cfg does not exist. If local.prod.cfg\n    already exists, the prod section will be added if it doesn't exist,\n    and any missing local settings will be prompted for and added.\n\n    \"\"\"\n    description = textwrap.dedent('    %s' % make_local_settings.__doc__)\n\n    parser = ArgParser(\n        description=description,\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n    )\n\n    parser.add_argument('env', nargs='?', help='Environment name (e.g., dev or prod)')\n    parser.add_argument('-t', '--type', default='cfg')\n    parser.add_argument(\n        '-b', '--base-settings-module', default=None,\n        help='Base settings module as a dotted path')\n    parser.add_argument(\n        '-f', '--file-name', default=None,\n        help='Name of file to write settings into')\n    parser.add_argument(\n        '-s', '--section', default=None,\n        help='Section to read/write settings from/to (default = <env>)')\n    parser.add_argument(\n        '-e', '--extends', default=None,\n        help='File name and section to extend from as file_name.ext#section (section is optional)')\n    parser.add_argument('-o', '--overwrite', action='store_true', default=False)\n\n    args = parser.parse_args(argv)\n\n    if args.type:\n        strategy_type = get_file_type_map()[args.type]\n        strategy = strategy_type()\n\n    if args.base_settings_module is None:\n        package = find_packages()[0]\n        path = os.path.join(os.getcwd(), package, 'settings.py')\n        if os.path.exists(path):\n            args.base_settings_module = '{package}.settings'.format(package=package)\n            printer.print_info(\n                'Using {0.base_settings_module} as base settings module'.format(args))\n        else:\n            parser.error('Could not guess which base settings module to use; specify with -b')\n\n    if args.file_name:\n        file_name = args.file_name\n        if not args.type:\n            strategy_type = guess_strategy_type(file_name)\n            strategy = strategy_type()\n    elif args.env:\n        file_name = 'local.{0.env}.{ext}'.format(args, ext=strategy.file_types[0])\n    else:\n        parser.error('Either env or file name must be specified')\n    file_name = os.path.normpath(os.path.abspath(file_name))\n\n    if args.section:\n        section = args.section\n    elif args.env:\n        section = args.env\n    else:\n        parser.error('Either env or section must be specified')\n\n    if os.path.exists(file_name):\n        if args.overwrite:\n            printer.print_warning('Overwriting', file_name)\n            os.remove(file_name)\n\n    # This will create the file if it doesn't exist. The extends\n    # settings will be written whether or not the file exists.\n    settings = {}\n    if args.extends:\n        settings['extends'] = args.extends\n    strategy.write_settings(settings, file_name, section)\n\n    # Load base settings from settings module while A) ensuring that\n    # local settings aren't loaded in the process and B) accounting for\n    # the fact that the base settings might not load local settings.\n    original_disable_value = os.environ.get('LOCAL_SETTINGS_CONFIG_DISABLE')\n    os.environ['LOCAL_SETTINGS_CONFIG_DISABLE'] = '1'\n    settings_module = importlib.import_module(args.base_settings_module)\n    base_settings = vars(settings_module)\n    os.environ.pop('LOCAL_SETTINGS_CONFIG_DISABLE')\n    if original_disable_value is not None:\n        os.environ['LOCAL_SETTINGS_CONFIG_DISABLE'] = original_disable_value\n\n    loader = Loader(file_name, section, strategy_type=strategy_type)\n    loader.load_and_check(base_settings, prompt=True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wind(direction: Number,\n         speed: Number,\n         gust: Number,\n         vardir: typing.List[Number] = None,\n         unit: str = 'kt') -> str:\n    \"\"\"\n    Format wind details into a spoken word string\n    \"\"\"\n    unit = SPOKEN_UNITS.get(unit, unit)\n    val = translate.wind(direction, speed, gust, vardir, unit,\n                         cardinals=False, spoken=True)\n    return 'Winds ' + (val or 'unknown')", "response": "Format wind details into a spoken word string"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef temperature(header: str, temp: Number, unit: str = 'C') -> str:\n    if not (temp and temp.value):\n        return header + ' unknown'\n    if unit in SPOKEN_UNITS:\n        unit = SPOKEN_UNITS[unit]\n    use_s = '' if temp.spoken in ('one', 'minus one') else 's'\n    return ' '.join((header, temp.spoken, 'degree' + use_s, unit))", "response": "Format a temperature into a spoken word string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef visibility(vis: Number, unit: str = 'm') -> str:\n    if not vis:\n        return 'Visibility unknown'\n    if vis.value is None or '/' in vis.repr:\n        ret_vis = vis.spoken\n    else:\n        ret_vis = translate.visibility(vis, unit=unit)\n        if unit == 'm':\n            unit = 'km'\n        ret_vis = ret_vis[:ret_vis.find(' (')].lower().replace(unit, '').strip()\n        ret_vis = core.spoken_number(core.remove_leading_zeros(ret_vis))\n    ret = 'Visibility ' + ret_vis\n    if unit in SPOKEN_UNITS:\n        if '/' in vis.repr and 'half' not in ret:\n            ret += ' of a'\n        ret += ' ' + SPOKEN_UNITS[unit]\n        if not (('one half' in ret and ' and ' not in ret) or 'of a' in ret):\n            ret += 's'\n    else:\n        ret += unit\n    return ret", "response": "Format visibility details into a spoken word string"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nformat the altimeter details into a spoken word string", "response": "def altimeter(alt: Number, unit: str = 'inHg') -> str:\n    \"\"\"\n    Format altimeter details into a spoken word string\n    \"\"\"\n    ret = 'Altimeter '\n    if not alt:\n        ret += 'unknown'\n    elif unit == 'inHg':\n        ret += core.spoken_number(alt.repr[:2]) + ' point ' + core.spoken_number(alt.repr[2:])\n    elif unit == 'hPa':\n        ret += core.spoken_number(alt.repr)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef other(wxcodes: typing.List[str]) -> str:\n    ret = []\n    for code in wxcodes:\n        item = translate.wxcode(code)\n        if item.startswith('Vicinity'):\n            item = item.lstrip('Vicinity ') + ' in the Vicinity'\n        ret.append(item)\n    return '. '.join(ret)", "response": "Format wx codes into a spoken word string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef type_and_times(type_: str, start: Timestamp, end: Timestamp, probability: Number = None) -> str:\n    if not type_:\n        return ''\n    if type_ == 'BECMG':\n        return f\"At {start.dt.hour or 'midnight'} zulu becoming\"\n    ret = f\"From {start.dt.hour or 'midnight'} to {end.dt.hour or 'midnight'} zulu,\"\n    if probability and probability.value:\n        ret += f\" there's a {probability.value}% chance for\"\n    if type_ == 'INTER':\n        ret += ' intermittent'\n    elif type_ == 'TEMPO':\n        ret += ' temporary'\n    return ret", "response": "Format line type and times into a spoken line string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nformatting wind shear string into a spoken word string", "response": "def wind_shear(shear: str, unit_alt: str = 'ft', unit_wind: str = 'kt') -> str:\n    \"\"\"\n    Format wind shear string into a spoken word string\n    \"\"\"\n    unit_alt = SPOKEN_UNITS.get(unit_alt, unit_alt)\n    unit_wind = SPOKEN_UNITS.get(unit_wind, unit_wind)\n    return translate.wind_shear(shear, unit_alt, unit_wind, spoken=True) or 'Wind shear unknown'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef metar(data: MetarData, units: Units) -> str:\n    speech = []\n    if data.wind_direction and data.wind_speed:\n        speech.append(wind(data.wind_direction, data.wind_speed,\n                           data.wind_gust, data.wind_variable_direction,\n                           units.wind_speed))\n    if data.visibility:\n        speech.append(visibility(data.visibility, units.visibility))\n    if data.temperature:\n        speech.append(temperature('Temperature', data.temperature, units.temperature))\n    if data.dewpoint:\n        speech.append(temperature('Dew point', data.dewpoint, units.temperature))\n    if data.altimeter:\n        speech.append(altimeter(data.altimeter, units.altimeter))\n    if data.other:\n        speech.append(other(data.other))\n    speech.append(translate.clouds(data.clouds,\n                                   units.altitude).replace(' - Reported AGL', ''))\n    return ('. '.join([l for l in speech if l])).replace(',', '.')", "response": "Convert MetarData into a string for text - to - speech"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef taf_line(line: TafLineData, units: Units) -> str:\n    speech = []\n    start = type_and_times(line.type, line.start_time, line.end_time, line.probability)\n    if line.wind_direction and line.wind_speed:\n        speech.append(wind(line.wind_direction, line.wind_speed,\n                           line.wind_gust, unit=units.wind_speed))\n    if line.wind_shear:\n        speech.append(wind_shear(line.wind_shear, units.altimeter, units.wind_speed))\n    if line.visibility:\n        speech.append(visibility(line.visibility, units.visibility))\n    if line.altimeter:\n        speech.append(altimeter(line.altimeter, units.altimeter))\n    if line.other:\n        speech.append(other(line.other))\n    speech.append(translate.clouds(line.clouds,\n                                   units.altitude).replace(' - Reported AGL', ''))\n    if line.turbulance:\n        speech.append(translate.turb_ice(line.turbulance, units.altitude))\n    if line.icing:\n        speech.append(translate.turb_ice(line.icing, units.altitude))\n    return start + ' ' + ('. '.join([l for l in speech if l])).replace(',', '.')", "response": "Convert TafLineData into a string for text - to - speech"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef taf(data: TafData, units: Units) -> str:\n    try:\n        month = data.start_time.dt.strftime(r'%B')\n        day = ordinal(data.start_time.dt.day)\n        ret = f\"Starting on {month} {day} - \"\n    except AttributeError:\n        ret = ''\n    return ret + '. '.join([taf_line(line, units) for line in data.forecast])", "response": "Convert TafData into a string for text - to - speech\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget listing of S3 Bucket", "response": "def get_bucket():\n    \"\"\"\n    Get listing of S3 Bucket\n    \"\"\"\n    args = parser.parse_args()\n\n    bucket = s3_bucket(args.aws_access_key_id, args.aws_secret_access_key, args.bucket_name)\n    for b in bucket.list():\n        print(''.join([i if ord(i) < 128 else ' ' for i in b.name]))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef walk_data(input_data):\n\n    ''' a generator function for retrieving data in a nested dictionary\n\n    :param input_data: dictionary or list with nested data\n    :return: string with dot_path, object with value of endpoint\n    '''\n\n    def _walk_dict(input_dict, path_to_root):\n        if not path_to_root:\n            yield '.', input_dict\n        for key, value in input_dict.items():\n            key_path = '%s.%s' % (path_to_root, key)\n            type_name = value.__class__.__name__\n            yield key_path, value\n            if type_name == 'dict':\n                for dot_path, value in _walk_dict(value, key_path):\n                    yield dot_path, value\n            elif type_name == 'list':\n                for dot_path, value in _walk_list(value, key_path):\n                    yield dot_path, value\n\n    def _walk_list(input_list, path_to_root):\n        for i in range(len(input_list)):\n            item_path = '%s[%s]' % (path_to_root, i)\n            type_name = input_list[i].__class__.__name__\n            yield item_path, input_list[i]\n            if type_name == 'dict':\n                for dot_path, value in _walk_dict(input_list[i], item_path):\n                    yield dot_path, value\n            elif type_name == 'list':\n                for dot_path, value in _walk_list(input_list[i], item_path):\n                    yield dot_path, value\n\n    if isinstance(input_data, dict):\n        for dot_path, value in _walk_dict(input_data, ''):\n            yield dot_path, value\n    elif isinstance(input_data, list):\n        for dot_path, value in _walk_list(input_data, ''):\n            yield dot_path, value\n    else:\n        raise ValueError('walk_data() input_data argument must be a list or dictionary.')", "response": "a generator function for retrieving data in a nested dictionary\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transform_data(function, input_data):\n\n    ''' a function to apply a function to each value in a nested dictionary\n\n    :param function: callable function with a single input of any datatype\n    :param input_data: dictionary or list with nested data to transform\n    :return: dictionary or list with data transformed by function\n    '''\n\n# construct copy\n    try:\n        from copy import deepcopy\n        output_data = deepcopy(input_data)\n    except:\n        raise ValueError('transform_data() input_data argument cannot contain module datatypes.')\n\n# walk over data and apply function\n    for dot_path, value in walk_data(input_data):\n        current_endpoint = output_data\n        segment_list = segment_path(dot_path)\n        segment = None\n        if segment_list:\n            for i in range(len(segment_list)):\n                try:\n                    segment = int(segment_list[i])\n                except:\n                    segment = segment_list[i]\n                if i + 1 == len(segment_list):\n                    pass\n                else:\n                    current_endpoint = current_endpoint[segment]\n            current_endpoint[segment] = function(value)\n\n    return output_data", "response": "a function to apply a function to each value in a nested dictionary with a single input of any datatype\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clean_data(input_value):\n\n    ''' a function to transform a value into a json or yaml valid datatype\n\n    :param input_value: object of any datatype\n    :return: object with json valid datatype\n    '''\n\n# pass normal json/yaml datatypes\n    if input_value.__class__.__name__ in ['bool', 'str', 'float', 'int', 'NoneType']:\n        pass\n\n# transform byte data to base64 encoded string\n    elif isinstance(input_value, bytes):\n        from base64 import b64encode\n        input_value = b64encode(input_value).decode()\n\n# convert tuples and sets into lists\n    elif isinstance(input_value, tuple) or isinstance(input_value, set):\n        new_list = []\n        new_list.extend(input_value)\n        input_value = transform_data(clean_data, new_list)\n\n# recurse through dictionaries and lists\n    elif isinstance(input_value, dict) or isinstance(input_value, list):\n        input_value = transform_data(clean_data, input_value)\n\n# convert to string all python objects and callables\n    else:\n        input_value = str(input_value)\n\n    return input_value", "response": "a function to transform a value into a json or yaml valid datatype\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reconstruct_dict(dot_paths, values):\n    \n    ''' a method for reconstructing a dictionary from the values along dot paths '''\n    \n    output_dict = {}\n    \n    for i in range(len(dot_paths)):\n        if i + 1 <= len(values):\n            path_segments = segment_path(dot_paths[i])\n            current_nest = output_dict\n            for j in range(len(path_segments)):\n                key_name = path_segments[j]\n                try:\n                    key_name = int(key_name)\n                except:\n                    pass\n                if j + 1 == len(path_segments):\n                    if isinstance(key_name, int):\n                        current_nest.append(values[i])\n                    else:\n                        current_nest[key_name] = values[i]\n                else:\n                    next_key = path_segments[j+1]\n                    try:\n                        next_key = int(next_key)\n                    except:\n                        pass\n                    if isinstance(next_key, int):\n                        if not key_name in current_nest.keys():\n                            current_nest[key_name] = []\n                        current_nest = current_nest[key_name]\n                    else:\n                        if isinstance(key_name, int):\n                            current_nest.append({})\n                            current_nest = current_nest[len(current_nest) - 1]\n                        else:\n                            if not key_name in current_nest.keys():\n                                current_nest[key_name] = {}\n                            current_nest = current_nest[key_name]\n    \n    return output_dict", "response": "a method for reconstructing a dictionary from the values along dot paths"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncopying a file to s3", "response": "def cp_file():\n    \"\"\"\n    dumps databases into /backups, uploads to s3, deletes backups older than a month\n    fab -f ./fabfile.py backup_dbs\n    \"\"\"\n\n    args = parser.parse_args()\n    copy_file(args.aws_access_key_id, args.aws_secret_access_key, args.bucket_name, args.file, args.s3_folder)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef topological_sorting(nodes, relations):\n    '''An implementation of Kahn's algorithm.\n    '''\n    ret = []\n    nodes = set(nodes) | _nodes(relations)\n    inc = _incoming(relations)\n    out = _outgoing(relations)\n    free = _free_nodes(nodes, inc)\n\n    while free:\n        n = free.pop()\n        ret.append(n)\n        \n        out_n = list(out[n])\n        for m in out_n:\n            out[n].remove(m)\n            inc[m].remove(n)\n            if _is_free(m, inc):\n                free.add(m)\n\n    if not all(_is_free(node, inc) and _is_free(node, out) for node in nodes):\n        raise ValueError(\"Cycle detected\")\n    return ret", "response": "An implementation of Kahn s algorithm.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndescending into a nested data structure, forcing any lazy translation strings into plain text.", "response": "def _force_text_recursive(data):\n    \"\"\"\n    Descend into a nested data structure, forcing any\n    lazy translation strings into plain text.\n    \"\"\"\n    if isinstance(data, list):\n        ret = [\n            _force_text_recursive(item) for item in data\n        ]\n        if isinstance(data, ReturnList):\n            return ReturnList(ret, serializer=data.serializer)\n        return data\n    elif isinstance(data, dict):\n        ret = {\n            key: _force_text_recursive(value)\n            for key, value in data.items()\n        }\n        if isinstance(data, ReturnDict):\n            return ReturnDict(ret, serializer=data.serializer)\n        return data\n    return force_text(data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a formated text with bash color", "response": "def color_text(text, color=\"none\", bcolor=\"none\", effect=\"none\"):\n    \"\"\"\n    Return a formated text with bash color\n    \"\"\"\n    istty = False\n    try:\n        istty = sys.stdout.isatty()\n    except:\n        pass\n    if not istty or not COLOR_ON:\n        return text\n    else:\n        if not effect in COLOR_EFFET.keys():\n            effect = \"none\"\n        if not color in COLOR_CODE_TEXT.keys():\n            color = \"none\"\n        if not bcolor in COLOR_CODE_BG.keys():\n            bcolor = \"none\"\n\n        v_effect = COLOR_EFFET[effect]\n        v_color = COLOR_CODE_TEXT[color]\n        v_bcolor = COLOR_CODE_BG[bcolor]\n\n        if effect == \"none\" and color == \"none\" and bcolor == \"none\":\n            return text\n        else:\n            return \"\\033[%d;%d;%dm\" % (v_effect, v_color, v_bcolor) + text + COLOR_RESET"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfast counting to the lines of a given filename", "response": "def countLines(filename, buf_size=1048576):\n    \"\"\"\n    fast counting to the lines of a given filename\n    through only reading out a limited buffer\n    \"\"\"\n    f = open(filename)\n    try:\n        lines = 1\n        read_f = f.read  # loop optimization\n        buf = read_f(buf_size)\n        # Empty file\n        if not buf:\n            return 0\n        while buf:\n            lines += buf.count('\\n')\n            buf = read_f(buf_size)\n        return lines\n    finally:\n        f.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef zfind(cls, **kwargs):\n        assert len(kwargs) == 1\n        fldcond = kwargs.keys()[0].split('__')\n        fld = fldcond[0]\n        f = cls.__dict__[fld]\n        val = kwargs.values()[0]\n        if isinstance(val, tuple):\n            assert len(val) == 2\n            val = (f.typecast_for_write(val[0]), f.typecast_for_write(val[1]))\n        else:\n            val = f.typecast_for_write(val)\n        if len(fldcond) == 1:\n            return f.zindex.zfind(eq = val)\n        else:\n            cond = fldcond[1]\n            return f.zindex.zfind(**{cond: val})", "response": "Returns a list of the objects in the zindex that match the given criteria."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _names_to_bytes(names):\n    names = sorted(names)\n    names_bytes = json.dumps(names).encode('utf8')\n    return names_bytes", "response": "Reproducibly converts an iterable of strings to bytes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef hash_names(names, hash_function=None):\n    hash_function = hash_function or hashlib.md5\n    names_bytes = _names_to_bytes(names)\n    return hash_function(names_bytes).hexdigest()", "response": "Return the hash of an iterable of strings or a dict if multiple hash functions given."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a BEL resource file and returns its semantic hash.", "response": "def get_bel_resource_hash(location, hash_function=None):\n    \"\"\"Get a BEL resource file and returns its semantic hash.\n\n    :param str location: URL of a resource\n    :param hash_function: A hash function or list of hash functions, like :func:`hashlib.md5` or :code:`hashlib.sha512`\n    :return: The hexadecimal digest of the hash of the values in the resource\n    :rtype: str\n    :raises: pybel.resources.exc.ResourceError\n    \"\"\"\n    resource = get_bel_resource(location)\n\n    return hash_names(\n        resource['Values'],\n        hash_function=hash_function\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute a hash for a given noteId date and title.", "response": "def compute_hash(self, noteId, date, title):\n        '''\n        Compute a hash. This is somewhat resistant to errors, e.g. if somehow the date is None,\n        this will still work.\n        '''\n        if not noteId:\n            noteId = ''.join(random.choice(string.digits) for _ in range(4))\n        if not date:\n            date = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        if not title:\n            title = ''.join(random.choice(string.ascii_lowercase + string.digits) for _ in range(100))\n        #print(str(title)+str(noteId)+str(date))\n        return(hashlib.sha256((str(title) + str(noteId) + str(date)).encode('utf8')).hexdigest())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef book_name(self, number):\n        '''Return name of book with given index.'''\n        try:\n            name = self.cur.execute(\"SELECT name FROM book WHERE number = ?;\", [number]).fetchone()\n        except:\n            self.error(\"cannot look up name of book number %s\" % number)\n        return(str(name[0]))", "response": "Return name of book with given index."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn number of book with given name.", "response": "def book_number(self, name):\n        '''Return number of book with given name.'''\n        try:\n            number = self.cur.execute(\"SELECT number FROM book WHERE name= ?;\", [name]).fetchone()\n        except:\n            self.error(\"cannot look up number of book with name %s\" % name)\n        return(number)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the list of book names", "response": "def list_books(self):\n        ''' Return the list of book names '''\n        names = []\n        try:\n            for n in self.cur.execute(\"SELECT name FROM book;\").fetchall():\n                names.extend(n)\n        except:\n            self.error(\"ERROR: cannot find database table 'book'\")\n        return(names)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new book", "response": "def create_book(self, name):\n        \"\"\"Create a new book\"\"\"\n        name = name.strip()\n        if not len(name):\n            self.error(\"Cannot have a blank book name\")\n        # The next could be relaxed, if users want commas in book names, but\n        # I prefer to keep it, in case later there could be a syntax for multiple\n        # book names, using comma.\n        if name.find(\",\") >= 0:\n            self.error(\"Cannot have a ',' in a book name\")\n        existing = self.list_books()\n        nexisting = len(existing)\n        if name in existing:\n            self.error(\"Already have a book named '%s'\" % name)\n        try:\n            self.cur.execute(\"INSERT INTO book (number, name) VALUES(?, ?);\", (nexisting, name))\n            self.con.commit()\n        except:\n            self.fyi(\"Error adding a book named '%s'\" % name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing the database. This is dangerous since it removes any existing content.", "response": "def initialize(self, author=\"\"):\n        ''' Initialize the database.  This is dangerous since it removes any\n        existing content.'''\n        self.cur.execute(\"CREATE TABLE version(major, minor);\")\n        self.cur.execute(\"INSERT INTO version(major, minor) VALUES (?,?);\",\n                (self.appversion[0], self.appversion[1]))\n        #20150314 self.cur.execute(\"CREATE TABLE note(noteId integer primary key autoincrement, authorId, date, modified, due, title, content, hash, privacy DEFAULT 0, in_trash DEFAULT 0);\")\n        self.cur.execute(\"CREATE TABLE note(noteId integer primary key autoincrement, authorId, date, modified, due, title, content, hash, privacy DEFAULT 0, book DEFAULT 1);\")\n        self.cur.execute(\"CREATE TABLE author(authorId integer primary key autoincrement, name, nickname);\")\n        self.cur.execute(\"CREATE TABLE alias(aliasId integer primary key autoincrement, item, alias);\")\n        self.cur.execute(\"CREATE TABLE keyword(keywordId integer primary key autoincrement, keyword);\")\n        self.cur.execute(\"CREATE TABLE notekeyword(notekeywordId integer primary key autoincrement, noteid, keywordid);\")\n        self.cur.execute(\"CREATE TABLE book(bookId integer primary key autoincrement, number, name DEFAULT '');\")\n        self.cur.execute(\"INSERT INTO book(number, name) VALUES (0, 'Trash');\")\n        self.cur.execute(\"INSERT INTO book(number, name) VALUES (1, 'Default');\")\n        self.con.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, title=\"\", keywords=\"\", content=\"\", attachments=\"\", due=\"\", book=1, privacy=0, date=\"\", modified=\"\"):\n        ''' Add a note to the database.  The title should be short (perhaps 3\n        to 7 words).  The keywords are comma-separated, and should be similar\n        in style to others in the database.  The content may be of any length. The\n        attachments are comma-separated, and must be full pathnames to files \n        that exist.'''\n        #self.debug = 1\n        try:\n            known_books = []\n            for b in self.cur.execute(\"SELECT number FROM book;\").fetchall():\n                known_books.extend(b)\n        except:\n            self.error(\"cannot look up list of known books\")\n        #print(\"known_books %s\" % known_books)\n        #print(\"book %s initially\" % book)\n        if not book in known_books:\n            if book != -1:\n                self.warning(\"the book is not known, so switching to \\\"Default\\\"\")\n            book = 1\n        #print(\"book %s later\" % book)\n        self.fyi(\"add with title='%s'\" % title)\n        self.fyi(\"add with keywords='%s'\" % keywords)\n        self.fyi(\"add with attachments='%s' (comma-separated string)\" % attachments)\n        self.fyi(\"add with due='%s'\" % due)\n        self.fyi(\"add with book='%s'\" % book)\n        if not isinstance(due, str):\n            due = \"\"\n        due = self.interpret_time(due)[0]\n        self.fyi(\"due: %s\" % due)\n        now = datetime.datetime.now()\n        if date == \"\":\n            date = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n        try:\n            self.cur.execute(\"INSERT INTO note(authorId, date, modified, title, content, privacy, due, book) VALUES(?, ?, ?, ?, ?, ?, ?, ?);\",\n                (self.authorId, date, modified, title, content, 0, due, book))\n        except:\n            self.error(\"error adding note to the database\")\n        noteId = self.cur.lastrowid\n        self.fyi(\"noteId: %s\" % noteId)\n        hash = self.compute_hash(noteId=noteId, date=date, title=title)\n        self.fyi(\"hash: %s\" % hash)\n        try:\n            self.cur.execute(\"UPDATE note SET hash=? WHERE noteId=?;\", (hash, noteId))\n        except:\n            self.error(\"error adding note hash to the database\")\n        for keyword in keywords:\n            self.fyi(\"  inserting keyword:\", keyword)\n            keywordId = self.con.execute(\"SELECT keywordId FROM keyword WHERE keyword = ?;\", [keyword]).fetchone()\n            if keywordId:\n                self.fyi(\"  (existing keyword with id %s)\" % keywordId)\n                keywordId = keywordId[0]\n            else:\n                self.fyi(\"  (new keyword)\")\n                self.cur.execute(\"INSERT INTO keyword(keyword) VALUES (?);\", [keyword])\n                keywordId = self.cur.lastrowid\n            self.con.execute(\"INSERT INTO notekeyword(noteId, keywordID) VALUES(?, ?)\", [noteId, keywordId])\n        # Handle attachments, which must be existing files.\n        attachments = [key.lstrip().rstrip() for key in attachments.split(',')]\n        attachments = filter(None, attachments) # remove blanks\n        for attachment in attachments:\n            self.fyi(\"processing attachment '%s'\" % attachment)\n            if not os.path.isfile(attachment):\n                self.warning(\" cannot attach file '%s' because it does not exist\" % attachment)\n            else:\n                self.fyi(\"    '%s' exists\" % attachment)\n                attachment = os.path.expanduser(attachment)\n                afile = open(attachment, \"rb\")\n                try:\n                    blob = afile.read()\n                    self.fyi(\"    read file '%s'\" % attachment)\n                    self.cur.execute('INSERT INTO attachment(filename,contents) VALUES(?,?)', [attachment,buffer(blob)])\n                    attachmentId = self.cur.lastrowid\n                    self.fyi(\"    inserted OK; attachmentID=%d\" % attachmentId)\n                    self.con.commit()\n                    self.fyi(\"    added to attachment table\")\n                    self.fyi('    try \"INSERT INTO note_attachment(noteId, attachmentId) VALUES(%d,%d)\"' % (noteId,attachmentId))\n                    self.cur.execute('INSERT INTO note_attachment(noteId, attachmentId) VALUES(?,?)', [noteId,attachmentId])\n                    self.con.commit()\n                    self.fyi(\"    ... OK\")\n                except:\n                    self.error(\"Problem storing attachment named '%s'\" % attachment)\n                finally:\n                    afile.close()\n                self.fyi(\" ... all done, writing attachment\")\n        self.con.commit()\n        self.fyi(\"add() returning noteId=%d ... is all ok?\" % noteId)\n        return noteId", "response": "Add a note to the database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef keyword_hookup(self, noteId, keywords):\n        '''\n        Unhook existing cross-linking entries.\n        '''\n        try:\n            self.cur.execute(\"DELETE FROM notekeyword WHERE noteid=?\", [noteId])\n        except:\n            self.error(\"ERROR: cannot unhook previous keywords\")\n        # Now, hook up new the entries, one by one.\n        for keyword in keywords:\n            keyword = keyword.decode('utf-8')\n            self.fyi(\" inserting keyword:\", keyword)\n            # Make sure the keyword table contains the word in question.\n            keywordId = self.con.execute(\"SELECT keywordId FROM keyword WHERE keyword = ?;\", [keyword]).fetchone()\n            try:\n                if keywordId:\n                    self.fyi(\"  (existing keyword with id: %s)\" % keywordId)\n                    keywordId = keywordId[0]\n                else:\n                    self.fyi(\"  (new keyword)\")\n                    self.cur.execute(\"INSERT INTO keyword(keyword) VALUES (?);\", [keyword])\n                    keywordId = self.cur.lastrowid\n                # Finally, do the actual hookup for this word.\n                self.con.execute(\"INSERT INTO notekeyword(noteId, keywordID) VALUES(?, ?)\", [noteId, keywordId])\n            except:\n                self.error(\"error hooking up keyword '%s'\" % keyword)\n        self.con.commit()", "response": "Hook up existing cross - linking entries."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_keywords(self):\n        ''' Return the list of keywords '''\n        names = []\n        try:\n            for n in self.cur.execute(\"SELECT keyword FROM keyword;\").fetchall():\n                # Strip out leading and trailing whitespaces (can be artifacts of old data)\n                k = n[0].strip()\n                if len(k):\n                    names.extend([k])\n        except:\n            self.error(\"ERROR: cannot find database table 'keyword'\")\n        names = list(set(names)) # remove duplicates\n        names = sorted(names, key=lambda s: s.lower())\n        return(names)", "response": "Return the list of keywords in the database"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef edit(self, hash=\"\"):\n        '''\n        Edit a note, given its abbreviated hash, which must be unique\n        across both visible and trashed notes. (It is permitted to edit\n        notes in the trash.)\n        '''\n        if not len(hash):\n            exit(0)\n        self.fyi(\"nota.edit() has hash: %s\" % hash)\n        ## do not use find_by_hash() because can be in hash or not.\n        rows = self.cur.execute(\"SELECT noteId, hash FROM note;\").fetchall()\n        hash_len = len(hash)\n        noteIds = []\n        for r in rows:\n            if r[1][0:hash_len] == hash:\n                noteIds.append((r[0],))\n        if not len(noteIds):\n            self.error(\"no active notes match abbreviated hash '%s'\" % hash)\n        if 1 != len(noteIds):\n            self.error(\"cannot edit %d notes at once; try adding more letters to the hash code\" % len(noteIds))\n        old = self.find_by_hash(hash)\n        if 1 != len(old):\n            self.error(\"cannot edit %d notes at once; try adding more letters to the hash code\" % len(old))\n        old = old[0]\n        keywords = []\n        keywords.extend(self.get_keywords(old['noteId']))\n        ee = self.editor_entry(title=old['title'], keywords=keywords, content=old['content'],\n                attachments='', book=old['book'], due=old['due'])\n        noteId = int(old[\"noteId\"])\n        try:\n            self.cur.execute(\"UPDATE note SET title = (?) WHERE noteId = ?;\", (ee[\"title\"], noteId))\n        except:\n            self.error(\"cannot do: UPDATE note SET title = (%s) WHERE noteId = %s;\" % (ee[\"title\"], noteId))\n        try:\n            self.cur.execute(\"UPDATE note SET content = (?) WHERE noteId = ?;\", (ee[\"content\"], noteId))\n        except:\n            self.error(\"cannot do: UPDATE note SET content = (%s) WHERE noteId = %s;\" % (ee[\"content\"], noteId))\n        try:\n            self.cur.execute(\"UPDATE note SET book = (?) WHERE noteId = ?;\", (ee[\"book\"], noteId))\n        except:\n            self.error(\"cannot do: UPDATE note SET book = (%s) WHERE noteId = %s;\" % (ee[\"book\"], noteId))\n        self.keyword_hookup(noteId, ee[\"keywords\"])\n        if ee[\"due\"] and ee[\"due\"] != \"None\":\n            try:\n                due = self.interpret_time(ee[\"due\"])[0]\n                self.cur.execute(\"UPDATE note SET due=(?) WHERE noteId=?;\", (due, noteId))\n            except:\n                self.error(\"cannot update the 'due' date\")\n        self.con.commit()\n        return noteId", "response": "Edit a note given its abbreviated hash."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cleanup(self):\n        ''' Clean up the database, e.g. removing unused keywords.'''\n        allList = []\n        allList.extend(self.cur.execute(\"SELECT keywordid FROM keyword;\"))\n        usedList = []\n        usedList.extend(self.cur.execute(\"SELECT keywordid FROM notekeyword;\"))\n        unusedList = [val for val in allList if val not in usedList]\n        for key in unusedList:\n            if self.debug:\n                print(\"About to delete keyword with ID %s\" % key)\n            try:\n                self.cur.execute(\"DELETE FROM keyword WHERE keywordId = ?;\", key)\n            except:\n                self.error(\"There was a problem deleting keyword %s\" % key)\n        self.con.commit()", "response": "Clean up the database e. g. removing unused keywords."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching notes for a given possibly abbreviated hash", "response": "def find_by_hash(self, hash=None, book=-1):\n        '''Search notes for a given (possibly abbreviated) hash'''\n        if hash:\n            self.fyi(\"nota.find_by_hash() with abbreviated hash %s; book=%s\" % (hash, book))\n        try:\n            if book < 0:\n                rows = self.cur.execute(\"SELECT noteId, hash FROM note WHERE book > 0;\").fetchall()\n            else:\n                rows = self.cur.execute(\"SELECT noteId, hash FROM note WHERE book=?;\", [book]).fetchall()\n        except:\n            self.error(\"nota.find_by_hash() cannot look up note list\")\n        # Possibly save time by finding IDs first.\n        noteIds = []\n        if hash:\n            l = len(hash)\n            for r in rows:\n                if hash == r[1][0:l]:\n                    noteIds.append((r[0],))\n        else:\n            for r in rows:\n                noteIds.append((r[0],))\n        self.fyi(\"noteIds: %s\" % noteIds)\n        rval = []\n        for n in noteIds:\n            try:\n                note = self.cur.execute(\"SELECT noteId, authorId, date, title, content, due, privacy, modified, hash, book FROM note WHERE noteId=?;\", n).fetchone()\n            except:\n                self.warning(\"Problem extracting note %s from database\" % n)\n                next\n            if note:\n                date = note[2]\n                due = note[5]\n                privacy = note[6]\n                keywordIds = []\n                keywordIds.extend(self.con.execute(\"SELECT keywordid FROM notekeyword WHERE notekeyword.noteid=?;\", n))\n                keywords = []\n                for k in keywordIds:\n                    keywords.append(self.cur.execute(\"SELECT keyword FROM keyword WHERE keywordId=?;\", k).fetchone()[0])\n                rval.append({\"noteId\":note[0], \"title\":note[3], \"keywords\":keywords,\n                    \"content\":note[4], \"due\":note[5], \"privacy\":note[6],\n                    \"date\":note[2], \"modified\":note[7], \"hash\":note[8], \"book\":note[9]})\n        return rval"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_by_keyword(self, keywords=\"\", strict_match=False, book=-1):\n        self.fyi(\"find_by_keyword, ... book=%s\" % book)\n        '''Search notes for a given keyword'''\n        self.fyi(\"nota.find_by_keyword() with keywords %s; book=%s\" % (keywords, book))\n        keywordsKnown = []\n        if not strict_match:\n            keywords[0] = keywords[0].lower()\n        for k in self.cur.execute(\"SELECT keyword FROM keyword;\").fetchall():\n            if strict_match:\n                keywordsKnown.extend(k)\n            else:\n                keywordsKnown.extend(k)\n                keywordsKnown.extend([str(k[0]).lower()])\n        self.fyi(\"keywordsKnown: %s\" % keywordsKnown)\n        # FIXME: only using first keyword here!\n        if not strict_match:\n            keywords_partial = []\n            kl = len(keywords[0])\n            if kl > 3:\n                for K in keywordsKnown:\n                    if K[0:kl] == keywords[0]:\n                        if K not in keywords_partial:\n                            keywords_partial.append(K)\n            # Try fuzzy search only if no direct matches\n            keywords_fuzzy = []\n            if not len(keywords_partial):\n                keywords_fuzzy = difflib.get_close_matches(keywords[0], keywordsKnown, n=1, cutoff=0.6)\n            self.fyi(\"  keywords_partial %s\" % keywords_partial)\n            self.fyi(\"  keywords_fuzzy %s\" % keywords_fuzzy)\n            keywords = list(set(keywords_partial + keywords_fuzzy))\n        self.fyi(\"nota.find_by_keyword() later, keywords: %s\" % keywords)\n        noteIds = []\n        for keyword in keywords:\n            self.fyi(\"keyword: %s\" % keyword)\n            if strict_match:\n                self.fyi(\"strict match on keyword '%s'\" % keyword)\n                try:\n                    keywordId = self.con.execute(\"SELECT keywordId FROM keyword WHERE keyword=?;\",\n                            [keyword]).fetchone()\n                except:\n                    self.error(\"cannot look up keyword '%s'\" % [keyword])\n            else:\n                self.fyi(\"non-strict match on keyword '%s'\" % keyword)\n                try:\n                    keywordId = []\n                    for k in self.cur.execute(\"SELECT keywordId FROM keyword WHERE keyword=? COLLATE NOCASE;\", [keyword]).fetchall():\n                        keywordId.extend(k)\n                except:\n                    self.error(\"cannot look up keyword '%s'\" % [keyword])\n            try:\n                if len(keywordId):\n                    self.fyi(\"looking for noteID matches to keywordId %s\" % keywordId)\n                    for k in keywordId:\n                        self.fyi(\"k: %s\" % k)\n                        try:\n                            if strict_match:\n                                noteIdtest = self.cur.execute(\"SELECT noteId FROM notekeyword WHERE keywordId=?;\", [k])\n                            else:\n                                noteIdtest = self.cur.execute(\"SELECT noteId FROM notekeyword WHERE keywordId=? COLLATE NOCASE;\", [k])\n                        except:\n                            self.error(\"cannot query database to find noteId corresponding to keywordId value %s\" % [k])\n                        for noteId in noteIdtest:\n                            self.fyi(\"got match to noteID %s\" % noteId)\n                            if noteId not in noteIds:\n                                noteIds.append(noteId)\n                                self.fyi(\"adding to list\")\n                            else:\n                                self.fyi(\"already in list\")\n                        self.fyi(\"done with keyword %s\" % k)\n                else:\n                    pass\n            except:\n                #20150314 self.error(\"problem finding keyword or note in database\")\n                #20150314 shouldn't be an error to not find a note!\n                pass\n        ## convert from hash to ids. Note that one hash may create several ids.\n        self.fyi(\"noteIds: %s\" % noteIds)\n        ## Find IDs of just the notes with the proper book value\n        noteIds2 = []\n        self.fyi(\"ORIGINAL noteIds: %s\" % noteIds)\n        for n in noteIds:\n            self.fyi(\"n=%s\" % n)\n            try:\n                row = self.cur.execute(\"SELECT noteId, book FROM note WHERE noteID=?;\", n).fetchone()\n            except:\n                self.error(\"cannot look up noteId %s\" % n)\n            self.fyi(\"row %s; book=%s\" % (row, book))\n            if book < 0 or row[1] == book:\n                self.fyi(\"appending id %s\" % row[0])\n                noteIds2.append((row[0],))\n            else:\n                self.fyi(\"skipping id %s because book is wrong\" % row[0])\n        noteIds = noteIds2\n        #self.fyi(\"  LATER    noteIds2: %s\" % noteIds2)\n        #self.fyi(\"  LATER    noteIds: %s\" % noteIds)\n        rval = []\n        for n in noteIds:\n            #self.fyi(\" processing id=%s\" % n)\n            try:\n                note = self.cur.execute(\"SELECT noteId, authorId, date, title, content, due, privacy, modified, hash, book FROM note WHERE noteId=?;\", n).fetchone()\n            except:\n                self.warning(\"Problem extracting note %s from database\" % n)\n                next\n            if note:\n                date = note[2]\n                due = note[5]\n                privacy = note[6]\n                keywordIds = []\n                keywordIds.extend(self.con.execute(\"SELECT keywordid FROM notekeyword WHERE notekeyword.noteid=?;\", n))\n                keywords = []\n                for k in keywordIds:\n                    keywords.append(self.cur.execute(\"SELECT keyword FROM keyword WHERE keywordId=?;\", k).fetchone()[0])\n                rval.append({\"noteId\":note[0], \"title\":note[3], \"keywords\":keywords,\n                    \"content\":note[4], \"due\":note[5], \"privacy\":note[6],\n                    \"date\":note[2], \"modified\":note[7], \"hash\":note[8], \"book\":note[9]})\n        return rval", "response": "Search notes for a given keyword"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_recent(self, nrecent=4):\n        '''Find recent non-trashed notes'''\n        try:\n            rows = self.cur.execute(\"SELECT noteId FROM note WHERE book > 0 ORDER BY date DESC LIMIT %d;\"%nrecent).fetchall()\n        except:\n            self.error(\"nota.find_recent() cannot look up note list\")\n        # Possibly save time by finding IDs first.\n        noteIds = []\n        for r in rows:\n            noteIds.append(r[0],)\n        self.fyi(\"noteIds: %s\" % noteIds)\n        rval = []\n        for n in noteIds:\n            note = None\n            try:\n                note = self.cur.execute(\"SELECT noteId, date, title, content, hash, book FROM note WHERE noteId = ?;\", [n]).fetchone()\n            except:\n                self.warning(\"Problem extracting note %s from database for recent-list\" % n)\n                next\n            if note:\n                keywordIds = []\n                keywordIds.extend(self.con.execute(\"SELECT keywordid FROM notekeyword WHERE notekeyword.noteid=?;\", [n]))\n                keywords = []\n                for k in keywordIds:\n                    keywords.append(self.cur.execute(\"SELECT keyword FROM keyword WHERE keywordId=?;\", k).fetchone()[0])\n                rval.append({\"noteId\":note[0], \"date\":note[1], \"title\":note[2], \"keywords\":keywords,\n                    \"content\":note[3], \"hash\":note[4], \"book\":note[5]})\n        return rval", "response": "Find recent non - trashed notes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_request(self, resource, params=None):\n        return super(VideoApi, self).make_request('video/%s' % resource, params)", "response": "Make a request to the API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _cosmoid_request(self, resource, cosmoid, **kwargs):\n\n        params = {\n            'cosmoid': cosmoid,\n        }\n        params.update(kwargs)\n\n        return self.make_request(resource, params)", "response": "This method is used to make a request to the specified resource with the given cosmoid value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef season_info(self, cosmoid, season, **kwargs):\n\n        resource = 'season/%d/info' % season\n        return self._cosmoid_request(resource, cosmoid, **kwargs)\n\n        params = {\n            'cosmoid': cosmoid,\n        }\n        params.update(kwargs)\n\n        return self.make_request(resource, params)", "response": "Returns information about a season of a TV"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef episode_info(self, cosmoid, season, episode, **kwargs):\n\n        resource = 'season/%d/episode/%d/info' % (season, episode)\n\n        return self._cosmoid_request(resource, cosmoid, **kwargs)", "response": "Returns information about an episode in a television series"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload a wav file into an array of floats.", "response": "def _load_zip_wav(zfile, offset=0, count=None):\n    \"\"\"Load a wav file into an array from frame start to fram end\n\n    :param zfile: ZipExtFile file-like object from where to load the audio\n    :param offset: First sample to load\n    :param count: Maximum number of samples to load\n    :return: The audio samples in a numpy array of floats\n    \"\"\"\n\n    buf = StringIO.StringIO(zfile.read())\n\n    sample_rate, audio = wavfile.read(buf)\n    audio = audio[offset:]\n\n    if count:\n        audio = audio[:count]\n\n    return sample_rate, audio"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_edit_scripts(pron_a, pron_b, edit_costs=(1.0, 1.0, 1.0)):\n    op_costs = {'insert': lambda x: edit_costs[0],\n                'match': lambda x, y: 0 if x == y else edit_costs[1],\n                'delete': lambda x: edit_costs[2]}\n\n    distance, scripts, costs, ops = edit_distance.best_transforms(pron_a, pron_b, op_costs=op_costs)\n\n    return [full_edit_script(script.to_primitive()) for script in scripts]", "response": "Get the edit scripts to transform between two pronunciations."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting an edit script to a pair of strings representing the operation in a human readable way.", "response": "def edit_script_to_strings(edit_script, use_colors=True):\n    \"\"\"Convert an edit script to a pair of strings representing the operation in a human readable way.\n\n    :param edit_script: The edit script as a list of operations, where each operation is a dictionary.\n    :param use_colors: Boolean indicating whether to use terminal color codes to color the output.\n    :return: Tuple with text corresponding to the first pronunciation and the text of the second one.\n    \"\"\"\n    colors = collections.defaultdict(str)\n\n    if use_colors:\n        colors['red'] = '\\x1b[31m'\n        colors['normal'] = '\\x1b[m'\n        colors['green'] = '\\x1b[32m'\n        colors['on_red'] = '\\x1b[41m'\n\n    src_txt = ''\n    dst_txt = ''\n    for op in edit_script:\n        if op['op_code'] == 'match':\n            width = max(len(op['from_symbol']), len(op['to_symbol']))\n            if op['from_symbol'] == op['to_symbol']:\n                src_txt += '{green}{from_symbol: ^{width}}{normal}'.format(**_combine_dicts(colors,\n                                                                                            op,\n                                                                                            {'width': width}))\n                dst_txt += '{green}{to_symbol: ^{width}}{normal}'.format(**_combine_dicts(colors,\n                                                                                          op,\n                                                                                          {'width': width}))\n            else:\n                src_txt += '{red}{from_symbol: ^{width}}{normal}'.format(**_combine_dicts(colors,\n                                                                                          op,\n                                                                                          {'width': width}))\n                dst_txt += '{red}{to_symbol: ^{width}}{normal}'.format(**_combine_dicts(colors,\n                                                                                        op,\n                                                                                        {'width': width}))\n\n        elif op['op_code'] == 'insert':\n            space = ' '*len(op['to_symbol'])\n            src_txt += '{on_red}{space}{normal}'.format(space=space, **_combine_dicts(colors,  op))\n            dst_txt += '{red}{to_symbol}{normal}'.format(**_combine_dicts(colors, op))\n\n        elif op['op_code'] == 'delete':\n            space = ' '*len(op['from_symbol'])\n            src_txt += '{red}{from_symbol}{normal}'.format(**_combine_dicts(colors, op))\n            dst_txt += '{on_red}{space}{normal}'.format(space=space, **_combine_dicts(colors, op))\n\n        elif op['op_code'] == 'noninsert':\n            continue\n\n        src_txt += ' '\n        dst_txt += ' '\n\n    return src_txt, dst_txt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nproviding the default prediction of the where task.", "response": "def _where_default(self, pronunciation):\n        \"\"\"Provide the default prediction of the where task.\n\n        This function is used to predict the probability of a given pronunciation being reported for a given token.\n\n        :param pronunciation: The list or array of confusion probabilities at each index\n        \"\"\"\n\n        token_default = self['metadata']['token_default']['where']\n\n        index_count = 2*len(pronunciation) + 1\n        confusion_probability = [token_default[i % 2] for i in range(index_count)]\n\n        return confusion_probability"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprovides the default prediction of the what task.", "response": "def _what_default(self, pronunciation):\n        \"\"\"Provide the default prediction of the what task.\n\n        This function is used to predict the probability of a given pronunciation being reported for a given token.\n\n        :param pronunciation: The list or array of confusion probabilities at each index\n        \"\"\"\n\n        token_default = self['metadata']['token_default']['what']\n        index_count = 2*len(pronunciation) + 1\n\n        predictions = {}\n        for i in range(index_count):\n            index_predictions = {}\n\n            if i % 2 == 0:\n                index_predictions.update(token_default['0'])\n\n            else:\n                presented_phoneme = pronunciation[int((i-1)/2)]\n                index_predictions[presented_phoneme] = token_default['1']['=']\n                index_predictions['*'] = token_default['1']['*']\n                index_predictions[''] = token_default['1']['']\n\n            predictions['{}'.format(i)] = index_predictions\n\n        return predictions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nproviding the default prediction of the where task.", "response": "def _full_default(self, pronunciation):\n        \"\"\"Provide the default prediction of the where task.\n\n        This function is used to predict the probability of a given pronunciation being reported for a given token.\n\n        :param pronunciation: The pronunciation of the token\n        \"\"\"\n\n        token_default = self['metadata']['token_default']['full']\n\n        key = pronunciation\n        if isinstance(key, list):\n            if not all([isinstance(phoneme, basestring) for phoneme in key]):\n                raise ValueError('The pronunciation must be of type string (a sequence of space separated phonemes) '\n                                 'or of type list (containing phonemes of type strings).'\n                                 'User supplied: {}'.format(key))\n\n            key = ' '.join(pronunciation)\n\n        predictions = {key: token_default['='],\n                       '*': token_default['*']}\n\n        return predictions"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef where_task(self, token_id, presented_pronunciation, confusion_probability):\n        self['tokens'].setdefault(token_id, {}) \\\n            .setdefault('where', self._where_default(presented_pronunciation))\n\n        if confusion_probability is not None:\n            self['tokens'][token_id]['where'] = list(confusion_probability)", "response": "Provide the prediction of the where task."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef what_task(self, token_id, presented_pronunciation, index, phonemes, phonemes_probability,\n                  warn=True, default=True):\n        \"\"\"Provide the prediction of the what task.\n\n        This function is used to predict the probability of a given phoneme being reported at a given index\n        for a given token.\n\n        :param token_id: The token for which the prediction is provided\n        :param index: The index of the token for which the prediction is provided\n        :param phonemes: The phoneme or phoneme sequence for which the prediction is being made\n        (as a space separated string)\n        :param phonemes_probability: The probability of the phoneme or phoneme sequence\n        :param warn: Set to False in order to avoid warnings about 0 or 1 probabilities\n        :param default: Set to False in order to avoid generating the default probabilities\n        \"\"\"\n\n        if phonemes_probability is not None and not 0. < phonemes_probability < 1. and warn:\n            logging.warning('Setting a probability of [{}] to phonemes [{}] for token [{}].\\n '\n                            'Using probabilities of 0.0 or 1.0 '\n                            'may lead to likelihoods of -Infinity'.format(phonemes_probability,\n                                                                          phonemes,\n                                                                          token_id))\n\n        default_preds = self._what_default(presented_pronunciation) if default else {}\n\n        self['tokens'].setdefault(token_id, {}) \\\n            .setdefault('what', default_preds)\n\n        if index is not None:\n            self['tokens'][token_id]['what'].setdefault(str(index), {})\n\n        if phonemes is not None:\n            if phonemes_probability is not None and index is not None:\n                self['tokens'][token_id]['what'][str(index)][phonemes] = phonemes_probability\n\n            else:\n                if index is not None:\n                    if phonemes in default_preds[str(index)]:\n                        self['tokens'][token_id]['what'][str(index)][phonemes] = default_preds[str(index)][phonemes]\n                    else:\n                        self['tokens'][token_id]['what'][str(index)].pop(phonemes)\n\n                else:\n                    if str(index) in default_preds:\n                        self['tokens'][token_id]['what'][str(index)] = default_preds[str(index)]\n                    else:\n                        self['tokens'][token_id]['what'].pop(str(index))", "response": "This function provides the prediction of the what task."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef full_task(self, token_id, presented_pronunciation, pronunciation, pronunciation_probability,\n                  warn=True, default=True):\n        \"\"\"Provide the prediction of the full task.\n\n        This function is used to predict the probability of a given pronunciation being reported for a given token.\n\n        :param token_id: The token for which the prediction is provided\n        :param pronunciation: The pronunciation for which the prediction is being made (as a list of strings\n        or space separated string)\n        :param pronunciation_probability: The probability of the pronunciation for the given token\n        :param warn: Set to False in order to avoid warnings about 0 or 1 probabilities\n        :param default: Set to False in order to avoid generating the default probabilities\n        \"\"\"\n\n        if pronunciation_probability is not None and not 0. < pronunciation_probability < 1. and warn:\n            logging.warning('Setting a probability of [{}] to pronunciation [{}] for token [{}].\\n '\n                            'Using probabilities of 0.0 or 1.0 '\n                            'may lead to likelihoods of -Infinity'.format(pronunciation_probability,\n                                                                          pronunciation,\n                                                                          token_id))\n\n        key = pronunciation\n        if isinstance(key, list):\n            if not all([isinstance(phoneme, basestring) for phoneme in key]):\n                raise ValueError('The pronunciation must be of type string (a sequence of space separated phonemes) '\n                                 'or of type list (containing phonemes of type strings).'\n                                 'User supplied: {}'.format(key))\n\n            key = ' '.join(pronunciation)\n\n        default_preds = self._full_default(presented_pronunciation) if default else {}\n\n        self['tokens'].setdefault(token_id, {}) \\\n            .setdefault('full', default_preds)\n\n        if key is not None:\n            if pronunciation_probability is not None:\n                self['tokens'][token_id]['full'][key] = pronunciation_probability\n\n            else:\n                if key in default_preds:\n                    self['tokens'][token_id]['full'][key] = default_preds[key]\n\n                else:\n                    self['tokens'][token_id]['full'].pop(key)", "response": "This function provides the prediction of the full task for a given token."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads the submission from a file - like object.", "response": "def load(fileobj):\n        \"\"\"Load the submission from a file-like object\n\n        :param fileobj: File-like object\n        :return: the loaded submission\n        \"\"\"\n        with gzip.GzipFile(fileobj=fileobj, mode='r') as z:\n            submission = Submission(metadata=json.loads(z.readline()))\n\n            for line in z:\n                token_id, token = json.loads(line)\n                submission['tokens'][token_id] = token\n\n        return submission"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_metadata(fileobj):\n        with gzip.GzipFile(fileobj=fileobj, mode='r') as z:\n            return json.loads(z.readline())", "response": "Load the submission from a file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef submit(self, password=''):\n\n        url = '{}/api/submit'.format(BASE_URL)\n        try:\n            r = requests.post(url,\n                              data=self.dumps(),\n                              headers={'content-type': 'application/json'},\n                              auth=(self['metadata']['email'], password))\n\n            response = r.json()\n\n        except requests.exceptions.HTTPError as e:\n            logging.error('Error while submitting the participation. {}'.format(e))\n            return Job()\n\n        if 'error' in response:\n            logging.error('Error while processing the participation. {}'.format(response['error']))\n            return Job()\n\n        return Job(response)", "response": "Submits the participation to the web site."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nevaluating the development set.", "response": "def evaluate(self, password=''):\n        \"\"\"Evaluates the development set.\n\n        The passwords is sent as plain text.\n\n        :return: the evaluation results.\n        \"\"\"\n\n        # Make a copy only keeping the development set\n        dev_submission = self\n        if self['metadata'].get('evaluation_setting', {}).get('development_set', None):\n            dev_submission = copy.deepcopy(self)\n            dev_submission['tokens'] = {token_id: token for token_id, token in self['tokens'].items()\n                                        if token_id in self['metadata']['evaluation_setting']['development_set']}\n\n        url = '{}/api/evaluate'.format(BASE_URL)\n        try:\n            r = requests.post(url,\n                              data=dev_submission.dumps(),\n                              headers={'content-type': 'application/json'},\n                              auth=(dev_submission['metadata']['email'], password))\n\n            response = r.json()\n\n        except requests.exceptions.HTTPError as e:\n            logging.error('Error while submitting the participation. {}'.format(e))\n            return Job()\n\n        if 'error' in response:\n            logging.error('Error while processing the participation. {}'.format(response['error']))\n            return Job()\n\n        return Job(response)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef author_mail_from_git(self):\n        try:\n            # launch git command and get answer\n            cmd = Popen([\"git\", \"config\", \"--get\", \"user.email\"], stdout=PIPE)\n            stdoutdata = cmd.communicate()\n            if (stdoutdata[0]):\n                self.author_mail = stdoutdata[0].rstrip(os.linesep)\n        except ImportError:\n            pass\n        except CalledProcessError:\n            pass\n        except OSError:\n            pass\n\n        return self.author_mail", "response": "Get the author mail from git information."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef author_mail_from_system(self):\n        self.author_mail = getpass.getuser() + '@' + socket.gethostname()\n        return self.author_mail", "response": "Get the author mail from system information."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a new object from the given input protocol and returns the object.", "response": "def read(cls, iprot):\n        '''\n        Read a new object from the given input protocol and return the object.\n\n        :type iprot: thryft.protocol._input_protocol._InputProtocol\n        :rtype: pastpy.gen.database.impl.online.online_database_object_detail_image.OnlineDatabaseObjectDetailImage\n        '''\n\n        init_kwds = {}\n\n        iprot.read_struct_begin()\n        while True:\n            ifield_name, ifield_type, _ifield_id = iprot.read_field_begin()\n            if ifield_type == 0:  # STOP\n                break\n            elif ifield_name == 'full_size_url':\n                init_kwds['full_size_url'] = iprot.read_string()\n            elif ifield_name == 'mediaid':\n                init_kwds['mediaid'] = iprot.read_string()\n            elif ifield_name == 'objectid':\n                init_kwds['objectid'] = iprot.read_string()\n            elif ifield_name == 'src':\n                init_kwds['src'] = iprot.read_string()\n            elif ifield_name == 'thumbnail_url':\n                init_kwds['thumbnail_url'] = iprot.read_string()\n            elif ifield_name == 'title':\n                init_kwds['title'] = iprot.read_string()\n            elif ifield_name == 'type':\n                init_kwds['type'] = pastpy.gen.database.impl.online.online_database_object_detail_image_type.OnlineDatabaseObjectDetailImageType.value_of(iprot.read_string().strip().upper())\n            iprot.read_field_end()\n        iprot.read_struct_end()\n\n        return cls(**init_kwds)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting the object to the given protocol and returns the object.", "response": "def write(self, oprot):\n        '''\n        Write this object to the given output protocol and return self.\n\n        :type oprot: thryft.protocol._output_protocol._OutputProtocol\n        :rtype: pastpy.gen.database.impl.online.online_database_object_detail_image.OnlineDatabaseObjectDetailImage\n        '''\n\n        oprot.write_struct_begin('OnlineDatabaseObjectDetailImage')\n\n        oprot.write_field_begin(name='full_size_url', type=11, id=None)\n        oprot.write_string(self.full_size_url)\n        oprot.write_field_end()\n\n        oprot.write_field_begin(name='mediaid', type=11, id=None)\n        oprot.write_string(self.mediaid)\n        oprot.write_field_end()\n\n        oprot.write_field_begin(name='objectid', type=11, id=None)\n        oprot.write_string(self.objectid)\n        oprot.write_field_end()\n\n        oprot.write_field_begin(name='src', type=11, id=None)\n        oprot.write_string(self.src)\n        oprot.write_field_end()\n\n        oprot.write_field_begin(name='thumbnail_url', type=11, id=None)\n        oprot.write_string(self.thumbnail_url)\n        oprot.write_field_end()\n\n        oprot.write_field_begin(name='title', type=11, id=None)\n        oprot.write_string(self.title)\n        oprot.write_field_end()\n\n        oprot.write_field_begin(name='type', type=11, id=None)\n        oprot.write_string(str(self.type))\n        oprot.write_field_end()\n\n        oprot.write_field_stop()\n\n        oprot.write_struct_end()\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprovides basic content negotiation and returns a view method based on the best match of content types as indicated in formats. :param formats: dictionary of content types and corresponding methods :param default_type: string the decorated method is the return type for. Example usage:: def rdf_view(request, arg): return RDF_RESPONSE @content_negotiation({'application/rdf+xml': rdf_view}) def html_view(request, arg): return HTML_RESPONSE The above example would return the rdf_view on a request type of ``application/rdf+xml`` and the normal view for anything else. Any :class:`django.http.HttpResponse` returned by the view method chosen by content negotiation will have a 'Vary: Accept' HTTP header added. **NOTE:** Some web browsers do content negotiation poorly, requesting ``application/xml`` when what they really want is ``application/xhtml+xml`` or ``text/html``. When this type of Accept request is detected, the default type will be returned rather than the best match that would be determined by parsing the Accept string properly (since in some cases the best match is ``application/xml``, which could return non-html content inappropriate for display in a web browser).", "response": "def content_negotiation(formats, default_type='text/html'):\n    \"\"\"\n    Provides basic content negotiation and returns a view method based on the\n    best match of content types as indicated in formats.\n\n    :param formats: dictionary of content types and corresponding methods\n    :param default_type: string the decorated method is the return type for.\n\n    Example usage::\n\n        def rdf_view(request, arg):\n            return RDF_RESPONSE\n\n        @content_negotiation({'application/rdf+xml': rdf_view})\n        def html_view(request, arg):\n            return HTML_RESPONSE\n\n    The above example would return the rdf_view on a request type of\n    ``application/rdf+xml`` and the normal view for anything else.\n\n    Any :class:`django.http.HttpResponse` returned by the view method chosen\n    by content negotiation will have a 'Vary: Accept' HTTP header added.\n\n    **NOTE:** Some web browsers do content negotiation poorly, requesting\n    ``application/xml`` when what they really want is ``application/xhtml+xml`` or\n    ``text/html``.  When this type of Accept request is detected, the default type\n    will be returned rather than the best match that would be determined by parsing\n    the Accept string properly (since in some cases the best match is\n    ``application/xml``, which could return non-html content inappropriate for\n    display in a web browser).\n    \"\"\"    \n    def _decorator(view_method):\n        @wraps(view_method)\n        def _wrapped(request, *args, **kwargs):\n            # Changed this to be a value passed as a method argument defaulting\n            # to text/html instead so it's more flexible.\n            # default_type = 'text/html'  # If not specificied assume HTML request.\n\n            # Add text/html for the original method if not already included.\n            if default_type not in formats:\n                formats[default_type] = view_method\n\n            try:\n                req_type = request.META['HTTP_ACCEPT']\n                \n                # If this request is coming from a browser like that, just\n                # give them our default type instead of honoring the actual best match\n                # (see note above for more detail)\n                if '*/*' in req_type:\n                    req_type = default_type\n                    \n            except KeyError:\n                req_type = default_type\n\n            # Get the best match for the content type requested.\n            content_type = mimeparse.best_match(formats.keys(),\n                                                req_type)\n                                                \n            # Return the view matching content type or the original view\n            # if no match.\n            if not content_type or content_type not in formats:\n                response = view_method(request, *args, **kwargs)\n            else:\n                response = formats[content_type](request, *args, **kwargs)\n\n            # set a Vary header to indicate content may vary based on Accept header            \n            if isinstance(response, HttpResponse):    # views should return HttpResponse objects, but check to be sure\n                # note: using the same utility method used by django's vary_on_headers decorator\n                patch_vary_headers(response, ['Accept'])\n            return response\n        return _wrapped\n    return _decorator"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming one expensive computation cooperatively with any other iterator passed into twisted s cooperate then use it s result to pass into the second computation.", "response": "def do_less_expensive_things(number):\n    \"\"\"\n    Perform one expensive computation cooperatively with any\n     other iterator passed into twisted's cooperate, then\n     use it's result to pass into the second computation.\n\n    :param number:\n    :return:\n    \"\"\"\n    result = yield batch_accumulate(1000, expensive(number))\n    total = reduce(add, result, 0)\n    log.msg(\"only for {}: {}\".format(number, total))\n    defer.returnValue(total)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _captcha_form(self):\n        try:\n            last_attempt = FailedAccessAttempt.objects.get(\n                ip_address=self._ip,\n                is_locked=True,\n                captcha_enabled=True,\n                is_expired=False\n\n            )\n        except FailedAccessAttempt.DoesNotExist:\n            last_attempt = None\n            self.required = False\n            self.widget = HiddenInput()\n\n        if last_attempt:\n            self._last_attempt = last_attempt\n\n            if last_attempt.is_locked:\n                self.required = True\n                self.widget = ReCaptcha(\n                    public_key=self.public_key, use_ssl=self.use_ssl, attrs=self.attrs\n                )", "response": "Form the captcha page."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sync_one(self, aws_syncr, amazon, route):\n        route_info = amazon.route53.route_info(route.name, route.zone)\n        target = route.record_target\n        if callable(target):\n            target = target(amazon)\n\n        if not route_info:\n            amazon.route53.create_route(route.name, route.zone, route.record_type, target)\n        else:\n            amazon.route53.modify_route(route_info, route.name, route.zone, route.record_type, target)", "response": "Make sure this role exists and has only what policies we want it to have"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nturning a FrameFunction into an Animation.", "response": "def animation(frame_function: types.FrameFunction) -> types.Animation:\n    \"\"\"Turn a FrameFunction into an Animation.\n\n    Args:\n        frame_function: A function that returns a FrameGenerator.\n\n    Returns:\n        an Animation decorator function.\n    \"\"\"\n    animation_ = core.Animation(frame_function)\n\n    @functools.wraps(frame_function)\n    def wrapper(*args, **kwargs):\n        return animation_(*args, **kwargs)\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef animate(func: types.AnyFunction = None,\n            *,\n            animation: types.AnimationGenerator = _default_animation(),\n            step: float = 0.1) -> types.AnyFunction:\n    \"\"\"Wrapper function for the _Animate wrapper class.\n    \n    Args:\n        func: A function to run while animation is showing.\n        animation: An AnimationGenerator that yields animation frames.\n        step: Approximate timestep (in seconds) between frames.\n    Returns:\n        An animated version of func if func is not None. Otherwise, a function\n        that takes a function and returns an animated version of that.\n    \"\"\"\n    if callable(func):\n        return _animate_no_kwargs(func, animation, step)\n    elif func is None:\n        return _animate_with_kwargs(animation_gen=animation, step=step)\n    else:\n        raise TypeError(\"argument 'func' must either be None or callable\")", "response": "Wrapper function for the _Animate wrapper class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef multiline_frame_function(frame_function: types.FrameFunction,\n                             height: int,\n                             offset: int = 0,\n                             *args,\n                             **kwargs) -> types.FrameGenerator:\n    \"\"\"Multiline a singlelined frame function. Simply chains several frame\n    generators together, and applies the specified offset to each one.\n\n    Args:\n        frame_function: A function that returns a singleline FrameGenerator.\n        height: The amount of frame generators to stack vertically (determines\n        the height in characters).\n        offset: An offset to apply to each successive generator. If the offset\n        is 2, then the first generator starts at frame 0, the second at frame\n        2, the third at frame 4, and so on.\n\n    Returns:\n        a multiline version fo the generator returned by frame_function\n    \"\"\"\n    frame_generators = []\n    for i in range(height):\n        frame_generators.append(frame_function(*args, **kwargs))\n        for _ in range(i * offset):  # advance animation\n            frame_generators[i].__next__()\n    frame_gen = concatechain(*frame_generators, separator='\\n')\n    yield from frame_gen", "response": "A function that returns a single frame generator."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connected_components(image, connectivity=2, background=None):\n    # Work around skimage.measure.label behaviour in version 0.12 and higher\n    # treats all 0 pixels as background even if \"background\" argument is set\n    # to None.\n    if background is None:\n        image[np.where(image == 0)] = np.max(image) + 1\n\n    ar = skimage.measure.label(image, connectivity=connectivity,\n                               background=background)\n\n    # The :class:`jicbioimage.core.image.SegmentedImage` assumes that zero is\n    # background.  So we need to change the identifier of any pixels that are\n    # marked as zero if there is no background in the input image.\n    if background is None:\n        ar[np.where(ar == 0)] = np.max(ar) + 1\n    else:\n        if np.min(ar) == -1:\n            # Work around skimage.measure.label behaviour pre version 0.12.\n            # Pre version 0.12 the background in skimage was labeled -1 and the\n            # first component was labelled with 0.\n            # The jicbioimage.core.image.SegmentedImage assumes that the\n            # background is labelled 0.\n            ar[np.where(ar == 0)] = np.max(ar) + 1\n            ar[np.where(ar == -1)] = 0\n\n    segmentation = SegmentedImage.from_array(ar)\n    return segmentation", "response": "Return the connected components of the image."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a segmented image with the given seeds.", "response": "def watershed_with_seeds(image, seeds, mask=None):\n    \"\"\"Return :class:`jicbioimage.core.image.SegmentedImage`.\n\n    :param image: input :class:`jicbioimage.core.image.Image`\n    :param seeds: numpy.ndarray of same shape as image,\n                  each seed needs to be a unique integer\n    :param mask: bool numpy.ndarray of same shape as image,\n                 only regions that are marked as True will be labelled\n    :returns: :class:`jicbioimage.core.image.SegmentedImage`\n    \"\"\"\n    ar = skimage.morphology.watershed(-image, seeds, mask=mask)\n    segmentation = SegmentedImage.from_array(ar)\n    return segmentation"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the region of interest corresponding to the supplied identifier.", "response": "def region_by_identifier(self, identifier):\n        \"\"\"Return region of interest corresponding to the supplied identifier.\n\n        :param identifier: integer corresponding to the segment of interest\n        :returns: `jicbioimage.core.region.Region`\n        \"\"\"\n\n        if identifier < 0:\n            raise(ValueError(\"Identifier must be a positive integer.\"))\n\n        if not np.equal(np.mod(identifier, 1), 0):\n            raise(ValueError(\"Identifier must be a positive integer.\"))\n\n        if identifier == 0:\n            raise(ValueError(\"0 represents the background.\"))\n\n        return Region.select_from_array(self, identifier)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmerges two regions into one.", "response": "def merge_regions(self, id1, id2):\n        \"\"\"Merge two regions into one.\n\n        The merged region will take on the id1 identifier.\n\n        :param id1: region 1 identifier\n        :param id2: region 2 identifier\n        \"\"\"\n        region2 = self.region_by_identifier(id2)\n        self[region2] = id1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef task2ics():\n    from argparse import ArgumentParser, FileType\n    from sys import stdout\n\n    parser = ArgumentParser(description='Converter from Taskwarrior to iCalendar syntax.')\n    parser.add_argument('indir', nargs='?', help='Input Taskwarrior directory (default to ~/.task)', default=expanduser('~/.task'))\n    parser.add_argument('outfile', nargs='?', type=FileType('w'), default=stdout,\n                        help='Output iCalendar file (default: stdout)')\n    args = parser.parse_args()\n\n    task = IcsTask(args.indir)\n    args.outfile.write(task.to_vobject().serialize())", "response": "Command line tool to convert from Taskwarrior to iCalendar"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncommanding line tool to convert from iCalendar to Taskwarrior", "response": "def ics2task():\n    \"\"\"Command line tool to convert from iCalendar to Taskwarrior\"\"\"\n    from argparse import ArgumentParser, FileType\n    from sys import stdin\n\n    parser = ArgumentParser(description='Converter from iCalendar to Taskwarrior syntax.')\n    parser.add_argument('infile', nargs='?', type=FileType('r'), default=stdin,\n                        help='Input iCalendar file (default: stdin)')\n    parser.add_argument('outdir', nargs='?', help='Output Taskwarrior directory (default to ~/.task)', default=expanduser('~/.task'))\n    args = parser.parse_args()\n\n    vobject = readOne(args.infile.read())\n    task = IcsTask(args.outdir)\n    for todo in vobject.vtodo_list:\n        task.to_task(todo)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreload the Taskwarrior files if the mtime is newer", "response": "def _update(self):\n        \"\"\"Reload Taskwarrior files if the mtime is newer\"\"\"\n        update = False\n\n        with self._lock:\n            for fname in ['pending.data', 'completed.data']:\n                data_file = join(self._data_location, fname)\n                if exists(data_file):\n                    mtime = getmtime(data_file)\n                    if mtime > self._mtime:\n                        self._mtime = mtime\n                        update = True\n\n            if update:\n                self._tasks = {}\n                tasklist = loads(run(['task', 'rc.verbose=nothing', 'rc.hooks=off', 'rc.data.location={self._data_location}'.format(**locals()), 'export'], stdout=PIPE).stdout.decode('utf-8'))\n                for task in tasklist:\n                    project = task['project'] if 'project' in task else 'unaffiliated'\n                    if project not in self._tasks:\n                        self._tasks[project] = {}\n                    self._tasks[project][task['uuid']] = task"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_vobjects(self, filename, uids=None):\n        self._update()\n\n        if not uids:\n            uids = self.get_uids(filename)\n\n        project = basename(filename)\n        items = []\n\n        for uid in uids:\n            vtodos = iCalendar()\n            uuid = uid.split('@')[0]\n            self._gen_vtodo(self._tasks[project][uuid], vtodos.add('vtodo'))\n            items.append((uid, vtodos, '\"%s\"' % self._tasks[project][uuid]['modified']))\n        return items", "response": "Return iCal objects and etags of all Taskwarrior entries in uids"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_vobject(self, project=None, uid=None):\n        self._update()\n        vtodos = iCalendar()\n\n        if uid:\n            uid = uid.split('@')[0]\n            if not project:\n                for p in self._tasks:\n                    if uid in self._tasks[p]:\n                        project = p\n                        break\n            self._gen_vtodo(self._tasks[basename(project)][uid], vtodos.add('vtodo'))\n        elif project:\n            for task in self._tasks[basename(project)].values():\n                self._gen_vtodo(task, vtodos.add('vtodo'))\n        else:\n            for project in self._tasks:\n                for task in self._tasks[project].values():\n                    self._gen_vtodo(task, vtodos.add('vtodo'))\n\n        return vtodos", "response": "Return vObject object of Taskwarrior tasks."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding or modify a task from a vTodo object to Taskwarrior s base record.", "response": "def to_task(self, vtodo, project=None, uuid=None):\n        \"\"\"Add or modify a task from vTodo to Taskwarrior\n        vtodo -- the vTodo to add\n        project -- the project to add (see get_filesnames() as well)\n        uuid -- the UID of the task in Taskwarrior\n        \"\"\"\n        task = {}\n\n        if project and project != 'all_projects' and project != 'unaffiliated':\n            task['project'] = project\n\n        if uuid:\n            task['uuid'] = uuid\n\n        if hasattr(vtodo, 'dtstamp'):\n            task['entry'] = self._tw_timestamp(vtodo.dtstamp.value)\n\n        if hasattr(vtodo, 'last_modified'):\n            task['modified'] = self._tw_timestamp(vtodo.last_modified.value)\n\n        if hasattr(vtodo, 'dtstart'):\n            task['start'] = self._tw_timestamp(vtodo.dtstart.value)\n\n        if hasattr(vtodo, 'due'):\n            task['due'] = self._tw_timestamp(vtodo.due.value)\n\n        if hasattr(vtodo, 'completed'):\n            task['end'] = self._tw_timestamp(vtodo.completed.value)\n\n        task['description'] = vtodo.summary.value\n\n        if hasattr(vtodo, 'categories'):\n            task['tags'] = vtodo.categories.value\n\n        if hasattr(vtodo, 'priority'):\n            priority = int(vtodo.priority.value)\n            if priority < 3:\n                task['priority'] = 'H'\n            elif 3 < priority < 7:\n                task['priority'] = 'M'\n            else:\n                task['priority'] = 'L'\n\n        if hasattr(vtodo, 'description'):\n            task['annotations'] = []\n            for delta, comment in enumerate(vtodo.description.value.split('\\n')):\n                # Hack because Taskwarrior import doesn't accept multiple annotations with the same timestamp\n                stamp = self._tw_timestamp(vtodo.dtstamp.value + timedelta(seconds=delta))\n                if uuid in self._tasks.get(project, {}) and 'annotations' in self._tasks[project][uuid]:\n                    for annotation in self._tasks[project][uuid]['annotations']:\n                        if annotation['description'] == comment:\n                            stamp = annotation['entry']\n                            break\n                task['annotations'].append({'entry': stamp, 'description': comment})\n\n        if hasattr(vtodo, 'status'):\n            if vtodo.status.value == 'IN-PROCESS':\n                task['status'] = 'pending'\n                if 'start' not in task:\n                    task['start'] = self._tw_timestamp(vtodo.dtstamp.value)\n            elif vtodo.status.value == 'NEEDS-ACTION':\n                task['status'] = 'pending'\n            elif vtodo.status.value == 'COMPLETED':\n                task['status'] = 'completed'\n                if 'end' not in task:\n                    task['end'] = self._tw_timestamp(vtodo.dtstamp.value)\n            elif vtodo.status.value == 'CANCELLED':\n                task['status'] = 'deleted'\n                if 'end' not in task:\n                    task['end'] = self._tw_timestamp(vtodo.dtstamp.value)\n\n        json = dumps(task, separators=(',', ':'), sort_keys=True)\n        with self._lock:\n            p = run(['task', 'rc.verbose=nothing', 'rc.recurrence.confirmation=no', 'rc.data.location={self._data_location}'.format(**locals()), 'import', '-'], input=json, encoding='utf-8', stdout=PIPE)\n        uuid = findall('(?:add|mod)  ([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}) ', p.stdout)[0]\n        self._update()\n        return self._gen_uid(uuid)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of all Taskwarrior projects as virtual files in the data directory", "response": "def get_filesnames(self):\n        \"\"\"Return a list of all Taskwarrior projects as virtual files in the data directory\"\"\"\n        self._update()\n        projects = set(list(self._tasks.keys()) + self._task_projects + ['all_projects', 'unaffiliated'])\n        return [join(self._data_location, p.split()[0]) for p in projects]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of UIDs that are available for the current project", "response": "def get_uids(self, project=None):\n        \"\"\"Return a list of UIDs\n        project -- the Project to filter for\n        \"\"\"\n        self._update()\n\n        if not project or project.endswith('all_projects'):\n            return [self._gen_uid(task['uuid']) for project in self._tasks for task in self._tasks[project].values()]\n\n        if basename(project) not in self._tasks:\n            return []\n\n        return [self._gen_uid(uuid) for uuid in self._tasks[basename(project)]]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a task from vObject to Taskwarrior", "response": "def append_vobject(self, vtodo, project=None):\n        \"\"\"Add a task from vObject to Taskwarrior\n        vtodo -- the iCalendar to add\n        project -- the project to add (see get_filesnames() as well)\n        \"\"\"\n        if project:\n            project = basename(project)\n        return self.to_task(vtodo.vtodo, project)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove(self, uuid, project=None):\n        uuid = uuid.split('@')[0]\n        with self._lock:\n            run(['task', 'rc.verbose=nothing', 'rc.data.location={self._data_location}'.format(**locals()), 'rc.confirmation=no', uuid, 'delete'])", "response": "Remove a task from Taskwarrior"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef replace_vobject(self, uuid, vtodo, project=None):\n        self._update()\n        uuid = uuid.split('@')[0]\n        if project:\n            project = basename(project)\n        return self.to_task(vtodo.vtodo, project, uuid)", "response": "Replace the vObject with the UID of the vObject."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef move_vobject(self, uuid, from_project, to_project):\n        if to_project not in self.get_filesnames():\n            return\n\n        uuid = uuid.split('@')[0]\n        with self._lock:\n            run(['task', 'rc.verbose=nothing', 'rc.data.location={self._data_location}'.format(**locals()), 'rc.confirmation=no', uuid, 'modify', 'project:{}'.format(basename(to_project))])", "response": "Move the vobject from one project to another"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef merge(self, obj):\n        for attribute in dir(obj):\n            if '__' in attribute:\n                continue\n            setattr(self, attribute, getattr(obj, attribute))", "response": "This function merges another object s values with this instance s values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_layer(self, obj=None):\n        new_layer = Layer()\n        if obj:\n            new_layer.merge(obj)\n        self.layers.append(new_layer)", "response": "This function adds an empty layer to the layers list and optionally merges a given object into this layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_layer_from_py_file(self, filename):\n        if filename.endswith('.py'):\n            try:\n                path, filename = os.path.split(os.path.abspath(filename))\n                sys.path.append(path)\n                filename = filename.rsplit('.', 1)[0]\n                stack = __import__(filename, fromlist=['*'],)\n            except ImportError:\n                logging.info(\"Could not import stack from %s\" % filename)\n                return\n\n            self.add_layer()\n            for attribute in dir(stack):\n                setattr(self, attribute, getattr(stack, attribute))\n            sys.path.pop()\n            del sys.modules[filename]\n            del stack", "response": "This function implements loading a Python file and populating a new Layer with its contents."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_layer_from_yaml_file(self, filename):\n        if filename.endswith(('.yaml', '.yml')):\n            file_stream = None\n            try:\n                file_stream = open(os.path.abspath(filename), 'r')\n                stack = yaml.safe_load(file_stream)\n\n                self.add_layer()\n                for attribute in stack:\n                    setattr(self, attribute, stack[attribute])\n                del stack\n            except (TypeError, IOError):\n                logging.info(\"Could not import stack from %s\" % filename)\n            finally:\n                if file_stream:\n                    file_stream.close()", "response": "This function loads a YAML file and populates a new empty layer with its contents."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef luminance(mycolour):\n\n    colour_for_type = Colour()\n    if type(mycolour) is type(colour_for_type):\n        mycolour2 = mycolour\n    else:\n        try:\n            mycolour2 = Colour(mycolour)\n        except:\n            raise TypeError(\"Must supply a colourettu.Colour\")\n\n    (r1, g1, b1) = mycolour2.normalized_rgb()\n\n    return math.sqrt(0.299*math.pow(r1, 2) +\n                     0.587*math.pow(g1, 2) +\n                     0.114*math.pow(b1, 2))", "response": "r Returns the relative luminance of a colour."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef hex(self):\n        return \"#{:02x}{:02x}{:02x}\".format(self._r, self._g, self._b).upper()", "response": "Returns the HTML - style hex code for the Colour."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy_tree(src, dst):\n    for root, subdirs, files in os.walk(src):\n        current_dest = root.replace(src, dst)\n        if not os.path.exists(current_dest):\n            os.makedirs(current_dest)\n        for f in files:\n            shutil.copy(os.path.join(root, f), os.path.join(current_dest, f))", "response": "Copy directory tree src to dst"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninstall conda packages update = True", "response": "def install(self, update=False):\n        \"\"\"\n        install conda packages\n        \"\"\"\n        offline = self.offline or update\n        self.create_env(offline)\n        self.install_pkgs(offline)\n        self.install_pip(offline)\n        return tuple()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninstalls conda packages for the current instance of the class.", "response": "def install_pkgs(self, offline=False):\n        \"\"\"\n        TODO: maybe use conda as python package\n        \"\"\"\n        if not offline and self.pkgs:\n            self.logger.info(\"Installing conda packages ...\")\n            cmd = [join(self.anaconda_home, 'bin', 'conda')]\n            cmd.append('install')\n            # if offline:\n            #     cmd.append('--offline')\n            #     self.logger.info(\"... offline mode ...\")\n            if not self.newest:\n                cmd.append('--no-update-deps')\n                self.logger.info(\"... no update dependencies ...\")\n            if self.env:\n                self.logger.info(\"... in conda environment %s ...\", self.env)\n                cmd.extend(['-n', self.env])\n            cmd.append('--yes')\n            if self.no_pin:\n                cmd.append('--no-pin')\n                self.logger.info(\"... no pin ...\")\n            if self.channel_priority:\n                self.logger.info(\"... channel priority ...\")\n                cmd.append('--channel-priority')\n            if self.channels:\n                if self.override_channels:\n                    self.logger.info('... override channels ...')\n                    cmd.append('--override-channels')\n                self.logger.info(\"... with conda channels: %s ...\",\n                                 ', '.join(self.channels))\n                for channel in self.channels:\n                    cmd.append('-c')\n                    cmd.append(channel)\n            cmd.extend(self.pkgs)\n            try:\n                self.logger.debug(\"install_pkgs cmd: %s\", cmd)\n                check_call(cmd)\n            except CalledProcessError as err:\n                self.logger.error(\"Conda exited with errors: %s\", err.output)\n        return self.pkgs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_fields(self, **fields):\n        for field_name, value in iteritems(fields):\n            field = getattr(self, field_name)\n            field.proxy_set(value)", "response": "Set many fields using the proxy setter for each of them."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_queue(cls, name, priority=0, **fields_if_new):\n        queue_kwargs = {'name': name, 'priority': priority}\n        retries = 0\n        while retries < 10:\n            retries += 1\n            try:\n                queue, created = cls.get_or_connect(**queue_kwargs)\n            except IndexError:\n                # Failure during the retrieval https://friendpaste.com/5U63a8aFuV44SEgQckgMP\n                # => retry\n                continue\n            except ValueError:\n                # more than one (race condition https://github.com/yohanboniface/redis-limpyd/issues/82 ?)\n                try:\n                    queue = cls.collection(**queue_kwargs).instances()[0]\n                except IndexError:\n                    # but no more now ?!\n                    # => retry\n                    continue\n                else:\n                    created = False\n\n            # ok we have our queue, stop now\n            break\n\n        if created and fields_if_new:\n            queue.set_fields(**fields_if_new)\n\n        return queue", "response": "Get or create a queue with the given name and priority."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd the job to the delayed list.", "response": "def delay_job(self, job, delayed_until):\n        \"\"\"\n        Add the job to the delayed list (zset) of the queue.\n        \"\"\"\n        timestamp = datetime_to_score(delayed_until)\n        self.delayed.zadd(timestamp, job.ident)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd the job to the waiting list, at the end (it's a fifo list). If `prepend` is True, add it at the beginning of the list.", "response": "def enqueue_job(self, job, prepend=False):\n        \"\"\"\n        Add the job to the waiting list, at the end (it's a fifo list). If\n        `prepend` is True, add it at the beginning of the list.\n        \"\"\"\n        push_method = getattr(self.waiting, 'lpush' if prepend else 'rpush')\n        push_method(job.ident)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all available queues for the given names.", "response": "def get_all(cls, names):\n        \"\"\"\n        Return all queues for the given names (for all available priorities)\n        \"\"\"\n        names = cls._get_iterable_for_names(names)\n\n        queues = []\n        for queue_name in names:\n            queues.extend(cls.collection(name=queue_name).instances())\n\n        return queues"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns all the queues with the given names sorted by priority first then by name.", "response": "def get_all_by_priority(cls, names):\n        \"\"\"\n        Return all the queues with the given names, sorted by priorities (higher\n        priority first), then by name\n        \"\"\"\n        names = cls._get_iterable_for_names(names)\n\n        queues = cls.get_all(names)\n\n        # sort all queues by priority\n        queues.sort(key=lambda q: int(q.priority.hget() or 0), reverse=True)\n\n        return queues"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of all queue waiting keys in the given names", "response": "def get_waiting_keys(cls, names):\n        \"\"\"\n        Return a list of all queue waiting keys, to use with blpop\n        \"\"\"\n        return [queue.waiting.key for queue in cls.get_all_by_priority(names)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the number of all jobs waiting in queues with the given names", "response": "def count_waiting_jobs(cls, names):\n        \"\"\"\n        Return the number of all jobs waiting in queues with the given names\n        \"\"\"\n        return sum([queue.waiting.llen() for queue in cls.get_all(names)])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef count_delayed_jobs(cls, names):\n        return sum([queue.delayed.zcard() for queue in cls.get_all(names)])", "response": "Return the number of delayed jobs in queues with the given names"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef first_delayed(self):\n        entries = self.delayed.zrange(0, 0, withscores=True)\n        return entries[0] if entries else None", "response": "Return the first delayed job in the delayed zset"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nput all delayed jobs that are now ready, back in the queue waiting list Return a list of failures", "response": "def requeue_delayed_jobs(self):\n        \"\"\"\n        Put all delayed jobs that are now ready, back in the queue waiting list\n        Return a list of failures\n        \"\"\"\n        lock_key = self.make_key(\n            self._name,\n            self.pk.get(),\n            \"requeue_all_delayed_ready_jobs\",\n        )\n        connection = self.get_connection()\n\n        if connection.exists(lock_key):\n            # if locked, a worker is already on it, don't wait and exit\n            return []\n\n        with Lock(connection, lock_key, timeout=60):\n\n            # stop here if we know we have nothing\n            first_delayed_time = self.first_delayed_time\n            if not first_delayed_time:\n                return []\n\n            # get when we are :)\n            now_timestamp = datetime_to_score(datetime.utcnow())\n\n            # the first job will be ready later, and so the other ones too, then\n            # abort\n            if float(first_delayed_time) > now_timestamp:\n                return []\n\n            failures = []\n            while True:\n                # get the first entry\n                first_entry = self.first_delayed\n\n                # no first entry, another worker took all from us !\n                if not first_entry:\n                    break\n\n                # split into vars for readability\n                job_ident, delayed_until = first_entry\n\n                # if the date of the job is in the future, another work took the\n                # job we wanted, so we let this job here and stop the loop as we\n                # know (its a zset sorted by date) that no other jobs are ready\n                if delayed_until > now_timestamp:\n                    break\n\n                # remove the entry we just got from the delayed ones\n                self.delayed.zrem(job_ident)\n\n                # and add it to the waiting queue\n                try:\n                    job = Job.get_from_ident(job_ident)\n                    if job.status.hget() == STATUSES.DELAYED:\n                        job.status.hset(STATUSES.WAITING)\n                    self.enqueue_job(job)\n                except Exception as e:\n                    failures.append((job_ident, '%s' % e))\n\n            return failures"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_from_ident(self, ident):\n        model_repr, job_pk = ident.split(':', 1)\n        klass = import_class(model_repr)\n        return klass.get(job_pk)", "response": "Take a string as returned by get_ident and return a job object based on the class representation and the job s pk from the ident"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the given queue_name if defined else the class s one.", "response": "def _get_queue_name(cls, queue_name=None):\n        \"\"\"\n        Return the given queue_name if defined, else the class's one.\n        If both are None, raise an Exception\n        \"\"\"\n        if queue_name is None and cls.queue_name is None:\n            raise LimpydJobsException(\"Queue's name not defined\")\n        if queue_name is None:\n            return cls.queue_name\n        return queue_name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_job(cls, identifier, queue_name=None, priority=0, queue_model=None,\n                prepend=False, delayed_for=None, delayed_until=None,\n                **fields_if_new):\n        \"\"\"\n        Add a job to a queue.\n        If this job already exists, check it's current priority. If its higher\n        than the new one, don't touch it, else move the job to the wanted queue.\n        Before setting/moving the job to the queue, check for a `delayed_for`\n        (int/foat/timedelta) or `delayed_until` (datetime) argument to see if\n        it must be delayed instead of queued.\n        If the job is created, fields in fields_if_new will be set for the new\n        job.\n        Finally return the job.\n        \"\"\"\n\n        # check for delayed_for/delayed_until arguments\n        delayed_until = compute_delayed_until(delayed_for, delayed_until)\n\n        # create the job or get an existing one\n        job_kwargs = {'identifier': identifier, 'queued': '1'}\n        retries = 0\n        while retries < 10:\n            retries += 1\n            try:\n                job, created = cls.get_or_connect(**job_kwargs)\n            except IndexError:\n                # Failure during the retrieval https://friendpaste.com/5U63a8aFuV44SEgQckgMP\n                # => retry\n                continue\n            except ValueError:\n                # more than one already in the queue !\n                try:\n                    job = cls.collection(**job_kwargs).instances()[0]\n                except IndexError:\n                    # but no more now ?!\n                    # => retry\n                    continue\n                else:\n                    created = False\n\n            # ok we have our job, stop now\n            break\n\n        try:\n            # check queue_name\n            queue_name = cls._get_queue_name(queue_name)\n\n            # if the job already exists, and we want a higher priority or move it,\n            # start by updating it\n            if not created:\n                current_priority = int(job.priority.hget() or 0)\n                # if the job has a higher priority, or don't need to be moved,\n                # don't move it\n                if not prepend and current_priority >= priority:\n                    return job\n\n                # cancel it temporarily, we'll set it as waiting later\n                job.status.hset(STATUSES.CANCELED)\n\n                # remove it from the current queue, we'll add it to the new one later\n                if queue_model is None:\n                    queue_model = cls.queue_model\n                current_queue = queue_model.get_queue(queue_name, current_priority)\n                current_queue.waiting.lrem(0, job.ident)\n\n            else:\n                job.set_fields(added=str(datetime.utcnow()), **(fields_if_new or {}))\n\n            # add the job to the queue\n            job.enqueue_or_delay(queue_name, priority, delayed_until, prepend, queue_model)\n\n            return job\n        except Exception:\n            job.queued.delete()\n            raise", "response": "Add a job to a queue."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the duration of the job in seconds.", "response": "def duration(self):\n        \"\"\"\n        If the start and end times of the job are defined, return a timedelta,\n        else return None\n        \"\"\"\n        try:\n            start, end = self.hmget('start', 'end')\n            return parse(end) - parse(start)\n        except:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef requeue(self, queue_name=None, priority=None, delayed_for=None,\n                                        delayed_until=None, queue_model=None):\n        \"\"\"\n        Requeue the job in the given queue if it has previously failed\n        \"\"\"\n        queue_name = self._get_queue_name(queue_name)\n\n        # we can only requeue a job that raised an error\n        if self.status.hget() != STATUSES.ERROR:\n            raise LimpydJobsException('Job cannot be requeued if not in ERROR status')\n\n        self.hdel('start', 'end')\n\n        if priority is None:\n            priority = self.priority.hget()\n\n        delayed_until = compute_delayed_until(delayed_for, delayed_until)\n\n        self.enqueue_or_delay(queue_name, priority, delayed_until, queue_model=queue_model)", "response": "Requeue the job in the given queue if it has previously failed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a new error in redis.", "response": "def add_error(cls, queue_name, job, error, when=None, trace=None,\n                                                        **additional_fields):\n        \"\"\"\n        Add a new error in redis.\n        `job` is a job which generated the error\n        `queue_name` is the name of the queue where the error arrived\n        `error` is an exception, which can has a code (better if it is)\n        `when` is the datetime of the error, utcnow will be used if not defined\n        `trace` is the traceback generated by the exception, may be null\n        The new created instance is returned, with additional_fields set for\n        aubclasses.\n        \"\"\"\n        if when is None:\n            when = datetime.utcnow()\n        when = str(when)\n\n        fields = dict(\n            queue_name=queue_name,\n            job_model_repr=job.get_model_repr(),\n            job_pk=job.pk.get(),\n            identifier=getattr(job, '_cached_identifier', job.identifier.hget()),\n            date_time=when,\n            date=when[:10],\n            time=when[11:],\n            message=str(error),\n        )\n\n        try:\n            # exception can be a class (should not, but just in case...)\n            fields['type'] = error.__name__\n        except AttributeError:\n            # or excetion is an instance\n            fields['type'] = error.__class__.__name__\n\n        error_code = getattr(error, 'code', None)\n        if error_code is not None:\n            fields['code'] = error_code\n\n        if trace:\n            fields['traceback'] = trace\n\n        error = cls(**fields)\n\n        if additional_fields:\n            error.set_fields(**additional_fields)\n\n        return error"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts wavelength to RGB.", "response": "def wavelengthToRGB(wavelength):\n\tgamma = 0.80;\n\tintensityMax = 255;\n\n\t\"\"\" Taken from Earl F. Glynn's web page:\n\t* <a href=\"http://www.efg2.com/Lab/ScienceAndEngineering/Spectra.htm\">Spectra Lab Report</a>\n\t\"\"\"\n\n\tfactor = None\n\tr = None\n\tg = None\n\tb = None\n\n\tif((wavelength >= 380) and (wavelength<440)):\n\t\tr = -(wavelength - 440) / (440.0 - 380.0)\n\t\tg = 0.0\n\t\tb = 1.0\n\telif((wavelength >= 440) and (wavelength<490)):\n\t\tr = 0.0\n\t\tg = (wavelength - 440) / (490.0 - 440.0)\n\t\tb = 1.0\n\telif((wavelength >= 490) and (wavelength<510)):\n\t\tr = 0.0\n\t\tg = 1.0\n\t\tb = -(wavelength - 510) / (510.0 - 490.0)\n\telif((wavelength >= 510) and (wavelength<580)):\n\t\tr = (wavelength - 510) / (580.0 - 510.0)\n\t\tg = 1.0\n\t\tb = 0.0\n\telif((wavelength >= 580) and (wavelength<645)):\n\t\tr = 1.0\n\t\tg = -(wavelength - 645) / (645.0 - 580.0)\n\t\tb = 0.0\n\telif((wavelength >= 645) and (wavelength<781)):\n\t\tr = 1.0\n\t\tg = 0.0\n\t\tb = 0.0\n\telse:\n\t\tr = 0.0\n\t\tg = 0.0\n\t\tb = 0.0\n\n\t# Let the intensity fall off near the vision limits\n\tif((wavelength >= 380) and (wavelength<420)):\n\t    factor = 0.3 + 0.7*(wavelength - 380) / (420.0 - 380.0)\n\telif((wavelength >= 420) and (wavelength<701)):\n\t    factor = 1.0\n\telif((wavelength >= 701) and (wavelength<781)):\n\t    factor = 0.3 + 0.7*(780 - wavelength) / (780.0 - 700.0)\n\telse:\n\t    factor = 0.0\n\n\t# Don't want 0^x = 1 for x != 0\n\n\tr = int(round(intensityMax * pow(r * factor, gamma)))\n\tg = int(round(intensityMax * pow(g * factor, gamma)))\n\tb = int(round(intensityMax * pow(b * factor, gamma)))\n\n\treturn (r, g, b)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, key):\n\n    \"\"\"\n    Retrieve object indexed by <key>\n    \"\"\"\n\n    try:\n      try:\n        obj = self.bucket.get(key)\n      except:\n        raise\n\n      return dict(obj or {})\n\n    except:\n      raise", "response": "Retrieve object indexed by key"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set(self, key, data, retry=0):\n\n    \"\"\"\n    Store data <data> index by key <key>\n\n    Args\n\n    key <string> couchdb document id\n    data <dict> data to store\n    \"\"\"\n\n    try:\n\n      if type(data) != dict:\n        raise Exception(\"data needs to be of type <dict>\")\n\n      #t1 = time.time()\n\n      if not data.has_key(\"_rev\"):\n        exists = self.bucket.get(key)\n        if exists:\n          data[\"_rev\"] = exists.get(\"_rev\")\n      data[\"_id\"] = key\n      try:\n        #print \"Preparing save: %s %s\" % (key, data)\n        (id, rev) = self.bucket.save(data)\n      except couchdb.http.ResourceConflict, inst:\n        if retry > 0:\n          if data.has_key(\"_rev\"):\n            del data[\"_rev\"]\n          retry -= 1\n          return self.set(key, data, retry=retry)\n        else:\n          if self.logger:\n            self.logger.error(\"Document update conflict '%s' on '%s', rev '%s'\" % (inst, key, data.get(\"_rev\")))\n            return 0\n          else:\n            raise\n\n      return rev\n\n      #print \"Saved in %.5f\" % (time.time() - t1)\n    except:\n      raise", "response": "Store data in the database index by key"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_batch(self, data):\n    \n    \"\"\"\n    Store multiple documents\n    \n    Args\n\n    data <dict> data to store, use document ids as keys\n\n    Returns\n\n    revs <dict> dictionary of new revisions indexed by document ids\n    \"\"\"\n\n    # fetch existing documents to get current revisions\n    rows = self.bucket.view(\"_all_docs\", keys=data.keys(), include_docs=True)\n    existing = {}\n    for row in rows:\n      key = row.id\n      if key and not data[key].has_key(\"_rev\"):\n        data[key][\"_rev\"] = row.doc[\"_rev\"]\n\n    for id,item in data.items():\n      data[id][\"_id\"] = id\n\n    revs = {}\n    for success, docid, rev_or_exc in self.bucket.update(data.values()):\n      if not success and self.logger:\n        self.logger.error(\"Document update conflict (batch) '%s', %s\" % (docid, rev_or_exc))\n      elif success:\n        revs[docid] = rev_or_exc\n\n    return revs", "response": "Store multiple documents in the bucket"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve recently changed and added docs", "response": "def recent_docs(self, include_docs=True, limit=None):\n\n    \"\"\"\n    Retrieve recently changed / added docs\n\n\n    Args:\n\n    include_docs <bools> if true full document data will be retrieved\n    limit <int> if != None and > 0 limit the result set to this amount of rows\n\n    Returns a view result to be iterated through\n    \"\"\"\n\n    try:\n      return self.bucket.view(\"_changed\", include_docs=include_docs, limit=limit)\n    except:\n      raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_design(self, design_name):\n\n    try:\n      r = requests.request(\n        \"GET\",\n        \"%s/%s/_design/%s\" % (\n          self.host,\n          self.database_name,\n          design_name\n        ),\n        auth=self.auth\n      )\n\n      return self.result(r.text)\n\n    except:\n      raise", "response": "Returns dict representation of the design document with the matching\n    name and design_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove the specified design from the specified resource.", "response": "def del_design(self, design_name):\n    \"\"\"\n    Removes the specified design\n\n    design_name <str>\n    \"\"\"\n\n    try:\n\n      design = self.get_design(design_name)\n      r = requests.request(\n        \"DELETE\",\n        \"%s/%s/_design/%s\" % (\n          self.host,\n          self.database_name,\n          design_name\n        ),\n        params={\"rev\" : design.get(\"_rev\")},\n        auth=self.auth\n      )\n      return self.result(r.text)\n\n    except:\n      raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate a design document for the loaded databases", "response": "def put_design(self, design_name, design, verbose=False):\n    \"\"\"\n    Updates a design document for the loaded databases\n\n    design_name <str> name of the design\n    design <str> json string of the design document\n    \"\"\"\n\n    try:\n\n      try:\n        # check if there is a previous revision of the\n        # specified design, if there is get the _rev\n        # id from it and apply it to the new version\n        existing = self.get_design(design_name)\n\n        design = json.loads(design)\n\n        if design.get(\"version\") and existing.get(\"version\") == design.get(\"version\"):\n          if verbose:\n            print \"No change in design... skipping update!\"\n          return\n\n        design[\"_rev\"] = existing[\"_rev\"]\n        design = json.dumps(design)\n      except RESTException:\n        pass\n\n      r = requests.request(\n        \"PUT\",\n        \"%s/%s/_design/%s\" % (\n          self.host,\n          self.database_name,\n          design_name\n        ),\n        auth=self.auth,\n        data=design,\n        headers={\"content-type\" : \"application/json\"}\n      )\n\n      return self.result(r.text)\n\n    except:\n      raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a REST CouchDB response as a dict.", "response": "def result(self, couchdb_response_text):\n    \"\"\"\n    Return whether a REST couchdb operation was successful or not.\n\n    On error will raise a RESTException\n    \"\"\"\n    result = json.loads(couchdb_response_text)\n\n    if result.get(\"ok\"):\n      return True\n    elif result.get(\"error\"):\n      raise RESTException(\n        \"%s: %s\" % (result.get(\"error\"), result.get(\"reason\"))\n      )\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds the x value at a given index in xArr yArr yVal", "response": "def findXAt(xArr, yArr, yVal, index=0, s=0.0):\n    \"\"\"\n    index: position of root (return index=0 by default)\n\n    return all x values where y would be equal to given yVal\n    if arrays are spline interpolated\n    \"\"\"\n    if xArr[1] < xArr[0]:\n        # numbers must be in ascending order, otherwise method crashes...\n        xArr = xArr[::-1]\n        yArr = yArr[::-1]\n\n    yArr = yArr - yVal\n    if len(yArr) < 5:\n        xn = np.linspace(xArr[0], xArr[-1], 5)\n        yArr = np.interp(xn, xArr, yArr)\n        xArr = xn\n    f = interpolate.UnivariateSpline(xArr, yArr, s=s)\n    return f.roots()[index]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads a single object from a file.", "response": "def _load(self, location):\n        \"\"\"\n        location -- URL or file location\n        isxsd -- is this a xsd file?\n        \"\"\"\n        cachedir = self._cachedir\n        # wsdl2py: deal with XML Schema\n        if not os.path.isdir(cachedir): os.mkdir(cachedir)\n    \n        file = os.path.join(cachedir, '.cache')\n        section = 'TYPES'\n        cp = ConfigParser()\n        try:\n            cp.readfp(open(file, 'r'))\n        except IOError:\n            del cp;  cp = None\n            \n        option = location.replace(':', '-') # colons seem to screw up option\n        if (not self._force and cp is not None and cp.has_section(section) and \n            cp.has_option(section, option)):\n            types = cp.get(section, option)\n        else:\n            # dont do anything to anames\n            if not self._pyclass:\n                containers.ContainerBase.func_aname = lambda instnc,n: str(n)\n                \n            args = ['-o', cachedir, location]\n            if self._lazy: args.insert(0, '-l')\n            if self._pyclass: args.insert(0, '-b')\n            files = commands.wsdl2py(args)\n\n            if cp is None: cp = ConfigParser()\n            if not cp.has_section(section): cp.add_section(section)\n            types = filter(lambda f: f.endswith('_types.py'), files)[0]\n            cp.set(section, option, types)\n            cp.write(open(file, 'w'))\n            \n        if os.path.abspath(cachedir) not in sys.path:\n            sys.path.append(os.path.abspath(cachedir))\n            \n        mod = os.path.split(types)[-1].rstrip('.py')\n        return __import__(mod)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a schema from a file and return a key - value dict.", "response": "def _load_schema(self, location, xml=None):\n        \"\"\"\n        location -- location of schema, also used as a key\n        xml -- optional string representation of schema\n        \"\"\"\n        cachedir = self._cachedir\n        # wsdl2py: deal with XML Schema\n        if not os.path.isdir(cachedir): os.mkdir(cachedir)\n    \n        file = os.path.join(cachedir, '.cache')\n        section = 'TYPES'\n        cp = ConfigParser()\n        try:\n            cp.readfp(open(file, 'r'))\n        except IOError:\n            del cp;  cp = None\n            \n        option = location.replace(':', '-') # colons seem to screw up option\n        if (cp is not None and cp.has_section(section) and \n            cp.has_option(section, option)):\n            types = cp.get(section, option)\n        else:\n            # dont do anything to anames\n            if not self._pyclass:\n                containers.ContainerBase.func_aname = lambda instnc,n: str(n)\n                \n            from pyremotevbox.ZSI.wstools import XMLSchema\n            reader = XMLSchema.SchemaReader(base_url=location)\n            if xml is not None and isinstance(xml, basestring):\n                schema = reader.loadFromString(xml)\n            elif xml is not None:\n                raise RuntimeError, 'Unsupported: XML must be string'\n            elif not os.path.isfile(location):\n                schema = reader.loadFromURL(location)\n            else:\n                schema = reader.reader.loadFromFile(location)\n                \n            # TODO: change this to keyword list\n            class options:\n                output_dir = cachedir\n                schema = True\n                simple_naming = False\n                address = False\n                lazy = self._lazy\n                complexType = self._pyclass\n\n            schema.location = location\n            files = commands._wsdl2py(options, schema)\n            if cp is None: cp = ConfigParser()\n            if not cp.has_section(section): cp.add_section(section)\n            types = filter(lambda f: f.endswith('_types.py'), files)[0]\n            cp.set(section, option, types)\n            cp.write(open(file, 'w'))\n            \n        if os.path.abspath(cachedir) not in sys.path:\n            sys.path.append(os.path.abspath(cachedir))\n            \n        mod = os.path.split(types)[-1].rstrip('.py')\n        return __import__(mod)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a function that returns a call to the named remote web service method.", "response": "def _call(self, name, soapheaders):\n        \"\"\"return the Call to the named remote web service method.\n        closure used to prevent multiple values for name and soapheaders \n        parameters \n        \"\"\"\n        \n        def call_closure(*args, **kwargs):\n            \"\"\"Call the named remote web service method.\"\"\"\n            if len(args) and len(kwargs):\n                raise TypeError, 'Use positional or keyword argument only.'\n                \n            if len(args) > 0:\n                raise TypeError, 'Not supporting SOAPENC:Arrays or XSD:List'\n            \n            if len(kwargs): \n                args = kwargs\n\n            callinfo = getattr(self, name).callinfo\n    \n            # go through the list of defined methods, and look for the one with\n            # the same number of arguments as what was passed.  this is a weak\n            # check that should probably be improved in the future to check the\n            # types of the arguments to allow for polymorphism\n            for method in self._methods[name]:\n                if len(method.callinfo.inparams) == len(kwargs):\n                    callinfo = method.callinfo\n    \n            binding = _Binding(url=self._url or callinfo.location,\n                              soapaction=callinfo.soapAction,\n                              **self._kw)\n    \n            kw = dict(unique=True)\n            if callinfo.use == 'encoded':\n                kw['unique'] = False\n    \n            if callinfo.style == 'rpc':\n                request = TC.Struct(None, ofwhat=[], \n                                 pname=(callinfo.namespace, name), **kw)\n                \n                response = TC.Struct(None, ofwhat=[], \n                                 pname=(callinfo.namespace, name+\"Response\"), **kw)\n                \n                if len(callinfo.getInParameters()) != len(args):\n                    raise RuntimeError('expecting \"%s\" parts, got %s' %(\n                           str(callinfo.getInParameters(), str(args))))\n                \n                for msg,pms in ((request,callinfo.getInParameters()), \n                                (response,callinfo.getOutParameters())):\n                    msg.ofwhat = []\n                    for part in pms:\n                        klass = GTD(*part.type)\n                        if klass is None:\n                            if part.type:\n                                klass = filter(lambda gt: part.type==gt.type,TC.TYPES)\n                                if len(klass) == 0:\n                                    klass = filter(lambda gt: part.type[1]==gt.type[1],TC.TYPES)\n                                    if not len(klass):klass = [TC.Any]\n                                if len(klass) > 1: #Enumerations, XMLString, etc\n                                    klass = filter(lambda i: i.__dict__.has_key('type'), klass)\n                                klass = klass[0]\n                            else:\n                                klass = TC.Any\n                    \n                        msg.ofwhat.append(klass(part.name))\n                        \n                    msg.ofwhat = tuple(msg.ofwhat)\n                if not args: args = {}\n            else:\n                # Grab <part element> attribute\n                ipart,opart = callinfo.getInParameters(),callinfo.getOutParameters()\n                if ( len(ipart) != 1 or not ipart[0].element_type or \n                    ipart[0].type is None ):\n                    raise RuntimeError, 'Bad Input Message \"%s\"' %callinfo.name\n        \n                if ( len(opart) not in (0,1) or not opart[0].element_type or \n                    opart[0].type is None ):\n                    raise RuntimeError, 'Bad Output Message \"%s\"' %callinfo.name\n                \n#                if ( len(args) > 1 ):\n#                    raise RuntimeError, 'Message has only one part:  %s' %str(args)\n                \n                ipart = ipart[0]\n                request,response = GED(*ipart.type),None\n                if opart: response = GED(*opart[0].type)\n    \n            msg = args\n            if self._asdict: \n                if not msg: msg = dict()\n                self._nullpyclass(request)\n            elif request.pyclass is not None:\n                if type(args) is dict:\n                    msg = request.pyclass()\n                    msg.__dict__.update(args)\n                elif type(args) is list and len(args) == 1: \n                    msg = request.pyclass(args[0])\n                else: \n                    msg = request.pyclass()\n                    \n            binding.Send(None, None, msg,\n                         requesttypecode=request,\n                         soapheaders=soapheaders,\n                         encodingStyle=callinfo.encodingStyle)\n            \n            if response is None: \n                return None\n            \n            if self._asdict: self._nullpyclass(response)\n            return binding.Receive(replytype=response,\n                         encodingStyle=callinfo.encodingStyle)\n            \n        return call_closure"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds headers to the SOAP message", "response": "def add_headers(self, **headers):\n        \"\"\"packing dicts into typecode pyclass, may fail if typecodes are\n        used in the body (when asdict=True)\n        \"\"\"\n        class _holder: pass\n        def _remap(pyobj, **d):\n            pyobj.__dict__ = d\n            for k,v in pyobj.__dict__.items():\n                if type(v) is not dict: continue\n                pyobj.__dict__[k] = p = _holder()\n                _remap(p, **v)\n    \n        for k,v in headers.items():\n            h = filter(lambda i: k in i.type, self.callinfo.inheaders)[0]\n            if h.element_type != 1: \n                raise RuntimeError, 'not implemented'\n\n            typecode = GED(*h.type)\n            if typecode is None: \n                raise RuntimeError, 'no matching element for %s' %str(h.type)\n\n            pyclass = typecode.pyclass\n            if pyclass is None: \n                raise RuntimeError, 'no pyclass for typecode %s' %str(h.type)\n\n            if type(v) is not dict:\n                pyobj = pyclass(v)\n            else:\n                pyobj = pyclass()\n                _remap(pyobj, **v)\n\n            self.soapheaders.append(pyobj)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef default_child_path(path):\n    try:\n        # Recurse until we find a path with no default child\n        child_path = default_child_path(\n            current_app.config['DEFAULT_CHILDREN'][path]\n        )\n    except KeyError:\n        child_path = path\n    return child_path", "response": "Return the default child of the parent path if it exists else path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a C ++ module.", "response": "def build_module(\n        name, source=None, *, sources=None, preprocess=None, output=None, output_dir='.',\n        build_dir='build', include_dirs=None, library_dirs=None, libraries=None, macros=None,\n        compiler_preargs=None, compiler_postargs=None, linker_preargs=None, linker_postargs=None, cache=True):\n\n    '''\n        Args:\n            name (str): The module name (must be unique).\n            source (str): the source code in C++.\n\n        Keyword Args:\n            sources (str): Source files.\n            preprocess (str): Source files that need cfly's preprocessing.\n            build_dir (str): The build directory. defaults to 'build'.\n            output (str): The output file. defaults to '{name}.{ext}'.\n            output_dir (str): The output directory. defaults to '.'.\n            build_dir (str): The build directory. defaults to 'build'.\n            include_dirs (list): Additional include directories.\n            library_dirs (list): Additional library directories.\n            libraries (list): Additional libraries.\n            macros (list): Predefined macros. (name, value) pairs.\n            compiler_preargs (list): Compiler preargs.\n            compiler_postargs (list): Compiler postargs.\n            linker_preargs (list): Linker preargs.\n            linker_postargs (list): Linker postargs.\n            cache (bool): Enable cache.\n\n        Returns:\n            the compiled and imported module.\n    '''\n\n    if output is None:\n        output = name + get_config_var('EXT_SUFFIX')\n\n    if sources is None:\n        sources = []\n\n    if preprocess is None:\n        preprocess = []\n\n    if source is None:\n        source = ''\n\n    preprocess_set = set(preprocess)\n    sources = [x for x in sources if x not in preprocess_set]\n\n    if source and sources + preprocess:\n        raise ValueError('invalid arguments')\n\n    os.makedirs(build_dir, exist_ok=True)\n\n    module_home = os.path.join(build_dir, 'temp', name)\n    old_checksum = readall(module_home, 'args.txt')\n    checksum = args_checksum(\n        name,\n        source,\n        sources,\n        preprocess,\n        output,\n        output_dir,\n        build_dir,\n        include_dirs,\n        library_dirs,\n        libraries,\n        macros,\n        compiler_preargs,\n        compiler_postargs,\n        linker_preargs,\n        linker_postargs,\n    )\n\n    if checksum != old_checksum:\n        cache = False\n\n    output = os.path.join(output_dir, output)\n\n    if cache and is_up_to_date(output, sources + preprocess):\n        return load_module(name, output)\n\n    with open(os.path.join(build_dir, name + '.log'), 'wb+') as build_log:\n        shutil.rmtree(module_home, ignore_errors=True)\n        os.makedirs(module_home, exist_ok=True)\n\n        if source:\n            preprocess = [writeall(module_home, 'source.cpp', source)]\n\n        global_module_methods = {}\n        global_module_types = {}\n\n        sources = [(x, None) for x in sources]\n\n        for filename in preprocess:\n            source = readall('.', filename)\n            module_methods, module_types = parse_source(source, build_log)\n            global_module_methods.update(module_methods)\n            global_module_types.update(module_types)\n            code = render_template(source_template, module=name, types=module_types, methods=module_methods)\n            sources.append((writeall(module_home, filename, source + code), filename))\n\n        code = render_template(module_template, module=name, types=global_module_types, methods=global_module_methods)\n        sources.append((writeall(module_home, 'module.cpp', code), None))\n        exports = ['PyInit_' + name]\n\n        compiler = create_compiler()\n\n        def spawn(cmd):\n            old_path = os.getenv('path', '')\n            try:\n                os.environ['path'] = getattr(compiler, '_paths', old_path)\n                ret = subprocess.call(cmd, stdout=build_log, stderr=subprocess.STDOUT)\n                if ret:\n                    build_log.seek(0)\n                    entire_log = build_log.read().decode()\n                    raise DistutilsExecError('Compiler failed:\\n' + entire_log)\n\n            finally:\n                build_log.flush()\n                os.environ['path'] = old_path\n\n        compiler.spawn = spawn\n\n        for include_dir in include_dirs or []:\n            compiler.add_include_dir(include_dir)\n\n        for library_dir in library_dirs or []:\n            compiler.add_library_dir(library_dir)\n\n        try:\n            objects = compiler.object_filenames([source for source, original in sources], 0, build_dir)\n\n            todo = []\n            for pair, obj in zip(sources, objects):\n                source, original = pair\n                if not is_up_to_date(obj, [original or source]):\n                    todo.append(pair)\n\n            if not cache:\n                todo = sources\n\n            if todo:\n                for source, original in todo:\n                    original_folder = [os.path.abspath(os.path.dirname(original))] if original else []\n                    compiler.compile(\n                        [source],\n                        build_dir,\n                        macros,\n                        original_folder,\n                        0,\n                        compiler_preargs,\n                        compiler_postargs,\n                    )\n\n                compiler.link(\n                    'shared_object',\n                    objects,\n                    'output',\n                    build_dir,\n                    libraries,\n                    [],\n                    [],\n                    exports,\n                    0,\n                    linker_preargs,\n                    linker_postargs,\n                )\n\n                if os.path.isfile(output):\n                    try:\n                        os.unlink(output)\n                    except PermissionError:\n                        shutil.move(output, os.path.join(build_dir, '_' + os.urandom(8).hex()))\n                shutil.move(os.path.join(build_dir, 'output'), output)\n\n        except CompileError as ex:\n            raise ex from None\n\n        writeall(module_home, 'args.txt', checksum)\n\n    return load_module(name, output)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef files(self):\n        files_description = [\n            [ self.project_name,\n              self.project_name + '.tex',\n              'LaTeXBookFileTemplate'\n            ],\n            [ self.project_name,\n              'references.bib',\n              'BibTeXFileTemplate'\n            ],\n            [ self.project_name,\n              'Makefile',\n              'LaTeXMakefileFileTemplate'\n            ],\n        ]\n        return files_description", "response": "Return the names of files to be created."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the substitutions for the templating replacements.", "response": "def substitutes(self):\n        \"\"\" Return the substitutions for the templating replacements. \"\"\"\n        author_collector = AuthorCollector()\n        substitute_dict = dict(\n            project = self.project_name,\n            date = date.today().isoformat(),\n            author = author_collector.collect()\n        )\n        return substitute_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef view_input(window):\n    store = window.store\n\n    def change_label(sender):\n        \"\"\"event func\"\"\"\n        store.label.value = sender.value\n\n    window += Input(\n        label='Introducir: ',\n        cursor=red('_'),\n        left_l='< ',\n        right_l=' >',\n        on_enter=change_label,\n        ref='input'\n    )\n    window += Label(\n        cordx=28,\n        ref='label'\n    )", "response": "View input and label in window."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lazy_send(chainlet, chunks):\n    fork, join = chainlet.chain_fork, chainlet.chain_join\n    if fork and join:\n        return _send_n_get_m(chainlet, chunks)\n    elif fork:\n        return _lazy_send_1_get_m(chainlet, chunks)\n    elif join:\n        return _lazy_send_n_get_1(chainlet, chunks)\n    else:\n        return _lazy_send_1_get_1(chainlet, chunks)", "response": "Canonical version of chainlet_send that always takes and returns an iterable\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef eager_send(chainlet, chunks):\n    fork, join = chainlet.chain_fork, chainlet.chain_join\n    if fork and join:\n        return _send_n_get_m(chainlet, chunks)\n    elif fork:\n        return tuple(_lazy_send_1_get_m(chainlet, chunks))\n    elif join:\n        return tuple(_lazy_send_n_get_1(chainlet, chunks))\n    else:\n        return tuple(_lazy_send_1_get_1(chainlet, chunks))", "response": "Eager version of lazy_send"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_doc_list(text=None, is_stripped=True, split_character=\"::\"):\n    text = text or function_doc(2)\n    text = text.split(split_character, 1)[-1]\n    text = text.split(':param')[0].split(':return')[0]\n    text = text.strip().split('\\n')\n\n    def clean(t): return is_stripped and t.strip() or t\n\n    return [clean(line) for line in text]", "response": "Parses a list of the docstrings for a given language."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_doc_str(text=None, is_untabbed=True, is_stripped=True,\n                  tab=None, split_character=\"::\"):\n    \"\"\"\n    Returns a str of the parsed doc for example \n    the following would return 'a:A\\nb:B' ::\n        a:A\n        b:B\n    :param text:            str of the text to parse, by \n                            default uses calling function doc\n    :param is_untabbed:     bool if True will untab the text\n    :param is_stripped:     bool if True will strip the text\n    :param tab:             str of the tab to use when untabbing, \n                            by default it will self determine tab size\n    :param split_character: str of the character to split the text on\n    :return: dict\n    \"\"\"\n    text = text or function_doc(2)\n    text = text.split(split_character, 1)[-1]\n    text = text.split(':param')[0].split(':return')[0]\n    tab = is_untabbed and \\\n          (tab or text[:-1 * len(text.lstrip())].split('\\n')[-1]) or ''\n    text = is_stripped and text.strip() or text\n    return text.replace('\\n%s' % tab, '\\n')", "response": "Parses the text of the example \n   ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_arg_types(text=None, is_return_included=False):\n    text = text or function_doc(2)\n    if is_return_included:\n        text = text.replace(':return:', ':param return:')\n    ret = {}\n\n    def evl(text_):\n        try:\n            return eval(text_)\n        except Exception as e:\n            return text_\n\n    if ':param' in text:\n        for param in text.split(':param ')[1:]:\n            name, desc = param.split(':', 1)\n            name = name.strip()\n            if desc.strip().startswith('list of '):\n                ret[name] = (list, evl(desc.split()[2].replace('str', STR)))\n            elif desc.strip().startswith('str timestamp'):\n                ret[name] = datetime\n            else:\n                ret[name] = evl(desc.split(None, 1)[0].replace('str', STR))\n    return ret", "response": "parses the arg types of the given text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(fname):\n    path = os.path.join(SCRIPTDIR, fname)\n    if PY3:\n        f = open(path, 'r', encoding='utf8')\n    else:\n        f = open(path, 'r')\n    content = f.read()\n    f.close()\n    return content", "response": "Return content of specified file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_function(self):\n        if not hasattr(self, '_function'):\n            try:\n                modname, funcname = self.function.rsplit('.', 1)\n                mod = import_module(modname)\n                self._function = getattr(mod, funcname)\n            except (ImportError, AttributeError, ValueError), err:\n                raise ProcessorConfigurationError(err)\n\n        return self._function", "response": "Return function object for my function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess a file and return the list of lines that match the expression", "response": "def process_file(self, path, dryrun):\n        \"\"\"\n        Print files path.\n        \"\"\"\n        # if dryrun just return files\n        if dryrun:\n            return path\n\n        # scan file and match lines\n        ret = []\n        with open(path, \"r\") as infile:\n            for line in infile:\n                if re.search(self.__exp, line):\n                    ret.append(line)\n\n        # if found matches return list of lines, else return None\n        return ret if len(ret) > 0 else None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_matching_files(dir, extensions=None, recursive=True):\n    from .modules import utils\n    return utils.list_matching_files(dir, extensions=extensions, recursive=recursive)", "response": "Returns a list of all files in the specified directory optionally recursively with the specified extensions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef concatenate(input_files, output_file):\n    from .modules import utils, concat\n\n    if not isinstance(input_files, (list, tuple)):\n        raise RuntimeError('Concatenate takes a list of input files.')\n\n    return {\n        'dependencies_fn': utils.no_dependencies,\n        'compiler_fn': concat.concatenate_input_files,\n        'input': input_files,\n        'output': output_file,\n        'kwargs': {},\n    }", "response": "Concatenates the input files into a single output file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copy_files(src_dir, dst_dir, filespec='*', recursive=False):\n    import os\n    from .modules import copyfiles\n\n    if src_dir == dst_dir:\n        raise RuntimeError('copy_files() src and dst directories must be different.')\n\n    if not os.path.isdir(src_dir):\n        raise RuntimeError('copy_files() src directory \"{}\" does not exist.'.format(src_dir))\n\n    return {\n        'dependencies_fn': copyfiles.list_files,\n        'compiler_fn': copyfiles.copy_files,\n        'input': src_dir,\n        'output': dst_dir,\n        'kwargs': {\n            'filespec': filespec,\n            'recursive': recursive,\n        },\n    }", "response": "Copies any files matching filespec from src_dir into dst_dir."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef minify_js(input_files, output_file):\n    from .modules import minify, utils\n\n    if not isinstance(input_files, (list, tuple)):\n        raise RuntimeError('JS minifier takes a list of input files.')\n\n    return {\n        'dependencies_fn': utils.no_dependencies,\n        'compiler_fn': minify.minify_js,\n        'input': input_files,\n        'output': output_file,\n        'kwargs': {},\n    }", "response": "Minifies the input javascript files to the output file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef split_css_for_ie_selector_limit(input_file, output_file):\n    from .modules import bless, utils\n\n    if not isinstance(input_file, str):\n        raise RuntimeError('CSS splitter takes only a single input file.')\n\n    return {\n        'dependencies_fn': utils.no_dependencies,\n        'compiler_fn': bless.bless_css,\n        'input': input_file,\n        'output': output_file,\n        'kwargs': {},\n    }", "response": "Splits a large CSS file into several smaller files each one containing less than the IE 4096 selector limit."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompile a LESS source file.", "response": "def compile_less(input_file, output_file):\n    \"\"\"\n    Compile a LESS source file. Minifies the output in release mode.\n    \"\"\"\n    from .modules import less\n\n    if not isinstance(input_file, str):\n        raise RuntimeError('LESS compiler takes only a single input file.')\n\n    return {\n        'dependencies_fn': less.less_dependencies,\n        'compiler_fn': less.less_compile,\n        'input': input_file,\n        'output': output_file,\n        'kwargs': {},\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compile_sass(input_file, output_file):\n    from .modules import sass\n\n    if not isinstance(input_file, str):\n        raise RuntimeError('SASS compiler takes only a single input file.')\n\n    return {\n        'dependencies_fn': sass.sass_dependencies,\n        'compiler_fn': sass.sass_compile,\n        'input': input_file,\n        'output': output_file,\n        'kwargs': {},\n    }", "response": "Compile a SASS source file and output it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef browserify_libs(lib_dirs, output_file, babelify=False):\n    from .modules import browserify\n\n    if not isinstance(lib_dirs, (list, tuple)):\n        raise RuntimeError('Browserify Libs compiler takes a list of library directories as input.')\n\n    return {\n        'dependencies_fn': browserify.browserify_deps_libs,\n        'compiler_fn': browserify.browserify_compile_libs,\n        'input': lib_dirs,\n        'output': output_file,\n        'kwargs': {\n            'babelify': babelify,\n        },\n    }", "response": "Browserify one or more library directories into a single\n    javascript file. Generates source maps in debug mode Minifies the\n    output in release mode."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef browserify_file(entry_point, output_file, babelify=False, export_as=None):\n    from .modules import browserify\n\n    if not isinstance(entry_point, str):\n        raise RuntimeError('Browserify File compiler takes a single entry point as input.')\n\n    return {\n        'dependencies_fn': browserify.browserify_deps_file,\n        'compiler_fn': browserify.browserify_compile_file,\n        'input': entry_point,\n        'output': output_file,\n        'kwargs': {\n            'babelify': babelify,\n            'export_as': export_as,\n        },\n    }", "response": "Browserify a single javascript entry point plus non - external modules into a single javascript file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef custom_function(func, input_files, output_file):\n    from .modules import utils\n\n    return {\n        'dependencies_fn': utils.no_dependencies,\n        'compiler_fn': func,\n        'input': input_files,\n        'output': output_file,\n        'kwargs': {},\n    }", "response": "A custom function which must create the output file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_lxc(name, template='ubuntu', service=None):\n    service = service or LXCService\n    service.create(name, template=template)\n    meta = LXCMeta(initial=dict(type='LXC'))\n    lxc = LXC.with_meta(name, service, meta, save=True)\n    return lxc", "response": "Factory method for the generic LXC"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_lxc_with_overlays(name, base, overlays, overlay_temp_path=None,\n        service=None):\n    \"\"\"Creates an LXC using overlays.\n\n    This is a fast process in comparison to LXC.create because it does not\n    involve any real copying of data.\n    \"\"\"\n    service = service or LXCService\n    # Check that overlays has content\n    if not overlays:\n        raise TypeError(\"Argument 'overlays' must have at least one item\")\n\n    # Get the system's LXC path\n    lxc_path = service.lxc_path()\n    # Calculate base LXC's path\n    base_path = os.path.join(lxc_path, base)\n    # Calculate the new LXC's path\n    new_path = os.path.join(lxc_path, name)\n\n    # Create the new directory if it doesn't exist\n    if not os.path.exists(new_path):\n        os.mkdir(new_path)\n\n    overlay_group = OverlayGroup.create(new_path, base_path, overlays)\n    initial_meta = dict(type='LXCWithOverlays',\n            overlay_group=overlay_group.meta())\n    meta = LXCMeta(initial=initial_meta)\n    return LXCWithOverlays.with_meta(name, service, meta, overlay_group,\n            save=True)", "response": "Creates an LXC using overlays."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndestroys the unmanaged LXC object.", "response": "def destroy(self, force=False):\n        \"\"\"UnmanagedLXC Destructor.\n\n        It requires force to be true in order to work. Otherwise it throws an\n        error.\n        \"\"\"\n        if force:\n            super(UnmanagedLXC, self).destroy()\n        else:\n            raise UnmanagedLXCError('Destroying an unmanaged LXC might not '\n                'work. To continue please call this method with force=True')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets s all of the LXC s and creates objects for them", "response": "def list(self):\n        \"\"\"Get's all of the LXC's and creates objects for them\"\"\"\n        service = self._service\n\n        lxc_names = service.list_names()\n        lxc_list = []\n        for name in lxc_names:\n            lxc = self.get(name)\n            lxc_list.append(lxc)\n        return lxc_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve a single LXC by name", "response": "def get(self, name):\n        \"\"\"Retrieves a single LXC by name\"\"\"\n        lxc_meta_path = self._service.lxc_path(name,\n                constants.LXC_META_FILENAME)\n        meta = LXCMeta.load_from_file(lxc_meta_path)\n        lxc = self._loader.load(name, meta)\n        return lxc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize the pagination preference by query parameter Numbers only >= 0 & each query param may only be used once.", "response": "def init(req, model):  # pylint: disable=unused-argument\n    \"\"\" Determine the pagination preference by query parameter\n\n    Numbers only, >=0, & each query param may only be\n    specified once.\n\n    :return: Paginator object\n    \"\"\"\n\n    limit = req.get_param('page[limit]') or goldman.config.PAGE_LIMIT\n    offset = req.get_param('page[offset]') or 0\n\n    try:\n        return Paginator(limit, offset)\n    except ValueError:\n        raise InvalidQueryParams(**{\n            'detail': 'The page[\\'limit\\'] & page[\\'offset\\'] query '\n                      'params may only be specified once each & must '\n                      'both be an integer >= 0.',\n            'links': 'jsonapi.org/format/#fetching-pagination',\n            'parameter': 'page',\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate query parameters for the first page of the assessment set", "response": "def first(self):\n        \"\"\" Generate query parameters for the first page \"\"\"\n\n        if self.total and self.limit < self.total:\n            return {'page[offset]': 0, 'page[limit]': self.limit}\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating query parameters for the last page of the assessment set", "response": "def last(self):\n        \"\"\" Generate query parameters for the last page \"\"\"\n\n        if self.limit > self.total:\n            return None\n        elif self.offset >= self.total:\n            return None\n        else:\n            offset = (self.total / self.limit) * self.limit\n            return {'page[offset]': offset, 'page[limit]': self.limit}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prev(self):\n\n        if self.total:\n            if self.offset - self.limit - self.limit < 0:\n                return self.first\n            else:\n                offset = self.offset - self.limit\n                return {'page[offset]': offset, 'page[limit]': self.limit}\n        else:\n            return None", "response": "Generate query parameters for the previous page"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _cast_page(val):\n\n        try:\n            val = int(val)\n            if val < 0:\n                raise ValueError\n            return val\n        except (TypeError, ValueError):\n            raise ValueError", "response": "Convert the page limit & offset into int s & type check"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_dict(self):\n\n        return {\n            'current': self.current,\n            'first': self.first,\n            'last': self.last,\n            'next': self.more,\n            'prev': self.prev,\n        }", "response": "Convert the Paginator into a dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an array of shape nrows ncols with n subblocks preserving the physical layout of arr.", "response": "def blockshaped(arr, nrows, ncols):\n    \"\"\"\n    Return an new array of shape (n, nrows, ncols) where\n    n * nrows * ncols = arr.size\n\n    If arr is a 2D array, the returned array looks like n subblocks with\n    each subblock preserving the \"physical\" layout of arr.\n    \"\"\"\n    h, w = arr.shape\n    return (arr.reshape(h // nrows, nrows, -1, ncols)\n               .swapaxes(1, 2)\n               .reshape(-1, nrows, ncols))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unblockshaped(arr, h, w):\n    n, nrows, ncols = arr.shape\n    return (arr.reshape(h // nrows, -1, nrows, ncols)\n               .swapaxes(1, 2)\n               .reshape(h, w))", "response": "Return an array with h and w sublocks removed."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsplit an array into n0 n1 blocks", "response": "def into2dBlocks(arr, n0, n1):\n    \"\"\"\n    similar to blockshaped\n    but splits an array into n0*n1 blocks\n    \"\"\"\n    s0, s1 = arr.shape\n    b = blockshaped(arr, s0// n0, s1// n1)\n    return b.reshape(n0, n1, *b.shape[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from2dBlocks(arr):\n    s = arr.shape\n    s0, s1 = s[0] * s[2], s[1] * s[3]\n    return unblockshaped(arr.reshape(s[0] * s[1], s[2], s[3]), s0, s1)", "response": "Convert a 2d array of 2d blocks into a 2d array of 3d blocks"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef launch_server():\n    print(os.path.dirname(os.path.abspath(__file__)))\n    cur_dir = os.getcwd()\n    path = os.path.dirname(os.path.abspath(__file__))\n    run = True\n    os.chdir(path)\n    os.system('python manage.py runserver --nostatic')\n    os.chdir(cur_dir)", "response": "Launches the django server at 127. 0. 1 :8000"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndownload and unzip the report file at the given URL and return the contents of the first file found in the zip archive.", "response": "def get_zipped_file(url, encoding_error_opt='ignore'):\n    \"\"\"Download and unzip the report file at the given URL.\n\n    Downloads and unzips the CO-TRACER archive at the given URL. This is not\n    intended for data outside of the CO-TRACER official site and it will\n    automatically extract the first file found in the downloaded zip archive\n    as the CO-TRACER website produces single file archives. Note that the\n    contents of that file are loaded directly into memory.\n\n    @param url: The URL to download the archive from.\n    @type url: str\n    @return: The contents of the first file found in the provided archive.\n    @rtype: str\n    \"\"\"\n    remotezip = urllib2.urlopen(url)\n    raw_contents = cStringIO.StringIO(remotezip.read())\n    target_zip = zipfile.ZipFile(raw_contents)\n    first_filename = target_zip.namelist()[0]\n    return unicode(target_zip.read(first_filename), errors=encoding_error_opt)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_report_raw(year, report_type):\n    if not is_valid_report_type(report_type):\n        msg = '%s is not a valid report type.' % report_type\n        raise ValueError(msg)\n\n    url = get_url(year, report_type)\n    raw_contents = get_zipped_file(url)\n    return csv.DictReader(cStringIO.StringIO(raw_contents))", "response": "Download and extract a CO - TRACER report."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_report_interpreted(year, report_type):\n    if not is_valid_report_type(report_type):\n        msg = '%s is not a valid report type.' % report_type\n        raise ValueError(msg)\n\n    raw_report = get_report_raw(year, report_type)\n    interpreter = REPORT_TYPE_INTERPRETERS[report_type]\n    return interpreter(raw_report)", "response": "Download exract and interpret a CO - TRACER report and return a collection of dicts with the loaded data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_report(year, report_type=None):\n    if report_type == None:\n        report_types = constants.REPORT_TYPES\n        report_sections = [\n            get_report_interpreted(year, report) for report in report_types\n        ]\n\n        return dict(zip(constants.REPORT_TYPES, report_sections))\n    \n    else:\n        return get_report_interpreted(year, report_type)", "response": "Download extract and interpret a CO - TRACER report or reports for a given year."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef evalPatternInArray(pattern, arr):\n    l = len(pattern)\n    ll = len(arr)\n    # print l, ll\n    mx_additions = 3\n    sim = 0\n    i = 0\n    j = 0\n    c = 0\n    p = pattern[j]\n    v = arr[i]\n\n    while True:\n        # relative difference:\n        if p == v:\n            d = 0\n        elif v + p == 0:\n            d = v\n        else:\n            d = (p - v) / (v + p)\n        # print d\n        if abs(d) < 0.15:\n            c = mx_additions\n            j += 1\n            i += 1\n            if j == l:\n                j = 0\n            if i == ll:\n                # print sim, v, p,a\n                return sim\n            p = pattern[j]\n            v = arr[i]\n\n        elif d < 0:\n            # surplus line\n            c += 1\n            j += 1\n            if j == l:\n                j = 0\n            p += pattern[j]\n            sim += abs(d)\n        else:\n            # line missing\n            c += 1\n            i += 1\n            if i == ll:\n                return sim\n            v += arr[i]\n            sim += abs(d)\n        if c == mx_additions:\n            sim += abs(d)", "response": "returns similarity parameter of given pattern in given array"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a human - readable version string.", "response": "def version():\n    \"\"\"\n    Returns a human-readable version string.\n\n    For official releases, it will follow a semver style (e.g. ``1.2.7``).\n    For dev versions, it will have the semver style first, followed by\n    hyphenated qualifiers (e.g. ``1.2.7-dev``).\n\n    Returns a string.\n    \"\"\"\n    short = '.'.join([str(bit) for bit in __version__[:3]])\n    return '-'.join([short] + [str(bit) for bit in __version__[3:]])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setup(self, puller: bool=None, subscriptions: Dict[str, Any]={}):\n\t\tif puller:\n\t\t\tpuller = self._zmq.socket(zmq.PULL)\n\t\t\tip, port, host = self.rslv('rcv')\n\t\t\tpuller.bind('tcp://{}:{}'.format(host or ip, port))\n\t\t\tself.poll(puller)\n\t\tif subscriptions:\n\t\t\tfor publisher in subscriptions:  # type: str\n\t\t\t\tself.add(publisher, subscriptions[publisher].get('slots'), subscriptions[publisher].get('buffer-length'))\n\t\t\tlogger.info('Listening to %s', {\n\t\t\t\tk: (1 if subscriptions[k].get('slots') is None else len(subscriptions[k].get('slots')))\n\t\t\t\tfor k in subscriptions\n\t\t\t})", "response": "Sets up this Node with the specified Interfaces before it is run."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getBaseFileData(self, fileInfo, data, index1 = 47, index2 = 1):\n\t\tresult = fileInfo[fileInfo.find(data):]\n\t\tresult = result[result.find(\"<FONT \") + index1:]\n\t\tresult = result[:result.find(\"</FONT>\") - index2]\n\t\treturn result", "response": "Function to initialize the simple data for file info"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getFileCategory(self, fileInfo):\n\t\tcategory = fileInfo[fileInfo.find(\"Category\"):]\n\t\tcategory = category[category.find(\"<FONT \") + 47:]\n\t\tcategory = category[category.find('\">') + 2:]\n\t\tcategory = category[:category.find(\"</A></B>\") - 0]\n\t\treturn category", "response": "Function to get the file category for file info"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning to get the file s author for file info", "response": "def getFileAuthor(self, fileInfo):\n\t\t\"\"\"Function to get the file's author for file info, note that we are pretending that multiple authors do not exist here\"\"\"\n\t\tauthor = fileInfo[fileInfo.find(\"Author\"):]\n\t\tauthor = author[author.find(\"<FONT \") + 47:]\n\t\tauthor = author[author.find('<B>') + 3:]\n\t\tauthormail = author[author.find(\"mailto:\") + 7:]\n\t\tauthormail = authormail[:authormail.find('\"')]\n\t\tauthor = author[:author.find(\"</B></A>\") - 0]\n\t\tauthor = author + \" (\" + authormail + \")\"\n\t\treturn author"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions to get the number of times a file has been downloaded", "response": "def getNumDownloads(self, fileInfo):\n\t\t\"\"\"Function to get the number of times a file has been downloaded\"\"\"\n\t\tdownloads = fileInfo[fileInfo.find(\"FILE INFORMATION\"):]\n\t\tif -1 != fileInfo.find(\"not included in ranking\"):\n\t\t\treturn \"0\"\n\t\tdownloads = downloads[:downloads.find(\".<BR>\")]\n\t\tdownloads = downloads[downloads.find(\"</A> with \") + len(\"</A> with \"):]\n\t\treturn downloads"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts napoleon docstring to plain sphinx string.", "response": "def napoleon_to_sphinx(docstring, **config_params):\n    \"\"\"\n    Convert napoleon docstring to plain sphinx string.\n\n    Args:\n        docstring (str): Docstring in napoleon format.\n        **config_params (dict): Whatever napoleon doc configuration you want.\n\n    Returns:\n        str: Sphinx string.\n    \"\"\"\n    if \"napoleon_use_param\" not in config_params:\n        config_params[\"napoleon_use_param\"] = False\n\n    if \"napoleon_use_rtype\" not in config_params:\n        config_params[\"napoleon_use_rtype\"] = False\n\n    config = Config(**config_params)\n\n    return str(GoogleDocstring(docstring, config))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninvoke the CSV parser on an individual row", "response": "def run(cls, row, reader):\n        \"\"\" Invoke the CSV parser on an individual row\n\n        The row should already be a dict from the CSV reader.\n        The reader is passed in so we can easily reference the\n        CSV document headers & line number when generating\n        errors.\n        \"\"\"\n\n        cls._parse_keys(row, reader.line_num)\n        cls._parse_relationships(row, reader.line_num)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the keys in the row and check that they are not overrun.", "response": "def _parse_keys(row, line_num):\n        \"\"\" Perform some sanity checks on they keys\n\n        Each key in the row should not be named None cause\n        (that's an overrun). A key named `type` MUST be\n        present on the row & have a string value.\n\n        :param row: dict\n        :param line_num: int\n        \"\"\"\n\n        link = 'tools.ietf.org/html/rfc4180#section-2'\n\n        none_keys = [key for key in row.keys() if key is None]\n\n        if none_keys:\n            fail('You have more fields defined on row number {} '\n                 'than field headers in your CSV data. Please fix '\n                 'your request body.'.format(line_num), link)\n\n        elif not row.get('type'):\n            fail('Row number {} does not have a type value defined. '\n                 'Please fix your request body.'.format(line_num), link)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninvokes the deserializer If the payload is a collection (more than 1 records) then a list will be returned of normalized dict's. If the payload is a single item then the normalized dict will be returned (not a list) :return: list or dict", "response": "def deserialize(self, data=None):\n        \"\"\" Invoke the deserializer\n\n        If the payload is a collection (more than 1 records)\n        then a list will be returned of normalized dict's.\n\n        If the payload is a single item then the normalized\n        dict will be returned (not a list)\n\n        :return: list or dict\n        \"\"\"\n\n        data = []\n\n        if self.req.content_type_params.get('header') != 'present':\n            abort(exceptions.InvalidRequestHeader(**{\n                'detail': 'When using text/csv your Content-Type '\n                          'header MUST have a header=present parameter '\n                          '& the payload MUST include a header of fields',\n                'links': 'tools.ietf.org/html/rfc4180#section-3'\n            }))\n\n        try:\n            reader = csv.DictReader(self.req.stream)\n\n            self._validate_field_headers(reader)\n\n            for row in reader:\n                Parser.run(row, reader)\n\n                row = Normalizer.run(row, reader)\n                row = super(Deserializer, self).deserialize(data)\n\n                data.append(row)\n        except csv.Error:\n            abort(exceptions.InvalidRequestBody)\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms some validations on the CSV headers clf.", "response": "def _validate_field_headers(reader):\n        \"\"\" Perform some validations on the CSV headers\n\n        A `type` field header must be present & all field\n        headers must be strings.\n\n        :param reader: csv reader object\n        \"\"\"\n\n        link = 'tools.ietf.org/html/rfc4180#section-2'\n\n        for field in reader.fieldnames:\n            if not isinstance(field, str):\n                fail('All headers in your CSV payload must be '\n                     'strings.', link)\n\n        if 'type' not in reader.fieldnames:\n            fail('A type header must be present in your CSV '\n                 'payload.', link)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates xml content from given text", "response": "def __create_xml_request(self, text):\n        \"\"\" make xml content from given text \"\"\"\n        # create base stucture\n        soap_root = ET.Element('soap:Envelope', {\n            'xmlns:xsi': 'http://www.w3.org/2001/XMLSchema-instance',\n            'xmlns:xsd': 'http://www.w3.org/2001/XMLSchema',\n            'xmlns:soap': 'http://schemas.xmlsoap.org/soap/envelope/', })\n        body = ET.SubElement(soap_root, 'soap:Body')\n        process_text = ET.SubElement(body, 'ProcessText', {\n            'xmlns': 'http://typograf.artlebedev.ru/webservices/', })\n        # add contents\n        ET.SubElement(process_text, 'text').text = text\n        ET.SubElement(process_text, 'entityType').text = str(self._entityType)\n        ET.SubElement(process_text, 'useBr').text = str(self._useBr)\n        ET.SubElement(process_text, 'useP').text = str(self._useP)\n        ET.SubElement(process_text, 'maxNobr').text = str(self._maxNobr)\n        # create tree and write it\n        string = Container()\n        soap = ET.ElementTree(soap_root)\n        soap.write(string, encoding=self._encoding, xml_declaration=True)\n        if PY3:\n            return string.getvalue().decode(self._encoding)\n        return string.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __parse_xml_response(self, response):\n        # get xml from response\n        xml_response = response[response.find('<?xml'):].replace(' encoding=\"\"', '')\n        xml_content = xml.dom.minidom.parseString(xml_response)\n        return xml_content.getElementsByTagName('ProcessTextResult')[0].firstChild.nodeValue", "response": "parse response and get text result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_text(self, text):\n        # escape base char\n        text = text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')\n        # make xml request body\n        soap_body = self.__create_xml_request(text)\n        # make total request\n        length = len(soap_body.encode('UTF-8')) if PY3 else len(soap_body)\n        soap_request = self.SOAP_REQUEST.format(\n            length=length, host=self.HOST, content=soap_body)\n\n        if PY3:  # convert to bytes\n            soap_request = soap_request.encode(self._encoding)\n\n        # send request use soket\n        connector = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        connector.settimeout(self._timeout)\n        connector.connect((self.HOST, 80))\n        connector.sendall(soap_request)\n        # call for response\n        response = b''\n        buf = '0'\n        while len(buf):\n            buf = connector.recv(8192)\n            response += buf\n        connector.close()\n\n        if PY3:  # convert to str\n            response = response.decode()\n\n        # parse response\n        text_result = self.__parse_xml_response(response)\n        # back replace and return\n        return text_result.replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')", "response": "send request with given text and get result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef try_process_text(self, text):\n        if not text:\n            return text\n        try:\n            return self.process_text(text)\n        except (socket.gaierror, socket.timeout, xml.parsers.expat.ExpatError):\n            return text", "response": "safe process text if error - return not modifyed text"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_exe(name):\n    for path in os.getenv('PATH').split(os.pathsep):\n        for ext in ('', '.exe', '.cmd', '.bat', '.sh'):\n            full_path = os.path.join(path, name + ext)\n            if os.path.isfile(full_path) and os.access(full_path, os.X_OK):\n                return full_path\n    return None", "response": "Find an executable with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a version file for this package.", "response": "def generate_version_file(infile='version.py.in', outfile='version.py', **kwargs):\n    \"\"\"\n    Using input file, generate an output file with the version info for this package.\n    This should generally be used in setup.py to generate build stamp info.\n    :param infile:\n    :param outfile:\n    :param kwargs:\n    :return:\n    \"\"\"\n\n    if not os.path.exists(outfile) and os.path.exists(infile):\n        now = datetime.datetime.now()\n        repo_hash = ''\n        git_path = find_exe('git')\n        if git_path is not None:\n            git_cmd = [find_exe('git'), 'log', '--format=%h', '-1']\n            repo_hash = subprocess.Popen(git_cmd, stdout=subprocess.PIPE).communicate()[0].strip()\n        if repo_hash.strip() == '':\n            repo_hash = '{now.hour}.{now.minute}.{now.second}'.format(now=now)\n\n        sub_dict = {\n            'repo_hash': repo_hash,\n            'build_date': '{now.year}.{now.month}.{now.day}'.format(now=now),\n            'build_time': '{now.hour}.{now.minute}.{now.second}'.format(now=now),\n            'build_host': socket.gethostname(),\n            'build_user': getpass.getuser()\n        }\n        sub_dict.update(**kwargs)\n\n        with open(infile) as version_in:\n            version_data = version_in.read()\n            version_final = string.Template(version_data).safe_substitute(sub_dict)\n\n        with open(outfile, 'w') as version_out:\n            version_out.write(version_final)\n\n    return outfile if os.path.exists(outfile) else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets alignment of the current object.", "response": "def _set_align(self, orientation, value):\n        '''We define a setter because it's better to diagnose this kind of\n        programmatic error here than have to work out why alignment is odd when\n        we sliently fail!\n        '''\n        orientation_letter = orientation[0]\n        possible_alignments = getattr(\n            self, '_possible_{}aligns'.format(orientation_letter))\n        all_alignments = getattr(\n            self, '_all_{}aligns'.format(orientation_letter))\n        if value not in possible_alignments:\n            if value in all_alignments:\n                msg = 'non-permitted'\n            else:\n                msg = 'non-existant'\n            raise ValueError(\n                \"Can't set {} {} alignment {!r} on element {!r}\".format(\n                    msg, orientation, value, self))\n        setattr(self, '_{}align'.format(orientation_letter), value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake some lines to draw to the terminal and inserts the appropriate concrete escapes sequences by using data from the terminal object and styles dictionary.", "response": "def _populate_lines(self, block, terminal, styles, default_esc_seq):\n        '''Takes some lines to draw to the terminal, which may contain\n        formatting placeholder objects, and inserts the appropriate concrete\n        escapes sequences by using data from the terminal object and styles\n        dictionary.\n        '''\n        for line in block:\n            if hasattr(line, 'populate'):\n                line = line.populate(terminal, styles, default_esc_seq)\n            else:\n                line = default_esc_seq + line\n            yield line"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _tokenize(bytes, mimetype, extra_tokens=True):\n\n    # Start with only the ASCII bytes. Limit it to 8+ character strings.\n    try:\n        ascii_bytes = b' '.join(re.compile(b'[\\x00\\x09\\x0A\\x0D\\x20-\\x7E]{8,}').findall(bytes))\n        ascii_bytes = ascii_bytes.replace(b'\\x00', b'')\n    except:\n        return []\n\n    tokens = []\n\n    # Find anything sandwiched between ( )\n    results = re.compile(b'\\(([^\\)]+)\\)').findall(ascii_bytes)\n    #results = re.compile(b'\\(([^\\(\\)]+)\\)').findall(ascii_bytes)\n    tokens += results\n\n    # Find anything sandwiched between < >\n    results = re.compile(b'\\<([^\\>]+)\\>').findall(ascii_bytes)\n    #results = re.compile(b'\\<([^\\<\\>]+)\\>').findall(ascii_bytes)\n    tokens += results\n\n    # Find anything sandwiched between [ ]\n    results = re.compile(b'\\[([^\\]]+)\\]').findall(ascii_bytes)\n    #results = re.compile(b'\\[([^\\[\\]]+)\\]').findall(ascii_bytes)\n    tokens += results\n\n    # Find anything sandwiched between { }\n    results = re.compile(b'\\{([^\\}]+)\\}').findall(ascii_bytes)\n    #results = re.compile(b'\\{([^\\{\\}]+)\\}').findall(ascii_bytes)\n    tokens += results\n\n    if not mimetype == 'data':\n\n        # Find anything sandwiched between ' '\n        results = re.compile(b'\\'\\s*(.*?)\\s*\\'').findall(ascii_bytes)\n        tokens += results\n\n        # Find anything sandwiched between \" \"\n        results = re.compile(b'\\\"\\s*(.*?)\\s*\\\"').findall(ascii_bytes)\n        tokens += results\n\n    # Find anything sandwiched between spaces\n    results = re.compile(b'\\ ([^\\ ]+)\\ ').findall(ascii_bytes)\n    tokens += results\n\n    # Break the bytes apart if we want to generate even more tokens.\n    if extra_tokens:\n\n        # Add each newline as a token.\n        lines = ascii_bytes.decode('ascii', errors='ignore').splitlines()\n        tokens += [l.encode('ascii') for l in lines]\n\n        # Now replace these characters in the ASCII bytes with spaces to create more tokens.\n        replace_these = [b'(', b')', b'<', b'>', b'[', b']', b'{', b'}', b\"'\", b'\"', b'\\n', b'\\r', b'\\t', b'\\\\', b'`', b';']\n        for char in replace_these:\n            ascii_bytes = ascii_bytes.replace(char, b' ')\n\n        # Split the bytes on spaces and use the results as tokens.\n        tokens += ascii_bytes.split(b' ')\n\n    # Decode the tokens as ASCII.\n    tokens = [token.decode('ascii', errors='ignore') for token in tokens]\n\n    # Since we want this to find full URLs and not just potential domain names, we want\n    # to ensure that the tokens have at least \"http\" or \"/\" in them.\n    tokens = list(set([t for t in tokens if ('http' in t or 'ftp' in t or ('/' in t and '.' in t)) and len(t) >= 8]))\n\n    # Remove any tokens that look like they're probably bad based on the regex statements above.\n    tokens = [t for t in tokens if not all(x in t for x in ['(', ')'])]\n    tokens = [t for t in tokens if not all(x in t for x in ['<', '>'])]\n    tokens = [t for t in tokens if not all(x in t for x in ['[', ']'])]\n    tokens = [t for t in tokens if not all(x in t for x in ['{', '}'])]\n    tokens = [t for t in tokens if not any(x in t for x in ['\\t', '\\n', '\\r'])]\n    tokens = [t for t in tokens if t[:1].isalpha() or t[:1].isdigit()]\n    tokens = [t for t in tokens if not t.count('\\'') > 1]\n    tokens = [t for t in tokens if not t.count('\\\"') > 1]\n\n    # Return a list of the tokens in ASCII format.\n    return tokens", "response": "This function tokenizes the input bytes based on some common characters and returns the tokens in ASCII format."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _html_find_urls(bytes, mimetype, base_url=None):\n\n    def _recursive_tag_values(tag, values=[]):\n        \"\"\" This sub-function recursively loops through all of the tags to get all of the attribute values. \"\"\"\n\n        if hasattr(tag, 'children'):\n            for child in tag.children:\n                if hasattr(child, 'attrs'):\n                    for key in child.attrs:\n                        if isinstance(child.attrs[key], list):\n                            for value in child.attrs[key]:\n                                values.append(value)\n                        elif isinstance(child.attrs[key], str):\n                            values.append(child.attrs[key])\n\n                    values = _recursive_tag_values(child, values)\n\n        return values\n\n    # Only convert the ASCII bytes to HTML.\n    ascii_bytes = b''.join(re.compile(b'[\\x00\\x09\\x0A\\x0D\\x20-\\x7E]{8,}').findall(bytes))\n    ascii_bytes = ascii_bytes.replace(b'\\x00', b'')\n\n    # Store all of the URLs we find.\n    urls = []\n\n    # Convert the bytes into soup. Also try url decoding the bytes to bypass some obfuscation.\n    soups = []\n    soups.append(BeautifulSoup(ascii_bytes, 'lxml'))\n    try:\n        soups.append(BeautifulSoup(urllib.parse.unquote(str(ascii_bytes)), 'lxml'))\n    except:\n        pass\n\n    # Loop over both soups.\n    for soup in soups:\n\n        # Find any URLs embedded in script + document.write JavaScript.\n        # \\r\\n\\r\\ndocument.write(unescape('<meta HTTP-EQUIV=\"REFRESH\" content=\"0; url=http://somebadsite.com/catalog/index.php\">'));\\r\\n\\r\\n\n        script_urls = []\n        script_tags = soup.find_all('script')\n        for script_tag in script_tags:\n            for tag_content in script_tag.contents:\n                if 'document.write' in tag_content.lower():\n                    # Find the last position of the ( character, which should denote where the\n                    # code that they are writing to the page begins. Also find the position of\n                    # the first ) character which should denote where the code ends.\n                    code_begin = tag_content.rfind('(')\n                    code_end = tag_content.find(')')\n                    code = tag_content[code_begin+1:code_end]\n                    # Strip off any ' or \" quotes.\n                    if code.startswith('\\'') and code.endswith('\\''):\n                        code = code[1:-1]\n                    if code.startswith('\"') and code.endswith('\"'):\n                        code = code[1:-1]\n                    # Turn the string into bytes and feed it back into the _html_find_urls function.\n                    code = code.encode()\n                    script_urls += _html_find_urls(code, mimetype)\n\n        # Find any URLs embedded in <script> tags. Use the _ascii_find_urls function to try and catch everything.\n        for script_tag in script_tags:\n            script_urls += _ascii_find_urls(str(script_tag).encode('utf-8'), mimetype)\n\n        # Find any meta-refresh URLs.\n        # <meta HTTP-Equiv=\"refresh\" content=\"0; URL=UntitledNotebook1.html\">\n        meta_urls = []\n        meta_tags = soup.find_all('meta')\n        for meta_tag in meta_tags:\n            for key in meta_tag.attrs:\n                if key.lower() == 'content':\n                    value = meta_tag.attrs[key]\n                    if 'url=' in value.lower():\n                        split_value = value.split('=', 1)\n                        url = split_value[1]\n                        # Remove any quotes around the URL.\n                        if url.startswith('\"') and url.endswith('\"'):\n                            url = url[1:-1]\n                        if url.startswith(\"'\") and url.endswith(\"'\"):\n                            url = url[1:-1]\n                        meta_urls.append(url)\n\n        # Hacky way to find URLs in the CSS.\n        css_urls = re.compile(r'url\\((.*?)\\)').findall(str(soup))\n        \n        # Make sure none of the CSS URLs are in quotes.\n        for u in css_urls[:]:\n            if u.startswith('\\'') and u.endswith('\\''):\n                css_urls.remove(u)\n                css_urls.append(u[1:-1])\n            if u.startswith('\\\"') and u.endswith('\\\"'):\n                css_urls.remove(u)\n                css_urls.append(u[1:-1])\n\n        # Look to see if there is a \"base\" HTML tag specified. This is the \"baseStriker\" method.\n        for tag in soup.find_all('base'):\n            try:\n                if tag['href']:\n                    base_url = tag['href'].replace('\\\\\\\\', '//')\n            except:\n                pass\n\n        # If we were given a base URL, only extract specific tag values that are likely\n        # to be URLs. Otherwise, we would end up with joined URLs for every single tag\n        # attribute value that exists in the HTML, which is not the correct behavior.\n        if base_url:\n\n            # Join any of the CSS URLs we found.\n            for css_url in css_urls:\n                urls.append(urljoin(base_url, css_url))\n\n            # Join any of the script URLs we found.\n            for script_url in script_urls:\n                urls.append(urljoin(base_url, script_url))\n\n            # Join any of the meta-refresh URLs we found.\n            for meta_url in meta_urls:\n                urls.append(urljoin(base_url, meta_url))\n\n            # Get all of the action URLs.\n            for tag in soup.find_all(action=True):\n                urls.append(urljoin(base_url, tag['action']))\n\n            # Get all of the background URLs.\n            for tag in soup.find_all(background=True):\n                urls.append(urljoin(base_url, tag['background']))\n\n            # Get all of the href URLs.\n            for tag in soup.find_all(href=True):\n                urls.append(urljoin(base_url, tag['href']))\n\n            # Get all of the src URLs.\n            for tag in soup.find_all(src=True):\n                urls.append(urljoin(base_url, tag['src']))\n\n            # Get all of the xmlns URLs.\n            for tag in soup.find_all(xmlns=True):\n                urls.append(urljoin(base_url, tag['xmlns']))\n\n        # We weren't given a base URL, so just search for URLs by getting every single\n        # tag attribute value. That way we will catch everything regardless of the attribute name.\n        else:\n            urls = _recursive_tag_values(soup)\n            urls += css_urls\n            urls += meta_urls\n            urls += script_urls\n\n        # As a last-ditch effort, find URLs in the visible text of the HTML. However,\n        # we only want to add strings that are valid URLs as they are. What we do not\n        # want is to add every string as a potential URL, since if a base_url was given,\n        # we will likely end up with a joined URL for every string found in the HTML.\n        for s in soup.stripped_strings:\n            if is_valid(s):\n                urls.append(s)\n\n        # Remove any newlines from the potential URLs. Some HTML has newlines\n        # after the href=\" part before the actual URL begins. This renders\n        # correctly in web browsers but is otherwise considered an invalid\n        # URL by the is_valid function.\n        urls = [u.strip() for u in urls]\n\n        # Remove any leading //'s from the URLs.\n        urls = [u[2:] if u.startswith('//') else u for u in urls]\n\n    return urls", "response": "This function finds URLs inside of valid HTML bytes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _pdf_find_urls(bytes, mimetype):\n\n    # Start with only the ASCII bytes. Limit it to 12+ character strings.\n    try:\n        ascii_bytes = b' '.join(re.compile(b'[\\x00\\x09\\x0A\\x0D\\x20-\\x7E]{12,}').findall(bytes))\n        ascii_bytes = ascii_bytes.replace(b'\\x00', b'')\n    except:\n        return []\n\n    urls = []\n\n    # Find the embedded text sandwiched between [ ]\n    embedded_text = set(re.compile(b'(\\[(\\([\\x20-\\x27\\x2A-\\x7E]{1,3}\\)[\\-\\d]*){5,}\\])').findall(ascii_bytes))\n\n    # Get the text inside the parentheses. This catches URLs embedded in the text of the PDF that don't\n    # use the normal \"URI/URI()>>\" method.\n    for match in embedded_text:\n        text = match[0]\n        parentheses_text = b''.join(re.compile(b'\\((.*?)\\)').findall(text))\n        urls.append(parentheses_text)\n\n    # Find any URLs that use the \"URI/URI()>>\" method.\n    urls += re.compile(b'\\/URI\\s*\\((.*?)\\)\\s*>>').findall(ascii_bytes)\n\n    if urls:\n        # PDF URLs escape certain characters. We want to remove any of the escapes (backslashes)\n        # from the URLs so that we get the original URL.\n        urls = [u.replace(b'\\\\', b'') for u in urls]\n\n    return urls", "response": "This function finds URLs inside of a PDF file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_urls(thing, base_url=None, mimetype=None, log=False):\n\n    if log:\n        logging.basicConfig(level=logging.INFO,\n                            format='%(asctime)s %(name)s.%(funcName)s +%(lineno)s: %(levelname)-8s %(message)s')\n        logger = logging.getLogger(__name__)\n\n    # Convert \"thing\" to bytes if it is a string.\n    try:\n        if isinstance(thing, str):\n            thing = thing.encode(encoding='ascii', errors='ignore')\n    except:\n        if log:\n            logger.exception('Unable to convert thing to bytes.')\n        return []\n\n    # Store any URLs we find in the bytes.\n    all_urls = []\n\n    # Continue if we have bytes.\n    if isinstance(thing, bytes):\n\n        # Return an empty list if we failed to get the mimetype.\n        try:\n            if not mimetype:\n                mimetype = magic.from_buffer(thing)\n        except:\n            if log:\n                logger.exception('Unable to get mimetype from the bytes buffer.')\n            return []\n\n        mimetype = mimetype.lower()\n\n        # If the bytes are HTML...\n        if 'html' in mimetype:\n            try:\n                all_urls += _html_find_urls(thing, mimetype, base_url)\n            except:\n                if log:\n                    logger.exception('Error when finding HTML URLs.')\n\n        # If the bytes are a PDF...\n        elif 'pdf' in mimetype:\n            try:\n                all_urls += _pdf_find_urls(thing, mimetype)\n            except:\n                if log:\n                    logger.exception('Error when finding PDF URLs.')\n\n        # If the bytes are an RFC 822 e-mail...\n        elif 'rfc 822' in mimetype:\n            return []\n\n        # If the bytes are ASCII or Unicode text...\n        elif 'ascii' in mimetype or 'text' in mimetype:\n            try:\n                all_urls += _html_find_urls(thing, mimetype, base_url)\n            except:\n                if log:\n                    logger.exception('Error when finding ASCII/HTML URLs.')\n\n            try:\n                all_urls += _ascii_find_urls(thing, mimetype)\n            except:\n                if log:\n                    logger.exception('Error when finding ASCII URLs.')\n\n            try:\n                all_urls += _pdf_find_urls(thing, mimetype)\n            except:\n                if log:\n                    logger.exception('Error when finding ASCII/PDF URLs.')\n\n        # If the bytes are anything else...\n        else:\n\n            # Try to treat the bytes as a PDF and find URLs.\n            try:\n                all_urls += _pdf_find_urls(thing, mimetype)\n            except:\n                if log:\n                    logger.exception('Error when finding unknown/PDF URLs.')\n\n            # If we don't know how to handle this mimetype, the bytes are likely just \"data\".\n            # In that case, we don't want to find all possible ASCII URLs, as it will result\n            # in a lot of bad URLs. Try to treat the bytes as ASCII and find URLs.\n            try:\n                all_urls += _ascii_find_urls(thing, mimetype, extra_tokens=False)\n            except:\n                if log:\n                    logger.exception('Error when finding unknown/ASCII URLs.')\n\n    # Make sure we only have valid URLs.\n    valid_urls = []\n    for url in list(set(all_urls)):\n        try:\n            # If the URL is valid as-is, just add it to the list.\n            if is_valid(url):\n                valid_urls.append(url)\n\n            # The URL is not valid. If we were given a base URL, try joining them and checking if the result is valid.\n            elif base_url:\n                joined_url = urljoin(base_url, url)\n                if is_valid(joined_url):\n                    valid_urls.append(joined_url)\n        except:\n            pass\n\n    # For the edge cases of HTML files where we didn't find any URLs, treat it as an ASCII file\n    # and re-find any URLs that way.\n    if not valid_urls and 'html' in mimetype:\n        try:\n            for url in _ascii_find_urls(thing, mimetype):\n                # If the URL is valid as-is, just add it to the list.\n                if is_valid(url):\n                    valid_urls.append(url)\n\n                # The URL is not valid. If we were given a base URL, try joining them and checking if the result is valid.\n                elif base_url:\n                    joined_url = urljoin(base_url, url)\n                    if is_valid(joined_url):\n                        valid_urls.append(joined_url)\n        except:\n            pass\n\n    # Return the valid URLs in ASCII form.\n    ascii_urls = []\n    for url in valid_urls:\n        try:\n            if isinstance(url, str):\n                ascii_urls.append(url)\n\n            if isinstance(url, bytes):\n                ascii_urls.append(url.decode('ascii', errors='ignore'))\n        except:\n            pass\n\n    # Check if any of the URLs are Proofpoint URLs and try to decode them.\n    for url in ascii_urls[:]:\n        if 'urldefense.proofpoint.com/v2/url' in url:\n            try:\n                query_u=parse_qs(urlparse(url).query)['u'][0]\n                decoded_url = query_u.replace('-3A', ':').replace('_', '/').replace('-2D', '-')\n                if is_valid(decoded_url):\n                    ascii_urls.append(decoded_url)\n            except:\n                if log:\n                    logger.exception('Error decoding Proofpoint URL: {}'.format(url))\n\n    # Check if any of the URLs are Outlook safelinks and try to decode them.\n    for url in ascii_urls[:]:\n        if 'safelinks.protection.outlook.com' in url:\n            try:\n                query_url=parse_qs(urlparse(url).query)['url'][0]\n                decoded_url = urllib.parse.unquote(query_url)\n                if is_valid(decoded_url):\n                    ascii_urls.append(decoded_url)\n            except:\n                if log:\n                    logger.exception('Error decoding Outlook safelinks URL: {}'.format(url))\n\n    # Check if any of the URLs are Google redirection URLs and try to decode them.\n    for url in ascii_urls[:]:\n        if 'www.google.com/url?' in url:\n            try:\n                query_url=parse_qs(urlparse(url).query)['q'][0]\n                decoded_url = urllib.parse.unquote(query_url)\n                if is_valid(decoded_url):\n                    ascii_urls.append(decoded_url)\n            except:\n                if log:\n                    logger.exception('Error decoding Google redirection URL: {}'.format(url))\n\n    # Add an unquoted version of each URL to the list.\n    for url in ascii_urls[:]:\n        ascii_urls.append(urllib.parse.unquote(url))\n\n    # Add http:// to the beginning of each URL if it isn't there already. This lets us properly\n    # catch URLs that may not have the scheme on the front of them.\n    ascii_urls = ['http://' + u if not u.lower().startswith('http') and not u.lower().startswith('ftp') else u for u in ascii_urls]\n\n    # Remove any trailing \"/\" from the URLs so that they are consistent with how they go in CRITS.\n    ascii_urls = [u[:-1] if u.endswith('/') else u for u in ascii_urls]\n\n    return sorted(list(set(ascii_urls)))", "response": "This function will extract URLs from a string or bytes buffer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the given URL is a valid URL.", "response": "def is_valid(url, fix=True):\n    \"\"\" Returns True if this is what we consider to be a valid URL.\n\n        A valid URL has:\n            * http OR https scheme\n            * a valid TLD\n\n        If there is no scheme, it will check the URL assuming the scheme is http.\n\n        Returns False if the URL is not valid.\n    \"\"\"\n\n    try:\n        # Convert the url to a string if we were given it as bytes.\n        if isinstance(url, bytes):\n            url = url.decode('ascii', errors='replace')\n\n        # Hacky way to deal with URLs that have a username:password notation.\n        user_pass_url = ''\n\n        # Check for no scheme and assume http.\n        split_url = urlsplit(url)\n\n        # If there is no scheme, there is a higher chance that this might not actually be a URL.\n        # For example, it might be something that resembles a URL that got pulled out of random bytes.\n        # As such, we can probably safely exclude URLs that have unusual characters in them.\n        if not split_url.scheme:\n            invalid_chars = ['\\'']\n            if any(c in url for c in invalid_chars):\n                return False\n\n        # Append the http scheme to the URL if it doesn't have any scheme.\n        if fix and not split_url.scheme:\n            split_url = urlsplit('http://{}'.format(url))\n\n        # Check for the edge case of results returned by find_urls, such as google.com URLs\n        # like: http://google.com#default#userData\n        if split_url.netloc and not split_url.path and split_url.fragment:\n            return False\n\n        # Check if the netloc has a ':' in it, which indicates that\n        # there is a port number specified. We need to remove that in order\n        # to properly check if it is a valid IP address.\n        if ':' in split_url.netloc:\n            netloc = split_url.netloc.split(':')[0]\n        else:\n            netloc = split_url.netloc\n\n        # Make sure the URL doesn't have a \\ character in it.\n        if '\\\\' in url:\n            return False\n\n        # Some quick and dirty tests to detect invalid characters from different parts of the URL.\n        # Domain names need to have only: a-z, 0-9, -, and . But due to how urlsplit works, they\n        # might also contain : and @ if there is a user/pass or port number specified.\n        if re.compile(r'([^a-zA-Z0-9\\-\\.\\:\\@]+)').findall(split_url.netloc):\n            return False\n\n        # Check if the valid URL conditions are now met.\n        if split_url.scheme == 'http' or split_url.scheme == 'https' or split_url.scheme == 'ftp':\n\n            # Look for the edge case of the URL having a username:password notation.\n            if ':' in split_url.netloc and '@' in split_url.netloc:\n                user_pass = re.compile(r'(.*?:.*?@)').findall(split_url.netloc)[0]\n                user_pass_url = url.replace(user_pass, '')\n                split_url = urlsplit(user_pass_url)\n                netloc = split_url.netloc\n\n            # Check the netloc. Check if it is an IP address.\n            try:\n                ipaddress.ip_address(netloc)\n                return True\n            # If we got an exception, it must be a domain name.\n            except:\n\n                # Hacky way to out which version of the URL we need to check.\n                if user_pass_url:\n                    url_to_check = user_pass_url\n                else:\n                    url_to_check = url\n\n                # Hacky way to deal with FTP URLs since the tld package cannot handle them.\n                if split_url.scheme == 'ftp':\n                    url_to_check = url_to_check.replace('ftp', 'http')\n\n                # Check the URL for a valid TLD.\n                res = get_tld(url_to_check, fix_protocol=True, as_object=True)\n\n                # The tld package likes to consider single words (like \"is\") as a valid domain. To fix this,\n                # we want to only consider it a valid URL if there is actually a suffix. Additionally, to weed\n                # out \"URLs\" that are probably e-mail addresses or other garbage, we do not want to consider\n                # anything that has invalid characters in it.\n                if res.fld and res.tld and res.domain:\n                    if all(ord(c) == 45 or ord(c) == 46 or (48 <= ord(c) <= 57) or (65 <= ord(c) <= 90) or (97 <= ord(c) <= 122) for c in netloc):\n\n                        # Finally, check if all of the characters in the URL are ASCII.\n                        if all(32 <= ord(c) <= 126 for c in url):\n                            return True\n\n        # Return False by default.\n        return False\n    except:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef translate_path(self, path):\n        # abandon query parameters\n        path = path.split('?', 1)[0]\n        path = path.split('#', 1)[0]\n        # Don't forget explicit trailing slash when normalizing. Issue17324\n        trailing_slash = path.rstrip().endswith('/')\n        path = posixpath.normpath(urllib.unquote(path))\n        # remove url_prefix\n        #print \"PATH 1: \", path, self._url_prefix\n        path = path.replace(self._url_prefix, '/', 1)\n        #print \"PATH 2: \", path\n        words = path.split('/')\n        words = filter(None, words)\n        # This the new way to NOT only work in CWD\n        path = self._root\n        for word in words:\n            if os.path.dirname(word) or word in (os.curdir, os.pardir):\n                # Ignore components that are not a simple file/directory name\n                continue\n            path = os.path.join(path, word)\n        if trailing_slash:\n            path += '/'\n        #print \"PATH: \", path\n        #print \"URL_PREFIX\", self._url_prefix\n        #print \"PREFIX\", self.prefix\n        return path", "response": "Translate a / - separated PATH to the local filename syntax."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(self):\n\n        if self.rid and not self.is_loaded:\n            store = goldman.sess.store\n            self._is_loaded = True\n\n            self.model = store.find(self.rtype, self.field, self.rid)\n\n        return self.model", "response": "Load the model from the store"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting the value to a ToOne instance.", "response": "def to_native(self, value, context=None):\n        \"\"\" Schematics deserializer override\n\n        :return: ToOne instance\n        \"\"\"\n\n        if isinstance(value, ToOne):\n            return value\n\n        value = self._cast_rid(value)\n        return ToOne(self.rtype, self.field, rid=value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_primitive(self, value, context=None):\n\n        if context and context.get('rel_ids'):\n            return value.rid\n        else:\n            return {'rtype': value.rtype, 'rid': value.rid}", "response": "Schematics serializer override\n\n        :return: dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the to_one field is valid.", "response": "def validate_to_one(self, value):\n        \"\"\" Check if the to_one should exist & casts properly \"\"\"\n\n        if value.rid and self.typeness is int:\n            validators.validate_int(value)\n\n        if value.rid and not self.skip_exists:\n            if not value.load():\n                raise ValidationError(self.messages['exists'])\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a HTTPStatus compliant body of the object.", "response": "def get_body(self):\n        \"\"\" Return a HTTPStatus compliant body attribute\n\n        Be sure to purge any unallowed properties from the object.\n\n        TIP: At the risk of being a bit slow we copy the errors\n             instead of mutating them since they may have key/vals\n             like headers that are useful elsewhere.\n        \"\"\"\n\n        body = copy.deepcopy(self.errors)\n\n        for error in body:\n            for key in error.keys():\n                if key not in self.ERROR_OBJECT_FIELDS:\n                    del error[key]\n        return json.dumps({'errors': body})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_headers(self):\n\n        headers = {'Content-Type': goldman.JSON_MIMETYPE}\n\n        for error in self.errors:\n            if 'headers' in error:\n                headers.update(error['headers'])\n        return headers", "response": "Return a HTTPStatus compliant headers attribute"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_status(self):\n\n        codes = [error['status'] for error in self.errors]\n        same = all(code == codes[0] for code in codes)\n\n        if not same and codes[0].startswith('4'):\n            return falcon.HTTP_400\n        elif not same and codes[0].startswith('5'):\n            return falcon.HTTP_500\n        else:\n            return codes[0]", "response": "Return a HTTPStatus compliant status attribute for the current HTTP response code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deserialize(self, mimetypes):  # pylint: disable=arguments-differ\n\n        super(Deserializer, self).deserialize()\n\n        parts = self.parse(mimetypes)\n        data = self.normalize(parts)\n\n        return data", "response": "Deserializes the request object into a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef normalize(self, parts):\n\n        part = parts.list[0]\n\n        return {\n            'content': part.file.read(),\n            'content-type': part.type,\n            'file-ext': extensions.get(part.type),\n            'file-name': part.filename,\n        }", "response": "This method is used to normalize the already vetted & parsed FieldStorage objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse & validate a part according to section 3.", "response": "def _parse_section_three(self, part, mimetypes):\n        \"\"\" Parse & validate a part according to section #3\n\n        The logic applied follows section 3 guidelines from top\n        to bottom.\n        \"\"\"\n\n        link = 'tools.ietf.org/html/rfc2388#section-3'\n\n        if part.disposition != 'form-data' or not part.name:\n            self.fail('Each part of a multipart/form-data requires a '\n                      'Content-Disposition header with a disposition type '\n                      'of \"form-data\" AND a unique \"name\" parameter.', link)\n        elif part.type.lower() not in mimetypes:\n            allowed = ', '.join(mimetypes)\n            self.fail('Invalid upload Content-Type. Each part of the '\n                      'multipart/form-data upload MUST be one of: %s. '\n                      '%s is not allowed.' % (allowed, part.type), link)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(self, mimetypes):\n\n        self._parse_top_level_content_type()\n\n        link = 'tools.ietf.org/html/rfc2388'\n        parts = cgi.FieldStorage(\n            fp=self.req.stream,\n            environ=self.req.env,\n        )\n\n        if not parts:\n            self.fail('A payload in the body of your request is required '\n                      '& must be encapsulated by the boundary with proper '\n                      'headers according to RFC 2388', link)\n        elif len(parts) > 1:\n            self.fail('Currently, only 1 upload at a time is allowed. Please '\n                      'break up your request into %s individual requests & '\n                      'retry' % len(parts), link)\n        else:\n            self._parse_part(parts.list[0], mimetypes)\n            return parts", "response": "Parse the request and return a list of cgi. FieldStorage objects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef range_per_level(start, stop):\n    if start < 0 or stop > MAX_POSITION + 1:\n        raise OutOfRangeError(\n            'Interval %d:%d is out of range (maximum position is %d)'\n            % (start, stop, MAX_POSITION))\n\n    # Note that we treat the zero-length interval `x:x` as `x:x+1`.\n    start_bin = start\n    stop_bin = max(start, stop - 1)\n\n    start_bin >>= SHIFT_FIRST\n    stop_bin >>= SHIFT_FIRST\n\n    for offset in BIN_OFFSETS:\n        yield offset + start_bin, offset + stop_bin\n        start_bin >>= SHIFT_NEXT\n        stop_bin >>= SHIFT_NEXT", "response": "Returns an iterator that yields each level of the tree that is sorted by the interval start and stop."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef assign_bin(start, stop):\n    try:\n        return next(dropwhile(lambda r: r[0] != r[1],\n                              range_per_level(start, stop)))[0]\n    except StopIteration:\n        raise Exception('An unexpected error occured in assigning a bin')", "response": "Given an interval start and stop return the smallest bin containing start and stop."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef overlapping_bins(start, stop=None):\n    if stop is None:\n        stop = start + 1\n\n    return [bin\n            for first, last in range_per_level(start, stop)\n            for bin in range(first, last + 1)]", "response": "Given an interval start and stop return a list of overlapping bin numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef containing_bins(start, stop=None):\n    if stop is None:\n        stop = start + 1\n\n    max_bin = assign_bin(start, stop)\n    return [bin for bin in overlapping_bins(start, stop) if bin <= max_bin]", "response": "Given an interval start and stop return all the bin numbers that are contained within the bin level."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives an interval start and stop return all contained bins.", "response": "def contained_bins(start, stop=None):\n    \"\"\"\n    Given an interval `start:stop`, return bins for intervals completely\n    *contained by* `start:stop`. The order is according to the bin level\n    (starting with the smallest bins), and within a level according to the bin\n    number (ascending).\n\n    :arg int start, stop: Interval positions (zero-based, open-ended). If\n      `stop` is not provided, the interval is assumed to be of length 1\n      (equivalent to `stop = start + 1`).\n\n    :return: All bins for intervals contained by `start:stop`, ordered first\n      according to bin level (ascending) and then according to bin number\n      (ascending).\n    :rtype: list(int)\n\n    :raise OutOfRangeError: If `start:stop` exceeds the range of the binning\n      scheme.\n    \"\"\"\n    if stop is None:\n        stop = start + 1\n\n    min_bin = assign_bin(start, stop)\n    return [bin for bin in overlapping_bins(start, stop) if bin >= min_bin]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef covered_interval(bin):\n    if bin < 0 or bin > MAX_BIN:\n        raise OutOfRangeError(\n            'Invalid bin number %d (maximum bin number is %d)'\n            % (bin, MAX_BIN))\n\n    shift = SHIFT_FIRST\n    for offset in BIN_OFFSETS:\n        if offset <= bin:\n            return bin - offset << shift, bin + 1 - offset << shift\n        shift += SHIFT_NEXT", "response": "Given a bin number bin return the interval covered by this bin."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stitchModules(module, fallbackModule):\n    \n    for name, attr in fallbackModule.__dict__.items():\n        if name not in module.__dict__:\n            module.__dict__[name] = attr", "response": "stitches the given module with the attributes of the given fallbackModule"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getTarget(self, iid):\n        '''\n            Returns a dictionary containing information about a certain target\n        '''\n        sql = 'select name, path from {} where _id=?'.format(self.TABLE_ITEMS)\n        data = self.db.execute(sql, (iid,)).fetchone()\n\n        if data:\n            return {'name': data[0], 'path': data[1]}\n\n        return None", "response": "Returns a dictionary containing information about a certain target\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insertTarget(self, name, path):\n        '''\n            Inserts a new target into the vault database\n            Returns the id of the created target\n        '''\n        sql = 'insert into {}(name, path) values (?,?);'.format(self.TABLE_ITEMS)\n\n        try:\n            _id = self.db.execute(sql, (name, path)).lastrowid\n            self.db.commit()\n\n            return _id\n        except sqlite3.IntegrityError:\n            return None", "response": "Inserts a new target into the vault database returning the id of the created target"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef removeTarget(self, iid):\n        '''\n            Removes target information from vault database\n        '''\n        sql = 'delete from {} where _id=?'.format(self.TABLE_ITEMS)\n        cursor = self.db.execute(sql, (iid,))\n\n        if cursor.rowcount > 0:\n            self.db.commit()\n\n            return True\n\n        return False", "response": "Removes target information from vault database"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of all the items secured in the vault", "response": "def listTargets(self):\n        '''\n            Returns a list of all the items secured in the vault\n        '''\n        sql = 'select * from {}'.format(self.TABLE_ITEMS)\n        cursor = self.db.execute(sql)\n\n        return [(iid, name, path) for iid, name, path in cursor]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pre_create(sender, model):\n\n    model.created = dt.utcnow()\n    model.creator = goldman.sess.login", "response": "Callback before creating any new model"}
