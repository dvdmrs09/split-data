{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef security_descriptor(self):\n    fwnt_security_descriptor = pyfwnt.security_descriptor()\n    fwnt_security_descriptor.copy_from_byte_stream(self._fsntfs_attribute.data)\n    return fwnt_security_descriptor", "response": "pyfwnt. security_descriptor : security descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _EntriesGenerator(self):\n    try:\n      fsntfs_file_entry = self._file_system.GetNTFSFileEntryByPathSpec(\n          self.path_spec)\n    except errors.PathSpecError:\n      fsntfs_file_entry = None\n\n    if fsntfs_file_entry:\n      location = getattr(self.path_spec, 'location', None)\n\n      for fsntfs_sub_file_entry in fsntfs_file_entry.sub_file_entries:\n        directory_entry = fsntfs_sub_file_entry.name\n\n        # Ignore references to self or parent.\n        if directory_entry in ('.', '..'):\n          continue\n\n        file_reference = fsntfs_sub_file_entry.file_reference\n        directory_entry_mft_entry = (\n            file_reference & _FILE_REFERENCE_MFT_ENTRY_BITMASK)\n\n        if location == self._file_system.PATH_SEPARATOR:\n          directory_entry = self._file_system.JoinPath([directory_entry])\n        else:\n          directory_entry = self._file_system.JoinPath([\n              location, directory_entry])\n\n        yield ntfs_path_spec.NTFSPathSpec(\n            location=directory_entry,\n            mft_attribute=fsntfs_sub_file_entry.name_attribute_index,\n            mft_entry=directory_entry_mft_entry, parent=self.path_spec.parent)", "response": "Retrieves the directory entries."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _GetAttributes(self):\n    if self._attributes is None:\n      self._attributes = []\n      for fsntfs_attribute in self._fsntfs_file_entry.attributes:\n        attribute_class = self._ATTRIBUTE_TYPE_CLASS_MAPPINGS.get(\n            fsntfs_attribute.attribute_type, NTFSAttribute)\n\n        attribute_object = attribute_class(fsntfs_attribute)\n        self._attributes.append(attribute_object)\n\n    return self._attributes", "response": "Retrieves the attributes.\n\n    Returns:\n      list[NTFSAttribute]: attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve the data streams.", "response": "def _GetDataStreams(self):\n    \"\"\"Retrieves the data streams.\n\n    Returns:\n      list[NTFSDataStream]: data streams.\n    \"\"\"\n    if self._data_streams is None:\n      self._data_streams = []\n      if self._fsntfs_file_entry.has_default_data_stream():\n        data_stream = NTFSDataStream(None)\n        self._data_streams.append(data_stream)\n\n      for fsntfs_data_stream in self._fsntfs_file_entry.alternate_data_streams:\n        data_stream = NTFSDataStream(fsntfs_data_stream)\n        self._data_streams.append(data_stream)\n\n    return self._data_streams"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve a directory from the file system.", "response": "def _GetDirectory(self):\n    \"\"\"Retrieves a directory.\n\n    Returns:\n      NTFSDirectory: directory or None if not available.\n    \"\"\"\n    if self._fsntfs_file_entry.number_of_sub_file_entries == 0:\n      return None\n    return NTFSDirectory(self._file_system, self.path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _GetLink(self):\n    if self._link is None:\n      self._link = ''\n      if not self._IsLink(self._fsntfs_file_entry.file_attribute_flags):\n        return self._link\n\n      link = self._fsntfs_file_entry.reparse_point_print_name\n      if link:\n        # Strip off the drive letter, we assume the link is within\n        # the same volume.\n        _, _, self._link = link.rpartition(':')\n\n    return self._link", "response": "Retrieves the link.\n\n    Returns:\n      str: path of the linked file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves the stat information about the file entry.", "response": "def _GetStat(self):\n    \"\"\"Retrieves information about the file entry.\n\n    Returns:\n      VFSStat: a stat object.\n    \"\"\"\n    stat_object = super(NTFSFileEntry, self)._GetStat()\n\n    # File data stat information.\n    if self._fsntfs_file_entry.has_default_data_stream():\n      stat_object.size = self._fsntfs_file_entry.get_size()\n\n    # Ownership and permissions stat information.\n    # TODO: stat_object.mode\n    # TODO: stat_object.uid\n    # TODO: stat_object.gid\n\n    # File entry type stat information.\n    if self._IsLink(self._fsntfs_file_entry.file_attribute_flags):\n      stat_object.type = stat_object.TYPE_LINK\n    elif self._fsntfs_file_entry.has_directory_entries_index():\n      stat_object.type = stat_object.TYPE_DIRECTORY\n    else:\n      stat_object.type = stat_object.TYPE_FILE\n\n    # Other stat information.\n    file_reference = self._fsntfs_file_entry.file_reference\n    stat_object.ino = file_reference & _FILE_REFERENCE_MFT_ENTRY_BITMASK\n    stat_object.fs_type = 'NTFS'\n\n    stat_object.is_allocated = self._fsntfs_file_entry.is_allocated()\n\n    return stat_object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef access_time(self):\n    timestamp = self._fsntfs_file_entry.get_access_time_as_integer()\n    return dfdatetime_filetime.Filetime(timestamp=timestamp)", "response": "Returns the current access time of the file entry or None if not available."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the change time of the file entry or None if not available.", "response": "def change_time(self):\n    \"\"\"dfdatetime.DateTimeValues: change time or None if not available.\"\"\"\n    timestamp = self._fsntfs_file_entry.get_entry_modification_time_as_integer()\n    return dfdatetime_filetime.Filetime(timestamp=timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the creation time of the file.", "response": "def creation_time(self):\n    \"\"\"dfdatetime.DateTimeValues: creation time or None if not available.\"\"\"\n    timestamp = self._fsntfs_file_entry.get_creation_time_as_integer()\n    return dfdatetime_filetime.Filetime(timestamp=timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef name(self):\n    # The root directory file name is typically '.', dfVFS however uses ''.\n    if self._is_root:\n      return ''\n\n    mft_attribute = getattr(self.path_spec, 'mft_attribute', None)\n    if mft_attribute is not None:\n      return self._fsntfs_file_entry.get_name_by_attribute_index(mft_attribute)\n    return self._fsntfs_file_entry.get_name()", "response": "str name of the file entry which does not include the full path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the modification time of the file entry or None if not available.", "response": "def modification_time(self):\n    \"\"\"dfdatetime.DateTimeValues: modification time or None if not available.\"\"\"\n    timestamp = self._fsntfs_file_entry.get_modification_time_as_integer()\n    return dfdatetime_filetime.Filetime(timestamp=timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the file - like object.", "response": "def GetFileObject(self, data_stream_name=''):\n    \"\"\"Retrieves the file-like object.\n\n    Args:\n      data_stream_name (Optional[str]): data stream name, where an empty\n          string represents the default data stream.\n\n    Returns:\n      NTFSFileIO: file-like object or None.\n    \"\"\"\n    if (not data_stream_name and\n        not self._fsntfs_file_entry.has_default_data_stream()):\n      return None\n\n    # Make sure to make the changes on a copy of the path specification, so we\n    # do not alter self.path_spec.\n    path_spec = copy.deepcopy(self.path_spec)\n    if data_stream_name:\n      setattr(path_spec, 'data_stream', data_stream_name)\n\n    return resolver.Resolver.OpenFileObject(\n        path_spec, resolver_context=self._resolver_context)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the linked file entry e. g. for a symbolic link.", "response": "def GetLinkedFileEntry(self):\n    \"\"\"Retrieves the linked file entry, e.g. for a symbolic link.\n\n    Returns:\n      NTFSFileEntry: linked file entry or None.\n    \"\"\"\n    link = self._GetLink()\n    if not link:\n      return None\n\n    # TODO: is there a way to determine the MFT entry here?\n    link_mft_entry = None\n\n    parent_path_spec = getattr(self.path_spec, 'parent', None)\n    path_spec = ntfs_path_spec.NTFSPathSpec(\n        location=link, parent=parent_path_spec)\n\n    is_root = bool(\n        link == self._file_system.LOCATION_ROOT or\n        link_mft_entry == self._file_system.MFT_ENTRY_ROOT_DIRECTORY)\n\n    return NTFSFileEntry(\n        self._resolver_context, self._file_system, path_spec, is_root=is_root)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves the parent file entry.", "response": "def GetParentFileEntry(self):\n    \"\"\"Retrieves the parent file entry.\n\n    Returns:\n      NTFSFileEntry: parent file entry or None if not available.\n    \"\"\"\n    location = getattr(self.path_spec, 'location', None)\n    if location is not None:\n      parent_location = self._file_system.DirnamePath(location)\n      if parent_location == '':\n        parent_location = self._file_system.PATH_SEPARATOR\n\n    parent_file_reference = None\n    mft_attribute = getattr(self.path_spec, 'mft_attribute', None)\n    if mft_attribute is not None:\n      parent_file_reference = (\n          self._fsntfs_file_entry.get_parent_file_reference_by_attribute_index(\n              mft_attribute))\n    else:\n      parent_file_reference = (\n          self._fsntfs_file_entry.get_parent_file_reference())\n\n    if parent_file_reference is None:\n      return None\n\n    parent_mft_entry = (\n        parent_file_reference & _FILE_REFERENCE_MFT_ENTRY_BITMASK)\n\n    parent_path_spec = getattr(self.path_spec, 'parent', None)\n    # TODO: determine and pass the mft_attribute of the parent\n    # for a faster resolve of the file entry.\n    path_spec = ntfs_path_spec.NTFSPathSpec(\n        location=parent_location, mft_entry=parent_mft_entry,\n        parent=parent_path_spec)\n\n    # TODO: handle parent correctly use attribute index?\n    is_root = bool(\n        parent_location == self._file_system.LOCATION_ROOT or\n        parent_mft_entry == self._file_system.MFT_ENTRY_ROOT_DIRECTORY)\n\n    return NTFSFileEntry(\n        self._resolver_context, self._file_system, path_spec, is_root=is_root)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the security descriptor.", "response": "def GetSecurityDescriptor(self):\n    \"\"\"Retrieves the security descriptor.\n\n    Returns:\n      pyfwnt.security_descriptor: security descriptor.\n    \"\"\"\n    fwnt_security_descriptor = pyfwnt.security_descriptor()\n    fwnt_security_descriptor.copy_from_byte_stream(\n        self._fsntfs_file_entry.security_descriptor_data)\n\n    return fwnt_security_descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _ReadFileEntry(self, file_object, file_offset):\n    if self.file_format == 'bin-big-endian':\n      data_type_map = self._CPIO_BINARY_BIG_ENDIAN_FILE_ENTRY\n      file_entry_data_size = self._CPIO_BINARY_BIG_ENDIAN_FILE_ENTRY_SIZE\n    elif self.file_format == 'bin-little-endian':\n      data_type_map = self._CPIO_BINARY_LITTLE_ENDIAN_FILE_ENTRY\n      file_entry_data_size = self._CPIO_BINARY_LITTLE_ENDIAN_FILE_ENTRY_SIZE\n    elif self.file_format == 'odc':\n      data_type_map = self._CPIO_PORTABLE_ASCII_FILE_ENTRY\n      file_entry_data_size = self._CPIO_PORTABLE_ASCII_FILE_ENTRY_SIZE\n    elif self.file_format in ('crc', 'newc'):\n      data_type_map = self._CPIO_NEW_ASCII_FILE_ENTRY\n      file_entry_data_size = self._CPIO_NEW_ASCII_FILE_ENTRY_SIZE\n\n    file_entry = self._ReadStructure(\n        file_object, file_offset, file_entry_data_size, data_type_map,\n        'file entry')\n\n    file_offset += file_entry_data_size\n\n    if self.file_format in ('bin-big-endian', 'bin-little-endian'):\n      file_entry.modification_time = (\n          (file_entry.modification_time.upper << 16) |\n          file_entry.modification_time.lower)\n\n      file_entry.file_size = (\n          (file_entry.file_size.upper << 16) | file_entry.file_size.lower)\n\n    if self.file_format == 'odc':\n      for attribute_name in self._CPIO_ATTRIBUTE_NAMES_ODC:\n        value = getattr(file_entry, attribute_name, None)\n        try:\n          value = int(value, 8)\n        except ValueError:\n          raise errors.FileFormatError(\n              'Unable to convert attribute: {0:s} into an integer'.format(\n                  attribute_name))\n\n        value = setattr(file_entry, attribute_name, value)\n\n    elif self.file_format in ('crc', 'newc'):\n      for attribute_name in self._CPIO_ATTRIBUTE_NAMES_CRC:\n        value = getattr(file_entry, attribute_name, None)\n        try:\n          value = int(value, 16)\n        except ValueError:\n          raise errors.FileFormatError(\n              'Unable to convert attribute: {0:s} into an integer'.format(\n                  attribute_name))\n\n        value = setattr(file_entry, attribute_name, value)\n\n    path_data = file_object.read(file_entry.path_size)\n\n    file_offset += file_entry.path_size\n\n    # TODO: should this be ASCII?\n    path = path_data.decode('ascii')\n    path, _, _ = path.partition('\\x00')\n\n    if self.file_format in ('bin-big-endian', 'bin-little-endian'):\n      padding_size = file_offset % 2\n      if padding_size > 0:\n        padding_size = 2 - padding_size\n\n    elif self.file_format == 'odc':\n      padding_size = 0\n\n    elif self.file_format in ('crc', 'newc'):\n      padding_size = file_offset % 4\n      if padding_size > 0:\n        padding_size = 4 - padding_size\n\n    file_offset += padding_size\n\n    archive_file_entry = CPIOArchiveFileEntry()\n\n    archive_file_entry.data_offset = file_offset\n    archive_file_entry.data_size = file_entry.file_size\n    archive_file_entry.group_identifier = file_entry.group_identifier\n    archive_file_entry.inode_number = file_entry.inode_number\n    archive_file_entry.modification_time = file_entry.modification_time\n    archive_file_entry.path = path\n    archive_file_entry.mode = file_entry.mode\n    archive_file_entry.size = (\n        file_entry_data_size + file_entry.path_size + padding_size +\n        file_entry.file_size)\n    archive_file_entry.user_identifier = file_entry.user_identifier\n\n    file_offset += file_entry.file_size\n\n    if self.file_format in ('bin-big-endian', 'bin-little-endian'):\n      padding_size = file_offset % 2\n      if padding_size > 0:\n        padding_size = 2 - padding_size\n\n    elif self.file_format == 'odc':\n      padding_size = 0\n\n    elif self.file_format in ('crc', 'newc'):\n      padding_size = file_offset % 4\n      if padding_size > 0:\n        padding_size = 4 - padding_size\n\n    if padding_size > 0:\n      archive_file_entry.size += padding_size\n\n    return archive_file_entry", "response": "Reads a file entry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _ReadFileEntries(self, file_object):\n    self._file_entries = {}\n\n    file_offset = 0\n    while file_offset < self._file_size or self._file_size == 0:\n      file_entry = self._ReadFileEntry(file_object, file_offset)\n      file_offset += file_entry.size\n      if file_entry.path == 'TRAILER!!!':\n        break\n\n      if file_entry.path in self._file_entries:\n        # TODO: alert on file entries with duplicate paths?\n        continue\n\n      self._file_entries[file_entry.path] = file_entry", "response": "Reads the file entries from the cpio archive."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetFileEntries(self, path_prefix=''):\n    if self._file_entries:\n      for path, file_entry in iter(self._file_entries.items()):\n        if path.startswith(path_prefix):\n          yield file_entry", "response": "Retrieves the file entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Open(self, file_object):\n    file_object.seek(0, os.SEEK_SET)\n    signature_data = file_object.read(6)\n\n    self.file_format = None\n    if len(signature_data) > 2:\n      if signature_data[:2] == self._CPIO_SIGNATURE_BINARY_BIG_ENDIAN:\n        self.file_format = 'bin-big-endian'\n      elif signature_data[:2] == self._CPIO_SIGNATURE_BINARY_LITTLE_ENDIAN:\n        self.file_format = 'bin-little-endian'\n      elif signature_data == self._CPIO_SIGNATURE_PORTABLE_ASCII:\n        self.file_format = 'odc'\n      elif signature_data == self._CPIO_SIGNATURE_NEW_ASCII:\n        self.file_format = 'newc'\n      elif signature_data == self._CPIO_SIGNATURE_NEW_ASCII_WITH_CHECKSUM:\n        self.file_format = 'crc'\n\n    if self.file_format is None:\n      raise IOError('Unsupported CPIO format.')\n\n    self._file_object = file_object\n    self._file_size = file_object.get_size()\n\n    self._ReadFileEntries(self._file_object)", "response": "Opens the CPIO archive file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a byte string from the file - like object at a specific offset.", "response": "def ReadDataAtOffset(self, file_offset, size):\n    \"\"\"Reads a byte string from the file-like object at a specific offset.\n\n    Args:\n      file_offset (int): file offset.\n      size (int): number of bytes to read.\n\n    Returns:\n      bytes: data read.\n\n    Raises:\n      IOError: if the read failed.\n      OSError: if the read failed.\n    \"\"\"\n    self._file_object.seek(file_offset, os.SEEK_SET)\n    return self._file_object.read(size)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef FileEntryExistsByPathSpec(self, path_spec):\n    location = getattr(path_spec, 'location', None)\n\n    if location is None:\n      return False\n\n    is_device = False\n    if platform.system() == 'Windows':\n      # Note that os.path.exists() returns False for Windows device files so\n      # instead use libsmdev to do the check.\n      try:\n        is_device = pysmdev.check_device(location)\n      except IOError as exception:\n        # Since pysmdev will raise IOError when it has no access to the device\n        # we check if the exception message contains ' access denied ' and\n        # return true.\n\n        # Note that exception.message no longer works in Python 3.\n        exception_string = str(exception)\n        if not isinstance(exception_string, py2to3.UNICODE_TYPE):\n          exception_string = py2to3.UNICODE_TYPE(\n              exception_string, errors='replace')\n\n        if ' access denied ' in exception_string:\n          is_device = True\n\n    # Note that os.path.exists() returns False for broken symbolic links hence\n    # an additional check using os.path.islink() is necessary.\n    return is_device or os.path.exists(location) or os.path.islink(location)", "response": "Determines if a file entry for a path specification exists."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve a file entry for a path specification.", "response": "def GetFileEntryByPathSpec(self, path_spec):\n    \"\"\"Retrieves a file entry for a path specification.\n\n    Args:\n      path_spec (PathSpec): a path specification.\n\n    Returns:\n      OSFileEntry: a file entry or None if not available.\n    \"\"\"\n    if not self.FileEntryExistsByPathSpec(path_spec):\n      return None\n    return os_file_entry.OSFileEntry(self._resolver_context, self, path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves the root file entry.", "response": "def GetRootFileEntry(self):\n    \"\"\"Retrieves the root file entry.\n\n    Returns:\n      OSFileEntry: a file entry or None if not available.\n    \"\"\"\n    if platform.system() == 'Windows':\n      # Return the root with the drive letter of the volume the current\n      # working directory is on.\n      location = os.getcwd()\n      location, _, _ = location.partition('\\\\')\n      location = '{0:s}\\\\'.format(location)\n    else:\n      location = '/'\n\n    if not os.path.exists(location):\n      return None\n\n    path_spec = os_path_spec.OSPathSpec(location=location)\n    return self.GetFileEntryByPathSpec(path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef JoinPath(self, path_segments):\n    # For paths on Windows we need to make sure to handle the first path\n    # segment correctly.\n    first_path_segment = None\n\n    if path_segments and platform.system() == 'Windows':\n      # Check if the first path segment contains a \"special\" path definition.\n      first_path_segment = path_segments[0]\n      first_path_segment_length = len(first_path_segment)\n      first_path_segment_prefix = None\n\n      # In case the path start with: \\\\.\\C:\\\n      if (first_path_segment_length >= 7 and\n          first_path_segment.startswith('\\\\\\\\.\\\\') and\n          first_path_segment[5:7] == ':\\\\'):\n        first_path_segment_prefix = first_path_segment[4:6]\n        first_path_segment = first_path_segment[7:]\n\n      # In case the path start with: \\\\.\\ or \\\\?\\\n      elif (first_path_segment_length >= 4 and\n            first_path_segment[:4] in ['\\\\\\\\.\\\\', '\\\\\\\\?\\\\']):\n        first_path_segment_prefix = first_path_segment[:4]\n        first_path_segment = first_path_segment[4:]\n\n      # In case the path start with: C:\n      elif first_path_segment_length >= 2 and first_path_segment[1] == ':':\n        first_path_segment_prefix = first_path_segment[:2]\n        first_path_segment = first_path_segment[2:]\n\n      # In case the path start with: \\\\server\\share (UNC).\n      elif first_path_segment.startswith('\\\\\\\\'):\n        prefix, _, remainder = first_path_segment[2:].partition(\n            self.PATH_SEPARATOR)\n\n        first_path_segment_prefix = '\\\\\\\\{0:s}'.format(prefix)\n        first_path_segment = '\\\\{0:s}'.format(remainder)\n\n      if first_path_segment_prefix:\n        first_path_segment, _, remainder = first_path_segment.partition(\n            self.PATH_SEPARATOR)\n\n        if not remainder:\n          _ = path_segments.pop(0)\n        else:\n          path_segments[0] = remainder\n\n        first_path_segment = ''.join([\n            first_path_segment_prefix, first_path_segment])\n\n      else:\n        first_path_segment = None\n\n    # We are not using os.path.join() here since it will not remove all\n    # variations of successive path separators.\n\n    # Split all the path segments based on the path (segment) separator.\n    path_segments = [\n        segment.split(self.PATH_SEPARATOR) for segment in path_segments]\n\n    # Flatten the sublists into one list.\n    path_segments = [\n        element for sublist in path_segments for element in sublist]\n\n    # Remove empty path segments.\n    path_segments = list(filter(None, path_segments))\n\n    if first_path_segment is None:\n      path = '{0:s}{1:s}'.format(\n          self.PATH_SEPARATOR, self.PATH_SEPARATOR.join(path_segments))\n    else:\n      path = first_path_segment\n      if path_segments:\n        path = '{0:s}{1:s}{2:s}'.format(\n            path, self.PATH_SEPARATOR, self.PATH_SEPARATOR.join(path_segments))\n\n    return path", "response": "Joins the path segments into a single path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nopening the file system object defined by path specification.", "response": "def _Open(self, path_spec, mode='rb'):\n    \"\"\"Opens the file system object defined by path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n      mode (Optional[str]): file access mode. The default is 'rb' which\n          represents read-only binary.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file system object could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n\n    try:\n      fsnfts_volume = pyfsntfs.volume()\n      fsnfts_volume.open_file_object(file_object)\n    except:\n      file_object.close()\n      raise\n\n    self._file_object = file_object\n    self._fsntfs_volume = fsnfts_volume"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine if a file entry for a path specification exists.", "response": "def FileEntryExistsByPathSpec(self, path_spec):\n    \"\"\"Determines if a file entry for a path specification exists.\n\n    Args:\n      path_spec (PathSpec): path specification.\n\n    Returns:\n      bool: True if the file entry exists.\n\n    Raises:\n      BackEndError: if the file entry cannot be opened.\n    \"\"\"\n    # Opening a file by MFT entry is faster than opening a file by location.\n    # However we need the index of the corresponding $FILE_NAME MFT attribute.\n    fsntfs_file_entry = None\n    location = getattr(path_spec, 'location', None)\n    mft_attribute = getattr(path_spec, 'mft_attribute', None)\n    mft_entry = getattr(path_spec, 'mft_entry', None)\n\n    try:\n      if mft_attribute is not None and mft_entry is not None:\n        fsntfs_file_entry = self._fsntfs_volume.get_file_entry(mft_entry)\n      elif location is not None:\n        fsntfs_file_entry = self._fsntfs_volume.get_file_entry_by_path(location)\n\n    except IOError as exception:\n      raise errors.BackEndError(exception)\n\n    return fsntfs_file_entry is not None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve a file entry for a path specification.", "response": "def GetFileEntryByPathSpec(self, path_spec):\n    \"\"\"Retrieves a file entry for a path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n\n    Returns:\n      NTFSFileEntry: file entry or None if not available.\n\n    Raises:\n      BackEndError: if the file entry cannot be opened.\n    \"\"\"\n    # Opening a file by MFT entry is faster than opening a file by location.\n    # However we need the index of the corresponding $FILE_NAME MFT attribute.\n    fsntfs_file_entry = None\n    location = getattr(path_spec, 'location', None)\n    mft_attribute = getattr(path_spec, 'mft_attribute', None)\n    mft_entry = getattr(path_spec, 'mft_entry', None)\n\n    if (location == self.LOCATION_ROOT or\n        mft_entry == self.MFT_ENTRY_ROOT_DIRECTORY):\n      fsntfs_file_entry = self._fsntfs_volume.get_root_directory()\n      return ntfs_file_entry.NTFSFileEntry(\n          self._resolver_context, self, path_spec,\n          fsntfs_file_entry=fsntfs_file_entry, is_root=True)\n\n    try:\n      if mft_attribute is not None and mft_entry is not None:\n        fsntfs_file_entry = self._fsntfs_volume.get_file_entry(mft_entry)\n      elif location is not None:\n        fsntfs_file_entry = self._fsntfs_volume.get_file_entry_by_path(location)\n\n    except IOError as exception:\n      raise errors.BackEndError(exception)\n\n    if fsntfs_file_entry is None:\n      return None\n\n    return ntfs_file_entry.NTFSFileEntry(\n        self._resolver_context, self, path_spec,\n        fsntfs_file_entry=fsntfs_file_entry)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the NTFS file entry for a path specification.", "response": "def GetNTFSFileEntryByPathSpec(self, path_spec):\n    \"\"\"Retrieves the NTFS file entry for a path specification.\n\n    Args:\n      path_spec (PathSpec): a path specification.\n\n    Returns:\n      pyfsntfs.file_entry: NTFS file entry.\n\n    Raises:\n      PathSpecError: if the path specification is missing location and\n          MFT entry.\n    \"\"\"\n    # Opening a file by MFT entry is faster than opening a file by location.\n    # However we need the index of the corresponding $FILE_NAME MFT attribute.\n    location = getattr(path_spec, 'location', None)\n    mft_attribute = getattr(path_spec, 'mft_attribute', None)\n    mft_entry = getattr(path_spec, 'mft_entry', None)\n\n    if mft_attribute is not None and mft_entry is not None:\n      fsntfs_file_entry = self._fsntfs_volume.get_file_entry(mft_entry)\n    elif location is not None:\n      fsntfs_file_entry = self._fsntfs_volume.get_file_entry_by_path(location)\n    else:\n      raise errors.PathSpecError(\n          'Path specification missing location and MFT entry.')\n\n    return fsntfs_file_entry"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetRootFileEntry(self):\n    path_spec = ntfs_path_spec.NTFSPathSpec(\n        location=self.LOCATION_ROOT, mft_entry=self.MFT_ENTRY_ROOT_DIRECTORY,\n        parent=self._path_spec.parent)\n    return self.GetFileEntryByPathSpec(path_spec)", "response": "Retrieves the root file entry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _Open(self, path_spec, mode='rb'):\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n\n    self._file_object = file_object", "response": "Opens the file system object defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef FileEntryExistsByPathSpec(self, path_spec):\n    # All checks for correct path spec is done in SQLiteBlobFile.\n    # Therefore, attempt to open the path specification and\n    # check if errors occurred.\n    try:\n      file_object = resolver.Resolver.OpenFileObject(\n          path_spec, resolver_context=self._resolver_context)\n    except (IOError, ValueError, errors.AccessError, errors.PathSpecError):\n      return False\n\n    file_object.close()\n    return True", "response": "Determines if a file entry for a path specification exists."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve a file entry for a path specification.", "response": "def GetFileEntryByPathSpec(self, path_spec):\n    \"\"\"Retrieves a file entry for a path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n\n    Returns:\n      FileEntry: a file entry or None.\n    \"\"\"\n    row_index = getattr(path_spec, 'row_index', None)\n    row_condition = getattr(path_spec, 'row_condition', None)\n\n    # If no row_index or row_condition is provided, return a directory.\n    if row_index is None and row_condition is None:\n      return sqlite_blob_file_entry.SQLiteBlobFileEntry(\n          self._resolver_context, self, path_spec, is_root=True,\n          is_virtual=True)\n\n    return sqlite_blob_file_entry.SQLiteBlobFileEntry(\n        self._resolver_context, self, path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the root file entry.", "response": "def GetRootFileEntry(self):\n    \"\"\"Retrieves the root file entry.\n\n    Returns:\n      FileEntry: a file entry or None.\n    \"\"\"\n    path_spec = sqlite_blob_path_spec.SQLiteBlobPathSpec(\n        table_name=self._path_spec.table_name,\n        column_name=self._path_spec.column_name,\n        parent=self._path_spec.parent)\n    return self.GetFileEntryByPathSpec(path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef comparable(self):\n    string_parts = []\n\n    string_parts.append('table name: {0:s}'.format(self.table_name))\n    string_parts.append('column name: {0:s}'.format(self.column_name))\n\n    if self.row_condition is not None:\n      row_condition_string = ' '.join([\n          '{0!s}'.format(value) for value in self.row_condition])\n      string_parts.append('row condition: \"{0:s}\"'.format(\n          row_condition_string))\n\n    if self.row_index is not None:\n      string_parts.append('row index: {0:d}'.format(self.row_index))\n\n    return self._GetComparable(sub_comparable_string=', '.join(string_parts))", "response": "str - > str"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves directory entries using the path specification.", "response": "def _EntriesGenerator(self):\n    \"\"\"Retrieves directory entries.\n\n    Since a directory can contain a vast number of entries using\n    a generator is more memory efficient.\n\n    Yields:\n      TSKPartitionPathSpec: a path specification.\n    \"\"\"\n    location = getattr(self.path_spec, 'location', None)\n    part_index = getattr(self.path_spec, 'part_index', None)\n    start_offset = getattr(self.path_spec, 'start_offset', None)\n\n    # Only the virtual root file has directory entries.\n    if (part_index is None and start_offset is None and\n        location is not None and location == self._file_system.LOCATION_ROOT):\n      tsk_volume = self._file_system.GetTSKVolume()\n      bytes_per_sector = tsk_partition.TSKVolumeGetBytesPerSector(tsk_volume)\n      part_index = 0\n      partition_index = 0\n\n      # pytsk3 does not handle the Volume_Info iterator correctly therefore\n      # the explicit list is needed to prevent the iterator terminating too\n      # soon or looping forever.\n      for tsk_vs_part in list(tsk_volume):\n        kwargs = {}\n\n        if tsk_partition.TSKVsPartIsAllocated(tsk_vs_part):\n          partition_index += 1\n          kwargs['location'] = '/p{0:d}'.format(partition_index)\n\n        kwargs['part_index'] = part_index\n        part_index += 1\n\n        start_sector = tsk_partition.TSKVsPartGetStartSector(tsk_vs_part)\n\n        if start_sector is not None:\n          kwargs['start_offset'] = start_sector * bytes_per_sector\n\n        kwargs['parent'] = self.path_spec.parent\n\n        yield tsk_partition_path_spec.TSKPartitionPathSpec(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve a directory from the file system.", "response": "def _GetDirectory(self):\n    \"\"\"Retrieves a directory.\n\n    Returns:\n      TSKPartitionDirectory: a directory or None if not available.\n    \"\"\"\n    if self.entry_type != definitions.FILE_ENTRY_TYPE_DIRECTORY:\n      return None\n    return TSKPartitionDirectory(self._file_system, self.path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _GetStat(self):\n    stat_object = super(TSKPartitionFileEntry, self)._GetStat()\n\n    bytes_per_sector = tsk_partition.TSKVolumeGetBytesPerSector(\n        self._tsk_volume)\n\n    # File data stat information.\n    if self._tsk_vs_part is not None:\n      number_of_sectors = tsk_partition.TSKVsPartGetNumberOfSectors(\n          self._tsk_vs_part)\n\n      if number_of_sectors:\n        stat_object.size = number_of_sectors * bytes_per_sector\n\n    # Date and time stat information.\n\n    # Ownership and permissions stat information.\n\n    # File entry type stat information.\n\n    # The root file entry is virtual and should have type directory.\n    if not self._is_virtual:\n      stat_object.is_allocated = tsk_partition.TSKVsPartIsAllocated(\n          self._tsk_vs_part)\n\n    return stat_object", "response": "Retrieves the stat object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef name(self):\n    if self._name is None:\n      # Directory entries without a location in the path specification\n      # are not given a name for now.\n      location = getattr(self.path_spec, 'location', None)\n      if location is not None:\n        self._name = self._file_system.BasenamePath(location)\n      else:\n        self._name = ''\n    return self._name", "response": "str name of the file entry which does not include the full path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _EntriesGenerator(self):\n    location = getattr(self.path_spec, 'location', None)\n    if location is not None:\n      paths = self._file_system.GetPaths()\n\n      for path in iter(paths.keys()):\n        # Determine if the start of the path is similar to the location string.\n        # If not the file the path refers to is not in the same directory.\n        if not path or not path.startswith(location):\n          continue\n\n        _, suffix = self._file_system.GetPathSegmentAndSuffix(location, path)\n\n        # Ignore anything that is part of a sub directory or the directory\n        # itself.\n        if suffix or path == location:\n          continue\n\n        path_spec_location = self._file_system.JoinPath([path])\n        yield fake_path_spec.FakePathSpec(location=path_spec_location)", "response": "Retrieves the directory entries."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _GetDirectory(self):\n    if self.entry_type != definitions.FILE_ENTRY_TYPE_DIRECTORY:\n      return None\n    return FakeDirectory(self._file_system, self.path_spec)", "response": "Retrieves a directory.\n\n    Returns:\n      FakeDirectory: a directory or None if not available."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve the VFSStat object for the file entry.", "response": "def _GetStat(self):\n    \"\"\"Retrieves information about the file entry.\n\n    Returns:\n      VFSStat: a stat object.\n    \"\"\"\n    stat_object = super(FakeFileEntry, self)._GetStat()\n\n    location = getattr(self.path_spec, 'location', None)\n    if location:\n      file_data = self._file_system.GetDataByPath(location)\n\n      if file_data is not None:\n        stat_object.size = len(file_data)\n\n    return stat_object"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving the sub file entries.", "response": "def _GetSubFileEntries(self):\n    \"\"\"Retrieves sub file entries.\n\n    Yields:\n      FakeFileEntry: a sub file entry.\n    \"\"\"\n    if self._directory is None:\n      self._directory = self._GetDirectory()\n\n    if self._directory:\n      for path_spec in self._directory.entries:\n        yield self._file_system.GetFileEntryByPathSpec(path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetFileObject(self, data_stream_name=''):\n    if not self.IsFile():\n      raise IOError('Cannot open non-file.')\n\n    if data_stream_name:\n      return None\n\n    location = getattr(self.path_spec, 'location', None)\n    if location is None:\n      return None\n\n    file_data = self._file_system.GetDataByPath(location)\n    file_object = fake_file_io.FakeFile(self._resolver_context, file_data)\n    file_object.open(path_spec=self.path_spec)\n    return file_object", "response": "Retrieves the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves the parent file entry.", "response": "def GetParentFileEntry(self):\n    \"\"\"Retrieves the root file entry.\n\n    Returns:\n      FakeFileEntry: parent file entry or None if not available.\n    \"\"\"\n    location = getattr(self.path_spec, 'location', None)\n    if location is None:\n      return None\n\n    parent_location = self._file_system.DirnamePath(location)\n    if parent_location is None:\n      return None\n\n    if parent_location == '':\n      parent_location = self._file_system.PATH_SEPARATOR\n\n    path_spec = fake_path_spec.FakePathSpec(location=parent_location)\n    return self._file_system.GetFileEntryByPathSpec(path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _RawGlobPathSpecWithAlphabeticalSchema(\n    file_system, parent_path_spec, segment_format, location, segment_length,\n    upper_case=False):\n  \"\"\"Globs for path specifications according to an alphabetical naming schema.\n\n  Args:\n    file_system (FileSystem): file system.\n    parent_path_spec (PathSpec): parent path specification.\n    segment_format (str): naming schema of the segment file location.\n    location (str): the base segment file location string.\n    segment_length (int): length (number of characters) of the segment\n        indicator.\n    upper_case (Optional[bool]): True if the segment name is in upper case.\n\n  Returns:\n    list[PathSpec]: path specifications that match the glob.\n  \"\"\"\n  segment_number = 0\n  segment_files = []\n\n  while True:\n    segment_index = segment_number\n    segment_letters = []\n    while len(segment_letters) < segment_length:\n      segment_index, remainder = divmod(segment_index, 26)\n      if upper_case:\n        segment_letters.append(chr(ord('A') + remainder))\n      else:\n        segment_letters.append(chr(ord('a') + remainder))\n\n    # Reverse the segment letters list to form the extension.\n    segment_letters = ''.join(segment_letters[::-1])\n    segment_location = segment_format.format(location, segment_letters)\n\n    # Note that we don't want to set the keyword arguments when not used\n    # because the path specification base class will check for unused\n    # keyword arguments and raise.\n    kwargs = path_spec_factory.Factory.GetProperties(parent_path_spec)\n\n    kwargs['location'] = segment_location\n    if parent_path_spec.parent is not None:\n      kwargs['parent'] = parent_path_spec.parent\n\n    segment_path_spec = path_spec_factory.Factory.NewPathSpec(\n        parent_path_spec.type_indicator, **kwargs)\n\n    if not file_system.FileEntryExistsByPathSpec(segment_path_spec):\n      break\n\n    segment_files.append(segment_path_spec)\n\n    segment_number += 1\n\n  return segment_files", "response": "Globs for path specifications according to an alphabetical naming schema."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _Open(self, path_spec=None, mode='rb'):\n    if not path_spec:\n      raise ValueError('Missing path specification.')\n\n    store_index = vshadow.VShadowPathSpecGetStoreIndex(path_spec)\n    if store_index is None:\n      raise errors.PathSpecError(\n          'Unable to retrieve store index from path specification.')\n\n    self._file_system = resolver.Resolver.OpenFileSystem(\n        path_spec, resolver_context=self._resolver_context)\n    vshadow_volume = self._file_system.GetVShadowVolume()\n\n    if (store_index < 0 or\n        store_index >= vshadow_volume.number_of_stores):\n      raise errors.PathSpecError((\n          'Unable to retrieve VSS store: {0:d} from path '\n          'specification.').format(store_index))\n\n    vshadow_store = vshadow_volume.get_store(store_index)\n    if not vshadow_store.has_in_volume_data():\n      raise IOError((\n          'Unable to open VSS store: {0:d} without in-volume stored '\n          'data.').format(store_index))\n\n    self._vshadow_store = vshadow_store", "response": "Opens the file - like object defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read(self, size=None):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    return self._vshadow_store.read(size)", "response": "Reads a byte string from the file - like object at the current offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GetSubNodeByLocation(self, location):\n    for sub_node in self.sub_nodes:\n      sub_node_location = getattr(sub_node.path_spec, 'location', None)\n      if location == sub_node_location:\n        return sub_node\n\n    return None", "response": "Retrieves a sub scan node based on the location."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the first unscanned sub node.", "response": "def GetUnscannedSubNode(self):\n    \"\"\"Retrieves the first unscanned sub node.\n\n    Returns:\n      SourceScanNode: sub scan node or None if not available.\n    \"\"\"\n    if not self.sub_nodes and not self.scanned:\n      return self\n\n    for sub_node in self.sub_nodes:\n      result = sub_node.GetUnscannedSubNode()\n      if result:\n        return result\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a scan node for a certain path specification.", "response": "def AddScanNode(self, path_spec, parent_scan_node):\n    \"\"\"Adds a scan node for a certain path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n      parent_scan_node (SourceScanNode): parent scan node or None.\n\n    Returns:\n      SourceScanNode: scan node.\n\n    Raises:\n      KeyError: if the scan node already exists.\n      RuntimeError: if the parent scan node is not present.\n    \"\"\"\n    scan_node = self._scan_nodes.get(path_spec, None)\n    if scan_node:\n      raise KeyError('Scan node already exists.')\n\n    scan_node = SourceScanNode(path_spec)\n    if parent_scan_node:\n      if parent_scan_node.path_spec not in self._scan_nodes:\n        raise RuntimeError('Parent scan node not present.')\n      scan_node.parent_node = parent_scan_node\n      parent_scan_node.sub_nodes.append(scan_node)\n\n    if not self._root_path_spec:\n      self._root_path_spec = path_spec\n\n    self._scan_nodes[path_spec] = scan_node\n\n    if path_spec.IsFileSystem():\n      self._file_system_scan_nodes[path_spec] = scan_node\n\n    self.updated = True\n    return scan_node"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GetUnscannedScanNode(self):\n    root_scan_node = self._scan_nodes.get(self._root_path_spec, None)\n    if not root_scan_node or not root_scan_node.scanned:\n      return root_scan_node\n\n    return root_scan_node.GetUnscannedSubNode()", "response": "Retrieves the first unscanned scan node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmarking a scan node as locked.", "response": "def LockScanNode(self, path_spec):\n    \"\"\"Marks a scan node as locked.\n\n    Args:\n      path_spec (PathSpec): path specification.\n\n    Raises:\n      KeyError: if the scan node does not exists.\n    \"\"\"\n    scan_node = self._scan_nodes.get(path_spec, None)\n    if not scan_node:\n      raise KeyError('Scan node does not exist.')\n\n    self._locked_scan_nodes[path_spec] = scan_node"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef OpenSourcePath(self, source_path):\n    source_path_spec = path_spec_factory.Factory.NewPathSpec(\n        definitions.TYPE_INDICATOR_OS, location=source_path)\n\n    self.AddScanNode(source_path_spec, None)", "response": "Opens the source path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef RemoveScanNode(self, path_spec):\n    scan_node = self._scan_nodes.get(path_spec, None)\n    if not scan_node:\n      return None\n\n    if scan_node.sub_nodes:\n      raise RuntimeError('Scan node has sub nodes.')\n\n    parent_scan_node = scan_node.parent_node\n    if parent_scan_node:\n      parent_scan_node.sub_nodes.remove(scan_node)\n\n    if path_spec == self._root_path_spec:\n      self._root_path_spec = None\n    del self._scan_nodes[path_spec]\n\n    if path_spec.IsFileSystem():\n      del self._file_system_scan_nodes[path_spec]\n\n    return parent_scan_node", "response": "Removes a scan node from the tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef UnlockScanNode(self, path_spec):\n    if not self.HasScanNode(path_spec):\n      raise KeyError('Scan node does not exist.')\n\n    if path_spec not in self._locked_scan_nodes:\n      raise KeyError('Scan node is not locked.')\n\n    del self._locked_scan_nodes[path_spec]\n\n    # Scan a node again after it has been unlocked.\n    self._scan_nodes[path_spec].scanned = False", "response": "Unlocks a scan node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nscans a source scan node for supported formats.", "response": "def _ScanNode(self, scan_context, scan_node, auto_recurse=True):\n    \"\"\"Scans a node for supported formats.\n\n    Args:\n      scan_context (SourceScannerContext): source scanner context.\n      scan_node (SourceScanNode): source scan node.\n      auto_recurse (Optional[bool]): True if the scan should automatically\n          recurse as far as possible.\n\n    Raises:\n      BackEndError: if the source cannot be scanned.\n      ValueError: if the scan context or scan node is invalid.\n    \"\"\"\n    if not scan_context:\n      raise ValueError('Invalid scan context.')\n\n    if not scan_node:\n      raise ValueError('Invalid scan node.')\n\n    scan_path_spec = scan_node.path_spec\n\n    system_level_file_entry = None\n    if scan_node.IsSystemLevel():\n      system_level_file_entry = resolver.Resolver.OpenFileEntry(\n          scan_node.path_spec, resolver_context=self._resolver_context)\n\n      if system_level_file_entry is None:\n        raise errors.BackEndError('Unable to open file entry.')\n\n      if system_level_file_entry.IsDirectory():\n        scan_context.SetSourceType(definitions.SOURCE_TYPE_DIRECTORY)\n        return\n\n      source_path_spec = self.ScanForStorageMediaImage(scan_node.path_spec)\n      if source_path_spec:\n        scan_node.scanned = True\n        scan_node = scan_context.AddScanNode(source_path_spec, scan_node)\n\n        if system_level_file_entry.IsDevice():\n          source_type = definitions.SOURCE_TYPE_STORAGE_MEDIA_DEVICE\n        else:\n          source_type = definitions.SOURCE_TYPE_STORAGE_MEDIA_IMAGE\n\n        scan_context.SetSourceType(source_type)\n\n        if not auto_recurse:\n          return\n\n      # In case we did not find a storage media image type we keep looking\n      # since not all RAW storage media image naming schemas are known and\n      # its type can only detected by its content.\n\n    source_path_spec = None\n    while True:\n      if scan_node.IsFileSystem():\n        # No need to scan a file systems scan node for volume systems.\n        break\n\n      if scan_node.SupportsEncryption():\n        self._ScanEncryptedVolumeNode(scan_context, scan_node)\n\n      if scan_context.IsLockedScanNode(scan_node.path_spec):\n        # Scan node is locked, such as an encrypted volume, and we cannot\n        # scan it for a volume system.\n        break\n\n      source_path_spec = self.ScanForVolumeSystem(scan_node.path_spec)\n      if not source_path_spec:\n        # No volume system found continue with a file system scan.\n        break\n\n      if not scan_context.HasScanNode(source_path_spec):\n        scan_node.scanned = True\n        scan_node = scan_context.AddScanNode(source_path_spec, scan_node)\n\n        if system_level_file_entry and system_level_file_entry.IsDevice():\n          source_type = definitions.SOURCE_TYPE_STORAGE_MEDIA_DEVICE\n        else:\n          source_type = definitions.SOURCE_TYPE_STORAGE_MEDIA_IMAGE\n\n        scan_context.SetSourceType(source_type)\n\n      if scan_node.IsVolumeSystemRoot():\n        self._ScanVolumeSystemRootNode(\n            scan_context, scan_node, auto_recurse=auto_recurse)\n\n        # We already have already scanned for the file systems.\n        return\n\n      if not auto_recurse and scan_context.updated:\n        return\n\n      # Nothing new found.\n      if not scan_context.updated:\n        break\n\n    # In case we did not find a volume system type we keep looking\n    # since we could be dealing with a storage media image that contains\n    # a single volume.\n\n    # No need to scan the root of a volume system for a file system.\n    if scan_node.IsVolumeSystemRoot():\n      pass\n\n    elif scan_context.IsLockedScanNode(scan_node.path_spec):\n      # Scan node is locked, such as an encrypted volume, and we cannot\n      # scan it for a file system.\n      pass\n\n    elif (scan_node.type_indicator == definitions.TYPE_INDICATOR_VSHADOW and\n          auto_recurse and scan_node.path_spec != scan_path_spec):\n      # Since scanning for file systems in VSS snapshot volumes can\n      # be expensive we only do this when explicitly asked for.\n      pass\n\n    elif not scan_node.IsFileSystem():\n      source_path_spec = self.ScanForFileSystem(scan_node.path_spec)\n      if not source_path_spec:\n        # Since RAW storage media image can only be determined by naming schema\n        # we could have single file that is not a RAW storage media image yet\n        # matches the naming schema.\n        if scan_node.path_spec.type_indicator == definitions.TYPE_INDICATOR_RAW:\n          scan_node = scan_context.RemoveScanNode(scan_node.path_spec)\n\n          # Make sure to override the previously assigned source type.\n          scan_context.source_type = definitions.SOURCE_TYPE_FILE\n        else:\n          scan_context.SetSourceType(definitions.SOURCE_TYPE_FILE)\n\n      elif not scan_context.HasScanNode(source_path_spec):\n        scan_node.scanned = True\n        scan_node = scan_context.AddScanNode(source_path_spec, scan_node)\n\n        if system_level_file_entry and system_level_file_entry.IsDevice():\n          source_type = definitions.SOURCE_TYPE_STORAGE_MEDIA_DEVICE\n        else:\n          source_type = definitions.SOURCE_TYPE_STORAGE_MEDIA_IMAGE\n\n        scan_context.SetSourceType(source_type)\n\n    # If all scans failed mark the scan node as scanned so we do not scan it\n    # again.\n    if not scan_node.scanned:\n      scan_node.scanned = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nscans an encrypted volume node for supported formats.", "response": "def _ScanEncryptedVolumeNode(self, scan_context, scan_node):\n    \"\"\"Scans an encrypted volume node for supported formats.\n\n    Args:\n      scan_context (SourceScannerContext): source scanner context.\n      scan_node (SourceScanNode): source scan node.\n\n    Raises:\n      BackEndError: if the scan node cannot be unlocked.\n      ValueError: if the scan context or scan node is invalid.\n    \"\"\"\n    if scan_node.type_indicator == definitions.TYPE_INDICATOR_APFS_CONTAINER:\n      # TODO: consider changes this when upstream changes have been made.\n      # Currently pyfsapfs does not support reading from a volume as a device.\n      # Also see: https://github.com/log2timeline/dfvfs/issues/332\n      container_file_entry = resolver.Resolver.OpenFileEntry(\n          scan_node.path_spec, resolver_context=self._resolver_context)\n      fsapfs_volume = container_file_entry.GetAPFSVolume()\n\n      # TODO: unlocking the volume multiple times is inefficient cache volume\n      # object in scan node and use is_locked = fsapfs_volume.is_locked()\n      try:\n        is_locked = not apfs_helper.APFSUnlockVolume(\n            fsapfs_volume, scan_node.path_spec, resolver.Resolver.key_chain)\n      except IOError as exception:\n        raise errors.BackEndError(\n            'Unable to unlock APFS volume with error: {0!s}'.format(exception))\n\n    else:\n      file_object = resolver.Resolver.OpenFileObject(\n          scan_node.path_spec, resolver_context=self._resolver_context)\n      is_locked = not file_object or file_object.is_locked\n      file_object.close()\n\n    if is_locked:\n      scan_context.LockScanNode(scan_node.path_spec)\n\n      # For BitLocker To Go add a scan node for the unencrypted part of\n      # the volume.\n      if scan_node.type_indicator == definitions.TYPE_INDICATOR_BDE:\n        path_spec = self.ScanForFileSystem(scan_node.path_spec.parent)\n        if path_spec:\n          scan_context.AddScanNode(path_spec, scan_node.parent_node)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nscan a volume system root node for supported formats.", "response": "def _ScanVolumeSystemRootNode(\n      self, scan_context, scan_node, auto_recurse=True):\n    \"\"\"Scans a volume system root node for supported formats.\n\n    Args:\n      scan_context (SourceScannerContext): source scanner context.\n      scan_node (SourceScanNode): source scan node.\n      auto_recurse (Optional[bool]): True if the scan should automatically\n          recurse as far as possible.\n\n    Raises:\n      ValueError: if the scan context or scan node is invalid.\n    \"\"\"\n    if scan_node.type_indicator == definitions.TYPE_INDICATOR_VSHADOW:\n      # For VSS add a scan node for the current volume.\n      path_spec = self.ScanForFileSystem(scan_node.path_spec.parent)\n      if path_spec:\n        scan_context.AddScanNode(path_spec, scan_node.parent_node)\n\n    # Determine the path specifications of the sub file entries.\n    file_entry = resolver.Resolver.OpenFileEntry(\n        scan_node.path_spec, resolver_context=self._resolver_context)\n\n    for sub_file_entry in file_entry.sub_file_entries:\n      sub_scan_node = scan_context.AddScanNode(\n          sub_file_entry.path_spec, scan_node)\n\n      if scan_node.type_indicator == definitions.TYPE_INDICATOR_VSHADOW:\n        # Since scanning for file systems in VSS snapshot volumes can\n        # be expensive we only do this when explicitly asked for.\n        continue\n\n      if auto_recurse or not scan_context.updated:\n        self._ScanNode(scan_context, sub_scan_node, auto_recurse=auto_recurse)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving the volume identifiers.", "response": "def GetVolumeIdentifiers(self, volume_system):\n    \"\"\"Retrieves the volume identifiers.\n\n    Args:\n      volume_system (VolumeSystem): volume system.\n\n    Returns:\n      list[str]: sorted volume identifiers.\n    \"\"\"\n    volume_identifiers = []\n    for volume in volume_system.volumes:\n      volume_identifier = getattr(volume, 'identifier', None)\n      if volume_identifier:\n        volume_identifiers.append(volume_identifier)\n\n    return sorted(volume_identifiers)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Scan(self, scan_context, auto_recurse=True, scan_path_spec=None):\n    if not scan_context:\n      raise ValueError('Invalid scan context.')\n\n    scan_context.updated = False\n\n    if scan_path_spec:\n      scan_node = scan_context.GetScanNode(scan_path_spec)\n\n    else:\n      scan_node = scan_context.GetUnscannedScanNode()\n\n    if scan_node:\n      self._ScanNode(scan_context, scan_node, auto_recurse=auto_recurse)", "response": "Scans for supported formats."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nscans the path specification for a supported file system format.", "response": "def ScanForFileSystem(self, source_path_spec):\n    \"\"\"Scans the path specification for a supported file system format.\n\n    Args:\n      source_path_spec (PathSpec): source path specification.\n\n    Returns:\n      PathSpec: file system path specification or None if no supported file\n          system type was found.\n\n    Raises:\n      BackEndError: if the source cannot be scanned or more than one file\n          system type is found.\n    \"\"\"\n    if source_path_spec.type_indicator == (\n        definitions.TYPE_INDICATOR_APFS_CONTAINER):\n      # TODO: consider changes this when upstream changes have been made.\n      # Currently pyfsapfs does not support reading from a volume as a device.\n      # Also see: https://github.com/log2timeline/dfvfs/issues/332\n      return path_spec_factory.Factory.NewPathSpec(\n          definitions.TYPE_INDICATOR_APFS, location='/',\n          parent=source_path_spec)\n\n    try:\n      type_indicators = analyzer.Analyzer.GetFileSystemTypeIndicators(\n          source_path_spec, resolver_context=self._resolver_context)\n    except RuntimeError as exception:\n      raise errors.BackEndError((\n          'Unable to process source path specification with error: '\n          '{0!s}').format(exception))\n\n    if not type_indicators:\n      return None\n\n    type_indicator = type_indicators[0]\n    if len(type_indicators) > 1:\n      if definitions.PREFERRED_NTFS_BACK_END not in type_indicators:\n        raise errors.BackEndError(\n            'Unsupported source found more than one file system types.')\n\n      type_indicator = definitions.PREFERRED_NTFS_BACK_END\n\n    # TODO: determine root location from file system or path specification.\n    if type_indicator == definitions.TYPE_INDICATOR_NTFS:\n      root_location = '\\\\'\n    else:\n      root_location = '/'\n\n    file_system_path_spec = path_spec_factory.Factory.NewPathSpec(\n        type_indicator, location=root_location, parent=source_path_spec)\n\n    if type_indicator == definitions.TYPE_INDICATOR_TSK:\n      # Check if the file system can be opened since the file system by\n      # signature detection results in false positives.\n      try:\n        file_system = resolver.Resolver.OpenFileSystem(\n            file_system_path_spec, resolver_context=self._resolver_context)\n        file_system.Close()\n      except errors.BackEndError:\n        file_system_path_spec = None\n\n    return file_system_path_spec"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ScanForStorageMediaImage(self, source_path_spec):\n    try:\n      type_indicators = analyzer.Analyzer.GetStorageMediaImageTypeIndicators(\n          source_path_spec, resolver_context=self._resolver_context)\n    except RuntimeError as exception:\n      raise errors.BackEndError((\n          'Unable to process source path specification with error: '\n          '{0!s}').format(exception))\n\n    if not type_indicators:\n      # The RAW storage media image type cannot be detected based on\n      # a signature so we try to detect it based on common file naming schemas.\n      file_system = resolver.Resolver.OpenFileSystem(\n          source_path_spec, resolver_context=self._resolver_context)\n      raw_path_spec = path_spec_factory.Factory.NewPathSpec(\n          definitions.TYPE_INDICATOR_RAW, parent=source_path_spec)\n\n      try:\n        # The RAW glob function will raise a PathSpecError if the path\n        # specification is unsuitable for globbing.\n        glob_results = raw.RawGlobPathSpec(file_system, raw_path_spec)\n      except errors.PathSpecError:\n        glob_results = None\n\n      file_system.Close()\n\n      if not glob_results:\n        return None\n\n      return raw_path_spec\n\n    if len(type_indicators) > 1:\n      raise errors.BackEndError(\n          'Unsupported source found more than one storage media image types.')\n\n    return path_spec_factory.Factory.NewPathSpec(\n        type_indicators[0], parent=source_path_spec)", "response": "Scans the path specification for a supported storage media image format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nscan the path specification for a supported volume system format.", "response": "def ScanForVolumeSystem(self, source_path_spec):\n    \"\"\"Scans the path specification for a supported volume system format.\n\n    Args:\n      source_path_spec (PathSpec): source path specification.\n\n    Returns:\n      PathSpec: volume system path specification or None if no supported volume\n          system type was found.\n\n    Raises:\n      BackEndError: if the source cannot be scanned or more than one volume\n          system type is found.\n    \"\"\"\n    if source_path_spec.type_indicator == definitions.TYPE_INDICATOR_VSHADOW:\n      # It is technically possible to scan for VSS-in-VSS but makes no sense\n      # to do so.\n      return None\n\n    if source_path_spec.IsVolumeSystemRoot():\n      return source_path_spec\n\n    if source_path_spec.type_indicator == (\n        definitions.TYPE_INDICATOR_APFS_CONTAINER):\n      # TODO: consider changes this when upstream changes have been made.\n      # Currently pyfsapfs does not support reading from a volume as a device.\n      # Also see: https://github.com/log2timeline/dfvfs/issues/332\n      return None\n\n    try:\n      type_indicators = analyzer.Analyzer.GetVolumeSystemTypeIndicators(\n          source_path_spec, resolver_context=self._resolver_context)\n    except (IOError, RuntimeError) as exception:\n      raise errors.BackEndError((\n          'Unable to process source path specification with error: '\n          '{0!s}').format(exception))\n\n    if not type_indicators:\n      return None\n\n    if len(type_indicators) > 1:\n      raise errors.BackEndError(\n          'Unsupported source found more than one volume system types.')\n\n    if (type_indicators[0] == definitions.TYPE_INDICATOR_TSK_PARTITION and\n        source_path_spec.type_indicator in [\n            definitions.TYPE_INDICATOR_TSK_PARTITION]):\n      return None\n\n    if type_indicators[0] in definitions.VOLUME_SYSTEM_TYPE_INDICATORS:\n      return path_spec_factory.Factory.NewPathSpec(\n          type_indicators[0], location='/', parent=source_path_spec)\n\n    return path_spec_factory.Factory.NewPathSpec(\n        type_indicators[0], parent=source_path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nunlock a locked scan node.", "response": "def Unlock(\n      self, scan_context, path_spec, credential_identifier, credential_data):\n    \"\"\"Unlocks a locked scan node e.g. the scan node of an encrypted volume.\n\n    Args:\n      scan_context (SourceScannerContext): source scanner context.\n      path_spec (PathSpec): path specification of the locked scan node.\n      credential_identifier (str): credential identifier used to unlock\n          the scan node.\n      credential_data (bytes): credential data used to unlock the scan node.\n\n    Returns:\n      bool: True if the scan node was successfully unlocked.\n\n    Raises:\n      BackEndError: if the scan node cannot be unlocked.\n      KeyError: if the scan node does not exists or is not locked.\n    \"\"\"\n    if not scan_context.HasScanNode(path_spec):\n      raise KeyError('Scan node does not exist.')\n\n    if not scan_context.IsLockedScanNode(path_spec):\n      raise KeyError('Scan node is not locked.')\n\n    resolver.Resolver.key_chain.SetCredential(\n        path_spec, credential_identifier, credential_data)\n\n    if path_spec.type_indicator == definitions.TYPE_INDICATOR_APFS_CONTAINER:\n      # TODO: consider changes this when upstream changes have been made.\n      # Currently pyfsapfs does not support reading from a volume as a device.\n      # Also see: https://github.com/log2timeline/dfvfs/issues/332\n      container_file_entry = resolver.Resolver.OpenFileEntry(\n          path_spec, resolver_context=self._resolver_context)\n      fsapfs_volume = container_file_entry.GetAPFSVolume()\n\n      try:\n        is_locked = not apfs_helper.APFSUnlockVolume(\n            fsapfs_volume, path_spec, resolver.Resolver.key_chain)\n      except IOError as exception:\n        raise errors.BackEndError(\n            'Unable to unlock APFS volume with error: {0!s}'.format(exception))\n\n    else:\n      file_object = resolver.Resolver.OpenFileObject(\n          path_spec, resolver_context=self._resolver_context)\n      is_locked = not file_object or file_object.is_locked\n      file_object.close()\n\n    if not is_locked:\n      scan_context.UnlockScanNode(path_spec)\n\n    return not is_locked"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nclosing the file - like object.", "response": "def _Close(self):\n    \"\"\"Closes the file-like object.\"\"\"\n    self._fsntfs_data_stream = None\n    self._fsntfs_file_entry = None\n\n    self._file_system.Close()\n    self._file_system = None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _Open(self, path_spec=None, mode='rb'):\n    if not path_spec:\n      raise ValueError('Missing path specification.')\n\n    data_stream = getattr(path_spec, 'data_stream', None)\n\n    self._file_system = resolver.Resolver.OpenFileSystem(\n        path_spec, resolver_context=self._resolver_context)\n\n    file_entry = self._file_system.GetFileEntryByPathSpec(path_spec)\n    if not file_entry:\n      raise IOError('Unable to open file entry.')\n\n    fsntfs_data_stream = None\n    fsntfs_file_entry = file_entry.GetNTFSFileEntry()\n    if not fsntfs_file_entry:\n      raise IOError('Unable to open NTFS file entry.')\n\n    if data_stream:\n      fsntfs_data_stream = fsntfs_file_entry.get_alternate_data_stream_by_name(\n          data_stream)\n      if not fsntfs_data_stream:\n        raise IOError('Unable to open data stream: {0:s}.'.format(\n            data_stream))\n\n    elif not fsntfs_file_entry.has_default_data_stream():\n      raise IOError('Missing default data stream.')\n\n    self._fsntfs_data_stream = fsntfs_data_stream\n    self._fsntfs_file_entry = fsntfs_file_entry", "response": "Opens the file - like object defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread a byte string from the file - like object at the current offset.", "response": "def read(self, size=None):\n    \"\"\"Reads a byte string from the file-like object at the current offset.\n\n    The function will read a byte string of the specified size or\n    all of the remaining data if no size was specified.\n\n    Args:\n      size (Optional[int]): number of bytes to read, where None is all\n          remaining data.\n\n    Returns:\n      bytes: data read.\n\n    Raises:\n      IOError: if the read failed.\n      OSError: if the read failed.\n    \"\"\"\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._fsntfs_data_stream:\n      return self._fsntfs_data_stream.read(size=size)\n    return self._fsntfs_file_entry.read(size=size)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef seek(self, offset, whence=os.SEEK_SET):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._fsntfs_data_stream:\n      self._fsntfs_data_stream.seek(offset, whence)\n    else:\n      self._fsntfs_file_entry.seek(offset, whence)", "response": "Seeks to an offset within the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_offset(self):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._fsntfs_data_stream:\n      return self._fsntfs_data_stream.get_offset()\n    return self._fsntfs_file_entry.get_offset()", "response": "Retrieves the current offset into the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the size of the file - like object.", "response": "def get_size(self):\n    \"\"\"Retrieves the size of the file-like object.\n\n    Returns:\n      int: size of the file-like object data.\n\n    Raises:\n      IOError: if the file-like object has not been opened.\n      OSError: if the file-like object has not been opened.\n    \"\"\"\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._fsntfs_data_stream:\n      return self._fsntfs_data_stream.get_size()\n    return self._fsntfs_file_entry.get_size()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _GetStat(self):\n    stat_object = super(GzipFileEntry, self)._GetStat()\n\n    if self._gzip_file:\n      stat_object.size = self._gzip_file.uncompressed_data_size\n\n    # Other stat information.\n    # gzip_file.comment\n    # gzip_file.operating_system\n    # gzip_file.original_filename\n\n    return stat_object", "response": "Retrieves information about the file entry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef modification_time(self):\n    timestamps = self._gzip_file.modification_times\n    if not timestamps:\n      return None\n    return dfdatetime_posix_time.PosixTime(timestamp=timestamps[0])", "response": "Returns the modification time of the gzipped file or None if not available."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Read(self):\n    input_string = self._file_object.readline()\n\n    if isinstance(input_string, py2to3.BYTES_TYPE):\n      try:\n        input_string = codecs.decode(input_string, self._encoding, self._errors)\n      except UnicodeDecodeError:\n        if self._errors == 'strict':\n          logging.error(\n              'Unable to properly read input due to encoding error. '\n              'Switching to error tolerant encoding which can result in '\n              'non Basic Latin (C0) characters to be replaced with \"?\" or '\n              '\"\\\\ufffd\".')\n          self._errors = 'replace'\n\n        input_string = codecs.decode(input_string, self._encoding, self._errors)\n\n    return input_string", "response": "Reads a string from the input."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _WriteRow(self, output_writer, values, in_bold=False):\n    row_strings = []\n    for value_index, value_string in enumerate(values):\n      padding_size = self._column_sizes[value_index] - len(value_string)\n      padding_string = ' ' * padding_size\n\n      row_strings.extend([value_string, padding_string])\n\n    row_strings.pop()\n\n    row_strings = ''.join(row_strings)\n\n    if in_bold and not win32console:\n      # TODO: for win32console get current color and set intensity,\n      # write the header separately then reset intensity.\n      row_strings = '\\x1b[1m{0:s}\\x1b[0m'.format(row_strings)\n\n    output_writer.Write('{0:s}\\n'.format(row_strings))", "response": "Writes a single row of values to the output writer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting the table to output writer.", "response": "def Write(self, output_writer):\n    \"\"\"Writes the table to output writer.\n\n    Args:\n      output_writer (CLIOutputWriter): output writer.\n    \"\"\"\n    # Round up the column sizes to the nearest tab.\n    for column_index, column_size in enumerate(self._column_sizes):\n      column_size, _ = divmod(column_size, self._NUMBER_OF_SPACES_IN_TAB)\n      column_size = (column_size + 1) * self._NUMBER_OF_SPACES_IN_TAB\n      self._column_sizes[column_index] = column_size\n\n    if self._columns:\n      self._WriteRow(output_writer, self._columns, in_bold=True)\n\n    for values in self._rows:\n      self._WriteRow(output_writer, values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetVSSStoreIdentifiers(self, volume_system, volume_identifiers):\n    print_header = True\n    while True:\n      if print_header:\n        self._PrintVSSStoreIdentifiersOverview(\n            volume_system, volume_identifiers)\n\n        print_header = False\n\n      self._output_writer.Write('\\n')\n\n      lines = self._textwrapper.wrap(self._USER_PROMPT_VSS)\n      self._output_writer.Write('\\n'.join(lines))\n      self._output_writer.Write('\\n\\nVSS identifier(s): ')\n\n      try:\n        selected_volumes = self._ReadSelectedVolumes(\n            volume_system, prefix='vss')\n        if (not selected_volumes or\n            not set(selected_volumes).difference(volume_identifiers)):\n          break\n      except ValueError:\n        pass\n\n      self._output_writer.Write('\\n')\n\n      lines = self._textwrapper.wrap(\n          'Unsupported VSS identifier(s), please try again or abort with '\n          'Ctrl^C.')\n      self._output_writer.Write('\\n'.join(lines))\n      self._output_writer.Write('\\n\\n')\n\n    return selected_volumes", "response": "Retrieves VSS store identifiers."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nunlocks an encrypted volume.", "response": "def UnlockEncryptedVolume(\n      self, source_scanner_object, scan_context, locked_scan_node, credentials):\n    \"\"\"Unlocks an encrypted volume.\n\n    This method can be used to prompt the user to provide encrypted volume\n    credentials.\n\n    Args:\n      source_scanner_object (SourceScanner): source scanner.\n      scan_context (SourceScannerContext): source scanner context.\n      locked_scan_node (SourceScanNode): locked scan node.\n      credentials (Credentials): credentials supported by the locked scan node.\n\n    Returns:\n      bool: True if the volume was unlocked.\n    \"\"\"\n    # TODO: print volume description.\n    if locked_scan_node.type_indicator == (\n        definitions.TYPE_INDICATOR_APFS_CONTAINER):\n      header = 'Found an APFS encrypted volume.'\n    elif locked_scan_node.type_indicator == definitions.TYPE_INDICATOR_BDE:\n      header = 'Found a BitLocker encrypted volume.'\n    elif locked_scan_node.type_indicator == definitions.TYPE_INDICATOR_FVDE:\n      header = 'Found a CoreStorage (FVDE) encrypted volume.'\n    else:\n      header = 'Found an encrypted volume.'\n\n    self._output_writer.Write(header)\n\n    credentials_list = list(credentials.CREDENTIALS)\n    credentials_list.append('skip')\n\n    self._output_writer.Write('Supported credentials:\\n\\n')\n\n    for index, name in enumerate(credentials_list):\n      available_credential = '  {0:d}. {1:s}\\n'.format(index + 1, name)\n      self._output_writer.Write(available_credential)\n\n    self._output_writer.Write('\\nNote that you can abort with Ctrl^C.\\n\\n')\n\n    result = False\n    while not result:\n      self._output_writer.Write('Select a credential to unlock the volume: ')\n\n      input_line = self._input_reader.Read()\n      input_line = input_line.strip()\n\n      if input_line in credentials_list:\n        credential_type = input_line\n      else:\n        try:\n          credential_type = int(input_line, 10)\n          credential_type = credentials_list[credential_type - 1]\n        except (IndexError, ValueError):\n          self._output_writer.Write(\n              'Unsupported credential: {0:s}\\n'.format(input_line))\n          continue\n\n      if credential_type == 'skip':\n        break\n\n      getpass_string = 'Enter credential data: '\n      if sys.platform.startswith('win') and sys.version_info[0] < 3:\n        # For Python 2 on Windows getpass (win_getpass) requires an encoded\n        # byte string. For Python 3 we need it to be a Unicode string.\n        getpass_string = self._EncodeString(getpass_string)\n\n      credential_data = getpass.getpass(getpass_string)\n      self._output_writer.Write('\\n')\n\n      if credential_type == 'key':\n        try:\n          credential_data = credential_data.decode('hex')\n        except TypeError:\n          self._output_writer.Write('Unsupported credential data.\\n')\n          continue\n\n      result = source_scanner_object.Unlock(\n          scan_context, locked_scan_node.path_spec, credential_type,\n          credential_data)\n\n      if not result:\n        self._output_writer.Write('Unable to unlock volume.\\n\\n')\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating directory entries using the specified directory structure.", "response": "def _EntriesGenerator(self):\n    \"\"\"Retrieves directory entries.\n\n    Since a directory can contain a vast number of entries using\n    a generator is more memory efficient.\n\n    Yields:\n      TARPathSpec: TAR path specification.\n    \"\"\"\n    location = getattr(self.path_spec, 'location', None)\n\n    if location and location.startswith(self._file_system.PATH_SEPARATOR):\n      # The TAR info name does not have the leading path separator as\n      # the location string does.\n      tar_path = location[1:]\n\n      # Set of top level sub directories that have been yielded.\n      processed_directories = set()\n\n      tar_file = self._file_system.GetTARFile()\n      for tar_info in iter(tar_file.getmembers()):\n        path = tar_info.name\n\n        # Determine if the start of the TAR info name is similar to\n        # the location string. If not the file TAR info refers to is not in\n        # the same directory.\n        if not path or not path.startswith(tar_path):\n          continue\n\n        # Ignore the directory itself.\n        if path == tar_path:\n          continue\n\n        path_segment, suffix = self._file_system.GetPathSegmentAndSuffix(\n            tar_path, path)\n        if not path_segment:\n          continue\n\n        # Sometimes the TAR file lacks directories, therefore we will\n        # provide virtual ones.\n        if suffix:\n          path_spec_location = self._file_system.JoinPath([\n              location, path_segment])\n          is_directory = True\n\n        else:\n          path_spec_location = self._file_system.JoinPath([path])\n          is_directory = tar_info.isdir()\n\n        if is_directory:\n          if path_spec_location in processed_directories:\n            continue\n          processed_directories.add(path_spec_location)\n\n        yield tar_path_spec.TARPathSpec(\n            location=path_spec_location, parent=self.path_spec.parent)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve a directory from the file system.", "response": "def _GetDirectory(self):\n    \"\"\"Retrieves a directory.\n\n    Returns:\n      TARDirectory: a directory or None if not available.\n    \"\"\"\n    if self.entry_type != definitions.FILE_ENTRY_TYPE_DIRECTORY:\n      return None\n    return TARDirectory(self._file_system, self.path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _GetLink(self):\n    if self._link is None:\n      if self._tar_info:\n        self._link = self._tar_info.linkname\n\n    return self._link", "response": "Retrieves the link.\n\n    Returns:\n      str: link."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the stat object.", "response": "def _GetStat(self):\n    \"\"\"Retrieves the stat object.\n\n    Returns:\n      VFSStat: stat object.\n    \"\"\"\n    stat_object = super(TARFileEntry, self)._GetStat()\n\n    # File data stat information.\n    stat_object.size = getattr(self._tar_info, 'size', None)\n\n    # Ownership and permissions stat information.\n    stat_object.mode = getattr(self._tar_info, 'mode', None)\n    stat_object.uid = getattr(self._tar_info, 'uid', None)\n    stat_object.gid = getattr(self._tar_info, 'gid', None)\n\n    # TODO: implement support for:\n    # stat_object.uname = getattr(self._tar_info, 'uname', None)\n    # stat_object.gname = getattr(self._tar_info, 'gname', None)\n\n    # File entry type stat information.\n\n    # The root file entry is virtual and should have type directory.\n\n    # TODO: determine if this covers all the types:\n    # REGTYPE, AREGTYPE, LNKTYPE, SYMTYPE, DIRTYPE, FIFOTYPE, CONTTYPE,\n    # CHRTYPE, BLKTYPE, GNUTYPE_SPARSE\n\n    # Other stat information.\n    # tar_info.pax_headers\n\n    return stat_object"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves the sub file entries.", "response": "def _GetSubFileEntries(self):\n    \"\"\"Retrieves sub file entries.\n\n    Yields:\n      TARFileEntry: a sub file entry.\n    \"\"\"\n    tar_file = self._file_system.GetTARFile()\n\n    if self._directory is None:\n      self._directory = self._GetDirectory()\n\n    if self._directory and tar_file:\n      for path_spec in self._directory.entries:\n        location = getattr(path_spec, 'location', None)\n        if location is None:\n          continue\n\n        kwargs = {}\n        try:\n          kwargs['tar_info'] = tar_file.getmember(location[1:])\n        except KeyError:\n          kwargs['is_virtual'] = True\n\n        yield TARFileEntry(\n            self._resolver_context, self._file_system, path_spec, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef modification_time(self):\n    timestamp = getattr(self._tar_info, 'mtime', None)\n    if timestamp is None:\n      return None\n    return dfdatetime_posix_time.PosixTime(timestamp=timestamp)", "response": "Returns the modification time of the archive."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the parent file entry.", "response": "def GetParentFileEntry(self):\n    \"\"\"Retrieves the parent file entry.\n\n    Returns:\n      TARFileEntry: parent file entry or None.\n    \"\"\"\n    location = getattr(self.path_spec, 'location', None)\n    if location is None:\n      return None\n\n    parent_location = self._file_system.DirnamePath(location)\n    if parent_location is None:\n      return None\n\n    if parent_location == '':\n      parent_location = self._file_system.PATH_SEPARATOR\n      is_root = True\n      is_virtual = True\n    else:\n      is_root = False\n      is_virtual = False\n\n    parent_path_spec = getattr(self.path_spec, 'parent', None)\n    path_spec = tar_path_spec.TARPathSpec(\n        location=parent_location, parent=parent_path_spec)\n    return TARFileEntry(\n        self._resolver_context, self._file_system, path_spec, is_root=is_root,\n        is_virtual=is_virtual)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetTARInfo(self):\n    if not self._tar_info:\n      location = getattr(self.path_spec, 'location', None)\n      if location is None:\n        raise errors.PathSpecError('Path specification missing location.')\n\n      if not location.startswith(self._file_system.LOCATION_ROOT):\n        raise errors.PathSpecError('Invalid location in path specification.')\n\n      if len(location) == 1:\n        return None\n\n      tar_file = self._file_system.GetTARFile()\n      try:\n        self._tar_info = tar_file.getmember(location[1:])\n      except KeyError:\n        pass\n\n    return self._tar_info", "response": "Retrieves the TAR info."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen the file - like object defined by path specification.", "response": "def _OpenFileObject(self, path_spec):\n    \"\"\"Opens the file-like object defined by path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n\n    Returns:\n      pyvde.volume: BDE volume file-like object.\n\n    Raises:\n      PathSpecError: if the path specification is incorrect.\n    \"\"\"\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    resolver.Resolver.key_chain.ExtractCredentialsFromPathSpec(path_spec)\n\n    file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n    bde_volume = pybde.volume()\n\n    bde.BDEVolumeOpen(\n        bde_volume, path_spec, file_object, resolver.Resolver.key_chain)\n    return bde_volume"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves the decoder object for a specific encoding method.", "response": "def GetDecoder(cls, encoding_method):\n    \"\"\"Retrieves the decoder object for a specific encoding method.\n\n    Args:\n      encoding_method (str): encoding method identifier.\n\n    Returns:\n      Decoder: decoder or None if the encoding method does not exists.\n    \"\"\"\n    encoding_method = encoding_method.lower()\n    decoder = cls._decoders.get(encoding_method, None)\n    if not decoder:\n      return None\n\n    return decoder()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nregister a decoder for a specific encoding method.", "response": "def RegisterDecoder(cls, decoder):\n    \"\"\"Registers a decoder for a specific encoding method.\n\n    Args:\n      decoder (type): decoder class.\n\n    Raises:\n      KeyError: if the corresponding decoder is already set.\n    \"\"\"\n    encoding_method = decoder.ENCODING_METHOD.lower()\n    if encoding_method in cls._decoders:\n      raise KeyError(\n          'Decoder for encoding method: {0:s} already set.'.format(\n              decoder.ENCODING_METHOD))\n\n    cls._decoders[encoding_method] = decoder"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _EntriesGenerator(self):\n    volume_index = getattr(self.path_spec, 'volume_index', None)\n    location = getattr(self.path_spec, 'location', None)\n\n    # Only the virtual root file has directory entries.\n    if (volume_index is None and location is not None and\n        location == self._file_system.LOCATION_ROOT):\n      vslvm_volume_group = self._file_system.GetLVMVolumeGroup()\n\n      for volume_index in range(\n          0, vslvm_volume_group.number_of_logical_volumes):\n        location = '/lvm{0:d}'.format(volume_index + 1)\n        yield lvm_path_spec.LVMPathSpec(\n            location=location, parent=self.path_spec.parent,\n            volume_index=volume_index)", "response": "Generates directory entries using the specified path specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the directory object.", "response": "def _GetDirectory(self):\n    \"\"\"Retrieves the directory.\n\n    Returns:\n      LVMDirectory: a directory or None if not available.\n    \"\"\"\n    if self.entry_type != definitions.FILE_ENTRY_TYPE_DIRECTORY:\n      return None\n    return LVMDirectory(self._file_system, self.path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the stat object for the current entry.", "response": "def _GetStat(self):\n    \"\"\"Retrieves information about the file entry.\n\n    Returns:\n      VFSStat: a stat object.\n    \"\"\"\n    stat_object = super(LVMFileEntry, self)._GetStat()\n\n    if self._vslvm_logical_volume is not None:\n      stat_object.size = self._vslvm_logical_volume.size\n\n    return stat_object"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the parent file entry.", "response": "def GetParentFileEntry(self):\n    \"\"\"Retrieves the parent file entry.\n\n    Returns:\n      LVMFileEntry: parent file entry or None if not available.\n    \"\"\"\n    volume_index = lvm.LVMPathSpecGetVolumeIndex(self.path_spec)\n    if volume_index is None:\n      return None\n\n    return self._file_system.GetRootFileEntry()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve the TSK volume system part object from the TSK volume object.", "response": "def GetTSKVsPartByPathSpec(tsk_volume, path_spec):\n  \"\"\"Retrieves the TSK volume system part object from the TSK volume object.\n\n  Args:\n    tsk_volume (pytsk3.Volume_Info): TSK volume information.\n    path_spec (PathSpec): path specification.\n\n  Returns:\n    tuple: contains:\n\n      pytsk3.TSK_VS_PART_INFO: TSK volume system part information or\n          None on error.\n      int: partition index or None if not available.\n  \"\"\"\n  location = getattr(path_spec, 'location', None)\n  part_index = getattr(path_spec, 'part_index', None)\n  start_offset = getattr(path_spec, 'start_offset', None)\n  partition_index = None\n\n  if part_index is None:\n    if location is not None:\n      if location.startswith('/p'):\n        try:\n          partition_index = int(location[2:], 10) - 1\n        except ValueError:\n          pass\n\n      if partition_index is None or partition_index < 0:\n        location = None\n\n    if location is None and start_offset is None:\n      return None, None\n\n  bytes_per_sector = TSKVolumeGetBytesPerSector(tsk_volume)\n  current_part_index = 0\n  current_partition_index = 0\n  tsk_vs_part = None\n\n  # pytsk3 does not handle the Volume_Info iterator correctly therefore\n  # the explicit cast to list is needed to prevent the iterator terminating\n  # too soon or looping forever.\n  tsk_vs_part_list = list(tsk_volume)\n  number_of_tsk_vs_parts = len(tsk_vs_part_list)\n\n  if number_of_tsk_vs_parts > 0:\n    if (part_index is not None and\n        (part_index < 0 or part_index >= number_of_tsk_vs_parts)):\n      return None, None\n\n    for tsk_vs_part in tsk_vs_part_list:\n      if TSKVsPartIsAllocated(tsk_vs_part):\n        if partition_index is not None:\n          if partition_index == current_partition_index:\n            break\n        current_partition_index += 1\n\n      if part_index is not None and part_index == current_part_index:\n        break\n\n      if start_offset is not None:\n        start_sector = TSKVsPartGetStartSector(tsk_vs_part)\n\n        if start_sector is not None:\n          start_sector *= bytes_per_sector\n          if start_sector == start_offset:\n            break\n\n      current_part_index += 1\n\n  # Note that here we cannot solely rely on testing if tsk_vs_part is set\n  # since the for loop will exit with tsk_vs_part set.\n  if tsk_vs_part is None or current_part_index >= number_of_tsk_vs_parts:\n    return None, None\n\n  if not TSKVsPartIsAllocated(tsk_vs_part):\n    current_partition_index = None\n  return tsk_vs_part, current_partition_index"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef TSKVolumeGetBytesPerSector(tsk_volume):\n  # Note that because pytsk3.Volume_Info does not explicitly defines info\n  # we need to check if the attribute exists and has a value other\n  # than None. Default to 512 otherwise.\n  if hasattr(tsk_volume, 'info') and tsk_volume.info is not None:\n    block_size = getattr(tsk_volume.info, 'block_size', 512)\n  else:\n    block_size = 512\n\n  return block_size", "response": "Retrieves the number of bytes per sector from a TSK volume object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an iterator over the directory entries.", "response": "def _EntriesGenerator(self):\n    \"\"\"Retrieves directory entries.\n\n    Since a directory can contain a vast number of entries using\n    a generator is more memory efficient.\n\n    Yields:\n      SQLiteBlobPathSpec: a path specification.\n\n    Raises:\n      AccessError: if the access to list the directory was denied.\n      BackEndError: if the directory could not be listed.\n    \"\"\"\n    table_name = getattr(self.path_spec, 'table_name', None)\n    column_name = getattr(self.path_spec, 'column_name', None)\n\n    if table_name and column_name:\n      if self._number_of_entries is None:\n        # Open the first entry to determine how many entries we have.\n        # TODO: change this when there is a move this to a central temp file\n        # manager. https://github.com/log2timeline/dfvfs/issues/92\n        path_spec = sqlite_blob_path_spec.SQLiteBlobPathSpec(\n            table_name=table_name, column_name=column_name, row_index=0,\n            parent=self.path_spec.parent)\n\n        sub_file_entry = self._file_system.GetFileEntryByPathSpec(path_spec)\n        if not file_entry:\n          self._number_of_entries = 0\n        else:\n          self._number_of_entries = sub_file_entry.GetNumberOfRows()\n\n      for row_index in range(0, self._number_of_entries):\n        yield sqlite_blob_path_spec.SQLiteBlobPathSpec(\n            table_name=table_name, column_name=column_name, row_index=row_index,\n            parent=self.path_spec.parent)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve a directory from the file system.", "response": "def _GetDirectory(self):\n    \"\"\"Retrieves a directory.\n\n    Returns:\n      SQLiteBlobDirectory: a directory or None if not available.\n    \"\"\"\n    if self.entry_type != definitions.FILE_ENTRY_TYPE_DIRECTORY:\n      return None\n    return SQLiteBlobDirectory(self._file_system, self.path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the stat object.", "response": "def _GetStat(self):\n    \"\"\"Retrieves the stat object.\n\n    Returns:\n      VFSStat: stat object.\n\n    Raises:\n      BackEndError: when the SQLite blob file-like object is missing.\n    \"\"\"\n    stat_object = super(SQLiteBlobFileEntry, self)._GetStat()\n\n    if not self._is_virtual:\n      file_object = self.GetFileObject()\n      if not file_object:\n        raise errors.BackEndError(\n            'Unable to retrieve SQLite blob file-like object.')\n\n      try:\n        stat_object.size = file_object.get_size()\n      finally:\n        file_object.close()\n\n    return stat_object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the number of rows in the table.", "response": "def GetNumberOfRows(self):\n    \"\"\"Retrieves the number of rows in the table.\n\n    Returns:\n      int: number of rows.\n\n    Raises:\n      BackEndError: when the SQLite blob file-like object is missing.\n    \"\"\"\n    file_object = self.GetFileObject()\n    if not file_object:\n      raise errors.BackEndError(\n          'Unable to retrieve SQLite blob file-like object.')\n\n    try:\n      # TODO: move this function out of SQLiteBlobFile.\n      self._number_of_entries = file_object.GetNumberOfRows()\n    finally:\n      file_object.close()\n\n    return self._number_of_entries"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving the parent file entry.", "response": "def GetParentFileEntry(self):\n    \"\"\"Retrieves the parent file entry.\n\n    Returns:\n      SQLiteBlobFileEntry: parent file entry or None if not available.\n    \"\"\"\n    # If the file entry is a sub entry, return the SQLite blob directory.\n    if self._is_virtual:\n      return None\n\n    path_spec = sqlite_blob_path_spec.SQLiteBlobPathSpec(\n        table_name=self.path_spec.table_name,\n        column_name=self.path_spec.column_name,\n        parent=self.path_spec.parent)\n    return SQLiteBlobFileEntry(\n        self._resolver_context, self._file_system,\n        path_spec, is_root=True, is_virtual=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncloses the file - like object.", "response": "def _Close(self):\n    \"\"\"Closes the file-like object.\"\"\"\n    super(VHDIFile, self)._Close()\n\n    for vhdi_file in self._parent_vhdi_files:\n      vhdi_file.close()\n\n    for file_object in self._sub_file_objects:\n      file_object.close()\n\n    self._parent_vhdi_files = []\n    self._sub_file_objects = []"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _OpenFileObject(self, path_spec):\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n\n    vhdi_file = pyvhdi.file()\n    vhdi_file.open_file_object(file_object)\n\n    if vhdi_file.parent_identifier:\n      file_system = resolver.Resolver.OpenFileSystem(\n          path_spec.parent, resolver_context=self._resolver_context)\n\n      try:\n        self._OpenParentFile(file_system, path_spec.parent, vhdi_file)\n      finally:\n        file_system.Close()\n\n    self._sub_file_objects.append(file_object)\n\n    self._parent_vhdi_files.reverse()\n    self._sub_file_objects.reverse()\n\n    return vhdi_file", "response": "Opens the file - like object defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _OpenParentFile(self, file_system, path_spec, vhdi_file):\n    location = getattr(path_spec, 'location', None)\n    if not location:\n      raise errors.PathSpecError(\n          'Unsupported path specification without location.')\n\n    location_path_segments = file_system.SplitPath(location)\n\n    parent_filename = vhdi_file.parent_filename\n    _, _, parent_filename = parent_filename.rpartition('\\\\')\n\n    location_path_segments.pop()\n    location_path_segments.append(parent_filename)\n    parent_file_location = file_system.JoinPath(location_path_segments)\n\n    # Note that we don't want to set the keyword arguments when not used\n    # because the path specification base class will check for unused\n    # keyword arguments and raise.\n    kwargs = path_spec_factory.Factory.GetProperties(path_spec)\n\n    kwargs['location'] = parent_file_location\n    if path_spec.parent is not None:\n      kwargs['parent'] = path_spec.parent\n\n    parent_file_path_spec = path_spec_factory.Factory.NewPathSpec(\n        path_spec.type_indicator, **kwargs)\n\n    if not file_system.FileEntryExistsByPathSpec(parent_file_path_spec):\n      return\n\n    file_object = resolver.Resolver.OpenFileObject(\n        parent_file_path_spec, resolver_context=self._resolver_context)\n\n    vhdi_parent_file = pyvhdi.file()\n    vhdi_parent_file.open_file_object(file_object)\n\n    if vhdi_parent_file.parent_identifier:\n      self._OpenParentFile(\n          file_system, parent_file_path_spec, vhdi_parent_file)\n\n    vhdi_file.set_parent(vhdi_parent_file)\n\n    self._parent_vhdi_files.append(vhdi_parent_file)\n    self._sub_file_objects.append(file_object)", "response": "Opens the parent file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetFileEntryByPathSpec(self, path_spec):\n    return gzip_file_entry.GzipFileEntry(\n        self._resolver_context, self, path_spec, is_root=True, is_virtual=True)", "response": "Retrieves a file entry for a path specification."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the root file entry.", "response": "def GetRootFileEntry(self):\n    \"\"\"Retrieves the root file entry.\n\n    Returns:\n      GzipFileEntry: a file entry or None if not available.\n    \"\"\"\n    path_spec = gzip_path_spec.GzipPathSpec(parent=self._path_spec.parent)\n    return self.GetFileEntryByPathSpec(path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _OpenFileObject(self, path_spec):\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    resolver.Resolver.key_chain.ExtractCredentialsFromPathSpec(path_spec)\n\n    file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n    fvde_volume = pyfvde.volume()\n    fvde.FVDEVolumeOpen(\n        fvde_volume, path_spec, file_object, resolver.Resolver.key_chain)\n    return fvde_volume", "response": "Opens the file - like object defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef DeregisterDecrypter(cls, decrypter):\n    encryption_method = decrypter.ENCRYPTION_METHOD.lower()\n    if encryption_method not in cls._decrypters:\n      raise KeyError(\n          'Decrypter for encryption method: {0:s} not set.'.format(\n              decrypter.ENCRYPTION_METHOD))\n\n    del cls._decrypters[encryption_method]", "response": "Deregisters a decrypter for a specific encryption method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the decrypter object for a specific encryption method.", "response": "def GetDecrypter(cls, encryption_method, **kwargs):\n    \"\"\"Retrieves the decrypter object for a specific encryption method.\n\n    Args:\n      encryption_method (str): encryption method identifier.\n      kwargs (dict): keyword arguments depending on the decrypter.\n\n    Returns:\n      Decrypter: decrypter or None if the encryption method does not exists.\n\n    Raises:\n      CredentialError: if the necessary credentials are missing.\n    \"\"\"\n    encryption_method = encryption_method.lower()\n    decrypter = cls._decrypters.get(encryption_method, None)\n    if not decrypter:\n      return None\n\n    return decrypter(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _EntriesGenerator(self):\n    # Only the virtual root file has directory entries.\n    volume_index = apfs_helper.APFSContainerPathSpecGetVolumeIndex(\n        self.path_spec)\n    if volume_index is not None:\n      return\n\n    location = getattr(self.path_spec, 'location', None)\n    if location is None or location != self._file_system.LOCATION_ROOT:\n      return\n\n    fsapfs_container = self._file_system.GetAPFSContainer()\n\n    for volume_index in range(0, fsapfs_container.number_of_volumes):\n      yield apfs_container_path_spec.APFSContainerPathSpec(\n          location='/apfs{0:d}'.format(volume_index + 1),\n          volume_index=volume_index, parent=self.path_spec.parent)", "response": "Returns an iterator over the directory entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves a directory from the file system.", "response": "def _GetDirectory(self):\n    \"\"\"Retrieves a directory.\n\n    Returns:\n      APFSContainerDirectory: a directory or None if not available.\n    \"\"\"\n    if self.entry_type != definitions.FILE_ENTRY_TYPE_DIRECTORY:\n      return None\n\n    return APFSContainerDirectory(self._file_system, self.path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _GetStat(self):\n    stat_object = super(APFSContainerFileEntry, self)._GetStat()\n\n    if self._fsapfs_volume is not None:\n      # File data stat information.\n      # TODO: implement volume size.\n      # stat_object.size = self._fsapfs_volume.size\n      pass\n\n    # Ownership and permissions stat information.\n\n    # File entry type stat information.\n\n    # The root file entry is virtual and should have type directory.\n    return stat_object", "response": "Retrieves the VFSStat object for the file entry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef name(self):\n    if self._name is None:\n      location = getattr(self.path_spec, 'location', None)\n      if location is not None:\n        self._name = self._file_system.BasenamePath(location)\n      else:\n        volume_index = apfs_helper.APFSContainerPathSpecGetVolumeIndex(\n            self.path_spec)\n        if volume_index is not None:\n          self._name = 'apfs{0:d}'.format(volume_index + 1)\n        else:\n          self._name = ''\n    return self._name", "response": "str name of the file entry which does not include the full path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetParentFileEntry(self):\n    volume_index = apfs_helper.APFSContainerPathSpecGetVolumeIndex(\n        self.path_spec)\n    if volume_index is None:\n      return None\n\n    return self._file_system.GetRootFileEntry()", "response": "Retrieves the parent file entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncloses the file system.", "response": "def _Close(self):\n    \"\"\"Closes the file system.\n\n    Raises:\n      IOError: if the close failed.\n    \"\"\"\n    self._tar_file.close()\n    self._tar_file = None\n\n    self._file_object.close()\n    self._file_object = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nopens the file system defined by path specification.", "response": "def _Open(self, path_spec, mode='rb'):\n    \"\"\"Opens the file system defined by path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n      mode (Optional[str]): file access mode. The default is 'rb' which\n          represents read-only binary.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file system could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n\n    try:\n      # Set the file offset to 0 because tarfile.open() does not.\n      file_object.seek(0, os.SEEK_SET)\n\n      # Explicitly tell tarfile not to use compression. Compression should be\n      # handled by the file-like object.\n      tar_file = tarfile.open(mode='r:', fileobj=file_object)\n    except:\n      file_object.close()\n      raise\n\n    self._file_object = file_object\n    self._tar_file = tar_file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetermining if a file entry for a path specification exists.", "response": "def FileEntryExistsByPathSpec(self, path_spec):\n    \"\"\"Determines if a file entry for a path specification exists.\n\n    Args:\n      path_spec (PathSpec): path specification.\n\n    Returns:\n      bool: True if the file entry exists.\n    \"\"\"\n    location = getattr(path_spec, 'location', None)\n\n    if (location is None or\n        not location.startswith(self.LOCATION_ROOT)):\n      return False\n\n    if len(location) == 1:\n      return True\n\n    try:\n      self._tar_file.getmember(location[1:])\n      return True\n    except KeyError:\n      pass\n\n    # Check if location could be a virtual directory.\n    for name in iter(self._tar_file.getnames()):\n      # The TAR info name does not have the leading path separator as\n      # the location string does.\n      if name.startswith(location[1:]):\n        return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetFileEntryByPathSpec(self, path_spec):\n    if not self.FileEntryExistsByPathSpec(path_spec):\n      return None\n\n    location = getattr(path_spec, 'location', None)\n\n    if len(location) == 1:\n      return tar_file_entry.TARFileEntry(\n          self._resolver_context, self, path_spec, is_root=True,\n          is_virtual=True)\n\n    kwargs = {}\n    try:\n      kwargs['tar_info'] = self._tar_file.getmember(location[1:])\n    except KeyError:\n      kwargs['is_virtual'] = True\n\n    return tar_file_entry.TARFileEntry(\n        self._resolver_context, self, path_spec, **kwargs)", "response": "Retrieves a file entry for a path specification."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the root file entry.", "response": "def GetRootFileEntry(self):\n    \"\"\"Retrieves the root file entry.\n\n    Returns:\n      TARFileEntry: file entry.\n    \"\"\"\n    path_spec = tar_path_spec.TARPathSpec(\n        location=self.LOCATION_ROOT, parent=self._path_spec.parent)\n    return self.GetFileEntryByPathSpec(path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves the TAR info for a path specification.", "response": "def GetTARInfoByPathSpec(self, path_spec):\n    \"\"\"Retrieves the TAR info for a path specification.\n\n    Args:\n      path_spec (PathSpec): a path specification.\n\n    Returns:\n      tarfile.TARInfo: TAR info or None if it does not exist.\n\n    Raises:\n      PathSpecError: if the path specification is incorrect.\n    \"\"\"\n    location = getattr(path_spec, 'location', None)\n    if location is None:\n      raise errors.PathSpecError('Path specification missing location.')\n\n    if not location.startswith(self.LOCATION_ROOT):\n      raise errors.PathSpecError('Invalid location in path specification.')\n\n    if len(location) == 1:\n      return None\n\n    try:\n      return self._tar_file.getmember(location[1:])\n    except KeyError:\n      pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Decrypt(self, encrypted_data):\n    index_split = -(len(encrypted_data) % Blowfish.block_size)\n    if index_split:\n      remaining_encrypted_data = encrypted_data[index_split:]\n      encrypted_data = encrypted_data[:index_split]\n    else:\n      remaining_encrypted_data = b''\n\n    decrypted_data = self._blowfish_cipher.decrypt(encrypted_data)\n\n    return decrypted_data, remaining_encrypted_data", "response": "Decrypts the encrypted data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef readline(self, size=None):\n    if size is not None and size < 0:\n      raise ValueError('Invalid size value smaller than zero.')\n\n    if size is not None and size > self._MAXIMUM_READ_BUFFER_SIZE:\n      raise ValueError('Invalid size value exceeds maximum.')\n\n    if not self._lines:\n      if self._lines_buffer_offset >= self._file_object_size:\n        return ''\n\n      read_size = size\n      if not read_size:\n        read_size = self._MAXIMUM_READ_BUFFER_SIZE\n\n      if self._lines_buffer_offset + read_size > self._file_object_size:\n        read_size = self._file_object_size - self._lines_buffer_offset\n\n      self._file_object.seek(self._lines_buffer_offset, os.SEEK_SET)\n      read_buffer = self._file_object.read(read_size)\n\n      self._lines_buffer_offset += len(read_buffer)\n\n      self._lines = read_buffer.split(self._end_of_line)\n      if self._lines_buffer:\n        self._lines[0] = b''.join([self._lines_buffer, self._lines[0]])\n        self._lines_buffer = b''\n\n      # Move a partial line from the lines list to the lines buffer.\n      if read_buffer[self._end_of_line_length:] != self._end_of_line:\n        self._lines_buffer = self._lines.pop()\n\n      for index, line in enumerate(self._lines):\n        self._lines[index] = b''.join([line, self._end_of_line])\n\n      if (self._lines_buffer and\n          self._lines_buffer_offset >= self._file_object_size):\n        self._lines.append(self._lines_buffer)\n        self._lines_buffer = b''\n\n    if not self._lines:\n      line = self._lines_buffer\n      self._lines_buffer = b''\n\n    elif not size or size >= len(self._lines[0]):\n      line = self._lines.pop(0)\n\n    else:\n      line = self._lines[0]\n      self._lines[0] = line[size:]\n      line = line[:size]\n\n    last_offset = self._current_offset\n    self._current_offset += len(line)\n\n    decoded_line = line.decode(self._encoding)\n\n    # Remove a byte-order mark at the start of the file.\n    if last_offset == 0 and decoded_line[0] == '\\ufeff':\n      decoded_line = decoded_line[1:]\n\n    return decoded_line", "response": "Reads a single line of text from the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclose the file system.", "response": "def _Close(self):\n    \"\"\"Closes the file system.\n\n    Raises:\n      IOError: if the close failed.\n    \"\"\"\n    self._cpio_archive_file.Close()\n    self._cpio_archive_file = None\n\n    self._file_object.close()\n    self._file_object = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen the file system defined by path specification.", "response": "def _Open(self, path_spec, mode='rb'):\n    \"\"\"Opens the file system defined by path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n      mode (Optional[str]): file access mode. The default is 'rb' which\n          represents read-only binary.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file system could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n\n    cpio_archive_file = cpio.CPIOArchiveFile()\n    try:\n      cpio_archive_file.Open(file_object)\n    except:\n      file_object.close()\n      raise\n\n    self._file_object = file_object\n    self._cpio_archive_file = cpio_archive_file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef FileEntryExistsByPathSpec(self, path_spec):\n    location = getattr(path_spec, 'location', None)\n    if location is None or not location.startswith(self.LOCATION_ROOT):\n      return False\n\n    if len(location) == 1:\n      return True\n\n    return self._cpio_archive_file.FileEntryExistsByPath(location[1:])", "response": "Determines if a file entry for a path specification exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves the CPIO archive file entry for a path specification.", "response": "def GetCPIOArchiveFileEntryByPathSpec(self, path_spec):\n    \"\"\"Retrieves the CPIO archive file entry for a path specification.\n\n    Args:\n      path_spec (PathSpec): a path specification.\n\n    Returns:\n      CPIOArchiveFileEntry: CPIO archive file entry or None if not available.\n\n    Raises:\n      PathSpecError: if the path specification is incorrect.\n    \"\"\"\n    location = getattr(path_spec, 'location', None)\n    if location is None:\n      raise errors.PathSpecError('Path specification missing location.')\n\n    if not location.startswith(self.LOCATION_ROOT):\n      raise errors.PathSpecError('Invalid location in path specification.')\n\n    if len(location) == 1:\n      return None\n\n    return self._cpio_archive_file.GetFileEntryByPath(location[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetFileEntryByPathSpec(self, path_spec):\n    location = getattr(path_spec, 'location', None)\n\n    if (location is None or\n        not location.startswith(self.LOCATION_ROOT)):\n      return None\n\n    if len(location) == 1:\n      return cpio_file_entry.CPIOFileEntry(\n          self._resolver_context, self, path_spec, is_root=True,\n          is_virtual=True)\n\n    cpio_archive_file_entry = self._cpio_archive_file.GetFileEntryByPath(\n        location[1:])\n    if cpio_archive_file_entry is None:\n      return None\n\n    return cpio_file_entry.CPIOFileEntry(\n        self._resolver_context, self, path_spec,\n        cpio_archive_file_entry=cpio_archive_file_entry)", "response": "Retrieves a file entry for a path specification."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetRootFileEntry(self):\n    path_spec = cpio_path_spec.CPIOPathSpec(\n        location=self.LOCATION_ROOT, parent=self._path_spec.parent)\n    return self.GetFileEntryByPathSpec(path_spec)", "response": "Retrieves the root file entry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _PathStripPrefix(self, path):\n    if path.startswith('\\\\\\\\.\\\\') or path.startswith('\\\\\\\\?\\\\'):\n      if len(path) < 7 or path[5] != ':' or path[6] != self._PATH_SEPARATOR:\n        # Cannot handle a non-volume path.\n        return None\n\n      path = path[7:]\n\n    elif path.startswith('\\\\\\\\'):\n      # Cannot handle an UNC path.\n      return None\n\n    elif len(path) >= 3 and path[1] == ':':\n      # Check if the path is a Volume 'absolute' path.\n      if path[2] != self._PATH_SEPARATOR:\n        # Cannot handle a Volume 'relative' path.\n        return None\n\n      path = path[3:]\n\n    elif path.startswith('\\\\'):\n      path = path[1:]\n\n    else:\n      # Cannot handle a relative path.\n      return None\n\n    return path", "response": "Strips the prefix from a path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresolving a Windows path in file system specific format.", "response": "def _ResolvePath(self, path, expand_variables=True):\n    \"\"\"Resolves a Windows path in file system specific format.\n\n    This function will check if the individual path segments exists within\n    the file system. For this it will prefer the first case sensitive match\n    above a case insensitive match. If no match was found None is returned.\n\n    Args:\n      path (str): Windows path to resolve.\n      expand_variables (Optional[bool]): True if path variables should be\n          expanded or not.\n\n    Returns:\n      tuple[str, PathSpec]: location and matching path specification or\n          (None, None) if not available.\n    \"\"\"\n    # Allow for paths that start with an environment variable e.g.\n    # %SystemRoot%\\file.txt\n    if path.startswith('%'):\n      path_segment, _, _ = path.partition(self._PATH_SEPARATOR)\n      if not self._PATH_EXPANSION_VARIABLE.match(path_segment):\n        path = None\n    else:\n      path = self._PathStripPrefix(path)\n\n    if path is None:\n      return None, None\n\n    if path_spec_factory.Factory.IsSystemLevelTypeIndicator(\n        self._file_system.type_indicator):\n      file_entry = self._file_system.GetFileEntryByPathSpec(self._mount_point)\n      expanded_path_segments = self._file_system.SplitPath(\n          self._mount_point.location)\n    else:\n      file_entry = self._file_system.GetRootFileEntry()\n      expanded_path_segments = []\n\n    number_of_expanded_path_segments = 0\n\n    search_path_segments = path.split(self._PATH_SEPARATOR)\n    while search_path_segments:\n      path_segment = search_path_segments.pop(0)\n      if file_entry is None:\n        return None, None\n\n      # Ignore empty path segments or path segments containing a single dot.\n      if not path_segment or path_segment == '.':\n        continue\n\n      if path_segment == '..':\n        # Only allow to traverse back up to the mount point.\n        if number_of_expanded_path_segments > 0:\n          _ = expanded_path_segments.pop(0)\n          number_of_expanded_path_segments -= 1\n          file_entry = file_entry.GetParentFileEntry()\n        continue\n\n      if (expand_variables and\n          self._PATH_EXPANSION_VARIABLE.match(path_segment)):\n        path_segment = self._environment_variables.get(\n            path_segment[1:-1].upper(), path_segment)\n\n        if self._PATH_SEPARATOR in path_segment:\n          # The expanded path segment itself can consist of multiple\n          # path segments, hence we need to split it and prepend it to\n          # the search path segments list.\n          path_segments = path_segment.split(self._PATH_SEPARATOR)\n          path_segments.extend(search_path_segments)\n          search_path_segments = path_segments\n          path_segment = search_path_segments.pop(0)\n\n      sub_file_entry = file_entry.GetSubFileEntryByName(\n          path_segment, case_sensitive=False)\n      if sub_file_entry is None:\n        return None, None\n\n      expanded_path_segments.append(sub_file_entry.name)\n      number_of_expanded_path_segments += 1\n      file_entry = sub_file_entry\n\n    location = self._file_system.JoinPath(expanded_path_segments)\n    return location, file_entry.path_spec"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ResolvePath(self, path, expand_variables=True):\n    location, path_spec = self._ResolvePath(\n        path, expand_variables=expand_variables)\n\n    if not location or not path_spec:\n      return None\n\n    # Note that we don't want to set the keyword arguments when not used because\n    # the path specification base class will check for unused keyword arguments\n    # and raise.\n    kwargs = path_spec_factory.Factory.GetProperties(path_spec)\n\n    kwargs['location'] = location\n    if not path_spec_factory.Factory.IsSystemLevelTypeIndicator(\n        self._file_system.type_indicator):\n      kwargs['parent'] = self._mount_point\n\n    return path_spec_factory.Factory.NewPathSpec(\n        self._file_system.type_indicator, **kwargs)", "response": "Resolves a Windows path in file system specific format."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets an environment variable in the Windows path helper.", "response": "def SetEnvironmentVariable(self, name, value):\n    \"\"\"Sets an environment variable in the Windows path helper.\n\n    Args:\n      name (str): name of the environment variable without enclosing\n          %-characters, e.g. SystemRoot as in %SystemRoot%.\n      value (str): value of the environment variable.\n    \"\"\"\n    if isinstance(value, py2to3.STRING_TYPES):\n      value = self._PathStripPrefix(value)\n\n    if value is not None:\n      self._environment_variables[name.upper()] = value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the volume index from the path specification.", "response": "def APFSContainerPathSpecGetVolumeIndex(path_spec):\n  \"\"\"Retrieves the volume index from the path specification.\n\n  Args:\n    path_spec (PathSpec): path specification.\n\n  Returns:\n    int: volume index or None if the index cannot be determined.\n  \"\"\"\n  volume_index = getattr(path_spec, 'volume_index', None)\n  if volume_index is not None:\n    return volume_index\n\n  location = getattr(path_spec, 'location', None)\n  if location is None or not location.startswith('/apfs'):\n    return None\n\n  try:\n    volume_index = int(location[5:], 10) - 1\n  except (TypeError, ValueError):\n    volume_index = None\n\n  if volume_index is None or volume_index < 0 or volume_index > 99:\n    volume_index = None\n\n  return volume_index"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nunlocking an APFS volume using the path specification.", "response": "def APFSUnlockVolume(fsapfs_volume, path_spec, key_chain):\n  \"\"\"Unlocks an APFS volume using the path specification.\n\n  Args:\n    fsapfs_volume (pyapfs.volume): APFS volume.\n    path_spec (PathSpec): path specification.\n    key_chain (KeyChain): key chain.\n\n  Returns:\n    bool: True if the volume is unlocked, False otherwise.\n  \"\"\"\n  is_locked = fsapfs_volume.is_locked()\n  if is_locked:\n    password = key_chain.GetCredential(path_spec, 'password')\n    if password:\n      fsapfs_volume.set_password(password)\n\n    recovery_password = key_chain.GetCredential(path_spec, 'recovery_password')\n    if recovery_password:\n      fsapfs_volume.set_recovery_password(recovery_password)\n\n    is_locked = not fsapfs_volume.unlock()\n\n  return not is_locked"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _Close(self):\n    if self._database_object:\n      self._database_object.Close()\n\n    self._blob = None\n    self._current_offset = 0\n    self._size = 0\n    self._table_name = None", "response": "Closes the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _Open(self, path_spec=None, mode='rb'):\n    if not path_spec:\n      raise ValueError('Missing path specification.')\n\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    table_name = getattr(path_spec, 'table_name', None)\n    if table_name is None:\n      raise errors.PathSpecError('Path specification missing table name.')\n\n    column_name = getattr(path_spec, 'column_name', None)\n    if column_name is None:\n      raise errors.PathSpecError('Path specification missing column name.')\n\n    row_condition = getattr(path_spec, 'row_condition', None)\n    if row_condition:\n      if not isinstance(row_condition, tuple) or len(row_condition) != 3:\n        raise errors.PathSpecError((\n            'Unsupported row_condition not a tuple in the form: '\n            '(column_name, operator, value).'))\n\n    row_index = getattr(path_spec, 'row_index', None)\n    if row_index is not None:\n      if not isinstance(row_index, py2to3.INTEGER_TYPES):\n        raise errors.PathSpecError(\n            'Unsupported row_index not of integer type.')\n\n    if not row_condition and row_index is None:\n      raise errors.PathSpecError(\n          'Path specification requires either a row_condition or row_index.')\n\n    if self._database_object:\n      raise IOError('Database file already set.')\n\n    file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n\n    try:\n      database_object = sqlite_database.SQLiteDatabaseFile()\n      database_object.Open(file_object)\n    finally:\n      file_object.close()\n\n    # Sanity check the table and column names.\n    error_string = ''\n    if not database_object.HasTable(table_name):\n      error_string = 'Missing table: {0:s}'.format(table_name)\n\n    elif not database_object.HasColumn(table_name, column_name):\n      error_string = 'Missing column: {0:s} in table: {1:s}'.format(\n          column_name, table_name)\n\n    elif not row_condition:\n      query = 'SELECT {0:s} FROM {1:s} LIMIT 1 OFFSET {2:d}'.format(\n          column_name, table_name, row_index)\n      rows = database_object.Query(query)\n\n    elif not database_object.HasColumn(table_name, row_condition[0]):\n      error_string = (\n          'Missing row condition column: {0:s} in table: {1:s}'.format(\n              row_condition[0], table_name))\n\n    elif row_condition[1] not in self._OPERATORS:\n      error_string = (\n          'Unsupported row condition operator: {0:s}.'.format(\n              row_condition[1]))\n\n    else:\n      query = 'SELECT {0:s} FROM {1:s} WHERE {2:s} {3:s} ?'.format(\n          column_name, table_name, row_condition[0], row_condition[1])\n      rows = database_object.Query(query, parameters=(row_condition[2], ))\n\n    # Make sure the query returns a single row, using cursor.rowcount\n    # is not reliable for this purpose.\n    if not error_string and (len(rows) != 1 or len(rows[0]) != 1):\n      if not row_condition:\n        error_string = (\n            'Unable to open blob in table: {0:s} and column: {1:s} '\n            'for row: {2:d}.').format(table_name, column_name, row_index)\n\n      else:\n        row_condition_string = ' '.join([\n            '{0!s}'.format(value) for value in iter(row_condition)])\n        error_string = (\n            'Unable to open blob in table: {0:s} and column: {1:s} '\n            'where: {2:s}.').format(\n                table_name, column_name, row_condition_string)\n\n    if error_string:\n      database_object.Close()\n      raise IOError(error_string)\n\n    self._blob = rows[0][0]\n    self._current_offset = 0\n    self._database_object = database_object\n    self._size = len(self._blob)\n    self._table_name = table_name", "response": "Opens the file - like object defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the number of rows of the table.", "response": "def GetNumberOfRows(self):\n    \"\"\"Retrieves the number of rows of the table.\n\n    Returns:\n      int: number of rows.\n\n    Raises:\n      IOError: if the file-like object has not been opened.\n      OSError: if the file-like object has not been opened.\n    \"\"\"\n    if not self._database_object:\n      raise IOError('Not opened.')\n\n    if self._number_of_rows is None:\n      self._number_of_rows = self._database_object.GetNumberOfRows(\n          self._table_name)\n\n    return self._number_of_rows"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a byte string from the file - like object at the current offset.", "response": "def read(self, size=None):\n    \"\"\"Reads a byte string from the file-like object at the current offset.\n\n    The function will read a byte string of the specified size or\n    all of the remaining data if no size was specified.\n\n    Args:\n      size (Optional[int]): number of bytes to read, where None is all\n          remaining data.\n\n    Returns:\n      bytes: data read.\n\n    Raises:\n      IOError: if the read failed.\n      OSError: if the read failed.\n    \"\"\"\n    if not self._database_object:\n      raise IOError('Not opened.')\n\n    if self._current_offset < 0:\n      raise IOError('Invalid offset value out of bounds.')\n\n    if size == 0 or self._current_offset >= self._size:\n      return b''\n\n    if size is None:\n      size = self._size\n    if self._current_offset + size > self._size:\n      size = self._size - self._current_offset\n\n    start_offset = self._current_offset\n    self._current_offset += size\n    return self._blob[start_offset:self._current_offset]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nseek to an offset within the file - like object.", "response": "def seek(self, offset, whence=os.SEEK_SET):\n    \"\"\"Seeks to an offset within the file-like object.\n\n    Args:\n      offset (int): offset to seek to.\n      whence (Optional(int)): value that indicates whether offset is an absolute\n          or relative position within the file.\n\n    Raises:\n      IOError: if the seek failed.\n      OSError: if the seek failed.\n    \"\"\"\n    if not self._database_object:\n      raise IOError('Not opened.')\n\n    if whence == os.SEEK_CUR:\n      offset += self._current_offset\n    elif whence == os.SEEK_END:\n      offset += self._size\n    elif whence != os.SEEK_SET:\n      raise IOError('Unsupported whence.')\n\n    if offset < 0:\n      raise IOError('Invalid offset value out of bounds.')\n\n    self._current_offset = offset"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nopens the file - like object defined by path specification.", "response": "def _Open(self, path_spec=None, mode='rb'):\n    \"\"\"Opens the file-like object defined by path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n      mode (Optional[str]): file access mode.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file-like object could not be opened.\n      OSError: if the file-like object could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec:\n      raise ValueError('Missing path specification.')\n\n    if path_spec.HasParent():\n      raise errors.PathSpecError('Unsupported path specification with parent.')\n\n    location = getattr(path_spec, 'location', None)\n    if location is None:\n      raise errors.PathSpecError('Path specification missing location.')\n\n    self._current_offset = 0\n    self._size = len(self._file_data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(self, size=None):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._current_offset < 0:\n      raise IOError(\n          'Invalid current offset: {0:d} value less than zero.'.format(\n              self._current_offset))\n\n    if self._file_data is None or self._current_offset >= self._size:\n      return b''\n\n    if size is None:\n      size = self._size\n    if self._current_offset + size > self._size:\n      size = self._size - self._current_offset\n\n    start_offset = self._current_offset\n    self._current_offset += size\n    return self._file_data[start_offset:self._current_offset]", "response": "Reads a byte string from the file - like object at the current offset."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _Parse(self):\n    fsapfs_volume = self._file_entry.GetAPFSVolume()\n\n    volume_attribute = volume_system.VolumeAttribute(\n        'identifier', fsapfs_volume.identifier)\n    self._AddAttribute(volume_attribute)\n\n    volume_attribute = volume_system.VolumeAttribute(\n        'name', fsapfs_volume.name)\n    self._AddAttribute(volume_attribute)", "response": "Extracts attributes and extents from the volume."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _Parse(self):\n    root_file_entry = self._file_system.GetRootFileEntry()\n\n    for sub_file_entry in root_file_entry.sub_file_entries:\n      volume = APFSVolume(sub_file_entry)\n      self._AddVolume(volume)", "response": "Extracts sections and volumes from the volume system."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _OpenFileObject(self, path_spec):\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    parent_path_spec = path_spec.parent\n\n    parent_location = getattr(parent_path_spec, 'location', None)\n    if not parent_location:\n      raise errors.PathSpecError(\n          'Unsupported parent path specification without location.')\n\n    # Note that we cannot use pyvmdk's open_extent_data_files function\n    # since it does not handle the file system abstraction dfvfs provides.\n\n    file_system = resolver.Resolver.OpenFileSystem(\n        parent_path_spec, resolver_context=self._resolver_context)\n\n    file_object = resolver.Resolver.OpenFileObject(\n        parent_path_spec, resolver_context=self._resolver_context)\n\n    vmdk_handle = pyvmdk.handle()\n    vmdk_handle.open_file_object(file_object)\n\n    parent_location_path_segments = file_system.SplitPath(parent_location)\n\n    extent_data_files = []\n    for extent_descriptor in iter(vmdk_handle.extent_descriptors):\n      extent_data_filename = extent_descriptor.filename\n\n      _, path_separator, filename = extent_data_filename.rpartition('/')\n      if not path_separator:\n        _, path_separator, filename = extent_data_filename.rpartition('\\\\')\n\n      if not path_separator:\n        filename = extent_data_filename\n\n      # The last parent location path segment contains the extent data filename.\n      # Since we want to check if the next extent data file exists we remove\n      # the previous one form the path segments list and add the new filename.\n      # After that the path segments list can be used to create the location\n      # string.\n      parent_location_path_segments.pop()\n      parent_location_path_segments.append(filename)\n      extent_data_file_location = file_system.JoinPath(\n          parent_location_path_segments)\n\n      # Note that we don't want to set the keyword arguments when not used\n      # because the path specification base class will check for unused\n      # keyword arguments and raise.\n      kwargs = path_spec_factory.Factory.GetProperties(parent_path_spec)\n\n      kwargs['location'] = extent_data_file_location\n      if parent_path_spec.parent is not None:\n        kwargs['parent'] = parent_path_spec.parent\n\n      extent_data_file_path_spec = path_spec_factory.Factory.NewPathSpec(\n          parent_path_spec.type_indicator, **kwargs)\n\n      if not file_system.FileEntryExistsByPathSpec(extent_data_file_path_spec):\n        break\n\n      extent_data_files.append(extent_data_file_path_spec)\n\n    if len(extent_data_files) != vmdk_handle.number_of_extents:\n      raise IOError('Unable to locate all extent data files.')\n\n    file_objects = []\n    for extent_data_file_path_spec in extent_data_files:\n      file_object = resolver.Resolver.OpenFileObject(\n          extent_data_file_path_spec, resolver_context=self._resolver_context)\n      file_objects.append(file_object)\n\n    # TODO: add parent image support.\n    vmdk_handle.open_extent_data_files_file_objects(file_objects)\n\n    return vmdk_handle", "response": "Opens the file - like object defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nopens the file system defined by path specification.", "response": "def _Open(self, path_spec, mode='rb'):\n    \"\"\"Opens the file system defined by path specification.\n\n    Args:\n      path_spec (PathSpec): a path specification.\n      mode (Optional[str]): file access mode. The default is 'rb' which\n          represents read-only binary.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file system could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    encoding_method = getattr(path_spec, 'encoding_method', None)\n    if not encoding_method:\n      raise errors.PathSpecError(\n          'Unsupported path specification without encoding method.')\n\n    self._encoding_method = encoding_method"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetFileEntryByPathSpec(self, path_spec):\n    return encoded_stream_file_entry.EncodedStreamFileEntry(\n        self._resolver_context, self, path_spec, is_root=True, is_virtual=True)", "response": "Retrieves a file entry for a path specification."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the root file entry.", "response": "def GetRootFileEntry(self):\n    \"\"\"Retrieves the root file entry.\n\n    Returns:\n      EncodedStreamFileEntry: a file entry or None if not available.\n    \"\"\"\n    path_spec = encoded_stream_path_spec.EncodedStreamPathSpec(\n        encoding_method=self._encoding_method,\n        parent=self._path_spec.parent)\n    return self.GetFileEntryByPathSpec(path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef comparable(self):\n    sub_comparable_string = 'identifier: {0:s}'.format(self.identifier)\n    return self._GetComparable(sub_comparable_string=sub_comparable_string)", "response": "str - > comparable representation of the path specification."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetFormatSpecification(self):\n    format_specification = specification.FormatSpecification(\n        self.type_indicator)\n\n    # FAT volume header signature.\n    format_specification.AddNewSignature(b'\\x55\\xaa', offset=510)\n\n    if definitions.PREFERRED_NTFS_BACK_END == self.TYPE_INDICATOR:\n      # NTFS file system signature.\n      format_specification.AddNewSignature(b'NTFS    ', offset=3)\n\n    # HFS boot block signature.\n    format_specification.AddNewSignature(b'LK', offset=0)\n\n    # HFS master directory block signature.\n    format_specification.AddNewSignature(b'BD', offset=0)\n\n    # HFS+ file system signature.\n    format_specification.AddNewSignature(b'H+', offset=1024)\n\n    # HFSX file system signature.\n    format_specification.AddNewSignature(b'HX', offset=1024)\n\n    # Ext file system signature.\n    format_specification.AddNewSignature(b'\\x53\\xef', offset=1080)\n\n    # ISO9660 file system signature.\n    format_specification.AddNewSignature(b'CD001', offset=32769)\n\n    # YAFFS file system signature.\n\n    return format_specification", "response": "Retrieves the format specification."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclosing the file system object.", "response": "def _Close(self):\n    \"\"\"Closes the file system object.\n\n    Raises:\n      IOError: if the close failed.\n    \"\"\"\n    self._zip_file.close()\n    self._zip_file = None\n\n    self._file_object.close()\n    self._file_object = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nopens the file system object defined by path specification.", "response": "def _Open(self, path_spec, mode='rb'):\n    \"\"\"Opens the file system object defined by path specification.\n\n    Args:\n      path_spec (PathSpec): path specification of the file system.\n      mode (Optional[str]): file access mode. The default is 'rb' which\n          represents read-only binary.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file system object could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n\n    try:\n      zip_file = zipfile.ZipFile(file_object, 'r')\n    except:\n      file_object.close()\n      raise\n\n    self._file_object = file_object\n    self._zip_file = zip_file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef FileEntryExistsByPathSpec(self, path_spec):\n    location = getattr(path_spec, 'location', None)\n\n    if (location is None or\n        not location.startswith(self.LOCATION_ROOT)):\n      return False\n\n    if len(location) == 1:\n      return True\n\n    try:\n      self._zip_file.getinfo(location[1:])\n      return True\n    except KeyError:\n      pass\n\n    # Check if location could be a virtual directory.\n    for name in iter(self._zip_file.namelist()):\n      # The ZIP info name does not have the leading path separator as\n      # the location string does.\n      if name.startswith(location[1:]):\n        return True\n\n    return False", "response": "Determines if a file entry for a path specification exists."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving a file entry for a path specification.", "response": "def GetFileEntryByPathSpec(self, path_spec):\n    \"\"\"Retrieves a file entry for a path specification.\n\n    Args:\n      path_spec (PathSpec): path specification of the file entry.\n\n    Returns:\n      ZipFileEntry: a file entry or None.\n    \"\"\"\n    if not self.FileEntryExistsByPathSpec(path_spec):\n      return None\n\n    location = getattr(path_spec, 'location', None)\n\n    if len(location) == 1:\n      return zip_file_entry.ZipFileEntry(\n          self._resolver_context, self, path_spec, is_root=True,\n          is_virtual=True)\n\n    kwargs = {}\n    try:\n      kwargs['zip_info'] = self._zip_file.getinfo(location[1:])\n    except KeyError:\n      kwargs['is_virtual'] = True\n\n    return zip_file_entry.ZipFileEntry(\n        self._resolver_context, self, path_spec, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the root file entry.", "response": "def GetRootFileEntry(self):\n    \"\"\"Retrieves the root file entry.\n\n    Returns:\n      ZipFileEntry: a file entry or None.\n    \"\"\"\n    path_spec = zip_path_spec.ZipPathSpec(\n        location=self.LOCATION_ROOT, parent=self._path_spec.parent)\n    return self.GetFileEntryByPathSpec(path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GetZipInfoByPathSpec(self, path_spec):\n    location = getattr(path_spec, 'location', None)\n    if location is None:\n      raise errors.PathSpecError('Path specification missing location.')\n\n    if not location.startswith(self.LOCATION_ROOT):\n      raise errors.PathSpecError('Invalid location in path specification.')\n\n    if len(location) > 1:\n      return self._zip_file.getinfo(location[1:])\n\n    return None", "response": "Retrieves the ZIP info object for a path specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef comparable(self):\n    sub_comparable_string = 'location: {0:s}'.format(self.location)\n    return self._GetComparable(sub_comparable_string=sub_comparable_string)", "response": "str - > comparable representation of the path specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts the attributes and extents from the volume.", "response": "def _Parse(self):\n    \"\"\"Extracts attributes and extents from the volume.\"\"\"\n    vshadow_store = self._file_entry.GetVShadowStore()\n\n    self._AddAttribute(volume_system.VolumeAttribute(\n        'identifier', vshadow_store.identifier))\n    self._AddAttribute(volume_system.VolumeAttribute(\n        'copy_identifier', vshadow_store.copy_identifier))\n    self._AddAttribute(volume_system.VolumeAttribute(\n        'copy_set_identifier', vshadow_store.copy_set_identifier))\n    self._AddAttribute(volume_system.VolumeAttribute(\n        'creation_time', vshadow_store.get_creation_time_as_integer()))\n\n    volume_extent = volume_system.VolumeExtent(0, vshadow_store.volume_size)\n    self._extents.append(volume_extent)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _Close(self):\n    self._cpio_archive_file_entry = None\n    self._cpio_archive_file = None\n\n    self._file_system.Close()\n    self._file_system = None", "response": "Closes the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _Open(self, path_spec=None, mode='rb'):\n    if not path_spec:\n      raise ValueError('Missing path specification.')\n\n    file_system = resolver.Resolver.OpenFileSystem(\n        path_spec, resolver_context=self._resolver_context)\n\n    file_entry = file_system.GetFileEntryByPathSpec(path_spec)\n    if not file_entry:\n      file_system.Close()\n      raise IOError('Unable to retrieve file entry.')\n\n    self._file_system = file_system\n    self._cpio_archive_file = self._file_system.GetCPIOArchiveFile()\n    self._cpio_archive_file_entry = file_entry.GetCPIOArchiveFileEntry()\n\n    self._current_offset = 0", "response": "Opens the file - like object defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read(self, size=None):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._current_offset >= self._cpio_archive_file_entry.data_size:\n      return b''\n\n    file_offset = (\n        self._cpio_archive_file_entry.data_offset + self._current_offset)\n\n    read_size = self._cpio_archive_file_entry.data_size - self._current_offset\n    if read_size > size:\n      read_size = size\n\n    data = self._cpio_archive_file.ReadDataAtOffset(file_offset, read_size)\n\n    # It is possible the that returned data size is not the same as the\n    # requested data size. At this layer we don't care and this discrepancy\n    # should be dealt with on a higher layer if necessary.\n    self._current_offset += len(data)\n\n    return data", "response": "Reads a byte string from the file - like object at the current offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nseeks to an offset within the file - like object.", "response": "def seek(self, offset, whence=os.SEEK_SET):\n    \"\"\"Seeks to an offset within the file-like object.\n\n    Args:\n      offset (int): offset to seek to.\n      whence (Optional(int)): value that indicates whether offset is an absolute\n          or relative position within the file.\n\n    Raises:\n      IOError: if the seek failed.\n      OSError: if the seek failed.\n    \"\"\"\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if whence == os.SEEK_CUR:\n      offset += self._current_offset\n    elif whence == os.SEEK_END:\n      offset += self._cpio_archive_file_entry.data_size\n    elif whence != os.SEEK_SET:\n      raise IOError('Unsupported whence.')\n\n    if offset < 0:\n      raise IOError('Invalid offset value less than zero.')\n\n    self._current_offset = offset"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclose the file system.", "response": "def _Close(self):\n    \"\"\"Closes the file system.\n\n    Raises:\n      IOError: if the close failed.\n    \"\"\"\n    self._bde_volume.close()\n    self._bde_volume = None\n\n    self._file_object.close()\n    self._file_object = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _Open(self, path_spec, mode='rb'):\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    resolver.Resolver.key_chain.ExtractCredentialsFromPathSpec(path_spec)\n\n    bde_volume = pybde.volume()\n    file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n\n    try:\n      bde.BDEVolumeOpen(\n          bde_volume, path_spec, file_object, resolver.Resolver.key_chain)\n    except:\n      file_object.close()\n      raise\n\n    self._bde_volume = bde_volume\n    self._file_object = file_object", "response": "Opens the file system defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetFileEntryByPathSpec(self, path_spec):\n    return bde_file_entry.BDEFileEntry(\n        self._resolver_context, self, path_spec, is_root=True, is_virtual=True)", "response": "Retrieves a file entry for a path specification."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the root file entry.", "response": "def GetRootFileEntry(self):\n    \"\"\"Retrieves the root file entry.\n\n    Returns:\n      BDEFileEntry: file entry or None.\n    \"\"\"\n    path_spec = bde_path_spec.BDEPathSpec(parent=self._path_spec.parent)\n    return self.GetFileEntryByPathSpec(path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _Open(self, path_spec, mode='rb'):\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    if path_spec.parent.type_indicator != (\n        definitions.TYPE_INDICATOR_APFS_CONTAINER):\n      raise errors.PathSpecError(\n          'Unsupported path specification not type APFS container.')\n\n    apfs_container_file_system = resolver.Resolver.OpenFileSystem(\n        path_spec.parent, resolver_context=self._resolver_context)\n\n    fsapfs_volume = apfs_container_file_system.GetAPFSVolumeByPathSpec(\n        path_spec.parent)\n    if not fsapfs_volume:\n      raise IOError('Unable to retrieve APFS volume')\n\n    try:\n      is_locked = not apfs_helper.APFSUnlockVolume(\n          fsapfs_volume, path_spec.parent, resolver.Resolver.key_chain)\n    except IOError as exception:\n      raise IOError('Unable to unlock APFS volume with error: {0!s}'.format(\n          exception))\n\n    if is_locked:\n      raise IOError('Unable to unlock APFS volume.')\n\n    self._fsapfs_volume = fsapfs_volume", "response": "Opens the file system defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef FileEntryExistsByPathSpec(self, path_spec):\n    # Opening a file by identifier is faster than opening a file by location.\n    fsapfs_file_entry = None\n    location = getattr(path_spec, 'location', None)\n    identifier = getattr(path_spec, 'identifier', None)\n\n    try:\n      if identifier is not None:\n        fsapfs_file_entry = self._fsapfs_volume.get_file_entry_by_identifier(\n            identifier)\n      elif location is not None:\n        fsapfs_file_entry = self._fsapfs_volume.get_file_entry_by_path(location)\n\n    except IOError as exception:\n      raise errors.BackEndError(exception)\n\n    return fsapfs_file_entry is not None", "response": "Determines if a file entry for a path specification exists."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving a file entry for a path specification.", "response": "def GetFileEntryByPathSpec(self, path_spec):\n    \"\"\"Retrieves a file entry for a path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n\n    Returns:\n      APFSFileEntry: file entry or None if not available.\n\n    Raises:\n      BackEndError: if the file entry cannot be opened.\n    \"\"\"\n    # Opening a file by identifier is faster than opening a file by location.\n    fsapfs_file_entry = None\n    location = getattr(path_spec, 'location', None)\n    identifier = getattr(path_spec, 'identifier', None)\n\n    if (location == self.LOCATION_ROOT or\n        identifier == self.ROOT_DIRECTORY_IDENTIFIER):\n      fsapfs_file_entry = self._fsapfs_volume.get_root_directory()\n      return apfs_file_entry.APFSFileEntry(\n          self._resolver_context, self, path_spec,\n          fsapfs_file_entry=fsapfs_file_entry, is_root=True)\n\n    try:\n      if identifier is not None:\n        fsapfs_file_entry = self._fsapfs_volume.get_file_entry_by_identifier(\n            identifier)\n      elif location is not None:\n        fsapfs_file_entry = self._fsapfs_volume.get_file_entry_by_path(location)\n\n    except IOError as exception:\n      raise errors.BackEndError(exception)\n\n    if fsapfs_file_entry is None:\n      return None\n\n    return apfs_file_entry.APFSFileEntry(\n        self._resolver_context, self, path_spec,\n        fsapfs_file_entry=fsapfs_file_entry)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetAPFSFileEntryByPathSpec(self, path_spec):\n    # Opening a file by identifier is faster than opening a file by location.\n    location = getattr(path_spec, 'location', None)\n    identifier = getattr(path_spec, 'identifier', None)\n\n    if identifier is not None:\n      fsapfs_file_entry = self._fsapfs_volume.get_file_entry_by_identifier(\n          identifier)\n    elif location is not None:\n      fsapfs_file_entry = self._fsapfs_volume.get_file_entry_by_path(location)\n    else:\n      raise errors.PathSpecError(\n          'Path specification missing location and identifier.')\n\n    return fsapfs_file_entry", "response": "Retrieves the APFS file entry for a path specification."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetRootFileEntry(self):\n    path_spec = apfs_path_spec.APFSPathSpec(\n        location=self.LOCATION_ROOT, identifier=self.ROOT_DIRECTORY_IDENTIFIER,\n        parent=self._path_spec.parent)\n    return self.GetFileEntryByPathSpec(path_spec)", "response": "Retrieves the root file entry."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _Open(self, path_spec=None, mode='rb'):\n    if not path_spec:\n      raise ValueError('Missing path specification.')\n\n    data_stream = getattr(path_spec, 'data_stream', None)\n    if data_stream:\n      raise errors.NotSupported(\n          'Open data stream: {0:s} not supported.'.format(data_stream))\n\n    self._file_system = resolver.Resolver.OpenFileSystem(\n        path_spec, resolver_context=self._resolver_context)\n\n    file_entry = self._file_system.GetFileEntryByPathSpec(path_spec)\n    if not file_entry:\n      raise IOError('Unable to open file entry.')\n\n    fsapfs_file_entry = file_entry.GetAPFSFileEntry()\n    if not fsapfs_file_entry:\n      raise IOError('Unable to open APFS file entry.')\n\n    self._fsapfs_file_entry = fsapfs_file_entry", "response": "Opens the file - like object defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a byte string from the file - like object at the current offset.", "response": "def read(self, size=None):\n    \"\"\"Reads a byte string from the file-like object at the current offset.\n\n    The function will read a byte string of the specified size or\n    all of the remaining data if no size was specified.\n\n    Args:\n      size (Optional[int]): number of bytes to read, where None is all\n          remaining data.\n\n    Returns:\n      bytes: data read.\n\n    Raises:\n      IOError: if the read failed.\n      OSError: if the read failed.\n    \"\"\"\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    return self._fsapfs_file_entry.read(size=size)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve directory entries. Since a directory can contain a vast number of entries using a generator is more memory efficient. Yields: VShadowPathSpec: a path specification.", "response": "def _EntriesGenerator(self):\n    \"\"\"Retrieves directory entries.\n\n    Since a directory can contain a vast number of entries using\n    a generator is more memory efficient.\n\n    Yields:\n      VShadowPathSpec: a path specification.\n    \"\"\"\n    location = getattr(self.path_spec, 'location', None)\n    store_index = getattr(self.path_spec, 'store_index', None)\n\n    # Only the virtual root file has directory entries.\n    if (store_index is None and location is not None and\n        location == self._file_system.LOCATION_ROOT):\n      vshadow_volume = self._file_system.GetVShadowVolume()\n\n      for store_index in range(0, vshadow_volume.number_of_stores):\n        yield vshadow_path_spec.VShadowPathSpec(\n            location='/vss{0:d}'.format(store_index + 1),\n            store_index=store_index, parent=self.path_spec.parent)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _GetDirectory(self):\n    if self.entry_type != definitions.FILE_ENTRY_TYPE_DIRECTORY:\n      return None\n    return VShadowDirectory(self._file_system, self.path_spec)", "response": "Retrieves a directory from the file system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving information about the file entry.", "response": "def _GetStat(self):\n    \"\"\"Retrieves information about the file entry.\n\n    Returns:\n      VFSStat: a stat object.\n    \"\"\"\n    stat_object = super(VShadowFileEntry, self)._GetStat()\n\n    if self._vshadow_store is not None:\n      # File data stat information.\n      stat_object.size = self._vshadow_store.volume_size\n\n    # Ownership and permissions stat information.\n\n    # File entry type stat information.\n\n    # The root file entry is virtual and should have type directory.\n    return stat_object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef creation_time(self):\n    if self._vshadow_store is None:\n      return None\n\n    timestamp = self._vshadow_store.get_creation_time_as_integer()\n    return dfdatetime_filetime.Filetime(timestamp=timestamp)", "response": "Returns the creation time of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetParentFileEntry(self):\n    store_index = vshadow.VShadowPathSpecGetStoreIndex(self.path_spec)\n    if store_index is None:\n      return None\n\n    return self._file_system.GetRootFileEntry()", "response": "Retrieves the parent file entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef DeregisterPathSpec(cls, path_spec_type):\n    type_indicator = path_spec_type.TYPE_INDICATOR\n    if type_indicator not in cls._path_spec_types:\n      raise KeyError(\n          'Path specification type: {0:s} not set.'.format(type_indicator))\n\n    del cls._path_spec_types[type_indicator]\n\n    if type_indicator in cls._system_level_type_indicators:\n      del cls._system_level_type_indicators[type_indicator]", "response": "Deregisters a path specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves the properties of the path specification.", "response": "def GetProperties(cls, path_spec):\n    \"\"\"Retrieves a dictionary containing the path specification properties.\n\n    Args:\n      path_spec (PathSpec): path specification.\n\n    Returns:\n      dict[str, str]: path specification properties.\n\n    Raises:\n      dict: path specification properties.\n    \"\"\"\n    properties = {}\n\n    for property_name in cls.PROPERTY_NAMES:\n      # Note that we do not want to set the properties when not used.\n      if hasattr(path_spec, property_name):\n        properties[property_name] = getattr(path_spec, property_name)\n\n    return properties"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new path specification for the specific type indicator.", "response": "def NewPathSpec(cls, type_indicator, **kwargs):\n    \"\"\"Creates a new path specification for the specific type indicator.\n\n    Args:\n      type_indicator (str): type indicator.\n      kwargs (dict): keyword arguments depending on the path specification.\n\n    Returns:\n      PathSpec: path specification.\n\n    Raises:\n      KeyError: if path specification is not registered.\n    \"\"\"\n    if type_indicator not in cls._path_spec_types:\n      raise KeyError(\n          'Path specification type: {0:s} not set.'.format(type_indicator))\n\n    # An empty parent will cause parentless path specifications to raise\n    # so we conveniently remove it here.\n    if 'parent' in kwargs and kwargs['parent'] is None:\n      del kwargs['parent']\n\n    path_spec_type = cls._path_spec_types[type_indicator]\n    return path_spec_type(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregister a path specification type.", "response": "def RegisterPathSpec(cls, path_spec_type):\n    \"\"\"Registers a path specification type.\n\n    Args:\n      path_spec_type (type): path specification type.\n\n    Raises:\n      KeyError: if path specification is already registered.\n    \"\"\"\n    type_indicator = path_spec_type.TYPE_INDICATOR\n    if type_indicator in cls._path_spec_types:\n      raise KeyError(\n          'Path specification type: {0:s} already set.'.format(\n              type_indicator))\n\n    cls._path_spec_types[type_indicator] = path_spec_type\n\n    if getattr(path_spec_type, '_IS_SYSTEM_LEVEL', False):\n      cls._system_level_type_indicators[type_indicator] = path_spec_type"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a string from the file - like object.", "response": "def _ReadString(\n      self, file_object, file_offset, data_type_map, description):\n    \"\"\"Reads a string.\n\n    Args:\n      file_object (FileIO): file-like object.\n      file_offset (int): offset of the data relative from the start of\n          the file-like object.\n      data_type_map (dtfabric.DataTypeMap): data type map of the string.\n      description (str): description of the string.\n\n    Returns:\n      object: structure values object.\n\n    Raises:\n      FileFormatError: if the string cannot be read.\n      ValueError: if file-like object or date type map are invalid.\n    \"\"\"\n    # pylint: disable=protected-access\n    element_data_size = (\n        data_type_map._element_data_type_definition.GetByteSize())\n    elements_terminator = (\n        data_type_map._data_type_definition.elements_terminator)\n\n    byte_stream = []\n\n    element_data = file_object.read(element_data_size)\n    byte_stream.append(element_data)\n    while element_data and element_data != elements_terminator:\n      element_data = file_object.read(element_data_size)\n      byte_stream.append(element_data)\n\n    byte_stream = b''.join(byte_stream)\n\n    return self._ReadStructureFromByteStream(\n        byte_stream, file_offset, data_type_map, description)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading a structure from a file - like object.", "response": "def _ReadStructure(\n      self, file_object, file_offset, data_size, data_type_map, description):\n    \"\"\"Reads a structure.\n\n    Args:\n      file_object (FileIO): file-like object.\n      file_offset (int): offset of the data relative from the start of\n          the file-like object.\n      data_size (int): data size of the structure.\n      data_type_map (dtfabric.DataTypeMap): data type map of the structure.\n      description (str): description of the structure.\n\n    Returns:\n      object: structure values object.\n\n    Raises:\n      FileFormatError: if the structure cannot be read.\n      ValueError: if file-like object or date type map are invalid.\n    \"\"\"\n    data = self._ReadData(file_object, file_offset, data_size, description)\n\n    return self._ReadStructureFromByteStream(\n        data, file_offset, data_type_map, description)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a structure from a byte stream.", "response": "def _ReadStructureFromByteStream(\n      self, byte_stream, file_offset, data_type_map, description, context=None):\n    \"\"\"Reads a structure from a byte stream.\n\n    Args:\n      byte_stream (bytes): byte stream.\n      file_offset (int): offset of the data relative from the start of\n          the file-like object.\n      data_type_map (dtfabric.DataTypeMap): data type map of the structure.\n      description (str): description of the structure.\n      context (Optional[dtfabric.DataTypeMapContext]): data type map context.\n\n    Returns:\n      object: structure values object.\n\n    Raises:\n      FileFormatError: if the structure cannot be read.\n      ValueError: if file-like object or date type map are invalid.\n    \"\"\"\n    if not byte_stream:\n      raise ValueError('Invalid byte stream.')\n\n    if not data_type_map:\n      raise ValueError('Invalid data type map.')\n\n    try:\n      return data_type_map.MapByteStream(byte_stream, context=context)\n    except dtfabric_errors.MappingError as exception:\n      raise errors.FileFormatError((\n          'Unable to map {0:s} data at offset: 0x{1:08x} with error: '\n          '{2!s}').format(description, file_offset, exception))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _Close(self):\n    self._fvde_volume.close()\n    self._fvde_volume = None\n\n    self._file_object.close()\n    self._file_object = None", "response": "Closes the file system."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nopens the file system defined by path specification.", "response": "def _Open(self, path_spec, mode='rb'):\n    \"\"\"Opens the file system defined by path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n      mode (Optional[str]): file access mode. The default is 'rb'\n          read-only binary.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file system could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    resolver.Resolver.key_chain.ExtractCredentialsFromPathSpec(path_spec)\n\n    fvde_volume = pyfvde.volume()\n    file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n\n    try:\n      fvde.FVDEVolumeOpen(\n          fvde_volume, path_spec, file_object, resolver.Resolver.key_chain)\n    except:\n      file_object.close()\n      raise\n\n    self._fvde_volume = fvde_volume\n    self._file_object = file_object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve a file entry for a path specification.", "response": "def GetFileEntryByPathSpec(self, path_spec):\n    \"\"\"Retrieves a file entry for a path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n\n    Returns:\n      FVDEFileEntry: file entry or None.\n    \"\"\"\n    return fvde_file_entry.FVDEFileEntry(\n        self._resolver_context, self, path_spec, is_root=True, is_virtual=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetRootFileEntry(self):\n    path_spec = fvde_path_spec.FVDEPathSpec(parent=self._path_spec.parent)\n    return self.GetFileEntryByPathSpec(path_spec)", "response": "Retrieves the root file entry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Decompress(self, compressed_data):\n    try:\n      if hasattr(lzma, 'LZMA_VERSION'):\n        # Note that we cannot use max_length=0 here due to different\n        # versions of the lzma code.\n        uncompressed_data = self._lzma_decompressor.decompress(\n            compressed_data, 0)\n      else:\n        uncompressed_data = self._lzma_decompressor.decompress(compressed_data)\n\n      remaining_compressed_data = getattr(\n          self._lzma_decompressor, 'unused_data', b'')\n\n    except (EOFError, IOError, LZMAError) as exception:\n      raise errors.BackEndError((\n          'Unable to decompress XZ compressed stream with error: '\n          '{0!s}.').format(exception))\n\n    return uncompressed_data, remaining_compressed_data", "response": "Decompresses the compressed data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef comparable(self):\n    string_parts = []\n\n    if self.cipher_mode:\n      string_parts.append('cipher_mode: {0:s}'.format(self.cipher_mode))\n\n    if self.encryption_method:\n      string_parts.append('encryption_method: {0:s}'.format(\n          self.encryption_method))\n\n    if self.initialization_vector:\n      initialization_vector = codecs.encode(self.initialization_vector, 'hex')\n      initialization_vector = initialization_vector.decode('ascii')\n      string_parts.append('initialization_vector: {0:s}'.format(\n          initialization_vector))\n\n    if self.key:\n      key = codecs.encode(self.key, 'hex')\n      key = key.decode('ascii')\n      string_parts.append('key: {0:s}'.format(key))\n\n    return self._GetComparable(sub_comparable_string=', '.join(string_parts))", "response": "str : comparable representation of the path specification."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(self, offset, size):\n    self._file_object.seek(offset, os.SEEK_SET)\n    return self._file_object.read(size)", "response": "Reads a byte string from the image object at the specified offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _GetNormalizedTimestamp(self):\n    if self._normalized_timestamp is None:\n      if self._timestamp is not None:\n        self._normalized_timestamp = decimal.Decimal(self._timestamp)\n\n        if self.fraction_of_second is not None:\n          fraction_of_second = decimal.Decimal(self.fraction_of_second)\n\n          if self._precision == dfdatetime_definitions.PRECISION_1_NANOSECOND:\n            fraction_of_second /= self._NANOSECONDS_PER_SECOND\n          else:\n            fraction_of_second /= self._100_NANOSECONDS_PER_SECOND\n\n          self._normalized_timestamp += fraction_of_second\n\n    return self._normalized_timestamp", "response": "Retrieves the normalized timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef CopyFromDateTimeString(self, time_string):\n    date_time_values = self._CopyDateTimeFromString(time_string)\n\n    year = date_time_values.get('year', 0)\n    month = date_time_values.get('month', 0)\n    day_of_month = date_time_values.get('day_of_month', 0)\n    hours = date_time_values.get('hours', 0)\n    minutes = date_time_values.get('minutes', 0)\n    seconds = date_time_values.get('seconds', 0)\n    microseconds = date_time_values.get('microseconds', 0)\n\n    self._timestamp = self._GetNumberOfSecondsFromElements(\n        year, month, day_of_month, hours, minutes, seconds)\n    self.fraction_of_second = microseconds\n\n    if pytsk3.TSK_VERSION_NUM >= 0x040200ff:\n      self.fraction_of_second *= 1000\n    else:\n      self.fraction_of_second *= 10\n\n    self._normalized_timestamp = None\n    self.is_local_time = False", "response": "Copies a SleuthKit timestamp from a date and time string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncopying the date time value to a date and time string.", "response": "def CopyToDateTimeString(self):\n    \"\"\"Copies the date time value to a date and time string.\n\n    Returns:\n      str: date and time value formatted as:\n          YYYY-MM-DD hh:mm:ss or\n          YYYY-MM-DD hh:mm:ss.####### or\n          YYYY-MM-DD hh:mm:ss.#########\n    \"\"\"\n    if self._timestamp is None:\n      return None\n\n    number_of_days, hours, minutes, seconds = self._GetTimeValues(\n        self._timestamp)\n\n    year, month, day_of_month = self._GetDateValues(number_of_days, 1970, 1, 1)\n\n    if self.fraction_of_second is None:\n      return '{0:04d}-{1:02d}-{2:02d} {3:02d}:{4:02d}:{5:02d}'.format(\n          year, month, day_of_month, hours, minutes, seconds)\n\n    if pytsk3.TSK_VERSION_NUM >= 0x040200ff:\n      return '{0:04d}-{1:02d}-{2:02d} {3:02d}:{4:02d}:{5:02d}.{6:09d}'.format(\n          year, month, day_of_month, hours, minutes, seconds,\n          self.fraction_of_second)\n\n    return '{0:04d}-{1:02d}-{2:02d} {3:02d}:{4:02d}:{5:02d}.{6:07d}'.format(\n        year, month, day_of_month, hours, minutes, seconds,\n        self.fraction_of_second)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncopying the SleuthKit timestamp to a stat timestamp tuple.", "response": "def CopyToStatTimeTuple(self):\n    \"\"\"Copies the SleuthKit timestamp to a stat timestamp tuple.\n\n    Returns:\n      tuple[int, int]: a POSIX timestamp in seconds and the remainder in\n          100 nano seconds or (None, None) on error.\n    \"\"\"\n    if self.fraction_of_second is None:\n      return self._timestamp, None\n\n    return super(TSKTime, self).CopyToStatTimeTuple()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the date represented by the date and time values.", "response": "def GetDate(self):\n    \"\"\"Retrieves the date represented by the date and time values.\n\n    Returns:\n       tuple[int, int, int]: year, month, day of month or (None, None, None)\n           if the date and time values do not represent a date.\n    \"\"\"\n    if self._timestamp is None:\n      return None, None, None\n\n    try:\n      number_of_days, _, _, _ = self._GetTimeValues(self._timestamp)\n      return self._GetDateValues(number_of_days, 1970, 1, 1)\n    except ValueError:\n      return None, None, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef IsDefault(self):\n    if not self._tsk_attribute or not self._file_system:\n      return True\n\n    if self._file_system.IsHFS():\n      attribute_type = getattr(self._tsk_attribute.info, 'type', None)\n      return attribute_type in (\n          pytsk3.TSK_FS_ATTR_TYPE_HFS_DEFAULT, pytsk3.TSK_FS_ATTR_TYPE_HFS_DATA)\n\n    if self._file_system.IsNTFS():\n      return not bool(self.name)\n\n    return True", "response": "Determines if the data stream is the default data stream."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _EntriesGenerator(self):\n    # Opening a file by inode number is faster than opening a file\n    # by location.\n    inode = getattr(self.path_spec, 'inode', None)\n    location = getattr(self.path_spec, 'location', None)\n\n    fs_info = self._file_system.GetFsInfo()\n    tsk_directory = None\n\n    try:\n      if inode is not None:\n        tsk_directory = fs_info.open_dir(inode=inode)\n      elif location is not None:\n        tsk_directory = fs_info.open_dir(path=location)\n\n    except IOError as exception:\n      raise errors.BackEndError(\n          'Unable to open directory with error: {0!s}'.format(exception))\n\n    if tsk_directory:\n      for tsk_directory_entry in tsk_directory:\n        # Note that because pytsk3.Directory does not explicitly define info\n        # we need to check if the attribute exists and has a value other\n        # than None.\n        if getattr(tsk_directory_entry, 'info', None) is None:\n          continue\n\n        # Note that because pytsk3.TSK_FS_FILE does not explicitly define\n        # fs_info we need to check if the attribute exists and has a value\n        # other than None.\n        if getattr(tsk_directory_entry.info, 'fs_info', None) is None:\n          continue\n\n        # Note that because pytsk3.TSK_FS_FILE does not explicitly define meta\n        # we need to check if the attribute exists and has a value other\n        # than None.\n        if getattr(tsk_directory_entry.info, 'meta', None) is None:\n          # Most directory entries will have an \"inode\" but not all, e.g.\n          # previously deleted files. Currently directory entries without\n          # a pytsk3.TSK_FS_META object are ignored.\n          continue\n\n        # Note that because pytsk3.TSK_FS_META does not explicitly define addr\n        # we need to check if the attribute exists.\n        if not hasattr(tsk_directory_entry.info.meta, 'addr'):\n          continue\n\n        directory_entry_inode = tsk_directory_entry.info.meta.addr\n        directory_entry = None\n\n        # Ignore references to self.\n        if directory_entry_inode == inode:\n          continue\n\n        # On non-NTFS file systems ignore inode 0.\n        if directory_entry_inode == 0 and not self._file_system.IsNTFS():\n          continue\n\n        # Note that because pytsk3.TSK_FS_FILE does not explicitly define name\n        # we need to check if the attribute exists and has a value other\n        # than None.\n        if getattr(tsk_directory_entry.info, 'name', None) is not None:\n          # Ignore file entries marked as \"unallocated\".\n          flags = getattr(tsk_directory_entry.info.name, 'flags', 0)\n          if int(flags) & pytsk3.TSK_FS_NAME_FLAG_UNALLOC:\n            continue\n\n          directory_entry = getattr(tsk_directory_entry.info.name, 'name', '')\n\n          try:\n            # pytsk3 returns an UTF-8 encoded byte string.\n            directory_entry = directory_entry.decode('utf8')\n          except UnicodeError:\n            # Continue here since we cannot represent the directory entry.\n            continue\n\n          if directory_entry:\n            # Ignore references to self or parent.\n            if directory_entry in ['.', '..']:\n              continue\n\n            if location == self._file_system.PATH_SEPARATOR:\n              directory_entry = self._file_system.JoinPath([directory_entry])\n            else:\n              directory_entry = self._file_system.JoinPath([\n                  location, directory_entry])\n\n        yield tsk_path_spec.TSKPathSpec(\n            inode=directory_entry_inode, location=directory_entry,\n            parent=self.path_spec.parent)", "response": "Retrieves the directory entries using the specified path specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _GetAttributes(self):\n    if self._attributes is None:\n      self._attributes = []\n\n      for tsk_attribute in self._tsk_file:\n        if getattr(tsk_attribute, 'info', None) is None:\n          continue\n\n        # At the moment there is no way to expose the attribute data\n        # from pytsk3.\n        attribute_object = TSKAttribute(tsk_attribute)\n        self._attributes.append(attribute_object)\n\n    return self._attributes", "response": "Retrieves the attributes.\n\n    Returns:\n      list[TSKAttribute]: attributes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _GetDataStreams(self):\n    if self._data_streams is None:\n      if self._file_system.IsHFS():\n        known_data_attribute_types = [\n            pytsk3.TSK_FS_ATTR_TYPE_HFS_DEFAULT,\n            pytsk3.TSK_FS_ATTR_TYPE_HFS_DATA]\n\n      elif self._file_system.IsNTFS():\n        known_data_attribute_types = [pytsk3.TSK_FS_ATTR_TYPE_NTFS_DATA]\n\n      else:\n        known_data_attribute_types = None\n\n      self._data_streams = []\n\n      tsk_fs_meta_type = getattr(\n          self._tsk_file.info.meta, 'type', pytsk3.TSK_FS_META_TYPE_UNDEF)\n\n      if not known_data_attribute_types:\n        if tsk_fs_meta_type == pytsk3.TSK_FS_META_TYPE_REG:\n          data_stream = TSKDataStream(self._file_system, None)\n          self._data_streams.append(data_stream)\n\n      else:\n        for tsk_attribute in self._tsk_file:\n          # NTFS allows directories to have data streams.\n          if (not self._file_system.IsNTFS() and\n              tsk_fs_meta_type != pytsk3.TSK_FS_META_TYPE_REG):\n            continue\n\n          if getattr(tsk_attribute, 'info', None) is None:\n            continue\n\n          attribute_type = getattr(tsk_attribute.info, 'type', None)\n          if attribute_type in known_data_attribute_types:\n            data_stream = TSKDataStream(self._file_system, tsk_attribute)\n            self._data_streams.append(data_stream)\n\n    return self._data_streams", "response": "Retrieves the data streams."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _GetDirectory(self):\n    if self.entry_type != definitions.FILE_ENTRY_TYPE_DIRECTORY:\n      return None\n    return TSKDirectory(self._file_system, self.path_spec)", "response": "Retrieves a directory object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _GetLink(self):\n    if self._link is None:\n      self._link = ''\n\n      if self.entry_type != definitions.FILE_ENTRY_TYPE_LINK:\n        return self._link\n\n      # Note that the SleuthKit does not expose NTFS\n      # IO_REPARSE_TAG_MOUNT_POINT or IO_REPARSE_TAG_SYMLINK as a link.\n      link = getattr(self._tsk_file.info.meta, 'link', None)\n\n      if link is None:\n        return self._link\n\n      try:\n        # pytsk3 returns an UTF-8 encoded byte string without a leading\n        # path segment separator.\n        link = '{0:s}{1:s}'.format(\n            self._file_system.PATH_SEPARATOR, link.decode('utf8'))\n      except UnicodeError:\n        raise errors.BackEndError(\n            'pytsk3 returned a non UTF-8 formatted link.')\n\n      self._link = link\n\n    return self._link", "response": "Retrieves the link.\n\n    Returns:\n      str: path of the linked file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves the stat object.", "response": "def _GetStat(self):\n    \"\"\"Retrieves the stat object.\n\n    Returns:\n      VFSStat: stat object.\n    \"\"\"\n    stat_object = super(TSKFileEntry, self)._GetStat()\n\n    # File data stat information.\n    stat_object.size = getattr(self._tsk_file.info.meta, 'size', None)\n\n    # Date and time stat information.\n    stat_time, stat_time_nano = self._TSKFileTimeCopyToStatTimeTuple(\n        self._tsk_file, 'bkup')\n    if stat_time is not None:\n      stat_object.bkup = stat_time\n      stat_object.bkup_nano = stat_time_nano\n\n    stat_time, stat_time_nano = self._TSKFileTimeCopyToStatTimeTuple(\n        self._tsk_file, 'dtime')\n    if stat_time is not None:\n      stat_object.dtime = stat_time\n      stat_object.dtime_nano = stat_time_nano\n\n    # Ownership and permissions stat information.\n    mode = getattr(self._tsk_file.info.meta, 'mode', None)\n    if mode is not None:\n      # We need to cast mode to an int since it is of type\n      # pytsk3.TSK_FS_META_MODE_ENUM.\n      stat_object.mode = int(mode)\n\n    stat_object.uid = getattr(self._tsk_file.info.meta, 'uid', None)\n    stat_object.gid = getattr(self._tsk_file.info.meta, 'gid', None)\n\n    # File entry type stat information.\n\n    # Other stat information.\n    stat_object.ino = getattr(self._tsk_file.info.meta, 'addr', None)\n    # stat_object.dev = stat_info.st_dev\n    # stat_object.nlink = getattr(self._tsk_file.info.meta, 'nlink', None)\n    # stat_object.fs_type = 'Unknown'\n\n    flags = getattr(self._tsk_file.info.meta, 'flags', 0)\n\n    # The flags are an instance of pytsk3.TSK_FS_META_FLAG_ENUM.\n    stat_object.is_allocated = bool(int(flags) & pytsk3.TSK_FS_META_FLAG_ALLOC)\n\n    return stat_object"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves the sub file entries.", "response": "def _GetSubFileEntries(self):\n    \"\"\"Retrieves sub file entries.\n\n    Yields:\n      TSKFileEntry: a sub file entry.\n    \"\"\"\n    if self._directory is None:\n      self._directory = self._GetDirectory()\n\n    if self._directory:\n      for path_spec in self._directory.entries:\n        yield TSKFileEntry(self._resolver_context, self._file_system, path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _GetTimeValue(self, name):\n    timestamp = getattr(self._tsk_file.info.meta, name, None)\n\n    if self._file_system_type in self._TSK_HAS_NANO_FS_TYPES:\n      name_fragment = '{0:s}_nano'.format(name)\n      fraction_of_second = getattr(\n          self._tsk_file.info.meta, name_fragment, None)\n    else:\n      fraction_of_second = None\n\n    return TSKTime(timestamp=timestamp, fraction_of_second=fraction_of_second)", "response": "Retrieves a date and time value from the specified meta data object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _TSKFileTimeCopyToStatTimeTuple(self, tsk_file, time_value):\n    if (not tsk_file or not tsk_file.info or not tsk_file.info.meta or\n        not tsk_file.info.fs_info):\n      raise errors.BackEndError(\n          'Missing TSK File .info, .info.meta. or .info.fs_info')\n\n    stat_time = getattr(tsk_file.info.meta, time_value, None)\n    stat_time_nano = None\n    if self._file_system_type in self._TSK_HAS_NANO_FS_TYPES:\n      time_value_nano = '{0:s}_nano'.format(time_value)\n      stat_time_nano = getattr(tsk_file.info.meta, time_value_nano, None)\n\n    # Sleuthkit 4.2.0 switched from 100 nano seconds precision to\n    # 1 nano seconds precision.\n    if stat_time_nano is not None and pytsk3.TSK_VERSION_NUM >= 0x040200ff:\n      stat_time_nano /= 100\n\n    return stat_time, stat_time_nano", "response": "Copies a SleuthKit file object time value to a stat timestamp tuple."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef name(self):\n    if self._name is None:\n      # If pytsk3.FS_Info.open() was used file.info has an attribute name\n      # (pytsk3.TSK_FS_FILE) that contains the name string. Otherwise the\n      # name from the path specification is used.\n      if getattr(self._tsk_file.info, 'name', None) is not None:\n        name = getattr(self._tsk_file.info.name, 'name', None)\n\n        try:\n          # pytsk3 returns an UTF-8 encoded byte string.\n          self._name = name.decode('utf8')\n        except UnicodeError:\n          raise errors.BackEndError(\n              'pytsk3 returned a non UTF-8 formatted name.')\n\n      else:\n        location = getattr(self.path_spec, 'location', None)\n        if location:\n          self._name = self._file_system.BasenamePath(location)\n\n    return self._name", "response": "str - name of the file entry which does not include the full path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the file - like object.", "response": "def GetFileObject(self, data_stream_name=''):\n    \"\"\"Retrieves the file-like object.\n\n    Args:\n      data_stream_name (Optional[str]): data stream name, where an empty\n          string represents the default data stream.\n\n    Returns:\n      TSKFileIO: file-like object or None.\n    \"\"\"\n    data_stream_names = [\n        data_stream.name for data_stream in self._GetDataStreams()]\n    if data_stream_name and data_stream_name not in data_stream_names:\n      return None\n\n    path_spec = copy.deepcopy(self.path_spec)\n    if data_stream_name:\n      # For HFS DECOMP fork name is exposed however libtsk 4.6.0 seems to handle\n      # these differently when opened and the correct behavior seems to be\n      # treating this as the default (nameless) fork instead. For context libtsk\n      # 4.5.0 is unable to read the data steam and yields an error.\n      if self._file_system.IsHFS() and data_stream_name == 'DECOMP':\n        data_stream_name = ''\n\n      setattr(path_spec, 'data_stream', data_stream_name)\n\n    return resolver.Resolver.OpenFileObject(\n        path_spec, resolver_context=self._resolver_context)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef GetLinkedFileEntry(self):\n    link = self._GetLink()\n    if not link:\n      return None\n\n    # TODO: is there a way to determine the link inode number here?\n    link_inode = None\n\n    parent_path_spec = getattr(self.path_spec, 'parent', None)\n    path_spec = tsk_path_spec.TSKPathSpec(\n        location=link, parent=parent_path_spec)\n\n    root_inode = self._file_system.GetRootInode()\n    is_root = bool(\n        link == self._file_system.LOCATION_ROOT or (\n            link_inode is not None and root_inode is not None and\n            link_inode == root_inode))\n\n    return TSKFileEntry(\n        self._resolver_context, self._file_system, path_spec, is_root=is_root)", "response": "Retrieves the linked file entry e. g. for a symbolic link."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GetParentFileEntry(self):\n    location = getattr(self.path_spec, 'location', None)\n    if location is None:\n      return None\n    parent_inode = self._parent_inode\n    parent_location = self._file_system.DirnamePath(location)\n    if parent_inode is None and parent_location is None:\n      return None\n\n    if parent_location == '':\n      parent_location = self._file_system.PATH_SEPARATOR\n\n    root_inode = self._file_system.GetRootInode()\n    is_root = bool(\n        parent_location == self._file_system.LOCATION_ROOT or (\n            parent_inode is not None and root_inode is not None and\n            parent_inode == root_inode))\n\n    parent_path_spec = getattr(self.path_spec, 'parent', None)\n    path_spec = tsk_path_spec.TSKPathSpec(\n        inode=parent_inode, location=parent_location, parent=parent_path_spec)\n    return TSKFileEntry(\n        self._resolver_context, self._file_system, path_spec, is_root=is_root)", "response": "Retrieves the parent file entry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef FVDEVolumeOpen(fvde_volume, path_spec, file_object, key_chain):\n  encrypted_root_plist = key_chain.GetCredential(\n      path_spec, 'encrypted_root_plist')\n  if encrypted_root_plist:\n    fvde_volume.read_encrypted_root_plist(encrypted_root_plist)\n\n  password = key_chain.GetCredential(path_spec, 'password')\n  if password:\n    fvde_volume.set_password(password)\n\n  recovery_password = key_chain.GetCredential(path_spec, 'recovery_password')\n  if recovery_password:\n    fvde_volume.set_recovery_password(recovery_password)\n\n  fvde_volume.open_file_object(file_object)", "response": "Opens the FVDE volume using the path specification."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve the store index from the path specification.", "response": "def VShadowPathSpecGetStoreIndex(path_spec):\n  \"\"\"Retrieves the store index from the path specification.\n\n  Args:\n    path_spec (PathSpec): path specification.\n\n  Returns:\n    int: store index or None if not available.\n  \"\"\"\n  store_index = getattr(path_spec, 'store_index', None)\n\n  if store_index is None:\n    location = getattr(path_spec, 'location', None)\n\n    if location is None or not location.startswith('/vss'):\n      return None\n\n    store_index = None\n    try:\n      store_index = int(location[4:], 10) - 1\n    except (TypeError, ValueError):\n      pass\n\n    if store_index is None or store_index < 0:\n      return None\n\n  return store_index"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the gzip file member that contains the provided offset.", "response": "def _GetMemberForOffset(self, offset):\n    \"\"\"Finds the member whose data includes the provided offset.\n\n    Args:\n      offset (int): offset in the uncompressed data to find the\n          containing member for.\n\n    Returns:\n      gzipfile.GzipMember: gzip file member or None if not available.\n\n    Raises:\n      ValueError: if the provided offset is outside of the bounds of the\n          uncompressed data.\n    \"\"\"\n    if offset < 0 or offset >= self.uncompressed_data_size:\n      raise ValueError('Offset {0:d} is larger than file size {1:d}.'.format(\n          offset, self.uncompressed_data_size))\n\n    for end_offset, member in iter(self._members_by_end_offset.items()):\n      if offset < end_offset:\n        return member\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nseeking to an offset within the file - like object.", "response": "def seek(self, offset, whence=os.SEEK_SET):\n    \"\"\"Seeks to an offset within the file-like object.\n\n    Args:\n      offset (int): offset to seek to.\n      whence (Optional(int)): value that indicates whether offset is an absolute\n          or relative position within the file.\n\n    Raises:\n      IOError: if the seek failed or the file has not been opened.\n      OSError: if the seek failed or the file has not been opened.\n    \"\"\"\n    if not self._gzip_file_object:\n      raise IOError('Not opened.')\n\n    if whence == os.SEEK_CUR:\n      offset += self._current_offset\n    elif whence == os.SEEK_END:\n      offset += self.uncompressed_data_size\n    elif whence != os.SEEK_SET:\n      raise IOError('Unsupported whence.')\n\n    if offset < 0:\n      raise IOError('Invalid offset value less than zero.')\n\n    self._current_offset = offset"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(self, size=None):\n    data = b''\n    while ((size and len(data) < size) and\n           self._current_offset < self.uncompressed_data_size):\n      member = self._GetMemberForOffset(self._current_offset)\n      member_offset = self._current_offset - member.uncompressed_data_offset\n      data_read = member.ReadAtOffset(member_offset, size)\n      if data_read:\n        self._current_offset += len(data_read)\n        data = b''.join([data, data_read])\n\n    return data", "response": "Reads a byte string from the gzip file at the current offset."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nopening the file - like object defined by path specification.", "response": "def _Open(self, path_spec=None, mode='rb'):\n    \"\"\"Opens the file-like object defined by path specification.\n\n    Args:\n      path_spec (Optional[PathSpec]): path specification.\n      mode (Optional[str]): file access mode.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file-like object could not be opened.\n      OSError: if the file-like object could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec:\n      raise ValueError('Missing path specification.')\n\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    self._gzip_file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n    file_size = self._gzip_file_object.get_size()\n\n    self._gzip_file_object.seek(0, os.SEEK_SET)\n\n    uncompressed_data_offset = 0\n    next_member_offset = 0\n\n    while next_member_offset < file_size:\n      member = gzipfile.GzipMember(\n          self._gzip_file_object, next_member_offset, uncompressed_data_offset)\n      uncompressed_data_offset = (\n          uncompressed_data_offset + member.uncompressed_data_size)\n      self._members_by_end_offset[uncompressed_data_offset] = member\n      self.uncompressed_data_size += member.uncompressed_data_size\n      next_member_offset = member.member_end_offset"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _GetStat(self):\n    stat_object = vfs_stat.VFSStat()\n\n    # File data stat information.\n    stat_object.size = self.path_spec.range_size\n\n    # File entry type stat information.\n    stat_object.type = stat_object.TYPE_FILE\n\n    return stat_object", "response": "Retrieves a stat object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _GetComparable(self, sub_comparable_string=''):\n    string_parts = []\n\n    string_parts.append(getattr(self.parent, 'comparable', ''))\n    string_parts.append('type: {0:s}'.format(self.type_indicator))\n\n    if sub_comparable_string:\n      string_parts.append(', {0:s}'.format(sub_comparable_string))\n    string_parts.append('\\n')\n\n    return ''.join(string_parts)", "response": "Retrieves the comparable representation of the path specification."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncopy the path specification to a dictionary.", "response": "def CopyToDict(self):\n    \"\"\"Copies the path specification to a dictionary.\n\n    Returns:\n      dict[str, object]: path specification attributes.\n    \"\"\"\n    path_spec_dict = {}\n    for attribute_name, attribute_value in iter(self.__dict__.items()):\n      if attribute_value is None:\n        continue\n\n      if attribute_name == 'parent':\n        attribute_value = attribute_value.CopyToDict()\n\n      path_spec_dict[attribute_name] = attribute_value\n\n    return path_spec_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef DeregisterMountPoint(cls, mount_point):\n    if mount_point not in cls._mount_points:\n      raise KeyError('Mount point: {0:s} not set.'.format(mount_point))\n\n    del cls._mount_points[mount_point]", "response": "Deregisters a path specification mount point."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister a path specification mount point.", "response": "def RegisterMountPoint(cls, mount_point, path_spec):\n    \"\"\"Registers a path specification mount point.\n\n    Args:\n      mount_point (str): mount point identifier.\n      path_spec (PathSpec): path specification of the mount point.\n\n    Raises:\n      KeyError: if the corresponding mount point is already set.\n    \"\"\"\n    if mount_point in cls._mount_points:\n      raise KeyError('Mount point: {0:s} already set.'.format(mount_point))\n\n    cls._mount_points[mount_point] = path_spec"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef DeregisterHelper(cls, resolver_helper):\n    if resolver_helper.type_indicator not in cls._resolver_helpers:\n      raise KeyError(\n          'Resolver helper object not set for type indicator: {0:s}.'.format(\n              resolver_helper.type_indicator))\n\n    del cls._resolver_helpers[resolver_helper.type_indicator]", "response": "Deregisters a path specification resolver helper."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GetHelper(cls, type_indicator):\n    if type_indicator not in cls._resolver_helpers:\n      raise KeyError(\n          'Resolver helper not set for type indicator: {0:s}.'.format(\n              type_indicator))\n\n    return cls._resolver_helpers[type_indicator]", "response": "Retrieves the resolver helper for the specified type indicator."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef RegisterHelper(cls, resolver_helper):\n    if resolver_helper.type_indicator in cls._resolver_helpers:\n      raise KeyError((\n          'Resolver helper object already set for type indicator: '\n          '{0!s}.').format(resolver_helper.type_indicator))\n\n    cls._resolver_helpers[resolver_helper.type_indicator] = resolver_helper", "response": "Registers a path specification resolver helper."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef comparable(self):\n    sub_comparable_string = (\n        'compression_method: {0:s}').format(self.compression_method)\n    return self._GetComparable(sub_comparable_string=sub_comparable_string)", "response": "str - comparable representation of the path specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _Close(self):\n    if not self._file_object_set_in_init:\n      self._file_object.close()\n      self._file_object = None\n      self._range_offset = -1\n      self._range_size = -1", "response": "Closes the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the data range of the file - like object.", "response": "def SetRange(self, range_offset, range_size):\n    \"\"\"Sets the data range (offset and size).\n\n    The data range is used to map a range of data within one file\n    (e.g. a single partition within a full disk image) as a file-like object.\n\n    Args:\n      range_offset (int): start offset of the data range.\n      range_size (int): size of the data range.\n\n    Raises:\n      IOError: if the file-like object is already open.\n      OSError: if the file-like object is already open.\n      ValueError: if the range offset or range size is invalid.\n    \"\"\"\n    if self._is_open:\n      raise IOError('Already open.')\n\n    if range_offset < 0:\n      raise ValueError(\n          'Invalid range offset: {0:d} value out of bounds.'.format(\n              range_offset))\n\n    if range_size < 0:\n      raise ValueError(\n          'Invalid range size: {0:d} value out of bounds.'.format(\n              range_size))\n\n    self._range_offset = range_offset\n    self._range_size = range_size\n    self._current_offset = 0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a byte string from the file - like object at the current offset.", "response": "def read(self, size=None):\n    \"\"\"Reads a byte string from the file-like object at the current offset.\n\n    The function will read a byte string of the specified size or\n    all of the remaining data if no size was specified.\n\n    Args:\n      size (Optional[int]): number of bytes to read, where None is all\n          remaining data.\n\n    Returns:\n      bytes: data read.\n\n    Raises:\n      IOError: if the read failed.\n      OSError: if the read failed.\n    \"\"\"\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._range_offset < 0 or self._range_size < 0:\n      raise IOError('Invalid data range.')\n\n    if self._current_offset < 0:\n      raise IOError(\n          'Invalid current offset: {0:d} value less than zero.'.format(\n              self._current_offset))\n\n    if self._current_offset >= self._range_size:\n      return b''\n\n    if size is None:\n      size = self._range_size\n    if self._current_offset + size > self._range_size:\n      size = self._range_size - self._current_offset\n\n    self._file_object.seek(\n        self._range_offset + self._current_offset, os.SEEK_SET)\n\n    data = self._file_object.read(size)\n\n    self._current_offset += len(data)\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef seek(self, offset, whence=os.SEEK_SET):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._current_offset < 0:\n      raise IOError(\n          'Invalid current offset: {0:d} value less than zero.'.format(\n              self._current_offset))\n\n    if whence == os.SEEK_CUR:\n      offset += self._current_offset\n    elif whence == os.SEEK_END:\n      offset += self._range_size\n    elif whence != os.SEEK_SET:\n      raise IOError('Unsupported whence.')\n    if offset < 0:\n      raise IOError('Invalid offset value less than zero.')\n    self._current_offset = offset", "response": "Seeks to an offset within the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening the file system defined by path specification.", "response": "def _Open(self, path_spec, mode='rb'):\n    \"\"\"Opens the file system defined by path specification.\n\n    Args:\n      path_spec (PathSpec): a path specification.\n      mode (Optional[str]): file access mode. The default is 'rb' which\n          represents read-only binary.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file system could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    compression_method = getattr(path_spec, 'compression_method', None)\n    if not compression_method:\n      raise errors.PathSpecError(\n          'Unsupported path specification without compression method.')\n\n    self._compression_method = compression_method"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve a file entry for a path specification.", "response": "def GetFileEntryByPathSpec(self, path_spec):\n    \"\"\"Retrieves a file entry for a path specification.\n\n    Args:\n      path_spec (PathSpec): a path specification.\n\n    Returns:\n      CompressedStreamFileEntry: a file entry or None if not available.\n    \"\"\"\n    return compressed_stream_file_entry.CompressedStreamFileEntry(\n        self._resolver_context, self, path_spec, is_root=True, is_virtual=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving the root file entry.", "response": "def GetRootFileEntry(self):\n    \"\"\"Retrieves the root file entry.\n\n    Returns:\n      CompressedStreamFileEntry: a file entry or None if not available.\n    \"\"\"\n    path_spec = compressed_stream_path_spec.CompressedStreamPathSpec(\n        compression_method=self._compression_method,\n        parent=self._path_spec.parent)\n    return self.GetFileEntryByPathSpec(path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _GetDataStreams(self):\n    if self._data_streams is None:\n      if self._directory is None:\n        self._directory = self._GetDirectory()\n\n      self._data_streams = []\n\n      # It is assumed that directory and link file entries typically\n      # do not have data streams.\n      if not self._directory and not self.link:\n        data_stream = DataStream()\n        self._data_streams.append(data_stream)\n\n    return self._data_streams", "response": "Retrieves the data streams."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _GetStat(self):\n    stat_object = vfs_stat.VFSStat()\n\n    # Date and time stat information.\n    access_time = self.access_time\n    if access_time:\n      stat_time, stat_time_nano = access_time.CopyToStatTimeTuple()\n      if stat_time is not None:\n        stat_object.atime = stat_time\n      if stat_time_nano is not None:\n        stat_object.atime_nano = stat_time_nano\n\n    change_time = self.change_time\n    if change_time:\n      stat_time, stat_time_nano = change_time.CopyToStatTimeTuple()\n      if stat_time is not None:\n        stat_object.ctime = stat_time\n      if stat_time_nano is not None:\n        stat_object.ctime_nano = stat_time_nano\n\n    creation_time = self.creation_time\n    if creation_time:\n      stat_time, stat_time_nano = creation_time.CopyToStatTimeTuple()\n      if stat_time is not None:\n        stat_object.crtime = stat_time\n      if stat_time_nano is not None:\n        stat_object.crtime_nano = stat_time_nano\n\n    modification_time = self.modification_time\n    if modification_time:\n      stat_time, stat_time_nano = modification_time.CopyToStatTimeTuple()\n      if stat_time is not None:\n        stat_object.mtime = stat_time\n      if stat_time_nano is not None:\n        stat_object.mtime_nano = stat_time_nano\n\n    # File entry type stat information.\n    if self.entry_type:\n      stat_object.type = self.entry_type\n\n    return stat_object", "response": "Retrieves the stat information of the file entry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetDataStream(self, name, case_sensitive=True):\n    if not isinstance(name, py2to3.STRING_TYPES):\n      raise ValueError('Name is not a string.')\n\n    name_lower = name.lower()\n    matching_data_stream = None\n\n    for data_stream in self._GetDataStreams():\n      if data_stream.name == name:\n        return data_stream\n\n      if not case_sensitive and data_stream.name.lower() == name_lower:\n        if not matching_data_stream:\n          matching_data_stream = data_stream\n\n    return matching_data_stream", "response": "Retrieves a data stream by name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef GetFileObject(self, data_stream_name=''):\n    if data_stream_name:\n      return None\n\n    return resolver.Resolver.OpenFileObject(\n        self.path_spec, resolver_context=self._resolver_context)", "response": "Retrieves the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving a sub file entry by name.", "response": "def GetSubFileEntryByName(self, name, case_sensitive=True):\n    \"\"\"Retrieves a sub file entry by name.\n\n    Args:\n      name (str): name of the file entry.\n      case_sensitive (Optional[bool]): True if the name is case sensitive.\n\n    Returns:\n      FileEntry: a file entry or None if not available.\n    \"\"\"\n    name_lower = name.lower()\n    matching_sub_file_entry = None\n\n    for sub_file_entry in self.sub_file_entries:\n      if sub_file_entry.name == name:\n        return sub_file_entry\n\n      if not case_sensitive and sub_file_entry.name.lower() == name_lower:\n        if not matching_sub_file_entry:\n          matching_sub_file_entry = sub_file_entry\n\n    return matching_sub_file_entry"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the VFSStat object associated with this file entry.", "response": "def GetStat(self):\n    \"\"\"Retrieves information about the file entry.\n\n    Returns:\n      VFSStat: a stat object or None if not available.\n    \"\"\"\n    if self._stat_object is None:\n      self._stat_object = self._GetStat()\n    return self._stat_object"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetermines if the file entry has a specific data stream.", "response": "def HasDataStream(self, name, case_sensitive=True):\n    \"\"\"Determines if the file entry has specific data stream.\n\n    Args:\n      name (str): name of the data stream.\n      case_sensitive (Optional[bool]): True if the name is case sensitive.\n\n    Returns:\n      bool: True if the file entry has the data stream.\n\n    Raises:\n      ValueError: if the name is not string.\n    \"\"\"\n    if not isinstance(name, py2to3.STRING_TYPES):\n      raise ValueError('Name is not a string.')\n\n    name_lower = name.lower()\n\n    for data_stream in self._GetDataStreams():\n      if data_stream.name == name:\n        return True\n\n      if not case_sensitive and data_stream.name.lower() == name_lower:\n        return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines if the file entry is allocated.", "response": "def IsAllocated(self):\n    \"\"\"Determines if the file entry is allocated.\n\n    Returns:\n      bool: True if the file entry is allocated.\n    \"\"\"\n    if self._stat_object is None:\n      self._stat_object = self._GetStat()\n    return self._stat_object and self._stat_object.is_allocated"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine if the file entry is a device.", "response": "def IsDevice(self):\n    \"\"\"Determines if the file entry is a device.\n\n    Returns:\n      bool: True if the file entry is a device.\n    \"\"\"\n    if self._stat_object is None:\n      self._stat_object = self._GetStat()\n    if self._stat_object is not None:\n      self.entry_type = self._stat_object.type\n    return self.entry_type == definitions.FILE_ENTRY_TYPE_DEVICE"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef IsDirectory(self):\n    if self._stat_object is None:\n      self._stat_object = self._GetStat()\n    if self._stat_object is not None:\n      self.entry_type = self._stat_object.type\n    return self.entry_type == definitions.FILE_ENTRY_TYPE_DIRECTORY", "response": "Determines if the file entry is a directory."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef IsFile(self):\n    if self._stat_object is None:\n      self._stat_object = self._GetStat()\n    if self._stat_object is not None:\n      self.entry_type = self._stat_object.type\n    return self.entry_type == definitions.FILE_ENTRY_TYPE_FILE", "response": "Determines if the file entry is a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef IsLink(self):\n    if self._stat_object is None:\n      self._stat_object = self._GetStat()\n    if self._stat_object is not None:\n      self.entry_type = self._stat_object.type\n    return self.entry_type == definitions.FILE_ENTRY_TYPE_LINK", "response": "Determines if the file entry is a link."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef IsPipe(self):\n    if self._stat_object is None:\n      self._stat_object = self._GetStat()\n    if self._stat_object is not None:\n      self.entry_type = self._stat_object.type\n    return self.entry_type == definitions.FILE_ENTRY_TYPE_PIPE", "response": "Determines if the file entry is a pipe."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetermining if the file entry is a socket.", "response": "def IsSocket(self):\n    \"\"\"Determines if the file entry is a socket.\n\n    Returns:\n      bool: True if the file entry is a socket.\n    \"\"\"\n    if self._stat_object is None:\n      self._stat_object = self._GetStat()\n    if self._stat_object is not None:\n      self.entry_type = self._stat_object.type\n    return self.entry_type == definitions.FILE_ENTRY_TYPE_SOCKET"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _Parse(self):\n    tsk_vs_part = self._file_entry.GetTSKVsPart()\n\n    tsk_addr = getattr(tsk_vs_part, 'addr', None)\n    if tsk_addr is not None:\n      address = volume_system.VolumeAttribute('address', tsk_addr)\n      self._AddAttribute(address)\n\n    tsk_desc = getattr(tsk_vs_part, 'desc', None)\n    if tsk_desc is not None:\n      # pytsk3 returns an UTF-8 encoded byte string.\n      try:\n        tsk_desc = tsk_desc.decode('utf8')\n        self._AddAttribute(volume_system.VolumeAttribute(\n            'description', tsk_desc))\n      except UnicodeError:\n        pass\n\n    start_sector = tsk_partition.TSKVsPartGetStartSector(tsk_vs_part)\n    number_of_sectors = tsk_partition.TSKVsPartGetNumberOfSectors(tsk_vs_part)\n    volume_extent = volume_system.VolumeExtent(\n        start_sector * self._bytes_per_sector,\n        number_of_sectors * self._bytes_per_sector)\n    self._extents.append(volume_extent)", "response": "Extracts attributes and extents from the volume."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _Parse(self):\n    root_file_entry = self._file_system.GetRootFileEntry()\n    tsk_volume = self._file_system.GetTSKVolume()\n    self.bytes_per_sector = tsk_partition.TSKVolumeGetBytesPerSector(tsk_volume)\n\n    for sub_file_entry in root_file_entry.sub_file_entries:\n      tsk_vs_part = sub_file_entry.GetTSKVsPart()\n      start_sector = tsk_partition.TSKVsPartGetStartSector(tsk_vs_part)\n      number_of_sectors = tsk_partition.TSKVsPartGetNumberOfSectors(tsk_vs_part)\n\n      if start_sector is None or number_of_sectors is None:\n        continue\n\n      if tsk_partition.TSKVsPartIsAllocated(tsk_vs_part):\n        volume = TSKVolume(sub_file_entry, self.bytes_per_sector)\n        self._AddVolume(volume)\n\n      volume_extent = volume_system.VolumeExtent(\n          start_sector * self.bytes_per_sector,\n          number_of_sectors * self.bytes_per_sector)\n\n      self._sections.append(volume_extent)", "response": "Extracts sections and volumes from the volume system."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Open(self, path_spec):\n    self._file_system = resolver.Resolver.OpenFileSystem(path_spec)\n    if self._file_system is None:\n      raise errors.VolumeSystemError('Unable to resolve path specification.')\n\n    type_indicator = self._file_system.type_indicator\n    if type_indicator != definitions.TYPE_INDICATOR_TSK_PARTITION:\n      raise errors.VolumeSystemError('Unsupported type indicator.')", "response": "Opens a TSK partition virtual file system."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclose the file system object.", "response": "def _Close(self):\n    \"\"\"Closes the file system object.\n\n    Raises:\n      IOError: if the close failed.\n    \"\"\"\n    self._vslvm_volume_group = None\n    self._vslvm_handle.close()\n    self._vslvm_handle = None\n\n    self._file_object.close()\n    self._file_object = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _Open(self, path_spec, mode='rb'):\n    if not path_spec.HasParent():\n      raise errors.PathSpecError(\n          'Unsupported path specification without parent.')\n\n    file_object = resolver.Resolver.OpenFileObject(\n        path_spec.parent, resolver_context=self._resolver_context)\n\n    try:\n      vslvm_handle = pyvslvm.handle()\n      vslvm_handle.open_file_object(file_object)\n      # TODO: implement multi physical volume support.\n      vslvm_handle.open_physical_volume_files_as_file_objects([\n          file_object])\n      vslvm_volume_group = vslvm_handle.get_volume_group()\n    except:\n      file_object.close()\n      raise\n\n    self._file_object = file_object\n    self._vslvm_handle = vslvm_handle\n    self._vslvm_volume_group = vslvm_volume_group", "response": "Opens the file system object defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef FileEntryExistsByPathSpec(self, path_spec):\n    volume_index = lvm.LVMPathSpecGetVolumeIndex(path_spec)\n\n    # The virtual root file has not corresponding volume index but\n    # should have a location.\n    if volume_index is None:\n      location = getattr(path_spec, 'location', None)\n      return location is not None and location == self.LOCATION_ROOT\n\n    return (\n        0 <= volume_index < self._vslvm_volume_group.number_of_logical_volumes)", "response": "Determines if a file entry for a path specification exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves a file entry for a path specification.", "response": "def GetFileEntryByPathSpec(self, path_spec):\n    \"\"\"Retrieves a file entry for a path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n\n    Returns:\n      LVMFileEntry: a file entry or None if not available.\n    \"\"\"\n    volume_index = lvm.LVMPathSpecGetVolumeIndex(path_spec)\n\n    # The virtual root file has not corresponding volume index but\n    # should have a location.\n    if volume_index is None:\n      location = getattr(path_spec, 'location', None)\n      if location is None or location != self.LOCATION_ROOT:\n        return None\n\n      return lvm_file_entry.LVMFileEntry(\n          self._resolver_context, self, path_spec, is_root=True,\n          is_virtual=True)\n\n    if (volume_index < 0 or\n        volume_index >= self._vslvm_volume_group.number_of_logical_volumes):\n      return None\n\n    return lvm_file_entry.LVMFileEntry(self._resolver_context, self, path_spec)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GetLVMLogicalVolumeByPathSpec(self, path_spec):\n    volume_index = lvm.LVMPathSpecGetVolumeIndex(path_spec)\n    if volume_index is None:\n      return None\n    return self._vslvm_volume_group.get_logical_volume(volume_index)", "response": "Retrieves a LVM logical volume for a path specification."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetRootFileEntry(self):\n    path_spec = lvm_path_spec.LVMPathSpec(\n        location=self.LOCATION_ROOT, parent=self._path_spec.parent)\n    return self.GetFileEntryByPathSpec(path_spec)", "response": "Retrieves the root file entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _Close(self):\n    self._tar_ext_file.close()\n    self._tar_ext_file = None\n\n    self._file_system.Close()\n    self._file_system = None", "response": "Closes the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen the file - like object defined by path specification.", "response": "def _Open(self, path_spec=None, mode='rb'):\n    \"\"\"Opens the file-like object defined by path specification.\n\n    Args:\n      path_spec (Optional[PathSpec]): path specification.\n      mode (Optional[str]): file access mode.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file-like object could not be opened.\n      OSError: if the file-like object could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not path_spec:\n      raise ValueError('Missing path specification.')\n\n    file_system = resolver.Resolver.OpenFileSystem(\n        path_spec, resolver_context=self._resolver_context)\n\n    file_entry = file_system.GetFileEntryByPathSpec(path_spec)\n    if not file_entry:\n      file_system.Close()\n      raise IOError('Unable to retrieve file entry.')\n\n    if not file_entry.IsFile():\n      file_system.Close()\n      raise IOError('Not a regular file.')\n\n    self._file_system = file_system\n    tar_file = self._file_system.GetTARFile()\n    tar_info = file_entry.GetTARInfo()\n\n    self._tar_ext_file = tar_file.extractfile(tar_info)\n\n    self._current_offset = 0\n    self._size = tar_info.size"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(self, size=None):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._current_offset < 0:\n      raise IOError('Invalid current offset value less than zero.')\n\n    if self._current_offset > self._size:\n      return b''\n\n    if size is None or self._current_offset + size > self._size:\n      size = self._size - self._current_offset\n\n    self._tar_ext_file.seek(self._current_offset, os.SEEK_SET)\n\n    data = self._tar_ext_file.read(size)\n\n    # It is possible the that returned data size is not the same as the\n    # requested data size. At this layer we don't care and this discrepancy\n    # should be dealt with on a higher layer if necessary.\n    self._current_offset += len(data)\n\n    return data", "response": "Reads a byte string from the file - like object at the current offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts credentials from a path specification.", "response": "def ExtractCredentialsFromPathSpec(self, path_spec):\n    \"\"\"Extracts credentials from a path specification.\n\n    Args:\n      path_spec (PathSpec): path specification to extract credentials from.\n    \"\"\"\n    credentials = manager.CredentialsManager.GetCredentials(path_spec)\n    for identifier in credentials.CREDENTIALS:\n      value = getattr(path_spec, identifier, None)\n      if value is None:\n        continue\n\n      self.SetCredential(path_spec, identifier, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GetCredential(self, path_spec, identifier):\n    credentials = self._credentials_per_path_spec.get(path_spec.comparable, {})\n    return credentials.get(identifier, None)", "response": "Retrieves a specific credential from the key chain."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets a specific credential for the path specification.", "response": "def SetCredential(self, path_spec, identifier, data):\n    \"\"\"Sets a specific credential for the path specification.\n\n    Args:\n      path_spec (PathSpec): path specification.\n      identifier (str): credential identifier.\n      data (object): credential data.\n\n    Raises:\n      KeyError: if the credential is not supported by the path specification\n          type.\n    \"\"\"\n    supported_credentials = manager.CredentialsManager.GetCredentials(path_spec)\n\n    if identifier not in supported_credentials.CREDENTIALS:\n      raise KeyError((\n          'Unsuppored credential: {0:s} for path specification type: '\n          '{1:s}').format(identifier, path_spec.type_indicator))\n\n    credentials = self._credentials_per_path_spec.get(path_spec.comparable, {})\n    credentials[identifier] = data\n    self._credentials_per_path_spec[path_spec.comparable] = credentials"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _GetStat(self):\n    stat_object = super(BDEFileEntry, self)._GetStat()\n\n    stat_object.size = self._bde_volume.get_size()\n\n    return stat_object", "response": "Retrieves the stat object for the current file entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef creation_time(self):\n    timestamp = self._bde_volume.get_creation_time_as_integer()\n    return dfdatetime_filetime.Filetime(timestamp=timestamp)", "response": "Returns the creation time of the BDE volume."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef EWFGlobPathSpec(file_system, path_spec):\n  if not path_spec.HasParent():\n    raise errors.PathSpecError(\n        'Unsupported path specification without parent.')\n\n  parent_path_spec = path_spec.parent\n\n  parent_location = getattr(parent_path_spec, 'location', None)\n  if not parent_location:\n    raise errors.PathSpecError(\n        'Unsupported parent path specification without location.')\n\n  parent_location, _, segment_extension = parent_location.rpartition('.')\n  segment_extension_start = segment_extension[0]\n  segment_extension_length = len(segment_extension)\n\n  if (segment_extension_length not in [3, 4] or\n      not segment_extension.endswith('01') or (\n          segment_extension_length == 3 and\n          segment_extension_start not in ['E', 'e', 's']) or (\n              segment_extension_length == 4 and\n              not segment_extension.startswith('Ex'))):\n    raise errors.PathSpecError((\n        'Unsupported parent path specification invalid segment file '\n        'extension: {0:s}').format(segment_extension))\n\n  segment_number = 1\n  segment_files = []\n  while True:\n    segment_location = '{0:s}.{1:s}'.format(parent_location, segment_extension)\n\n    # Note that we don't want to set the keyword arguments when not used\n    # because the path specification base class will check for unused\n    # keyword arguments and raise.\n    kwargs = path_spec_factory.Factory.GetProperties(parent_path_spec)\n\n    kwargs['location'] = segment_location\n    if parent_path_spec.parent is not None:\n      kwargs['parent'] = parent_path_spec.parent\n\n    segment_path_spec = path_spec_factory.Factory.NewPathSpec(\n        parent_path_spec.type_indicator, **kwargs)\n\n    if not file_system.FileEntryExistsByPathSpec(segment_path_spec):\n      break\n\n    segment_files.append(segment_path_spec)\n\n    segment_number += 1\n    if segment_number <= 99:\n      if segment_extension_length == 3:\n        segment_extension = '{0:s}{1:02d}'.format(\n            segment_extension_start, segment_number)\n      elif segment_extension_length == 4:\n        segment_extension = '{0:s}x{1:02d}'.format(\n            segment_extension_start, segment_number)\n\n    else:\n      segment_index = segment_number - 100\n\n      if segment_extension_start in ['e', 's']:\n        letter_offset = ord('a')\n      else:\n        letter_offset = ord('A')\n\n      segment_index, remainder = divmod(segment_index, 26)\n      third_letter = chr(letter_offset + remainder)\n\n      segment_index, remainder = divmod(segment_index, 26)\n      second_letter = chr(letter_offset + remainder)\n\n      first_letter = chr(ord(segment_extension_start) + segment_index)\n      if first_letter in ['[', '{']:\n        raise RuntimeError('Unsupported number of segment files.')\n\n      if segment_extension_length == 3:\n        segment_extension = '{0:s}{1:s}{2:s}'.format(\n            first_letter, second_letter, third_letter)\n      elif segment_extension_length == 4:\n        segment_extension = '{0:s}x{1:s}{2:s}'.format(\n            first_letter, second_letter, third_letter)\n\n  return segment_files", "response": "Globs for path specifications according to the EWF naming schema."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd the parent directories of a path to the fake file system.", "response": "def _AddParentDirectories(self, path):\n    \"\"\"Adds the parent directories of a path to the fake file system.\n\n    Args:\n      path (str): path of the file within the fake file system.\n\n    Raises:\n      ValueError: if a parent directory is already set and is not a directory.\n    \"\"\"\n    path_segments = self.file_system.SplitPath(path)\n    for segment_index in range(len(path_segments)):\n      parent_path = self.file_system.JoinPath(path_segments[:segment_index])\n      file_entry = self.file_system.GetFileEntryByPath(parent_path)\n      if file_entry and not file_entry.IsDirectory():\n        raise ValueError(\n            'Non-directory parent file entry: {0:s} already exists.'.format(\n                parent_path))\n\n    for segment_index in range(len(path_segments)):\n      parent_path = self.file_system.JoinPath(path_segments[:segment_index])\n      if not self.file_system.FileEntryExistsByPath(parent_path):\n        self.file_system.AddFileEntry(\n            parent_path, file_entry_type=definitions.FILE_ENTRY_TYPE_DIRECTORY)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a directory to the fake file system.", "response": "def AddDirectory(self, path):\n    \"\"\"Adds a directory to the fake file system.\n\n    Note that this function will create parent directories if needed.\n\n    Args:\n      path (str): path of the directory within the fake file system.\n\n    Raises:\n      ValueError: if the path is already set.\n    \"\"\"\n    if self.file_system.FileEntryExistsByPath(path):\n      raise ValueError('Path: {0:s} already set.'.format(path))\n\n    self._AddParentDirectories(path)\n    self.file_system.AddFileEntry(\n        path, file_entry_type=definitions.FILE_ENTRY_TYPE_DIRECTORY)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a regular file to the fake file system.", "response": "def AddFile(self, path, file_data):\n    \"\"\"Adds a \"regular\" file to the fake file system.\n\n    Note that this function will create parent directories if needed.\n\n    Args:\n      path (str): path of the file within the fake file system.\n      file_data (bytes): data of the file.\n\n    Raises:\n      ValueError: if the path is already set.\n    \"\"\"\n    if self.file_system.FileEntryExistsByPath(path):\n      raise ValueError('Path: {0:s} already set.'.format(path))\n\n    self._AddParentDirectories(path)\n    self.file_system.AddFileEntry(path, file_data=file_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a regular file to the fake file system.", "response": "def AddFileReadData(self, path, file_data_path):\n    \"\"\"Adds a \"regular\" file to the fake file system.\n\n    Args:\n      path (str): path of the file within the fake file system.\n      file_data_path (str): path of the file to read the file data from.\n\n    Raises:\n      ValueError: if the path is already set.\n    \"\"\"\n    if self.file_system.FileEntryExistsByPath(path):\n      raise ValueError('Path: {0:s} already set.'.format(path))\n\n    with open(file_data_path, 'rb') as file_object:\n      file_data = file_object.read()\n\n    self._AddParentDirectories(path)\n    self.file_system.AddFileEntry(path, file_data=file_data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef AddSymbolicLink(self, path, linked_path):\n    if self.file_system.FileEntryExistsByPath(path):\n      raise ValueError('Path: {0:s} already set.'.format(path))\n\n    self._AddParentDirectories(path)\n    self.file_system.AddFileEntry(\n        path, file_entry_type=definitions.FILE_ENTRY_TYPE_LINK,\n        link_data=linked_path)", "response": "Adds a symbolic link to the fake file system."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef DeregisterCredentials(cls, credentials):\n    if credentials.type_indicator not in cls._credentials:\n      raise KeyError(\n          'Credential object not set for type indicator: {0:s}.'.format(\n              credentials.type_indicator))\n\n    del cls._credentials[credentials.type_indicator]", "response": "Deregisters a path specification credentials."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering a path specification credentials.", "response": "def RegisterCredentials(cls, credentials):\n    \"\"\"Registers a path specification credentials.\n\n    Args:\n      credentials (Credentials): credentials.\n\n    Raises:\n      KeyError: if credentials object is already set for the corresponding\n          type indicator.\n    \"\"\"\n    if credentials.type_indicator in cls._credentials:\n      raise KeyError(\n          'Credentials object already set for type indicator: {0:s}.'.format(\n              credentials.type_indicator))\n\n    cls._credentials[credentials.type_indicator] = credentials"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread the next uncompressed data from the gzip stream.", "response": "def Read(self, file_object):\n    \"\"\"Reads the next uncompressed data from the gzip stream.\n\n    Args:\n      file_object (FileIO): file object that contains the compressed stream.\n\n    Returns:\n      bytes: next uncompressed data from the compressed stream.\n    \"\"\"\n    file_object.seek(self.last_read, os.SEEK_SET)\n    read_data = file_object.read(self._MAXIMUM_READ_SIZE)\n    self.last_read = file_object.get_offset()\n    compressed_data = b''.join([self._compressed_data, read_data])\n    decompressed, extra_compressed = self._decompressor.Decompress(\n        compressed_data)\n    self._compressed_data = extra_compressed\n    self.uncompressed_offset += len(decompressed)\n    return decompressed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a member header from a file - like object.", "response": "def _ReadMemberHeader(self, file_object):\n    \"\"\"Reads a member header.\n\n    Args:\n      file_object (FileIO): file-like object to read from.\n\n    Raises:\n      FileFormatError: if the member header cannot be read.\n    \"\"\"\n    file_offset = file_object.get_offset()\n    member_header = self._ReadStructure(\n        file_object, file_offset, self._MEMBER_HEADER_SIZE,\n        self._MEMBER_HEADER, 'member header')\n\n    if member_header.signature != self._GZIP_SIGNATURE:\n      raise errors.FileFormatError(\n          'Unsupported signature: 0x{0:04x}.'.format(member_header.signature))\n\n    if member_header.compression_method != self._COMPRESSION_METHOD_DEFLATE:\n      raise errors.FileFormatError(\n          'Unsupported compression method: {0:d}.'.format(\n              member_header.compression_method))\n\n    self.modification_time = member_header.modification_time\n    self.operating_system = member_header.operating_system\n\n    if member_header.flags & self._FLAG_FEXTRA:\n      file_offset = file_object.get_offset()\n      extra_field_data_size = self._ReadStructure(\n          file_object, file_offset, self._UINT16LE_SIZE,\n          self._UINT16LE, 'extra field data size')\n\n      file_object.seek(extra_field_data_size, os.SEEK_CUR)\n\n    if member_header.flags & self._FLAG_FNAME:\n      file_offset = file_object.get_offset()\n      string_value = self._ReadString(\n          file_object, file_offset, self._CSTRING, 'original filename')\n\n      self.original_filename = string_value.rstrip('\\x00')\n\n    if member_header.flags & self._FLAG_FCOMMENT:\n      file_offset = file_object.get_offset()\n      string_value = self._ReadString(\n          file_object, file_offset, self._CSTRING, 'comment')\n\n      self.comment = string_value.rstrip('\\x00')\n\n    if member_header.flags & self._FLAG_FHCRC:\n      file_object.read(2)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread a member footer.", "response": "def _ReadMemberFooter(self, file_object):\n    \"\"\"Reads a member footer.\n\n    Args:\n      file_object (FileIO): file-like object to read from.\n\n    Raises:\n      FileFormatError: if the member footer cannot be read.\n    \"\"\"\n    file_offset = file_object.get_offset()\n    member_footer = self._ReadStructure(\n        file_object, file_offset, self._MEMBER_FOOTER_SIZE,\n        self._MEMBER_FOOTER, 'member footer')\n\n    self.uncompressed_data_size = member_footer.uncompressed_data_size"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nempties the cache that holds cached decompressed data.", "response": "def FlushCache(self):\n    \"\"\"Empties the cache that holds cached decompressed data.\"\"\"\n    self._cache = b''\n    self._cache_start_offset = None\n    self._cache_end_offset = None\n    self._ResetDecompressorState()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining the size of the uncompressed cached data.", "response": "def GetCacheSize(self):\n    \"\"\"Determines the size of the uncompressed cached data.\n\n    Returns:\n      int: number of cached bytes.\n    \"\"\"\n    if not self._cache_start_offset or not self._cache_end_offset:\n      return 0\n    return self._cache_end_offset - self._cache_start_offset"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ReadAtOffset(self, offset, size=None):\n    if size is not None and size < 0:\n      raise ValueError('Invalid size value {0!s}'.format(size))\n\n    if offset < 0:\n      raise ValueError('Invalid offset value {0!s}'.format(offset))\n\n    if size == 0 or offset >= self.uncompressed_data_size:\n      return b''\n\n    if self._cache_start_offset is None:\n      self._LoadDataIntoCache(self._file_object, offset)\n\n    if offset > self._cache_end_offset or offset < self._cache_start_offset:\n      self.FlushCache()\n      self._LoadDataIntoCache(self._file_object, offset)\n\n    cache_offset = offset - self._cache_start_offset\n    if not size:\n      return self._cache[cache_offset:]\n\n    data_end_offset = cache_offset + size\n\n    if data_end_offset > self._cache_end_offset:\n      return self._cache[cache_offset:]\n\n    return self._cache[cache_offset:data_end_offset]", "response": "Reads a byte string from the gzip member at the specified offset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _LoadDataIntoCache(\n      self, file_object, minimum_offset, read_all_data=False):\n    \"\"\"Reads and decompresses the data in the member.\n\n    This function already loads as much data as possible in the cache, up to\n    UNCOMPRESSED_DATA_CACHE_SIZE bytes.\n\n    Args:\n      file_object (FileIO): file-like object.\n      minimum_offset (int): offset into this member's uncompressed data at\n          which the cache should start.\n      read_all_data (bool): True if all the compressed data should be read\n          from the member.\n    \"\"\"\n    # Decompression can only be performed from beginning to end of the stream.\n    # So, if data before the current position of the decompressor in the stream\n    # is required, it's necessary to throw away the current decompression\n    # state and start again.\n    if minimum_offset < self._decompressor_state.uncompressed_offset:\n      self._ResetDecompressorState()\n\n    while not self.IsCacheFull() or read_all_data:\n      decompressed_data = self._decompressor_state.Read(file_object)\n      # Note that decompressed_data will be empty if there is no data left\n      # to read and decompress.\n      if not decompressed_data:\n        break\n\n      decompressed_data_length = len(decompressed_data)\n      decompressed_end_offset = self._decompressor_state.uncompressed_offset\n      decompressed_start_offset = (\n          decompressed_end_offset - decompressed_data_length)\n\n      data_to_add = decompressed_data\n      added_data_start_offset = decompressed_start_offset\n\n      if decompressed_start_offset < minimum_offset:\n        data_to_add = None\n\n      if decompressed_start_offset < minimum_offset < decompressed_end_offset:\n        data_add_offset = decompressed_end_offset - minimum_offset\n        data_to_add = decompressed_data[-data_add_offset]\n        added_data_start_offset = decompressed_end_offset - data_add_offset\n\n      if not self.IsCacheFull() and data_to_add:\n        self._cache = b''.join([self._cache, data_to_add])\n        if self._cache_start_offset is None:\n          self._cache_start_offset = added_data_start_offset\n        if self._cache_end_offset is None:\n          self._cache_end_offset = self._cache_start_offset + len(data_to_add)\n        else:\n          self._cache_end_offset += len(data_to_add)\n\n      # If there's no more data in the member, the unused_data value is\n      # populated in the decompressor. When this situation arises, we rewind\n      # to the end of the compressed_data section.\n      unused_data = self._decompressor_state.GetUnusedData()\n      if unused_data:\n        seek_offset = -len(unused_data)\n        file_object.seek(seek_offset, os.SEEK_CUR)\n        self._ResetDecompressorState()\n        break", "response": "Reads and decompresses the data in the member into the cache."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting a file entry.", "response": "def _ListFileEntry(\n      self, file_system, file_entry, parent_full_path, output_writer):\n    \"\"\"Lists a file entry.\n\n    Args:\n      file_system (dfvfs.FileSystem): file system that contains the file entry.\n      file_entry (dfvfs.FileEntry): file entry to list.\n      parent_full_path (str): full path of the parent file entry.\n      output_writer (StdoutWriter): output writer.\n    \"\"\"\n    # Since every file system implementation can have their own path\n    # segment separator we are using JoinPath to be platform and file system\n    # type independent.\n    full_path = file_system.JoinPath([parent_full_path, file_entry.name])\n    if not self._list_only_files or file_entry.IsFile():\n      output_writer.WriteFileEntry(full_path)\n\n    for sub_file_entry in file_entry.sub_file_entries:\n      self._ListFileEntry(file_system, sub_file_entry, full_path, output_writer)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting file entries in the base path specification.", "response": "def ListFileEntries(self, base_path_specs, output_writer):\n    \"\"\"Lists file entries in the base path specification.\n\n    Args:\n      base_path_specs (list[dfvfs.PathSpec]): source path specification.\n      output_writer (StdoutWriter): output writer.\n    \"\"\"\n    for base_path_spec in base_path_specs:\n      file_system = resolver.Resolver.OpenFileSystem(base_path_spec)\n      file_entry = resolver.Resolver.OpenFileEntry(base_path_spec)\n      if file_entry is None:\n        logging.warning(\n            'Unable to open base path specification:\\n{0:s}'.format(\n                base_path_spec.comparable))\n        return\n\n      self._ListFileEntry(file_system, file_entry, '', output_writer)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite the file path to the file.", "response": "def WriteFileEntry(self, path):\n    \"\"\"Writes the file path to file.\n\n    Args:\n      path (str): path of the file.\n    \"\"\"\n    string = '{0:s}\\n'.format(path)\n\n    encoded_string = self._EncodeString(string)\n    self._file_object.write(encoded_string)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a fake file entry.", "response": "def AddFileEntry(\n      self, path, file_entry_type=definitions.FILE_ENTRY_TYPE_FILE,\n      file_data=None, link_data=None):\n    \"\"\"Adds a fake file entry.\n\n    Args:\n      path (str): path of the file entry.\n      file_entry_type (Optional[str]): type of the file entry object.\n      file_data (Optional[bytes]): data of the fake file-like object.\n      link_data (Optional[bytes]): link data of the fake file entry object.\n\n    Raises:\n      KeyError: if the path already exists.\n      ValueError: if the file data is set but the file entry type is not a file\n          or if the link data is set but the file entry type is not a link.\n    \"\"\"\n    if path in self._paths:\n      raise KeyError('File entry already set for path: {0:s}.'.format(path))\n\n    if file_data and file_entry_type != definitions.FILE_ENTRY_TYPE_FILE:\n      raise ValueError('File data set for non-file file entry type.')\n\n    if link_data and file_entry_type != definitions.FILE_ENTRY_TYPE_LINK:\n      raise ValueError('Link data set for non-link file entry type.')\n\n    if file_data is not None:\n      path_data = file_data\n    elif link_data is not None:\n      path_data = link_data\n    else:\n      path_data = None\n\n    self._paths[path] = (file_entry_type, path_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the data associated to a path.", "response": "def GetDataByPath(self, path):\n    \"\"\"Retrieves the data associated to a path.\n\n    Args:\n      path (str): path of the file entry.\n\n    Returns:\n      bytes: data or None if not available.\n    \"\"\"\n    _, path_data = self._paths.get(path, (None, None))\n    return path_data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetFileEntryByPath(self, path):\n    if path is None:\n      return None\n\n    file_entry_type, _ = self._paths.get(path, (None, None))\n    if not file_entry_type:\n      return None\n\n    path_spec = fake_path_spec.FakePathSpec(location=path)\n    return fake_file_entry.FakeFileEntry(\n        self._resolver_context, self, path_spec,\n        file_entry_type=file_entry_type)", "response": "Retrieves a file entry for a path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetRootFileEntry(self):\n    path_spec = fake_path_spec.FakePathSpec(location=self.LOCATION_ROOT)\n    return self.GetFileEntryByPathSpec(path_spec)", "response": "Retrieves the root file entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines the basename of the path.", "response": "def BasenamePath(self, path):\n    \"\"\"Determines the basename of the path.\n\n    Args:\n      path (str): path.\n\n    Returns:\n      str: basename of the path.\n    \"\"\"\n    if path.endswith(self.PATH_SEPARATOR):\n      path = path[:-1]\n    _, _, basename = path.rpartition(self.PATH_SEPARATOR)\n    return basename"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Close(self):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if not self._is_cached:\n      close_file_system = True\n    elif self._resolver_context.ReleaseFileSystem(self):\n      self._is_cached = False\n      close_file_system = True\n    else:\n      close_file_system = False\n\n    if close_file_system:\n      self._Close()\n      self._is_open = False\n      self._path_spec = None", "response": "Closes the file system object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef DirnamePath(self, path):\n    if path.endswith(self.PATH_SEPARATOR):\n      path = path[:-1]\n    if not path:\n      return None\n\n    dirname, _, _ = path.rpartition(self.PATH_SEPARATOR)\n    return dirname", "response": "Determines the directory name of the path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GetDataStreamByPathSpec(self, path_spec):\n    file_entry = self.GetFileEntryByPathSpec(path_spec)\n    if not file_entry:\n      return None\n\n    data_stream_name = getattr(path_spec, 'data_stream', None)\n    return file_entry.GetDataStream(data_stream_name)", "response": "Retrieves a data stream for a path specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GetFileObjectByPathSpec(self, path_spec):\n    file_entry = self.GetFileEntryByPathSpec(path_spec)\n    if not file_entry:\n      return None\n\n    return file_entry.GetFileObject()", "response": "Retrieves a file - like object for a path specification."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef GetPathSegmentAndSuffix(self, base_path, path):\n    if path is None or base_path is None or not path.startswith(base_path):\n      return None, None\n\n    path_index = len(base_path)\n    if base_path and not base_path.endswith(self.PATH_SEPARATOR):\n      path_index += 1\n\n    if path_index == len(path):\n      return '', ''\n\n    path_segment, _, suffix = path[path_index:].partition(self.PATH_SEPARATOR)\n    return path_segment, suffix", "response": "Determines the path segment and suffix of the path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef JoinPath(self, path_segments):\n    # This is an optimized way to combine the path segments into a single path\n    # and combine multiple successive path separators to one.\n\n    # Split all the path segments based on the path (segment) separator.\n    path_segments = [\n        segment.split(self.PATH_SEPARATOR) for segment in path_segments]\n\n    # Flatten the sublists into one list.\n    path_segments = [\n        element for sublist in path_segments for element in sublist]\n\n    # Remove empty path segments.\n    path_segments = list(filter(None, path_segments))\n\n    return '{0:s}{1:s}'.format(\n        self.PATH_SEPARATOR, self.PATH_SEPARATOR.join(path_segments))", "response": "Joins the path segments into a single path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Open(self, path_spec, mode='rb'):\n    if self._is_open and not self._is_cached:\n      raise IOError('Already open.')\n\n    if mode != 'rb':\n      raise ValueError('Unsupported mode: {0:s}.'.format(mode))\n\n    if not path_spec:\n      raise ValueError('Missing path specification.')\n\n    if not self._is_open:\n      self._Open(path_spec, mode=mode)\n      self._is_open = True\n      self._path_spec = path_spec\n\n      if path_spec and not self._resolver_context.GetFileSystem(path_spec):\n        self._resolver_context.CacheFileSystem(path_spec, self)\n        self._is_cached = True\n\n    if self._is_cached:\n      self._resolver_context.GrabFileSystem(path_spec)", "response": "Opens the file system object defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves the directory entries.", "response": "def _EntriesGenerator(self):\n    \"\"\"Retrieves directory entries.\n\n    Since a directory can contain a vast number of entries using\n    a generator is more memory efficient.\n\n    Yields:\n      CPIOPathSpec: path specification.\n    \"\"\"\n    location = getattr(self.path_spec, 'location', None)\n\n    if location and location.startswith(self._file_system.PATH_SEPARATOR):\n      cpio_archive_file = self._file_system.GetCPIOArchiveFile()\n      for cpio_archive_file_entry in cpio_archive_file.GetFileEntries(\n          path_prefix=location[1:]):\n\n        path = cpio_archive_file_entry.path\n        if not path:\n          continue\n\n        _, suffix = self._file_system.GetPathSegmentAndSuffix(\n            location[1:], path)\n\n        # Ignore anything that is part of a sub directory or the directory\n        # itself.\n        if suffix or path == location:\n          continue\n\n        path_spec_location = self._file_system.JoinPath([path])\n        yield cpio_path_spec.CPIOPathSpec(\n            location=path_spec_location, parent=self.path_spec.parent)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _GetDirectory(self):\n    if self.entry_type != definitions.FILE_ENTRY_TYPE_DIRECTORY:\n      return None\n    return CPIODirectory(self._file_system, self.path_spec)", "response": "Retrieves a directory.\n\n    Returns:\n      CPIODirectory: a directory or None if not available."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _GetLink(self):\n    if self._link is None:\n      self._link = ''\n\n      if self.entry_type != definitions.FILE_ENTRY_TYPE_LINK:\n        return self._link\n\n      cpio_archive_file = self._file_system.GetCPIOArchiveFile()\n      link_data = cpio_archive_file.ReadDataAtOffset(\n          self._cpio_archive_file_entry.data_offset,\n          self._cpio_archive_file_entry.data_size)\n\n      # TODO: should this be ASCII?\n      self._link = link_data.decode('ascii')\n\n    return self._link", "response": "Retrieves the link.\n\n    Returns:\n      str: full path of the linked file entry."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the stat information about the file entry.", "response": "def _GetStat(self):\n    \"\"\"Retrieves information about the file entry.\n\n    Returns:\n      VFSStat: a stat object.\n    \"\"\"\n    stat_object = super(CPIOFileEntry, self)._GetStat()\n\n    # File data stat information.\n    stat_object.size = getattr(\n        self._cpio_archive_file_entry, 'data_size', None)\n\n    # Ownership and permissions stat information.\n    mode = getattr(self._cpio_archive_file_entry, 'mode', 0)\n    stat_object.mode = stat.S_IMODE(mode)\n    stat_object.uid = getattr(\n        self._cpio_archive_file_entry, 'user_identifier', None)\n    stat_object.gid = getattr(\n        self._cpio_archive_file_entry, 'group_identifier', None)\n\n    return stat_object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef modification_time(self):\n    timestamp = getattr(\n        self._cpio_archive_file_entry, 'modification_time', None)\n    if timestamp is None:\n      return None\n    return dfdatetime_posix_time.PosixTime(timestamp=timestamp)", "response": "Returns the modification time of the archive file entry or None if not available."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving the parent file entry.", "response": "def GetParentFileEntry(self):\n    \"\"\"Retrieves the parent file entry.\n\n    Returns:\n      CPIOFileEntry: parent file entry or None if not available.\n    \"\"\"\n    location = getattr(self.path_spec, 'location', None)\n    if location is None:\n      return None\n\n    parent_location = self._file_system.DirnamePath(location)\n    if parent_location is None:\n      return None\n\n    if parent_location == '':\n      parent_location = self._file_system.PATH_SEPARATOR\n      is_root = True\n      is_virtual = True\n    else:\n      is_root = False\n      is_virtual = False\n\n    parent_path_spec = getattr(self.path_spec, 'parent', None)\n    path_spec = cpio_path_spec.CPIOPathSpec(\n        location=parent_location, parent=parent_path_spec)\n    return CPIOFileEntry(\n        self._resolver_context, self._file_system, path_spec,\n        is_root=is_root, is_virtual=is_virtual)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the volume index from the path specification.", "response": "def LVMPathSpecGetVolumeIndex(path_spec):\n  \"\"\"Retrieves the volume index from the path specification.\n\n  Args:\n    path_spec (PathSpec): path specification.\n\n  Returns:\n    int: volume index or None if not available.\n  \"\"\"\n  volume_index = getattr(path_spec, 'volume_index', None)\n\n  if volume_index is None:\n    location = getattr(path_spec, 'location', None)\n\n    if location is None or not location.startswith('/lvm'):\n      return None\n\n    volume_index = None\n    try:\n      volume_index = int(location[4:], 10) - 1\n    except ValueError:\n      pass\n\n    if volume_index is None or volume_index < 0:\n      return None\n\n  return volume_index"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _GetResolverHelper(cls, type_indicator):\n    if not cls._resolver_helpers_manager:\n      # Delay the import of the resolver helpers manager to prevent circular\n      # imports.\n      from dfvfs.resolver_helpers import manager\n\n      cls._resolver_helpers_manager = manager.ResolverHelperManager\n\n    return cls._resolver_helpers_manager.GetHelper(type_indicator)", "response": "Retrieves the resolver helper for the specified type."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef OpenFileEntry(cls, path_spec_object, resolver_context=None):\n    file_system = cls.OpenFileSystem(\n        path_spec_object, resolver_context=resolver_context)\n\n    if resolver_context is None:\n      resolver_context = cls._resolver_context\n\n    file_entry = file_system.GetFileEntryByPathSpec(path_spec_object)\n\n    # Release the file system so it will be removed from the cache\n    # when the file entry is destroyed.\n    resolver_context.ReleaseFileSystem(file_system)\n\n    return file_entry", "response": "Opens a file entry object defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen a file - like object defined by path specification.", "response": "def OpenFileObject(cls, path_spec_object, resolver_context=None):\n    \"\"\"Opens a file-like object defined by path specification.\n\n    Args:\n      path_spec_object (PathSpec): path specification.\n      resolver_context (Optional[Context]): resolver context, where None\n          represents the built in context which is not multi process safe.\n\n    Returns:\n      FileIO: file-like object or None if the path specification could not\n          be resolved.\n\n    Raises:\n      PathSpecError: if the path specification is incorrect.\n      TypeError: if the path specification type is unsupported.\n    \"\"\"\n    if not isinstance(path_spec_object, path_spec.PathSpec):\n      raise TypeError('Unsupported path specification type.')\n\n    if resolver_context is None:\n      resolver_context = cls._resolver_context\n\n    if path_spec_object.type_indicator == definitions.TYPE_INDICATOR_MOUNT:\n      if path_spec_object.HasParent():\n        raise errors.PathSpecError(\n            'Unsupported mount path specification with parent.')\n\n      mount_point = getattr(path_spec_object, 'identifier', None)\n      if not mount_point:\n        raise errors.PathSpecError(\n            'Unsupported path specification without mount point identifier.')\n\n      path_spec_object = mount_manager.MountPointManager.GetMountPoint(\n          mount_point)\n      if not path_spec_object:\n        raise errors.MountPointError(\n            'No such mount point: {0:s}'.format(mount_point))\n\n    file_object = resolver_context.GetFileObject(path_spec_object)\n    if not file_object:\n      resolver_helper = cls._GetResolverHelper(path_spec_object.type_indicator)\n      file_object = resolver_helper.NewFileObject(resolver_context)\n\n    file_object.open(path_spec=path_spec_object)\n    return file_object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef OpenFileSystem(cls, path_spec_object, resolver_context=None):\n    if not isinstance(path_spec_object, path_spec.PathSpec):\n      raise TypeError('Unsupported path specification type.')\n\n    if resolver_context is None:\n      resolver_context = cls._resolver_context\n\n    if path_spec_object.type_indicator == definitions.TYPE_INDICATOR_MOUNT:\n      if path_spec_object.HasParent():\n        raise errors.PathSpecError(\n            'Unsupported mount path specification with parent.')\n\n      mount_point = getattr(path_spec_object, 'identifier', None)\n      if not mount_point:\n        raise errors.PathSpecError(\n            'Unsupported path specification without mount point identifier.')\n\n      path_spec_object = mount_manager.MountPointManager.GetMountPoint(\n          mount_point)\n      if not path_spec_object:\n        raise errors.MountPointError(\n            'No such mount point: {0:s}'.format(mount_point))\n\n    file_system = resolver_context.GetFileSystem(path_spec_object)\n    if not file_system:\n      resolver_helper = cls._GetResolverHelper(path_spec_object.type_indicator)\n      file_system = resolver_helper.NewFileSystem(resolver_context)\n\n    try:\n      file_system.Open(path_spec_object)\n    except (IOError, ValueError) as exception:\n      raise errors.BackEndError(\n          'Unable to open file system with error: {0!s}'.format(exception))\n\n    return file_system", "response": "Opens a file system object defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecode the base32 stream.", "response": "def Decode(self, encoded_data):\n    \"\"\"Decode the encoded data.\n\n    Args:\n      encoded_data (byte): encoded data.\n\n    Returns:\n      tuple(bytes, bytes): decoded data and remaining encoded data.\n\n    Raises:\n      BackEndError: if the base32 stream cannot be decoded.\n    \"\"\"\n    try:\n      decoded_data = base64.b32decode(encoded_data, casefold=False)\n    except (TypeError, binascii.Error) as exception:\n      raise errors.BackEndError(\n          'Unable to decode base32 stream with error: {0!s}.'.format(\n              exception))\n\n    return decoded_data, b''"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef BDEVolumeOpen(bde_volume, path_spec, file_object, key_chain):\n  password = key_chain.GetCredential(path_spec, 'password')\n  if password:\n    bde_volume.set_password(password)\n\n  recovery_password = key_chain.GetCredential(path_spec, 'recovery_password')\n  if recovery_password:\n    bde_volume.set_recovery_password(recovery_password)\n\n  startup_key = key_chain.GetCredential(path_spec, 'startup_key')\n  if startup_key:\n    bde_volume.read_startup_key(startup_key)\n\n  bde_volume.open_file_object(file_object)", "response": "Opens the BDE volume using the path specification."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetDecompressor(cls, compression_method):\n    compression_method = compression_method.lower()\n    decompressor = cls._decompressors.get(compression_method, None)\n    if not decompressor:\n      return None\n\n    return decompressor()", "response": "Retrieves the decompressor object for a specific compression method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef RegisterDecompressor(cls, decompressor):\n    compression_method = decompressor.COMPRESSION_METHOD.lower()\n    if compression_method in cls._decompressors:\n      raise KeyError(\n          'Decompressor for compression method: {0:s} already set.'.format(\n              decompressor.COMPRESSION_METHOD))\n\n    cls._decompressors[compression_method] = decompressor", "response": "Registers a decompressor for a specific compression method."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef open(self, path_spec=None, mode='rb'):\n    if self._is_open and not self._is_cached:\n      raise IOError('Already open.')\n\n    if mode != 'rb':\n      raise ValueError('Unsupported mode: {0:s}.'.format(mode))\n\n    if not self._is_open:\n      self._Open(path_spec=path_spec, mode=mode)\n      self._is_open = True\n\n      if path_spec and not self._resolver_context.GetFileObject(path_spec):\n        self._resolver_context.CacheFileObject(path_spec, self)\n        self._is_cached = True\n\n    if self._is_cached:\n      self._resolver_context.GrabFileObject(path_spec)", "response": "Opens the file - like object defined by path specification."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclose the file - like object.", "response": "def close(self):\n    \"\"\"Closes the file-like object.\n\n    Raises:\n      IOError: if the file-like object was not opened or the close failed.\n      OSError: if the file-like object was not opened or the close failed.\n    \"\"\"\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if not self._is_cached:\n      close_file_object = True\n    elif self._resolver_context.ReleaseFileObject(self):\n      self._is_cached = False\n      close_file_object = True\n    else:\n      close_file_object = False\n\n    if close_file_object:\n      self._Close()\n      self._is_open = False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncloses the encrypted stream file - like object.", "response": "def _Close(self):\n    \"\"\"Closes the file-like object.\n\n    If the file-like object was passed in the init function\n    the encrypted stream file-like object does not control\n    the file-like object and should not actually close it.\n    \"\"\"\n    if not self._file_object_set_in_init:\n      self._file_object.close()\n      self._file_object = None\n\n    self._decrypter = None\n    self._decrypted_data = b''\n    self._encrypted_data = b''"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _GetDecrypter(self):\n    resolver.Resolver.key_chain.ExtractCredentialsFromPathSpec(self._path_spec)\n\n    try:\n      credentials = resolver.Resolver.key_chain.GetCredentials(self._path_spec)\n      return encryption_manager.EncryptionManager.GetDecrypter(\n          self._encryption_method, **credentials)\n    except ValueError as exception:\n      raise IOError(exception)", "response": "Retrieves a decrypter.\n\n    Returns:\n      Decrypter: decrypter.\n\n    Raises:\n      IOError: if the decrypter cannot be initialized.\n      OSError: if the decrypter cannot be initialized."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _GetDecryptedStreamSize(self):\n    self._file_object.seek(0, os.SEEK_SET)\n\n    self._decrypter = self._GetDecrypter()\n    self._decrypted_data = b''\n\n    encrypted_data_offset = 0\n    encrypted_data_size = self._file_object.get_size()\n    decrypted_stream_size = 0\n\n    while encrypted_data_offset < encrypted_data_size:\n      read_count = self._ReadEncryptedData(self._ENCRYPTED_DATA_BUFFER_SIZE)\n      if read_count == 0:\n        break\n\n      encrypted_data_offset += read_count\n      decrypted_stream_size += self._decrypted_data_size\n\n    return decrypted_stream_size", "response": "Retrieves the decrypted stream size."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nopening the file - like object.", "response": "def _Open(self, path_spec=None, mode='rb'):\n    \"\"\"Opens the file-like object.\n\n    Args:\n      path_spec (Optional[PathSpec]): path specification.\n      mode (Optional[str]): file access mode.\n\n    Raises:\n      AccessError: if the access to open the file was denied.\n      IOError: if the file-like object could not be opened.\n      OSError: if the file-like object could not be opened.\n      PathSpecError: if the path specification is incorrect.\n      ValueError: if the path specification is invalid.\n    \"\"\"\n    if not self._file_object_set_in_init and not path_spec:\n      raise ValueError('Missing path specification.')\n\n    if not self._file_object_set_in_init:\n      if not path_spec.HasParent():\n        raise errors.PathSpecError(\n            'Unsupported path specification without parent.')\n\n      self._encryption_method = getattr(path_spec, 'encryption_method', None)\n\n      if self._encryption_method is None:\n        raise errors.PathSpecError(\n            'Path specification missing encryption method.')\n\n      self._file_object = resolver.Resolver.OpenFileObject(\n          path_spec.parent, resolver_context=self._resolver_context)\n\n    self._path_spec = path_spec"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _AlignDecryptedDataOffset(self, decrypted_data_offset):\n    self._file_object.seek(0, os.SEEK_SET)\n\n    self._decrypter = self._GetDecrypter()\n    self._decrypted_data = b''\n\n    encrypted_data_offset = 0\n    encrypted_data_size = self._file_object.get_size()\n\n    while encrypted_data_offset < encrypted_data_size:\n      read_count = self._ReadEncryptedData(self._ENCRYPTED_DATA_BUFFER_SIZE)\n      if read_count == 0:\n        break\n\n      encrypted_data_offset += read_count\n\n      if decrypted_data_offset < self._decrypted_data_size:\n        self._decrypted_data_offset = decrypted_data_offset\n        break\n\n      decrypted_data_offset -= self._decrypted_data_size", "response": "Aligns the encrypted file with the decrypted data offset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ReadEncryptedData(self, read_size):\n    encrypted_data = self._file_object.read(read_size)\n\n    read_count = len(encrypted_data)\n\n    self._encrypted_data = b''.join([self._encrypted_data, encrypted_data])\n\n    self._decrypted_data, self._encrypted_data = (\n        self._decrypter.Decrypt(self._encrypted_data))\n\n    self._decrypted_data_size = len(self._decrypted_data)\n\n    return read_count", "response": "Reads encrypted data from the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the decrypted stream size.", "response": "def SetDecryptedStreamSize(self, decrypted_stream_size):\n    \"\"\"Sets the decrypted stream size.\n\n    This function is used to set the decrypted stream size if it can be\n    determined separately.\n\n    Args:\n      decrypted_stream_size (int): size of the decrypted stream in bytes.\n\n    Raises:\n      IOError: if the file-like object is already open.\n      OSError: if the file-like object is already open.\n      ValueError: if the decrypted stream size is invalid.\n    \"\"\"\n    if self._is_open:\n      raise IOError('Already open.')\n\n    if decrypted_stream_size < 0:\n      raise ValueError((\n          'Invalid decrypted stream size: {0:d} value out of '\n          'bounds.').format(decrypted_stream_size))\n\n    self._decrypted_stream_size = decrypted_stream_size"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a byte string from the file - like object at the current offset.", "response": "def read(self, size=None):\n    \"\"\"Reads a byte string from the file-like object at the current offset.\n\n    The function will read a byte string of the specified size or\n    all of the remaining data if no size was specified.\n\n    Args:\n      size (Optional[int]): number of bytes to read, where None is all\n          remaining data.\n\n    Returns:\n      bytes: data read.\n\n    Raises:\n      IOError: if the read failed.\n      OSError: if the read failed.\n    \"\"\"\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._current_offset < 0:\n      raise IOError(\n          'Invalid current offset: {0:d} value less than zero.'.format(\n              self._current_offset))\n\n    if self._decrypted_stream_size is None:\n      self._decrypted_stream_size = self._GetDecryptedStreamSize()\n\n    if self._decrypted_stream_size < 0:\n      raise IOError('Invalid decrypted stream size.')\n\n    if self._current_offset >= self._decrypted_stream_size:\n      return b''\n\n    if self._realign_offset:\n      self._AlignDecryptedDataOffset(self._current_offset)\n      self._realign_offset = False\n\n    if size is None:\n      size = self._decrypted_stream_size\n    if self._current_offset + size > self._decrypted_stream_size:\n      size = self._decrypted_stream_size - self._current_offset\n\n    decrypted_data = b''\n\n    if size == 0:\n      return decrypted_data\n\n    while size > self._decrypted_data_size:\n      decrypted_data = b''.join([\n          decrypted_data,\n          self._decrypted_data[self._decrypted_data_offset:]])\n\n      remaining_decrypted_data_size = (\n          self._decrypted_data_size - self._decrypted_data_offset)\n\n      self._current_offset += remaining_decrypted_data_size\n      size -= remaining_decrypted_data_size\n\n      if self._current_offset >= self._decrypted_stream_size:\n        break\n\n      read_count = self._ReadEncryptedData(self._ENCRYPTED_DATA_BUFFER_SIZE)\n      self._decrypted_data_offset = 0\n      if read_count == 0:\n        break\n\n    if size > 0:\n      slice_start_offset = self._decrypted_data_offset\n      slice_end_offset = slice_start_offset + size\n\n      decrypted_data = b''.join([\n          decrypted_data,\n          self._decrypted_data[slice_start_offset:slice_end_offset]])\n\n      self._decrypted_data_offset += size\n      self._current_offset += size\n\n    return decrypted_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef seek(self, offset, whence=os.SEEK_SET):\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._current_offset < 0:\n      raise IOError(\n          'Invalid current offset: {0:d} value less than zero.'.format(\n              self._current_offset))\n\n    if whence == os.SEEK_CUR:\n      offset += self._current_offset\n\n    elif whence == os.SEEK_END:\n      if self._decrypted_stream_size is None:\n        self._decrypted_stream_size = self._GetDecryptedStreamSize()\n        if self._decrypted_stream_size is None:\n          raise IOError('Invalid decrypted stream size.')\n\n      offset += self._decrypted_stream_size\n\n    elif whence != os.SEEK_SET:\n      raise IOError('Unsupported whence.')\n\n    if offset < 0:\n      raise IOError('Invalid offset value less than zero.')\n\n    if offset != self._current_offset:\n      self._current_offset = offset\n      self._realign_offset = True", "response": "Seeks to an offset within the file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the size of the decrypted stream.", "response": "def get_size(self):\n    \"\"\"Retrieves the size of the file-like object.\n\n    Returns:\n      int: size of the decrypted stream.\n\n    Raises:\n      IOError: if the file-like object has not been opened.\n      OSError: if the file-like object has not been opened.\n    \"\"\"\n    if not self._is_open:\n      raise IOError('Not opened.')\n\n    if self._decrypted_stream_size is None:\n      self._decrypted_stream_size = self._GetDecryptedStreamSize()\n\n    return self._decrypted_stream_size"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the Viewlet with the given name or None if no such viewlet exists.", "response": "def getViewletByName(self, name):\n\n        \"\"\" Viewlets allow through-the-web customizations.\n\n        Through-the-web customization magic is managed by five.customerize.\n        We need to think of this when looking up viewlets.\n\n        @return: Viewlet registration object\n        \"\"\"\n        views = registration.getViews(IBrowserRequest)\n\n        for v in views:\n\n            if v.provided == IViewlet:\n                # Note that we might have conflicting BrowserView with the same\n                # name, thus we need to check for provided\n                if v.name == name:\n                    return v\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setupViewletByName(self, name):\n        context = aq_inner(self.context)\n        request = self.request\n\n        # Perform viewlet regisration look-up\n        # from adapters registry\n        reg = self.getViewletByName(name)\n        if reg is None:\n            return None\n\n        # factory method is responsible for creating the viewlet instance\n        factory = reg.factory\n\n        # Create viewlet and put it to the acquisition chain\n        # Viewlet need initialization parameters: context, request, view\n        try:\n            viewlet = factory(context, request, self, None).__of__(context)\n        except TypeError:\n            # Bad constructor call parameters\n            raise RuntimeError(\n                \"Unable to initialize viewlet {}. \"\n                \"Factory method {} call failed.\"\n                .format(name, str(factory)))\n\n        return viewlet", "response": "Constructs a viewlet instance by its name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pre_install(portal_setup):\n    logger.info(\"SENAITE LIMS pre-install handler [BEGIN]\")\n\n    # https://docs.plone.org/develop/addons/components/genericsetup.html#custom-installer-code-setuphandlers-py\n    profile_id = \"profile-senaite.lims:default\"\n    context = portal_setup._getImportContext(profile_id)\n    portal = context.getSite()  # noqa\n\n    # Only install the core once!\n    qi = portal.portal_quickinstaller\n    if not qi.isProductInstalled(\"bika.lims\"):\n        portal_setup.runAllImportStepsFromProfile(\"profile-bika.lims:default\")\n\n    logger.info(\"SENAITE LIMS pre-install handler [DONE]\")", "response": "Runs berfore the first import step of the default profile"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitial version to 1000", "response": "def to_1000(portal_setup):\n    \"\"\"Initial version to 1000\n\n    :param portal_setup: The portal_setup tool\n    \"\"\"\n\n    logger.info(\"Run all import steps from SENAITE LIMS ...\")\n    context = portal_setup._getImportContext(PROFILE_ID)\n    portal = context.getSite()\n    setup_html_filter(portal)\n    portal_setup.runAllImportStepsFromProfile(PROFILE_ID)\n    logger.info(\"Run all import steps from SENAITE LIMS [DONE]\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef spotlight_search_route(context, request):\n    catalogs = [\n        CATALOG_ANALYSIS_REQUEST_LISTING,\n        \"portal_catalog\",\n        \"bika_setup_catalog\",\n        \"bika_catalog\",\n        \"bika_catalog_worksheet_listing\"\n    ]\n\n    search_results = []\n    for catalog in catalogs:\n        search_results.extend(search(catalog=catalog))\n\n    # extract the data from all the brains\n    items = map(get_brain_info, search_results)\n\n    return {\n        \"count\": len(items),\n        \"items\": sorted(items, key=itemgetter(\"title\")),\n    }", "response": "The spotlight search route"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_brain_info(brain):\n    icon = api.get_icon(brain)\n    # avoid 404 errors with these guys\n    if \"document_icon.gif\" in icon:\n        icon = \"\"\n\n    id = api.get_id(brain)\n    url = api.get_url(brain)\n    title = api.get_title(brain)\n    description = api.get_description(brain)\n    parent = api.get_parent(brain)\n    parent_title = api.get_title(parent)\n    parent_url = api.get_url(parent)\n\n    return {\n        \"id\": id,\n        \"title\": title,\n        \"title_or_id\": title or id,\n        \"description\": description,\n        \"url\": url,\n        \"parent_title\": parent_title,\n        \"parent_url\": parent_url,\n        \"icon\": icon,\n    }", "response": "Extract the brain info"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches for objects in the catalog.", "response": "def search(query=None, catalog=None):\n    \"\"\"Search\n    \"\"\"\n    if query is None:\n        query = make_query(catalog)\n    if query is None:\n        return []\n    return api.search(query, catalog=catalog)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the search index to query", "response": "def get_search_index_for(catalog):\n    \"\"\"Returns the search index to query\n    \"\"\"\n    searchable_text_index = \"SearchableText\"\n    listing_searchable_text_index = \"listing_searchable_text\"\n\n    if catalog == CATALOG_ANALYSIS_REQUEST_LISTING:\n        tool = api.get_tool(catalog)\n        indexes = tool.indexes()\n        if listing_searchable_text_index in indexes:\n            return listing_searchable_text_index\n\n    return searchable_text_index"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef icon_cache_key(method, self, brain_or_object):\n    url = api.get_url(brain_or_object)\n    modified = api.get_modification_date(brain_or_object).millis()\n    key = \"{}?modified={}\".format(url, modified)\n    logger.debug(\"Generated Cache Key: {}\".format(key))\n    return key", "response": "Generates a cache key for the icon lookup\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the html tag that will be used to display the portal type for the brain or object", "response": "def get_icon_for(self, brain_or_object):\n        \"\"\"Get the navigation portlet icon for the brain or object\n\n        The cache key ensures that the lookup is done only once per domain name\n        \"\"\"\n        portal_types = api.get_tool(\"portal_types\")\n        fti = portal_types.getTypeInfo(api.get_portal_type(brain_or_object))\n        icon = fti.getIcon()\n        if not icon:\n            return \"\"\n        # Always try to get the big icon for high-res displays\n        icon_big = icon.replace(\".png\", \"_big.png\")\n        # fall back to a default icon if the looked up icon does not exist\n        if self.context.restrictedTraverse(icon_big, None) is None:\n            icon_big = None\n        portal_url = api.get_url(api.get_portal())\n        title = api.get_title(brain_or_object)\n        html_tag = \"<img title='{}' src='{}/{}' width='16' />\".format(\n            title, portal_url, icon_big or icon)\n        logger.info(\"Generated Icon Tag for {}: {}\".format(\n            api.get_path(brain_or_object), html_tag))\n        return html_tag"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getViewportValues(self, view=None):\n        values = {\n            'width': 'device-width',\n            'initial-scale': '1.0',\n        }\n\n        return ','.join('%s=%s' % (k, v) for k, v in values.items())", "response": "Determine the value of the viewport meta - tag\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getColumnsClasses(self, view=None):\n\n        plone_view = getMultiAdapter(\n            (self.context, self.request), name=u'plone')\n        portal_state = getMultiAdapter(\n            (self.context, self.request), name=u'plone_portal_state')\n\n        sl = plone_view.have_portlets('plone.leftcolumn', view=view)\n        sr = plone_view.have_portlets('plone.rightcolumn', view=view)\n\n        isRTL = portal_state.is_rtl()\n\n        # pre-fill dictionary\n        columns = dict(one=\"\", content=\"\", two=\"\")\n\n        if not sl and not sr:\n            # we don't have columns, thus conten takes the whole width\n            columns['content'] = \"col-md-12\"\n\n        elif sl and sr:\n            # In case we have both columns, content takes 50% of the whole\n            # width and the rest 50% is spread between the columns\n            columns['one'] = \"col-xs-12 col-md-2\"\n            columns['content'] = \"col-xs-12 col-md-8\"\n            columns['two'] = \"col-xs-12 col-md-2\"\n\n        elif (sr and not sl) and not isRTL:\n            # We have right column and we are NOT in RTL language\n            columns['content'] = \"col-xs-12 col-md-10\"\n            columns['two'] = \"col-xs-12 col-md-2\"\n\n        elif (sl and not sr) and isRTL:\n            # We have left column and we are in RTL language\n            columns['one'] = \"col-xs-12 col-md-2\"\n            columns['content'] = \"col-xs-12 col-md-10\"\n\n        elif (sl and not sr) and not isRTL:\n            # We have left column and we are in NOT RTL language\n            columns['one'] = \"col-xs-12 col-md-2\"\n            columns['content'] = \"col-xs-12 col-md-10\"\n\n        # # append cell to each css-string\n        # for key, value in columns.items():\n        #     columns[key] = \"cell \" + value\n\n        return columns", "response": "Determine whether a column should be shown."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_icon_url(self, brain):\n        icon_url = api.get_icon(brain, html_tag=False)\n        url, icon = icon_url.rsplit(\"/\", 1)\n        relative_url = url.lstrip(self.portal.absolute_url())\n        name, ext = os.path.splitext(icon)\n\n        # big icons endwith _big\n        if not name.endswith(\"_big\"):\n            icon = \"{}_big{}\".format(name, ext)\n\n        icon_big_url = \"/\".join([relative_url, icon])\n\n        # fall back to a default icon if the looked up icon does not exist\n        if self.context.restrictedTraverse(icon_big_url, None) is None:\n            icon_big_url = \"++resource++senaite.lims.images/gears.png\"\n\n        return icon_big_url", "response": "Returns the big icon URL for the given brain"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setupitems(self):\n        query = {\n            \"path\": {\n                \"query\": api.get_path(self.setup),\n                \"depth\": 1,\n            },\n        }\n        items = api.search(query, \"portal_catalog\")\n        # filter out items\n        items = filter(lambda item: not item.exclude_from_nav, items)\n\n        # sort by (translated) title\n        def cmp_by_translated_title(brain1, brain2):\n            title1 = t(api.get_title(brain1))\n            title2 = t(api.get_title(brain2))\n            return cmp(title1, title2)\n\n        return sorted(items, cmp=cmp_by_translated_title)", "response": "Lookup available setup items\n            = > catalog brains\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the content - type value determined by file extension.", "response": "def content_type(self):\n        \"\"\"Returns the content-type value determined by file extension.\"\"\"\n\n        if hasattr(self, '_content_type'):\n            return self._content_type\n\n        filename, extension = os.path.splitext(self._file_path)\n        if extension == '.csv':\n            self._content_type = 'text/csv'\n        elif extension == '.tsv':\n            self._content_type = 'text/tab-separated-values'\n        else:\n            self._content_type = 'text/plain'\n\n        return self._content_type"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting the current TONUpload object.", "response": "def perform(self):\n        \"\"\"Executes the current TONUpload object.\"\"\"\n\n        if self._file_size < self._SINGLE_UPLOAD_MAX:\n            resource = \"{0}{1}\".format(self._DEFAULT_RESOURCE, self.bucket)\n            response = self.__upload(resource, open(self._file_path, 'rb').read())\n            return response.headers['location']\n        else:\n            response = self.__init_chunked_upload()\n            min_chunk_size = int(response.headers['x-ton-min-chunk-size'])\n            chunk_size = min_chunk_size * self._DEFAULT_CHUNK_SIZE\n            location = response.headers['location']\n\n            f = open(self._file_path, 'rb')\n            bytes_read = 0\n            while True:\n                bytes = f.read(chunk_size)\n                if not bytes:\n                    break\n                bytes_start = bytes_read\n                bytes_read += len(bytes)\n                response = self.__upload_chunk(location, chunk_size, bytes, bytes_start, bytes_read)\n                response_time = int(response.headers['x-response-time'])\n                chunk_size = min_chunk_size * size(self._DEFAULT_CHUNK_SIZE,\n                                                   self._RESPONSE_TIME_MAX,\n                                                   response_time)\n            f.close()\n\n            return location.split(\"?\")[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __upload(self, resource, bytes):\n\n        # note: string conversion required here due to open encoding bug in requests-oauthlib.\n        headers = {\n            'x-ton-expires': http_time(self.options.get('x-ton-expires', self._DEFAULT_EXPIRE)),\n            'content-length': str(self._file_size),\n            'content-type': self.content_type\n        }\n\n        return Request(self._client, 'post', resource,\n                       domain=self._DEFAULT_DOMAIN, headers=headers, body=bytes).perform()", "response": "Performs a single chunk upload."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupload a single chunk of a multi - chunk upload.", "response": "def __upload_chunk(self, resource, chunk_size, bytes, bytes_start, bytes_read):\n        \"\"\"Uploads a single chunk of a multi-chunk upload.\"\"\"\n\n        # note: string conversion required here due to open encoding bug in requests-oauthlib.\n        headers = {\n            'content-type': self.content_type,\n            'content-length': str(min([chunk_size, self._file_size - bytes_read])),\n            'content-range': \"bytes {0}-{1}/{2}\".format(\n                bytes_start, bytes_read - 1, self._file_size)\n        }\n\n        return Request(self._client, 'put', resource,\n                       domain=self._DEFAULT_DOMAIN, headers=headers, body=bytes).perform()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the next item in the cursor.", "response": "def next(self):\n        \"\"\"Returns the next item in the cursor.\"\"\"\n        if self._current_index < len(self._collection):\n            value = self._collection[self._current_index]\n            self._current_index += 1\n            return value\n        elif self._next_cursor:\n            self.__fetch_next()\n            return self.next()\n        else:\n            self._current_index = 0\n            raise StopIteration"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving or updates the current object instance depending on the the presence of object. id.", "response": "def save(self):\n        \"\"\"\n        Saves or updates the current object instance depending on the\n        presence of `object.id`.\n        \"\"\"\n        params = self.to_params()\n        if 'tweet_id' in params:\n            params['tweet_ids'] = [params['tweet_id']]\n            del params['tweet_id']\n\n        if self.id:\n            raise HTTPError(\"Method PUT not allowed.\")\n\n        resource = self.RESOURCE_COLLECTION.format(account_id=self.account.id)\n        response = Request(self.account.client, 'post', resource, params=params).perform()\n        return self.from_response(response.body['data'][0])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an HTML preview for a Scheduled Tweet.", "response": "def preview(self):\n        \"\"\"\n        Returns an HTML preview for a Scheduled Tweet.\n        \"\"\"\n        if self.id:\n            resource = self.PREVIEW\n            resource = resource.format(account_id=self.account.id, id=self.id)\n            response = Request(self.account.client, 'get', resource).perform()\n            return response.body['data']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load(klass, client, id, **kwargs):\n        resource = klass.RESOURCE.format(id=id)\n        response = Request(client, 'get', resource, params=kwargs).perform()\n        return klass(client).from_response(response.body['data'])", "response": "Returns an object instance for a given resource."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef all(klass, client, **kwargs):\n        resource = klass.RESOURCE_COLLECTION\n        request = Request(client, 'get', resource, params=kwargs)\n        return Cursor(klass, request, init_with=[client])", "response": "Returns a Cursor instance for a given resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a collection of features available to the current account.", "response": "def features(self):\n        \"\"\"\n        Returns a collection of features available to the current account.\n        \"\"\"\n        self._validate_loaded()\n\n        resource = self.FEATURES.format(id=self.id)\n        response = Request(self.client, 'get', resource).perform()\n\n        return response.body['data']"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef scoped_timeline(self, *id, **kwargs):\n        self._validate_loaded()\n\n        params = {'user_id': id}\n        params.update(kwargs)\n\n        resource = self.SCOPED_TIMELINE.format(id=self.id)\n        response = Request(self.client, 'get', resource, params=params).perform()\n\n        return response.body['data']", "response": "Returns the most recent promotable Tweets created by the specified Twitter user."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the minimum activity start time and maximum activity end time from the active entities response.", "response": "def date_range(data):\n    \"\"\"Returns the minimum activity start time and the maximum activity end time\n    from the active entities response. These dates are modified in the following\n    way. The hours (and minutes and so on) are removed from the start and end\n    times and a *day* is added to the end time. These are the dates that should\n    be used in the subsequent analytics request.\n    \"\"\"\n    start = min([parse(d['activity_start_time']) for d in data])\n    end = max([parse(d['activity_end_time']) for d in data])\n    start = remove_hours(start)\n    end = remove_hours(end) + timedelta(days=1)\n    return start, end"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a string representation of the current SDK version.", "response": "def get_version():\n    \"\"\"Returns a string representation of the current SDK version.\"\"\"\n    if isinstance(VERSION[-1], str):\n        return '.'.join(map(str, VERSION[:-1])) + VERSION[-1]\n    return '.'.join(map(str, VERSION))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_time(time, granularity):\n    if not granularity:\n        if type(time) is datetime.date:\n            return format_date(time)\n        else:\n            return format_time(time)\n    if granularity == GRANULARITY.HOUR:\n        return format_time(remove_minutes(time))\n    elif granularity == GRANULARITY.DAY:\n        return format_date(remove_hours(time))\n    else:\n        return format_time(time)", "response": "Returns a truncated and rounded time string based on the specified granularity."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef http_time(time):\n    return formatdate(timeval=mktime(time.timetuple()), localtime=False, usegmt=True)", "response": "Formats a datetime as an RFC 1123 compliant string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef size(default_chunk_size, response_time_max, response_time_actual):\n    if response_time_actual == 0:\n        response_time_actual = 1\n    scale = 1 / (response_time_actual / response_time_max)\n    size = int(default_chunk_size * scale)\n    return min(max(size, 1), default_chunk_size)", "response": "Determines the chunk size based on response times."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the correct error type from a Response object.", "response": "def from_response(response):\n        \"\"\"Returns the correct error type from a ::class::`Response` object.\"\"\"\n        if response.code:\n            return ERRORS[response.code](response)\n        else:\n            return Error(response)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nenable and disables sandbox mode.", "response": "def sandbox():\n        \"\"\"Enables and disables sandbox mode.\"\"\"\n        def fget(self):\n            return self._options.get('sandbox', None)\n\n        def fset(self, value):\n            self._options['sandbox'] = value\n\n        return locals()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nenabling and disables request tracing.", "response": "def trace():\n        \"\"\"Enables and disables request tracing.\"\"\"\n        def fget(self):\n            return self._options.get('trace', None)\n\n        def fset(self, value):\n            self._options['trace'] = value\n\n        return locals()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef accounts(self, id=None):\n        return Account.load(self, id) if id else Account.all(self)", "response": "Returns a collection of accounts available to the current access token."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef platform_versions(klass, account, **kwargs):\n        resource = klass.RESOURCE_OPTIONS + 'platform_versions'\n        request = Request(account.client, 'get', resource, params=kwargs)\n        return Cursor(None, request)", "response": "Returns a list of supported platform versions"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a collection of targeting criteria available to the current line item.", "response": "def targeting_criteria(self, id=None, **kwargs):\n        \"\"\"\n        Returns a collection of targeting criteria available to the\n        current line item.\n        \"\"\"\n        self._validate_loaded()\n        if id is None:\n            return TargetingCriteria.all(self.account, self.id, **kwargs)\n        else:\n            return TargetingCriteria.load(self.account, id, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an HTML preview of a tweet either new or existing.", "response": "def preview(klass, account, **kwargs):\n        \"\"\"\n        Returns an HTML preview of a tweet, either new or existing.\n        \"\"\"\n        params = {}\n        params.update(kwargs)\n\n        # handles array to string conversion for media IDs\n        if 'media_ids' in params and isinstance(params['media_ids'], list):\n            params['media_ids'] = ','.join(map(str, params['media_ids']))\n\n        resource = klass.TWEET_ID_PREVIEW if params.get('id') else klass.TWEET_PREVIEW\n        resource = resource.format(account_id=account.id, id=params.get('id'))\n        response = Request(account.client, 'get', resource, params=params).perform()\n        return response.body['data']"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a Promoted - Only Tweet using the specialized Ads API end point.", "response": "def create(klass, account, **kwargs):\n        \"\"\"\n        Creates a \"Promoted-Only\" Tweet using the specialized Ads API end point.\n        \"\"\"\n        params = {}\n        params.update(kwargs)\n\n        # handles array to string conversion for media IDs\n        if 'media_ids' in params and isinstance(params['media_ids'], list):\n            params['media_ids'] = ','.join(map(str, params['media_ids']))\n\n        resource = klass.TWEET_CREATE.format(account_id=account.id)\n        response = Request(account.client, 'post', resource, params=params).perform()\n        return response.body['data']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a resource object property.", "response": "def resource_property(klass, name, **kwargs):\n    \"\"\"Builds a resource object property.\"\"\"\n    klass.PROPERTIES[name] = kwargs\n\n    def getter(self):\n        return getattr(self, '_%s' % name, kwargs.get('default', None))\n\n    if kwargs.get('readonly', False):\n        setattr(klass, name, property(getter))\n    else:\n        def setter(self, value):\n            setattr(self, '_%s' % name, value)\n        setattr(klass, name, property(getter, setter))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_response(self, response):\n        for name in self.PROPERTIES:\n            attr = '_{0}'.format(name)\n            transform = self.PROPERTIES[name].get('transform', None)\n            value = response.get(name, None)\n            if transform and transform == TRANSFORM.TIME and value:\n                setattr(self, attr, dateutil.parser.parse(value))\n            if isinstance(value, int) and value == 0:\n                continue  # skip attribute\n            else:\n                setattr(self, attr, value)\n\n        return self", "response": "Populates a given object from a parsed JSON API response."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a Hash of property values for the current object. This helper handles all necessary type coercions as it generates its output.", "response": "def to_params(self):\n        \"\"\"\n        Generates a Hash of property values for the current object. This helper\n        handles all necessary type coercions as it generates its output.\n        \"\"\"\n        params = {}\n        for name in self.PROPERTIES:\n            attr = '_{0}'.format(name)\n            value = getattr(self, attr, None) or getattr(self, name, None)\n\n            # skip attribute\n            if value is None:\n                continue\n\n            if isinstance(value, datetime):\n                params[name] = format_time(value)\n            elif isinstance(value, list):\n                params[name] = ','.join(map(str, value))\n            elif isinstance(value, bool):\n                params[name] = str(value).lower()\n            else:\n                params[name] = value\n\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake a batch request for a list of objects", "response": "def batch_save(klass, account, objs):\n        \"\"\"\n        Makes batch request(s) for a passed in list of objects\n        \"\"\"\n\n        resource = klass.BATCH_RESOURCE_COLLECTION.format(account_id=account.id)\n\n        json_body = []\n\n        for obj in objs:\n            entity_type = klass._ENTITY_MAP[klass.__name__].lower()\n            obj_json = {'params': obj.to_params()}\n\n            if obj.id is None:\n                obj_json['operation_type'] = 'Create'\n            elif obj.to_delete is True:\n                obj_json['operation_type'] = 'Delete'\n                obj_json['params'][entity_type + '_id'] = obj.id\n            else:\n                obj_json['operation_type'] = 'Update'\n                obj_json['params'][entity_type + '_id'] = obj.id\n\n            json_body.append(obj_json)\n\n        resource = klass.BATCH_RESOURCE_COLLECTION.format(account_id=account.id)\n        response = Request(account.client,\n                           'post', resource,\n                           body=json.dumps(json_body),\n                           headers={'Content-Type': 'application/json'}).perform()\n\n        # persist each entity\n        for obj, res_obj in zip(objs, response.body['data']):\n            obj = obj.from_response(res_obj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stats(self, metrics, **kwargs):  # noqa\n        return self.__class__.all_stats(self.account, [self.id], metrics, **kwargs)", "response": "Pulls a list of metrics for the current object instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the standard params for a stats request.", "response": "def _standard_params(klass, ids, metric_groups, **kwargs):\n        \"\"\"\n        Sets the standard params for a stats request\n        \"\"\"\n        end_time = kwargs.get('end_time', datetime.utcnow())\n        start_time = kwargs.get('start_time', end_time - timedelta(seconds=604800))\n        granularity = kwargs.get('granularity', GRANULARITY.HOUR)\n        placement = kwargs.get('placement', PLACEMENT.ALL_ON_TWITTER)\n\n        params = {\n            'metric_groups': ','.join(metric_groups),\n            'start_time': to_time(start_time, granularity),\n            'end_time': to_time(end_time, granularity),\n            'granularity': granularity.upper(),\n            'entity': klass.ANALYTICS_MAP[klass.__name__],\n            'placement': placement\n        }\n\n        params['entity_ids'] = ','.join(ids)\n\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef all_stats(klass, account, ids, metric_groups, **kwargs):\n        params = klass._standard_params(ids, metric_groups, **kwargs)\n\n        resource = klass.RESOURCE_SYNC.format(account_id=account.id)\n        response = Request(account.client, 'get', resource, params=params).perform()\n        return response.body['data']", "response": "Pulls a list of metrics for a specified set of object IDs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nqueuing a list of metrics for a specified set of object IDs asynchronously", "response": "def queue_async_stats_job(klass, account, ids, metric_groups, **kwargs):\n        \"\"\"\n        Queues a list of metrics for a specified set of object IDs asynchronously\n        \"\"\"\n        params = klass._standard_params(ids, metric_groups, **kwargs)\n\n        params['platform'] = kwargs.get('platform', None)\n        params['country'] = kwargs.get('country', None)\n        params['segmentation_type'] = kwargs.get('segmentation_type', None)\n\n        resource = klass.RESOURCE_ASYNC.format(account_id=account.id)\n        response = Request(account.client, 'post', resource, params=params).perform()\n        return response.body['data']"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the results of the specified async job IDs", "response": "def async_stats_job_result(klass, account, job_id, **kwargs):\n        \"\"\"\n        Returns the results of the specified async job IDs\n        \"\"\"\n        params = {\n            'job_ids': job_id\n        }\n\n        resource = klass.RESOURCE_ASYNC.format(account_id=account.id)\n        response = Request(account.client, 'get', resource, params=params).perform()\n\n        return response.body['data'][0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the results of the specified async job IDs", "response": "def async_stats_job_data(klass, account, url, **kwargs):\n        \"\"\"\n        Returns the results of the specified async job IDs\n        \"\"\"\n        resource = urlparse(url)\n        domain = '{0}://{1}'.format(resource.scheme, resource.netloc)\n\n        response = Request(account.client, 'get', resource.path, domain=domain,\n                           raw_body=True, stream=True).perform()\n\n        return response.body"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new tailored audience.", "response": "def create(klass, account, name):\n        \"\"\"\n        Creates a new tailored audience.\n        \"\"\"\n        audience = klass(account)\n        getattr(audience, '__create_audience__')(name)\n        try:\n            return audience.reload()\n        except BadRequest as e:\n            audience.delete()\n            raise e"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef users(self, params):\n        resource = self.RESOURCE_USERS.format(account_id=self.account.id, id=self.id)\n        headers = {'Content-Type': 'application/json'}\n        response = Request(self.account.client,\n                           'post',\n                           resource,\n                           headers=headers,\n                           body=json.dumps(params)).perform()\n        success_count = response.body['data']['success_count']\n        total_count = response.body['data']['total_count']\n        return (success_count, total_count)", "response": "This endpoint allows partners to add update and remove users from a given tailored audience id."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a collection of all permissions for the tailored audience.", "response": "def permissions(self, **kwargs):\n        \"\"\"\n        Returns a collection of permissions for the curent tailored audience.\n        \"\"\"\n        self._validate_loaded()\n        return TailoredAudiencePermission.all(self.account, self.id, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef all(klass, account, tailored_audience_id, **kwargs):\n\n        resource = klass.RESOURCE_COLLECTION.format(\n            account_id=account.id,\n            tailored_audience_id=tailored_audience_id)\n        request = Request(account.client, 'get', resource, params=kwargs)\n\n        return Cursor(klass, request, init_with=[account])", "response": "Returns a Cursor instance for the given tailored audience permission resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave or updates the current tailored audience permission.", "response": "def save(self):\n        \"\"\"\n        Saves or updates the current tailored audience permission.\n        \"\"\"\n        if self.id:\n            method = 'put'\n            resource = self.RESOURCE.format(\n                account_id=self.account.id,\n                tailored_audience_id=self.tailored_audience_id,\n                id=self.id)\n        else:\n            method = 'post'\n            resource = self.RESOURCE_COLLECTION.format(\n                account_id=self.account.id,\n                tailored_audience_id=self.tailored_audience_id)\n\n        response = Request(\n            self.account.client, method,\n            resource, params=self.to_params()).perform()\n\n        return self.from_response(response.body['data'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete the current tailored audience permission.", "response": "def delete(self):\n        \"\"\"\n        Deletes the current tailored audience permission.\n        \"\"\"\n        resource = self.RESOURCE.format(\n            account_id=self.account.id,\n            tailored_audience_id=self.tailored_audience_id,\n            id=self.id)\n        response = Request(self.account.client, 'delete', resource).perform()\n        return self.from_response(response.body['data'])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef conversations(self):\n        body = {\n            \"conversation_type\": self.conversation_type,\n            \"audience_definition\": self.audience_definition,\n            \"targeting_inputs\": self.targeting_inputs\n        }\n        return self.__get(account=self.account, client=self.account.client, params=json.dumps(body))", "response": "Get the conversations for an input targeting criteria"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the demographic breakdown for an input targeting criteria", "response": "def demographics(self):\n        \"\"\"\n        Get the demographic breakdown for an input targeting criteria\n        \"\"\"\n        body = {\n            \"audience_definition\": self.audience_definition,\n            \"targeting_inputs\": self.targeting_inputs\n        }\n        resource = self.RESOURCE_DEMOGRAPHICS.format(account_id=self.account.id)\n        response = Request(\n            self.account.client, self.METHOD,\n            resource, headers=self.HEADERS, body=json.dumps(body)).perform()\n        return response.body['data']"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setupEnvironment(self, cmd):\n        shell.ShellCommand.setupEnvironment(self, cmd)\n        env = {}\n        for k, v in self.build.getProperties().properties.items():\n            env[str(k)] = str(v[0])\n        if cmd.args['env'] is None:\n            cmd.args['env'] = {}\n        cmd.args['env'].update(env)", "response": "Turn all build properties into environment variables"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the common test harnesses and update the stats of the common test harnesses.", "response": "def updateStats(self, log):\n        \"\"\"\n        Parse test results out of common test harnesses.\n\n        Currently supported are:\n\n         * Plone\n         * Nose\n         * Trial\n         * Something mitchell wrote in Java\n        \"\"\"\n        stdio = log.getText()\n\n        total = passed = skipped = fails = warnings = errors = 0\n        hastests = False\n\n        # Plone? That has lines starting \"Ran\" and \"Total\". Total is missing if there is only a single layer.\n        # For this reason, we total ourselves which lets us work even if someone runes 2 batches of plone tests\n        # from a single target\n\n        # Example::\n        #     Ran 24 tests with 0 failures and 0 errors in 0.009 seconds\n\n        if not hastests:\n            outputs = re.findall(\n                \"Ran (?P<count>[\\d]+) tests with (?P<fail>[\\d]+) failures and (?P<error>[\\d]+) errors\",\n                stdio)\n            for output in outputs:\n                total += int(output[0])\n                fails += int(output[1])\n                errors += int(output[2])\n                hastests = True\n\n        # Twisted\n\n        # Example::\n        #    FAILED (errors=5, successes=11)\n        #    PASSED (successes=16)\n        if not hastests:\n            for line in stdio.split(\"\\n\"):\n                if line.startswith(\"FAILED (\") or line.startswith(\"PASSED (\"):\n                    hastests = True\n\n                    line = line[8:][:-1]\n                    stats = line.split(\", \")\n                    data = {}\n\n                    for stat in stats:\n                        k, v = stat.split(\"=\")\n                        data[k] = int(v)\n\n                    if \"successes\" not in data:\n                        total = 0\n                        for number in re.findall(\n                                \"Ran (?P<count>[\\d]+) tests in \", stdio):\n                            total += int(number)\n                        data[\"successes\"] = total - sum(data.values())\n\n        # This matches Nose and Django output\n\n        # Example::\n        #     Ran 424 tests in 152.927s\n        #     FAILED (failures=1)\n        #     FAILED (errors=3)\n\n        if not hastests:\n            fails += len(re.findall('FAIL:', stdio))\n            errors += len(\n                re.findall(\n                    '======================================================================\\nERROR:',\n                    stdio))\n            for number in re.findall(\"Ran (?P<count>[\\d]+)\", stdio):\n                total += int(number)\n                hastests = True\n\n        # We work out passed at the end because most test runners dont tell us\n        # and we can't distinguish between different test systems easily so we\n        # might double count.\n        passed = total - (skipped + fails + errors + warnings)\n\n        # Update the step statistics with out shiny new totals\n        if hastests:\n            self.setStatistic('total', total)\n            self.setStatistic('fails', fails)\n            self.setStatistic('errors', errors)\n            self.setStatistic('warnings', warnings)\n            self.setStatistic('skipped', skipped)\n            self.setStatistic('passed', passed)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute the anti_alias operation steps times on the given map_in", "response": "def anti_alias(map_in, steps):\n    \"\"\"\n    Execute the anti_alias operation steps times on the given map\n    \"\"\"\n\n    height, width = map_in.shape\n\n    map_part = (2.0/11.0)*map_in\n\n    # notice how [-1/sqrt(3), -1/sqrt(3), -1/sqrt(3)] * [-1/sqrt(3), -1/sqrt(3), -1/sqrt(3)]^T\n    # equals [[1/3, 1/3, 1/3], [1/3, 1/3, 1/3], [1/3, 1/3, 1/3]]\n    # multiply that by (3/11) and we have the 2d kernel from the example above\n    # therefore the kernel is seperable\n\n    w = -1.0/numpy.sqrt(3.0)\n    kernel = [w, w, w]\n\n    def _anti_alias_step(original):\n\n        # cf. comments above fo the factor\n        # this also makes a copy which might actually be superfluous\n        result = original * (3.0/11.0)\n\n        # we need to handle boundary conditions by hand, unfortunately\n        # there might be a better way but this works (circular boundary)\n        # notice how we'll need to add 2 to width and height later \n        # because of this\n        result = numpy.append(result, [result[0,:]], 0)\n        result = numpy.append(result, numpy.transpose([result[:,0]]), 1)\n\n        result = numpy.insert(result, [0], [result[-2,:]],0)\n        result = numpy.insert(result, [0], numpy.transpose([result[:,-2]]), 1)\n\n        # with a seperable kernel we can convolve the rows first ...\n        for y in range(height+2):\n            result[y,1:-1] = numpy.convolve(result[y,:], kernel, 'valid')\n\n        # ... and then the columns\n        for x in range(width+2):\n            result[1:-1,x] = numpy.convolve(result[:,x], kernel, 'valid')\n\n        # throw away invalid values at the boundary\n        result = result[1:-1,1:-1]\n\n        result += map_part\n\n        return result\n\n    current = map_in\n    for i in range(steps):\n        current = _anti_alias_step(current)\n    return current"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef count_neighbours(mask, radius=1):\n    '''Count how many neighbours of a coordinate are set to one.\n    This uses the same principles as anti_alias, compare comments there.'''\n\n    height, width = mask.shape\n\n    f = 2.0*radius+1.0\n\n    w = -1.0/numpy.sqrt(f)\n    kernel = [w]*radius + [w] + [w]*radius\n\n    result = mask * f\n\n    for y in range(height):\n        result[y,:]  = numpy.convolve(result[y,:], kernel, 'same')\n\n    for x in range(width):\n        result[:,x] = numpy.convolve(result[:, x], kernel, 'same')\n\n    return result - mask", "response": "Count how many neighbours of a coordinate are set to one."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the random values for the current system and return them.", "response": "def _calculate(world, seed, elevation, mountain_level):\n        width = world.width\n        height = world.height\n\n        rng = numpy.random.RandomState(seed)  # create our own random generator\n        base = rng.randint(0, 4096)\n        temp = numpy.zeros((height, width), dtype=float)\n\n        '''\n        Set up variables to take care of some orbital parameters:\n         distance_to_sun: -Earth-like planet = 1.0\n                          -valid range between ~0.7 and ~1.3\n                                see https://en.wikipedia.org/wiki/Circumstellar_habitable_zone\n                          -random value chosen via Gaussian distribution\n                                see https://en.wikipedia.org/wiki/Gaussian_function\n                          -width of distribution around 1.0 is determined by HWHM (half width at half maximum)\n                          -HWHM is used to calculate the second parameter passed to random.gauss():\n                                sigma = HWHM / sqrt(2*ln(2))\n                          -*only HWHM* should be considered a parameter here\n                          -most likely outcomes can be estimated:\n                                HWHM * sqrt(2*ln(10)) / sqrt(2*ln(2)) = HWHM * 1.822615728;\n                                e.g. for HWHM = 0.12: 0.78 < distance_to_sun < 1.22\n         axial_tilt:      -the world/planet may move around its star at an angle\n                                see https://en.wikipedia.org/wiki/Axial_tilt\n                          -a value of 0.5 here would refer to an angle of 90 degrees, Uranus-style\n                                see https://en.wikipedia.org/wiki/Uranus\n                          -this value should usually be in the range -0.15 < axial_tilt < 0.15 for a habitable planet\n        '''\n        distance_to_sun_hwhm = 0.12\n        axial_tilt_hwhm = 0.07\n\n        #derive parameters\n        distance_to_sun = rng.normal(loc=1.0, scale=distance_to_sun_hwhm / 1.177410023)\n        distance_to_sun = max(0.1, distance_to_sun)  # clamp value; no planets inside the star allowed\n        distance_to_sun *= distance_to_sun  # prepare for later usage; use inverse-square law\n        # TODO: an atmoshphere would soften the effect of distance_to_sun by *some* factor\n        axial_tilt = rng.normal(scale=axial_tilt_hwhm / 1.177410023)\n        axial_tilt = min(max(-0.5, axial_tilt), 0.5)  # cut off Gaussian\n\n        border = width / 4\n        octaves = 8  # number of passes of snoise2\n        freq = 16.0 * octaves\n        n_scale = 1024 / float(height)\n\n        for y in range(0, height):  # TODO: Check for possible numpy optimizations.\n            y_scaled = float(y) / height - 0.5  # -0.5...0.5\n\n            #map/linearly interpolate y_scaled to latitude measured from where the most sunlight hits the world:\n            #1.0 = hottest zone, 0.0 = coldest zone\n            latitude_factor = numpy.interp(y_scaled, [axial_tilt - 0.5, axial_tilt, axial_tilt + 0.5],\n                                           [0.0, 1.0, 0.0], left=0.0, right=0.0)\n            for x in range(0, width):\n                n = snoise2((x * n_scale) / freq, (y * n_scale) / freq, octaves, base=base)\n\n                # Added to allow noise pattern to wrap around right and left.\n                if x <= border:\n                    n = (snoise2((x * n_scale) / freq, (y * n_scale) / freq, octaves,\n                                 base=base) * x / border) \\\n                        + (snoise2(((x * n_scale) + width) / freq, (y * n_scale) / freq, octaves,\n                                   base=base) * (border - x) / border)\n\n                t = (latitude_factor * 12 + n * 1) / 13.0 / distance_to_sun\n                if elevation[y, x] > mountain_level:  # vary temperature based on height\n                    if elevation[y, x] > (mountain_level + 29):\n                        altitude_factor = 0.033\n                    else:\n                        altitude_factor = 1.00 - (\n                            float(elevation[y, x] - mountain_level) / 30)\n                    t *= altitude_factor\n                temp[y, x] = t\n\n        return temp"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef index_of_nearest(p, hot_points, distance_f=distance):\n    min_dist = None\n    nearest_hp_i = None\n    for i, hp in enumerate(hot_points):\n        dist = distance_f(p, hp)\n        if min_dist is None or dist < min_dist:\n            min_dist = dist\n            nearest_hp_i = i\n    return nearest_hp_i", "response": "Given a point and a set of hot points find the index of the nearest hot point to the given point."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _calculate(seed, world):\n        rng = numpy.random.RandomState(seed)  # create our own random generator\n        base = rng.randint(0, 4096)\n\n        curve_gamma = world.gamma_curve\n        curve_bonus = world.curve_offset\n        height = world.height\n        width = world.width\n        border = width / 4\n        precipitations = numpy.zeros((height, width), dtype=float)\n\n        octaves = 6\n        freq = 64.0 * octaves\n\n        n_scale = 1024 / float(height) #This is a variable I am adding. It exists\n                                       #so that worlds sharing a common seed but\n                                       #different sizes will have similar patterns\n\n        for y in range(height):#TODO: numpy\n            for x in range(width):\n                n = snoise2((x * n_scale) / freq, (y * n_scale) / freq, octaves, base=base)\n\n                # Added to allow noise pattern to wrap around right and left.\n                if x < border:\n                    n = (snoise2( (x * n_scale) / freq, (y * n_scale) / freq, octaves,\n                                 base=base) * x / border) + (\n                        snoise2(( (x * n_scale) + width) / freq, (y * n_scale) / freq, octaves,\n                                base=base) * (border - x) / border)\n\n                precipitations[y, x] = n\n\n        #find ranges\n        min_precip = precipitations.min()\n        max_precip = precipitations.max()\n        min_temp = world.layers['temperature'].min()\n        max_temp = world.layers['temperature'].max()\n        precip_delta = (max_precip - min_precip)\n        temp_delta = (max_temp - min_temp)\n        \n        #normalize temperature and precipitation arrays\n        t = (world.layers['temperature'].data - min_temp) / temp_delta\n        p = (precipitations - min_precip) / precip_delta\n        \n        #modify precipitation based on temperature\n\n        #--------------------------------------------------------------------------------\n        #\n        # Ok, some explanation here because why the formula is doing this may be a\n        # little confusing. We are going to generate a modified gamma curve based on \n        # normalized temperature and multiply our precipitation amounts by it.\n        #\n        # numpy.power(t,curve_gamma) generates a standard gamma curve. However\n        # we probably don't want to be multiplying precipitation by 0 at the far\n        # side of the curve. To avoid this we multiply the curve by (1 - curve_bonus)\n        # and then add back curve_bonus. Thus, if we have a curve bonus of .2 then\n        # the range of our modified gamma curve goes from 0-1 to 0-.8 after we\n        # multiply and then to .2-1 after we add back the curve_bonus.\n        #\n        # Because we renormalize there is not much point to offsetting the opposite end\n        # of the curve so it is less than or more than 1. We are trying to avoid\n        # setting the start of the curve to 0 because f(t) * p would equal 0 when t equals\n        # 0. However f(t) * p does not automatically equal 1 when t equals 1 and if we\n        # raise or lower the value for f(t) at 1 it would have negligible impact after\n        # renormalizing.\n        #\n        #--------------------------------------------------------------------------------\n        \n        curve = (numpy.power(t, curve_gamma) * (1-curve_bonus)) + curve_bonus\n        precipitations = numpy.multiply(p, curve)\n\n        #Renormalize precipitation because the precipitation \n        #changes will probably not fully extend from -1 to 1.\n        min_precip = precipitations.min()\n        max_precip = precipitations.max()\n        precip_delta = (max_precip - min_precip)\n        precipitations = (((precipitations - min_precip) / precip_delta) * 2) - 1\n        \n        return precipitations", "response": "Calculate the precipitation for a specific entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an empty image according to the specified dimensions.", "response": "def from_dimensions(cls, width, height, channels, filename=None,\r\n                        grayscale=False, channel_bitdepth=8,\r\n                        has_alpha=False, palette=None):\r\n        \"\"\"\r\n        Creates an empty image according to width, height and channels.\r\n        Channels must be 1 (grayscale/palette), 2 (LA), 3 (RGB) or 4 (RGBA).\r\n        The image will be filled with black, transparent pixels.\r\n        \"\"\"\r\n        assert 1 <= channels <= 4, \"PNG only supports 1 to 4 channels per pixel. Error writing %s.\" % filename\r\n\r\n        dimensions = (height, width, channels)\r\n        if channels == 1:\r\n            dimensions = (height, width)  # keep the array 2-dimensional when possible\r\n\r\n        _array = numpy.zeros(dimensions, dtype=PNGWriter.get_dtype(channel_bitdepth))\r\n        return cls(_array, filename,\r\n                   grayscale=grayscale, channel_bitdepth=channel_bitdepth,\r\n                   has_alpha=has_alpha, palette=palette, channels=channels)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an image from a 3 - dimensional array.", "response": "def from_array(cls, array, filename=None, channels=3, scale_to_range=False,\r\n                   grayscale=False, channel_bitdepth=8,\r\n                   has_alpha=False, palette=None):\r\n        \"\"\"\r\n        Creates an image by using a provided array. The array may be ready to\r\n        be written or still need fine-tuning via set_pixel().\r\n        The array should not have more than 3 dimensions or the output might be\r\n        unexpected.\r\n        \"\"\"\r\n        if scale_to_range:\r\n            amax = array.max()\r\n            amin = array.min()\r\n            _array = (2**channel_bitdepth - 1) * (array - amin) / (amax - amin)\r\n        else:\r\n            _array = array\r\n        _array = numpy.rint(_array).astype(dtype=PNGWriter.get_dtype(channel_bitdepth))  # proper rounding\r\n        return cls(_array, filename, channels=channels,\r\n                   grayscale=grayscale, channel_bitdepth=channel_bitdepth,\r\n                   has_alpha=has_alpha, palette=palette)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_pixel(self, x, y, color):\r\n        try:  # these checks are for convenience, not for safety\r\n            if len(color) < self.channels:  # color is a a tuple (length >= 1)\r\n                if len(color) == 1:\r\n                    if self.channels == 2:\r\n                        color = [color[0], 255]\r\n                    elif self.channels == 3:\r\n                        color = [color[0], color[0], color[0]]\r\n                    elif self.channels == 4:\r\n                        color = [color[0], color[0], color[0], 255]\r\n                elif len(color) == 2:\r\n                    if self.channels == 3:\r\n                        color = [color[0], color[1], 0]\r\n                    elif self.channels == 4:\r\n                        color = [color[0], color[1], 0, 255]\r\n                elif len(color) == 3:\r\n                    if self.channels == 4:\r\n                        color = [color[0], color[1], color[2], 255]\r\n        except TypeError:  # color is not an iterable\r\n            if self.channels > 1:\r\n                if self.channels == 2:\r\n                    color = [color, 255]\r\n                elif self.channels == 3:\r\n                    color = [color, color, color]\r\n                else:  # only values 1..4 are allowed\r\n                    color = [color, color, color, 255]\r\n        self.array[y, x] = color", "response": "Set the color of the image at the given coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _elevation_color(elevation, sea_level=1.0):\n    color_step = 1.5\n    if sea_level is None:\n        sea_level = -1\n    if elevation < sea_level/2:\n        elevation /= sea_level\n        return 0.0, 0.0, 0.75 + 0.5 * elevation\n    elif elevation < sea_level:\n        elevation /= sea_level\n        return 0.0, 2 * (elevation - 0.5), 1.0\n    else:\n        elevation -= sea_level\n        if elevation < 1.0 * color_step:\n            return (0.0, 0.5 +\n                    0.5 * elevation / color_step, 0.0)\n        elif elevation < 1.5 * color_step:\n            return 2 * (elevation - 1.0 * color_step) / color_step, 1.0, 0.0\n        elif elevation < 2.0 * color_step:\n            return 1.0, 1.0 - (elevation - 1.5 * color_step) / color_step, 0\n        elif elevation < 3.0 * color_step:\n            return (1.0 - 0.5 * (elevation - 2.0 *\n                                 color_step) / color_step,\n                    0.5 - 0.25 * (elevation - 2.0 *\n                                  color_step) / color_step, 0)\n        elif elevation < 5.0 * color_step:\n            return (0.5 - 0.125 * (elevation - 3.0 *\n                                   color_step) / (2 * color_step),\n                    0.25 + 0.125 * (elevation - 3.0 *\n                                    color_step) / (2 * color_step),\n                    0.375 * (elevation - 3.0 *\n                             color_step) / (2 * color_step))\n        elif elevation < 8.0 * color_step:\n            return (0.375 + 0.625 * (elevation - 5.0 *\n                                     color_step) / (3 * color_step),\n                    0.375 + 0.625 * (elevation - 5.0 *\n                                     color_step) / (3 * color_step),\n                    0.375 + 0.625 * (elevation - 5.0 *\n                                     color_step) / (3 * color_step))\n        else:\n            elevation -= 8.0 * color_step\n            while elevation > 2.0 * color_step:\n                elevation -= 2.0 * color_step\n            return 1, 1 - elevation / 4.0, 1", "response": "Calculate color based on elevation"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_colors(*args):\n    ''' Do some *args magic to return a tuple, which has the sums of all tuples in *args '''\n    # Adapted from an answer here: http://stackoverflow.com/questions/14180866/sum-each-value-in-a-list-of-tuples\n    added = [sum(x) for x in zip(*args)]\n    return numpy.clip(added, 0, 255)", "response": "Add colors to the last tuple in the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef average_colors(c1, c2):\n    ''' Average the values of two colors together '''\n    r = int((c1[0] + c2[0])/2)\n    g = int((c1[1] + c2[1])/2)\n    b = int((c1[2] + c2[2])/2)\n\n    return (r, g, b)", "response": "Average the values of two colors together"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_normalized_elevation_array(world):\n    ''' Convert raw elevation into normalized values between 0 and 255,\n        and return a numpy array of these values '''\n\n    e = world.layers['elevation'].data\n    ocean = world.layers['ocean'].data\n\n    mask = numpy.ma.array(e, mask=ocean)  # only land\n    min_elev_land = mask.min()\n    max_elev_land = mask.max()\n    elev_delta_land = max_elev_land - min_elev_land\n\n    mask = numpy.ma.array(e, mask=numpy.logical_not(ocean))  # only ocean\n    min_elev_sea = mask.min()\n    max_elev_sea = mask.max()\n    elev_delta_sea = max_elev_sea - min_elev_sea\n\n    c = numpy.empty(e.shape, dtype=numpy.float)\n    c[numpy.invert(ocean)] = (e[numpy.invert(ocean)] - min_elev_land) * 127 / elev_delta_land + 128\n    c[ocean] = (e[ocean] - min_elev_sea) * 127 / elev_delta_sea\n    c = numpy.rint(c).astype(dtype=numpy.int32)  # proper rounding\n\n    return c", "response": "Convert raw elevation into normalized values between 0 and 255 and\n        and return a numpy array of these values"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_biome_color_based_on_elevation(world, elev, x, y, rng):\n    ''' This is the \"business logic\" for determining the base biome color in satellite view.\n        This includes generating some \"noise\" at each spot in a pixel's rgb value, potentially \n        modifying the noise based on elevation, and finally incorporating this with the base biome color. \n\n        The basic rules regarding noise generation are:\n        - Oceans have no noise added\n        - land tiles start with noise somewhere inside (-NOISE_RANGE, NOISE_RANGE) for each rgb value\n        - land tiles with high elevations further modify the noise by set amounts (to drain some of the \n          color and make the map look more like mountains) \n\n        The biome's base color may be interpolated with a predefined mountain brown color if the elevation is high enough.\n\n        Finally, the noise plus the biome color are added and returned.\n\n        rng refers to an instance of a random number generator used to draw the random samples needed by this function.\n    '''\n    v = world.biome_at((x, y)).name()\n    biome_color = _biome_satellite_colors[v]\n\n    # Default is no noise - will be overwritten if this tile is land\n    noise = (0, 0, 0)\n\n    if world.is_land((x, y)):\n        ## Generate some random noise to apply to this pixel\n        #  There is noise for each element of the rgb value\n        #  This noise will be further modified by the height of this tile\n\n        noise = rng.randint(-NOISE_RANGE, NOISE_RANGE, size=3)  # draw three random numbers at once\n\n        ####### Case 1 - elevation is very high ########\n        if elev > HIGH_MOUNTAIN_ELEV:     \n            # Modify the noise to make the area slightly brighter to simulate snow-topped mountains.\n            noise = add_colors(noise, HIGH_MOUNTAIN_NOISE_MODIFIER)\n            # Average the biome's color with the MOUNTAIN_COLOR to tint the terrain\n            biome_color = average_colors(biome_color, MOUNTAIN_COLOR)\n\n        ####### Case 2 - elevation is high ########\n        elif elev > MOUNTAIN_ELEV:   \n            # Modify the noise to make this tile slightly darker, especially draining the green\n            noise = add_colors(noise, MOUNTAIN_NOISE_MODIFIER)\n            # Average the biome's color with the MOUNTAIN_COLOR to tint the terrain\n            biome_color = average_colors(biome_color, MOUNTAIN_COLOR)\n\n        ####### Case 3 - elevation is somewhat high ########\n        elif elev > HIGH_HILL_ELEV:   \n            noise = add_colors(noise, HIGH_HILL_NOISE_MODIFIER)\n\n        ####### Case 4 - elevation is a little bit high ########\n        elif elev > HILL_ELEV:   \n            noise = add_colors(noise, HILL_NOISE_MODIFIER)\n\n    # There is also a minor base modifier to the pixel's rgb value based on height\n    modification_amount = int(elev / BASE_ELEVATION_INTENSITY_MODIFIER)\n    base_elevation_modifier = (modification_amount, modification_amount, modification_amount)\n\n    this_tile_color = add_colors(biome_color, noise, base_elevation_modifier)\n    return this_tile_color", "response": "This function calculates the base biome color based on an elevation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef draw_satellite(world, target):\n    ''' This draws a \"satellite map\" - a view of the generated planet as it may look from space '''\n\n    # Get an elevation mask where heights are normalized between 0 and 255\n    elevation_mask = get_normalized_elevation_array(world)\n    smooth_mask = numpy.invert(world.layers['ocean'].data)  # all land shall be smoothed (other tiles can be included by setting them to True)\n\n    rng = numpy.random.RandomState(world.seed)  # create our own random generator; necessary for now to make the tests reproducible, even though it is a bit ugly\n\n    ## The first loop sets each pixel's color based on colors defined in _biome_satellite_colors\n    #  and additional \"business logic\" defined in get_biome_color_based_on_elevation\n    for y in range(world.height):\n        for x in range(world.width):\n            # Get the normalized elevation at this pixel\n            elev = elevation_mask[y, x]\n            \n            # Get a rgb noise value, with some logic to modify it based on the elevation of the tile\n            r, g, b = get_biome_color_based_on_elevation(world, elev, x, y, rng)\n\n            # Set pixel to this color. This initial color will be accessed and modified later when \n            # the map is smoothed and shaded.\n            target.set_pixel(x, y, (r, g, b, 255))\n\n    # Paint frozen areas.\n    ice_color_variation = int(30)  # 0 means perfectly white ice; must be in [0, 255]; only affects R- and G-channel\n    for y in range(world.height):\n        for x in range(world.width):\n            if world.layers['icecap'].data[y, x] > 0.0:\n                smooth_mask[y, x] = True  # smooth the frozen areas, too\n                variation = rng.randint(0, ice_color_variation)\n                target.set_pixel(x, y, (255 - ice_color_variation + variation, 255 - ice_color_variation + variation, 255, 255))\n\n    # Loop through and average a pixel with its neighbors to smooth transitions between biomes\n    for y in range(1, world.height-1):\n        for x in range(1, world.width-1):\n            ## Only smooth land tiles\n            if smooth_mask[y, x]:\n                # Lists to hold the separated rgb values of the neighboring pixels\n                all_r = []\n                all_g = []\n                all_b = []\n\n                # Loop through this pixel and all neighboring pixels\n                for j in range(y-1, y+2):\n                    for i in range(x-1, x+2):\n                        # Don't include ocean in the smoothing, if this tile happens to border an ocean\n                        if smooth_mask[j, i]:\n                            # Grab each rgb value and append to the list\n                            r, g, b, a = target[j, i]\n                            all_r.append(r)\n                            all_g.append(g)\n                            all_b.append(b)\n\n                # Making sure there is at least one valid tile to be smoothed before we attempt to average the values\n                if len(all_r) > 0:\n                    avg_r = int(sum(all_r) / len(all_r))\n                    avg_g = int(sum(all_g) / len(all_g))\n                    avg_b = int(sum(all_b) / len(all_b))\n\n                    ## Setting color of the pixel again - this will be once more modified by the shading algorithm\n                    target.set_pixel(x, y, (avg_r, avg_g, avg_b, 255))\n\n    ## After smoothing, draw rivers\n    for y in range(world.height):\n        for x in range(world.width):\n            ## Color rivers\n            if world.is_land((x, y)) and (world.layers['river_map'].data[y, x] > 0.0):\n                base_color = target[y, x]\n\n                r, g, b = add_colors(base_color, RIVER_COLOR_CHANGE)\n                target.set_pixel(x, y, (r, g, b, 255))\n\n            ## Color lakes\n            if world.is_land((x, y)) and (world.layers['lake_map'].data[y, x] != 0):\n                base_color = target[y, x]\n\n                r, g, b = add_colors(base_color, LAKE_COLOR_CHANGE)\n                target.set_pixel(x, y, (r, g, b, 255))\n\n    # \"Shade\" the map by sending beams of light west to east, and increasing or decreasing value of pixel based on elevation difference\n    for y in range(SAT_SHADOW_SIZE-1, world.height-SAT_SHADOW_SIZE-1):\n        for x in range(SAT_SHADOW_SIZE-1, world.width-SAT_SHADOW_SIZE-1):\n            if world.is_land((x, y)):\n                r, g, b, a = target[y, x]\n                \n                # Build up list of elevations in the previous n tiles, where n is the shadow size.\n                # This goes northwest to southeast\n                prev_elevs = [ world.layers['elevation'].data[y-n, x-n] for n in range(1, SAT_SHADOW_SIZE+1) ]\n\n                # Take the average of the height of the previous n tiles\n                avg_prev_elev = int( sum(prev_elevs) / len(prev_elevs) )\n\n                # Find the difference between this tile's elevation, and the average of the previous elevations\n                difference = int(world.layers['elevation'].data[y, x] - avg_prev_elev)\n\n                # Amplify the difference\n                adjusted_difference = difference * SAT_SHADOW_DISTANCE_MULTIPLIER\n\n                # The amplified difference is now translated into the rgb of the tile.\n                # This adds light to tiles higher that the previous average, and shadow\n                # to tiles lower than the previous average\n                r = numpy.clip(adjusted_difference + r, 0, 255)  # prevent under-/overflows\n                g = numpy.clip(adjusted_difference + g, 0, 255)\n                b = numpy.clip(adjusted_difference + b, 0, 255)\n\n                # Set the final color for this pixel\n                target.set_pixel(x, y, (r, g, b, 255))", "response": "This function draws a satellite map from the world."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the flow direction for each cell in heightmap", "response": "def find_water_flow(self, world, water_path):\n        \"\"\"Find the flow direction for each cell in heightmap\"\"\"\n\n        # iterate through each cell\n        for x in range(world.width - 1):\n            for y in range(world.height - 1):\n                # search around cell for a direction\n                path = self.find_quick_path([x, y], world)\n                if path:\n                    tx, ty = path\n                    flow_dir = [tx - x, ty - y]\n                    key = 0\n                    for direction in DIR_NEIGHBORS_CENTER:\n                        if direction == flow_dir:\n                            water_path[y, x] = key\n                        key += 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef river_sources(world, water_flow, water_path):\n        river_source_list = []\n\n        # Using the wind and rainfall data, create river 'seeds' by\n        #     flowing rainfall along paths until a 'flow' threshold is reached\n        #     and we have a beginning of a river... trickle->stream->river->sea\n\n        # step one: Using flow direction, follow the path for each cell\n        #     adding the previous cell's flow to the current cell's flow.\n        # step two: We loop through the water flow map looking for cells\n        #     above the water flow threshold. These are our river sources and\n        #     we mark them as rivers. While looking, the cells with no\n        #     out-going flow, above water flow threshold and are still\n        #     above sea level are marked as 'sources'.\n        for y in range(0, world.height - 1):\n            for x in range(0, world.width - 1):\n                rain_fall = world.layers['precipitation'].data[y, x]\n                water_flow[y, x] = rain_fall\n\n                if water_path[y, x] == 0:\n                    continue  # ignore cells without flow direction\n                cx, cy = x, y  # begin with starting location\n                neighbour_seed_found = False\n                # follow flow path to where it may lead\n                while not neighbour_seed_found:\n\n                    # have we found a seed?\n                    if world.is_mountain((cx, cy)) and water_flow[cy, cx] >= RIVER_TH:\n\n                        # try not to create seeds around other seeds\n                        for seed in river_source_list:\n                            sx, sy = seed\n                            if in_circle(9, cx, cy, sx, sy):\n                                neighbour_seed_found = True\n                        if neighbour_seed_found:\n                            break  # we do not want seeds for neighbors\n\n                        river_source_list.append([cx, cy])  # river seed\n                        break\n\n                    # no path means dead end...\n                    if water_path[cy, cx] == 0:\n                        break  # break out of loop\n\n                    # follow path, add water flow from previous cell\n                    dx, dy = DIR_NEIGHBORS_CENTER[water_path[cy, cx]]\n                    nx, ny = cx + dx, cy + dy  # calculate next cell\n                    water_flow[ny, nx] += rain_fall\n                    cx, cy = nx, ny  # set current cell to next cell\n        return river_source_list", "response": "Find places on map where sources of river can be found."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsimulating fluid dynamics by using starting point and flowing to the lowest available point", "response": "def river_flow(self, source, world, river_list, lake_list):\n        \"\"\"simulate fluid dynamics by using starting point and flowing to the\n        lowest available point\"\"\"\n        current_location = source\n        path = [source]\n\n        # start the flow\n        while True:\n            x, y = current_location\n\n            # is there a river nearby, flow into it\n            for dx, dy in DIR_NEIGHBORS:\n                ax, ay = x + dx, y + dy\n                if self.wrap:\n                    ax, ay = overflow(ax, world.width), overflow(ay,\n                                                                 world.height)\n\n                for river in river_list:\n                    if [ax, ay] in river:\n                        merge = False\n                        for rx, ry in river:\n                            if [ax, ay] == [rx, ry]:\n                                merge = True\n                                path.append([rx, ry])\n                            elif merge:\n                                path.append([rx, ry])\n                        return path  # skip the rest, return path\n\n            # found a sea?\n            if world.is_ocean((x, y)):\n                break\n\n            # find our immediate lowest elevation and flow there\n            quick_section = self.find_quick_path(current_location, world)\n\n            if quick_section:\n                path.append(quick_section)\n                current_location = quick_section\n                continue  # stop here and enter back into loop\n\n            is_wrapped, lower_elevation = self.findLowerElevation(\n                current_location, world)\n            if lower_elevation and not is_wrapped:\n                lower_path = worldengine.astar.PathFinder().find(\n                    world.layers['elevation'].data, current_location, lower_elevation)\n                if lower_path:\n                    path += lower_path\n                    current_location = path[-1]\n                else:\n                    break\n            elif lower_elevation and is_wrapped:\n                # TODO: make this more natural\n                max_radius = 40\n\n                cx, cy = current_location\n                lx, ly = lower_elevation\n\n                if x < 0 or y < 0 or x > world.width or y > world.height:\n                    raise Exception(\n                        \"BUG: fix me... we shouldn't be here: %s %s\" % (\n                            current_location, lower_elevation))\n\n                if not in_circle(max_radius, cx, cy, lx, cy):\n                    # are we wrapping on x axis?\n                    if cx - lx < 0:\n                        lx = 0  # move to left edge\n                        nx = world.width - 1  # next step is wrapped around\n                    else:\n                        lx = world.width - 1  # move to right edge\n                        nx = 0  # next step is wrapped around\n                    ly = ny = int((cy + ly) / 2)  # move halfway\n                elif not in_circle(max_radius, cx, cy, cx, ly):\n                    # are we wrapping on y axis?\n                    if cy - ly < 0:\n                        ly = 0  # move to top edge\n                        ny = world.height - 1  # next step is wrapped around\n                    else:\n                        ly = world.height - 1  # move to bottom edge\n                        ny = 0  # next step is wrapped around\n                    lx = nx = int((cx + lx) / 2)  # move halfway\n                else:\n                    raise Exception(\n                        \"BUG: fix me... we are not in circle: %s %s\" % (\n                            current_location, lower_elevation))\n\n                # find our way to the edge\n                edge_path = worldengine.astar.PathFinder().find(\n                    world.layers['elevation'].data, [cx, cy], [lx, ly])\n                if not edge_path:\n                    # can't find another other path, make it a lake\n                    lake_list.append(current_location)\n                    break\n                path += edge_path  # add our newly found path\n                path.append([nx, ny])  # finally add our overflow to other side\n                current_location = path[-1]\n\n                # find our way to lowest position original found\n                lower_path = worldengine.astar.PathFinder().find(\n                    world.layers['elevation'].data, current_location, lower_elevation)\n                path += lower_path\n                current_location = path[-1]\n\n            else:  # can't find any other path, make it a lake\n                lake_list.append(current_location)\n                break  # end of river\n\n            if not world.contains(current_location):\n                print(\"Why are we here:\", current_location)\n\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cleanUpFlow(self, river, world):\n        '''Validate that for each point in river is equal to or lower than the\n        last'''\n        celevation = 1.0\n        for r in river:\n            rx, ry = r\n            relevation = world.layers['elevation'].data[ry, rx]\n            if relevation <= celevation:\n                celevation = relevation\n            elif relevation > celevation:\n                world.layers['elevation'].data[ry, rx] = celevation\n        return river", "response": "Validate that for each point in river is equal to or lower than the\n        last"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntry to find a lower elevation with in a range of an increasing circle s radius and try to find a best path and return it", "response": "def findLowerElevation(self, source, world):\n        '''Try to find a lower elevation with in a range of an increasing\n        circle's radius and try to find the best path and return it'''\n        x, y = source\n        currentRadius = 1\n        maxRadius = 40\n        lowestElevation = world.layers['elevation'].data[y, x]\n        destination = []\n        notFound = True\n        isWrapped = False\n        wrapped = []\n\n        while notFound and currentRadius <= maxRadius:\n            for cx in range(-currentRadius, currentRadius + 1):\n                for cy in range(-currentRadius, currentRadius + 1):\n                    rx, ry = x + cx, y + cy\n\n                    # are we within bounds?\n                    if not self.wrap and not world.contains((rx, ry)):\n                        continue\n\n                    # are we within a circle?\n                    if not in_circle(currentRadius, x, y, rx, ry):\n                        continue\n\n                    rx, ry = overflow(rx, world.width), overflow(ry,\n                                                                 world.height)\n\n                    # if utilities.outOfBounds([x+cx, y+cy], self.size):\n                    #                        print \"Fixed:\",x ,y,  rx, ry\n\n                    elevation = world.layers['elevation'].data[ry, rx]\n                    # have we found a lower elevation?\n                    if elevation < lowestElevation:\n                        lowestElevation = elevation\n                        destination = [rx, ry]\n                        notFound = False\n                        if not world.contains((x + cx, y + cy)):\n                            wrapped.append(destination)\n\n            currentRadius += 1\n\n        if destination in wrapped:\n            isWrapped = True\n        # print \"Wrapped lower elevation found:\", rx, ry, \"!\"\n        return isWrapped, destination"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsimulating erosion around river.", "response": "def river_erosion(self, river, world):\n        \"\"\" Simulate erosion in heightmap based on river path.\n            * current location must be equal to or less than previous location\n            * riverbed is carved out by % of volume/flow\n            * sides of river are also eroded to slope into riverbed.\n        \"\"\"\n\n        # erosion around river, create river valley\n        for r in river:\n            rx, ry = r\n            radius = 2\n            for x in range(rx - radius, rx + radius):\n                for y in range(ry - radius, ry + radius):\n                    if not self.wrap and not world.contains(\n                            (x, y)):  # ignore edges of map\n                        continue\n                    x, y = overflow(x, world.width), overflow(y, world.height)\n                    curve = 1.0\n                    if [x, y] == [0, 0]:  # ignore center\n                        continue\n                    if [x, y] in river:  # ignore river itself\n                        continue\n                    if world.layers['elevation'].data[y, x] <= world.layers['elevation'].data[ry, rx]:\n                        # ignore areas lower than river itself\n                        continue\n                    if not in_circle(radius, rx, ry, x,\n                                     y):  # ignore things outside a circle\n                        continue\n\n                    adx, ady = math.fabs(rx - x), math.fabs(ry - y)\n                    if adx == 1 or ady == 1:\n                        curve = 0.2\n                    elif adx == 2 or ady == 2:\n                        curve = 0.05\n\n                    diff = world.layers['elevation'].data[ry, rx] - world.layers['elevation'].data[y, x]\n                    newElevation = world.layers['elevation'].data[y, x] + (\n                        diff * curve)\n                    if newElevation <= world.layers['elevation'].data[ry, rx]:\n                        print('newElevation is <= than river, fix me...')\n                        newElevation = world.layers['elevation'].data[r, x]\n                    world.layers['elevation'].data[y, x] = newElevation\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the rivermap with the rainfall that is to become the water flow", "response": "def rivermap_update(self, river, water_flow, rivermap, precipitations):\n        \"\"\"Update the rivermap with the rainfall that is to become\n        the waterflow\"\"\"\n\n        isSeed = True\n        px, py = (0, 0)\n        for x, y in river:\n            if isSeed:\n                rivermap[y, x] = water_flow[y, x]\n                isSeed = False\n            else:\n                rivermap[y, x] = precipitations[y, x] + rivermap[py, px]\n            px, py = x, y"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_plates(seed, world_name, output_dir, width, height,\n                    num_plates=10):\n    \"\"\"\n    Eventually this method should be invoked when generation is called at\n    asked to stop at step \"plates\", it should not be a different operation\n    :param seed:\n    :param world_name:\n    :param output_dir:\n    :param width:\n    :param height:\n    :param num_plates:\n    :return:\n    \"\"\"\n    elevation, plates = generate_plates_simulation(seed, width, height,\n                                                   num_plates=num_plates)\n\n    world = World(world_name, Size(width, height), seed,\n                  GenerationParameters(num_plates, -1.0, \"plates\"))\n    world.elevation = (numpy.array(elevation).reshape(height, width), None)\n    world.plates = numpy.array(plates, dtype=numpy.uint16).reshape(height, width)\n\n    # Generate images\n    filename = '%s/plates_%s.png' % (output_dir, world_name)\n    draw_simple_elevation_on_file(world, filename, None)\n    print(\"+ plates image generated in '%s'\" % filename)\n    geo.center_land(world)\n    filename = '%s/centered_plates_%s.png' % (output_dir, world_name)\n    draw_simple_elevation_on_file(world, filename, None)\n    print(\"+ centered plates image generated in '%s'\" % filename)", "response": "Generates a single - order - based random plates."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef draw_rivers_on_image(world, target, factor=1):\n\n    for y in range(world.height):\n        for x in range(world.width):\n            if world.is_land((x, y)) and (world.layers['river_map'].data[y, x] > 0.0):\n                for dx in range(factor):\n                    for dy in range(factor):\n                        target.set_pixel(x * factor + dx, y * factor + dy, (0, 0, 128, 255))\n            if world.is_land((x, y)) and (world.layers['lake_map'].data[y, x] != 0):\n                for dx in range(factor):\n                    for dy in range(factor):\n                        target.set_pixel(x * factor + dx, y * factor + dy, (0, 100, 128, 255))", "response": "Draw only the rivers on the image"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntranslates the map horizontally and vertically and put as much ocean as possible at the borders", "response": "def center_land(world):\n    \"\"\"Translate the map horizontally and vertically to put as much ocean as\n       possible at the borders. It operates on elevation and plates map\"\"\"\n\n    y_sums = world.layers['elevation'].data.sum(1)  # 1 == sum along x-axis\n    y_with_min_sum = y_sums.argmin()\n    if get_verbose():\n        print(\"geo.center_land: height complete\")\n\n    x_sums = world.layers['elevation'].data.sum(0)  # 0 == sum along y-axis\n    x_with_min_sum = x_sums.argmin()\n    if get_verbose():\n        print(\"geo.center_land: width complete\")\n\n    latshift = 0\n    world.layers['elevation'].data = numpy.roll(numpy.roll(world.layers['elevation'].data, -y_with_min_sum + latshift, axis=0), - x_with_min_sum, axis=1)\n    world.layers['plates'].data = numpy.roll(numpy.roll(world.layers['plates'].data, -y_with_min_sum + latshift, axis=0), - x_with_min_sum, axis=1)\n    if get_verbose():\n        print(\"geo.center_land: width complete\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplace oceans at the border of the map.", "response": "def place_oceans_at_map_borders(world):\n    \"\"\"\n    Lower the elevation near the border of the map\n    \"\"\"\n\n    ocean_border = int(min(30, max(world.width / 5, world.height / 5)))\n\n    def place_ocean(x, y, i):\n        world.layers['elevation'].data[y, x] = \\\n            (world.layers['elevation'].data[y, x] * i) / ocean_border\n\n    for x in range(world.width):\n        for i in range(ocean_border):\n            place_ocean(x, i, i)\n            place_ocean(x, world.height - i - 1, i)\n\n    for y in range(world.height):\n        for i in range(ocean_border):\n            place_ocean(i, y, i)\n            place_ocean(world.width - i - 1, y, i)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing the ocean depth and elevation thresholds for a single ocean layer.", "response": "def initialize_ocean_and_thresholds(world, ocean_level=1.0):\n    \"\"\"\n    Calculate the ocean, the sea depth and the elevation thresholds\n    :param world: a world having elevation but not thresholds\n    :param ocean_level: the elevation representing the ocean level\n    :return: nothing, the world will be changed\n    \"\"\"\n    e = world.layers['elevation'].data\n    ocean = fill_ocean(e, ocean_level)\n    hl = find_threshold_f(e, 0.10)  # the highest 10% of all (!) land are declared hills\n    ml = find_threshold_f(e, 0.03)  # the highest 3% are declared mountains\n    e_th = [('sea', ocean_level),\n            ('plain', hl),\n            ('hill', ml),\n            ('mountain', None)]\n    harmonize_ocean(ocean, e, ocean_level)\n    world.ocean = ocean\n    world.elevation = (e, e_th)\n    world.sea_depth = sea_depth(world, ocean_level)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef harmonize_ocean(ocean, elevation, ocean_level):\n\n    shallow_sea = ocean_level * 0.85\n    midpoint = shallow_sea / 2.0\n\n    ocean_points = numpy.logical_and(elevation < shallow_sea, ocean)\n\n    shallow_ocean = numpy.logical_and(elevation < midpoint, ocean_points)\n    elevation[shallow_ocean] = midpoint - ((midpoint - elevation[shallow_ocean]) / 5.0)\n\n    deep_ocean = numpy.logical_and(elevation > midpoint, ocean_points)\n    elevation[deep_ocean] = midpoint + ((elevation[deep_ocean] - midpoint) / 5.0)", "response": "This function harmonizes the ocean floor."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the version of the current version of the current version of the current version of the current version of the current version of the current version of the current version of the current version.", "response": "def get_version(\n    root=\".\",\n    version_scheme=\"guess-next-dev\",\n    local_scheme=\"node-and-date\",\n    write_to=None,\n    write_to_template=None,\n    relative_to=None,\n    tag_regex=None,\n    fallback_version=None,\n    parse=None,\n    git_describe_command=None,\n):\n    \"\"\"\n    If supplied, relative_to should be a file from which root may\n    be resolved. Typically called by a script or module that is not\n    in the root of the repository to direct setuptools_scm to the\n    root of the repository by supplying ``__file__``.\n    \"\"\"\n\n    config = Configuration()\n    config.root = root\n    config.version_scheme = version_scheme\n    config.local_scheme = local_scheme\n    config.write_to = write_to\n    config.write_to_template = write_to_template\n    config.relative_to = relative_to\n    config.tag_regex = tag_regex\n    config.fallback_version = fallback_version\n    config.parse = parse\n    config.git_describe_command = git_describe_command\n\n    parsed_version = _do_parse(config)\n\n    if parsed_version:\n        version_string = format_version(\n            parsed_version, version_scheme=version_scheme, local_scheme=local_scheme\n        )\n        dump_version(\n            root=root,\n            version=version_string,\n            write_to=write_to,\n            template=write_to_template,\n        )\n\n        return version_string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nensure that environment dictionaries are always strings.", "response": "def _always_strings(env_dict):\n    \"\"\"\n    On Windows and Python 2, environment dictionaries must be strings\n    and not unicode.\n    \"\"\"\n    if IS_WINDOWS or PY2:\n        env_dict.update((key, str(value)) for (key, value) in env_dict.items())\n    return env_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compat_stat(path):\n\tstat = os.stat(path)\n\tinfo = get_file_info(path)\n\t# rewrite st_ino, st_dev, and st_nlink based on file info\n\treturn nt.stat_result(\n\t\t(stat.st_mode,) +\n\t\t(info.file_index, info.volume_serial_number, info.number_of_links) +\n\t\tstat[4:]\n\t)", "response": "Generate stat as found on Python 3. 2 and later."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding all files in path and returns a set of all the scm controlled files and scm_dirs", "response": "def scm_find_files(path, scm_files, scm_dirs):\n    \"\"\" setuptools compatible file finder that follows symlinks\n\n    - path: the root directory from which to search\n    - scm_files: set of scm controlled files and symlinks\n      (including symlinks to directories)\n    - scm_dirs: set of scm controlled directories\n      (including directories containing no scm controlled files)\n\n    scm_files and scm_dirs must be absolute with symlinks resolved (realpath),\n    with normalized case (normcase)\n\n    Spec here: http://setuptools.readthedocs.io/en/latest/setuptools.html#\\\n        adding-support-for-revision-control-systems\n    \"\"\"\n    realpath = os.path.normcase(os.path.realpath(path))\n    seen = set()\n    res = []\n    for dirpath, dirnames, filenames in os.walk(realpath, followlinks=True):\n        # dirpath with symlinks resolved\n        realdirpath = os.path.normcase(os.path.realpath(dirpath))\n\n        def _link_not_in_scm(n):\n            fn = os.path.join(realdirpath, os.path.normcase(n))\n            return os.path.islink(fn) and fn not in scm_files\n\n        if realdirpath not in scm_dirs:\n            # directory not in scm, don't walk it's content\n            dirnames[:] = []\n            continue\n        if (\n            os.path.islink(dirpath)\n            and not os.path.relpath(realdirpath, realpath).startswith(os.pardir)\n        ):\n            # a symlink to a directory not outside path:\n            # we keep it in the result and don't walk its content\n            res.append(os.path.join(path, os.path.relpath(dirpath, path)))\n            dirnames[:] = []\n            continue\n        if realdirpath in seen:\n            # symlink loop protection\n            dirnames[:] = []\n            continue\n        dirnames[:] = [dn for dn in dirnames if not _link_not_in_scm(dn)]\n        for filename in filenames:\n            if _link_not_in_scm(filename):\n                continue\n            # dirpath + filename with symlinks preserved\n            fullfilename = os.path.join(dirpath, filename)\n            if os.path.normcase(os.path.realpath(fullfilename)) in scm_files:\n                res.append(os.path.join(path, os.path.relpath(fullfilename, path)))\n        seen.add(realdirpath)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a tree of objects into a single object.", "response": "def parse(\n    root, describe_command=DEFAULT_DESCRIBE, pre_parse=warn_on_shallow, config=None\n):\n    \"\"\"\n    :param pre_parse: experimental pre_parse action, may change at any time\n    \"\"\"\n    if not config:\n        config = Configuration(root=root)\n\n    if not has_command(\"git\"):\n        return\n\n    wd = GitWorkdir.from_potential_worktree(config.absolute_root)\n    if wd is None:\n        return\n    if pre_parse:\n        pre_parse(wd)\n\n    if config.git_describe_command:\n        describe_command = config.git_describe_command\n\n    out, unused_err, ret = wd.do_ex(describe_command)\n    if ret:\n        # If 'git git_describe_command' failed, try to get the information otherwise.\n        rev_node = wd.node()\n        dirty = wd.is_dirty()\n\n        if rev_node is None:\n            return meta(\"0.0\", distance=0, dirty=dirty, config=config)\n\n        return meta(\n            \"0.0\",\n            distance=wd.count_all_nodes(),\n            node=\"g\" + rev_node,\n            dirty=dirty,\n            branch=wd.get_branch(),\n            config=config,\n        )\n    else:\n        tag, number, node, dirty = _git_parse_describe(out)\n\n        branch = wd.get_branch()\n        if number:\n            return meta(\n                tag,\n                config=config,\n                distance=number,\n                node=node,\n                dirty=dirty,\n                branch=branch,\n            )\n        else:\n            return meta(tag, config=config, node=node, dirty=dirty, branch=branch)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tag_to_version(tag, config=None):\n    trace(\"tag\", tag)\n\n    if not config:\n        config = Configuration()\n\n    tagdict = _parse_version_tag(tag, config)\n    if not isinstance(tagdict, dict) or not tagdict.get(\"version\", None):\n        warnings.warn(\"tag %r no version found\" % (tag,))\n        return None\n\n    version = tagdict[\"version\"]\n    trace(\"version pre parse\", version)\n\n    if tagdict.get(\"suffix\", \"\"):\n        warnings.warn(\n            \"tag %r will be stripped of its suffix '%s'\" % (tag, tagdict[\"suffix\"])\n        )\n\n    if VERSION_CLASS is not None:\n        version = pkg_parse_version(version)\n        trace(\"version\", repr(version))\n\n    return version", "response": "take a tag that might be prefixed with a keyword and return only the version part\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake tags that might be prefixed with a keyword and return only the version part", "response": "def tags_to_versions(tags, config=None):\n    \"\"\"\n    take tags that might be prefixed with a keyword and return only the version part\n    :param tags: an iterable of tags\n    :param config: optional configuration object\n    \"\"\"\n    result = []\n    for tag in tags:\n        tag = tag_to_version(tag, config=config)\n        if tag:\n            result.append(tag)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a context with an open SQLAlchemy session.", "response": "def session(self):\n        \"\"\" Creates a context with an open SQLAlchemy session.\n        \"\"\"\n        engine = self.engine\n        connection = engine.connect()\n        db_session = scoped_session(\n            sessionmaker(autocommit=False, autoflush=True, bind=engine))\n        yield db_session\n        db_session.close()\n        connection.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a tuple of octal permissions for a given path.", "response": "def get_path_permission(path):\n    ''' on platforms that do not support symbolic links,\n    lstat is an alias for stat()\n    so we return a tuple of both\n    '''\n    lst = os.lstat(path)\n    st = os.stat(path)\n    permission = octal_permissions(lst.st_mode), octal_permissions(st.st_mode)\n    return permission"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _robust_rmtree(path, logger=None, max_retries=5):\n\n    for i in range(max_retries):\n        try:\n            shutil.rmtree(path)\n            return\n        except OSError as e:\n            if logger:\n                info('Unable to remove path: %s' % path)\n                info('Retrying after %d seconds' % i)\n            time.sleep(i)\n\n    # Final attempt, pass any Exceptions up to caller.\n    shutil.rmtree(path)", "response": "Try to delete paths robustly."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprepare a testing instance of Geoserver.", "response": "def setup_geoserver(options):\n    from geonode.settings import INSTALLED_APPS, OGC_SERVER\n    \"\"\"Prepare a testing instance of GeoServer.\"\"\"\n    # only start if using Geoserver backend\n    _backend = os.environ.get('BACKEND', OGC_SERVER['default']['BACKEND'])\n    if (_backend == 'geonode.qgis_server'\n            or 'geonode.geoserver' not in INSTALLED_APPS):\n        return\n\n    download_dir = path('downloaded')\n    if not download_dir.exists():\n        download_dir.makedirs()\n\n    geoserver_dir = path('geoserver')\n\n    geoserver_bin = download_dir / \\\n        os.path.basename(dev_config['GEOSERVER_URL'])\n    jetty_runner = download_dir / \\\n        os.path.basename(dev_config['JETTY_RUNNER_URL'])\n\n    grab(\n        options.get('geoserver', dev_config['GEOSERVER_URL']), geoserver_bin,\n        \"geoserver binary\")\n    grab(\n        options.get('jetty', dev_config['JETTY_RUNNER_URL']), jetty_runner,\n        \"jetty runner\")\n\n    if not geoserver_dir.exists():\n        geoserver_dir.makedirs()\n\n        webapp_dir = geoserver_dir / 'geoserver'\n        if not webapp_dir:\n            webapp_dir.makedirs()\n\n        print 'extracting geoserver'\n        z = zipfile.ZipFile(geoserver_bin, \"r\")\n        z.extractall(webapp_dir)\n\n    _install_data_dir()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart GeoServer with extensions", "response": "def start_geoserver(options):\n    \"\"\"\n    Start GeoServer with GeoNode extensions\n    \"\"\"\n    from geonode.settings import INSTALLED_APPS, OGC_SERVER\n    # only start if using Geoserver backend\n    _backend = os.environ.get('BACKEND', OGC_SERVER['default']['BACKEND'])\n    if (_backend == 'geonode.qgis_server'\n            or 'geonode.geoserver' not in INSTALLED_APPS):\n        return\n\n    GEOSERVER_BASE_URL = OGC_SERVER['default']['LOCATION']\n    url = GEOSERVER_BASE_URL\n\n    if urlparse(GEOSERVER_BASE_URL).hostname != 'localhost':\n        print \"Warning: OGC_SERVER['default']['LOCATION'] hostname is not equal to 'localhost'\"\n\n    if not GEOSERVER_BASE_URL.endswith('/'):\n        print \"Error: OGC_SERVER['default']['LOCATION'] does not end with a '/'\"\n        sys.exit(1)\n\n    download_dir = path('downloaded').abspath()\n    jetty_runner = download_dir / \\\n        os.path.basename(dev_config['JETTY_RUNNER_URL'])\n    data_dir = path('geoserver/data').abspath()\n    geofence_dir = path('geoserver/data/geofence').abspath()\n    web_app = path('geoserver/geoserver').abspath()\n    log_file = path('geoserver/jetty.log').abspath()\n    config = path('scripts/misc/jetty-runner.xml').abspath()\n    jetty_port = urlparse(GEOSERVER_BASE_URL).port\n\n    import socket\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    socket_free = True\n    try:\n        s.bind((\"127.0.0.1\", jetty_port))\n    except socket.error as e:\n        socket_free = False\n        if e.errno == 98:\n            info('Port %s is already in use' % jetty_port)\n        else:\n            info(\n                'Something else raised the socket.error exception while checking port %s'\n                % jetty_port)\n            print(e)\n    finally:\n        s.close()\n\n    if socket_free:\n        # @todo - we should not have set workdir to the datadir but a bug in geoserver\n        # prevents geonode security from initializing correctly otherwise\n        with pushd(data_dir):\n            javapath = \"java\"\n            loggernullpath = os.devnull\n\n            # checking if our loggernullpath exists and if not, reset it to\n            # something manageable\n            if loggernullpath == \"nul\":\n                try:\n                    open(\"../../downloaded/null.txt\", 'w+').close()\n                except IOError as e:\n                    print \"Chances are that you have Geoserver currently running.  You \\\n                            can either stop all servers with paver stop or start only \\\n                            the django application with paver start_django.\"\n\n                    sys.exit(1)\n                loggernullpath = \"../../downloaded/null.txt\"\n\n            try:\n                sh(('java -version'))\n            except BaseException:\n                print \"Java was not found in your path.  Trying some other options: \"\n                javapath_opt = None\n                if os.environ.get('JAVA_HOME', None):\n                    print \"Using the JAVA_HOME environment variable\"\n                    javapath_opt = os.path.join(\n                        os.path.abspath(os.environ['JAVA_HOME']), \"bin\",\n                        \"java.exe\")\n                elif options.get('java_path'):\n                    javapath_opt = options.get('java_path')\n                else:\n                    print \"Paver cannot find java in the Windows Environment.  \\\n                    Please provide the --java_path flag with your full path to \\\n                    java.exe e.g. --java_path=C:/path/to/java/bin/java.exe\"\n\n                    sys.exit(1)\n                # if there are spaces\n                javapath = 'START /B \"\" \"' + javapath_opt + '\"'\n\n            sh((\n                '%(javapath)s -Xms512m -Xmx2048m -server -XX:+UseConcMarkSweepGC -XX:MaxPermSize=512m'\n                ' -DGEOSERVER_DATA_DIR=%(data_dir)s'\n                ' -Dgeofence.dir=%(geofence_dir)s'\n                # ' -Dgeofence-ovr=geofence-datasource-ovr.properties'\n                # workaround for JAI sealed jar issue and jetty classloader\n                # ' -Dorg.eclipse.jetty.server.webapp.parentLoaderPriority=true'\n                ' -jar %(jetty_runner)s'\n                ' --port %(jetty_port)i'\n                ' --log %(log_file)s'\n                ' %(config)s'\n                ' > %(loggernullpath)s &' % locals()))\n\n        info('Starting GeoServer on %s' % url)\n\n    # wait for GeoServer to start\n    started = waitfor(url)\n    info('The logs are available at %s' % log_file)\n\n    if not started:\n        # If applications did not start in time we will give the user a chance\n        # to inspect them and stop them manually.\n        info(('GeoServer never started properly or timed out.'\n              'It may still be running in the background.'))\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstopping a proces that contains arg1 and is filtered by arg2 and returns a new version of the proces that contains arg1 and is filtered by arg2.", "response": "def kill(arg1, arg2):\n    \"\"\"Stops a proces that contains arg1 and is filtered by arg2\n    \"\"\"\n    from subprocess import Popen, PIPE\n\n    # Wait until ready\n    t0 = time.time()\n    # Wait no more than these many seconds\n    time_out = 30\n    running = True\n\n    while running and time.time() - t0 < time_out:\n        if os.name == 'nt':\n            p = Popen(\n                'tasklist | find \"%s\"' % arg1,\n                shell=True,\n                stdin=PIPE,\n                stdout=PIPE,\n                stderr=PIPE,\n                close_fds=False)\n        else:\n            p = Popen(\n                'ps aux | grep %s' % arg1,\n                shell=True,\n                stdin=PIPE,\n                stdout=PIPE,\n                stderr=PIPE,\n                close_fds=True)\n\n        lines = p.stdout.readlines()\n\n        running = False\n        for line in lines:\n            # this kills all java.exe and python including self in windows\n            if ('%s' % arg2 in line) or (os.name == 'nt'\n                                         and '%s' % arg1 in line):\n                running = True\n\n                # Get pid\n                fields = line.strip().split()\n\n                info('Stopping %s (process number %s)' % (arg1, fields[1]))\n                if os.name == 'nt':\n                    kill = 'taskkill /F /PID \"%s\"' % fields[1]\n                else:\n                    kill = 'kill -9 %s 2> /dev/null' % fields[1]\n                os.system(kill)\n\n        # Give it a little more time\n        time.sleep(1)\n    else:\n        pass\n\n    if running:\n        raise Exception('Could not stop %s: '\n                        'Running processes are\\n%s' % (arg1, '\\n'.join(\n                            [l.strip() for l in lines])))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncopy Bulma static files from package s static and bulma into project s static_root_bulma_dir", "response": "def copy_bulma_files(self):\n        \"\"\"\n        Copies Bulma static files from package's static/bulma into project's\n        STATIC_ROOT/bulma\n        \"\"\"\n        original_bulma_dir = os.path.join(\n            os.path.dirname(os.path.dirname(os.path.dirname(__file__))),\n            'static',\n            'bulma'\n        )\n        shutil.copytree(original_bulma_dir, self.static_root_bulma_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sign(self, consumer_secret, method, url, oauth_token_secret=None,\n             **params):\n        \"\"\"Create a signature using HMAC-SHA1.\"\"\"\n        # build the url the same way aiohttp will build the query later on\n        # cf https://github.com/KeepSafe/aiohttp/blob/master/aiohttp/client.py#L151\n        # and https://github.com/KeepSafe/aiohttp/blob/master/aiohttp/client_reqrep.py#L81\n        url = yarl.URL(url).with_query(sorted(params.items()))\n        url, params = str(url).split('?', 1)\n        method = method.upper()\n\n        signature = b\"&\".join(map(self._escape, (method, url, params)))\n\n        key = self._escape(consumer_secret) + b\"&\"\n        if oauth_token_secret:\n            key += self._escape(oauth_token_secret)\n\n        hashed = hmac.new(key, signature, sha1)\n        return base64.b64encode(hashed.digest()).decode()", "response": "Create a signature using HMAC - SHA1."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sign(self, consumer_secret, method, url, oauth_token_secret=None,\n             **params):\n        \"\"\"Create a signature using PLAINTEXT.\"\"\"\n        key = self._escape(consumer_secret) + b'&'\n        if oauth_token_secret:\n            key += self._escape(oauth_token_secret)\n        return key.decode()", "response": "Create a signature using PLAINTEXT."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds provider s url. Join with base_url part.", "response": "def _get_url(self, url):\n        \"\"\"Build provider's url. Join with base_url part if needed.\"\"\"\n        if self.base_url and not url.startswith(('http://', 'https://')):\n            return urljoin(self.base_url, url)\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking a request through AIOHTTP.", "response": "async def _request(self, method, url, loop=None, timeout=None, **kwargs):\n        \"\"\"Make a request through AIOHTTP.\"\"\"\n        session = self.session or aiohttp.ClientSession(\n            loop=loop, conn_timeout=timeout, read_timeout=timeout)\n        try:\n            async with session.request(method, url, **kwargs) as response:\n\n                if response.status / 100 > 2:\n                    raise web.HTTPBadRequest(\n                        reason='HTTP status code: %s' % response.status)\n\n                if 'json' in response.headers.get('CONTENT-TYPE'):\n                    data = await response.json()\n                else:\n                    data = await response.text()\n                    data = dict(parse_qsl(data))\n\n                return data\n\n        except asyncio.TimeoutError:\n            raise web.HTTPBadRequest(reason='HTTP Timeout')\n\n        finally:\n            if not self.session and not session.closed:\n                await session.close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def user_info(self, loop=None, **kwargs):\n        if not self.user_info_url:\n            raise NotImplementedError(\n                'The provider doesnt support user_info method.')\n\n        data = await self.request('GET', self.user_info_url, loop=loop, **kwargs)\n        user = User(**dict(self.user_parse(data)))\n        return user, data", "response": "Load user information from provider."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef request(self, method, url, params=None, **aio_kwargs):\n        oparams = {\n            'oauth_consumer_key': self.consumer_key,\n            'oauth_nonce': sha1(str(RANDOM()).encode('ascii')).hexdigest(),\n            'oauth_signature_method': self.signature.name,\n            'oauth_timestamp': str(int(time.time())),\n            'oauth_version': self.version,\n        }\n        oparams.update(params or {})\n\n        if self.oauth_token:\n            oparams['oauth_token'] = self.oauth_token\n\n        url = self._get_url(url)\n\n        if urlsplit(url).query:\n            raise ValueError(\n                'Request parameters should be in the \"params\" parameter, '\n                'not inlined in the URL')\n\n        oparams['oauth_signature'] = self.signature.sign(\n            self.consumer_secret, method, url,\n            oauth_token_secret=self.oauth_token_secret, **oparams)\n        self.logger.debug(\"%s %s\", url, oparams)\n\n        return self._request(method, url, params=oparams, **aio_kwargs)", "response": "Make a request to the provider."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def get_request_token(self, loop=None, **params):\n        params = dict(self.params, **params)\n        data = await self.request('GET', self.request_token_url, params=params, loop=loop)\n\n        self.oauth_token = data.get('oauth_token')\n        self.oauth_token_secret = data.get('oauth_token_secret')\n        return self.oauth_token, self.oauth_token_secret, data", "response": "Get a request_token and request_token_secret from OAuth1 provider."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets access token from OAuth1 provider.", "response": "async def get_access_token(self, oauth_verifier, request_token=None, loop=None, **params):\n        \"\"\"Get access_token from OAuth1 provider.\n\n        :returns: (access_token, access_token_secret, provider_data)\n        \"\"\"\n        # Possibility to provide REQUEST DATA to the method\n        if not isinstance(oauth_verifier, str) and self.shared_key in oauth_verifier:\n            oauth_verifier = oauth_verifier[self.shared_key]\n\n        if request_token and self.oauth_token != request_token:\n            raise web.HTTPBadRequest(\n                reason='Failed to obtain OAuth 1.0 access token. '\n                       'Request token is invalid')\n\n        data = await self.request('POST', self.access_token_url, params={\n            'oauth_verifier': oauth_verifier, 'oauth_token': request_token}, loop=loop)\n\n        self.oauth_token = data.get('oauth_token')\n        self.oauth_token_secret = data.get('oauth_token_secret')\n\n        return self.oauth_token, self.oauth_token_secret, data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn formatted authorize URL.", "response": "def get_authorize_url(self, **params):\n        \"\"\"Return formatted authorize URL.\"\"\"\n        params = dict(self.params, **params)\n        params.update({'client_id': self.client_id, 'response_type': 'code'})\n        return self.authorize_url + '?' + urlencode(params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def get_access_token(self, code, loop=None, redirect_uri=None, **payload):\n        # Possibility to provide REQUEST DATA to the method\n        payload.setdefault('grant_type', 'authorization_code')\n        payload.update({'client_id': self.client_id, 'client_secret': self.client_secret})\n\n        if not isinstance(code, str) and self.shared_key in code:\n            code = code[self.shared_key]\n        payload['refresh_token' if payload['grant_type'] == 'refresh_token' else 'code'] = code\n\n        redirect_uri = redirect_uri or self.params.get('redirect_uri')\n        if redirect_uri:\n            payload['redirect_uri'] = redirect_uri\n\n        self.access_token = None\n        data = await self.request('POST', self.access_token_url, data=payload, loop=loop)\n\n        try:\n            self.access_token = data['access_token']\n\n        except KeyError:\n            self.logger.error(\n                'Error when getting the access token.\\nData returned by OAuth server: %r',\n                data,\n            )\n            raise web.HTTPBadRequest(reason='Failed to obtain OAuth access token.')\n\n        return self.access_token, data", "response": "Get an access token from OAuth provider."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef user_parse(data):\n        user_ = data.get('user')\n        yield 'id', user_.get('username')\n        yield 'username', user_.get('username')\n        yield 'first_name', user_.get('first_name')\n        yield 'last_name', user_.get('last_name')\n        yield 'picture', user_.get('avatar')\n        yield 'link', user_.get('resource_url')", "response": "Parse information from the provider."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing information from the provider.", "response": "def user_parse(data):\n        \"\"\"Parse information from the provider.\"\"\"\n        yield 'id', data.get('uuid')\n        yield 'username', data.get('username')\n        yield 'last_name', data.get('display_name')\n        links = data.get('links', {})\n        yield 'picture', links.get('avatar', {}).get('href')\n        yield 'link', links.get('html', {}).get('href')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef user_parse(data):\n        yield 'id', data.get('id')\n        yield 'username', data.get('username')\n        yield 'discriminator', data.get('discriminator')\n        yield 'picture', \"https://cdn.discordapp.com/avatars/{}/{}.png\".format(\n            data.get('id'), data.get('avatar'))", "response": "Parse information from the provider."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses information from the provider.", "response": "def user_parse(data):\n        \"\"\"Parse information from the provider.\"\"\"\n        user_ = data.get('user', {})\n        yield 'id', data.get('user_nsid') or user_.get('id')\n        yield 'username', user_.get('username', {}).get('_content')\n        first_name, _, last_name = data.get(\n            'fullname', {}).get('_content', '').partition(' ')\n        yield 'first_name', first_name\n        yield 'last_name', last_name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing user information from the provider.", "response": "def user_parse(data):\n        \"\"\"Parse information from the provider.\"\"\"\n        _user = data.get('user_info', {})\n        _id = _user.get('id') or _user.get('uid')\n        yield 'id', _id\n        yield 'locale', _user.get('default_lang')\n        yield 'username', _user.get('display_name')\n        first_name, _, last_name = _user.get('full_name', '').partition(' ')\n        yield 'first_name', first_name\n        yield 'last_name', last_name\n        yield 'picture', 'http://avatars.plurk.com/{0}-big2.jpg'.format(_id)\n        city, country = map(lambda s: s.strip(),\n                            _user.get('location', ',').split(','))\n        yield 'city', city\n        yield 'country', country"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef user_parse(data):\n        yield 'id', data.get('id') or data.get('user_id')\n        first_name, _, last_name = data['name'].partition(' ')\n        yield 'first_name', first_name\n        yield 'last_name', last_name\n        yield 'picture', data.get('profile_image_url')\n        yield 'locale', data.get('lang')\n        yield 'link', data.get('url')\n        yield 'username', data.get('screen_name')\n        city, _, country = map(lambda s: s.strip(),\n                               data.get('location', '').partition(','))\n        yield 'city', city\n        yield 'country', country", "response": "Parse information from the provider."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse information from the provider.", "response": "def user_parse(data):\n        \"\"\"Parse information from the provider.\"\"\"\n        _user = data.get('response', {}).get('user', {})\n        yield 'id', _user.get('name')\n        yield 'username', _user.get('name')\n        yield 'link', _user.get('blogs', [{}])[0].get('url')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef user_parse(data):\n        _user = data.get('oauth', {}).get('user', {})\n        yield 'id', _user.get('id')\n        yield 'username', _user.get('username')\n        first_name, _, last_name = _user.get('display_name').partition(' ')\n        yield 'first_name', first_name\n        yield 'last_name', last_name", "response": "Parse information from the provider."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef user_parse(data):\n        _user = data.get('query', {}).get('results', {}).get('profile', {})\n        yield 'id', _user.get('guid')\n        yield 'username', _user.get('username')\n        yield 'link', _user.get('profileUrl')\n        emails = _user.get('emails')\n        if isinstance(emails, list):\n            for email in emails:\n                if 'primary' in list(email.keys()):\n                    yield 'email', email.get('handle')\n        elif isinstance(emails, dict):\n            yield 'email', emails.get('handle')\n        yield 'picture', _user.get('image', {}).get('imageUrl')\n        city, country = map(lambda s: s.strip(),\n                            _user.get('location', ',').split(','))\n        yield 'city', city\n        yield 'country', country", "response": "Parse information from the provider."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef user_parse(data):\n        for email in data.get('emails', []):\n            if email.get('primary'):\n                yield 'id', email.get('email')\n                yield 'email', email.get('email')\n                break", "response": "Parse information from provider."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef user_parse(data):\n        id_ = data.get('id')\n        yield 'id', id_\n        yield 'email', data.get('email')\n        yield 'first_name', data.get('first_name')\n        yield 'last_name', data.get('last_name')\n        yield 'username', data.get('name')\n        yield 'picture', 'http://graph.facebook.com/{0}/picture?' \\\n                         'type=large'.format(id_)\n        yield 'link', data.get('link')\n        yield 'locale', data.get('locale')\n        yield 'gender', data.get('gender')\n\n        location = data.get('location', {}).get('name')\n        if location:\n            split_location = location.split(', ')\n            yield 'city', split_location[0].strip()\n            if len(split_location) > 1:\n                yield 'country', split_location[1].strip()", "response": "Parse user information from provider."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing information from the provider.", "response": "def user_parse(data):\n        \"\"\"Parse information from the provider.\"\"\"\n        user = data.get('response', {}).get('user', {})\n        yield 'id', user.get('id')\n        yield 'email', user.get('contact', {}).get('email')\n        yield 'first_name', user.get('firstName')\n        yield 'last_name', user.get('lastName')\n        city, country = user.get('homeCity', ', ').split(', ')\n        yield 'city', city\n        yield 'country', country"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing information from provider.", "response": "def user_parse(data):\n        \"\"\"Parse information from provider.\"\"\"\n        yield 'id', data.get('id')\n        yield 'email', data.get('email')\n        first_name, _, last_name = (data.get('name') or '').partition(' ')\n        yield 'first_name', first_name\n        yield 'last_name', last_name\n        yield 'username', data.get('login')\n        yield 'picture', data.get('avatar_url')\n        yield 'link', data.get('html_url')\n        location = data.get('location', '')\n        if location:\n            split_location = location.split(',')\n            yield 'country', split_location[0].strip()\n            if len(split_location) > 1:\n                yield 'city', split_location[1].strip()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef user_parse(data):\n        yield 'id', data.get('id')\n        yield 'email', data.get('email')\n        yield 'first_name', data.get('given_name')\n        yield 'last_name', data.get('family_name')\n        yield 'link', data.get('link')\n        yield 'locale', data.get('locale')\n        yield 'picture', data.get('picture')\n        yield 'gender', data.get('gender')", "response": "Parse information from provider."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses information from provider.", "response": "def user_parse(data):\n        \"\"\"Parse information from provider.\"\"\"\n        resp = data.get('response', [{}])[0]\n        yield 'id', resp.get('uid')\n        yield 'first_name', resp.get('first_name')\n        yield 'last_name', resp.get('last_name')\n        yield 'username', resp.get('nickname')\n        yield 'city', resp.get('city')\n        yield 'country', resp.get('country')\n        yield 'picture', resp.get('photo_big')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping for \"require_http_methods\" decorator. POST required by default, GET can optionally be allowed", "response": "def hijack_require_http_methods(fn):\n    \"\"\"\n    Wrapper for \"require_http_methods\" decorator. POST required by default, GET can optionally be allowed\n    \"\"\"\n    required_methods = ['POST']\n    if hijack_settings.HIJACK_ALLOW_GET_REQUESTS:\n        required_methods.append('GET')\n    return require_http_methods(required_methods)(fn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndisconnects any signals to update_last_login() for the scope of the context manager, then restore.", "response": "def no_update_last_login():\n    \"\"\"\n    Disconnect any signals to update_last_login() for the scope of the context\n    manager, then restore.\n    \"\"\"\n    kw = {'receiver': update_last_login}\n    kw_id = {'receiver': update_last_login, 'dispatch_uid': 'update_last_login'}\n\n    was_connected = user_logged_in.disconnect(**kw)\n    was_connected_id = not was_connected and user_logged_in.disconnect(**kw_id)\n    yield\n    # Restore signal if needed\n    if was_connected:\n        user_logged_in.connect(**kw)\n    elif was_connected_id:\n        user_logged_in.connect(**kw_id)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_authorized_default(hijacker, hijacked):\n\n    if hijacker.is_superuser:\n        return True\n\n    if hijacked.is_superuser:\n        return False\n\n    if hijacker.is_staff and hijack_settings.HIJACK_AUTHORIZE_STAFF:\n        if hijacked.is_staff and not hijack_settings.HIJACK_AUTHORIZE_STAFF_TO_HIJACK_STAFF:\n            return False\n        return True\n\n    return False", "response": "Checks if the user has the correct permission to Hijack another user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nevaluate the authorization check specified in settings", "response": "def is_authorized(hijack, hijacked):\n    '''\n    Evaluates the authorization check specified in settings\n    '''\n    authorization_check = import_string(hijack_settings.HIJACK_AUTHORIZATION_CHECK)\n    return authorization_check(hijack, hijacked)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhijacks mechanisms for handling user login", "response": "def login_user(request, hijacked):\n    ''' hijack mechanism '''\n    hijacker = request.user\n    hijack_history = [request.user._meta.pk.value_to_string(hijacker)]\n    if request.session.get('hijack_history'):\n        hijack_history = request.session['hijack_history'] + hijack_history\n\n    check_hijack_authorization(request, hijacked)\n\n    backend = get_used_backend(request)\n    hijacked.backend = \"%s.%s\" % (backend.__module__, backend.__class__.__name__)\n\n    with no_update_last_login():\n        # Actually log user in\n        login(request, hijacked)\n\n    hijack_started.send(\n            sender=None, request=request,\n            hijacker=hijacker, hijacked=hijacked,\n            # send IDs for backward compatibility\n            hijacker_id=hijacker.pk, hijacked_id=hijacked.pk)\n    request.session['hijack_history'] = hijack_history\n    request.session['is_hijacked_user'] = True\n    request.session['display_hijack_warning'] = True\n    request.session.modified = True\n    return redirect_to_next(request, default_url=hijack_settings.HIJACK_LOGIN_REDIRECT_URL)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_downloadable(self, response):\n        '''\n        Checks whether the response object is a html page\n        or a likely downloadable file.\n        Intended to detect error pages or prompts\n        such as kaggle's competition rules acceptance prompt.\n\n        Returns True if the response is a html page. False otherwise.\n        '''\n\n        content_type = response.headers.get('Content-Type', '')\n        content_disp = response.headers.get('Content-Disposition', '')\n\n        if 'text/html' in content_type and 'attachment' not in content_disp:\n            # This response is a html file\n            # which is not marked as an attachment,\n            # so we likely hit a rules acceptance prompt\n            return False\n        return True", "response": "Checks whether the response object is likely to be downloaded."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the number of records the query would yield", "response": "def count(self):\n        \"\"\" Returns the number of records the query would yield\"\"\"\n        self.request_params.update({'sysparm_count': True})\n        response = self.session.get(self._get_stats_url(),\n                                    params=self._get_formatted_query(fields=list(),\n                                                                     limit=None,\n                                                                     order_by=list(),\n                                                                     offset=None))\n\n        content = self._get_content(response)\n\n        return int(content['stats']['count'])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _all_inner(self, fields, limit, order_by, offset):\n        response = self.session.get(self._get_table_url(),\n                                    params=self._get_formatted_query(fields, limit, order_by, offset))\n\n        yield self._get_content(response)\n        while 'next' in response.links:\n            self.url_link = response.links['next']['url']\n            response = self.session.get(self.url_link)\n            yield self._get_content(response)", "response": "Yields all records for the query and follows links if present on the response after validating\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeprecating - see get_multiple()", "response": "def get_all(self, fields=list(), limit=None, order_by=list(), offset=None):\n        \"\"\"DEPRECATED - see get_multiple()\"\"\"\n        warnings.warn(\"get_all() is deprecated, please use get_multiple() instead\", DeprecationWarning)\n        return self.get_multiple(fields, limit, order_by, offset)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_multiple(self, fields=list(), limit=None, order_by=list(), offset=None):\n        return itertools.chain.from_iterable(self._all_inner(fields, limit, order_by, offset))", "response": "Wrapper method that returns all the records in one iterable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_one(self, fields=list()):\n        response = self.session.get(self._get_table_url(),\n                                    params=self._get_formatted_query(fields, limit=None, order_by=list(), offset=None))\n\n        content = self._get_content(response)\n        l = len(content)\n        if l > 1:\n            raise MultipleResults('Multiple results for get_one()')\n\n        if len(content) == 0:\n            return {}\n\n        return content[0]", "response": "Convenience function for queries returning only one result. Validates response before returning."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninsert a new record with the payload passed as an argument", "response": "def insert(self, payload):\n        \"\"\"Inserts a new record with the payload passed as an argument\n\n        :param payload: The record to create (dict)\n        :return:\n            - Created record\n        \"\"\"\n        response = self.session.post(self._get_table_url(), data=json.dumps(payload))\n        return self._get_content(response)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the queried record with payload and returns the updated record after validating the response", "response": "def update(self, payload):\n        \"\"\"Updates the queried record with `payload` and returns the updated record after validating the response\n\n        :param payload: Payload to update the record with\n        :raise:\n            :NoResults: if query returned no results\n            :MultipleResults: if query returned more than one result (currently not supported)\n        :return:\n            - The updated record\n        \"\"\"\n        try:\n            result = self.get_one()\n            if 'sys_id' not in result:\n                raise NoResults()\n        except MultipleResults:\n            raise MultipleResults(\"Update of multiple records is not supported\")\n        except NoResults as e:\n            e.args = ('Cannot update a non-existing record',)\n            raise\n\n        if not isinstance(payload, dict):\n            raise InvalidUsage(\"Update payload must be of type dict\")\n\n        response = self.session.put(self._get_table_url(sys_id=result['sys_id']), data=json.dumps(payload))\n        return self._get_content(response)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncloning the queried record and returns a new record", "response": "def clone(self, reset_fields=list()):\n        \"\"\"Clones the queried record\n\n        :param reset_fields: Fields to reset\n        :raise:\n            :NoResults: if query returned no results\n            :MultipleResults: if query returned more than one result (currently not supported)\n            :UnexpectedResponse: informs the user about what likely went wrong\n        :return:\n            - The cloned record\n        \"\"\"\n\n        if not isinstance(reset_fields, list):\n            raise InvalidUsage(\"reset_fields must be a `list` of fields\")\n\n        try:\n            response = self.get_one()\n            if 'sys_id' not in response:\n                raise NoResults()\n        except MultipleResults:\n            raise MultipleResults('Cloning multiple records is not supported')\n        except NoResults as e:\n            e.args = ('Cannot clone a non-existing record',)\n            raise\n\n        payload = {}\n\n        # Iterate over fields in the result\n        for field in response:\n            # Ignore fields in reset_fields\n            if field in reset_fields:\n                continue\n\n            item = response[field]\n            # Check if the item is of type dict and has a sys_id ref (value)\n            if isinstance(item, dict) and 'value' in item:\n                payload[field] = item['value']\n            else:\n                payload[field] = item\n\n        try:\n            return self.insert(payload)\n        except UnexpectedResponse as e:\n            if e.status_code == 403:\n                # User likely attempted to clone a record without resetting a unique field\n                e.args = ('Unable to create clone. Make sure unique fields has been reset.',)\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef attach(self, file):\n        try:\n            result = self.get_one()\n            if 'sys_id' not in result:\n                raise NoResults()\n        except MultipleResults:\n            raise MultipleResults('Attaching a file to multiple records is not supported')\n        except NoResults:\n            raise NoResults('Attempted to attach file to a non-existing record')\n\n        if not os.path.isfile(file):\n            raise InvalidUsage(\"Attachment '%s' must be an existing regular file\" % file)\n\n        response = self.session.post(\n            self._get_attachment_url('upload'),\n            data={\n                'table_name': self.table,\n                'table_sys_id': result['sys_id'],\n                'file_name': ntpath.basename(file)\n            },\n            files={'file': open(file, 'rb')},\n            headers={'content-type': None}  # Temporarily override header\n        )\n        return self._get_content(response)", "response": "Attaches the file to the record and returns the response after validating the response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_content(self, response):\n        method = response.request.method\n        self.last_response = response\n\n        server_error = {\n            'summary': None,\n            'details': None\n        }\n\n        try:\n            content_json = response.json()\n            if 'error' in content_json:\n                e = content_json['error']\n                if 'message' in e:\n                    server_error['summary'] = e['message']\n                if 'detail' in e:\n                    server_error['details'] = e['detail']\n        except ValueError:\n            content_json = {}\n\n        if method == 'DELETE':\n            # Make sure the delete operation returned the expected response\n            if response.status_code == 204:\n                return {'success': True}\n            else:\n                raise UnexpectedResponse(\n                    204, response.status_code, method,\n                    server_error['summary'], server_error['details']\n                )\n        # Make sure the POST operation returned the expected response\n        elif method == 'POST' and response.status_code != 201:\n            raise UnexpectedResponse(\n                201, response.status_code, method,\n                server_error['summary'], server_error['details']\n            )\n        # It seems that Helsinki and later returns status 200 instead of 404 on empty result sets\n        if ('result' in content_json and len(content_json['result']) == 0) or response.status_code == 404:\n            if self.raise_on_empty is True:\n                raise NoResults('Query yielded no results')\n        elif 'error' in content_json:\n            raise UnexpectedResponse(\n                200, response.status_code, method,\n                server_error['summary'], server_error['details']\n            )\n\n        if 'result' not in content_json:\n            raise MissingResult(\"The request was successful but the content didn't contain the expected 'result'\")\n\n        return content_json['result']", "response": "Checks for errors in the response and returns the response content in bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes table and sys_id and returns a URL", "response": "def _get_url(self, resource, item, sys_id=None):\n        \"\"\"Takes table and sys_id (if present), and returns a URL\n\n        :param resource: API resource\n        :param item: API resource item\n        :param sys_id: Record sys_id\n        :return:\n            - url string\n        \"\"\"\n\n        url_str = '%(base_url)s/%(base_path)s/%(resource)s/%(item)s' % (\n            {\n                'base_url': self.base_url,\n                'base_path': self.base_path,\n                'resource': resource,\n                'item': item\n            }\n        )\n\n        if sys_id:\n            return \"%s/%s\" % (url_str, sys_id)\n\n        return url_str"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts the query to a ServiceNow - interpretable format", "response": "def _get_formatted_query(self, fields, limit, order_by, offset):\n        \"\"\"\n        Converts the query to a ServiceNow-interpretable format\n        :return:\n            - ServiceNow query\n        \"\"\"\n\n        if not isinstance(order_by, list):\n            raise InvalidUsage(\"Argument order_by should be a `list` of fields\")\n\n        if not isinstance(fields, list):\n            raise InvalidUsage(\"Argument fields should be a `list` of fields\")\n\n        if isinstance(self.query, QueryBuilder):\n            sysparm_query = str(self.query)\n        elif isinstance(self.query, dict):  # Dict-type query\n            sysparm_query = '^'.join(['%s=%s' % (k, v) for k, v in six.iteritems(self.query)])\n        elif isinstance(self.query, six.string_types):  # String-type query\n            sysparm_query = self.query\n        else:\n            raise InvalidUsage(\"Query must be instance of %s, %s or %s\" % (QueryBuilder, str, dict))\n\n        for field in order_by:\n            if field[0] == '-':\n                sysparm_query += \"^ORDERBYDESC%s\" % field[1:]\n            else:\n                sysparm_query += \"^ORDERBY%s\" % field\n\n        params = {'sysparm_query': sysparm_query}\n        params.update(self.request_params)\n\n        if limit is not None:\n            params.update({'sysparm_limit': limit, 'sysparm_suppress_pagination_header': True})\n\n        if offset is not None:\n            params.update({'sysparm_offset': offset})\n\n        if len(fields) > 0:\n            params.update({'sysparm_fields': \",\".join(fields)})\n\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_session(self, session):\n\n        if not session:\n            logger.debug('(SESSION_CREATE) User: %s' % self._user)\n            s = requests.Session()\n            s.auth = HTTPBasicAuth(self._user, self._password)\n        else:\n            logger.debug('(SESSION_CREATE) Object: %s' % session)\n            s = session\n\n        s.headers.update(\n            {\n                'content-type': 'application/json',\n                'accept': 'application/json',\n                'User-Agent': 'pysnow/%s' % pysnow.__version__\n            }\n        )\n\n        return s", "response": "Creates a new session with basic auth unless one was provided and sets headers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _legacy_request(self, method, table, **kwargs):\n\n        warnings.warn(\"`%s` is deprecated and will be removed in a future release. \"\n                      \"Please use `resource()` instead.\" % inspect.stack()[1][3], DeprecationWarning)\n\n        return LegacyRequest(method,\n                             table,\n                             request_params=self.request_params,\n                             raise_on_empty=self.raise_on_empty,\n                             session=self.session,\n                             instance=self.instance,\n                             base_url=self.base_url,\n                             **kwargs)", "response": "Returns a LegacyRequest object compatible with Client. query and Client. insert\n\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resource(self, api_path=None, base_path='/api/now', chunk_size=None, **kwargs):\n\n        for path in [api_path, base_path]:\n            URLBuilder.validate_path(path)\n\n        return Resource(api_path=api_path,\n                        base_path=base_path,\n                        parameters=self.parameters,\n                        chunk_size=chunk_size or 8192,\n                        session=self.session,\n                        base_url=self.base_url,\n                        **kwargs)", "response": "Creates a new Resource object after validating paths"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninserts ( POST ) request wrapper for the request object insert", "response": "def insert(self, table, payload, **kwargs):\n        \"\"\"Insert (POST) request wrapper\n\n        :param table: table to insert on\n        :param payload: update payload (dict)\n        :param kwargs: Keyword arguments passed along to `Request`\n        :return:\n            - Dictionary containing the created record\n        \"\"\"\n\n        r = self._legacy_request('POST', table, **kwargs)\n        return r.insert(payload)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps - creates a : class : requests. Response object and passes along to _send", "response": "def _get_response(self, method, **kwargs):\n        \"\"\"Response wrapper - creates a :class:`requests.Response` object and passes along to :class:`pysnow.Response`\n        for validation and parsing.\n\n        :param args: args to pass along to _send()\n        :param kwargs: kwargs to pass along to _send()\n        :return:\n            - :class:`pysnow.Response` object\n        \"\"\"\n\n        params = self._parameters.as_dict()\n        use_stream = kwargs.pop('stream', False)\n\n        logger.debug('(REQUEST_SEND) Method: %s, Resource: %s' % (method, self._resource))\n\n        response = self._session.request(method, self._url, stream=use_stream, params=params, **kwargs)\n        response.raw.decode_content = True\n\n        logger.debug('(RESPONSE_RECEIVE) Code: %d, Resource: %s' % (response.status_code, self._resource))\n\n        return Response(response=response, resource=self._resource, chunk_size=self._chunk_size, stream=use_stream)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfetches one or more records - : class : pysnow. Response object", "response": "def get(self, *args, **kwargs):\n        \"\"\"Fetches one or more records\n\n        :return:\n            - :class:`pysnow.Response` object\n        \"\"\"\n\n        self._parameters.query = kwargs.pop('query', {}) if len(args) == 0 else args[0]\n        self._parameters.limit = kwargs.pop('limit', 10000)\n        self._parameters.offset = kwargs.pop('offset', 0)\n        self._parameters.fields = kwargs.pop('fields', kwargs.pop('fields', []))\n\n        return self._get_response('GET', stream=kwargs.pop('stream', False))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self, query, payload):\n\n        if not isinstance(payload, dict):\n            raise InvalidUsage(\"Update payload must be of type dict\")\n\n        record = self.get(query).one()\n\n        self._url = self._url_builder.get_appended_custom(\"/{0}\".format(record['sys_id']))\n        return self._get_response('PUT', data=json.dumps(payload))", "response": "Updates a record with the given query and payload."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, query):\n\n        record = self.get(query=query).one()\n\n        self._url = self._url_builder.get_appended_custom(\"/{0}\".format(record['sys_id']))\n        return self._get_response('DELETE').one()", "response": "Deletes a record by name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a custom request for the current resource.", "response": "def custom(self, method, path_append=None, headers=None, **kwargs):\n        \"\"\"Creates a custom request\n\n        :param method: HTTP method\n        :param path_append: (optional) append path to resource.api_path\n        :param headers: (optional) Dictionary of headers to add or override\n        :param kwargs: kwargs to pass along to :class:`requests.Request`\n        :return:\n            - :class:`pysnow.Response` object\n        \"\"\"\n\n        if headers:\n            self._session.headers.update(headers)\n\n        if path_append is not None:\n            try:\n                self._url = self._url_builder.get_appended_custom(path_append)\n            except InvalidUsage:\n                raise InvalidUsage(\"Argument 'path_append' must be a string in the following format: \"\n                                   \"/path-to-append[/.../...]\")\n\n        return self._get_response(method, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef attachments(self):\n\n        resource = copy(self)\n        resource._url_builder = URLBuilder(self._base_url, self._base_path, '/attachment')\n\n        path = self._api_path.strip('/').split('/')\n\n        if path[0] != 'table':\n            raise InvalidUsage('The attachment API can only be used with the table API')\n\n        return Attachment(resource, path[1])", "response": "Provides an Attachment API for this resource."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap for the request object.", "response": "def _request(self):\n        \"\"\"Request wrapper\n\n        :return: SnowRequest object\n        \"\"\"\n\n        parameters = copy(self.parameters)\n\n        return SnowRequest(url_builder=self._url_builder, parameters=parameters, resource=self, **self.kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef request(self, method, path_append=None, headers=None, **kwargs):\n\n        return self._request.custom(method, path_append=path_append, headers=headers, **kwargs)", "response": "Create a custom request object with the given method and path."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the response content and yields the object objects.", "response": "def _parse_response(self):\n        \"\"\"Looks for `result.item` (array), `result` (object) and `error` (object) keys and parses\n        the raw response content (stream of bytes)\n\n        :raise:\n            - ResponseError: If there's an error in the response\n            - MissingResult: If no result nor error was found\n        \"\"\"\n\n        response = self._get_response()\n\n        has_result_single = False\n        has_result_many = False\n        has_error = False\n\n        builder = ObjectBuilder()\n\n        for prefix, event, value in ijson.parse(response.raw, buf_size=self._chunk_size):\n            if (prefix, event) == ('error', 'start_map'):\n                # Matched ServiceNow `error` object at the root\n                has_error = True\n            elif prefix == 'result' and event in ['start_map', 'start_array']:\n                # Matched ServiceNow `result`\n                if event == 'start_map':  # Matched object\n                    has_result_single = True\n                elif event == 'start_array':  # Matched array\n                    has_result_many = True\n\n            if has_result_many:\n                # Build the result\n                if (prefix, event) == ('result.item', 'end_map'):\n                    # Reached end of object. Set count and yield\n                    builder.event(event, value)\n                    self.count += 1\n                    yield getattr(builder, 'value')\n                elif prefix.startswith('result.item'):\n                    # Build the result object\n                    builder.event(event, value)\n            elif has_result_single:\n                if (prefix, event) == ('result', 'end_map'):\n                    # Reached end of the result object. Set count and yield.\n                    builder.event(event, value)\n                    self.count += 1\n                    yield getattr(builder, 'value')\n                elif prefix.startswith('result'):\n                    # Build the error object\n                    builder.event(event, value)\n            elif has_error:\n                if (prefix, event) == ('error', 'end_map'):\n                    # Reached end of the error object - raise ResponseError exception\n                    raise ResponseError(getattr(builder, 'value'))\n                elif prefix.startswith('error'):\n                    # Build the error object\n                    builder.event(event, value)\n\n        if (has_result_single or has_result_many) and self.count == 0:  # Results empty\n            return\n\n        if not (has_result_single or has_result_many or has_error):  # None of the expected keys were found\n            raise MissingResult('The expected `result` key was missing in the response. Cannot continue')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a buffered response for the current record ID.", "response": "def _get_buffered_response(self):\n        \"\"\"Returns a buffered response\n\n        :return: Buffered response\n        \"\"\"\n\n        response = self._get_response()\n\n        if response.request.method == 'DELETE' and response.status_code == 204:\n            return [{'status': 'record deleted'}], 1\n\n        result = self._response.json().get('result', None)\n\n        if result is None:\n            raise MissingResult('The expected `result` key was missing in the response. Cannot continue')\n\n        length = 0\n\n        if isinstance(result, list):\n            length = len(result)\n        elif isinstance(result, dict):\n            result = [result]\n            length = 1\n\n        return result, length"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef all(self):\n\n        if self._stream:\n            return chain.from_iterable(self._get_streamed_response())\n\n        return self._get_buffered_response()[0]", "response": "Returns a chained generator that returns all matching records\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the first record in the response or raise an exception", "response": "def first(self):\n        \"\"\"Return the first record or raise an exception if the result doesn't contain any data\n\n        :return:\n            - Dictionary containing the first item in the response content\n\n        :raise:\n            - NoResults: If no results were found\n        \"\"\"\n\n        if not self._stream:\n            raise InvalidUsage('first() is only available when stream=True')\n\n        try:\n            content = next(self.all())\n        except StopIteration:\n            raise NoResults(\"No records found\")\n\n        return content"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning exactly one record or raise an exception.", "response": "def one(self):\n        \"\"\"Return exactly one record or raise an exception.\n\n        :return:\n            - Dictionary containing the only item in the response content\n\n        :raise:\n            - MultipleResults: If more than one records are present in the content\n            - NoResults: If the result is empty\n        \"\"\"\n\n        result, count = self._get_buffered_response()\n\n        if count == 0:\n            raise NoResults(\"No records found\")\n        elif count > 1:\n            raise MultipleResults(\"Expected single-record result, got multiple\")\n\n        return result[0]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upload(self, *args, **kwargs):\n\n        return self._resource.attachments.upload(self['sys_id'], *args, **kwargs)", "response": "Convenience method for attaching files to a fetched recordset"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, sys_id=None, limit=100):\n\n        if sys_id:\n            return self.resource.get(query={'table_sys_id': sys_id, 'table_name': self.table_name}).all()\n\n        return self.resource.get(query={'table_name': self.table_name}, limit=limit).all()", "response": "Returns a list of attachments for a given record sys_id"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upload(self, sys_id, file_path, name=None, multipart=False):\n\n        if not isinstance(multipart, bool):\n            raise InvalidUsage('Multipart must be of type bool')\n\n        resource = self.resource\n\n        if name is None:\n            name = os.path.basename(file_path)\n\n        resource.parameters.add_custom({\n            'table_name': self.table_name,\n            'table_sys_id': sys_id,\n            'file_name': name\n        })\n\n        data = open(file_path, 'rb').read()\n        headers = {}\n\n        if multipart:\n            headers[\"Content-Type\"] = \"multipart/form-data\"\n            path_append = '/upload'\n        else:\n            headers[\"Content-Type\"] = \"text/plain\"\n            path_append = '/file'\n\n        return resource.request(method='POST', data=data, headers=headers, path_append=path_append)", "response": "Uploads a new file to the record with the given sys_id."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nvalidate the provided path for the current node.", "response": "def validate_path(path):\n        \"\"\"Validates the provided path\n\n        :param path: path to validate (string)\n        :raise:\n            :InvalidUsage: If validation fails.\n        \"\"\"\n\n        if not isinstance(path, six.string_types) or not re.match('^/(?:[._a-zA-Z0-9-]/?)+[^/]$', path):\n            raise InvalidUsage(\n                \"Path validation failed - Expected: '/<component>[/component], got: %s\" % path\n            )\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_base_url(use_ssl, instance=None, host=None):\n\n        if instance is not None:\n            host = (\"%s.service-now.com\" % instance).rstrip('/')\n\n        if use_ssl is True:\n            return \"https://%s\" % host\n\n        return \"http://%s\" % host", "response": "Formats the base URL either host or instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new OAuth session object", "response": "def _get_oauth_session(self):\n        \"\"\"Creates a new OAuth session\n\n        :return:\n            - OAuth2Session object\n        \"\"\"\n\n        return self._get_session(\n            OAuth2Session(\n                client_id=self.client_id,\n                token=self.token,\n                token_updater=self.token_updater,\n                auto_refresh_url=self.token_url,\n                auto_refresh_kwargs={\n                    \"client_id\": self.client_id,\n                    \"client_secret\": self.client_secret\n                }\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates and set the token to the given dictionary", "response": "def set_token(self, token):\n        \"\"\"Validate and set token\n\n        :param token: the token (dict) to set\n        \"\"\"\n\n        if not token:\n            self.token = None\n            return\n\n        expected_keys = ['token_type', 'refresh_token', 'access_token', 'scope', 'expires_in', 'expires_at']\n        if not isinstance(token, dict) or not set(token) >= set(expected_keys):\n            raise InvalidUsage(\"Expected a token dictionary containing the following keys: {0}\"\n                               .format(expected_keys))\n\n        # Set sanitized token\n        self.token = dict((k, v) for k, v in token.items() if k in expected_keys)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _legacy_request(self, *args, **kwargs):\n\n        if isinstance(self.token, dict):\n            self.session = self._get_oauth_session()\n            return super(OAuthClient, self)._legacy_request(*args, **kwargs)\n\n        raise MissingToken(\"You must set_token() before creating a legacy request with OAuthClient\")", "response": "Makes sure token has been set then calls parent s _legacy_request method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\noverriding the default resource method to use OAuth session if needed", "response": "def resource(self, api_path=None, base_path='/api/now', chunk_size=None):\n        \"\"\"Overrides :meth:`resource` provided by :class:`pysnow.Client` with extras for OAuth\n\n        :param api_path: Path to the API to operate on\n        :param base_path: (optional) Base path override\n        :param chunk_size: Response stream parser chunk size (in bytes)\n        :return:\n            - :class:`Resource` object\n        :raises:\n            - InvalidUsage: If a path fails validation\n        \"\"\"\n\n        if isinstance(self.token, dict):\n            self.session = self._get_oauth_session()\n            return super(OAuthClient, self).resource(api_path, base_path, chunk_size)\n\n        raise MissingToken(\"You must set_token() before creating a resource with OAuthClient\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_token(self, user, password):\n\n        logger.debug('(TOKEN_CREATE) :: User: %s' % user)\n\n        session = OAuth2Session(client=LegacyApplicationClient(client_id=self.client_id))\n\n        try:\n            return dict(session.fetch_token(token_url=self.token_url,\n                                            username=user,\n                                            password=password,\n                                            client_id=self.client_id,\n                                            client_secret=self.client_secret))\n        except OAuth2Error as exception:\n            raise TokenCreateError('Error creating user token', exception.description, exception.status_code)", "response": "Takes user and password credentials and generates a new token"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting ordering of field descending", "response": "def order_descending(self):\n        \"\"\"Sets ordering of field descending\"\"\"\n\n        self._query.append('ORDERBYDESC{0}'.format(self.current_field))\n        self.c_oper = inspect.currentframe().f_back.f_code.co_name\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef equals(self, data):\n\n        if isinstance(data, six.string_types):\n            return self._add_condition('=', data, types=[int, str])\n        elif isinstance(data, list):\n            return self._add_condition('IN', \",\".join(map(str, data)), types=[str])\n\n        raise QueryTypeError('Expected value of type `str` or `list`, not %s' % type(data))", "response": "Adds new IN or = condition depending on if a list or string was provided\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef greater_than(self, greater_than):\n\n        if hasattr(greater_than, 'strftime'):\n            greater_than = datetime_as_utc(greater_than).strftime('%Y-%m-%d %H:%M:%S')\n        elif isinstance(greater_than, six.string_types):\n            raise QueryTypeError('Expected value of type `int` or instance of `datetime`, not %s' % type(greater_than))\n\n        return self._add_condition('>', greater_than, types=[int, str])", "response": "Adds new > condition that checks that the current value is greater than the given value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef less_than(self, less_than):\n\n        if hasattr(less_than, 'strftime'):\n            less_than = datetime_as_utc(less_than).strftime('%Y-%m-%d %H:%M:%S')\n        elif isinstance(less_than, six.string_types):\n            raise QueryTypeError('Expected value of type `int` or instance of `datetime`, not %s' % type(less_than))\n\n        return self._add_condition('<', less_than, types=[int, str])", "response": "Adds new < condition to be performed when the current value of the key is less than the given value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef between(self, start, end):\n\n        if hasattr(start, 'strftime') and hasattr(end, 'strftime'):\n            dt_between = (\n              'javascript:gs.dateGenerate(\"%(start)s\")'\n              \"@\"\n              'javascript:gs.dateGenerate(\"%(end)s\")'\n            ) % {\n              'start': start.strftime('%Y-%m-%d %H:%M:%S'),\n              'end': end.strftime('%Y-%m-%d %H:%M:%S')\n            }\n        elif isinstance(start, int) and isinstance(end, int):\n            dt_between = '%d@%d' % (start, end)\n        else:\n            raise QueryTypeError(\"Expected `start` and `end` of type `int` \"\n                                 \"or instance of `datetime`, not %s and %s\" % (type(start), type(end)))\n\n        return self._add_condition('BETWEEN', dt_between, types=[str])", "response": "Adds a BETWEEN condition to the query."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nappends a condition to the internal list of the current record set.", "response": "def _add_condition(self, operator, operand, types):\n        \"\"\"Appends condition to self._query after performing validation\n\n        :param operator: operator (str)\n        :param operand: operand\n        :param types: allowed types\n        :raise:\n            - QueryMissingField: if a field hasn't been set\n            - QueryMultipleExpressions: if a condition already has been set\n            - QueryTypeError: if the value is of an unexpected type\n        \"\"\"\n\n        if not self.current_field:\n            raise QueryMissingField(\"Conditions requires a field()\")\n\n        elif not type(operand) in types:\n            caller = inspect.currentframe().f_back.f_code.co_name\n            raise QueryTypeError(\"Invalid type passed to %s() , expected: %s\" % (caller, types))\n\n        elif self.c_oper:\n            raise QueryMultipleExpressions(\"Expected logical operator after expression\")\n\n        self.c_oper = inspect.currentframe().f_back.f_code.co_name\n\n        self._query.append(\"%(current_field)s%(operator)s%(operand)s\" % {\n                               'current_field': self.current_field,\n                               'operator': operator,\n                               'operand': operand\n        })\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a logical operator in query", "response": "def _add_logical_operator(self, operator):\n        \"\"\"Adds a logical operator in query\n\n        :param operator: logical operator (str)\n        :raise:\n            - QueryExpressionError: if a expression hasn't been set\n        \"\"\"\n\n        if not self.c_oper:\n            raise QueryExpressionError(\"Logical operators must be preceded by an expression\")\n\n        self.current_field = None\n        self.c_oper = None\n\n        self.l_oper = inspect.currentframe().f_back.f_code.co_name\n        self._query.append(operator)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding new custom parameter after making sure it s of type dict.", "response": "def add_custom(self, params):\n        \"\"\"Adds new custom parameter after making sure it's of type dict.\n\n        :param params: Dictionary containing one or more parameters\n        \"\"\"\n\n        if isinstance(params, dict) is False:\n            raise InvalidUsage(\"custom parameters must be of type `dict`\")\n\n        self._custom_params.update(params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset `sysparm_display_value` :param value: Bool or 'all'", "response": "def display_value(self, value):\n        \"\"\"Sets `sysparm_display_value`\n\n        :param value:  Bool or 'all'\n        \"\"\"\n\n        if not (isinstance(value, bool) or value == 'all'):\n            raise InvalidUsage(\"Display value can be of type bool or value 'all'\")\n\n        self._sysparms['sysparm_display_value'] = value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset sysparm_limit to limit the size of the record set.", "response": "def limit(self, limit):\n        \"\"\"Sets `sysparm_limit`\n\n        :param limit: Size limit (int)\n        \"\"\"\n\n        if not isinstance(limit, int) or isinstance(limit, bool):\n            raise InvalidUsage(\"limit size must be of type integer\")\n\n        self._sysparms['sysparm_limit'] = limit"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting sysparm_offset to be used to accomplish pagination", "response": "def offset(self, offset):\n        \"\"\"Sets `sysparm_offset`, usually used to accomplish pagination\n\n        :param offset: Number of records to skip before fetching records\n        :raise:\n            :InvalidUsage: if offset is of an unexpected type\n        \"\"\"\n\n        if not isinstance(offset, int) or isinstance(offset, bool):\n            raise InvalidUsage('Offset must be an integer')\n\n        self._sysparms['sysparm_offset'] = offset"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fields(self, fields):\n\n        if not isinstance(fields, list):\n            raise InvalidUsage('fields must be of type `list`')\n\n        self._sysparms['sysparm_fields'] = \",\".join(fields)", "response": "Sets sysparm_fields after joining the given list of fields"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exclude_reference_link(self, exclude):\n        if not isinstance(exclude, bool):\n            raise InvalidUsage('exclude_reference_link must be of type bool')\n\n        self._sysparms['sysparm_exclude_reference_link'] = exclude", "response": "Sets the sysparm_exclude_reference_link to a bool value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef suppress_pagination_header(self, suppress):\n        if not isinstance(suppress, bool):\n            raise InvalidUsage('suppress_pagination_header must be of type bool')\n\n        self._sysparms['sysparm_suppress_pagination_header'] = suppress", "response": "Enables or disables pagination header by setting sysparm_suppress_pagination_header"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef as_dict(self):\n\n        sysparms = self._sysparms\n        sysparms.update(self._custom_params)\n\n        return sysparms", "response": "Constructs query params compatible with requests. Request"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nquits the main loop.", "response": "def quit(self):\n        \"\"\"\n        This could be called from another thread, so let's do this via alarm\n        \"\"\"\n        def q(*args):\n            raise urwid.ExitMainLoop()\n        self.worker.shutdown(wait=False)\n        self.ui_worker.shutdown(wait=False)\n        self.loop.set_alarm_in(0, q)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd provided widget to widget list and display it :param widget: :return:", "response": "def _set_main_widget(self, widget, redraw):\n        \"\"\"\n        add provided widget to widget list and display it\n\n        :param widget:\n        :return:\n        \"\"\"\n        self.set_body(widget)\n        self.reload_footer()\n        if redraw:\n            logger.debug(\"redraw main widget\")\n            self.refresh()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef display_buffer(self, buffer, redraw=True):\n        logger.debug(\"display buffer %r\", buffer)\n        self.buffer_movement_history.append(buffer)\n        self.current_buffer = buffer\n        self._set_main_widget(buffer.widget, redraw=redraw)", "response": "display buffer in main window"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_and_display_buffer(self, buffer, redraw=True):\n        # FIXME: some buffers have arguments, do a proper comparison -- override __eq__\n        if buffer not in self.buffers:\n            logger.debug(\"adding new buffer {!r}\".format(buffer))\n            self.buffers.append(buffer)\n        self.display_buffer(buffer, redraw=redraw)", "response": "add provided buffer to buffer list and display it"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npick i - th buffer from list and display it", "response": "def pick_and_display_buffer(self, i):\n        \"\"\"\n        pick i-th buffer from list and display it\n\n        :param i: int\n        :return: None\n        \"\"\"\n        if len(self.buffers) == 1:\n            # we don't need to display anything\n            # listing is already displayed\n            return\n        else:\n            try:\n                self.display_buffer(self.buffers[i])\n            except IndexError:\n                # i > len\n                self.display_buffer(self.buffers[0])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_statusbar(self):\n        if self.prompt_bar:\n            logger.info(\"prompt is active, won't build status bar\")\n            return\n        try:\n            left_widgets = self.current_buffer.build_status_bar() or []\n        except AttributeError:\n            left_widgets = []\n        text_list = []\n        # FIXME: this code should be placed in buffer\n        # TODO: display current active worker threads\n        for idx, buffer in enumerate(self.buffers):\n            #  #1 [I] fedora #2 [L]\n            fmt = \"#{idx} [{name}]\"\n            markup = fmt.format(idx=idx, name=buffer.display_name)\n            text_list.append((\n                \"status_box_focus\" if buffer == self.current_buffer else \"status_box\",\n                markup,\n            ))\n            text_list.append(\" \")\n        text_list = text_list[:-1]\n\n        if text_list:\n            buffer_text = urwid.Text(text_list, align=\"right\")\n        else:\n            buffer_text = urwid.Text(\"\", align=\"right\")\n        columns = urwid.Columns(left_widgets + [buffer_text])\n        return urwid.AttrMap(columns, \"status\")", "response": "construct and return statusbar widget"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndisplaying a notification for the current user.", "response": "def notify_message(self, message, level=\"info\", clear_if_dupl=True,\n                       clear_in=CLEAR_NOTIF_BAR_MESSAGE_IN):\n        \"\"\"\n        :param message, str\n        :param level: str, {info, error}\n        :param clear_if_dupl: bool, if True, don't display the notification again\n        :param clear_in: seconds, remove the notificantion after some time\n\n        opens notification popup.\n        \"\"\"\n        with self.notifications_lock:\n            if clear_if_dupl and message in self.message_widget_dict.keys():\n                logger.debug(\"notification %r is already displayed\", message)\n                return\n            logger.debug(\"display notification %r\", message)\n            widget = urwid.AttrMap(urwid.Text(message), \"notif_{}\".format(level))\n        return self.notify_widget(widget, message=message, clear_in=clear_in)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef notify_widget(self, widget, message=None, clear_in=CLEAR_NOTIF_BAR_MESSAGE_IN):\n\n        @log_traceback\n        def clear_notification(*args, **kwargs):\n            # the point here is the log_traceback\n            self.remove_widget(widget, message=message)\n\n        if not widget:\n            return\n\n        logger.debug(\"display notification widget %s\", widget)\n\n        with self.notifications_lock:\n            self.widget_message_dict[widget] = message\n            if message:\n                self.message_widget_dict[message] = widget\n\n        self.reload_footer(rebuild_statusbar=False)\n        self.loop.set_alarm_in(clear_in, clear_notification)\n\n        return widget", "response": "displays a widget with a message"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef refresh(self):\n        logger.debug(\"refresh user interface\")\n        try:\n            with self.refresh_lock:\n                self.draw_screen()\n        except AssertionError:\n            logger.warning(\"application is not running\")\n            pass", "response": "explicitely refresh user interface; useful when changing widgets dynamically"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the maximum length of each column in a table.", "response": "def calculate_max_cols_length(table, size):\n    \"\"\"\n    :param table: list of lists:\n\n    [[\"row 1 column 1\", \"row 1 column 2\"],\n     [\"row 2 column 1\", \"row 2 column 2\"]]\n\n    each item consists of instance of urwid.Text\n\n    :returns dict, {index: width}\n    \"\"\"\n    max_cols_lengths = {}\n\n    for row in table:\n        col_index = 0\n        for idx, widget in enumerate(row.widgets):\n            l = widget.pack((size[0], ))[0]\n            max_cols_lengths[idx] = max(max_cols_lengths.get(idx, 0), l)\n            col_index += 1\n\n    max_cols_lengths.setdefault(0, 1)  # in case table is empty\n    return max_cols_lengths"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nassembling the list of rows from a list of urwid. Text objects.", "response": "def assemble_rows(data, max_allowed_lengths=None, dividechars=1,\n                  ignore_columns=None):\n    \"\"\"\n    :param data: list of lists:\n    [[\"row 1 column 1\", \"row 1 column 2\"],\n     [\"row 2 column 1\", \"row 2 column 2\"]]\n    each item consists of instance of urwid.Text\n\n    :param max_allowed_lengths: dict:\n        {col_index: maximum_allowed_length}\n    :param ignore_columns: list of ints, indexes which should not be calculated\n    \"\"\"\n    rows = []\n    max_lengths = {}\n    ignore_columns = ignore_columns or []\n\n    # shitty performance, here we go\n    # it would be way better to do a single double loop and provide mutable variable\n    # FIXME: merge this code with calculate() from above\n    for row in data:\n        col_index = 0\n        for widget in row:\n            if col_index in ignore_columns:\n                continue\n            l = len(widget.text)\n            if max_allowed_lengths:\n                if col_index in max_allowed_lengths and max_allowed_lengths[col_index] < l:\n                    # l is bigger then what is allowed\n                    l = max_allowed_lengths[col_index]\n\n            max_lengths.setdefault(col_index, l)\n            max_lengths[col_index] = max(l, max_lengths[col_index])\n            col_index += 1\n\n    for row in data:\n        row_widgets = []\n        for idx, item in enumerate(row):\n            if idx in ignore_columns:\n                row_widgets.append(item)\n            else:\n                row_widgets.append((max_lengths[idx], item))\n        rows.append(\n            RowWidget(row_widgets, dividechars=dividechars)\n        )\n\n    return rows"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_time_attr_map(t):\n    now = datetime.datetime.now()\n    if t + datetime.timedelta(hours=3) > now:\n        return get_map(\"main_list_white\")\n    if t + datetime.timedelta(days=3) > now:\n        return get_map(\"main_list_lg\")\n    else:\n        return get_map(\"main_list_dg\")", "response": "Returns a map of the attributes that are set for the given time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef strip_from_ansi_esc_sequences(text):\n    # esc[ + values + control character\n    # h, l, p commands are complicated, let's ignore them\n    seq_regex = r\"\\x1b\\[[0-9;]*[mKJusDCBAfH]\"\n    regex = re.compile(seq_regex)\n    start = 0\n    response = \"\"\n    for match in regex.finditer(text):\n        end = match.start()\n        response += text[start:end]\n\n        start = match.end()\n    response += text[start:len(text)]\n    return response", "response": "strip ANSI escape sequences in text and remove them"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches realtime events from docker and pass them to buffers", "response": "def realtime_updates(self):\n        \"\"\"\n        fetch realtime events from docker and pass them to buffers\n\n        :return: None\n        \"\"\"\n        # TODO: make this available for every buffer\n        logger.info(\"starting receiving events from docker\")\n        it = self.d.realtime_updates()\n        while True:\n            try:\n                event = next(it)\n            except NotifyError as ex:\n                self.ui.notify_message(\"error when receiving realtime events from docker: %s\" % ex,\n                                       level=\"error\")\n                return\n            # FIXME: we should pass events to all buffers\n            # ATM the buffers can't be rendered since they are not displayed\n            # and hence traceback like this: ListBoxError(\"Listbox contents too short! ...\n            logger.debug(\"pass event to current buffer %s\", self.ui.current_buffer)\n            try:\n                self.ui.current_buffer.process_realtime_event(event)\n            except Exception as ex:\n                # swallow any exc\n                logger.error(\"error while processing runtime event: %r\", ex)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup_dirs():\n    try:\n        top_dir = os.path.abspath(os.path.expanduser(os.environ[\"XDG_CACHE_HOME\"]))\n    except KeyError:\n        top_dir = os.path.abspath(os.path.expanduser(\"~/.cache\"))\n    our_cache_dir = os.path.join(top_dir, PROJECT_NAME)\n    os.makedirs(our_cache_dir, mode=0o775, exist_ok=True)\n    return our_cache_dir", "response": "Make required directories to hold logfile."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhumanizes the given byte size.", "response": "def humanize_bytes(bytesize, precision=2):\n    \"\"\"\n    Humanize byte size figures\n\n    https://gist.github.com/moird/3684595\n    \"\"\"\n    abbrevs = (\n        (1 << 50, 'PB'),\n        (1 << 40, 'TB'),\n        (1 << 30, 'GB'),\n        (1 << 20, 'MB'),\n        (1 << 10, 'kB'),\n        (1, 'bytes')\n    )\n    if bytesize == 1:\n        return '1 byte'\n    for factor, suffix in abbrevs:\n        if bytesize >= factor:\n            break\n    if factor == 1:\n        precision = 0\n    return '%.*f %s' % (precision, bytesize / float(factor), suffix)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef repeater(call, args=None, kwargs=None, retries=4):\n    args = args or ()\n    kwargs = kwargs or {}\n    t = 1.0\n    for x in range(retries):\n        try:\n            return call(*args, **kwargs)\n        except APIError as ex:\n            logger.error(\"query #%d: docker returned an error: %r\", x, ex)\n        except Exception as ex:\n            # this may be pretty bad\n            log_last_traceback()\n            logger.error(\"query #%d: generic error: %r\", x, ex)\n        t *= 2\n        time.sleep(t)", "response": "repeat a docker call x - times"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget metadata from inspect specified by path", "response": "def metadata_get(self, path, cached=True):\n        \"\"\"\n        get metadata from inspect, specified by path\n\n        :param path: list of str\n        :param cached: bool, use cached version of inspect if available\n        \"\"\"\n        try:\n            value = graceful_chain_get(self.inspect(cached=cached).response, *path)\n        except docker.errors.NotFound:\n            logger.warning(\"object %s is not available anymore\", self)\n            raise NotAvailableAnymore()\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all layers of this image", "response": "def layers(self):\n        \"\"\"\n        similar as parent images, except that it uses /history API endpoint\n        :return:\n        \"\"\"\n        # sample output:\n        # {\n        #     \"Created\": 1457116802,\n        #     \"Id\": \"sha256:507cb13a216097710f0d234668bf64a4c92949c573ba15eba13d05aad392fe04\",\n        #     \"Size\": 204692029,\n        #     \"Tags\": [\n        #         \"docker.io/fedora:latest\"\n        #     ],\n        #     \"Comment\": \"\",\n        #     \"CreatedBy\": \"/bin/sh -c #(nop) ADD file:bcb5e5c... in /\"\n        # }\n        try:\n            response = self.d.history(self.image_id)\n        except docker.errors.NotFound:\n            raise NotAvailableAnymore()\n\n        layers = []\n        for l in response:\n            layer_id = l[\"Id\"]\n            if layer_id == \"<missing>\":\n                layers.append(DockerImage(l, self.docker_backend))\n            else:\n                layers.append(self.docker_backend.get_image_by_id(layer_id))\n        return layers"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unique_size(self):\n        self._virtual_size = self._virtual_size or \\\n                             graceful_chain_get(self.data, \"VirtualSize\", default=0)\n        try:\n            return self._virtual_size - self._shared_size\n        except TypeError:\n            return 0", "response": "Returns the size of only this particular layer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef image_id(self):\n        try:\n            # docker >= 1.9\n            image_id = self.data[\"ImageID\"]\n        except KeyError:\n            # docker <= 1.8\n            image_id = self.metadata_get([\"Image\"])\n        return image_id", "response": "this container is created from image with id..."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the ACTIVE port mappings of a container", "response": "def net(self):\n        \"\"\"\n        get ACTIVE port mappings of a container\n\n        :return: dict:\n        {\n            \"host_port\": \"container_port\"\n        }\n        \"\"\"\n        try:\n            return NetData(self.inspect(cached=True).response)\n        except docker.errors.NotFound:\n            raise NotAvailableAnymore()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of dicts with the top level processes in a running container", "response": "def top(self):\n        \"\"\"\n        list of processes in a running container\n\n        :return: None or list of dicts\n        \"\"\"\n        # let's get resources from .stats()\n        ps_args = \"-eo pid,ppid,wchan,args\"\n        # returns {\"Processes\": [values], \"Titles\": [values]}\n        # it's easier to play with list of dicts: [{\"pid\": 1, \"ppid\": 0}]\n        try:\n            response = self.d.top(self.container_id, ps_args=ps_args)\n        except docker.errors.APIError as ex:\n            logger.warning(\"error getting processes: %r\", ex)\n            return []\n        # TODO: sort?\n        logger.debug(json.dumps(response, indent=2))\n        return [dict(zip(response[\"Titles\"], process))\n                for process in response[\"Processes\"] or []]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filter(self, containers=True, images=True, stopped=True, cached=False, sort_by_created=True):\n        content = []\n        containers_o = None\n        images_o = None\n        # return containers when containers=False and running=True\n        if containers or not stopped:\n            containers_o = self.get_containers(cached=cached, stopped=stopped)\n            content += containers_o.response\n        if images:\n            images_o = self.get_images(cached=cached)\n            content += images_o.response\n        if sort_by_created:\n            content.sort(key=attrgetter(\"natural_sort_value\"), reverse=True)\n        return content, containers_o, images_o", "response": "Return a list of the available items for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef column_widths(self, size, focus=False):\n        maxcol = size[0]\n        self._cache_maxcol = maxcol\n        widths = [width for i, (w, (t, width, b)) in enumerate(self.contents)]\n        self._cache_column_widths = widths\n\n        return widths", "response": "Return a list of column widths."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extract_data_from_inspect(network_name, network_data):\n    a4 = None\n    if network_name == \"host\":\n        a4 = \"127.0.0.1\"\n    n = {}\n    a4 = graceful_chain_get(network_data, \"IPAddress\") or a4\n    if a4:\n        n[\"ip_address4\"] = a4\n    a6 = graceful_chain_get(network_data, \"GlobalIPv6Address\")\n    if a6:\n        n[\"ip_address4\"] = a6\n    return n", "response": "Extract data from the network data dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ports(self):\n\n        if self._ports is None:\n            self._ports = {}\n            if self.net_settings[\"Ports\"]:\n                for key, value in self.net_settings[\"Ports\"].items():\n                    cleaned_port = key.split(\"/\")[0]\n                    self._ports[cleaned_port] = graceful_chain_get(value, 0, \"HostPort\")\n            # in case of --net=host, there's nothing in network settings, let's get it from \"Config\"\n            exposed_ports_section = graceful_chain_get(self.inspect_data, \"Config\", \"ExposedPorts\")\n            if exposed_ports_section:\n                for key, value in exposed_ports_section.items():\n                    cleaned_port = key.split(\"/\")[0]\n                    self._ports[cleaned_port] = None  # extremely docker specific\n        return self._ports", "response": "Returns a dict of ports and their respective hostnames."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dict of all the ips that are available for this application.", "response": "def ips(self):\n        \"\"\"\n        :return: dict:\n        {\n            \"default\": {\n                \"ip_address4\": \"12.34.56.78\"\n                \"ip_address6\": \"ff:fa:...\"\n            }\n            \"other\": {\n                ...\n            }\n        }\n        \"\"\"\n        if self._ips is None:\n            self._ips = {}\n            default_net = extract_data_from_inspect(\"default\", self.net_settings)\n            if default_net:\n                self._ips[\"default\"] = default_net\n            # this can be None\n            networks = self.inspect_data[\"NetworkSettings\"][\"Networks\"]\n            if networks:\n                for network_name, network_data in networks.items():\n                    self._ips[network_name] = extract_data_from_inspect(network_name, network_data)\n\n        return self._ips"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef refresh(self, query=None):\n        logger.info(\"refresh listing\")\n        focus_on_top = len(self.body) == 0  # focus if empty\n        with self.refresh_lock:\n            self.query(query_string=query)\n        if focus_on_top:\n            try:\n                self.set_focus(0)\n            except IndexError:\n                pass", "response": "refresh the list of items"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef query(self, query_string=\"\"):\n\n        def query_notify(operation):\n            w = get_operation_notify_widget(operation, display_always=False)\n            if w:\n                self.ui.notify_widget(w)\n\n        if query_string is not None:\n            self.filter_query = query_string.strip()\n\n        # FIXME: this could be part of filter command since it's command line\n        backend_query = {\n            \"cached\": False,\n            \"containers\": True,\n            \"images\": True,\n        }\n\n        def containers():\n            backend_query[\"containers\"] = True\n            backend_query[\"images\"] = not backend_query[\"images\"]\n            backend_query[\"cached\"] = True\n\n        def images():\n            backend_query[\"containers\"] = not backend_query[\"containers\"]\n            backend_query[\"images\"] = True\n            backend_query[\"cached\"] = True\n\n        def running():\n            backend_query[\"stopped\"] = False\n            backend_query[\"cached\"] = True\n            backend_query[\"images\"] = False\n\n        query_conf = [\n            {\n                \"query_keys\": [\"t\", \"type\"],\n                \"query_values\": [\"c\", \"container\", \"containers\"],\n                \"callback\": containers\n            }, {\n                \"query_keys\": [\"t\", \"type\"],\n                \"query_values\": [\"i\", \"images\", \"images\"],\n                \"callback\": images\n            }, {\n                \"query_keys\": [\"s\", \"state\"],\n                \"query_values\": [\"r\", \"running\"],\n                \"callback\": running\n            },\n        ]\n        query_list = re.split(r\"[\\s,]\", self.filter_query)\n        unprocessed = []\n        for query_str in query_list:\n            if not query_str:\n                continue\n            # process here x=y queries and pass rest to parent filter()\n            try:\n                query_key, query_value = query_str.split(\"=\", 1)\n            except ValueError:\n                unprocessed.append(query_str)\n            else:\n                logger.debug(\"looking up query key %r and query value %r\", query_key, query_value)\n                for c in query_conf:\n                    if query_key in c[\"query_keys\"] and query_value in c[\"query_values\"]:\n                        c[\"callback\"]()\n                        break\n                else:\n                    raise NotifyError(\"Invalid query string: %r\", query_str)\n\n        widgets = []\n        logger.debug(\"doing query %s\", backend_query)\n        query, c_op, i_op = self.d.filter(**backend_query)\n\n        for o in query:\n            try:\n                line = MainLineWidget(o)\n            except NotAvailableAnymore:\n                continue\n            widgets.append(line)\n        if unprocessed:\n            new_query = \" \".join(unprocessed)\n            logger.debug(\"doing parent query for unprocessed string: %r\", new_query)\n            super().filter(new_query, widgets_to_filter=widgets)\n        else:\n            self.set_body(widgets)\n            self.ro_content = widgets\n\n        query_notify(i_op)\n        query_notify(c_op)", "response": "query and display the related items"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process(self, argument_list):\n        arg_index = 0\n        for a in argument_list:\n            opt_and_val = a.split(\"=\", 1)\n            opt_name = opt_and_val[0]\n            try:\n                # option\n                argument = self.options[opt_name]\n            except KeyError:\n                # argument\n                try:\n                    argument = self.arguments[arg_index]\n                except IndexError:\n                    logger.error(\"option/argument %r not specified\", a)\n                    raise NoSuchOptionOrArgument(\"No such option or argument: %r\" % opt_name)\n            logger.info(\"argument found: %s\", argument)\n\n            safe_arg_name = normalize_arg_name(argument.name)  # so we can access names-with-dashes\n\n            logger.info(\"argument is available under name %r\", safe_arg_name)\n\n            if isinstance(argument, Argument):\n                arg_index += 1\n                value = (a, )\n            else:\n                try:\n                    value = (opt_and_val[1], )\n                except IndexError:\n                    value = tuple()\n\n            arg_val = argument.action(*value)\n\n            logger.info(\"argument %r has value %r\", safe_arg_name, arg_val)\n            self.given_arguments[safe_arg_name] = arg_val\n        return self.given_arguments", "response": "Process the given argument list and return the dictionary of arguments that can be used to set the value of the given option."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_command(self, command_input, docker_object=None, buffer=None, size=None):\n        logger.debug(\"get command for command input %r\", command_input)\n\n        if not command_input:\n            # noop, don't do anything\n            return\n\n        if command_input[0] in [\"/\"]:  # we could add here !, @, ...\n            command_name = command_input[0]\n            unparsed_command_args = shlex.split(command_input[1:])\n        else:\n            command_input_list = shlex.split(command_input)\n            command_name = command_input_list[0]\n            unparsed_command_args = command_input_list[1:]\n\n        try:\n            CommandClass = commands_mapping[command_name]\n        except KeyError:\n            logger.info(\"no such command: %r\", command_name)\n            raise NoSuchCommand(\"There is no such command: %s\" % command_name)\n        else:\n            cmd = CommandClass(ui=self.ui, docker_backend=self.docker_backend,\n                               docker_object=docker_object, buffer=buffer, size=size)\n            cmd.process_args(unparsed_command_args)\n            return cmd", "response": "get command instance from command input"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nplaying a single audio file or raw audio data", "response": "def play(self, wav=None, data=None, rate=16000, channels=1, width=2, block=True, spectrum=None):\n        \"\"\"\n        play wav file or raw audio (string or generator)\n        Args:\n            wav: wav file path\n            data: raw audio data, str or iterator\n            rate: sample rate, only for raw audio\n            channels: channel number, only for raw data\n            width: raw audio data width, 16 bit is 2, only for raw data\n            block: if true, block until audio is played.\n            spectrum: if true, use a spectrum analyzer thread to analyze data\n        \"\"\"\n        if wav:\n            f = wave.open(wav, 'rb')\n            rate = f.getframerate()\n            channels = f.getnchannels()\n            width = f.getsampwidth()\n\n            def gen(w):\n                d = w.readframes(CHUNK_SIZE)\n                while d:\n                    yield d\n                    d = w.readframes(CHUNK_SIZE)\n                w.close()\n\n            data = gen(f)\n\n        self.stop_event.clear()\n        if block:\n            self._play(data, rate, channels, width, spectrum)\n        else:\n            thread = threading.Thread(target=self._play, args=(data, rate, channels, width, spectrum))\n            thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getAllConnectedInterface():\n        # find all devices matching the vid/pid specified\n        dev = usb.core.find(idVendor=0x2886, idProduct=0x0007)\n\n        if not dev:\n            logging.debug(\"No device connected\")\n            return []\n\n        interface_number = -1\n\n        # get active config\n        config = dev.get_active_configuration()\n\n        # iterate on all interfaces:\n        #    - if we found a HID interface\n        for interface in config:\n            if interface.bInterfaceClass == 0x03:\n                interface_number = interface.bInterfaceNumber\n                break\n\n        if interface_number == -1:\n            return []\n\n        try:\n            if dev.is_kernel_driver_active(interface_number):\n                dev.detach_kernel_driver(interface_number)\n        except Exception as e:\n            print(e)\n\n        ep_in, ep_out = None, None\n        for ep in interface:\n            if ep.bEndpointAddress & 0x80:\n                ep_in = ep\n            else:\n                ep_out = ep\n\n        \"\"\"If there is no EP for OUT then we can use CTRL EP\"\"\"\n        if not ep_in:\n            logging.error('Endpoints not found')\n            return []\n\n        board = PyUSB()\n        board.ep_in = ep_in\n        board.ep_out = ep_out\n        board.dev = dev\n        board.intf_number = interface_number\n        board.start_rx()\n\n        return [board]", "response": "getAllConnectedInterface - Returns all the connected devices which matches the vid / pid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, data):\n\n        # report_size = 64\n        # if self.ep_out:\n        #     report_size = self.ep_out.wMaxPacketSize\n        #\n        # for _ in range(report_size - len(data)):\n        #    data.append(0)\n\n        self.read_sem.release()\n\n        if not self.ep_out:\n            bmRequestType = 0x21       #Host to device request of type Class of Recipient Interface\n            bmRequest = 0x09           #Set_REPORT (HID class-specific request for transferring data over EP0)\n            wValue = 0x200             #Issuing an OUT report\n            wIndex = self.intf_number  #mBed Board interface number for HID\n            self.dev.ctrl_transfer(bmRequestType, bmRequest, wValue, wIndex, data)\n            return\n            #raise ValueError('EP_OUT endpoint is NULL')\n\n        self.ep_out.write(data)\n        #logging.debug('sent: %s', data)\n        return", "response": "write data on the OUT endpoint associated to the HID interface"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getAllConnectedInterface():\n        all_devices = hid.find_all_hid_devices()\n\n        # find devices with good vid/pid\n        all_mbed_devices = []\n        for d in all_devices:\n            if (d.product_name.find(\"MicArray\") >= 0):\n                all_mbed_devices.append(d)\n\n        boards = []\n        for dev in all_mbed_devices:\n            try:\n                dev.open(shared=False)\n                report = dev.find_output_reports()\n                if (len(report) == 1):\n                    new_board = PyWinUSB()\n                    new_board.report = report[0]\n                    new_board.vendor_name = dev.vendor_name\n                    new_board.product_name = dev.product_name\n                    new_board.serial_number = dev.serial_number\n                    new_board.vid = dev.vendor_id\n                    new_board.pid = dev.product_id\n                    new_board.device = dev\n                    new_board.device.set_raw_data_handler(new_board.rx_handler)\n\n                    boards.append(new_board)\n            except Exception as e:\n                logging.error(\"Receiving Exception: %s\", e)\n                dev.close()\n\n        return boards", "response": "Returns all the connected CMSIS -DAP boards."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites data on the OUT endpoint associated to the HID interface", "response": "def write(self, data):\n        \"\"\"\n        write data on the OUT endpoint associated to the HID interface\n        \"\"\"\n        for _ in range(64 - len(data)):\n            data.append(0)\n        #logging.debug(\"send: %s\", data)\n        self.report.send(bytearray([0]) + data)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read(self, timeout=1.0):\n        start = time()\n        while len(self.rcv_data) == 0:\n            if time() - start > timeout:\n                # Read operations should typically take ~1-2ms.\n                # If this exception occurs, then it could indicate\n                # a problem in one of the following areas:\n                # 1. Bad usb driver causing either a dropped read or write\n                # 2. CMSIS-DAP firmware problem cause a dropped read or write\n                # 3. CMSIS-DAP is performing a long operation or is being\n                #    halted in a debugger\n                raise Exception(\"Read timed out\")\n        return self.rcv_data.popleft()", "response": "read data from the IN endpoint associated to the HID interface"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns all the connected USB interfaces which match the given USB device.", "response": "def getAllConnectedInterface():\n        \"\"\"\n        returns all the connected devices which matches HidApiUSB.vid/HidApiUSB.pid.\n        returns an array of HidApiUSB (Interface) objects\n        \"\"\"\n\n        devices = hid.enumerate()\n\n        if not devices:\n            logging.debug(\"No Mbed device connected\")\n            return []\n\n        boards = []\n\n        for deviceInfo in devices:\n            product_name = deviceInfo['product_string']\n            if (product_name.find(\"MicArray\") < 0):\n                # Skip non cmsis-dap devices\n                continue\n\n            try:\n                dev = hid.device(vendor_id=deviceInfo['vendor_id'], product_id=deviceInfo['product_id'],\n                    path=deviceInfo['path'])\n            except IOError:\n                logging.debug(\"Failed to open Mbed device\")\n                continue\n\n            # Create the USB interface object for this device.\n            new_board = HidApiUSB()\n            new_board.vendor_name = deviceInfo['manufacturer_string']\n            new_board.product_name = deviceInfo['product_string']\n            new_board.serial_number = deviceInfo['serial_number']\n            new_board.vid = deviceInfo['vendor_id']\n            new_board.pid = deviceInfo['product_id']\n            new_board.device_info = deviceInfo\n            new_board.device = dev\n            try:\n                dev.open_path(deviceInfo['path'])\n            except AttributeError:\n                pass\n            except IOError:\n                # Ignore failure to open a device by skipping the device.\n                continue\n\n            boards.append(new_board)\n\n        return boards"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(self, data):\n        for _ in range(64 - len(data)):\n            data.append(0)\n        #logging.debug(\"send: %s\", data)\n        self.device.write(bytearray([0]) + data)\n        return", "response": "write data on the OUT endpoint associated to the HID interface"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef encode(epochs, iso_8601=True):  # @NoSelf\n        if (isinstance(epochs, int) or isinstance(epochs, np.int64)):\n            return CDFepoch.encode_tt2000(epochs, iso_8601)\n        elif (isinstance(epochs, float) or isinstance(epochs, np.float64)):\n            return CDFepoch.encode_epoch(epochs, iso_8601)\n        elif (isinstance(epochs, complex) or isinstance(epochs, np.complex128)):\n            return CDFepoch.encode_epoch16(epochs, iso_8601)\n        elif (isinstance(epochs, list) or isinstance(epochs, np.ndarray)):\n            if (isinstance(epochs[0], int) or isinstance(epochs[0], np.int64)):\n                return CDFepoch.encode_tt2000(epochs, iso_8601)\n            elif (isinstance(epochs[0], float) or\n                  isinstance(epochs[0], np.float64)):\n                return CDFepoch.encode_epoch(epochs, iso_8601)\n            elif (isinstance(epochs[0], complex) or\n                  isinstance(epochs[0], np.complex128)):\n                return CDFepoch.encode_epoch16(epochs, iso_8601)\n            else:\n                print('Bad input')\n                return None\n        else:\n            print('Bad input')\n            return None", "response": "Encodes the epoch in a list of time series."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unixtime(cdf_time, to_np=False):  # @NoSelf\n        import datetime\n        time_list = CDFepoch.breakdown(cdf_time, to_np=False)\n\n        #Check if only one time was input into unixtime.\n        #If so, turn the output of breakdown into a list for this function to work\n        if hasattr(cdf_time, '__len__'):\n           if len(cdf_time) == 1:\n               time_list = [time_list]\n        else:\n            time_list = [time_list]\n\n        unixtime = []\n        for t in time_list:\n            date = ['year', 'month', 'day', 'hour', 'minute', 'second', 'microsecond']\n            for i in range(0, len(t)):\n                if i > 7:\n                    continue\n                elif i == 6:\n                    date[i] = 1000*t[i]\n                elif i == 7:\n                    date[i-1] += t[i]\n                else:\n                    date[i] = t[i]\n            unixtime.append(datetime.datetime(*date).replace(tzinfo=datetime.timezone.utc).timestamp())\n        return np.array(unixtime) if to_np else unixtime", "response": "Converts a time in the format of a UNIX time into a list of datetime objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the CDF_EPOCH value for the provided date and time values.", "response": "def compute(datetimes, to_np=None):  # @NoSelf\n        \"\"\"\n        Computes the provided date/time components into CDF epoch value(s).\n\n        For CDF_EPOCH:\n                For computing into CDF_EPOCH value, each date/time elements should\n                have exactly seven (7) components, as year, month, day, hour, minute,\n                second and millisecond, in a list. For example:\n                [[2017,1,1,1,1,1,111],[2017,2,2,2,2,2,222]]\n                Or, call function compute_epoch directly, instead, with at least three\n                (3) first (up to seven) components. The last component, if\n                not the 7th, can be a float that can have a fraction of the unit.\n\n        For CDF_EPOCH16:\n                They should have exactly ten (10) components, as year,\n                month, day, hour, minute, second, millisecond, microsecond, nanosecond\n                and picosecond, in a list. For example:\n                [[2017,1,1,1,1,1,123,456,789,999],[2017,2,2,2,2,2,987,654,321,999]]\n                Or, call function compute_epoch directly, instead, with at least three\n                (3) first (up to ten) components. The last component, if\n                not the 10th, can be a float that can have a fraction of the unit.\n\n        For TT2000:\n                Each TT2000 typed date/time should have exactly nine (9) components, as\n                year, month, day, hour, minute, second, millisecond, microsecond,\n                and nanosecond, in a list.  For example:\n                [[2017,1,1,1,1,1,123,456,789],[2017,2,2,2,2,2,987,654,321]]\n                Or, call function compute_tt2000 directly, instead, with at least three\n                (3) first (up to nine) components. The last component, if\n                not the 9th, can be a float that can have a fraction of the unit.\n\n        Specify to_np to True, if the result should be in numpy class.\n        \"\"\"\n\n        if not isinstance(datetimes, (list, tuple, np.ndarray)):\n            raise TypeError('datetime must be in list form')\n\n        if isinstance(datetimes[0], numbers.Number):\n            items = len(datetimes)\n        elif isinstance(datetimes[0], (list, tuple, np.ndarray)):\n            items = len(datetimes[0])\n        else:\n            print('Unknown input')\n            return\n\n        if (items == 7):\n            return CDFepoch.compute_epoch(datetimes, to_np)\n        elif (items == 10):\n            return CDFepoch.compute_epoch16(datetimes, to_np)\n        elif (items == 9):\n            return CDFepoch.compute_tt2000(datetimes, to_np)\n        else:\n            print('Unknown input')\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef findepochrange(epochs, starttime=None, endtime=None):  # @NoSelf\n        if (isinstance(epochs, float) or isinstance(epochs, np.float64)):\n            return CDFepoch.epochrange_epoch(epochs, starttime, endtime)\n        elif (isinstance(epochs, int) or isinstance(epochs, np.int64)):\n            return CDFepoch.epochrange_tt2000(epochs, starttime, endtime)\n        elif isinstance(epochs, (complex, np.complex128)):\n            return CDFepoch.epochrange_epoch16(epochs, starttime, endtime)\n        elif isinstance(epochs, (list, tuple, np.ndarray)):\n            if (isinstance(epochs[0], float) or\n                    isinstance(epochs[0], np.float64)):\n                return CDFepoch.epochrange_epoch(epochs, starttime, endtime)\n            elif (isinstance(epochs[0], int) or\n                  isinstance(epochs[0], np.int64)):\n                return CDFepoch.epochrange_tt2000(epochs, starttime, endtime)\n            elif (isinstance(epochs[0], complex) or\n                  isinstance(epochs[0], np.complex128)):\n                return CDFepoch.epochrange_epoch16(epochs, starttime, endtime)\n            else:\n                print('Bad input')\n                return None\n        else:\n            print('Bad input')\n            return None", "response": "This function returns a list of record numbers within the start and end time of a CDF epoch."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef breakdown_tt2000(tt2000, to_np=None):  # @NoSelf\n        if (isinstance(tt2000, int) or isinstance(tt2000, np.int64)):\n            new_tt2000 = [tt2000]\n        elif (isinstance(tt2000, list) or isinstance(tt2000, tuple) or\n              isinstance(tt2000, np.ndarray)):\n            new_tt2000 = tt2000\n        else:\n            print('Bad input data')\n            return None\n        count = len(new_tt2000)\n        toutcs = []\n        for x in range(0, count):\n            nanoSecSinceJ2000 = new_tt2000[x]\n            toPlus = 0.0\n            t3 = nanoSecSinceJ2000\n            datx = CDFepoch._LeapSecondsfromJ2000(nanoSecSinceJ2000)\n            if (nanoSecSinceJ2000 > 0):\n                secSinceJ2000 = int(nanoSecSinceJ2000/CDFepoch.SECinNanoSecsD)\n                nansec = int(nanoSecSinceJ2000 - secSinceJ2000 *\n                             CDFepoch.SECinNanoSecs)\n                secSinceJ2000 = secSinceJ2000 - 32\n                secSinceJ2000 = secSinceJ2000 + 43200\n                nansec = nansec - 184000000\n            else:\n                nanoSecSinceJ2000 = nanoSecSinceJ2000 + CDFepoch.T12hinNanoSecs\n                nanoSecSinceJ2000 = nanoSecSinceJ2000 - CDFepoch.dTinNanoSecs\n                secSinceJ2000 = int(nanoSecSinceJ2000/CDFepoch.SECinNanoSecsD)\n                nansec = int(nanoSecSinceJ2000 - secSinceJ2000 *\n                             CDFepoch.SECinNanoSecs)\n            if (nansec < 0):\n                nansec = CDFepoch.SECinNanoSecs + nansec\n                secSinceJ2000 = secSinceJ2000 - 1\n            t2 = secSinceJ2000 * CDFepoch.SECinNanoSecs + nansec\n            if (datx[0] > 0.0):\n                # post-1972...\n                secSinceJ2000 = secSinceJ2000 - int(datx[0])\n                epoch = CDFepoch.J2000Since0AD12hSec + secSinceJ2000\n                if (datx[1] == 0.0):\n                    date1 = CDFepoch._EPOCHbreakdownTT2000(epoch)\n                else:\n                    epoch = epoch - 1\n                    date1 = CDFepoch._EPOCHbreakdownTT2000(epoch)\n                    date1[5] = date1[5] + 1\n                ye1 = date1[0]\n                mo1 = date1[1]\n                da1 = date1[2]\n                ho1 = date1[3]\n                mi1 = date1[4]\n                se1 = date1[5]\n            else:\n                # pre-1972...\n                epoch = secSinceJ2000 + CDFepoch.J2000Since0AD12hSec\n                xdate1 = CDFepoch._EPOCHbreakdownTT2000(epoch)\n                xdate1.append(0)\n                xdate1.append(0)\n                xdate1.append(nansec)\n                tmpNanosecs = CDFepoch.compute_tt2000(xdate1)\n                if (tmpNanosecs != t3):\n                    dat0 = CDFepoch._LeapSecondsfromYMD(xdate1[0],\n                                                        xdate1[1], xdate1[2])\n                    tmpx = t2 - int(dat0 * CDFepoch.SECinNanoSecs)\n                    tmpy = int(float(tmpx/CDFepoch.SECinNanoSecsD))\n                    nansec = int(tmpx - tmpy * CDFepoch.SECinNanoSecs)\n                if (nansec < 0):\n                    nansec = CDFepoch.SECinNanoSecs + nansec\n                    tmpy = tmpy - 1\n                    epoch = tmpy + CDFepoch.J2000Since0AD12hSec\n                    xdate1 = CDFepoch._EPOCHbreakdownTT2000(epoch)\n                    xdate1.append(0)\n                    xdate1.append(0)\n                    xdate1.append(nansec)\n                    tmpNanosecs = CDFepoch.compute_tt2000(xdate1)\n                if (tmpNanosecs != t3):\n                    dat0 = CDFepoch._LeapSecondsfromYMD(xdate1[0],\n                                                        xdate1[1], xdate1[2])\n                    tmpx = t2 - int(dat0 * CDFepoch.SECinNanoSecs)\n                    tmpy = int((1.0*tmpx)/CDFepoch.SECinNanoSecsD)\n                    nansec = int(tmpx - tmpy * CDFepoch.SECinNanoSecs)\n                    if (nansec < 0):\n                        nansec = CDFepoch.SECinNanoSecs + nansec\n                        tmpy = tmpy - 1\n                    epoch = tmpy + CDFepoch.J2000Since0AD12hSec\n                    xdate1 = CDFepoch._EPOCHbreakdownTT2000(epoch)\n                    xdate1.append(0)\n                    xdate1.append(0)\n                    xdate1.append(nansec)\n                    tmpNanosecs = CDFepoch.compute_tt2000(xdate1)\n                    if (tmpNanosecs != t3):\n                        dat0 = CDFepoch._LeapSecondsfromYMD(xdate1[0],\n                                                            xdate1[1],\n                                                            xdate1[2])\n                        tmpx = t2 - int(dat0 * CDFepoch.SECinNanoSecs)\n                        tmpy = int((1.0*tmpx)/CDFepoch.SECinNanoSecsD)\n                        nansec = int(tmpx - tmpy * CDFepoch.SECinNanoSecs)\n                        if (nansec < 0):\n                            nansec = CDFepoch.SECinNanoSecs + nansec\n                            tmpy = tmpy - 1\n                        epoch = tmpy + CDFepoch.J2000Since0AD12hSec\n                        # One more determination\n                        xdate1 = CDFepoch._EPOCHbreakdownTT2000(epoch)\n                ye1 = int(xdate1[0])\n                mo1 = int(xdate1[1])\n                da1 = int(xdate1[2])\n                ho1 = int(xdate1[3])\n                mi1 = int(xdate1[4])\n                se1 = int(xdate1[5])\n            ml1 = int(nansec / 1000000)\n            tmp1 = nansec - 1000000 * ml1\n            if (ml1 > 1000):\n                ml1 = ml1 - 1000\n                se1 = se1 + 1\n            ma1 = int(tmp1 / 1000)\n            na1 = int(tmp1 - 1000 * ma1)\n            datetime = []\n            datetime.append(ye1)\n            datetime.append(mo1)\n            datetime.append(da1)\n            datetime.append(ho1)\n            datetime.append(mi1)\n            datetime.append(se1)\n            datetime.append(ml1)\n            datetime.append(ma1)\n            datetime.append(na1)\n            if (count == 1):\n                if (to_np == None):\n                    return datetime\n                else:\n                    return np.array(datetime)\n            else:\n                toutcs.append(datetime)\n        if (to_np == None):\n            return toutcs\n        else:\n            return np.array(toutcs)", "response": "Breakdown the TT2000 time to UTC components."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse(value, to_np=None):  # @NoSelf\n        if ((isinstance(value, list) or isinstance(value, tuple)) and\n                not (isinstance(value[0], str))):\n            print('Invalid value... should be a string or a list of string')\n            return None\n        elif ((not (isinstance(value, list))) and\n              (not (isinstance(value, tuple))) and\n              (not (isinstance(value, str)))):\n            print('Invalid value... should be a string or a list of string')\n            return None\n        else:\n            if (isinstance(value, list) or isinstance(value, tuple)):\n                num = len(value)\n                epochs = []\n                for x in range(0, num):\n                    epochs.append(CDFepoch._parse_epoch(value[x]))\n                if (to_np == None):\n                    return epochs\n                else:\n                    return np.array(epochs)\n            else:\n                if (to_np == None):\n                    return CDFepoch._parse_epoch(value)\n                else:\n                    return np.array(CDFepoch._parse_epoch(value))", "response": "Parses the provided date or time string into CDF epoch value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getVersion():  # @NoSelf\n        print('epochs version:', str(CDFepoch.version) + '.' +\n              str(CDFepoch.release) + '.'+str(CDFepoch.increment))", "response": "Shows the code version."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the last date a leap second was added to the leap second table.", "response": "def getLeapSecondLastUpdated():  # @NoSelf\n        \"\"\"\n        Shows the latest date a leap second was added to the leap second table.\n        \"\"\"\n        print('Leap second last updated:', str(CDFepoch.LTS[-1][0]) + '-' +\n              str(CDFepoch.LTS[-1][1]) + '-' + str(CDFepoch.LTS[-1][2]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef close(self):\n        '''\n        Closes the CDF Class.\n\n            1. If compression was set, this is where the compressed file is\n               written.\n            2. If a checksum is needed, this will place the checksum at the end\n               of the file.\n\n        '''\n\n        if self.compressed_file is None:\n            with self.path.open('rb+') as f:\n                f.seek(0, 2)\n                eof = f.tell()\n                self._update_offset_value(f, self.gdr_head+36, 8, eof)\n                if self.checksum:\n                    f.write(self._md5_compute(f))\n            return\n# %%\n        with self.path.open('rb+') as f:\n            f.seek(0, 2)\n            eof = f.tell()\n            self._update_offset_value(f, self.gdr_head+36, 8, eof)\n\n            with self.compressed_file.open('wb+') as g:\n                g.write(bytearray.fromhex(CDF.V3magicNUMBER_1))\n                g.write(bytearray.fromhex(CDF.V3magicNUMBER_2c))\n                self._write_ccr(f, g, self.compression)\n\n                if self.checksum:\n                    g.seek(0, 2)\n                    g.write(self._md5_compute(g))\n\n        self.path.unlink()  # NOTE: for Windows this is necessary\n        self.compressed_file.rename(self.path)", "response": "Closes the CDF Class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_globalattrs(self, globalAttrs):\n        '''\n        Writes the global attributes.\n\n        Parameters\n        ----------\n        globalAttrs: dict\n            Global attribute name(s) and their value(s) pair(s).\n\n            The value(s) is a dictionary of entry number and value pair(s).\n            For example::\n\n                globalAttrs={}\n                globalAttrs['Global1']={0: 'Global Value 1'}\n                globalAttrs['Global2']={0: 'Global Value 2'}\n\n            For a non-string value, use a list with the value and its\n            CDF data type. For example::\n\n                globalAttrs['Global3']={0: [12, 'cdf_int4']}\n                globalAttrs['Global4']={0: [12.34, 'cdf_double']}\n\n            If the data type is not provided, a corresponding\n            CDF data type is assumed::\n\n                globalAttrs['Global3']={0: 12}     as 'cdf_int4'\n                globalAttrs['Global4']={0: 12.34}  as 'cdf_double'\n\n            CDF allows multi-values for non-string data for an attribute::\n\n                globalAttrs['Global5']={0: [[12.34,21.43], 'cdf_double']}\n\n            For multi-entries from a global variable, they should be\n            presented in this form::\n\n                GA6={}\n                GA6[0]='abcd'\n                GA6[1]=[12, 'cdf_int2']\n                GA6[2]=[12.5, 'cdf_float']\n                GA6[3]=[[0,1,2], 'cdf_int8']\n                globalAttrs['Global6']=GA6\n                ....\n                f.write_globalattrs(globalAttrs)\n        '''\n        if not (isinstance(globalAttrs, dict)):\n            print('Global attribute(s) not in dictionary form.... Stop')\n            return\n        dataType = None\n        numElems = None\n        with self.path.open('rb+') as f:\n            f.seek(0, 2)  # EOF (appending)\n            for attr, entry in globalAttrs.items():\n                if (attr in self.gattrs):\n                    raise ValueError('Global attribute: {} already exists.'.format(attr))\n\n                if (attr in self.vattrs):\n                    logging.warning('Attribute: {} already defined as a variable attribute.'.format(attr))\n                    continue\n\n                attrNum, offsetADR = self._write_adr(f, True, attr)\n                entries = 0\n                if (entry == None):\n                    continue\n                entryNumMaX = -1\n                poffset = -1\n                for entryNum, value in entry.items():\n                    if (entryNumMaX < entryNum):\n                        entryNumMaX = entryNum\n                    if (isinstance(value, list) or isinstance(value, tuple)):\n                        if (len(value) == 2):\n                            # Check if the second value is a valid data type\n                            value2 = value[1]\n                            dataType = CDF._datatype_token(value2)\n                            if (dataType > 0):\n                                # Data Type found\n                                data = value[0]\n                                if (dataType == CDF.CDF_CHAR or\n                                        dataType == CDF.CDF_UCHAR):\n                                    if (isinstance(data, list) or\n                                            isinstance(data, tuple)):\n                                        print('Invalid global attribute value.... Skip')\n                                        return\n                                    numElems = len(data)\n                                elif (dataType == CDF.CDF_EPOCH or\n                                      dataType == CDF.CDF_EPOCH16\n                                      or dataType == CDF.CDF_TIME_TT2000):\n                                    cvalue = []\n                                    if (isinstance(data, list) or\n                                            isinstance(data, tuple)):\n                                        numElems = len(data)\n                                        for x in range(0, numElems):\n                                            if (isinstance(data[x], str)):\n                                                cvalue.append(cdfepoch.CDFepoch.parse(data[x]))\n                                            else:\n                                                cvalue.append(data[x])\n                                        data = cvalue\n                                    else:\n                                        if (isinstance(data, str)):\n                                            data = cdfepoch.CDFepoch.parse(data)\n                                        numElems = 1\n                                else:\n                                    if (isinstance(data, list) or\n                                            isinstance(data, tuple)):\n                                        numElems = len(data)\n                                    else:\n                                        numElems = 1\n                            else:\n                                # Data type not found, both values are data.\n                                data = value\n                                numElems, dataType = CDF._datatype_define(value[0])\n                                numElems = len(value)\n                        else:\n                            # Length greater than 2, so it is all data.\n                            data = value\n                            numElems, dataType = CDF._datatype_define(value[0])\n                            numElems = len(value)\n                    else:\n                        # Just one value\n                        data = value\n                        numElems, dataType = CDF._datatype_define(value)\n                        if (numElems is None):\n                            print('Unknown data.... Skip')\n                            return\n\n                    offset = self._write_aedr(f, True, attrNum, entryNum, data,\n                                              dataType, numElems, None)\n                    if (entries == 0):\n                        # ADR's AgrEDRhead\n                        self._update_offset_value(f, offsetADR+20, 8, offset)\n                    else:\n                        # ADR's ADRnext\n                        self._update_offset_value(f, poffset+12, 8, offset)\n\n                    poffset = offset\n                    entries = entries + 1\n                # ADR's NgrEntries\n                self._update_offset_value(f, offsetADR+36, 4, entries)\n                # ADR's MAXgrEntry\n                self._update_offset_value(f, offsetADR+40, 4, entryNumMaX)", "response": "Writes the global attributes to the file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting a dictionary of variable attributes to the file.", "response": "def write_variableattrs(self, variableAttrs):\n        \"\"\"\n        Writes a variable's attributes, provided the variable already exists.\n\n        Parameters\n        ----------\n        variableAttrs : dict\n            Variable attribute name and its entry value pair(s).\n            The entry value is also a dictionary of variable id and value\n            pair(s).  Variable id can be the variable name or its id number\n            in the file. Use write_var function if the variable does not exist.\n            For example::\n\n                variableAttrs={}\n                entries_1={}\n                entries_1['var_name_1'] = 'abcd'\n                entries_1['var_name_2'] = [12, 'cdf_int4']\n                ....\n                variableAttrs['attr_name_1']=entries_1\n                entries_2={}\n                entries_2['var_name_1'] = 'xyz'\n                entries_2['var_name_2'] = [[12, 34], 'cdf_int4']\n                ....\n                variableAttrs['attr_name_2']=entries_2\n                ....\n                ....\n                f.write_variableattrs(variableAttrs)\n        \"\"\"\n        if not (isinstance(variableAttrs, dict)):\n            print('Variable attribute(s) not in dictionary form.... Stop')\n            return\n        dataType = None\n        numElems = None\n        with self.path.open('rb+') as f:\n            f.seek(0, 2)  # EOF (appending)\n            for attr, attrs in variableAttrs.items():\n                if not (isinstance(attr, str)):\n                    print('Attribute name should be a string... Stop')\n                    return\n                if (attr in self.gattrs):\n                    print('Variable attribute: ', attr,\n                          ' is already a global variable... Stop')\n                    return\n                if (attr in self.vattrs):\n                    attrNum = self.vattrs.index(attr)\n                    offsetA = self.attrsinfo[attrNum][2]\n                else:\n                    attrNum, offsetA = self._write_adr(f, False, attr)\n                entries = 0\n                if (attrs == None):\n                    continue\n                if not (isinstance(attrs, dict)):\n                    print('An attribute''s attribute(s) not in dictionary form.... ',\n                          'Stop')\n                    return\n                entryNumX = -1\n                poffset = -1\n                for entryID, value in attrs.items():\n                    if (isinstance(entryID, str) and (not (entryID in self.zvars) and\n                                                      not (entryID in self.rvars))):\n                        raise KeyError('{} not found in the CDF'.format(entryID))\n\n                    if (isinstance(entryID, numbers.Number) and\n                            (len(self.zvars) > 0 and len(self.rvars) > 0)):\n                        raise ValueError('{} can not be used as the CDF has both zVariables and rVariables'.format(entryID))\n\n                    if (isinstance(entryID, str)):\n                        try:\n                            entryNum = self.zvars.index(entryID)\n                            zVar = True\n                        except Exception:\n                            try:\n                                entryNum = self.rvars.index(entryID)\n                                zVar = False\n                            except Exception:\n                                raise KeyError('{} not found'.format(entryID))\n                    else:\n                        entryNum = int(entryID)\n                        if (len(self.zvars) > 0 and len(self.rvars) > 0):\n                            print('Can not use integer form for variable id as there ',\n                                  'are both zVariables and rVaribales... Stop')\n                            return\n                        if (len(self.zvars) > 0):\n                            if (entryNum >= len(self.zvars)):\n                                print('Variable id: ', entryID, ' not found... Stop')\n                                return\n                            else:\n                                zVar = True\n                        else:\n                            if (entryNum >= len(self.rvars)):\n                                print('Variable id: ', entryID, ' not found... Stop')\n                                return\n                            else:\n                                zVar = False\n                    if (entryNum > entryNumX):\n                        entryNumX = entryNum\n                    if (isinstance(value, list) or isinstance(value, tuple)):\n                        if (len(value) == 2):\n                            value2 = value[1]\n                            dataType = CDF._datatype_token(value2)\n                            if (dataType > 0):\n                                data = value[0]\n                                if (dataType == CDF.CDF_CHAR or\n                                        dataType == CDF.CDF_UCHAR):\n                                    if (isinstance(data, list) or\n                                            isinstance(data, tuple)):\n                                        print('Invalid variable attribute value.... Skip')\n                                        continue\n                                    numElems = len(data)\n                                elif (dataType == CDF.CDF_EPOCH or\n                                      dataType == CDF.CDF_EPOCH16\n                                      or dataType == CDF.CDF_TIME_TT2000):\n                                    cvalue = []\n                                    if (isinstance(data, list) or\n                                            isinstance(data, tuple)):\n                                        numElems = len(data)\n                                        for x in range(0, numElems):\n                                            if (isinstance(data[x], str)):\n                                                avalue = cdfepoch.CDFepoch.parse(data[x])\n                                            else:\n                                                avalue = data[x]\n                                            if (dataType == CDF.CDF_EPOCH16):\n                                                cvalue.append(avalue.real)\n                                                cvalue.append(avalue.imag)\n                                            else:\n                                                cvalue.append(avalue)\n                                                data = cvalue\n                                    else:\n                                        if (isinstance(data, str)):\n                                            data = cdfepoch.CDFepoch.parse(data)\n                                        numElems = 1\n                                else:\n                                    if (isinstance(data, list) or isinstance(data, tuple)):\n                                        numElems = len(data)\n                                    else:\n                                        numElems = 1\n                            else:\n                                data = value\n                                numElems, dataType = CDF._datatype_define(value[0])\n                                numElems = len(value)\n                        else:\n                            data = value\n                            numElems, dataType = CDF._datatype_define(value[0])\n                            numElems = len(value)\n                    else:\n                        data = value\n                        numElems, dataType = CDF._datatype_define(value)\n                        if (numElems is None):\n                            print('Unknown data.... Skip')\n                            return\n                    offset = self._write_aedr(f, False, attrNum, entryNum, data,\n                                              dataType, numElems, zVar)\n                    if (entries == 0):\n                        if (zVar == True):\n                            # ADR's AzEDRhead\n                            self._update_offset_value(f, offsetA+48, 8, offset)\n                        else:\n                            # ADR's AgrEDRhead\n                            self._update_offset_value(f, offsetA+20, 8, offset)\n                    else:\n                        # ADR's ADRnext\n                        self._update_offset_value(f, poffset+12, 8, offset)\n                    poffset = offset\n                    entries = entries + 1\n                if (zVar == True):\n                    # ADR's NzEntries\n                    self._update_offset_value(f, offsetA+56, 4, entries)\n                    # ADR's MAXzEntry\n                    self._update_offset_value(f, offsetA+60, 4, entryNumX)\n                else:\n                    # ADR's NgrEntries\n                    self._update_offset_value(f, offsetA+36, 4, entries)\n                    # ADR's MAXgrEntry\n                    self._update_offset_value(f, offsetA+40, 4, entryNumX)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite a variable to the log file.", "response": "def write_var(self, var_spec, var_attrs=None, var_data=None):\n        '''\n        Writes a variable, along with variable attributes and data.\n\n        Parameters\n        ----------\n        var_spec : dict\n            The specifications of the variable.\n\n            The required/optional keys for creating a variable:\n            Required keys:\n\n            - ['Variable']: The name of the variable\n            - ['Data_Type']: the CDF data type\n            - ['Num_Elements']: The number of elements. Always 1 the\n              for numeric type. The char length for string type.\n            - ['Rec_Vary']: Record variance\n\n            For zVariables:\n\n            - ['Dims_Sizes']: The dimensional sizes for zVariables only.\n              Use [] for 0-dimension. Each and\n              every dimension is varying for zVariables.\n\n            For rVariables:\n\n            - ['Dim_Vary']: The dimensional variances for rVariables only.\n\n            Optional keys:\n\n            - ['Var_Type']: Whether the variable is a zVariable or\n              rVariable. Valid values: \"zVariable\" and\n              \"rVariable\". The default is \"zVariable\".\n            - ['Sparse']: Whether the variable has sparse records.\n              Valid values are \"no_sparse\", \"pad_sparse\",\n              and \"prev_sparse\". The default is 'no_sparse'.\n            - ['Compress']: Set the gzip compression level (0 to 9), 0 for\n              no compression. The default is to compress\n              with level 6 (done only if the compressed\n              data is less than the uncompressed data).\n            - ['Block_Factor']: The blocking factor, the number of\n              records in a chunk when the variable is compressed.\n            - ['Pad']: The padded value (in bytes, numpy.ndarray or string)\n\n        var_attrs : dict\n            {attribute:value} pairs.\n\n            The attribute is the name of a variable attribute.\n            The value can have its data type specified for the\n            numeric data. If not, based on Python's type, a\n            corresponding CDF type is assumed: CDF_INT4 for int,\n            CDF_DOUBLE for float, CDF_EPOCH16 for complex and\n            and CDF_INT8 for long.\n\n            For example, the following defined attributes will\n            have the same types in the CDF::\n\n                var_attrs= { 'attr1':  'value1',\n                          'attr2':  12.45,\n                          'attr3':  [3,4,5],\n                          .....\n                        }\n\n            With data type (in the list form)::\n\n                var_attrs= { 'attr1':  'value1',\n                          'attr2':  [12.45, 'CDF_DOUBLE'],\n                          'attr3':  [[3,4,5], 'CDF_INT4'],\n                          .....\n                        }\n\n        var_data :\n            The data for the variable. If the variable is\n            a regular variable without sparse records, it must\n            be in a single structure of bytes, or numpy.ndarray\n            for numeric variable, or str or list of strs for\n            string variable.\n            If the variable has sparse records, var_data should\n            be presented in a list/tuple with two elements,\n            the first being a list/tuple that contains the\n            physical record number(s), the second being the variable\n            data in bytes, numpy.ndarray, or a list of strings. Variable\n            data can have just physical records' data (with the same\n            number of records as the first element) or have data from both\n            physical records and virtual records (which with filled data).\n            The var_data has the form::\n\n                [[rec_#1,rec_#2,rec_#3,...],\n                [data_#1,data_#2,data_#3,...]]\n\n            See the sample for its setup.\n\n        '''\n        if not isinstance(var_spec, dict):\n            raise TypeError('Variable should be in dictionary form.')\n\n        # Get variable info from var_spec\n        try:\n            dataType = int(var_spec['Data_Type'])\n            numElems = int(var_spec['Num_Elements'])\n            name = var_spec['Variable']\n            recVary = var_spec['Rec_Vary']\n        except Exception:\n            raise ValueError('Missing/invalid required spec for creating variable.')\n        # Get whether or not it is a z variable\n        var_type = var_spec.setdefault('Var_Type', 'zvariable')\n        if (var_type.lower() == 'zvariable'):\n            zVar = True\n        else:\n            var_spec['Var_Type'] = 'rVariable'\n            zVar = False\n\n        if (dataType == CDF.CDF_CHAR or dataType == CDF.CDF_UCHAR):\n            if numElems < 1:\n                raise ValueError('Invalid Num_Elements for string data type variable')\n        else:\n            if numElems != 1:\n                raise ValueError('Invalid Num_Elements for numeric data type variable')\n        # If its a z variable, get the dimension info\n        # Otherwise, use r variable info\n        if zVar:\n            try:\n                dimSizes = var_spec['Dim_Sizes']\n                numDims = len(dimSizes)\n                dimVary = []\n                for _ in range(0, numDims):\n                    dimVary.append(True)\n            except Exception:\n                raise ValueError('Missing/invalid required spec for creating variable.')\n        else:\n            dimSizes = self.rdim_sizes\n            numDims = self.num_rdim\n            try:\n                dimVary = var_spec['Dim_Vary']\n                if (len(dimVary) != numDims):\n                    raise ValueError('Invalid Dim_Vary size for the rVariable.')\n            except Exception:\n                raise ValueError('Missing/invalid required spec for Dim_Vary for rVariable')\n        # Get Sparseness info\n        sparse = CDF._sparse_token(var_spec.get('Sparse', 'no_sparse'))\n        # Get compression info\n        compression = var_spec.get('Compress', 6)\n        if (isinstance(compression, int)):\n            if not 0 <= compression <= 9:\n                compression = 0\n        else:\n            compression = 6 if compression else 0\n\n        # Get blocking factor\n        blockingfactor = int(var_spec.get('Block_Factor', 1))\n\n        # Get pad value\n        pad = var_spec.get('Pad', None)\n        if (isinstance(pad, list) or isinstance(pad, tuple)):\n            pad = pad[0]\n\n        if (name in self.zvars or name in self.rvars):\n            raise ValueError('{} already exists'.format(name))\n\n        with self.path.open('rb+') as f:\n            f.seek(0, 2)  # EOF (appending)\n            varNum, offset = self._write_vdr(f, dataType, numElems, numDims,\n                                             dimSizes, name, dimVary, recVary,\n                                             sparse, blockingfactor, compression,\n                                             pad, zVar)\n            # Update the GDR pointers if needed\n            if zVar:\n                if len(self.zvars) == 1:\n                    # GDR's zVDRhead\n                    self._update_offset_value(f, self.gdr_head+20, 8, offset)\n            else:\n                if len(self.rvars) == 1:\n                    # GDR's rVDRhead\n                    self._update_offset_value(f, self.gdr_head+12, 8, offset)\n\n            # Write the variable attributes\n            if var_attrs is not None:\n                self._write_var_attrs(f, varNum, var_attrs, zVar)\n\n            # Write the actual data to the file\n            if not (var_data is None):\n                if (sparse == 0):\n                    varMaxRec = self._write_var_data_nonsparse(f, zVar, varNum,\n                                                               dataType, numElems,\n                                                               recVary, compression,\n                                                               blockingfactor,\n                                                               var_data)\n                else:\n                    notsupport = False\n                    if not isinstance(var_data, (list, tuple)):\n                        notsupport = True\n\n                    if notsupport or len(var_data) != 2:\n                        print('Sparse record #s and data are not of list/tuple form:')\n                        print(' [ [rec_#1, rec_#2, rec_#3,    ],')\n                        print('   [data_#1, data_#2, data_#3, ....] ]')\n                        return\n\n                    # Format data into: [[recstart1, recend1, data1],\n                    #                   [recstart2,recend2,data2], ...]\n                    var_data = self._make_sparse_blocks(var_spec, var_data[0],\n                                                        var_data[1])\n\n                    for block in var_data:\n                        varMaxRec = self._write_var_data_sparse(f, zVar, varNum,\n                                                                dataType, numElems,\n                                                                recVary, block)\n                # Update GDR MaxRec if writing an r variable\n                if not zVar:\n                    # GDR's rMaxRec\n                    f.seek(self.gdr_head+52)\n                    maxRec = int.from_bytes(f.read(4), 'big', signed=True)\n                    if (maxRec < varMaxRec):\n                        self._update_offset_value(f, self.gdr_head+52, 4, varMaxRec)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites variable attributes to the file f.", "response": "def _write_var_attrs(self, f, varNum, var_attrs, zVar):\n        '''\n        Writes ADRs and AEDRs for variables\n\n        Parameters:\n            f : file\n                The open CDF file\n            varNum : int\n                The variable number for adding attributes\n            var_attrs : dict\n                A dictionary object full of variable attributes\n            zVar : bool\n                True if varNum is referencing a z variable\n\n        Returns: None\n        '''\n\n        if (not isinstance(var_attrs, dict)):\n            raise TypeError('Variable attribute(s) should be in dictionary form.')\n\n        for attr, entry in var_attrs.items():\n            if (attr in self.gattrs):\n                print('Attribute: ', attr,\n                      ' already defined as a global attribute... Skip')\n                continue\n\n            if not (attr in self.attrs):\n                attrNum, offset = self._write_adr(f, False, attr)\n                if (len(self.attrs) == 0):\n                    # GDR's ADRhead\n                    self._update_offset_value(self.grd_offset+28, 8, offset)\n            else:\n                attrNum = self.attrs.index(attr)\n                offset = self.attrsinfo[attrNum][2]\n\n            if (entry is None):\n                continue\n\n            # Check if dataType was provided\n            dataType = 0\n            if (isinstance(entry, list) or isinstance(entry, tuple)):\n                items = len(entry)\n                if (items == 2):\n                    dataType = CDF._datatype_token(entry[1])\n\n            if (dataType > 0):\n                # CDF data type defined in entry\n                data = entry[0]\n                if (CDF._checklistofNums(data)):\n                    # All are numbers\n                    if (isinstance(data, list) or isinstance(data, tuple)):\n                        numElems = len(data)\n                    else:\n                        numElems = 1\n                else:\n                    # Then string(s) -- either in CDF_type or epoch in string(s)\n                    if (dataType == CDF.CDF_CHAR or dataType == CDF.CDF_UCHAR):\n                        if isinstance(data, (list, tuple)):\n                            items = len(data)\n                            odata = data\n                            data = str('')\n                            for x in range(0, items):\n                                if (x > 0):\n                                    data += str('\\\\N ')\n                                    data += odata[x]\n                                else:\n                                    data = odata[x]\n                        numElems = len(data)\n                    elif (dataType == CDF.CDF_EPOCH or dataType == CDF.CDF_EPOCH16\n                          or dataType == CDF.CDF_TIME_TT2000):\n                        cvalue = []\n                        if isinstance(data, (list, tuple)):\n                            numElems = len(data)\n                            for x in range(0, numElems):\n                                cvalue.append(cdfepoch.CDFepoch.parse(data[x]))\n                            data = cvalue\n                        else:\n                            data = cdfepoch.CDFepoch.parse(data)\n                            numElems = 1\n            else:\n                # No data type defined...\n                data = entry\n                if isinstance(entry, (list, tuple)):\n                    numElems, dataType = CDF._datatype_define(entry[0])\n                    if (dataType == CDF.CDF_CHAR or dataType == CDF.CDF_UCHAR):\n                        data = str('')\n                        for x in range(0, len(entry)):\n                            if (x > 0):\n                                data += str('\\\\N ')\n                                data += entry[x]\n                            else:\n                                data = entry[x]\n                    numElems = len(data)\n                else:\n                    numElems, dataType = CDF._datatype_define(entry)\n\n            offset = self._write_aedr(f, False, attrNum, varNum, data, dataType, numElems, zVar)\n\n            self._update_aedr_link(f, attrNum, zVar, varNum, offset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites a variable data to a nonsparse VVR file.", "response": "def _write_var_data_nonsparse(self, f, zVar, var, dataType, numElems,\n                                  recVary, compression, blockingfactor, indata):\n        '''\n        Creates VVRs and the corresponding VXRs full of \"indata\" data.\n        If there is no compression, creates exactly one VXR and VVR\n        If there is compression\n\n        Parameters:\n            f : file\n                The open CDF file\n            zVar : bool\n                True if this is z variable data\n            var : str\n                The name of the variable\n            dataType : int\n                the CDF variable type\n            numElems : int\n                number of elements in each record\n            recVary : bool\n                True if each record is unque\n            compression : int\n                The amount of compression\n            blockingfactor: int\n                The size (in number of records) of a VVR data block\n            indata : varies\n                the data to write, should be a numpy or byte array\n\n        Returns:\n            recs : int\n                The number of records\n\n        '''\n\n        numValues = self._num_values(zVar, var)\n        dataTypeSize = CDF._datatype_size(dataType, numElems)\n        if (isinstance(indata, dict)):\n            indata = indata['Data']\n\n        # Deal with EPOCH16 data types\n        if (dataType == CDF.CDF_EPOCH16):\n            epoch16 = []\n            if isinstance(indata, (list, tuple, np.ndarray)):\n                adata = indata[0]\n                if (isinstance(adata, complex)):\n                    recs = len(indata)\n                    for x in range(0, recs):\n                        epoch16.append(indata[x].real)\n                        epoch16.append(indata[x].imag)\n                    indata = epoch16\n            else:\n                if (isinstance(indata, complex)):\n                    epoch16.append(indata.real)\n                    epoch16.append(indata.imag)\n                    indata = epoch16\n\n        # Convert to byte stream\n        recs, data = self._convert_data(dataType, numElems, numValues, indata)\n\n        if not recVary:\n            recs = 1\n        if zVar:\n            vdr_offset = self.zvarsinfo[var][1]\n        else:\n            vdr_offset = self.rvarsinfo[var][1]\n\n        usedEntries = 0\n        editedVDR = False\n        numVXRs = 0\n        if compression > 0:\n            default_blockingfactor = math.ceil(CDF.BLOCKING_BYTES/(numValues * dataTypeSize))\n            # If the given blocking factor is too small, use the default one\n            # Will re-adjust if the records are less than this computed BF.\n            if (blockingfactor < default_blockingfactor):\n                blockingfactor = default_blockingfactor\n            if (blockingfactor == 0):\n                blockingfactor = 1\n            # set blocking factor\n            if (recs < blockingfactor):\n                blockingfactor = recs\n            blocks = math.ceil(recs / blockingfactor)\n            nEntries = CDF.NUM_VXR_ENTRIES\n            VXRhead = None\n\n            # Loop through blocks, create VVRs/CVVRs\n            for x in range(0, blocks):\n                startrec = x * blockingfactor\n                startloc = startrec * numValues * dataTypeSize\n                endrec = (x + 1) * blockingfactor - 1\n                if (endrec > (recs-1)):\n                    endrec = recs - 1\n                endloc = (endrec + 1) * numValues * dataTypeSize\n                if (endloc > len(data)):\n                    endrec = recs - 1\n                    endloc = len(data)\n                bdata = data[startloc:endloc]\n                cdata = gzip.compress(bdata, compression)\n                if (len(cdata) < len(bdata)):\n                    if not editedVDR:\n                        f.seek(vdr_offset+44, 0)\n                        # VDR's Flags\n                        flags = int.from_bytes(f.read(4), 'big', signed=True)\n                        flags = CDF._set_bit(flags, 2)\n                        self._update_offset_value(f, vdr_offset+44, 4, flags)\n                        f.seek(vdr_offset+80, 0)\n                        # VDR's BlockingFactor\n                        self._update_offset_value(f, vdr_offset+80, 4,\n                                                  blockingfactor)\n                        editedVDR = True\n                    n1offset = self._write_cvvr(f, cdata)\n                else:\n                    # Not worth compressing\n                    n1offset = self._write_vvr(f, bdata)\n                if (x == 0):\n                    # Create a VXR\n                    VXRoffset = self._write_vxr(f)\n                    VXRhead = VXRoffset\n                    numVXRs = 1\n                    self._update_vdr_vxrheadtail(f, vdr_offset, VXRoffset)\n                if (usedEntries < nEntries):\n                    # Use the exisitng VXR\n                    usedEntries = self._use_vxrentry(f, VXRoffset, startrec,\n                                                     endrec, n1offset)\n                else:\n                    # Create a new VXR and an upper level VXR, if needed.\n                    # Two levels of VXRs are the maximum, which is simpler\n                    # to implement.\n                    savedVXRoffset = VXRoffset\n                    VXRoffset = self._write_vxr(f)\n                    numVXRs += 1\n                    usedEntries = self._use_vxrentry(f, VXRoffset, startrec,\n                                                     endrec, n1offset)\n                    # Edit the VXRnext field of the previous VXR\n                    self._update_offset_value(f, savedVXRoffset+12, 8, VXRoffset)\n                    # Edit the VXRtail of the VDR\n                    self._update_offset_value(f, vdr_offset+36, 8, VXRoffset)\n\n            # After we're done with the blocks, check the way\n            # we have VXRs set up\n            if (numVXRs > CDF.NUM_VXRlvl_ENTRIES):\n                newvxrhead, newvxrtail = self._add_vxr_levels_r(f, VXRhead,\n                                                                numVXRs)\n                self._update_offset_value(f, vdr_offset+28, 8, newvxrhead)\n                self._update_offset_value(f, vdr_offset+36, 8, newvxrtail)\n        else:\n            # Create one VVR and VXR, with one VXR entry\n            offset = self._write_vvr(f, data)\n            VXRoffset = self._write_vxr(f)\n            usedEntries = self._use_vxrentry(f, VXRoffset, 0, recs-1, offset)\n            self._update_vdr_vxrheadtail(f, vdr_offset, VXRoffset)\n\n        # VDR's MaxRec\n        self._update_offset_value(f, vdr_offset+24, 4, recs-1)\n\n        return (recs-1)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _write_var_data_sparse(self, f, zVar, var, dataType, numElems, recVary,\n                               oneblock):\n        '''\n        Writes a VVR and a VXR for this block of sparse data\n\n        Parameters:\n            f : file\n                The open CDF file\n            zVar : bool\n                True if this is for a z variable\n            var : int\n                The variable number\n            dataType : int\n                The CDF data type of this variable\n            numElems : str\n                The number of elements in each record\n            recVary : bool\n                True if the value varies across records\n            oneblock: list\n                A list of data in the form [startrec, endrec, [data]]\n\n        Returns:\n            recend : int\n                Just the \"endrec\" value input by the user in \"oneblock\"\n        '''\n\n        rec_start = oneblock[0]\n        rec_end = oneblock[1]\n        indata = oneblock[2]\n        numValues = self._num_values(zVar, var)\n\n        # Convert oneblock[2] into a byte stream\n        _, data = self._convert_data(dataType, numElems, numValues, indata)\n\n        # Gather dimension information\n        if zVar:\n            vdr_offset = self.zvarsinfo[var][1]\n        else:\n            vdr_offset = self.rvarsinfo[var][1]\n\n        # Write one VVR\n        offset = self._write_vvr(f, data)\n        f.seek(vdr_offset+28, 0)\n\n        # Get first VXR\n        vxrOne = int.from_bytes(f.read(8), 'big', signed=True)\n        foundSpot = 0\n        usedEntries = 0\n        currentVXR = 0\n\n        # Search through VXRs to find an open one\n        while foundSpot == 0 and vxrOne > 0:\n            # have a VXR\n            f.seek(vxrOne, 0)\n            currentVXR = f.tell()\n            f.seek(vxrOne+12, 0)\n            vxrNext = int.from_bytes(f.read(8), 'big', signed=True)\n            nEntries = int.from_bytes(f.read(4), 'big', signed=True)\n            usedEntries = int.from_bytes(f.read(4), 'big', signed=True)\n            if (usedEntries == nEntries):\n                # all entries are used -- check the next vxr in link\n                vxrOne = vxrNext\n            else:\n                # found a vxr with an vailable entry spot\n                foundSpot = 1\n\n        # vxrOne == 0 from vdr's vxrhead vxrOne == -1 from a vxr's vxrnext\n        if (vxrOne == 0 or vxrOne == -1):\n            # no available vxr... create a new one\n            currentVXR = self._create_vxr(f, rec_start, rec_end, vdr_offset,\n                                          currentVXR, offset)\n        else:\n            self._use_vxrentry(f, currentVXR, rec_start, rec_end, offset)\n\n        # Modify the VDR's MaxRec if needed\n        f.seek(vdr_offset+24, 0)\n        recNumc = int.from_bytes(f.read(4), 'big', signed=True)\n        if (rec_end > recNumc):\n            self._update_offset_value(f, vdr_offset+24, 4, rec_end)\n\n        return rec_end", "response": "Writes a sparse data for a variable in a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a VXR and link it to the prior VXR.", "response": "def _create_vxr(self, f, recStart, recEnd, currentVDR, priorVXR, vvrOffset):\n        '''\n        Create a VXR AND use a VXR\n\n        Parameters:\n            f : file\n                The open CDF file\n            recStart : int\n                The start record of this block\n            recEnd : int\n                The ending record of this block\n            currentVDR : int\n                The byte location of the variables VDR\n            priorVXR : int\n                The byte location of the previous VXR\n            vvrOffset : int\n                The byte location of ther VVR\n\n        Returns:\n            vxroffset : int\n                The byte location of the created vxr\n\n        '''\n        # add a VXR, use an entry, and link it to the prior VXR if it exists\n        vxroffset = self._write_vxr(f)\n        self._use_vxrentry(f, vxroffset, recStart, recEnd, vvrOffset)\n        if (priorVXR == 0):\n            # VDR's VXRhead\n            self._update_offset_value(f, currentVDR+28, 8, vxroffset)\n        else:\n            # VXR's next\n            self._update_offset_value(f, priorVXR+12, 8, vxroffset)\n        # VDR's VXRtail\n        self._update_offset_value(f, currentVDR+36, 8, vxroffset)\n        return vxroffset"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a VVR pointer to a VXR", "response": "def _use_vxrentry(self, f, VXRoffset, recStart, recEnd, offset):\n        '''\n        Adds a VVR pointer to a VXR\n        '''\n        # Select the next unused entry in a VXR for a VVR/CVVR\n        f.seek(VXRoffset+20)\n        # num entries\n        numEntries = int.from_bytes(f.read(4), 'big', signed=True)\n        # used entries\n        usedEntries = int.from_bytes(f.read(4), 'big', signed=True)\n        # VXR's First\n        self._update_offset_value(f, VXRoffset+28+4*usedEntries, 4, recStart)\n        # VXR's Last\n        self._update_offset_value(f, VXRoffset+28+4*numEntries+4*usedEntries,\n                                  4, recEnd)\n        # VXR's Offset\n        self._update_offset_value(f, VXRoffset+28+2*4*numEntries+8*usedEntries,\n                                  8, offset)\n        # VXR's NusedEntries\n        usedEntries += 1\n        self._update_offset_value(f, VXRoffset+24, 4, usedEntries)\n        return usedEntries"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a new level of VXRs... make VXRs more tree-like From: VXR1 -> VXR2 -> VXR3 -> VXR4 -> ... -> VXRn To: new VXR1 / | \\ VXR2 VXR3 VXR4 / | \\ ... VXR5 .......... VXRn Parameters: f : file The open CDF file vxrhead : int The byte location of the first VXR for a variable numVXRs : int The total number of VXRs Returns: newVXRhead : int The byte location of the newest VXR head newvxroff : int The byte location of the last VXR head", "response": "def _add_vxr_levels_r(self, f, vxrhead, numVXRs):\n        '''\n        Build a new level of VXRs... make VXRs more tree-like\n\n        From:\n\n        VXR1 -> VXR2 -> VXR3 -> VXR4 -> ... -> VXRn\n\n        To:\n                           new VXR1\n                         /    |    \\\n                        VXR2 VXR3 VXR4\n                       /      |      \\\n                             ...\n                    VXR5  ..........  VXRn\n\n        Parameters:\n            f : file\n                The open CDF file\n            vxrhead : int\n                The byte location of the first VXR for a variable\n            numVXRs : int\n                The total number of VXRs\n\n        Returns:\n            newVXRhead : int\n                The byte location of the newest VXR head\n            newvxroff : int\n                The byte location of the last VXR head\n\n        '''\n        newNumVXRs = int(numVXRs / CDF.NUM_VXRlvl_ENTRIES)\n        remaining = int(numVXRs % CDF.NUM_VXRlvl_ENTRIES)\n        vxroff = vxrhead\n        prevxroff = -1\n        if (remaining != 0):\n            newNumVXRs += 1\n        CDF.level += 1\n        for x in range(0, newNumVXRs):\n            newvxroff = self._write_vxr(f, numEntries=CDF.NUM_VXRlvl_ENTRIES)\n            if (x > 0):\n                self._update_offset_value(f, prevxroff+12, 8, newvxroff)\n            else:\n                newvxrhead = newvxroff\n            prevxroff = newvxroff\n            if (x == (newNumVXRs - 1)):\n                if (remaining == 0):\n                    endEntry = CDF.NUM_VXRlvl_ENTRIES\n                else:\n                    endEntry = remaining\n            else:\n                endEntry = CDF.NUM_VXRlvl_ENTRIES\n            for _ in range(0, endEntry):\n                recFirst, recLast = self._get_recrange(f, vxroff)\n                self._use_vxrentry(f, newvxroff, recFirst, recLast, vxroff)\n                vxroff = self._read_offset_value(f, vxroff+12, 8)\n        vxroff = vxrhead\n\n        # Break the horizontal links\n        for x in range(0, numVXRs):\n            nvxroff = self._read_offset_value(f, vxroff+12, 8)\n            self._update_offset_value(f, vxroff+12, 8, 0)\n            vxroff = nvxroff\n\n        # Iterate this process if we're over NUM_VXRlvl_ENTRIES\n        if (newNumVXRs > CDF.NUM_VXRlvl_ENTRIES):\n            return self._add_vxr_levels_r(f, newvxrhead, newNumVXRs)\n        else:\n            return newvxrhead, newvxroff"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _update_vdr_vxrheadtail(self, f, vdr_offset, VXRoffset):\n        '''\n        This sets a VXR to be the first and last VXR in the VDR\n        '''\n        # VDR's VXRhead\n        self._update_offset_value(f, vdr_offset+28, 8, VXRoffset)\n        # VDR's VXRtail\n        self._update_offset_value(f, vdr_offset+36, 8, VXRoffset)", "response": "Updates the VXR head and tail entries in the VXR record."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_recrange(self, f, VXRoffset):\n        '''\n        Finds the first and last record numbers pointed by the VXR\n        Assumes the VXRs are in order\n        '''\n        f.seek(VXRoffset+20)\n        # Num entries\n        numEntries = int.from_bytes(f.read(4), 'big', signed=True)\n        # used entries\n        usedEntries = int.from_bytes(f.read(4), 'big', signed=True)\n        # VXR's First record\n        firstRec = int.from_bytes(f.read(4), 'big', signed=True)\n        # VXR's Last record\n        f.seek(VXRoffset+28+(4*numEntries+4*(usedEntries-1)))\n        lastRec = int.from_bytes(f.read(4), 'big', signed=True)\n        return firstRec, lastRec", "response": "Returns the first and last record numbers pointed by the VXR in order of VXRs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _datatype_size(datatype, numElms):    # @NoSelf\n        '''\n        Gets datatype size\n\n        Parameters:\n            datatype : int\n                CDF variable data type\n            numElms : int\n                number of elements\n\n        Returns:\n            numBytes : int\n                The number of bytes for the data\n        '''\n        sizes = {1: 1,\n                 2: 2,\n                 4: 4,\n                 8: 8,\n                 11: 1,\n                 12: 2,\n                 14: 4,\n                 21: 4,\n                 22: 8,\n                 31: 8,\n                 32: 16,\n                 33: 8,\n                 41: 1,\n                 44: 4,\n                 45: 8,\n                 51: 1,\n                 52: 1}\n        try:\n            if (isinstance(datatype, int)):\n                if (datatype == 51 or datatype == 52):\n                    return numElms\n                else:\n                    return sizes[datatype]\n            else:\n                datatype = datatype.upper()\n                if (datatype == 'CDF_INT1' or datatype == 'CDF_UINT1' or\n                        datatype == 'CDF_BYTE'):\n                    return 1\n                elif (datatype == 'CDF_INT2' or datatype == 'CDF_UINT2'):\n                    return 2\n                elif (datatype == 'CDF_INT4' or datatype == 'CDF_UINT4'):\n                    return 4\n                elif (datatype == 'CDF_INT8' or datatype == 'CDF_TIME_TT2000'):\n                    return 8\n                elif (datatype == 'CDF_REAL4' or datatype == 'CDF_FLOAT'):\n                    return 4\n                elif (datatype == 'CDF_REAL8' or datatype == 'CDF_DOUBLE' or\n                      datatype == 'CDF_EPOCH'):\n                    return 8\n                elif (datatype == 'CDF_EPOCH16'):\n                    return 16\n                elif (datatype == 'CDF_CHAR' or datatype == 'CDF_UCHAR'):\n                    return numElms\n                else:\n                    return -1\n        except Exception:\n            return -1", "response": "Returns the size of the data in the specified CDF variable data type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _write_adr(self, f, gORv, name):\n        '''\n        Writes and ADR to the end of the file.\n\n        Additionally, it will update the offset values to either the previous ADR\n        or the ADRhead field in the GDR.\n\n        Parameters:\n            f : file\n                The open CDF file\n            gORv : bool\n                True if a global attribute, False if variable attribute\n            name : str\n                name of the attribute\n        Returns:\n            num : int\n                The attribute number\n            byte_loc : int\n                The current location in file f\n        '''\n\n        f.seek(0, 2)\n        byte_loc = f.tell()\n        block_size = CDF.ADR_BASE_SIZE64\n        section_type = CDF.ADR_\n        nextADR = 0\n        headAgrEDR = 0\n        if (gORv == True):\n            scope = 1\n        else:\n            scope = 2\n        num = len(self.attrs)\n        ngrEntries = 0\n        maxgrEntry = -1\n        rfuA = 0\n        headAzEDR = 0\n        nzEntries = 0\n        maxzEntry = -1\n        rfuE = -1\n\n        adr = bytearray(block_size)\n        adr[0:8] = struct.pack('>q', block_size)\n        adr[8:12] = struct.pack('>i', section_type)\n        adr[12:20] = struct.pack('>q', nextADR)\n        adr[20:28] = struct.pack('>q', headAgrEDR)\n        adr[28:32] = struct.pack('>i', scope)\n        adr[32:36] = struct.pack('>i', num)\n        adr[36:40] = struct.pack('>i', ngrEntries)\n        adr[40:44] = struct.pack('>i', maxgrEntry)\n        adr[44:48] = struct.pack('>i', rfuA)\n        adr[48:56] = struct.pack('>q', headAzEDR)\n        adr[56:60] = struct.pack('>i', nzEntries)\n        adr[60:64] = struct.pack('>i', maxzEntry)\n        adr[64:68] = struct.pack('>i', rfuE)\n        tofill = 256 - len(name)\n        adr[68:324] = (name+'\\0'*tofill).encode()\n        f.write(adr)\n        info = []\n        info.append(name)\n        info.append(scope)\n        info.append(byte_loc)\n        self.attrsinfo[num] = info\n        if (scope == 1):\n            self.gattrs.append(name)\n        else:\n            self.vattrs.append(name)\n\n        self.attrs.append(name)\n        if (num > 0):\n            # ADR's ADRnext\n            self._update_offset_value(f, self.attrsinfo[num-1][2]+12, 8,\n                                      byte_loc)\n        else:\n            # GDR's ADRhead\n            self._update_offset_value(f, self.gdr_head+28, 8, byte_loc)\n\n        # GDR's NumAttr\n        self._update_offset_value(f, self.gdr_head+48, 4, num+1)\n\n        return num, byte_loc", "response": "Writes and ADR to the end of the file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites an aedr into the end of the file. Parameters: f : file The current open CDF file gORz : bool True if this entry is for a global or z variable, False if r variable attrNum : int Number of the attribute this aedr belongs to. entryNum : int Number of the entry value : The value of this entry pdataType : int The CDF data type of the value pnumElems : int Number of elements in the value. zVar : bool True if this entry belongs to a z variable Returns: byte_loc : int This current location in the file after writing the aedr.", "response": "def _write_aedr(self, f, gORz, attrNum, entryNum, value, pdataType,\n                    pnumElems, zVar):\n        '''\n        Writes an aedr into the end of the file.\n\n        Parameters:\n            f : file\n                The current open CDF file\n            gORz : bool\n                True if this entry is for a global or z variable, False if r variable\n            attrNum : int\n                Number of the attribute this aedr belongs to.\n            entryNum : int\n                Number of the entry\n            value :\n                The value of this entry\n            pdataType : int\n                The CDF data type of the value\n            pnumElems : int\n                Number of elements in the value.\n            zVar : bool\n                True if this entry belongs to a z variable\n\n        Returns:\n            byte_loc : int\n                This current location in the file after writing the aedr.\n        '''\n        f.seek(0, 2)\n        byte_loc = f.tell()\n        if (gORz == True or zVar != True):\n            section_type = CDF.AgrEDR_\n        else:\n            section_type = CDF.AzEDR_\n        nextAEDR = 0\n\n        if pdataType is None:\n            # Figure out Data Type if not supplied\n            if isinstance(value, (list, tuple)):\n                avalue = value[0]\n            else:\n                avalue = value\n            if (isinstance(avalue, int)):\n                pdataType = CDF.CDF_INT8\n            elif (isinstance(avalue, float)):\n                pdataType = CDF.CDF_FLOAT\n            elif (isinstance(avalue, complex)):\n                pdataType = CDF.CDF_EPOCH16\n            else:\n                # assume a boolean\n                pdataType = CDF.CDF_INT1\n\n        if pnumElems is None:\n            # Figure out number of elements if not supplied\n            if isinstance(value, str):\n                pdataType = CDF.CDF_CHAR\n                pnumElems = len(value)\n            else:\n                if isinstance(value, (list, tuple)):\n                    pnumElems = len(value)\n                else:\n                    pnumElems = 1\n\n        dataType = pdataType\n        numElems = pnumElems\n\n        rfuB = 0\n        rfuC = 0\n        rfuD = -1\n        rfuE = -1\n        if gORz:\n            numStrings = 0\n        else:\n            if (isinstance(value, str)):\n                numStrings = value.count('\\\\N ') + 1\n            else:\n                numStrings = 0\n        recs, cdata = self._convert_data(dataType, numElems, 1, value)\n        if (dataType == 51):\n            numElems = len(cdata)\n        block_size = len(cdata) + 56\n        aedr = bytearray(block_size)\n        aedr[0:8] = struct.pack('>q', block_size)\n        aedr[8:12] = struct.pack('>i', section_type)\n        aedr[12:20] = struct.pack('>q', nextAEDR)\n        aedr[20:24] = struct.pack('>i', attrNum)\n        aedr[24:28] = struct.pack('>i', dataType)\n        aedr[28:32] = struct.pack('>i', entryNum)\n        aedr[32:36] = struct.pack('>i', numElems)\n        aedr[36:40] = struct.pack('>i', numStrings)\n        aedr[40:44] = struct.pack('>i', rfuB)\n        aedr[44:48] = struct.pack('>i', rfuC)\n        aedr[48:52] = struct.pack('>i', rfuD)\n        aedr[52:56] = struct.pack('>i', rfuE)\n        aedr[56:block_size] = cdata\n        f.write(aedr)\n\n        return byte_loc"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites a VDR block to the end of the file. Parameters: f : file The open CDF file cdataType : int The CDF data type numElems : int The number of elements in the variable numDims : int The number of dimensions in the variable dimSizes : int The size of each dimension name : str The name of the variable dimVary : array of bool Bool array of size numDims. True if a dimension is physical, False if a dimension is not physical recVary : bool True if each record is unique sparse : bool True if using sparse records blockingfactor: int No idea compression : int The level of compression between 0-9 pad : num The pad values to insert zVar : bool True if this variable is a z variable Returns: num : int The number of the variable byte_loc : int The current byte location within the file", "response": "def _write_vdr(self, f, cdataType, numElems, numDims, dimSizes, name,\n                   dimVary, recVary, sparse, blockingfactor, compression,\n                   pad, zVar):\n        '''\n        Writes a VDR block to the end of the file.\n\n        Parameters:\n            f : file\n                The open CDF file\n            cdataType : int\n                The CDF data type\n            numElems : int\n                The number of elements in the variable\n            numDims : int\n                The number of dimensions in the variable\n            dimSizes : int\n                The size of each dimension\n            name : str\n                The name of the variable\n            dimVary : array of bool\n                Bool array of size numDims.\n                True if a dimension is physical, False if a dimension is not physical\n            recVary : bool\n                True if each record is unique\n            sparse : bool\n                True if using sparse records\n            blockingfactor: int\n                No idea\n            compression : int\n                The level of compression between 0-9\n            pad : num\n                The pad values to insert\n            zVar : bool\n                True if this variable is a z variable\n\n        Returns:\n            num : int\n                The number of the variable\n            byte_loc : int\n                The current byte location within the file\n        '''\n\n        if zVar:\n            block_size = CDF.zVDR_BASE_SIZE64\n            section_type = CDF.zVDR_\n        else:\n            block_size = CDF.rVDR_BASE_SIZE64\n            section_type = CDF.rVDR_\n\n        nextVDR = 0\n        dataType = cdataType\n        if dataType == -1:\n            raise ValueError('Bad data type.')\n\n        maxRec = -1\n        headVXR = 0\n        tailVXR = 0\n        flags = 0\n        if recVary:\n            flags = CDF._set_bit(flags, 0)\n        flags = CDF._set_bit(flags, 1)\n        sRecords = sparse\n        rfuB = 0\n        rfuC = -1\n        rfuF = -1\n        if zVar:\n            num = len(self.zvars)\n        else:\n            num = len(self.rvars)\n\n        if compression > 0:\n            offsetCPRorSPR = self._write_cpr(f, CDF.GZIP_COMPRESSION,\n                                             compression)\n        else:\n            offsetCPRorSPR = -1\n\n        if blockingfactor is None:\n            blockingFactor = 1\n        else:\n            blockingFactor = blockingfactor\n\n        # Increase the block size to account for \"zDimSizes\" and \"DimVarys\" fields\n        if numDims > 0:\n            if zVar:\n                block_size = block_size + numDims * 8\n            else:\n                block_size = block_size + numDims * 4\n\n        # Determine pad value\n        if pad is not None:\n            if (dataType == 51 or dataType == 52):\n                # pad needs to be the correct number of elements\n                if (len(pad) < numElems):\n                    pad += '\\0'*(numElems-len(pad))\n                elif (len(pad) > numElems):\n                    pad = pad[:numElems]\n                pad = pad.encode()\n            else:\n                dummy, pad = self._convert_data(dataType, numElems, 1, pad)\n        else:\n            pad = self._default_pad(dataType, numElems)\n\n        f.seek(0, 2)\n        byte_loc = f.tell()\n        block_size += len(pad)\n        vdr = bytearray(block_size)\n        # if (dataType == 51):\n        #    numElems = len(pad)\n        vdr[0:8] = struct.pack('>q', block_size)\n        vdr[8:12] = struct.pack('>i', section_type)\n        vdr[12:20] = struct.pack('>q', nextVDR)\n        vdr[20:24] = struct.pack('>i', dataType)\n        vdr[24:28] = struct.pack('>i', maxRec)\n        vdr[28:36] = struct.pack('>q', headVXR)\n        vdr[36:44] = struct.pack('>q', tailVXR)\n        vdr[44:48] = struct.pack('>i', flags)\n        vdr[48:52] = struct.pack('>i', sRecords)\n        vdr[52:56] = struct.pack('>i', rfuB)\n        vdr[56:60] = struct.pack('>i', rfuC)\n        vdr[60:64] = struct.pack('>i', rfuF)\n        vdr[64:68] = struct.pack('>i', numElems)\n        vdr[68:72] = struct.pack('>i', num)\n        vdr[72:80] = struct.pack('>q', offsetCPRorSPR)\n        vdr[80:84] = struct.pack('>i', blockingFactor)\n        tofill = 256 - len(name)\n        vdr[84:340] = (name+'\\0'*tofill).encode()\n        if zVar:\n            vdr[340:344] = struct.pack('>i', numDims)\n            if (numDims > 0):\n                for i in range(0, numDims):\n                    vdr[344+i*4:344+(i+1)*4] = struct.pack('>i', dimSizes[i])\n                ist = 344+numDims*4\n                for i in range(0, numDims):\n                    vdr[ist+i*4:ist+(i+1)*4] = struct.pack('>i', CDF.VARY)\n            ist = 344 + 8 * numDims\n        else:\n            if (numDims > 0):\n                for i in range(0, numDims):\n                    if (dimVary[i] == True or dimVary[i] != 0):\n                        vdr[340+i*4:344+i*4] = struct.pack('>i', CDF.VARY)\n                    else:\n                        vdr[340+i*4:344+i*4] = struct.pack('>i', CDF.NOVARY)\n            ist = 340 + 4 * numDims\n        vdr[ist:block_size] = pad\n        f.write(vdr)\n\n        # Set variable info\n        info = []\n        info.append(name)\n        info.append(byte_loc)\n        if zVar:\n            info.append(numDims)\n            info.append(dimSizes)\n        else:\n            info.append(self.num_rdim)\n            info.append(self.rdim_sizes)\n        info.append(dimVary)\n\n        # Update the pointers from the CDR/previous VDR\n        if zVar:\n            self.zvarsinfo[num] = info\n            self.zvars.append(name)\n            if (num > 0):\n                # VDR's VDRnext\n                self._update_offset_value(f, self.zvarsinfo[num-1][1]+12, 8,\n                                          byte_loc)\n            # GDR's NzVars\n            self._update_offset_value(f, self.gdr_head+60, 4, num+1)\n        else:\n            self.rvarsinfo[num] = info\n            self.rvars.append(name)\n            if (num > 0):\n                # VDR's VDRnext\n                self._update_offset_value(f, self.rvarsinfo[num-1][1]+12, 8,\n                                          byte_loc)\n            # GDR's NrVars\n            self._update_offset_value(f, self.gdr_head+44, 4, num+1)\n\n        return num, byte_loc"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _write_vxr(self, f, numEntries=None):\n        '''\n        Creates a VXR at the end of the file.\n        Returns byte location of the VXR\n        The First, Last, and Offset fields will need to be filled in later\n        '''\n\n        f.seek(0, 2)\n        byte_loc = f.tell()\n        section_type = CDF.VXR_\n        nextVXR = 0\n        if (numEntries == None):\n            nEntries = CDF.NUM_VXR_ENTRIES\n        else:\n            nEntries = int(numEntries)\n        block_size = CDF.VXR_BASE_SIZE64 + (4 + 4 + 8) * nEntries\n        nUsedEntries = 0\n        firsts = [-1] * nEntries\n        lasts = [-1] * nEntries\n        offsets = [-1] * nEntries\n\n        vxr = bytearray(block_size)\n        vxr[0:8] = struct.pack('>q', block_size)\n        vxr[8:12] = struct.pack('>i', section_type)\n        vxr[12:20] = struct.pack('>q', nextVXR)\n        vxr[20:24] = struct.pack('>i', nEntries)\n        vxr[24:28] = struct.pack('>i', nUsedEntries)\n        estart = 28 + 4*nEntries\n        vxr[28:estart] = struct.pack('>%si' % nEntries, *firsts)\n        eend = estart + 4*nEntries\n        vxr[estart:eend] = struct.pack('>%si' % nEntries, *lasts)\n        vxr[eend:block_size] = struct.pack('>%sq' % nEntries, *offsets)\n        f.write(vxr)\n        return byte_loc", "response": "Create a VXR at the end of the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites a vvr to the end of file f with the byte stream data.", "response": "def _write_vvr(self, f, data):\n        '''\n        Writes a vvr to the end of file \"f\" with the byte stream \"data\".\n        '''\n        f.seek(0, 2)\n        byte_loc = f.tell()\n        block_size = CDF.VVR_BASE_SIZE64 + len(data)\n        section_type = CDF.VVR_\n\n        vvr1 = bytearray(12)\n        vvr1[0:8] = struct.pack('>q', block_size)\n        vvr1[8:12] = struct.pack('>i', section_type)\n        f.write(vvr1)\n        f.write(data)\n\n        return byte_loc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _write_cpr(self, f, cType, parameter) -> int:\n        '''\n        Write compression info to the end of the file in a CPR.\n        '''\n        f.seek(0, 2)\n        byte_loc = f.tell()\n        block_size = CDF.CPR_BASE_SIZE64 + 4\n        section_type = CDF.CPR_\n        rfuA = 0\n        pCount = 1\n\n        cpr = bytearray(block_size)\n        cpr[0:8] = struct.pack('>q', block_size)\n        cpr[8:12] = struct.pack('>i', section_type)\n        cpr[12:16] = struct.pack('>i', cType)\n        cpr[16:20] = struct.pack('>i', rfuA)\n        cpr[20:24] = struct.pack('>i', pCount)\n        cpr[24:28] = struct.pack('>i', parameter)\n        f.write(cpr)\n\n        return byte_loc", "response": "Write the CPR. nagle_cache entry to the end of the file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting a compressed CVVR version 1 file in a CVVRVersion 1 file.", "response": "def _write_cvvr(self, f, data):\n        '''\n        Write compressed \"data\" variable to the end of the file in a CVVR\n        '''\n        f.seek(0, 2)\n        byte_loc = f.tell()\n        cSize = len(data)\n        block_size = CDF.CVVR_BASE_SIZE64 + cSize\n        section_type = CDF.CVVR_\n        rfuA = 0\n\n        cvvr1 = bytearray(24)\n        cvvr1[0:8] = struct.pack('>q', block_size)\n        cvvr1[8:12] = struct.pack('>i', section_type)\n        cvvr1[12:16] = struct.pack('>i', rfuA)\n        cvvr1[16:24] = struct.pack('>q', cSize)\n        f.write(cvvr1)\n        f.write(data)\n\n        return byte_loc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting a CCR to file g from file f with level level.", "response": "def _write_ccr(self, f, g, level: int):\n        '''\n        Write a CCR to file \"g\" from file \"f\" with level \"level\".\n        Currently, only handles gzip compression.\n\n        Parameters:\n            f : file\n                Uncompressed file to read from\n            g : file\n                File to read the compressed file into\n            level : int\n                The level of the compression from 0 to 9\n\n        Returns: None\n\n        '''\n        f.seek(8)\n        data = f.read()\n        uSize = len(data)\n        section_type = CDF.CCR_\n        rfuA = 0\n        cData = gzip.compress(data, level)\n        block_size = CDF.CCR_BASE_SIZE64 + len(cData)\n        cprOffset = 0\n        ccr1 = bytearray(32)\n        #ccr1[0:4] = binascii.unhexlify(CDF.V3magicNUMBER_1)\n        #ccr1[4:8] = binascii.unhexlify(CDF.V3magicNUMBER_2c)\n        ccr1[0:8] = struct.pack('>q', block_size)\n        ccr1[8:12] = struct.pack('>i', section_type)\n        ccr1[12:20] = struct.pack('>q', cprOffset)\n        ccr1[20:28] = struct.pack('>q', uSize)\n        ccr1[28:32] = struct.pack('>i', rfuA)\n        g.seek(0, 2)\n        g.write(ccr1)\n        g.write(cData)\n        cprOffset = self._write_cpr(g, CDF.GZIP_COMPRESSION, level)\n        self._update_offset_value(g, 20, 8, cprOffset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the option to the equivalent numpy type.", "response": "def _convert_option(self):\n        '''\n        Determines which symbol to use for numpy conversions\n        > : a little endian system to big endian ordering\n        < : a big endian system to little endian ordering\n        = : No conversion\n        '''\n        data_endian = 'little'\n        if (self._encoding == 1 or self._encoding == 2 or self._encoding == 5 or\n            self._encoding == 7 or self._encoding == 9 or self._encoding == 11 or\n                self._encoding == 12 or self._encoding == 18):\n            data_endian = 'big'\n        if sys.byteorder == 'little' and data_endian == 'big':\n            # big->little\n            order = '>'\n        elif sys.byteorder == 'big' and data_endian == 'little':\n            # little->big\n            order = '<'\n        else:\n            # no conversion\n            order = '='\n\n        return order"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _convert_type(data_type):  # @NoSelf\n        '''\n        Converts CDF data types into python types\n        '''\n        if data_type in (1, 41):\n            dt_string = 'b'\n        elif data_type == 2:\n            dt_string = 'h'\n        elif data_type == 4:\n            dt_string = 'i'\n        elif data_type in (8, 33):\n            dt_string = 'q'\n        elif data_type == 11:\n            dt_string = 'B'\n        elif data_type == 12:\n            dt_string = 'H'\n        elif data_type == 14:\n            dt_string = 'I'\n        elif data_type in (21, 44):\n            dt_string = 'f'\n        elif data_type in (22, 45, 31):\n            dt_string = 'd'\n        elif data_type == 32:\n            dt_string = 'd'\n        elif data_type in (51, 52):\n            dt_string = 's'\n        else:\n            dt_string = ''\n\n        return dt_string", "response": "Converts CDF data types into python types."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting data of CDF type data_type into a numpy array", "response": "def _convert_nptype(data_type, data):  # @NoSelf\n        '''\n        Converts \"data\" of CDF type \"data_type\" into a numpy array\n        '''\n        if data_type in (1, 41):\n            return np.int8(data).tobytes()\n        elif data_type == 2:\n            return np.int16(data).tobytes()\n        elif data_type == 4:\n            return np.int32(data).tobytes()\n        elif (data_type == 8) or (data_type == 33):\n            return np.int64(data).tobytes()\n        elif data_type == 11:\n            return np.uint8(data).tobytes()\n        elif data_type == 12:\n            return np.uint16(data).tobytes()\n        elif data_type == 14:\n            return np.uint32(data).tobytes()\n        elif (data_type == 21) or (data_type == 44):\n            return np.float32(data).tobytes()\n        elif (data_type == 22) or (data_type == 45) or (data_type == 31):\n            return np.float64(data).tobytes()\n        elif (data_type == 32):\n            return np.complex128(data).tobytes()\n        else:\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _default_pad(self, data_type, numElems):\n        '''\n        Determines the default pad data for a \"data_type\"\n        '''\n        order = self._convert_option()\n        if (data_type == 1) or (data_type == 41):\n            pad_value = struct.pack(order+'b', -127)\n        elif data_type == 2:\n            pad_value = struct.pack(order+'h', -32767)\n        elif data_type == 4:\n            pad_value = struct.pack(order+'i', -2147483647)\n        elif (data_type == 8) or (data_type == 33):\n            pad_value = struct.pack(order+'q', -9223372036854775807)\n        elif data_type == 11:\n            pad_value = struct.pack(order+'B', 254)\n        elif data_type == 12:\n            pad_value = struct.pack(order+'H', 65534)\n        elif data_type == 14:\n            pad_value = struct.pack(order+'I', 4294967294)\n        elif (data_type == 21) or (data_type == 44):\n            pad_value = struct.pack(order+'f', -1.0E30)\n        elif (data_type == 22) or (data_type == 45):\n            pad_value = struct.pack(order+'d', -1.0E30)\n        elif (data_type == 31):\n            pad_value = struct.pack(order+'d', 0.0)\n        elif (data_type == 32):\n            pad_value = struct.pack(order+'2d', *[0.0, 0.0])\n        elif (data_type == 51) or (data_type == 52):\n            tmpPad = str(' '*numElems).encode()\n            form = str(numElems)\n            pad_value = struct.pack(form+'b', *tmpPad)\n        return pad_value", "response": "Determines the default pad data for a data_type"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _convert_data(self, data_type, num_elems, num_values, indata):\n        '''\n        Converts \"indata\" into a byte stream\n\n        Parameters:\n            data_type : int\n                The CDF file data type\n\n            num_elems : int\n                The number of elements in the data\n\n            num_values : int\n                The number of values in each record\n\n            indata : (varies)\n                The data to be converted\n\n        Returns:\n            recs : int\n                The number of records generated by converting indata\n            odata : byte stream\n                The stream of bytes to write to the CDF file\n        '''\n\n        recSize = CDF._datatype_size(data_type, num_elems) * num_values\n        if (isinstance(indata, list) or isinstance(indata, tuple)):\n            size = len(indata)\n            if (data_type == CDF.CDF_CHAR or data_type == CDF.CDF_UCHAR):\n                odata = ''\n                for x in range(0, size):\n                    adata = indata[x]\n                    if (isinstance(adata, list) or isinstance(adata, tuple)):\n                        size2 = len(adata)\n                        for y in range(0, size2):\n                            odata += adata[y].ljust(num_elems, '\\x00')\n                    else:\n                        size2 = 1\n                        odata += adata.ljust(num_elems, '\\x00')\n                recs = int((size*size2)/num_values)\n                return recs, odata.encode()\n            else:\n                tofrom = self._convert_option()\n                dt_string = CDF._convert_type(data_type)\n                recs = int(size/num_values)\n                if (data_type == CDF.CDF_EPOCH16 and\n                        isinstance(indata[0], complex)):\n                    complex_data = []\n                    for x in range(0, recs):\n                        acomplex = indata[x]\n                        complex_data.append(acomplex.real)\n                        complex_data.append(acomplex.imag)\n                    size = 2 * size\n                    indata = complex_data\n                if (data_type == CDF.CDF_EPOCH16 and\n                        not isinstance(indata[0], complex)):\n                    recs = int(recs/2)\n                form = tofrom + str(size) + dt_string\n                return recs, struct.pack(form, *indata)\n        elif (isinstance(indata, bytes)):\n            tofrom = self._convert_option()\n            recs = int(len(indata) / recSize)\n            dt_string = CDF._convert_type(data_type)\n            size = recs * num_values * num_elems\n            if (data_type == CDF.CDF_EPOCH16):\n                size = size * 2\n            form = str(size) + dt_string\n            form2 = tofrom + form\n            datau = struct.unpack(form, indata)\n            return recs, struct.pack(form2, *datau)\n        elif (isinstance(indata, np.ndarray)):\n            tofrom = self._convert_option()\n            npdata = CDF._convert_nptype(data_type, indata)\n            recs = len(indata)\n            dt_string = CDF._convert_type(data_type)\n            if (data_type == CDF.CDF_EPOCH16):\n                num_elems = 2 * num_elems\n            form = str(recs*num_values*num_elems) + dt_string\n            form2 = tofrom + str(recs*num_values*num_elems) + dt_string\n            datau = struct.unpack(form, npdata)\n            return recs, struct.pack(form2, *datau)\n        elif (isinstance(indata, str)):\n            return 1, indata.ljust(num_elems, '\\x00').encode()\n        else:\n            tofrom = self._convert_option()\n            dt_string = CDF._convert_type(data_type)\n            if (data_type == CDF.CDF_EPOCH16):\n                num_elems = 2 * num_elems\n            try:\n                recs = int(len(indata) / recSize)\n            except:\n                recs = 1\n            if (data_type == CDF.CDF_EPOCH16):\n                complex_data = []\n                if (recs > 1):\n                    for x in range(0, recs):\n                        acomplex = indata[x]\n                        complex_data.append(acomplex.real)\n                        complex_data.append(acomplex.imag)\n                else:\n                    complex_data.append(indata.real)\n                    complex_data.append(indata.imag)\n                indata = complex_data\n            form = tofrom + str(recs*num_values*num_elems) + dt_string\n            if (recs*num_values*num_elems > 1):\n                return recs, struct.pack(form, *indata)\n            else:\n                return recs, struct.pack(form, indata)", "response": "Converts the data from the CDF file to the byte stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines the number of values in a record.", "response": "def _num_values(self, zVar, varNum):\n        '''\n        Determines the number of values in a record.\n        Set zVar=True if this is a zvariable.\n        '''\n        values = 1\n        if (zVar == True):\n            numDims = self.zvarsinfo[varNum][2]\n            dimSizes = self.zvarsinfo[varNum][3]\n            dimVary = self.zvarsinfo[varNum][4]\n        else:\n            numDims = self.rvarsinfo[varNum][2]\n            dimSizes = self.rvarsinfo[varNum][3]\n            dimVary = self.rvarsinfo[varNum][4]\n        if (numDims < 1):\n            return values\n        else:\n            for x in range(0, numDims):\n                if (zVar == True):\n                    values = values * dimSizes[x]\n                else:\n                    if (dimVary[x] != 0):\n                        values = values * dimSizes[x]\n            return values"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading an integer value from file f at location offset.", "response": "def _read_offset_value(self, f, offset, size):\n        '''\n        Reads an integer value from file \"f\" at location \"offset\".\n        '''\n        f.seek(offset, 0)\n        if (size == 8):\n            return int.from_bytes(f.read(8), 'big', signed=True)\n        else:\n            return int.from_bytes(f.read(4), 'big', signed=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _update_offset_value(self, f, offset, size, value):\n        '''\n        Writes \"value\" into location \"offset\" in file \"f\".\n        '''\n        f.seek(offset, 0)\n        if (size == 8):\n            f.write(struct.pack('>q', value))\n        else:\n            f.write(struct.pack('>i', value))", "response": "Updates the value into location offset in file f."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _update_aedr_link(self, f, attrNum, zVar, varNum, offset):\n        '''\n        Updates variable aedr links\n\n        Parameters:\n            f : file\n                The open CDF file\n            attrNum : int\n                The number of the attribute to change\n            zVar : bool\n                True if we are updating a z variable attribute\n            varNum : int\n                The variable number associated with this aedr\n            offset : int\n                The offset in the file to the AEDR\n        Returns: None\n\n        '''\n\n        # The offset to this AEDR's ADR\n        adr_offset = self.attrsinfo[attrNum][2]\n\n        # Get the number of entries\n        if zVar:\n            f.seek(adr_offset+56, 0)\n            # ADR's NzEntries\n            entries = int.from_bytes(f.read(4), 'big', signed=True)\n            # ADR's MAXzEntry\n            maxEntry = int.from_bytes(f.read(4), 'big', signed=True)\n        else:\n            f.seek(adr_offset+36, 0)\n            # ADR's NgrEntries\n            entries = int.from_bytes(f.read(4), 'big', signed=True)\n            # ADR's MAXgrEntry\n            maxEntry = int.from_bytes(f.read(4), 'big', signed=True)\n\n        if (entries == 0):\n            # If this is the first entry, update the ADR to reflect\n            if zVar:\n                # AzEDRhead\n                self._update_offset_value(f, adr_offset+48, 8, offset)\n                # NzEntries\n                self._update_offset_value(f, adr_offset+56, 4, 1)\n                # MaxzEntry\n                self._update_offset_value(f, adr_offset+60, 4, varNum)\n            else:\n                # AgrEDRhead\n                self._update_offset_value(f, adr_offset+20, 8, offset)\n                # NgrEntries\n                self._update_offset_value(f, adr_offset+36, 4, 1)\n                # MaxgrEntry\n                self._update_offset_value(f, adr_offset+40, 4, varNum)\n        else:\n            if zVar:\n                f.seek(adr_offset+48, 0)\n                head = int.from_bytes(f.read(8), 'big', signed=True)\n            else:\n                f.seek(adr_offset+20, 0)\n                head = int.from_bytes(f.read(8), 'big', signed=True)\n            aedr = head\n            previous_aedr = head\n            done = False\n            # For each entry, re-adjust file offsets if needed\n            for _ in range(0, entries):\n                f.seek(aedr+28, 0)\n                # Get variable number for entry\n                num = int.from_bytes(f.read(4), 'big', signed=True)\n                if (num > varNum):\n                    # insert an aedr to the chain\n                    # AEDRnext\n                    self._update_offset_value(f, previous_aedr+12, 8, offset)\n                    # AEDRnext\n                    self._update_offset_value(f, offset+12, 8, aedr)\n                    done = True\n                    break\n                else:\n                    # move to the next aedr in chain\n                    f.seek(aedr+12, 0)\n                    previous_aedr = aedr\n                    aedr = int.from_bytes(f.read(8), 'big', signed=True)\n\n            # If no link was made, update the last found aedr\n            if not done:\n                self._update_offset_value(f, previous_aedr+12, 8, offset)\n\n            if zVar:\n                self._update_offset_value(f, adr_offset+56, 4, entries+1)\n                if (maxEntry < varNum):\n                    self._update_offset_value(f, adr_offset+60, 4, varNum)\n            else:\n                self._update_offset_value(f, adr_offset+36, 4, entries+1)\n                if (maxEntry < varNum):\n                    self._update_offset_value(f, adr_offset+40, 4, varNum)", "response": "Updates the variable aedr links in the ADR file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the checksum of the file", "response": "def _md5_compute(self, f):\n        '''\n        Computes the checksum of the file\n        '''\n        md5 = hashlib.md5()\n        block_size = 16384\n        f.seek(0, 2)\n        remaining = f.tell()\n        f.seek(0)\n\n        while (remaining > block_size):\n            data = f.read(block_size)\n            remaining = remaining - block_size\n            md5.update(data)\n\n        if remaining > 0:\n            data = f.read(remaining)\n            md5.update(data)\n\n        return md5.digest()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _make_blocks(records):  # @NoSelf\n        '''\n        Organizes the physical records into blocks in a list by\n        placing consecutive physical records into a single block, so\n        lesser VXRs will be created.\n          [[start_rec1,end_rec1,data_1], [start_rec2,enc_rec2,data_2], ...]\n\n        Parameters:\n            records: list\n                A list of records that there is data for\n\n        Returns:\n            sparse_blocks: list of list\n                A list of ranges we have physical values for.\n\n        Example:\n            Input: [1,2,3,4,10,11,12,13,50,51,52,53]\n            Output: [[1,4],[10,13],[50,53]]\n        '''\n\n        sparse_blocks = []\n        total = len(records)\n        if (total == 0):\n            return []\n\n        x = 0\n        while (x < total):\n            recstart = records[x]\n            y = x\n            recnum = recstart\n\n            # Find the location in the records before the next gap\n            # Call this value \"y\"\n            while ((y+1) < total):\n                y = y + 1\n                nextnum = records[y]\n                diff = nextnum - recnum\n                if (diff == 1):\n                    recnum = nextnum\n                else:\n                    y = y - 1\n                    break\n\n            # Put the values of the records into \"ablock\", append to sparse_blocks\n            ablock = []\n            ablock.append(recstart)\n            if ((y+1) == total):\n                recend = records[total-1]\n            else:\n                recend = records[y]\n            x = y + 1\n            ablock.append(recend)\n            sparse_blocks.append(ablock)\n\n        return sparse_blocks", "response": "This function creates a list of blocks that are used to store the physical records in a list of lists."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle the data for the variable with sparse records. Organizes the physical record numbers into blocks in a list: [[start_rec1,end_rec1,data_1], [start_rec2,enc_rec2,data_2], ...] Place consecutive physical records into a single block If all records are physical, this calls _make_sparse_blocks_with_physical If any records are virtual, this calls _make_sparse_blocks_with_virtual Parameters: variable : dict the variable dictionary, with 'Num_Dims', 'Dim_Sizes', 'Data_Type', 'Num_Elements' key words, typically returned from a call to cdf read's varinq('variable', expand=True) records : list a list of physical records data : varies bytes array, numpy.ndarray or list of str form with all physical data or embedded virtual data (returned from call to varget('variable') for a sparse variable) Returns: sparse_blocks: list A list of sparse records/data in the form [[start_rec1,end_rec1,data_1], [start_rec2,enc_rec2,data_2], ...]", "response": "def _make_sparse_blocks(self, variable, records, data):\n        '''\n        Handles the data for the variable with sparse records.\n        Organizes the physical record numbers into blocks in a list:\n          [[start_rec1,end_rec1,data_1], [start_rec2,enc_rec2,data_2], ...]\n        Place consecutive physical records into a single block\n\n        If all records are physical, this calls _make_sparse_blocks_with_physical\n\n        If any records are virtual, this calls _make_sparse_blocks_with_virtual\n\n        Parameters:\n            variable : dict\n                the variable dictionary, with 'Num_Dims', 'Dim_Sizes',\n                'Data_Type', 'Num_Elements' key words, typically\n                returned from a call to cdf read's varinq('variable',\n                expand=True)\n\n            records : list\n                a list of physical records\n\n            data : varies\n                bytes array, numpy.ndarray or list of str form with all physical\n                data or embedded virtual data (returned from call to\n                varget('variable') for a sparse variable)\n\n        Returns:\n            sparse_blocks: list\n                A list of sparse records/data in the form\n                [[start_rec1,end_rec1,data_1], [start_rec2,enc_rec2,data_2], ...]\n        '''\n\n        if (isinstance(data, dict)):\n            try:\n                data = data['Data']\n            except:\n                print('Unknown dictionary.... Skip')\n                return None\n        if (isinstance(data, np.ndarray)):\n            if (len(records) == len(data)):\n                # All are physical data\n                return self._make_sparse_blocks_with_physical(variable, records,\n                                                              data)\n            elif (len(records) < len(data)):\n                # There are some virtual data\n                return self._make_sparse_blocks_with_virtual(variable, records,\n                                                             data)\n            else:\n                print('Invalid sparse data... ',\n                      'Less data than the specified records... Skip')\n        elif (isinstance(data, bytes)):\n            record_length = len(records)\n            for z in range(0, variable['Num_Dims']):\n                record_length = record_length * variable['Dim_Sizes'][z]\n            if (record_length == len(data)):\n                # All are physical data\n                return self._make_sparse_blocks_with_physical(variable, records,\n                                                              data)\n            elif (record_length < len(data)):\n                # There are some virtual data\n                return self._make_sparse_blocks_with_virtual(variable, records,\n                                                             data)\n            else:\n                print('Invalid sparse data... ',\n                      'Less data than the specified records... Skip')\n        elif (isinstance(data, list)):\n            if (isinstance(data[0], list)):\n                if not (all(isinstance(el, str) for el in data[0])):\n                    print('Can not handle list data.... ',\n                          'Only support list of str... Skip')\n                    return\n            else:\n                if not (all(isinstance(el, str) for el in data)):\n                    print('Can not handle list data.... ',\n                          'Only support list of str... Skip')\n                    return\n            record_length = len(records)\n            # for z in range(0, variable['Num_Dims']):\n            #    record_length = record_length * variable['Dim_Sizes'][z]\n            if (record_length == len(data)):\n                # All are physical data\n                return self._make_sparse_blocks_with_physical(variable, records,\n                                                              data)\n            elif (record_length < len(data)):\n                # There are some virtual data\n                return self._make_sparse_blocks_with_virtual(variable, records,\n                                                             data)\n            else:\n                print('Invalid sparse data... ',\n                      'Less data than the specified records... Skip')\n        else:\n            print('Invalid sparse data... ',\n                  'Less data than the specified records... Skip')\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _make_sparse_blocks_with_virtual(self, variable, records, data):\n        '''\n        Handles the data for the variable with sparse records.\n        Organizes the physical record numbers into blocks in a list:\n          [[start_rec1,end_rec1,data_1], [start_rec2,enc_rec2,data_2], ...]\n        Place consecutive physical records into a single block\n\n        Parameters:\n            variable: dict\n                the variable, returned from varinq('variable', expand=True)\n            records: list\n                a list of physical records\n            data: varies\n                bytes array, numpy.ndarray or list of str form with vitual data\n                embedded, returned from varget('variable') call\n        '''\n\n        # Gather the ranges for which we have physical data\n        sparse_blocks = CDF._make_blocks(records)\n\n        sparse_data = []\n        if (isinstance(data, np.ndarray)):\n            for sblock in sparse_blocks:\n                # each block in this list: [starting_rec#, ending_rec#, data]\n                asparse = []\n                asparse.append(sblock[0])\n                asparse.append(sblock[1])\n                starting = sblock[0]\n                ending = sblock[1]+1\n                asparse.append(data[starting:ending])\n                sparse_data.append(asparse)\n            return sparse_data\n        elif (isinstance(data, bytes)):\n            y = 1\n            for z in range(0, variable['Num_Dims']):\n                y = y * variable['Dim_Sizes'][z]\n            y = y * CDF._datatype_size(variable['Data_Type'], variable['Num_Elements'])\n            for x in sparse_blocks:\n                # each block in this list: [starting_rec#, ending_rec#, data]\n                asparse = []\n                asparse.append(sblock[0])\n                asparse.append(sblock[1])\n                starting = sblock[0]*y\n                ending = (sblock[1]+1)*y\n                asparse.append(data[starting:ending])\n                sparse_data.append(asparse)\n            return sparse_data\n        elif (isinstance(data, list)):\n            for x in sparse_blocks:\n                # each block in this list: [starting_rec#, ending_rec#, data]\n                asparse = []\n                asparse.append(sblock[0])\n                asparse.append(sblock[1])\n                records = sparse_blocks[x][1] - sparse_blocks[x][0] + 1\n                datax = []\n                ist = sblock[0]\n                for z in range(0, records):\n                    datax.append(data[ist+z])\n                asparse.append(datax)\n                sparse_data.append(asparse)\n            return sparse_data\n        else:\n            print('Can not handle data... Skip')\n            return None", "response": "Create a sparse blocks of data for a variable with virtual records."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cdf_info(self):\n        mycdf_info = {}\n        mycdf_info['CDF'] = self.file\n        mycdf_info['Version'] = self._version\n        mycdf_info['Encoding'] = self._encoding\n        mycdf_info['Majority'] = self._majority\n        mycdf_info['rVariables'], mycdf_info['zVariables'] = self._get_varnames()\n        mycdf_info['Attributes'] = self._get_attnames()\n        mycdf_info['Copyright'] = self._copyright\n        mycdf_info['Checksum'] = self._md5\n        mycdf_info['Num_rdim'] = self._num_rdim\n        mycdf_info['rDim_sizes'] = self._rdim_sizes\n        mycdf_info['Compressed'] = self._compressed\n        if (self.cdfversion > 2):\n            mycdf_info['LeapSecondUpdated'] = self._leap_second_updated\n        return mycdf_info", "response": "Returns a dictionary that shows basic CDF information for the given resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the basic variable information for a particular variable in the CDF.", "response": "def varinq(self, variable):\n        \"\"\"\n        Returns a dictionary that shows the basic variable information.\n\n        This information includes\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Variable']    | the name of the variable                                                       |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Num']         | the variable number                                                            |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Var_Type']    | the variable type: zVariable or rVariable                                      |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Data_Type']   | the variable's CDF data type                                                   |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Num_Elements']| the number of elements of the variable                                         |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Num_Dims']    | the dimensionality of the variable record                                      |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Dim_Sizes']   | the shape of the variable record                                               |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Sparse']      | the variable's record sparseness                                               |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Last_Rec']    | the maximum written record number (0-based)                                    |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Dim_Vary']    | the dimensional variance(s)                                                    |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Rec_Vary']    | the record variance                                                            |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Pad']         | the padded value if set                                                        |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Compress']    | the GZIP compression level, 0 to 9. 0 if not compressed                        |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Block_Factor']| the blocking factor if the variable is compressed                              |\n                +-----------------+--------------------------------------------------------------------------------+\n\n        Parameters\n        ----------\n        variable :\n        \"\"\"\n        vdr_info = self.varget(variable=variable, inq=True)\n        if vdr_info is None:\n            raise KeyError(\"Variable {} not found.\".format(variable))\n\n        var = {}\n        var['Variable'] = vdr_info['name']\n        var['Num'] = vdr_info['variable_number']\n        var['Var_Type'] = CDF._variable_token(vdr_info['section_type'])\n        var['Data_Type'] = vdr_info['data_type']\n        var['Data_Type_Description'] = CDF._datatype_token(vdr_info['data_type'])\n        var['Num_Elements'] = vdr_info['num_elements']\n        var['Num_Dims'] = vdr_info['num_dims']\n        var['Dim_Sizes'] = vdr_info['dim_sizes']\n        var['Sparse'] = CDF._sparse_token(vdr_info['sparse'])\n        var['Last_Rec'] = vdr_info['max_records']\n        var['Rec_Vary'] = vdr_info['record_vary']\n        var['Dim_Vary'] = vdr_info['dim_vary']\n        if ('pad' in vdr_info):\n            var['Pad'] = vdr_info['pad']\n        var['Compress'] = vdr_info['compression_level']\n        if ('blocking_factor' in vdr_info):\n            var['Block_Factor'] = vdr_info['blocking_factor']\n\n        return var"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef attinq(self, attribute=None):\n        position = self._first_adr\n        if isinstance(attribute, str):\n            for _ in range(0, self._num_att):\n                name, next_adr = self._read_adr_fast(position)\n                if name.strip().lower() == attribute.strip().lower():\n                    return self._read_adr(position)\n\n                position = next_adr\n            raise KeyError('No attribute {}'.format(attribute))\n\n        elif isinstance(attribute, int):\n            if (attribute < 0 or attribute > self._num_zvariable):\n                raise KeyError('No attribute {}'.format(attribute))\n            for _ in range(0, attribute):\n                name, next_adr = self._read_adr_fast(position)\n                position = next_adr\n\n            return self._read_adr(position)\n        else:\n            print('Please set attribute keyword equal to the name or ',\n                  'number of an attribute')\n\n            attrs = self._get_attnames()\n            print(attrs)\n            for x in range(0, self._num_att):\n                name = list(attrs[x].keys())[0]\n                print('NAME: ' + name + ', NUMBER: ' + str(x) + ', SCOPE: ' + attrs[x][name])\n            return attrs", "response": "Get the attribute information."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef attget(self, attribute=None, entry=None, to_np=True):\n        # Starting position\n        position = self._first_adr\n\n        # Get Correct ADR\n        adr_info = None\n        if isinstance(attribute, str):\n            for _ in range(0, self._num_att):\n                name, next_adr = self._read_adr_fast(position)\n                if (name.strip().lower() == attribute.strip().lower()):\n                    adr_info = self._read_adr(position)\n                    break\n                else:\n                    position = next_adr\n\n            if adr_info is None:\n                raise KeyError('No attribute {}'.format(attribute))\n\n        elif isinstance(attribute, int):\n            if (attribute < 0) or (attribute > self._num_att):\n                raise KeyError('No attribute {}'.format(attribute))\n            if not isinstance(entry, int):\n                raise TypeError('{} has to be a number.'.format(entry))\n\n            for _ in range(0, attribute):\n                name, next_adr = self._read_adr_fast(position)\n                position = next_adr\n            adr_info = self._read_adr(position)\n        else:\n            print('Please set attribute keyword equal to the name or ',\n                  'number of an attribute')\n            for x in range(0, self._num_att):\n                name, next_adr = self._read_adr_fast(position)\n                print('NAME:' + name + ' NUMBER: ' + str(x))\n                position = next_adr\n            return\n\n        # Find the correct entry from the \"entry\" variable\n        if adr_info['scope'] == 1:\n            if not isinstance(entry, int):\n                print('Global entry should be an integer')\n                return\n            num_entry_string = 'num_gr_entry'\n            first_entry_string = 'first_gr_entry'\n            max_entry_string = 'max_gr_entry'\n            entry_num = entry\n        else:\n            var_num = -1\n            zvar = False\n            if isinstance(entry, str):\n                # a zVariable?\n                positionx = self._first_zvariable\n                for x in range(0, self._num_zvariable):\n                    if (self.cdfversion == 3):\n                        name, vdr_next = self._read_vdr_fast(positionx)\n                    else:\n                        name, vdr_next = self._read_vdr_fast2(positionx)\n                    if (name.strip().lower() == entry.strip().lower()):\n                        var_num = x\n                        zvar = True\n                        break\n                    positionx = vdr_next\n                if var_num == -1:\n                    # a rVariable?\n                    positionx = self._first_rvariable\n                    for x in range(0, self._num_rvariable):\n                        if (self.cdfversion == 3):\n                            name, vdr_next = self._read_vdr_fast(positionx)\n                        else:\n                            name, vdr_next = self._read_vdr_fast2(positionx)\n                        if (name.strip().lower() == entry.strip().lower()):\n                            var_num = x\n                            break\n                        positionx = vdr_next\n                if var_num == -1:\n                    print('No variable by this name:', entry)\n                    return\n                entry_num = var_num\n            else:\n                if (self._num_zvariable > 0 and self._num_rvariable > 0):\n                    print('This CDF has both r and z variables. Use variable name')\n                    return\n                if self._num_zvariable > 0:\n                    zvar = True\n                entry_num = entry\n            if zvar:\n                num_entry_string = 'num_z_entry'\n                first_entry_string = 'first_z_entry'\n                max_entry_string = 'max_z_entry'\n            else:\n                num_entry_string = 'num_gr_entry'\n                first_entry_string = 'first_gr_entry'\n                max_entry_string = 'max_gr_entry'\n        if entry_num > adr_info[max_entry_string]:\n            print('The entry does not exist')\n            return\n        return self._get_attdata(adr_info, entry_num, adr_info[num_entry_string],\n                                 adr_info[first_entry_string], to_np=to_np)", "response": "This method returns the value of the attribute at the entry number provided."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef varget(self, variable=None, epoch=None, starttime=None,\n               endtime=None, startrec=0, endrec=None,\n               record_range_only=False, inq=False, expand=False,\n               to_np=True):\n        \"\"\"\n        Returns the variable data.\n\n        Variable can be entered either\n        a name or a variable number. By default, it returns a\n        'numpy.ndarray' or 'list' class object, depending on the\n        data type, with the variable data and its specification.\n\n        If \"expand\" is set as True, a dictionary is returned\n        with the following defined keys for the output\n\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Rec_Ndim']         | the dimension number of each variable record                              |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Rec_Shape']        | the shape of the variable record dimensions                               |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Num_Records']      | the total number of records                                               |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Records_Returned'] | the number of records retrieved                                           |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Data_Type']        | the CDF data type                                                         |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Data']             | retrieved variable data                                                   |\n                +-----------------+--------------------------------------------------------------------------------+\n                | ['Real_Records']     | Record numbers for real data for sparse record variable in list           |\n                +-----------------+--------------------------------------------------------------------------------+\n\n        By default, the full variable data is returned. To acquire\n        only a portion of the data for a record-varying variable,\n        either the time or record (0-based) range can be specified.\n        'epoch' can be used to specify which time variable this\n        variable depends on and is to be searched for the time range.\n        For the ISTP-compliant CDFs, the time variable will come from\n        the attribute 'DEPEND_0' from this variable. The function will\n        automatically search for it thus no need to specify 'epoch'.\n        If either the start or end time is not specified,\n        the possible minimum or maximum value for the specific epoch\n        data type is assumed. If either the start or end record is not\n        specified, the range starts at 0 or/and ends at the last of the\n        written data.\n\n        The start (and end) time should be presented in a list as:\n        [year month day hour minute second millisec] for CDF_EPOCH\n        [year month day hour minute second millisec microsec nanosec picosec] for CDF_EPOCH16\n        [year month day hour minute second millisec microsec nanosec] for CDF_TIME_TT2000\n        If not enough time components are presented, only the last item can have the floating\n        portion for the sub-time components.\n\n        Note: CDF's CDF_EPOCH16 data type uses 2 8-byte doubles for each data value.\n        In Python, each value is presented as a complex or numpy.complex128.\n        \"\"\"\n        if (isinstance(variable, int) and self._num_zvariable > 0 and\n                self._num_rvariable > 0):\n            print('This CDF has both r and z variables. Use variable name')\n            return\n\n\n        if ((starttime is not None or endtime is not None) and\n                (startrec != 0 or endrec is not None)):\n            print('Can\\'t specify both time and record range')\n            return\n\n        if isinstance(variable, str):\n            # Check z variables for the name, then r variables\n            position = self._first_zvariable\n            num_variables = self._num_zvariable\n            vdr_info = None\n            for zVar in [1, 0]:\n                for _ in range(0, num_variables):\n                    if (self.cdfversion == 3):\n                        name, vdr_next = self._read_vdr_fast(position)\n                    else:\n                        name, vdr_next = self._read_vdr_fast2(position)\n                    if name.strip().lower() == variable.strip().lower():\n                        if (self.cdfversion == 3):\n                            vdr_info = self._read_vdr(position)\n                        else:\n                            vdr_info = self._read_vdr2(position)\n                        break\n                    position = vdr_next\n                position = self._first_rvariable\n                num_variables = self._num_rvariable\n            if vdr_info is None:\n                print(\"Variable name not found.\")\n                return\n        elif isinstance(variable, int):\n            if self._num_zvariable > 0:\n                position = self._first_zvariable\n                num_variable = self._num_zvariable\n                # zVar = True\n            elif self._num_rvariable > 0:\n                position = self._first_rvariable\n                num_variable = self._num_rvariable\n                # zVar = False\n            if (variable < 0 or variable >= num_variable):\n                print('No variable by this number:', variable)\n                return\n            for _ in range(0, variable):\n                if (self.cdfversion == 3):\n                    name, next_vdr = self._read_vdr_fast(position)\n                else:\n                    name, next_vdr = self._read_vdr_fast2(position)\n                position = next_vdr\n            if (self.cdfversion == 3):\n                vdr_info = self._read_vdr(position)\n            else:\n                vdr_info = self._read_vdr2(position)\n        else:\n            print('Please set variable keyword equal to the name or ',\n                  'number of an variable')\n            rvars, zvars = self._get_varnames()\n            print(\"RVARIABLES: \")\n            for x in rvars:\n                print(\"NAME: \" + str(x))\n            print(\"ZVARIABLES: \")\n            for x in zvars:\n                print(\"NAME: \" + str(x))\n            return\n\n        if inq:\n            return vdr_info\n        else:\n            if (vdr_info['max_records'] < 0):\n                    # print('No data is written for this variable')\n                return None\n            return self._read_vardata(vdr_info, epoch=epoch, starttime=starttime, endtime=endtime,\n                                      startrec=startrec, endrec=endrec, record_range_only=record_range_only,\n                                      expand=expand, to_np=to_np)", "response": "This function returns the variable data for the given time range and start and end times."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef epochrange(self, epoch=None, starttime=None, endtime=None):\n        return self.varget(variable=epoch, starttime=starttime,\n                           endtime=endtime, record_range_only=True)", "response": "Get the time range of the records in the specified epoch."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef globalattsget(self, expand=False, to_np=True):\n        byte_loc = self._first_adr\n        return_dict = {}\n        for _ in range(0, self._num_att):\n            adr_info = self._read_adr(byte_loc)\n\n            if (adr_info['scope'] != 1):\n                byte_loc = adr_info['next_adr_location']\n                continue\n            if (adr_info['num_gr_entry'] == 0):\n                if (expand is not False):\n                    return_dict[adr_info['name']] = None\n                byte_loc = adr_info['next_adr_location']\n                continue\n            if (expand is False):\n                entries = []\n            else:\n                entries = {}\n            aedr_byte_loc = adr_info['first_gr_entry']\n            for _ in range(0, adr_info['num_gr_entry']):\n                if (self.cdfversion == 3):\n                    aedr_info = self._read_aedr(aedr_byte_loc, to_np=to_np)\n                else:\n                    aedr_info = self._read_aedr2(aedr_byte_loc, to_np=to_np)\n                entryData = aedr_info['entry']\n                if (expand is False):\n                    entries.append(entryData)\n                else:\n                    entryWithType = []\n                    if (isinstance(entryData, str)):\n                        entryWithType.append(entryData)\n                    else:\n                        dataType = aedr_info['data_type']\n                        if (len(entryData.tolist()) == 1):\n                            if (dataType != 31 and dataType != 32 and dataType != 33):\n                                entryWithType.append(entryData.tolist()[0])\n                            else:\n                                if (dataType != 33):\n                                    entryWithType.append(epoch.CDFepoch.encode(entryData.tolist()[0],\n                                                                               iso_8601=False))\n                                else:\n                                    entryWithType.append(epoch.CDFepoch.encode(entryData.tolist()[0]))\n                        else:\n                            if (dataType != 31 and dataType != 32 and dataType != 33):\n                                entryWithType.append(entryData.tolist())\n                            else:\n                                if (dataType != 33):\n                                    entryWithType.append(epoch.CDFepoch.encode(entryData.tolist(),\n                                                                               iso_8601=False))\n                                else:\n                                    entryWithType.append(epoch.CDFepoch.encode(entryData.tolist()))\n                    entryWithType.append(CDF._datatype_token(aedr_info['data_type']))\n                    entries[aedr_info['entry_num']] = entryWithType\n                aedr_byte_loc = aedr_info['next_aedr']\n\n            if (len(entries) != 0):\n                if (expand is False):\n                    if (len(entries) == 1):\n                        return_dict[adr_info['name']] = entries[0]\n                    else:\n                        return_dict[adr_info['name']] = entries\n                else:\n                    return_dict[adr_info['name']] = entries\n            byte_loc = adr_info['next_adr_location']\n\n        return return_dict", "response": "This function returns all of the global attribute entries in a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef varattsget(self, variable=None, expand=False, to_np=True):\n        if (isinstance(variable, int) and self._num_zvariable > 0 and self._num_rvariable > 0):\n            print('This CDF has both r and z variables. Use variable name')\n            return None\n        if isinstance(variable, str):\n            position = self._first_zvariable\n            num_variables = self._num_zvariable\n            for zVar in [1, 0]:\n                for _ in range(0, num_variables):\n                    if (self.cdfversion == 3):\n                        name, vdr_next = self._read_vdr_fast(position)\n                    else:\n                        name, vdr_next = self._read_vdr_fast2(position)\n                    if name.strip().lower() == variable.strip().lower():\n                        if (self.cdfversion == 3):\n                            vdr_info = self._read_vdr(position)\n                        else:\n                            vdr_info = self._read_vdr2(position)\n                        return self._read_varatts(vdr_info['variable_number'], zVar, expand, to_np=to_np)\n                    position = vdr_next\n                position = self._first_rvariable\n                num_variables = self._num_rvariable\n            print('No variable by this name:', variable)\n            return None\n        elif isinstance(variable, int):\n            if self._num_zvariable > 0:\n                num_variable = self._num_zvariable\n                zVar = True\n            else:\n                num_variable = self._num_rvariable\n                zVar = False\n            if (variable < 0 or variable >= num_variable):\n                print('No variable by this number:', variable)\n                return None\n            return self._read_varatts(variable, zVar, expand, to_np=to_np)\n        else:\n            print('Please set variable keyword equal to the name or ',\n                  'number of an variable')\n            rvars, zvars = self._get_varnames()\n            print(\"RVARIABLES: \")\n            for x in rvars:\n                print(\"NAME: \" + str(x))\n            print(\"ZVARIABLES: \")\n            for x in zvars:\n                print(\"NAME: \" + str(x))\n            return", "response": "This function returns all of the variable attributes in a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite the current file into a file in the temporary directory. If that doesn't work, create a new file in the CDFs directory.", "response": "def _uncompress_file(self, path):\n        '''\n        Writes the current file into a file in the temporary directory.\n\n        If that doesn't work, create a new file in the CDFs directory.\n        '''\n\n        with self.file.open('rb') as f:\n            if (self.cdfversion == 3):\n                data_start, data_size, cType, _ = self._read_ccr(8)\n            else:\n                data_start, data_size, cType, _ = self._read_ccr2(8)\n\n            if cType != 5:\n                return\n            f.seek(data_start)\n            decompressed_data = gzip.decompress(f.read(data_size))\n\n        newpath = pathlib.Path(tempfile.NamedTemporaryFile(suffix='.cdf').name)\n        with newpath.open('wb') as g:\n            g.write(bytearray.fromhex('cdf30001'))\n            g.write(bytearray.fromhex('0000ffff'))\n            g.write(decompressed_data)\n\n        return newpath"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nverifies the MD5 checksum of the file.", "response": "def _md5_validation(self) -> bool:\n        '''\n        Verifies the MD5 checksum.\n        Only used in the __init__() function\n        '''\n        fn = self.file if self.compressed_file is None else self.compressed_file\n\n        md5 = hashlib.md5()\n        block_size = 16384\n        with fn.open('rb') as f:\n            f.seek(-16, 2)\n            remaining = f.tell()  # File size minus checksum size\n            f.seek(0)\n            while (remaining > block_size):\n                data = f.read(block_size)\n                remaining = remaining - block_size\n                md5.update(data)\n\n            if (remaining > 0):\n                data = f.read(remaining)\n                md5.update(data)\n\n            existing_md5 = f.read(16).hex()\n\n        return md5.hexdigest() == existing_md5"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_vvrs(self, vdr_dict, vvr_offs, vvr_start, vvr_end, startrec, endrec, to_np=True):\n        '''\n        Reads in all VVRS that are pointed to in the VVR_OFFS array.\n        Creates a large byte array of all values called \"byte_stream\".\n        Decodes the byte_stream, then returns them.\n        '''\n\n        numBytes = CDF._type_size(vdr_dict['data_type'],\n                                  vdr_dict['num_elements'])\n        numValues = self._num_values(vdr_dict)\n        totalRecs = endrec - startrec + 1\n        firstBlock = -1\n        lastBlock = -1\n        totalBytes = numBytes * numValues * totalRecs\n        byte_stream = bytearray(totalBytes)\n        pos = 0\n        if (vdr_dict['sparse'] == 0):\n            for vvr_num in range(0, len(vvr_offs)):\n                if (vvr_end[vvr_num] >= startrec and firstBlock == -1):\n                    firstBlock = vvr_num\n                if (vvr_end[vvr_num] >= endrec):\n                    lastBlock = vvr_num\n                    break\n            for vvr_num in range(firstBlock, (lastBlock+1)):\n                if (self.cdfversion == 3):\n                    var_block_data = self._read_vvr_block(vvr_offs[vvr_num])\n                else:\n                    var_block_data = self._read_vvr_block2(vvr_offs[vvr_num])\n                asize = len(var_block_data)\n                byte_stream[pos:pos+asize] = var_block_data\n                pos = pos + asize\n            startPos = (startrec - vvr_start[firstBlock]) * numBytes * numValues\n            stopOff = (vvr_end[lastBlock] - endrec) * numBytes * numValues\n            byte_stream = byte_stream[startPos:len(byte_stream)-stopOff]\n        else:\n            # with sparse records\n            if ('pad' in vdr_dict):\n                # use default pad value\n                filled_data = CDF._convert_np_data(vdr_dict['pad'],\n                                                   vdr_dict['data_type'],\n                                                   vdr_dict['num_elements'])\n            else:\n                filled_data = CDF._convert_np_data(\n                    self._default_pad(vdr_dict['data_type'],\n                                      vdr_dict['num_elements']),\n                    vdr_dict['data_type'],\n                    vdr_dict['num_elements'])\n            cur_block = -1\n            rec_size = numBytes * numValues\n            for rec_num in range(startrec, (endrec+1)):\n                block, prev_block = CDF._find_block(vvr_start, vvr_end,\n                                                    cur_block, rec_num)\n                if (block > -1):\n                    record_off = rec_num - vvr_start[block]\n                    if (cur_block != block):\n                        if (self.cdfversion == 3):\n                            var_block_data = self._read_vvr_block(vvr_offs[block])\n                        else:\n                            var_block_data = self._read_vvr_block2(vvr_offs[block])\n                        cur_block = block\n                    xoff = record_off * rec_size\n                    byte_stream[pos:pos+rec_size] = var_block_data[xoff:\n                                                                   xoff+rec_size]\n                else:\n                    if (vdr_dict['sparse'] == 1):\n                        # use defined pad or default pad\n                        byte_stream[pos:pos+rec_size] = filled_data * numValues\n                    else:\n                        # use previous physical record\n                        if (prev_block != -1):\n                            if (self.cdfversion == 3):\n                                var_prev_block_data = self._read_vvr_block(\n                                    vvr_offs[prev_block])\n                            else:\n                                var_prev_block_data = self._read_vvr_block2(\n                                    vvr_offs[prev_block])\n                            lastRecOff = (vvr_end[prev_block] -\n                                          vvr_start[prev_block]) * rec_size\n                            byte_stream[pos:pos+rec_size] = var_prev_block_data[lastRecOff:]\n                        else:\n                            byte_stream[pos:pos+rec_size] = filled_data * numValues\n                pos = pos + rec_size\n                if (block > -1):\n                    cur_block = block\n        dimensions = []\n        var_vary = vdr_dict['dim_vary']\n        var_sizes = vdr_dict['dim_sizes']\n        for x in range(0, vdr_dict['num_dims']):\n            if (var_vary[x] == 0):\n                continue\n            dimensions.append(var_sizes[x])\n        if to_np:\n            y = self._read_data(byte_stream, vdr_dict['data_type'],\n                                totalRecs, vdr_dict['num_elements'],\n                                dimensions)\n        else:\n            if (vdr_dict['data_type'] == 32):\n                y = self._convert_data(byte_stream, vdr_dict['data_type'],\n                                       totalRecs, self._num_values(vdr_dict)*2,\n                                       vdr_dict['num_elements'])\n            else:\n                y = self._convert_data(byte_stream, vdr_dict['data_type'],\n                                       totalRecs, self._num_values(vdr_dict),\n                                       vdr_dict['num_elements'])\n\n        return y", "response": "Reads in all VVRS that are pointed to in the VVR_OFFS array and returns them as a byte array."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining how to convert CDF byte ordering to the system byte ordering.", "response": "def _convert_option(self):\n        '''\n        Determines how to convert CDF byte ordering to the system\n        byte ordering.\n        '''\n\n        if sys.byteorder == 'little' and self._endian() == 'big-endian':\n            # big->little\n            order = '>'\n        elif sys.byteorder == 'big' and self._endian() == 'little-endian':\n            # little->big\n            order = '<'\n        else:\n            # no conversion\n            order = '='\n        return order"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine the endianess of the CDF file Only used in __init__ Only used in __init__", "response": "def _endian(self) -> str:\n        '''\n        Determines endianess of the CDF file\n        Only used in __init__\n        '''\n        if (self._encoding == 1 or self._encoding == 2 or self._encoding == 5 or\n            self._encoding == 7 or self._encoding == 9 or self._encoding == 11 or\n                self._encoding == 12):\n            return 'big-endian'\n        else:\n            return 'little-endian'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _read_data(self, byte_stream, data_type, num_recs, num_elems, dimensions=None):\n        '''\n        This is the primary routine that converts streams of bytes into usable data.\n\n        To do so, we need the bytes, the type of data, the number of records,\n        the number of elements in a record, and dimension information.\n        '''\n\n        squeeze_needed = False\n        # If the dimension is [n], it needs to be [n,1]\n        # for the numpy dtype.  This requires us to squeeze\n        # the matrix later, to get rid of this extra dimension.\n        dt_string = self._convert_option()\n        if dimensions != None:\n            if (len(dimensions) == 1):\n                dimensions.append(1)\n                squeeze_needed = True\n            dt_string += '('\n            count = 0\n            for dim in dimensions:\n                count += 1\n                dt_string += str(dim)\n                if count < len(dimensions):\n                    dt_string += ','\n            dt_string += ')'\n        if data_type == 52 or data_type == 51:\n            # string\n            if dimensions == None:\n                byte_data = bytearray(byte_stream[0:num_recs*num_elems])\n                # In each record, check for the first '\\x00' (null character).\n                # If found, make all the characters after it null as well.\n                for x in range(0, num_recs):\n                    y = x * num_elems\n                    z = byte_data[y:y+num_elems].find(b'\\x00')\n                    if (z > -1 and z < (num_elems-1)):\n                        byte_data[y+z+1:y+num_elems] = b'\\x00' * (num_elems - z - 1)\n                ret = byte_data[0:num_recs*num_elems].decode('utf-8').replace('\\x00', '')\n            else:\n                # Count total number of strings\n                count = 1\n                for x in range(0, len(dimensions)):\n                    count = count * dimensions[x]\n                strings = []\n                if (len(dimensions) == 0):\n                    for i in range(0, num_recs*count*num_elems, num_elems):\n                        string1 = byte_stream[i:i+num_elems].decode('utf-8').\\\n                            replace('\\x00', '')\n                        strings.append(string1)\n                else:\n                    for x in range(0, num_recs):\n                        onerec = []\n                        for i in range(x*count*num_elems, (x+1)*count*num_elems,\n                                       num_elems):\n                            string1 = byte_stream[i:i+num_elems].decode('utf-8')\\\n                                .replace('\\x00', '')\n                            onerec.append(string1)\n                        strings.append(onerec)\n                ret = strings\n            return ret\n        else:\n            if (data_type == 1) or (data_type == 41):\n                dt_string += 'i1'\n            elif data_type == 2:\n                dt_string += 'i2'\n            elif data_type == 4:\n                dt_string += 'i4'\n            elif (data_type == 8) or (data_type == 33):\n                dt_string += 'i8'\n            elif data_type == 11:\n                dt_string += 'u1'\n            elif data_type == 12:\n                dt_string += 'u2'\n            elif data_type == 14:\n                dt_string += 'u4'\n            elif (data_type == 21) or (data_type == 44):\n                dt_string += 'f'\n            elif (data_type == 22) or (data_type == 45) or (data_type == 31):\n                dt_string += 'd'\n            elif (data_type == 32):\n                dt_string += 'c16'\n            dt = np.dtype(dt_string)\n            ret = np.frombuffer(byte_stream, dtype=dt, count=num_recs*num_elems)\n            try:\n                ret.setflags('WRITEABLE')\n            except ValueError:\n                # If we can't set the writable flag, just continue\n                pass\n\n        if squeeze_needed:\n            ret = np.squeeze(ret, axis=(ret.ndim-1))\n\n        # Put the data into system byte order\n        if self._convert_option() != '=':\n            ret = ret.byteswap().newbyteorder()\n\n        return ret", "response": "This is the primary routine that converts a byte stream into usable data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the number of values in a record using a given VDRDict.", "response": "def _num_values(self, vdr_dict):\n        '''\n        Returns the number of values in a record, using a given VDR\n        dictionary. Multiplies the dimension sizes of each dimension,\n        if it is varying.\n        '''\n        values = 1\n        for x in range(0, vdr_dict['num_dims']):\n            if (vdr_dict['dim_vary'][x] != 0):\n                values = values * vdr_dict['dim_sizes'][x]\n        return values"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _convert_type(self, data_type):\n        '''\n        CDF data types to python struct data types\n        '''\n        if (data_type == 1) or (data_type == 41):\n            dt_string = 'b'\n        elif data_type == 2:\n            dt_string = 'h'\n        elif data_type == 4:\n            dt_string = 'i'\n        elif (data_type == 8) or (data_type == 33):\n            dt_string = 'q'\n        elif data_type == 11:\n            dt_string = 'B'\n        elif data_type == 12:\n            dt_string = 'H'\n        elif data_type == 14:\n            dt_string = 'I'\n        elif (data_type == 21) or (data_type == 44):\n            dt_string = 'f'\n        elif (data_type == 22) or (data_type == 45) or (data_type == 31):\n            dt_string = 'd'\n        elif (data_type == 32):\n            dt_string = 'd'\n        elif (data_type == 51) or (data_type == 52):\n            dt_string = 's'\n        return dt_string", "response": "Convert CDF data types to python string"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _convert_np_data(data, data_type, num_elems):   # @NoSelf\n        '''\n        Converts a single np data into byte stream.\n        '''\n        if (data_type == 51 or data_type == 52):\n            if (data == ''):\n                return ('\\x00'*num_elems).encode()\n            else:\n                return data.ljust(num_elems, '\\x00').encode('utf-8')\n        elif (data_type == 32):\n            data_stream = data.real.tobytes()\n            data_stream += data.imag.tobytes()\n            return data_stream\n        else:\n            return data.tobytes()", "response": "Converts a single np data into byte stream."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a VVR or decompressed CVVR block from the file at the given offset.", "response": "def _read_vvr_block(self, offset):\n        '''\n        Returns a VVR or decompressed CVVR block\n        '''\n        with self.file.open('rb') as f:\n            f.seek(offset, 0)\n            block_size = int.from_bytes(f.read(8), 'big')\n            block = f.read(block_size-8)\n\n        section_type = int.from_bytes(block[0:4], 'big')\n        if section_type == 13:\n            # a CVVR\n            compressed_size = int.from_bytes(block[12:16], 'big')\n            return gzip.decompress(block[16:16+compressed_size])\n        elif section_type == 7:\n            # a VVR\n            return block[4:]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding the block that rec_num is in.", "response": "def _find_block(starts, ends, cur_block, rec_num):   # @NoSelf\n        '''\n        Finds the block that rec_num is in if it is found. Otherwise it returns -1.\n        It also returns the block that has the physical data either at or\n        preceeding the rec_num.\n        It could be -1 if the preceeding block does not exists.\n        '''\n        total = len(starts)\n        if (cur_block == -1):\n            cur_block = 0\n        for x in range(cur_block, total):\n            if (starts[x] <= rec_num and ends[x] >= rec_num):\n                return x, x\n            if (starts[x] > rec_num):\n                break\n        return -1, x-1"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts data to the appropriate type using struct. unpack method.", "response": "def _convert_data(self, data, data_type, num_recs, num_values, num_elems):\n        '''\n        Converts data to the appropriate type using the struct.unpack method,\n        rather than using numpy.\n        '''\n\n        if (data_type == 51 or data_type == 52):\n            return [data[i:i+num_elems].decode('utf-8') for i in\n                    range(0, num_recs*num_values*num_elems, num_elems)]\n        else:\n            tofrom = self._convert_option()\n            dt_string = self._convert_type(data_type)\n            form = tofrom + str(num_recs*num_values*num_elems) + dt_string\n            value_len = CDF._type_size(data_type, num_elems)\n            return list(struct.unpack_from(form,\n                                           data[0:num_recs*num_values*value_len]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getVersion():   # @NoSelf\n        print('CDFread version:', str(CDF.version) + '.' + str(CDF.release) +\n              '.' + str(CDF.increment))\n        print('Date: 2018/01/11')", "response": "Displays the code version and last modified date."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an access token for the specified subscription.", "response": "def get_access_token(self):\n        '''\n        Returns an access token for the specified subscription.\n\n        This method uses a cache to limit the number of requests to the token service.\n        A fresh token can be re-used during its lifetime of 10 minutes. After a successful\n        request to the token service, this method caches the access token. Subsequent\n        invocations of the method return the cached token for the next 5 minutes. After\n        5 minutes, a new token is fetched from the token service and the cache is updated.\n        '''\n\n        if (self.token is None) or (datetime.utcnow() > self.reuse_token_until):\n            headers = {'Ocp-Apim-Subscription-Key': self.client_secret}\n            response = requests.post(self.base_url, headers=headers)\n            response.raise_for_status()\n\n            self.token = response.content\n            self.reuse_token_until = datetime.utcnow() + timedelta(minutes=5)\n\n        return self.token.decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main(from_lang, to_lang, provider, secret_access_key, output_only, text):\n    text = ' '.join(text)\n\n    kwargs = dict(from_lang=from_lang, to_lang=to_lang, provider=provider)\n    if provider != DEFAULT_PROVIDER:\n        kwargs['secret_access_key'] = secret_access_key\n\n    translator = Translator(**kwargs)\n    translation = translator.translate(text)\n    if sys.version_info.major == 2:\n        translation = translation.encode(locale.getpreferredencoding())\n\n    if output_only:\n        click.echo(translation)\n        return translation\n\n    click.echo('\\nTranslation: {}'.format(translation))\n    click.echo('-' * 25)\n    click.echo('Translated by: {}'.format(translator.provider.name))\n\n    return translation", "response": "This function is the main entry point for the translate - cli script."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main():\n    server_configs = (\n        {'url': url, 'auth': ('admin', 'changeme'), 'verify': False}\n        for url\n        in ('https://sat1.example.com', 'https://sat2.example.com')\n    )\n    for server_config in server_configs:\n        response = requests.post(\n            server_config['url'] + '/api/v2/users',\n            json.dumps({\n                'user': {\n                    'auth_source_id': 1,\n                    'login': 'Alice',\n                    'mail': 'alice@example.com',\n                    'organization_ids': [get_organization_id(\n                        server_config,\n                        'Default_Organization'\n                    )],\n                    'password': 'hackme',\n                }\n            }),\n            auth=server_config['auth'],\n            headers={'content-type': 'application/json'},\n            verify=server_config['verify'],\n        )\n        response.raise_for_status()\n        pprint(response.json())", "response": "Create an identical user account on a pair of satellites."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the ID of the organization with label label.", "response": "def get_organization_id(server_config, label):\n    \"\"\"Return the ID of the organization with label ``label``.\n\n    :param server_config: A dict of information about the server being talked\n        to. The dict should include the keys \"url\", \"auth\" and \"verify\".\n    :param label: A string label that will be used when searching. Every\n        organization should have a unique label.\n    :returns: An organization ID. (Typically an integer.)\n\n    \"\"\"\n    response = requests.get(\n        server_config['url'] + '/katello/api/v2/organizations',\n        data=json.dumps({'search': 'label={}'.format(label)}),\n        auth=server_config['auth'],\n        headers={'content-type': 'application/json'},\n        verify=server_config['verify'],\n    )\n    response.raise_for_status()\n    decoded = response.json()\n    if decoded['subtotal'] != 1:\n        print(\n            'Expected to find one organization, but instead found {0}. Search '\n            'results: {1}'.format(decoded['subtotal'], decoded['results'])\n        )\n        exit(1)\n    return decoded['results'][0]['id']"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main():\n    org = Organization(name='junk org').create()\n    pprint(org.get_values())  # e.g. {'name': 'junk org', \u2026}\n    org.delete()", "response": "Create an organization print out its attributes and delete it."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nimplementing :meth:`nailgun.entities.ForemanTask.poll`. See :meth:`nailgun.entities.ForemanTask.poll` for a full description of how this method acts. Other methods may also call this method, such as :meth:`nailgun.entity_mixins.EntityDeleteMixin.delete`. Certain mixins benefit from being able to poll the server after performing an operation. However, this module cannot use :meth:`nailgun.entities.ForemanTask.poll`, as that would be a circular import. Placing the implementation of :meth:`nailgun.entities.ForemanTask.poll` here allows both that method and the mixins in this module to use the same logic.", "response": "def _poll_task(task_id, server_config, poll_rate=None, timeout=None):\n    \"\"\"Implement :meth:`nailgun.entities.ForemanTask.poll`.\n\n    See :meth:`nailgun.entities.ForemanTask.poll` for a full description of how\n    this method acts. Other methods may also call this method, such as\n    :meth:`nailgun.entity_mixins.EntityDeleteMixin.delete`.\n\n    Certain mixins benefit from being able to poll the server after performing\n    an operation. However, this module cannot use\n    :meth:`nailgun.entities.ForemanTask.poll`, as that would be a circular\n    import. Placing the implementation of\n    :meth:`nailgun.entities.ForemanTask.poll` here allows both that method and\n    the mixins in this module to use the same logic.\n\n    \"\"\"\n    if poll_rate is None:\n        poll_rate = TASK_POLL_RATE\n    if timeout is None:\n        timeout = TASK_TIMEOUT\n\n    # Implement the timeout.\n    def raise_task_timeout():  # pragma: no cover\n        \"\"\"Raise a KeyboardInterrupt exception in the main thread.\"\"\"\n        thread.interrupt_main()\n\n    timer = threading.Timer(timeout, raise_task_timeout)\n\n    # Poll until the task finishes. The timeout prevents an infinite loop.\n    path = '{0}/foreman_tasks/api/tasks/{1}'.format(server_config.url, task_id)\n    try:\n        timer.start()\n        while True:\n            response = client.get(path, **server_config.get_client_kwargs())\n            response.raise_for_status()\n            task_info = response.json()\n            if task_info['state'] in ('paused', 'stopped'):\n                break\n            time.sleep(poll_rate)\n    except KeyboardInterrupt:  # pragma: no cover\n        # raise_task_timeout will raise a KeyboardInterrupt when the timeout\n        # expires. Catch the exception and raise TaskTimedOutError\n        raise TaskTimedOutError(\n            'Timed out polling task {0}. Task information: {1}'\n            .format(task_id, task_info)\n        )\n    finally:\n        timer.cancel()\n\n    # Check for task success or failure.\n    if task_info['result'] != 'success':\n        raise TaskFailedError(\n            'Task {0} did not succeed. Task information: {1}'\n            .format(task_id, task_info)\n        )\n    return task_info"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _make_entity_from_id(entity_cls, entity_obj_or_id, server_config):\n    if isinstance(entity_obj_or_id, entity_cls):\n        return entity_obj_or_id\n    return entity_cls(server_config, id=entity_obj_or_id)", "response": "Given an entity object or an ID return an entity object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _make_entities_from_ids(entity_cls, entity_objs_and_ids, server_config):\n    return [\n        _make_entity_from_id(entity_cls, entity_or_id, server_config)\n        for entity_or_id\n        in entity_objs_and_ids\n    ]", "response": "Given an iterable of entities and or IDs return a list of entities."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nimplement the * _payload method. This method creates a dict of values that can be encoded to the server.", "response": "def _payload(fields, values):\n    \"\"\"Implement the ``*_payload`` methods.\n\n    It's frequently useful to create a dict of values that can be encoded to\n    JSON and sent to the server. Unfortunately, there are mismatches between\n    the field names used by NailGun and the field names the server expects.\n    This method provides a default translation that works in many cases. For\n    example:\n\n    >>> from nailgun.entities import Product\n    >>> product = Product(name='foo', organization=1)\n    >>> set(product.get_fields())\n    {\n        'description',\n        'gpg_key',\n        'id',\n        'label',\n        'name',\n        'organization',\n        'sync_plan',\n    }\n    >>> set(product.get_values())\n    {'name', 'organization'}\n    >>> product.create_payload()\n    {'organization_id': 1, 'name': 'foo'}\n\n    :param fields: A value like what is returned by\n        :meth:`nailgun.entity_mixins.Entity.get_fields`.\n    :param values: A value like what is returned by\n        :meth:`nailgun.entity_mixins.Entity.get_values`.\n    :returns: A dict mapping field names to field values.\n\n    \"\"\"\n    for field_name, field in fields.items():\n        if field_name in values:\n            if isinstance(field, OneToOneField):\n                values[field_name + '_id'] = (\n                    getattr(values.pop(field_name), 'id', None)\n                )\n            elif isinstance(field, OneToManyField):\n                values[field_name + '_ids'] = [\n                    entity.id for entity in values.pop(field_name)\n                ]\n            elif isinstance(field, ListField):\n                def parse(obj):\n                    \"\"\"parse obj payload if it is an Entity\"\"\"\n                    if isinstance(obj, Entity):\n                        return _payload(obj.get_fields(), obj.get_values())\n                    return obj\n\n                values[field_name] = [\n                    parse(obj) for obj in values[field_name]]\n    return values"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_entity_id(field_name, attrs):\n    field_name_id = field_name + '_id'\n    if field_name in attrs:\n        if attrs[field_name] is None:\n            return None\n        elif 'id' in attrs[field_name]:\n            return attrs[field_name]['id']\n    if field_name_id in attrs:\n        return attrs[field_name_id]\n    else:\n        raise MissingValueError(\n            'Cannot find a value for the \"{0}\" field. Searched for keys named '\n            '{1}, but available keys are {2}.'\n            .format(field_name, (field_name, field_name_id), attrs.keys())\n        )", "response": "Find the ID for a one to one relationship."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_entity_ids(field_name, attrs):\n    field_name_ids = field_name + '_ids'\n    plural_field_name = pluralize(field_name)\n    if field_name_ids in attrs:\n        return attrs[field_name_ids]\n    elif field_name in attrs:\n        return [entity['id'] for entity in attrs[field_name]]\n    elif plural_field_name in attrs:\n        return [entity['id'] for entity in attrs[plural_field_name]]\n    else:\n        raise MissingValueError(\n            'Cannot find a value for the \"{0}\" field. Searched for keys named '\n            '{1}, but available keys are {2}.'\n            .format(\n                field_name,\n                (field_name_ids, field_name, plural_field_name),\n                attrs.keys()\n            )\n        )", "response": "Find the IDs for a one to many relationship."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntransforms obj into a json serializable object.", "response": "def to_json_serializable(obj):\n    \"\"\" Transforms obj into a json serializable object.\n\n    :param obj: entity or any json serializable object\n\n    :return: serializable object\n\n    \"\"\"\n    if isinstance(obj, Entity):\n        return obj.to_json_dict()\n\n    if isinstance(obj, dict):\n        return {k: to_json_serializable(v) for k, v in obj.items()}\n    elif isinstance(obj, (list, tuple)):\n        return [to_json_serializable(v) for v in obj]\n    elif isinstance(obj, datetime):\n        return obj.strftime('%Y-%m-%d %H:%M:%S')\n    elif isinstance(obj, date):\n        return obj.strftime('%Y-%m-%d')\n\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the path to the current entity.", "response": "def path(self, which=None):\n        \"\"\"Return the path to the current entity.\n\n        Return the path to base entities of this entity's type if:\n\n        * ``which`` is ``'base'``, or\n        * ``which`` is ``None`` and instance attribute ``id`` is unset.\n\n        Return the path to this exact entity if instance attribute ``id`` is\n        set and:\n\n        * ``which`` is ``'self'``, or\n        * ``which`` is ``None``.\n\n        Raise :class:`NoSuchPathError` otherwise.\n\n        Child classes may choose to extend this method, especially if a child\n        entity offers more than the two URLs supported by default. If extended,\n        then the extending class should check for custom parameters before\n        calling ``super``::\n\n            def path(self, which):\n                if which == 'custom':\n                    return urljoin(\u2026)\n                super(ChildEntity, self).__init__(which)\n\n        This will allow the extending method to accept a custom parameter\n        without accidentally raising a :class:`NoSuchPathError`.\n\n        :param which: A string. Optional. Valid arguments are 'self' and\n            'base'.\n        :return: A string. A fully qualified URL.\n        :raises nailgun.entity_mixins.NoSuchPathError: If no path can be built.\n\n        \"\"\"\n        # It is OK that member ``self._meta`` is not found. Subclasses are\n        # required to set that attribute if they wish to use this method.\n        #\n        # Beware of leading and trailing slashes:\n        #\n        #     urljoin('example.com', 'foo') => 'foo'\n        #     urljoin('example.com/', 'foo') => 'example.com/foo'\n        #     urljoin('example.com', '/foo') => '/foo'\n        #     urljoin('example.com/', '/foo') => '/foo'\n        #\n        base = urljoin(\n            self._server_config.url + '/',\n            self._meta['api_path']  # pylint:disable=no-member\n        )\n        if which == 'base' or (which is None and not hasattr(self, 'id')):\n            return base\n        elif (which == 'self' or which is None) and hasattr(self, 'id'):\n            return urljoin(base + '/', str(self.id))  # pylint:disable=E1101\n        raise NoSuchPathError"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a copy of field values on the current object.", "response": "def get_values(self):\n        \"\"\"Return a copy of field values on the current object.\n\n        This method is almost identical to ``vars(self).copy()``. However,\n        only instance attributes that correspond to a field are included in\n        the returned dict.\n\n        :return: A dict mapping field names to user-provided values.\n        \"\"\"\n        attrs = vars(self).copy()\n        attrs.pop('_server_config')\n        attrs.pop('_fields')\n        attrs.pop('_meta')\n        if '_path_fields' in attrs:\n            attrs.pop('_path_fields')\n        return attrs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a dictionary with Entity properties for json encoding.", "response": "def to_json_dict(self, filter_fcn=None):\n        \"\"\"Create a dict with Entity properties for json encoding.\n        It can be overridden by subclasses for each standard serialization\n        doesn't work. By default it call _to_json_dict on OneToOne fields\n        and build a list calling the same method on each OneToMany object's\n        fields.\n\n        Fields can be filtered accordingly to 'filter_fcn'. This callable\n        receives field's name as first parameter and fields itself as second\n        parameter. It must return True if field's value should be included on\n        dict and False otherwise. If not provided field will not be filtered.\n\n        :type filter_fcn: callable\n        :return: dct\n        \"\"\"\n        fields, values = self.get_fields(), self.get_values()\n        filtered_fields = fields.items()\n        if filter_fcn is not None:\n            filtered_fields = (\n                tpl for tpl in filtered_fields if filter_fcn(tpl[0], tpl[1])\n            )\n        json_dct = {}\n        for field_name, field in filtered_fields:\n            if field_name in values:\n                value = values[field_name]\n                if value is None:\n                    json_dct[field_name] = None\n                    # This conditions is needed because some times you get\n                    # None on an OneToOneField what lead to an error\n                    # on bellow condition, e.g., calling value.to_json_dict()\n                    # when value is None\n                elif isinstance(field, OneToOneField):\n                    json_dct[field_name] = value.to_json_dict()\n                elif isinstance(field, OneToManyField):\n                    json_dct[field_name] = [\n                        entity.to_json_dict() for entity in value\n                    ]\n                else:\n                    json_dct[field_name] = to_json_serializable(value)\n        return json_dct"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompare this entity with another entity.", "response": "def compare(self, other, filter_fcn=None):\n        \"\"\"Returns True if properties can be compared in terms of eq.\n        Entity's Fields can be filtered accordingly to 'filter_fcn'.\n        This callable receives field's name as first parameter and field itself\n        as second parameter.\n        It must return True if field's value should be included on\n        comparison and False otherwise. If not provided field's marked as\n        unique will not be compared by default. 'id' and 'name' are examples of\n        unique fields commonly ignored. Check Entities fields for fields marked\n        with 'unique=True'\n\n\n        :param other: entity to compare\n        :param filter_fcn: callable\n        :return: boolean\n        \"\"\"\n        if not isinstance(other, type(self)):\n            return False\n        if filter_fcn is None:\n            def filter_unique(_, field):\n                \"\"\"Filter function for unique fields\"\"\"\n                return not field.unique\n            filter_fcn = filter_unique\n\n        return self.to_json_dict(filter_fcn) == other.to_json_dict(filter_fcn)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes the current entity.", "response": "def delete_raw(self):\n        \"\"\"Delete the current entity.\n\n        Make an HTTP DELETE call to ``self.path('base')``. Return the response.\n\n        :return: A ``requests.response`` object.\n\n        \"\"\"\n        return client.delete(\n            self.path(which='self'),\n            **self._server_config.get_client_kwargs()\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete the current entity.", "response": "def delete(self, synchronous=True):\n        \"\"\"Delete the current entity.\n\n        Call :meth:`delete_raw` and check for an HTTP 4XX or 5XX response.\n        Return either the JSON-decoded response or information about a\n        completed foreman task.\n\n        :param synchronous: A boolean. What should happen if the server returns\n            an HTTP 202 (accepted) status code? Wait for the task to complete\n            if ``True``. Immediately return a response otherwise.\n        :returns: A dict. Either the JSON-decoded response or information about\n            a foreman task.\n        :raises: ``requests.exceptions.HTTPError`` if the response has an HTTP\n            4XX or 5XX status code.\n        :raises: ``ValueError`` If an HTTP 202 response is received and the\n            response JSON can not be decoded.\n        :raises nailgun.entity_mixins.TaskTimedOutError: If an HTTP 202\n            response is received, ``synchronous is True`` and the task times\n            out.\n\n        \"\"\"\n\n        response = self.delete_raw()\n        response.raise_for_status()\n\n        if (synchronous is True and\n                response.status_code == http_client.ACCEPTED):\n            return _poll_task(response.json()['id'], self._server_config)\n        elif (response.status_code == http_client.NO_CONTENT or\n              (response.status_code == http_client.OK and\n               hasattr(response, 'content') and\n               not response.content.strip())):\n            # \"The server successfully processed the request, but is not\n            # returning any content. Usually used as a response to a successful\n            # delete request.\"\n            return\n        return response.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets information about the current entity.", "response": "def read_raw(self, params=None):\n        \"\"\"Get information about the current entity.\n\n        Make an HTTP GET call to ``self.path('self')``. Return the response.\n\n        :return: A ``requests.response`` object.\n\n        \"\"\"\n        path_type = self._meta.get('read_type', 'self')\n\n        return client.get(\n            self.path(path_type),\n            params=params,\n            **self._server_config.get_client_kwargs()\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget information about the current entity.", "response": "def read_json(self, params=None):\n        \"\"\"Get information about the current entity.\n\n        Call :meth:`read_raw`. Check the response status code, decode JSON and\n        return the decoded JSON as a dict.\n\n        :return: A dict. The server's response, with all JSON decoded.\n        :raises: ``requests.exceptions.HTTPError`` if the response has an HTTP\n            4XX or 5XX status code.\n        :raises: ``ValueError`` If the response JSON can not be decoded.\n\n        \"\"\"\n        response = self.read_raw(params=params)\n        response.raise_for_status()\n        return response.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(self, entity=None, attrs=None, ignore=None, params=None):\n        if entity is None:\n            entity = type(self)(self._server_config)\n        if attrs is None:\n            attrs = self.read_json(params=params)\n        if ignore is None:\n            ignore = set()\n\n        for field_name, field in entity.get_fields().items():\n            if field_name in ignore:\n                continue\n            if isinstance(field, OneToOneField):\n                entity_id = _get_entity_id(field_name, attrs)\n                if entity_id is None:\n                    referenced_entity = None\n                else:\n                    referenced_entity = field.entity(\n                        self._server_config,\n                        id=entity_id,\n                    )\n                setattr(entity, field_name, referenced_entity)\n            elif isinstance(field, OneToManyField):\n                referenced_entities = [\n                    field.entity(self._server_config, id=entity_id)\n                    for entity_id\n                    in _get_entity_ids(field_name, attrs)\n                ]\n                setattr(entity, field_name, referenced_entities)\n            else:\n                setattr(entity, field_name, attrs[field_name])\n        return entity", "response": "Read the current entity and return the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_missing(self):\n        for field_name, field in self.get_fields().items():\n            if field.required and not hasattr(self, field_name):\n                # Most `gen_value` methods return a value such as an integer,\n                # string or dictionary, but OneTo{One,Many}Field.gen_value\n                # returns the referenced class.\n                if hasattr(field, 'default'):\n                    value = field.default\n                elif hasattr(field, 'choices'):\n                    value = gen_choice(field.choices)\n                elif isinstance(field, OneToOneField):\n                    value = field.gen_value()(self._server_config).create(True)\n                elif isinstance(field, OneToManyField):\n                    value = [\n                        field.gen_value()(self._server_config).create(True)\n                    ]\n                else:\n                    value = field.gen_value()\n                setattr(self, field_name, value)", "response": "Automagically populate all required instance attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an entity. Possibly call :meth:`create_missing`. Then make an HTTP POST call to ``self.path('base')``. The request payload consists of whatever is returned by :meth:`create_payload`. Return the response. :param create_missing: Should :meth:`create_missing` be called? In other words, should values be generated for required, empty fields? Defaults to :data:`nailgun.entity_mixins.CREATE_MISSING`. :return: A ``requests.response`` object.", "response": "def create_raw(self, create_missing=None):\n        \"\"\"Create an entity.\n\n        Possibly call :meth:`create_missing`. Then make an HTTP POST call to\n        ``self.path('base')``. The request payload consists of whatever is\n        returned by :meth:`create_payload`. Return the response.\n\n        :param create_missing: Should :meth:`create_missing` be called? In\n            other words, should values be generated for required, empty fields?\n            Defaults to :data:`nailgun.entity_mixins.CREATE_MISSING`.\n        :return: A ``requests.response`` object.\n\n        \"\"\"\n        if create_missing is None:\n            create_missing = CREATE_MISSING\n        if create_missing is True:\n            self.create_missing()\n        return client.post(\n            self.path('base'),\n            self.create_payload(),\n            **self._server_config.get_client_kwargs()\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_json(self, create_missing=None):\n        response = self.create_raw(create_missing)\n        response.raise_for_status()\n        return response.json()", "response": "Create an entity.\n\n        Call :meth:`create_raw`. Check the response status code, decode JSON\n        and return the decoded JSON as a dict.\n\n        :return: A dict. The server's response, with all JSON decoded.\n        :raises: ``requests.exceptions.HTTPError`` if the response has an HTTP\n            4XX or 5XX status code.\n        :raises: ``ValueError`` If the response JSON can not be decoded."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a payload of values that can be sent to the server.", "response": "def update_payload(self, fields=None):\n        \"\"\"Create a payload of values that can be sent to the server.\n\n        By default, this method behaves just like :func:`_payload`. However,\n        one can also specify a certain set of fields that should be returned.\n        For more information, see :meth:`update`.\n\n        \"\"\"\n        values = self.get_values()\n        if fields is not None:\n            values = {field: values[field] for field in fields}\n        return _payload(self.get_fields(), values)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the current entity.", "response": "def update_raw(self, fields=None):\n        \"\"\"Update the current entity.\n\n        Make an HTTP PUT call to ``self.path('base')``. The request payload\n        consists of whatever is returned by :meth:`update_payload`. Return the\n        response.\n\n        :param fields: See :meth:`update`.\n        :return: A ``requests.response`` object.\n\n        \"\"\"\n        return client.put(\n            self.path('self'),\n            self.update_payload(fields),\n            **self._server_config.get_client_kwargs()\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_json(self, fields=None):\n        response = self.update_raw(fields)\n        response.raise_for_status()\n        return response.json()", "response": "Update the current entity."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a search query for the current locale.", "response": "def search_payload(self, fields=None, query=None):\n        \"\"\"Create a search query.\n\n        Do the following:\n\n        1. Generate a search query. By default, all values returned by\n           :meth:`nailgun.entity_mixins.Entity.get_values` are used. If\n           ``fields`` is specified, only the named values are used.\n        2. Merge ``query`` in to the generated search query.\n        3. Return the result.\n\n        The rules for generating a search query can be illustrated by example.\n        Let's say that we have an entity with an\n        :class:`nailgun.entity_fields.IntegerField`, a\n        :class:`nailgun.entity_fields.OneToOneField` and a\n        :class:`nailgun.entity_fields.OneToManyField`::\n\n            >>> some_entity = SomeEntity(id=1, one=2, many=[3, 4])\n            >>> fields = some_entity.get_fields()\n            >>> isinstance(fields['id'], IntegerField)\n            True\n            >>> isinstance(fields['one'], OneToOneField)\n            True\n            >>> isinstance(fields['many'], OneToManyField)\n            True\n\n        This method appends \"_id\" and \"_ids\" on to the names of each\n        ``OneToOneField`` and ``OneToManyField``, respectively::\n\n            >>> some_entity.search_payload()\n            {'id': 1, 'one_id': 2, 'many_ids': [3, 4]}\n\n        By default, all fields are used. But you can specify a set of field\n        names to use::\n\n            >>> some_entity.search_payload({'id'})\n            {'id': 1}\n            >>> some_entity.search_payload({'one'})\n            {'one_id': 2}\n            >>> some_entity.search_payload({'id', 'one'})\n            {'id': 1, 'one_id': 2}\n\n        If a ``query`` is specified, it is merged in to the generated query::\n\n            >>> some_entity.search_payload(query={'id': 5})\n            {'id': 5, 'one_id': 2, 'many_ids': [3, 4]}\n            >>> some_entity.search_payload(query={'per_page': 1000})\n            {'id': 1, 'one_id': 2, 'many_ids': [3, 4], 'per_page': 1000}\n\n        .. WARNING:: This method currently generates an extremely naive search\n            query that will be wrong in many cases. In addition, Satellite\n            currently accepts invalid search queries without complaint. Make\n            sure to check the API documentation for your version of Satellite\n            against what this method produces.\n\n        :param fields: See :meth:`search`.\n        :param query: See :meth:`search`.\n        :returns: A dict that can be encoded as JSON and used in a search.\n\n        \"\"\"\n        if fields is None:\n            fields = set(self.get_values().keys())\n        if query is None:\n            query = {}\n\n        payload = {}\n        fields_dict = self.get_fields()\n        for field in fields:\n            value = getattr(self, field)\n            if isinstance(fields_dict[field], OneToOneField):\n                payload[field + '_id'] = value.id\n            elif isinstance(fields_dict[field], OneToManyField):\n                payload[field + '_ids'] = [entity.id for entity in value]\n            else:\n                payload[field] = value\n        payload.update(query)\n        return payload"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches for entities. Make an HTTP GET call to ``self.path('base')``. Return the response. .. WARNING:: Subclasses that override this method should not alter the ``fields`` or ``query`` arguments. (However, subclasses that override this method may still alter the server's response.) See :meth:`search_normalize` for details. :param fields: See :meth:`search`. :param query: See :meth:`search`. :return: A ``requests.response`` object.", "response": "def search_raw(self, fields=None, query=None):\n        \"\"\"Search for entities.\n\n        Make an HTTP GET call to ``self.path('base')``. Return the response.\n\n        .. WARNING:: Subclasses that override this method should not alter the\n            ``fields`` or ``query`` arguments. (However, subclasses that\n            override this method may still alter the server's response.) See\n            :meth:`search_normalize` for details.\n\n        :param fields: See :meth:`search`.\n        :param query: See :meth:`search`.\n        :return: A ``requests.response`` object.\n\n        \"\"\"\n        return client.get(\n            self.path('base'),\n            data=self.search_payload(fields, query),\n            **self._server_config.get_client_kwargs()\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef search_json(self, fields=None, query=None):\n        response = self.search_raw(fields, query)\n        response.raise_for_status()\n        return response.json()", "response": "Search for entities. This method returns the decoded JSON as a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_normalize(self, results):\n        fields = self.get_fields()\n        normalized = []\n        for result in results:\n            # For each field that we know about, copy the corresponding field\n            # from the server's search result. If any extra attributes are\n            # copied over, Entity.__init__ will raise a NoSuchFieldError.\n            # Examples of problematic results from server:\n            #\n            # * organization_id (denormalized OneToOne. see above)\n            # * organizations, organization_ids (denormalized OneToMany. above)\n            # * updated_at, created_at (these may be handled in the future)\n            # * sp_subnet (Host.sp_subnet is an undocumented field)\n            #\n            attrs = {}\n            for field_name, field in fields.items():\n                if isinstance(field, OneToOneField):\n                    try:\n                        attrs[field_name] = _get_entity_id(field_name, result)\n                    except MissingValueError:\n                        pass\n                elif isinstance(field, OneToManyField):\n                    try:\n                        attrs[field_name] = _get_entity_ids(field_name, result)\n                    except MissingValueError:\n                        pass\n                else:\n                    try:\n                        attrs[field_name] = result[field_name]\n                    except KeyError:\n                        pass\n            normalized.append(attrs)\n        return normalized", "response": "Normalize search results so that they can be used to create new entities."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsearch for all entities of a given kind.", "response": "def search(self, fields=None, query=None, filters=None):\n        \"\"\"Search for entities.\n\n        At its simplest, this method searches for all entities of a given kind.\n        For example, to ask for all\n        :class:`nailgun.entities.LifecycleEnvironment` entities::\n\n            LifecycleEnvironment().search()\n\n        Values on an entity are used to generate a search query, and the\n        ``fields`` argument can be used to specify which fields should be used\n        when generating a search query::\n\n            lc_env = LifecycleEnvironment(name='foo', organization=1)\n            results = lc_env.search()  # Search by name and organization.\n            results = lc_env.search({'name', 'organization'})  # Same.\n            results = lc_env.search({'name'})  # Search by name.\n            results = lc_env.search({'organization'})  # Search by organization\n            results = lc_env.search(set())  # Search for all lifecycle envs.\n            results = lc_env.search({'library'})  # Error!\n\n        In some cases, the simple search queries that can be generated by\n        NailGun are not sufficient. In this case, you can pass in a raw search\n        query instead. For example, to search for all lifecycle environments\n        with a name of 'foo'::\n\n            LifecycleEnvironment().search(query={'search': 'name=\"foo\"'})\n\n        The example above is rather pointless: it is easier and more concise to\n        use a generated query. But \u2014 and this is a **very** important \"but\" \u2014\n        the manual search query is melded in to the generated query. This can\n        be used to great effect::\n\n            LifecycleEnvironment(name='foo').search(query={'per_page': 50})\n\n        For examples of what the final search queries look like, see\n        :meth:`search_payload`. (That method also accepts the ``fields`` and\n        ``query`` arguments.)\n\n        In some cases, the server's search facilities may be insufficient, or\n        it may be inordinately difficult to craft a search query. In this case,\n        you can filter search results locally. For example, to ask the server\n        for a list of all lifecycle environments and then locally search\n        through the results for the lifecycle environment named \"foo\"::\n\n            LifecycleEnvironment().search(filters={'name': 'foo'})\n\n        Be warned that filtering locally can be **very** slow. NailGun must\n        ``read()`` every single entity returned by the server before filtering\n        results. This is because the values used in the filtering process may\n        not have been returned by the server in the initial response to the\n        search.\n\n        The fact that all entities are read when ``filters`` is specified can\n        be used to great effect. For example, this search returns a fully\n        populated list of every single lifecycle environment::\n\n            LifecycleEnvironment().search(filters={})\n\n        :param fields: A set naming which fields should be used when generating\n            a search query. If ``None``, all values on the entity are used. If\n            an empty set, no values are used.\n        :param query: A dict containing a raw search query. This is melded in\n            to the generated search query like so:  ``{generated:\n            query}.update({manual: query})``.\n        :param filters: A dict. Used to filter search results locally.\n        :return: A list of entities, all of type ``type(self)``.\n\n        \"\"\"\n        # Goals:\n        #\n        # * Be tolerant of missing values. It's reasonable for the server to\n        #   return an incomplete set of attributes for each search result.\n        # * Use as many returned values as possible. There's no point in\n        #   letting returned data go to waste. This implies that we must\u2026\n        # * \u2026parse irregular server responses. This includes pluralized field\n        #   names, misnamed attributes (e.g. BZ 1233245) and weirdly named\n        #   fields (e.g. Media.path_).\n        #\n        results = self.search_json(fields, query)['results']\n        results = self.search_normalize(results)\n        entities = [\n            type(self)(self._server_config, **result)\n            for result in results\n        ]\n        if filters is not None:\n            entities = self.search_filter(entities, filters)\n        return entities"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef search_filter(entities, filters):\n        # Check to make sure all arguments are sane.\n        if len(entities) == 0:\n            return entities\n        fields = entities[0].get_fields()  # assume all entities are identical\n        if not set(filters).issubset(fields):\n            raise NoSuchFieldError(\n                'Valid filters are {0}, but received {1} instead.'\n                .format(fields.keys(), filters.keys())\n            )\n        for field_name in filters:\n            if isinstance(fields[field_name], (OneToOneField, OneToManyField)):\n                raise NotImplementedError(\n                    'Search results cannot (yet?) be locally filtered by '\n                    '`OneToOneField`s and `OneToManyField`s. {0} is a {1}.'\n                    .format(field_name, type(fields[field_name]).__name__)\n                )\n\n        # The arguments are sane. Filter away!\n        filtered = [entity.read() for entity in entities]  # don't alter inputs\n        for field_name, field_value in filters.items():\n            filtered = [\n                entity for entity in filtered\n                if getattr(entity, field_name) == field_value\n            ]\n        return filtered", "response": "Read all entities and locally filter them."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an organization print out its attributes and delete it.", "response": "def main():\n    \"\"\"Create an organization, print out its attributes and delete it.\"\"\"\n    auth = ('admin', 'changeme')\n    base_url = 'https://sat1.example.com'\n    organization_name = 'junk org'\n    args = {'auth': auth, 'headers': {'content-type': 'application/json'}}\n\n    response = requests.post(\n        base_url + '/katello/api/v2/organizations',\n        json.dumps({\n            'name': organization_name,\n            'organization': {'name': organization_name},\n        }),\n        **args\n    )\n    response.raise_for_status()\n    pprint(response.json())\n    response = requests.delete(\n        '{0}/katello/api/v2/organizations/{1}'.format(\n            base_url,\n            response.json()['id'],\n        ),\n        **args\n    )\n    response.raise_for_status()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_config_file_path(xdg_config_dir, xdg_config_file):\n    for config_dir in BaseDirectory.load_config_paths(xdg_config_dir):\n        path = join(config_dir, xdg_config_file)\n        if isfile(path):\n            return path\n    raise ConfigFileError(\n        'No configuration files could be located after searching for a file '\n        'named \"{0}\" in the standard XDG configuration paths, such as '\n        '\"~/.config/{1}/\".'.format(xdg_config_file, xdg_config_dir)\n    )", "response": "Search XDG_CONFIG_DIRS for a config file and return the first found."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete a server configuration.", "response": "def delete(cls, label='default', path=None):\n        \"\"\"Delete a server configuration.\n\n        This method is thread safe.\n\n        :param label: A string. The configuration identified by ``label`` is\n            deleted.\n        :param path: A string. The configuration file to be manipulated.\n            Defaults to what is returned by\n            :func:`nailgun.config._get_config_file_path`.\n        :returns: ``None``\n\n        \"\"\"\n        if path is None:\n            path = _get_config_file_path(\n                cls._xdg_config_dir,\n                cls._xdg_config_file\n            )\n        cls._file_lock.acquire()\n        try:\n            with open(path) as config_file:\n                config = json.load(config_file)\n            del config[label]\n            with open(path, 'w') as config_file:\n                json.dump(config, config_file)\n        finally:\n            cls._file_lock.release()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading a server configuration from a configuration file.", "response": "def get(cls, label='default', path=None):\n        \"\"\"Read a server configuration from a configuration file.\n\n        :param label: A string. The configuration identified by ``label`` is\n            read.\n        :param path: A string. The configuration file to be manipulated.\n            Defaults to what is returned by\n            :func:`nailgun.config._get_config_file_path`.\n        :returns: A brand new :class:`nailgun.config.BaseServerConfig` object\n            whose attributes have been populated as appropriate.\n        :rtype: BaseServerConfig\n\n        \"\"\"\n        if path is None:\n            path = _get_config_file_path(\n                cls._xdg_config_dir,\n                cls._xdg_config_file\n            )\n        with open(path) as config_file:\n            return cls(**json.load(config_file)[label])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_labels(cls, path=None):\n        if path is None:\n            path = _get_config_file_path(\n                cls._xdg_config_dir,\n                cls._xdg_config_file\n            )\n        with open(path) as config_file:\n            # keys() returns a list in Python 2 and a view in Python 3.\n            return tuple(json.load(config_file).keys())", "response": "Get all server configuration labels."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the current connection configuration to a file.", "response": "def save(self, label='default', path=None):\n        \"\"\"Save the current connection configuration to a file.\n\n        This method is thread safe.\n\n        :param label: A string. An identifier for the current configuration.\n            This allows multiple configurations with unique labels to be saved\n            in a single file. If a configuration identified by ``label``\n            already exists in the destination configuration file, it is\n            replaced.\n        :param path: A string. The configuration file to be manipulated. By\n            default, an XDG-compliant configuration file is used. A\n            configuration file is created if one does not exist already.\n        :returns: ``None``\n\n        \"\"\"\n        # What will we write out?\n        cfg = vars(self)\n        if 'version' in cfg:  # pragma: no cover\n            cfg['version'] = str(cfg['version'])\n\n        # Where is the file we're writing to?\n        if path is None:\n            path = join(\n                BaseDirectory.save_config_path(self._xdg_config_dir),\n                self._xdg_config_file\n            )\n        self._file_lock.acquire()\n\n        try:\n            # Either read an existing config or make an empty one. Then update\n            # the config and write it out.\n            try:\n                with open(path) as config_file:\n                    config = json.load(config_file)\n            except IOError:  # pragma: no cover\n                config = {}\n            config[label] = cfg\n            with open(path, 'w') as config_file:\n                json.dump(config, config_file)\n        finally:\n            self._file_lock.release()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_client_kwargs(self):\n        config = vars(self).copy()\n        config.pop('url')\n        config.pop('version', None)\n        return config", "response": "Get kwargs for use with the methods in nichgun. client."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a server configuration from a configuration file.", "response": "def get(cls, label='default', path=None):\n        \"\"\"Read a server configuration from a configuration file.\n\n        This method extends :meth:`nailgun.config.BaseServerConfig.get`. Please\n        read up on that method before trying to understand this one.\n\n        The entity classes rely on the requests library to be a transport\n        mechanism. The methods provided by that library, such as ``get`` and\n        ``post``, accept an ``auth`` argument. That argument must be a tuple:\n\n            Auth tuple to enable Basic/Digest/Custom HTTP Auth.\n\n        However, the JSON decoder does not recognize a tuple as a type, and\n        represents sequences of elements as a tuple. Compensate for that by\n        converting ``auth`` to a two element tuple if it is a two element list.\n\n        This override is done here, and not in the base class, because the base\n        class may be extracted out into a separate library and used in other\n        contexts. In those contexts, the presence of a list may not matter or\n        may be desirable.\n\n        \"\"\"\n        config = super(ServerConfig, cls).get(label, path)\n        if hasattr(config, 'auth') and isinstance(config.auth, list):\n            config.auth = tuple(config.auth)\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a value suitable for a : class : StringField.", "response": "def gen_value(self):\n        \"\"\"Return a value suitable for a :class:`StringField`.\"\"\"\n        return gen_string(\n            gen_choice(self.str_type),\n            gen_integer(self.min_len, self.max_len)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates an organization print out its attributes and delete it.", "response": "def main():\n    \"\"\"Create an organization, print out its attributes and delete it.\"\"\"\n    server_config = ServerConfig(\n        auth=('admin', 'changeme'),      # Use these credentials\u2026\n        url='https://sat1.example.com',  # \u2026to talk to this server.\n    )\n    org = Organization(server_config, name='junk org').create()\n    pprint(org.get_values())  # e.g. {'name': 'junk org', \u2026}\n    org.delete()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_content_type(kwargs):\n    if 'files' in kwargs:\n        return  # requests will automatically set the content-type\n    headers = kwargs.pop('headers', {})\n    headers.setdefault('content-type', 'application/json')\n    kwargs['headers'] = headers", "response": "Set the content - type header to applcation. json."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _log_request(method, url, kwargs, data=None, params=None):\n    logger.debug(\n        'Making HTTP %s request to %s with %s, %s and %s.',\n        method,\n        url,\n        'options {0}'.format(kwargs) if len(kwargs) > 0 else 'no options',\n        'params {0}'.format(params) if params else 'no params',\n        'data {0}'.format(data) if data is not None else 'no data',\n    )", "response": "Log out information about the arguments given."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _log_response(response):\n    message = u'Received HTTP {0} response: {1}'.format(\n        response.status_code,\n        response.text\n    )\n    if response.status_code >= 400:  # pragma: no cover\n        logger.warning(message)\n    else:\n        logger.debug(message)", "response": "Log out information about a HTTP response."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef request(method, url, **kwargs):\n    _set_content_type(kwargs)\n    if _content_type_is_json(kwargs) and kwargs.get('data') is not None:\n        kwargs['data'] = dumps(kwargs['data'])\n    _log_request(method, url, kwargs)\n    response = requests.request(method, url, **kwargs)\n    _log_response(response)\n    return response", "response": "A wrapper for requests. request."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef head(url, **kwargs):\n    _set_content_type(kwargs)\n    if _content_type_is_json(kwargs) and kwargs.get('data') is not None:\n        kwargs['data'] = dumps(kwargs['data'])\n    _log_request('HEAD', url, kwargs)\n    response = requests.head(url, **kwargs)\n    _log_response(response)\n    return response", "response": "A wrapper for requests. head."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef put(url, data=None, **kwargs):\n    _set_content_type(kwargs)\n    if _content_type_is_json(kwargs) and data is not None:\n        data = dumps(data)\n    _log_request('PUT', url, kwargs, data)\n    response = requests.put(url, data, **kwargs)\n    _log_response(response)\n    return response", "response": "A wrapper for requests. put."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main():\n    server_configs = ServerConfig.get('sat1'), ServerConfig.get('sat2')\n    for server_config in server_configs:\n        org = Organization(server_config).search(\n            query={'search': 'name=\"Default_Organization\"'}\n        )[0]\n        # The LDAP authentication source with an ID of 1 is internal. It is\n        # nearly guaranteed to exist and be functioning.\n        user = User(\n            server_config,\n            auth_source=1,  # or: AuthSourceLDAP(server_config, id=1),\n            login='Alice',\n            mail='alice@example.com',\n            organization=[org],\n            password='hackme',\n        ).create()\n        pprint(user.get_values())", "response": "Create an identical user account on a pair of satellites."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles a server s response in a typical fashion.", "response": "def _handle_response(response, server_config, synchronous=False, timeout=None):\n    \"\"\"Handle a server's response in a typical fashion.\n\n    Do the following:\n\n    1. Check the server's response for an HTTP status code indicating an error.\n    2. Poll the server for a foreman task to complete if an HTTP 202 (accepted)\n       status code is returned and ``synchronous is True``.\n    3. Immediately return if an HTTP \"NO CONTENT\" response is received.\n    4. Determine what type of the content returned from server. Depending on\n       the type method should return server's response, with all JSON decoded\n       or just response content itself.\n\n    :param response: A response object as returned by one of the functions in\n        :mod:`nailgun.client` or the requests library.\n    :param server_config: A `nailgun.config.ServerConfig` object.\n    :param synchronous: Should this function poll the server?\n    :param timeout: Maximum number of seconds to wait until timing out.\n            Defaults to ``nailgun.entity_mixins.TASK_TIMEOUT``.\n\n    \"\"\"\n    response.raise_for_status()\n    if synchronous is True and response.status_code == ACCEPTED:\n        return ForemanTask(\n            server_config, id=response.json()['id']).poll(timeout=timeout)\n    if response.status_code == NO_CONTENT:\n        return\n    if 'application/json' in response.headers.get('content-type', '').lower():\n        return response.json()\n    elif isinstance(response.content, bytes):\n        return response.content.decode('utf-8')\n    else:\n        return response.content"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds an organization object.", "response": "def _get_org(server_config, label):\n    \"\"\"Find an :class:`nailgun.entities.Organization` object.\n\n    :param nailgun.config.ServerConfig server_config: The server that should be\n        searched.\n    :param label: A string. The label of the organization to find.\n    :raises APIResponseError: If exactly one organization is not found.\n    :returns: An :class:`nailgun.entities.Organization` object.\n\n    \"\"\"\n    organizations = Organization(server_config).search(\n        query={u'search': u'label={0}'.format(label)}\n    )\n    if len(organizations) != 1:\n        raise APIResponseError(\n            u'Could not find exactly one organization with label \"{0}\". '\n            u'Actual search results: {1}'.format(label, organizations)\n        )\n    return organizations[0].read()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef path(self, which=None):\n        if which in (\n                'add_subscriptions',\n                'content_override',\n                'copy',\n                'host_collections',\n                'product_content',\n                'releases',\n                'remove_subscriptions',\n                'subscriptions'):\n            return '{0}/{1}'.format(\n                super(ActivationKey, self).path(which='self'),\n                which\n            )\n        return super(ActivationKey, self).path(which)", "response": "Extend nailgun. entity_mixins. Entity. path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef path(self, which=None):\n        if which in ('download_html',):\n            return '{0}/{1}'.format(\n                super(ArfReport, self).path(which='self'),\n                which\n            )\n        return super(ArfReport, self).path(which)", "response": "Extend nailgun. entity_mixins. Entity. path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_missing(self):\n        super(AuthSourceLDAP, self).create_missing()\n        if getattr(self, 'onthefly_register', False) is True:\n            for field in (\n                    'account_password',\n                    'attr_firstname',\n                    'attr_lastname',\n                    'attr_login',\n                    'attr_mail'):\n                if not hasattr(self, field):\n                    setattr(self, field, self._fields[field].gen_value())", "response": "Possibly set several extra instance attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the LDAP entry.", "response": "def read(self, entity=None, attrs=None, ignore=None, params=None):\n        \"\"\"Do not read the ``account_password`` attribute. Work around a bug.\n\n        For more information, see `Bugzilla #1243036\n        <https://bugzilla.redhat.com/show_bug.cgi?id=1243036>`_.\n\n        \"\"\"\n        if attrs is None:\n            attrs = self.update_json([])\n        if ignore is None:\n            ignore = set()\n        ignore.add('account_password')\n        return super(AuthSourceLDAP, self).read(entity, attrs, ignore, params)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef path(self, which=None):\n        if which and which.startswith('content_'):\n            return '{0}/content/{1}'.format(\n                super(Capsule, self).path(which='self'),\n                which.split('content_')[1]\n            )\n        return super(Capsule, self).path(which)", "response": "Extend nailgun. entity_mixins. Entity. path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextend nailgun. entity_mixins. Entity. path.", "response": "def path(self, which=None):\n        \"\"\"Extend ``nailgun.entity_mixins.Entity.path``.\n\n        The format of the returned path depends on the value of ``which``:\n\n        facts\n            /discovered_hosts/facts\n\n        ``super`` is called otherwise.\n\n        \"\"\"\n        if which == 'facts':\n            return '{0}/{1}'.format(\n                super(DiscoveredHost, self).path(which='base'),\n                which\n            )\n        return super(DiscoveredHost, self).path(which)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_payload(self):\n        payload = super(DiscoveryRule, self).create_payload()\n        if 'search_' in payload:\n            payload['search'] = payload.pop('search_')\n        return {u'discovery_rule': payload}", "response": "Wrap submitted data within an extra dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new object of the correct type.", "response": "def create(self, create_missing=None):\n        \"\"\"Do extra work to fetch a complete set of attributes for this entity.\n\n        For more information, see `Bugzilla #1381129\n        <https://bugzilla.redhat.com/show_bug.cgi?id=1381129>`_.\n\n        \"\"\"\n        return type(self)(\n            self._server_config,\n            id=self.create_json(create_missing)['id'],\n        ).read()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nworks around a bug. Rename ``search`` to ``search_``. For more information on the bug, see `Bugzilla #1257255 <https://bugzilla.redhat.com/show_bug.cgi?id=1257255>`_.", "response": "def read(self, entity=None, attrs=None, ignore=None, params=None):\n        \"\"\"Work around a bug. Rename ``search`` to ``search_``.\n\n        For more information on the bug, see `Bugzilla #1257255\n        <https://bugzilla.redhat.com/show_bug.cgi?id=1257255>`_.\n\n        \"\"\"\n        if attrs is None:\n            attrs = self.read_json()\n        attrs['search_'] = attrs.pop('search')\n\n        # Satellite doesn't return this attribute. See BZ 1257255.\n        attr = 'max_count'\n        if ignore is None:\n            ignore = set()\n        if attr not in ignore:\n            # We cannot call `self.update_json([])`, as an ID might not be\n            # present on self. However, `attrs` is guaranteed to have an ID.\n            attrs[attr] = DiscoveryRule(\n                self._server_config,\n                id=attrs['id'],\n            ).update_json([])[attr]\n        return super(DiscoveryRule, self).read(entity, attrs, ignore, params)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap submitted data within an extra dict.", "response": "def update_payload(self, fields=None):\n        \"\"\"Wrap submitted data within an extra dict.\"\"\"\n        payload = super(DiscoveryRule, self).update_payload(fields)\n        if 'search_' in payload:\n            payload['search'] = payload.pop('search_')\n        return {u'discovery_rule': payload}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new instance of the object.", "response": "def create(self, create_missing=None):\n        \"\"\"Do extra work to fetch a complete set of attributes for this entity.\n\n        For more information, see `Bugzilla #1223540\n        <https://bugzilla.redhat.com/show_bug.cgi?id=1223540>`_.\n\n        \"\"\"\n        return DockerComputeResource(\n            self._server_config,\n            id=self.create_json(create_missing)['id'],\n        ).read()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads the attributes of a specific entity.", "response": "def read(self, entity=None, attrs=None, ignore=None, params=None):\n        \"\"\"Do extra work to fetch a complete set of attributes for this entity.\n\n        For more information, see `Bugzilla #1223540\n        <https://bugzilla.redhat.com/show_bug.cgi?id=1223540>`_.\n\n        Also, do not try to read the \"password\" field. No value is returned for\n        the field, for obvious reasons.\n\n        \"\"\"\n        if attrs is None:\n            attrs = self.read_json()\n        if ignore is None:\n            ignore = set()\n        ignore.add('password')\n        if 'email' not in attrs and 'email' not in ignore:\n            response = client.put(\n                self.path('self'),\n                {},\n                **self._server_config.get_client_kwargs()\n            )\n            response.raise_for_status()\n            attrs['email'] = response.json().get('email')\n        return super(DockerComputeResource, self).read(\n            entity, attrs, ignore, params)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(self, entity=None, attrs=None, ignore=None, params=None):\n        if entity is None:\n            entity = type(self)(\n                self._server_config,\n                usergroup=self.usergroup,  # pylint:disable=no-member\n            )\n        if ignore is None:\n            ignore = set()\n        ignore.add('usergroup')\n        if attrs is None:\n            attrs = self.read_json()\n        attrs['auth_source'] = attrs.pop('auth_source_ldap')\n        return super(ExternalUserGroup, self).read(entity, attrs, ignore, params)", "response": "Read usergroup from server config and update auth_source_ldap with auth_source"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextending nailgun. entity_mixins. Entity. path.", "response": "def path(self, which=None):\n        \"\"\"Extend ``nailgun.entity_mixins.Entity.path``.\n\n        The format of the returned path depends on the value of ``which``:\n\n        refresh\n            /api/usergroups/:usergroup_id/external_usergroups/:id/refresh\n        \"\"\"\n        if which == 'refresh':\n            return '{0}/{1}'.format(\n                super(ExternalUserGroup, self).path(which='self'),\n                which\n            )\n        return super(ExternalUserGroup, self).path(which)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_payload(self):\n        payload = super(ConfigTemplate, self).create_payload()\n        if 'template_combinations' in payload:\n            payload['template_combinations_attributes'] = payload.pop(\n                'template_combinations')\n        return {u'config_template': payload}", "response": "Wrap submitted data within an extra dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_payload(self, fields=None):\n        payload = super(ConfigTemplate, self).update_payload(fields)\n        if 'template_combinations' in payload:\n            payload['template_combinations_attributes'] = payload.pop(\n                'template_combinations')\n        return {u'config_template': payload}", "response": "Wrap submitted data within an extra dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextends nailgun. entity_mixins. Entity. path.", "response": "def path(self, which=None):\n        \"\"\"Extend ``nailgun.entity_mixins.Entity.path``.\n\n        The format of the returned path depends on the value of ``which``:\n\n        build_pxe_default\n            /config_templates/build_pxe_default\n        clone\n            /config_templates/clone\n        revision\n            /config_templates/revision\n\n        ``super`` is called otherwise.\n\n        \"\"\"\n        if which in ('build_pxe_default', 'clone', 'revision'):\n            prefix = 'self' if which == 'clone' else 'base'\n            return '{0}/{1}'.format(\n                super(ConfigTemplate, self).path(prefix),\n                which\n            )\n        return super(ConfigTemplate, self).path(which)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the object from the server.", "response": "def read(self, entity=None, attrs=None, ignore=None, params=None):\n        \"\"\"Create a JobTemplate object before calling read()\n        ignore 'advanced'\n        \"\"\"\n        if entity is None:\n            entity = TemplateInput(self._server_config, template=self.template)\n        if ignore is None:\n            ignore = set()\n        ignore.add('advanced')\n        return super(TemplateInput, self).read(entity=entity, attrs=attrs,\n                                               ignore=ignore, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self, synchronous=True, **kwargs):\n        kwargs = kwargs.copy()  # shadow the passed-in kwargs\n        kwargs.update(self._server_config.get_client_kwargs())\n        if 'data' in kwargs:\n            if 'job_template_id' not in kwargs['data'] and 'feature' not in kwargs['data']:\n                raise KeyError('Provide either job_template_id or feature value')\n            if 'search_query' not in kwargs['data'] and 'bookmark_id' not in kwargs['data']:\n                raise KeyError('Provide either search_query or bookmark_id value')\n            for param_name in ['targeting_type', 'inputs']:\n                if param_name not in kwargs['data']:\n                    raise KeyError('Provide {} value'.format(param_name))\n            kwargs['data'] = {u'job_invocation': kwargs['data']}\n        response = client.post(self.path('base'), **kwargs)\n        response.raise_for_status()\n        if synchronous is True:\n            return ForemanTask(\n                server_config=self._server_config, id=response.json()['task']['id']).poll()\n        return response.json()", "response": "Runs the existing job template."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping submitted data within an extra dict.", "response": "def create_payload(self):\n        \"\"\"Wrap submitted data within an extra dict.\"\"\"\n\n        payload = super(JobTemplate, self).create_payload()\n        effective_user = payload.pop(u'effective_user', None)\n        if effective_user:\n            payload[u'ssh'] = {u'effective_user': effective_user}\n\n        return {u'job_template': payload}"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrap submitted data within an extra dict.", "response": "def update_payload(self, fields=None):\n        \"\"\"Wrap submitted data within an extra dict.\"\"\"\n        payload = super(JobTemplate, self).update_payload(fields)\n        effective_user = payload.pop(u'effective_user', None)\n        if effective_user:\n            payload[u'ssh'] = {u'effective_user': effective_user}\n        return {u'job_template': payload}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(self, entity=None, attrs=None, ignore=None, params=None):\n        if attrs is None:\n            attrs = self.read_json(params=params)\n        if ignore is None:\n            ignore = set()\n        ignore.add('template_inputs')\n        entity = super(JobTemplate, self).read(entity=entity, attrs=attrs,\n                                               ignore=ignore, params=params)\n        referenced_entities = [\n            TemplateInput(entity._server_config, id=entity_id,\n                          template=JobTemplate(entity._server_config,\n                                               id=entity.id))\n            for entity_id\n            in _get_entity_ids('template_inputs', attrs)\n        ]\n        setattr(entity, 'template_inputs', referenced_entities)\n        return entity", "response": "Read the job template."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_missing(self):\n        super(ProvisioningTemplate, self).create_missing()\n        if (getattr(self, 'snippet', None) is False and\n                not hasattr(self, 'template_kind')):\n            self.template_kind = TemplateKind(self._server_config, id=1)", "response": "Customize the process of auto - generating instance attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps submitted data within an extra dict.", "response": "def create_payload(self):\n        \"\"\"Wrap submitted data within an extra dict.\n\n        For more information, see `Bugzilla #1151220\n        <https://bugzilla.redhat.com/show_bug.cgi?id=1151220>`_.\n\n        \"\"\"\n        payload = super(ProvisioningTemplate, self).create_payload()\n        if 'template_combinations' in payload:\n            payload['template_combinations_attributes'] = payload.pop(\n                'template_combinations')\n        return {u'provisioning_template': payload}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_payload(self, fields=None):\n        payload = super(ProvisioningTemplate, self).update_payload(fields)\n        if 'template_combinations' in payload:\n            payload['template_combinations_attributes'] = payload.pop(\n                'template_combinations')\n        return {u'provisioning_template': payload}", "response": "Wrap submitted data within an extra dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef path(self, which=None):\n        if which in ('build_pxe_default', 'clone', 'revision'):\n            prefix = 'self' if which == 'clone' else 'base'\n            return '{0}/{1}'.format(\n                super(ProvisioningTemplate, self).path(prefix),\n                which\n            )\n        return super(ProvisioningTemplate, self).path(which)", "response": "Extend nailgun. entity_mixins. Entity. path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef path(self, which=None):\n        if which in ('logs', 'power'):\n            return '{0}/{1}'.format(\n                super(AbstractDockerContainer, self).path(which='self'),\n                which\n            )\n        return super(AbstractDockerContainer, self).path(which)", "response": "Extend nailgun. entity_mixins. Entity. path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read(self, entity=None, attrs=None, ignore=None, params=None):\n        # read() should not change the state of the object it's called on, but\n        # super() alters the attributes of any entity passed in. Creating a new\n        # object and passing it to super() lets this one avoid changing state.\n        if entity is None:\n            entity = type(self)(\n                self._server_config,\n                repository=self.repository,  # pylint:disable=no-member\n            )\n        if ignore is None:\n            ignore = set()\n        ignore.add('repository')\n        return super(ContentUpload, self).read(entity, attrs, ignore, params)", "response": "Read the content of an object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the current entity.", "response": "def update(self, fields=None, **kwargs):\n        \"\"\"Update the current entity.\n\n        Make an HTTP PUT call to ``self.path('base')``. Return the response.\n\n        :param fields: An iterable of field names. Only the fields named in\n            this iterable will be updated. No fields are updated if an empty\n            iterable is passed in. All fields are updated if ``None`` is passed\n            in.\n        :return: A ``requests.response`` object.\n\n        \"\"\"\n        kwargs = kwargs.copy()  # shadow the passed-in kwargs\n        kwargs.update(self._server_config.get_client_kwargs())\n        # a content upload is always multipart\n        headers = kwargs.pop('headers', {})\n        headers['content-type'] = 'multipart/form-data'\n        kwargs['headers'] = headers\n        return client.put(\n            self.path('self'),\n            fields,\n            **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef upload(self, filepath, filename=None):\n        if not filename:\n            filename = os.path.basename(filepath)\n\n        content_upload = self.create()\n\n        try:\n            offset = 0\n            content_chunk_size = 2 * 1024 * 1024\n\n            with open(filepath, 'rb') as contentfile:\n                chunk = contentfile.read(content_chunk_size)\n                while len(chunk) > 0:\n                    data = {'offset': offset,\n                            'content': chunk}\n                    content_upload.update(data)\n\n                    offset += len(chunk)\n                    chunk = contentfile.read(content_chunk_size)\n\n            size = 0\n            checksum = hashlib.sha256()\n            with open(filepath, 'rb') as contentfile:\n                contents = contentfile.read()\n                size = len(contents)\n                checksum.update(contents)\n\n            uploads = [{'id': content_upload.upload_id, 'name': filename,\n                        'size': size, 'checksum': checksum.hexdigest()}]\n            # pylint:disable=no-member\n            json = self.repository.import_uploads(uploads)\n        finally:\n            content_upload.delete()\n\n        return json", "response": "Uploads a file to the server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef path(self, which=None):\n        if which in ('incremental_update', 'promote'):\n            prefix = 'base' if which == 'incremental_update' else 'self'\n            return '{0}/{1}'.format(\n                super(ContentViewVersion, self).path(prefix),\n                which\n            )\n        return super(ContentViewVersion, self).path(which)", "response": "Extend nailgun. entity_mixins. Entity. path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the content_view_filter attribute of the current object.", "response": "def read(self, entity=None, attrs=None, ignore=None, params=None):\n        \"\"\"Do not read certain fields.\n\n        Do not expect the server to return the ``content_view_filter``\n        attribute. This has no practical impact, as the attribute must be\n        provided when a :class:`nailgun.entities.ContentViewFilterRule` is\n        instantiated.\n\n        Also, ignore any field that is not returned by the server. For more\n        information, see `Bugzilla #1238408\n        <https://bugzilla.redhat.com/show_bug.cgi?id=1238408>`_.\n\n        \"\"\"\n        if entity is None:\n            entity = type(self)(\n                self._server_config,\n                # pylint:disable=no-member\n                content_view_filter=self.content_view_filter,\n            )\n        if attrs is None:\n            attrs = self.read_json()\n        if ignore is None:\n            ignore = set()\n        ignore.add('content_view_filter')\n        ignore.update([\n            field_name\n            for field_name in entity.get_fields().keys()\n            if field_name not in attrs\n        ])\n        return super(ContentViewFilterRule, self).read(\n            entity, attrs, ignore, params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a payload dict from the DB ID to the errata_id.", "response": "def create_payload(self):\n        \"\"\"Reset ``errata_id`` from DB ID to ``errata_id``.\"\"\"\n        payload = super(ContentViewFilterRule, self).create_payload()\n        if 'errata_id' in payload:\n            if not hasattr(self.errata, 'errata_id'):\n                self.errata = self.errata.read()\n            payload['errata_id'] = self.errata.errata_id\n        return payload"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the payload with errata_id from DB ID to errata_id.", "response": "def update_payload(self, fields=None):\n        \"\"\"Reset ``errata_id`` from DB ID to ``errata_id``.\"\"\"\n        payload = super(ContentViewFilterRule, self).update_payload(fields)\n        if 'errata_id' in payload:\n            if not hasattr(self.errata, 'errata_id'):\n                self.errata = self.errata.read()\n            payload['errata_id'] = self.errata.errata_id\n        return payload"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search_payload(self, fields=None, query=None):\n        payload = super(ContentViewFilterRule, self).search_payload(\n            fields, query)\n        if 'errata_id' in payload:\n            if not hasattr(self.errata, 'errata_id'):\n                self.errata = self.errata.read()\n            payload['errata_id'] = self.errata.errata_id\n        return payload", "response": "Search for the content view rule."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read(self, entity=None, attrs=None, ignore=None, params=None):\n        # read() should not change the state of the object it's called on, but\n        # super() alters the attributes of any entity passed in. Creating a new\n        # object and passing it to super() lets this one avoid changing state.\n        if entity is None:\n            entity = type(self)(\n                self._server_config,\n                content_view=self.content_view,  # pylint:disable=no-member\n            )\n        if ignore is None:\n            ignore = set()\n        ignore.add('content_view')\n        return super(ContentViewPuppetModule, self).read(\n            entity, attrs, ignore, params)", "response": "Read the antenna entry in the database."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read(self, entity=None, attrs=None, ignore=None, params=None):\n        if attrs is None:\n            attrs = self.read_json()\n        if _get_version(self._server_config) < Version('6.1'):\n            org = _get_org(self._server_config, attrs['organization']['label'])\n            attrs['organization'] = org.get_values()\n\n        if ignore is None:\n            ignore = set()\n        ignore.add('content_view_component')\n        result = super(ContentView, self).read(entity, attrs, ignore, params)\n        if 'content_view_components' in attrs and attrs['content_view_components']:\n            result.content_view_component = [\n                ContentViewComponent(\n                    self._server_config,\n                    composite_content_view=result.id,\n                    id=content_view_component['id'],\n                )\n                for content_view_component in attrs['content_view_components']\n            ]\n        return result", "response": "Read an attribute missing from the server s response."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch for entities. :param fields: A set naming which fields should be used when generating a search query. If ``None``, all values on the entity are used. If an empty set, no values are used. :param query: A dict containing a raw search query. This is melded in to the generated search query like so: ``{generated: query}.update({manual: query})``. :param filters: A dict. Used to filter search results locally. :return: A list of entities, all of type ``type(self)``.", "response": "def search(self, fields=None, query=None, filters=None):\n        \"\"\"Search for entities.\n\n        :param fields: A set naming which fields should be used when generating\n            a search query. If ``None``, all values on the entity are used. If\n            an empty set, no values are used.\n        :param query: A dict containing a raw search query. This is melded in\n            to the generated search query like so:  ``{generated:\n            query}.update({manual: query})``.\n        :param filters: A dict. Used to filter search results locally.\n        :return: A list of entities, all of type ``type(self)``.\n        \"\"\"\n        results = self.search_json(fields, query)['results']\n        results = self.search_normalize(results)\n        entities = []\n        for result in results:\n            content_view_components = result.get('content_view_component')\n            if content_view_components is not None:\n                del result['content_view_component']\n            entity = type(self)(self._server_config, **result)\n            if content_view_components:\n                entity.content_view_component = [\n                    ContentViewComponent(\n                        self._server_config,\n                        composite_content_view=result['id'],\n                        id=cvc_id,\n                    )\n                    for cvc_id in content_view_components\n                ]\n            entities.append(entity)\n        if filters is not None:\n            entities = self.search_filter(entities, filters)\n        return entities"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextending nailgun. entity_mixins. Entity. path.", "response": "def path(self, which=None):\n        \"\"\"Extend ``nailgun.entity_mixins.Entity.path``.\n\n        The format of the returned path depends on the value of ``which``:\n\n        content_view_puppet_modules\n            /content_views/<id>/content_view_puppet_modules\n        content_view_versions\n            /content_views/<id>/content_view_versions\n        publish\n            /content_views/<id>/publish\n        available_puppet_module_names\n            /content_views/<id>/available_puppet_module_names\n\n        ``super`` is called otherwise.\n\n        \"\"\"\n        if which in (\n                'available_puppet_module_names',\n                'available_puppet_modules',\n                'content_view_puppet_modules',\n                'content_view_versions',\n                'copy',\n                'publish'):\n            return '{0}/{1}'.format(\n                super(ContentView, self).path(which='self'),\n                which\n            )\n        return super(ContentView, self).path(which)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef publish(self, synchronous=True, **kwargs):\n        kwargs = kwargs.copy()  # shadow the passed-in kwargs\n        if 'data' in kwargs and 'id' not in kwargs['data']:\n            kwargs['data']['id'] = self.id  # pylint:disable=no-member\n        kwargs.update(self._server_config.get_client_kwargs())\n        response = client.post(self.path('publish'), **kwargs)\n        return _handle_response(response, self._server_config, synchronous)", "response": "Publishes an existing content view."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting this content view version from an environment.", "response": "def delete_from_environment(self, environment, synchronous=True):\n        \"\"\"Delete this content view version from an environment.\n\n        This method acts much like\n        :meth:`nailgun.entity_mixins.EntityDeleteMixin.delete`.  The\n        documentation on that method describes how the deletion procedure works\n        in general. This method differs only in accepting an ``environment``\n        parameter.\n\n        :param environment: A :class:`nailgun.entities.Environment` object. The\n            environment's ``id`` parameter *must* be specified. As a\n            convenience, an environment ID may be passed in instead of an\n            ``Environment`` object.\n\n        \"\"\"\n        if isinstance(environment, Environment):\n            environment_id = environment.id\n        else:\n            environment_id = environment\n        response = client.delete(\n            '{0}/environments/{1}'.format(self.path(), environment_id),\n            **self._server_config.get_client_kwargs()\n        )\n        return _handle_response(response, self._server_config, synchronous)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the content of the specified entity.", "response": "def read(self, entity=None, attrs=None, ignore=None, params=None):\n        \"\"\"\n        Add composite_content_view to the response if needed, as\n        :meth:`nailgun.entity_mixins.EntityReadMixin.read` can't initialize\n        composite_content_view.\n        \"\"\"\n        if attrs is None:\n            attrs = self.read_json()\n        if ignore is None:\n            ignore = set()\n        if entity is None:\n            entity = type(self)(\n                self._server_config,\n                composite_content_view=self.composite_content_view,\n            )\n\n        ignore.add('composite_content_view')\n        return super(ContentViewComponent, self).read(entity, attrs, ignore, params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextends nailgun. entity_mixins. Entity. path.", "response": "def path(self, which=None):\n        \"\"\"Extend ``nailgun.entity_mixins.Entity.path``.\n        The format of the returned path depends on the value of ``which``:\n\n        add\n            /content_view_components/add\n        remove\n            /content_view_components/remove\n\n        Otherwise, call ``super``.\n\n        \"\"\"\n        if which in (\n                'add',\n                'remove'):\n            return '{0}/{1}'.format(\n                super(ContentViewComponent, self).path(which='base'),\n                which\n            )\n\n        return super(ContentViewComponent, self).path(which)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, synchronous=True, **kwargs):\n        kwargs = kwargs.copy()  # shadow the passed-in kwargs\n        if 'data' not in kwargs:\n            # data is required\n            kwargs['data'] = dict()\n        if 'component_ids' not in kwargs['data']:\n            kwargs['data']['components'] = [_payload(self.get_fields(), self.get_values())]\n        kwargs.update(self._server_config.get_client_kwargs())\n        response = client.put(self.path('add'), **kwargs)\n        return _handle_response(response, self._server_config, synchronous)", "response": "Add the content view component to the current object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_missing(self):\n        if not hasattr(self, 'name'):\n            self.name = gen_alphanumeric().lower()\n        super(Domain, self).create_missing()", "response": "Customize the process of auto - generating instance attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new domain.", "response": "def create(self, create_missing=None):\n        \"\"\"Manually fetch a complete set of attributes for this entity.\n\n        For more information, see `Bugzilla #1219654\n        <https://bugzilla.redhat.com/show_bug.cgi?id=1219654>`_.\n\n        \"\"\"\n        return Domain(\n            self._server_config,\n            id=self.create_json(create_missing)['id'],\n        ).read()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextending nailgun. entity_mixins. Entity. path.", "response": "def path(self, which=None):\n        \"\"\"Extend ``nailgun.entity_mixins.Entity.path``.\n        The format of the returned path depends on the value of ``which``:\n\n        smart_class_parameters\n            /api/environments/:environment_id/smart_class_parameters\n\n        Otherwise, call ``super``.\n\n        \"\"\"\n        if which in ('smart_class_parameters',):\n            return '{0}/{1}'.format(\n                super(Environment, self).path(which='self'),\n                which\n            )\n        return super(Environment, self).path(which)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextends nailgun. entity_mixins. Entity. path.", "response": "def path(self, which=None):\n        \"\"\"Extend ``nailgun.entity_mixins.Entity.path``.\n\n        The format of the returned path depends on the value of ``which``:\n\n        compare\n            /katello/api/errata/compare\n\n        Otherwise, call ``super``.\n\n        \"\"\"\n        if which in ('compare',):\n            return '{0}/{1}'.format(super(Errata, self).path('base'), which)\n        return super(Errata, self).path(which)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeals with different named data returned from the server", "response": "def read(self, entity=None, attrs=None, ignore=None, params=None):\n        \"\"\"Deal with different named data returned from the server\n        \"\"\"\n        if attrs is None:\n            attrs = self.read_json()\n        attrs['override'] = attrs.pop('override?')\n        attrs['unlimited'] = attrs.pop('unlimited?')\n        return super(Filter, self).read(entity, attrs, ignore, params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef path(self, which=None):\n        if which in ('bulk_resume', 'bulk_search', 'summary'):\n            return '{0}/{1}'.format(\n                super(ForemanTask, self).path('base'),\n                which\n            )\n        return super(ForemanTask, self).path(which)", "response": "Extend nailgun. entity_mixins. Entity. path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npolling the status of a task or timeout.", "response": "def poll(self, poll_rate=None, timeout=None):\n        \"\"\"Return the status of a task or timeout.\n\n        There are several API calls that trigger asynchronous tasks, such as\n        synchronizing a repository, or publishing or promoting a content view.\n        It is possible to check on the status of a task if you know its UUID.\n        This method polls a task once every ``poll_rate`` seconds and, upon\n        task completion, returns information about that task.\n\n        :param poll_rate: Delay between the end of one task check-up and\n            the start of the next check-up. Defaults to\n            ``nailgun.entity_mixins.TASK_POLL_RATE``.\n        :param timeout: Maximum number of seconds to wait until timing out.\n            Defaults to ``nailgun.entity_mixins.TASK_TIMEOUT``.\n        :returns: Information about the asynchronous task.\n        :raises: ``nailgun.entity_mixins.TaskTimedOutError`` if the task\n            completes with any result other than \"success\".\n        :raises: ``nailgun.entity_mixins.TaskFailedError`` if the task finishes\n            with any result other than \"success\".\n        :raises: ``requests.exceptions.HTTPError`` If the API returns a message\n            with an HTTP 4XX or 5XX status code.\n\n        \"\"\"\n        # See nailgun.entity_mixins._poll_task for an explanation of why a\n        # private method is called.\n        return _poll_task(\n            self.id,  # pylint:disable=no-member\n            self._server_config,\n            poll_rate,\n            timeout\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_payload(self):\n        payload = super(HostCollection, self).create_payload()\n        if 'system_ids' in payload:\n            payload['system_uuids'] = payload.pop('system_ids')\n        return payload", "response": "Rename system_ids to system_uuids."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_payload(self, fields=None):\n        payload = super(HostCollection, self).update_payload(fields)\n        if 'system_ids' in payload:\n            payload['system_uuids'] = payload.pop('system_ids')\n        return payload", "response": "Rename system_ids to system_uuids."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new HostGroup object.", "response": "def create(self, create_missing=None):\n        \"\"\"Do extra work to fetch a complete set of attributes for this entity.\n\n        For more information, see `Bugzilla #1235377\n        <https://bugzilla.redhat.com/show_bug.cgi?id=1235377>`_.\n\n        \"\"\"\n        return HostGroup(\n            self._server_config,\n            id=self.create_json(create_missing)['id'],\n        ).read()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeals with several bugs.", "response": "def read(self, entity=None, attrs=None, ignore=None, params=None):\n        \"\"\"Deal with several bugs.\n\n        For more information, see:\n\n        * `Bugzilla #1235377\n          <https://bugzilla.redhat.com/show_bug.cgi?id=1235377>`_\n        * `Bugzilla #1235379\n          <https://bugzilla.redhat.com/show_bug.cgi?id=1235379>`_\n        * `Bugzilla #1450379\n          <https://bugzilla.redhat.com/show_bug.cgi?id=1450379>`_\n\n        \"\"\"\n        if ignore is None:\n            ignore = set()\n        ignore.add('root_pass')\n        ignore.add('kickstart_repository')\n\n        if attrs is None:\n            attrs = self.read_json()\n        attrs['parent_id'] = attrs.pop('ancestry')  # either an ID or None\n        version = _get_version(self._server_config)\n        if version >= Version('6.1') and version < Version('6.2'):\n            # We cannot call `self.update_json([])`, as an ID might not be\n            # present on self. However, `attrs` is guaranteed to have an ID.\n            attrs2 = HostGroup(\n                self._server_config,\n                id=attrs['id']\n            ).update_json([])\n            for attr in ('content_source_id',\n                         'content_view_id',\n                         'lifecycle_environment_id'):\n                attrs[attr] = attrs2.get(attr)\n        return super(HostGroup, self).read(entity, attrs, ignore, params)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef path(self, which=None):\n        if which in (\n                'clone',\n                'puppetclass_ids',\n                'smart_class_parameters',\n                'smart_variables'\n        ):\n            return '{0}/{1}'.format(\n                super(HostGroup, self).path(which='self'),\n                which\n            )\n        return super(HostGroup, self).path(which)", "response": "Extend nailgun. entity_mixins. Entity. path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove a Puppet class from host group.", "response": "def delete_puppetclass(self, synchronous=True, **kwargs):\n        \"\"\"Remove a Puppet class from host group\n\n        Here is an example of how to use this method::\n            hostgroup.delete_puppetclass(data={'puppetclass_id': puppet.id})\n\n        Constructs path:\n            /api/hostgroups/:hostgroup_id/puppetclass_ids/:id\n\n        :param synchronous: What should happen if the server returns an HTTP\n            202 (accepted) status code? Wait for the task to complete if\n            ``True``. Immediately return the server's response otherwise.\n        :param kwargs: Arguments to pass to requests.\n        :returns: The server's response, with all JSON decoded.\n        :raises: ``requests.exceptions.HTTPError`` If the server responds with\n            an HTTP 4XX or 5XX message.\n\n        \"\"\"\n        kwargs = kwargs.copy()\n        kwargs.update(self._server_config.get_client_kwargs())\n        path = \"{0}/{1}\".format(\n            self.path('puppetclass_ids'),\n            kwargs['data'].pop('puppetclass_id')\n        )\n        return _handle_response(\n            client.delete(path, **kwargs), self._server_config, synchronous)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextending nailgun. entity_mixins. Entity. path.", "response": "def path(self, which=None):\n        \"\"\"Extend ``nailgun.entity_mixins.Entity.path``.\n\n        The format of the returned path depends on the value of ``which``:\n\n        add_subscriptions\n            /hosts/<id>/add_subscriptions\n        remove_subscriptions\n            /hosts/<id>/remove_subscriptions\n\n        ``super`` is called otherwise.\n\n        \"\"\"\n        if which in (\n                'add_subscriptions',\n                'remove_subscriptions'):\n            return '{0}/{1}'.format(\n                super(HostSubscription, self).path(which='base'),\n                which\n            )\n        return super(HostSubscription, self).path(which)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef owner_type(self, value):\n        self._owner_type = value\n        if value == 'User':\n            self._fields['owner'] = entity_fields.OneToOneField(User)\n            if hasattr(self, 'owner'):\n                # pylint:disable=no-member\n                self.owner = User(\n                    self._server_config,\n                    id=self.owner.id if isinstance(self.owner, Entity)\n                    else self.owner\n                )\n        elif value == 'Usergroup':\n            self._fields['owner'] = entity_fields.OneToOneField(UserGroup)\n            if hasattr(self, 'owner'):\n                # pylint:disable=no-member\n                self.owner = UserGroup(\n                    self._server_config,\n                    id=self.owner.id if isinstance(self.owner, Entity)\n                    else self.owner\n                )", "response": "Sets the owner type of the resource."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_values(self):\n        attrs = super(Host, self).get_values()\n        if '_owner_type' in attrs and attrs['_owner_type'] is not None:\n            attrs['owner_type'] = attrs.pop('_owner_type')\n        else:\n            attrs.pop('_owner_type')\n        return attrs", "response": "Correctly set the owner_type attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a bogus managed host.", "response": "def create_missing(self):\n        \"\"\"Create a bogus managed host.\n\n        The exact set of attributes that are required varies depending on\n        whether the host is managed or inherits values from a host group and\n        other factors. Unfortunately, the rules for determining which\n        attributes should be filled in are mildly complex, and it is hard to\n        know which scenario a user is aiming for.\n\n        Populate the values necessary to create a bogus managed host. The\n        resultant dependency graph will look, in part, like this::\n\n                 .-> medium --------.\n                 |-> architecture <-V-.\n            host --> operatingsystem -|\n                 |-> ptable <---------'\n                 |-> domain\n                 '-> environment\n\n        If nested entities were passed by `id` (i.e. entity was only\n        initialized and not read, and therefore contains only `id` field)\n        perform additional read request.\n        \"\"\"\n        # pylint:disable=no-member,too-many-branches,too-many-statements\n        super(Host, self).create_missing()\n        # See: https://bugzilla.redhat.com/show_bug.cgi?id=1227854\n        self.name = self.name.lower()\n        if not hasattr(self, 'mac'):\n            self.mac = self._fields['mac'].gen_value()\n        if not hasattr(self, 'root_pass'):\n            self.root_pass = self._fields['root_pass'].gen_value()\n\n        # Flesh out the dependency graph shown in the docstring.\n        if not hasattr(self, 'domain'):\n            self.domain = Domain(\n                self._server_config,\n                location=[self.location],\n                organization=[self.organization],\n            ).create(True)\n        else:\n            if not hasattr(self.domain, 'organization'):\n                self.domain = self.domain.read()\n            if self.location.id not in [\n                    loc.id for loc in self.domain.location]:\n                self.domain.location.append(self.location)\n                self.domain.update(['location'])\n            if self.organization.id not in [\n                    org.id for org in self.domain.organization]:\n                self.domain.organization.append(self.organization)\n                self.domain.update(['organization'])\n        if not hasattr(self, 'environment'):\n            self.environment = Environment(\n                self._server_config,\n                location=[self.location],\n                organization=[self.organization],\n            ).create(True)\n        else:\n            if not hasattr(self.environment, 'organization'):\n                self.environment = self.environment.read()\n            if self.location.id not in [\n                    loc.id for loc in self.environment.location]:\n                self.environment.location.append(self.location)\n                self.environment.update(['location'])\n            if self.organization.id not in [\n                    org.id for org in self.environment.organization]:\n                self.environment.organization.append(self.organization)\n                self.environment.update(['organization'])\n        if not hasattr(self, 'architecture'):\n            self.architecture = Architecture(self._server_config).create(True)\n        if not hasattr(self, 'ptable'):\n            if _get_version(self._server_config) >= Version('6.2'):\n                self.ptable = PartitionTable(\n                    self._server_config,\n                    location=[self.location],\n                    organization=[self.organization],\n                ).create(True)\n            else:\n                self.ptable = PartitionTable(self._server_config).create(True)\n        if not hasattr(self, 'operatingsystem'):\n            self.operatingsystem = OperatingSystem(\n                self._server_config,\n                architecture=[self.architecture],\n                ptable=[self.ptable],\n            ).create(True)\n        else:\n            if not hasattr(self.operatingsystem, 'architecture'):\n                self.operatingsystem = self.operatingsystem.read()\n            if self.architecture.id not in [\n                    arch.id for arch in self.operatingsystem.architecture]:\n                self.operatingsystem.architecture.append(self.architecture)\n                self.operatingsystem.update(['architecture'])\n            if self.ptable.id not in [\n                    ptable.id for ptable in self.operatingsystem.ptable]:\n                self.operatingsystem.ptable.append(self.ptable)\n                self.operatingsystem.update(['ptable'])\n        if not hasattr(self, 'medium'):\n            self.medium = Media(\n                self._server_config,\n                operatingsystem=[self.operatingsystem],\n                location=[self.location],\n                organization=[self.organization],\n            ).create(True)\n        else:\n            if not hasattr(self.medium, 'organization'):\n                self.medium = self.medium.read()\n            if self.operatingsystem.id not in [\n                    operatingsystem.id for operatingsystem in\n                    self.medium.operatingsystem]:\n                self.medium.operatingsystem.append(self.operatingsystem)\n                self.medium.update(['operatingsystem'])\n            if self.location.id not in [\n                    loc.id for loc in self.medium.location]:\n                self.medium.location.append(self.location)\n                self.medium.update(['location'])\n            if self.organization.id not in [\n                    org.id for org in self.medium.organization]:\n                self.medium.organization.append(self.organization)\n                self.medium.update(['organization'])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef errata_applicability(self, synchronous=True, **kwargs):\n        kwargs = kwargs.copy()  # shadow the passed-in kwargs\n        kwargs.update(self._server_config.get_client_kwargs())\n        response = client.put(self.path('errata/applicability'), **kwargs)\n        return _handle_response(response, self._server_config, synchronous)", "response": "Force regenerate errata applicability for the current errata entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the object and return a dict of the object.", "response": "def read(self, entity=None, attrs=None, ignore=None, params=None):\n        \"\"\"Deal with oddly named and structured data returned by the server.\n\n        For more information, see `Bugzilla #1235019\n        <https://bugzilla.redhat.com/show_bug.cgi?id=1235019>`_\n        and `Bugzilla #1449749\n        <https://bugzilla.redhat.com/show_bug.cgi?id=1449749>`_.\n\n        `content_facet_attributes` are returned only in case any of facet\n        attributes were actually set.\n\n        Also add image to the response if needed, as\n        :meth:`nailgun.entity_mixins.EntityReadMixin.read` can't initialize\n        image.\n        \"\"\"\n        if attrs is None:\n            attrs = self.read_json()\n        if ignore is None:\n            ignore = set()\n        if 'parameters' in attrs:\n            attrs['host_parameters_attributes'] = attrs.pop('parameters')\n        else:\n            ignore.add('host_parameters_attributes')\n        if 'content_facet_attributes' not in attrs:\n            ignore.add('content_facet_attributes')\n        ignore.add('compute_attributes')\n        ignore.add('interfaces_attributes')\n        ignore.add('root_pass')\n        # Image entity requires compute_resource_id to initialize as it is\n        # part of its path. The thing is that entity_mixins.read() initializes\n        # entities by id only.\n        # Workaround is to add image to ignore, call entity_mixins.read()\n        # and then add 'manually' initialized image to the result.\n        # If image_id is None set image to None as it is done by default.\n        ignore.add('image')\n        # host id is required for interface initialization\n        ignore.add('interface')\n        ignore.add('build_status_label')\n        result = super(Host, self).read(entity, attrs, ignore, params)\n        if attrs.get('image_id'):\n            result.image = Image(\n                server_config=self._server_config,\n                id=attrs.get('image_id'),\n                compute_resource=attrs.get('compute_resource_id'),\n            )\n        else:\n            result.image = None\n        if 'interfaces' in attrs and attrs['interfaces']:\n            result.interface = [\n                Interface(\n                    self._server_config,\n                    host=result.id,\n                    id=interface['id'],\n                )\n                for interface in attrs['interfaces']\n            ]\n        if 'build_status_label' in attrs:\n            result.build_status_label = attrs['build_status_label']\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextending nailgun. entity_mixins. Entity. path.", "response": "def path(self, which=None):\n        \"\"\"Extend ``nailgun.entity_mixins.Entity.path``.\n        The format of the returned path depends on the value of ``which``:\n\n        bulk/install_content\n            /api/hosts/:host_id/bulk/install_content\n        errata\n            /api/hosts/:host_id/errata\n        power\n            /api/hosts/:host_id/power\n        errata/apply\n            /api/hosts/:host_id/errata/apply\n        puppetclass_ids\n            /api/hosts/:host_id/puppetclass_ids\n        smart_class_parameters\n            /api/hosts/:host_id/smart_class_parameters\n        smart_variables\n            /api/hosts/:host_id/smart_class_variables\n        module_streams\n            /api/hosts/:host_id/module_streams\n\n        Otherwise, call ``super``.\n\n        \"\"\"\n        if which in (\n                'enc',\n                'errata',\n                'errata/apply',\n                'errata/applicability',\n                'facts',\n                'packages',\n                'power',\n                'puppetclass_ids',\n                'smart_class_parameters',\n                'smart_variables',\n                'module_streams',\n        ):\n            return '{0}/{1}'.format(\n                super(Host, self).path(which='self'),\n                which\n            )\n        elif which in ('bulk/install_content',):\n            return '{0}/{1}'.format(\n                super(Host, self).path(which='base'),\n                which\n            )\n        elif which in ('upload_facts',):\n            return '{0}/{1}'.format(\n                super(Host, self).path(which='base'),\n                'facts'\n            )\n        return super(Host, self).path(which)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching for entities. :param fields: A set naming which fields should be used when generating a search query. If ``None``, all values on the entity are used. If an empty set, no values are used. :param query: A dict containing a raw search query. This is melded in to the generated search query like so: ``{generated: query}.update({manual: query})``. :param filters: A dict. Used to filter search results locally. :return: A list of entities, all of type ``type(self)``.", "response": "def search(self, fields=None, query=None, filters=None):\n        \"\"\"Search for entities.\n\n        :param fields: A set naming which fields should be used when generating\n            a search query. If ``None``, all values on the entity are used. If\n            an empty set, no values are used.\n        :param query: A dict containing a raw search query. This is melded in\n            to the generated search query like so:  ``{generated:\n            query}.update({manual: query})``.\n        :param filters: A dict. Used to filter search results locally.\n        :return: A list of entities, all of type ``type(self)``.\n        \"\"\"\n        results = self.search_json(fields, query)['results']\n        results = self.search_normalize(results)\n        entities = []\n        for result in results:\n            image = result.get('image')\n            if image is not None:\n                del result['image']\n            entity = type(self)(self._server_config, **result)\n            if image:\n                entity.image = Image(\n                    server_config=self._server_config,\n                    id=image,\n                    compute_resource=AbstractComputeResource(\n                        server_config=self._server_config,\n                        id=result.get('compute_resource')\n                    ),\n                )\n            entities.append(entity)\n        if filters is not None:\n            entities = self.search_filter(entities, filters)\n        return entities"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads the object with the specified attributes.", "response": "def read(self, entity=None, attrs=None, ignore=None, params=None):\n        \"\"\"Provide a default value for ``entity``.\n\n        By default, ``nailgun.entity_mixins.EntityReadMixin.read`` provides a\n        default value for ``entity`` like so::\n\n            entity = type(self)()\n\n        However, :class:`Image` requires that an\n        ``compute_resource`` be provided, so this technique will not work. Do\n        this instead::\n\n            entity = type(self)(compute_resource=self.compute_resource.id)\n\n        \"\"\"\n        # read() should not change the state of the object it's called on, but\n        # super() alters the attributes of any entity passed in. Creating a new\n        # object and passing it to super() lets this one avoid changing state.\n        if entity is None:\n            entity = type(self)(\n                self._server_config,\n                compute_resource=self.compute_resource,  # pylint:disable=E1101\n            )\n        if ignore is None:\n            ignore = set()\n        ignore.add('compute_resource')\n        return super(Image, self).read(entity, attrs, ignore, params)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(self, entity=None, attrs=None, ignore=None, params=None):\n        # read() should not change the state of the object it's called on, but\n        # super() alters the attributes of any entity passed in. Creating a new\n        # object and passing it to super() lets this one avoid changing state.\n        if entity is None:\n            entity = type(self)(\n                self._server_config,\n                host=self.host,  # pylint:disable=no-member\n            )\n        if attrs is None:\n            attrs = self.read_json()\n        if ignore is None:\n            ignore = set()\n        ignore.add('host')\n        # type-specific fields\n        if attrs['type'] != 'bmc':\n            ignore.add('password')\n            ignore.add('provider')\n            ignore.add('username')\n        if attrs['type'] != 'bond':\n            ignore.add('mode')\n            ignore.add('bond_options')\n        if attrs['type'] != 'virtual':\n            ignore.add('attached_to')\n            ignore.add('tag')\n        if attrs['type'] != 'bridge' and attrs['type'] != 'bond':\n            ignore.add('attached_devices')\n        return super(Interface, self).read(entity, attrs, ignore, params)", "response": "Read the object with the specified attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds host id to search results to be able to initialize found", "response": "def search_normalize(self, results):\n        \"\"\"Append host id to search results to be able to initialize found\n        :class:`Interface` successfully\n        \"\"\"\n        for interface in results:\n            interface[u'host_id'] = self.host.id  # pylint:disable=no-member\n        return super(Interface, self).search_normalize(results)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenames the payload key prior_id to prior.", "response": "def create_payload(self):\n        \"\"\"Rename the payload key \"prior_id\" to \"prior\".\n\n        For more information, see `Bugzilla #1238757\n        <https://bugzilla.redhat.com/show_bug.cgi?id=1238757>`_.\n\n        \"\"\"\n        payload = super(LifecycleEnvironment, self).create_payload()\n        if (_get_version(self._server_config) < Version('6.1') and\n                'prior_id' in payload):\n            payload['prior'] = payload.pop('prior_id')\n        return payload"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_missing(self):\n        # We call `super` first b/c it populates `self.organization`, and we\n        # need that field to perform a search a little later.\n        super(LifecycleEnvironment, self).create_missing()\n        if (self.name != 'Library' and  # pylint:disable=no-member\n                not hasattr(self, 'prior')):\n            results = self.search({'organization'}, {u'name': u'Library'})\n            if len(results) != 1:\n                raise APIResponseError(\n                    u'Could not find the \"Library\" lifecycle environment for '\n                    u'organization {0}. Search results: {1}'\n                    .format(self.organization, results)  # pylint:disable=E1101\n                )\n            self.prior = results[0]", "response": "Automatically populate the additional instance attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrap submitted data within an extra dict and rename path_.", "response": "def create_payload(self):\n        \"\"\"Wrap submitted data within an extra dict and rename ``path_``.\n\n        For more information on wrapping submitted data, see `Bugzilla #1151220\n        <https://bugzilla.redhat.com/show_bug.cgi?id=1151220>`_.\n\n        \"\"\"\n        payload = super(Media, self).create_payload()\n        if 'path_' in payload:\n            payload['path'] = payload.pop('path_')\n        return {u'medium': payload}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(self, create_missing=None):\n        return Media(\n            self._server_config,\n            id=self.create_json(create_missing)['id'],\n        ).read()", "response": "Manually create a complete set of attributes for this entity."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwraps submitted data within an extra dict.", "response": "def update_payload(self, fields=None):\n        \"\"\"Wrap submitted data within an extra dict.\"\"\"\n        payload = super(Media, self).update_payload(fields)\n        if 'path_' in payload:\n            payload['path'] = payload.pop('path_')\n        return {u'medium': payload}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(self, entity=None, attrs=None, ignore=None, params=None):\n        # read() should not change the state of the object it's called on, but\n        # super() alters the attributes of any entity passed in. Creating a new\n        # object and passing it to super() lets this one avoid changing state.\n        if entity is None:\n            entity = type(self)(\n                self._server_config,\n                operatingsystem=self.operatingsystem,  # pylint:disable=E1101\n            )\n        if ignore is None:\n            ignore = set()\n        ignore.add('operatingsystem')\n        return super(OperatingSystemParameter, self).read(\n            entity,\n            attrs,\n            ignore,\n            params\n        )", "response": "Read an object from the object store."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextends nailgun. entity_mixins. Entity. path.", "response": "def path(self, which=None):\n        \"\"\"Extend ``nailgun.entity_mixins.Entity.path``.\n\n        The format of the returned path depends on the value of ``which``:\n\n        download_debug_certificate\n            /organizations/<id>/download_debug_certificate\n        subscriptions\n            /organizations/<id>/subscriptions\n        subscriptions/upload\n            /organizations/<id>/subscriptions/upload\n        subscriptions/delete_manifest\n            /organizations/<id>/subscriptions/delete_manifest\n        subscriptions/refresh_manifest\n            /organizations/<id>/subscriptions/refresh_manifest\n        sync_plans\n            /organizations/<id>/sync_plans\n\n        Otherwise, call ``super``.\n\n        \"\"\"\n        if which in (\n                'download_debug_certificate',\n                'subscriptions',\n                'subscriptions/delete_manifest',\n                'subscriptions/manifest_history',\n                'subscriptions/refresh_manifest',\n                'subscriptions/upload',\n                'sync_plans',\n        ):\n            return '{0}/{1}'.format(\n                super(Organization, self).path(which='self'),\n                which\n            )\n        return super(Organization, self).path(which)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(self, create_missing=None):\n        return Organization(\n            self._server_config,\n            id=self.create_json(create_missing)['id'],\n        ).read()", "response": "Create an organization object for this entity."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_payload(self, fields=None):\n        org_payload = super(Organization, self).update_payload(fields)\n        payload = {u'organization': org_payload}\n        if 'redhat_repository_url' in org_payload:\n            rh_repo_url = org_payload.pop('redhat_repository_url')\n            payload['redhat_repository_url'] = rh_repo_url\n        return payload", "response": "Wrap submitted data within an extra dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_payload(self, fields=None):\n        payload = super(OSDefaultTemplate, self).update_payload(fields)\n        return {'os_default_template': payload}", "response": "Wrap payload in os_default_template"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_payload(self):\n        payload = super(OverrideValue, self).create_payload()\n        if hasattr(self, 'smart_class_parameter'):\n            del payload['smart_class_parameter_id']\n        if hasattr(self, 'smart_variable'):\n            del payload['smart_variable_id']\n        return payload", "response": "Create a payload dict from this instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read(self, entity=None, attrs=None, ignore=None, params=None):\n        # read() should not change the state of the object it's called on, but\n        # super() alters the attributes of any entity passed in. Creating a new\n        # object and passing it to super() lets this one avoid changing state.\n        if entity is None:\n            if hasattr(self, 'smart_class_parameter'):\n                entity = type(self)(\n                    self._server_config,\n                    # pylint:disable=no-member\n                    smart_class_parameter=self.smart_class_parameter,\n                )\n            elif hasattr(self, 'smart_variable'):\n                entity = type(self)(\n                    self._server_config,\n                    # pylint:disable=no-member\n                    smart_variable=self.smart_variable,\n                )\n        if ignore is None:\n            ignore = set()\n        ignore.update(['smart_class_parameter', 'smart_variable'])\n        return super(OverrideValue, self).read(entity, attrs, ignore, params)", "response": "OverrideValue. read method for override value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read(self, entity=None, attrs=None, ignore=None, params=None):\n        if entity is None:\n            entity = type(self)(\n                self._server_config,\n                **{self._parent_type: self._parent_id}\n            )\n        if ignore is None:\n            ignore = set()\n        for field_name in self._path_fields:\n            ignore.add(field_name)\n        return super(Parameter, self).read(entity, attrs, ignore, params)", "response": "Read the object from the server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextend nailgun. entity_mixins. Entity. path.", "response": "def path(self, which=None):\n        \"\"\"Extend ``nailgun.entity_mixins.Entity.path``.\n\n        The format of the returned path depends on the value of ``which``:\n\n        sync\n            /products/<product_id>/sync\n\n        ``super`` is called otherwise.\n\n        \"\"\"\n        if which == 'sync':\n            return '{0}/{1}'.format(\n                super(Product, self).path(which='self'),\n                which,\n            )\n        return super(Product, self).path(which)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading an attribute missing from the server s response.", "response": "def read(self, entity=None, attrs=None, ignore=None, params=None):\n        \"\"\"Fetch an attribute missing from the server's response.\n\n        Also add sync plan to the responce if needed, as\n        :meth:`nailgun.entity_mixins.EntityReadMixin.read` can't initialize\n        sync plan.\n\n        For more information, see `Bugzilla #1237283\n        <https://bugzilla.redhat.com/show_bug.cgi?id=1237283>`_ and\n        `nailgun#261 <https://github.com/SatelliteQE/nailgun/issues/261>`_.\n\n        \"\"\"\n        if attrs is None:\n            attrs = self.read_json()\n        if _get_version(self._server_config) < Version('6.1'):\n            org = _get_org(self._server_config, attrs['organization']['label'])\n            attrs['organization'] = org.get_values()\n        if ignore is None:\n            ignore = set()\n        ignore.add('sync_plan')\n        result = super(Product, self).read(entity, attrs, ignore, params)\n        if 'sync_plan' in attrs:\n            sync_plan_id = attrs.get('sync_plan_id')\n            if sync_plan_id is None:\n                result.sync_plan = None\n            else:\n                result.sync_plan = SyncPlan(\n                    server_config=self._server_config,\n                    id=sync_plan_id,\n                    organization=result.organization,\n                )\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching for entities with missing attribute.", "response": "def search(self, fields=None, query=None, filters=None):\n        \"\"\"Search for entities with missing attribute\n\n        :param fields: A set naming which fields should be used when generating\n            a search query. If ``None``, all values on the entity are used. If\n            an empty set, no values are used.\n        :param query: A dict containing a raw search query. This is melded in\n            to the generated search query like so:  ``{generated:\n            query}.update({manual: query})``.\n        :param filters: A dict. Used to filter search results locally.\n        :return: A list of entities, all of type ``type(self)``.\n\n        For more information, see `Bugzilla #1237283\n        <https://bugzilla.redhat.com/show_bug.cgi?id=1237283>`_ and\n        `nailgun#261 <https://github.com/SatelliteQE/nailgun/issues/261>`_.\n        \"\"\"\n        results = self.search_json(fields, query)['results']\n        results = self.search_normalize(results)\n        entities = []\n        for result in results:\n            sync_plan = result.get('sync_plan')\n            if sync_plan is not None:\n                del result['sync_plan']\n            entity = type(self)(self._server_config, **result)\n            if sync_plan:\n                entity.sync_plan = SyncPlan(\n                    server_config=self._server_config,\n                    id=sync_plan,\n                    organization=Organization(\n                        server_config=self._server_config,\n                        id=result.get('organization')\n                    ),\n                )\n            entities.append(entity)\n        if filters is not None:\n            entities = self.search_filter(entities, filters)\n        return entities"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nflatten results. expects structure like list ( class_1 class_2... ) where class_1 is class_2 and class_2 is class_3.", "response": "def search_normalize(self, results):\n        \"\"\"Flattens results.\n        :meth:`nailgun.entity_mixins.EntitySearchMixin.search_normalize`\n        expects structure like\n        list(dict_1(name: class_1), dict_2(name: class_2)),\n        while Puppet Class entity returns dictionary with lists of subclasses\n        split by main puppet class.\n        \"\"\"\n        flattened_results = []\n        for key in results.keys():\n            for item in results[key]:\n                flattened_results.append(item)\n        return super(PuppetClass, self).search_normalize(flattened_results)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef path(self, which=None):\n        if which in ('smart_class_parameters', 'smart_variables'):\n            return '{0}/{1}'.format(\n                super(PuppetClass, self).path(which='self'),\n                which\n            )\n        return super(PuppetClass, self).path(which)", "response": "Extend nailgun. entity_mixins. Entity. path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new instance of the class.", "response": "def create(self, create_missing=None):\n        \"\"\"Do extra work to fetch a complete set of attributes for this entity.\n\n        For more information, see `Bugzilla #1232855\n        <https://bugzilla.redhat.com/show_bug.cgi?id=1232855>`_.\n\n        \"\"\"\n        return Realm(\n            self._server_config,\n            id=self.create_json(create_missing)['id'],\n        ).read()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextending the base class path method to return the path to the recurring logic.", "response": "def path(self, which=None):\n        \"\"\"Extend ``nailgun.entity_mixins.RecurringLogic.path``.\n        The format of the returned path depends on the value of ``which``:\n\n        cancel\n            /foreman_tasks/api/recurring_logics/:id/cancel\n\n        Otherwise, call ``super``.\n\n        \"\"\"\n        if which in ('cancel',):\n            return '{0}/{1}'.format(\n                super(RecurringLogic, self).path(which='self'),\n                which\n            )\n        return super(RecurringLogic, self).path(which)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, create_missing=None):\n        return Registry(\n            self._server_config,\n            id=self.create_json(create_missing)['id'],\n        ).read()", "response": "Manually create a complete set of attributes for this entity."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndoing not read the password argument.", "response": "def read(self, entity=None, attrs=None, ignore=None, params=None):\n        \"\"\"Do not read the ``password`` argument.\"\"\"\n        if attrs is None:\n            attrs = self.read_json()\n        if ignore is None:\n            ignore = set()\n        ignore.add('password')\n        return super(Registry, self).read(entity, attrs, ignore, params)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef path(self, which=None):\n        if which in (\n                'errata',\n                'files',\n                'packages',\n                'module_streams',\n                'puppet_modules',\n                'remove_content',\n                'sync',\n                'import_uploads',\n                'upload_content'):\n            return '{0}/{1}'.format(\n                super(Repository, self).path(which='self'),\n                which\n            )\n        return super(Repository, self).path(which)", "response": "Extend nailgun. entity_mixins. Entity. path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef upload_content(self, synchronous=True, **kwargs):\n        kwargs = kwargs.copy()  # shadow the passed-in kwargs\n        kwargs.update(self._server_config.get_client_kwargs())\n        response = client.post(self.path('upload_content'), **kwargs)\n        json = _handle_response(response, self._server_config, synchronous)\n        if json['status'] != 'success':\n            raise APIResponseError(\n                # pylint:disable=no-member\n                'Received error when uploading file {0} to repository {1}: {2}'\n                .format(kwargs.get('files'), self.id, json)\n            )\n        return json", "response": "Uploads a file or files to the current repository."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nimport uploads into a repository .", "response": "def import_uploads(self, uploads=None, upload_ids=None, synchronous=True,\n                       **kwargs):\n        \"\"\"Import uploads into a repository\n\n        It expects either a list of uploads or upload_ids (but not both).\n\n        :param uploads: Array of uploads to be imported\n        :param upload_ids: Array of upload ids to be imported\n        :param synchronous: What should happen if the server returns an HTTP\n            202 (accepted) status code? Wait for the task to complete if\n            ``True``. Immediately return the server's response otherwise.\n        :param kwargs: Arguments to pass to requests.\n        :returns: The server's response, with all JSON decoded.\n        :raises: ``requests.exceptions.HTTPError`` If the server responds with\n            an HTTP 4XX or 5XX message.\n\n        \"\"\"\n        kwargs = kwargs.copy()  # shadow the passed-in kwargs\n        kwargs.update(self._server_config.get_client_kwargs())\n        if uploads:\n            data = {'uploads': uploads}\n        elif upload_ids:\n            data = {'upload_ids': upload_ids}\n        response = client.put(self.path('import_uploads'), data, **kwargs)\n        json = _handle_response(response, self._server_config, synchronous)\n        return json"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting the available repositories for the product.", "response": "def available_repositories(self, **kwargs):\n        \"\"\"Lists available repositories for the repository set\n\n        :param synchronous: What should happen if the server returns an HTTP\n            202 (accepted) status code? Wait for the task to complete if\n            ``True``. Immediately return the server's response otherwise.\n        :param kwargs: Arguments to pass to requests.\n        :returns: The server's response, with all JSON decoded.\n        :raises: ``requests.exceptions.HTTPError`` If the server responds with\n            an HTTP 4XX or 5XX message.\n\n        \"\"\"\n        if 'data' not in kwargs:\n            kwargs['data'] = dict()\n            kwargs['data']['product_id'] = self.product.id\n        kwargs = kwargs.copy()  # shadow the passed-in kwargs\n        kwargs.update(self._server_config.get_client_kwargs())\n        response = client.get(self.path('available_repositories'), **kwargs)\n        return _handle_response(response, self._server_config)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef enable(self, synchronous=True, **kwargs):\n        if 'data' not in kwargs:\n            kwargs['data'] = dict()\n            kwargs['data']['product_id'] = self.product.id\n        kwargs = kwargs.copy()  # shadow the passed-in kwargs\n        kwargs.update(self._server_config.get_client_kwargs())\n        response = client.put(self.path('enable'), **kwargs)\n        return _handle_response(response, self._server_config, synchronous)", "response": "Enables the RedHat Repository and returns the ID of the new RedHat Repository entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef path(self, which=None):\n        if which in (\n                'available_repositories',\n                'enable',\n                'disable',\n        ):\n            return '{0}/{1}'.format(\n                super(RepositorySet, self).path(which='self'),\n                which\n            )\n        return super(RepositorySet, self).path(which)", "response": "Extend the Entity. path method."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read(self, entity=None, attrs=None, ignore=None, params=None):\n        # read() should not change the state of the object it's called on, but\n        # super() alters the attributes of any entity passed in. Creating a new\n        # object and passing it to super() lets this one avoid changing state.\n        if entity is None:\n            entity = type(self)(\n                self._server_config,\n                product=self.product,  # pylint:disable=no-member\n            )\n        if ignore is None:\n            ignore = set()\n        return super(RepositorySet, self).read(entity, attrs, ignore, params)", "response": "Read the object with the specified attributes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef path(self, which=None):\n        if which == 'deploy':\n            return '{0}/{1}'.format(\n                super(RHCIDeployment, self).path(which='self'),\n                which\n            )\n        return super(RHCIDeployment, self).path(which)", "response": "Extend the base class path method."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef path(self, which=None):\n        if which == 'clone':\n            return '{0}/{1}'.format(\n                super(Role, self).path(which='self'),\n                which\n            )\n        return super(Role, self).path(which)", "response": "Extend nailgun. entity_mixins. Entity. path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextend ``nailgun.entity_mixins.Entity.path``. The format of the returned path depends on the value of ``which``: refresh /api/smart_proxies/:id/refresh Otherwise, call ``super``.", "response": "def path(self, which=None):\n        \"\"\"Extend ``nailgun.entity_mixins.Entity.path``.\n        The format of the returned path depends on the value of ``which``:\n\n        refresh\n            /api/smart_proxies/:id/refresh\n\n        Otherwise, call ``super``.\n\n        \"\"\"\n        if which in ('refresh',):\n            return '{0}/{1}'.format(\n                super(SmartProxy, self).path(which='self'),\n                which\n            )\n        return super(SmartProxy, self).path(which)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef import_puppetclasses(self, synchronous=True, **kwargs):\n        kwargs = kwargs.copy()\n        kwargs.update(self._server_config.get_client_kwargs())\n        # Check if environment_id was sent and substitute it to the path\n        # but do not pass it to requests\n        if 'environment' in kwargs:\n            if isinstance(kwargs['environment'], Environment):\n                environment_id = kwargs.pop('environment').id\n            else:\n                environment_id = kwargs.pop('environment')\n            path = '{0}/environments/{1}/import_puppetclasses'.format(\n                self.path(), environment_id)\n        else:\n            path = '{0}/import_puppetclasses'.format(self.path())\n        return _handle_response(\n            client.post(path, **kwargs), self._server_config, synchronous)", "response": "Imports puppet classes from puppet Capsule."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the SSHKey from the server.", "response": "def read(self, entity=None, attrs=None, ignore=None, params=None):\n        \"\"\"Provide a default value for ``entity``.\n\n        By default, ``nailgun.entity_mixins.EntityReadMixin.read`` provides a\n        default value for ``entity`` like so::\n\n            entity = type(self)()\n\n        However, :class:`SSHKey` requires that an ``user`` be\n        provided, so this technique will not work. Do this instead::\n\n            entity = type(self)(user=self.user.id)\n\n        \"\"\"\n        # read() should not change the state of the object it's called on, but\n        # super() alters the attributes of any entity passed in. Creating a new\n        # object and passing it to super() lets this one avoid changing state.\n        if entity is None:\n            entity = type(self)(\n                self._server_config,\n                user=self.user,  # pylint:disable=no-member\n            )\n        if ignore is None:\n            ignore = set()\n        ignore.add('user')\n        return super(SSHKey, self).read(entity, attrs, ignore, params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_normalize(self, results):\n        for sshkey in results:\n            sshkey[u'user_id'] = self.user.id  # pylint:disable=no-member\n        return super(SSHKey, self).search_normalize(results)", "response": "Add user id to search results to be able to initialize found\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_payload(self):\n        payload = super(Subnet, self).create_payload()\n        if 'from_' in payload:\n            payload['from'] = payload.pop('from_')\n        return {u'subnet': payload}", "response": "Wrap submitted data within an extra dict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch as many attributes as possible for this entity.", "response": "def read(self, entity=None, attrs=None, ignore=None, params=None):\n        \"\"\"Fetch as many attributes as possible for this entity.\n\n        Do not read the ``discovery`` attribute. For more information, see\n        `Bugzilla #1217146\n        <https://bugzilla.redhat.com/show_bug.cgi?id=1217146>`_.\n\n        In addition, rename the ``from_`` field to ``from``.\n\n        \"\"\"\n        if attrs is None:\n            attrs = self.read_json()\n        attrs['from_'] = attrs.pop('from')\n\n        if ignore is None:\n            ignore = set()\n        if attrs is not None and 'parameters' in attrs:\n            attrs['subnet_parameters_attributes'] = attrs.pop('parameters')\n        else:\n            ignore.add('subnet_parameters_attributes')\n        ignore.add('discovery')\n        ignore.add('remote_execution_proxy')\n        return super(Subnet, self).read(entity, attrs, ignore, params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap submitted data within an extra dict.", "response": "def update_payload(self, fields=None):\n        \"\"\"Wrap submitted data within an extra dict.\"\"\"\n        payload = super(Subnet, self).update_payload(fields)\n        if 'from_' in payload:\n            payload['from'] = payload.pop('from_')\n        return {u'subnet': payload}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextending nailgun. entity_mixins. Entity. path.", "response": "def path(self, which=None):\n        \"\"\"Extend ``nailgun.entity_mixins.Entity.path``.\n\n        The format of the returned path depends on the value of ``which``:\n\n        delete_manifest\n            /katello/api/v2/organizations/:organization_id/subscriptions/delete_manifest\n        manifest_history\n            /katello/api/v2/organizations/:organization_id/subscriptions/manifest_history\n        refresh_manifest\n            /katello/api/v2/organizations/:organization_id/subscriptions/refresh_manifest\n        upload\n            /katello/api/v2/organizations/:organization_id/subscriptions/upload\n\n        \"\"\"\n        if which in (\n                'delete_manifest',\n                'manifest_history',\n                'refresh_manifest',\n                'upload'):\n            _check_for_value('organization', self.get_values())\n            # pylint:disable=no-member\n            return self.organization.path('subscriptions/{0}'.format(which))\n        return super(Subscription, self).path(which)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _org_path(self, which, payload):\n        return Subscription(\n            self._server_config,\n            organization=payload['organization_id'],\n        ).path(which)", "response": "A helper method for generating paths with organization IDs in them."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nobtains manifest history for subscriptions.", "response": "def manifest_history(self, synchronous=True, **kwargs):\n        \"\"\"Obtain manifest history for subscriptions.\n\n        :param synchronous: What should happen if the server returns an HTTP\n            202 (accepted) status code? Wait for the task to complete if\n            ``True``. Immediately return the server's response otherwise.\n        :param kwargs: Arguments to pass to requests.\n        :returns: The server's response, with all JSON decoded.\n        :raises: ``requests.exceptions.HTTPError`` If the server responds with\n            an HTTP 4XX or 5XX message.\n\n        \"\"\"\n        kwargs = kwargs.copy()  # shadow the passed-in kwargs\n        kwargs.update(self._server_config.get_client_kwargs())\n        response = client.get(\n            self._org_path('manifest_history', kwargs['data']),\n            **kwargs\n        )\n        return _handle_response(response, self._server_config, synchronous)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read(self, entity=None, attrs=None, ignore=None, params=None):\n        if ignore is None:\n            ignore = set()\n        ignore.add('organization')\n        return super(Subscription, self).read(entity, attrs, ignore, params)", "response": "Read the object from the server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef refresh_manifest(self, synchronous=True, **kwargs):\n        kwargs = kwargs.copy()  # shadow the passed-in kwargs\n        kwargs.update(self._server_config.get_client_kwargs())\n        response = client.put(\n            self._org_path('refresh_manifest', kwargs['data']),\n            **kwargs\n        )\n        return _handle_response(\n            response,\n            self._server_config,\n            synchronous,\n            timeout=1500,\n        )", "response": "Refresh the manifest for Red Hat provider."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nuploading a subscription manifest.", "response": "def upload(self, synchronous=True, **kwargs):\n        \"\"\"Upload a subscription manifest.\n\n        Here is an example of how to use this method::\n\n            with open('my_manifest.zip') as manifest:\n                sub.upload({'organization_id': org.id}, manifest)\n\n        :param synchronous: What should happen if the server returns an HTTP\n            202 (accepted) status code? Wait for the task to complete if\n            ``True``. Immediately return the server's response otherwise.\n        :param kwargs: Arguments to pass to requests.\n        :returns: The server's response, with all JSON decoded.\n        :raises: ``requests.exceptions.HTTPError`` If the server responds with\n            an HTTP 4XX or 5XX message.\n\n        \"\"\"\n        kwargs = kwargs.copy()  # shadow the passed-in kwargs\n        kwargs.update(self._server_config.get_client_kwargs())\n        response = client.post(\n            self._org_path('upload', kwargs['data']),\n            **kwargs\n        )\n        # Setting custom timeout as manifest upload can take enormously huge\n        # amount of time. See BZ#1339696 for more details\n        return _handle_response(\n            response,\n            self._server_config,\n            synchronous,\n            timeout=1500,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read(self, entity=None, attrs=None, ignore=None, params=None):\n        # read() should not change the state of the object it's called on, but\n        # super() alters the attributes of any entity passed in. Creating a new\n        # object and passing it to super() lets this one avoid changing state.\n        if entity is None:\n            entity = type(self)(\n                self._server_config,\n                organization=self.organization,  # pylint:disable=no-member\n            )\n        if ignore is None:\n            ignore = set()\n        ignore.add('organization')\n        return super(SyncPlan, self).read(entity, attrs, ignore, params)", "response": "Read the object with the specified attributes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_payload(self):\n        data = super(SyncPlan, self).create_payload()\n        if isinstance(data.get('sync_date'), datetime):\n            data['sync_date'] = data['sync_date'].strftime('%Y-%m-%d %H:%M:%S')\n        return data", "response": "Convert sync_date to a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextends Natello. Entity. path.", "response": "def path(self, which=None):\n        \"\"\"Extend ``nailgun.entity_mixins.Entity.path``.\n\n        The format of the returned path depends on the value of ``which``:\n\n        add_products\n            /katello/api/v2/organizations/:organization_id/sync_plans/:sync_plan_id/add_products\n        remove_products\n            /katello/api/v2/organizations/:organization_id/sync_plans/:sync_plan_id/remove_products\n\n        \"\"\"\n        if which in ('add_products', 'remove_products'):\n            return '{0}/{1}'.format(\n                super(SyncPlan, self).path(which='self'),\n                which\n            )\n        return super(SyncPlan, self).path(which)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting sync_date to a string if datetime object provided.", "response": "def update_payload(self, fields=None):\n        \"\"\"Convert ``sync_date`` to a string if datetime object provided.\"\"\"\n        data = super(SyncPlan, self).update_payload(fields)\n        if isinstance(data.get('sync_date'), datetime):\n            data['sync_date'] = data['sync_date'].strftime('%Y-%m-%d %H:%M:%S')\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef path(self, which=None):\n        if which == 'subscriptions':\n            return '{0}/{1}/{2}'.format(\n                super(System, self).path('base'),\n                self.uuid,  # pylint:disable=no-member\n                which,\n            )\n        if hasattr(self, 'uuid') and (which is None or which == 'self'):\n            return '{0}/{1}'.format(\n                super(System, self).path('base'),\n                self.uuid  # pylint:disable=no-member\n            )\n        return super(System, self).path(which)", "response": "Extend nailgun. entity_mixins. Entity. path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read(self, entity=None, attrs=None, ignore=None, params=None):\n        if attrs is None:\n            attrs = self.read_json()\n        attrs['last_checkin'] = attrs.pop('checkin_time')\n        attrs['host_collections'] = attrs.pop('hostCollections')\n        attrs['installed_products'] = attrs.pop('installedProducts')\n        if ignore is None:\n            ignore = set()\n        ignore.update(['facts', 'organization', 'type'])\n        return super(System, self).read(entity, attrs, ignore, params)", "response": "Fetch as many attributes as possible for this entity."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef path(self, which=None):\n        if which:\n            return '{0}/{1}'.format(\n                super(Template, self).path(which='base'), which)\n        return super(Template, self).path(which)", "response": "Extend nailgun. entity_mixins. Entity. path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, create_missing=None):\n        return UserGroup(\n            self._server_config,\n            id=self.create_json(create_missing)['id'],\n        ).read()", "response": "Create a new UserGroup object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef path(self, which=None):\n        if which and which in ('deploy_script'):\n            return '{0}/{1}'.format(\n                super(VirtWhoConfig, self).path(which='self'), which)\n        return super(VirtWhoConfig, self).path(which)", "response": "Extend nailgun. entity_mixins. Entity. path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if docker can run.", "response": "def ensure_docker_can_run() -> None:\n    \"\"\"\n    :raises docker.errors.ContainerError\n    :raises docker.errors.ImageNotFound\n    :raises docker.errors.APIError\n    \"\"\"\n    logger.info(\"checking docker can run\")\n    version = docker_client.version()[\"ApiVersion\"]\n    docker_client.containers.run(\"hello-world\")\n    logger.debug(f\"using docker API version {version}\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates docker local net if not found.", "response": "def ensure_local_net(\n        network_name: str = DOCKER_STARCRAFT_NETWORK,\n        subnet_cidr: str = SUBNET_CIDR\n) -> None:\n    \"\"\"\n    Create docker local net if not found.\n\n    :raises docker.errors.APIError\n    \"\"\"\n    logger.info(f\"checking whether docker has network {network_name}\")\n    ipam_pool = docker.types.IPAMPool(subnet=subnet_cidr)\n    ipam_config = docker.types.IPAMConfig(pool_configs=[ipam_pool])\n    networks = docker_client.networks.list(names=DOCKER_STARCRAFT_NETWORK)\n    output = networks[0].short_id if networks else None\n    if not output:\n        logger.info(\"network not found, creating ...\")\n        output = docker_client.networks.create(DOCKER_STARCRAFT_NETWORK, ipam=ipam_config).short_id\n    logger.debug(f\"docker network id: {output}\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if local_image is present locally and if not create it.", "response": "def ensure_local_image(\n        local_image: str,\n        parent_image: str = SC_PARENT_IMAGE,\n        java_image: str = SC_JAVA_IMAGE,\n        starcraft_base_dir: str = SCBW_BASE_DIR,\n        starcraft_binary_link: str = SC_BINARY_LINK,\n) -> None:\n    \"\"\"\n    Check if `local_image` is present locally. If it is not, pull parent images and build.\n    This includes pulling starcraft binary.\n\n    :raises docker.errors.ImageNotFound\n    :raises docker.errors.APIError\n    \"\"\"\n    logger.info(f\"checking if there is local image {local_image}\")\n    docker_images = docker_client.images.list(local_image)\n    if len(docker_images) and docker_images[0].short_id is not None:\n        logger.info(f\"image {local_image} found locally.\")\n        return\n\n    logger.info(\"image not found locally, creating...\")\n    pkg_docker_dir = os.path.join(os.path.abspath(os.path.dirname(__file__)), \"local_docker\")\n    base_dir = os.path.join(starcraft_base_dir, \"docker\")\n    logger.info(f\"copying files from {pkg_docker_dir} to {base_dir}.\")\n    distutils.dir_util.copy_tree(pkg_docker_dir, base_dir)\n\n    starcraft_zip_file = f\"{base_dir}/starcraft.zip\"\n    if not os.path.exists(starcraft_zip_file):\n        logger.info(f\"downloading starcraft.zip to {starcraft_zip_file}\")\n        download_file(starcraft_binary_link, starcraft_zip_file)\n\n    logger.info(f\"pulling image {parent_image}, this may take a while...\")\n    pulled_image = docker_client.images.pull(parent_image)\n    pulled_image.tag(java_image)\n\n    logger.info(f\"building local image {local_image}, this may take a while...\")\n    docker_client.images.build(path=base_dir, dockerfile=\"game.dockerfile\", tag=local_image)\n    logger.info(f\"successfully built image {local_image}\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking that docker - machine is available on the computer and returns a boolean indicating if it is available.", "response": "def check_dockermachine() -> bool:\n    \"\"\"\n    Checks that docker-machine is available on the computer\n\n    :raises FileNotFoundError if docker-machine is not present\n    \"\"\"\n    logger.debug(\"checking docker-machine presence\")\n    # noinspection PyBroadException\n    try:\n        out = subprocess \\\n            .check_output([\"docker-machine\", \"version\"]) \\\n            .decode(\"utf-8\") \\\n            .replace(\"docker-machine.exe\", \"\") \\\n            .replace(\"docker-machine\", \"\") \\\n            .strip()\n        logger.debug(f\"using docker machine version {out}\")\n        return True\n    except Exception:\n        logger.debug(f\"docker machine not present\")\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets IP address of the default docker machine", "response": "def dockermachine_ip() -> Optional[str]:\n    \"\"\"\n    Gets IP address of the default docker machine\n    Returns None if no docker-machine executable\n    in the PATH and if there no Docker machine\n    with name default present\n    \"\"\"\n    if not check_dockermachine():\n        return None\n\n    # noinspection PyBroadException\n    try:\n        out = subprocess.check_output(['docker-machine', 'ip'])\n        return out.decode(\"utf-8\").strip()\n    except Exception:\n        logger.debug(f\"docker machine not present\")\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef xoscmounts(host_mount):\n    callback_lower_drive_letter = lambda pat: pat.group(1).lower()\n    host_mount = re.sub(r\"^([a-zA-Z])\\:\", callback_lower_drive_letter, host_mount)\n    host_mount = re.sub(r\"^([a-z])\", \"//\\\\1\", host_mount)\n    host_mount = re.sub(r\"\\\\\", \"/\", host_mount)\n    return host_mount", "response": "Return a list of cross OS compatible mount dirs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef launch_image(\n        # players info\n        player: Player,\n        nth_player: int,\n        num_players: int,\n\n        # game settings\n        headless: bool,\n        game_name: str,\n        map_name: str,\n        game_type: GameType,\n        game_speed: int,\n        timeout: Optional[int],\n        hide_names: bool,\n        random_names: bool,\n        drop_players: bool,\n        allow_input: bool,\n        auto_launch: bool,\n\n        # mount dirs\n        game_dir: str,\n        bot_dir: str,\n        map_dir: str,\n        bwapi_data_bwta_dir: str,\n        bwapi_data_bwta2_dir: str,\n\n        vnc_base_port: int,\n        vnc_host: int,\n        capture_movement: bool,\n\n        # docker\n        docker_image: str,\n        docker_opts: List[str]\n) -> None:\n    \"\"\"\n    :raises docker,errors.APIError\n    :raises DockerException\n    \"\"\"\n    container_name = f\"{game_name}_{nth_player}_{player.name.replace(' ', '_')}\"\n\n    log_dir = f\"{game_dir}/{game_name}/logs_{nth_player}\"\n    crashes_dir = f\"{game_dir}/{game_name}/crashes_{nth_player}\"\n    os.makedirs(log_dir, mode=0o777, exist_ok=True)  # todo: proper mode\n    os.makedirs(crashes_dir, mode=0o777, exist_ok=True)  # todo: proper mode\n\n    volumes = {\n        xoscmounts(log_dir): {\"bind\": LOG_DIR, \"mode\": \"rw\"},\n        xoscmounts(map_dir): {\"bind\": MAP_DIR, \"mode\": \"rw\"},\n        xoscmounts(crashes_dir): {\"bind\": ERRORS_DIR, \"mode\": \"rw\"},\n        xoscmounts(bwapi_data_bwta_dir): {\"bind\": BWAPI_DATA_BWTA_DIR, \"mode\": \"rw\"},\n        xoscmounts(bwapi_data_bwta2_dir): {\"bind\": BWAPI_DATA_BWTA2_DIR, \"mode\": \"rw\"},\n    }\n\n    ports = {}\n    if not headless:\n        ports.update({\"5900/tcp\": vnc_base_port + nth_player})\n\n    env = dict(\n        PLAYER_NAME=player.name if not random_names else random_string(8),\n        PLAYER_RACE=player.race.value,\n        NTH_PLAYER=nth_player,\n        NUM_PLAYERS=num_players,\n        GAME_NAME=game_name,\n        MAP_NAME=f\"/app/sc/maps/{map_name}\",\n        GAME_TYPE=game_type.value,\n        SPEED_OVERRIDE=game_speed,\n        HIDE_NAMES=\"1\" if hide_names else \"0\",\n        DROP_PLAYERS=\"1\" if drop_players else \"0\",\n\n        TM_LOG_RESULTS=f\"../logs/scores.json\",\n        TM_LOG_FRAMETIMES=f\"../logs/frames.csv\",\n        TM_SPEED_OVERRIDE=game_speed,\n        TM_ALLOW_USER_INPUT=\"1\" if isinstance(player, HumanPlayer) or allow_input else \"0\",\n\n        EXIT_CODE_REALTIME_OUTED=EXIT_CODE_REALTIME_OUTED,\n        CAPTURE_MOUSE_MOVEMENT=\"1\" if capture_movement else \"0\",\n        HEADFUL_AUTO_LAUNCH=\"1\" if auto_launch else \"0\",\n\n        JAVA_DEBUG=\"0\"\n    )\n\n    if timeout is not None:\n        env[\"PLAY_TIMEOUT\"] = timeout\n\n    if isinstance(player, BotPlayer):\n        # Only mount write directory, read and AI\n        # are copied from the bot directory in proper places in bwapi-data\n        bot_data_write_dir = f\"{game_dir}/{game_name}/write_{nth_player}/\"\n        os.makedirs(bot_data_write_dir, mode=0o777, exist_ok=True)  # todo: proper mode\n        volumes.update({\n            xoscmounts(bot_data_write_dir): {\"bind\": BOT_DATA_WRITE_DIR, \"mode\": \"rw\"},\n            xoscmounts(player.bot_dir): {\"bind\": BOT_DIR, \"mode\": \"ro\"},\n        })\n        env[\"BOT_FILE\"] = player.bot_basefilename\n        env[\"BOT_BWAPI\"] = player.bwapi_version\n\n        env[\"JAVA_DEBUG\"] = \"0\"\n        env[\"JAVA_DEBUG_PORT\"] = \"\"\n        env[\"JAVA_OPTS\"] = \"\"\n\n        command = [\"/app/play_bot.sh\"]\n        if player.meta.javaDebugPort is not None:\n            ports.update({\"player.meta.javaDebugPort/tcp\": player.meta.javaDebugPort})\n            env[\"JAVA_DEBUG\"] = \"1\"\n            env[\"JAVA_DEBUG_PORT\"] = player.meta.javaDebugPort\n        if player.meta.javaOpts is not None:\n            env[\"JAVA_OPTS\"] = player.meta.javaOpts\n        if player.meta.port is not None:\n            if isinstance(player.meta.port, int) or player.meta.port.isdigit():\n                ports.update({str(player.meta.port) + '/tcp': int(player.meta.port)})\n            else:\n                forward, local = [int(x) for x in player.meta.port.split(':')]\n                ports.update({str(local) + '/tcp': forward})\n    else:\n        command = [\"/app/play_human.sh\"]\n\n    is_server = nth_player == 0\n\n    entrypoint_opts = [\"--headful\"]\n    if headless:\n        entrypoint_opts = [\n            \"--game\", game_name, \"--name\", player.name,\n            \"--race\", player.race.value, \"--lan\"\n        ]\n        if is_server:\n            entrypoint_opts += [\"--host\", \"--map\", f\"/app/sc/maps/{map_name}\"]\n        else:\n            entrypoint_opts += [\"--join\"]\n    command += entrypoint_opts\n\n    logger.debug(\n        \"\\n\"\n        f\"docker_image={docker_image}\\n\"\n        f\"command={pformat(command, indent=4)}\\n\"\n        f\"name={container_name}\\n\"\n        f\"detach={True}\\n\"\n        f\"environment={pformat(env, indent=4)}\\n\"\n        f\"privileged={True}\\n\"\n        f\"volumes={pformat(volumes, indent=4)}\\n\"\n        f\"network={DOCKER_STARCRAFT_NETWORK}\\n\"\n        f\"ports={ports}\\n\"\n    )\n\n    container = docker_client.containers.run(\n        docker_image,\n        command=command,\n        name=container_name,\n        detach=True,\n        environment=env,\n        privileged=True,\n        volumes=volumes,\n        network=DOCKER_STARCRAFT_NETWORK,\n        ports=ports\n    )\n    if container:\n        container_id = running_containers(container_name)\n        logger.info(f\"launched {player}\")\n        logger.debug(f\"container name = '{container_name}', container id = '{container_id}'\")\n    else:\n        raise DockerException(f\"could not launch {player} in container {container_name}\")", "response": "Launches a new image on the local machine."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef running_containers(name_filter: str) -> List[str]:\n    return [container.short_id for container in\n            docker_client.containers.list(filters={\"name\": name_filter})]", "response": "Returns a list of running containers."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef container_exit_code(container_id: str) -> Optional[int]:\n    container = docker_client.containers.get(container_id)\n    return container.wait()[\"StatusCode\"]", "response": "Returns the exit code of a container."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlaunch the game with the specified players.", "response": "def launch_game(\n        players: List[Player],\n        launch_params: Dict[str, Any],\n        show_all: bool,\n        read_overwrite: bool,\n        wait_callback: Callable\n) -> None:\n    \"\"\"\n    :raises DockerException, ContainerException, RealtimeOutedException\n    \"\"\"\n    if not players:\n        raise GameException(\"at least one player must be specified\")\n\n    game_dir = launch_params[\"game_dir\"]\n    game_name = launch_params[\"game_name\"]\n\n    if os.path.exists(f\"{game_dir}/{game_name}\"):\n        logger.info(f\"removing existing game results of {game_name}\")\n        shutil.rmtree(f\"{game_dir}/{game_name}\")\n\n    for nth_player, player in enumerate(players):\n        launch_image(player, nth_player=nth_player, num_players=len(players), **launch_params)\n\n    logger.debug(\"checking if game has launched properly...\")\n    time.sleep(1)\n    start_containers = running_containers(game_name + \"_\")\n    if len(start_containers) != len(players):\n        raise DockerException(\"some containers exited prematurely, please check logs\")\n\n    if not launch_params[\"headless\"]:\n        for index, player in enumerate(players if show_all else players[:1]):\n            port = launch_params[\"vnc_base_port\"] + index\n            host = launch_params[\"vnc_host\"]\n            logger.info(f\"launching vnc viewer for {player} on address {host}:{port}\")\n            launch_vnc_viewer(host, port)\n\n        logger.info(\"\\n\"\n                    \"In headful mode, you must specify and start the game manually.\\n\"\n                    \"Select the map, wait for bots to join the game \"\n                    \"and then start the game.\")\n\n    logger.info(f\"waiting until game {game_name} is finished...\")\n    running_time = time.time()\n    while True:\n        containers = running_containers(game_name)\n        if len(containers) == 0:  # game finished\n            break\n        if len(containers) >= 2:  # update the last time when there were multiple containers\n            running_time = time.time()\n        if len(containers) == 1 and time.time() - running_time > MAX_TIME_RUNNING_SINGLE_CONTAINER:\n            raise ContainerException(\n                f\"One lingering container has been found after single container \"\n                f\"timeout ({MAX_TIME_RUNNING_SINGLE_CONTAINER} sec), the game probably crashed.\")\n        logger.debug(f\"waiting. {containers}\")\n        wait_callback()\n\n    exit_codes = [container_exit_code(container) for container in containers]\n\n    # remove containers before throwing exception\n    logger.debug(\"removing game containers\")\n    remove_game_containers(game_name)\n\n    if any(exit_code == EXIT_CODE_REALTIME_OUTED for exit_code in exit_codes):\n        raise RealtimeOutedException(f\"some of the game containers has realtime outed.\")\n    if any(exit_code == 1 for exit_code in exit_codes):\n        raise ContainerException(f\"some of the game containers has finished with error exit code.\")\n\n    if read_overwrite:\n        logger.info(\"overwriting bot files\")\n        for nth_player, player in enumerate(players):\n            if isinstance(player, BotPlayer):\n                logger.debug(f\"overwriting files for {player}\")\n                distutils.dir_util.copy_tree(\n                    f\"{game_dir}/{game_name}/write_{nth_player}\",\n                    player.read_dir\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_version():\n    version_regex = re.compile(\n        '__version__\\\\s*=\\\\s*(?P<q>[\\'\"])(?P<version>\\\\d+(\\\\.\\\\d+)*(-(alpha|beta|rc)(\\\\.\\\\d+)?)?)(?P=q)'\n    )\n    here = path.abspath(path.dirname(__file__))\n    init_location = path.join(here, \"CHAID/__init__.py\")\n\n    with open(init_location) as init_file:\n        for line in init_file:\n            match = version_regex.search(line)\n\n    if not match:\n        raise Exception(\n            \"Couldn't read version information from '{0}'\".format(init_location)\n        )\n\n    return match.group('version')", "response": "Read version from __init__. py\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the chisquare for a matrix of ind_v x dep_v for the unweighted and SPSS weighted case", "response": "def chisquare(n_ij, weighted):\n    \"\"\"\n    Calculates the chisquare for a matrix of ind_v x dep_v\n    for the unweighted and SPSS weighted case\n    \"\"\"\n    if weighted:\n        m_ij = n_ij / n_ij\n\n        nan_mask = np.isnan(m_ij)\n        m_ij[nan_mask] = 0.000001  # otherwise it breaks the chi-squared test\n\n        w_ij = m_ij\n        n_ij_col_sum = n_ij.sum(axis=1)\n        n_ij_row_sum = n_ij.sum(axis=0)\n        alpha, beta, eps = (1, 1, 1)\n        while eps > 10e-6:\n            alpha = alpha * np.vstack(n_ij_col_sum / m_ij.sum(axis=1))\n            beta = n_ij_row_sum / (alpha * w_ij).sum(axis=0)\n            eps = np.max(np.absolute(w_ij * alpha * beta - m_ij))\n            m_ij = w_ij * alpha * beta\n\n    else:\n        m_ij = (np.vstack(n_ij.sum(axis=1)) * n_ij.sum(axis=0)) / n_ij.sum().astype(float)\n\n    dof = (n_ij.shape[0] - 1) * (n_ij.shape[1] - 1)\n    chi, p_val = stats.chisquare(n_ij, f_exp=m_ij, ddof=n_ij.size - 1 - dof, axis=None)\n\n    return (chi, p_val, dof)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef best_split(self, ind, dep):\n        if isinstance(dep, ContinuousColumn):\n            return self.best_con_split(ind, dep)\n        else:\n            return self.best_cat_heuristic_split(ind, dep)", "response": "determine which splitting function to apply"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetermines best categorical variable split using heuristic methods", "response": "def best_cat_heuristic_split(self, ind, dep):\n        \"\"\" determine best categorical variable split using heuristic methods \"\"\"\n        split = Split(None, None, None, None, 0)\n        min_child_node_size = self.min_child_node_size\n\n        all_dep = np.unique(dep.arr)\n        if len(all_dep) == 1:\n            split.invalid_reason = InvalidSplitReason.PURE_NODE\n            return split\n        elif len(dep.arr) < min_child_node_size and dep.weights is None:\n            # if not weights and too small, skip\n            split.invalid_reason = InvalidSplitReason.MIN_CHILD_NODE_SIZE\n            return split\n        elif dep.weights is not None and len(dep.weights) < min_child_node_size:\n            # if weighted count is too small, skip\n            split.invalid_reason = InvalidSplitReason.PURE_NODE\n            return split\n\n        for i, ind_var in enumerate(ind):\n            split.invalid_reason = None # must reset because using invalid reason to break\n            ind_var = ind_var.deep_copy()\n            unique = np.unique(ind_var.arr)\n\n            freq = {}\n            if dep.weights is None:\n                for col in unique:\n                    counts = np.unique(np.compress(ind_var.arr == col, dep.arr), return_counts=True)\n                    freq[col] = cl.defaultdict(int)\n                    freq[col].update(np.transpose(counts))\n            else:\n                for col in unique:\n                    counts = np.unique(np.compress(ind_var.arr == col, dep.arr), return_counts=True)\n                    freq[col] = cl.defaultdict(int)\n                    for dep_v in all_dep:\n                        freq[col][dep_v] = dep.weights[(ind_var.arr == col) * (dep.arr == dep_v)].sum()\n\n\n            if dep.weights is not None:\n                row_count = dep.weights.sum()\n            else:\n                row_count = len(dep.arr)\n\n            if len(list(ind_var.possible_groupings())) == 0:\n                split.invalid_reason = InvalidSplitReason.PURE_NODE\n            while next(ind_var.possible_groupings(), None) is not None:\n                choice, highest_p_join, split_chi = None, None, None\n\n                for comb in ind_var.possible_groupings():\n                    col1_freq = freq[comb[0]]\n                    col2_freq = freq[comb[1]]\n\n                    keys = set(col1_freq.keys()).union(col2_freq.keys())\n                    n_ij = np.array([\n                        [col1_freq.get(k, 0) for k in keys],\n                        [col2_freq.get(k, 0) for k in keys]\n                    ])\n\n                    # check to see if min_child_node_size permits this direction\n                    # 31 can't merge with 10 if it only leaves 27 for the other node(s)\n                    # but if these are the only two, can't skip, because the level can be defined\n                    # as these two nodes\n                    other_splits = row_count - n_ij.sum()\n                    if other_splits < min_child_node_size and other_splits != 0:\n                        p_split, dof, chi = 1, NaN, NaN\n                        continue\n\n                    if n_ij.shape[1] == 1:\n                        p_split, dof, chi = 1, NaN, NaN\n                        # could be the only valid combination, as we skip\n                        # ones that result in other nodes that give min child node sizes\n                        # this solves [[20], [10, 11]] even though 10 & 11 are exact,\n                        # this must be the choice of this iteration\n                        choice = comb\n                        break\n                    else:\n                        chi, p_split, dof = chisquare(n_ij, dep.weights is not None)\n\n                    if choice is None or p_split > highest_p_join or (p_split == highest_p_join and chi > split_chi):\n                        choice, highest_p_join, split_chi = comb, p_split, chi\n\n                sufficient_split = not highest_p_join or highest_p_join < self.alpha_merge\n                if not sufficient_split:\n                  split.invalid_reason = InvalidSplitReason.ALPHA_MERGE\n                elif (n_ij.sum(axis=1) < min_child_node_size).any():\n                  split.invalid_reason = InvalidSplitReason.MIN_CHILD_NODE_SIZE\n                else:\n                    n_ij = np.array([\n                        [f[dep_val] for dep_val in all_dep] for f in freq.values()\n                    ])\n\n                    dof = (n_ij.shape[0] - 1) * (n_ij.shape[1] - 1)\n                    chi, p_split, dof = chisquare(n_ij, dep.weights is not None)\n\n                    temp_split = Split(i, ind_var.groups(), chi, p_split, dof, split_name=ind_var.name)\n                    better_split = not split.valid() or p_split < split.p or (p_split == split.p and chi > split.score)\n\n                    if better_split:\n                        split, temp_split = temp_split, split\n\n                    chi_threshold = self.split_threshold * split.score\n\n                    if temp_split.valid() and temp_split.score >= chi_threshold:\n                        for sur in temp_split.surrogates:\n                            if sur.column_id != i and sur.score >= chi_threshold:\n                                split.surrogates.append(sur)\n\n                        temp_split.surrogates = []\n                        split.surrogates.append(temp_split)\n\n                    break\n\n                # all combinations created don't suffice. i.e. what's left is below min_child_node_size\n                if choice is None:\n                    break\n                else:\n                    ind_var.group(choice[0], choice[1])\n                    for val, count in freq[choice[1]].items():\n                        freq[choice[0]][val] += count\n                    del freq[choice[1]]\n        if split.valid():\n            split.sub_split_values(ind[split.column_id].metadata)\n        return split"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetermine the best continuous variable split", "response": "def best_con_split(self, ind, dep):\n        \"\"\" determine best continuous variable split \"\"\"\n        split = Split(None, None, None, None, 0)\n        is_normal = stats.normaltest(self.dep_population)[1] > 0.05\n        sig_test = stats.bartlett if is_normal else stats.levene\n        response_set = dep.arr\n        if dep.weights is not None:\n            response_set = dep.arr * dep.weights\n\n        for i, ind_var in enumerate(ind):\n            ind_var = ind_var.deep_copy()\n            unique = np.unique(ind_var.arr)\n            keyed_set = {}\n\n            for col in unique:\n                matched_elements = np.compress(ind_var.arr == col, response_set)\n                keyed_set[col] = matched_elements\n\n            while next(ind_var.possible_groupings(), None) is not None:\n                choice, highest_p_join, split_score = None, None, None\n                for comb in ind_var.possible_groupings():\n                    col1_keyed_set = keyed_set[comb[0]]\n                    col2_keyed_set = keyed_set[comb[1]]\n                    dof = len(np.concatenate((col1_keyed_set, col2_keyed_set))) - 2\n                    score, p_split = sig_test(col1_keyed_set, col2_keyed_set)\n\n                    if choice is None or p_split > highest_p_join or (p_split == highest_p_join and score > split_score):\n                        choice, highest_p_join, split_score = comb, p_split, score\n\n                sufficient_split = highest_p_join < self.alpha_merge and all(\n                    len(node_v) >= self.min_child_node_size for node_v in keyed_set.values()\n                )\n\n                invalid_reason = None\n                sufficient_split = highest_p_join < self.alpha_merge\n                if not sufficient_split: invalid_reason = InvalidSplitReason.ALPHA_MERGE\n\n                sufficient_split = sufficient_split and all(\n                    len(node_v) >= self.min_child_node_size for node_v in keyed_set.values()\n                )\n\n                if not sufficient_split: invalid_reason = InvalidSplitReason.MIN_CHILD_NODE_SIZE\n\n                if sufficient_split and len(keyed_set.values()) > 1:\n                    dof = len(np.concatenate(list(keyed_set.values()))) - 2\n                    score, p_split = sig_test(*keyed_set.values())\n\n                    temp_split = Split(i, ind_var.groups(), score, p_split, dof, split_name=ind_var.name)\n\n                    better_split = not split.valid() or p_split < split.p or (p_split == split.p and score > split.score)\n\n                    if better_split:\n                        split, temp_split = temp_split, split\n\n                    score_threshold = self.split_threshold * split.score\n\n                    if temp_split.valid() and temp_split.score >= score_threshold:\n                        for sur in temp_split.surrogates:\n                            if sur.column_id != i and sur.score >= score_threshold:\n                                split.surrogates.append(sur)\n\n                        temp_split.surrogates = []\n                        split.surrogates.append(temp_split)\n\n                    break\n                else:\n                    split.invalid_reason = invalid_reason\n\n                ind_var.group(choice[0], choice[1])\n\n                keyed_set[choice[0]] = np.concatenate((keyed_set[choice[1]], keyed_set[choice[0]]))\n                del keyed_set[choice[1]]\n\n        if split.valid():\n            split.sub_split_values(ind[split.column_id].metadata)\n        return split"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_numpy(ndarr, arr, alpha_merge=0.05, max_depth=2, min_parent_node_size=30,\n                 min_child_node_size=30, split_titles=None, split_threshold=0, weights=None,\n                 variable_types=None, dep_variable_type='categorical'):\n        \"\"\"\n        Create a CHAID object from numpy\n\n        Parameters\n        ----------\n        ndarr : numpy.ndarray\n            non-aggregated 2-dimensional array containing\n            independent variables on the veritcal axis and (usually)\n            respondent level data on the horizontal axis\n        arr : numpy.ndarray\n            1-dimensional array of the dependent variable associated with\n            ndarr\n        alpha_merge : float\n            the threshold value in which to create a split (default 0.05)\n        max_depth : float\n            the threshold value for the maximum number of levels after the root\n            node in the tree (default 2)\n        min_parent_node_size : float\n            the threshold value of the number of respondents that the node must\n            contain (default 30)\n        split_titles : array-like\n            array of names for the independent variables in the data\n        variable_types : array-like or dict\n            array of variable types, or dict of column names to variable types.\n            Supported variable types are the strings 'nominal' or 'ordinal' in\n            lower case\n        \"\"\"\n        vectorised_array = []\n        variable_types = variable_types or ['nominal'] * ndarr.shape[1]\n        for ind, col_type in enumerate(variable_types):\n            title = None\n            if split_titles is not None: title = split_titles[ind]\n            if col_type == 'ordinal':\n                col = OrdinalColumn(ndarr[:, ind], name=title)\n            elif col_type == 'nominal':\n                col = NominalColumn(ndarr[:, ind], name=title)\n            else:\n                raise NotImplementedError('Unknown independent variable type ' + col_type)\n            vectorised_array.append(col)\n\n        if dep_variable_type == 'categorical':\n            observed = NominalColumn(arr, weights=weights)\n        elif dep_variable_type == 'continuous':\n            observed = ContinuousColumn(arr, weights=weights)\n        else:\n            raise NotImplementedError('Unknown dependent variable type ' + dep_variable_type)\n        config = { 'alpha_merge': alpha_merge, 'max_depth': max_depth, 'min_parent_node_size': min_parent_node_size,\n                   'min_child_node_size': min_child_node_size, 'split_threshold': split_threshold }\n        return Tree(vectorised_array, observed, config)", "response": "Create a CHAID object from a numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_tree(self):\n        tree = TreeLibTree()\n        for node in self:\n            tree.create_node(node, node.node_id, parent=node.parent)\n        return tree", "response": "returns a TreeLib tree"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine which rows fall into which node", "response": "def node_predictions(self):\n        \"\"\" Determines which rows fall into which node \"\"\"\n        pred = np.zeros(self.data_size)\n        for node in self:\n            if node.is_terminal:\n                pred[node.indices] = node.node_id\n        return pred"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef model_predictions(self):\n        if isinstance(self.observed, ContinuousColumn):\n            return ValueError(\"Cannot make model predictions on a continuous scale\")\n        pred = np.zeros(self.data_size).astype('object')\n        for node in self:\n            if node.is_terminal:\n                pred[node.indices] = max(node.members, key=node.members.get)\n        return pred", "response": "Determines the highest frequency of the categorical dependent variable in the terminal node where that column fell\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the accuracy of the tree by comparing the model predictions to the dataset", "response": "def accuracy(self):\n        \"\"\"\n        Calculates the accuracy of the tree by comparing\n        the model predictions to the dataset\n        (TP + TN) / (TP + TN + FP + FN) == (T / (T + F))\n        \"\"\"\n        sub_observed = np.array([self.observed.metadata[i] for i in self.observed.arr])\n        return float((self.model_predictions() == sub_observed).sum()) / self.data_size"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the Bell set from a list of strings.", "response": "def bell_set(self, collection, ordinal=False):\n        \"\"\"\n        Calculates the Bell set\n        \"\"\"\n        if len(collection) == 1:\n            yield [ collection ]\n            return\n\n        first = collection[0]\n        for smaller in self.bell_set(collection[1:]):\n            for n, subset in enumerate(smaller):\n                if not ordinal or (ordinal and is_sorted(smaller[:n] + [[ first ] + subset] + smaller[n+1:], self._nan)):\n                    yield smaller[:n] + [[ first ] + subset] + smaller[n+1:]\n\n            if not ordinal or (ordinal and is_sorted([ [ first ] ] + smaller, self._nan)):\n                yield [ [ first ] ] + smaller"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a deep copy of the object.", "response": "def deep_copy(self):\n        \"\"\"\n        Returns a deep copy.\n        \"\"\"\n        return NominalColumn(self.arr, metadata=self.metadata, name=self.name,\n                             missing_id=self._missing_id, substitute=False, weights=self.weights)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsubstitute integers into the vector and construct the metadata dictionary.", "response": "def substitute_values(self, vect):\n        \"\"\"\n        Internal method to substitute integers into the vector, and construct\n        metadata to convert back to the original vector.\n\n        np.nan is always given -1, all other objects are given integers in\n        order of apperence.\n\n        Parameters\n        ----------\n        vect : np.array\n            the vector in which to substitute values in\n        \"\"\"\n\n        try:\n            unique = np.unique(vect)\n        except:\n            unique = set(vect)\n\n        unique = [\n            x for x in unique if not isinstance(x, float) or not isnan(x)\n        ]\n\n        arr = np.copy(vect)\n        for new_id, value in enumerate(unique):\n            np.place(arr, arr==value, new_id)\n            self.metadata[new_id] = value\n        arr = arr.astype(np.float)\n        np.place(arr, np.isnan(arr), -1)\n        self.arr = arr\n\n        if -1 in arr:\n            self.metadata[-1] = self._missing_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a deep copy of the current object.", "response": "def deep_copy(self):\n        \"\"\"\n        Returns a deep copy.\n        \"\"\"\n        return OrdinalColumn(self.arr, metadata=self.metadata, name=self.name,\n                             missing_id=self._missing_id, substitute=True,\n                             groupings=self._groupings, weights=self.weights)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a deep copy of this ContinuousColumn.", "response": "def deep_copy(self):\n        \"\"\"\n        Returns a deep copy.\n        \"\"\"\n        return ContinuousColumn(self.arr, metadata=self.metadata, missing_id=self._missing_id, weights=self.weights)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sub_split_values(self, sub):\n        for i, arr in enumerate(self.splits):\n            self.split_map[i] = [sub.get(x, x) for x in arr]\n        for split in self.surrogates:\n            split.sub_split_values(sub)", "response": "Substitutes the splits with other values into the split_map"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef name_columns(self, sub):\n        if self.column_id is not None and len(sub) > self.column_id:\n            self.split_name = sub[self.column_id]\n        for split in self.surrogates:\n            split.name_columns(sub)", "response": "Substitutes the split column index with a human readable string"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n\n    parser = argparse.ArgumentParser(description='Run the chaid algorithm on a'\n                                     ' csv/sav file.')\n    parser.add_argument('file')\n    parser.add_argument('dependent_variable', nargs=1)\n    parser.add_argument('--dependent-variable-type', type=str)\n\n    var = parser.add_argument_group('Independent Variable Specification')\n    var.add_argument('nominal_variables', nargs='*', help='The names of '\n                     'independent variables to use that have no intrinsic '\n                     'order to them')\n    var.add_argument('--ordinal-variables', type=str, nargs='*',\n                     help='The names of independent variables to use that '\n                     'have an intrinsic order but a finite amount of states')\n    parser.add_argument('--weights', type=str, help='Name of weight column')\n\n    parser.add_argument('--max-depth', type=int, help='Max depth of generated '\n                        'tree')\n    parser.add_argument('--min-parent-node-size', type=int, help='Minimum number of '\n                        'samples required to split the parent node')\n    parser.add_argument('--min-child-node-size', type=int, help='Minimum number of '\n                        'samples required to split the child node')\n    parser.add_argument('--alpha-merge', type=float, help='Alpha Merge')\n    group = parser.add_mutually_exclusive_group(required=False)\n    group.add_argument('--classify', action='store_true', help='Add column to'\n                       ' input with the node id of the node that that '\n                       'respondent has been placed into')\n    group.add_argument('--predict', action='store_true', help='Add column to '\n                       'input with the value of the  dependent variable that '\n                       'the majority of respondents in that node selected')\n    group.add_argument('--rules', action='store_true')\n    group.add_argument('--export', action='store_true', help='Whether to export the chart to pdf/dot')\n    group.add_argument('--export-path', type=str, help='Path to store chart output')\n\n\n    nspace = parser.parse_args()\n\n    if nspace.file[-4:] == '.csv':\n        data = pd.read_csv(nspace.file)\n    elif nspace.file[-4:] == '.sav':\n        import savReaderWriter as spss\n        raw_data = spss.SavReader(nspace.file, returnHeader=True)\n        raw_data_list = list(raw_data)\n        data = pd.DataFrame(raw_data_list)\n        data = data.rename(columns=data.loc[0]).iloc[1:]\n    else:\n        print('Unknown file type')\n        exit(1)\n\n    config = {}\n    if nspace.max_depth:\n        config['max_depth'] = nspace.max_depth\n    if nspace.alpha_merge:\n        config['alpha_merge'] = nspace.alpha_merge\n    if nspace.min_parent_node_size:\n        config['min_parent_node_size'] = nspace.min_parent_node_size\n    if nspace.min_child_node_size:\n        config['min_child_node_size'] = nspace.min_child_node_size\n    if nspace.weights:\n        config['weight'] = nspace.weights\n    if nspace.dependent_variable_type:\n        config['dep_variable_type'] = nspace.dependent_variable_type\n\n\n    ordinal = nspace.ordinal_variables or []\n    nominal = nspace.nominal_variables or []\n    independent_variables = nominal + ordinal\n    types = dict(zip(nominal + ordinal, ['nominal'] * len(nominal) + ['ordinal'] * len(ordinal)))\n    if len(independent_variables) == 0:\n        print('Need to provide at least one independent variable')\n        exit(1)\n    tree = Tree.from_pandas_df(data, types, nspace.dependent_variable[0],\n                               **config)\n\n    if nspace.export or nspace.export_path:\n        tree.render(nspace.export_path, True)\n\n    if nspace.classify:\n        predictions = pd.Series(tree.node_predictions())\n        predictions.name = 'node_id'\n        data = pd.concat([data, predictions], axis=1)\n        print(data.to_csv())\n    elif nspace.predict:\n        predictions = pd.Series(tree.model_predictions())\n        predictions.name = 'predicted'\n        data = pd.concat([data, predictions], axis=1)\n        print(data.to_csv())\n    elif nspace.rules:\n        print('\\n'.join(str(x) for x in tree.classification_rules()))\n    else:\n        tree.print_tree()\n        print('Accuracy: ', tree.accuracy())", "response": "Entry point when module is run from command line"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npartitioning a set of integers in 3 parts of same total value", "response": "def three_partition(x):\n    \"\"\"partition a set of integers in 3 parts of same total value\n\n    :param x: table of non negative values\n    :returns: triplet of the integers encoding the sets, or None otherwise\n    :complexity: :math:`O(2^{2n})`\n    \"\"\"\n    f = [0] * (1 << len(x))\n    for i in range(len(x)):\n        for S in range(1 << i):\n            f[S | (1 << i)] = f[S] + x[i]\n    for A in range(1 << len(x)):\n        for B in range(1 << len(x)):\n            if A & B == 0 and f[A] == f[B] and 3 * f[A] == f[-1]:\n                return (A, B, ((1 << len(x)) - 1) ^ A ^ B)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef freivalds(A, B, C):\n    n = len(A)\n    x = [randint(0, 1000000) for j in range(n)]\n    return mult(A, mult(B, x)) == mult(C, x)", "response": "Tests matrix product AB = C by Freivalds\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef min_scalar_prod(x, y):\n    x = sorted(x)  # make copies\n    y = sorted(y)  # to save arguments\n    return sum(x[i] * y[-i - 1] for i in range(len(x)))", "response": "Permute vector to minimize scalar product over all permutations"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef laser_mirrors(rows, cols, mir):\n    # build structures\n    n = len(mir)\n    orien = [None] * (n + 2)\n    orien[n] = 0      # arbitrary orientations\n    orien[n + 1] = 0\n    succ = [[None for direc in range(4)] for i in range(n + 2)]\n    L = [(mir[i][0], mir[i][1], i) for i in range(n)]\n    L.append((0, -1, n))                  # enter\n    L.append((0, cols, n + 1))            # exit\n    last_r, last_i = None, None\n    for (r, c, i) in sorted(L):           # sweep by row\n        if last_r == r:\n            succ[i][LEFT] = last_i\n            succ[last_i][RIGHT] = i\n        last_r, last_i = r, i\n    last_c = None\n    for (r, c, i) in sorted(L, key=lambda rci: (rci[1], rci[0])):\n        if last_c == c:                   # sweep by column\n            succ[i][UP] = last_i\n            succ[last_i][DOWN] = i\n        last_c, last_i = c, i\n    if solve(succ, orien, n, RIGHT):      # exploration\n        return orien[:n]\n    else:\n        return None", "response": "This function computes the beam of the mir by laser."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsolves the tree of trees in a mirror.", "response": "def solve(succ, orien, i, direc):\n    \"\"\"Can a laser leaving mirror i in direction direc reach exit ?\n\n    :param i: mirror index\n    :param direc: direction leaving mirror i\n    :param orient: orient[i]=orientation of mirror i\n    :param succ: succ[i][direc]=succ mirror reached\n                 when leaving i in direction direc\n    \"\"\"\n    assert orien[i] is not None\n    j = succ[i][direc]\n    if j is None:          # basic case\n        return False\n    if j == len(orien) - 1:\n        return True\n    if orien[j] is None:   # try both orientations\n        for x in [0, 1]:\n            orien[j] = x\n            if solve(succ, orien, j, reflex[direc][x]):\n                return True\n        orien[j] = None\n        return False\n    else:\n        return solve(succ, orien, j, reflex[direc][orien[j]])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef closest_values(L):\n    assert len(L) >= 2\n    L.sort()\n    valmin, argmin = min((L[i] - L[i - 1], i) for i in range(1, len(L)))\n    return L[argmin - 1], L[argmin]", "response": "Closest values from L with minimal distance"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dancing_links(size_universe, sets):\n    header = Cell(None, None, 0, None)  # building the cell structure\n    col = []\n    for j in range(size_universe):\n        col.append(Cell(header, None, 0, None))\n    for i in range(len(sets)):\n        row = None\n        for j in sets[i]:\n            col[j].S += 1               # one more entry in this column\n            row = Cell(row, col[j], i, col[j])\n    sol = []\n    if solve(header, sol):\n        return sol\n    else:\n        return None", "response": "This function returns the set cover by the dancing links algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsolving a 2 - SAT boolean formula returning a table with boolean assignments satisfying the formula or None if no such table is satisfying the formula.", "response": "def two_sat(formula):\n    \"\"\"Solving a 2-SAT boolean formula\n\n    :param formula: list of clauses, a clause is pair of literals\n                    over X1,...,Xn for some n.\n                    a literal is an integer, for example -1 = not X1, 3 = X3\n    :returns: table with boolean assignment satisfying the formula or None\n    :complexity: linear\n    \"\"\"\n    #                                   -- n is the number of variables\n    n = max(abs(clause[p]) for p in (0, 1) for clause in formula)\n    graph = [[] for node in range(2 * n)]\n    for x, y in formula:                           # x or y\n        graph[_vertex(-x)].append(_vertex(y))      # -x => y\n        graph[_vertex(-y)].append(_vertex(x))      # -y => x\n    sccp = tarjan(graph)\n    comp_id = [None] * (2 * n)     # for each node the ID of its component\n    assignment = [None] * (2 * n)\n    for component in sccp:\n        rep = min(component)             # representative of the component\n        for vtx in component:\n            comp_id[vtx] = rep\n            if assignment[vtx] is None:\n                assignment[vtx] = True\n                assignment[vtx ^ 1] = False    # complementary literal\n    for i in range(n):\n        if comp_id[2 * i] == comp_id[2 * i + 1]:\n            return None                        # insatisfiable formula\n    return assignment[::2]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sudoku(G):\n    global N, N2, N4\n    if len(G) == 16:              # for a 16 x 16 sudoku grid\n        N, N2, N4 = 4, 16, 256\n    e = 4 * N4\n    universe = e + 1\n    S = [[rc(a), rv(a), cv(a), bv(a)] for a in range(N4 * N2)]\n    A = [e]\n    for r in range(N2):\n        for c in range(N2):\n            if G[r][c] != 0:\n                a = assignation(r, c, G[r][c] - 1)\n                A += S[a]\n    sol = dancing_links(universe, S + [A])\n    if sol:\n        for a in sol:\n            if a < len(S):\n                G[row(a)][col(a)] = val(a) + 1\n        return True\n    else:\n        return False", "response": "Solving Sudoku - based grids"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rectangles_from_grid(P, black=1):\n    rows = len(P)\n    cols = len(P[0])\n    t = [0] * cols\n    best = None\n    for i in range(rows):\n        for j in range(cols):\n            if P[i][j] == black:\n                t[j] += 1\n            else:\n                t[j] = 0\n        (area, left, height, right) = rectangles_from_histogram(t)\n        alt = (area, left, i, right, i-height)\n        if best is None or alt > best:\n            best = alt\n    return best", "response": "Returns the largest area rectangle in a binary matrix where the black value is given."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if there are negative cycles in the graph", "response": "def floyd_warshall(weight):\n    \"\"\"All pairs shortest paths by Floyd-Warshall\n\n    :param weight: edge weight matrix\n    :modifies: weight matrix to contain distances in graph\n    :returns: True if there are negative cycles\n    :complexity: :math:`O(|V|^3)`\n    \"\"\"\n    V = range(len(weight))\n    for k in V:\n        for u in V:\n            for v in V:\n                weight[u][v] = min(weight[u][v],\n                                   weight[u][k] + weight[k][v])\n    for v in V:\n        if weight[v][v] < 0:      # negative cycle found\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bellman_ford(graph, weight, source=0):\n    n = len(graph)\n    dist = [float('inf')] * n\n    prec = [None] * n\n    dist[source] = 0\n    for nb_iterations in range(n):\n        changed = False\n        for node in range(n):\n            for neighbor in graph[node]:\n                alt = dist[node] + weight[node][neighbor]\n                if alt < dist[neighbor]:\n                    dist[neighbor] = alt\n                    prec[neighbor] = node\n                    changed = True\n        if not changed:                   # fixed point\n            return dist, prec, False\n    return dist, prec, True", "response": "Single source shortest paths by Bellman - Ford"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef roman2int(s):\n    val = 0\n    pos10 = 1000\n    beg = 0\n    for pos in range(3, -1, -1):\n        for digit in range(9,-1,-1):\n            r = roman[pos][digit]\n            if s.startswith(r, beg):  # footnote 1\n                beg += len(r)\n                val += digit * pos10\n                break\n        pos10 //= 10\n    return val", "response": "Decode a roman number into a number of integers."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts an integer to a code roman number", "response": "def int2roman(val):\n    \"\"\"Code roman number\n\n    :param val: integer between 1 and 9999\n    :returns: the corresponding roman number\n    :complexity: linear (if that makes sense for constant bounded input size)\n    \"\"\"\n    s = ''\n    pos10 = 1000\n    for pos in range(3, -1, -1):\n        digit = val // pos10\n        s += roman[pos][digit]\n        val %= pos10\n        pos10 //= 10\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsingle source shortest paths by Dijkstra", "response": "def dijkstra(graph, weight, source=0, target=None):\n    \"\"\"single source shortest paths by Dijkstra\n\n       :param graph: directed graph in listlist or listdict format\n       :param weight: in matrix format or same listdict graph\n       :assumes: weights are non-negative\n       :param source: source vertex\n       :type source: int\n       :param target: if given, stops once distance to target found\n       :type target: int\n\n       :returns: distance table, precedence table\n       :complexity: `O(|V| + |E|log|V|)`\n    \"\"\"\n    n = len(graph)\n    assert all(weight[u][v] >= 0 for u in range(n) for v in graph[u])\n    prec = [None] * n\n    black = [False] * n\n    dist = [float('inf')] * n\n    dist[source] = 0\n    heap = [(0, source)]\n    while heap:\n        dist_node, node = heappop(heap)       # Closest node from source\n        if not black[node]:\n            black[node] = True\n            if node == target:\n                break\n            for neighbor in graph[node]:\n                dist_neighbor = dist_node + weight[node][neighbor]\n                if dist_neighbor < dist[neighbor]:\n                    dist[neighbor] = dist_neighbor\n                    prec[neighbor] = node\n                    heappush(heap, (dist_neighbor, neighbor))\n    return dist, prec"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dijkstra_update_heap(graph, weight, source=0, target=None):\n    n = len(graph)\n    assert all(weight[u][v] >= 0 for u in range(n) for v in graph[u])\n    prec = [None] * n\n    dist = [float('inf')] * n\n    dist[source] = 0\n    heap = OurHeap([(dist[node], node) for node in range(n)])\n    while heap:\n        dist_node, node = heap.pop()       # Closest node from source\n        if node == target:\n            break\n        for neighbor in graph[node]:\n            old = dist[neighbor]\n            new = dist_node + weight[node][neighbor]\n            if new < old:\n                dist[neighbor] = new\n                prec[neighbor] = node\n                heap.update((old, neighbor), (new, neighbor))\n    return dist, prec", "response": "update the heap for a single source shortest path by Dijkstra\n      "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bfs(graph, start=0):\n    to_visit = deque()\n    dist = [float('inf')] * len(graph)\n    prec = [None] * len(graph)\n    dist[start] = 0\n    to_visit.appendleft(start)\n    while to_visit:              # an empty queue is considered False\n        node = to_visit.pop()\n        for neighbor in graph[node]:\n            if dist[neighbor] == float('inf'):\n                dist[neighbor] = dist[node] + 1\n                prec[neighbor] = node\n                to_visit.appendleft(neighbor)\n    return dist, prec", "response": "Shortest path in unweighted graph by BFS\nMF"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding word w into trie T", "response": "def add(T, w, i=0):\n    \"\"\"\n    :param T: trie\n    :param string w: word to be added to T\n    :returns: new trie consisting of w added into T\n    :complexity: O(len(w))\n    \"\"\"\n    if T is None:\n        T = Trie_Node()\n    if i == len(w):\n        T.isWord = True\n    else:\n        T.s[w[i]] = add(T.s[w[i]], w, i + 1)\n    return T"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a trie containing all words from S", "response": "def Trie(S):\n    \"\"\"\n    :param S: set of words\n    :returns: trie containing all words from S\n    :complexity: linear in total word sizes from S\n    \"\"\"\n    T = None\n    for w in S:\n        T = add(T, w)\n    return T"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef spell_check(T, w):\n    assert T is not None\n    dist = 0\n    while True:   # Try increasing distances\n        u = search(T, dist, w)\n        if u is not None:\n            return u\n        dist += 1", "response": "Spell checker for the given word in the given dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search(T, dist, w, i=0):\n    if i == len(w):\n        if T is not None and T.isWord and dist == 0:\n            return \"\"\n        else:\n            return None\n    if T is None:\n        return None\n    f = search(T.s[w[i]], dist, w, i + 1)       # matching\n    if f is not None:\n        return w[i] + f\n    if dist == 0:\n        return None\n    for c in ascii_letters:\n        f = search(T.s[c], dist - 1, w, i)      # insertion\n        if f is not None:\n            return c + f\n        f = search(T.s[c], dist - 1, w, i + 1)  # substitution\n        if f is not None:\n            return c + f\n    return search(T, dist - 1, w, i + 1)", "response": "Searches for w in trie T with distance at most dist"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a graph from a text file.", "response": "def read_graph(filename, directed=False, weighted=False, default_weight=None):\n    \"\"\"Read a graph from a text file\n\n    :param filename: plain text file. All numbers are separated by space.\n              Starts with a line containing n (#vertices) and m (#edges).\n              Then m lines follow, for each edge.\n              Vertices are numbered from 0 to n-1.\n              Line for unweighted edge u,v contains two integers u, v.\n              Line for weighted edge u,v contains three integers u, v, w[u,v].\n\n    :param directed: true for a directed graph, false for undirected\n    :param weighted: true for an edge weighted graph\n    :returns: graph in listlist format, possibly followed by weight matrix\n    :complexity: O(n + m) for unweighted graph,\n                 :math:`O(n^2)` for weighted graph\n    \"\"\"\n    with open(filename, 'r') as f:\n        while True:\n            line = f.readline()         # ignore leading comments\n            if line[0] != '#':\n                break\n        nb_nodes, nb_edges = tuple(map(int, line.split()))\n        graph = [[] for u in range(nb_nodes)]\n        if weighted:\n            weight = [[default_weight] * nb_nodes for v in range(nb_nodes)]\n            for v in range(nb_nodes):\n                weight[v][v] = 0\n            for _ in range(nb_edges):\n                u, v, w = readtab(f, int)\n                graph[u].append(v)\n                weight[u][v] = w\n                if not directed:\n                    graph[v].append(u)\n                    weight[v][u] = w\n            return graph, weight\n        else:\n            for _ in range(nb_edges):\n                # si le fichier contient des poids, ils seront ignor\u00e9s\n                u, v = readtab(f, int)[:2]\n                graph[u].append(v)\n                if not directed:\n                    graph[v].append(u)\n            return graph"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites a graph to a DOT file in the DOT format.", "response": "def write_graph(dotfile, graph, directed=False,\n                node_label=None, arc_label=None, comment=\"\",\n                node_mark=set(), arc_mark=set()):\n    \"\"\"Writes a graph to a file in the DOT format\n\n    :param dotfile: the filename.\n    :param graph: directed graph in listlist or listdict format\n    :param directed: true if graph is directed, false if undirected\n    :param weight: in matrix format or same listdict graph or None\n    :param node_label: vertex label table or None\n    :param arc_label: arc label matrix or None\n    :param comment: comment string for the dot file or None\n    :param node_mark: set of nodes to be shown in gray\n    :param arc_marc: set of arcs to be shown in red\n    :complexity: `O(|V| + |E|)`\n    \"\"\"\n    with open(dotfile, 'w') as f:\n        if directed:\n            f.write(\"digraph G{\\n\")\n        else:\n            f.write(\"graph G{\\n\")\n        if comment:\n            f.write('label=\"%s\";\\n' % comment)\n        V = range(len(graph))\n        #                              -- vertices\n        for u in V:\n            if node_mark and u in node_mark:\n                f.write('%d [style=filled, color=\"lightgrey\", ' % u)\n            else:\n                f.write('%d [' % u)\n            if node_label:\n                f.write('label=\"%u [%s]\"];\\n' % (u, node_label[u]))\n            else:\n                f.write('shape=circle, label=\"%u\"];\\n' % u)\n        #                              -- edges\n        if isinstance(arc_mark, list):\n            arc_mark = set((u, arc_mark[u]) for u in V)\n        for u in V:\n            for v in graph[u]:\n                if not directed and u > v:\n                    continue   # don't show twice the edge\n                if arc_label and arc_label[u][v] == None:\n                    continue   # suppress arcs with no label\n                if directed:\n                    arc = \"%d -> %d \" % (u, v)\n                else:\n                    arc = \"%d -- %d \" % (u, v)\n                if arc_mark and ( (v,u) in arc_mark or (not directed and (u,v) in arc_mark) ):\n                    pen = 'color=\"red\"'\n                else:\n                    pen = \"\"\n                if arc_label:\n                    tag = 'label=\"%s\"' % arc_label[u][v]\n                else:\n                    tag = \"\"\n                if tag and pen:\n                    sep = \", \"\n                else:\n                    sep = \"\"\n                f.write(arc + \"[\" + tag + sep + pen + \"];\\n\")\n        f.write(\"}\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntransforming a tree given as predecessor table into adjacency list form", "response": "def tree_prec_to_adj(prec, root=0):\n    \"\"\"Transforms a tree given as predecessor table into adjacency list form\n\n    :param prec: predecessor table representing a tree, prec[u] == v iff u is successor of v,\n                 except for the root where prec[root] == root\n    :param root: root vertex of the tree\n    :returns: undirected graph in listlist representation\n    :complexity: linear\n    \"\"\"\n    n = len(prec)\n    graph = [[prec[u]] for u in range(n)]   # add predecessors\n    graph[root] = []\n    for u in range(n):                      # add successors\n        if u != root:\n            graph[prec[u]].append(u)\n    return graph"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tree_adj_to_prec(graph, root=0):\n    prec = [None] * len(graph)\n    prec[root] = root            # mark to visit root only once\n    to_visit = [root]\n    while to_visit:              # DFS\n        node = to_visit.pop()\n        for neighbor in graph[node]:\n            if prec[neighbor] is None:\n                prec[neighbor] = node\n                to_visit.append(neighbor)\n    prec[root] = None            # put the standard mark for root\n    return prec", "response": "Transforms a tree given as adjacency list into a DFS spanning tree\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_reverse_arcs(graph, capac=None):\n    for u in range(len(graph)):\n        for v in graph[u]:\n            if u not in graph[v]:\n                if type(graph[v]) is list:\n                    graph[v].append(u)\n                    if capac:\n                        capac[v][u] = 0\n                else:\n                    assert type(graph[v]) is dict\n                    graph[v][u] = 0", "response": "Utility function for flow algorithms that need for every arc in graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntransforming a squared weight matrix in a adjacency table of type listlist encoding the unweighted directed graph corresponding to the entries of the matrix different from None iff arc u exists", "response": "def matrix_to_listlist(weight):\n    \"\"\"transforms a squared weight matrix in a adjacency table of type listlist\n    encoding the directed graph corresponding to the entries of the matrix\n    different from None\n\n    :param weight: squared weight matrix, weight[u][v] != None iff arc (u,v) exists\n    :complexity: linear\n    :returns: the unweighted directed graph in the listlist representation,\n                       listlist[u] contains all v for which arc (u,v) exists.\n    \"\"\"\n    graph = [[] for _ in range(len(weight))]\n    for u in range(len(graph)):\n        for v in range(len(graph)):\n            if weight[u][v] != None:\n                graph[u].append(v)\n    return graph"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntransforms the weighted adjacency list representation of a graph into a listdict representation of the graph.", "response": "def listlist_and_matrix_to_listdict(graph, weight=None):\n    \"\"\"Transforms the weighted adjacency list representation of a graph\n    of type listlist + optional weight matrix\n    into the listdict representation\n\n    :param graph: in listlist representation\n    :param weight: optional weight matrix\n    :returns: graph in listdict representation\n    :complexity: linear\n    \"\"\"\n    if weight:\n        return [{v:weight[u][v] for v in graph[u]} for u in range(len(graph))]\n    else:\n        return [{v:None for v in graph[u]} for u in range(len(graph))]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntransform the adjacency list representation of a graph of type listdict into the listlist representation and weight matrix representation.", "response": "def listdict_to_listlist_and_matrix(sparse):\n    \"\"\"Transforms the adjacency list representation of a graph\n    of type listdict into the listlist + weight matrix representation\n\n    :param sparse: graph in listdict representation\n    :returns: couple with listlist representation, and weight matrix\n    :complexity: linear\n    \"\"\"\n    V = range(len(sparse))\n    graph = [[] for _ in V]\n    weight = [[None for v in V] for u in V]\n    for u in V:\n        for v in sparse[u]:\n            graph[u].append(v)\n            weight[u][v] = sparse[u][v]\n    return graph, weight"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntransform a dict - dict graph representation into a list - dict representation.", "response": "def dictdict_to_listdict(dictgraph):\n    \"\"\"Transforms a dict-dict graph representation into a\n    adjacency dictionary representation (list-dict)\n\n    :param dictgraph: dictionary mapping vertices to dictionary\n           such that dictgraph[u][v] is weight of arc (u,v)\n    :complexity: linear\n    :returns: tuple with graph (listdict), name_to_node (dict), node_to_name (list)\n    \"\"\"\n    n = len(dictgraph)                            # vertices\n    node_to_name = [name for name in dictgraph]   # bijection indices <-> names\n    node_to_name.sort()                           # to make it more readable\n    name_to_node = {}\n    for i in range(n):\n        name_to_node[node_to_name[i]] = i\n    sparse = [{} for _ in range(n)]               # build sparse graph\n    for u in dictgraph:\n        for v in dictgraph[u]:\n            sparse[name_to_node[u]][name_to_node[v]] = dictgraph[u][v]\n    return sparse, name_to_node, node_to_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts a path from source to tree to v", "response": "def extract_path(prec, v):\n    \"\"\"extracts a path in form of vertex list from source to vertex v\n       given a precedence table prec leading to the source\n\n    :param prec: precedence table of a tree\n    :param v: vertex on the tree\n    :returns: path from root to v, in form of a list\n    :complexity: linear\n    \"\"\"\n    L = []\n    while v is not None:\n        L.append(v)\n        v = prec[v]\n        assert v not in L   # prevent infinite loops for a bad formed table prec\n    return L[::-1]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_flow_labels(graph, flow, capac):\n    V = range(len(graph))\n    arc_label = [{v:\"\" for v in graph[u]} for u in V]\n    for u in V:\n        for v in graph[u]:\n            if flow[u][v] >= 0:\n                arc_label[u][v] = \"%s/%s\" % (flow[u][v], capac[u][v])\n            else:\n                arc_label[u][v] = None   # do not show negative flow arcs\n    return arc_label", "response": "Generate the arc labels for a flow in a listdic graph with capacities."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dilworth(graph):\n    n = len(graph)\n    match = max_bipartite_matching(graph)  # maximum matching\n    part = [None] * n                      # partition into chains\n    nb_chains = 0\n    for v in range(n - 1, -1, -1):         # in inverse topological order\n        if part[v] is None:                # start of chain\n            u = v\n            while u is not None:           # follow the chain\n                part[u] = nb_chains        # mark\n                u = match[u]\n            nb_chains += 1\n    return part", "response": "Decompose a DAG into a minimum number of chains by Dilworth\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extract(code, tree, prefix=[]):\n    if isinstance(tree, list):\n        l, r = tree\n        prefix.append('0')\n        extract(code, l, prefix)\n        prefix.pop()\n        prefix.append('1')\n        extract(code, r, prefix)\n        prefix.pop()\n    else:\n        code[tree] = ''.join(prefix)", "response": "Extract a Huffman code from a Huffman tree"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the next permutation of the lexicographical order", "response": "def next_permutation(tab):\n    \"\"\"find the next permutation of tab in the lexicographical order\n\n    :param tab: table with n elements from an ordered set\n    :modifies: table to next permutation\n    :returns: False if permutation is already lexicographical maximal\n    :complexity: O(n)\n    \"\"\"\n    n = len(tab)\n    pivot = None                         # find pivot\n    for i in range(n - 1):\n        if tab[i] < tab[i + 1]:\n            pivot = i\n    if pivot is None:                    # tab is already the last perm.\n        return False\n    for i in range(pivot + 1, n):        # find the element to swap\n        if tab[i] > tab[pivot]:\n            swap = i\n    tab[swap], tab[pivot] = tab[pivot], tab[swap]\n    i = pivot + 1\n    j = n - 1                            # invert suffix\n    while i < j:\n        tab[i], tab[j] = tab[j], tab[i]\n        i += 1\n        j -= 1\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nquerying u and v", "response": "def query(self, u, v):\n        \"\"\":returns: the lowest common ancestor of u and v\n        :complexity: O(log n)\n        \"\"\"\n        # -- assume w.l.o.g. that v is not higher than u in the tree\n        if self.level[u] > self.level[v]:\n            u, v = v, u\n        # -- put v at the same level as u\n        depth = len(self.anc)\n        for k in range(depth-1, -1, -1):\n            if self.level[u] <= self.level[v] - (1 << k):\n                v = self.anc[k][v]\n        assert self.level[u] == self.level[v]\n        if u == v:\n            return u\n        # -- climb until the lowest common ancestor\n        for k in range(depth-1, -1, -1):\n            if self.anc[k][u] != self.anc[k][v]:\n                u = self.anc[k][u]\n                v = self.anc[k][v]\n        assert self.anc[0][u] == self.anc[0][v]\n        return self.anc[0][u]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nquerying - returns the lowest common ancestor of u and v", "response": "def query(self, u, v):\n        \"\"\":returns: the lowest common ancestor of u and v\n        :complexity: O(log n)\n        \"\"\"\n        lu = self.last[u]\n        lv = self.last[v]\n        if lu > lv:\n            lu, lv = lv, lu\n        return self.rmq.range_min(lu, lv + 1)[1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fast_exponentiation2(a, b, q):\n    assert a >= 0 and b >= 0 and q >= 1\n    p = 0               # only for documentation\n    p2 = 1              # 2 ** p\n    ap2 = a % q         # a ** (2 ** p)\n    result = 1\n    while b > 0:\n        if p2 & b > 0:  # b's binary decomposition contains 2 ** p\n            b -= p2\n            result = (result * ap2) % q\n        p += 1\n        p2 *= 2\n        ap2 = (ap2 * ap2) % q\n    return result", "response": "Compute a fast exponentiation of a and b."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fast_exponentiation(a, b, q):\n    assert a >= 0 and b >= 0 and q >= 1\n    result = 1\n    while b:\n        if b % 2 == 1:\n            result = (result * a) % q\n        a = (a * a) % q\n        b >>= 1\n    return result", "response": "Compute a fast exponentiation of a and b."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind an augmenting path from u to target with value at most val", "response": "def _augment(graph, capacity, flow, val, u, target, visit):\n    \"\"\"Find an augmenting path from u to target with value at most val\"\"\"\n    visit[u] = True\n    if u == target:\n        return val\n    for v in graph[u]:\n        cuv = capacity[u][v]\n        if not visit[v] and cuv > flow[u][v]:  # reachable arc\n            res = min(val, cuv - flow[u][v])\n            delta = _augment(graph, capacity, flow, res, v, target, visit)\n            if delta > 0:\n                flow[u][v] += delta            # augment flow\n                flow[v][u] -= delta\n                return delta\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ford_fulkerson(graph, capacity, s, t):\n    add_reverse_arcs(graph, capacity)\n    n = len(graph)\n    flow = [[0] * n for _ in range(n)]\n    INF = float('inf')\n    while _augment(graph, capacity, flow, INF, s, t, [False] * n) > 0:\n        pass                         # work already done in _augment\n    return (flow, sum(flow[s]))", "response": "Maximum flow by Ford - Fulkerson"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding all windows containing exactly k distinct elements in x.", "response": "def windows_k_distinct(x, k):\n    \"\"\"Find all largest windows containing exactly k distinct elements\n\n    :param x: list or string\n    :param k: positive integer\n    :yields: largest intervals [i, j) with len(set(x[i:j])) == k\n    :complexity: `O(|x|)`\n    \"\"\"\n    dist, i, j = 0, 0, 0                # dist = |{x[i], ..., x[j-1]}|\n    occ = {xi: 0 for xi in x}           # number of occurrences in x[i:j]\n    while j < len(x):\n        while dist == k:                # move start of interval\n            occ[x[i]] -= 1              # update counters\n            if occ[x[i]] == 0:\n                dist -= 1\n            i += 1\n        while j < len(x) and (dist < k or occ[x[j]]):\n            if occ[x[j]] == 0:          # update counters\n                dist += 1\n            occ[x[j]] += 1\n            j += 1                      # move end of interval\n        if dist == k:\n            yield (i, j)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bezout(a, b):\n    if b == 0:\n        return (1, 0)\n    else:\n        u, v = bezout(b, a % b)\n        return (v, u - (a // b) * v)", "response": "Computes the Bezout coefficients for a and b."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef binom_modulo(n, k, p):\n    prod = 1\n    for i in range(k):\n        prod = (prod * (n - i) * inv(i + 1, p)) % p\n    return prod", "response": "Binomial coefficients for n \\ choose k modulo p"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef max_bipartite_matching(bigraph):\n    n = len(bigraph)               # same domain for U and V\n    match = [None] * n\n    for u in range(n):\n        augment(u, bigraph, [False] * n, match)\n    return match", "response": "Bipartie maximum matching of a given set of neighbors."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef predictive_text(dic):\n    freq = {}   # freq[p] = total weight of words having prefix p\n    for word, weight in dic:\n        prefix = \"\"\n        for x in word:\n            prefix += x\n            if prefix in freq:\n                freq[prefix] += weight\n            else:\n                freq[prefix] = weight\n    #   prop[s] = prefix to display for s\n    prop = {}\n    for prefix in freq:\n        code = code_word(prefix)\n        if code not in prop or freq[prop[code]] < freq[prefix]:\n            prop[code] = prefix\n    return prop", "response": "Predictive text for mobile phones."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cut_nodes_edges(graph):\n    n = len(graph)\n    time = 0\n    num = [None] * n\n    low = [n] * n\n    father = [None] * n        # father[v] = None if root else father of v\n    critical_childs = [0] * n  # c_c[u] = #childs v s.t. low[v] >= num[u]\n    times_seen = [-1] * n\n    for start in range(n):\n        if times_seen[start] == -1:               # init DFS path\n            times_seen[start] = 0\n            to_visit = [start]\n            while to_visit:\n                node = to_visit[-1]\n                if times_seen[node] == 0:         # start processing\n                    num[node] = time\n                    time += 1\n                    low[node] = float('inf')\n                children = graph[node]\n                if times_seen[node] == len(children):  # end processing\n                    to_visit.pop()\n                    up = father[node]            # propagate low to father\n                    if up is not None:\n                        low[up] = min(low[up], low[node])\n                        if low[node] >= num[up]:\n                            critical_childs[up] += 1\n                else:\n                    child = children[times_seen[node]]   # next arrow\n                    times_seen[node] += 1\n                    if times_seen[child] == -1:   # not visited yet\n                        father[child] = node      # link arrow\n                        times_seen[child] = 0\n                        to_visit.append(child)    # (below) back arrow\n                    elif num[child] < num[node] and father[node] != child:\n                        low[node] = min(low[node], num[child])\n    cut_edges = []\n    cut_nodes = []                                # extract solution\n    for node in range(n):\n        if father[node] is None:                  # characteristics\n            if critical_childs[node] >= 2:\n                cut_nodes.append(node)\n        else:                                     # internal nodes\n            if critical_childs[node] >= 1:\n                cut_nodes.append(node)\n            if low[node] >= num[node]:\n                cut_edges.append((father[node], node))\n    return cut_nodes, cut_edges", "response": "Returns a tuple with the list of nodes and edges of the undirected graph."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cut_nodes_edges2(graph):\n    N = len(graph)\n    assert N <= 5000\n    recursionlimit = getrecursionlimit()\n    setrecursionlimit(max(recursionlimit, N + 42))\n    edges = set((i, j) for i in range(N) for j in graph[i] if i <= j)\n    nodes = set()\n    NOT = -2  # not visited yet; -1 would be buggy `marked[v] != prof - 1`\n    FIN = -3  # already visited\n    marked = [NOT] * N  # if >= 0, it means depth within the DFS\n\n    def DFS(n, prof=0):\n        \"\"\"\n        Recursively search graph, update edge list and returns the first\n        node the first edge within search to which we can come back.\n        \"\"\"\n        if marked[n] == FIN:\n            return  # only when there are several connected components\n        if marked[n] != NOT:\n            return marked[n]\n        marked[n] = prof\n        m = float('inf')\n        count = 0  # useful only for prof == 0\n        for v in graph[n]:\n            if marked[v] != FIN and marked[v] != prof - 1:\n                count += 1\n                r = DFS(v, prof+1)\n                if r <= prof:\n                    edges.discard(tuple(sorted((n, v))))\n                if prof and r >= prof:  # only if we are not at root\n                    nodes.add(n)\n                m = min(m, r)\n        # root is an articulation point iff it has more than 2 childs\n        if prof == 0 and count >= 2:\n            nodes.add(n)\n        marked[n] = FIN\n        return m\n    for r in range(N):\n        DFS(r)  # we can count connected components by nb += DFS(r)\n    setrecursionlimit(recursionlimit)\n    return nodes, edges", "response": "A function that returns a tuple with the list of nodes and edges that are part of the undirected graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef area(p):\n    A = 0\n    for i in range(len(p)):\n        A += p[i - 1][0] * p[i][1] - p[i][0] * p[i - 1][1]\n    return A / 2.", "response": "Area of a polygone in any orientation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntesting if a rectilinear polygon is a simple segment.", "response": "def is_simple(polygon):\n    \"\"\"Test if a rectilinear polygon is is_simple\n\n    :param polygon: list of points as (x,y) pairs along the closed polygon\n    :returns: True if the segements do not intersect\n    :complexity: O(n log n) for n=len(polygon)\n    \"\"\"\n    n = len(polygon)\n    order = list(range(n))\n    order.sort(key=lambda i: polygon[i])         # lexicographic order\n    rank_to_y = list(set(p[1] for p in polygon))\n    rank_to_y.sort()\n    y_to_rank = {y: rank for rank, y in enumerate(rank_to_y)}\n    S = RangeMinQuery([0] * len(rank_to_y))      # sweep structure\n    last_y = None\n    for i in order:\n        x, y = polygon[i]\n        rank = y_to_rank[y]\n        #                             -- type of point\n        right_x = max(polygon[i - 1][0], polygon[(i + 1) % n][0])\n        left = x < right_x\n        below_y = min(polygon[i - 1][1], polygon[(i + 1) % n][1])\n        high = y > below_y\n        if left:                      # y does not need to be in S yet\n            if S[rank]:\n                return False          # two horizontal segments intersect\n            S[rank] = -1              # add y to S\n        else:\n            S[rank] = 0               # remove y from S\n        if high:\n            lo = y_to_rank[below_y]   # check S between [lo + 1, rank - 1]\n            if (below_y != last_y or last_y == y or\n                    rank - lo >= 2 and S.range_min(lo + 1, rank)):\n                return False          # horiz. & vert. segments intersect\n        last_y = y                    # remember for next iteration\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dfs_grid(grid, i, j, mark='X', free='.'):\n    height = len(grid)\n    width = len(grid[0])\n    to_visit = [(i, j)]\n    grid[i][j] = mark\n    while to_visit:\n        i1, j1 = to_visit.pop()\n        for i2, j2 in [(i1 + 1, j1), (i1, j1 + 1),\n                       (i1 - 1, j1), (i1, j1 - 1)]:\n            if (0 <= i2 < height and 0 <= j2 < width and\n                    grid[i2][j2] == free):\n                grid[i2][j2] = mark  # mark path\n                to_visit.append((i2, j2))", "response": "DFS on a grid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind a cycle in an undirected graph or listdict format", "response": "def find_cycle(graph):\n    \"\"\"find a cycle in an undirected graph\n\n    :param graph: undirected graph in listlist or listdict format\n    :returns: list of vertices in a cycle or None\n    :complexity: `O(|V|+|E|)`\n    \"\"\"\n    n = len(graph)\n    prec = [None] * n  # ancestor marks for visited vertices\n    for u in range(n):\n        if prec[u] is None:  # unvisited vertex\n            S = [u]  # start new DFS\n            prec[u] = u  # mark root (not necessary for this algorithm)\n            while S:\n                u = S.pop()\n                for v in graph[u]:  # for all neighbors\n                    if v != prec[u]:  # except arcs to father in DFS tree\n                        if prec[v] is not None:\n                            cycle = [v, u]  # cycle found, (u,v) back edge\n                            while u != prec[v] and u != prec[u]:  # directed\n                                u = prec[u]  # climb up the tree\n                                cycle.append(u)\n                            return cycle\n                        else:\n                            prec[v] = u  # v is new vertex in tree\n                            S.append(v)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef arithm_expr_eval(cell, expr):\n    if isinstance(expr, tuple):\n        (left, op, right) = expr\n        lval = arithm_expr_eval(cell, left)\n        rval = arithm_expr_eval(cell, right)\n        if op == '+':\n            return lval + rval\n        if op == '-':\n            return lval - rval\n        if op == '*':\n            return lval * rval\n        if op == '/':\n            return lval // rval\n    elif isinstance(expr, int):\n        return expr\n    else:\n        cell[expr] = arithm_expr_eval(cell, cell[expr])\n        return cell[expr]", "response": "Evaluates a given expression in the given dictionary variable name - > expression\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef arithm_expr_parse(line):\n    vals = []\n    ops = []\n    for tok in line + [';']:\n        if tok in priority:  # tok is an operator\n            while (tok != '(' and ops and\n                   priority[ops[-1]] >= priority[tok]):\n                right = vals.pop()\n                left = vals.pop()\n                vals.append((left, ops.pop(), right))\n            if tok == ')':\n                ops.pop()    # this is the corresponding '('\n            else:\n                ops.append(tok)\n        elif tok.isdigit():  # tok is an integer\n            vals.append(int(tok))\n        else:                # tok is an identifier\n            vals.append(tok)\n    return vals.pop()", "response": "Parses an arithmetic expression tree."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the sum of the entries in the set with the prefix i", "response": "def prefixSum(self, i):\n        \"\"\"\n        :param int i: non negative\n        :returns: t[1] + ... + t[i]\n        \"\"\"\n        sum = 0\n        while i > 0:\n            sum += self.s[i]\n            i -= (i & -i)\n        return sum"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef intervalSum(self, a, b):\n        return self.prefixSum(b) - self.prefixSum(a-1)", "response": "returns the sum of the prefix sum of two entries"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding val to the set i", "response": "def add(self,  i, val):\n        \"\"\"\n        :param int i: positive\n        :modifies: adds val to t[i]\n        \"\"\"\n        assert i > 0\n        while i < len(self.s):\n            self.s[i] += val\n            i += (i & -i)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _alternate(u, bigraph, visitU, visitV, matchV):\n    visitU[u] = True\n    for v in bigraph[u]:\n        if not visitV[v]:\n            visitV[v] = True\n            assert matchV[v] is not None  # otherwise match is not maximum\n            _alternate(matchV[v], bigraph, visitU, visitV, matchV)", "response": "extend alternating tree from free vertex u. visitU marks all vertices covered by the tree. matchV marks all vertices covered by the tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the area of union of rectangles.", "response": "def union_rectangles(R):\n    \"\"\"Area of union of rectangles\n\n    :param R: list of rectangles defined by (x1, y1, x2, y2)\n       where (x1, y1) is top left corner and (x2, y2) bottom right corner\n    :returns: area\n    :complexity: :math:`O(n^2)`\n    \"\"\"\n    if R == []:\n        return 0\n    X = []\n    Y = []\n    for j in range(len(R)):\n        (x1, y1, x2, y2) = R[j]\n        assert x1 <= x2 and y1 <= y2\n        X.append(x1)\n        X.append(x2)\n        Y.append((y1, +1, j))    # generate events\n        Y.append((y2, -1, j))\n    X.sort()\n    Y.sort()\n    X2i = {X[i]: i for i in range(len(X))}\n    L = [X[i + 1] - X[i] for i in range(len(X) - 1)]\n    C = Cover_query(L)\n    area = 0\n    last = 0\n    for (y, delta, j) in Y:\n        area += (y - last) * C.cover()\n        last = y\n        (x1, y1, x2, y2) = R[j]\n        i = X2i[x1]\n        k = X2i[x2]\n        C.change(i, k, delta)\n    return area"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef change(self, i, k, delta):\n        self._change(1, 0, self.N, i, k, delta)", "response": "change the interval i k to delta"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(filename):\n    formula = []\n    for line in open(filename, 'r'):\n        line = line.strip()\n        if line[0] == \"#\":\n            continue\n        lit = line.split(\":-\")\n        if len(lit) == 1:\n            posvar = lit[0]\n            negvars = []\n        else:\n            assert len(lit) == 2\n            posvar = lit[0].strip()\n            if posvar == '':\n                posvar = None\n            negvars = lit[1].split(',')\n            for i in range(len(negvars)):\n                negvars[i] = negvars[i].strip()\n        formula.append((posvar, negvars))\n    return formula", "response": "reads a Horn SAT formula from a text file"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef horn_sat(formula):\n    # --- construct data structures\n    CLAUSES = range(len(formula))\n    score = [0 for c in CLAUSES]                # number of negative vars that are not yet in solution\n    posvar_in_clause = [None for c in CLAUSES]  # the unique positive variable of a clause (if any)\n    clauses_with_negvar = defaultdict(set)      # all clauses where a variable appears negatively\n    for c in CLAUSES:\n        posvar, negvars = formula[c]\n        score[c] = len(set(negvars))            # do not count twice repeated negative variables\n        posvar_in_clause[c] = posvar\n        for v in negvars:\n            clauses_with_negvar[v].add(c)\n    pool = [set() for s in range(max(score) + 1)]   # create the pool\n    for c in CLAUSES:\n        pool[score[c]].add(c)                   # pool[s] = set of clauses with score s\n\n    # --- solve Horn SAT formula\n    solution = set()                            # contains all variables set to True\n    while pool[0]:\n        curr = pool[0].pop()                    # arbitrary zero score clause\n        v = posvar_in_clause[curr]\n        if v == None:                           # formula is not satisfiable\n            return None\n        if v in solution or curr in clauses_with_negvar[v]:\n            continue                            # clause is already satisfied\n        solution.add(v)\n        for c in clauses_with_negvar[v]:        # update score\n            pool[score[c]].remove(c)\n            score[c] -= 1\n            pool[score[c]].add(c)               # change c to lower score in pool\n    return solution", "response": "Solving a HORN Sat formula\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dinic(graph, capacity, source, target):\n    assert source != target\n    add_reverse_arcs(graph, capacity)\n    Q = deque()\n    total = 0\n    n = len(graph)\n    flow = [[0] * n for u in range(n)]   # flow initially empty\n    while True:                   # repeat while we can increase\n        Q.appendleft(source)\n        lev = [None] * n          # build levels, None = inaccessible\n        lev[source] = 0           # by BFS\n        while Q:\n            u = Q.pop()\n            for v in graph[u]:\n                if lev[v] is None and capacity[u][v] > flow[u][v]:\n                    lev[v] = lev[u] + 1\n                    Q.appendleft(v)\n\n        if lev[target] is None:   # stop if sink is not reachable\n            return flow, total\n        up_bound = sum(capacity[source][v] for v in graph[source]) - total\n        total += _dinic_step(graph, capacity, lev, flow, source, target,\n                             up_bound)", "response": "Maximum flow by Dinic\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _dinic_step(graph, capacity, lev, flow, u, target, limit):\n    if limit <= 0:\n        return 0\n    if u == target:\n        return limit\n    val = 0\n    for v in graph[u]:\n        residual = capacity[u][v] - flow[u][v]\n        if lev[v] == lev[u] + 1 and residual > 0:\n            z = min(limit, residual)\n            aug = _dinic_step(graph, capacity, lev, flow, v, target, z)\n            flow[u][v] += aug\n            flow[v][u] -= aug\n            val += aug\n            limit -= aug\n    if val == 0:\n        lev[u] = None         # remove unreachable node\n    return val", "response": "tenter de pousser le plus de flot de u \u00e0 target sans d\u00e9passer limit de pousser le plus de flot de u \u00e0 target sans d\u00e9passer limit de pousser le plus de flot de u \u00e0 target sans d\u00e9passer limit de pousser le plus de flot de u \u00e0 target sans d\u00e9passer limit de pousser le"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninsert new element x into the heap.", "response": "def push(self, x):\n        \"\"\"Insert new element x in the heap.\n           Assumption: x is not already in the heap\"\"\"\n        assert x not in self.rank\n        i = len(self.heap)\n        self.heap.append(x)    # add a new leaf\n        self.rank[x] = i\n        self.up(i)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pop(self):\n        root = self.heap[1]\n        del self.rank[root]\n        x = self.heap.pop()    # remove last leaf\n        if self:               # if heap is not empty\n            self.heap[1] = x   # put last leaf to root\n            self.rank[x] = 1\n            self.down(1)       # maintain heap order\n        return root", "response": "Remove and return smallest element"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef up(self, i):\n        x = self.heap[i]\n        while i > 1 and x < self.heap[i // 2]:\n            self.heap[i] = self.heap[i // 2]\n            self.rank[self.heap[i // 2]] = i\n            i //= 2\n        self.heap[i] = x       # insertion index found\n        self.rank[x] = i", "response": "Decreases the value of heap[i has decreased. Maintain heap invariant."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclimb down the tree and insert the i - th item in the heap. Maintain heap invariant.", "response": "def down(self, i):\n        \"\"\"the value of heap[i] has increased. Maintain heap invariant.\"\"\"\n        x = self.heap[i]\n        n = len(self.heap)\n        while True:\n            left = 2 * i       # climb down the tree\n            right = left + 1\n            if (right < n and self.heap[right] < x and\n                    self.heap[right] < self.heap[left]):\n                self.heap[i] = self.heap[right]\n                self.rank[self.heap[right]] = i   # go back up right child\n                i = right\n            elif left < n and self.heap[left] < x:\n                self.heap[i] = self.heap[left]\n                self.rank[self.heap[left]] = i    # go back up left child\n                i = left\n            else:\n                self.heap[i] = x   # insertion index found\n                self.rank[x] = i\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self, old, new):\n        i = self.rank[old]     # change value at index i\n        del self.rank[old]\n        self.heap[i] = new\n        self.rank[new] = i\n        if old < new:          # maintain heap order\n            self.down(i)\n        else:\n            self.up(i)", "response": "Update the heap with the new one."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the identifier of part containing x", "response": "def find(self, x):\n        \"\"\":returns: identifier of part containing x\n        :complexity: O(inverse_ackerman(n))\n        \"\"\"\n        if self.up[x] == x:\n            return x\n        else:\n            self.up[x] = self.find(self.up[x])\n            return self.up[x]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmerge part that contain x and part containing y into the current set. Returns True if x and y are already in same part otherwise False.", "response": "def union(self, x, y):\n        \"\"\"Merges part that contain x and part containing y\n\n        :returns: False if x, y are already in same part\n        :complexity: O(inverse_ackerman(n))\n        \"\"\"\n        repr_x = self.find(x)\n        repr_y = self.find(y)\n        if repr_x == repr_y:       # already in the same component\n            return False\n        if self.rank[repr_x] == self.rank[repr_y]:\n            self.rank[repr_x] += 1\n            self.up[repr_y] = repr_x\n        elif self.rank[repr_x] > self.rank[repr_y]:\n            self.up[repr_y] = repr_x\n        else:\n            self.up[repr_x] = repr_y\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninserting list item before anchor", "response": "def insert(self, anchor):\n        \"\"\"insert list item before anchor\n        \"\"\"\n        self.prec = anchor.prec        # point to neighbors\n        self.succ = anchor\n        self.succ.prec = self          # make neighbors point to item\n        self.prec.succ = self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef append(self, item):\n        if not self.items:        # was list empty ?\n            self.items = item     # then this is the new head\n        item.insert(self.items)", "response": "add item to the end of the item list"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves item from its class", "response": "def remove(self):\n        \"\"\"remove item from its class\n        \"\"\"\n        DoubleLinkedListItem.remove(self)     # remove from double linked list\n        if self.succ is self:                 # list was a singleton\n            self.theclass.items = None        # class is empty\n        elif self.theclass.items is self:     # oups we removed the head\n            self.theclass.items = self.succ"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsplit every class C in the partition into two sets of items and the intersection pivot and C setminus pivot.", "response": "def refine(self, pivot):\n        \"\"\"Split every class C in the partition into C intersection pivot and C setminus pivot\n        complexity: linear in size of pivot\n        \"\"\"\n        has_split = []                        # remember which classes split\n        for i in pivot:\n            if 0 <= i < len(self.items):      # ignore if outside of domain\n                x = self.items[i]\n                c = x.theclass                # c = class of x\n                if not c.split:               # possibly create new split class\n                    c.split = PartitionClass(c)\n                    if self.classes is c:\n                        self.classes = c.split   # always make self.classes point to the first class\n                    has_split.append(c)\n                x.remove()                    # remove from its class\n                x.theclass = c.split\n                c.split.append(x)             # append to the split class\n        for c in has_split:                   # clean information about split classes\n            c.split = None\n            if not c.items:                   # delete class if it became empty\n                c.remove()\n                del c"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tolist(self):\n        return [[x.val for x in theclass.items] for theclass in self.classes]", "response": "produce a list representation of the partition\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef order(self):\n        return [x.val for theclass in self.classes for x in theclass.items]", "response": "Produce a flatten list of the partition ordered by classes"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprimes numbers by sieve of Eratosthene", "response": "def eratosthene(n):\n    \"\"\"Prime numbers by sieve of Eratosthene\n\n    :param n: positive integer\n    :assumes: n > 2\n    :returns: list of prime numbers <n\n    :complexity: O(n loglog n)\n    \"\"\"\n    P = [True] * n\n    answ = [2]\n    for i in range(3, n, 2):\n        if P[i]:\n            answ.append(i)\n            for j in range(2 * i, n, i):\n                P[j] = False\n    return answ"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the list of all prime numbers less than n and a table mapping every integer 2 \u2264 x < n to its smallest prime factor.", "response": "def gries_misra(n):\n    \"\"\"Prime numbers by the sieve of Gries-Misra\n    Computes both the list of all prime numbers less than n,\n    and a table mapping every integer 2 \u2264 x < n to its smallest prime factor\n\n    :param n: positive integer\n    :returns: list of prime numbers, and list of prime factors\n    :complexity: O(n)\n    \"\"\"\n    primes = []\n    factor = [0] * n\n    for x in range(2, n):\n        if not factor[x]:     # no factor found\n            factor[x] = x     # meaning x is prime\n            primes.append(x)\n        for p in primes:      # loop over all non primes of the form p * x\n            if p > factor[x] or p * x >= n:\n                break\n            factor[p * x] = p\n    return primes, factor"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _augment(graph, capacity, flow, source, target):\n    n = len(graph)\n    A = [0] * n               # A[v] = min residual cap. on path source->v\n    augm_path = [None] * n    # None = node was not visited yet\n    Q = deque()               # BFS\n    Q.append(source)\n    augm_path[source] = source\n    A[source] = float('inf')\n    while Q:\n        u = Q.popleft()\n        for v in graph[u]:\n            cuv = capacity[u][v]\n            residual = cuv - flow[u][v]\n            if residual > 0 and augm_path[v] is None:\n                augm_path[v] = u    # store predecessor\n                A[v] = min(A[u], residual)\n                if v == target:\n                    break\n                else:\n                    Q.append(v)\n    return (augm_path, A[target])", "response": "find a shortest augmenting path from source to target"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gauss_jordan(A, x, b):\n    n = len(x)\n    m = len(b)\n    assert len(A) == m and len(A[0]) == n\n    S = []                        # put linear system in a single matrix S\n    for i in range(m):\n        S.append(A[i][:] + [b[i]])\n    S.append(list(range(n)))      # indices in x\n    k = diagonalize(S, n, m)\n    if k < m:\n        for i in range(k, m):\n            if not is_zero(S[i][n]):\n                return GJ_ZERO_SOLUTIONS\n    for j in range(k):\n        x[S[m][j]] = S[j][n]\n    if k < n:\n        for j in range(k, n):\n            x[S[m][j]] = 0\n        return GJ_SEVERAL_SOLUTIONS\n    return GJ_SINGLE_SOLUTION", "response": "Linear equation system Ax = b by Gauss - Jordan algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntest if s i j k matches t", "response": "def matches(s, t, i, j, k):\n    \"\"\"tests if s[i:i + k] equals t[j:j + k]\"\"\"\n    for d in range(k):\n        if s[i + d] != t[j + d]:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rabin_karp_matching(s, t):\n    hash_s = 0\n    hash_t = 0\n    len_s = len(s)\n    len_t = len(t)\n    last_pos = pow(DOMAIN, len_t - 1) % PRIME\n    if len_s < len_t:\n        return -1\n    for i in range(len_t):         # preprocessing\n        hash_s = (DOMAIN * hash_s + ord(s[i])) % PRIME\n        hash_t = (DOMAIN * hash_t + ord(t[i])) % PRIME\n    for i in range(len_s - len_t + 1):\n        if hash_s == hash_t:       # check character by character\n            if matches(s, t, i, 0, len_t):\n                return i\n        if i < len_s - len_t:\n            hash_s = roll_hash(hash_s, ord(s[i]), ord(s[i + len_t]),\n                               last_pos)\n    return -1", "response": "Find a substring by Rabin - Karp - Available algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind a common factor by Rabin - Karp", "response": "def rabin_karp_factor(s, t, k):\n    \"\"\"Find a common factor by Rabin-Karp\n\n    :param string s: haystack\n    :param string t: needle\n    :param int k: factor length\n    :returns: (i, j) such that s[i:i + k] == t[j:j + k] or None.\n              In case of tie, lexicographical minimum (i, j) is returned\n    :complexity: O(len(s) + len(t)) in expected time,\n                and O(len(s) + len(t) * k) in worst case\n    \"\"\"\n    last_pos = pow(DOMAIN, k - 1) % PRIME\n    pos = {}\n    assert k > 0\n    if len(s) < k or len(t) < k:\n        return None\n    hash_t = 0\n    for j in range(k):         # store hashing values\n        hash_t = (DOMAIN * hash_t + ord(t[j])) % PRIME\n    for j in range(len(t) - k + 1):\n        if hash_t in pos:\n            pos[hash_t].append(j)\n        else:\n            pos[hash_t] = [j]\n        if j < len(t) - k:\n            hash_t = roll_hash(hash_t, ord(t[j]), ord(t[j + k]), last_pos)\n    hash_s = 0\n    for i in range(k):         # preprocessing\n        hash_s = (DOMAIN * hash_s + ord(s[i])) % PRIME\n    for i in range(len(s) - k + 1):\n        if hash_s in pos:      # is this signature in s?\n            for j in pos[hash_s]:\n                if matches(s, t, i, j, k):\n                    return (i, j)\n        if i < len(s) - k:\n            hash_s = roll_hash(hash_s, ord(s[i]), ord(s[i + k]), last_pos)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nextKey(self, key):\n        ans = self.nextNode(key)\n        return (ans.key\n                if ans is not None\n                else None)", "response": "Return the next key in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lastKey(self, key):\n        update = self._updateList(key)[0]\n        return (update[0].key\n                if update\n                else None)", "response": "lastKey - Returns the last key in the cache or None if no such key exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npops the first element from the set and returns it.", "response": "def pop(self):\n        \"\"\"Pops the first element\"\"\"\n        try:\n            x = next(iter(self))\n            self.remove(x)\n            return x\n        except StopIteration:\n            raise KeyError('pop from an empty set')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef permutation_rank(p):\n    n = len(p)\n    fact = 1                                 # compute (n-1) factorial\n    for i in range(2, n):\n        fact *= i\n    r = 0                                    # compute rank of p\n    digits = list(range(n))                  # all yet unused digits\n    for i in range(n-1):                     # for all digits except last one\n        q = digits.index(p[i])\n        r += fact * q\n        del digits[q]                        # remove this digit p[i]\n        fact //= (n - 1 - i)                 # weight of next digit\n    return r", "response": "Given a list of integers n find its rank according to lexicographical order\nDAO"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving r and n find the permutation of n integers with rank equal to r.", "response": "def rank_permutation(r, n):\n    \"\"\"Given r and n find the permutation of {0,..,n-1} with rank according to lexicographical order equal to r\n\n       :param r n: integers with 0 \u2264 r < n!\n       :returns: permutation p as a list of n integers\n       :beware: computation with big numbers\n       :complexity: `O(n^2)`\n    \"\"\"\n    fact = 1                                # compute (n-1) factorial\n    for i in range(2, n):\n        fact *= i\n    digits = list(range(n))                 # all yet unused digits\n    p = []                                  # build permutation\n    for i in range(n):\n        q = r // fact                       # by decomposing r = q * fact + rest\n        r %= fact\n        p.append(digits[q])\n        del digits[q]                       # remove digit at position q\n        if i != n - 1:\n            fact //= (n - 1 - i)            # weight of next digit\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef merge(x, y):\n    z = []\n    i = 0\n    j = 0\n    while i < len(x) or j < len(y):\n        if j == len(y) or i < len(x) and x[i] <= y[j]:  # priority on x\n            z.append(x[i])\n            i += 1\n        else:\n            z.append(y[j])\n            j += 1\n    return z", "response": "Merge two ordered lists of items x and y into a single list of items."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking the consecutive ones property.", "response": "def consecutive_ones_property(sets, universe=None):\n    \"\"\" Check the consecutive ones property.\n\n    :param list sets: is a list of subsets of the ground set.\n    :param groundset: is the set of all elements,\n                by default it is the union of the given sets\n    :returns: returns a list of the ordered ground set where\n              every given set is consecutive,\n              or None if there is no solution.\n    :complexity: O(len(groundset) * len(sets))\n    :disclaimer: an optimal implementation would have complexity\n                 O(len(groundset) + len(sets) + sum(map(len,sets))),\n                 and there are more recent easier algorithms for this problem.\n    \"\"\"\n    if universe is None:\n        universe = set()\n        for S in sets:\n            universe |= set(S)\n    tree = PQ_tree(universe)\n    try:\n        for S in sets:\n            tree.reduce(S)\n        return tree.border()\n    except IsNotC1P:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding one node as descendant", "response": "def add(self, node):\n        \"\"\"Add one node as descendant\n        \"\"\"\n        self.sons.append(node)\n        node.parent = self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_group(self, L):\n        if len(L) == 1:\n            self.add(L[0])\n        elif len(L) >= 2:\n            x = PQ_node(P_shape)\n            x.add_all(L)\n            self.add(x)", "response": "Add elements of L as descendants of the node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef border(self, L):\n        if self.shape == L_shape:\n            L.append(self.value)\n        else:\n            for x in self.sons:\n                x.border(L)", "response": "Append to L the border of the subtree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding a substring by Knuth - Morris - Pratt", "response": "def knuth_morris_pratt(s, t):\n    \"\"\"Find a substring by Knuth-Morris-Pratt\n\n    :param s: the haystack string\n    :param t: the needle string\n    :returns: index i such that s[i: i + len(t)] == t, or -1\n    :complexity: O(len(s) + len(t))\n    \"\"\"\n    sep = '\\x00'                   # special unused character\n    assert sep not in t and sep not in s\n    f = maximum_border_length(t + sep + s)\n    n = len(t)\n    for i, fi in enumerate(f):\n        if fi == n:                # found a border of the length of t\n            return i - 2 * n       # beginning of the border in s\n    return -1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef powerstring_by_border(u):\n    f = maximum_border_length(u)\n    n = len(u)\n    if n % (n - f[-1]) == 0:       # does the alignment shift divide n ?\n        return n // (n - f[-1])    # we found a power decomposition\n    return 1", "response": "Power string by Knuth - Morris - Pratt\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef matrix_chain_mult(M):\n    opt, arg = matrix_mult_opt_order(M)\n    return _apply_order(M, arg, 0, len(M)-1)", "response": "Matrix chain multiplication\n\n    :param M: list of matrices\n    :returns: M[0] * ... * M[-1], computed in time optimal order\n    :complexity: whatever is needed by the multiplications"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef levenshtein(x, y):\n    n = len(x)\n    m = len(y)\n    #                         initializing row 0 and column 0\n    A = [[i + j for j in range(m + 1)] for i in range(n + 1)]\n    for i in range(n):\n        for j in range(m):\n            A[i + 1][j + 1] = min(A[i][j + 1] + 1,              # insert\n                                  A[i + 1][j] + 1,              # delete\n                                  A[i][j] + int(x[i] != y[j]))  # subst.\n    return A[n][m]", "response": "Levenshtein edit distance between strings x and y."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gale_shapley(men, women):\n    n = len(men)\n    assert n == len(women)\n    current_suitor = [0] * n\n    spouse = [None] * n\n    rank = [[0] * n for j in range(n)]  # build rank\n    for j in range(n):\n        for r in range(n):\n            rank[j][women[j][r]] = r\n    singles = deque(range(n))  # all men are single and get in the queue\n    while singles:\n        i = singles.popleft()\n        j = men[i][current_suitor[i]]\n        current_suitor[i] += 1\n        if spouse[j] is None:\n            spouse[j] = i\n        elif rank[j][spouse[j]] < rank[j][i]:\n            singles.append(i)\n        else:\n            singles.put(spouse[j])  # sorry for spouse[j]\n            spouse[j] = i\n    return spouse", "response": "Stable matching by Gale - Shapley"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting an eulerian tour in DOT format", "response": "def write_cycle(filename, graph, cycle, directed):\n    \"\"\"Write an eulerian tour in DOT format\n\n       :param filename: the file to be written in DOT format\n       :param graph: graph in listlist format, cannot be listdict\n       :param bool directed: describes the graph\n       :param cycle: tour as a vertex list\n       :returns: nothing\n       :complexity: `O(|V|^2 + |E|)`\n    \"\"\"\n    n = len(graph)\n    weight = [[float('inf')] * n for _ in range(n)]\n    for r in range(1, len(cycle)):\n        weight[cycle[r-1]][cycle[r]] = r\n        if not directed:\n            weight[cycle[r]][cycle[r-1]] = r\n    write_graph(filename, graph, arc_label=weight, directed=directed)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef random_eulerien_graph(n):\n    graphe = [[] for _ in range(n)]\n    for v in range(n - 1):\n        noeuds = random.sample(range(v + 1, n), random.choice(\n            range(0 if len(graphe[v]) % 2 == 0 else 1, (n - v), 2)))\n        graphe[v].extend(noeuds)\n        for w in graphe[v]:\n            if w > v:\n                graphe[w].append(v)\n    return graphe", "response": "Generates some random eulerian graph in listlist representation"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntest if tour is eulerian", "response": "def is_eulerian_tour(graph, tour):\n    \"\"\"Eulerian tour on an undirected graph\n\n       :param graph: directed graph in listlist format, cannot be listdict\n       :param tour: vertex list\n       :returns: test if tour is eulerian\n       :complexity: `O(|V|*|E|)` under the assumption that set membership is in constant time\n    \"\"\"\n    m = len(tour)-1\n    arcs = set((tour[i], tour[i+1]) for i in range(m))\n    if len(arcs) != m:\n        return False\n    for (u,v) in arcs:\n        if v not in graph[u]:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates arithmetic expression approaching target value", "response": "def arithm_expr_target(x, target):\n    \"\"\" Create arithmetic expression approaching target value\n    :param x: allowed constants\n    :param target: target value\n    :returns: string in form 'expression=value'\n    :complexity: huge\n    \"\"\"\n    n = len(x)\n    expr = [{} for _ in range(1 << n)]\n    # expr[S][val]\n    # = string solely composed of values in set S that evaluates to val\n    for i in range(n):\n        expr[1 << i] = {x[i]: str(x[i])}   # store singletons\n    all_ = (1 << n) - 1\n    for S in range(3, all_ + 1):  # 3: first num that isn't a power of 2\n        if expr[S] != {}:\n            continue            # in that case S is a power of 2\n        for L in range(1, S):   # decompose set S into non-empty sets L, R\n            if L & S == L:\n                R = S ^ L\n                for vL in expr[L]:         # combine expressions from L\n                    for vR in expr[R]:     # with expressions from R\n                        eL = expr[L][vL]\n                        eR = expr[R][vR]\n                        expr[S][vL] = eL\n                        if vL > vR:    # difference cannot become negative\n                            expr[S][vL - vR] = \"(%s-%s)\" % (eL, eR)\n                        if L < R:      # break symmetry\n                            expr[S][vL + vR] = \"(%s+%s)\" % (eL, eR)\n                            expr[S][vL * vR] = \"(%s*%s)\" % (eL, eR)\n                        if vR != 0 and vL % vR == 0:  # only integer div\n                            expr[S][vL // vR] = \"(%s/%s)\" % (eL, eR)\n    # look for the closest expression from the target\n    for dist in range(target + 1):\n        for sign in [-1, +1]:\n            val = target + sign * dist\n            if val in expr[all_]:\n                return \"%s=%i\" % (expr[all_][val], val)\n    # never reaches here if x contains integers between 0 and target\n    pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef kuhn_munkres(G):      # maximum profit bipartite matching in O(n^4)\n    assert len(G) == len(G[0])\n    n = len(G)\n    mu = [None] * n                 # Empty matching\n    mv = [None] * n\n    lu = [max(row) for row in G]    # Trivial labels\n    lv = [0] * n\n    for u0 in range(n):\n        if mu[u0] is None:          # Free node\n            while True:\n                au = [False] * n    # Empty alternating tree\n                av = [False] * n\n                if improve_matching(G, u0, mu, mv, au, av, lu, lv):\n                    break\n                improve_labels(G, au, av, lu, lv)\n    return (mu,  sum(lu) + sum(lv))", "response": "Maximum profit perfect matching for minimum cost perfect matching just inverse the weights of the weights of a complete bipartite graph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef subset_sum(x, R):\n    b = [False] * (R + 1)\n    b[0] = True\n    for xi in x:\n        for s in range(R, xi - 1, -1):\n            b[s] |= b[s - xi]\n    return b[R]", "response": "Subsetsums the non negative values of a tree of non - negative values to a target value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef kuhn_munkres(G, TOLERANCE=1e-6):\n    nU = len(G)\n    U = range(nU)\n    nV = len(G[0])\n    V = range(nV)\n    assert nU <= nV\n    mu = [None] * nU                # empty matching\n    mv = [None] * nV\n    lu = [max(row) for row in G]    # trivial labels\n    lv = [0] * nV\n    for root in U:                  # build an alternate tree\n        au = [False] * nU           # au, av mark nodes...\n        au[root] = True             # ... covered by the tree\n        Av = [None] * nV            # Av[v] successor of v in the tree\n        # for every vertex u, slack[u] := (val, v) such that\n        # val is the smallest slack on the constraints (*)\n        # with fixed u and v being the corresponding vertex\n        slack = [(lu[root] + lv[v] - G[root][v], root) for v in V]\n        while True:\n            ((delta, u), v) = min((slack[v], v) for v in V if Av[v] is None)\n            assert au[u]\n            if delta > TOLERANCE:   # tree is full\n                for u0 in U:        # improve labels\n                    if au[u0]:\n                        lu[u0] -= delta\n                for v0 in V:\n                    if Av[v0] is not None:\n                        lv[v0] += delta\n                    else:\n                        (val, arg) = slack[v0]\n                        slack[v0] = (val - delta, arg)\n            assert abs(lu[u] + lv[v] - G[u][v]) <= TOLERANCE  # equality\n            Av[v] = u                # add (u, v) to A\n            if mv[v] is None:\n                break                # alternating path found\n            u1 = mv[v]\n            assert not au[u1]\n            au[u1] = True            # add (u1, v) to A\n            for v1 in V:\n                if Av[v1] is None:   # update margins\n                    alt = (lu[u1] + lv[v1] - G[u1][v1], u1)\n                    if slack[v1] > alt:\n                        slack[v1] = alt\n        while v is not None:         # ... alternating path found\n            u = Av[v]                # along path to root\n            prec = mu[u]\n            mv[v] = u                # augment matching\n            mu[u] = v\n            v = prec\n    return (mu,  sum(lu) + sum(lv))", "response": "Maximum profit bipartite matching by Kuhn - Munkres."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining a value that is contained in a largest number of given intervals", "response": "def max_interval_intersec(S):\n    \"\"\"determine a value that is contained in a largest number of given intervals\n\n    :param S: list of half open intervals\n    :complexity: O(n log n), where n = len(S)\n    \"\"\"\n    B = ([(left,  +1) for left, right in S] +\n         [(right, -1) for left, right in S])\n    B.sort()\n    c = 0\n    best = (c, None)\n    for x, d in B:\n        c += d\n        if best[0] < c:\n            best = (c, x)\n    return best"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dist_grid(grid, source, target=None):\n    rows = len(grid)\n    cols = len(grid[0])\n    dirs = [(0, +1, '>'), (0, -1, '<'), (+1, 0, 'v'), (-1, 0, '^')]\n    i, j = source\n    grid[i][j] = 's'\n    Q = deque()\n    Q.append(source)\n    while Q:\n        i1, j1 = Q.popleft()\n        for di, dj, symbol in dirs:   # explore all directions\n            i2 = i1 + di\n            j2 = j1 + dj\n            if not (0 <= i2 and i2 < rows and 0 <= j2 and j2 < cols):\n                continue              # reached the bounds of the grid\n            if grid[i2][j2] != ' ':   # inaccessible or already visited\n                continue\n            grid[i2][j2] = symbol     # mark visit\n            if (i2, j2) == target:\n                grid[i2][j2] = 't'    # goal is reached\n                return\n            Q.append((i2, j2))", "response": "Distances in a grid by BFS"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef range_min(self, i, k):\n        return self._range_min(1, 0, self.N, i, k)", "response": "returns the minimum value of the key i in the key set k"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the minimum in t in the indexes [ i k ) intersected by start + span", "response": "def _range_min(self, p, start, span, i, k):\n        \"\"\"returns the minimum in t in the indexes [i, k) intersected\n           with [start, start + span).\n           p is the node associated to the later interval.\n        \"\"\"\n        if start + span <= i or k <= start:        # disjoint intervals\n            return self.INF\n        if i <= start and start + span <= k:       # included intervals\n            return self.s[p]\n        left = self._range_min(2 * p, start, span // 2,\n                               i, k)\n        right = self._range_min(2 * p + 1, start + span // 2, span // 2,\n                                i, k)\n        return min(left, right)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmaintain the invariant for the given node", "response": "def _maintain(self, node):\n        \"\"\"maintains the invariant for the given node\n        :promize: the lazy values are None/0 for this node\n        \"\"\"\n        # requires node and its direct descends to be clean\n        l = 2 * node\n        r = 2 * node + 1\n        assert self.lazyset[node] is None\n        assert self.lazyadd[node] == 0\n        assert self.lazyset[l] is None\n        assert self.lazyadd[l] == 0\n        assert self.lazyset[r] is None\n        assert self.lazyadd[r] == 0\n        self.maxval[node] = max(self.maxval[l], self.maxval[r])\n        self.minval[node] = min(self.minval[l], self.minval[r])\n        self.sumval[node] = self.sumval[l] + self.sumval[r]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npropagate the lazy updates for this node to the subtrees.", "response": "def _clear(self, node, left, right):\n        \"\"\"propagates the lazy updates for this node to the subtrees.\n        as a result the maxval, minval, sumval values for the node\n        are up to date.\n        \"\"\"\n        if self.lazyset[node] is not None:  # first do the pending set\n            val = self.lazyset[node]\n            self.minval[node] = val\n            self.maxval[node] = val\n            self.sumval[node] = val * (right - left)\n            self.lazyset[node] = None\n            if left < right - 1:            # not a leaf\n                self.lazyset[2 * node] = val    # propagate to direct descendents\n                self.lazyadd[2 * node] = 0\n                self.lazyset[2 * node + 1] = val\n                self.lazyadd[2 * node + 1] = 0\n        if self.lazyadd[node] != 0:        # then do the pending add\n            val = self.lazyadd[node]\n            self.minval[node] += val\n            self.maxval[node] += val\n            self.sumval[node] += val * (right - left)\n            self.lazyadd[node] = 0\n            if left < right - 1:            # not at a leaf\n                self.lazyadd[2 * node] += val     # propagate to direct descendents\n                self.lazyadd[2 * node + 1] += val"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef left_right_inversions(tab):\n    n = len(tab)\n    left = [0] * n\n    right = [0] * n\n    tmp = [None] * n      # temporary table\n    rank = list(range(n))\n    _merge_sort(tab, tmp, rank, left, right, 0, n)\n    return left, right", "response": "Compute left and right inversions of each element of a table."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef interval_tree(intervals):\n    if intervals == []:\n        return None\n    center = intervals[len(intervals) // 2][0]\n    L = []\n    R = []\n    C = []\n    for I in intervals:\n        if I[1] <= center:\n            L.append(I)\n        elif center < I[0]:\n            R.append(I)\n        else:\n            C.append(I)\n    by_low = sorted((I[0], I) for I in C)\n    by_high = sorted((I[1], I) for I in C)\n    IL = interval_tree(L)\n    IR = interval_tree(R)\n    return _Node(center, by_low, by_high, IL, IR)", "response": "Construct an interval tree from a list of half - open intervals."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nquery the interval tree t for the root of the interval tree containing p", "response": "def intervals_containing(t, p):\n    \"\"\"Query the interval tree\n\n    :param t: root of the interval tree\n    :param p: value\n    :returns: a list of intervals containing p\n    :complexity: O(log n + m), where n is the number of intervals in t,\n                and m the length of the returned list\n    \"\"\"\n    INF = float('inf')\n    if t is None:\n        return []\n    if p < t.center:\n        retval = intervals_containing(t.left, p)\n        j = bisect_right(t.by_low, (p, (INF, INF)))\n        for i in range(j):\n            retval.append(t.by_low[i][1])\n    else:\n        retval = intervals_containing(t.right, p)\n        i = bisect_right(t.by_high, (p, (INF, INF)))\n        for j in range(i, len(t.by_high)):\n            retval.append(t.by_high[j][1])\n    return retval"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef andrew(S):\n    S.sort()\n    top = []\n    bot = []\n    for p in S:\n        while len(top) >= 2 and not left_turn(p, top[-1], top[-2]):\n            top.pop()\n        top.append(p)\n        while len(bot) >= 2 and not left_turn(bot[-2], bot[-1], p):\n            bot.pop()\n        bot.append(p)\n    return bot[:-1] + top[:0:-1]", "response": "Convex hull by Andrew"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef optimized_binary_search_lower(tab, logsize):\n    lo = 0\n    intervalsize = (1 << logsize) >> 1\n    while intervalsize > 0:\n        if not tab[lo | intervalsize]:\n            lo |= intervalsize\n        intervalsize >>= 1\n    return lo", "response": "Binary search in a table using bit operations"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef anagrams(w):\n    w = list(set(w))             # remove duplicates\n    d = {}                       # group words according to some signature\n    for i in range(len(w)):\n        s = ''.join(sorted(w[i]))  # signature\n        if s in d:\n            d[s].append(i)\n        else:\n            d[s] = [i]\n    # -- extract anagrams\n    answer = []\n    for s in d:\n        if len(d[s]) > 1:          # ignore words without anagram\n            answer.append([w[i] for i in d[s]])\n    return answer", "response": "group a list of words into anagrams\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tarjan(graph):\n    n = len(graph)\n    dfs_num = [None] * n\n    dfs_min = [n] * n\n    waiting = []\n    waits = [False] * n  # invariant: waits[v] iff v in waiting\n    sccp = []          # list of detected components\n    dfs_time = 0\n    times_seen = [-1] * n\n    for start in range(n):\n        if times_seen[start] == -1:                    # initiate path\n            times_seen[start] = 0\n            to_visit = [start]\n            while to_visit:\n                node = to_visit[-1]                    # top of stack\n                if times_seen[node] == 0:              # start process\n                    dfs_num[node] = dfs_time\n                    dfs_min[node] = dfs_time\n                    dfs_time += 1\n                    waiting.append(node)\n                    waits[node] = True\n                children = graph[node]\n                if times_seen[node] == len(children):  # end of process\n                    to_visit.pop()                     # remove from stack\n                    dfs_min[node] = dfs_num[node]      # compute dfs_min\n                    for child in children:\n                        if waits[child] and dfs_min[child] < dfs_min[node]:\n                            dfs_min[node] = dfs_min[child]\n                    if dfs_min[node] == dfs_num[node]:  # representative\n                        component = []                 # make component\n                        while True:                    # add nodes\n                            u = waiting.pop()\n                            waits[u] = False\n                            component.append(u)\n                            if u == node:              # until repr.\n                                break\n                        sccp.append(component)\n                else:\n                    child = children[times_seen[node]]\n                    times_seen[node] += 1\n                    if times_seen[child] == -1:        # not visited yet\n                        times_seen[child] = 0\n                        to_visit.append(child)\n    return sccp", "response": "Strongly connected components by Tarjan iterative implementation of the internal listlist format."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreverses the graph by removing all arcs ( u v ) in a graph", "response": "def reverse(graph):\n    \"\"\"replace all arcs (u, v) by arcs (v, u) in a graph\"\"\"\n    rev_graph = [[] for node in graph]\n    for node in range(len(graph)):\n        for neighbor in graph[node]:\n            rev_graph[neighbor].append(node)\n    return rev_graph"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef kosaraju(graph):\n    n = len(graph)\n    order = []\n    sccp = []\n    kosaraju_dfs(graph, range(n), order, [])\n    kosaraju_dfs(reverse(graph), order[::-1], [], sccp)\n    return sccp[::-1]", "response": "Strongly connected components by Kosaraju"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the directory level levels above base_dir.", "response": "def get_parent_dir(base_dir, level=1):\n    \"Get the directory $level levels above $base_dir.\"\n    while level > 0:\n        base_dir = os.path.dirname(base_dir)\n        level -= 1\n    return base_dir"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a ParsedTemplate instance based on the contents of .", "response": "def get_pystache_parsed(mustache_file):\n    \"\"\"Return a ParsedTemplate instance based on the contents of\n    $mustache_file.\"\"\"\n    with open(mustache_file, 'r') as file_:\n        parsed = pystache.parse(file_.read())\n    return parsed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_template_dirs():\n    temp_glob = rel_to_cwd('templates', '**', 'templates', 'config.yaml')\n    temp_groups = glob(temp_glob)\n    temp_groups = [get_parent_dir(path, 2) for path in temp_groups]\n    return set(temp_groups)", "response": "Return a set of all template directories."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a set of all scheme directories.", "response": "def get_scheme_dirs():\n    \"\"\"Return a set of all scheme directories.\"\"\"\n    scheme_glob = rel_to_cwd('schemes', '**', '*.yaml')\n    scheme_groups = glob(scheme_glob)\n    scheme_groups = [get_parent_dir(path) for path in scheme_groups]\n    return set(scheme_groups)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_scheme_files(patterns=None):\n    patterns = patterns or ['*']\n    pattern_list = ['{}.yaml'.format(pattern) for pattern in patterns]\n    scheme_files = []\n    for scheme_path in get_scheme_dirs():\n        for pattern in pattern_list:\n            file_paths = glob(os.path.join(scheme_path, pattern))\n            scheme_files.extend(file_paths)\n\n    return scheme_files", "response": "Return a list of all yaml files matching the given pattern."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchanging the given scheme so it can be applied to a template.", "response": "def format_scheme(scheme, slug):\n    \"\"\"Change $scheme so it can be applied to a template.\"\"\"\n    scheme['scheme-name'] = scheme.pop('scheme')\n    scheme['scheme-author'] = scheme.pop('author')\n    scheme['scheme-slug'] = slug\n    bases = ['base{:02X}'.format(x) for x in range(0, 16)]\n    for base in bases:\n        scheme['{}-hex'.format(base)] = scheme.pop(base)\n        scheme['{}-hex-r'.format(base)] = scheme['{}-hex'.format(base)][0:2]\n        scheme['{}-hex-g'.format(base)] = scheme['{}-hex'.format(base)][2:4]\n        scheme['{}-hex-b'.format(base)] = scheme['{}-hex'.format(base)][4:6]\n\n        scheme['{}-rgb-r'.format(base)] = str(\n            int(scheme['{}-hex-r'.format(base)], 16))\n        scheme['{}-rgb-g'.format(base)] = str(\n            int(scheme['{}-hex-g'.format(base)], 16))\n        scheme['{}-rgb-b'.format(base)] = str(\n            int(scheme['{}-hex-b'.format(base)], 16))\n\n        scheme['{}-dec-r'.format(base)] = str(\n            int(scheme['{}-rgb-r'.format(base)]) / 255)\n        scheme['{}-dec-g'.format(base)] = str(\n            int(scheme['{}-rgb-g'.format(base)]) / 255)\n        scheme['{}-dec-b'.format(base)] = str(\n            int(scheme['{}-rgb-b'.format(base)]) / 255)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nformatting the scheme file name to be used as a slug variable.", "response": "def slugify(scheme_file):\n    \"\"\"Format $scheme_file_name to be used as a slug variable.\"\"\"\n    scheme_file_name = os.path.basename(scheme_file)\n    if scheme_file_name.endswith('.yaml'):\n        scheme_file_name = scheme_file_name[:-5]\n    return scheme_file_name.lower().replace(' ', '-')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_single(scheme_file, templates, base_output_dir):\n    scheme = get_yaml_dict(scheme_file)\n    scheme_slug = slugify(scheme_file)\n    format_scheme(scheme, scheme_slug)\n\n    scheme_name = scheme['scheme-name']\n    print('Building colorschemes for scheme \"{}\"\u2026'.format(scheme_name))\n    for temp_group in templates:\n\n        for _, sub in temp_group.templates.items():\n            output_dir = os.path.join(base_output_dir,\n                                      temp_group.name,\n                                      sub['output'])\n            try:\n                os.makedirs(output_dir)\n            except FileExistsError:\n                pass\n\n            if sub['extension'] is not None:\n                filename = 'base16-{}{}'.format(scheme_slug, sub['extension'])\n            else:\n                filename = 'base16-{}'.format(scheme_slug)\n\n            build_path = os.path.join(output_dir, filename)\n            with open(build_path, 'w') as file_:\n                file_content = pystache.render(sub['parsed'], scheme)\n                file_.write(file_content)\n\n    print('Built colorschemes for scheme \"{}\".'.format(scheme_name))", "response": "Build a single color scheme for a single scheme_file using all templates in templates."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_single_worker(queue, templates, base_output_dir):\n    while True:\n        scheme_file = queue.get()\n        if scheme_file is None:\n            break\n        build_single(scheme_file, templates, base_output_dir)\n        queue.task_done()", "response": "Worker thread for building b16\n    templates using queue."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_from_job_list(scheme_files, templates, base_output_dir):\n    queue = Queue()\n    for scheme in scheme_files:\n        queue.put(scheme)\n\n    if len(scheme_files) < 40:\n        thread_num = len(scheme_files)\n    else:\n        thread_num = 40\n\n    threads = []\n    for _ in range(thread_num):\n        thread = Thread(target=build_single_worker,\n                        args=(queue, templates, base_output_dir))\n        thread.start()\n        threads.append(thread)\n\n    queue.join()\n\n    for _ in range(thread_num):\n        queue.put(None)\n\n    for thread in threads:\n        thread.join()", "response": "Use scheme_files as a job lists and build base16 templates using base16 templates."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_templates(self):\n        config_path = rel_to_cwd(self.base_path, 'templates', 'config.yaml')\n        templates = get_yaml_dict(config_path)\n        for temp, sub in templates.items():\n            mustache_path = os.path.join(get_parent_dir(config_path),\n                                         '{}.mustache'.format(temp))\n            sub['parsed'] = get_pystache_parsed(mustache_path)\n        return templates", "response": "Return a list of template_dicts based on the config. yaml in\n        base_path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_sources_file():\n    file_content = (\n        'schemes: '\n        'https://github.com/chriskempson/base16-schemes-source.git\\n'\n        'templates: '\n        'https://github.com/chriskempson/base16-templates-source.git'\n    )\n    file_path = rel_to_cwd('sources.yaml')\n    with open(file_path, 'w') as file_:\n        file_.write(file_content)", "response": "Write a sources. yaml file to current working dir."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef yaml_to_job_list(yaml_file, base_dir):\n    yaml_dict = get_yaml_dict(yaml_file)\n    job_list = []\n    for key, value in yaml_dict.items():\n        job_list.append((value, rel_to_cwd(base_dir, key)))\n\n    return job_list", "response": "Return a job_list consisting of git repos from a yaml file as well as\n    their base target directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncloning git repository at git_url to path.", "response": "def git_clone(git_url, path):\n    \"\"\"Clone git repository at $git_url to $path.\"\"\"\n    if os.path.exists(os.path.join(path, '.git')):\n        # get rid of local repo if it already exists\n        shutil.rmtree(path)\n\n    os.makedirs(path, exist_ok=True)\n    print('Start cloning from {}\u2026'.format(git_url))\n    git_proc = subprocess.Popen(['git', 'clone', git_url, path],\n                                stderr=subprocess.PIPE,\n                                stdout=subprocess.PIPE,\n                                env={'GIT_TERMINAL_PROMPT': '0'})\n\n    try:\n        stdoutmsg, stderrmsg = git_proc.communicate(timeout=120)\n    except subprocess.TimeoutExpired:\n        git_proc.kill()\n        stderrmsg = b'Timed out.'\n\n    if git_proc.returncode == 0:\n        print('Cloned {}.'.format(git_url))\n    else:\n        print('Error cloning from {}:\\n{}'.format(git_url,\n                                                  stderrmsg.decode('utf-8')))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef git_clone_worker(queue):\n    while True:\n        job = queue.get()\n        if job is None:\n            break\n        git_url, path = job\n        git_clone(git_url, path)\n        queue.task_done()", "response": "Worker thread for picking up git clone jobs from the queue until it receives None."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef git_clone_job_list(job_list):\n    queue = Queue()\n    for job in job_list:\n        queue.put(job)\n\n    if len(job_list) < 20:\n        thread_num = len(job_list)\n    else:\n        thread_num = 20\n\n    threads = []\n    for _ in range(thread_num):\n        thread = Thread(target=git_clone_worker, args=(queue, ))\n        thread.start()\n        threads.append(thread)\n\n    queue.join()\n\n    for _ in range(thread_num):\n        queue.put(None)\n\n    for thread in threads:\n        thread.join()", "response": "Deal with all git clone jobs in job_list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the sources. yaml file with the list of jobs.", "response": "def update(custom_sources=False):\n    \"\"\"Update function to be called from cli.py\"\"\"\n    if not shutil.which('git'):\n        print('Git executable not found in $PATH.')\n        sys.exit(1)\n\n    if not custom_sources:\n        print('Creating sources.yaml\u2026')\n        write_sources_file()\n        print('Cloning sources\u2026')\n        sources_file = rel_to_cwd('sources.yaml')\n        jobs = yaml_to_job_list(sources_file, rel_to_cwd('sources'))\n        git_clone_job_list(jobs)\n\n    print('Cloning templates\u2026')\n    jobs = yaml_to_job_list(rel_to_cwd('sources', 'templates', 'list.yaml'),\n                            rel_to_cwd('templates'))\n    print('Cloning schemes\u2026')\n    jobs.extend(yaml_to_job_list(rel_to_cwd('sources', 'schemes', 'list.yaml'),\n                                 rel_to_cwd('schemes')))\n    git_clone_job_list(jobs)\n    print('Completed updating repositories.')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a yaml_dict from reading yaml_file.", "response": "def get_yaml_dict(yaml_file):\n    \"\"\"Return a yaml_dict from reading yaml_file. If yaml_file is empty or\n    doesn't exist, return an empty dict instead.\"\"\"\n    try:\n        with open(yaml_file, 'r') as file_:\n            yaml_dict = yaml.safe_load(file_.read()) or {}\n        return yaml_dict\n    except FileNotFoundError:\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef inject_into_files(scheme_file, files):\n    for file_ in files:\n        rec = Recipient(file_)\n        colorscheme = rec.get_colorscheme(scheme_file)\n        rec.inject_scheme(colorscheme)\n        rec.write()", "response": "Injects a scheme into a list of files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a string representation file content at path.", "response": "def _get_file_content(self, path):\n        \"\"\"Return a string representation file content at $path.\"\"\"\n        with open(path, 'r') as file_:\n            content = file_.read()\n        return content"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_temp(self, content):\n        temp = None\n        for line in content.splitlines():\n\n            # make sure there's both start and end line\n            if not temp:\n                match = TEMP_NEEDLE.match(line)\n                if match:\n                    temp = match.group(1).strip()\n                    continue\n            else:\n                match = TEMP_END_NEEDLE.match(line)\n                if match:\n                    return temp\n\n        raise IndexError(self.path)", "response": "Get the string that points to a specific base16 scheme."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_colorscheme(self, scheme_file):\n        scheme = get_yaml_dict(scheme_file)\n        scheme_slug = builder.slugify(scheme_file)\n        builder.format_scheme(scheme, scheme_slug)\n\n        try:\n            temp_base, temp_sub = self.temp.split('##')\n        except ValueError:\n            temp_base, temp_sub = (self.temp.strip('##'), 'default')\n\n        temp_path = rel_to_cwd('templates', temp_base)\n        temp_group = builder.TemplateGroup(temp_path)\n        try:\n            single_temp = temp_group.templates[temp_sub]\n        except KeyError:\n            raise FileNotFoundError(None,\n                                    None,\n                                    self.path + ' (sub-template)')\n\n        colorscheme = pystache.render(single_temp['parsed'], scheme)\n        return colorscheme", "response": "Return a string object with the colorscheme that is to be\n        inserted."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninjects string b16_scheme into self. content.", "response": "def inject_scheme(self, b16_scheme):\n        \"\"\"Inject string $b16_scheme into self.content.\"\"\"\n        # correctly formatted start and end of block should have already been\n        # ascertained by _get_temp\n        content_lines = self.content.splitlines()\n        b16_scheme_lines = b16_scheme.splitlines()\n        start_line = None\n        for num, line in enumerate(content_lines):\n            if not start_line:\n                match = TEMP_NEEDLE.match(line)\n                if match:\n                    start_line = num + 1\n            else:\n                match = TEMP_END_NEEDLE.match(line)\n                if match:\n                    end_line = num\n\n        # put lines back together\n        new_content_lines = (content_lines[0:start_line]\n                             + b16_scheme_lines\n                             + content_lines[end_line:])\n        self.content = '\\n'.join(new_content_lines)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite content back to file.", "response": "def write(self):\n        \"\"\"Write content back to file.\"\"\"\n        with open(self.path, 'w') as file_:\n            file_.write(self.content)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_mode(arg_namespace):\n    custom_temps = arg_namespace.template or []\n    temp_paths = [rel_to_cwd('templates', temp) for temp in custom_temps]\n\n    try:\n        builder.build(templates=temp_paths,\n                      schemes=arg_namespace.scheme,\n                      base_output_dir=arg_namespace.output)\n    except (LookupError, PermissionError) as exception:\n        if isinstance(exception, LookupError):\n            print('Necessary resources for building not found in current '\n                  'working directory.')\n        if isinstance(exception, PermissionError):\n            print(\"No write permission for output directory.\")", "response": "Check command line arguments and run build function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck command line arguments and run build function.", "response": "def inject_mode(arg_namespace):\n    \"\"\"Check command line arguments and run build function.\"\"\"\n\n    try:\n        injector.inject_into_files(arg_namespace.scheme, arg_namespace.file)\n    except (IndexError, FileNotFoundError,\n            PermissionError, IsADirectoryError) as exception:\n        if isinstance(exception, IndexError):\n            print('\"{}\" has no valid injection marker lines.'.format(\n                exception.args[0]))\n        if isinstance(exception, FileNotFoundError):\n            print('Lacking resource \"{}\" to complete operation.'.format(\n                exception.filename))\n        if isinstance(exception, PermissionError):\n            print('No write permission for current working directory.')\n        if isinstance(exception, IsADirectoryError):\n            print('\"{}\" is a directory. Provide a *.yaml scheme file instead.'\n                  .format(exception.filename))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks command line arguments and run update function.", "response": "def update_mode(arg_namespace):\n    \"\"\"Check command line arguments and run update function.\"\"\"\n    try:\n        updater.update(custom_sources=arg_namespace.custom)\n    except (PermissionError, FileNotFoundError) as exception:\n        if isinstance(exception, PermissionError):\n            print('No write permission for current working directory.')\n        if isinstance(exception, FileNotFoundError):\n            print('Necessary resources for updating not found in current '\n                  'working directory.')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef script_to_address(script, vbyte=0):\n    '''\n    Like script_to_address but supports altcoins\n    Copied 2015-10-02 from https://github.com/mflaxman/pybitcointools/blob/faf56c53148989ea390238c3c4541a6ae1d601f5/bitcoin/transaction.py#L224-L236\n    '''\n    if re.match('^[0-9a-fA-F]*$', script):\n        script = binascii.unhexlify(script)\n    if script[:3] == b'\\x76\\xa9\\x14' and script[-2:] == b'\\x88\\xac' and len(script) == 25:\n        return bin_to_b58check(script[3:-2], vbyte)  # pubkey hash addresses\n    else:\n        if vbyte in [111, 196]:\n            # Testnet\n            scripthash_byte = 196\n        else:\n            scripthash_byte = vbyte\n        # BIP0016 scripthash addresses\n        return bin_to_b58check(script[2:-1], scripthash_byte)", "response": "Convert a script to an address."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _clean_tx(response_dict):\n    ''' Pythonize a blockcypher API response '''\n    confirmed_txrefs = []\n    for confirmed_txref in response_dict.get('txrefs', []):\n        confirmed_txref['confirmed'] = parser.parse(confirmed_txref['confirmed'])\n        confirmed_txrefs.append(confirmed_txref)\n    response_dict['txrefs'] = confirmed_txrefs\n\n    unconfirmed_txrefs = []\n    for unconfirmed_txref in response_dict.get('unconfirmed_txrefs', []):\n        unconfirmed_txref['received'] = parser.parse(unconfirmed_txref['received'])\n        unconfirmed_txrefs.append(unconfirmed_txref)\n    response_dict['unconfirmed_txrefs'] = unconfirmed_txrefs\n\n    return response_dict", "response": "Pythonize a blockcypher API response dict to include all the txrefs and unconfirmed txrefs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the details of an address in a blockchain.", "response": "def get_address_details(address, coin_symbol='btc', txn_limit=None, api_key=None, before_bh=None, after_bh=None, unspent_only=False, show_confidence=False, confirmations=0, include_script=False):\n    '''\n    Takes an address and coin_symbol and returns the address details\n\n    Optional:\n      - txn_limit: # transactions to include\n      - before_bh: filters response to only include transactions below before\n      height in the blockchain.\n      - after_bh: filters response to only include transactions above after\n      height in the blockchain.\n      - confirmations: returns the balance and TXRefs that have this number\n      of confirmations\n      - unspent_only: filters response to only include unspent TXRefs.\n      - show_confidence: adds confidence information to unconfirmed TXRefs.\n\n    For batching a list of addresses, see get_addresses_details\n    '''\n\n    assert is_valid_address_for_coinsymbol(\n            b58_address=address,\n            coin_symbol=coin_symbol), address\n    assert isinstance(show_confidence, bool), show_confidence\n\n    url = make_url(coin_symbol, **dict(addrs=address))\n\n    params = {}\n    if txn_limit:\n        params['limit'] = txn_limit\n    if api_key:\n        params['token'] = api_key\n    if before_bh:\n        params['before'] = before_bh\n    if after_bh:\n        params['after'] = after_bh\n    if confirmations:\n        params['confirmations'] = confirmations\n    if unspent_only:\n        params['unspentOnly'] = 'true'\n    if show_confidence:\n        params['includeConfidence'] = 'true'\n    if include_script:\n        params['includeScript'] = 'true'\n\n    r = requests.get(url, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    r = get_valid_json(r)\n\n    return _clean_tx(response_dict=r)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_addresses_details(address_list, coin_symbol='btc', txn_limit=None, api_key=None,\n        before_bh=None, after_bh=None, unspent_only=False, show_confidence=False,\n        confirmations=0, include_script=False):\n    '''\n    Batch version of get_address_details method\n    '''\n\n    for address in address_list:\n        assert is_valid_address_for_coinsymbol(\n                b58_address=address,\n                coin_symbol=coin_symbol), address\n    assert isinstance(show_confidence, bool), show_confidence\n\n    kwargs = dict(addrs=';'.join([str(addr) for addr in address_list]))\n    url = make_url(coin_symbol, **kwargs)\n\n    params = {}\n    if txn_limit:\n        params['limit'] = txn_limit\n    if api_key:\n        params['token'] = api_key\n    if before_bh:\n        params['before'] = before_bh\n    if after_bh:\n        params['after'] = after_bh\n    if confirmations:\n        params['confirmations'] = confirmations\n    if unspent_only:\n        params['unspentOnly'] = 'true'\n    if show_confidence:\n        params['includeConfidence'] = 'true'\n    if include_script:\n        params['includeScript'] = 'true'\n\n    r = requests.get(url, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    r = get_valid_json(r)\n    return [_clean_tx(response_dict=d) for d in r]", "response": "Get the details of a list of addresses."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_wallet_transactions(wallet_name, api_key, coin_symbol='btc',\n        before_bh=None, after_bh=None, txn_limit=None, omit_addresses=False,\n        unspent_only=False, show_confidence=False, confirmations=0):\n    '''\n    Takes a wallet, api_key, coin_symbol and returns the wallet's details\n\n\n    Optional:\n      - txn_limit: # transactions to include\n      - before_bh: filters response to only include transactions below before\n      height in the blockchain.\n      - after_bh: filters response to only include transactions above after\n      height in the blockchain.\n      - confirmations: returns the balance and TXRefs that have this number\n      of confirmations\n      - unspent_only: filters response to only include unspent TXRefs.\n      - show_confidence: adds confidence information to unconfirmed TXRefs.\n    '''\n\n    assert len(wallet_name) <= 25, wallet_name\n    assert api_key\n    assert is_valid_coin_symbol(coin_symbol=coin_symbol)\n    assert isinstance(show_confidence, bool), show_confidence\n    assert isinstance(omit_addresses, bool), omit_addresses\n\n    url = make_url(coin_symbol, **dict(addrs=wallet_name))\n\n    params = {}\n    if txn_limit:\n        params['limit'] = txn_limit\n    if api_key:\n        params['token'] = api_key\n    if before_bh:\n        params['before'] = before_bh\n    if after_bh:\n        params['after'] = after_bh\n    if confirmations:\n        params['confirmations'] = confirmations\n    if unspent_only:\n        params['unspentOnly'] = 'true'\n    if show_confidence:\n        params['includeConfidence'] = 'true'\n    if omit_addresses:\n        params['omitWalletAddresses'] = 'true'\n\n    r = requests.get(url, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    return _clean_tx(get_valid_json(r))", "response": "Takes a wallet api_key coin_symbol and returns the wallet s details."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake an address and coin_symbol and return the address details", "response": "def get_address_overview(address, coin_symbol='btc', api_key=None):\n    '''\n    Takes an address and coin_symbol and return the address details\n    '''\n\n    assert is_valid_address_for_coinsymbol(b58_address=address,\n            coin_symbol=coin_symbol)\n\n    url = make_url(coin_symbol, 'addrs', **{address: 'balance'})\n\n    params = {}\n    if api_key:\n        params['token'] = api_key\n\n    r = requests.get(url, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    return get_valid_json(r)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_new_address(coin_symbol='btc', api_key=None):\n    '''\n    Takes a coin_symbol and returns a new address with it's public and private keys.\n\n    This method will create the address server side, which is inherently insecure and should only be used for testing.\n\n    If you want to create a secure address client-side using python, please check out bitmerchant:\n\n        from bitmerchant.wallet import Wallet\n        Wallet.new_random_wallet()\n\n    https://github.com/sbuss/bitmerchant\n    '''\n\n    assert api_key, 'api_key required'\n    assert is_valid_coin_symbol(coin_symbol)\n\n    if coin_symbol not in ('btc-testnet', 'bcy'):\n        WARNING_MSG = [\n                'Generating private key details server-side.',\n                'You really should do this client-side.',\n                'See https://github.com/sbuss/bitmerchant for an example.',\n                ]\n        print(' '.join(WARNING_MSG))\n\n    url = make_url(coin_symbol, 'addrs')\n    params = {'token': api_key}\n\n    r = requests.post(url, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    return get_valid_json(r)", "response": "This method generates a new address with the given coin_symbol s public and private keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef derive_hd_address(api_key=None, wallet_name=None, num_addresses=1,\n        subchain_index=None, coin_symbol='btc'):\n    '''\n    Returns a new address (without access to the private key) and adds it to\n    your HD wallet (previously created using create_hd_wallet).\n\n    This method will traverse/discover a new address server-side from your\n    previously supplied extended public key, the server will never see your\n    private key. It is therefor safe for production use.\n\n    You may also include a subchain_index directive if your wallet has multiple\n    subchain_indices and you'd like to specify which one should be traversed.\n    '''\n\n    assert is_valid_coin_symbol(coin_symbol)\n    assert api_key, 'api_key required'\n    assert wallet_name, wallet_name\n    assert isinstance(num_addresses, int), num_addresses\n\n    url = make_url(coin_symbol, 'wallets/hd', **{wallet_name, 'addresses/derive'})\n    params = {'token': api_key}\n    if subchain_index:\n        params['subchain_index'] = subchain_index\n    if num_addresses > 1:\n        params['count'] = num_addresses\n\n    r = requests.post(url, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    return get_valid_json(r)", "response": "Derives a new HD address from a private key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_transaction_details(tx_hash, coin_symbol='btc', limit=None, tx_input_offset=None, tx_output_offset=None,\n        include_hex=False, show_confidence=False, confidence_only=False, api_key=None):\n    \"\"\"\n    Takes a tx_hash, coin_symbol, and limit and returns the transaction details\n\n    Optional:\n      - limit: # inputs/ouputs to include (applies to both)\n      - tx_input_offset: input offset\n      - tx_output_offset: output offset\n      - include_hex: include the raw TX hex\n      - show_confidence: adds confidence information to unconfirmed TXRefs.\n      - confidence_only: show only the confidence statistics and don't return the rest of the endpoint details (faster)\n\n    \"\"\"\n\n    assert is_valid_hash(tx_hash), tx_hash\n    assert is_valid_coin_symbol(coin_symbol), coin_symbol\n\n    added = 'txs/{}{}'.format(tx_hash, '/confidence' if confidence_only else  '')\n    url = make_url(coin_symbol, added)\n\n    params = {}\n    if api_key:\n        params['token'] = api_key\n    if limit:\n        params['limit'] = limit\n    if tx_input_offset:\n        params['inStart'] = tx_input_offset\n    if tx_output_offset:\n        params['outStart'] = tx_output_offset\n    if include_hex:\n        params['includeHex'] = 'true'\n    if show_confidence and not confidence_only:\n        params['includeConfidence'] = 'true'\n\n    r = requests.get(url, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    response_dict = get_valid_json(r)\n\n    if 'error' not in response_dict and not confidence_only:\n        if response_dict['block_height'] > 0:\n            response_dict['confirmed'] = parser.parse(response_dict['confirmed'])\n        else:\n            response_dict['block_height'] = None\n            # Blockcypher reports fake times if it's not in a block\n            response_dict['confirmed'] = None\n\n        # format this string as a datetime object\n        response_dict['received'] = parser.parse(response_dict['received'])\n\n    return response_dict", "response": "Takes a hash coin_symbol and limit and returns the transaction details."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake a list of tx_hashes coin_symbol and limit and returns the transaction details", "response": "def get_transactions_details(tx_hash_list, coin_symbol='btc', limit=None, api_key=None):\n    \"\"\"\n    Takes a list of tx_hashes, coin_symbol, and limit and returns the transaction details\n\n    Limit applies to both num inputs and num outputs.\n    TODO: add offsetting once supported\n    \"\"\"\n\n    for tx_hash in tx_hash_list:\n        assert is_valid_hash(tx_hash)\n    assert is_valid_coin_symbol(coin_symbol)\n\n    if len(tx_hash_list) == 0:\n        return []\n    elif len(tx_hash_list) == 1:\n        return [get_transaction_details(tx_hash=tx_hash_list[0],\n                                        coin_symbol=coin_symbol,\n                                        limit=limit,\n                                        api_key=api_key\n                                        )]\n\n        url = make_url(coin_symbol, **dict(txs=';'.join(tx_hash_list)))\n\n    params = {}\n    if api_key:\n        params['token'] = api_key\n    if limit:\n        params['limit'] = limit\n\n    r = requests.get(url, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    response_dict_list = get_valid_json(r)\n\n    cleaned_dict_list = []\n\n    for response_dict in response_dict_list:\n        if 'error' not in response_dict:\n            if response_dict['block_height'] > 0:\n                response_dict['confirmed'] = parser.parse(response_dict['confirmed'])\n            else:\n                # Blockcypher reports fake times if it's not in a block\n                response_dict['confirmed'] = None\n                response_dict['block_height'] = None\n\n            # format this string as a datetime object\n            response_dict['received'] = parser.parse(response_dict['received'])\n        cleaned_dict_list.append(response_dict)\n\n    return cleaned_dict_list"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_num_confirmations(tx_hash, coin_symbol='btc', api_key=None):\n    '''\n    Given a tx_hash, return the number of confirmations that transactions has.\n\n    Answer is going to be from 0 - current_block_height.\n    '''\n    return get_transaction_details(tx_hash=tx_hash, coin_symbol=coin_symbol,\n            limit=1, api_key=api_key).get('confirmations')", "response": "Given a tx_hash return the number of confirmations that transactions have."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a list of broadcast but unconfirmed transactions Similar to bitcoind s getrawmempool method", "response": "def get_broadcast_transactions(coin_symbol='btc', limit=10, api_key=None):\n    \"\"\"\n    Get a list of broadcast but unconfirmed transactions\n    Similar to bitcoind's getrawmempool method\n    \"\"\"\n    url = make_url(coin_symbol, 'txs')\n\n    params = {}\n    if api_key:\n        params['token'] = api_key\n    if limit:\n        params['limit'] = limit\n\n    r = requests.get(url, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    response_dict = get_valid_json(r)\n\n    unconfirmed_txs = []\n    for unconfirmed_tx in response_dict:\n        unconfirmed_tx['received'] = parser.parse(unconfirmed_tx['received'])\n        unconfirmed_txs.append(unconfirmed_tx)\n    return unconfirmed_txs"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a list of broadcast transactions.", "response": "def get_broadcast_transaction_hashes(coin_symbol='btc', api_key=None, limit=10):\n    '''\n    Warning, slow!\n    '''\n    transactions = get_broadcast_transactions(\n            coin_symbol=coin_symbol,\n            api_key=api_key,\n            limit=limit,\n            )\n\n    return [tx['hash'] for tx in transactions]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_block_overview(block_representation, coin_symbol='btc', txn_limit=None,\n        txn_offset=None, api_key=None):\n    \"\"\"\n    Takes a block_representation, coin_symbol and txn_limit and gets an overview\n    of that block, including up to X transaction ids.\n    Note that block_representation may be the block number or block hash\n    \"\"\"\n\n    assert is_valid_coin_symbol(coin_symbol)\n    assert is_valid_block_representation(\n            block_representation=block_representation,\n            coin_symbol=coin_symbol)\n\n    url = make_url(coin_symbol, **dict(blocks=block_representation))\n\n    params = {}\n    if api_key:\n        params['token'] = api_key\n    if txn_limit:\n        params['limit'] = txn_limit\n    if txn_offset:\n        params['txstart'] = txn_offset\n\n    r = requests.get(url, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    response_dict = get_valid_json(r)\n\n    if 'error' in response_dict:\n        return response_dict\n    return _clean_block(response_dict=response_dict)", "response": "Takes a block_representation coin_symbol and txn_limit and returns an overview of that block."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_blocks_overview(block_representation_list, coin_symbol='btc', txn_limit=None, api_key=None):\n    '''\n    Batch request version of get_blocks_overview\n    '''\n    for block_representation in block_representation_list:\n        assert is_valid_block_representation(\n                block_representation=block_representation,\n                coin_symbol=coin_symbol)\n    assert is_valid_coin_symbol(coin_symbol)\n\n    blocks = ';'.join([str(x) for x in block_representation_list])\n    url = make_url(coin_symbol, **dict(blocks=blocks))\n\n    logger.info(url)\n\n    params = {}\n    if api_key:\n        params['token'] = api_key\n    if txn_limit:\n        params['limit'] = txn_limit\n\n    r = requests.get(url, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    r = get_valid_json(r)\n    return [_clean_tx(response_dict=d) for d in r]", "response": "Batch request version of get_blocks_overview"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake a block_representation and returns the merkle root", "response": "def get_merkle_root(block_representation, coin_symbol='btc', api_key=None):\n    '''\n    Takes a block_representation and returns the merkle root\n    '''\n    return get_block_overview(block_representation=block_representation,\n            coin_symbol=coin_symbol, txn_limit=1, api_key=api_key)['mrkl_root']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_bits(block_representation, coin_symbol='btc', api_key=None):\n    '''\n    Takes a block_representation and returns the number of bits\n    '''\n    return get_block_overview(block_representation=block_representation,\n            coin_symbol=coin_symbol, txn_limit=1, api_key=api_key)['bits']", "response": "Takes a block_representation and returns the number of bits that are in the block."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_nonce(block_representation, coin_symbol='btc', api_key=None):\n    '''\n    Takes a block_representation and returns the nonce\n    '''\n    return get_block_overview(block_representation=block_representation,\n            coin_symbol=coin_symbol, txn_limit=1, api_key=api_key)['bits']", "response": "Takes a block_representation and returns the nonce"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_prev_block_hash(block_representation, coin_symbol='btc', api_key=None):\n    '''\n    Takes a block_representation and returns the previous block hash\n    '''\n    return get_block_overview(block_representation=block_representation,\n            coin_symbol=coin_symbol, txn_limit=1, api_key=api_key)['prev_block']", "response": "Takes a block_representation and returns the previous block hash"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake a block_height and returns the block_hash", "response": "def get_block_hash(block_height, coin_symbol='btc', api_key=None):\n    '''\n    Takes a block_height and returns the block_hash\n    '''\n    return get_block_overview(block_representation=block_height,\n            coin_symbol=coin_symbol, txn_limit=1, api_key=api_key)['hash']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_block_height(block_hash, coin_symbol='btc', api_key=None):\n    '''\n    Takes a block_hash and returns the block_height\n    '''\n    return get_block_overview(block_representation=block_hash,\n            coin_symbol=coin_symbol, txn_limit=1, api_key=api_key)['height']", "response": "Takes a block_hash and returns the block_height"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_block_details(block_representation, coin_symbol='btc', txn_limit=None,\n        txn_offset=None, in_out_limit=None, api_key=None):\n    \"\"\"\n    Takes a block_representation, coin_symbol and txn_limit and\n    1) Gets the block overview\n    2) Makes a separate API call to get specific data on txn_limit transactions\n\n    Note: block_representation may be the block number or block hash\n\n    WARNING: using a high txn_limit will make this *extremely* slow.\n    \"\"\"\n\n    assert is_valid_coin_symbol(coin_symbol)\n\n    block_overview = get_block_overview(\n            block_representation=block_representation,\n            coin_symbol=coin_symbol,\n            txn_limit=txn_limit,\n            txn_offset=txn_offset,\n            api_key=api_key,\n            )\n\n    if 'error' in block_overview:\n        return block_overview\n\n    txids_to_lookup = block_overview['txids']\n\n    txs_details = get_transactions_details(\n            tx_hash_list=txids_to_lookup,\n            coin_symbol=coin_symbol,\n            limit=in_out_limit,\n            api_key=api_key,\n            )\n\n    if 'error' in txs_details:\n        return txs_details\n\n    # build comparator dict to use for fast sorting of batched results later\n    txids_comparator_dict = {}\n    for cnt, tx_id in enumerate(txids_to_lookup):\n        txids_comparator_dict[tx_id] = cnt\n\n    # sort results using comparator dict\n    block_overview['txids'] = sorted(\n            txs_details,\n            key=lambda k: txids_comparator_dict.get(k.get('hash'), 9999),  # anything that fails goes last\n            )\n\n    return block_overview", "response": "Takes a block_representation coin_symbol and txn_limit and returns the block overview"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_blockchain_fee_estimates(coin_symbol='btc', api_key=None):\n    overview = get_blockchain_overview(coin_symbol=coin_symbol, api_key=api_key)\n    return {\n            'high_fee_per_kb': overview['high_fee_per_kb'],\n            'medium_fee_per_kb': overview['medium_fee_per_kb'],\n            'low_fee_per_kb': overview['low_fee_per_kb'],\n            }", "response": "Returns high medium and low fee estimates for a given blockchain."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_forwarding_address_details(destination_address, api_key, callback_url=None, coin_symbol='btc'):\n\n    assert is_valid_coin_symbol(coin_symbol)\n    assert api_key, 'api_key required'\n\n    url = make_url(coin_symbol, 'payments')\n    logger.info(url)\n\n    params = {'token': api_key}\n    data = {\n            'destination': destination_address,\n            }\n\n    if callback_url:\n        data['callback_url'] = callback_url\n\n    r = requests.post(url, json=data, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    return get_valid_json(r)", "response": "Get details of the destination address and return the details of the input address that will automatically forward to the destination address"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_forwarding_address(destination_address, api_key, callback_url=None, coin_symbol='btc'):\n    assert api_key, 'api_key required'\n\n    resp_dict = get_forwarding_address_details(\n            destination_address=destination_address,\n            api_key=api_key,\n            callback_url=callback_url,\n            coin_symbol=coin_symbol\n            )\n\n    return resp_dict['input_address']", "response": "Get the forwarding address for a blockcypher virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_forwarding_addresses(api_key, offset=None, coin_symbol='btc'):\n    '''\n    List the forwarding addresses for a certain api key\n    (and on a specific blockchain)\n    '''\n\n    assert is_valid_coin_symbol(coin_symbol)\n    assert api_key\n\n    url = make_url(coin_symbol, 'payments')\n\n    params = {'token': api_key}\n\n    if offset:\n        params['start'] = offset\n\n    r = requests.get(url, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    return get_valid_json(r)", "response": "List the forwarding addresses for a specific api key and on a specific blockchain"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_forwarding_address(payment_id, coin_symbol='btc', api_key=None):\n    '''\n    Delete a forwarding address on a specific blockchain, using its\n    payment id\n    '''\n\n    assert payment_id, 'payment_id required'\n    assert is_valid_coin_symbol(coin_symbol)\n    assert api_key, 'api_key required'\n\n    params = {'token': api_key}\n\n    url = make_url(**dict(payments=payment_id))\n\n    r = requests.delete(url, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    return get_valid_json(r, allow_204=True)", "response": "Delete a forwarding address on a specific blockchain using its\n    payment id"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef subscribe_to_address_webhook(callback_url, subscription_address, event='tx-confirmation', confirmations=0, confidence=0.00, coin_symbol='btc', api_key=None):\n    '''\n    Subscribe to transaction webhooks on a given address.\n    Webhooks for transaction broadcast and each confirmation (up to 6).\n\n    Returns the blockcypher ID of the subscription\n    '''\n    assert is_valid_coin_symbol(coin_symbol)\n    assert is_valid_address_for_coinsymbol(subscription_address, coin_symbol)\n    assert api_key, 'api_key required'\n\n    url = make_url(coin_symbol, 'hooks')\n\n    params = {'token': api_key}\n    data = {\n        'event': event,\n        'url': callback_url,\n        'address': subscription_address,\n    }\n\n    if event == 'tx-confirmation' and confirmations:\n        data['confirmations'] = confirmations\n    elif event == 'tx-confidence' and confidence:\n        data['confidence'] = confidence\n\n    r = requests.post(url, json=data, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    response_dict = get_valid_json(r)\n    return response_dict['id']", "response": "Subscribe to transaction webhooks on a given address."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef subscribe_to_wallet_webhook(callback_url, wallet_name,\n        event='tx-confirmation', coin_symbol='btc', api_key=None):\n    '''\n    Subscribe to transaction webhooks on a given address.\n    Webhooks for transaction broadcast and each confirmation (up to 6).\n\n    Returns the blockcypher ID of the subscription\n    '''\n    assert is_valid_coin_symbol(coin_symbol)\n    assert is_valid_wallet_name(wallet_name), wallet_name\n    assert api_key, 'api_key required'\n\n    url = make_url(coin_symbol, 'hooks')\n\n    params = {'token': api_key}\n    data = {\n        'event': event,\n        'url': callback_url,\n        'wallet_name': wallet_name,\n    }\n\n    r = requests.post(url, json=data, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    response_dict = get_valid_json(r)\n    return response_dict['id']", "response": "Subscribe to transaction webhooks on a given address."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_faucet_coins(address_to_fund, satoshis, api_key, coin_symbol='bcy'):\n    '''\n    Send yourself test coins on the bitcoin or blockcypher testnet\n\n    You can see your balance info at:\n    - https://live.blockcypher.com/bcy/ for BCY\n    - https://live.blockcypher.com/btc-testnet/ for BTC Testnet\n    '''\n    assert coin_symbol in ('bcy', 'btc-testnet')\n    assert is_valid_address_for_coinsymbol(b58_address=address_to_fund, coin_symbol=coin_symbol)\n    assert satoshis > 0\n    assert api_key, 'api_key required'\n\n    url = make_url(coin_symbol, 'faucet')\n\n    data = {\n            'address': address_to_fund,\n            'amount': satoshis,\n            }\n    params = {'token': api_key}\n\n    r = requests.post(url, json=data, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    return get_valid_json(r)", "response": "Send a fund test coins on the bitcoin or blockcypher testnet"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake a signed transaction hex binary and coin_symbol and broadcasts it to the bitcoin network.", "response": "def pushtx(tx_hex, coin_symbol='btc', api_key=None):\n    '''\n    Takes a signed transaction hex binary (and coin_symbol) and broadcasts it to the bitcoin network.\n    '''\n\n    assert is_valid_coin_symbol(coin_symbol)\n    assert api_key, 'api_key required'\n\n    url = _get_pushtx_url(coin_symbol=coin_symbol)\n\n    logger.info(url)\n\n    data = {'tx': tx_hex}\n\n    params = {'token': api_key}\n\n    r = requests.post(url, json=data, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    return get_valid_json(r)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake a signed transaction hex binary and coin_symbol and decodes it to JSON.", "response": "def decodetx(tx_hex, coin_symbol='btc', api_key=None):\n    '''\n    Takes a signed transaction hex binary (and coin_symbol) and decodes it to JSON.\n\n    Does NOT broadcast the transaction to the bitcoin network.\n    Especially useful for testing/debugging and sanity checking\n    '''\n\n    assert is_valid_coin_symbol(coin_symbol)\n    assert api_key, 'api_key required'\n\n    url = make_url(coin_symbol, **dict(txs='decode'))\n\n    params = {'token': api_key}\n    data = {\n        'tx': tx_hex,\n        'token': api_key,\n    }\n\n    r = requests.post(url, json=data, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    return get_valid_json(r)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_wallet_names(api_key, is_hd_wallet=False, coin_symbol='btc'):\n    ''' Get all the wallets belonging to an API key '''\n    assert is_valid_coin_symbol(coin_symbol), coin_symbol\n    assert api_key\n\n    params = {'token': api_key}\n\n    kwargs = dict(wallets='hd' if is_hd_wallet else '')\n    url = make_url(coin_symbol, **kwargs)\n\n    r = requests.get(url, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    return get_valid_json(r)", "response": "Get all the wallets belonging to an API key"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new wallet with one address", "response": "def create_wallet_from_address(wallet_name, address, api_key, coin_symbol='btc'):\n    '''\n    Create a new wallet with one address\n\n    You can add addresses with the add_address_to_wallet method below\n    You can delete the wallet with the delete_wallet method below\n    '''\n    assert is_valid_address_for_coinsymbol(address, coin_symbol)\n    assert api_key\n    assert is_valid_wallet_name(wallet_name), wallet_name\n\n    data = {\n            'name': wallet_name,\n            'addresses': [address, ],\n            }\n    params = {'token': api_key}\n\n    url = make_url(coin_symbol, 'wallets')\n    r = requests.post(url, json=data, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    return get_valid_json(r)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_hd_wallet(wallet_name, xpubkey, api_key, subchain_indices=[], coin_symbol='btc'):\n    '''\n    Create a new wallet from an extended pubkey (xpub... for BTC)\n\n    You can delete the wallet with the delete_wallet method below\n    '''\n    inferred_coin_symbol = coin_symbol_from_mkey(mkey=xpubkey)\n    if inferred_coin_symbol:\n        assert inferred_coin_symbol == coin_symbol\n    assert api_key, 'api_key required'\n    assert len(wallet_name) <= 25, wallet_name\n\n    data = {\n            'name': wallet_name,\n            'extended_public_key': xpubkey,\n            }\n    params = {'token': api_key}\n\n    if subchain_indices:\n        data['subchain_indexes'] = subchain_indices\n\n    url = make_url(coin_symbol, **dict(wallets='hd'))\n\n    r = requests.post(url, json=data, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    return get_valid_json(r)", "response": "Create a new HD wallet from an extended pubkey"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of wallet addresses as well as some meta - data", "response": "def get_wallet_addresses(wallet_name, api_key, is_hd_wallet=False,\n        zero_balance=None, used=None, omit_addresses=False, coin_symbol='btc'):\n    '''\n    Returns a list of wallet addresses as well as some meta-data\n    '''\n    assert is_valid_coin_symbol(coin_symbol)\n    assert api_key\n    assert len(wallet_name) <= 25, wallet_name\n    assert zero_balance in (None, True, False)\n    assert used in (None, True, False)\n    assert isinstance(omit_addresses, bool), omit_addresses\n\n    params = {'token': api_key}\n    kwargs = {'hd/' if is_hd_wallet else '': wallet_name} # hack!\n    url = make_url(coin_symbol, 'wallets', **kwargs)\n\n    if zero_balance is True:\n        params['zerobalance'] = 'true'\n    elif zero_balance is False:\n        params['zerobalance'] = 'false'\n    if used is True:\n        params['used'] = 'true'\n    elif used is False:\n        params['used'] = 'false'\n    if omit_addresses:\n        params['omitWalletAddresses'] = 'true'\n\n    r = requests.get(url, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    return get_valid_json(r)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_unsigned_tx(inputs, outputs, change_address=None,\n        include_tosigntx=False, verify_tosigntx=False, min_confirmations=0,\n        preference='high', coin_symbol='btc', api_key=None):\n    '''\n    Create a new transaction to sign. Doesn't ask for or involve private keys.\n    Behind the scenes, blockcypher will:\n    1) Fetch unspent outputs\n    2) Decide which make the most sense to consume for the given transaction\n    3) Return an unsigned transaction for you to sign\n\n    min_confirmations is the minimum number of confirmations an unspent output\n    must have in order to be included in a transaction\n\n    tosign_tx is the raw tx which can be decoded to verify the transaction\n    you're signing matches what you want to sign. You can also verify:\n    sha256(sha256(tosign_tx))== tosign\n\n    verify_tosigntx will take the raw tx data in tosign_tx and run the\n    verification for you and protect you against a malicious or compromised\n    blockcypher server\n\n    Inputs is a list of either:\n    - {'address': '1abcxyz...'} that will be included in the TX\n    - {'pubkeys' : [pubkey1, pubkey2, pubkey3], \"script_type\": \"multisig-2-of-3\"}\n    - {'wallet_name': 'bar', 'wallet_token': 'yourtoken'} that was previously registered and will be used\n      to choose which addresses/inputs are included in the TX\n\n    Note that for consistency with the API `inputs` is always a list.\n    Currently, it is a singleton list, but it is possible it could have more elements in future versions.\n\n    Details here: http://dev.blockcypher.com/#generic_transactions\n    '''\n\n    # Lots of defensive checks\n    assert isinstance(inputs, list), inputs\n    assert isinstance(outputs, list), outputs\n    assert len(inputs) >= 1, inputs\n    assert len(outputs) >= 1, outputs\n\n    inputs_cleaned = []\n    for input_obj in inputs:\n        # `input` is a reserved word\n        if 'address' in input_obj:\n            address = input_obj['address']\n            assert is_valid_address_for_coinsymbol(\n                    b58_address=address,\n                    coin_symbol=coin_symbol,\n                    ), address\n            inputs_cleaned.append({\n                'addresses': [address, ],\n                })\n        elif 'pubkeys' in input_obj and input_obj.get('script_type', '').startswith('multisig-'):\n            for pubkey in input_obj['pubkeys']:\n                # TODO: better pubkey test\n                assert uses_only_hash_chars(pubkey), pubkey\n            inputs_cleaned.append({\n                'addresses': input_obj['pubkeys'],\n                'script_type': input_obj['script_type'],\n                })\n        elif 'wallet_name' in input_obj and 'wallet_token' in input_obj:\n            # good behavior\n            inputs_cleaned.append(input_obj)\n        else:\n            raise Exception('Invalid Input: %s' % input_obj)\n\n    outputs_cleaned = []\n    sweep_funds = False\n    for output in outputs:\n        clean_output = {}\n        assert 'value' in output, output\n        assert isinstance(output['value'], int), output['value']\n        if output['value'] == -1:\n            sweep_funds = True\n            assert not change_address, 'Change Address Supplied for Sweep TX'\n        clean_output['value'] = output['value']\n\n        # no address required for null-data outputs\n        if output.get('script_type') == 'null-data':\n            assert output['value'] == 0\n            assert 'script' in output, output\n            clean_output['script_type'] = 'null-data'\n            clean_output['script'] = output['script']\n        # but note that API requires the singleton list 'addresses' which is\n        # intentionally hidden away from the user here\n        else:\n            assert 'address' in output, output\n            assert is_valid_address_for_coinsymbol(b58_address=output['address'],\n                                                   coin_symbol=coin_symbol,\n                                                  )\n            clean_output['addresses'] = [output['address']]\n        outputs_cleaned.append(clean_output)\n\n    if change_address:\n        assert is_valid_address_for_coinsymbol(b58_address=change_address,\n                                               coin_symbol=coin_symbol), change_address\n\n    assert preference in ('high', 'medium', 'low', 'zero'), preference\n\n    # Beginning of method code\n    url = make_url(coin_symbol, **dict(txs='new'))\n\n    data = {\n        'inputs': inputs_cleaned,\n        'outputs': outputs_cleaned,\n        'preference': preference,\n    }\n    if min_confirmations:\n        data['confirmations'] = min_confirmations\n    if change_address:\n        data['change_address'] = change_address\n\n    if include_tosigntx or verify_tosigntx:\n        params = {'includeToSignTx': 'true'}  # Nasty hack\n    else:\n        params = {}\n\n    # Nasty Hack - remove when API updated\n    if 'wallet_token' in inputs[0]:\n        params['token'] = inputs[0]['wallet_token']\n    elif api_key:\n        params['token'] = api_key\n    else:\n        raise Exception('No API Token Supplied')\n\n    r = requests.post(url, json=data, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    unsigned_tx = get_valid_json(r)\n\n    if verify_tosigntx:\n        tx_is_correct, err_msg = verify_unsigned_tx(\n            unsigned_tx=unsigned_tx,\n            inputs=inputs,\n            outputs=outputs,\n            sweep_funds=sweep_funds,\n            change_address=change_address,\n            coin_symbol=coin_symbol,\n            )\n        if not tx_is_correct:\n            print(unsigned_tx)  # for debug\n            raise Exception('TX Verification Error: %s' % err_msg)\n\n    return unsigned_tx", "response": "Create an unsigned transaction for a blockcypher server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef verify_unsigned_tx(unsigned_tx, outputs, inputs=None, sweep_funds=False,\n                       change_address=None, coin_symbol='btc'):\n    '''\n    Takes an unsigned transaction and what was used to build it (in\n    create_unsigned_tx) and verifies that tosign_tx matches what is being\n    signed and what was requestsed to be signed.\n\n    Returns if valid:\n        (True, '')\n    Returns if invalid:\n        (False, 'err_msg')\n\n    Specifically, this checks that the outputs match what we're expecting\n    (bad inputs would fail signature anyway).\n\n    Note: it was a mistake to include `inputs` in verify_unsigned_tx as it by definition is not used.\n    It would be removed but that would break compatibility.\n    '''\n\n    if not (change_address or sweep_funds):\n        err_msg = 'Cannot Verify Without Developer Supplying Change Address (or Sweeping)'\n        return False, err_msg\n\n    if 'tosign_tx' not in unsigned_tx:\n        err_msg = 'tosign_tx not in API response:\\n%s' % unsigned_tx\n        return False, err_msg\n\n    output_addr_list = [x['address'] for x in outputs if x.get('address') != None]\n    if change_address:\n        output_addr_list.append(change_address)\n\n    assert len(unsigned_tx['tosign_tx']) == len(unsigned_tx['tosign']), unsigned_tx\n    for cnt, tosign_tx_toverify in enumerate(unsigned_tx['tosign_tx']):\n\n        # Confirm tosign is the dsha256 of tosign_tx\n        if double_sha256(tosign_tx_toverify) != unsigned_tx['tosign'][cnt]:\n            err_msg = 'double_sha256(%s) =! %s' % (tosign_tx_toverify, unsigned_tx['tosign'][cnt])\n            print(unsigned_tx)\n            return False, err_msg\n\n        try:\n            txn_outputs_response_dict = get_txn_outputs_dict(raw_tx_hex=tosign_tx_toverify,\n                                                             output_addr_list=output_addr_list,\n                                                             coin_symbol=coin_symbol)\n        except Exception as inst:\n            # Could be wrong output addresses, keep print statement for debug\n            print(unsigned_tx)\n            print(coin_symbol)\n            return False, str(inst)\n\n        if sweep_funds:\n            # output adresses are already confirmed in `get_txn_outputs`,\n            # which was called by `get_txn_outputs_dict`\n            # no point in confirming values for a sweep\n            continue\n\n        else:\n            # get rid of change address as tx fee (which affects value)\n            # is determined by blockcypher and can't be known up front\n            try:\n                txn_outputs_response_dict.pop(change_address)\n            except KeyError:\n                # This is possible in the case of change address not needed\n                pass\n\n        user_outputs = compress_txn_outputs(outputs)\n        if txn_outputs_response_dict != user_outputs:\n            # TODO: more helpful error message\n            err_msg = 'API Response Ouputs != Supplied Outputs\\n\\n%s\\n\\n%s' % (\n                    txn_outputs_response_dict, user_outputs)\n            return False, err_msg\n\n    return True, ''", "response": "Verify that an unsigned transaction is signed and that it has the correct outputs and inputs."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake a list of transactions and signs them using the privkey_list and pubkey_list.", "response": "def make_tx_signatures(txs_to_sign, privkey_list, pubkey_list):\n    \"\"\"\n    Loops through txs_to_sign and makes signatures using privkey_list and pubkey_list\n\n    Not sure what privkeys and pubkeys to supply?\n    Use get_input_addresses() to return a list of addresses.\n    Matching those addresses to keys is up to you and how you store your private keys.\n    A future version of this library may handle this for you, but it is not trivial.\n\n    Note that if spending multisig funds the process is significantly more complicated.\n    Each tx_to_sign must be signed by *each* private key.\n    In a 2-of-3 transaction, two of [privkey1, privkey2, privkey3] must sign each tx_to_sign\n\n    http://dev.blockcypher.com/#multisig-transactions\n    \"\"\"\n    assert len(privkey_list) == len(pubkey_list) == len(txs_to_sign)\n    # in the event of multiple inputs using the same pub/privkey,\n    # that privkey should be included multiple times\n\n    signatures = []\n    for cnt, tx_to_sign in enumerate(txs_to_sign):\n        sig = der_encode_sig(*ecdsa_raw_sign(tx_to_sign.rstrip(' \\t\\r\\n\\0'), privkey_list[cnt]))\n        err_msg = 'Bad Signature: sig %s for tx %s with pubkey %s' % (\n            sig,\n            tx_to_sign,\n            pubkey_list[cnt],\n            )\n        assert ecdsa_raw_verify(tx_to_sign, der_decode_sig(sig), pubkey_list[cnt]), err_msg\n        signatures.append(sig)\n    return signatures"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef broadcast_signed_transaction(unsigned_tx, signatures, pubkeys, coin_symbol='btc', api_key=None):\n    '''\n    Broadcasts the transaction from create_unsigned_tx\n    '''\n\n    assert 'errors' not in unsigned_tx, unsigned_tx\n    assert api_key, 'api_key required'\n\n    url = make_url(coin_symbol, **dict(txs='send'))\n\n    data = unsigned_tx.copy()\n    data['signatures'] = signatures\n    data['pubkeys'] = pubkeys\n\n    params = {'token': api_key}\n\n    r = requests.post(url, params=params, json=data, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    response_dict = get_valid_json(r)\n\n    if response_dict.get('tx') and response_dict.get('received'):\n        response_dict['tx']['received'] = parser.parse(response_dict['tx']['received'])\n\n    return response_dict", "response": "Broadcasts the signed transaction from create_unsigned_tx\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef simple_spend_p2sh(all_from_pubkeys, from_privkeys_to_use, to_address, to_satoshis,\n        change_address=None, min_confirmations=0, api_key=None, coin_symbol='btc'):\n    '''\n    Simple method to spend from a p2sh address.\n\n    all_from_pubkeys is a list of *all* pubkeys for the address in question.\n\n    from_privkeys_to_use is a list of all privkeys that will be used to sign the tx (and no more).\n    If the address is a 2-of-3 multisig and you supply 1 (or 3) from_privkeys_to_use this will break.\n\n    Signature takes place locally (client-side) after unsigned transaction is verified.\n\n    Returns the tx_hash of the newly broadcast tx.\n\n    A change_address *must* be specified, except for a sweep (set to_satoshis = -1)\n\n    Note that this currently only supports compressed private keys.\n    '''\n\n    assert is_valid_coin_symbol(coin_symbol), coin_symbol\n    assert isinstance(to_satoshis, int), to_satoshis\n    assert api_key, 'api_key required'\n\n    if change_address:\n        err_msg = '%s not a valid address for %s' % (change_address, coin_symbol)\n        assert is_valid_address_for_coinsymbol(change_address, coin_symbol), err_msg\n    else:\n        assert to_satoshis == -1, 'you must supply a change address or sweep'\n\n    err_msg = '%s not a valid address for %s' % (to_address, coin_symbol)\n    assert is_valid_address_for_coinsymbol(to_address, coin_symbol), err_msg\n\n    # TODO: calculate from address from pubkeys\n    # err_msg = '%s is not a p2sh address' % to_address\n    # assert from_address[0] in COIN_SYMBOL_MAPPINGS[coin_symbol]['multisig_prefix_list'], err_msg\n\n    assert isinstance(all_from_pubkeys, (list, tuple))\n    assert len(all_from_pubkeys) > 1\n\n    assert isinstance(from_privkeys_to_use, (list, tuple)), from_privkeys_to_use\n\n    for from_privkey in from_privkeys_to_use:\n        from_pubkey = compress(privkey_to_pubkey(from_privkey))\n        err_msg = '%s not in %s' % (from_pubkey, all_from_pubkeys)\n        assert from_pubkey in all_from_pubkeys\n\n    script_type = 'multisig-%s-of-%s' % (\n            len(from_privkeys_to_use),\n            len(all_from_pubkeys),\n            )\n    inputs = [\n            {\n                'pubkeys': all_from_pubkeys,\n                'script_type': script_type,\n                },\n            ]\n    logger.info('inputs: %s' % inputs)\n    outputs = [{'address': to_address, 'value': to_satoshis}, ]\n    logger.info('outputs: %s' % outputs)\n\n    # will fail loudly if tx doesn't verify client-side\n    unsigned_tx = create_unsigned_tx(\n        inputs=inputs,\n        outputs=outputs,\n        # may build with no change address, but if so will verify change in next step\n        # done for extra security in case of client-side bug in change address generation\n        change_address=change_address,\n        coin_symbol=coin_symbol,\n        min_confirmations=min_confirmations,\n        verify_tosigntx=False,  # will verify in next step\n        include_tosigntx=True,\n        api_key=api_key,\n        )\n    logger.info('unsigned_tx: %s' % unsigned_tx)\n\n    if 'errors' in unsigned_tx:\n        print('TX Error(s): Tx NOT Signed or Broadcast')\n        for error in unsigned_tx['errors']:\n            print(error['error'])\n        # Abandon\n        raise Exception('Build Unsigned TX Error')\n\n    tx_is_correct, err_msg = verify_unsigned_tx(\n            unsigned_tx=unsigned_tx,\n            inputs=None,\n            outputs=outputs,\n            sweep_funds=bool(to_satoshis == -1),\n            change_address=change_address,\n            coin_symbol=coin_symbol,\n            )\n    if not tx_is_correct:\n        print(unsigned_tx)  # for debug\n        raise Exception('TX Verification Error: %s' % err_msg)\n\n    txs_to_sign, privkey_list, pubkey_list = [], [], []\n    for cnt, proposed_input in enumerate(unsigned_tx['tx']['inputs']):\n\n        # confirm that the input matches the all_from_pubkeys\n        err_msg = 'Invalid input: %s != %s' % (\n                proposed_input['addresses'],\n                all_from_pubkeys,\n                )\n        assert set(proposed_input['addresses']) == set(all_from_pubkeys), err_msg\n\n        # build items to pass to make_tx_signatures\n        for from_privkey in from_privkeys_to_use:\n            txs_to_sign.append(unsigned_tx['tosign'][cnt])\n            privkey_list.append(from_privkey)\n            pubkey_list.append(compress(privkey_to_pubkey(from_privkey)))\n    logger.info('txs_to_sign: %s' % txs_to_sign)\n    # logger.info('privkey_list: %s' % privkey_list)\n    logger.info('pubkey_list: %s' % pubkey_list)\n\n    # sign locally\n    tx_signatures = make_tx_signatures(\n            txs_to_sign=txs_to_sign,\n            privkey_list=privkey_list,\n            pubkey_list=pubkey_list,\n            )\n    logger.info('tx_signatures: %s' % tx_signatures)\n\n    # broadcast TX\n    broadcasted_tx = broadcast_signed_transaction(\n            unsigned_tx=unsigned_tx,\n            signatures=tx_signatures,\n            pubkeys=pubkey_list,\n            coin_symbol=coin_symbol,\n            api_key=api_key,\n    )\n    logger.info('broadcasted_tx: %s' % broadcasted_tx)\n\n    if 'errors' in broadcasted_tx:\n        print('TX Error(s): Tx May NOT Have Been Broadcast')\n        for error in broadcasted_tx['errors']:\n            print(error['error'])\n        print(broadcasted_tx)\n        return\n\n    return broadcasted_tx['tx']['hash']", "response": "Simple method to spend a p2sh address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting metadata for a single node.", "response": "def get_metadata(address=None, tx_hash=None, block_hash=None, api_key=None, private=True, coin_symbol='btc'):\n    '''\n    Get metadata using blockcypher's API.\n\n    This is data on blockcypher's servers and not embedded into the bitcoin (or other) blockchain.\n    '''\n    assert is_valid_coin_symbol(coin_symbol), coin_symbol\n    assert api_key or not private, 'Cannot see private metadata without an API key'\n\n    kwarg = get_valid_metadata_identifier(\n        coin_symbol=coin_symbol,\n        address=address,\n        tx_hash=tx_hash,\n        block_hash=block_hash,\n        )\n\n    url = make_url(coin_symbol, meta=True, **kwarg)\n\n    params = {'token': api_key} if api_key else {'private': 'true'}\n\n    r = requests.get(url, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    response_dict = get_valid_json(r)\n\n    return response_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nput metadata into the blockchain.", "response": "def put_metadata(metadata_dict, address=None, tx_hash=None, block_hash=None, api_key=None, private=True, coin_symbol='btc'):\n    '''\n    Embed metadata using blockcypher's API.\n\n    This is not embedded into the bitcoin (or other) blockchain,\n    and is only stored on blockcypher's servers.\n    '''\n    assert is_valid_coin_symbol(coin_symbol), coin_symbol\n    assert api_key\n    assert metadata_dict and isinstance(metadata_dict, dict), metadata_dict\n\n    kwarg = get_valid_metadata_identifier(\n        coin_symbol=coin_symbol,\n        address=address,\n        tx_hash=tx_hash,\n        block_hash=block_hash,\n        )\n\n    url = make_url(coin_symbol, meta=True, **kwarg)\n\n    params = {'token': api_key}\n    if private:\n        params['private'] = 'true'\n\n    r = requests.put(url, json=metadata_dict, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    return get_valid_json(r, allow_204=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete metadata from the blockchain.", "response": "def delete_metadata(address=None, tx_hash=None, block_hash=None, api_key=None, coin_symbol='btc'):\n    '''\n    Only available for metadata that was embedded privately.\n    '''\n    assert is_valid_coin_symbol(coin_symbol), coin_symbol\n    assert api_key, 'api_key required'\n\n    kwarg = get_valid_metadata_identifier(\n        coin_symbol=coin_symbol,\n        address=address,\n        tx_hash=tx_hash,\n        block_hash=block_hash,\n        )\n\n    url = make_url(coin_symbol, meta=True, **kwarg)\n\n    params = {'token': api_key}\n\n    r = requests.delete(url, params=params, verify=True, timeout=TIMEOUT_IN_SECONDS)\n    return get_valid_json(r, allow_204=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_satoshis(input_quantity, input_type):\n    ''' convert to satoshis, no rounding '''\n    assert input_type in UNIT_CHOICES, input_type\n\n    # convert to satoshis\n    if input_type in ('btc', 'mbtc', 'bit'):\n        satoshis = float(input_quantity) * float(UNIT_MAPPINGS[input_type]['satoshis_per'])\n    elif input_type == 'satoshi':\n        satoshis = input_quantity\n    else:\n        raise Exception('Invalid Unit Choice: %s' % input_type)\n\n    return int(satoshis)", "response": "converts a quantity to satoshis"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef safe_trim(qty_as_string):\n    '''\n    Safe trimming means the following:\n        1.0010000 -> 1.001\n        1.0 -> 1.0 (no change)\n        1.0000001 -> 1.0000001 (no change)\n    '''\n    qty_formatted = qty_as_string\n    if '.' in qty_as_string:\n        # only affect numbers with decimals\n        while True:\n            if qty_formatted[-1] == '0' and qty_formatted[-2] != '.':\n                qty_formatted = qty_formatted[:-1]\n            else:\n                break\n\n    return qty_formatted", "response": "Trim the qty_as_string to the nearest number."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake an input like 11002343 satoshis and converts it to another unit and formats it with appropriate units.", "response": "def format_crypto_units(input_quantity, input_type, output_type, coin_symbol=None, print_cs=False, safe_trimming=False, round_digits=0):\n    '''\n    Take an input like 11002343 satoshis and convert it to another unit (e.g. BTC) and format it with appropriate units\n\n    if coin_symbol is supplied and print_cs == True then the units will be added (e.g. BTC or satoshis)\n\n    Smart trimming gets rid of trailing 0s in the decimal place, except for satoshis (irrelevant) and bits (always two decimals points).\n    It also preserves one decimal place in the case of 1.0 to show significant figures.\n    It is stil technically correct and reversible.\n\n    Smart rounding performs a rounding operation (so it is techincally not the correct number and is not reversible).\n    The number of decimals to round by is a function of the output_type\n\n    Requires python >= 2.7\n    '''\n    assert input_type in UNIT_CHOICES, input_type\n    assert output_type in UNIT_CHOICES, output_type\n    if print_cs:\n        assert is_valid_coin_symbol(coin_symbol=coin_symbol), coin_symbol\n    assert isinstance(round_digits, int)\n\n    satoshis_float = to_satoshis(input_quantity=input_quantity, input_type=input_type)\n\n    if round_digits:\n        satoshis_float = round(satoshis_float, -1*round_digits)\n\n    output_quantity = from_satoshis(\n            input_satoshis=satoshis_float,\n            output_type=output_type,\n            )\n\n    if output_type == 'bit' and round_digits >= 2:\n        pass\n        # hack to add thousands separator with no decimals\n        output_quantity_formatted = format_output(num=output_quantity, output_type='satoshi')\n    else:\n        # add thousands separator and appropriate # of decimals\n        output_quantity_formatted = format_output(num=output_quantity, output_type=output_type)\n\n    if safe_trimming and output_type not in ('satoshi', 'bit'):\n        output_quantity_formatted = safe_trim(qty_as_string=output_quantity_formatted)\n\n    if print_cs:\n        curr_symbol = get_curr_symbol(\n                coin_symbol=coin_symbol,\n                output_type=output_type,\n                )\n        output_quantity_formatted += ' %s' % curr_symbol\n    return output_quantity_formatted"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_txn_outputs(raw_tx_hex, output_addr_list, coin_symbol):\n    '''\n    Used to verify a transaction hex does what's expected of it.\n\n    Must supply a list of output addresses so that the library can try to\n    convert from script to address using both pubkey and script.\n\n    Returns a list of the following form:\n        [{'value': 12345, 'address': '1abc...'}, ...]\n\n    Uses @vbuterin's decoding methods.\n    '''\n    # Defensive checks:\n    err_msg = 'Library not able to parse %s transactions' % coin_symbol\n    assert lib_can_deserialize_cs(coin_symbol), err_msg\n    assert isinstance(output_addr_list, (list, tuple))\n    for output_addr in output_addr_list:\n        assert is_valid_address(output_addr), output_addr\n\n    output_addr_set = set(output_addr_list)  # speed optimization\n\n    outputs = []\n    deserialized_tx = deserialize(str(raw_tx_hex))\n    for out in deserialized_tx.get('outs', []):\n        output = {'value': out['value']}\n\n        # determine if the address is a pubkey address, script address, or op_return\n        pubkey_addr = script_to_address(out['script'],\n            vbyte=COIN_SYMBOL_MAPPINGS[coin_symbol]['vbyte_pubkey'])\n        script_addr = script_to_address(out['script'],\n            vbyte=COIN_SYMBOL_MAPPINGS[coin_symbol]['vbyte_script'])\n        nulldata = out['script'] if out['script'][0:2] == '6a' else None\n        if pubkey_addr in output_addr_set:\n            address = pubkey_addr\n            output['address'] = address\n        elif script_addr in output_addr_set:\n            address = script_addr\n            output['address'] = address\n        elif nulldata:\n            output['script'] = nulldata\n            output['script_type'] = 'null-data'\n        else:\n            raise Exception('Script %s Does Not Contain a Valid Output Address: %s' % (\n                out['script'],\n                output_addr_set,\n                ))\n\n        outputs.append(output)\n    return outputs", "response": "Given a raw hex transaction and a list of output addresses return a list of the outputs that are expected by the library."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking a list of txn outputs and compresses it to the sum of satoshis sent to each address in a dictionary.", "response": "def compress_txn_outputs(txn_outputs):\n    '''\n    Take a list of txn ouputs (from get_txn_outputs output of pybitcointools)\n    and compress it to the sum of satoshis sent to each address in a dictionary.\n\n    Returns a dict of the following form:\n        {'1abc...': 12345, '1def': 54321, ...}\n    '''\n    result_dict = {}\n    outputs = (output for output in txn_outputs if output.get('address'))\n    for txn_output in outputs:\n        if txn_output['address'] in result_dict:\n            result_dict[txn_output['address']] += txn_output['value']\n        else:\n            result_dict[txn_output['address']] = txn_output['value']\n    return result_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the blockcypher wallet name from a master pubkey.", "response": "def get_blockcypher_walletname_from_mpub(mpub, subchain_indices=[]):\n    '''\n    Blockcypher limits wallet names to 25 chars.\n\n    Hash the master pubkey (with subchain indexes) and take the first 25 chars.\n\n    Hackey determinstic method for naming.\n    '''\n\n    #  http://stackoverflow.com/a/19877309/1754586\n    mpub = mpub.encode('utf-8')\n\n    if subchain_indices:\n        mpub += ','.join([str(x) for x in subchain_indices]).encode('utf-8')\n    return 'X%s' % sha256(mpub).hexdigest()[:24]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef flatten_txns_by_hash(tx_list, nesting=True):\n    '''\n    Flattens a response from querying a list of address (or wallet) transactions\n\n    If nesting==True then it will return an ordered dictionary where the keys are tranasaction hashes, otherwise it will be a list of dicts.\n    (nesting==False is good for django templates)\n    '''\n    nested_cleaned_txs = OrderedDict()\n    for tx in tx_list:\n        tx_hash = tx.get('tx_hash')\n\n        satoshis = tx.get('value', 0)  # rare edge case where API returns 0\n\n        if tx.get('tx_input_n') >= 0:\n            satoshis *= -1\n\n        if tx_hash in nested_cleaned_txs:\n            nested_cleaned_txs[tx_hash]['txns_satoshis_list'].append(satoshis)\n            nested_cleaned_txs[tx_hash]['satoshis_net'] = sum(nested_cleaned_txs[tx_hash]['txns_satoshis_list'])\n            if tx.get('double_spend') and not nested_cleaned_txs[tx_hash]['double_spend']:\n                nested_cleaned_txs[tx_hash]['double_spend'] = True\n\n        else:\n            nested_cleaned_txs[tx_hash] = {\n                    'txns_satoshis_list': [satoshis, ],\n                    'satoshis_net': satoshis,\n                    'received_at': tx.get('received'),\n                    'confirmed_at': tx.get('confirmed'),\n                    'confirmations': tx.get('confirmations', 0),\n                    'block_height': tx.get('block_height'),\n                    'double_spend': tx.get('double_spend', False),\n                    }\n    if nesting:\n        return nested_cleaned_txs\n    else:\n        unnested_cleaned_txs = []\n        for tx_hash in nested_cleaned_txs:\n            tx_cleaned = nested_cleaned_txs[tx_hash]\n            tx_cleaned['tx_hash'] = tx_hash\n            unnested_cleaned_txs.append(tx_cleaned)\n        return unnested_cleaned_txs", "response": "Flattens a response from querying a list of transactions by hash."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _long_to_bytes(n, length, byteorder):\n    if byteorder == 'little':\n        indexes = range(length)\n    else:\n        indexes = reversed(range(length))\n    return bytearray((n >> i * 8) & 0xff for i in indexes)", "response": "Convert a long to a bytestring"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbeing an address both valid and start with the correct character for the coin symbol?", "response": "def is_valid_address_for_coinsymbol(b58_address, coin_symbol):\n    '''\n    Is an address both valid *and* start with the correct character\n    for its coin symbol (chain/network)\n    '''\n    assert is_valid_coin_symbol(coin_symbol)\n\n    if b58_address[0] in COIN_SYMBOL_MAPPINGS[coin_symbol]['address_first_char_list']:\n        if is_valid_address(b58_address):\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef default_validity_start():\n    start = datetime.now() - timedelta(days=1)\n    return start.replace(hour=0, minute=0, second=0, microsecond=0)", "response": "Sets validity_start field to 1 day before the current date."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_revoked_certs(self):\n        now = timezone.now()\n        return self.cert_set.filter(revoked=True,\n                                    validity_start__lte=now,\n                                    validity_end__gte=now)", "response": "Returns a QuerySet of revoked certificates of this CA."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef crl(self):\n        revoked_certs = self.get_revoked_certs()\n        crl = crypto.CRL()\n        now_str = timezone.now().strftime(generalized_time)\n        for cert in revoked_certs:\n            revoked = crypto.Revoked()\n            revoked.set_serial(bytes_compat(cert.serial_number))\n            revoked.set_reason(b'unspecified')\n            revoked.set_rev_date(bytes_compat(now_str))\n            crl.add_revoked(revoked)\n        return crl.export(self.x509, self.pkey, days=1, digest=b'sha256')", "response": "Returns up to date CRL of this CA"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef revoke(self):\n        now = timezone.now()\n        self.revoked = True\n        self.revoked_at = now\n        self.save()", "response": "flag certificate as revoked"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef crl(request, pk):\n    authenticated = request.user.is_authenticated\n    authenticated = authenticated() if callable(authenticated) else authenticated\n    if app_settings.CRL_PROTECTED and not authenticated:\n        return HttpResponse(_('Forbidden'),\n                            status=403,\n                            content_type='text/plain')\n    ca = crl.ca_model.objects.get(pk=pk)\n    return HttpResponse(ca.crl,\n                        status=200,\n                        content_type='application/x-pem-file')", "response": "Returns a CRL of a CA"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef font_size_splitter(font_map):\n    small_font = []\n    medium_font = []\n    large_font = []\n    xlarge_font = []\n    fonts = set(font_map.keys()) - set(RANDOM_FILTERED_FONTS)\n    for font in fonts:\n        length = max(map(len, font_map[font][0].values()))\n        if length <= FONT_SMALL_THRESHOLD:\n            small_font.append(font)\n        elif length > FONT_SMALL_THRESHOLD and length <= FONT_MEDIUM_THRESHOLD:\n            medium_font.append(font)\n        elif length > FONT_MEDIUM_THRESHOLD and length <= FONT_LARGE_THRESHOLD:\n            large_font.append(font)\n        else:\n            xlarge_font.append(font)\n    return {\n        \"small_list\": small_font,\n        \"medium_list\": medium_font,\n        \"large_list\": large_font,\n        \"xlarge_list\": xlarge_font}", "response": "Split fonts to 4 category small medium large xlarge."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints all fonts in the .", "response": "def font_list(text=\"test\", test=False):\n    \"\"\"\n    Print all fonts.\n\n    :param text : input text\n    :type text : str\n    :param test: test flag\n    :type test: bool\n    :return: None\n    \"\"\"\n    fonts = set(FONT_MAP.keys())\n    if test:\n        fonts = fonts - set(TEST_FILTERED_FONTS)\n    for item in sorted(list(fonts)):\n        print(str(item) + \" : \")\n        text_temp = text\n        try:\n            tprint(text_temp, str(item))\n        except Exception:\n            print(FONT_ENVIRONMENT_WARNING)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting all 1 - Line arts.", "response": "def art_list(test=False):\n    \"\"\"\n    Print all 1-Line arts.\n\n    :param test : exception test flag\n    :type test : bool\n    :return: None\n    \"\"\"\n    for i in sorted(list(art_dic.keys())):\n        try:\n            if test:\n                raise Exception\n            print(i)\n            aprint(i)\n            line()\n        except Exception:\n            print(ART_ENVIRONMENT_WARNING)\n            line()\n            if test:\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef help_func():\n    tprint(\"art\")\n    tprint(\"v\" + VERSION)\n    print(DESCRIPTION + \"\\n\")\n    print(\"Webpage : http://art.shaghighi.ir\\n\")\n    print(\"Help : \\n\")\n    print(\"     - list --> (list of arts)\\n\")\n    print(\"     - fonts --> (list of fonts)\\n\")\n    print(\"     - test --> (run tests)\\n\")\n    print(\"     - text 'yourtext' 'font(optional)' --> (text art) Example : 'python -m art text exampletext block'\\n\")\n    print(\"     - shape 'shapename' --> (shape art) Example : 'python -m art shape butterfly'\\n\")\n    print(\"     - save 'yourtext' 'font(optional)'  -->  Example : 'python -m art save exampletext block'\\n\")\n    print(\"     - all 'yourtext'  -->  Example : 'python -m art all exampletext'\")", "response": "Print help page.\n\n    :return: None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints 1-line art. :param artname: artname :type artname : str :return: None", "response": "def aprint(artname, number=1, text=\"\"):\n    \"\"\"\n    Print 1-line art.\n\n    :param artname: artname\n    :type artname : str\n    :return: None\n    \"\"\"\n    print(art(artname=artname, number=number, text=text))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef art(artname, number=1, text=\"\"):\n    if isinstance(artname, str) is False:\n        raise artError(ART_TYPE_ERROR)\n    artname = artname.lower()\n    arts = sorted(art_dic.keys())\n    if artname == \"random\" or artname == \"rand\" or artname == \"rnd\":\n        filtered_arts = list(set(arts) - set(RANDOM_FILTERED_ARTS))\n        artname = random.choice(filtered_arts)\n    elif artname not in art_dic.keys():\n        distance_list = list(map(lambda x: distance_calc(artname, x),\n                                 arts))\n        min_distance = min(distance_list)\n        selected_art = arts[distance_list.index(min_distance)]\n        threshold = max(len(artname), len(selected_art)) / 2\n        if min_distance < threshold:\n            artname = selected_art\n        else:\n            raise artError(ART_NAME_ERROR)\n    art_value = art_dic[artname]\n    if isinstance(number, int) is False:\n        raise artError(NUMBER_TYPE_ERROR)\n    if isinstance(art_value, str):\n        return (art_value + \" \") * number\n    if isinstance(text, str) is False:\n        raise artError(TEXT_TYPE_ERROR)\n    return (art_value[0] + text + art_value[1] + \" \") * number", "response": "Return 1 - line art."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tprint(text, font=DEFAULT_FONT, chr_ignore=True):\n    result = text2art(text, font=font, chr_ignore=chr_ignore)\n    print(result)", "response": "r Prints text to the output of the current character."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tsave(\n        text,\n        font=DEFAULT_FONT,\n        filename=\"art\",\n        chr_ignore=True,\n        print_status=True):\n    r\"\"\"\n    Save ascii art (support \\n).\n\n    :param text: input text\n    :param font: input font\n    :type font:str\n    :type text:str\n    :param filename: output file name\n    :type filename:str\n    :param chr_ignore: ignore not supported character\n    :type chr_ignore:bool\n    :param print_status : save message print flag\n    :type print_status:bool\n    :return: None\n    \"\"\"\n    try:\n        if isinstance(text, str) is False:\n            raise Exception(TEXT_TYPE_ERROR)\n        files_list = os.listdir(os.getcwd())\n        extension = \".txt\"\n        splitted_filename = filename.split(\".\")\n        name = splitted_filename[0]\n        if len(splitted_filename) > 1:\n            extension = \".\" + splitted_filename[1]\n        index = 2\n        test_name = name\n        while(True):\n            if test_name + extension in files_list:\n                test_name = name + str(index)\n                index = index + 1\n            else:\n                break\n        if font.lower() in TEST_FILTERED_FONTS:\n            file = codecs.open(test_name + extension, \"w\", encoding='utf-8')\n        else:\n            file = open(test_name + extension, \"w\")\n        result = text2art(text, font=font, chr_ignore=chr_ignore)\n        file.write(result)\n        file.close()\n        if print_status:\n            print(\"Saved! \\nFilename: \" + test_name + extension)\n        return {\"Status\": True, \"Message\": \"OK\"}\n    except Exception as e:\n        return {\"Status\": False, \"Message\": str(e)}", "response": "r Save ascii art."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef distance_calc(s1, s2):\n    if len(s1) > len(s2):\n        s1, s2 = s2, s1\n\n    distances = range(len(s1) + 1)\n    for i2, c2 in enumerate(s2):\n        distances_ = [i2 + 1]\n        for i1, c1 in enumerate(s1):\n            if c1 == c2:\n                distances_.append(distances[i1])\n            else:\n                distances_.append(\n                    1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n        distances = distances_\n    return distances[-1]", "response": "Calculate Levenshtein distance between two words."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a random font for the next wizard mode.", "response": "def wizard_font(text):\n    \"\"\"\n    Check input text length for wizard mode.\n\n    :param text: input text\n    :type text:str\n    :return: font as str\n    \"\"\"\n    text_length = len(text)\n    if text_length <= TEXT_XLARGE_THRESHOLD:\n        font = random.choice(XLARGE_WIZARD_FONT)\n    elif text_length > TEXT_XLARGE_THRESHOLD and text_length <= TEXT_LARGE_THRESHOLD:\n        font = random.choice(LARGE_WIZARD_FONT)\n    elif text_length > TEXT_LARGE_THRESHOLD and text_length <= TEXT_MEDIUM_THRESHOLD:\n        font = random.choice(MEDIUM_WIZARD_FONT)\n    else:\n        font = random.choice(SMALL_WIZARD_FONT)\n    return font"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef indirect_font(font, fonts, text):\n    if font == \"rnd-small\" or font == \"random-small\" or font == \"rand-small\":\n        font = random.choice(RND_SIZE_DICT[\"small_list\"])\n        return font\n    if font == \"rnd-medium\" or font == \"random-medium\" or font == \"rand-medium\":\n        font = random.choice(RND_SIZE_DICT[\"medium_list\"])\n        return font\n    if font == \"rnd-large\" or font == \"random-large\" or font == \"rand-large\":\n        font = random.choice(RND_SIZE_DICT[\"large_list\"])\n        return font\n    if font == \"rnd-xlarge\" or font == \"random-xlarge\" or font == \"rand-xlarge\":\n        font = random.choice(RND_SIZE_DICT[\"xlarge_list\"])\n        return font\n    if font == \"random\" or font == \"rand\" or font == \"rnd\":\n        filtered_fonts = list(set(fonts) - set(RANDOM_FILTERED_FONTS))\n        font = random.choice(filtered_fonts)\n        return font\n    if font == \"wizard\" or font == \"wiz\" or font == \"magic\":\n        font = wizard_font(text)\n        return font\n    if font == \"rnd-na\" or font == \"random-na\" or font == \"rand-na\":\n        font = random.choice(TEST_FILTERED_FONTS)\n        return font\n    if font not in FONT_MAP.keys():\n        distance_list = list(map(lambda x: distance_calc(font, x), fonts))\n        font = fonts[distance_list.index(min(distance_list))]\n    return font", "response": "Return a random font in the list of indirect modes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __word2art(word, font, chr_ignore, letters):\n    split_list = []\n    result_list = []\n    splitter = \"\\n\"\n    for i in word:\n        if (ord(i) == 9) or (ord(i) == 32 and font == \"block\"):\n            continue\n        if (i not in letters.keys()):\n            if (chr_ignore):\n                continue\n            else:\n                raise artError(str(i) + \" is invalid.\")\n        if len(letters[i]) == 0:\n            continue\n        split_list.append(letters[i].split(\"\\n\"))\n    if font in [\"mirror\", \"mirror_flip\"]:\n        split_list.reverse()\n    if len(split_list) == 0:\n        return \"\"\n    for i in range(len(split_list[0])):\n        temp = \"\"\n        for j in range(len(split_list)):\n            if j > 0 and (\n                    i == 1 or i == len(\n                        split_list[0]) -\n                    2) and font == \"block\":\n                temp = temp + \" \"\n            temp = temp + split_list[j][i]\n        result_list.append(temp)\n    if \"win32\" != sys.platform:\n        splitter = \"\\r\\n\"\n    result = (splitter).join(result_list)\n    if result[-1] != \"\\n\":\n        result += splitter\n    return result", "response": "Convert a word to an ascii art."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef text2art(text, font=DEFAULT_FONT, chr_ignore=True):\n    letters = standard_dic\n    text_temp = text\n    if isinstance(text, str) is False:\n        raise artError(TEXT_TYPE_ERROR)\n    if isinstance(font, str) is False:\n        raise artError(FONT_TYPE_ERROR)\n    font = font.lower()\n    fonts = sorted(FONT_MAP.keys())\n    font = indirect_font(font, fonts, text)\n    letters = FONT_MAP[font][0]\n    if FONT_MAP[font][1]:\n        text_temp = text.lower()\n    if font in UPPERCASE_FONTS:\n        text_temp = text.upper()\n    word_list = text_temp.split(\"\\n\")\n    result = \"\"\n    for word in word_list:\n        if len(word) != 0:\n            result = result + __word2art(word=word,\n                                         font=font,\n                                         chr_ignore=chr_ignore,\n                                         letters=letters)\n    return result", "response": "r Converts text to ascii art text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_default(font=DEFAULT_FONT, chr_ignore=True, filename=\"art\",\n                print_status=True):\n    \"\"\"\n    Change text2art, tprint and tsave default values.\n\n    :param font: input font\n    :type font:str\n    :param chr_ignore: ignore not supported character\n    :type chr_ignore:bool\n    :param filename: output file name (only tsave)\n    :type filename:str\n    :param print_status : save message print flag (only tsave)\n    :type print_status:bool\n    :return: None\n    \"\"\"\n    if isinstance(font, str) is False:\n        raise artError(FONT_TYPE_ERROR)\n    if isinstance(chr_ignore, bool) is False:\n        raise artError(CHR_IGNORE_TYPE_ERROR)\n    if isinstance(filename, str) is False:\n        raise artError(FILE_TYPE_ERROR)\n    if isinstance(print_status, bool) is False:\n        raise artError(PRINT_STATUS_TYPE_ERROR)\n    tprint.__defaults__ = (font, chr_ignore)\n    tsave.__defaults__ = (font, filename, chr_ignore, print_status)\n    text2art.__defaults__ = (font, chr_ignore)", "response": "Change text2art tprint and tsave default values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef predicate(fn=None, name=None, **options):\n    if not name and not callable(fn):\n        name = fn\n        fn = None\n\n    def inner(fn):\n        if isinstance(fn, Predicate):\n            return fn\n        p = Predicate(fn, name, **options)\n        update_wrapper(p, fn)\n        return p\n\n    if fn:\n        return inner(fn)\n    else:\n        return inner", "response": "Decorator that creates a Predicate instance from any function that returns True."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef objectgetter(model, attr_name='pk', field_name='pk'):\n    def _getter(request, *view_args, **view_kwargs):\n        if attr_name not in view_kwargs:\n            raise ImproperlyConfigured(\n                'Argument {0} is not available. Given arguments: [{1}]'\n                .format(attr_name, ', '.join(view_kwargs.keys())))\n        try:\n            return get_object_or_404(model, **{field_name: view_kwargs[attr_name]})\n        except FieldError:\n            raise ImproperlyConfigured(\n                'Model {0} has no field named {1}'\n                .format(model, field_name))\n    return _getter", "response": "A decorator that returns a function suitable for use as the fn argument\n    to the permission_required decorator."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef permission_required(perm, fn=None, login_url=None, raise_exception=False, redirect_field_name=REDIRECT_FIELD_NAME):\n    def decorator(view_func):\n        @wraps(view_func, assigned=available_attrs(view_func))\n        def _wrapped_view(request, *args, **kwargs):\n            # Normalize to a list of permissions\n            if isinstance(perm, six.string_types):\n                perms = (perm,)\n            else:\n                perms = perm\n\n            # Get the object to check permissions against\n            if callable(fn):\n                obj = fn(request, *args, **kwargs)\n            else:  # pragma: no cover\n                obj = fn\n\n            # Get the user\n            user = request.user\n\n            # Check for permissions and return a response\n            if not user.has_perms(perms, obj):\n                # User does not have a required permission\n                if raise_exception:\n                    raise PermissionDenied()\n                else:\n                    return _redirect_to_login(request, view_func.__name__,\n                                              login_url, redirect_field_name)\n            else:\n                # User has all required permissions -- allow the view to execute\n                return view_func(request, *args, **kwargs)\n\n        return _wrapped_view\n\n    return decorator", "response": "Decorator that allows the user to perform a view on the object that has the given permission."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_permission_object(self):\n        if not isinstance(self, BaseCreateView):\n            # We do NOT want to call get_object in a BaseCreateView, see issue #85\n            if hasattr(self, 'get_object') and callable(self.get_object):\n                # Requires SingleObjectMixin or equivalent ``get_object`` method\n                return self.get_object()\n        return None", "response": "Returns the object to check for permission\n        against."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_base_dir(self, base_dir):\n\n        self._base_dir = base_dir\n        self.icon_cache.set_base_dir(base_dir)", "response": "Set the base directory for all relative filenames."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a C ++ alignment to the corresponding flags.", "response": "def _parse_alignment(alignment):\n    \"\"\" Convert a C++ alignment to the corresponding flags. \"\"\"\n\n    align_flags = None\n    for qt_align in alignment.split('|'):\n        _, qt_align = qt_align.split('::')\n        align = getattr(QtCore.Qt, qt_align)\n\n        if align_flags is None:\n            align_flags = align\n        else:\n            align_flags |= align\n\n    return align_flags"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn either a tuple of row column rowspan colspan alignment", "response": "def _layout_position(elem):\n    \"\"\" Return either (), (0, alignment), (row, column, rowspan, colspan) or\n    (row, column, rowspan, colspan, alignment) depending on the type of layout\n    and its configuration.  The result will be suitable to use as arguments to\n    the layout.\n    \"\"\"\n\n    row = elem.attrib.get('row')\n    column = elem.attrib.get('column')\n    alignment = elem.attrib.get('alignment')\n\n    # See if it is a box layout.\n    if row is None or column is None:\n        if alignment is None:\n            return ()\n\n        return (0, _parse_alignment(alignment))\n\n    # It must be a grid or a form layout.\n    row = int(row)\n    column = int(column)\n\n    rowspan = int(elem.attrib.get('rowspan', 1))\n    colspan = int(elem.attrib.get('colspan', 1))\n\n    if alignment is None:\n        return (row, column, rowspan, colspan)\n\n    return (row, column, rowspan, colspan, _parse_alignment(alignment))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef uniqueName(self, name):\n        try:\n            suffix = self.name_suffixes[name]\n        except KeyError:\n            self.name_suffixes[name] = 0\n            return name\n\n        suffix += 1\n        self.name_suffixes[name] = suffix\n\n        return \"%s%i\" % (name, suffix)", "response": "Create a unique name from a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if any argument appears to be an i18n string.", "response": "def any_i18n(*args):\n        \"\"\" Return True if any argument appears to be an i18n string. \"\"\"\n\n        for a in args:\n            if a is not None and not isinstance(a, str):\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a specific type of widget item.", "response": "def createWidgetItem(self, item_type, elem, getter, *getter_args):\n        \"\"\" Create a specific type of widget item. \"\"\"\n\n        item = self.factory.createQObject(item_type, \"item\", (), False)\n        props = self.wprops\n\n        # Note that not all types of widget items support the full set of\n        # properties.\n\n        text = props.getProperty(elem, 'text')\n        status_tip = props.getProperty(elem, 'statusTip')\n        tool_tip = props.getProperty(elem, 'toolTip')\n        whats_this = props.getProperty(elem, 'whatsThis')\n\n        if self.any_i18n(text, status_tip, tool_tip, whats_this):\n            self.factory.invoke(\"item\", getter, getter_args)\n\n        if text:\n            item.setText(text)\n\n        if status_tip:\n            item.setStatusTip(status_tip)\n\n        if tool_tip:\n            item.setToolTip(tool_tip)\n\n        if whats_this:\n            item.setWhatsThis(whats_this)\n\n        text_alignment = props.getProperty(elem, 'textAlignment')\n        if text_alignment:\n            item.setTextAlignment(text_alignment)\n\n        font = props.getProperty(elem, 'font')\n        if font:\n            item.setFont(font)\n\n        icon = props.getProperty(elem, 'icon')\n        if icon:\n            item.setIcon(icon)\n\n        background = props.getProperty(elem, 'background')\n        if background:\n            item.setBackground(background)\n\n        foreground = props.getProperty(elem, 'foreground')\n        if foreground:\n            item.setForeground(foreground)\n\n        flags = props.getProperty(elem, 'flags')\n        if flags:\n            item.setFlags(flags)\n\n        check_state = props.getProperty(elem, 'checkState')\n        if check_state:\n            item.setCheckState(check_state)\n\n        return item"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a resources tag and add the module to the parser s list of resources.", "response": "def readResources(self, elem):\n        \"\"\"\n        Read a \"resources\" tag and add the module to import to the parser's\n        list of them.\n        \"\"\"\n        try:\n            iterator = getattr(elem, 'iter')\n        except AttributeError:\n            iterator = getattr(elem, 'getiterator')\n\n        for include in iterator(\"include\"):\n            loc = include.attrib.get(\"location\")\n\n            # Apply the convention for naming the Python files generated by\n            # pyrcc5.\n            if loc and loc.endswith('.qrc'):\n                mname = os.path.basename(loc[:-4] + self._resource_suffix)\n                if mname not in self.resources:\n                    self.resources.append(mname)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompile a directory or a directory tree of Qt Designer. ui files into a Python module.", "response": "def compileUiDir(dir, recurse=False, map=None, **compileUi_args):\n    \"\"\"compileUiDir(dir, recurse=False, map=None, **compileUi_args)\n\n    Creates Python modules from Qt Designer .ui files in a directory or\n    directory tree.\n\n    dir is the name of the directory to scan for files whose name ends with\n    '.ui'.  By default the generated Python module is created in the same\n    directory ending with '.py'.\n    recurse is set if any sub-directories should be scanned.  The default is\n    False.\n    map is an optional callable that is passed the name of the directory\n    containing the '.ui' file and the name of the Python module that will be\n    created.  The callable should return a tuple of the name of the directory\n    in which the Python module will be created and the (possibly modified)\n    name of the module.  The default is None.\n    compileUi_args are any additional keyword arguments that are passed to\n    the compileUi() function that is called to create each Python module.\n    \"\"\"\n\n    import os\n\n    # Compile a single .ui file.\n    def compile_ui(ui_dir, ui_file):\n        # Ignore if it doesn't seem to be a .ui file.\n        if ui_file.endswith('.ui'):\n            py_dir = ui_dir\n            py_file = ui_file[:-3] + '.py'\n\n            # Allow the caller to change the name of the .py file or generate\n            # it in a different directory.\n            if map is not None:\n                py_dir, py_file = map(py_dir, py_file)\n\n            # Make sure the destination directory exists.\n            try:\n                os.makedirs(py_dir)\n            except:\n                pass\n\n            ui_path = os.path.join(ui_dir, ui_file)\n            py_path = os.path.join(py_dir, py_file)\n\n            ui_file = open(ui_path, 'r')\n            py_file = open(py_path, 'w')\n\n            try:\n                compileUi(ui_file, py_file, **compileUi_args)\n            finally:\n                ui_file.close()\n                py_file.close()\n\n    if recurse:\n        for root, _, files in os.walk(dir):\n            for ui in files:\n                compile_ui(root, ui)\n    else:\n        for ui in os.listdir(dir):\n            if os.path.isfile(os.path.join(dir, ui)):\n                compile_ui(dir, ui)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompile a Qt Designer. ui file into a Python module.", "response": "def compileUi(uifile, pyfile, execute=False, indent=4, from_imports=False, resource_suffix='_rc', import_from='.'):\n    \"\"\"compileUi(uifile, pyfile, execute=False, indent=4, from_imports=False, resource_suffix='_rc', import_from='.')\n\n    Creates a Python module from a Qt Designer .ui file.\n    \n    uifile is a file name or file-like object containing the .ui file.\n    pyfile is the file-like object to which the Python code will be written to.\n    execute is optionally set to generate extra Python code that allows the\n    code to be run as a standalone application.  The default is False.\n    indent is the optional indentation width using spaces.  If it is 0 then a\n    tab is used.  The default is 4.\n    from_imports is optionally set to generate relative import statements.  At\n    the moment this only applies to the import of resource modules.\n    resource_suffix is the suffix appended to the basename of any resource file\n    specified in the .ui file to create the name of the Python module generated\n    from the resource file by pyrcc4.  The default is '_rc', i.e. if the .ui\n    file specified a resource file called foo.qrc then the corresponding Python\n    module is foo_rc.\n    import_from is optionally set to the package used for relative import\n    statements.  The default is ``'.'``.\n    \"\"\"\n\n    from PyQt5.QtCore import PYQT_VERSION_STR\n\n    try:\n        uifname = uifile.name\n    except AttributeError:\n        uifname = uifile\n\n    indenter.indentwidth = indent\n\n    pyfile.write(_header % (uifname, PYQT_VERSION_STR))\n\n    winfo = compiler.UICompiler().compileUi(uifile, pyfile, from_imports, resource_suffix, import_from)\n\n    if execute:\n        indenter.write_code(_display_code % winfo)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a Qt Designer. ui file and return the generated form class and base class.", "response": "def loadUiType(uifile, from_imports=False, resource_suffix='_rc', import_from='.'):\n    \"\"\"loadUiType(uifile, from_imports=False, resource_suffix='_rc', import_from='.') -> (form class, base class)\n\n    Load a Qt Designer .ui file and return the generated form class and the Qt\n    base class.\n\n    uifile is a file name or file-like object containing the .ui file.\n    from_imports is optionally set to generate relative import statements.  At\n    the moment this only applies to the import of resource modules.\n    resource_suffix is the suffix appended to the basename of any resource file\n    specified in the .ui file to create the name of the Python module generated\n    from the resource file by pyrcc4.  The default is '_rc', i.e. if the .ui\n    file specified a resource file called foo.qrc then the corresponding Python\n    module is foo_rc.\n    import_from is optionally set to the package used for relative import\n    statements.  The default is ``'.'``.\n    \"\"\"\n\n    import sys\n\n    from PyQt5 import QtWidgets\n\n    if sys.hexversion >= 0x03000000:\n        from .port_v3.string_io import StringIO\n    else:\n        from .port_v2.string_io import StringIO\n\n    code_string = StringIO()\n    winfo = compiler.UICompiler().compileUi(uifile, code_string, from_imports, resource_suffix, import_from)\n\n    ui_globals = {}\n    exec(code_string.getvalue(), ui_globals)\n\n    return (ui_globals[winfo[\"uiclass\"]], getattr(QtWidgets, winfo[\"baseclass\"]))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a Qt Designer. ui file and return an instance of the widget class.", "response": "def loadUi(uifile, baseinstance=None, package='', resource_suffix='_rc'):\n    \"\"\"loadUi(uifile, baseinstance=None, package='') -> widget\n\n    Load a Qt Designer .ui file and return an instance of the user interface.\n\n    uifile is a file name or file-like object containing the .ui file.\n    baseinstance is an optional instance of the Qt base class.  If specified\n    then the user interface is created in it.  Otherwise a new instance of the\n    base class is automatically created.\n    package is the optional package which is used as the base for any relative\n    imports of custom widgets.\n    resource_suffix is the suffix appended to the basename of any resource file\n    specified in the .ui file to create the name of the Python module generated\n    from the resource file by pyrcc4.  The default is '_rc', i.e. if the .ui\n    file specified a resource file called foo.qrc then the corresponding Python\n    module is foo_rc.\n    \"\"\"\n\n    from .Loader.loader import DynamicUILoader\n\n    return DynamicUILoader(package).loadUi(uifile, baseinstance, resource_suffix)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an icon described by the given iconset tag.", "response": "def get_icon(self, iconset):\n        \"\"\"Return an icon described by the given iconset tag.\"\"\"\n\n        # Handle a themed icon.\n        theme = iconset.attrib.get('theme')\n        if theme is not None:\n            return self._object_factory.createQObject(\"QIcon.fromTheme\",\n                    'icon', (self._object_factory.asString(theme), ),\n                    is_attribute=False)\n\n        # Handle an empty iconset property.\n        if iconset.text is None:\n            return None\n\n        iset = _IconSet(iconset, self._base_dir)\n\n        try:\n            idx = self._cache.index(iset)\n        except ValueError:\n            idx = -1\n\n        if idx >= 0:\n            # Return the icon from the cache.\n            iset = self._cache[idx]\n        else:\n            # Follow uic's naming convention.\n            name = 'icon'\n            idx = len(self._cache)\n\n            if idx > 0:\n                name += str(idx)\n\n            icon = self._object_factory.createQObject(\"QIcon\", name, (),\n                    is_attribute=False)\n            iset.set_icon(icon, self._qtgui_module)\n            self._cache.append(iset)\n\n        return iset.icon"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a relative filename if we have a base directory.", "response": "def _file_name(fname, base_dir):\n        \"\"\" Convert a relative filename if we have a base directory. \"\"\"\n\n        fname = fname.replace(\"\\\\\", \"\\\\\\\\\")\n\n        if base_dir != '' and fname[0] != ':' and not os.path.isabs(fname):\n            fname = os.path.join(base_dir, fname)\n\n        return fname"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_icon(self, icon, qtgui_module):\n\n        if self._use_fallback:\n            icon.addFile(self._fallback)\n        else:\n            for role, pixmap in self._roles.items():\n                if role.endswith(\"off\"):\n                    mode = role[:-3]\n                    state = qtgui_module.QIcon.Off\n                elif role.endswith(\"on\"):\n                    mode = role[:-2]\n                    state = qtgui_module.QIcon.On\n                else:\n                    continue\n\n                mode = getattr(qtgui_module.QIcon, mode.title())\n\n                if pixmap:\n                    icon.addPixmap(qtgui_module.QPixmap(pixmap), mode, state)\n                else:\n                    icon.addPixmap(qtgui_module.QPixmap(), mode, state)\n\n        self.icon = icon", "response": "Save the icon and set its attributes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef createqtconf():\n\n    template = \"\"\"[Paths]\nPrefix = {path}\nBinaries = {path}\n\"\"\"\n\n    import PyQt5\n\n    exedir = os.path.dirname(sys.executable)\n    qtpath = os.path.join(exedir, \"qt.conf\")\n    pyqt5path = os.path.abspath(PyQt5.__file__)\n    binpath = os.path.dirname(pyqt5path).replace(\"\\\\\", \"/\")\n\n    try:\n        with open(qtpath, \"w\") as f:\n            f.write(template.format(path=binpath))\n    except:\n        pass", "response": "Create a qt. conf file next to the current executable"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_package_data():\n    package_data = dict()\n\n    package_data['PyQt5'] = list()\n    for subdir in (\"doc/\", \"examples/\", \"include/\",\n                   \"mkspecs/\", \"plugins/\", \"qml/\",\n                   \"qsci/\", \"sip/\", \"translations/\", \"uic/\"):\n        abspath = os.path.abspath(\"PyQt5/\" + subdir)\n        for root, dirs, files in os.walk(abspath):\n            for f in files:\n                fpath = os.path.join(root, f)\n                relpath = os.path.relpath(fpath, abspath)\n                relpath = relpath.replace(\"\\\\\", \"/\")\n                package_data['PyQt5'].append(subdir + relpath)\n\n    package_data['PyQt5'].extend([\"*.exe\",\n                                  \"*.dll\",\n                                  \"*.pyd\",\n                                  \"*.conf\",\n                                  \"*.api\",\n                                  \"*.qm\",\n                                  \"*.bat\"])\n    return package_data", "response": "Return a dictionary of all files from all sub - directories"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _preview(self):\n\n        from PyQt5 import QtWidgets\n\n        app = QtWidgets.QApplication([self._ui_file])\n        widget = loadUi(self._ui_file)\n        widget.show()\n\n        return app.exec_()", "response": "Preview the. ui file. Return the exit status to be passed back to\n        the parent process."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _generate(self):\n\n        needs_close = False\n\n        if sys.hexversion >= 0x03000000:\n            if self._opts.output == '-':\n                from io import TextIOWrapper\n\n                pyfile = TextIOWrapper(sys.stdout.buffer, encoding='utf8')\n            else:\n                pyfile = open(self._opts.output, 'wt', encoding='utf8')\n                needs_close = True\n        else:\n            if self._opts.output == '-':\n                pyfile = sys.stdout\n            else:\n                pyfile = open(self._opts.output, 'wt')\n                needs_close = True\n\n        import_from = self._opts.import_from\n\n        if import_from:\n            from_imports = True\n        elif self._opts.from_imports:\n            from_imports = True\n            import_from = '.'\n        else:\n            from_imports = False\n\n        compileUi(self._ui_file, pyfile, self._opts.execute, self._opts.indent,\n                from_imports, self._opts.resource_suffix, import_from)\n\n        if needs_close:\n            pyfile.close()", "response": "Generates the Python code."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle an IOError exception.", "response": "def on_IOError(self, e):\n        \"\"\" Handle an IOError exception. \"\"\"\n\n        sys.stderr.write(\"Error: %s: \\\"%s\\\"\\n\" % (e.strerror, e.filename))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_Exception(self, e):\n\n        if logging.getLogger(self.LOGGER_NAME).level == logging.DEBUG:\n            import traceback\n\n            traceback.print_exception(*sys.exc_info())\n        else:\n            from PyQt5 import QtCore\n\n            sys.stderr.write(\"\"\"An unexpected error occurred.\nCheck that you are using the latest version of PyQt5 and send an error report to\nsupport@riverbankcomputing.com, including the following information:\n\n  * your version of PyQt (%s)\n  * the UI file that caused this error\n  * the debug output of pyuic5 (use the -d flag when calling pyuic5)\n\"\"\" % QtCore.PYQT_VERSION_STR)", "response": "Handle an unexpected exception."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the plugin from the given file.", "response": "def load_plugin(filename, plugin_globals, plugin_locals):\n        \"\"\" Load the plugin from the given file.  Return True if the plugin was\n        loaded, or False if it wanted to be ignored.  Raise an exception if\n        there was an error.\n        \"\"\"\n\n        plugin = open(filename, 'rU')\n\n        try:\n            exec(plugin.read(), plugin_globals, plugin_locals)\n        except ImportError:\n            return False\n        except Exception as e:\n            raise WidgetPluginError(\"%s: %s\" % (e.__class__, str(e)))\n        finally:\n            plugin.close()\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing an RFC822 date string into a date object.", "response": "def _parse_date_rfc822(dateString):\n    '''Parse an RFC822, RFC1123, RFC2822, or asctime-style date'''\n    data = dateString.split()\n    if data[0][-1] in (',', '.') or data[0].lower() in _daynames:\n        del data[0]\n    if len(data) == 4:\n        s = data[3]\n        s = s.split('+', 1)\n        if len(s) == 2:\n            data[3:] = s\n        else:\n            data.append('')\n        dateString = \" \".join(data)\n    if len(data) < 5:\n        dateString += ' 00:00:00 GMT'\n    return email.utils.parsedate_tz(dateString)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize symbols and single character constants.", "response": "def _initSymbols(ptc):\n    \"\"\"\n    Initialize symbols and single character constants.\n    \"\"\"\n    # build am and pm lists to contain\n    # original case, lowercase, first-char and dotted\n    # versions of the meridian text\n    ptc.am = ['', '']\n    ptc.pm = ['', '']\n    for idx, xm in enumerate(ptc.locale.meridian[:2]):\n        # 0: am\n        # 1: pm\n        target = ['am', 'pm'][idx]\n        setattr(ptc, target, [xm])\n        target = getattr(ptc, target)\n        if xm:\n            lxm = xm.lower()\n            target.extend((xm[0], '{0}.{1}.'.format(*xm),\n                           lxm, lxm[0], '{0}.{1}.'.format(*lxm)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _convertUnitAsWords(self, unitText):\n        word_list, a, b = re.split(r\"[,\\s-]+\", unitText), 0, 0\n        for word in word_list:\n            x = self.ptc.small.get(word)\n            if x is not None:\n                a += x\n            elif word == \"hundred\":\n                a *= 100\n            else:\n                x = self.ptc.magnitude.get(word)\n                if x is not None:\n                    b += a * x\n                    a = 0\n                elif word in self.ptc.ignore:\n                    pass\n                else:\n                    raise Exception(\"Unknown number: \" + word)\n        return a + b", "response": "Converts text units into their number value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding the time for the given source and quantity and units.", "response": "def _buildTime(self, source, quantity, modifier, units):\n        \"\"\"\n        Take C{quantity}, C{modifier} and C{unit} strings and convert them\n        into values. After converting, calcuate the time and return the\n        adjusted sourceTime.\n\n        @type  source:   time\n        @param source:   time to use as the base (or source)\n        @type  quantity: string\n        @param quantity: quantity string\n        @type  modifier: string\n        @param modifier: how quantity and units modify the source time\n        @type  units:    string\n        @param units:    unit of the quantity (i.e. hours, days, months, etc)\n\n        @rtype:  struct_time\n        @return: C{struct_time} of the calculated time\n        \"\"\"\n        ctx = self.currentContext\n        debug and log.debug('_buildTime: [%s][%s][%s]',\n                            quantity, modifier, units)\n\n        if source is None:\n            source = time.localtime()\n\n        if quantity is None:\n            quantity = ''\n        else:\n            quantity = quantity.strip()\n\n        qty = self._quantityToReal(quantity)\n\n        if modifier in self.ptc.Modifiers:\n            qty = qty * self.ptc.Modifiers[modifier]\n\n            if units is None or units == '':\n                units = 'dy'\n\n        # plurals are handled by regex's (could be a bug tho)\n\n        (yr, mth, dy, hr, mn, sec, _, _, _) = source\n\n        start = datetime.datetime(yr, mth, dy, hr, mn, sec)\n        target = start\n        # realunit = next((key for key, values in self.ptc.units.items()\n        #                  if any(imap(units.__contains__, values))), None)\n        realunit = units\n        for key, values in self.ptc.units.items():\n            if units in values:\n                realunit = key\n                break\n\n        debug and log.debug('units %s --> realunit %s (qty=%s)',\n                            units, realunit, qty)\n\n        try:\n            if realunit in ('years', 'months'):\n                target = self.inc(start, **{realunit[:-1]: qty})\n            elif realunit in ('days', 'hours', 'minutes', 'seconds', 'weeks'):\n                delta = datetime.timedelta(**{realunit: qty})\n                target = start + delta\n        except OverflowError:\n            # OverflowError is raise when target.year larger than 9999\n            pass\n        else:\n            ctx.updateAccuracy(realunit)\n\n        return target.timetuple()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a short - form date string and return a C { struct_time } value.", "response": "def parseDate(self, dateString, sourceTime=None):\n        \"\"\"\n        Parse short-form date strings::\n\n            '05/28/2006' or '04.21'\n\n        @type  dateString: string\n        @param dateString: text to convert to a C{datetime}\n        @type  sourceTime:     struct_time\n        @param sourceTime:     C{struct_time} value to use as the base\n\n        @rtype:  struct_time\n        @return: calculated C{struct_time} value of dateString\n        \"\"\"\n        if sourceTime is None:\n            yr, mth, dy, hr, mn, sec, wd, yd, isdst = time.localtime()\n        else:\n            yr, mth, dy, hr, mn, sec, wd, yd, isdst = sourceTime\n\n        # values pulled from regex's will be stored here and later\n        # assigned to mth, dy, yr based on information from the locale\n        # -1 is used as the marker value because we want zero values\n        # to be passed thru so they can be flagged as errors later\n        v1 = -1\n        v2 = -1\n        v3 = -1\n        accuracy = []\n\n        s = dateString\n        m = self.ptc.CRE_DATE2.search(s)\n        if m is not None:\n            index = m.start()\n            v1 = int(s[:index])\n            s = s[index + 1:]\n\n        m = self.ptc.CRE_DATE2.search(s)\n        if m is not None:\n            index = m.start()\n            v2 = int(s[:index])\n            v3 = int(s[index + 1:])\n        else:\n            v2 = int(s.strip())\n\n        v = [v1, v2, v3]\n        d = {'m': mth, 'd': dy, 'y': yr}\n\n        # yyyy/mm/dd format\n        dp_order = self.ptc.dp_order if v1 <= 31 else ['y', 'm', 'd']\n\n        for i in range(0, 3):\n            n = v[i]\n            c = dp_order[i]\n            if n >= 0:\n                d[c] = n\n                accuracy.append({'m': pdtContext.ACU_MONTH,\n                                 'd': pdtContext.ACU_DAY,\n                                 'y': pdtContext.ACU_YEAR}[c])\n\n        # if the year is not specified and the date has already\n        # passed, increment the year\n        if v3 == -1 and ((mth > d['m']) or (mth == d['m'] and dy > d['d'])):\n            yr = d['y'] + self.ptc.YearParseStyle\n        else:\n            yr = d['y']\n\n        mth = d['m']\n        dy = d['d']\n\n        # birthday epoch constraint\n        if yr < self.ptc.BirthdayEpoch:\n            yr += 2000\n        elif yr < 100:\n            yr += 1900\n\n        daysInCurrentMonth = self.ptc.daysInMonth(mth, yr)\n        debug and log.debug('parseDate: %s %s %s %s',\n                            yr, mth, dy, daysInCurrentMonth)\n\n        with self.context() as ctx:\n            if mth > 0 and mth <= 12 and dy > 0 and \\\n                    dy <= daysInCurrentMonth:\n                sourceTime = (yr, mth, dy, hr, mn, sec, wd, yd, isdst)\n                ctx.updateAccuracy(*accuracy)\n            else:\n                # return current time if date string is invalid\n                sourceTime = time.localtime()\n\n        return sourceTime"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parseDateText(self, dateString, sourceTime=None):\n        if sourceTime is None:\n            yr, mth, dy, hr, mn, sec, wd, yd, isdst = time.localtime()\n        else:\n            yr, mth, dy, hr, mn, sec, wd, yd, isdst = sourceTime\n\n        currentMth = mth\n        currentDy = dy\n        accuracy = []\n\n        debug and log.debug('parseDateText currentMth %s currentDy %s',\n                            mth, dy)\n\n        s = dateString.lower()\n        m = self.ptc.CRE_DATE3.search(s)\n        mth = m.group('mthname')\n        mth = self.ptc.MonthOffsets[mth]\n        accuracy.append('month')\n\n        if m.group('day') is not None:\n            dy = int(m.group('day'))\n            accuracy.append('day')\n        else:\n            dy = 1\n\n        if m.group('year') is not None:\n            yr = int(m.group('year'))\n            accuracy.append('year')\n\n            # birthday epoch constraint\n            if yr < self.ptc.BirthdayEpoch:\n                yr += 2000\n            elif yr < 100:\n                yr += 1900\n\n        elif (mth < currentMth) or (mth == currentMth and dy < currentDy):\n            # if that day and month have already passed in this year,\n            # then increment the year by 1\n            yr += self.ptc.YearParseStyle\n\n        with self.context() as ctx:\n            if dy > 0 and dy <= self.ptc.daysInMonth(mth, yr):\n                sourceTime = (yr, mth, dy, hr, mn, sec, wd, yd, isdst)\n                ctx.updateAccuracy(*accuracy)\n            else:\n                # Return current time if date string is invalid\n                sourceTime = time.localtime()\n\n        debug and log.debug('parseDateText returned '\n                            'mth %d dy %d yr %d sourceTime %s',\n                            mth, dy, yr, sourceTime)\n\n        return sourceTime", "response": "Parse a long - form date string into a base date and time."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nevaluates the text and determine if the base record is a date or time range.", "response": "def evalRanges(self, datetimeString, sourceTime=None):\n        \"\"\"\n        Evaluate the C{datetimeString} text and determine if\n        it represents a date or time range.\n\n        @type  datetimeString: string\n        @param datetimeString: datetime text to evaluate\n        @type  sourceTime:     struct_time\n        @param sourceTime:     C{struct_time} value to use as the base\n\n        @rtype:  tuple\n        @return: tuple of: start datetime, end datetime and the invalid flag\n        \"\"\"\n        rangeFlag = retFlag = 0\n        startStr = endStr = ''\n\n        s = datetimeString.strip().lower()\n\n        if self.ptc.rangeSep in s:\n            s = s.replace(self.ptc.rangeSep, ' %s ' % self.ptc.rangeSep)\n            s = s.replace('  ', ' ')\n\n        for cre, rflag in [(self.ptc.CRE_TIMERNG1, 1),\n                           (self.ptc.CRE_TIMERNG2, 2),\n                           (self.ptc.CRE_TIMERNG4, 7),\n                           (self.ptc.CRE_TIMERNG3, 3),\n                           (self.ptc.CRE_DATERNG1, 4),\n                           (self.ptc.CRE_DATERNG2, 5),\n                           (self.ptc.CRE_DATERNG3, 6)]:\n            m = cre.search(s)\n            if m is not None:\n                rangeFlag = rflag\n                break\n\n        debug and log.debug('evalRanges: rangeFlag = %s [%s]', rangeFlag, s)\n\n        if m is not None:\n            if (m.group() != s):\n                # capture remaining string\n                parseStr = m.group()\n                chunk1 = s[:m.start()]\n                chunk2 = s[m.end():]\n                s = '%s %s' % (chunk1, chunk2)\n\n                sourceTime, ctx = self.parse(s, sourceTime,\n                                             VERSION_CONTEXT_STYLE)\n\n                if not ctx.hasDateOrTime:\n                    sourceTime = None\n            else:\n                parseStr = s\n\n        if rangeFlag in (1, 2):\n            m = re.search(self.ptc.rangeSep, parseStr)\n            startStr = parseStr[:m.start()]\n            endStr = parseStr[m.start() + 1:]\n            retFlag = 2\n\n        elif rangeFlag in (3, 7):\n            m = re.search(self.ptc.rangeSep, parseStr)\n            # capturing the meridian from the end time\n            if self.ptc.usesMeridian:\n                ampm = re.search(self.ptc.am[0], parseStr)\n\n                # appending the meridian to the start time\n                if ampm is not None:\n                    startStr = parseStr[:m.start()] + self.ptc.meridian[0]\n                else:\n                    startStr = parseStr[:m.start()] + self.ptc.meridian[1]\n            else:\n                startStr = parseStr[:m.start()]\n\n            endStr = parseStr[m.start() + 1:]\n            retFlag = 2\n\n        elif rangeFlag == 4:\n            m = re.search(self.ptc.rangeSep, parseStr)\n            startStr = parseStr[:m.start()]\n            endStr = parseStr[m.start() + 1:]\n            retFlag = 1\n\n        elif rangeFlag == 5:\n            m = re.search(self.ptc.rangeSep, parseStr)\n            endStr = parseStr[m.start() + 1:]\n\n            # capturing the year from the end date\n            date = self.ptc.CRE_DATE3.search(endStr)\n            endYear = date.group('year')\n\n            # appending the year to the start date if the start date\n            # does not have year information and the end date does.\n            # eg : \"Aug 21 - Sep 4, 2007\"\n            if endYear is not None:\n                startStr = (parseStr[:m.start()]).strip()\n                date = self.ptc.CRE_DATE3.search(startStr)\n                startYear = date.group('year')\n\n                if startYear is None:\n                    startStr = startStr + ', ' + endYear\n            else:\n                startStr = parseStr[:m.start()]\n\n            retFlag = 1\n\n        elif rangeFlag == 6:\n            m = re.search(self.ptc.rangeSep, parseStr)\n\n            startStr = parseStr[:m.start()]\n\n            # capturing the month from the start date\n            mth = self.ptc.CRE_DATE3.search(startStr)\n            mth = mth.group('mthname')\n\n            # appending the month name to the end date\n            endStr = mth + parseStr[(m.start() + 1):]\n\n            retFlag = 1\n\n        else:\n            # if range is not found\n            startDT = endDT = time.localtime()\n\n        if retFlag:\n            startDT, sctx = self.parse(startStr, sourceTime,\n                                       VERSION_CONTEXT_STYLE)\n            endDT, ectx = self.parse(endStr, sourceTime,\n                                     VERSION_CONTEXT_STYLE)\n\n            if not sctx.hasDateOrTime or not ectx.hasDateOrTime:\n                retFlag = 0\n\n        return startDT, endDT, retFlag"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _CalculateDOWDelta(self, wd, wkdy, offset, style, currentDayStyle):\n        diffBase = wkdy - wd\n        origOffset = offset\n\n        if offset == 2:\n            # no modifier is present.\n            # i.e. string to be parsed is just DOW\n            if wkdy * style > wd * style or \\\n                    currentDayStyle and wkdy == wd:\n                # wkdy located in current week\n                offset = 0\n            elif style in (-1, 1):\n                # wkdy located in last (-1) or next (1) week\n                offset = style\n            else:\n                # invalid style, or should raise error?\n                offset = 0\n\n        # offset = -1 means last week\n        # offset = 0 means current week\n        # offset = 1 means next week\n        diff = diffBase + 7 * offset\n        if style == 1 and diff < -7:\n            diff += 7\n        elif style == -1 and diff > 7:\n            diff -= 7\n\n        debug and log.debug(\"wd %s, wkdy %s, offset %d, \"\n                            \"style %d, currentDayStyle %d\",\n                            wd, wkdy, origOffset, style, currentDayStyle)\n\n        return diff", "response": "Calculates the delta between the current and the current DOW values."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _quantityToReal(self, quantity):\n        if not quantity:\n            return 1.0\n\n        try:\n            return float(quantity.replace(',', '.'))\n        except ValueError:\n            pass\n\n        try:\n            return float(self.ptc.numbers[quantity])\n        except KeyError:\n            pass\n\n        return 0.0", "response": "Convert a quantity either spelled - out or numeric to a float"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nevaluate the modifier string and following text and return the modified sourceTime.", "response": "def _evalModifier(self, modifier, chunk1, chunk2, sourceTime):\n        \"\"\"\n        Evaluate the C{modifier} string and following text (passed in\n        as C{chunk1} and C{chunk2}) and if they match any known modifiers\n        calculate the delta and apply it to C{sourceTime}.\n\n        @type  modifier:   string\n        @param modifier:   modifier text to apply to sourceTime\n        @type  chunk1:     string\n        @param chunk1:     text chunk that preceded modifier (if any)\n        @type  chunk2:     string\n        @param chunk2:     text chunk that followed modifier (if any)\n        @type  sourceTime: struct_time\n        @param sourceTime: C{struct_time} value to use as the base\n\n        @rtype:  tuple\n        @return: tuple of: remaining text and the modified sourceTime\n        \"\"\"\n        ctx = self.currentContext\n        offset = self.ptc.Modifiers[modifier]\n\n        if sourceTime is not None:\n            (yr, mth, dy, hr, mn, sec, wd, yd, isdst) = sourceTime\n        else:\n            (yr, mth, dy, hr, mn, sec, wd, yd, isdst) = time.localtime()\n\n        if self.ptc.StartTimeFromSourceTime:\n            startHour = hr\n            startMinute = mn\n            startSecond = sec\n        else:\n            startHour = 9\n            startMinute = 0\n            startSecond = 0\n\n        # capture the units after the modifier and the remaining\n        # string after the unit\n        m = self.ptc.CRE_REMAINING.search(chunk2)\n        if m is not None:\n            index = m.start() + 1\n            unit = chunk2[:m.start()]\n            chunk2 = chunk2[index:]\n        else:\n            unit = chunk2\n            chunk2 = ''\n\n        debug and log.debug(\"modifier [%s] chunk1 [%s] \"\n                            \"chunk2 [%s] unit [%s]\",\n                            modifier, chunk1, chunk2, unit)\n\n        if unit in self.ptc.units['months']:\n            currentDaysInMonth = self.ptc.daysInMonth(mth, yr)\n            if offset == 0:\n                dy = currentDaysInMonth\n                sourceTime = (yr, mth, dy, startHour, startMinute,\n                              startSecond, wd, yd, isdst)\n            elif offset == 2:\n                # if day is the last day of the month, calculate the last day\n                # of the next month\n                if dy == currentDaysInMonth:\n                    dy = self.ptc.daysInMonth(mth + 1, yr)\n\n                start = datetime.datetime(yr, mth, dy, startHour,\n                                          startMinute, startSecond)\n                target = self.inc(start, month=1)\n                sourceTime = target.timetuple()\n            else:\n                start = datetime.datetime(yr, mth, 1, startHour,\n                                          startMinute, startSecond)\n                target = self.inc(start, month=offset)\n                sourceTime = target.timetuple()\n            ctx.updateAccuracy(ctx.ACU_MONTH)\n\n        elif unit in self.ptc.units['weeks']:\n            if offset == 0:\n                start = datetime.datetime(yr, mth, dy, 17, 0, 0)\n                target = start + datetime.timedelta(days=(4 - wd))\n                sourceTime = target.timetuple()\n            elif offset == 2:\n                start = datetime.datetime(yr, mth, dy, startHour,\n                                          startMinute, startSecond)\n                target = start + datetime.timedelta(days=7)\n                sourceTime = target.timetuple()\n            else:\n                start = datetime.datetime(yr, mth, dy, startHour,\n                                          startMinute, startSecond)\n                target = start + offset * datetime.timedelta(weeks=1)\n                sourceTime = target.timetuple()\n            ctx.updateAccuracy(ctx.ACU_WEEK)\n\n        elif unit in self.ptc.units['days']:\n            if offset == 0:\n                sourceTime = (yr, mth, dy, 17, 0, 0, wd, yd, isdst)\n                ctx.updateAccuracy(ctx.ACU_HALFDAY)\n            elif offset == 2:\n                start = datetime.datetime(yr, mth, dy, hr, mn, sec)\n                target = start + datetime.timedelta(days=1)\n                sourceTime = target.timetuple()\n            else:\n                start = datetime.datetime(yr, mth, dy, startHour,\n                                          startMinute, startSecond)\n                target = start + datetime.timedelta(days=offset)\n                sourceTime = target.timetuple()\n            ctx.updateAccuracy(ctx.ACU_DAY)\n\n        elif unit in self.ptc.units['hours']:\n            if offset == 0:\n                sourceTime = (yr, mth, dy, hr, 0, 0, wd, yd, isdst)\n            else:\n                start = datetime.datetime(yr, mth, dy, hr, 0, 0)\n                target = start + datetime.timedelta(hours=offset)\n                sourceTime = target.timetuple()\n            ctx.updateAccuracy(ctx.ACU_HOUR)\n\n        elif unit in self.ptc.units['years']:\n            if offset == 0:\n                sourceTime = (yr, 12, 31, hr, mn, sec, wd, yd, isdst)\n            elif offset == 2:\n                sourceTime = (yr + 1, mth, dy, hr, mn, sec, wd, yd, isdst)\n            else:\n                sourceTime = (yr + offset, 1, 1, startHour, startMinute,\n                              startSecond, wd, yd, isdst)\n            ctx.updateAccuracy(ctx.ACU_YEAR)\n\n        elif modifier == 'eom':\n            dy = self.ptc.daysInMonth(mth, yr)\n            sourceTime = (yr, mth, dy, startHour, startMinute,\n                          startSecond, wd, yd, isdst)\n            ctx.updateAccuracy(ctx.ACU_DAY)\n\n        elif modifier == 'eoy':\n            mth = 12\n            dy = self.ptc.daysInMonth(mth, yr)\n            sourceTime = (yr, mth, dy, startHour, startMinute,\n                          startSecond, wd, yd, isdst)\n            ctx.updateAccuracy(ctx.ACU_MONTH)\n\n        elif self.ptc.CRE_WEEKDAY.match(unit):\n            m = self.ptc.CRE_WEEKDAY.match(unit)\n            debug and log.debug('CRE_WEEKDAY matched')\n            wkdy = m.group()\n\n            if modifier == 'eod':\n                ctx.updateAccuracy(ctx.ACU_HOUR)\n                # Calculate the upcoming weekday\n                sourceTime, subctx = self.parse(wkdy, sourceTime,\n                                                VERSION_CONTEXT_STYLE)\n                sTime = self.ptc.getSource(modifier, sourceTime)\n                if sTime is not None:\n                    sourceTime = sTime\n                    ctx.updateAccuracy(ctx.ACU_HALFDAY)\n            else:\n                # unless one of these modifiers is being applied to the\n                # day-of-week, we want to start with target as the day\n                # in the current week.\n                dowOffset = offset\n                relativeModifier = modifier not in ['this', 'next', 'last', 'prior', 'previous']\n                if relativeModifier:\n                    dowOffset = 0\n\n                wkdy = self.ptc.WeekdayOffsets[wkdy]\n                diff = self._CalculateDOWDelta(\n                    wd, wkdy, dowOffset, self.ptc.DOWParseStyle,\n                    self.ptc.CurrentDOWParseStyle)\n                start = datetime.datetime(yr, mth, dy, startHour,\n                                          startMinute, startSecond)\n                target = start + datetime.timedelta(days=diff)\n\n                if chunk1 != '' and relativeModifier:\n                    # consider \"one day before thursday\": we need to parse chunk1 (\"one day\")\n                    # and apply according to the offset (\"before\"), rather than allowing the\n                    # remaining parse step to apply \"one day\" without the offset direction.\n                    t, subctx = self.parse(chunk1, sourceTime, VERSION_CONTEXT_STYLE)\n                    if subctx.hasDateOrTime:\n                        delta = time.mktime(t) - time.mktime(sourceTime)\n                        target = start + datetime.timedelta(days=diff) + datetime.timedelta(seconds=delta * offset)\n                        chunk1 = ''\n\n                sourceTime = target.timetuple()\n            ctx.updateAccuracy(ctx.ACU_DAY)\n\n        elif chunk1 == '' and chunk2 == '' and self.ptc.CRE_TIME.match(unit):\n            m = self.ptc.CRE_TIME.match(unit)\n            debug and log.debug('CRE_TIME matched')\n            (yr, mth, dy, hr, mn, sec, wd, yd, isdst), subctx = \\\n                self.parse(unit, None, VERSION_CONTEXT_STYLE)\n\n            start = datetime.datetime(yr, mth, dy, hr, mn, sec)\n            target = start + datetime.timedelta(days=offset)\n            sourceTime = target.timetuple()\n\n        else:\n            # check if the remaining text is parsable and if so,\n            # use it as the base time for the modifier source time\n\n            debug and log.debug('check for modifications '\n                                'to source time [%s] [%s]',\n                                chunk1, unit)\n\n            unit = unit.strip()\n            if unit:\n                s = '%s %s' % (unit, chunk2)\n                t, subctx = self.parse(s, sourceTime, VERSION_CONTEXT_STYLE)\n\n                if subctx.hasDate:  # working with dates\n                    u = unit.lower()\n                    if u in self.ptc.Months or \\\n                            u in self.ptc.shortMonths:\n                        yr, mth, dy, hr, mn, sec, wd, yd, isdst = t\n                        start = datetime.datetime(\n                            yr, mth, dy, hr, mn, sec)\n                        t = self.inc(start, year=offset).timetuple()\n                    elif u in self.ptc.Weekdays:\n                        t = t + datetime.timedelta(weeks=offset)\n\n                if subctx.hasDateOrTime:\n                    sourceTime = t\n                    chunk2 = ''\n\n            chunk1 = chunk1.strip()\n\n            # if the word after next is a number, the string is more than\n            # likely to be \"next 4 hrs\" which we will have to combine the\n            # units with the rest of the string\n            if chunk1:\n                try:\n                    m = list(self.ptc.CRE_NUMBER.finditer(chunk1))[-1]\n                except IndexError:\n                    pass\n                else:\n                    qty = None\n                    debug and log.debug('CRE_NUMBER matched')\n                    qty = self._quantityToReal(m.group()) * offset\n                    chunk1 = '%s%s%s' % (chunk1[:m.start()],\n                                         qty, chunk1[m.end():])\n                t, subctx = self.parse(chunk1, sourceTime,\n                                       VERSION_CONTEXT_STYLE)\n\n                chunk1 = ''\n\n                if subctx.hasDateOrTime:\n                    sourceTime = t\n\n            debug and log.debug('looking for modifier %s', modifier)\n            sTime = self.ptc.getSource(modifier, sourceTime)\n            if sTime is not None:\n                debug and log.debug('modifier found in sources')\n                sourceTime = sTime\n                ctx.updateAccuracy(ctx.ACU_HALFDAY)\n\n        debug and log.debug('returning chunk = \"%s %s\" and sourceTime = %s',\n                            chunk1, chunk2, sourceTime)\n\n        return '%s %s' % (chunk1, chunk2), sourceTime"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the datetime from a string of ISO 8601 or W3CDTF formatted dates and return the parsed datetime.", "response": "def _evalDT(self, datetimeString, sourceTime):\n        \"\"\"\n        Calculate the datetime from known format like RFC822 or W3CDTF\n\n        Examples handled::\n            RFC822, W3CDTF formatted dates\n            HH:MM[:SS][ am/pm]\n            MM/DD/YYYY\n            DD MMMM YYYY\n\n        @type  datetimeString: string\n        @param datetimeString: text to try and parse as more \"traditional\"\n                               date/time text\n        @type  sourceTime:     struct_time\n        @param sourceTime:     C{struct_time} value to use as the base\n\n        @rtype:  datetime\n        @return: calculated C{struct_time} value or current C{struct_time}\n                 if not parsed\n        \"\"\"\n        ctx = self.currentContext\n        s = datetimeString.strip()\n\n        # Given string date is a RFC822 date\n        if sourceTime is None:\n            sourceTime = _parse_date_rfc822(s)\n            debug and log.debug(\n                'attempt to parse as rfc822 - %s', str(sourceTime))\n\n            if sourceTime is not None:\n                (yr, mth, dy, hr, mn, sec, wd, yd, isdst, _) = sourceTime\n                ctx.updateAccuracy(ctx.ACU_YEAR, ctx.ACU_MONTH, ctx.ACU_DAY)\n\n                if hr != 0 and mn != 0 and sec != 0:\n                    ctx.updateAccuracy(ctx.ACU_HOUR, ctx.ACU_MIN, ctx.ACU_SEC)\n\n                sourceTime = (yr, mth, dy, hr, mn, sec, wd, yd, isdst)\n\n        # Given string date is a W3CDTF date\n        if sourceTime is None:\n            sourceTime = _parse_date_w3dtf(s)\n\n            if sourceTime is not None:\n                ctx.updateAccuracy(ctx.ACU_YEAR, ctx.ACU_MONTH, ctx.ACU_DAY,\n                                   ctx.ACU_HOUR, ctx.ACU_MIN, ctx.ACU_SEC)\n\n        if sourceTime is None:\n            sourceTime = time.localtime()\n\n        return sourceTime"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _evalUnits(self, datetimeString, sourceTime):\n        s = datetimeString.strip()\n        sourceTime = self._evalDT(datetimeString, sourceTime)\n\n        # Given string is a time string with units like \"5 hrs 30 min\"\n        modifier = ''  # TODO\n\n        m = self.ptc.CRE_UNITS.search(s)\n        if m is not None:\n            units = m.group('units')\n            quantity = s[:m.start('units')]\n\n        sourceTime = self._buildTime(sourceTime, quantity, modifier, units)\n        return sourceTime", "response": "Evaluate text passed by L { _partialParseUnits } and build a time object"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nevaluate text passed by L { _partialParseQUnits } and build a time object", "response": "def _evalQUnits(self, datetimeString, sourceTime):\n        \"\"\"\n        Evaluate text passed by L{_partialParseQUnits()}\n        \"\"\"\n        s = datetimeString.strip()\n        sourceTime = self._evalDT(datetimeString, sourceTime)\n\n        # Given string is a time string with single char units like \"5 h 30 m\"\n        modifier = ''  # TODO\n\n        m = self.ptc.CRE_QUNITS.search(s)\n        if m is not None:\n            units = m.group('qunits')\n            quantity = s[:m.start('qunits')]\n\n        sourceTime = self._buildTime(sourceTime, quantity, modifier, units)\n        return sourceTime"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nevaluate the given string and return a datetime object.", "response": "def _evalDateStr(self, datetimeString, sourceTime):\n        \"\"\"\n        Evaluate text passed by L{_partialParseDateStr()}\n        \"\"\"\n        s = datetimeString.strip()\n        sourceTime = self._evalDT(datetimeString, sourceTime)\n\n        # Given string is in the format  \"May 23rd, 2005\"\n        debug and log.debug('checking for MMM DD YYYY')\n        return self.parseDateText(s, sourceTime)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nevaluating text passed by L { _partialParseDateStd } and return a datetime object.", "response": "def _evalDateStd(self, datetimeString, sourceTime):\n        \"\"\"\n        Evaluate text passed by L{_partialParseDateStd()}\n        \"\"\"\n        s = datetimeString.strip()\n        sourceTime = self._evalDT(datetimeString, sourceTime)\n\n        # Given string is in the format 07/21/2006\n        return self.parseDate(s, sourceTime)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nevaluate the given string and return a datetime. datetime object.", "response": "def _evalDayStr(self, datetimeString, sourceTime):\n        \"\"\"\n        Evaluate text passed by L{_partialParseDaystr()}\n        \"\"\"\n        s = datetimeString.strip()\n        sourceTime = self._evalDT(datetimeString, sourceTime)\n\n        # Given string is a natural language date string like today, tomorrow..\n        (yr, mth, dy, hr, mn, sec, wd, yd, isdst) = sourceTime\n\n        try:\n            offset = self.ptc.dayOffsets[s]\n        except KeyError:\n            offset = 0\n\n        if self.ptc.StartTimeFromSourceTime:\n            startHour = hr\n            startMinute = mn\n            startSecond = sec\n        else:\n            startHour = 9\n            startMinute = 0\n            startSecond = 0\n\n        self.currentContext.updateAccuracy(pdtContext.ACU_DAY)\n        start = datetime.datetime(yr, mth, dy, startHour,\n                                  startMinute, startSecond)\n        target = start + datetime.timedelta(days=offset)\n        return target.timetuple()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nevaluates text passed by L { _partialParseWeekday } and return a datetime. datetime object.", "response": "def _evalWeekday(self, datetimeString, sourceTime):\n        \"\"\"\n        Evaluate text passed by L{_partialParseWeekday()}\n        \"\"\"\n        s = datetimeString.strip()\n        sourceTime = self._evalDT(datetimeString, sourceTime)\n\n        # Given string is a weekday\n        yr, mth, dy, hr, mn, sec, wd, yd, isdst = sourceTime\n\n        start = datetime.datetime(yr, mth, dy, hr, mn, sec)\n        wkdy = self.ptc.WeekdayOffsets[s]\n\n        if wkdy > wd:\n            qty = self._CalculateDOWDelta(wd, wkdy, 2,\n                                          self.ptc.DOWParseStyle,\n                                          self.ptc.CurrentDOWParseStyle)\n        else:\n            qty = self._CalculateDOWDelta(wd, wkdy, 2,\n                                          self.ptc.DOWParseStyle,\n                                          self.ptc.CurrentDOWParseStyle)\n\n        self.currentContext.updateAccuracy(pdtContext.ACU_DAY)\n        target = start + datetime.timedelta(days=qty)\n        return target.timetuple()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _evalTimeStr(self, datetimeString, sourceTime):\n        s = datetimeString.strip()\n        sourceTime = self._evalDT(datetimeString, sourceTime)\n\n        if s in self.ptc.re_values['now']:\n            self.currentContext.updateAccuracy(pdtContext.ACU_NOW)\n        else:\n            # Given string is a natural language time string like\n            # lunch, midnight, etc\n            sTime = self.ptc.getSource(s, sourceTime)\n            if sTime:\n                sourceTime = sTime\n            self.currentContext.updateAccuracy(pdtContext.ACU_HALFDAY)\n\n        return sourceTime", "response": "Evaluate text passed by L { _partialParseTimeStr } and return the source time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _evalMeridian(self, datetimeString, sourceTime):\n        s = datetimeString.strip()\n        sourceTime = self._evalDT(datetimeString, sourceTime)\n\n        # Given string is in the format HH:MM(:SS)(am/pm)\n        yr, mth, dy, hr, mn, sec, wd, yd, isdst = sourceTime\n\n        m = self.ptc.CRE_TIMEHMS2.search(s)\n        if m is not None:\n            dt = s[:m.start('meridian')].strip()\n            if len(dt) <= 2:\n                hr = int(dt)\n                mn = 0\n                sec = 0\n            else:\n                hr, mn, sec = _extract_time(m)\n\n            if hr == 24:\n                hr = 0\n\n            meridian = m.group('meridian').lower()\n\n            # if 'am' found and hour is 12 - force hour to 0 (midnight)\n            if (meridian in self.ptc.am) and hr == 12:\n                hr = 0\n\n            # if 'pm' found and hour < 12, add 12 to shift to evening\n            if (meridian in self.ptc.pm) and hr < 12:\n                hr += 12\n\n        # time validation\n        if hr < 24 and mn < 60 and sec < 60:\n            sourceTime = (yr, mth, dy, hr, mn, sec, wd, yd, isdst)\n            _pop_time_accuracy(m, self.currentContext)\n\n        return sourceTime", "response": "Evaluate text passed by L { _partialParseMeridian } and return a tuple of the time and the meridian of the source time."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _evalTimeStd(self, datetimeString, sourceTime):\n        s = datetimeString.strip()\n        sourceTime = self._evalDT(datetimeString, sourceTime)\n\n        # Given string is in the format HH:MM(:SS)\n        yr, mth, dy, hr, mn, sec, wd, yd, isdst = sourceTime\n\n        m = self.ptc.CRE_TIMEHMS.search(s)\n        if m is not None:\n            hr, mn, sec = _extract_time(m)\n        if hr == 24:\n            hr = 0\n\n        # time validation\n        if hr < 24 and mn < 60 and sec < 60:\n            sourceTime = (yr, mth, dy, hr, mn, sec, wd, yd, isdst)\n            _pop_time_accuracy(m, self.currentContext)\n\n        return sourceTime", "response": "Evaluate text passed by L { _partialParseTimeStd } and return the source time."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the MODIFIER and return the remaining string s and sourceTime.", "response": "def _partialParseModifier(self, s, sourceTime):\n        \"\"\"\n        test if giving C{s} matched CRE_MODIFIER, used by L{parse()}\n\n        @type  s:          string\n        @param s:          date/time text to evaluate\n        @type  sourceTime: struct_time\n        @param sourceTime: C{struct_time} value to use as the base\n\n        @rtype:  tuple\n        @return: tuple of remained date/time text, datetime object and\n                 an boolean value to describ if matched or not\n\n        \"\"\"\n        parseStr = None\n        chunk1 = chunk2 = ''\n\n        # Modifier like next/prev/from/after/prior..\n        m = self.ptc.CRE_MODIFIER.search(s)\n        if m is not None:\n            if m.group() != s:\n                # capture remaining string\n                parseStr = m.group()\n                chunk1 = s[:m.start()].strip()\n                chunk2 = s[m.end():].strip()\n            else:\n                parseStr = s\n\n        if parseStr:\n            debug and log.debug('found (modifier) [%s][%s][%s]',\n                                parseStr, chunk1, chunk2)\n            s, sourceTime = self._evalModifier(parseStr, chunk1,\n                                               chunk2, sourceTime)\n\n        return s, sourceTime, bool(parseStr)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntest if giving s matched CRE_UNITS and return s datetime object and a boolean value to describ if matched or not", "response": "def _partialParseUnits(self, s, sourceTime):\n        \"\"\"\n        test if giving C{s} matched CRE_UNITS, used by L{parse()}\n\n        @type  s:          string\n        @param s:          date/time text to evaluate\n        @type  sourceTime: struct_time\n        @param sourceTime: C{struct_time} value to use as the base\n\n        @rtype:  tuple\n        @return: tuple of remained date/time text, datetime object and\n                 an boolean value to describ if matched or not\n\n        \"\"\"\n        parseStr = None\n        chunk1 = chunk2 = ''\n\n        # Quantity + Units\n        m = self.ptc.CRE_UNITS.search(s)\n        if m is not None:\n            debug and log.debug('CRE_UNITS matched')\n            if self._UnitsTrapped(s, m, 'units'):\n                debug and log.debug('day suffix trapped by unit match')\n            else:\n                if (m.group('qty') != s):\n                    # capture remaining string\n                    parseStr = m.group('qty')\n                    chunk1 = s[:m.start('qty')].strip()\n                    chunk2 = s[m.end('qty'):].strip()\n\n                    if chunk1[-1:] == '-':\n                        parseStr = '-%s' % parseStr\n                        chunk1 = chunk1[:-1]\n\n                    s = '%s %s' % (chunk1, chunk2)\n                else:\n                    parseStr = s\n                    s = ''\n\n        if parseStr:\n            debug and log.debug('found (units) [%s][%s][%s]',\n                                parseStr, chunk1, chunk2)\n            sourceTime = self._evalUnits(parseStr, sourceTime)\n\n        return s, sourceTime, bool(parseStr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the string s containing CRE_QUNITS and return the parsed string s and sourceTime.", "response": "def _partialParseQUnits(self, s, sourceTime):\n        \"\"\"\n        test if giving C{s} matched CRE_QUNITS, used by L{parse()}\n\n        @type  s:          string\n        @param s:          date/time text to evaluate\n        @type  sourceTime: struct_time\n        @param sourceTime: C{struct_time} value to use as the base\n\n        @rtype:  tuple\n        @return: tuple of remained date/time text, datetime object and\n                 an boolean value to describ if matched or not\n\n        \"\"\"\n        parseStr = None\n        chunk1 = chunk2 = ''\n\n        # Quantity + Units\n        m = self.ptc.CRE_QUNITS.search(s)\n        if m is not None:\n            debug and log.debug('CRE_QUNITS matched')\n            if self._UnitsTrapped(s, m, 'qunits'):\n                debug and log.debug(\n                    'day suffix trapped by qunit match')\n            else:\n                if (m.group('qty') != s):\n                    # capture remaining string\n                    parseStr = m.group('qty')\n                    chunk1 = s[:m.start('qty')].strip()\n                    chunk2 = s[m.end('qty'):].strip()\n\n                    if chunk1[-1:] == '-':\n                        parseStr = '-%s' % parseStr\n                        chunk1 = chunk1[:-1]\n\n                    s = '%s %s' % (chunk1, chunk2)\n                else:\n                    parseStr = s\n                    s = ''\n\n        if parseStr:\n            debug and log.debug('found (qunits) [%s][%s][%s]',\n                                parseStr, chunk1, chunk2)\n            sourceTime = self._evalQUnits(parseStr, sourceTime)\n\n        return s, sourceTime, bool(parseStr)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntest if giving C{s} matched CRE_DATE3, used by L{parse()} @type s: string @param s: date/time text to evaluate @type sourceTime: struct_time @param sourceTime: C{struct_time} value to use as the base @rtype: tuple @return: tuple of remained date/time text, datetime object and an boolean value to describ if matched or not", "response": "def _partialParseDateStr(self, s, sourceTime):\n        \"\"\"\n        test if giving C{s} matched CRE_DATE3, used by L{parse()}\n\n        @type  s:          string\n        @param s:          date/time text to evaluate\n        @type  sourceTime: struct_time\n        @param sourceTime: C{struct_time} value to use as the base\n\n        @rtype:  tuple\n        @return: tuple of remained date/time text, datetime object and\n                 an boolean value to describ if matched or not\n\n        \"\"\"\n        parseStr = None\n        chunk1 = chunk2 = ''\n\n        m = self.ptc.CRE_DATE3.search(s)\n        # NO LONGER NEEDED, THE REGEXP HANDLED MTHNAME NOW\n        # for match in self.ptc.CRE_DATE3.finditer(s):\n        # to prevent \"HH:MM(:SS) time strings\" expressions from\n        # triggering this regex, we checks if the month field\n        # exists in the searched expression, if it doesn't exist,\n        # the date field is not valid\n        #     if match.group('mthname'):\n        #         m = self.ptc.CRE_DATE3.search(s, match.start())\n        #         valid_date = True\n        #         break\n\n        # String date format\n        if m is not None:\n\n            if (m.group('date') != s):\n                # capture remaining string\n                mStart = m.start('date')\n                mEnd = m.end('date')\n\n                # we need to check that anything following the parsed\n                # date is a time expression because it is often picked\n                # up as a valid year if the hour is 2 digits\n                fTime = False\n                mm = self.ptc.CRE_TIMEHMS2.search(s)\n                # \"February 24th 1PM\" doesn't get caught\n                # \"February 24th 12PM\" does\n                mYear = m.group('year')\n                if mm is not None and mYear is not None:\n                    fTime = True\n                else:\n                    # \"February 24th 12:00\"\n                    mm = self.ptc.CRE_TIMEHMS.search(s)\n                    if mm is not None and mYear is None:\n                        fTime = True\n                if fTime:\n                    hoursStart = mm.start('hours')\n\n                    if hoursStart < m.end('year'):\n                        mEnd = hoursStart\n\n                parseStr = s[mStart:mEnd]\n                chunk1 = s[:mStart]\n                chunk2 = s[mEnd:]\n\n                s = '%s %s' % (chunk1, chunk2)\n            else:\n                parseStr = s\n                s = ''\n\n        if parseStr:\n            debug and log.debug(\n                'found (date3) [%s][%s][%s]', parseStr, chunk1, chunk2)\n            sourceTime = self._evalDateStr(parseStr, sourceTime)\n\n        return s, sourceTime, bool(parseStr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _partialParseDateStd(self, s, sourceTime):\n        parseStr = None\n        chunk1 = chunk2 = ''\n\n        # Standard date format\n        m = self.ptc.CRE_DATE.search(s)\n        if m is not None:\n\n            if (m.group('date') != s):\n                # capture remaining string\n                parseStr = m.group('date')\n                chunk1 = s[:m.start('date')]\n                chunk2 = s[m.end('date'):]\n                s = '%s %s' % (chunk1, chunk2)\n            else:\n                parseStr = s\n                s = ''\n\n        if parseStr:\n            debug and log.debug(\n                'found (date) [%s][%s][%s]', parseStr, chunk1, chunk2)\n            sourceTime = self._evalDateStd(parseStr, sourceTime)\n\n        return s, sourceTime, bool(parseStr)", "response": "Parse the date in the standard date format and return the date and the boolean value to describ if matched or not"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _partialParseDayStr(self, s, sourceTime):\n        parseStr = None\n        chunk1 = chunk2 = ''\n\n        # Natural language day strings\n        m = self.ptc.CRE_DAY.search(s)\n        if m is not None:\n\n            if (m.group() != s):\n                # capture remaining string\n                parseStr = m.group()\n                chunk1 = s[:m.start()]\n                chunk2 = s[m.end():]\n                s = '%s %s' % (chunk1, chunk2)\n            else:\n                parseStr = s\n                s = ''\n\n        if parseStr:\n            debug and log.debug(\n                'found (day) [%s][%s][%s]', parseStr, chunk1, chunk2)\n            sourceTime = self._evalDayStr(parseStr, sourceTime)\n\n        return s, sourceTime, bool(parseStr)", "response": "Test if giving C { s matched CRE_DAY and return the parsed date and time object and a boolean value to describ if matched or not"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the weekday and return the parsed date and time.", "response": "def _partialParseWeekday(self, s, sourceTime):\n        \"\"\"\n        test if giving C{s} matched CRE_WEEKDAY, used by L{parse()}\n\n        @type  s:          string\n        @param s:          date/time text to evaluate\n        @type  sourceTime: struct_time\n        @param sourceTime: C{struct_time} value to use as the base\n\n        @rtype:  tuple\n        @return: tuple of remained date/time text, datetime object and\n                 an boolean value to describ if matched or not\n\n        \"\"\"\n        parseStr = None\n        chunk1 = chunk2 = ''\n\n        ctx = self.currentContext\n        log.debug('eval %s with context - %s, %s', s, ctx.hasDate, ctx.hasTime)\n\n        # Weekday\n        m = self.ptc.CRE_WEEKDAY.search(s)\n        if m is not None:\n            gv = m.group()\n            if s not in self.ptc.dayOffsets:\n\n                if (gv != s):\n                    # capture remaining string\n                    parseStr = gv\n                    chunk1 = s[:m.start()]\n                    chunk2 = s[m.end():]\n                    s = '%s %s' % (chunk1, chunk2)\n                else:\n                    parseStr = s\n                    s = ''\n\n        if parseStr and not ctx.hasDate:\n            debug and log.debug(\n                'found (weekday) [%s][%s][%s]', parseStr, chunk1, chunk2)\n            sourceTime = self._evalWeekday(parseStr, sourceTime)\n\n        return s, sourceTime, bool(parseStr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _partialParseTimeStr(self, s, sourceTime):\n        parseStr = None\n        chunk1 = chunk2 = ''\n\n        # Natural language time strings\n        m = self.ptc.CRE_TIME.search(s)\n        if m is not None or s in self.ptc.re_values['now']:\n\n            if (m and m.group() != s):\n                # capture remaining string\n                parseStr = m.group()\n                chunk1 = s[:m.start()]\n                chunk2 = s[m.end():]\n                s = '%s %s' % (chunk1, chunk2)\n            else:\n                parseStr = s\n                s = ''\n\n        if parseStr:\n            debug and log.debug(\n                'found (time) [%s][%s][%s]', parseStr, chunk1, chunk2)\n            sourceTime = self._evalTimeStr(parseStr, sourceTime)\n\n        return s, sourceTime, bool(parseStr)", "response": "Test if giving C { s matched CRE_TIME and return the parsed string and the source time and a boolean value to describ if matched or not"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the meridian of a string.", "response": "def _partialParseMeridian(self, s, sourceTime):\n        \"\"\"\n        test if giving C{s} matched CRE_TIMEHMS2, used by L{parse()}\n\n        @type  s:          string\n        @param s:          date/time text to evaluate\n        @type  sourceTime: struct_time\n        @param sourceTime: C{struct_time} value to use as the base\n\n        @rtype:  tuple\n        @return: tuple of remained date/time text, datetime object and\n                 an boolean value to describ if matched or not\n\n        \"\"\"\n        parseStr = None\n        chunk1 = chunk2 = ''\n\n        # HH:MM(:SS) am/pm time strings\n        m = self.ptc.CRE_TIMEHMS2.search(s)\n        if m is not None:\n\n            if m.group('minutes') is not None:\n                if m.group('seconds') is not None:\n                    parseStr = '%s:%s:%s' % (m.group('hours'),\n                                             m.group('minutes'),\n                                             m.group('seconds'))\n                else:\n                    parseStr = '%s:%s' % (m.group('hours'),\n                                          m.group('minutes'))\n            else:\n                parseStr = m.group('hours')\n            parseStr += ' ' + m.group('meridian')\n\n            chunk1 = s[:m.start()]\n            chunk2 = s[m.end():]\n\n            s = '%s %s' % (chunk1, chunk2)\n\n        if parseStr:\n            debug and log.debug('found (meridian) [%s][%s][%s]',\n                                parseStr, chunk1, chunk2)\n            sourceTime = self._evalMeridian(parseStr, sourceTime)\n\n        return s, sourceTime, bool(parseStr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the string s and return the date and time of the base object and a boolean value to describ if matched or not", "response": "def _partialParseTimeStd(self, s, sourceTime):\n        \"\"\"\n        test if giving C{s} matched CRE_TIMEHMS, used by L{parse()}\n\n        @type  s:          string\n        @param s:          date/time text to evaluate\n        @type  sourceTime: struct_time\n        @param sourceTime: C{struct_time} value to use as the base\n\n        @rtype:  tuple\n        @return: tuple of remained date/time text, datetime object and\n                 an boolean value to describ if matched or not\n\n        \"\"\"\n        parseStr = None\n        chunk1 = chunk2 = ''\n\n        # HH:MM(:SS) time strings\n        m = self.ptc.CRE_TIMEHMS.search(s)\n        if m is not None:\n\n            if m.group('seconds') is not None:\n                parseStr = '%s:%s:%s' % (m.group('hours'),\n                                         m.group('minutes'),\n                                         m.group('seconds'))\n                chunk1 = s[:m.start('hours')]\n                chunk2 = s[m.end('seconds'):]\n            else:\n                parseStr = '%s:%s' % (m.group('hours'),\n                                      m.group('minutes'))\n                chunk1 = s[:m.start('hours')]\n                chunk2 = s[m.end('minutes'):]\n\n            s = '%s %s' % (chunk1, chunk2)\n\n        if parseStr:\n            debug and log.debug(\n                'found (hms) [%s][%s][%s]', parseStr, chunk1, chunk2)\n            sourceTime = self._evalTimeStd(parseStr, sourceTime)\n\n        return s, sourceTime, bool(parseStr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parseDT(self, datetimeString, sourceTime=None,\n                tzinfo=None, version=None):\n        \"\"\"\n        C{datetimeString} is as C{.parse}, C{sourceTime} has the same semantic\n        meaning as C{.parse}, but now also accepts datetime objects.  C{tzinfo}\n        accepts a tzinfo object.  It is advisable to use pytz.\n\n\n        @type  datetimeString: string\n        @param datetimeString: date/time text to evaluate\n        @type  sourceTime:     struct_time, datetime, date, time\n        @param sourceTime:     time value to use as the base\n        @type  tzinfo:         tzinfo\n        @param tzinfo:         Timezone to apply to generated datetime objs.\n        @type  version:        integer\n        @param version:        style version, default will use L{Calendar}\n                               parameter version value\n\n        @rtype:  tuple\n        @return: tuple of: modified C{sourceTime} and the result flag/context\n\n        see .parse for return code details.\n        \"\"\"\n        # if sourceTime has a timetuple method, use thet, else, just pass the\n        # entire thing to parse and prey the user knows what the hell they are\n        # doing.\n        sourceTime = getattr(sourceTime, 'timetuple', (lambda: sourceTime))()\n        # You REALLY SHOULD be using pytz.  Using localize if available,\n        # hacking if not.  Note, None is a valid tzinfo object in the case of\n        # the ugly hack.\n        localize = getattr(\n            tzinfo,\n            'localize',\n            (lambda dt: dt.replace(tzinfo=tzinfo)),  # ugly hack is ugly :(\n        )\n\n        # Punt\n        time_struct, ret_code = self.parse(\n            datetimeString,\n            sourceTime=sourceTime,\n            version=version)\n\n        # Comments from GHI indicate that it is desired to have the same return\n        # signature on this method as that one it punts to, with the exception\n        # of using datetime objects instead of time_structs.\n        dt = localize(datetime.datetime(*time_struct[:6]))\n        return dt, ret_code", "response": "Parse a datetime string into a tuple of the base time and time_structs."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the given string into a tuple of modified and context entries.", "response": "def parse(self, datetimeString, sourceTime=None, version=None):\n        \"\"\"\n        Splits the given C{datetimeString} into tokens, finds the regex\n        patterns that match and then calculates a C{struct_time} value from\n        the chunks.\n\n        If C{sourceTime} is given then the C{struct_time} value will be\n        calculated from that value, otherwise from the current date/time.\n\n        If the C{datetimeString} is parsed and date/time value found, then::\n\n            If C{version} equals to L{VERSION_FLAG_STYLE}, the second item of\n            the returned tuple will be a flag to let you know what kind of\n            C{struct_time} value is being returned::\n\n                0 = not parsed at all\n                1 = parsed as a C{date}\n                2 = parsed as a C{time}\n                3 = parsed as a C{datetime}\n\n            If C{version} equals to L{VERSION_CONTEXT_STYLE}, the second value\n            will be an instance of L{pdtContext}\n\n        @type  datetimeString: string\n        @param datetimeString: date/time text to evaluate\n        @type  sourceTime:     struct_time\n        @param sourceTime:     C{struct_time} value to use as the base\n        @type  version:        integer\n        @param version:        style version, default will use L{Calendar}\n                               parameter version value\n\n        @rtype:  tuple\n        @return: tuple of: modified C{sourceTime} and the result flag/context\n        \"\"\"\n        debug and log.debug('parse()')\n\n        datetimeString = re.sub(r'(\\w)\\.(\\s)', r'\\1\\2', datetimeString)\n        datetimeString = re.sub(r'(\\w)[\\'\"](\\s|$)', r'\\1 \\2', datetimeString)\n        datetimeString = re.sub(r'(\\s|^)[\\'\"](\\w)', r'\\1 \\2', datetimeString)\n\n        if sourceTime:\n            if isinstance(sourceTime, datetime.datetime):\n                debug and log.debug('coercing datetime to timetuple')\n                sourceTime = sourceTime.timetuple()\n            else:\n                if not isinstance(sourceTime, time.struct_time) and \\\n                        not isinstance(sourceTime, tuple):\n                    raise ValueError('sourceTime is not a struct_time')\n        else:\n            sourceTime = time.localtime()\n\n        with self.context() as ctx:\n            s = datetimeString.lower().strip()\n            debug and log.debug('remainedString (before parsing): [%s]', s)\n\n            while s:\n                for parseMeth in (self._partialParseModifier,\n                                  self._partialParseUnits,\n                                  self._partialParseQUnits,\n                                  self._partialParseDateStr,\n                                  self._partialParseDateStd,\n                                  self._partialParseDayStr,\n                                  self._partialParseWeekday,\n                                  self._partialParseTimeStr,\n                                  self._partialParseMeridian,\n                                  self._partialParseTimeStd):\n                    retS, retTime, matched = parseMeth(s, sourceTime)\n                    if matched:\n                        s, sourceTime = retS.strip(), retTime\n                        break\n                else:\n                    # nothing matched\n                    s = ''\n\n                debug and log.debug('hasDate: [%s], hasTime: [%s]',\n                                    ctx.hasDate, ctx.hasTime)\n                debug and log.debug('remainedString: [%s]', s)\n\n            # String is not parsed at all\n            if sourceTime is None:\n                debug and log.debug('not parsed [%s]', str(sourceTime))\n                sourceTime = time.localtime()\n\n        if not isinstance(sourceTime, time.struct_time):\n            sourceTime = time.struct_time(sourceTime)\n\n        version = self.version if version is None else version\n        if version == VERSION_CONTEXT_STYLE:\n            return sourceTime, ctx\n        else:\n            return sourceTime, ctx.dateTimeFlag"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes the given C{source} date, or current date if none is passed, and increments it according to the values passed in by month and/or year. This routine is needed because Python's C{timedelta()} function does not allow for month or year increments. @type source: struct_time @param source: C{struct_time} value to increment @type month: float or integer @param month: optional number of months to increment @type year: float or integer @param year: optional number of years to increment @rtype: datetime @return: C{source} incremented by the number of months and/or years", "response": "def inc(self, source, month=None, year=None):\n        \"\"\"\n        Takes the given C{source} date, or current date if none is\n        passed, and increments it according to the values passed in\n        by month and/or year.\n\n        This routine is needed because Python's C{timedelta()} function\n        does not allow for month or year increments.\n\n        @type  source: struct_time\n        @param source: C{struct_time} value to increment\n        @type  month:  float or integer\n        @param month:  optional number of months to increment\n        @type  year:   float or integer\n        @param year:   optional number of years to increment\n\n        @rtype:  datetime\n        @return: C{source} incremented by the number of months and/or years\n        \"\"\"\n        yr = source.year\n        mth = source.month\n        dy = source.day\n\n        try:\n            month = float(month)\n        except (TypeError, ValueError):\n            month = 0\n\n        try:\n            year = float(year)\n        except (TypeError, ValueError):\n            year = 0\n        finally:\n            month += year * 12\n            year = 0\n\n        subMi = 0.0\n        maxDay = 0\n        if month:\n            mi = int(month)\n            subMi = month - mi\n\n            y = int(mi / 12.0)\n            m = mi - y * 12\n\n            mth = mth + m\n            if mth < 1:  # cross start-of-year?\n                y -= 1  # yes - decrement year\n                mth += 12  # and fix month\n            elif mth > 12:  # cross end-of-year?\n                y += 1  # yes - increment year\n                mth -= 12  # and fix month\n\n            yr += y\n\n            # if the day ends up past the last day of\n            # the new month, set it to the last day\n            maxDay = self.ptc.daysInMonth(mth, yr)\n            if dy > maxDay:\n                dy = maxDay\n\n        if yr > datetime.MAXYEAR or yr < datetime.MINYEAR:\n            raise OverflowError('year is out of range')\n\n        d = source.replace(year=yr, month=mth, day=dy)\n        if subMi:\n            d += datetime.timedelta(days=subMi * maxDay)\n        return source + (d - source)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nlp(self, inputString, sourceTime=None, version=None):\n\n        orig_inputstring = inputString\n\n        # replace periods at the end of sentences w/ spaces\n        # opposed to removing them altogether in order to\n        # retain relative positions (identified by alpha, period, space).\n        # this is required for some of the regex patterns to match\n        inputString = re.sub(r'(\\w)(\\.)(\\s)', r'\\1 \\3', inputString).lower()\n        inputString = re.sub(r'(\\w)(\\'|\")(\\s|$)', r'\\1 \\3', inputString)\n        inputString = re.sub(r'(\\s|^)(\\'|\")(\\w)', r'\\1 \\3', inputString)\n\n        startpos = 0  # the start position in the inputString during the loop\n\n        # list of lists in format:\n        # [startpos, endpos, matchedstring, flags, type]\n        matches = []\n\n        while startpos < len(inputString):\n\n            # empty match\n            leftmost_match = [0, 0, None, 0, None]\n\n            # Modifier like next\\prev..\n            m = self.ptc.CRE_MODIFIER.search(inputString[startpos:])\n            if m is not None:\n                if leftmost_match[1] == 0 or \\\n                        leftmost_match[0] > m.start() + startpos:\n                    leftmost_match[0] = m.start() + startpos\n                    leftmost_match[1] = m.end() + startpos\n                    leftmost_match[2] = m.group()\n                    leftmost_match[3] = 0\n                    leftmost_match[4] = 'modifier'\n\n            # Quantity + Units\n            m = self.ptc.CRE_UNITS.search(inputString[startpos:])\n            if m is not None:\n                debug and log.debug('CRE_UNITS matched')\n                if self._UnitsTrapped(inputString[startpos:], m, 'units'):\n                    debug and log.debug('day suffix trapped by unit match')\n                else:\n\n                    if leftmost_match[1] == 0 or \\\n                            leftmost_match[0] > m.start('qty') + startpos:\n                        leftmost_match[0] = m.start('qty') + startpos\n                        leftmost_match[1] = m.end('qty') + startpos\n                        leftmost_match[2] = m.group('qty')\n                        leftmost_match[3] = 3\n                        leftmost_match[4] = 'units'\n\n                        if m.start('qty') > 0 and \\\n                                inputString[m.start('qty') - 1] == '-':\n                            leftmost_match[0] = leftmost_match[0] - 1\n                            leftmost_match[2] = '-' + leftmost_match[2]\n\n            # Quantity + Units\n            m = self.ptc.CRE_QUNITS.search(inputString[startpos:])\n            if m is not None:\n                debug and log.debug('CRE_QUNITS matched')\n                if self._UnitsTrapped(inputString[startpos:], m, 'qunits'):\n                    debug and log.debug('day suffix trapped by qunit match')\n                else:\n                    if leftmost_match[1] == 0 or \\\n                            leftmost_match[0] > m.start('qty') + startpos:\n                        leftmost_match[0] = m.start('qty') + startpos\n                        leftmost_match[1] = m.end('qty') + startpos\n                        leftmost_match[2] = m.group('qty')\n                        leftmost_match[3] = 3\n                        leftmost_match[4] = 'qunits'\n\n                        if m.start('qty') > 0 and \\\n                                inputString[m.start('qty') - 1] == '-':\n                            leftmost_match[0] = leftmost_match[0] - 1\n                            leftmost_match[2] = '-' + leftmost_match[2]\n\n            m = self.ptc.CRE_DATE3.search(inputString[startpos:])\n            # NO LONGER NEEDED, THE REGEXP HANDLED MTHNAME NOW\n            # for match in self.ptc.CRE_DATE3.finditer(inputString[startpos:]):\n            # to prevent \"HH:MM(:SS) time strings\" expressions from\n            # triggering this regex, we checks if the month field exists\n            # in the searched expression, if it doesn't exist, the date\n            # field is not valid\n            #     if match.group('mthname'):\n            #         m = self.ptc.CRE_DATE3.search(inputString[startpos:],\n            #                                       match.start())\n            #         break\n\n            # String date format\n            if m is not None:\n                if leftmost_match[1] == 0 or \\\n                        leftmost_match[0] > m.start('date') + startpos:\n                    leftmost_match[0] = m.start('date') + startpos\n                    leftmost_match[1] = m.end('date') + startpos\n                    leftmost_match[2] = m.group('date')\n                    leftmost_match[3] = 1\n                    leftmost_match[4] = 'dateStr'\n\n            # Standard date format\n            m = self.ptc.CRE_DATE.search(inputString[startpos:])\n            if m is not None:\n                if leftmost_match[1] == 0 or \\\n                        leftmost_match[0] > m.start('date') + startpos:\n                    leftmost_match[0] = m.start('date') + startpos\n                    leftmost_match[1] = m.end('date') + startpos\n                    leftmost_match[2] = m.group('date')\n                    leftmost_match[3] = 1\n                    leftmost_match[4] = 'dateStd'\n\n            # Natural language day strings\n            m = self.ptc.CRE_DAY.search(inputString[startpos:])\n            if m is not None:\n                if leftmost_match[1] == 0 or \\\n                        leftmost_match[0] > m.start() + startpos:\n                    leftmost_match[0] = m.start() + startpos\n                    leftmost_match[1] = m.end() + startpos\n                    leftmost_match[2] = m.group()\n                    leftmost_match[3] = 1\n                    leftmost_match[4] = 'dayStr'\n\n            # Weekday\n            m = self.ptc.CRE_WEEKDAY.search(inputString[startpos:])\n            if m is not None:\n                if inputString[startpos:] not in self.ptc.dayOffsets:\n                    if leftmost_match[1] == 0 or \\\n                            leftmost_match[0] > m.start() + startpos:\n                        leftmost_match[0] = m.start() + startpos\n                        leftmost_match[1] = m.end() + startpos\n                        leftmost_match[2] = m.group()\n                        leftmost_match[3] = 1\n                        leftmost_match[4] = 'weekdy'\n\n            # Natural language time strings\n            m = self.ptc.CRE_TIME.search(inputString[startpos:])\n            if m is not None:\n                if leftmost_match[1] == 0 or \\\n                        leftmost_match[0] > m.start() + startpos:\n                    leftmost_match[0] = m.start() + startpos\n                    leftmost_match[1] = m.end() + startpos\n                    leftmost_match[2] = m.group()\n                    leftmost_match[3] = 2\n                    leftmost_match[4] = 'timeStr'\n\n            # HH:MM(:SS) am/pm time strings\n            m = self.ptc.CRE_TIMEHMS2.search(inputString[startpos:])\n            if m is not None:\n                if leftmost_match[1] == 0 or \\\n                        leftmost_match[0] > m.start('hours') + startpos:\n                    leftmost_match[0] = m.start('hours') + startpos\n                    leftmost_match[1] = m.end('meridian') + startpos\n                    leftmost_match[2] = inputString[leftmost_match[0]:\n                                                    leftmost_match[1]]\n                    leftmost_match[3] = 2\n                    leftmost_match[4] = 'meridian'\n\n            # HH:MM(:SS) time strings\n            m = self.ptc.CRE_TIMEHMS.search(inputString[startpos:])\n            if m is not None:\n                if leftmost_match[1] == 0 or \\\n                        leftmost_match[0] > m.start('hours') + startpos:\n                    leftmost_match[0] = m.start('hours') + startpos\n                    if m.group('seconds') is not None:\n                        leftmost_match[1] = m.end('seconds') + startpos\n                    else:\n                        leftmost_match[1] = m.end('minutes') + startpos\n                    leftmost_match[2] = inputString[leftmost_match[0]:\n                                                    leftmost_match[1]]\n                    leftmost_match[3] = 2\n                    leftmost_match[4] = 'timeStd'\n\n            # Units only; must be preceded by a modifier\n            if len(matches) > 0 and matches[-1][3] == 0:\n                m = self.ptc.CRE_UNITS_ONLY.search(inputString[startpos:])\n                # Ensure that any match is immediately proceded by the\n                # modifier. \"Next is the word 'month'\" should not parse as a\n                # date while \"next month\" should\n                if m is not None and \\\n                        inputString[startpos:startpos +\n                                    m.start()].strip() == '':\n                    debug and log.debug('CRE_UNITS_ONLY matched [%s]',\n                                        m.group())\n                    if leftmost_match[1] == 0 or \\\n                            leftmost_match[0] > m.start() + startpos:\n                        leftmost_match[0] = m.start() + startpos\n                        leftmost_match[1] = m.end() + startpos\n                        leftmost_match[2] = m.group()\n                        leftmost_match[3] = 3\n                        leftmost_match[4] = 'unitsOnly'\n\n            # set the start position to the end pos of the leftmost match\n            startpos = leftmost_match[1]\n\n            # nothing was detected\n            # so break out of the loop\n            if startpos == 0:\n                startpos = len(inputString)\n            else:\n                if leftmost_match[3] > 0:\n                    m = self.ptc.CRE_NLP_PREFIX.search(\n                        inputString[:leftmost_match[0]] +\n                        ' ' + str(leftmost_match[3]))\n                    if m is not None:\n                        leftmost_match[0] = m.start('nlp_prefix')\n                        leftmost_match[2] = inputString[leftmost_match[0]:\n                                                        leftmost_match[1]]\n                matches.append(leftmost_match)\n\n        # find matches in proximity with one another and\n        # return all the parsed values\n        proximity_matches = []\n        if len(matches) > 1:\n            combined = ''\n            from_match_index = 0\n            date = matches[0][3] == 1\n            time = matches[0][3] == 2\n            units = matches[0][3] == 3\n            for i in range(1, len(matches)):\n\n                # test proximity (are there characters between matches?)\n                endofprevious = matches[i - 1][1]\n                begofcurrent = matches[i][0]\n                if orig_inputstring[endofprevious:\n                                    begofcurrent].lower().strip() != '':\n                    # this one isn't in proximity, but maybe\n                    # we have enough to make a datetime\n                    # TODO: make sure the combination of\n                    # formats (modifier, dateStd, etc) makes logical sense\n                    # before parsing together\n                    if date or time or units:\n                        combined = orig_inputstring[matches[from_match_index]\n                                                    [0]:matches[i - 1][1]]\n                        parsed_datetime, flags = self.parse(combined,\n                                                            sourceTime,\n                                                            version)\n                        proximity_matches.append((\n                            datetime.datetime(*parsed_datetime[:6]),\n                            flags,\n                            matches[from_match_index][0],\n                            matches[i - 1][1],\n                            combined))\n                    # not in proximity, reset starting from current\n                    from_match_index = i\n                    date = matches[i][3] == 1\n                    time = matches[i][3] == 2\n                    units = matches[i][3] == 3\n                    continue\n                else:\n                    if matches[i][3] == 1:\n                        date = True\n                    if matches[i][3] == 2:\n                        time = True\n                    if matches[i][3] == 3:\n                        units = True\n\n            # check last\n            # we have enough to make a datetime\n            if date or time or units:\n                combined = orig_inputstring[matches[from_match_index][0]:\n                                            matches[len(matches) - 1][1]]\n                parsed_datetime, flags = self.parse(combined, sourceTime,\n                                                    version)\n                proximity_matches.append((\n                    datetime.datetime(*parsed_datetime[:6]),\n                    flags,\n                    matches[from_match_index][0],\n                    matches[len(matches) - 1][1],\n                    combined))\n\n        elif len(matches) == 0:\n            return None\n        else:\n            if matches[0][3] == 0:  # not enough info to parse\n                return None\n            else:\n                combined = orig_inputstring[matches[0][0]:matches[0][1]]\n                parsed_datetime, flags = self.parse(matches[0][2], sourceTime,\n                                                    version)\n                proximity_matches.append((\n                    datetime.datetime(*parsed_datetime[:6]),\n                    flags,\n                    matches[0][0],\n                    matches[0][1],\n                    combined))\n\n        return tuple(proximity_matches)", "response": "This function parses a string containing a natural language text and returns a parsed_datetime as a tuple of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the number of days in a given month and year.", "response": "def daysInMonth(self, month, year):\n        \"\"\"\n        Take the given month (1-12) and a given year (4 digit) return\n        the number of days in the month adjusting for leap year as needed\n        \"\"\"\n        result = None\n        debug and log.debug('daysInMonth(%s, %s)', month, year)\n        if month > 0 and month <= 12:\n            result = self._DaysInMonthList[month - 1]\n\n            if month == 2:\n                if year in self._leapYears:\n                    result += 1\n                else:\n                    if calendar.isleap(year):\n                        self._leapYears.append(year)\n                        result += 1\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getSource(self, sourceKey, sourceTime=None):\n        if sourceKey not in self.re_sources:\n            return None\n\n        if sourceTime is None:\n            (yr, mth, dy, hr, mn, sec, wd, yd, isdst) = time.localtime()\n        else:\n            (yr, mth, dy, hr, mn, sec, wd, yd, isdst) = sourceTime\n\n        defaults = {'yr': yr, 'mth': mth, 'dy': dy,\n                    'hr': hr, 'mn': mn, 'sec': sec}\n\n        source = self.re_sources[sourceKey]\n\n        values = {}\n\n        for key, default in defaults.items():\n            values[key] = source.get(key, default)\n\n        return (values['yr'], values['mth'], values['dy'],\n                values['hr'], values['mn'], values['sec'],\n                wd, yd, isdst)", "response": "GetReturn a date or time tuple based on the giving source key and the corresponding key found in self. re_sources."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef updateAccuracy(self, *accuracy):\n        for acc in accuracy:\n            if not isinstance(acc, int):\n                acc = self._ACCURACY_REVERSE_MAPPING[acc]\n            self.accuracy |= acc", "response": "Updates the current accuracy flag."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a locale from the cache.", "response": "def load_locale(locale, icu=False):\n    \"\"\"\n    Return data of locale\n    :param locale:\n    :return:\n    \"\"\"\n    if locale not in locales:\n        raise NotImplementedError(\"The locale '%s' is not supported\" % locale)\n    if locale not in __locale_caches:\n        mod = __import__(__name__, fromlist=[locale], level=0)\n        __locale_caches[locale] = getattr(mod, locale)\n    return __locale_caches[locale]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef indent(func):\n    def wrapper(self, *args, **kwds):\n        func(self, *args, **kwds)\n        return Indent(self)\n    return wrapper", "response": "Decorator for allowing to use method as normal method or with\n    context manager for auto - indenting code blocks."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresolves a path fragment into a single schema definition.", "response": "def resolve_path(schema, fragment):\r\n    \"\"\"\r\n    Return definition from path.\r\n\r\n    Path is unescaped according https://tools.ietf.org/html/rfc6901\r\n    \"\"\"\r\n    fragment = fragment.lstrip('/')\r\n    parts = unquote(fragment).split('/') if fragment else []\r\n    for part in parts:\r\n        part = part.replace('~1', '/').replace('~0', '~')\r\n        if isinstance(schema, list):\r\n            schema = schema[int(part)]\r\n        elif part in schema:\r\n            schema = schema[part]\r\n        else:\r\n            raise JsonSchemaException('Unresolvable ref: {}'.format(part))\r\n    return schema"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resolve_remote(uri, handlers):\r\n    scheme = urlparse.urlsplit(uri).scheme\r\n    if scheme in handlers:\r\n        result = handlers[scheme](uri)\r\n    else:\r\n        req = urlopen(uri)\r\n        encoding = req.info().get_content_charset() or 'utf-8'\r\n        result = json.loads(req.read().decode(encoding),)\r\n    return result", "response": "Resolve a remote uri."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconstructing a resolver from a JSON schema object.", "response": "def from_schema(cls, schema, handlers={}, **kwargs):\r\n        \"\"\"\r\n        Construct a resolver from a JSON schema object.\r\n        \"\"\"\r\n        return cls(\r\n            schema.get('$id', schema.get('id', '')) if isinstance(schema, dict) else '',\r\n            schema,\r\n            handlers=handlers,\r\n            **kwargs\r\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef in_scope(self, scope: str):\r\n        old_scope = self.resolution_scope\r\n        self.resolution_scope = urlparse.urljoin(old_scope, scope)\r\n        try:\r\n            yield\r\n        finally:\r\n            self.resolution_scope = old_scope", "response": "Context manager to handle current scope."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_scope_name(self):\r\n        name = 'validate_' + unquote(self.resolution_scope).replace('~1', '_').replace('~0', '_')\r\n        name = re.sub(r'[:/#\\.\\-\\%]', '_', name)\r\n        name = name.lower().rstrip('_')\r\n        return name", "response": "Get current scope and return it as a valid function name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef walk(self, node: dict):\r\n        if isinstance(node, bool):\r\n            pass\r\n        elif '$ref' in node and isinstance(node['$ref'], str):\r\n            ref = node['$ref']\r\n            node['$ref'] = urlparse.urljoin(self.resolution_scope, ref)\r\n        elif 'id' in node and isinstance(node['id'], str):\r\n            with self.in_scope(node['id']):\r\n                self.store[normalize(self.resolution_scope)] = node\r\n                for _, item in node.items():\r\n                    if isinstance(item, dict):\r\n                        self.walk(item)\r\n        else:\r\n            for _, item in node.items():\r\n                if isinstance(item, dict):\r\n                    self.walk(item)", "response": "Walk thru schema and dereferencing id and ref instances"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_type(self):\n        types = enforce_list(self._definition['type'])\n        try:\n            python_types = ', '.join(JSON_TYPE_TO_PYTHON_TYPE[t] for t in types)\n        except KeyError as exc:\n            raise JsonSchemaDefinitionException('Unknown type: {}'.format(exc))\n\n        extra = ''\n\n        if 'integer' in types:\n            extra += ' and not (isinstance({variable}, float) and {variable}.is_integer())'.format(\n                variable=self._variable,\n            )\n\n        if ('number' in types or 'integer' in types) and 'boolean' not in types:\n            extra += ' or isinstance({variable}, bool)'.format(variable=self._variable)\n\n        with self.l('if not isinstance({variable}, ({})){}:', python_types, extra):\n            self.l('raise JsonSchemaException(\"{name} must be {}\")', ' or '.join(types))", "response": "Generates the validation of type."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_property_names(self):\n        property_names_definition = self._definition.get('propertyNames', {})\n        if property_names_definition is True:\n            pass\n        elif property_names_definition is False:\n            self.create_variable_keys()\n            with self.l('if {variable}_keys:'):\n                self.l('raise JsonSchemaException(\"{name} must not be there\")')\n        else:\n            self.create_variable_is_dict()\n            with self.l('if {variable}_is_dict:'):\n                self.create_variable_with_length()\n                with self.l('if {variable}_len != 0:'):\n                    self.l('{variable}_property_names = True')\n                    with self.l('for {variable}_key in {variable}:'):\n                        with self.l('try:'):\n                            self.generate_func_code_block(\n                                property_names_definition,\n                                '{}_key'.format(self._variable),\n                                self._variable_name,\n                                clear_variables=True,\n                            )\n                        with self.l('except JsonSchemaException:'):\n                            self.l('{variable}_property_names = False')\n                    with self.l('if not {variable}_property_names:'):\n                        self.l('raise JsonSchemaException(\"{name} must be named by propertyName definition\")')", "response": "Generates the property names for the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating contains function for the resource class.", "response": "def generate_contains(self):\n        \"\"\"\n        Means that array must contain at least one defined item.\n\n        .. code-block:: python\n\n            {\n                'contains': {\n                    'type': 'number',\n                },\n            }\n\n        Valid array is any with at least one number.\n        \"\"\"\n        self.create_variable_is_list()\n        with self.l('if {variable}_is_list:'):\n            contains_definition = self._definition['contains']\n\n            if contains_definition is False:\n                self.l('raise JsonSchemaException(\"{name} is always invalid\")')\n            elif contains_definition is True:\n                with self.l('if not {variable}:'):\n                    self.l('raise JsonSchemaException(\"{name} must not be empty\")')\n            else:\n                self.l('{variable}_contains = False')\n                with self.l('for {variable}_key in {variable}:'):\n                    with self.l('try:'):\n                        self.generate_func_code_block(\n                            contains_definition,\n                            '{}_key'.format(self._variable),\n                            self._variable_name,\n                            clear_variables=True,\n                        )\n                        self.l('{variable}_contains = True')\n                        self.l('break')\n                    self.l('except JsonSchemaException: pass')\n\n                with self.l('if not {variable}_contains:'):\n                    self.l('raise JsonSchemaException(\"{name} must contain one of contains definition\")')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a variable for the current locale.", "response": "def generate_const(self):\n        \"\"\"\n        Means that value is valid when is equeal to const definition.\n\n        .. code-block:: python\n\n            {\n                'const': 42,\n            }\n\n        Only valid value is 42 in this example.\n        \"\"\"\n        const = self._definition['const']\n        if isinstance(const, str):\n            const = '\"{}\"'.format(const)\n        with self.l('if {variable} != {}:', const):\n            self.l('raise JsonSchemaException(\"{name} must be same as const definition\")')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a dictionary of global variables for generating function from func_code.", "response": "def global_state(self):\n        \"\"\"\n        Returns global variables for generating function from ``func_code``. Includes\n        compiled regular expressions and imports, so it does not have to do it every\n        time when validation function is called.\n        \"\"\"\n        self._generate_func_code()\n\n        return dict(\n            REGEX_PATTERNS=self._compile_regexps,\n            re=re,\n            JsonSchemaException=JsonSchemaException,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the code for generating the function from func_code as code.", "response": "def global_state_code(self):\n        \"\"\"\n        Returns global variables for generating function from ``func_code`` as code.\n        Includes compiled regular expressions and imports.\n        \"\"\"\n        self._generate_func_code()\n\n        if not self._compile_regexps:\n            return '\\n'.join(\n                [\n                    'from fastjsonschema import JsonSchemaException',\n                    '',\n                    '',\n                ]\n            )\n        regexs = ['\"{}\": re.compile(r\"{}\")'.format(key, value.pattern) for key, value in self._compile_regexps.items()]\n        return '\\n'.join(\n            [\n                'import re',\n                'from fastjsonschema import JsonSchemaException',\n                '',\n                '',\n                'REGEX_PATTERNS = {',\n                '    ' + ',\\n    '.join(regexs),\n                '}',\n                '',\n            ]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_func_code(self):\n        self.l('NoneType = type(None)')\n        # Generate parts that are referenced and not yet generated\n        while self._needed_validation_functions:\n            # During generation of validation function, could be needed to generate\n            # new one that is added again to `_needed_validation_functions`.\n            # Therefore usage of while instead of for loop.\n            uri, name = self._needed_validation_functions.popitem()\n            self.generate_validation_function(uri, name)", "response": "Generates base code of validation function and calls helper\n        for creating code by definition."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating validation function for given uri with given name", "response": "def generate_validation_function(self, uri, name):\n        \"\"\"\n        Generate validation function for given uri with given name\n        \"\"\"\n        self._validation_functions_done.add(uri)\n        self.l('')\n        with self._resolver.resolving(uri) as definition:\n            with self.l('def {}(data):', name):\n                self.generate_func_code_block(definition, 'data', 'data', clear_variables=True)\n                self.l('return data')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_func_code_block(self, definition, variable, variable_name, clear_variables=False):\n        backup = self._definition, self._variable, self._variable_name\n        self._definition, self._variable, self._variable_name = definition, variable, variable_name\n        if clear_variables:\n            backup_variables = self._variables\n            self._variables = set()\n\n        self._generate_func_code_block(definition)\n\n        self._definition, self._variable, self._variable_name = backup\n        if clear_variables:\n            self._variables = backup_variables", "response": "Generates the code block for the function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_ref(self):\n        with self._resolver.in_scope(self._definition['$ref']):\n            name = self._resolver.get_scope_name()\n            uri = self._resolver.get_uri()\n            if uri not in self._validation_functions_done:\n                self._needed_validation_functions[uri] = name\n            # call validation function\n            self.l('{}({variable})', name)", "response": "Generate a new ref for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuses for inserting line in context manager.", "response": "def l(self, line, *args, **kwds):\n        \"\"\"\n        Short-cut of line. Used for inserting line. It's formated with parameters\n        ``variable``, ``variable_name`` (as ``name`` for short-cut), all keys from\n        current JSON schema ``definition`` and also passed arguments in ``args``\n        and named ``kwds``.\n\n        .. code-block:: python\n\n            self.l('if {variable} not in {enum}: raise JsonSchemaException(\"Wrong!\")')\n\n        When you want to indent block, use it as context manager. For example:\n\n        .. code-block:: python\n\n            with self.l('if {variable} not in {enum}:'):\n                self.l('raise JsonSchemaException(\"Wrong!\")')\n        \"\"\"\n        spaces = ' ' * self.INDENT * self._indent\n\n        name = self._variable_name\n        if name and '{' in name:\n            name = '\"+\"{}\".format(**locals())+\"'.format(self._variable_name)\n\n        context = dict(\n            self._definition or {},\n            variable=self._variable,\n            name=name,\n            **kwds\n        )\n        self._code.append(spaces + line.format(*args, **context))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nappending code for creating variable with length of that variable.", "response": "def create_variable_with_length(self):\n        \"\"\"\n        Append code for creating variable with length of that variable\n        (for example length of list or dictionary) with name ``{variable}_len``.\n        It can be called several times and always it's done only when that variable\n        still does not exists.\n        \"\"\"\n        variable_name = '{}_len'.format(self._variable)\n        if variable_name in self._variables:\n            return\n        self._variables.add(variable_name)\n        self.l('{variable}_len = len({variable})')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nappends code for creating variable with keys of that variable.", "response": "def create_variable_keys(self):\n        \"\"\"\n        Append code for creating variable with keys of that variable (dictionary)\n        with a name ``{variable}_keys``. Similar to `create_variable_with_length`.\n        \"\"\"\n        variable_name = '{}_keys'.format(self._variable)\n        if variable_name in self._variables:\n            return\n        self._variables.add(variable_name)\n        self.l('{variable}_keys = set({variable}.keys())')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_variable_is_list(self):\n        variable_name = '{}_is_list'.format(self._variable)\n        if variable_name in self._variables:\n            return\n        self._variables.add(variable_name)\n        self.l('{variable}_is_list = isinstance({variable}, list)')", "response": "Append code for creating variable with bool if it s instance of list\n        with a name named variable_is_list. Similar to create_variable_with_length."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_variable_is_dict(self):\n        variable_name = '{}_is_dict'.format(self._variable)\n        if variable_name in self._variables:\n            return\n        self._variables.add(variable_name)\n        self.l('{variable}_is_dict = isinstance({variable}, dict)')", "response": "Append code for creating variable with bool if it s instance of list\n        with a name is_dict. Similar to create_variable_with_length."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates the if - then - else code for the current locale.", "response": "def generate_if_then_else(self):\n        \"\"\"\n        Implementation of if-then-else.\n\n        .. code-block:: python\n\n            {\n                'if': {\n                    'exclusiveMaximum': 0,\n                },\n                'then': {\n                    'minimum': -10,\n                },\n                'else': {\n                    'multipleOf': 2,\n                },\n            }\n\n        Valid values are any between -10 and 0 or any multiplication of two.\n        \"\"\"\n        with self.l('try:'):\n            self.generate_func_code_block(\n                self._definition['if'],\n                self._variable,\n                self._variable_name,\n                clear_variables=True\n            )\n        with self.l('except JsonSchemaException:'):\n            if 'else' in self._definition:\n                self.generate_func_code_block(\n                    self._definition['else'],\n                    self._variable,\n                    self._variable_name,\n                    clear_variables=True\n                )\n            else:\n                self.l('pass')\n        if 'then' in self._definition:\n            with self.l('else:'):\n                self.generate_func_code_block(\n                    self._definition['then'],\n                    self._variable,\n                    self._variable_name,\n                    clear_variables=True\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating the content encoding of the current object.", "response": "def generate_content_encoding(self):\n        \"\"\"\n        Means decoding value when it's encoded by base64.\n\n        .. code-block:: python\n\n            {\n                'contentEncoding': 'base64',\n            }\n        \"\"\"\n        if self._definition['contentEncoding'] == 'base64':\n            with self.l('if isinstance({variable}, str):'):\n                with self.l('try:'):\n                    self.l('import base64')\n                    self.l('{variable} = base64.b64decode({variable})')\n                with self.l('except Exception:'):\n                    self.l('raise JsonSchemaException(\"{name} must be encoded by base64\")')\n                with self.l('if {variable} == \"\":'):\n                    self.l('raise JsonSchemaException(\"contentEncoding must be base64\")')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates the content media type of the current object.", "response": "def generate_content_media_type(self):\n        \"\"\"\n        Means loading value when it's specified as JSON.\n\n        .. code-block:: python\n\n            {\n                'contentMediaType': 'application/json',\n            }\n        \"\"\"\n        if self._definition['contentMediaType'] == 'application/json':\n            with self.l('if isinstance({variable}, bytes):'):\n                with self.l('try:'):\n                    self.l('{variable} = {variable}.decode(\"utf-8\")')\n                with self.l('except Exception:'):\n                    self.l('raise JsonSchemaException(\"{name} must encoded by utf8\")')\n            with self.l('if isinstance({variable}, str):'):\n                with self.l('try:'):\n                    self.l('import json')\n                    self.l('{variable} = json.loads({variable})')\n                with self.l('except Exception:'):\n                    self.l('raise JsonSchemaException(\"{name} must be valid JSON\")')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating the enum definition", "response": "def generate_enum(self):\n        \"\"\"\n        Means that only value specified in the enum is valid.\n\n        .. code-block:: python\n\n            {\n                'enum': ['a', 'b'],\n            }\n        \"\"\"\n        enum = self._definition['enum']\n        if not isinstance(enum, (list, tuple)):\n            raise JsonSchemaDefinitionException('enum must be an array')\n        with self.l('if {variable} not in {enum}:'):\n            enum = str(enum).replace('\"', '\\\\\"')\n            self.l('raise JsonSchemaException(\"{name} must be one of {}\")', enum)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_all_of(self):\n        for definition_item in self._definition['allOf']:\n            self.generate_func_code_block(definition_item, self._variable, self._variable_name, clear_variables=True)", "response": "Generate all of the functions that are used in the code block."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_one_of(self):\n        self.l('{variable}_one_of_count = 0')\n        for definition_item in self._definition['oneOf']:\n            # When we know it's failing (one of means exactly once), we do not need to do another expensive try-except.\n            with self.l('if {variable}_one_of_count < 2:'):\n                with self.l('try:'):\n                    self.generate_func_code_block(definition_item, self._variable, self._variable_name, clear_variables=True)\n                    self.l('{variable}_one_of_count += 1')\n                self.l('except JsonSchemaException: pass')\n\n        with self.l('if {variable}_one_of_count != 1:'):\n            self.l('raise JsonSchemaException(\"{name} must be valid exactly by one of oneOf definition\")')", "response": "Generates a code block that can be used to validate a single one - of - one - of - the - alternatives value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_not(self):\n        not_definition = self._definition['not']\n        if not_definition is True:\n            self.l('raise JsonSchemaException(\"{name} must not be there\")')\n        elif not_definition is False:\n            return\n        elif not not_definition:\n            with self.l('if {}:', self._variable):\n                self.l('raise JsonSchemaException(\"{name} must not be valid by not definition\")')\n        else:\n            with self.l('try:'):\n                self.generate_func_code_block(not_definition, self._variable, self._variable_name)\n            self.l('except JsonSchemaException: pass')\n            self.l('else: raise JsonSchemaException(\"{name} must not be valid by not definition\")')", "response": "Generates a not - value code block for the resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_format(self):\n        with self.l('if isinstance({variable}, str):'):\n            format_ = self._definition['format']\n            if format_ in self.FORMAT_REGEXS:\n                format_regex = self.FORMAT_REGEXS[format_]\n                self._generate_format(format_, format_ + '_re_pattern', format_regex)\n            # format regex is used only in meta schemas\n            elif format_ == 'regex':\n                with self.l('try:'):\n                    self.l('re.compile({variable})')\n                with self.l('except Exception:'):\n                    self.l('raise JsonSchemaException(\"{name} must be a valid regex\")')\n            else:\n                self.l('pass')", "response": "Generate format for the current locale"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_items(self):\n        items_definition = self._definition['items']\n        if items_definition is True:\n            return\n\n        self.create_variable_is_list()\n        with self.l('if {variable}_is_list:'):\n            self.create_variable_with_length()\n            if items_definition is False:\n                with self.l('if {variable}:'):\n                    self.l('raise JsonSchemaException(\"{name} must not be there\")')\n            elif isinstance(items_definition, list):\n                for idx, item_definition in enumerate(items_definition):\n                    with self.l('if {variable}_len > {}:', idx):\n                        self.l('{variable}__{0} = {variable}[{0}]', idx)\n                        self.generate_func_code_block(\n                            item_definition,\n                            '{}__{}'.format(self._variable, idx),\n                            '{}[{}]'.format(self._variable_name, idx),\n                        )\n                    if isinstance(item_definition, dict) and 'default' in item_definition:\n                        self.l('else: {variable}.append({})', repr(item_definition['default']))\n\n                if 'additionalItems' in self._definition:\n                    if self._definition['additionalItems'] is False:\n                        self.l('if {variable}_len > {}: raise JsonSchemaException(\"{name} must contain only specified items\")', len(items_definition))\n                    else:\n                        with self.l('for {variable}_x, {variable}_item in enumerate({variable}[{0}:], {0}):', len(items_definition)):\n                            self.generate_func_code_block(\n                                self._definition['additionalItems'],\n                                '{}_item'.format(self._variable),\n                                '{}[{{{}_x}}]'.format(self._variable_name, self._variable),\n                            )\n            else:\n                if items_definition:\n                    with self.l('for {variable}_x, {variable}_item in enumerate({variable}):'):\n                        self.generate_func_code_block(\n                            items_definition,\n                            '{}_item'.format(self._variable),\n                            '{}[{{{}_x}}]'.format(self._variable_name, self._variable),\n                        )", "response": "Generate the items field for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate the properties of the object that contains the keys of the object that are defined in the definition.", "response": "def generate_properties(self):\n        \"\"\"\n        Means object with defined keys.\n\n        .. code-block:: python\n\n            {\n                'properties': {\n                    'key': {'type': 'number'},\n                },\n            }\n\n        Valid object is containing key called 'key' and value any number.\n        \"\"\"\n        self.create_variable_is_dict()\n        with self.l('if {variable}_is_dict:'):\n            self.create_variable_keys()\n            for key, prop_definition in self._definition['properties'].items():\n                key_name = re.sub(r'($[^a-zA-Z]|[^a-zA-Z0-9])', '', key)\n                with self.l('if \"{}\" in {variable}_keys:', key):\n                    self.l('{variable}_keys.remove(\"{}\")', key)\n                    self.l('{variable}__{0} = {variable}[\"{1}\"]', key_name, key)\n                    self.generate_func_code_block(\n                        prop_definition,\n                        '{}__{}'.format(self._variable, key_name),\n                        '{}.{}'.format(self._variable_name, key),\n                    )\n                if isinstance(prop_definition, dict) and 'default' in prop_definition:\n                    self.l('else: {variable}[\"{}\"] = {}', key, repr(prop_definition['default']))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates pattern properties for the current locale.", "response": "def generate_pattern_properties(self):\n        \"\"\"\n        Means object with defined keys as patterns.\n\n        .. code-block:: python\n\n            {\n                'patternProperties': {\n                    '^x': {'type': 'number'},\n                },\n            }\n\n        Valid object is containing key starting with a 'x' and value any number.\n        \"\"\"\n        self.create_variable_is_dict()\n        with self.l('if {variable}_is_dict:'):\n            self.create_variable_keys()\n            for pattern, definition in self._definition['patternProperties'].items():\n                self._compile_regexps[pattern] = re.compile(pattern)\n            with self.l('for {variable}_key, {variable}_val in {variable}.items():'):\n                for pattern, definition in self._definition['patternProperties'].items():\n                    with self.l('if REGEX_PATTERNS[\"{}\"].search({variable}_key):', pattern):\n                        with self.l('if {variable}_key in {variable}_keys:'):\n                            self.l('{variable}_keys.remove({variable}_key)')\n                        self.generate_func_code_block(\n                            definition,\n                            '{}_val'.format(self._variable),\n                            '{}.{{{}_key}}'.format(self._variable_name, self._variable),\n                        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_additional_properties(self):\n        self.create_variable_is_dict()\n        with self.l('if {variable}_is_dict:'):\n            self.create_variable_keys()\n            add_prop_definition = self._definition[\"additionalProperties\"]\n            if add_prop_definition:\n                properties_keys = list(self._definition.get(\"properties\", {}).keys())\n                with self.l('for {variable}_key in {variable}_keys:'):\n                    with self.l('if {variable}_key not in {}:', properties_keys):\n                        self.l('{variable}_value = {variable}.get({variable}_key)')\n                        self.generate_func_code_block(\n                            add_prop_definition,\n                            '{}_value'.format(self._variable),\n                            '{}.{{{}_key}}'.format(self._variable_name, self._variable),\n                        )\n            else:\n                with self.l('if {variable}_keys:'):\n                    self.l('raise JsonSchemaException(\"{name} must contain only specified properties\")')", "response": "Generate the additional properties of the resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates the dependencies of the object.", "response": "def generate_dependencies(self):\n        \"\"\"\n        Means when object has property, it needs to have also other property.\n\n        .. code-block:: python\n\n            {\n                'dependencies': {\n                    'bar': ['foo'],\n                },\n            }\n\n        Valid object is containing only foo, both bar and foo or none of them, but not\n        object with only bar.\n\n        Since draft 06 definition can be boolean or empty array. True and empty array\n        means nothing, False means that key cannot be there at all.\n        \"\"\"\n        self.create_variable_is_dict()\n        with self.l('if {variable}_is_dict:'):\n            self.create_variable_keys()\n            for key, values in self._definition[\"dependencies\"].items():\n                if values == [] or values is True:\n                    continue\n                with self.l('if \"{}\" in {variable}_keys:', key):\n                    if values is False:\n                        self.l('raise JsonSchemaException(\"{} in {name} must not be there\")', key)\n                    elif isinstance(values, list):\n                        for value in values:\n                            with self.l('if \"{}\" not in {variable}_keys:', value):\n                                self.l('raise JsonSchemaException(\"{name} missing dependency {} for {}\")', value, key)\n                    else:\n                        self.generate_func_code_block(values, self._variable, self._variable_name, clear_variables=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates validation function for validating JSON schema passed in definition.", "response": "def compile(definition, handlers={}):\n    \"\"\"\n    Generates validation function for validating JSON schema passed in ``definition``.\n    Example:\n\n    .. code-block:: python\n\n        import fastjsonschema\n\n        validate = fastjsonschema.compile({'type': 'string'})\n        validate('hello')\n\n    This implementation support keyword ``default``:\n\n    .. code-block:: python\n\n        validate = fastjsonschema.compile({\n            'type': 'object',\n            'properties': {\n                'a': {'type': 'number', 'default': 42},\n            },\n        })\n\n        data = validate({})\n        assert data == {'a': 42}\n\n    Supported implementations are draft-04, draft-06 and draft-07. Which version\n    should be used is determined by `$draft` in your ``definition``. When not\n    specified, the latest implementation is used (draft-07).\n\n    .. code-block:: python\n\n        validate = fastjsonschema.compile({\n            '$schema': 'http://json-schema.org/draft-04/schema',\n            'type': 'number',\n        })\n\n    You can pass mapping from URI to function that should be used to retrieve\n    remote schemes used in your ``definition`` in parameter ``handlers``.\n\n    Exception :any:`JsonSchemaDefinitionException` is raised when generating the\n    code fails (bad definition).\n\n    Exception :any:`JsonSchemaException` is raised from generated funtion when\n    validation fails (data do not follow the definition).\n    \"\"\"\n    resolver, code_generator = _factory(definition, handlers)\n    global_state = code_generator.global_state\n    # Do not pass local state so it can recursively call itself.\n    exec(code_generator.func_code, global_state)\n    return global_state[resolver.get_scope_name()]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compile_to_code(definition, handlers={}):\n    _, code_generator = _factory(definition, handlers)\n    return (\n        'VERSION = \"' + VERSION + '\"\\n' +\n        code_generator.global_state_code + '\\n' +\n        code_generator.func_code\n    )", "response": "Generates validation code for validating JSON schema passed in definition."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _read_cmap(self):\n\n        try:\n            i = 0\n            colormap = {0: (0, 0, 0)}\n            with open(settings.COLORMAP) as cmap:\n                lines = cmap.readlines()\n                for line in lines:\n                    if i == 0 and 'mode = ' in line:\n                        i = 1\n                        maxval = float(line.replace('mode = ', ''))\n                    elif i > 0:\n                        str = line.split()\n                        if str == []:  # when there are empty lines at the end of the file\n                            break\n                        colormap.update(\n                            {\n                                i: (int(round(float(str[0]) * 255 / maxval)),\n                                    int(round(float(str[1]) * 255 / maxval)),\n                                    int(round(float(str[2]) * 255 / maxval)))\n                            }\n                        )\n                        i += 1\n        except IOError:\n            pass\n\n        self.cmap = {k: v[:4] for k, v in colormap.items()}", "response": "reads the colormap from a text file given in settings. py.\n        See colormap_cubehelix. txt."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef data_collector(iterable, def_buf_size=5242880):\n    buf = b''\n    for data in iterable:\n        buf += data\n        if len(buf) >= def_buf_size:\n            output = buf[:def_buf_size]\n            buf = buf[def_buf_size:]\n            yield output\n    if len(buf) > 0:\n        yield buf", "response": "A generator that yields n bytes of data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef upload(bucket, aws_access_key, aws_secret_key,\n           iterable, key, progress_cb=None,\n           threads=5, replace=False, secure=True,\n           connection=None):\n    \"\"\" Upload data to s3 using the s3 multipart upload API.\n\n    :param bucket:\n        Name of the S3 bucket\n    :type bucket:\n        String\n    :param aws_access_key:\n        AWS access key id (optional)\n    :type aws_access_key:\n        String\n    :param aws_secret_key:\n        AWS access secret key (optional)\n    :type aws_secret_key:\n        String\n    :param iterable:\n        The data to upload. Each 'part' in the list. will be uploaded in parallel. Each part must be at\n        least 5242880 bytes (5mb).\n    :type iterable:\n        An iterable object\n    :param key:\n        The name of the key (filename) to create in the s3 bucket\n    :type key:\n        String\n    :param progress_cb:\n        Progress callback, will be called with (part_no, uploaded, total) each time a progress update\n        is available. (optional)\n    :type progress_cb:\n        function\n    :param threads:\n        the number of threads to use while uploading. (Default is 5)\n    :type threads:\n        int\n    :param replace:\n        will replace the key (filename) on S3 if set to true. (Default is false)\n    :type replace:\n        boolean\n    :param secure:\n        Use ssl when talking to s3. (Default is true)\n    :type secure:\n        boolean\n    :param connection:\n        Used for testing (optional)\n    :type connection:\n        S3 connection class\n\n    :returns:\n        void\n    \"\"\"\n\n    if not connection:\n        from boto.s3.connection import S3Connection as connection\n        c = connection(aws_access_key, aws_secret_key, is_secure=secure)\n    else:\n        c = connection\n\n    b = c.get_bucket(bucket)\n\n    if not replace and b.lookup(key):\n        raise Exception('s3 key ' + key + ' already exists')\n\n    multipart_obj = b.initiate_multipart_upload(key)\n    err_queue = queue.Queue()\n    lock = threading.Lock()\n    upload.counter = 0\n\n    try:\n        tpool = pool.ThreadPool(processes=threads)\n\n        def check_errors():\n            try:\n                exc = err_queue.get(block=False)\n            except queue.Empty:\n                pass\n            else:\n                raise exc\n\n        def waiter():\n            while upload.counter >= threads:\n                check_errors()\n                time.sleep(0.1)\n\n        def cb(err):\n            if err:\n                err_queue.put(err)\n            with lock:\n                upload.counter -= 1\n\n        args = [multipart_obj.upload_part_from_file, progress_cb]\n\n        for part_no, part in enumerate(iterable):\n            part_no += 1\n            tpool.apply_async(upload_part, args + [part_no, part], callback=cb)\n            with lock:\n                upload.counter += 1\n            waiter()\n\n        tpool.close()\n        tpool.join()\n        # Check for thread errors before completing the upload,\n        # sometimes an error can be left unchecked until we\n        # get to this point.\n        check_errors()\n        multipart_obj.complete_upload()\n    except:\n        multipart_obj.cancel_upload()\n        tpool.terminate()\n        raise", "response": "Upload data to s3 using the multipart upload API."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitiating the upload. :param bucket_name: Name of the S3 bucket :type bucket_name: String :param filename: The filname :type filename: String :param path: The path to the file that needs to be uploaded :type path: String :returns: void", "response": "def run(self, bucket_name, filename, path):\n        \"\"\"\n        Initiate the upload.\n\n        :param bucket_name:\n            Name of the S3 bucket\n        :type bucket_name:\n            String\n        :param filename:\n            The filname\n        :type filename:\n            String\n        :param path:\n            The path to the file that needs to be uploaded\n        :type path:\n            String\n\n        :returns:\n            void\n        \"\"\"\n\n        f = open(path, 'rb')\n        self.source_size = os.stat(path).st_size\n        total_dict = {}\n\n        def cb(part_no, uploaded, total):\n\n            total_dict[part_no] = uploaded\n\n            params = {\n                'uploaded': round(sum(total_dict.values()) / 1048576, 0),\n                'size': round(self.source_size / 1048576, 0),\n            }\n\n            p = (self.progress_template + '\\r') % params\n\n            STREAM.write(p)\n            STREAM.flush()\n\n        self.output('Uploading to S3', normal=True, arrow=True)\n        upload(bucket_name, self.key, self.secret,\n               data_collector(iter(f)), filename, cb,\n               threads=10, replace=True, secure=True, connection=self.conn)\n\n        print('\\n')\n        self.output('Upload Completed', normal=True, arrow=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading a list of scenes from Google Storage or Amazon S3.", "response": "def download(self, scenes, bands=None):\n        \"\"\"\n        Download scenese from Google Storage or Amazon S3 if bands are provided\n\n        :param scenes:\n            A list of scene IDs\n        :type scenes:\n            List\n        :param bands:\n            A list of bands. Default value is None.\n        :type scenes:\n            List\n\n        :returns:\n            (List) includes downloaded scenes as key and source as value (aws or google)\n        \"\"\"\n\n        if isinstance(scenes, list):\n            files = []\n\n            for scene in scenes:\n\n                # for all scenes if bands provided, first check AWS, if the bands exist\n                # download them, otherwise use Google and then USGS.\n                try:\n                    # if bands are not provided, directly go to Goodle and then USGS\n                    if not isinstance(bands, list):\n                        raise RemoteFileDoesntExist\n                    files.append(self.amazon_s3(scene, bands))\n\n                except RemoteFileDoesntExist:\n                    try:\n                        files.append(self.google_storage(scene, self.download_dir))\n                    except RemoteFileDoesntExist:\n                        files.append(self.usgs_eros(scene, self.download_dir))\n\n            return files\n\n        else:\n            raise Exception('Expected sceneIDs list')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef usgs_eros(self, scene, path):\n\n        # download from usgs if login information is provided\n        if self.usgs_user and self.usgs_pass:\n            try:\n                api_key = api.login(self.usgs_user, self.usgs_pass)\n            except USGSError as e:\n                error_tree = ElementTree.fromstring(str(e.message))\n                error_text = error_tree.find(\"SOAP-ENV:Body/SOAP-ENV:Fault/faultstring\", api.NAMESPACES).text\n                raise USGSInventoryAccessMissing(error_text)\n\n            download_url = api.download('LANDSAT_8', 'EE', [scene], api_key=api_key)\n            if download_url:\n                self.output('Source: USGS EarthExplorer', normal=True, arrow=True)\n                return self.fetch(download_url[0], path)\n\n            raise RemoteFileDoesntExist('%s is not available on AWS S3, Google or USGS Earth Explorer' % scene)\n        raise RemoteFileDoesntExist('%s is not available on AWS S3 or Google Storage' % scene)", "response": "Downloads the image from USGS"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndownloads the image from Google Storage.", "response": "def google_storage(self, scene, path):\n        \"\"\"\n        Google Storage Downloader.\n\n        :param scene:\n            The scene id\n        :type scene:\n            String\n        :param path:\n            The directory path to where the image should be stored\n        :type path:\n            String\n\n        :returns:\n            Boolean\n        \"\"\"\n\n        sat = self.scene_interpreter(scene)\n        url = self.google_storage_url(sat)\n\n        self.remote_file_exists(url)\n\n        self.output('Source: Google Storage', normal=True, arrow=True)\n        return self.fetch(url, path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading and return the path to the Amazon S3 file for the specified scene and bands", "response": "def amazon_s3(self, scene, bands):\n        \"\"\"\n        Amazon S3 downloader\n        \"\"\"\n\n        sat = self.scene_interpreter(scene)\n\n        # Always grab MTL.txt and QA band if bands are specified\n        if 'BQA' not in bands:\n            bands.append('QA')\n\n        if 'MTL' not in bands:\n            bands.append('MTL')\n\n        urls = []\n\n        for band in bands:\n            # get url for the band\n            url = self.amazon_s3_url(sat, band)\n\n            # make sure it exist\n            self.remote_file_exists(url)\n            urls.append(url)\n\n        # create folder\n        path = check_create_folder(join(self.download_dir, scene))\n\n        self.output('Source: AWS S3', normal=True, arrow=True)\n        for url in urls:\n            self.fetch(url, path)\n\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndownloads the given url and stores it in the given path.", "response": "def fetch(self, url, path):\n        \"\"\" Downloads the given url.\n\n        :param url:\n            The url to be downloaded.\n        :type url:\n            String\n        :param path:\n            The directory path to where the image should be stored\n        :type path:\n            String\n        :param filename:\n            The filename that has to be downloaded\n        :type filename:\n            String\n\n        :returns:\n            Boolean\n        \"\"\"\n\n        segments = url.split('/')\n        filename = segments[-1]\n\n        # remove query parameters from the filename\n        filename = filename.split('?')[0]\n\n        self.output('Downloading: %s' % filename, normal=True, arrow=True)\n\n        # print(join(path, filename))\n        # raise Exception\n        if exists(join(path, filename)):\n            size = getsize(join(path, filename))\n            if size == self.get_remote_file_size(url):\n                self.output('%s already exists on your system' % filename, normal=True, color='green', indent=1)\n\n        else:\n            fetch(url, path)\n        self.output('stored at %s' % path, normal=True, color='green', indent=1)\n\n        return join(path, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef google_storage_url(self, sat):\n        filename = sat['scene'] + '.tar.bz'\n        return url_builder([self.google, sat['sat'], sat['path'], sat['row'], filename])", "response": "Returns a google storage url the contains the scene provided."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef amazon_s3_url(self, sat, band):\n        if band != 'MTL':\n            filename = '%s_B%s.TIF' % (sat['scene'], band)\n        else:\n            filename = '%s_%s.txt' % (sat['scene'], band)\n\n        return url_builder([self.s3, sat['sat'], sat['path'], sat['row'], sat['scene'], filename])", "response": "Returns an Amazon s3 url the contains the scene and band provided."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck whether the remote file exists.", "response": "def remote_file_exists(self, url):\n        \"\"\" Checks whether the remote file exists.\n\n        :param url:\n            The url that has to be checked.\n        :type url:\n            String\n\n        :returns:\n            **True** if remote file exists and **False** if it doesn't exist.\n        \"\"\"\n        status = requests.head(url).status_code\n\n        if status != 200:\n            raise RemoteFileDoesntExist"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the filesize of a remote file.", "response": "def get_remote_file_size(self, url):\n        \"\"\" Gets the filesize of a remote file.\n\n        :param url:\n            The url that has to be checked.\n        :type url:\n            String\n\n        :returns:\n            int\n        \"\"\"\n        headers = requests.head(url).headers\n        return int(headers['content-length'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scene_interpreter(self, scene):\n        anatomy = {\n            'path': None,\n            'row': None,\n            'sat': None,\n            'scene': scene\n        }\n        if isinstance(scene, str) and len(scene) == 21:\n            anatomy['path'] = scene[3:6]\n            anatomy['row'] = scene[6:9]\n            anatomy['sat'] = 'L' + scene[2:3]\n\n            return anatomy\n        else:\n            raise IncorrectSceneId('Received incorrect scene')", "response": "This function is used to generate the necessary data for the nationary interpreter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search(self, paths_rows=None, lat=None, lon=None, address=None, start_date=None, end_date=None, cloud_min=None,\n               cloud_max=None, limit=1, geojson=False):\n        \"\"\"\n        The main method of Search class. It searches Development Seed's Landsat API.\n\n        :param paths_rows:\n            A string in this format: \"003,003,004,004\". Must be in pairs and separated by comma.\n        :type paths_rows:\n            String\n        :param lat:\n            The latitude\n        :type lat:\n            String, float, integer\n        :param lon:\n            The The longitude\n        :type lon:\n            String, float, integer\n        :param address:\n            The address\n        :type address:\n            String\n        :param start_date:\n            Date string. format: YYYY-MM-DD\n        :type start_date:\n            String\n        :param end_date:\n            date string. format: YYYY-MM-DD\n        :type end_date:\n            String\n        :param cloud_min:\n            float specifying the minimum percentage. e.g. 4.3\n        :type cloud_min:\n            float\n        :param cloud_max:\n            float specifying the maximum percentage. e.g. 78.9\n        :type cloud_max:\n            float\n        :param limit:\n            integer specigying the maximum results return.\n        :type limit:\n            integer\n        :param geojson:\n            boolean specifying whether to return a geojson object\n        :type geojson:\n            boolean\n\n        :returns:\n            dict\n\n        :example:\n            >>> search = Search()\n            >>> search('003,003', '2014-01-01', '2014-06-01')\n            >>> {\n                    'status': u'SUCCESS',\n                    'total_returned': 1,\n                    'total': 1,\n                    'limit': 1\n                    'results': [\n                        {\n                            'sat_type': u'L8',\n                            'sceneID': u'LC80030032014142LGN00',\n                            'date': u'2014-05-22',\n                            'path': u'003',\n                            'thumbnail': u'http://....../landsat_8/2014/003/003/LC80030032014142LGN00.jpg',\n                            'cloud': 33.36,\n                            'row': u'003\n                        }\n                    ]\n                }\n        \"\"\"\n\n        search_string = self.query_builder(paths_rows, lat, lon, address, start_date, end_date, cloud_min, cloud_max)\n\n        # Have to manually build the URI to bypass requests URI encoding\n        # The api server doesn't accept encoded URIs\n\n        r = requests.get('%s?search=%s&limit=%s' % (self.api_url, search_string, limit))\n\n        r_dict = json.loads(r.text)\n        result = {}\n\n        if 'error' in r_dict:\n            result['status'] = u'error'\n            result['code'] = r_dict['error']['code']\n            result['message'] = r_dict['error']['message']\n\n        elif 'meta' in r_dict:\n            if geojson:\n                result = {\n                    'type': 'FeatureCollection',\n                    'features': []\n                }\n                for r in r_dict['results']:\n                    feature = {\n                        'type': 'Feature',\n                        'properties': {\n                            'sceneID': r['sceneID'],\n                            'row': three_digit(r['row']),\n                            'path': three_digit(r['path']),\n                            'thumbnail': r['browseURL'],\n                            'date': r['acquisitionDate'],\n                            'cloud': r['cloud_coverage']\n                        },\n                        'geometry': {\n                            'type': 'Polygon',\n                            'coordinates': [\n                                [\n                                    [r['upperLeftCornerLongitude'], r['upperLeftCornerLatitude']],\n                                    [r['lowerLeftCornerLongitude'], r['lowerLeftCornerLatitude']],\n                                    [r['lowerRightCornerLongitude'], r['lowerRightCornerLatitude']],\n                                    [r['upperRightCornerLongitude'], r['upperRightCornerLatitude']],\n                                    [r['upperLeftCornerLongitude'], r['upperLeftCornerLatitude']]\n                                ]\n                            ]\n                        }\n                    }\n\n                    result['features'].append(feature)\n\n            else:\n                result['status'] = u'SUCCESS'\n                result['total'] = r_dict['meta']['found']\n                result['limit'] = r_dict['meta']['limit']\n                result['total_returned'] = len(r_dict['results'])\n                result['results'] = [{'sceneID': i['sceneID'],\n                                      'sat_type': u'L8',\n                                      'path': three_digit(i['path']),\n                                      'row': three_digit(i['row']),\n                                      'thumbnail': i['browseURL'],\n                                      'date': i['acquisitionDate'],\n                                      'cloud': i['cloud_coverage']}\n                                     for i in r_dict['results']]\n\n        return result", "response": "This method is used to search the Landsat API for a specific entry in the base class Search class. It returns a dictionary containing the results of the search."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef query_builder(self, paths_rows=None, lat=None, lon=None, address=None, start_date=None, end_date=None,\n                      cloud_min=None, cloud_max=None):\n        \"\"\" Builds the proper search syntax (query) for Landsat API.\n\n        :param paths_rows:\n            A string in this format: \"003,003,004,004\". Must be in pairs and separated by comma.\n        :type paths_rows:\n            String\n        :param lat:\n            The latitude\n        :type lat:\n            String, float, integer\n        :param lon:\n            The The longitude\n        :type lon:\n            String, float, integer\n        :param address:\n            The address\n        :type address:\n            String\n        :param start_date:\n            Date string. format: YYYY-MM-DD\n        :type start_date:\n            String\n        :param end_date:\n            date string. format: YYYY-MM-DD\n        :type end_date:\n            String\n        :param cloud_min:\n            float specifying the minimum percentage. e.g. 4.3\n        :type cloud_min:\n            float\n        :param cloud_max:\n            float specifying the maximum percentage. e.g. 78.9\n        :type cloud_max:\n            float\n\n        :returns:\n            String\n        \"\"\"\n\n        query = []\n        or_string = ''\n        and_string = ''\n        search_string = ''\n\n        if paths_rows:\n            # Coverting rows and paths to paired list\n            new_array = create_paired_list(paths_rows)\n            paths_rows = ['(%s)' % self.row_path_builder(i[0], i[1]) for i in new_array]\n            or_string = '+OR+'.join(map(str, paths_rows))\n\n        if start_date and end_date:\n            query.append(self.date_range_builder(start_date, end_date))\n        elif start_date:\n            query.append(self.date_range_builder(start_date, '2100-01-01'))\n        elif end_date:\n            query.append(self.date_range_builder('2009-01-01', end_date))\n\n        if cloud_min and cloud_max:\n            query.append(self.cloud_cover_prct_range_builder(cloud_min, cloud_max))\n        elif cloud_min:\n            query.append(self.cloud_cover_prct_range_builder(cloud_min, '100'))\n        elif cloud_max:\n            query.append(self.cloud_cover_prct_range_builder('-1', cloud_max))\n\n        if address:\n            query.append(self.address_builder(address))\n        elif (lat is not None) and (lon is not None):\n            query.append(self.lat_lon_builder(lat, lon))\n\n        if query:\n            and_string = '+AND+'.join(map(str, query))\n\n        if and_string and or_string:\n            search_string = and_string + '+AND+(' + or_string + ')'\n        else:\n            search_string = or_string + and_string\n\n        return search_string", "response": "Builds the proper search syntax for the Landsat API."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef date_range_builder(self, start='2013-02-11', end=None):\n        if not end:\n            end = time.strftime('%Y-%m-%d')\n\n        return 'acquisitionDate:[%s+TO+%s]' % (start, end)", "response": "Builds a date range query."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef exit(message, code=0):\n\n    v = VerbosityMixin()\n    if code == 0:\n        v.output(message, normal=True, arrow=True)\n        v.output('Done!', normal=True, arrow=True)\n    else:\n        v.output(message, normal=True, error=True)\n    sys.exit(code)", "response": "output a message to stdout and exits the process."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a list of paired items from a string.", "response": "def create_paired_list(value):\n    \"\"\" Create a list of paired items from a string.\n\n    :param value:\n        the format must be 003,003,004,004 (commas with no space)\n    :type value:\n        String\n\n    :returns:\n        List\n\n    :example:\n        >>> create_paired_list('003,003,004,004')\n        [['003','003'], ['004', '004']]\n\n    \"\"\"\n\n    if isinstance(value, list):\n        value = \",\".join(value)\n\n    array = re.split('\\D+', value)\n\n    # Make sure the elements in the list are even and pairable\n    if len(array) % 2 == 0:\n        new_array = [list(array[i:i + 2]) for i in range(0, len(array), 2)]\n        return new_array\n    else:\n        raise ValueError('The string should include pairs and be formated. '\n                         'The format must be 003,003,004,004 (commas with '\n                         'no space)')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking whether a folder exists if not creates it.", "response": "def check_create_folder(folder_path):\n    \"\"\" Check whether a folder exists, if not the folder is created.\n\n    :param folder_path:\n        Path to the folder\n    :type folder_path:\n        String\n\n    :returns:\n        (String) the path to the folder\n    \"\"\"\n    if not os.path.exists(folder_path):\n        os.makedirs(folder_path)\n\n    return folder_path"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef three_digit(number):\n    number = str(number)\n    if len(number) == 1:\n        return u'00%s' % number\n    elif len(number) == 2:\n        return u'0%s' % number\n    else:\n        return number", "response": "Converts a number to a three digit string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef georgian_day(date):\n    try:\n        fmt = '%m/%d/%Y'\n        return datetime.strptime(date, fmt).timetuple().tm_yday\n    except (ValueError, TypeError):\n        return 0", "response": "Returns the number of days passed since the start of the year."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the year of the current node in the alphabetical order", "response": "def year(date):\n    \"\"\" Returns the year.\n\n    :param date:\n        The string date with this format %m/%d/%Y\n    :type date:\n        String\n\n    :returns:\n        int\n\n    :example:\n        >>> year('05/1/2015')\n        2015\n    \"\"\"\n    try:\n        fmt = '%m/%d/%Y'\n        return datetime.strptime(date, fmt).timetuple().tm_year\n    except ValueError:\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the string date with this format %m/%d/%Y", "response": "def reformat_date(date, new_fmt='%Y-%m-%d'):\n    \"\"\" Returns reformated date.\n\n    :param date:\n        The string date with this format %m/%d/%Y\n    :type date:\n        String\n    :param new_fmt:\n        date format string. Default is '%Y-%m-%d'\n    :type date:\n        String\n\n    :returns:\n        int\n\n    :example:\n        >>> reformat_date('05/1/2015', '%d/%m/%Y')\n        '1/05/2015'\n    \"\"\"\n    try:\n        if isinstance(date, datetime):\n            return date.strftime(new_fmt)\n        else:\n            fmt = '%m/%d/%Y'\n            return datetime.strptime(date, fmt).strftime(new_fmt)\n    except ValueError:\n        return date"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a comma separated string to a list of integers", "response": "def convert_to_integer_list(value):\n    \"\"\" Converts a comma separate string to a list\n\n    :param value:\n        the format must be 003,003,004,004 (commas with no space)\n    :type value:\n        String\n\n    :returns:\n        List\n\n    :example:\n        >>> convert_to_integer_list('003,003,004,004')\n        ['003', '003', '004', '004']\n\n    \"\"\"\n    if isinstance(value, list) or value is None:\n        return value\n    else:\n        s = re.findall('(10|11|QA|[0-9])', value)\n        for k, v in enumerate(s):\n            try:\n                s[k] = int(v)\n            except ValueError:\n                pass\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the coordinates of an address in the geocoding region", "response": "def geocode(address, required_precision_km=1.):\n    \"\"\" Identifies the coordinates of an address\n\n    :param address:\n        the address to be geocoded\n    :type value:\n        String\n    :param required_precision_km:\n        the maximum permissible geographic uncertainty for the geocoding\n    :type required_precision_km:\n        float\n\n    :returns:\n        dict\n\n    :example:\n        >>> geocode('1600 Pennsylvania Ave NW, Washington, DC 20500')\n        {'lat': 38.89767579999999, 'lon': -77.0364827}\n\n    \"\"\"\n    geocoded = geocoder.google(address)\n    precision_km = geocode_confidences[geocoded.confidence]\n\n    if precision_km <= required_precision_km:\n        (lon, lat) = geocoded.geometry['coordinates']\n        return {'lat': lat, 'lon': lon}\n    else:\n        raise ValueError(\"Address could not be precisely located\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_to_float_list(value):\n    if isinstance(value, list) or value is None:\n        return value\n    else:\n        s = re.findall('([-+]?\\d*\\.\\d+|\\d+|[-+]?\\d+)', value)\n        for k, v in enumerate(s):\n            try:\n                s[k] = float(v)\n            except ValueError:\n                pass\n        return s", "response": "Converts a comma separated string to a list of float values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef adjust_bounding_box(bounds1, bounds2):\n\n    # out of bound check\n    # If it is completely outside of target bounds, return target bounds\n    if ((bounds2[0] > bounds1[0] and bounds2[2] > bounds1[0]) or\n            (bounds2[2] < bounds1[2] and bounds2[2] < bounds1[0])):\n        return bounds1\n\n    if ((bounds2[1] < bounds1[1] and bounds2[3] < bounds1[1]) or\n            (bounds2[3] > bounds1[3] and bounds2[1] > bounds1[3])):\n        return bounds1\n\n    new_bounds = list(bounds2)\n\n    # Adjust Y axis (Longitude)\n    if (bounds2[0] > bounds1[0] or bounds2[0] < bounds1[3]):\n        new_bounds[0] = bounds1[0]\n    if (bounds2[2] < bounds1[2] or bounds2[2] > bounds1[0]):\n        new_bounds[2] = bounds1[2]\n\n    # Adjust X axis (Latitude)\n    if (bounds2[1] < bounds1[1] or bounds2[1] > bounds1[3]):\n        new_bounds[1] = bounds1[1]\n    if (bounds2[3] > bounds1[3] or bounds2[3] < bounds1[1]):\n        new_bounds[3] = bounds1[3]\n\n    return tuple(new_bounds)", "response": "Adjusts the bounds of a single resource in a sequence of 2 corners."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef args_options():\n\n    parser = argparse.ArgumentParser(prog='landsat',\n                                     formatter_class=argparse.RawDescriptionHelpFormatter,\n                                     description=textwrap.dedent(DESCRIPTION))\n\n    subparsers = parser.add_subparsers(help='Landsat Utility',\n                                       dest='subs')\n\n    parser.add_argument('--version', action='version', version='%(prog)s version ' + __version__)\n\n    # Search Logic\n    parser_search = subparsers.add_parser('search',\n                                          help='Search Landsat metadata')\n\n    # Global search options\n    parser_search.add_argument('-l', '--limit', default=10, type=int,\n                               help='Search return results limit\\n'\n                               'default is 10')\n    parser_search.add_argument('-s', '--start',\n                               help='Start Date - Most formats are accepted '\n                               'e.g. Jun 12 2014 OR 06/12/2014')\n    parser_search.add_argument('-e', '--end',\n                               help='End Date - Most formats are accepted '\n                               'e.g. Jun 12 2014 OR 06/12/2014')\n    parser_search.add_argument('--latest', default=-1, type=int,\n                               help='returns the N latest images within the last 365 days')\n    parser_search.add_argument('-c', '--cloud', type=float, default=100.0,\n                               help='Maximum cloud percentage '\n                               'default is 100 perct')\n    parser_search.add_argument('-p', '--pathrow',\n                               help='Paths and Rows in order separated by comma. Use quotes (\"001\").'\n                               'Example: path,row,path,row 001,001,190,204')\n    parser_search.add_argument('--lat', type=float, help='The latitude')\n    parser_search.add_argument('--lon', type=float, help='The longitude')\n    parser_search.add_argument('--address', type=str, help='The address')\n    parser_search.add_argument('--json', action='store_true', help='Returns a bare JSON response')\n    parser_search.add_argument('--geojson', action='store_true', help='Returns a geojson response')\n\n    parser_download = subparsers.add_parser('download',\n                                            help='Download images from Google Storage')\n    parser_download.add_argument('scenes',\n                                 metavar='sceneID',\n                                 nargs=\"+\",\n                                 help=\"Provide Full sceneID, e.g. LC81660392014196LGN00\")\n\n    parser_download.add_argument('-b', '--bands', help='If you specify bands, landsat-util will try to download '\n                                 'the band from S3. If the band does not exist, an error is returned', default=None)\n    parser_download.add_argument('-d', '--dest', help='Destination path')\n    parser_download.add_argument('-p', '--process', help='Process the image after download', action='store_true')\n    parser_download.add_argument('--pansharpen', action='store_true',\n                                 help='Whether to also pansharpen the process '\n                                 'image. Pansharpening requires larger memory')\n    parser_download.add_argument('--ndvi', action='store_true',\n                                 help='Whether to run the NDVI process. If used, bands parameter is disregarded')\n    parser_download.add_argument('--ndvigrey', action='store_true', help='Create an NDVI map in grayscale (grey)')\n    parser_download.add_argument('--clip', help='Clip the image with the bounding box provided. Values must be in ' +\n                                 'WGS84 datum, and with longitude and latitude units of decimal degrees ' +\n                                 'separated by comma.' +\n                                 'Example: --clip=-346.06658935546875,49.93531194616915,-345.4595947265625,' +\n                                 '50.2682767372753')\n    parser_download.add_argument('-u', '--upload', action='store_true',\n                                 help='Upload to S3 after the image processing completed')\n    parser_download.add_argument('--username', help='USGS Eros account Username (only works if the account has' +\n                                 ' special inventory access). Username and password as a fallback if the image' +\n                                 'is not found on AWS S3 or Google Storage')\n    parser_download.add_argument('--password', help='USGS Eros username, used as a fallback')\n    parser_download.add_argument('--key', help='Amazon S3 Access Key (You can also be set AWS_ACCESS_KEY_ID as '\n                                 'Environment Variables)')\n    parser_download.add_argument('--secret', help='Amazon S3 Secret Key (You can also be set AWS_SECRET_ACCESS_KEY '\n                                 'as Environment Variables)')\n    parser_download.add_argument('--bucket', help='Bucket name (required if uploading to s3)')\n    parser_download.add_argument('--region', help='URL to S3 region e.g. s3-us-west-2.amazonaws.com')\n    parser_download.add_argument('--force-unzip', help='Force unzip tar file', action='store_true')\n\n    parser_process = subparsers.add_parser('process', help='Process Landsat imagery')\n    parser_process.add_argument('path',\n                                help='Path to the compressed image file')\n    parser_process.add_argument('--pansharpen', action='store_true',\n                                help='Whether to also pansharpen the process '\n                                'image. Pansharpening requires larger memory')\n    parser_process.add_argument('--ndvi', action='store_true', help='Create an NDVI map in color.')\n    parser_process.add_argument('--ndvigrey', action='store_true', help='Create an NDVI map in grayscale (grey)')\n    parser_process.add_argument('--clip', help='Clip the image with the bounding box provided. Values must be in ' +\n                                'WGS84 datum, and with longitude and latitude units of decimal degrees ' +\n                                'separated by comma.' +\n                                'Example: --clip=-346.06658935546875,49.93531194616915,-345.4595947265625,' +\n                                '50.2682767372753')\n    parser_process.add_argument('-b', '--bands', help='specify band combinations. Default is 432'\n                                'Example: --bands 321', default='432')\n    parser_process.add_argument('-v', '--verbose', action='store_true',\n                                help='Turn on verbosity')\n    parser_process.add_argument('-u', '--upload', action='store_true',\n                                help='Upload to S3 after the image processing completed')\n    parser_process.add_argument('--key', help='Amazon S3 Access Key (You can also be set AWS_ACCESS_KEY_ID as '\n                                'Environment Variables)')\n    parser_process.add_argument('--secret', help='Amazon S3 Secret Key (You can also be set AWS_SECRET_ACCESS_KEY '\n                                'as Environment Variables)')\n    parser_process.add_argument('--bucket', help='Bucket name (required if uploading to s3)')\n    parser_process.add_argument('--region', help='URL to S3 region e.g. s3-us-west-2.amazonaws.com')\n    parser_process.add_argument('--force-unzip', help='Force unzip tar file', action='store_true')\n\n    return parser", "response": "Generates an arugment parser for the base object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main(args):\n\n    v = VerbosityMixin()\n\n    if args:\n\n        if 'clip' in args:\n            bounds = convert_to_float_list(args.clip)\n        else:\n            bounds = None\n\n        if args.subs == 'process':\n            verbose = True if args.verbose else False\n            force_unzip = True if args.force_unzip else False\n            stored = process_image(args.path, args.bands, verbose, args.pansharpen, args.ndvi, force_unzip,\n                                   args.ndvigrey, bounds)\n\n            if args.upload:\n                u = Uploader(args.key, args.secret, args.region)\n                u.run(args.bucket, get_file(stored), stored)\n\n            return [\"The output is stored at %s\" % stored]\n\n        elif args.subs == 'search':\n\n            try:\n                if args.start:\n                    args.start = reformat_date(parse(args.start))\n                if args.end:\n                    args.end = reformat_date(parse(args.end))\n                if args.latest > 0:\n                    args.limit = 25\n                    end = datetime.now()\n                    start = end - relativedelta(days=+365)\n                    args.end = end.strftime(\"%Y-%m-%d\")\n                    args.start = start.strftime(\"%Y-%m-%d\")\n            except (TypeError, ValueError):\n                return [\"Your date format is incorrect. Please try again!\", 1]\n\n            s = Search()\n\n            try:\n                if args.lat is not None:\n                    lat = float(args.lat)\n                else:\n                    lat = None\n\n                if args.lon is not None:\n                    lon = float(args.lon)\n                else:\n                    lon = None\n            except ValueError:\n                return [\"The latitude and longitude values must be valid numbers\", 1]\n\n            address = args.address\n            if address and (lat and lon):\n                return [\"Cannot specify both address and latitude-longitude\"]\n\n            result = s.search(paths_rows=args.pathrow,\n                              lat=lat,\n                              lon=lon,\n                              address=address,\n                              limit=args.limit,\n                              start_date=args.start,\n                              end_date=args.end,\n                              cloud_max=args.cloud,\n                              geojson=args.geojson)\n\n            if 'status' in result:\n\n                if result['status'] == 'SUCCESS':\n                    if args.json:\n                        return json.dumps(result)\n\n                    if args.latest > 0:\n                        datelist = []\n                        for i in range(0, result['total_returned']):\n                            datelist.append((result['results'][i]['date'], result['results'][i]))\n\n                        datelist.sort(key=lambda tup: tup[0], reverse=True)\n                        datelist = datelist[:args.latest]\n\n                        result['results'] = []\n                        for i in range(0, len(datelist)):\n                            result['results'].append(datelist[i][1])\n                            result['total_returned'] = len(datelist)\n\n                    else:\n                        v.output('%s items were found' % result['total'], normal=True, arrow=True)\n\n                    if result['total'] > 100:\n                        return ['Over 100 results. Please narrow your search', 1]\n                    else:\n                        v.output(json.dumps(result, sort_keys=True, indent=4), normal=True, color='green')\n                    return ['Search completed!']\n\n                elif result['status'] == 'error':\n                    return [result['message'], 1]\n\n            if args.geojson:\n                return json.dumps(result)\n\n        elif args.subs == 'download':\n            d = Downloader(download_dir=args.dest, usgs_user=args.username, usgs_pass=args.password)\n            try:\n                bands = convert_to_integer_list(args.bands)\n\n                if args.process:\n                    if args.pansharpen:\n                        bands.append(8)\n\n                    if args.ndvi or args.ndvigrey:\n                        bands = [4, 5]\n\n                    if not args.bands:\n                        bands = [4, 3, 2]\n\n                files = d.download(args.scenes, bands)\n\n                if args.process:\n                    if not args.bands:\n                        args.bands = '432'\n                    force_unzip = True if args.force_unzip else False\n                    for f in files:\n                        stored = process_image(f, args.bands, False, args.pansharpen, args.ndvi, force_unzip,\n                                               args.ndvigrey, bounds=bounds)\n\n                        if args.upload:\n                            try:\n                                u = Uploader(args.key, args.secret, args.region)\n                            except NoAuthHandlerFound:\n                                return [\"Could not authenticate with AWS\", 1]\n                            except URLError:\n                                return [\"Connection timeout. Probably the region parameter is incorrect\", 1]\n                            u.run(args.bucket, get_file(stored), stored)\n\n                    return ['The output is stored at %s' % stored, 0]\n                else:\n                    return ['Download Completed', 0]\n            except IncorrectSceneId:\n                return ['The SceneID provided was incorrect', 1]\n            except (RemoteFileDoesntExist, USGSInventoryAccessMissing) as e:\n                return [e.message, 1]", "response": "This function is the main function of the base class. It is intended to be used by the main function of the base class. It is intended to be used by the main function of the base class."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess an image and returns the path to the processed image.", "response": "def process_image(path, bands=None, verbose=False, pansharpen=False, ndvi=False, force_unzip=None,\n                  ndvigrey=False, bounds=None):\n    \"\"\" Handles constructing and image process.\n\n    :param path:\n        The path to the image that has to be processed\n    :type path:\n        String\n    :param bands:\n        List of bands that has to be processed. (optional)\n    :type bands:\n        List\n    :param verbose:\n        Sets the level of verbosity. Default is False.\n    :type verbose:\n        boolean\n    :param pansharpen:\n        Whether to pansharpen the image. Default is False.\n    :type pansharpen:\n        boolean\n\n    :returns:\n        (String) path to the processed image\n    \"\"\"\n    try:\n        bands = convert_to_integer_list(bands)\n        if pansharpen:\n            p = PanSharpen(path, bands=bands, dst_path=settings.PROCESSED_IMAGE,\n                           verbose=verbose, force_unzip=force_unzip, bounds=bounds)\n        elif ndvigrey:\n            p = NDVI(path, verbose=verbose, dst_path=settings.PROCESSED_IMAGE, force_unzip=force_unzip, bounds=bounds)\n        elif ndvi:\n            p = NDVIWithManualColorMap(path, dst_path=settings.PROCESSED_IMAGE,\n                                       verbose=verbose, force_unzip=force_unzip, bounds=bounds)\n        else:\n            p = Simple(path, bands=bands, dst_path=settings.PROCESSED_IMAGE, verbose=verbose, force_unzip=force_unzip,\n                       bounds=bounds)\n\n    except IOError as err:\n        exit(str(err), 1)\n    except FileDoesNotExist as err:\n        exit(str(err), 1)\n\n    return p.run()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a band with rasterio", "response": "def _read_bands(self):\n        \"\"\" Reads a band with rasterio \"\"\"\n        bands = []\n\n        try:\n            for i, band in enumerate(self.bands):\n                bands.append(rasterio.open(self.bands_path[i]).read_band(1))\n        except IOError as e:\n            exit(e.message, 1)\n\n        return bands"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_if_zipped(self, path):\n\n        filename = get_file(path).split('.')\n\n        if filename[-1] in ['bz', 'bz2', 'gz']:\n            return True\n\n        return False", "response": "Checks if the filename shows a tar file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _calculate_cloud_ice_perc(self):\n        self.output('Calculating cloud and snow coverage from QA band', normal=True, arrow=True)\n        a = rasterio.open(join(self.scene_path, self._get_full_filename('QA'))).read_band(1)\n\n        cloud_high_conf = int('1100000000000000', 2)\n        snow_high_conf = int('0000110000000000', 2)\n        fill_pixels = int('0000000000000001', 2)\n        cloud_mask = numpy.bitwise_and(a, cloud_high_conf) == cloud_high_conf\n        snow_mask = numpy.bitwise_and(a, snow_high_conf) == snow_high_conf\n        fill_mask = numpy.bitwise_and(a, fill_pixels) == fill_pixels\n\n        perc = numpy.true_divide(numpy.sum(cloud_mask | snow_mask),\n                                 a.size - numpy.sum(fill_mask)) * 100.0\n        self.output('cloud/snow coverage: %s' % round(perc, 2), indent=1, normal=True, color='green')\n        return perc", "response": "Calculate the percentage of pixels that are either cloud or snow with the high confidence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a filename for the current image.", "response": "def _filename(self, name=None, suffix=None, prefix=None):\n        \"\"\" File name generator for processed images \"\"\"\n\n        filename = ''\n\n        if prefix:\n            filename += str(prefix) + '_'\n\n        if name:\n            filename += str(name)\n        else:\n            filename += str(self.scene)\n\n        if suffix:\n            filename += '_' + str(suffix)\n\n        if self.clipped:\n            bounds = [tuple(self.bounds[0:2]), tuple(self.bounds[2:4])]\n            polyline = PolylineCodec().encode(bounds)\n            filename += '_clipped_' + polyline\n\n        filename += '.TIF'\n\n        return filename"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nclipping images based on bounds provided by the user.", "response": "def clip(self):\n        \"\"\" Clip images based on bounds provided\n        Implementation is borrowed from\n        https://github.com/brendan-ward/rasterio/blob/e3687ce0ccf8ad92844c16d913a6482d5142cf48/rasterio/rio/convert.py\n        \"\"\"\n\n        self.output(\"Clipping\", normal=True)\n\n        # create new folder for clipped images\n        path = check_create_folder(join(self.scene_path, 'clipped'))\n\n        try:\n            temp_bands = copy(self.bands)\n            temp_bands.append('QA')\n            for i, band in enumerate(temp_bands):\n                band_name = self._get_full_filename(band)\n                band_path = join(self.scene_path, band_name)\n\n                self.output(\"Band %s\" % band, normal=True, color='green', indent=1)\n                with rasterio.open(band_path) as src:\n                    bounds = transform_bounds(\n                        {\n                            'proj': 'longlat',\n                            'ellps': 'WGS84',\n                            'datum': 'WGS84',\n                            'no_defs': True\n                        },\n                        src.crs,\n                        *self.bounds\n                    )\n\n                    if disjoint_bounds(bounds, src.bounds):\n                        bounds = adjust_bounding_box(src.bounds, bounds)\n\n                    window = src.window(*bounds)\n\n                    out_kwargs = src.meta.copy()\n                    out_kwargs.update({\n                        'driver': 'GTiff',\n                        'height': window[0][1] - window[0][0],\n                        'width': window[1][1] - window[1][0],\n                        'transform': src.window_transform(window)\n                    })\n\n                    with rasterio.open(join(path, band_name), 'w', **out_kwargs) as out:\n                        out.write(src.read(window=window))\n\n            # Copy MTL to the clipped folder\n            copyfile(join(self.scene_path, self.scene + '_MTL.txt'), join(path, self.scene + '_MTL.txt'))\n\n            return path\n\n        except IOError as e:\n            exit(e.message, 1)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self):\n\n        self.output('Image processing started for bands %s' % '-'.join(map(str, self.bands)), normal=True, arrow=True)\n\n        bands = self._read_bands()\n        image_data = self._get_image_data()\n\n        new_bands = self._generate_new_bands(image_data['shape'])\n\n        self._warp(image_data, bands, new_bands)\n\n        # Bands are no longer needed\n        del bands\n\n        rasterio_options = {\n            'driver': 'GTiff',\n            'width': image_data['shape'][1],\n            'height': image_data['shape'][0],\n            'count': 3,\n            'dtype': numpy.uint8,\n            'nodata': 0,\n            'transform': image_data['dst_transform'],\n            'photometric': 'RGB',\n            'crs': self.dst_crs\n        }\n\n        return self._write_to_file(new_bands, **rasterio_options)", "response": "Executes the image processing."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes the pansharpen image processing.", "response": "def run(self):\n        \"\"\" Executes the pansharpen image processing.\n        :returns:\n            (String) the path to the processed image\n        \"\"\"\n\n        self.output('PanSharpened Image processing started for bands %s' % '-'.join(map(str, self.bands)),\n                    normal=True, arrow=True)\n\n        bands = self._read_bands()\n        image_data = self._get_image_data()\n\n        new_bands = self._generate_new_bands(image_data['shape'])\n\n        bands[:3] = self._rescale(bands[:3])\n        new_bands.append(numpy.empty(image_data['shape'], dtype=numpy.uint16))\n\n        self._warp(image_data, bands, new_bands)\n\n        # Bands are no longer needed\n        del bands\n\n        # Calculate pan band\n        pan = self._pansize(new_bands)\n        del self.bands[self.band8]\n        del new_bands[self.band8]\n\n        rasterio_options = {\n            'driver': 'GTiff',\n            'width': image_data['shape'][1],\n            'height': image_data['shape'][0],\n            'count': 3,\n            'dtype': numpy.uint8,\n            'nodata': 0,\n            'transform': image_data['dst_transform'],\n            'photometric': 'RGB',\n            'crs': self.dst_crs\n        }\n\n        return self._write_to_file(new_bands, pan, **rasterio_options)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef output(self, value, normal=False, color=None, error=False,\n               arrow=False, indent=None):\n        \"\"\" Handles verbosity of this calls.\n        if priority is set to 1, the value is printed\n\n        if class instance verbose is True, the value is printed\n\n        :param value:\n            a string representing the message to be printed\n        :type value:\n            String\n        :param normal:\n            if set to true the message is always printed, otherwise it is only shown if verbosity is set\n        :type normal:\n            boolean\n        :param color:\n            The color of the message, choices: 'red', 'green', 'blue'\n        :type normal:\n            String\n        :param error:\n            if set to true the message appears in red\n        :type error:\n            Boolean\n        :param arrow:\n            if set to true an arrow appears before the message\n        :type arrow:\n            Boolean\n        :param indent:\n            indents the message based on the number provided\n        :type indent:\n            Boolean\n\n        :returns:\n            void\n        \"\"\"\n\n        if error and value and (normal or self.verbose):\n            return self._print(value, color='red', indent=indent)\n\n        if self.verbose or normal:\n            return self._print(value, color, arrow, indent)\n\n        return", "response": "Prints the message to the screen."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef subprocess(self, argv):\n\n        if self.verbose:\n            proc = subprocess.Popen(argv, stderr=subprocess.PIPE)\n        else:\n            proc = subprocess.Popen(argv, stdout=subprocess.PIPE,\n                                    stderr=subprocess.PIPE)\n\n        self.output(proc.stderr.read(), error=True)\n\n        return", "response": "Execute subprocess commands with proper ouput.\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\noutput an exit message and exits", "response": "def exit(self, message):\n        \"\"\" outputs an exit message and exits\n\n        :param message:\n            The message to be outputed\n        :type message:\n            String\n\n        :returns:\n            void\n        \"\"\"\n\n        self.output(message, normal=True, color=\"green\")\n        sys.exit()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _print(self, msg, color=None, arrow=False, indent=None):\n        if color:\n            msg = colored(msg, color)\n\n        if arrow:\n            msg = colored('===> ', 'blue') + msg\n\n        if indent:\n            msg = ('     ' * indent) + msg\n\n        print(msg)\n\n        return msg", "response": "Print the message with the color provided."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nqueries the names and values of nanomsg symbols", "response": "def nn_symbols():\n    \"query the names and values of nanomsg symbols\"\n    value = ctypes.c_int()\n    name_value_pairs = []\n    i = 0\n    while True:\n        name = _nn_symbol(i, ctypes.byref(value))\n        if name is None:\n            break\n        i += 1\n        name_value_pairs.append((name.decode('ascii'), value.value))\n    return name_value_pairs"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset a socket option returning 0 on success - 1 on error", "response": "def nn_setsockopt(socket, level, option, value):\n    \"\"\"set a socket option\n\n    socket - socket number\n    level - option level\n    option - option\n    value - a readable byte buffer (not a Unicode string) containing the value\n    returns - 0 on success or < 0 on error\n\n    \"\"\"\n    try:\n        return _nn_setsockopt(socket, level, option, ctypes.addressof(value),\n                              len(value))\n    except (TypeError, AttributeError):\n        buf_value = ctypes.create_string_buffer(value)\n        return _nn_setsockopt(socket, level, option,\n                              ctypes.addressof(buf_value), len(value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves a socket optionby level optionby value", "response": "def nn_getsockopt(socket, level, option, value):\n    \"\"\"retrieve a socket option\n\n    socket - socket number\n    level - option level\n    option - option\n    value - a writable byte buffer (e.g. a bytearray) which the option value\n    will be copied to\n    returns - number of bytes copied or on error nunber < 0\n\n    \"\"\"\n    if memoryview(value).readonly:\n        raise TypeError('Writable buffer is required')\n    size_t_size = ctypes.c_size_t(len(value))\n    rtn = _nn_getsockopt(socket, level, option, ctypes.addressof(value),\n                         ctypes.byref(size_t_size))\n    return (rtn, size_t_size.value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_message_buffer(size, type):\n    rtn = wrapper.nn_allocmsg(size, type)\n    if rtn is None:\n        raise NanoMsgAPIError()\n    return rtn", "response": "Create a message buffer"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npolls a list of sockets and return a tuple of lists of lists of sockets and lists of sockets.", "response": "def poll(in_sockets, out_sockets, timeout=-1):\n    \"\"\"\n    Poll a list of sockets\n    :param in_sockets: sockets for reading\n    :param out_sockets: sockets for writing\n    :param timeout: poll timeout in seconds, -1 is infinite wait\n    :return: tuple (read socket list, write socket list)\n    \"\"\"\n    sockets = {}\n    # reverse map fd => socket\n    fd_sockets = {}\n    for s in in_sockets:\n        sockets[s.fd] = POLLIN\n        fd_sockets[s.fd] = s\n    for s in out_sockets:\n        modes = sockets.get(s.fd, 0)\n        sockets[s.fd] = modes | POLLOUT\n        fd_sockets[s.fd] = s\n\n    # convert to milliseconds or -1\n    if timeout >= 0:\n        timeout_ms = int(timeout*1000)\n    else:\n        timeout_ms = -1\n    res, sockets = wrapper.nn_poll(sockets, timeout_ms)\n    _nn_check_positive_rtn(res)\n    read_list, write_list = [], []\n    for fd, result in sockets.items():\n        if (result & POLLIN) != 0:\n            read_list.append(fd_sockets[fd])\n        if (result & POLLOUT) != 0:\n            write_list.append(fd_sockets[fd])\n\n    return read_list, write_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbind a local endpoint to the socket.", "response": "def bind(self, address):\n        \"\"\"Add a local endpoint to the socket\"\"\"\n        if self.uses_nanoconfig:\n            raise ValueError(\"Nanoconfig address must be sole endpoint\")\n        endpoint_id = _nn_check_positive_rtn(\n            wrapper.nn_bind(self._fd, address)\n        )\n        ep = Socket.BindEndpoint(self, endpoint_id, address)\n        self._endpoints.append(ep)\n        return ep"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a remote endpoint to the socket", "response": "def connect(self, address):\n        \"\"\"Add a remote endpoint to the socket\"\"\"\n        if self.uses_nanoconfig:\n            raise ValueError(\"Nanoconfig address must be sole endpoint\")\n        endpoint_id = _nn_check_positive_rtn(\n            wrapper.nn_connect(self.fd, address)\n        )\n        ep = Socket.ConnectEndpoint(self, endpoint_id, address)\n        self._endpoints.append(ep)\n        return ep"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconfigure socket s addresses with nanoconfig", "response": "def configure(self, address):\n        \"\"\"Configure socket's addresses with nanoconfig\"\"\"\n        global nanoconfig_started\n        if len(self._endpoints):\n            raise ValueError(\"Nanoconfig address must be sole endpoint\")\n        endpoint_id = _nn_check_positive_rtn(\n            wrapper.nc_configure(self.fd, address)\n        )\n        if not nanoconfig_started:\n            nanoconfig_started = True\n        ep = Socket.NanoconfigEndpoint(self, endpoint_id, address)\n        self._endpoints.append(ep)\n        return ep"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a message to the socket.", "response": "def send(self, msg, flags=0):\n        \"\"\"Send a message\"\"\"\n        _nn_check_positive_rtn(wrapper.nn_send(self.fd, msg, flags))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning to return a list of bounding boxes in data coordinates for a scatter plot", "response": "def get_bboxes_pathcollection(sc, ax):\n    \"\"\"Function to return a list of bounding boxes in data coordinates\n    for a scatter plot\n    Thank you to ImportanceOfBeingErnest\n    https://stackoverflow.com/a/55007838/1304161\"\"\"\n#    ax.figure.canvas.draw() # need to draw before the transforms are set.\n    transform = sc.get_transform()\n    transOffset = sc.get_offset_transform()\n    offsets = sc._offsets\n    paths = sc.get_paths()\n    transforms = sc.get_transforms()\n\n    if not transform.is_affine:\n        paths = [transform.transform_path_non_affine(p) for p in paths]\n        transform = transform.get_affine()\n    if not transOffset.is_affine:\n        offsets = transOffset.transform_non_affine(offsets)\n        transOffset = transOffset.get_affine()\n\n    if isinstance(offsets, np.ma.MaskedArray):\n        offsets = offsets.filled(np.nan)\n\n    bboxes = []\n\n    if len(paths) and len(offsets):\n        if len(paths) < len(offsets):\n            # for usual scatters you have one path, but several offsets\n            paths = [paths[0]]*len(offsets)\n        if len(transforms) < len(offsets):\n            # often you may have a single scatter size, but several offsets\n            transforms = [transforms[0]]*len(offsets)\n\n        for p, o, t in zip(paths, offsets, transforms):\n            result = get_path_collection_extents(\n                transform.frozen(), [p], [t],\n                [o], transOffset.frozen())\n            bboxes.append(result.inverse_transformed(ax.transData))\n\n    return bboxes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef overlap_bbox_and_point(bbox, xp, yp):\n    cx, cy = get_midpoint(bbox)\n\n    dir_x = np.sign(cx-xp)\n    dir_y = np.sign(cy-yp)\n\n    if dir_x == -1:\n        dx = xp - bbox.xmax\n    elif dir_x == 1:\n        dx = xp - bbox.xmin\n    else:\n        dx = 0\n\n    if dir_y == -1:\n        dy = yp - bbox.ymax\n    elif dir_y == 1:\n        dy = yp - bbox.ymin\n    else:\n        dy = 0\n    return dx, dy", "response": "Given a bounding box and a point return the x y displacement\n    necessary to make the bbox not overlap the point."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef optimally_align_text(x, y, texts, expand=(1., 1.), add_bboxes=[],\n                         renderer=None, ax=None,\n                         direction='xy'):\n    \"\"\"\n    For all text objects find alignment that causes the least overlap with\n    points and other texts and apply it\n    \"\"\"\n    if ax is None:\n        ax = plt.gca()\n    if renderer is None:\n        r = get_renderer(ax.get_figure())\n    else:\n        r = renderer\n    xmin, xmax = sorted(ax.get_xlim())\n    ymin, ymax = sorted(ax.get_ylim())\n    bboxes = get_bboxes(texts, r, expand, ax=ax)\n    if 'x' not in direction:\n        ha = ['']\n    else:\n        ha = ['left', 'right', 'center']\n    if 'y' not in direction:\n        va = ['']\n    else:\n        va = ['bottom', 'top', 'center']\n    alignment = list(product(ha, va))\n#    coords = np.array(zip(x, y))\n    for i, text in enumerate(texts):\n#        tcoords = np.array(text.get_position()).T\n#        nonself_coords = coords[~np.all(coords==tcoords, axis=1)]\n#        nonself_x, nonself_y = np.split(nonself_coords, 2, axis=1)\n        counts = []\n        for h, v in alignment:\n            if h:\n                text.set_ha(h)\n            if v:\n                text.set_va(v)\n            bbox = text.get_window_extent(r).expanded(*expand).\\\n                                       transformed(ax.transData.inverted())\n            c = len(get_points_inside_bbox(x, y, bbox))\n            intersections = [bbox.intersection(bbox, bbox2) if i!=j else None\n                             for j, bbox2 in enumerate(bboxes+add_bboxes) ]\n            intersections = sum([abs(b.width*b.height) if b is not None else 0\n                                 for b in intersections])\n            # Check for out-of-axes position\n            bbox = text.get_window_extent(r).transformed(ax.transData.inverted())\n            x1, y1, x2, y2 = bbox.xmin, bbox.ymin, bbox.xmax, bbox.ymax\n            if x1 < xmin or x2 > xmax or y1 < ymin or y2 > ymax:\n                axout = 1\n            else:\n                axout = 0\n            counts.append((axout, c, intersections))\n        # Most important: prefer alignments that keep the text inside the axes.\n        # If tied, take the alignments that minimize the number of x, y points\n        # contained inside the text.\n        # Break any remaining ties by minimizing the total area of intersections\n        # with all text bboxes and other objects to avoid.\n        a, value = min(enumerate(counts), key=itemgetter(1))\n        if 'x' in direction:\n            text.set_ha(alignment[a][0])\n        if 'y' in direction:\n            text.set_va(alignment[a][1])\n        bboxes[i] = text.get_window_extent(r).expanded(*expand).\\\n                                       transformed(ax.transData.inverted())\n    return texts", "response": "Optimizes text objects with the least overlap with other texts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef repel_text(texts, renderer=None, ax=None, expand=(1.2, 1.2),\n               only_use_max_min=False, move=False):\n    \"\"\"\n    Repel texts from each other while expanding their bounding boxes by expand\n    (x, y), e.g. (1.2, 1.2) would multiply width and height by 1.2.\n    Requires a renderer to get the actual sizes of the text, and to that end\n    either one needs to be directly provided, or the axes have to be specified,\n    and the renderer is then got from the axes object.\n    \"\"\"\n    if ax is None:\n        ax = plt.gca()\n    if renderer is None:\n        r = get_renderer(ax.get_figure())\n    else:\n        r = renderer\n    bboxes = get_bboxes(texts, r, expand, ax=ax)\n    xmins = [bbox.xmin for bbox in bboxes]\n    xmaxs = [bbox.xmax for bbox in bboxes]\n    ymaxs = [bbox.ymax for bbox in bboxes]\n    ymins = [bbox.ymin for bbox in bboxes]\n\n    overlaps_x = np.zeros((len(bboxes), len(bboxes)))\n    overlaps_y = np.zeros_like(overlaps_x)\n    overlap_directions_x = np.zeros_like(overlaps_x)\n    overlap_directions_y = np.zeros_like(overlaps_y)\n    for i, bbox1 in enumerate(bboxes):\n        overlaps = get_points_inside_bbox(xmins*2+xmaxs*2, (ymins+ymaxs)*2,\n                                             bbox1) % len(bboxes)\n        overlaps = np.unique(overlaps)\n        for j in overlaps:\n            bbox2 = bboxes[j]\n            x, y = bbox1.intersection(bbox1, bbox2).size\n            overlaps_x[i, j] = x\n            overlaps_y[i, j] = y\n            direction = np.sign(bbox1.extents - bbox2.extents)[:2]\n            overlap_directions_x[i, j] = direction[0]\n            overlap_directions_y[i, j] = direction[1]\n\n    move_x = overlaps_x*overlap_directions_x\n    move_y = overlaps_y*overlap_directions_y\n\n    delta_x = move_x.sum(axis=1)\n    delta_y = move_y.sum(axis=1)\n\n    q = np.sum(overlaps_x), np.sum(overlaps_y)\n    if move:\n        move_texts(texts, delta_x, delta_y, bboxes, ax=ax)\n    return delta_x, delta_y, q", "response": "Repel texts from each other while expanding their bounding boxes by expand."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrepel texts from other objects' bboxes while expanding their (texts') bounding boxes by expand (x, y), e.g. (1.2, 1.2) would multiply width and height by 1.2. Requires a renderer to get the actual sizes of the text, and to that end either one needs to be directly provided, or the axes have to be specified, and the renderer is then got from the axes object.", "response": "def repel_text_from_bboxes(add_bboxes, texts, renderer=None, ax=None,\n                           expand=(1.2, 1.2), only_use_max_min=False,\n                           move=False):\n    \"\"\"\n    Repel texts from other objects' bboxes while expanding their (texts')\n    bounding boxes by expand (x, y), e.g. (1.2, 1.2) would multiply width and\n    height by 1.2.\n    Requires a renderer to get the actual sizes of the text, and to that end\n    either one needs to be directly provided, or the axes have to be specified,\n    and the renderer is then got from the axes object.\n    \"\"\"\n    if ax is None:\n        ax = plt.gca()\n    if renderer is None:\n        r = get_renderer(ax.get_figure())\n    else:\n        r = renderer\n\n    bboxes = get_bboxes(texts, r, expand, ax=ax)\n\n    overlaps_x = np.zeros((len(bboxes), len(add_bboxes)))\n    overlaps_y = np.zeros_like(overlaps_x)\n    overlap_directions_x = np.zeros_like(overlaps_x)\n    overlap_directions_y = np.zeros_like(overlaps_y)\n\n    for i, bbox1 in enumerate(bboxes):\n        for j, bbox2 in enumerate(add_bboxes):\n            try:\n                x, y = bbox1.intersection(bbox1, bbox2).size\n                direction = np.sign(bbox1.extents - bbox2.extents)[:2]\n                overlaps_x[i, j] = x\n                overlaps_y[i, j] = y\n                overlap_directions_x[i, j] = direction[0]\n                overlap_directions_y[i, j] = direction[1]\n            except AttributeError:\n                pass\n\n    move_x = overlaps_x*overlap_directions_x\n    move_y = overlaps_y*overlap_directions_y\n\n    delta_x = move_x.sum(axis=1)\n    delta_y = move_y.sum(axis=1)\n\n    q = np.sum(overlaps_x), np.sum(overlaps_y)\n    if move:\n        move_texts(texts, delta_x, delta_y, bboxes, ax=ax)\n    return delta_x, delta_y, q"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrepelling texts from all points specified by x and y.", "response": "def repel_text_from_points(x, y, texts, renderer=None, ax=None,\n                           expand=(1.2, 1.2), move=False):\n    \"\"\"\n    Repel texts from all points specified by x and y while expanding their\n    (texts'!) bounding boxes by expandby  (x, y), e.g. (1.2, 1.2)\n    would multiply both width and height by 1.2.\n    Requires a renderer to get the actual sizes of the text, and to that end\n    either one needs to be directly provided, or the axes have to be specified,\n    and the renderer is then got from the axes object.\n    \"\"\"\n    assert len(x) == len(y)\n    if ax is None:\n        ax = plt.gca()\n    if renderer is None:\n        r = get_renderer(ax.get_figure())\n    else:\n        r = renderer\n    bboxes = get_bboxes(texts, r, expand, ax=ax)\n\n    # move_x[i,j] is the x displacement of the i'th text caused by the j'th point\n    move_x = np.zeros((len(bboxes), len(x)))\n    move_y = np.zeros((len(bboxes), len(x)))\n    for i, bbox in enumerate(bboxes):\n        xy_in = get_points_inside_bbox(x, y, bbox)\n        for j in xy_in:\n            xp, yp = x[j], y[j]\n            dx, dy = overlap_bbox_and_point(bbox, xp, yp)\n\n            move_x[i, j] = dx\n            move_y[i, j] = dy\n\n    delta_x = move_x.sum(axis=1)\n    delta_y = move_y.sum(axis=1)\n    q = np.sum(np.abs(move_x)), np.sum(np.abs(move_y))\n    if move:\n        move_texts(texts, delta_x, delta_y, bboxes, ax=ax)\n    return delta_x, delta_y, q"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bounter(size_mb=None, need_iteration=True, need_counts=True, log_counting=None):\n    if not need_counts:\n        return CardinalityEstimator()\n    if size_mb is None:\n        raise ValueError(\"Max size in MB must be provided.\")\n    if need_iteration:\n        if log_counting:\n            raise ValueError(\"Log counting is only supported with CMS implementation (need_iteration=False).\")\n        return HashTable(size_mb=size_mb)\n    else:\n        return CountMinSketch(size_mb=size_mb, log_counting=log_counting)", "response": "Factory method for bounter implementation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the Authorize URL as returned by QB and specified by OAuth 1. 0a.", "response": "def get_authorize_url(self, callback_url):\n        \"\"\"\n        Returns the Authorize URL as returned by QB, and specified by OAuth 1.0a.\n        :return URI:\n        \"\"\"\n        self.authorize_url = self.authorize_url[:self.authorize_url.find('?')] \\\n            if '?' in self.authorize_url else self.authorize_url\n\n        qb_service = OAuth1Service(\n            consumer_key=self.consumer_key,\n            consumer_secret=self.consumer_secret,\n            request_token_url=self.request_token_url,\n            access_token_url=self.access_token_url,\n            authorize_url=self.authorize_url,\n        )\n\n        response = qb_service.get_raw_request_token(\n            params={'oauth_callback': callback_url})\n\n        oauth_resp = dict(parse_qsl(response.text))\n\n        self.request_token = oauth_resp['oauth_token']\n        self.request_token_secret = oauth_resp['oauth_token_secret']\n\n        return qb_service.get_authorize_url(self.request_token)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_access_tokens(self, oauth_verifier):\n        qb_service = OAuth1Service(\n            consumer_key=self.consumer_key,\n            consumer_secret=self.consumer_secret,\n            request_token_url=self.request_token_url,\n            access_token_url=self.access_token_url,\n            authorize_url=self.authorize_url,\n        )\n\n        session = qb_service.get_auth_session(\n            self.request_token,\n            self.request_token_secret,\n            data={'oauth_verifier': oauth_verifier})\n\n        self.access_token = session.access_token\n        self.access_token_secret = session.access_token_secret\n        return session", "response": "Wrapper around get_auth_session and sets access_token and access_token_secret on the QB Object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_authorize_url(self, callback_url, state=None):\n        auth_service = OAuth2Service(\n            name='quickbooks',\n            client_id=self.client_id,\n            client_secret=self.client_secret,\n            authorize_url=self.authorize_url,\n            access_token_url=self.access_token_url,\n            base_url=self.base_url,\n        )\n\n        params = {\n            'client_id': self.client_id,\n            'response_type': 'code',\n            'scope': 'com.intuit.quickbooks.accounting',\n            'redirect_uri': callback_url,\n            'state': state,\n        }\n\n        url = auth_service.get_authorize_url(**params)\n\n        return url", "response": "Returns the Authorize URL as returned by QB and specified by OAuth 2. 0a."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef json_filter(self):\n        return lambda obj: dict((k, v) for k, v in obj.__dict__.items()\n                                if not k.startswith('_') and getattr(obj, k) is not None)", "response": "Return a function that filters out properties that have a value of None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of all the nagios metadata.", "response": "def all(cls, start_position=\"\", max_results=100, qb=None):\n        \"\"\"\n        :param start_position:\n        :param max_results: The max number of entities that can be returned in a response is 1000.\n        :param qb:\n        :return: Returns list\n        \"\"\"\n        return cls.where(\"\", start_position=start_position, max_results=max_results, qb=qb)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filter(cls, start_position=\"\", max_results=\"\", qb=None, **kwargs):\n        return cls.where(build_where_clause(**kwargs),\n                         start_position=start_position, max_results=max_results, qb=qb)", "response": "Returns a new list of the items in the current queryset with the given start and max results."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef choose(cls, choices, field=\"Id\", qb=None):\n        return cls.where(build_choose_clause(choices, field), qb=qb)", "response": "Returns a new queryset with the given field and choices."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns list of all the entries in the database that match the given where clause.", "response": "def where(cls, where_clause=\"\", start_position=\"\", max_results=\"\", qb=None):\n        \"\"\"\n        :param where_clause: QBO SQL where clause (DO NOT include 'WHERE')\n        :param start_position:\n        :param max_results:\n        :param qb:\n        :return: Returns list filtered by input where_clause\n        \"\"\"\n        if where_clause:\n            where_clause = \"WHERE \" + where_clause\n\n        if start_position:\n            start_position = \" STARTPOSITION \" + str(start_position)\n\n        if max_results:\n            max_results = \" MAXRESULTS \" + str(max_results)\n\n        select = \"SELECT * FROM {0} {1}{2}{3}\".format(\n            cls.qbo_object_name, where_clause, start_position, max_results)\n\n        return cls.query(select, qb=qb)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef query(cls, select, qb=None):\n        if not qb:\n            qb = QuickBooks()\n\n        json_data = qb.query(select)\n\n        obj_list = []\n\n        if cls.qbo_object_name in json_data[\"QueryResponse\"]:\n            for item_json in json_data[\"QueryResponse\"][cls.qbo_object_name]:\n                obj_list.append(cls.from_json(item_json))\n\n        return obj_list", "response": "Query QuickBooks object by name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef count(cls, where_clause=\"\", qb=None):\n        if not qb:\n            qb = QuickBooks()\n\n        if where_clause:\n            where_clause = \"WHERE \" + where_clause\n\n        select = \"SELECT COUNT(*) FROM {0} {1}\".format(\n            cls.qbo_object_name, where_clause)\n\n        json_data = qb.query(select)\n\n        if \"totalCount\" in json_data[\"QueryResponse\"]:\n            return json_data[\"QueryResponse\"][\"totalCount\"]\n        else:\n            return None", "response": "Returns the number of records in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_current_user(self):\n        url = self.current_user_url\n        result = self.get(url)\n        return result", "response": "Get data from the current user endpoint"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget data from the report endpoint", "response": "def get_report(self, report_type, qs=None):\n        \"\"\"Get data from the report endpoint\"\"\"\n        if qs is None:\n            qs = {}\n\n        url = self.api_url + \"/company/{0}/reports/{1}\".format(self.company_id, report_type)\n        result = self.get(url, params=qs)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef disconnect_account(self):\n        url = self.disconnect_url\n        result = self.get(url)\n        return result", "response": "Disconnect current account from the application"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the current account s reconnection token.", "response": "def reconnect_account(self):\n        \"\"\"\n        Reconnect current account by refreshing OAuth access tokens\n        :return:\n        \"\"\"\n        url = self.reconnect_url\n        result = self.get(url)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _meters_per_pixel(zoom, lat=0.0, tilesize=256):\n    return (math.cos(lat * math.pi / 180.0) * 2 * math.pi * 6378137) / (\n        tilesize * 2 ** zoom\n    )", "response": "Returns the pixel resolution for a given mercator tile zoom and lattitude."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef zoom_for_pixelsize(pixel_size, max_z=24, tilesize=256):\n    for z in range(max_z):\n        if pixel_size > _meters_per_pixel(z, 0, tilesize=tilesize):\n            return max(0, z - 1)  # We don't want to scale up\n\n    return max_z - 1", "response": "Returns the mercator zoom level corresponding to a pixel size."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_zooms(src_dst, ensure_global_max_zoom=False, tilesize=256):\n    bounds = transform_bounds(\n        *[src_dst.crs, \"epsg:4326\"] + list(src_dst.bounds), densify_pts=21\n    )\n    center = [(bounds[0] + bounds[2]) / 2, (bounds[1] + bounds[3]) / 2]\n    lat = center[1] if ensure_global_max_zoom else 0\n\n    dst_affine, w, h = calculate_default_transform(\n        src_dst.crs, \"epsg:3857\", src_dst.width, src_dst.height, *src_dst.bounds\n    )\n\n    mercator_resolution = max(abs(dst_affine[0]), abs(dst_affine[4]))\n\n    # Correction factor for web-mercator projection latitude scale change\n    latitude_correction_factor = math.cos(math.radians(lat))\n    adjusted_resolution = mercator_resolution * latitude_correction_factor\n\n    max_zoom = zoom_for_pixelsize(adjusted_resolution, tilesize=tilesize)\n\n    ovr_resolution = adjusted_resolution * max(h, w) / tilesize\n    min_zoom = zoom_for_pixelsize(ovr_resolution, tilesize=tilesize)\n\n    return (min_zoom, max_zoom)", "response": "Calculate min max mercator zoom levels."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bounds(address):\n    with rasterio.open(address) as src:\n        wgs_bounds = transform_bounds(\n            *[src.crs, \"epsg:4326\"] + list(src.bounds), densify_pts=21\n        )\n\n    return {\"url\": address, \"bounds\": list(wgs_bounds)}", "response": "Retrieve image bounds.\n\n    Attributes\n    ----------\n    address : str\n        file url.\n\n    Returns\n    -------\n    out : dict\n        dictionary with image bounds."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef metadata(address, pmin=2, pmax=98, **kwargs):\n    info = {\"address\": address}\n    info.update(utils.raster_get_stats(address, percentiles=(pmin, pmax), **kwargs))\n    return info", "response": "Return image bounds and band statistics."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tile(address, tile_x, tile_y, tile_z, tilesize=256, **kwargs):\n    with rasterio.open(address) as src:\n        wgs_bounds = transform_bounds(\n            *[src.crs, \"epsg:4326\"] + list(src.bounds), densify_pts=21\n        )\n\n        if not utils.tile_exists(wgs_bounds, tile_z, tile_x, tile_y):\n            raise TileOutsideBounds(\n                \"Tile {}/{}/{} is outside image bounds\".format(tile_z, tile_x, tile_y)\n            )\n\n        mercator_tile = mercantile.Tile(x=tile_x, y=tile_y, z=tile_z)\n        tile_bounds = mercantile.xy_bounds(mercator_tile)\n        return utils.tile_read(src, tile_bounds, tilesize, **kwargs)", "response": "Create mercator tile from any images."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _stats(arr, percentiles=(2, 98), **kwargs):\n    sample, edges = np.histogram(arr[~arr.mask], **kwargs)\n    return {\n        \"pc\": np.percentile(arr[~arr.mask], percentiles).astype(arr.dtype).tolist(),\n        \"min\": arr.min().item(),\n        \"max\": arr.max().item(),\n        \"std\": arr.std().item(),\n        \"histogram\": [sample.tolist(), edges.tolist()],\n    }", "response": "Calculate array statistics.\n\n    Attributes\n    ----------\n    arr: numpy ndarray\n        Input array data to get the stats from.\n    percentiles: tuple, optional\n        Tuple of Min/Max percentiles to compute.\n    kwargs: dict, optional\n        These will be passed to the numpy.histogram function.\n\n    Returns\n    -------\n    dict\n        numpy array statistics: percentiles, min, max, stdev, histogram\n\n        e.g.\n        {\n            'pc': [38, 147],\n            'min': 20,\n            'max': 180,\n            'std': 28.123562304138662,\n            'histogram': [\n                [1625, 219241, 28344, 15808, 12325, 10687, 8535, 7348, 4656, 1208],\n                [20.0, 36.0, 52.0, 68.0, 84.0, 100.0, 116.0, 132.0, 148.0, 164.0, 180.0]\n            ]\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef raster_get_stats(\n    src_path,\n    indexes=None,\n    nodata=None,\n    overview_level=None,\n    max_size=1024,\n    percentiles=(2, 98),\n    dst_crs=CRS({\"init\": \"EPSG:4326\"}),\n    histogram_bins=10,\n    histogram_range=None,\n):\n    \"\"\"\n    Retrieve dataset statistics.\n\n    Attributes\n    ----------\n    src_path : str or PathLike object\n        A dataset path or URL. Will be opened in \"r\" mode.\n    indexes : tuple, list, int, optional\n        Dataset band indexes.\n    nodata, int, optional\n        Custom nodata value if not preset in dataset.\n    overview_level : int, optional\n        Overview (decimation) level to fetch.\n    max_size: int, optional\n        Maximum size of dataset to retrieve\n        (will be used to calculate the overview level to fetch).\n    percentiles : tulple, optional\n        Percentile or sequence of percentiles to compute,\n        which must be between 0 and 100 inclusive (default: (2, 98)).\n    dst_crs: CRS or dict\n        Target coordinate reference system (default: EPSG:4326).\n    histogram_bins: int, optional\n        Defines the number of equal-width histogram bins (default: 10).\n    histogram_range: tuple or list, optional\n        The lower and upper range of the bins. If not provided, range is simply\n        the min and max of the array.\n\n    Returns\n    -------\n    out : dict\n        bounds, mercator zoom range, band descriptions\n        and band statistics: (percentiles), min, max, stdev, histogram\n\n        e.g.\n        {\n            'bounds': {\n                'value': (145.72265625, 14.853515625, 145.810546875, 14.94140625),\n                'crs': '+init=EPSG:4326'\n            },\n            'minzoom': 8,\n            'maxzoom': 12,\n            'band_descriptions': [(1, 'red'), (2, 'green'), (3, 'blue'), (4, 'nir')]\n            'statistics': {\n                1: {\n                    'pc': [38, 147],\n                    'min': 20,\n                    'max': 180,\n                    'std': 28.123562304138662,\n                    'histogram': [\n                        [1625, 219241, 28344, 15808, 12325, 10687, 8535, 7348, 4656, 1208],\n                        [20.0, 36.0, 52.0, 68.0, 84.0, 100.0, 116.0, 132.0, 148.0, 164.0, 180.0]\n                    ]\n                }\n                ...\n                3: {...}\n                4: {...}\n            }\n        }\n    \"\"\"\n    if isinstance(indexes, int):\n        indexes = [indexes]\n    elif isinstance(indexes, tuple):\n        indexes = list(indexes)\n\n    with rasterio.open(src_path) as src_dst:\n        levels = src_dst.overviews(1)\n        width = src_dst.width\n        height = src_dst.height\n        indexes = indexes if indexes else src_dst.indexes\n        nodata = nodata if nodata is not None else src_dst.nodata\n        bounds = transform_bounds(\n            *[src_dst.crs, dst_crs] + list(src_dst.bounds), densify_pts=21\n        )\n\n        minzoom, maxzoom = get_zooms(src_dst)\n\n        def _get_descr(ix):\n            \"\"\"Return band description.\"\"\"\n            name = src_dst.descriptions[ix - 1]\n            if not name:\n                name = \"band{}\".format(ix)\n            return name\n\n        band_descriptions = [(ix, _get_descr(ix)) for ix in indexes]\n\n        if len(levels):\n            if overview_level:\n                decim = levels[overview_level]\n            else:\n                # determine which zoom level to read\n                for ii, decim in enumerate(levels):\n                    if max(width // decim, height // decim) < max_size:\n                        break\n        else:\n            decim = 1\n            warnings.warn(\n                \"Dataset has no overviews, reading the full dataset\", NoOverviewWarning\n            )\n\n        out_shape = (len(indexes), height // decim, width // decim)\n\n        vrt_params = dict(add_alpha=True, resampling=Resampling.bilinear)\n        if has_alpha_band(src_dst):\n            vrt_params.update(dict(add_alpha=False))\n\n        if nodata is not None:\n            vrt_params.update(dict(nodata=nodata, add_alpha=False, src_nodata=nodata))\n\n        with WarpedVRT(src_dst, **vrt_params) as vrt:\n            arr = vrt.read(out_shape=out_shape, indexes=indexes, masked=True)\n\n            params = {}\n            if histogram_bins:\n                params.update(dict(bins=histogram_bins))\n            if histogram_range:\n                params.update(dict(range=histogram_range))\n\n            stats = {\n                indexes[b]: _stats(arr[b], percentiles=percentiles, **params)\n                for b in range(arr.shape[0])\n                if vrt.colorinterp[b] != ColorInterp.alpha\n            }\n\n    return {\n        \"bounds\": {\n            \"value\": bounds,\n            \"crs\": dst_crs.to_string() if isinstance(dst_crs, CRS) else dst_crs,\n        },\n        \"minzoom\": minzoom,\n        \"maxzoom\": maxzoom,\n        \"band_descriptions\": band_descriptions,\n        \"statistics\": stats,\n    }", "response": "This function returns the attributes of the object holding statistics for the specified raster dataset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_vrt_transform(src_dst, bounds, bounds_crs=\"epsg:3857\"):\n    dst_transform, _, _ = calculate_default_transform(\n        src_dst.crs, bounds_crs, src_dst.width, src_dst.height, *src_dst.bounds\n    )\n    w, s, e, n = bounds\n    vrt_width = math.ceil((e - w) / dst_transform.a)\n    vrt_height = math.ceil((s - n) / dst_transform.e)\n\n    vrt_transform = transform.from_bounds(w, s, e, n, vrt_width, vrt_height)\n\n    return vrt_transform, vrt_width, vrt_height", "response": "Calculate VRT transform.\n\n    Attributes\n    ----------\n    src_dst : rasterio.io.DatasetReader\n        Rasterio io.DatasetReader object\n    bounds : list\n        Bounds (left, bottom, right, top)\n    bounds_crs : str\n        Coordinate reference system string (default \"epsg:3857\")\n\n    Returns\n    -------\n    vrt_transform: Affine\n        Output affine transformation matrix\n    vrt_width, vrt_height: int\n        Output dimensions"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef has_alpha_band(src_dst):\n    if (\n        any([MaskFlags.alpha in flags for flags in src_dst.mask_flag_enums])\n        or ColorInterp.alpha in src_dst.colorinterp\n    ):\n        return True\n    return False", "response": "Check if alpha band or mask in source."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread data and mask from a single image.", "response": "def _tile_read(\n    src_dst, bounds, tilesize, indexes=None, nodata=None, resampling_method=\"bilinear\"\n):\n    \"\"\"\n    Read data and mask.\n\n    Attributes\n    ----------\n    src_dst : rasterio.io.DatasetReader\n        rasterio.io.DatasetReader object\n    bounds : list\n        Mercator tile bounds (left, bottom, right, top)\n    tilesize : int\n        Output image size\n    indexes : list of ints or a single int, optional, (defaults: None)\n        If `indexes` is a list, the result is a 3D array, but is\n        a 2D array if it is a band index number.\n    nodata: int or float, optional (defaults: None)\n    resampling_method : str, optional (default: \"bilinear\")\n         Resampling algorithm\n\n    Returns\n    -------\n    out : array, int\n        returns pixel value.\n\n    \"\"\"\n    if isinstance(indexes, int):\n        indexes = [indexes]\n    elif isinstance(indexes, tuple):\n        indexes = list(indexes)\n\n    vrt_params = dict(\n        add_alpha=True, crs=\"epsg:3857\", resampling=Resampling[resampling_method]\n    )\n\n    vrt_transform, vrt_width, vrt_height = get_vrt_transform(src_dst, bounds)\n    vrt_params.update(dict(transform=vrt_transform, width=vrt_width, height=vrt_height))\n\n    indexes = indexes if indexes is not None else src_dst.indexes\n    out_shape = (len(indexes), tilesize, tilesize)\n\n    nodata = nodata if nodata is not None else src_dst.nodata\n    if nodata is not None:\n        vrt_params.update(dict(nodata=nodata, add_alpha=False, src_nodata=nodata))\n\n    if has_alpha_band(src_dst):\n        vrt_params.update(dict(add_alpha=False))\n\n    with WarpedVRT(src_dst, **vrt_params) as vrt:\n        data = vrt.read(\n            out_shape=out_shape,\n            indexes=indexes,\n            resampling=Resampling[resampling_method],\n        )\n        mask = vrt.dataset_mask(out_shape=(tilesize, tilesize))\n\n        return data, mask"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads data and mask from a dataset reader.", "response": "def tile_read(source, bounds, tilesize, **kwargs):\n    \"\"\"\n    Read data and mask.\n\n    Attributes\n    ----------\n    source : str or rasterio.io.DatasetReader\n        input file path or rasterio.io.DatasetReader object\n    bounds : list\n        Mercator tile bounds (left, bottom, right, top)\n    tilesize : int\n        Output image size\n    kwargs: dict, optional\n        These will be passed to the _tile_read function.\n\n    Returns\n    -------\n    out : array, int\n        returns pixel value.\n\n    \"\"\"\n    if isinstance(source, DatasetReader):\n        return _tile_read(source, bounds, tilesize, **kwargs)\n    else:\n        with rasterio.open(source) as src_dst:\n            return _tile_read(src_dst, bounds, tilesize, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef linear_rescale(image, in_range=(0, 1), out_range=(1, 255)):\n    imin, imax = in_range\n    omin, omax = out_range\n    image = np.clip(image, imin, imax) - imin\n    image = image / np.float(imax - imin)\n    return image * (omax - omin) + omin", "response": "Linear rescaling.\n\n    Attributes\n    ----------\n    image : numpy ndarray\n        Image array to rescale.\n    in_range : list, int, optional, (default: [0,1])\n        Image min/max value to rescale.\n    out_range : list, int, optional, (default: [1,255])\n        output min/max bounds to rescale to.\n\n    Returns\n    -------\n    out : numpy ndarray\n        returns rescaled image array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tile_exists(bounds, tile_z, tile_x, tile_y):\n    mintile = mercantile.tile(bounds[0], bounds[3], tile_z)\n    maxtile = mercantile.tile(bounds[2], bounds[1], tile_z)\n\n    return (\n        (tile_x <= maxtile.x + 1)\n        and (tile_x >= mintile.x)\n        and (tile_y <= maxtile.y + 1)\n        and (tile_y >= mintile.y)\n    )", "response": "Check if a mercantile tile is inside a given bounds."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying discrete colormap. Attributes ---------- arr : numpy.ndarray 1D image array to convert. color_map: dict Discrete ColorMap dictionary e.g: { 1: [255, 255, 255], 2: [255, 0, 0] } Returns ------- arr: numpy.ndarray", "response": "def _apply_discrete_colormap(arr, cmap):\n    \"\"\"\n    Apply discrete colormap.\n\n    Attributes\n    ----------\n    arr : numpy.ndarray\n        1D image array to convert.\n    color_map: dict\n        Discrete ColorMap dictionary\n        e.g:\n        {\n            1: [255, 255, 255],\n            2: [255, 0, 0]\n        }\n\n    Returns\n    -------\n    arr: numpy.ndarray\n\n    \"\"\"\n    res = np.zeros((arr.shape[1], arr.shape[2], 3), dtype=np.uint8)\n    for k, v in cmap.items():\n        res[arr[0] == k] = v\n    return np.transpose(res, [2, 0, 1])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef array_to_image(\n    arr, mask=None, img_format=\"png\", color_map=None, **creation_options\n):\n    \"\"\"\n    Translate numpy ndarray to image buffer using GDAL.\n\n    Usage\n    -----\n    tile, mask = rio_tiler.utils.tile_read(......)\n    with open('test.jpg', 'wb') as f:\n        f.write(array_to_image(tile, mask, img_format=\"jpeg\"))\n\n    Attributes\n    ----------\n    arr : numpy ndarray\n        Image array to encode.\n    mask: numpy ndarray, optional\n        Mask array\n    img_format: str, optional\n        Image format to return (default: 'png').\n        List of supported format by GDAL: https://www.gdal.org/formats_list.html\n    color_map: numpy.ndarray or dict, optional\n        color_map can be either a (256, 3) array or RGB triplet\n        (e.g. [[255, 255, 255],...]) mapping each 1D pixel value rescaled\n        from 0 to 255\n        OR\n        it can be a dictionary of discrete values\n        (e.g. { 1.3: [255, 255, 255], 2.5: [255, 0, 0]}) mapping any pixel value to a triplet\n    creation_options: dict, optional\n        Image driver creation options to pass to GDAL\n\n    Returns\n    -------\n    bytes\n\n    \"\"\"\n    img_format = img_format.lower()\n\n    if len(arr.shape) < 3:\n        arr = np.expand_dims(arr, axis=0)\n\n    if color_map is not None and isinstance(color_map, dict):\n        arr = _apply_discrete_colormap(arr, color_map)\n    elif color_map is not None:\n        arr = np.transpose(color_map[arr][0], [2, 0, 1]).astype(np.uint8)\n\n    # WEBP doesn't support 1band dataset so we must hack to create a RGB dataset\n    if img_format == \"webp\" and arr.shape[0] == 1:\n        arr = np.repeat(arr, 3, axis=0)\n\n    if mask is not None and img_format != \"jpeg\":\n        nbands = arr.shape[0] + 1\n    else:\n        nbands = arr.shape[0]\n\n    output_profile = dict(\n        driver=img_format,\n        dtype=arr.dtype,\n        count=nbands,\n        height=arr.shape[1],\n        width=arr.shape[2],\n    )\n    output_profile.update(creation_options)\n\n    with MemoryFile() as memfile:\n        with memfile.open(**output_profile) as dst:\n            dst.write(arr, indexes=list(range(1, arr.shape[0] + 1)))\n\n            # Use Mask as an alpha band\n            if mask is not None and img_format != \"jpeg\":\n                dst.write(mask.astype(arr.dtype), indexes=nbands)\n\n        return memfile.read()", "response": "Translate numpy ndarray to image buffer using GDAL."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_colormap(name=\"cfastie\", format=\"pil\"):\n    cmap_file = os.path.join(os.path.dirname(__file__), \"cmap\", \"{0}.txt\".format(name))\n    with open(cmap_file) as cmap:\n        lines = cmap.read().splitlines()\n        colormap = [\n            list(map(int, line.split())) for line in lines if not line.startswith(\"#\")\n        ][1:]\n\n    cmap = list(np.array(colormap).flatten())\n    if format.lower() == \"pil\":\n        return cmap\n    elif format.lower() == \"gdal\":\n        return np.array(list(_chunks(cmap, 3)))\n    else:\n        raise Exception(\"Unsupported {} colormap format\".format(format))", "response": "Returns a Pillow or GDAL compatible colormap array."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nencode elevation value to RGB values compatible with Mapzen tangram.", "response": "def mapzen_elevation_rgb(arr):\n    \"\"\"\n    Encode elevation value to RGB values compatible with Mapzen tangram.\n\n    Attributes\n    ----------\n    arr : numpy ndarray\n        Image array to encode.\n\n    Returns\n    -------\n    out : numpy ndarray\n        RGB array (3, h, w)\n\n    \"\"\"\n    arr = np.clip(arr + 32768.0, 0.0, 65535.0)\n    r = arr / 256\n    g = arr % 256\n    b = (arr * 256) % 256\n    return np.stack([r, g, b]).astype(np.uint8)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction to apply expression on data.", "response": "def expression(sceneid, tile_x, tile_y, tile_z, expr=None, **kwargs):\n    \"\"\"\n    Apply expression on data.\n\n    Attributes\n    ----------\n    sceneid : str\n        Landsat id, Sentinel id, CBERS ids or file url.\n\n    tile_x : int\n        Mercator tile X index.\n    tile_y : int\n        Mercator tile Y index.\n    tile_z : int\n        Mercator tile ZOOM level.\n    expr : str, required\n        Expression to apply (e.g '(B5+B4)/(B5-B4)')\n        Band name should start with 'B'.\n\n    Returns\n    -------\n    out : ndarray\n        Returns processed pixel value.\n\n    \"\"\"\n    if not expr:\n        raise Exception(\"Missing expression\")\n\n    bands_names = tuple(set(re.findall(r\"b(?P<bands>[0-9A]{1,2})\", expr)))\n    rgb = expr.split(\",\")\n\n    if sceneid.startswith(\"L\"):\n        from rio_tiler.landsat8 import tile as l8_tile\n\n        arr, mask = l8_tile(\n            sceneid, tile_x, tile_y, tile_z, bands=bands_names, **kwargs\n        )\n    elif sceneid.startswith(\"S2\"):\n        from rio_tiler.sentinel2 import tile as s2_tile\n\n        arr, mask = s2_tile(\n            sceneid, tile_x, tile_y, tile_z, bands=bands_names, **kwargs\n        )\n    elif sceneid.startswith(\"CBERS\"):\n        from rio_tiler.cbers import tile as cbers_tile\n\n        arr, mask = cbers_tile(\n            sceneid, tile_x, tile_y, tile_z, bands=bands_names, **kwargs\n        )\n    else:\n        from rio_tiler.main import tile as main_tile\n\n        bands = tuple(map(int, bands_names))\n        arr, mask = main_tile(sceneid, tile_x, tile_y, tile_z, indexes=bands, **kwargs)\n\n    ctx = {}\n    for bdx, b in enumerate(bands_names):\n        ctx[\"b{}\".format(b)] = arr[bdx]\n\n    return (\n        np.array(\n            [np.nan_to_num(ne.evaluate(bloc.strip(), local_dict=ctx)) for bloc in rgb]\n        ),\n        mask,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing Sentinel - 2 scene id.", "response": "def _sentinel_parse_scene_id(sceneid):\n    \"\"\"Parse Sentinel-2 scene id.\n\n    Attributes\n    ----------\n    sceneid : str\n        Sentinel-2 sceneid.\n\n    Returns\n    -------\n    out : dict\n        dictionary with metadata constructed from the sceneid.\n\n        e.g:\n        _sentinel_parse_scene_id('S2A_tile_20170323_07SNC_0')\n        {\n            \"acquisitionDay\": \"23\",\n            \"acquisitionMonth\": \"03\",\n            \"acquisitionYear\": \"2017\",\n            \"key\": \"tiles/7/S/NC/2017/3/23/0\",\n            \"lat\": \"S\",\n            \"num\": \"0\",\n            \"satellite\": \"A\",\n            \"scene\": \"S2A_tile_20170323_07SNC_0\",\n            \"sensor\": \"2\",\n            \"sq\": \"NC\",\n            \"utm\": \"07\",\n        }\n\n    \"\"\"\n\n    if not re.match(\"^S2[AB]_tile_[0-9]{8}_[0-9]{2}[A-Z]{3}_[0-9]$\", sceneid):\n        raise InvalidSentinelSceneId(\"Could not match {}\".format(sceneid))\n\n    sentinel_pattern = (\n        r\"^S\"\n        r\"(?P<sensor>\\w{1})\"\n        r\"(?P<satellite>[AB]{1})\"\n        r\"_tile_\"\n        r\"(?P<acquisitionYear>[0-9]{4})\"\n        r\"(?P<acquisitionMonth>[0-9]{2})\"\n        r\"(?P<acquisitionDay>[0-9]{2})\"\n        r\"_\"\n        r\"(?P<utm>[0-9]{2})\"\n        r\"(?P<lat>\\w{1})\"\n        r\"(?P<sq>\\w{2})\"\n        r\"_\"\n        r\"(?P<num>[0-9]{1})$\"\n    )\n\n    meta = None\n    match = re.match(sentinel_pattern, sceneid, re.IGNORECASE)\n    if match:\n        meta = match.groupdict()\n\n    utm_zone = meta[\"utm\"].lstrip(\"0\")\n    grid_square = meta[\"sq\"]\n    latitude_band = meta[\"lat\"]\n    year = meta[\"acquisitionYear\"]\n    month = meta[\"acquisitionMonth\"].lstrip(\"0\")\n    day = meta[\"acquisitionDay\"].lstrip(\"0\")\n    img_num = meta[\"num\"]\n\n    meta[\"key\"] = \"tiles/{}/{}/{}/{}/{}/{}/{}\".format(\n        utm_zone, latitude_band, grid_square, year, month, day, img_num\n    )\n\n    meta[\"scene\"] = sceneid\n\n    return meta"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bounds(sceneid):\n    scene_params = _sentinel_parse_scene_id(sceneid)\n    sentinel_address = \"{}/{}\".format(SENTINEL_BUCKET, scene_params[\"key\"])\n\n    with rasterio.open(\"{}/preview.jp2\".format(sentinel_address)) as src:\n        wgs_bounds = transform_bounds(\n            *[src.crs, \"epsg:4326\"] + list(src.bounds), densify_pts=21\n        )\n\n    info = {\"sceneid\": sceneid}\n    info[\"bounds\"] = list(wgs_bounds)\n\n    return info", "response": "Retrieve image bounds.\n\n    Attributes\n    ----------\n    sceneid : str\n        Sentinel-2 sceneid.\n\n    Returns\n    -------\n    out : dict\n        dictionary with image bounds."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dictionary of statistics for the object holding the sentinel dataset.", "response": "def _sentinel_stats(\n    src_path, percentiles=(2, 98), histogram_bins=10, histogram_range=None\n):\n    \"\"\"\n    src_path : str or PathLike object\n        A dataset path or URL. Will be opened in \"r\" mode.\n    \"\"\"\n\n    with rasterio.open(src_path) as src:\n        arr = src.read(indexes=[1], masked=True)\n        arr[arr == 0] = np.ma.masked\n\n    params = {}\n    if histogram_bins:\n        params.update(dict(bins=histogram_bins))\n    if histogram_range:\n        params.update(dict(range=histogram_range))\n\n    return {1: utils._stats(arr, percentiles=percentiles, **params)}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve image bounds and band statistics.", "response": "def metadata(sceneid, pmin=2, pmax=98, **kwargs):\n    \"\"\"\n    Retrieve image bounds and band statistics.\n\n    Attributes\n    ----------\n    sceneid : str\n        Sentinel-2 sceneid.\n    pmin : int, optional, (default: 2)\n        Histogram minimum cut.\n    pmax : int, optional, (default: 98)\n        Histogram maximum cut.\n    kwargs : optional\n        These are passed to 'rio_tiler.sentinel2._sentinel_stats'\n        e.g: histogram_bins=20'\n\n    Returns\n    -------\n    out : dict\n        Dictionary with image bounds and bands statistics.\n\n    \"\"\"\n    scene_params = _sentinel_parse_scene_id(sceneid)\n    sentinel_address = \"{}/{}\".format(SENTINEL_BUCKET, scene_params[\"key\"])\n\n    dst_crs = CRS({\"init\": \"EPSG:4326\"})\n    with rasterio.open(\"{}/preview.jp2\".format(sentinel_address)) as src:\n        bounds = transform_bounds(\n            *[src.crs, dst_crs] + list(src.bounds), densify_pts=21\n        )\n\n    info = {\"sceneid\": sceneid}\n    info[\"bounds\"] = {\"value\": bounds, \"crs\": dst_crs.to_string()}\n\n    addresses = [\n        \"{}/preview/B{}.jp2\".format(sentinel_address, band) for band in SENTINEL_BANDS\n    ]\n\n    _stats_worker = partial(_sentinel_stats, percentiles=(pmin, pmax), **kwargs)\n    with futures.ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n        responses = executor.map(_stats_worker, addresses)\n    info[\"statistics\"] = {\n        b: v for b, d in zip(SENTINEL_BANDS, responses) for k, v in d.items()\n    }\n    return info"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tile(sceneid, tile_x, tile_y, tile_z, bands=(\"04\", \"03\", \"02\"), tilesize=256):\n    if not isinstance(bands, tuple):\n        bands = tuple((bands,))\n\n    for band in bands:\n        if band not in SENTINEL_BANDS:\n            raise InvalidBandName(\"{} is not a valid Sentinel band name\".format(band))\n\n    scene_params = _sentinel_parse_scene_id(sceneid)\n    sentinel_address = \"{}/{}\".format(SENTINEL_BUCKET, scene_params[\"key\"])\n\n    sentinel_preview = \"{}/preview.jp2\".format(sentinel_address)\n    with rasterio.open(sentinel_preview) as src:\n        wgs_bounds = transform_bounds(\n            *[src.crs, \"epsg:4326\"] + list(src.bounds), densify_pts=21\n        )\n\n    if not utils.tile_exists(wgs_bounds, tile_z, tile_x, tile_y):\n        raise TileOutsideBounds(\n            \"Tile {}/{}/{} is outside image bounds\".format(tile_z, tile_x, tile_y)\n        )\n\n    mercator_tile = mercantile.Tile(x=tile_x, y=tile_y, z=tile_z)\n    tile_bounds = mercantile.xy_bounds(mercator_tile)\n\n    addresses = [\"{}/B{}.jp2\".format(sentinel_address, band) for band in bands]\n\n    _tiler = partial(utils.tile_read, bounds=tile_bounds, tilesize=tilesize, nodata=0)\n    with futures.ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n        data, masks = zip(*list(executor.map(_tiler, addresses)))\n        mask = np.all(masks, axis=0).astype(np.uint8) * 255\n\n    return np.concatenate(data), mask", "response": "Create a mercantile tile from Sentinel - 2 data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting Landsat - 8 MTL metadata.", "response": "def _landsat_get_mtl(sceneid):\n    \"\"\"\n    Get Landsat-8 MTL metadata.\n\n    Attributes\n    ----------\n    sceneid : str\n        Landsat sceneid. For scenes after May 2017,\n        sceneid have to be LANDSAT_PRODUCT_ID.\n\n    Returns\n    -------\n    out : dict\n        returns a JSON like object with the metadata.\n\n    \"\"\"\n    scene_params = _landsat_parse_scene_id(sceneid)\n    meta_file = \"http://landsat-pds.s3.amazonaws.com/{}_MTL.txt\".format(\n        scene_params[\"key\"]\n    )\n    metadata = str(urlopen(meta_file).read().decode())\n    return toa_utils._parse_mtl_txt(metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _landsat_parse_scene_id(sceneid):\n    pre_collection = r\"(L[COTEM]8\\d{6}\\d{7}[A-Z]{3}\\d{2})\"\n    collection_1 = r\"(L[COTEM]08_L\\d{1}[A-Z]{2}_\\d{6}_\\d{8}_\\d{8}_\\d{2}_(T1|T2|RT))\"\n    if not re.match(\"^{}|{}$\".format(pre_collection, collection_1), sceneid):\n        raise InvalidLandsatSceneId(\"Could not match {}\".format(sceneid))\n\n    precollection_pattern = (\n        r\"^L\"\n        r\"(?P<sensor>\\w{1})\"\n        r\"(?P<satellite>\\w{1})\"\n        r\"(?P<path>[0-9]{3})\"\n        r\"(?P<row>[0-9]{3})\"\n        r\"(?P<acquisitionYear>[0-9]{4})\"\n        r\"(?P<acquisitionJulianDay>[0-9]{3})\"\n        r\"(?P<groundStationIdentifier>\\w{3})\"\n        r\"(?P<archiveVersion>[0-9]{2})$\"\n    )\n\n    collection_pattern = (\n        r\"^L\"\n        r\"(?P<sensor>\\w{1})\"\n        r\"(?P<satellite>\\w{2})\"\n        r\"_\"\n        r\"(?P<processingCorrectionLevel>\\w{4})\"\n        r\"_\"\n        r\"(?P<path>[0-9]{3})\"\n        r\"(?P<row>[0-9]{3})\"\n        r\"_\"\n        r\"(?P<acquisitionYear>[0-9]{4})\"\n        r\"(?P<acquisitionMonth>[0-9]{2})\"\n        r\"(?P<acquisitionDay>[0-9]{2})\"\n        r\"_\"\n        r\"(?P<processingYear>[0-9]{4})\"\n        r\"(?P<processingMonth>[0-9]{2})\"\n        r\"(?P<processingDay>[0-9]{2})\"\n        r\"_\"\n        r\"(?P<collectionNumber>\\w{2})\"\n        r\"_\"\n        r\"(?P<collectionCategory>\\w{2})$\"\n    )\n\n    meta = None\n    for pattern in [collection_pattern, precollection_pattern]:\n        match = re.match(pattern, sceneid, re.IGNORECASE)\n        if match:\n            meta = match.groupdict()\n            break\n\n    if meta.get(\"acquisitionJulianDay\"):\n        date = datetime.datetime(\n            int(meta[\"acquisitionYear\"]), 1, 1\n        ) + datetime.timedelta(int(meta[\"acquisitionJulianDay\"]) - 1)\n\n        meta[\"date\"] = date.strftime(\"%Y-%m-%d\")\n    else:\n        meta[\"date\"] = \"{}-{}-{}\".format(\n            meta[\"acquisitionYear\"], meta[\"acquisitionMonth\"], meta[\"acquisitionDay\"]\n        )\n\n    collection = meta.get(\"collectionNumber\", \"\")\n    if collection != \"\":\n        collection = \"c{}\".format(int(collection))\n\n    meta[\"key\"] = os.path.join(\n        collection, \"L8\", meta[\"path\"], meta[\"row\"], sceneid, sceneid\n    )\n\n    meta[\"scene\"] = sceneid\n\n    return meta", "response": "Parse Landsat - 8 scene id."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary of statistics for the given landsat dataset.", "response": "def _landsat_stats(\n    band,\n    address_prefix,\n    metadata,\n    overview_level=None,\n    max_size=1024,\n    percentiles=(2, 98),\n    dst_crs=CRS({\"init\": \"EPSG:4326\"}),\n    histogram_bins=10,\n    histogram_range=None,\n):\n    \"\"\"\n    Retrieve landsat dataset statistics.\n\n    Attributes\n    ----------\n    band : str\n        Landsat band number\n    address_prefix : str\n        A Landsat AWS S3 dataset prefix.\n    metadata : dict\n        Landsat metadata\n    overview_level : int, optional\n        Overview (decimation) level to fetch.\n    max_size: int, optional\n        Maximum size of dataset to retrieve\n        (will be used to calculate the overview level to fetch).\n    percentiles : tulple, optional\n        Percentile or sequence of percentiles to compute,\n        which must be between 0 and 100 inclusive (default: (2, 98)).\n    dst_crs: CRS or dict\n        Target coordinate reference system (default: EPSG:4326).\n    histogram_bins: int, optional\n        Defines the number of equal-width histogram bins (default: 10).\n    histogram_range: tuple or list, optional\n        The lower and upper range of the bins. If not provided, range is simply\n        the min and max of the array.\n\n    Returns\n    -------\n    out : dict\n        (percentiles), min, max, stdev, histogram for each band,\n        e.g.\n        {\n            \"4\": {\n                'pc': [15, 121],\n                'min': 1,\n                'max': 162,\n                'std': 27.22067722127997,\n                'histogram': [\n                    [102934, 135489, 20981, 13548, 11406, 8799, 7351, 5622, 2985, 662]\n                    [1., 17.1, 33.2, 49.3, 65.4, 81.5, 97.6, 113.7, 129.8, 145.9, 162.]\n                ]\n            }\n        }\n    \"\"\"\n    src_path = \"{}_B{}.TIF\".format(address_prefix, band)\n    with rasterio.open(src_path) as src:\n        levels = src.overviews(1)\n        width = src.width\n        height = src.height\n        bounds = transform_bounds(\n            *[src.crs, dst_crs] + list(src.bounds), densify_pts=21\n        )\n\n        if len(levels):\n            if overview_level:\n                decim = levels[overview_level]\n            else:\n                # determine which zoom level to read\n                for ii, decim in enumerate(levels):\n                    if max(width // decim, height // decim) < max_size:\n                        break\n        else:\n            decim = 1\n            warnings.warn(\n                \"Dataset has no overviews, reading the full dataset\", NoOverviewWarning\n            )\n\n        out_shape = (height // decim, width // decim)\n        vrt_params = dict(\n            nodata=0, add_alpha=False, src_nodata=0, init_dest_nodata=False\n        )\n        with WarpedVRT(src, **vrt_params) as vrt:\n            arr = vrt.read(out_shape=out_shape, indexes=[1], masked=True)\n\n    if band in [\"10\", \"11\"]:  # TIRS\n        multi_rad = metadata[\"RADIOMETRIC_RESCALING\"].get(\n            \"RADIANCE_MULT_BAND_{}\".format(band)\n        )\n        add_rad = metadata[\"RADIOMETRIC_RESCALING\"].get(\n            \"RADIANCE_ADD_BAND_{}\".format(band)\n        )\n        k1 = metadata[\"TIRS_THERMAL_CONSTANTS\"].get(\"K1_CONSTANT_BAND_{}\".format(band))\n        k2 = metadata[\"TIRS_THERMAL_CONSTANTS\"].get(\"K2_CONSTANT_BAND_{}\".format(band))\n\n        arr = brightness_temp.brightness_temp(arr, multi_rad, add_rad, k1, k2)\n    else:\n        multi_reflect = metadata[\"RADIOMETRIC_RESCALING\"].get(\n            \"REFLECTANCE_MULT_BAND_{}\".format(band)\n        )\n        add_reflect = metadata[\"RADIOMETRIC_RESCALING\"].get(\n            \"REFLECTANCE_ADD_BAND_{}\".format(band)\n        )\n        sun_elev = metadata[\"IMAGE_ATTRIBUTES\"][\"SUN_ELEVATION\"]\n\n        arr = 10000 * reflectance.reflectance(\n            arr, multi_reflect, add_reflect, sun_elev, src_nodata=0\n        )\n\n    params = {}\n    if histogram_bins:\n        params.update(dict(bins=histogram_bins))\n    if histogram_range:\n        params.update(dict(range=histogram_range))\n\n    stats = {band: utils._stats(arr, percentiles=percentiles, **params)}\n\n    return {\n        \"bounds\": {\n            \"value\": bounds,\n            \"crs\": dst_crs.to_string() if isinstance(dst_crs, CRS) else dst_crs,\n        },\n        \"statistics\": stats,\n    }"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves image bounds. Attributes ---------- sceneid : str Landsat sceneid. For scenes after May 2017, sceneid have to be LANDSAT_PRODUCT_ID. Returns ------- out : dict dictionary with image bounds.", "response": "def bounds(sceneid):\n    \"\"\"\n    Retrieve image bounds.\n\n    Attributes\n    ----------\n    sceneid : str\n        Landsat sceneid. For scenes after May 2017,\n        sceneid have to be LANDSAT_PRODUCT_ID.\n\n    Returns\n    -------\n    out : dict\n        dictionary with image bounds.\n\n    \"\"\"\n    meta_data = _landsat_get_mtl(sceneid).get(\"L1_METADATA_FILE\")\n\n    info = {\"sceneid\": sceneid}\n    info[\"bounds\"] = toa_utils._get_bounds_from_metadata(meta_data[\"PRODUCT_METADATA\"])\n\n    return info"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef metadata(sceneid, pmin=2, pmax=98, **kwargs):\n    scene_params = _landsat_parse_scene_id(sceneid)\n    meta_data = _landsat_get_mtl(sceneid).get(\"L1_METADATA_FILE\")\n    path_prefix = \"{}/{}\".format(LANDSAT_BUCKET, scene_params[\"key\"])\n\n    info = {\"sceneid\": sceneid}\n\n    _stats_worker = partial(\n        _landsat_stats,\n        address_prefix=path_prefix,\n        metadata=meta_data,\n        overview_level=1,\n        percentiles=(pmin, pmax),\n        **kwargs\n    )\n\n    with futures.ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n        responses = list(executor.map(_stats_worker, LANDSAT_BANDS))\n\n    info[\"bounds\"] = [\n        r[\"bounds\"] for b, r in zip(LANDSAT_BANDS, responses) if b == \"8\"\n    ][0]\n\n    info[\"statistics\"] = {\n        b: v\n        for b, d in zip(LANDSAT_BANDS, responses)\n        for k, v in d[\"statistics\"].items()\n    }\n    return info", "response": "Retrieve image bounds and band statistics."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tile(\n    sceneid, tile_x, tile_y, tile_z, bands=(\"4\", \"3\", \"2\"), tilesize=256, pan=False\n):\n    \"\"\"\n    Create mercator tile from Landsat-8 data.\n\n    Attributes\n    ----------\n    sceneid : str\n        Landsat sceneid. For scenes after May 2017,\n        sceneid have to be LANDSAT_PRODUCT_ID.\n    tile_x : int\n        Mercator tile X index.\n    tile_y : int\n        Mercator tile Y index.\n    tile_z : int\n        Mercator tile ZOOM level.\n    bands : tuple, str, optional (default: (\"4\", \"3\", \"2\"))\n        Bands index for the RGB combination.\n    tilesize : int, optional (default: 256)\n        Output image size.\n    pan : boolean, optional (default: False)\n        If True, apply pan-sharpening.\n\n    Returns\n    -------\n    data : numpy ndarray\n    mask: numpy array\n\n    \"\"\"\n    if not isinstance(bands, tuple):\n        bands = tuple((bands,))\n\n    for band in bands:\n        if band not in LANDSAT_BANDS:\n            raise InvalidBandName(\"{} is not a valid Landsat band name\".format(band))\n\n    scene_params = _landsat_parse_scene_id(sceneid)\n    meta_data = _landsat_get_mtl(sceneid).get(\"L1_METADATA_FILE\")\n    landsat_address = \"{}/{}\".format(LANDSAT_BUCKET, scene_params[\"key\"])\n\n    wgs_bounds = toa_utils._get_bounds_from_metadata(meta_data[\"PRODUCT_METADATA\"])\n\n    if not utils.tile_exists(wgs_bounds, tile_z, tile_x, tile_y):\n        raise TileOutsideBounds(\n            \"Tile {}/{}/{} is outside image bounds\".format(tile_z, tile_x, tile_y)\n        )\n\n    mercator_tile = mercantile.Tile(x=tile_x, y=tile_y, z=tile_z)\n    tile_bounds = mercantile.xy_bounds(mercator_tile)\n\n    addresses = [\"{}_B{}.TIF\".format(landsat_address, band) for band in bands]\n\n    _tiler = partial(utils.tile_read, bounds=tile_bounds, tilesize=tilesize, nodata=0)\n    with futures.ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n        data, masks = zip(*list(executor.map(_tiler, addresses)))\n        data = np.concatenate(data)\n        mask = np.all(masks, axis=0).astype(np.uint8) * 255\n\n        if pan:\n            pan_address = \"{}_B8.TIF\".format(landsat_address)\n            matrix_pan, mask = utils.tile_read(\n                pan_address, tile_bounds, tilesize, nodata=0\n            )\n            data = utils.pansharpening_brovey(data, matrix_pan, 0.2, matrix_pan.dtype)\n\n        sun_elev = meta_data[\"IMAGE_ATTRIBUTES\"][\"SUN_ELEVATION\"]\n\n        for bdx, band in enumerate(bands):\n            if int(band) > 9:  # TIRS\n                multi_rad = meta_data[\"RADIOMETRIC_RESCALING\"].get(\n                    \"RADIANCE_MULT_BAND_{}\".format(band)\n                )\n\n                add_rad = meta_data[\"RADIOMETRIC_RESCALING\"].get(\n                    \"RADIANCE_ADD_BAND_{}\".format(band)\n                )\n\n                k1 = meta_data[\"TIRS_THERMAL_CONSTANTS\"].get(\n                    \"K1_CONSTANT_BAND_{}\".format(band)\n                )\n\n                k2 = meta_data[\"TIRS_THERMAL_CONSTANTS\"].get(\n                    \"K2_CONSTANT_BAND_{}\".format(band)\n                )\n\n                data[bdx] = brightness_temp.brightness_temp(\n                    data[bdx], multi_rad, add_rad, k1, k2\n                )\n\n            else:\n                multi_reflect = meta_data[\"RADIOMETRIC_RESCALING\"].get(\n                    \"REFLECTANCE_MULT_BAND_{}\".format(band)\n                )\n\n                add_reflect = meta_data[\"RADIOMETRIC_RESCALING\"].get(\n                    \"REFLECTANCE_ADD_BAND_{}\".format(band)\n                )\n\n                data[bdx] = 10000 * reflectance.reflectance(\n                    data[bdx], multi_reflect, add_reflect, sun_elev\n                )\n\n        return data, mask", "response": "Create mercantile tile from Landsat - 8 data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _cbers_parse_scene_id(sceneid):\n    if not re.match(r\"^CBERS_4_\\w+_[0-9]{8}_[0-9]{3}_[0-9]{3}_L[0-9]$\", sceneid):\n        raise InvalidCBERSSceneId(\"Could not match {}\".format(sceneid))\n\n    cbers_pattern = (\n        r\"(?P<satellite>\\w+)_\"\n        r\"(?P<mission>[0-9]{1})\"\n        r\"_\"\n        r\"(?P<instrument>\\w+)\"\n        r\"_\"\n        r\"(?P<acquisitionYear>[0-9]{4})\"\n        r\"(?P<acquisitionMonth>[0-9]{2})\"\n        r\"(?P<acquisitionDay>[0-9]{2})\"\n        r\"_\"\n        r\"(?P<path>[0-9]{3})\"\n        r\"_\"\n        r\"(?P<row>[0-9]{3})\"\n        r\"_\"\n        r\"(?P<processingCorrectionLevel>L[0-9]{1})$\"\n    )\n\n    meta = None\n    match = re.match(cbers_pattern, sceneid, re.IGNORECASE)\n    if match:\n        meta = match.groupdict()\n\n    path = meta[\"path\"]\n    row = meta[\"row\"]\n    instrument = meta[\"instrument\"]\n    meta[\"key\"] = \"CBERS4/{}/{}/{}/{}\".format(instrument, path, row, sceneid)\n\n    meta[\"scene\"] = sceneid\n\n    instrument_params = {\n        \"MUX\": {\n            \"reference_band\": \"6\",\n            \"bands\": [\"5\", \"6\", \"7\", \"8\"],\n            \"rgb\": (\"7\", \"6\", \"5\"),\n        },\n        \"AWFI\": {\n            \"reference_band\": \"14\",\n            \"bands\": [\"13\", \"14\", \"15\", \"16\"],\n            \"rgb\": (\"15\", \"14\", \"13\"),\n        },\n        \"PAN10M\": {\n            \"reference_band\": \"4\",\n            \"bands\": [\"2\", \"3\", \"4\"],\n            \"rgb\": (\"3\", \"4\", \"2\"),\n        },\n        \"PAN5M\": {\"reference_band\": \"1\", \"bands\": [\"1\"], \"rgb\": (\"1\", \"1\", \"1\")},\n    }\n    meta[\"reference_band\"] = instrument_params[instrument][\"reference_band\"]\n    meta[\"bands\"] = instrument_params[instrument][\"bands\"]\n    meta[\"rgb\"] = instrument_params[instrument][\"rgb\"]\n\n    return meta", "response": "Parse a CBERS scene id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve image bounds. Attributes ---------- sceneid : str CBERS sceneid. Returns ------- out : dict dictionary with image bounds.", "response": "def bounds(sceneid):\n    \"\"\"\n    Retrieve image bounds.\n\n    Attributes\n    ----------\n    sceneid : str\n        CBERS sceneid.\n\n    Returns\n    -------\n    out : dict\n        dictionary with image bounds.\n\n    \"\"\"\n    scene_params = _cbers_parse_scene_id(sceneid)\n    cbers_address = \"{}/{}\".format(CBERS_BUCKET, scene_params[\"key\"])\n\n    with rasterio.open(\n        \"{}/{}_BAND{}.tif\".format(\n            cbers_address, sceneid, scene_params[\"reference_band\"]\n        )\n    ) as src:\n        wgs_bounds = transform_bounds(\n            *[src.crs, \"epsg:4326\"] + list(src.bounds), densify_pts=21\n        )\n\n    info = {\"sceneid\": sceneid}\n    info[\"bounds\"] = list(wgs_bounds)\n\n    return info"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn band bounds and statistics.", "response": "def metadata(sceneid, pmin=2, pmax=98, **kwargs):\n    \"\"\"\n    Return band bounds and statistics.\n\n    Attributes\n    ----------\n    sceneid : str\n        CBERS sceneid.\n    pmin : int, optional, (default: 2)\n        Histogram minimum cut.\n    pmax : int, optional, (default: 98)\n        Histogram maximum cut.\n    kwargs : optional\n        These are passed to 'rio_tiler.utils.raster_get_stats'\n        e.g: histogram_bins=20, dst_crs='epsg:4326'\n\n    Returns\n    -------\n    out : dict\n        Dictionary with bounds and bands statistics.\n\n    \"\"\"\n    scene_params = _cbers_parse_scene_id(sceneid)\n    cbers_address = \"{}/{}\".format(CBERS_BUCKET, scene_params[\"key\"])\n    bands = scene_params[\"bands\"]\n    ref_band = scene_params[\"reference_band\"]\n\n    info = {\"sceneid\": sceneid}\n\n    addresses = [\n        \"{}/{}_BAND{}.tif\".format(cbers_address, sceneid, band) for band in bands\n    ]\n    _stats_worker = partial(\n        utils.raster_get_stats,\n        indexes=[1],\n        nodata=0,\n        overview_level=2,\n        percentiles=(pmin, pmax),\n        **kwargs\n    )\n    with futures.ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n        responses = list(executor.map(_stats_worker, addresses))\n\n    info[\"bounds\"] = [r[\"bounds\"] for b, r in zip(bands, responses) if b == ref_band][0]\n    info[\"statistics\"] = {\n        b: v for b, d in zip(bands, responses) for k, v in d[\"statistics\"].items()\n    }\n    return info"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __datasets_desc():\n    datasets = __get_data_folder_path() + 'datasets.csv'\n    df = pd.read_csv(datasets)\n    df = df[['Item', 'Title']]\n    df.columns = ['dataset_id', 'title']\n    # print('a list of the available datasets:')\n    return df", "response": "return a df of the available datasets with description"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dumb_property_dict(style):\n    return dict([(x.strip(), y.strip()) for x, y in [z.split(':', 1) for z in style.split(';') if ':' in z]]);", "response": "returns a hash of css attributes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a hash of css selectors each of which contains a hash of css attributes", "response": "def dumb_css_parser(data):\n    \"\"\"returns a hash of css selectors, each of which contains a hash of css attributes\"\"\"\n    # remove @import sentences\n    data += ';'\n    importIndex = data.find('@import')\n    while importIndex != -1:\n        data = data[0:importIndex] + data[data.find(';', importIndex) + 1:]\n        importIndex = data.find('@import')\n\n    # parse the css. reverted from dictionary compehension in order to support older pythons\n    elements =  [x.split('{') for x in data.split('}') if '{' in x.strip()]\n    try:\n        elements = dict([(a.strip(), dumb_property_dict(b)) for a, b in elements])\n    except ValueError:\n        elements = {} # not that important\n\n    return elements"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a hash of the final style attributes of the element", "response": "def element_style(attrs, style_def, parent_style):\n    \"\"\"returns a hash of the 'final' style attributes of the element\"\"\"\n    style = parent_style.copy()\n    if 'class' in attrs:\n        for css_class in attrs['class'].split():\n            css_style = style_def['.' + css_class]\n            style.update(css_style)\n    if 'style' in attrs:\n        immediate_style = dumb_property_dict(attrs['style'])\n        style.update(immediate_style)\n    return style"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef google_text_emphasis(style):\n    emphasis = []\n    if 'text-decoration' in style:\n        emphasis.append(style['text-decoration'])\n    if 'font-style' in style:\n        emphasis.append(style['font-style'])\n    if 'font-weight' in style:\n        emphasis.append(style['font-weight'])\n    return emphasis", "response": "return a list of all emphasis modifiers of the element"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the css of the current element defines a fixed width font", "response": "def google_fixed_width_font(style):\n    \"\"\"check if the css of the current element defines a fixed width font\"\"\"\n    font_family = ''\n    if 'font-family' in style:\n        font_family = style['font-family']\n    if 'Courier New' == font_family or 'Consolas' == font_family:\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef escape_md_section(text, snob=False):\n    text = md_backslash_matcher.sub(r\"\\\\\\1\", text)\n    if snob:\n        text = md_chars_matcher_all.sub(r\"\\\\\\1\", text)\n    text = md_dot_matcher.sub(r\"\\1\\\\\\2\", text)\n    text = md_plus_matcher.sub(r\"\\1\\\\\\2\", text)\n    text = md_dash_matcher.sub(r\"\\1\\\\\\2\", text)\n    return text", "response": "Escapes markdown - sensitive characters across whole document sections."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef previousIndex(self, attrs):\n        if not has_key(attrs, 'href'): return None\n\n        i = -1\n        for a in self.a:\n            i += 1\n            match = 0\n\n            if has_key(a, 'href') and a['href'] == attrs['href']:\n                if has_key(a, 'title') or has_key(attrs, 'title'):\n                        if (has_key(a, 'title') and has_key(attrs, 'title') and\n                            a['title'] == attrs['title']):\n                            match = True\n                else:\n                    match = True\n\n            if match: return i", "response": "returns the index of the previous set of attributes of a link in the list\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle various text emphases", "response": "def handle_emphasis(self, start, tag_style, parent_style):\n        \"\"\"handles various text emphases\"\"\"\n        tag_emphasis = google_text_emphasis(tag_style)\n        parent_emphasis = google_text_emphasis(parent_style)\n\n        # handle Google's text emphasis\n        strikethrough =  'line-through' in tag_emphasis and self.hide_strikethrough\n        bold = 'bold' in tag_emphasis and not 'bold' in parent_emphasis\n        italic = 'italic' in tag_emphasis and not 'italic' in parent_emphasis\n        fixed = google_fixed_width_font(tag_style) and not \\\n                google_fixed_width_font(parent_style) and not self.pre\n\n        if start:\n            # crossed-out text must be handled before other attributes\n            # in order not to output qualifiers unnecessarily\n            if bold or italic or fixed:\n                self.emphasis += 1\n            if strikethrough:\n                self.quiet += 1\n            if italic:\n                self.o(self.emphasis_mark)\n                self.drop_white_space += 1\n            if bold:\n                self.o(self.strong_mark)\n                self.drop_white_space += 1\n            if fixed:\n                self.o('`')\n                self.drop_white_space += 1\n                self.code = True\n        else:\n            if bold or italic or fixed:\n                # there must not be whitespace before closing emphasis mark\n                self.emphasis -= 1\n                self.space = 0\n                self.outtext = self.outtext.rstrip()\n            if fixed:\n                if self.drop_white_space:\n                    # empty emphasis, drop it\n                    self.drop_last(1)\n                    self.drop_white_space -= 1\n                else:\n                    self.o('`')\n                self.code = False\n            if bold:\n                if self.drop_white_space:\n                    # empty emphasis, drop it\n                    self.drop_last(2)\n                    self.drop_white_space -= 1\n                else:\n                    self.o(self.strong_mark)\n            if italic:\n                if self.drop_white_space:\n                    # empty emphasis, drop it\n                    self.drop_last(1)\n                    self.drop_white_space -= 1\n                else:\n                    self.o(self.emphasis_mark)\n            # space is only allowed after *all* emphasis marks\n            if (bold or italic) and not self.emphasis:\n                    self.o(\" \")\n            if strikethrough:\n                self.quiet -= 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the nesting count of google doc lists", "response": "def google_nest_count(self, style):\n        \"\"\"calculate the nesting count of google doc lists\"\"\"\n        nest_count = 0\n        if 'margin-left' in style:\n            nest_count = int(style['margin-left'][:-2]) / self.google_list_indent\n        return nest_count"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef optwrap(self, text):\n        if not self.body_width:\n            return text\n\n        assert wrap, \"Requires Python 2.3.\"\n        result = ''\n        newlines = 0\n        for para in text.split(\"\\n\"):\n            if len(para) > 0:\n                if not skipwrap(para):\n                    result += \"\\n\".join(wrap(para, self.body_width))\n                    if para.endswith('  '):\n                        result += \"  \\n\"\n                        newlines = 1\n                    else:\n                        result += \"\\n\\n\"\n                        newlines = 2\n                else:\n                    if not onlywhite(para):\n                        result += para + \"\\n\"\n                        newlines = 1\n            else:\n                if newlines < 2:\n                    result += \"\\n\"\n                    newlines += 1\n        return result", "response": "Wrap all paragraphs in the provided text."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef similarity(w1, w2, threshold=0.5):\n    ratio = SM(None, str(w1).lower(), str(w2).lower()).ratio()\n    return ratio if ratio > threshold else 0", "response": "compare two strings words and return ratio of smiliarity or 0 otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the top MAX_SIMILARS [ dataset_id smilarity_ratio ] to s1", "response": "def search_similar(s1, dlist=DATASET_IDS, MAX_SIMILARS=10):\n    \"\"\"Returns the top MAX_SIMILARS [(dataset_id : smilarity_ratio)] to s1\"\"\"\n\n    similars = {s2: similarity(s1, s2)\n                for s2 in dlist\n                if similarity(s1, s2)}\n\n    # a list of tuples [(similar_word, ratio) .. ]\n    top_match = Counter(similars).most_common(MAX_SIMILARS+1)\n\n    return top_match"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef data(item=None, show_doc=False):\n\n    if item:\n        try:\n            if show_doc:\n                __print_item_docs(item)\n                return\n\n            df = __read_csv(item)\n            return df\n        except KeyError:\n            find_similar(item)\n    else:\n        return __datasets_desc()", "response": "loads a datasaet from in - modules datasets returns a dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef triangle_area(p0, p1, p2):\n    if p2.ndim < 2:\n        p2 = p2[np.newaxis, :]\n    '''p2 can be a vector'''\n    area = 0.5 * np.abs(p0[0] * p1[1] - p0[0] * p2[:,1] +\n           p1[0] * p2[:,1] - p1[0] * p0[1] +\n           p2[:,0] * p0[1] - p2[:,0] * p1[1])\n    return area", "response": "Calculates the area of a triangle."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove(self, parent):\n        '''remove ROI'''\n        parent.p0.removeItem(self.ROIplot)\n        parent.p0.removeItem(self.dotplot)", "response": "remove ROI and dotplot from parent"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dwrap(kx,nc):\n    '''compute a wrapped distance'''\n    q1 = np.mod(kx, nc)\n    q2 = np.minimum(q1, nc-q1)\n    return q2", "response": "compute a wrapped distance"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfits X into an embedded space and return that transformed output.", "response": "def fit_transform(self, X, u=None, sv=None, v=None):\n        \"\"\"Fit X into an embedded space and return that transformed\n        output.\n        Inputs\n        ----------\n        X : array, shape (n_samples, n_features). X contains a sample per row.\n\n        Returns\n        -------\n        embedding : array, shape (n_samples, n_components)\n            Embedding of the training data in low-dimensional space.\n        \"\"\"\n        self.fit(X, u, sv, v)\n        return self.embedding"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transform(self, X):\n        iclustup = []\n        dims = self.n_components\n        if hasattr(self, 'isort1'):\n            if X.shape[1] == self.v.shape[0]:\n                # reduce dimensionality of X\n                X = X @ self.v\n                nclust = self.n_X\n                AtS = self.A.T @ self.S\n                vnorm   = np.sum(self.S * (self.A @ AtS), axis=0)[np.newaxis,:]\n                cv      = X @ AtS\n                cmap    = np.maximum(0., cv)**2 / vnorm\n                iclustup, cmax = upsample(np.sqrt(cmap), dims, nclust, 10)\n            else:\n                print('ERROR: new points do not have as many features as original data')\n        else:\n            print('ERROR: need to fit model first before you can embed new points')\n        if iclustup.ndim > 1:\n            iclustup = iclustup.T\n        else:\n            iclustup = iclustup.flatten()\n        return iclustup", "response": "transform X to iclustup points"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfits X into an embedded space.", "response": "def fit(self, X=None, u=None, s = None):\n        \"\"\"Fit X into an embedded space.\n        Inputs\n        ----------\n        X : array, shape (n_samples, n_features)\n        u,s,v : svd decomposition of X (optional)\n\n        Assigns\n        ----------\n        embedding : array-like, shape (n_samples, n_components)\n            Stores the embedding vectors.\n        u,sv,v : singular value decomposition of data S, potentially with smoothing\n        isort1 : sorting along first dimension of matrix\n        isort2 : sorting along second dimension of matrix (if n_Y > 0)\n        cmap: correlation of each item with all locations in the embedding map (before upsampling)\n        A:    PC coefficients of each Fourier mode\n\n        \"\"\"\n        X = X.copy()\n        X -= X.mean(axis=0)\n\n        if self.mode is 'parallel':\n            Xall = X.copy()\n            X = np.reshape(Xall.copy(), (-1, Xall.shape[-1]))\n        #X -= X.mean(axis=-1)[:,np.newaxis]\n        if ((u is None)):\n            # compute svd and keep iPC's of data\n            nmin = min([X.shape[0], X.shape[1]])\n            nmin = np.minimum(nmin-1, self.nPC)\n            u,sv,v = svdecon(np.float64(X), k=nmin)\n            u = u * sv\n\n        NN, self.nPC = u.shape\n        # first smooth in Y (if n_Y > 0)\n        self.u = u\n\n        if self.mode is 'parallel':\n            NN = Xall.shape[1]\n            X = np.zeros((2, NN, u.shape[1]), 'float64')\n            for j in range(2):\n                Xall[j] -= Xall[j].mean(axis=-1)[:, np.newaxis]\n                X[j] = Xall[j] @ self.v\n\n        nclust = self.n_X\n\n        if self.n_components==1 and init_sort.ndim==1:\n            uinit = uinit[:,np.newaxis]\n\n        # now sort in X\n        Y = self._map(u.copy(), self.n_components)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfitting X into an embedded space.", "response": "def fit(self, X=None, u=None):\n        \"\"\"Fit X into an embedded space.\n        Inputs\n        ----------\n        X : array, shape (n_samples, n_features)\n        u,s,v : svd decomposition of X (optional)\n\n        Assigns\n        ----------\n        embedding : array-like, shape (n_samples, n_components)\n            Stores the embedding vectors.\n        u,sv,v : singular value decomposition of data S, potentially with smoothing\n        isort1 : sorting along first dimension of matrix\n        isort2 : sorting along second dimension of matrix (if n_Y > 0)\n        cmap: correlation of each item with all locations in the embedding map (before upsampling)\n        A:    PC coefficients of each Fourier mode\n\n        \"\"\"\n        X = X.copy()\n        if self.mode is 'parallel':\n            Xall = X.copy()\n            X = np.reshape(Xall.copy(), (-1, Xall.shape[-1]))\n        #X -= X.mean(axis=-1)[:,np.newaxis]\n        if ((u is None)):\n            nmin = min([X.shape[0], X.shape[1]])\n            nmin = np.minimum(nmin-1, self.nPC)\n            u,sv,v = svdecon(np.float64(X), k=nmin)\n            u = u * sv\n        NN, self.nPC = u.shape\n        self.u = u\n        # now sort in X\n        U = self._map(u.copy(), self.n_components, self.n_X, u.copy())\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fit(self, X, u=None, sv=None, v=None):\n        if self.mode is 'parallel':\n            Xall = X.copy()\n            X = np.reshape(Xall.copy(), (-1, Xall.shape[-1]))\n        #X -= X.mean(axis=-1)[:,np.newaxis]\n        if (u is None) or (sv is None) or (v is None):\n            # compute svd and keep iPC's of data\n            nmin = min([X.shape[0],X.shape[1]])\n            nmin = np.minimum(nmin-1, self.nPC)\n            u,sv,v = svdecon(np.float64(X), k=nmin)\n            #u, sv, v = np.float32(u), np.float32(sv), np.float32(v)\n        self.nPC = sv.size\n\n        # first smooth in Y (if n_Y > 0)\n        # this will be a 1-D fit\n        isort2 = []\n        if self.n_Y > 0:\n            vsort = np.argsort(v[:,0])[:,np.newaxis]\n            isort2, iclustup = self._map(v * sv, 1, self.n_Y, vsort)\n            #X = gaussian_filter1d(X[:, isort2], self.sig_Y, axis=1)\n            #u,sv,v = svdecon(np.float64(X), k=nmin)\n\n        self.u = u\n        self.sv = sv\n        self.v = v\n        if self.mode is 'parallel':\n            NN = Xall.shape[1]\n            X = np.zeros((2, NN, u.shape[1]), 'float64')\n            for j in range(2):\n                Xall[j] -= Xall[j].mean(axis=-1)[:, np.newaxis]\n                X[j] = Xall[j] @ self.v\n        else:\n            NN = X.shape[0]\n            X = X @ self.v\n\n        if self.init == 'pca':\n            u = u * np.sign(skew(u, axis=0))\n            init_sort = np.argsort(u[:NN, :self.n_components], axis=0)\n            #init_sort = u[:NN,:self.n_components]\n            if False:\n                ix = init_sort > 0\n                iy = init_sort < 0\n                init_sort[ix] = init_sort[ix] - 100.\n                init_sort[iy] = init_sort[iy] + 100.\n        elif self.init == 'random':\n            init_sort = np.random.permutation(NN)[:,np.newaxis]\n            for j in range(1,self.n_components):\n                init_sort = np.concatenate((init_sort, np.random.permutation(NN)[:,np.newaxis]), axis=-1)\n        else:\n            init_sort = self.init\n        if self.n_components==1 and init_sort.ndim==1:\n            init_sort = init_sort[:,np.newaxis]\n\n        # now sort in X\n        isort1, iclustup = self._map(X, self.n_components, self.n_X, init_sort)\n        self.isort2 = isort2\n        self.isort1 = isort1\n        self.embedding = iclustup\n        return self", "response": "Fit X into an embedded space."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting X into an embedded space and return that transformed output.", "response": "def fit_transform(self, X, u=None):\n        \"\"\"Fit X into an embedded space and return that transformed\n        output.\n        Inputs\n        ----------\n        X : array, shape (n_samples, n_features). X contains a sample per row.\n\n        Returns\n        -------\n        embedding : array, shape (n_samples, n_components)\n            Embedding of the training data in low-dimensional space.\n        \"\"\"\n        self.fit(X, u)\n        return self.embedding"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fit(self, X=None, u=None, s=None):\n        if self.mode is 'parallel':\n            #X = X.copy()\n            X = np.reshape(X, (-1, X.shape[-1]))\n        else:\n            X = X.copy()\n        if ((u is None)):\n            # compute svd and keep iPC's of data\n            X -= np.mean(X, axis=0)\n            nmin = min([X.shape[0], X.shape[1]])\n            nmin = np.minimum(nmin, self.nPC)\n            print(\"nmin %d\"%nmin)\n            u,sv,v = svdecon(X, k=nmin)\n            u = u * sv\n            self.v = v\n        self.u = u\n\n        NN, self.nPC = u.shape\n        if self.constraints==3:\n            plaw = 1/(1+np.arange(1000))**(self.alpha/2)\n            self.vscale = np.sum(u**2,axis=0)**.5\n            tail = self.vscale[-1] * plaw[u.shape[1]:]/plaw[u.shape[1]]\n            self.vscale = np.hstack((self.vscale, tail))\n        # first smooth in Y (if n_Y > 0)\n\n        if self.mode is 'parallel':\n            NN = int(X.shape[0]/2)\n            u = np.reshape(u, (2, NN, u.shape[1]))\n\n        nclust = self.n_X\n        if self.init == 'pca':\n            if self.mode is 'parallel':\n                usort = u[0] * np.sign(skew(u[0], axis=0))\n            else:\n                usort = u * np.sign(skew(u, axis=0))\n        elif self.init == 'random':\n            init_sort = np.random.permutation(NN)[:,np.newaxis]\n            for j in range(1,self.n_components):\n                init_sort = np.concatenate((init_sort, np.random.permutation(NN)[:,np.newaxis]), axis=-1)\n            xid = np.zeros(NN)\n            for j in range(self.n_components):\n                iclust = np.floor(nclust * init_sort[:,j].astype(np.float64)/NN)\n                xid = nclust * xid + iclust\n        elif self.init =='laplacian':\n            Uz = zscore(u, axis=1)/u.shape[1]**.5\n            CC = Uz @ Uz.T\n            CCsort = np.sort(CC, axis=0)[::-1, :]\n            CC[CC<CCsort[100, :]] = 0\n            CC = (CC + CC.T)/2\n            Ds = 1. - CC\n            W = np.diag(np.sum(Ds, axis=1)) - Ds\n            usort = svdecon(W, k=2)[0]\n            usort = usort * np.sign(skew(usort, axis=0))\n        else:\n            init_sort = self.init\n            xid = np.zeros(NN)\n            for j in range(self.n_components):\n                iclust = np.floor(nclust * init_sort[:,j].astype(np.float64)/NN)\n                xid = nclust * xid + iclust\n\n        if self.init=='pca' or self.init=='laplacian':\n            init_sort = np.argsort(usort[:, :self.n_components], axis=0)\n            xid = np.zeros(NN)\n            for j in range(self.n_components):\n                iclust = np.floor(nclust * init_sort[:,j].astype(np.float64)/NN)\n                xid = nclust * xid + iclust\n\n        xid = xid.astype('int').flatten()\n\n        #self.init_sort = usort\n\n        if self.n_components==1 and init_sort.ndim==1:\n            init_sort = init_sort[:,np.newaxis]\n\n        # now sort in X\n        isort1, iclustup = self._map(u.copy(), self.n_components, self.n_X, xid, s)\n        self.isort = isort1\n        self.embedding = iclustup\n        return self", "response": "Fit X into an embedded space."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfit X into an embedded space.", "response": "def fit(self, X=None, u=None, sv=None, v=None):\n        \"\"\"Fit X into an embedded space.\n        Inputs\n        ----------\n        X : array, shape (n_samples, n_features)\n        u,s,v : svd decomposition of X (optional)\n\n        Assigns\n        ----------\n        embedding : array-like, shape (n_samples, n_components)\n            Stores the embedding vectors.\n        u,sv,v : singular value decomposition of data S, potentially with smoothing\n        isort1 : sorting along first dimension of matrix\n        isort2 : sorting along second dimension of matrix (if n_Y > 0)\n        cmap: correlation of each item with all locations in the embedding map (before upsampling)\n        A:    PC coefficients of each Fourier mode\n\n        \"\"\"\n        if self.mode is 'parallel':\n            Xall = X.copy()\n            X = np.reshape(Xall.copy(), (-1, Xall.shape[-1]))\n        #X -= X.mean(axis=-1)[:,np.newaxis]\n        if ((u is None)):\n            # compute svd and keep iPC's of data\n            nmin = min([X.shape[0], X.shape[1]])\n            nmin = np.minimum(nmin-1, self.nPC)\n            u,sv,v = svdecon(np.float64(X), k=nmin)\n            u = u * sv\n\n        NN, self.nPC = u.shape\n        if self.constraints==3:\n            plaw = 1/(1+np.arange(1000))**(self.alpha/2)\n            self.vscale = np.sum(u**2,axis=0)**.5\n            tail = self.vscale[-1] * plaw[u.shape[1]:]/plaw[u.shape[1]]\n            self.vscale = np.hstack((self.vscale, tail))\n        # first smooth in Y (if n_Y > 0)\n        self.u = u\n        self.v = v\n        if self.mode is 'parallel':\n            NN = Xall.shape[1]\n            X = np.zeros((2, NN, u.shape[1]), 'float64')\n            for j in range(2):\n                Xall[j] -= Xall[j].mean(axis=-1)[:, np.newaxis]\n                X[j] = Xall[j] @ self.v\n\n        if self.init == 'pca':\n            usort = u * np.sign(skew(u, axis=0))\n            init_sort = np.argsort(usort[:NN, :self.n_components], axis=0)\n            #init_sort = u[:NN,:self.n_components]\n            if False:\n                ix = init_sort > 0\n                iy = init_sort < 0\n                init_sort[ix] = init_sort[ix] - 100.\n                init_sort[iy] = init_sort[iy] + 100.\n        elif self.init == 'random':\n            init_sort = np.random.permutation(NN)[:,np.newaxis]\n            for j in range(1,self.n_components):\n                init_sort = np.concatenate((init_sort, np.random.permutation(NN)[:,np.newaxis]), axis=-1)\n        else:\n            init_sort = self.init\n        if self.n_components==1 and init_sort.ndim==1:\n            init_sort = init_sort[:,np.newaxis]\n\n        # now sort in X\n        isort1, iclustup = self._map(u.copy(), self.n_components, self.n_X, init_sort)\n        self.isort = isort1\n        self.embedding = iclustup\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fit(self, X=None, u=None, s = None):\n        X = X.copy()\n        if self.mode is 'parallel':\n            Xall = X.copy()\n            X = np.reshape(Xall.copy(), (-1, Xall.shape[-1]))\n        #X -= X.mean(axis=-1)[:,np.newaxis]\n        if ((u is None)):\n            # compute svd and keep iPC's of data\n            nmin = min([X.shape[0], X.shape[1]])\n            nmin = np.minimum(nmin-1, self.nPC)\n            u,sv,v = svdecon(np.float64(X), k=nmin)\n            u = u * sv\n\n        NN, self.nPC = u.shape\n        # first smooth in Y (if n_Y > 0)\n        self.u = u\n\n        if self.mode is 'parallel':\n            NN = Xall.shape[1]\n            X = np.zeros((2, NN, u.shape[1]), 'float64')\n            for j in range(2):\n                Xall[j] -= Xall[j].mean(axis=-1)[:, np.newaxis]\n                X[j] = Xall[j] @ self.v\n\n        utu = np.sum(u**2, axis=1)\n        ikeep = np.argmax(utu)\n        #ikeep = int(NN/2)\n        #ikeep = np.random.randint(0, NN)\n        ccu = u @ u[ikeep,:]\n        cmax = np.maximum(0, ccu)**2/utu\n        ikeep = np.argsort(cmax)[::-1]\n        ikeep = ikeep[:int(NN/10)]\n        ikeep = np.sort(ikeep)\n\n        if self.init == 'pca':\n            U = svdecon(u[ikeep,:], k=2)[0]\n            #U = u[ikeep, :2]\n            usort = U * np.sign(skew(U, axis=0))\n            init_sort = np.argsort(usort[:, :self.n_components], axis=0)\n        elif self.init == 'random':\n            init_sort = np.random.permutation(len(ikeep))[:,np.newaxis]\n            for j in range(1,self.n_components):\n                init_sort = np.concatenate((init_sort, np.random.permutation(len(ikeep))[:,np.newaxis]), axis=-1)\n        else:\n            init_sort = self.init\n        if self.n_components==1 and init_sort.ndim==1:\n            init_sort = init_sort[:,np.newaxis]\n\n        # now sort in X\n        isort1, iclustup = self._map(u.copy(), self.n_components, self.n_X, init_sort, ikeep,  s)\n        self.isort = isort1\n        self.embedding = iclustup\n        return self", "response": "Fit X into an embedded space."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot_clicked(self, event):\n        flip = False\n        choose = False\n        zoom = False\n        replot = False\n        items = self.win.scene().items(event.scenePos())\n        posx = 0\n        posy = 0\n        iplot = 0\n        if self.loaded:\n            # print(event.modifiers() == QtCore.Qt.ControlModifier)\n            for x in items:\n                if x == self.p0:\n                    if self.embedded:\n                        iplot = 0\n                        vb = self.p0.vb\n                        pos = vb.mapSceneToView(event.scenePos())\n                        x = pos.x()\n                        y = pos.y()\n                        if event.double():\n                            self.zoom_plot(iplot)\n                        elif event.button() == 2:\n                            # do nothing\n                            nothing = True\n                        elif event.modifiers() == QtCore.Qt.ShiftModifier:\n                            if not self.startROI:\n                                self.startROI = True\n                                self.endROI = False\n                                self.posROI[0,:] = [x,y]\n                            else:\n                                # plotting\n                                self.startROI = True\n                                self.endROI = False\n                                self.posROI[1,:] = [x,y]\n                                #print(self.)\n                                self.posAll.append(self.posROI[:2,:].copy())\n                                pos = self.posAll[-1]\n                                self.lp.append(pg.PlotDataItem(pos[:, 0], pos[:, 1]))\n                                self.posROI[0,:] = [x,y]\n                                self.p0.addItem(self.lp[-1])\n                                self.p0.show()\n                        elif self.startROI:\n                            self.posROI[1,:] = [x,y]\n                            self.posAll.append(self.posROI[:2,:].copy())\n                            self.p0.removeItem(self.l0)\n                            pos = self.posAll[-1]\n                            self.lp.append(pg.PlotDataItem(pos[:, 0], pos[:, 1]))\n                            self.p0.addItem(self.lp[-1])\n                            self.p0.show()\n                            self.endROI = True\n                            self.startROI = False\n                        elif self.endROI:\n                            self.posROI[2,:] = [x,y]\n                            self.endROI = False\n                            for lp in self.lp:\n                                self.p0.removeItem(lp)\n                            self.ROI_add(self.posAll, self.prect)\n                            self.posAll = []\n                            self.lp = []\n\n                        elif event.modifiers() == QtCore.Qt.AltModifier:\n                            self.ROI_remove([x,y])\n\n                elif x == self.p1:\n                    iplot = 1\n                    y = self.p1.vb.mapSceneToView(event.scenePos()).y()\n                    ineur = min(self.colormat.shape[0]-1, max(0, int(np.floor(y))))\n                    ineur = ineur + self.yrange[0]\n                    if event.double():\n                        self.zoom_plot(iplot)\n                    elif event.modifiers() == QtCore.Qt.AltModifier:\n                        self.ROI_remove([ineur])\n                elif x == self.p3:\n                    iplot = 2\n                    y = self.p3.vb.mapSceneToView(event.scenePos()).y()\n                    ineur = min(self.colormat.shape[0]-1, max(0, int(np.floor(y))))\n                    if event.modifiers() == QtCore.Qt.AltModifier:\n                        self.ROI_remove([ineur])", "response": "left - click chooses a cell right - click flips cell to other view"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a Deferred that fires with an object that implements the Tor s IAgent interface.", "response": "def tor_agent(reactor, socks_endpoint, circuit=None, pool=None):\n    \"\"\"\n    This is the low-level method used by\n    :meth:`txtorcon.Tor.web_agent` and\n    :meth:`txtorcon.Circuit.web_agent` -- probably you should call one\n    of those instead.\n\n    :returns: a Deferred that fires with an object that implements\n        :class:`twisted.web.iweb.IAgent` and is thus suitable for passing\n        to ``treq`` as the ``agent=`` kwarg. Of course can be used\n        directly; see `using Twisted web cliet\n        <http://twistedmatrix.com/documents/current/web/howto/client.html>`_.\n\n    :param reactor: the reactor to use\n\n    :param circuit: If supplied, a particular circuit to use\n\n    :param socks_endpoint: Deferred that fires w/\n        IStreamClientEndpoint (or IStreamClientEndpoint instance)\n        which points at a SOCKS5 port of our Tor\n\n    :param pool: passed on to the Agent (as ``pool=``)\n    \"\"\"\n\n    if socks_endpoint is None:\n        raise ValueError(\n            \"Must provide socks_endpoint as Deferred or IStreamClientEndpoint\"\n        )\n    if circuit is not None:\n        factory = _AgentEndpointFactoryForCircuit(reactor, socks_endpoint, circuit)\n    else:\n        factory = _AgentEndpointFactoryUsingTor(reactor, socks_endpoint)\n    return Agent.usingEndpointFactory(reactor, factory, pool=pool)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noverriding nevow method to save ctx and client in self for multiple clients but not really safe to just save client in self for multiple clients.", "response": "def goingLive(self, ctx, client):\n        '''\n        Overrides nevow method; not really safe to just save ctx,\n        client in self for multiple clients, but nice and simple.\n        '''\n\n        self.ctx = ctx\n        self.client = client"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_tor_connection(connection, build_state=True, wait_for_proto=True,\n                         password_function=lambda: None):\n    \"\"\"\n    This is used to build a valid TorState (which has .protocol for\n    the TorControlProtocol). For example::\n\n        from twisted.internet import reactor\n        from twisted.internet.endpoints import TCP4ClientEndpoint\n        import txtorcon\n\n        def example(state):\n            print \"Fully bootstrapped state:\",state\n            print \"   with bootstrapped protocol:\",state.protocol\n\n        d = txtorcon.build_tor_connection(TCP4ClientEndpoint(reactor,\n                                                             \"localhost\",\n                                                             9051))\n        d.addCallback(example)\n        reactor.run()\n\n    :param password_function:\n        See :class:`txtorcon.TorControlProtocol`\n\n    :param build_state:\n        If True (the default) a TorState object will be\n        built as well. If False, just a TorControlProtocol will be\n        returned via the Deferred.\n\n    :return:\n        a Deferred that fires with a TorControlProtocol or, if you\n        specified build_state=True, a TorState. In both cases, the\n        object has finished bootstrapping\n        (i.e. TorControlProtocol.post_bootstrap or\n        TorState.post_bootstap has fired, as needed)\n    \"\"\"\n\n    if IStreamClientEndpoint.providedBy(connection):\n        endpoint = connection\n\n    elif isinstance(connection, tuple):\n        if len(connection) == 2:\n            reactor, socket = connection\n            if (os.path.exists(socket) and\n                os.stat(socket).st_mode & (stat.S_IRGRP | stat.S_IRUSR |\n                                           stat.S_IROTH)):\n                endpoint = UNIXClientEndpoint(reactor, socket)\n            else:\n                raise ValueError('Can\\'t use \"%s\" as a socket' % (socket, ))\n        elif len(connection) == 3:\n            endpoint = TCP4ClientEndpoint(*connection)\n        else:\n            raise TypeError('Expected either a (reactor, socket)- or a '\n                            '(reactor, host, port)-tuple for argument '\n                            '\"connection\", got %s' % (connection, ))\n    else:\n        raise TypeError('Expected a (reactor, socket)- or a (reactor, host, '\n                        'port)-tuple or an object implementing IStreamClient'\n                        'Endpoint for argument \"connection\", got %s' %\n                        (connection, ))\n\n    d = endpoint.connect(\n        TorProtocolFactory(\n            password_function=password_function\n        )\n    )\n    if build_state:\n        d.addCallback(build_state\n                      if isinstance(build_state, collections.Callable)\n                      else _build_state)\n    elif wait_for_proto:\n        d.addCallback(wait_for_proto\n                      if isinstance(wait_for_proto, collections.Callable)\n                      else _wait_for_proto)\n    return d", "response": "Build a TorState object from a connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef flags_from_dict(kw):\n\n    if len(kw) == 0:\n        return ''\n\n    flags = ''\n    for (k, v) in kw.items():\n        if v:\n            flags += ' ' + str(k)\n    # note that we want the leading space if there's at least one\n    # flag.\n    return flags", "response": "Converts a dict with keys that are flags and values that are true."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_keywords(lines, multiline_values=True, key_hints=None):\n\n    rtn = {}\n    key = None\n    value = ''\n    # FIXME could use some refactoring to reduce code duplication!\n    for line in lines.split('\\n'):\n        if line.strip() == 'OK':\n            continue\n\n        sp = line.split('=', 1)\n        found_key = ('=' in line and ' ' not in sp[0])\n        if found_key and key_hints and sp[0] not in key_hints:\n            found_key = False\n        if found_key:\n            if key:\n                if key in rtn:\n                    if isinstance(rtn[key], list):\n                        rtn[key].append(unquote(value))\n                    else:\n                        rtn[key] = [rtn[key], unquote(value)]\n                else:\n                    rtn[key] = unquote(value)\n            (key, value) = line.split('=', 1)\n\n        else:\n            if key is None:\n                rtn[line.strip()] = DEFAULT_VALUE\n\n            elif multiline_values is False:\n                rtn[key] = value\n                rtn[line.strip()] = DEFAULT_VALUE\n                key = None\n                value = ''\n\n            else:\n                value = value + '\\n' + line\n    if key:\n        if key in rtn:\n            if isinstance(rtn[key], list):\n                rtn[key].append(unquote(value))\n            else:\n                rtn[key] = [rtn[key], unquote(value)]\n        else:\n            rtn[key] = unquote(value)\n    return rtn", "response": "Utility method to parse keywords from a string with newline - separated lines and returns a dictionary with the keys and values."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _router_address(self, data):\n        args = data.split()[1:]\n        try:\n            self._relay_attrs['ip_v6'].extend(args)\n        except KeyError:\n            self._relay_attrs['ip_v6'] = list(args)", "response": "only for IPv6 addresses"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef listen(self, listen):\n\n        listener = IStreamListener(listen)\n        if listener not in self.listeners:\n            self.listeners.append(listener)", "response": "Add an IStreamListener to this stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef close(self, **kw):\n\n        self._closing_deferred = defer.Deferred()\n\n        def close_command_is_queued(*args):\n            return self._closing_deferred\n        d = self.circuit_container.close_stream(self, **kw)\n        d.addCallback(close_command_is_queued)\n        return self._closing_deferred", "response": "This method closes the underlying stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _create_flags(self, kw):\n\n        flags = {}\n        for k in kw.keys():\n            flags[k] = kw[k]\n            flags[k.lower()] = flags[k]\n        return flags", "response": "Create a dictionary of all the keys that are not in kw"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _notify(self, func, *args, **kw):\n        for x in self.listeners:\n            try:\n                getattr(x, func)(*args, **kw)\n            except Exception:\n                log.err()", "response": "Internal helper. Calls the given function with the given args guarding around errors."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef maybe_call_closing_deferred(self):\n\n        if self._closing_deferred:\n            self._closing_deferred.callback(self)\n            self._closing_deferred = None", "response": "Called by the _closing_deferred callback if it exists."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a new circuit within a timeout.", "response": "def build_timeout_circuit(tor_state, reactor, path, timeout, using_guards=False):\n    \"\"\"\n    Build a new circuit within a timeout.\n\n    CircuitBuildTimedOutError will be raised unless we receive a\n    circuit build result (success or failure) within the `timeout`\n    duration.\n\n    :returns: a Deferred which fires when the circuit build succeeds (or\n        fails to build).\n    \"\"\"\n    timed_circuit = []\n    d = tor_state.build_circuit(routers=path, using_guards=using_guards)\n\n    def get_circuit(c):\n        timed_circuit.append(c)\n        return c\n\n    def trap_cancel(f):\n        f.trap(defer.CancelledError)\n        if timed_circuit:\n            d2 = timed_circuit[0].close()\n        else:\n            d2 = defer.succeed(None)\n        d2.addCallback(lambda _: Failure(CircuitBuildTimedOutError(\"circuit build timed out\")))\n        return d2\n\n    d.addCallback(get_circuit)\n    d.addCallback(lambda circ: circ.when_built())\n    d.addErrback(trap_cancel)\n\n    reactor.callLater(timeout, d.cancel)\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef when_built(self):\n        # XXX note to self: we never do an errback; fix this behavior\n        if self.state == 'BUILT':\n            return defer.succeed(self)\n        return self._when_built.when_fired()", "response": "Returns a Deferred that is callback()'d when this circuit hits a BUILT."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef when_closed(self):\n        if self.state in ['CLOSED', 'FAILED']:\n            return defer.succeed(self)\n        return self._when_closed.when_fired()", "response": "Returns a Deferred that resolves with this Circuit instance when it hits CLOSED or FAILED."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new Tor Agent", "response": "def web_agent(self, reactor, socks_endpoint, pool=None):\n        \"\"\"\n        :param socks_endpoint: create one with\n            :meth:`txtorcon.TorConfig.create_socks_endpoint`. Can be a\n            Deferred.\n\n        :param pool: passed on to the Agent (as ``pool=``)\n        \"\"\"\n        # local import because there isn't Agent stuff on some\n        # platforms we support, so this will only error if you try\n        # this on the wrong platform (pypy [??] and old-twisted)\n        from txtorcon import web\n        return web.tor_agent(\n            reactor,\n            socks_endpoint,\n            circuit=self,\n            pool=pool,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an integer which is the difference in seconds from the time_created to when this circuit was created.", "response": "def age(self, now=None):\n        \"\"\"\n        Returns an integer which is the difference in seconds from\n        'now' to when this circuit was created.\n\n        Returns None if there is no created-time.\n        \"\"\"\n        if not self.time_created:\n            return None\n        if now is None:\n            now = datetime.utcnow()\n        return (now - self.time_created).seconds"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls by the _closing_deferred callback when the _closing_deferred is set to None.", "response": "def maybe_call_closing_deferred(self):\n        \"\"\"\n        Used internally to callback on the _closing_deferred if it\n        exists.\n        \"\"\"\n\n        if self._closing_deferred:\n            self._closing_deferred.callback(self)\n            self._closing_deferred = None\n        self._when_closed.fire(self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resolve(tor_endpoint, hostname):\n    if six.PY2 and isinstance(hostname, str):\n        hostname = unicode(hostname)  # noqa\n    elif six.PY3 and isinstance(hostname, bytes):\n        hostname = hostname.decode('ascii')\n    factory = _TorSocksFactory(\n        hostname, 0, 'RESOLVE', None,\n    )\n    proto = yield tor_endpoint.connect(factory)\n    result = yield proto.when_done()\n    returnValue(result)", "response": "Resolve a hostname on a Tor SOCKS endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_data(self, callback):\n        # a \"for x in self._outgoing_data\" would potentially be more\n        # efficient, but then there's no good way to bubble exceptions\n        # from callback() out without lying about how much data we\n        # processed .. or eat the exceptions in here.\n        while len(self._outgoing_data):\n            data = self._outgoing_data.pop(0)\n            callback(data)", "response": "Send all pending data to the callback."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_version_reply(self):\n        \"waiting for a version reply\"\n        if len(self._data) >= 2:\n            reply = self._data[:2]\n            self._data = self._data[2:]\n            (version, method) = struct.unpack('BB', reply)\n            if version == 5 and method in [0x00, 0x02]:\n                self.version_reply(method)\n            else:\n                if version != 5:\n                    self.version_error(SocksError(\n                        \"Expected version 5, got {}\".format(version)))\n                else:\n                    self.version_error(SocksError(\n                        \"Wanted method 0 or 2, got {}\".format(method)))", "response": "waiting for a version reply"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_request_reply(self):\n        \"waiting for a reply to our request\"\n        # we need at least 6 bytes of data: 4 for the \"header\", such\n        # as it is, and 2 more if it's DOMAINNAME (for the size) or 4\n        # or 16 more if it's an IPv4/6 address reply. plus there's 2\n        # bytes on the end for the bound port.\n        if len(self._data) < 8:\n            return\n        msg = self._data[:4]\n\n        # not changing self._data yet, in case we've not got\n        # enough bytes so far.\n        (version, reply, _, typ) = struct.unpack('BBBB', msg)\n\n        if version != 5:\n            self.reply_error(SocksError(\n                \"Expected version 5, got {}\".format(version)))\n            return\n\n        if reply != self.SUCCEEDED:\n            self.reply_error(_create_socks_error(reply))\n            return\n\n        reply_dispatcher = {\n            self.REPLY_IPV4: self._parse_ipv4_reply,\n            self.REPLY_HOST: self._parse_domain_name_reply,\n            self.REPLY_IPV6: self._parse_ipv6_reply,\n        }\n        try:\n            method = reply_dispatcher[typ]\n        except KeyError:\n            self.reply_error(SocksError(\n                \"Unexpected response type {}\".format(typ)))\n            return\n        method()", "response": "waiting for a reply to our request"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _make_connection(self, addr, port):\n        \"make our proxy connection\"\n        sender = self._create_connection(addr, port)\n        # XXX look out! we're depending on this \"sender\" implementing\n        # certain Twisted APIs, and the state-machine shouldn't depend\n        # on that.\n\n        # XXX also, if sender implements producer/consumer stuff, we\n        # should register ourselves (and implement it to) -- but this\n        # should really be taking place outside the state-machine in\n        # \"the I/O-doing\" stuff\n        self._sender = sender\n        self._when_done.fire(sender)", "response": "make our proxy connection"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling when the connection is lost.", "response": "def _disconnect(self, error):\n        \"done\"\n        if self._on_disconnect:\n            self._on_disconnect(str(error))\n        if self._sender:\n            self._sender.connectionLost(Failure(error))\n        self._when_done.fire(Failure(error))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrelays any data we have", "response": "def _relay_data(self):\n        \"relay any data we have\"\n        if self._data:\n            d = self._data\n            self._data = b''\n            # XXX this is \"doing I/O\" in the state-machine and it\n            # really shouldn't be ... probably want a passed-in\n            # \"relay_data\" callback or similar?\n            self._sender.dataReceived(d)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend RESOLVE_PTR request ( Tor custom", "response": "def _send_resolve_request(self):\n        \"sends RESOLVE_PTR request (Tor custom)\"\n        host = self._addr.host.encode()\n        self._data_to_send(\n            struct.pack(\n                '!BBBBB{}sH'.format(len(host)),\n                5,                   # version\n                0xF0,                # command\n                0x00,                # reserved\n                0x03,                # DOMAINNAME\n                len(host),\n                host,\n                0,  # self._addr.port?\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _send_resolve_ptr_request(self):\n        \"sends RESOLVE_PTR request (Tor custom)\"\n        addr_type = 0x04 if isinstance(self._addr, ipaddress.IPv4Address) else 0x01\n        encoded_host = inet_aton(self._addr.host)\n        self._data_to_send(\n            struct.pack(\n                '!BBBB4sH',\n                5,                   # version\n                0xF1,                # command\n                0x00,                # reserved\n                addr_type,\n                encoded_host,\n                0,                   # port; unused? SOCKS is fun\n            )\n        )", "response": "sends RESOLVE_PTR request ( Tor custom"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef modified(self):\n        # \"... in the form YYYY-MM-DD HH:MM:SS, in UTC\"\n        if self._modified is None:\n            self._modified = datetime.strptime(\n                self._modified_unparsed,\n                '%Y-%m-%d %H:%M:%S'\n            )\n        return self._modified", "response": "Returns the modified date of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a Deferred that fires with a NetLocation object for this object.", "response": "def get_location(self):\n        \"\"\"\n        Returns a Deferred that fires with a NetLocation object for this\n        router.\n        \"\"\"\n        if self._location:\n            return succeed(self._location)\n        if self.ip != 'unknown':\n            self._location = NetLocation(self.ip)\n        else:\n            self._location = NetLocation(None)\n        if not self._location.countrycode and self.ip != 'unknown':\n            # see if Tor is magic and knows more...\n            d = self.controller.get_info_raw('ip-to-country/' + self.ip)\n            d.addCallback(self._set_country)\n            d.addCallback(lambda _: self._location)\n            return d\n        return succeed(self._location)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef location(self):\n        if self._location:\n            return self._location\n\n        if self.ip != 'unknown':\n            self._location = NetLocation(self.ip)\n        else:\n            self._location = NetLocation(None)\n        if not self._location.countrycode and self.ip != 'unknown':\n            # see if Tor is magic and knows more...\n            d = self.controller.get_info_raw('ip-to-country/' + self.ip)\n            d.addCallback(self._set_country)\n            # ignore errors (e.g. \"GeoIP Information not loaded\")\n            d.addErrback(lambda _: None)\n        return self._location", "response": "Returns a NetLocation instance with some GeoIP or pygeoip information about location asn city."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the flags of the current object.", "response": "def flags(self, flags):\n        \"\"\"\n        It might be nice to make flags not a list of strings. This is\n        made harder by the control-spec: `...controllers MUST tolerate\n        unrecognized flags and lines...`\n\n        There is some current work in Twisted for open-ended constants\n        (enums) support however, it seems.\n        \"\"\"\n        if isinstance(flags, (six.text_type, bytes)):\n            flags = flags.split()\n        self._flags = [x.lower() for x in flags]\n        self.name_is_unique = 'named' in self._flags"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting details document from onionoo. torproject. org via the given IAgent.", "response": "def get_onionoo_details(self, agent):\n        \"\"\"\n        Requests the 'details' document from onionoo.torproject.org via\n        the given `twisted.web.iweb.IAgent` -- you can get a suitable\n        instance to pass here by calling either :meth:`txtorcon.Tor.web_agent` or\n        :meth:`txtorcon.Circuit.web_agent`.\n        \"\"\"\n\n        # clearnet: 'https://onionoo.torproject.org/details?lookup={}'\n        uri = 'http://tgel7v4rpcllsrk2.onion/details?lookup={}'.format(self.id_hex[1:]).encode('ascii')\n\n        resp = yield agent.request(b'GET', uri)\n        if resp.code != 200:\n            raise RuntimeError(\n                'Failed to lookup relay details for {}'.format(self.id_hex)\n            )\n        body = yield readBody(resp)\n        data = json.loads(body.decode('ascii'))\n        if len(data['relays']) != 1:\n            raise RuntimeError(\n                'Got multiple relays for {}'.format(self.id_hex)\n            )\n        relay_data = data['relays'][0]\n        if relay_data['fingerprint'].lower() != self.id_hex[1:].lower():\n            raise RuntimeError(\n                'Expected \"{}\" but got data for \"{}\"'.format(self.id_hex, relay_data['fingerprint'])\n            )\n        returnValue(relay_data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a string describing the port policies for this Router.", "response": "def policy(self):\n        \"\"\"\n        Port policies for this Router.\n        :return: a string describing the policy\n        \"\"\"\n        if self.accepted_ports:\n            return 'accept ' + ','.join(map(str, self.accepted_ports))\n        elif self.rejected_ports:\n            return 'reject ' + ','.join(map(str, self.rejected_ports))\n        else:\n            return ''"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef policy(self, args):\n\n        word = args[0]\n        if word == 'reject':\n            self.accepted_ports = None\n            self.rejected_ports = []\n            target = self.rejected_ports\n\n        elif word == 'accept':\n            self.accepted_ports = []\n            self.rejected_ports = None\n            target = self.accepted_ports\n\n        else:\n            raise RuntimeError(\"Don't understand policy word \\\"%s\\\"\" % word)\n\n        for port in args[1].split(','):\n            if '-' in port:\n                (a, b) = port.split('-')\n                target.append(PortRange(int(a), int(b)))\n            else:\n                target.append(int(port))", "response": "setter for the policy descriptor\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef accepts_port(self, port):\n\n        if self.rejected_ports is None and self.accepted_ports is None:\n            raise RuntimeError(\"policy hasn't been set yet\")\n\n        if self.rejected_ports:\n            for x in self.rejected_ports:\n                if port == x:\n                    return False\n            return True\n\n        for x in self.accepted_ports:\n            if port == x:\n                return True\n        return False", "response": "Query whether this Router will accept the given port."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the country code of the Tor location", "response": "def _set_country(self, c):\n        \"\"\"\n        callback if we used Tor's GETINFO ip-to-country\n        \"\"\"\n\n        self.location.countrycode = c.split()[0].split('=')[1].strip().upper()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a Tor instance for this Python process.", "response": "def get_global_tor_instance(reactor,\n                            control_port=None,\n                            progress_updates=None,\n                            _tor_launcher=None):\n    \"\"\"\n    Normal users shouldn't need to call this; use\n    TCPHiddenServiceEndpoint::system_tor instead.\n\n    :return Tor: a 'global to this Python process' instance of\n        Tor. There isn't one of these until the first time this method\n        is called. All calls to this method return the same instance.\n    \"\"\"\n    global _global_tor\n    global _global_tor_lock\n    yield _global_tor_lock.acquire()\n\n    if _tor_launcher is None:\n        # XXX :( mutual dependencies...really get_global_tor_instance\n        # should be in controller.py if it's going to return a Tor\n        # instance.\n        from .controller import launch\n        _tor_launcher = launch\n\n    try:\n        if _global_tor is None:\n            _global_tor = yield _tor_launcher(reactor, progress_updates=progress_updates)\n\n        else:\n            config = yield _global_tor.get_config()\n            already_port = config.ControlPort\n            if control_port is not None and control_port != already_port:\n                raise RuntimeError(\n                    \"ControlPort is already '{}', but you wanted '{}'\",\n                    already_port,\n                    control_port,\n                )\n\n        defer.returnValue(_global_tor)\n    finally:\n        _global_tor_lock.release()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_global_tor(reactor, control_port=None,\n                   progress_updates=None,\n                   _tor_launcher=None):\n    \"\"\"\n    See description of :class:`txtorcon.TCPHiddenServiceEndpoint`'s\n    class-method ``global_tor``\n\n    :param control_port:\n        a TCP port upon which to run the launched Tor's\n        control-protocol (selected by the OS by default).\n\n    :param progress_updates:\n        A callable that takes 3 args: ``percent, tag, message`` which\n        is called when Tor announcing some progress setting itself up.\n\n    :returns:\n        a ``Deferred`` that fires a :class:`txtorcon.TorConfig` which is\n        bootstrapped.\n\n    The _tor_launcher keyword arg is internal-only.\n    \"\"\"\n    tor = yield get_global_tor_instance(\n        reactor,\n        control_port=control_port,\n        progress_updates=progress_updates,\n        _tor_launcher=_tor_launcher,\n    )\n    cfg = yield tor.get_config()\n    defer.returnValue(cfg)", "response": "Returns a TorConfig object that is a singleton of the Tor."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _load_private_key_file(fname):\n    with open(fname, \"rb\") as f:\n        data = f.read()\n    if b\"\\x00\\x00\\x00\" in data:  # v3 private key file\n        blob = data[data.find(b\"\\x00\\x00\\x00\") + 3:]\n        return u\"ED25519-V3:{}\".format(b2a_base64(blob.strip()).decode('ascii').strip())\n    if b\"-----BEGIN RSA PRIVATE KEY-----\" in data:  # v2 RSA key\n        blob = \"\".join(data.decode('ascii').split('\\n')[1:-2])\n        return u\"RSA1024:{}\".format(blob)\n    blob = data.decode('ascii').strip()\n    if ':' in blob:\n        kind, key = blob.split(':', 1)\n        if kind in ['ED25519-V3', 'RSA1024']:\n            return blob\n    raise ValueError(\n        \"'{}' does not appear to contain v2 or v3 private key data\".format(\n            fname,\n        )\n    )", "response": "Loads an onion - service private key from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _maybe_unique_host(onion):\n    hosts = [\n        onion.get_client(nm).hostname\n        for nm in onion.client_names()\n    ]\n    if not hosts:\n        raise ValueError(\n            \"Can't access .onion_uri because there are no clients\"\n        )\n    host = hosts[0]\n    for h in hosts[1:]:\n        if h != host:\n            raise ValueError(\n                \"Cannot access .onion_uri for stealth-authenticated services \"\n                \"because each client has a unique URI\"\n            )\n    return host", "response": "Returns a. onion hostname if all clients have the same name or raises ValueError otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef launch_tor(config, reactor,\n               tor_binary=None,\n               progress_updates=None,\n               connection_creator=None,\n               timeout=None,\n               kill_on_stderr=True,\n               stdout=None, stderr=None):\n    \"\"\"\n    Deprecated; use launch() instead.\n\n    See also controller.py\n    \"\"\"\n    from .controller import launch\n    # XXX FIXME are we dealing with options in the config \"properly\"\n    # as far as translating semantics from the old launch_tor to\n    # launch()? DataDirectory, User, ControlPort, ...?\n    tor = yield launch(\n        reactor,\n        stdout=stdout,\n        stderr=stderr,\n        progress_updates=progress_updates,\n        tor_binary=tor_binary,\n        connection_creator=connection_creator,\n        timeout=timeout,\n        kill_on_stderr=kill_on_stderr,\n        _tor_config=config,\n    )\n    defer.returnValue(tor.process)", "response": "Launch a TOR process."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new method that wraps orig (the original method) with something that first calls on_modify from the instance. _ListWrapper uses this to wrap all methods that modify the list.", "response": "def _wrapture(orig):\n    \"\"\"\n    Returns a new method that wraps orig (the original method) with\n    something that first calls on_modify from the\n    instance. _ListWrapper uses this to wrap all methods that modify\n    the list.\n    \"\"\"\n\n#    @functools.wraps(orig)\n    def foo(*args):\n        obj = args[0]\n        obj.on_modify()\n        return orig(*args)\n    return foo"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an IStreamClientEndpoint for the given SOCKSPort line.", "response": "def _endpoint_from_socksport_line(reactor, socks_config):\n    \"\"\"\n    Internal helper.\n\n    Returns an IStreamClientEndpoint for the given config, which is of\n    the same format expected by the SOCKSPort option in Tor.\n    \"\"\"\n    if socks_config.startswith('unix:'):\n        # XXX wait, can SOCKSPort lines with \"unix:/path\" still\n        # include options afterwards? What about if the path has a\n        # space in it?\n        return UNIXClientEndpoint(reactor, socks_config[5:])\n\n    # options like KeepAliveIsolateSOCKSAuth can be appended\n    # to a SocksPort line...\n    if ' ' in socks_config:\n        socks_config = socks_config.split()[0]\n    if ':' in socks_config:\n        host, port = socks_config.split(':', 1)\n        port = int(port)\n    else:\n        host = '127.0.0.1'\n        port = int(socks_config)\n    return TCP4ClientEndpoint(reactor, host, port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef config_attributes(self):\n\n        rtn = [('HiddenServiceDir', str(self.dir))]\n        if self.conf._supports['HiddenServiceDirGroupReadable'] \\\n           and self.group_readable:\n            rtn.append(('HiddenServiceDirGroupReadable', str(1)))\n        for port in self.ports:\n            rtn.append(('HiddenServicePort', str(port)))\n        if self.version:\n            rtn.append(('HiddenServiceVersion', str(self.version)))\n        for authline in self.authorize_client:\n            rtn.append(('HiddenServiceAuthorizeClient', str(authline)))\n        return rtn", "response": "Returns a list of the attributes that are used by TorConfig when generating a torrc file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_to_tor(self, protocol):\n        '''\n        Returns a Deferred which fires with 'self' after at least one\n        descriptor has been uploaded. Errback if no descriptor upload\n        succeeds.\n        '''\n\n        upload_d = _await_descriptor_upload(protocol, self, progress=None, await_all_uploads=False)\n\n        # _add_ephemeral_service takes a TorConfig but we don't have\n        # that here ..  and also we're just keeping this for\n        # backwards-compatability anyway so instead of trying to\n        # re-use that helper I'm leaving this original code here. So\n        # this is what it supports and that's that:\n        ports = ' '.join(map(lambda x: 'Port=' + x.strip(), self._ports))\n        cmd = 'ADD_ONION %s %s' % (self._key_blob, ports)\n        ans = yield protocol.queue_command(cmd)\n        ans = find_keywords(ans.split('\\n'))\n        self.hostname = ans['ServiceID'] + '.onion'\n        if self._key_blob.startswith('NEW:'):\n            self.private_key = ans['PrivateKey']\n        else:\n            self.private_key = self._key_blob\n\n        log.msg('Created hidden-service at', self.hostname)\n\n        log.msg(\"Created '{}', waiting for descriptor uploads.\".format(self.hostname))\n        yield upload_d", "response": "Add this service to the Tor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving the hidden service from Tor.", "response": "def remove_from_tor(self, protocol):\n        '''\n        Returns a Deferred which fires with None\n        '''\n        r = yield protocol.queue_command('DEL_ONION %s' % self.hostname[:-6])\n        if r.strip() != 'OK':\n            raise RuntimeError('Failed to remove hidden service: \"%s\".' % r)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef socks_endpoint(self, reactor, port=None):\n\n        if len(self.SocksPort) == 0:\n            raise RuntimeError(\n                \"No SOCKS ports configured\"\n            )\n\n        socks_config = None\n        if port is None:\n            socks_config = self.SocksPort[0]\n        else:\n            port = str(port)  # in case e.g. an int passed in\n            if ' ' in port:\n                raise ValueError(\n                    \"Can't specify options; use create_socks_endpoint instead\"\n                )\n\n            for idx, port_config in enumerate(self.SocksPort):\n                # \"SOCKSPort\" is a gnarly beast that can have a bunch\n                # of options appended, so we have to split off the\n                # first thing which *should* be the port (or can be a\n                # string like 'unix:')\n                if port_config.split()[0] == port:\n                    socks_config = port_config\n                    break\n        if socks_config is None:\n            raise RuntimeError(\n                \"No SOCKSPort configured for port {}\".format(port)\n            )\n\n        return _endpoint_from_socksport_line(reactor, socks_config)", "response": "Returns a TorSocksEndpoint configured to use an already - configured SOCKSPort."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new TorSocksEndpoint instance given a valid configuration line for ``SocksPort``; if this configuration isn't already in the underlying tor, we add it. Note that this method may call :meth:`txtorcon.TorConfig.save()` on this instance. Note that calling this with `socks_config=None` is equivalent to calling `.socks_endpoint` (which is not async). XXX socks_config should be .. i dunno, but there's fucking options and craziness, e.g. default Tor Browser Bundle is: ['9150 IPv6Traffic PreferIPv6 KeepAliveIsolateSOCKSAuth', '9155'] XXX maybe we should say \"socks_port\" as the 3rd arg, insist it's an int, and then allow/support all the other options (e.g. via kwargs) XXX we could avoid the \"maybe call .save()\" thing; worth it? (actually, no we can't or the Tor won't have it config'd)", "response": "def create_socks_endpoint(self, reactor, socks_config):\n        \"\"\"\n        Creates a new TorSocksEndpoint instance given a valid\n        configuration line for ``SocksPort``; if this configuration\n        isn't already in the underlying tor, we add it. Note that this\n        method may call :meth:`txtorcon.TorConfig.save()` on this instance.\n\n        Note that calling this with `socks_config=None` is equivalent\n        to calling `.socks_endpoint` (which is not async).\n\n        XXX socks_config should be .. i dunno, but there's fucking\n        options and craziness, e.g. default Tor Browser Bundle is:\n        ['9150 IPv6Traffic PreferIPv6 KeepAliveIsolateSOCKSAuth',\n        '9155']\n\n        XXX maybe we should say \"socks_port\" as the 3rd arg, insist\n        it's an int, and then allow/support all the other options\n        (e.g. via kwargs)\n\n        XXX we could avoid the \"maybe call .save()\" thing; worth it?\n        (actually, no we can't or the Tor won't have it config'd)\n        \"\"\"\n\n        yield self.post_bootstrap\n\n        if socks_config is None:\n            if len(self.SocksPort) == 0:\n                raise RuntimeError(\n                    \"socks_port is None and Tor has no SocksPorts configured\"\n                )\n            socks_config = self.SocksPort[0]\n        else:\n            if not any([socks_config in port for port in self.SocksPort]):\n                # need to configure Tor\n                self.SocksPort.append(socks_config)\n                try:\n                    yield self.save()\n                except TorProtocolError as e:\n                    extra = ''\n                    if socks_config.startswith('unix:'):\n                        # XXX so why don't we check this for the\n                        # caller, earlier on?\n                        extra = '\\nNote Tor has specific ownership/permissions ' +\\\n                                'requirements for unix sockets and parent dir.'\n                    raise RuntimeError(\n                        \"While configuring SOCKSPort to '{}', error from\"\n                        \" Tor: {}{}\".format(\n                            socks_config, e, extra\n                        )\n                    )\n\n        defer.returnValue(\n            _endpoint_from_socksport_line(reactor, socks_config)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nattach a protocol to this object.", "response": "def attach_protocol(self, proto):\n        \"\"\"\n        returns a Deferred that fires once we've set this object up to\n        track the protocol. Fails if we already have a protocol.\n        \"\"\"\n        if self._protocol is not None:\n            raise RuntimeError(\"Already have a protocol.\")\n        # make sure we have nothing in self.unsaved\n        self.save()\n        self.__dict__['_protocol'] = proto\n\n        # FIXME some of this is duplicated from ctor\n        del self.__dict__['_accept_all_']\n        self.__dict__['post_bootstrap'] = defer.Deferred()\n        if proto.post_bootstrap:\n            proto.post_bootstrap.addCallback(self.bootstrap)\n        return self.__dict__['post_bootstrap']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the type of a config key", "response": "def get_type(self, name):\n        \"\"\"\n        return the type of a config key.\n\n        :param: name the key\n\n        FIXME can we do something more-clever than this for client\n        code to determine what sort of thing a key is?\n        \"\"\"\n\n        # XXX FIXME uhm...how to do all the different types of hidden-services?\n        if name.lower() == 'hiddenservices':\n            return FilesystemOnionService\n        return type(self.parsers[name])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bootstrap(self, arg=None):\n        '''\n        This only takes args so it can be used as a callback. Don't\n        pass an arg, it is ignored.\n        '''\n        try:\n            d = self.protocol.add_event_listener(\n                'CONF_CHANGED', self._conf_changed)\n        except RuntimeError:\n            # for Tor versions which don't understand CONF_CHANGED\n            # there's nothing we can really do.\n            log.msg(\n                \"Can't listen for CONF_CHANGED event; won't stay up-to-date \"\n                \"with other clients.\")\n            d = defer.succeed(None)\n        d.addCallback(lambda _: self.protocol.get_info_raw(\"config/names\"))\n        d.addCallback(self._do_setup)\n        d.addCallback(self.do_post_bootstrap)\n        d.addErrback(self.do_post_errback)", "response": "Bootstrap the Tor server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave any outstanding items. This returns a Deferred which will errback if Tor was unhappy with anything or callback with TorConfig object on success.", "response": "def save(self):\n        \"\"\"\n        Save any outstanding items. This returns a Deferred which will\n        errback if Tor was unhappy with anything, or callback with\n        this TorConfig object on success.\n        \"\"\"\n\n        if not self.needs_save():\n            return defer.succeed(self)\n\n        args = []\n        directories = []\n        for (key, value) in self.unsaved.items():\n            if key == 'HiddenServices':\n                self.config['HiddenServices'] = value\n                # using a list here because at least one unit-test\n                # cares about order -- and conceivably order *could*\n                # matter here, to Tor...\n                services = list()\n                # authenticated services get flattened into the HiddenServices list...\n                for hs in value:\n                    if IOnionClient.providedBy(hs):\n                        parent = IOnionClient(hs).parent\n                        if parent not in services:\n                            services.append(parent)\n                    elif isinstance(hs, (EphemeralOnionService, EphemeralHiddenService)):\n                        raise ValueError(\n                            \"Only filesystem based Onion services may be added\"\n                            \" via TorConfig.hiddenservices; ephemeral services\"\n                            \" must be created with 'create_onion_service'.\"\n                        )\n                    else:\n                        if hs not in services:\n                            services.append(hs)\n\n                for hs in services:\n                    for (k, v) in hs.config_attributes():\n                        if k == 'HiddenServiceDir':\n                            if v not in directories:\n                                directories.append(v)\n                                args.append(k)\n                                args.append(v)\n                            else:\n                                raise RuntimeError(\"Trying to add hidden service with same HiddenServiceDir: %s\" % v)\n                        else:\n                            args.append(k)\n                            args.append(v)\n                continue\n\n            if isinstance(value, list):\n                for x in value:\n                    # FIXME XXX\n                    if x is not DEFAULT_VALUE:\n                        args.append(key)\n                        args.append(str(x))\n\n            else:\n                args.append(key)\n                args.append(value)\n\n            # FIXME in future we should wait for CONF_CHANGED and\n            # update then, right?\n            real_name = self._find_real_name(key)\n            if not isinstance(value, list) and real_name in self.parsers:\n                value = self.parsers[real_name].parse(value)\n            self.config[real_name] = value\n\n        # FIXME might want to re-think this, but currently there's no\n        # way to put things into a config and get them out again\n        # nicely...unless you just don't assign a protocol\n        if self.protocol:\n            d = self.protocol.set_conf(*args)\n            d.addCallback(self._save_completed)\n            return d\n\n        else:\n            self._save_completed()\n            return defer.succeed(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef config_args(self):\n        '''\n        Returns an iterator of 2-tuples (config_name, value), one for each\n        configuration option in this config. This is more-or-less an\n        internal method, but see, e.g., launch_tor()'s implementation\n        if you think you need to use this for something.\n\n        See :meth:`txtorcon.TorConfig.create_torrc` which returns a\n        string which is also a valid ``torrc`` file\n        '''\n\n        everything = dict()\n        everything.update(self.config)\n        everything.update(self.unsaved)\n\n        for (k, v) in list(everything.items()):\n            if type(v) is _ListWrapper:\n                if k.lower() == 'hiddenservices':\n                    for x in v:\n                        for (kk, vv) in x.config_attributes():\n                            yield (str(kk), str(vv))\n\n                else:\n                    # FIXME actually, is this right? don't we want ALL\n                    # the values in one string?!\n                    for x in v:\n                        yield (str(k), str(x))\n\n            else:\n                yield (str(k), str(v))", "response": "Returns an iterator of 2 - tuples one for each\n        configuration option in this config."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlaunches a new Tor process and returns a Deferred that fires with the Tor instance created.", "response": "def launch(reactor,\n           progress_updates=None,\n           control_port=None,\n           data_directory=None,\n           socks_port=None,\n           non_anonymous_mode=None,\n           stdout=None,\n           stderr=None,\n           timeout=None,\n           tor_binary=None,\n           user=None,  # XXX like the config['User'] special-casing from before\n           # 'users' probably never need these:\n           connection_creator=None,\n           kill_on_stderr=True,\n           _tor_config=None,  # a TorConfig instance, mostly for tests\n           ):\n    \"\"\"\n    launches a new Tor process, and returns a Deferred that fires with\n    a new :class:`txtorcon.Tor` instance. From this instance, you can\n    create or get any \"interesting\" instances you need: the\n    :class:`txtorcon.TorConfig` instance, create endpoints, create\n    :class:`txtorcon.TorState` instance(s), etc.\n\n    Note that there is NO way to pass in a config; we only expost a\n    couple of basic Tor options. If you need anything beyond these,\n    you can access the ``TorConfig`` instance (via ``.config``)\n    and make any changes there, reflecting them in tor with\n    ``.config.save()``.\n\n    You can igore all the options and safe defaults will be\n    provided. However, **it is recommended to pass data_directory**\n    especially if you will be starting up Tor frequently, as it saves\n    a bunch of time (and bandwidth for the directory\n    authorities). \"Safe defaults\" means:\n\n      - a tempdir for a ``DataDirectory`` is used (respecting ``TMP``)\n        and is deleted when this tor is shut down (you therefore\n        *probably* want to supply the ``data_directory=`` kwarg);\n      - a random, currently-unused local TCP port is used as the\n        ``SocksPort`` (specify ``socks_port=`` if you want your\n        own). If you want no SOCKS listener at all, pass\n        ``socks_port=0``\n      - we set ``__OwningControllerProcess`` and call\n        ``TAKEOWNERSHIP`` so that if our control connection goes away,\n        tor shuts down (see `control-spec\n        <https://gitweb.torproject.org/torspec.git/blob/HEAD:/control-spec.txt>`_\n        3.23).\n      - the launched Tor will use ``COOKIE`` authentication.\n\n    :param reactor: a Twisted IReactorCore implementation (usually\n        twisted.internet.reactor)\n\n    :param progress_updates: a callback which gets progress updates; gets 3\n         args: percent, tag, summary (FIXME make an interface for this).\n\n    :param data_directory: set as the ``DataDirectory`` option to Tor,\n        this is where tor keeps its state information (cached relays,\n        etc); starting with an already-populated state directory is a lot\n        faster. If ``None`` (the default), we create a tempdir for this\n        **and delete it on exit**. It is recommended you pass something here.\n\n    :param non_anonymous_mode: sets the Tor options\n        `HiddenServiceSingleHopMode` and\n        `HiddenServiceNonAnonymousMode` to 1 and un-sets any\n        `SOCKSPort` config, thus putting this Tor client into\n        \"non-anonymous mode\" which allows starting so-called Single\n        Onion services -- which use single-hop circuits to rendezvous\n        points. See WARNINGs in Tor manual! Also you need Tor\n        `0.3.4.1` or later (e.g. any `0.3.5.*` or newer) for this to\n        work properly.\n\n    :param stdout: a file-like object to which we write anything that\n        Tor prints on stdout (just needs to support write()).\n\n    :param stderr: a file-like object to which we write anything that\n        Tor prints on stderr (just needs .write()). Note that we kill\n        Tor off by default if anything appears on stderr; pass\n        \"kill_on_stderr=False\" if you don't want this behavior.\n\n    :param tor_binary: path to the Tor binary to run. If None (the\n        default), we try to find the tor binary.\n\n    :param kill_on_stderr:\n        When True (the default), if Tor prints anything on stderr we\n        kill off the process, close the TorControlProtocol and raise\n        an exception.\n\n    :param connection_creator: is mostly available to ease testing, so\n        you probably don't want to supply this. If supplied, it is a\n        callable that should return a Deferred that delivers an\n        :api:`twisted.internet.interfaces.IProtocol <IProtocol>` or\n        ConnectError.\n        See :api:`twisted.internet.interfaces.IStreamClientEndpoint`.connect\n        Note that this parameter is ignored if config.ControlPort == 0\n\n    :return: a Deferred which callbacks with :class:`txtorcon.Tor`\n        instance, from which you can retrieve the TorControlProtocol\n        instance via the ``.protocol`` property.\n\n    HACKS:\n\n     1. It's hard to know when Tor has both (completely!) written its\n        authentication cookie file AND is listening on the control\n        port. It seems that waiting for the first 'bootstrap' message on\n        stdout is sufficient. Seems fragile...and doesn't work 100% of\n        the time, so FIXME look at Tor source.\n\n\n\n    XXX this \"User\" thing was, IIRC, a feature for root-using scripts\n    (!!) that were going to launch tor, but where tor would drop to a\n    different user. Do we still want to support this? Probably\n    relevant to Docker (where everything is root! yay!)\n\n    ``User``: if this exists, we attempt to set ownership of the tempdir\n    to this user (but only if our effective UID is 0).\n    \"\"\"\n\n    # We have a slight problem with the approach: we need to pass a\n    # few minimum values to a torrc file so that Tor will start up\n    # enough that we may connect to it. Ideally, we'd be able to\n    # start a Tor up which doesn't really do anything except provide\n    # \"AUTHENTICATE\" and \"GETINFO config/names\" so we can do our\n    # config validation.\n\n    if not IReactorCore.providedBy(reactor):\n        raise ValueError(\n            \"'reactor' argument must provide IReactorCore\"\n            \" (got '{}': {})\".format(\n                type(reactor).__class__.__name__,\n                repr(reactor)\n            )\n        )\n\n    if tor_binary is None:\n        tor_binary = find_tor_binary()\n    if tor_binary is None:\n        # We fail right here instead of waiting for the reactor to start\n        raise TorNotFound('Tor binary could not be found')\n\n    # make sure we got things that have write() for stderr, stdout\n    # kwargs (XXX is there a \"better\" way to check for file-like\n    # object? do we use anything besides 'write()'?)\n    for arg in [stderr, stdout]:\n        if arg and not getattr(arg, \"write\", None):\n            raise RuntimeError(\n                'File-like object needed for stdout or stderr args.'\n            )\n\n    config = _tor_config or TorConfig()\n    if data_directory is not None:\n        user_set_data_directory = True\n        config.DataDirectory = data_directory\n        try:\n            os.mkdir(data_directory, 0o0700)\n        except OSError:\n            pass\n    else:\n        user_set_data_directory = False\n        data_directory = tempfile.mkdtemp(prefix='tortmp')\n        config.DataDirectory = data_directory\n        # note: we also set up the ProcessProtocol to delete this when\n        # Tor exits, this is \"just in case\" fallback:\n        reactor.addSystemEventTrigger(\n            'before', 'shutdown',\n            functools.partial(delete_file_or_tree, data_directory)\n        )\n\n    # things that used launch_tor() had to set ControlPort and/or\n    # SocksPort on the config to pass them, so we honour that here.\n    if control_port is None and _tor_config is not None:\n        try:\n            control_port = config.ControlPort\n        except KeyError:\n            control_port = None\n\n    if socks_port is None and _tor_config is not None:\n        try:\n            socks_port = config.SocksPort\n        except KeyError:\n            socks_port = None\n\n    if non_anonymous_mode:\n        if socks_port is not None:\n            raise ValueError(\n                \"Cannot use SOCKS options with non_anonymous_mode=True\"\n            )\n        config.HiddenServiceNonAnonymousMode = 1\n        config.HiddenServiceSingleHopMode = 1\n        config.SOCKSPort = 0\n    else:\n        if socks_port is None:\n            socks_port = yield available_tcp_port(reactor)\n        config.SOCKSPort = socks_port\n\n    try:\n        our_user = user or config.User\n    except KeyError:\n        pass\n    else:\n        # if we're root, make sure the directory is owned by the User\n        # that Tor is configured to drop to\n        if sys.platform in ('linux', 'linux2', 'darwin') and os.geteuid() == 0:\n            os.chown(data_directory, pwd.getpwnam(our_user).pw_uid, -1)\n\n    # user can pass in a control port, or we set one up here\n    if control_port is None:\n        # on posix-y systems, we can use a unix-socket\n        if sys.platform in ('linux', 'linux2', 'darwin'):\n            # note: tor will not accept a relative path for ControlPort\n            control_port = 'unix:{}'.format(\n                os.path.join(os.path.realpath(data_directory), 'control.socket')\n            )\n        else:\n            control_port = yield available_tcp_port(reactor)\n    else:\n        if str(control_port).startswith('unix:'):\n            control_path = control_port.lstrip('unix:')\n            containing_dir = dirname(control_path)\n            if not exists(containing_dir):\n                raise ValueError(\n                    \"The directory containing '{}' must exist\".format(\n                        containing_dir\n                    )\n                )\n            # Tor will be sad if the directory isn't 0700\n            mode = (0o0777 & os.stat(containing_dir).st_mode)\n            if mode & ~(0o0700):\n                raise ValueError(\n                    \"The directory containing a unix control-socket ('{}') \"\n                    \"must only be readable by the user\".format(containing_dir)\n                )\n    config.ControlPort = control_port\n\n    config.CookieAuthentication = 1\n    config.__OwningControllerProcess = os.getpid()\n    if connection_creator is None:\n        if str(control_port).startswith('unix:'):\n            connection_creator = functools.partial(\n                UNIXClientEndpoint(reactor, control_port[5:]).connect,\n                TorProtocolFactory()\n            )\n        else:\n            connection_creator = functools.partial(\n                TCP4ClientEndpoint(reactor, 'localhost', control_port).connect,\n                TorProtocolFactory()\n            )\n    # not an \"else\" on purpose; if we passed in \"control_port=0\" *and*\n    # a custom connection creator, we should still set this to None so\n    # it's never called (since we can't connect with ControlPort=0)\n    if control_port == 0:\n        connection_creator = None\n\n    # NOTE well, that if we don't pass \"-f\" then Tor will merrily load\n    # its default torrc, and apply our options over top... :/ should\n    # file a bug probably? --no-defaults or something maybe? (does\n    # --defaults-torrc - or something work?)\n    config_args = ['-f', '/dev/null/non-existant-on-purpose', '--ignore-missing-torrc']\n\n    # ...now add all our config options on the command-line. This\n    # avoids writing a temporary torrc.\n    for (k, v) in config.config_args():\n        config_args.append(k)\n        config_args.append(v)\n\n    process_protocol = TorProcessProtocol(\n        connection_creator,\n        progress_updates,\n        config, reactor,\n        timeout,\n        kill_on_stderr,\n        stdout,\n        stderr,\n    )\n    if control_port == 0:\n        connected_cb = succeed(None)\n    else:\n        connected_cb = process_protocol.when_connected()\n\n    # we set both to_delete and the shutdown events because this\n    # process might be shut down way before the reactor, but if the\n    # reactor bombs out without the subprocess getting closed cleanly,\n    # we'll want the system shutdown events triggered so the temporary\n    # files get cleaned up either way\n\n    # we don't want to delete the user's directories, just temporary\n    # ones this method created.\n    if not user_set_data_directory:\n        process_protocol.to_delete = [data_directory]\n        reactor.addSystemEventTrigger(\n            'before', 'shutdown',\n            functools.partial(delete_file_or_tree, data_directory)\n        )\n\n    log.msg('Spawning tor process with DataDirectory', data_directory)\n    args = [tor_binary] + config_args\n    transport = reactor.spawnProcess(\n        process_protocol,\n        tor_binary,\n        args=args,\n        env={'HOME': data_directory},\n        path=data_directory if os.path.exists(data_directory) else None,  # XXX error if it doesn't exist?\n    )\n    transport.closeStdin()\n    proto = yield connected_cb\n    # note \"proto\" here is a TorProcessProtocol\n\n    # we might need to attach this protocol to the TorConfig\n    if config.protocol is None and proto is not None and proto.tor_protocol is not None:\n        # proto is None in the ControlPort=0 case\n        yield config.attach_protocol(proto.tor_protocol)\n        # note that attach_protocol waits for the protocol to be\n        # boostrapped if necessary\n\n    returnValue(\n        Tor(\n            reactor,\n            config.protocol,\n            _tor_config=config,\n            _process_proto=process_protocol,\n            _non_anonymous=True if non_anonymous_mode else False,\n        )\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connect(reactor, control_endpoint=None, password_function=None):\n\n    @inlineCallbacks\n    def try_endpoint(control_ep):\n        assert IStreamClientEndpoint.providedBy(control_ep)\n        proto = yield control_ep.connect(\n            TorProtocolFactory(\n                password_function=password_function\n            )\n        )\n        config = yield TorConfig.from_protocol(proto)\n        tor = Tor(reactor, proto, _tor_config=config)\n        returnValue(tor)\n\n    if control_endpoint is None:\n        to_try = [\n            UNIXClientEndpoint(reactor, '/var/run/tor/control'),\n            TCP4ClientEndpoint(reactor, '127.0.0.1', 9051),\n            TCP4ClientEndpoint(reactor, '127.0.0.1', 9151),\n        ]\n    elif IStreamClientEndpoint.providedBy(control_endpoint):\n        to_try = [control_endpoint]\n    elif isinstance(control_endpoint, Sequence):\n        to_try = control_endpoint\n        for ep in control_endpoint:\n            if not IStreamClientEndpoint.providedBy(ep):\n                raise ValueError(\n                    \"For control_endpoint=, '{}' must provide\"\n                    \" IStreamClientEndpoint\".format(ep)\n                )\n    else:\n        raise ValueError(\n            \"For control_endpoint=, '{}' must provide\"\n            \" IStreamClientEndpoint\".format(control_endpoint)\n        )\n\n    errors = []\n    for idx, ep in enumerate(to_try):\n        try:\n            tor = yield try_endpoint(ep)\n            txtorlog.msg(\"Connected via '{}'\".format(ep))\n            returnValue(tor)\n        except Exception as e:\n            errors.append(e)\n    if len(errors) == 1:\n        raise errors[0]\n    raise RuntimeError(\n        'Failed to connect to: {}'.format(\n            ', '.join(\n                '{}: {}'.format(ep, err) for ep, err in zip(to_try, errors)\n            )\n        )\n    )", "response": "Connect to an already - running Tor."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _maybe_notify_connected(self, arg):\n        if self._connected_listeners is None:\n            return\n        for d in self._connected_listeners:\n            # Twisted will turn this into an errback if \"arg\" is a\n            # Failure\n            d.callback(arg)\n        self._connected_listeners = None", "response": "Notify all connected Deferreds that arg is a\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef quit(self):\n\n        try:\n            self.transport.signalProcess('TERM')\n            d = Deferred()\n            self._on_exit.append(d)\n\n        except error.ProcessExitedAlready:\n            self.transport.loseConnection()\n            d = succeed(None)\n        except Exception:\n            d = fail()\n        return d", "response": "This method will terminate the underlying Tor process."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls when the output of a Tor process has been received.", "response": "def outReceived(self, data):\n        \"\"\"\n        :api:`twisted.internet.protocol.ProcessProtocol <ProcessProtocol>` API\n        \"\"\"\n\n        if self.stdout:\n            self.stdout.write(data.decode('ascii'))\n\n        # minor hack: we can't try this in connectionMade because\n        # that's when the process first starts up so Tor hasn't\n        # opened any ports properly yet. So, we presume that after\n        # its first output we're good-to-go. If this fails, we'll\n        # reset and try again at the next output (see this class'\n        # tor_connection_failed)\n        txtorlog.msg(data)\n        if not self.attempted_connect and self.connection_creator \\\n                and b'Opening Control listener' in data:\n            self.attempted_connect = True\n            # hmmm, we don't \"do\" anything with this Deferred?\n            # (should it be connected to the when_connected\n            # Deferreds?)\n            d = self.connection_creator()\n            d.addCallback(self._tor_connected)\n            d.addErrback(self._tor_connection_failed)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _timeout_expired(self):\n        self._did_timeout = True\n        try:\n            self.transport.signalProcess('TERM')\n        except error.ProcessExitedAlready:\n            # XXX why don't we just always do this?\n            self.transport.loseConnection()\n\n        fail = Failure(RuntimeError(\"timeout while launching Tor\"))\n        self._maybe_notify_connected(fail)", "response": "Called when a timeout has expired."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef errReceived(self, data):\n\n        if self.stderr:\n            self.stderr.write(data)\n\n        if self.kill_on_stderr:\n            self.transport.loseConnection()\n            raise RuntimeError(\n                \"Received stderr output from slave Tor process: \" + data.decode('utf8')\n            )", "response": "Called by the process when an error occurs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclean up my temporary files.", "response": "def cleanup(self):\n        \"\"\"\n        Clean up my temporary files.\n        \"\"\"\n\n        all([delete_file_or_tree(f) for f in self.to_delete])\n        self.to_delete = []"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef processEnded(self, status):\n        self.cleanup()\n\n        if status.value.exitCode is None:\n            if self._did_timeout:\n                err = RuntimeError(\"Timeout waiting for Tor launch.\")\n            else:\n                err = RuntimeError(\n                    \"Tor was killed (%s).\" % status.value.signal)\n        else:\n            err = RuntimeError(\n                \"Tor exited with error-code %d\" % status.value.exitCode)\n\n        # hmmm, this log() should probably go away...not always an\n        # error (e.g. .quit()\n        log.err(err)\n        self._maybe_notify_connected(Failure(err))", "response": "Called when the process has ended."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef progress(self, percent, tag, summary):\n\n        if self.progress_updates:\n            self.progress_updates(percent, tag, summary)", "response": "Update the current progress of a specific tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncloses all open streams and circuits in the Tor we connect to the Tor we connect to", "response": "def main(reactor):\n    \"\"\"\n    Close all open streams and circuits in the Tor we connect to\n    \"\"\"\n    control_ep = UNIXClientEndpoint(reactor, '/var/run/tor/control')\n    tor = yield txtorcon.connect(reactor, control_ep)\n    state = yield tor.create_state()\n    print(\"Closing all circuits:\")\n    for circuit in list(state.circuits.values()):\n        path = '->'.join(map(lambda r: r.id_hex, circuit.path))\n        print(\"Circuit {} through {}\".format(circuit.id, path))\n        for stream in circuit.streams:\n            print(\"  Stream {} to {}\".format(stream.id, stream.target_host))\n            yield stream.close()\n            print(\"  closed\")\n        yield circuit.close()\n        print(\"closed\")\n    yield tor.quit()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the internal state of the object", "response": "def update(self, *args):\n        \"\"\"\n        deals with an update from Tor; see parsing logic in torcontroller\n        \"\"\"\n\n        gmtexpires = None\n        (name, ip, expires) = args[:3]\n\n        for arg in args:\n            if arg.lower().startswith('expires='):\n                gmtexpires = arg[8:]\n\n        if gmtexpires is None:\n            if len(args) == 3:\n                gmtexpires = expires\n            else:\n                if args[2] == 'NEVER':\n                    gmtexpires = args[2]\n                else:\n                    gmtexpires = args[3]\n\n        self.name = name                # \"www.example.com\"\n        self.ip = maybe_ip_addr(ip)     # IPV4Address instance, or string\n\n        if self.ip == '<error>':\n            self._expire()\n            return\n\n        fmt = \"%Y-%m-%d %H:%M:%S\"\n\n        # if we already have expiry times, etc then we want to\n        # properly delay our timeout\n\n        oldexpires = self.expires\n\n        if gmtexpires.upper() == 'NEVER':\n            # FIXME can I just select a date 100 years in the future instead?\n            self.expires = None\n        else:\n            self.expires = datetime.datetime.strptime(gmtexpires, fmt)\n        self.created = datetime.datetime.utcnow()\n\n        if self.expires is not None:\n            if oldexpires is None:\n                if self.expires <= self.created:\n                    diff = datetime.timedelta(seconds=0)\n                else:\n                    diff = self.expires - self.created\n                self.expiry = self.map.scheduler.callLater(diff.seconds,\n                                                           self._expire)\n\n            else:\n                diff = self.expires - oldexpires\n                self.expiry.delay(diff.seconds)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _expire(self):\n        del self.map.addr[self.name]\n        self.map.notify(\"addrmap_expired\", *[self.name], **{})", "response": "Called by the time_before_record_expired callback."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, update):\n\n        params = shlex.split(update)\n        if params[0] in self.addr:\n            self.addr[params[0]].update(*params)\n\n        else:\n            a = Addr(self)\n            # add both name and IP address\n            self.addr[params[0]] = a\n            self.addr[params[1]] = a\n            a.update(*params)\n            self.notify(\"addrmap_added\", *[a], **{})", "response": "Deal with an update from Tor ; either creates a new Addr object or updates the addrmap with the given update."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_tbb_web_headers():\n    return Headers({\n        b\"User-Agent\": [b\"Mozilla/5.0 (Windows NT 6.1; rv:45.0) Gecko/20100101 Firefox/45.0\"],\n        b\"Accept\": [b\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\"],\n        b\"Accept-Language\": [b\"en-US,en;q=0.5\"],\n        b\"Accept-Encoding\": [b\"gzip, deflate\"],\n    })", "response": "Returns a new twisted. web. http_headers. Headers instance populated with tags to mimic Tor Browser."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if the version_string represents a Tor version at least major. minor. micro. patch version.", "response": "def version_at_least(version_string, major, minor, micro, patch):\n    \"\"\"\n    This returns True if the version_string represents a Tor version\n    of at least ``major``.``minor``.``micro``.``patch`` version,\n    ignoring any trailing specifiers.\n    \"\"\"\n    parts = re.match(\n        r'^([0-9]+)\\.([0-9]+)\\.([0-9]+)\\.([0-9]+).*$',\n        version_string,\n    )\n    for ver, gold in zip(parts.group(1, 2, 3, 4), (major, minor, micro, patch)):\n        if int(ver) < int(gold):\n            return False\n        elif int(ver) > int(gold):\n            return True\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntrying to find the tor executable using the shell first or in the given places and returns the path to the tor executable.", "response": "def find_tor_binary(globs=('/usr/sbin/', '/usr/bin/',\n                           '/Applications/TorBrowser_*.app/Contents/MacOS/'),\n                    system_tor=True):\n    \"\"\"\n    Tries to find the tor executable using the shell first or in in the\n    paths whose glob-patterns is in the given 'globs'-tuple.\n\n    :param globs:\n        A tuple of shell-style globs of directories to use to find tor\n        (TODO consider making that globs to actual tor binary?)\n\n    :param system_tor:\n        This controls whether bash is used to seach for 'tor' or\n        not. If False, we skip that check and use only the 'globs'\n        tuple.\n    \"\"\"\n\n    # Try to find the tor executable using the shell\n    if system_tor:\n        try:\n            proc = subprocess.Popen(\n                ('which tor'),\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n                shell=True\n            )\n        except OSError:\n            pass\n        else:\n            stdout, _ = proc.communicate()\n            if proc.poll() == 0 and stdout != '':\n                return stdout.strip()\n\n    # the shell may not provide type and tor is usually not on PATH when using\n    # the browser-bundle. Look in specific places\n    for pattern in globs:\n        for path in glob.glob(pattern):\n            torbin = os.path.join(path, 'tor')\n            if is_executable(torbin):\n                return torbin\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef maybe_ip_addr(addr):\n\n    if six.PY2 and isinstance(addr, str):\n        addr = unicode(addr)  # noqa\n    try:\n        return ipaddress.ip_address(addr)\n    except ValueError:\n        pass\n    return str(addr)", "response": "Try to return an IPAddress otherwise returns a string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_keywords(args, key_filter=lambda x: not x.startswith(\"$\")):\n    filtered = [x for x in args if '=' in x and key_filter(x.split('=')[0])]\n    return dict(x.split('=', 1) for x in filtered)", "response": "This method finds all keywords in a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete a file or a directory tree.", "response": "def delete_file_or_tree(*args):\n    \"\"\"\n    For every path in args, try to delete it as a file or a directory\n    tree. Ignores deletion errors.\n    \"\"\"\n\n    for f in args:\n        try:\n            os.unlink(f)\n        except OSError:\n            shutil.rmtree(f, ignore_errors=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_from_address(addr, port, torstate=None):\n\n    if addr is None:\n        return None\n\n    if \"(tor_internal)\" == str(addr).lower():\n        if torstate is None:\n            return None\n        return int(torstate.tor_pid)\n\n    proc = subprocess.Popen(['lsof', '-i', '4tcp@%s:%s' % (addr, port)],\n                            stdout=subprocess.PIPE)\n    (stdout, stderr) = proc.communicate()\n    lines = stdout.split(b'\\n')\n    if len(lines) > 1:\n        return int(lines[1].split()[1])", "response": "Returns the process ID of the Tor process that is connected to the given address and port."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the HMAC with SHA256 over msg with key.", "response": "def hmac_sha256(key, msg):\n    \"\"\"\n    Adapted from rransom's tor-utils git repository. Returns the\n    digest (binary) of an HMAC with SHA256 over msg with key.\n    \"\"\"\n\n    return hmac.new(key, msg, hashlib.sha256).digest()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a Deferred that fires the available TCP port on localhost.", "response": "def available_tcp_port(reactor):\n    \"\"\"\n    Returns a Deferred firing an available TCP port on localhost.\n    It does so by listening on port 0; then stopListening and fires the\n    assigned port number.\n    \"\"\"\n\n    endpoint = serverFromString(reactor, 'tcp:0:interface=127.0.0.1')\n    port = yield endpoint.listen(NoOpProtocolFactory())\n    address = port.getHost()\n    yield port.stopListening()\n    defer.returnValue(address.port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unescape_quoted_string(string):\n    r'''\n    This function implementes the recommended functionality described in the\n    tor control-spec to be compatible with older tor versions:\n\n      * Read \\\\n \\\\t \\\\r and \\\\0 ... \\\\377 as C escapes.\n      * Treat a backslash followed by any other character as that character.\n\n    Except the legacy support for the escape sequences above this function\n    implements parsing of QuotedString using qcontent from\n\n    QuotedString = DQUOTE *qcontent DQUOTE\n\n    :param string: The escaped quoted string.\n    :returns: The unescaped string.\n    :raises ValueError: If the string is in a invalid form\n                        (e.g. a single backslash)\n    '''\n    match = re.match(r'''^\"((?:[^\"\\\\]|\\\\.)*)\"$''', string)\n    if not match:\n        raise ValueError(\"Invalid quoted string\", string)\n    string = match.group(1)\n    # remove backslash before all characters which should not be\n    # handeled as escape codes by string.decode('string-escape').\n    # This is needed so e.g. '\\x00' is not unescaped as '\\0'\n    string = re.sub(r'((?:^|[^\\\\])(?:\\\\\\\\)*)\\\\([^ntr0-7\\\\])', r'\\1\\2', string)\n    if six.PY3:\n        # XXX hmmm?\n        return bytes(string, 'ascii').decode('unicode-escape')\n    return string.decode('string-escape')", "response": "r Unescape a quoted string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if host is not public False otherwise", "response": "def _is_non_public_numeric_address(host):\n    \"\"\"\n    returns True if 'host' is not public\n    \"\"\"\n    # for numeric hostnames, skip RFC1918 addresses, since no Tor exit\n    # node will be able to reach those. Likewise ignore IPv6 addresses.\n    try:\n        a = ipaddress.ip_address(six.text_type(host))\n    except ValueError:\n        return False        # non-numeric, let Tor try it\n    if a.is_loopback or a.is_multicast or a.is_private or a.is_reserved \\\n       or a.is_unspecified:\n        return True         # too weird, don't connect\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding an ephemeral service to the TorConfig.", "response": "def _add_ephemeral_service(config, onion, progress, version, auth=None, await_all_uploads=None):\n    \"\"\"\n    Internal Helper.\n\n    This uses ADD_ONION to add the given service to Tor. The Deferred\n    this returns will callback when the ADD_ONION call has succeed,\n    *and* when at least one descriptor has been uploaded to a Hidden\n    Service Directory.\n\n    :param config: a TorConfig instance\n\n    :param onion: an EphemeralOnionService instance\n\n    :param progress: a callable taking 3 arguments (percent, tag,\n        description) that is called some number of times to tell you of\n        progress.\n\n    :param version: 2 or 3, which kind of service to create\n\n    :param auth: if not None, create an authenticated service (\"basic\"\n        is the only kind supported currently so a AuthBasic instance\n        should be passed)\n    \"\"\"\n    if onion not in config.EphemeralOnionServices:\n        config.EphemeralOnionServices.append(onion)\n\n    # we have to keep this as a Deferred for now so that HS_DESC\n    # listener gets added before we issue ADD_ONION\n    assert version in (2, 3)\n    uploaded_d = _await_descriptor_upload(config.tor_protocol, onion, progress, await_all_uploads)\n\n    # we allow a key to be passed that *doestn'* start with\n    # \"RSA1024:\" because having to escape the \":\" for endpoint\n    # string syntax (which uses \":\" as delimeters) is annoying\n    # XXX rethink ^^? what do we do when the type is upgraded?\n    # maybe just a magic-character that's different from \":\", or\n    # force people to escape them?\n    if onion.private_key:\n        if onion.private_key is not DISCARD and ':' not in onion.private_key:\n            if version == 2:\n                if not onion.private_key.startswith(\"RSA1024:\"):\n                    onion._private_key = \"RSA1024:\" + onion.private_key\n            elif version == 3:\n                if not onion.private_key.startswith(\"ED25519-V3:\"):\n                    onion._private_key = \"ED25519-V3:\" + onion.private_key\n\n    # okay, we're set up to listen, and now we issue the ADD_ONION\n    # command. this will set ._hostname and ._private_key properly\n    keystring = 'NEW:BEST'\n    if onion.private_key not in (None, DISCARD):\n        keystring = onion.private_key\n    elif version == 3:\n        keystring = 'NEW:ED25519-V3'\n    if version == 3:\n        if 'V3' not in keystring:\n            raise ValueError(\n                \"version=3 but private key isn't 'ED25519-V3'\"\n            )\n\n    # hmm, is it better to validate keyblob args in the create\n    # methods? \"Feels nicer\" to see it here when building ADD_ONION\n    # though?\n    if '\\r' in keystring or '\\n' in keystring:\n        raise ValueError(\n            \"No newline or return characters allowed in key blobs\"\n        )\n\n    cmd = 'ADD_ONION {}'.format(keystring)\n    for port in onion._ports:\n        cmd += ' Port={},{}'.format(*port.split(' ', 1))\n    flags = []\n    if onion._detach:\n        flags.append('Detach')\n    if onion.private_key is DISCARD:\n        flags.append('DiscardPK')\n    if auth is not None:\n        assert isinstance(auth, AuthBasic)  # don't support AuthStealth yet\n        if isinstance(auth, AuthBasic):\n            flags.append('BasicAuth')\n    if onion._single_hop:\n        flags.append('NonAnonymous')  # depends on some Tor options, too\n    if flags:\n        cmd += ' Flags={}'.format(','.join(flags))\n\n    if auth is not None:\n        for client_name in auth.client_names():\n            keyblob = auth.keyblob_for(client_name)\n            if keyblob is None:\n                cmd += ' ClientAuth={}'.format(client_name)\n            else:\n                cmd += ' ClientAuth={}:{}'.format(client_name, keyblob)\n                onion._add_client(client_name, keyblob)\n\n    raw_res = yield config.tor_protocol.queue_command(cmd)\n    res = find_keywords(raw_res.split('\\n'))\n    try:\n        onion._hostname = res['ServiceID'] + '.onion'\n        if onion.private_key is DISCARD:\n            onion._private_key = None\n        else:\n            # if we specified a private key, it's not echoed back\n            if not onion.private_key:\n                onion._private_key = res['PrivateKey'].strip()\n    except KeyError:\n        raise RuntimeError(\n            \"Expected ADD_ONION to return ServiceID= and PrivateKey= args.\"\n            \"Got: {}\".format(res)\n        )\n\n    if auth is not None:\n        for line in raw_res.split('\\n'):\n            if line.startswith(\"ClientAuth=\"):\n                name, blob = line[11:].split(':', 1)\n                onion._add_client(name, blob)\n\n    log.msg(\"{}: waiting for descriptor uploads.\".format(onion.hostname))\n    yield uploaded_d"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _compute_permanent_id(private_key):\n    pub = private_key.public_key()\n    p = pub.public_bytes(\n        encoding=serialization.Encoding.PEM,\n        format=serialization.PublicFormat.PKCS1\n    )\n    z = ''.join(p.decode('ascii').strip().split('\\n')[1:-1])\n    b = base64.b64decode(z)\n    h1 = hashlib.new('sha1')\n    h1.update(b)\n    permanent_id = h1.digest()[:10]\n    return base64.b32encode(permanent_id).lower().decode('ascii')", "response": "Internal helper. Return an authenticated service s permanent ID given an RSA private key object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _validate_ports(reactor, ports):\n    if not isinstance(ports, (list, tuple)):\n        raise ValueError(\"'ports' must be a list of strings, ints or 2-tuples\")\n\n    processed_ports = []\n    for port in ports:\n        if isinstance(port, (set, list, tuple)):\n            if len(port) != 2:\n                raise ValueError(\n                    \"'ports' must contain a single int or a 2-tuple of ints\"\n                )\n            remote, local = port\n            try:\n                remote = int(remote)\n            except ValueError:\n                raise ValueError(\n                    \"'ports' has a tuple with a non-integer \"\n                    \"component: {}\".format(port)\n                )\n            try:\n                local = int(local)\n            except ValueError:\n                if local.startswith('unix:/'):\n                    pass\n                else:\n                    if ':' not in local:\n                        raise ValueError(\n                            \"local port must be either an integer\"\n                            \" or start with unix:/ or be an IP:port\"\n                        )\n                    ip, port = local.split(':')\n                    if not _is_non_public_numeric_address(ip):\n                        log.msg(\n                            \"'{}' used as onion port doesn't appear to be a \"\n                            \"local, numeric address\".format(ip)\n                        )\n                processed_ports.append(\n                    \"{} {}\".format(remote, local)\n                )\n            else:\n                processed_ports.append(\n                    \"{} 127.0.0.1:{}\".format(remote, local)\n                )\n\n        elif isinstance(port, (six.text_type, str)):\n            _validate_single_port_string(port)\n            processed_ports.append(port)\n\n        else:\n            try:\n                remote = int(port)\n            except (ValueError, TypeError):\n                raise ValueError(\n                    \"'ports' has a non-integer entry: {}\".format(port)\n                )\n            local = yield available_tcp_port(reactor)\n            processed_ports.append(\n                \"{} 127.0.0.1:{}\".format(remote, local)\n            )\n    defer.returnValue(processed_ports)", "response": "Validates an incoming list of ports and returns a list of strings suitable for passing to other onion - services functions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _validate_single_port_string(port):\n    if ' ' not in port or len(port.split(' ')) != 2:\n        raise ValueError(\n            \"Port '{}' should have exactly one space in it\".format(port)\n        )\n    (external, internal) = port.split(' ')\n    try:\n        external = int(external)\n    except ValueError:\n        raise ValueError(\n            \"Port '{}' external port isn't an int\".format(port)\n        )\n    if ':' not in internal:\n        raise ValueError(\n            \"Port '{}' local address should be 'IP:port'\".format(port)\n        )\n    if not internal.startswith('unix:'):\n        ip, localport = internal.split(':')\n        if ip != 'localhost' and not _is_non_public_numeric_address(ip):\n            raise ValueError(\n                \"Port '{}' internal IP '{}' should be a local \"\n                \"address\".format(port, ip)\n            )", "response": "Validate a single string specifying ports for Onion\n    services."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle(self, data):\n        if self.handler:\n            state = self.handler(data)\n            if state is None:\n                return self.next_state\n            return state\n        return self.next_state", "response": "Handle the incoming data and return the next state."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the distance from point to the line given by the points start and end.", "response": "def pldist(point, start, end):\n    \"\"\"\n    Calculates the distance from ``point`` to the line given\n    by the points ``start`` and ``end``.\n\n    :param point: a point\n    :type point: numpy array\n    :param start: a point of the line\n    :type start: numpy array\n    :param end: another point of the line\n    :type end: numpy array\n    \"\"\"\n    if np.all(np.equal(start, end)):\n        return np.linalg.norm(point - start)\n\n    return np.divide(\n            np.abs(np.linalg.norm(np.cross(end - start, start - point))),\n            np.linalg.norm(end - start))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rdp_rec(M, epsilon, dist=pldist):\n    dmax = 0.0\n    index = -1\n\n    for i in xrange(1, M.shape[0]):\n        d = dist(M[i], M[0], M[-1])\n\n        if d > dmax:\n            index = i\n            dmax = d\n\n    if dmax > epsilon:\n        r1 = rdp_rec(M[:index + 1], epsilon, dist)\n        r2 = rdp_rec(M[index:], epsilon, dist)\n\n        return np.vstack((r1[:-1], r2))\n    else:\n        return np.vstack((M[0], M[-1]))", "response": "Simplifies a given array of points."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rdp_iter(M, epsilon, dist=pldist, return_mask=False):\n    mask = _rdp_iter(M, 0, len(M) - 1, epsilon, dist)\n\n    if return_mask:\n        return mask\n\n    return M[mask]", "response": "Simplifies a given array of points."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsimplify a given array of points using the Ramer - Douglas - Peucker algorithm.", "response": "def rdp(M, epsilon=0, dist=pldist, algo=\"iter\", return_mask=False):\n    \"\"\"\n    Simplifies a given array of points using the Ramer-Douglas-Peucker\n    algorithm.\n\n    Example:\n\n    >>> from rdp import rdp\n    >>> rdp([[1, 1], [2, 2], [3, 3], [4, 4]])\n    [[1, 1], [4, 4]]\n\n    This is a convenience wrapper around both :func:`rdp.rdp_iter` \n    and :func:`rdp.rdp_rec` that detects if the input is a numpy array\n    in order to adapt the output accordingly. This means that\n    when it is called using a Python list as argument, a Python\n    list is returned, and in case of an invocation using a numpy\n    array, a NumPy array is returned.\n\n    The parameter ``return_mask=True`` can be used in conjunction\n    with ``algo=\"iter\"`` to return only the mask of points to keep. Example:\n\n    >>> from rdp import rdp\n    >>> import numpy as np\n    >>> arr = np.array([1, 1, 2, 2, 3, 3, 4, 4]).reshape(4, 2)\n    >>> arr\n    array([[1, 1],\n           [2, 2],\n           [3, 3],\n           [4, 4]])\n    >>> mask = rdp(arr, algo=\"iter\", return_mask=True)\n    >>> mask\n    array([ True, False, False,  True], dtype=bool)\n    >>> arr[mask]\n    array([[1, 1],\n           [4, 4]])\n\n    :param M: a series of points\n    :type M: numpy array with shape ``(n,d)`` where ``n`` is the number of points and ``d`` their dimension\n    :param epsilon: epsilon in the rdp algorithm\n    :type epsilon: float\n    :param dist: distance function\n    :type dist: function with signature ``f(point, start, end)`` -- see :func:`rdp.pldist`\n    :param algo: either ``iter`` for an iterative algorithm or ``rec`` for a recursive algorithm\n    :type algo: string\n    :param return_mask: return mask instead of simplified array\n    :type return_mask: bool\n    \"\"\"\n\n    if algo == \"iter\":\n        algo = partial(rdp_iter, return_mask=return_mask)\n    elif algo == \"rec\":\n        if return_mask:\n            raise NotImplementedError(\"return_mask=True not supported with algo=\\\"rec\\\"\")\n        algo = rdp_rec\n        \n    if \"numpy\" in str(type(M)):\n        return algo(M, epsilon, dist)\n\n    return algo(np.array(M), epsilon, dist).tolist()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting a new scene.", "response": "def on_start_scene(self, event: StartScene, signal: Callable[[Any], None]):\n        \"\"\"\n        Start a new scene. The current scene pauses.\n        \"\"\"\n        self.pause_scene()\n        self.start_scene(event.new_scene, event.kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstopping a running scene.", "response": "def on_stop_scene(self, event: events.StopScene, signal: Callable[[Any], None]):\n        \"\"\"\n        Stop a running scene. If there's a scene on the stack, it resumes.\n        \"\"\"\n        self.stop_scene()\n        if self.current_scene is not None:\n            signal(events.SceneContinued())\n        else:\n            signal(events.Quit())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall when a new scene is found.", "response": "def on_replace_scene(self, event: events.ReplaceScene, signal):\n        \"\"\"\n        Replace the running scene with a new one.\n        \"\"\"\n        self.stop_scene()\n        self.start_scene(event.new_scene, event.kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters a callback to be applied to an event at time of publishing.", "response": "def register(self, event_type: Union[Type, _ellipsis], callback: Callable[[], Any]):\n        \"\"\"\n        Register a callback to be applied to an event at time of publishing.\n\n        Primarily to be used by subsystems.\n\n        The callback will receive the event. Your code should modify the event\n        in place. It does not need to return it.\n\n        :param event_type: The class of an event.\n        :param callback: A callable, must accept an event, and return no value.\n        :return: None\n        \"\"\"\n        if not isinstance(event_type, type) and event_type is not ...:\n            raise TypeError(f\"{type(self)}.register requires event_type to be a type.\")\n        if not callable(callback):\n            raise TypeError(f\"{type(self)}.register requires callback to be callable.\")\n        self.event_extensions[event_type].append(callback)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrebuilding _module_file_index from sys. modules", "response": "def _build_index():\n    \"\"\"\n    Rebuild _module_file_index from sys.modules\n    \"\"\"\n    global _module_file_index\n    _module_file_index = {\n        mod.__file__: mod.__name__\n        for mod in sys.modules.values()\n        if hasattr(mod, '__file__') and hasattr(mod, '__name__')\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the logger for this class.", "response": "def logger(self):\n        \"\"\"\n        The logger for this class.\n        \"\"\"\n        # This is internal/CPython only/etc\n        # It's also astonishingly faster than alternatives.\n        frame = sys._getframe(1)\n        file_name = frame.f_code.co_filename\n\n        module_name = _get_module(file_name)\n        return logging.getLogger(module_name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef current_frame(self):\n        if not self._pause_level:\n            return (\n                int((self._clock() + self._offset) * self.frames_per_second)\n                % len(self._frames)\n            )\n        else:\n            return self._paused_frame", "response": "Compute the number of the current frame in the current session."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(setup: Callable[[BaseScene], None]=None, *, log_level=logging.WARNING,\n        starting_scene=BaseScene):\n    \"\"\"\n    Run a small game.\n\n    The resolution will 800 pixels wide by 600 pixels tall.\n\n    setup is a callable that accepts a scene and returns None.\n\n    log_level let's you set the expected log level. Consider logging.DEBUG if\n    something is behaving oddly.\n\n    starting_scene let's you change the scene used by the engine.\n    \"\"\"\n    logging.basicConfig(level=log_level)\n\n    kwargs = {\n        \"resolution\": (800, 600),\n        \"scene_kwargs\": {\n            \"set_up\": setup,\n        }\n    }\n\n    with GameEngine(starting_scene, **kwargs) as eng:\n        eng.run()", "response": "Run a small game."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, game_object: Hashable, tags: Iterable[Hashable]=()) -> None:\n        if isinstance(tags, (str, bytes)):\n            raise TypeError(\"You passed a string instead of an iterable, this probably isn't what you intended.\\n\\nTry making it a tuple.\")\n        self.all.add(game_object)\n\n        for kind in type(game_object).mro():\n            self.kinds[kind].add(game_object)\n        for tag in tags:\n            self.tags[tag].add(game_object)", "response": "Add a game_object to the container."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting an iterator of objects by kind or tag.", "response": "def get(self, *, kind: Type=None, tag: Hashable=None, **_) -> Iterator:\n        \"\"\"\n        Get an iterator of objects by kind or tag.\n\n        kind: Any type. Pass to get a subset of contained items with the given\n              type.\n        tag: Any Hashable object. Pass to get a subset of contained items with\n             the given tag.\n\n        Pass both kind and tag to get objects that are both that type and that\n        tag.\n\n        Examples:\n            container.get(type=MyObject)\n\n            container.get(tag=\"red\")\n\n            container.get(type=MyObject, tag=\"red\")\n        \"\"\"\n        if kind is None and tag is None:\n            raise TypeError(\"get() takes at least one keyword-only argument. 'kind' or 'tag'.\")\n        kinds = self.all\n        tags = self.all\n        if kind is not None:\n            kinds = self.kinds[kind]\n        if tag is not None:\n            tags = self.tags[tag]\n        return (x for x in kinds.intersection(tags))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove(self, game_object: Hashable) -> None:\n        self.all.remove(game_object)\n        for kind in type(game_object).mro():\n            self.kinds[kind].remove(game_object)\n        for s in self.tags.values():\n            s.discard(game_object)", "response": "Remove the given object from the container."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndefaulting case, override in subclass as necessary.", "response": "def change(self) -> Tuple[bool, dict]:\n        \"\"\"\n        Default case, override in subclass as necessary.\n        \"\"\"\n        next = self.next\n        self.next = None\n        if self.next or not self.running:\n            message = \"The Scene.change interface is deprecated. Use the events commands instead.\"\n            warn(message, DeprecationWarning)\n\n        return self.running, {\"scene_class\": next}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a game_object to the scene.", "response": "def add(self, game_object: Hashable, tags: Iterable=())-> None:\n        \"\"\"\n        Add a game_object to the scene.\n\n        game_object: Any GameObject object. The item to be added.\n        tags: An iterable of Hashable objects. Values that can be used to\n              retrieve a group containing the game_object.\n\n        Examples:\n            scene.add(MyGameObject())\n\n            scene.add(MyGameObject(), tags=(\"red\", \"blue\")\n        \"\"\"\n        self.game_objects.add(game_object, tags)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, *, kind: Type=None, tag: Hashable=None, **kwargs) -> Iterator:\n        return self.game_objects.get(kind=kind, tag=tag, **kwargs)", "response": "Get an iterator of GameObjects by kind or tag."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate and store hash key for file.", "response": "def set_hash_key(self, file):\n        \"\"\"Calculate and store hash key for file.\"\"\"\n        filehasher = hashlib.md5()\n        while True:\n            data = file.read(8192)\n            if not data:\n                break\n            filehasher.update(data)\n        file.seek(0)\n        self.hash_key = filehasher.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _append_sorted(root, el, comparator):\r\n    for child in root:\r\n        rel = comparator(el, child)\r\n        if rel > 0:\r\n            # el fits inside child, add to child and return\r\n            _append_sorted(child, el, comparator)\r\n            return\r\n        if rel < 0:\r\n            # child fits inside el, move child into el (may move more than one)\r\n            _append_sorted(el, child, comparator)\r\n    # we weren't added to a child, so add to root\r\n    root.append(el)", "response": "Append el to the list root with the given comparator."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _box_in_box(el, child):\r\n    return all([\r\n        float(el.get('x0')) <= float(child.get('x0')),\r\n        float(el.get('x1')) >= float(child.get('x1')),\r\n        float(el.get('y0')) <= float(child.get('y0')),\r\n        float(el.get('y1')) >= float(child.get('y1')),\r\n    ])", "response": "Return True if el is contained within child."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn 1 if el in el2 else 0", "response": "def _comp_bbox(el, el2):\r\n    \"\"\" Return 1 if el in el2, -1 if el2 in el, else 0\"\"\"\r\n    # only compare if both elements have x/y coordinates\r\n    if _comp_bbox_keys_required <= set(el.keys()) and \\\r\n            _comp_bbox_keys_required <= set(el2.keys()):\r\n        if _box_in_box(el2, el):\r\n            return 1\r\n        if _box_in_box(el, el2):\r\n            return -1\r\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving an encoded string of unknown format detect the format with RequestException chardet and return the unicode version.", "response": "def smart_unicode_decode(encoded_string):\r\n    \"\"\"\r\n        Given an encoded string of unknown format, detect the format with\r\n        chardet and return the unicode version.\r\n        Example input from bug #11:\r\n         ('\\xfe\\xff\\x00I\\x00n\\x00s\\x00p\\x00e\\x00c\\x00t\\x00i\\x00o\\x00n\\x00'\r\n          '\\x00R\\x00e\\x00p\\x00o\\x00r\\x00t\\x00 \\x00v\\x002\\x00.\\x002')\r\n    \"\"\"\r\n    if not encoded_string:\r\n        return u''\r\n\r\n    # optimization -- first try ascii\r\n    try:\r\n        return encoded_string.decode('ascii')\r\n    except UnicodeDecodeError:\r\n        pass\r\n\r\n    # detect encoding\r\n    detected_encoding = chardet.detect(encoded_string)\r\n    # bug 54 -- depending on chardet version, if encoding is not guessed,\r\n    # either detected_encoding will be None or detected_encoding['encoding'] will be None\r\n    detected_encoding = detected_encoding['encoding'] if detected_encoding and detected_encoding.get('encoding') else 'utf8'\r\n    decoded_string = six.text_type(\r\n        encoded_string,\r\n        encoding=detected_encoding,\r\n        errors='replace'\r\n    )\r\n\r\n    # unicode string may still have useless BOM character at the beginning\r\n    if decoded_string and decoded_string[0] in bom_headers:\r\n        decoded_string = decoded_string[1:]\r\n\r\n    return decoded_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prepare_for_json_encoding(obj):\r\n    obj_type = type(obj)\r\n    if obj_type == list or obj_type == tuple:\r\n        return [prepare_for_json_encoding(item) for item in obj]\r\n    if obj_type == dict:\r\n        # alphabetizing keys lets us compare attributes for equality across runs\r\n        return OrderedDict(\r\n            (prepare_for_json_encoding(k),\r\n             prepare_for_json_encoding(obj[k])) for k in sorted(obj.keys())\r\n        )\r\n    if obj_type == six.binary_type:\r\n        return smart_unicode_decode(obj)\r\n    if obj_type == bool or obj is None or obj_type == six.text_type or isinstance(obj, numbers.Number):\r\n        return obj\r\n    if obj_type == PSLiteral:\r\n        # special case because pdfminer.six currently adds extra quotes to PSLiteral.__repr__\r\n        return u\"/%s\" % obj.name\r\n    return six.text_type(obj)", "response": "Convert an arbitrary object into just JSON data types."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef obj_to_string(obj, top=True):\r\n    obj = prepare_for_json_encoding(obj)\r\n    if type(obj) == six.text_type:\r\n        return obj\r\n    return json.dumps(obj)", "response": "Turn an arbitrary object into a unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the page number for the given index.", "response": "def get_page_number(self, index):\r\n        \"\"\"\r\n        Given an index, return page label as specified by\r\n        catalog['PageLabels']['Nums']\r\n\r\n        In a PDF, page labels are stored as a list of pairs, like\r\n        [starting_index, label_format, starting_index, label_format ...]\r\n\r\n        For example:\r\n        [0, {'S': 'D', 'St': 151}, 4, {'S':'R', 'P':'Foo'}]\r\n\r\n        So we have to first find the correct label_format based on the closest\r\n        starting_index lower than the requested index, then use the\r\n        label_format to convert the index to a page label.\r\n\r\n        Label format meaning:\r\n            /S = [\r\n                    D Decimal arabic numerals\r\n                    R Uppercase roman numerals\r\n                    r Lowercase roman numerals\r\n                    A Uppercase letters (A to Z for the first 26 pages, AA to ZZ\r\n                      for the next 26, and so on)\r\n                    a Lowercase letters (a to z for the first 26 pages, aa to zz\r\n                      for the next 26, and so on)\r\n                ] (if no /S, just use prefix ...)\r\n            /P = text string label\r\n            /St = integer start value\r\n        \"\"\"\r\n\r\n        # get and cache page ranges\r\n        if not hasattr(self, 'page_range_pairs'):\r\n            try:\r\n                page_ranges = resolve1(self.catalog['PageLabels'])['Nums']\r\n                assert len(page_ranges) > 1 and len(page_ranges) % 2 == 0\r\n                self.page_range_pairs = list(\r\n                    reversed(list(zip(page_ranges[::2], page_ranges[1::2]))))\r\n            except:\r\n                self.page_range_pairs = []\r\n\r\n        if not self.page_range_pairs:\r\n            return \"\"\r\n\r\n        # find page range containing index\r\n        for starting_index, label_format in self.page_range_pairs:\r\n            if starting_index <= index:\r\n                break  # we found correct label_format\r\n        label_format = resolve1(label_format)\r\n\r\n        page_label = \"\"\r\n\r\n        # handle numeric part of label\r\n        if 'S' in label_format:\r\n\r\n            # first find number for this page ...\r\n            page_label = index - starting_index\r\n            if 'St' in label_format:  # alternate start value\r\n                page_label += label_format['St']\r\n            else:\r\n                page_label += 1\r\n\r\n            # ... then convert to correct format\r\n            num_type = label_format['S'].name\r\n\r\n            # roman (upper or lower)\r\n            if num_type.lower() == 'r':\r\n                import roman\r\n                page_label = roman.toRoman(page_label)\r\n                if num_type == 'r':\r\n                    page_label = page_label.lower()\r\n\r\n            # letters\r\n            elif num_type.lower() == 'a':\r\n                # a to z for the first 26 pages, aa to zz for the next 26, and\r\n                # so on\r\n                letter = chr(page_label % 26 + 65)\r\n                letter *= page_label / 26 + 1\r\n                if num_type == 'a':\r\n                    letter = letter.lower()\r\n                page_label = letter\r\n\r\n            # decimal arabic\r\n            else:  # if num_type == 'D':\r\n                page_label = obj_to_string(page_label)\r\n\r\n        # handle string prefix\r\n        if 'P' in label_format:\r\n            page_label = smart_unicode_decode(label_format['P']) + page_label\r\n\r\n        return page_label"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(self, *page_numbers):\r\n        self.tree = self.get_tree(*_flatten(page_numbers))\r\n        self.pq = self.get_pyquery(self.tree)", "response": "Load the tree and pyquery objects for the given page numbers."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract(self, searches, tree=None, as_dict=True):\r\n        if self.tree is None or self.pq is None:\r\n            self.load()\r\n        if tree is None:\r\n            pq = self.pq\r\n        else:\r\n            pq = PyQuery(tree, css_translator=PDFQueryTranslator())\r\n        results = []\r\n        formatter = None\r\n        parent = pq\r\n        for search in searches:\r\n            if len(search) < 3:\r\n                search = list(search) + [formatter]\r\n            key, search, tmp_formatter = search\r\n            if key == 'with_formatter':\r\n                if isinstance(search, six.string_types):\r\n                    # is a pyquery method name, e.g. 'text'\r\n                    formatter = lambda o, search=search: getattr(o, search)()\r\n                elif hasattr(search, '__call__') or not search:\r\n                    # is a method, or None to end formatting\r\n                    formatter = search\r\n                else:\r\n                    raise TypeError(\"Formatter should be either a pyquery \"\r\n                                    \"method name or a callable function.\")\r\n            elif key == 'with_parent':\r\n                parent = pq(search) if search else pq\r\n            else:\r\n                try:\r\n                    result = parent(\"*\").filter(search) if \\\r\n                        hasattr(search, '__call__') else parent(search)\r\n                except cssselect.SelectorSyntaxError as e:\r\n                    raise cssselect.SelectorSyntaxError(\r\n                        \"Error applying selector '%s': %s\" % (search, e))\r\n                if tmp_formatter:\r\n                    result = tmp_formatter(result)\r\n                results += result if type(result) == tuple else [[key, result]]\r\n        if as_dict:\r\n            results = dict(results)\r\n        return results", "response": "Returns a list of lists of words in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_pyquery(self, tree=None, page_numbers=None):\r\n        if not page_numbers:\r\n            page_numbers = []\r\n        if tree is None:\r\n            if not page_numbers and self.tree is not None:\r\n                tree = self.tree\r\n            else:\r\n                tree = self.get_tree(page_numbers)\r\n        if hasattr(tree, 'getroot'):\r\n            tree = tree.getroot()\r\n        return PyQuery(tree, css_translator=PDFQueryTranslator())", "response": "Returns a PyQuery object for the given tree and page_numbers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a lxml. etree. ElementTree for the entire document or page numbers given if any.", "response": "def get_tree(self, *page_numbers):\r\n        \"\"\"\r\n            Return lxml.etree.ElementTree for entire document, or page numbers\r\n            given if any.\r\n        \"\"\"\r\n        cache_key = \"_\".join(map(str, _flatten(page_numbers)))\r\n        tree = self._parse_tree_cacher.get(cache_key)\r\n        if tree is None:\r\n            # set up root\r\n            root = parser.makeelement(\"pdfxml\")\r\n            if self.doc.info:\r\n                for k, v in list(self.doc.info[0].items()):\r\n                    k = obj_to_string(k)\r\n                    v = obj_to_string(resolve1(v))\r\n                    try:\r\n                        root.set(k, v)\r\n                    except ValueError as e:\r\n                        # Sometimes keys have a character in them, like ':',\r\n                        # that isn't allowed in XML attribute names.\r\n                        # If that happens we just replace non-word characters\r\n                        # with '_'.\r\n                        if \"Invalid attribute name\" in e.args[0]:\r\n                            k = re.sub('\\W', '_', k)\r\n                            root.set(k, v)\r\n\r\n            # Parse pages and append to root.\r\n            # If nothing was passed in for page_numbers, we do this for all\r\n            # pages, but if None was explicitly passed in, we skip it.\r\n            if not(len(page_numbers) == 1 and page_numbers[0] is None):\r\n                if page_numbers:\r\n                    pages = [[n, self.get_layout(self.get_page(n))] for n in\r\n                             _flatten(page_numbers)]\r\n                else:\r\n                    pages = enumerate(self.get_layouts())\r\n                for n, page in pages:\r\n                    page = self._xmlize(page)\r\n                    page.set('page_index', obj_to_string(n))\r\n                    page.set('page_label', self.doc.get_page_number(n))\r\n                    root.append(page)\r\n                self._clean_text(root)\r\n\r\n            # wrap root in ElementTree\r\n            tree = etree.ElementTree(root)\r\n            self._parse_tree_cacher.set(cache_key, tree)\r\n\r\n        return tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _clean_text(self, branch):\r\n        if branch.text and self.input_text_formatter:\r\n            branch.text = self.input_text_formatter(branch.text)\r\n        try:\r\n            for child in branch:\r\n                self._clean_text(child)\r\n                if branch.text and branch.text.find(child.text) >= 0:\r\n                    branch.text = branch.text.replace(child.text, '', 1)\r\n        except TypeError:  # not an iterable node\r\n            pass", "response": "Remove text from node if same text exists in its children."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn dictionary of given attrs on given object.", "response": "def _getattrs(self, obj, *attrs):\r\n        \"\"\" Return dictionary of given attrs on given object, if they exist,\r\n        processing through _filter_value().\r\n        \"\"\"\r\n        filtered_attrs = {}\r\n        for attr in attrs:\r\n            if hasattr(obj, attr):\r\n                filtered_attrs[attr] = obj_to_string(\r\n                    self._filter_value(getattr(obj, attr))\r\n                )\r\n        return filtered_attrs"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget PDFMiner Layout object for given page object or page number.", "response": "def get_layout(self, page):\r\n        \"\"\" Get PDFMiner Layout object for given page object or page number. \"\"\"\r\n        if type(page) == int:\r\n            page = self.get_page(page)\r\n        self.interpreter.process_page(page)\r\n        layout = self.device.get_result()\r\n        layout = self._add_annots(layout, page.annots)\r\n        return layout"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a page or all pages from page generator caching results.", "response": "def _cached_pages(self, target_page=-1):\r\n        \"\"\"\r\n        Get a page or all pages from page generator, caching results.\r\n        This is necessary because PDFMiner searches recursively for pages,\r\n        so we won't know how many there are until we parse the whole document,\r\n        which we don't want to do until we need to.\r\n        \"\"\"\r\n        try:\r\n            # pdfminer < 20131022\r\n            self._pages_iter = self._pages_iter or self.doc.get_pages()\r\n        except AttributeError:\r\n            # pdfminer >= 20131022\r\n            self._pages_iter = self._pages_iter or \\\r\n                PDFPage.create_pages(self.doc)\r\n\r\n        if target_page >= 0:\r\n            while len(self._pages) <= target_page:\r\n                next_page = next(self._pages_iter)\r\n                if not next_page:\r\n                    return None\r\n                next_page.page_number = 0\r\n                self._pages += [next_page]\r\n            try:\r\n                return self._pages[target_page]\r\n            except IndexError:\r\n                return None\r\n        self._pages += list(self._pages_iter)\r\n        return self._pages"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _add_annots(self, layout, annots):\r\n        if annots:\r\n            for annot in resolve1(annots):\r\n                annot = resolve1(annot)\r\n                if annot.get('Rect') is not None:\r\n                    annot['bbox'] = annot.pop('Rect')  # Rename key\r\n                    annot = self._set_hwxy_attrs(annot)\r\n                try:\r\n                    annot['URI'] = resolve1(annot['A'])['URI']\r\n                except KeyError:\r\n                    pass\r\n                for k, v in six.iteritems(annot):\r\n                    if not isinstance(v, six.string_types):\r\n                        annot[k] = obj_to_string(v)\r\n                elem = parser.makeelement('Annot', annot)\r\n                layout.add(elem)\r\n        return layout", "response": "Adds annotations to the given layout object\r\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_hwxy_attrs(attr):\r\n        bbox = attr['bbox']\r\n        attr['x0'] = bbox[0]\r\n        attr['x1'] = bbox[2]\r\n        attr['y0'] = bbox[1]\r\n        attr['y1'] = bbox[3]\r\n        attr['height'] = attr['y1'] - attr['y0']\r\n        attr['width'] = attr['x1'] - attr['x0']\r\n        return attr", "response": "Set the x0 y0 and x1 y0 and y1 attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if result is True.", "response": "def _check_bool(result, func, args):  # pylint: disable=unused-argument\n    \"\"\"\n    Used as an error handler for Windows calls\n    Gets last error if call is not successful\n    \"\"\"\n\n    if not result:\n        raise ctypes.WinError(ctypes.get_last_error())\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a CONSOLE_SCREEN_BUFFER_INFO structure for the given console or stdout", "response": "def get_csbi(filehandle=None):\n    \"\"\"\n    Returns a CONSOLE_SCREEN_BUFFER_INFO structure for the given console or stdout\n    \"\"\"\n\n    if filehandle is None:\n        filehandle = msvcrt.get_osfhandle(sys.__stdout__.fileno())\n\n    csbi = ConsoleScreenBufferInfo()\n    KERNEL32.GetConsoleScreenBufferInfo(filehandle, ctypes.byref(csbi))\n    return csbi"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nenables virtual terminal processing mode for the given console or stdout.", "response": "def enable_vt_mode(filehandle=None):\n    \"\"\"\n    Enables virtual terminal processing mode for the given console or stdout\n    \"\"\"\n\n    if filehandle is None:\n        filehandle = msvcrt.get_osfhandle(sys.__stdout__.fileno())\n\n    current_mode = wintypes.DWORD()\n    KERNEL32.GetConsoleMode(filehandle, ctypes.byref(current_mode))\n    new_mode = 0x0004 | current_mode.value\n    KERNEL32.SetConsoleMode(filehandle, new_mode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a method that applies a color to the given color.", "response": "def create_color_method(color, code):\n    \"\"\"\n    Create a function for the given color\n    Done inside this function to keep the variables out of the main scope\n    \"\"\"\n\n    def func(self, content=''):\n        return self._apply_color(code, content)  # pylint: disable=protected-access\n\n    setattr(Terminal, color, func)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply a color code to text", "response": "def _apply_color(code, content):\n        \"\"\"\n        Apply a color code to text\n        \"\"\"\n\n        normal = u'\\x1B[0m'\n        seq = u'\\x1B[%sm' % code\n\n        # Replace any normal sequences with this sequence to support nested colors\n        return seq + (normal + seq).join(content.split(normal)) + normal"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef color(self, code):\n\n        def func(content=''):\n            return self._apply_color(u'38;5;%d' % code, content)\n        return func", "response": "Color function that returns a function that applies that color to the content of the content\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _height_and_width(self):\n\n        # In Python 3.3+ we can let the standard library handle this\n        if GTS_SUPPORTED:\n            return os.get_terminal_size(self.stream_fd)\n\n        window = get_csbi(self.stream_fh).srWindow\n        return TerminalSize(window.Right - window.Left + 1, window.Bottom - window.Top + 1)", "response": "Query console for dimensions\n        Returns named tuple"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading all files from an FTP share", "response": "def download():\n    \"\"\"\n    Download all files from an FTP share\n    \"\"\"\n\n    ftp = ftplib.FTP(SITE)\n    ftp.set_debuglevel(DEBUG)\n    ftp.login(USER, PASSWD)\n    ftp.cwd(DIR)\n    filelist = ftp.nlst()\n    filecounter = MANAGER.counter(total=len(filelist), desc='Downloading',\n                                  unit='files')\n\n    for filename in filelist:\n\n        with Writer(filename, ftp.size(filename), DEST) as writer:\n            ftp.retrbinary('RETR %s' % filename, writer.write)\n        print(filename)\n        filecounter.update()\n\n    ftp.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites to local file and update progress bar", "response": "def write(self, block):\n        \"\"\"\n        Write to local file and update progress bar\n        \"\"\"\n        self.fileobj.write(block)\n        self.status.update(len(block))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_files():\n\n    with enlighten.Manager() as manager:\n        with manager.counter(total=SPLINES, desc='Reticulating:', unit='splines') as retic:\n            for num in range(SPLINES):  # pylint: disable=unused-variable\n                time.sleep(random.uniform(0.1, 0.5))  # Random processing time\n                retic.update()\n\n        with manager.counter(total=LLAMAS, desc='Herding:', unit='llamas') as herd:\n            for num in range(SPLINES):  # pylint: disable=unused-variable\n                time.sleep(random.uniform(0.1, 0.5))  # Random processing time\n                herd.update()", "response": "Process the files in the sequence of base context."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_version(filename, encoding='utf8'):\n\n    with io.open(filename, encoding=encoding) as sourcecode:\n        for line in sourcecode:\n            version = RE_VERSION.match(line)\n            if version:\n                return version.group(1)\n\n    return None", "response": "Get the version of the __version__ definition out of a source file"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads the contents of a file", "response": "def readme(filename, encoding='utf8'):\n    \"\"\"\n    Read the contents of a file\n    \"\"\"\n\n    with io.open(filename, encoding=encoding) as source:\n        return source.read()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint misspelled words returned by sphinxcontrib - spelling", "response": "def print_spelling_errors(filename, encoding='utf8'):\n    \"\"\"\n    Print misspelled words returned by sphinxcontrib-spelling\n    \"\"\"\n\n    filesize = os.stat(filename).st_size\n    if filesize:\n        sys.stdout.write('Misspelled Words:\\n')\n        with io.open(filename, encoding=encoding) as wordlist:\n            for line in wordlist:\n                sys.stdout.write('    ' + line)\n\n    return 1 if filesize else 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initialize(manager, initials=15):\n\n    # Simulated preparation\n    pbar = manager.counter(total=initials, desc='Initializing:', unit='initials')\n    for num in range(initials):  # pylint: disable=unused-variable\n        time.sleep(random.uniform(0.1, 0.5))  # Random processing time\n        pbar.update()\n    pbar.close()", "response": "Initialize a random\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_manager(stream=None, counterclass=Counter, **kwargs):\n\n    stream = stream or sys.stdout\n    isatty = hasattr(stream, 'isatty') and stream.isatty()\n    kwargs['enabled'] = isatty and kwargs.get('enabled', True)\n    return Manager(stream=stream, counterclass=counterclass, **kwargs)", "response": "Returns a manager instance for the current state of the current element."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new instance of Counter class.", "response": "def counter(self, position=None, **kwargs):\n        \"\"\"\n        Args:\n            position(int): Line number counting from the bottom of the screen\n            kwargs(dict): Any additional :py:term:`keyword arguments<keyword argument>`\n                are passed to :py:class:`Counter`\n\n        Returns:\n            :py:class:`Counter`: Instance of counter class\n\n        Get a new progress bar instance\n\n        If ``position`` is specified, the counter's position can change dynamically if\n        additional counters are called without a ``position`` argument.\n\n        \"\"\"\n\n        for key, val in self.defaults.items():\n            if key not in kwargs:\n                kwargs[key] = val\n        kwargs['manager'] = self\n\n        counter = self.counter_class(**kwargs)\n\n        if position is None:\n            toRefresh = []\n            if self.counters:\n                pos = 2\n                for cter in reversed(self.counters):\n                    if self.counters[cter] < pos:\n                        toRefresh.append(cter)\n                        cter.clear(flush=False)\n                        self.counters[cter] = pos\n                        pos += 1\n\n            self.counters[counter] = 1\n            self._set_scroll_area()\n            for cter in reversed(toRefresh):\n                cter.refresh(flush=False)\n            self.stream.flush()\n\n        elif position in self.counters.values():\n            raise ValueError('Counter position %d is already occupied.' % position)\n        elif position > self.height:\n            raise ValueError('Counter position %d is greater than terminal height.' % position)\n        else:\n            self.counters[counter] = position\n\n        return counter"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _resize_handler(self, *args, **kwarg):  # pylint: disable=unused-argument\n\n        # Make sure only one resize handler is running\n        try:\n            assert self.resize_lock\n        except AssertionError:\n\n            self.resize_lock = True\n            term = self.term\n\n            term.clear_cache()\n            newHeight = term.height\n            newWidth = term.width\n            lastHeight = lastWidth = 0\n\n            while newHeight != lastHeight or newWidth != lastWidth:\n                lastHeight = newHeight\n                lastWidth = newWidth\n                time.sleep(.2)\n                term.clear_cache()\n                newHeight = term.height\n                newWidth = term.width\n\n            if newWidth < self.width:\n                offset = (self.scroll_offset - 1) * (1 + self.width // newWidth)\n                term.move_to(0, max(0, newHeight - offset))\n                self.stream.write(term.clear_eos)\n\n            self.width = newWidth\n            self._set_scroll_area(force=True)\n\n            for cter in self.counters:\n                cter.refresh(flush=False)\n            self.stream.flush()\n\n            self.resize_lock = False", "response": "Called when a window resize signal is detected and resizes the scroll window."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the scroll area based on the counter positions and the terminal height.", "response": "def _set_scroll_area(self, force=False):\n        \"\"\"\n        Args:\n            force(bool): Set the scroll area even if no change in height and position is detected\n\n        Sets the scroll window based on the counter positions\n        \"\"\"\n\n        # Save scroll offset for resizing\n        oldOffset = self.scroll_offset\n        self.scroll_offset = newOffset = max(self.counters.values()) + 1\n\n        if not self.enabled:\n            return\n\n        # Set exit handling only once\n        if not self.process_exit:\n            atexit.register(self._at_exit)\n            if not self.no_resize and RESIZE_SUPPORTED:\n                signal.signal(signal.SIGWINCH, self._resize_handler)\n            self.process_exit = True\n\n        if self.set_scroll:\n\n            term = self.term\n            newHeight = term.height\n            scrollPosition = max(0, newHeight - newOffset)\n\n            if force or newOffset > oldOffset or newHeight != self.height:\n                self.height = newHeight\n\n                # Add line feeds so we don't overwrite existing output\n                if newOffset - oldOffset > 0:\n                    term.move_to(0, max(0, newHeight - oldOffset))\n                    self.stream.write('\\n' * (newOffset - oldOffset))\n\n                # Reset scroll area\n                self.term.change_scroll(scrollPosition)\n\n            # Always reset position\n            term.move_to(0, scrollPosition)\n            if self.companion_term:\n                self.companion_term.move_to(0, scrollPosition)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreset terminal to normal configuration and feeds to the terminal.", "response": "def _at_exit(self):\n        \"\"\"\n        Resets terminal to normal configuration\n        \"\"\"\n\n        if self.process_exit:\n\n            try:\n\n                term = self.term\n\n                if self.set_scroll:\n                    term.reset()\n                else:\n                    term.move_to(0, term.height)\n\n                self.term.feed()\n\n            except ValueError:  # Possibly closed file handles\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstop the terminal and reset all counters and manager.", "response": "def stop(self):\n        \"\"\"\n        Clean up and reset terminal\n\n        This method should be called when the manager and counters will no longer be needed.\n\n        Any progress bars that have ``leave`` set to :py:data:`True` or have not been closed\n        will remain on the console. All others will be cleared.\n\n        Manager and all counters will be disabled.\n\n        \"\"\"\n\n        if self.enabled:\n\n            term = self.term\n            stream = self.stream\n            positions = self.counters.values()\n\n            if not self.no_resize and RESIZE_SUPPORTED:\n                signal.signal(signal.SIGWINCH, self.sigwinch_orig)\n\n            try:\n                for num in range(self.scroll_offset - 1, 0, -1):\n                    if num not in positions:\n                        term.move_to(0, term.height - num)\n                        stream.write(term.clear_eol)\n\n                stream.flush()\n\n            finally:\n\n                if self.set_scroll:\n\n                    self.term.reset()\n\n                    if self.companion_term:\n                        self.companion_term.reset()\n\n                else:\n                    term.move_to(0, term.height)\n\n                self.process_exit = False\n                self.enabled = False\n                for cter in self.counters:\n                    cter.enabled = False\n\n            # Feed terminal if lowest position isn't cleared\n            if 1 in positions:\n                term.feed()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write(self, output='', flush=True, position=0):\n\n        if self.enabled:\n\n            term = self.term\n            stream = self.stream\n\n            try:\n                term.move_to(0, term.height - position)\n                # Include \\r and term call to cover most conditions\n                if NEEDS_UNICODE_HELP:  # pragma: no cover (Version dependent 2.6)\n                    encoding = stream.encoding or 'UTF-8'\n                    stream.write(('\\r' + term.clear_eol + output).encode(encoding))\n                else:  # pragma: no cover (Version dependent >= 2.7)\n                    stream.write('\\r' + term.clear_eol + output)\n\n            finally:\n                # Reset position and scrolling\n                self._set_scroll_area()\n                if flush:\n                    stream.flush()", "response": "Writes the term to the output stream at the given position."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _format_time(seconds):\n\n    # Always do minutes and seconds in mm:ss format\n    minutes = seconds // 60\n    hours = minutes // 60\n    rtn = u'{0:02.0f}:{1:02.0f}'.format(minutes % 60, seconds % 60)\n\n    #  Add hours if there are any\n    if hours:\n\n        rtn = u'{0:d}h {1}'.format(int(hours % 24), rtn)\n\n        #  Add days if there are any\n        days = int(hours // 24)\n        if days:\n            rtn = u'{0:d}d {1}'.format(days, rtn)\n\n    return rtn", "response": "Format time string for eta and elapsed\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _colorize(self, content):\n\n        if self.color is None:\n            return content\n\n        if self._color and self._color[0] == self.color:\n            return self._color[1](content)\n\n        if self.color in COLORS:\n            spec = getattr(self.manager.term, self.color)\n        else:\n            spec = self.manager.term.color(self.color)\n\n        self._color = (self.color, spec)\n        return spec(content)", "response": "Colorize the content with the specified color"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the count and the parent s count.", "response": "def update(self, incr=1, force=False):\n        \"\"\"\n        Args:\n            incr(int): Amount to increment ``count`` (Default: 1)\n            force(bool): Force refresh even if ``min_delta`` has not been reached\n\n        Increment progress bar and redraw\n\n        Both this counter and the parent are incremented.\n\n        Progress bar is only redrawn if min_delta seconds past since the last update on the parent.\n        \"\"\"\n\n        self.count += incr\n        self.parent.update(incr, force)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_from(self, source, incr=1, force=False):\n\n        # Make sure source is a parent or peer\n        if source is self.parent or getattr(source, 'parent', None) is self.parent:\n\n            if self.count + incr < 0 or source.count - incr < 0:\n                raise ValueError('Invalid increment: %s' % incr)\n\n            if source is self.parent:\n                if self.parent.count - self.parent.subcount - incr < 0:\n                    raise ValueError('Invalid increment: %s' % incr)\n\n            else:\n                source.count -= incr\n\n            self.count += incr\n            self.parent.update(0, force)\n\n        else:\n            raise ValueError('source must be parent or peer')", "response": "Update the count of this counter from the source."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef elapsed(self):\n\n        # Clock stops running when total is reached\n        if self.count == self.total:\n            elapsed = self.last_update - self.start\n        else:\n            elapsed = time.time() - self.start\n\n        return elapsed", "response": "Get elapsed time is seconds"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclear the current state of the current object.", "response": "def clear(self, flush=True):\n        \"\"\"\n        Args:\n            flush(bool): Flush stream after clearing progress bar (Default:True)\n\n        Clear progress bar\n        \"\"\"\n\n        if self.enabled:\n            self.manager.write(flush=flush, position=self.position)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndoes final refresh and remove from manager", "response": "def close(self, clear=False):\n        \"\"\"\n        Do final refresh and remove from manager\n\n        If ``leave`` is True, the default, the effect is the same as :py:meth:`refresh`.\n        \"\"\"\n\n        if clear and not self.leave:\n            self.clear()\n        else:\n            self.refresh()\n\n        self.manager.remove(self)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_subcounters(self, elapsed):\n\n        fields = {}\n        subcounters = []\n\n        for num, subcounter in enumerate(self._subcounters, 1):\n\n            if self.total:\n                subPercentage = subcounter.count / float(self.total)\n            else:\n                subPercentage = 0.0\n\n            # Save in tuple: count, percentage, color\n            subcounters.append((subcounter, subPercentage))\n\n            # Set fields\n            fields['percentage_{0}'.format(num)] = subPercentage * 100\n            fields['count_{0}'.format(num)] = subcounter.count\n\n            if subcounter.all_fields:\n\n                interations = abs(subcounter.count - subcounter.start_count)\n\n                if elapsed:\n                    # Use float to force to float in Python 2\n                    rate = fields['rate_{0}'.format(num)] = interations / float(elapsed)\n                else:\n                    rate = fields['rate_{0}'.format(num)] = 0.0\n\n                if self.total == 0:\n                    fields['eta_{0}'.format(num)] = u'00:00'\n                elif rate:\n                    fields['eta_{0}'.format(num)] = _format_time((self.total - interations) / rate)\n                else:\n                    fields['eta_{0}'.format(num)] = u'?'\n\n        return subcounters, fields", "response": "Returns a list of subcounters and a dictionary of additional fields."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format(self, width=None, elapsed=None):\n\n        width = width or self.manager.width\n\n        iterations = abs(self.count - self.start_count)\n\n        fields = {'bar': u'{0}',\n                  'count': self.count,\n                  'desc': self.desc or u'',\n                  'total': self.total,\n                  'unit': self.unit or u'',\n                  'desc_pad': u' ' if self.desc else u'',\n                  'unit_pad': u' ' if self.unit else u''}\n\n        # Get elapsed time\n        if elapsed is None:\n            elapsed = self.elapsed\n\n        fields['elapsed'] = _format_time(elapsed)\n\n        # Get rate. Elapsed could be 0 if counter was not updated and has a zero total.\n        if elapsed:\n            # Use iterations so a counter running backwards is accurate\n            fields['rate'] = iterations / elapsed\n        else:\n            fields['rate'] = 0.0\n\n        # Only process bar if total was given and n doesn't exceed total\n        if self.total is not None and self.count <= self.total:\n\n            fields['len_total'] = len(str(self.total))\n\n            # Get percentage\n            if self.total == 0:\n                # If total is 0, force to 100 percent\n                percentage = 1\n                fields['eta'] = u'00:00'\n            else:\n                # Use float to force to float in Python 2\n                percentage = self.count / float(self.total)\n\n                # Get eta\n                if fields['rate']:\n                    # Use iterations so a counter running backwards is accurate\n                    fields['eta'] = _format_time((self.total - iterations) / fields['rate'])\n                else:\n                    fields['eta'] = u'?'\n\n            fields['percentage'] = percentage * 100\n\n            # Have to go through subcounters here so the fields are available\n            subcounters, subFields = self._get_subcounters(elapsed)\n\n            # Calculate count and percentage for remainder\n            if subcounters:\n                fields.update(subFields)\n                fields['count_0'] = self.count - sum(sub[0].count for sub in subcounters)\n                fields['percentage_0'] = (percentage - sum(sub[1] for sub in subcounters)) * 100\n\n            # Partially format\n            rtn = self.bar_format.format(**fields)\n\n            # Format the bar\n            barWidth = width - len(rtn) + self.offset + 3  # 3 is for the bar placeholder\n            complete = barWidth * percentage\n            barLen = int(complete)\n            barText = u''\n            subOffset = 0\n\n            for subcounter, subPercentage in reversed(subcounters):\n                subLen = int(barWidth * subPercentage)\n                # pylint: disable=protected-access\n                barText += subcounter._colorize(self.series[-1] * subLen)\n                subOffset += subLen\n\n            barText += self.series[-1] * (barLen - subOffset)\n\n            if barLen < barWidth:\n                barText += self.series[int(round((complete - barLen) * (len(self.series) - 1)))]\n                barText += self.series[0] * (barWidth - barLen - 1)\n\n            return rtn.format(self._colorize(barText))\n\n        # Otherwise return a counter\n        fields['fill'] = u'{0}'\n        rtn = self.counter_format.format(**fields)\n        return rtn.format(u' ' * (width - len(rtn) + self.offset + 3))", "response": "Formats the progress bar or counter for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrefresh the progress bar.", "response": "def refresh(self, flush=True, elapsed=None):\n        \"\"\"\n        Args:\n            flush(bool): Flush stream after writing progress bar (Default:True)\n            elapsed(float): Time since started. Automatically determined if :py:data:`None`\n\n        Redraw progress bar\n        \"\"\"\n\n        if self.enabled:\n            self.manager.write(output=self.format(elapsed=elapsed),\n                               flush=flush, position=self.position)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, incr=1, force=False):\n\n        self.count += incr\n        if self.enabled:\n            currentTime = time.time()\n            # Update if force, 100%, or minimum delta has been reached\n            if force or self.count == self.total or \\\n                    currentTime - self.last_update >= self.min_delta:\n                self.last_update = currentTime\n                self.refresh(elapsed=currentTime - self.start)", "response": "Updates the count of the object with the given amount."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_subcounter(self, color, count=0, all_fields=False):\n\n        subcounter = SubCounter(self, color=color, count=count, all_fields=all_fields)\n        self._subcounters.append(subcounter)\n        return subcounter", "response": "Add a subcounter to the multicolored progress bars."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_files(manager):\n\n    # Get a top level progress bar\n    enterprise = manager.counter(total=DATACENTERS, desc='Processing:', unit='datacenters')\n\n    # Iterate through data centers\n    for dnum in range(1, DATACENTERS + 1):\n        systems = random.randint(*SYSTEMS)  # Random number of systems\n        # Get a child progress bar. leave is False so it can be replaced\n        currCenter = manager.counter(total=systems, desc='  Datacenter %d:' % dnum,\n                                     unit='systems', leave=False)\n\n        # Iterate through systems\n        for snum in range(1, systems + 1):\n\n            # Has no total, so will act as counter. Leave is False\n            system = manager.counter(desc='    System %d:' % snum, unit='files', leave=False)\n            files = random.randint(*FILES)  # Random file count\n\n            # Iterate through files\n            for fnum in range(files):  # pylint: disable=unused-variable\n                system.update()  # Update count\n                time.sleep(random.uniform(0.0001, 0.0005))  # Random processing time\n\n            system.close()  # Close counter so it gets removed\n            # Log status\n            LOGGER.info('Updated %d files on System %d in Datacenter %d', files, snum, dnum)\n            currCenter.update()  # Update count\n\n        currCenter.close()  # Close counter so it gets removed\n\n        enterprise.update()  # Update count\n\n    enterprise.close()", "response": "Process a random number of files on a random number of systems across multiple data centers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprocess files with a single progress bar", "response": "def process_files():\n    \"\"\"\n    Process files with a single progress bar\n    \"\"\"\n\n    with enlighten.Counter(total=100, desc='Simple', unit='ticks') as pbar:\n        for num in range(100):  # pylint: disable=unused-variable\n            time.sleep(0.05)\n            pbar.update()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload a single node from a remote node.", "response": "def load(manager, units=80):\n    \"\"\"\n    Simulate loading services from a remote node\n    States are connecting (red), loading(yellow), and loaded (green)\n    \"\"\"\n\n    pb_connecting = manager.counter(total=units, desc='Loading', unit='services',\n                                    color='red', bar_format=BAR_FMT)\n    pb_loading = pb_connecting.add_subcounter('yellow')\n    pb_loaded = pb_connecting.add_subcounter('green', all_fields=True)\n\n    connecting = []\n    loading = []\n    loaded = []\n    count = 0\n\n    while pb_loaded.count < units:\n        time.sleep(random.uniform(0.05, 0.15))  # Random processing time\n\n        for idx, node in enumerate(loading):\n            if node.loaded:\n                loading.pop(idx)\n                loaded.append(node)\n                LOGGER.info('Service %d loaded', node.iden)\n                pb_loaded.update_from(pb_loading)\n\n        for idx, node in enumerate(connecting):\n            if node.connected:\n                connecting.pop(idx)\n                node.load()\n                loading.append(node)\n                LOGGER.info('Service %d connected', node.iden)\n                pb_loading.update_from(pb_connecting)\n\n        # Connect to up to 5 units at a time\n        for _ in range(0, min(units - count, 5 - len(connecting))):\n            node = Node(count)\n            node.connect()\n            connecting.append(node)\n            LOGGER.info('Connection to service %d', node.iden)\n            pb_connecting.update()\n            count += 1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _state(self, variable, num):\n\n        value = getattr(self, variable)\n\n        if value is None:\n            return False\n\n        if value is True:\n            return True\n\n        if random.randint(1, num) == num:\n            setattr(self, variable, True)\n            return True\n\n        return False", "response": "Generic method to randomly determine if state is reached in the current state."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess files with a single progress bar", "response": "def process_files(count=None):\n    \"\"\"\n    Process files with a single progress bar\n    \"\"\"\n\n    pbar = enlighten.Counter(total=count, desc='Simple', unit='ticks',\n                             bar_format=BAR_FMT, counter_format=COUNTER_FMT)\n\n    for num in range(100):  # pylint: disable=unused-variable\n        time.sleep(0.05)\n        pbar.update(1.1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reset(self):\n\n        self.stream.write(self.normal_cursor)\n        self.stream.write(self.csr(0, self.height))\n        self.stream.write(self.move(self.height, 0))", "response": "Reset scroll window and cursor to default"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef change_scroll(self, position):\n\n        self.stream.write(self.hide_cursor)\n        self.stream.write(self.csr(0, position))\n        self.stream.write(self.move(position, 0))", "response": "Args:\n            position (int): Vertical location to end scroll window\n\n        Change scroll window"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef move_to(self, xpos, ypos):\n\n        self.stream.write(self.move(ypos, xpos))", "response": "Move cursor to specified position."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\noverrides for blessings. Terminal. _height_and_width Adds caching", "response": "def _height_and_width(self):\n        \"\"\"\n        Override for blessings.Terminal._height_and_width\n        Adds caching\n        \"\"\"\n\n        try:\n            return self._cache['height_and_width']\n        except KeyError:\n            handw = self._cache['height_and_width'] = super(Terminal, self)._height_and_width()\n            return handw"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncaptures locals module name filename and line number from the stacktrace to provide the source of the assertion error and the formatted note.", "response": "def get_stack_info():\n    '''Capture locals, module name, filename, and line number from the\n    stacktrace to provide the source of the assertion error and\n    formatted note.\n    '''\n    stack = traceback.walk_stack(sys._getframe().f_back)\n\n    # We want locals from the test definition (which always begins\n    # with 'test_' in unittest), which will be at a different\n    # level in the stack depending on how many tests are in each\n    # test case, how many test cases there are, etc.\n\n    # The branch where we exhaust this loop is not covered\n    # because we always find a test.\n    for frame, _ in stack:  # pragma: no branch\n        code = frame.f_code\n        if code.co_name.startswith('test_'):\n            return (frame.f_locals.copy(), frame.f_globals['__name__'],\n                    code.co_filename, frame.f_lineno)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef assertBetween(self, obj, lower, upper, strict=True, msg=None):\n        '''Fail if ``obj`` is not between ``lower`` and ``upper``.\n\n        If ``strict=True`` (default), fail unless\n        ``lower < obj < upper``. If ``strict=False``, fail unless\n        ``lower <= obj <= upper``.\n\n        This is equivalent to ``self.assertTrue(lower < obj < upper)``\n        or ``self.assertTrue(lower <= obj <= upper)``, but with a nicer\n        default message.\n\n        Parameters\n        ----------\n        obj\n        lower\n        upper\n        strict : bool\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n        '''\n        if strict:\n            standardMsg = '%s is not strictly between %s and %s' % (\n                    obj, lower, upper)\n            op = operator.lt\n        else:\n            standardMsg = '%s is not between %s and %s' % (obj, lower, upper)\n            op = operator.le\n\n        if not (op(lower, obj) and op(obj, upper)):\n            self.fail(self._formatMessage(msg, standardMsg))", "response": "Fail if obj is not between lower and upper."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef assertMonotonicIncreasing(self, sequence, strict=True, msg=None):\n        '''Fail if ``sequence`` is not monotonically increasing.\n\n        If ``strict=True`` (default), fail unless each element in\n        ``sequence`` is less than the following element as determined\n        by the ``<`` operator. If ``strict=False``, fail unless each\n        element in ``sequence`` is less than or equal to the following\n        element as determined by the ``<=`` operator.\n\n        .. code-block:: python\n\n            assert all((i < j) for i, j in zip(sequence, sequence[1:]))\n            assert all((i <= j) for i, j in zip(sequence, sequence[1:]))\n\n        Parameters\n        ----------\n        sequence : iterable\n        strict : bool\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``sequence`` is not iterable.\n        '''\n        if not isinstance(sequence, collections.Iterable):\n            raise TypeError('First argument is not iterable')\n\n        if strict:\n            standardMsg = ('Elements in %s are not strictly monotonically '\n                           'increasing') % (sequence,)\n            op = operator.lt\n        else:\n            standardMsg = ('Elements in %s are not monotonically '\n                           'increasing') % (sequence,)\n            op = operator.le\n\n        if not self._monotonic(op, sequence):\n            self.fail(self._formatMessage(msg, standardMsg))", "response": "Fail if sequence is not monotonically increasing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfailing if sequence is monotonically decreasing.", "response": "def assertNotMonotonicDecreasing(self, sequence, strict=True, msg=None):\n        '''Fail if ``sequence`` is monotonically decreasing.\n\n        If ``strict=True`` (default), fail if each element in\n        ``sequence`` is greater than the following element as\n        determined by the ``>`` operator. If ``strict=False``, fail if\n        each element in ``sequence`` is greater than or equal to the\n        following element as determined by the ``>=`` operator.\n\n        .. code-block:: python\n\n            assert not all((i > j) for i, j in zip(sequence, sequence[1:]))\n            assert not all((i >= j) for i, j in zip(sequence, sequence[1:]))\n\n        Parameters\n        ----------\n        sequence : iterable\n        strict : bool\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``sequence`` is not iterable.\n        '''\n        if not isinstance(sequence, collections.Iterable):\n            raise TypeError('First argument is not iterable')\n\n        if strict:\n            standardMsg = ('Elements in %s are strictly monotonically '\n                           'decreasing') % (sequence,)\n            op = operator.gt\n        else:\n            standardMsg = ('Elements in %s are monotonically '\n                           'decreasing') % (sequence,)\n            op = operator.ge\n\n        if self._monotonic(op, sequence):\n            self.fail(self._formatMessage(msg, standardMsg))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfails if elements in container are not unique.", "response": "def assertUnique(self, container, msg=None):\n        '''Fail if elements in ``container`` are not unique.\n\n        Parameters\n        ----------\n        container : iterable\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``container`` is not iterable.\n        '''\n        if not isinstance(container, collections.Iterable):\n            raise TypeError('First argument is not iterable')\n\n        standardMsg = 'Elements in %s are not unique' % (container,)\n\n        # We iterate over each element in the container instead of\n        # comparing len(container) == len(set(container)) to allow\n        # for containers that contain unhashable types\n        for idx, elem in enumerate(container):\n            # If elem appears at an earlier or later index position\n            # the elements are not unique\n            if elem in container[:idx] or elem in container[idx+1:]:\n                self.fail(self._formatMessage(msg, standardMsg))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_or_open_file(filename):\n        '''If ``filename`` is a string or bytes object, open the\n        ``filename`` and return the file object. If ``filename`` is\n        file-like (i.e., it has 'read' and 'write' attributes, return\n        ``filename``.\n\n        Parameters\n        ----------\n        filename : str, bytes, file\n\n        Raises\n        ------\n        TypeError\n            If ``filename`` is not a string, bytes, or file-like\n            object.\n\n            File-likeness is determined by checking for 'read' and\n            'write' attributes.\n        '''\n        if isinstance(filename, (str, bytes)):\n            f = open(filename)\n        elif hasattr(filename, 'read') and hasattr(filename, 'write'):\n            f = filename\n        else:\n            raise TypeError('filename must be str or bytes, or a file')\n        return f", "response": "Open the file object and return the file object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef assertFileExists(self, filename, msg=None):\n        '''Fail if ``filename`` does not exist as determined by\n        ``os.path.isfile(filename)``.\n\n        Parameters\n        ----------\n        filename : str, bytes\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n        '''\n        standardMsg = '%s does not exist' % filename\n\n        if not os.path.isfile(filename):\n            self.fail(self._formatMessage(msg, standardMsg))", "response": "Fail if filename does not exist as determined by\n        os. path. isfile ( filename )."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfailing if filename does not have the given name as is not a file - like object.", "response": "def assertFileNameEqual(self, filename, name, msg=None):\n        '''Fail if ``filename`` does not have the given ``name`` as\n        determined by the ``==`` operator.\n\n        Parameters\n        ----------\n        filename : str, bytes, file-like\n        name : str, byes\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``filename`` is not a str or bytes object and is not\n            file-like.\n        '''\n        fname = self._get_file_name(filename)\n        self.assertEqual(fname, name, msg=msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef assertFileNameNotEqual(self, filename, name, msg=None):\n        '''Fail if ``filename`` has the given ``name`` as determined\n        by the ``!=`` operator.\n\n        Parameters\n        ----------\n        filename : str, bytes, file-like\n        name : str, byes\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``filename`` is not a str or bytes object and is not\n            file-like.\n        '''\n        fname = self._get_file_name(filename)\n        self.assertNotEqual(fname, name, msg=msg)", "response": "Fail if filename has the given name as determined\n            by the! = operator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfailing unless filename matches expected_regex.", "response": "def assertFileNameRegex(self, filename, expected_regex, msg=None):\n        '''Fail unless ``filename`` matches ``expected_regex``.\n\n        Parameters\n        ----------\n        filename : str, bytes, file-like\n        expected_regex : str, bytes\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``filename`` is not a str or bytes object and is not\n            file-like.\n        '''\n        fname = self._get_file_name(filename)\n        self.assertRegex(fname, expected_regex, msg=msg)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef assertFileNameNotRegex(self, filename, expected_regex, msg=None):\n        '''Fail if ``filename`` matches ``expected_regex``.\n\n        Parameters\n        ----------\n        filename : str, bytes, file-like\n        expected_regex : str, bytes\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``filename`` is not a str or bytes object and is not\n            file-like.\n        '''\n        fname = self._get_file_name(filename)\n        self.assertNotRegex(fname, expected_regex, msg=msg)", "response": "Fail if filename matches expected_regex."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef assertFileTypeEqual(self, filename, extension, msg=None):\n        '''Fail if ``filename`` does not have the given ``extension``\n        as determined by the ``==`` operator.\n\n        Parameters\n        ----------\n        filename : str, bytes, file-like\n        extension : str, bytes\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``filename`` is not a str or bytes object and is not\n            file-like.\n        '''\n        ftype = self._get_file_type(filename)\n        self.assertEqual(ftype, extension, msg=msg)", "response": "Fail if filename does not have the given extension as determined by the == operator."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef assertFileTypeNotEqual(self, filename, extension, msg=None):\n        '''Fail if ``filename`` has the given ``extension`` as\n        determined by the ``!=`` operator.\n\n        Parameters\n        ----------\n        filename : str, bytes, file-like\n        extension : str, bytes\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``filename`` is not a str or bytes object and is not\n            file-like.\n        '''\n        ftype = self._get_file_type(filename)\n        self.assertNotEqual(ftype, extension, msg=msg)", "response": "Fail if filename has the given extension as\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef assertFileEncodingEqual(self, filename, encoding, msg=None):\n        '''Fail if ``filename`` is not encoded with the given\n        ``encoding`` as determined by the '==' operator.\n\n        Parameters\n        ----------\n        filename : str, bytes, file-like\n        encoding : str, bytes\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``filename`` is not a str or bytes object and is not\n            file-like.\n        '''\n        fencoding = self._get_file_encoding(filename)\n\n        fname = self._get_file_name(filename)\n        standardMsg = '%s is not %s encoded' % (fname, encoding)\n\n        self.assertEqual(fencoding.lower(),\n                         encoding.lower(),\n                         self._formatMessage(msg, standardMsg))", "response": "Fail if filename is not encoded with the given encoding as determined by the '==' operator."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef assertFileEncodingNotEqual(self, filename, encoding, msg=None):\n        '''Fail if ``filename`` is encoded with the given ``encoding``\n        as determined by the '!=' operator.\n\n        Parameters\n        ----------\n        filename : str, bytes, file-like\n        encoding : str, bytes\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``filename`` is not a str or bytes object and is not\n            file-like.\n        '''\n        fencoding = self._get_file_encoding(filename)\n\n        fname = self._get_file_name(filename)\n        standardMsg = '%s is %s encoded' % (fname, encoding)\n\n        self.assertNotEqual(fencoding.lower(),\n                            encoding.lower(),\n                            self._formatMessage(msg, standardMsg))", "response": "Fail if filename is encoded with the given encoding as determined by the '!=' operator."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef assertFileSizeEqual(self, filename, size, msg=None):\n        '''Fail if ``filename`` does not have the given ``size`` as\n        determined by the '==' operator.\n\n        Parameters\n        ----------\n        filename : str, bytes, file-like\n        size : int, float\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``filename`` is not a str or bytes object and is not\n            file-like.\n        '''\n        fsize = self._get_file_size(filename)\n        self.assertEqual(fsize, size, msg=msg)", "response": "Fail if filename does not have the given size as\n           ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assertFileSizeNotEqual(self, filename, size, msg=None):\n        '''Fail if ``filename`` has the given ``size`` as determined\n        by the '!=' operator.\n\n        Parameters\n        ----------\n        filename : str, bytes, file-like\n        size : int, float\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``filename`` is not a str or bytes object and is not\n            file-like.\n        '''\n        fsize = self._get_file_size(filename)\n        self.assertNotEqual(fsize, size, msg=msg)", "response": "Fail if filename has the given size as determined\n            by the '!=' operator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfailing if filename does not have the given size as and if it is not equal to the given size.", "response": "def assertFileSizeAlmostEqual(\n            self, filename, size, places=None, msg=None, delta=None):\n        '''Fail if ``filename`` does not have the given ``size`` as\n        determined by their difference rounded to the given number of\n        decimal ``places`` (default 7) and comparing to zero, or if\n        their difference is greater than a given ``delta``.\n\n        Parameters\n        ----------\n        filename : str, bytes, file-like\n        size : int, float\n        places : int\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n        delta : int, float\n\n        Raises\n        ------\n        TypeError\n            If ``filename`` is not a str or bytes object and is not\n            file-like.\n        '''\n        fsize = self._get_file_size(filename)\n        self.assertAlmostEqual(\n                fsize, size, places=places, msg=msg, delta=delta)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfails unless filename has the given size and is not almost equal to the given number of decimal places or greater than a given delta.", "response": "def assertFileSizeNotAlmostEqual(\n            self, filename, size, places=None, msg=None, delta=None):\n        '''Fail unless ``filename`` does not have the given ``size``\n        as determined by their difference rounded to the given number\n        ofdecimal ``places`` (default 7) and comparing to zero, or if\n        their difference is greater than a given ``delta``.\n\n        Parameters\n        ----------\n        filename : str, bytes, file-like\n        size : int, float\n        places : int\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n        delta : int, float\n\n        Raises\n        ------\n        TypeError\n            If ``filename`` is not a str or bytes object and is not\n            file-like.\n        '''\n        fsize = self._get_file_size(filename)\n        self.assertNotAlmostEqual(\n                fsize, size, places=places, msg=msg, delta=delta)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfails if filename s size is not greater than size as is not a file - like object.", "response": "def assertFileSizeGreater(self, filename, size, msg=None):\n        '''Fail if ``filename``'s size is not greater than ``size`` as\n        determined by the '>' operator.\n\n        Parameters\n        ----------\n        filename : str, bytes, file-like\n        size : int, float\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``filename`` is not a str or bytes object and is not\n            file-like.\n        '''\n        fsize = self._get_file_size(filename)\n        self.assertGreater(fsize, size, msg=msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assertFileSizeGreaterEqual(self, filename, size, msg=None):\n        '''Fail if ``filename``'s size is not greater than or equal to\n        ``size`` as determined by the '>=' operator.\n\n        Parameters\n        ----------\n        filename : str, bytes, file-like\n        size : int, float\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``filename`` is not a str or bytes object and is not\n            file-like.\n        '''\n        fsize = self._get_file_size(filename)\n        self.assertGreaterEqual(fsize, size, msg=msg)", "response": "Fail if filename s size is not greater than or equal to\n           . msg is a string or bytes object representing the message to be used when the file - like object is not a file - like object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfail if filename s size is not less than size as is not a file - like object.", "response": "def assertFileSizeLess(self, filename, size, msg=None):\n        '''Fail if ``filename``'s size is not less than ``size`` as\n        determined by the '<' operator.\n\n        Parameters\n        ----------\n        filename : str, bytes, file-like\n        size : int, float\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``filename`` is not a str or bytes object and is not\n            file-like.\n        '''\n        fsize = self._get_file_size(filename)\n        self.assertLess(fsize, size, msg=msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef assertFileSizeLessEqual(self, filename, size, msg=None):\n        '''Fail if ``filename``'s size is not less than or equal to\n        ``size`` as determined by the '<=' operator.\n\n        Parameters\n        ----------\n        filename : str, bytes, file-like\n        size : int, float\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``filename`` is not a str or bytes object and is not\n            file-like.\n        '''\n        fsize = self._get_file_size(filename)\n        self.assertLessEqual(fsize, size, msg=msg)", "response": "Fail if filename s size is not less than or equal to\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfailing if levels1 and levels2 do not have the same categorical level domain.", "response": "def assertCategoricalLevelsEqual(self, levels1, levels2, msg=None):\n        '''Fail if ``levels1`` and ``levels2`` do not have the same\n        domain.\n\n        Parameters\n        ----------\n        levels1 : iterable\n        levels2 : iterable\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If either ``levels1`` or ``levels2`` is not iterable.\n        '''\n        if not isinstance(levels1, collections.Iterable):\n            raise TypeError('First argument is not iterable')\n        if not isinstance(levels2, collections.Iterable):\n            raise TypeError('Second argument is not iterable')\n\n        standardMsg = '%s levels != %s levels' % (levels1, levels2)\n\n        if not all(level in levels2 for level in levels1):\n            self.fail(self._formatMessage(msg, standardMsg))\n\n        if not all(level in levels1 for level in levels2):\n            self.fail(self._formatMessage(msg, standardMsg))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfail if levels1 and levels2 have the same domain.", "response": "def assertCategoricalLevelsNotEqual(self, levels1, levels2, msg=None):\n        '''Fail if ``levels1`` and ``levels2`` have the same domain.\n\n        Parameters\n        ----------\n        levels1 : iterable\n        levels2 : iterable\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If either ``levels1`` or ``levels2`` is not iterable.\n        '''\n        if not isinstance(levels1, collections.Iterable):\n            raise TypeError('First argument is not iterable')\n        if not isinstance(levels2, collections.Iterable):\n            raise TypeError('Second argument is not iterable')\n\n        standardMsg = '%s levels == %s levels' % (levels1, levels2)\n\n        unshared_levels = False\n        if not all(level in levels2 for level in levels1):\n            unshared_levels = True\n\n        if not all(level in levels1 for level in levels2):\n            unshared_levels = True\n\n        if not unshared_levels:\n            self.fail(self._formatMessage(msg, standardMsg))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef assertCategoricalLevelIn(self, level, levels, msg=None):\n        '''Fail if ``level`` is not in ``levels``.\n\n        This is equivalent to ``self.assertIn(level, levels)``.\n\n        Parameters\n        ----------\n        level\n        levels : iterable\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``levels`` is not iterable.\n        '''\n        if not isinstance(levels, collections.Iterable):\n            raise TypeError('Second argument is not iterable')\n\n        self.assertIn(level, levels, msg=msg)", "response": "Fail if level is not in levels."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfail if level is not in levels.", "response": "def assertCategoricalLevelNotIn(self, level, levels, msg=None):\n        '''Fail if ``level`` is in ``levels``.\n\n        This is equivalent to ``self.assertNotIn(level, levels)``.\n\n        Parameters\n        ----------\n        level\n        levels : iterable\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``levels`` is not iterable.\n        '''\n        if not isinstance(levels, collections.Iterable):\n            raise TypeError('Second argument is not iterable')\n\n        self.assertNotIn(level, levels, msg=msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfails if any elements in sequence are not before target.", "response": "def assertDateTimesBefore(self, sequence, target, strict=True, msg=None):\n        '''Fail if any elements in ``sequence`` are not before\n        ``target``.\n\n        If ``target`` is iterable, it must have the same length as\n        ``sequence``\n\n        If ``strict=True``, fail unless all elements in ``sequence``\n        are strictly less than ``target``. If ``strict=False``, fail\n        unless all elements in ``sequence`` are less than or equal to\n        ``target``.\n\n        Parameters\n        ----------\n        sequence : iterable\n        target : datetime, date, iterable\n        strict : bool\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``sequence`` is not iterable.\n        ValueError\n            If ``target`` is iterable but does not have the same length\n            as ``sequence``.\n        TypeError\n            If ``target`` is not a datetime or date object and is not\n            iterable.\n        '''\n        if not isinstance(sequence, collections.Iterable):\n            raise TypeError('First argument is not iterable')\n\n        if strict:\n            standardMsg = '%s is not strictly less than %s' % (sequence,\n                                                               target)\n            op = operator.lt\n        else:\n            standardMsg = '%s is not less than %s' % (sequence, target)\n            op = operator.le\n\n        # Null date(time)s will always compare False, but\n        # we want to know about null date(time)s\n        if isinstance(target, collections.Iterable):\n            if len(target) != len(sequence):\n                raise ValueError(('Length mismatch: '\n                                  'first argument contains %s elements, '\n                                  'second argument contains %s elements' % (\n                                      len(sequence), len(target))))\n            if not all(op(i, j) for i, j in zip(sequence, target)):\n                self.fail(self._formatMessage(msg, standardMsg))\n        elif isinstance(target, (date, datetime)):\n            if not all(op(element, target) for element in sequence):\n                self.fail(self._formatMessage(msg, standardMsg))\n        else:\n            raise TypeError(\n                'Second argument is not a datetime or date object or iterable')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfail if any elements in sequence are not in the past.", "response": "def assertDateTimesPast(self, sequence, strict=True, msg=None):\n        '''Fail if any elements in ``sequence`` are not in the past.\n\n        If the max element is a datetime, \"past\" is defined as anything\n        prior to ``datetime.now()``; if the max element is a date,\n        \"past\" is defined as anything prior to ``date.today()``.\n\n        If ``strict=True``, fail unless all elements in ``sequence``\n        are strictly less than ``date.today()`` (or ``datetime.now()``).\n        If ``strict=False``, fail unless all elements in ``sequence``\n        are less than or equal to ``date.today()`` (or\n        ``datetime.now()``).\n\n        Parameters\n        ----------\n        sequence : iterable\n        strict : bool\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``sequence`` is not iterable.\n        TypeError\n            If max element in ``sequence`` is not a datetime or date\n            object.\n        '''\n        if not isinstance(sequence, collections.Iterable):\n            raise TypeError('First argument is not iterable')\n\n        # Cannot compare datetime to date, so if dates are provided use\n        # date.today(), if datetimes are provided use datetime.today()\n        if isinstance(max(sequence), datetime):\n            target = datetime.today()\n        elif isinstance(max(sequence), date):\n            target = date.today()\n        else:\n            raise TypeError('Expected iterable of datetime or date objects')\n\n        self.assertDateTimesBefore(sequence, target, strict=strict, msg=msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assertDateTimesFuture(self, sequence, strict=True, msg=None):\n        '''Fail if any elements in ``sequence`` are not in the future.\n\n        If the min element is a datetime, \"future\" is defined as\n        anything after ``datetime.now()``; if the min element is a date,\n        \"future\" is defined as anything after ``date.today()``.\n\n        If ``strict=True``, fail unless all elements in ``sequence``\n        are strictly greater than ``date.today()``\n        (or ``datetime.now()``).  If ``strict=False``, fail all\n        elements in ``sequence`` are greater than or equal to\n        ``date.today()`` (or ``datetime.now()``).\n\n        Parameters\n        ----------\n        sequence : iterable\n        strict : bool\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``sequence`` is not iterable.\n        TypeError\n            If min element in ``sequence`` is not a datetime or date\n            object.\n        '''\n        if not isinstance(sequence, collections.Iterable):\n            raise TypeError('First argument is not iterable')\n\n        # Cannot compare datetime to date, so if dates are provided use\n        # date.today(), if datetimes are provided use datetime.today()\n        if isinstance(min(sequence), datetime):\n            target = datetime.today()\n        elif isinstance(min(sequence), date):\n            target = date.today()\n        else:\n            raise TypeError('Expected iterable of datetime or date objects')\n\n        self.assertDateTimesAfter(sequence, target, strict=strict, msg=msg)", "response": "Fail if any elements in sequence are not in the future."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfails if any elements in sequence are not separated by the expected fequency.", "response": "def assertDateTimesFrequencyEqual(self, sequence, frequency, msg=None):\n        '''Fail if any elements in ``sequence`` aren't separated by\n        the expected ``fequency``.\n\n        Parameters\n        ----------\n        sequence : iterable\n        frequency : timedelta\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``sequence`` is not iterable.\n        TypeError\n            If ``frequency`` is not a timedelta object.\n        '''\n        # TODO (jsa): check that elements in sequence are dates or\n        # datetimes, keeping in mind that sequence may contain null\n        # values\n        if not isinstance(sequence, collections.Iterable):\n            raise TypeError('First argument is not iterable')\n        if not isinstance(frequency, timedelta):\n            raise TypeError('Second argument is not a timedelta object')\n\n        standardMsg = 'unexpected frequencies found in %s' % sequence\n\n        s1 = pd.Series(sequence)\n        s2 = s1.shift(-1)\n\n        freq = s2 - s1\n\n        if not all(f == frequency for f in freq[:-1]):\n            self.fail(self._formatMessage(msg, standardMsg))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfails unless the max element in sequence is separated from the present by lag as determined by the '==' operator.", "response": "def assertDateTimesLagEqual(self, sequence, lag, msg=None):\n        '''Fail unless max element in ``sequence`` is separated from\n        the present by ``lag`` as determined by the '==' operator.\n\n        If the max element is a datetime, \"present\" is defined as\n        ``datetime.now()``; if the max element is a date, \"present\"\n        is defined as ``date.today()``.\n\n        This is equivalent to\n        ``self.assertEqual(present - max(sequence), lag)``.\n\n        Parameters\n        ----------\n        sequence : iterable\n        lag : timedelta\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``sequence`` is not iterable.\n        TypeError\n            If ``lag`` is not a timedelta object.\n        TypeError\n            If max element in ``sequence`` is not a datetime or date\n            object.\n        '''\n        if not isinstance(sequence, collections.Iterable):\n            raise TypeError('First argument is not iterable')\n        if not isinstance(lag, timedelta):\n            raise TypeError('Second argument is not a timedelta object')\n\n        # Cannot compare datetime to date, so if dates are provided use\n        # date.today(), if datetimes are provided use datetime.today()\n        if isinstance(max(sequence), datetime):\n            target = datetime.today()\n        elif isinstance(max(sequence), date):\n            target = date.today()\n        else:\n            raise TypeError('Expected iterable of datetime or date objects')\n\n        self.assertEqual(target - max(sequence), lag, msg=msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfail if max element in sequence is separated from the present by lag or more as determined by the '<' operator.", "response": "def assertDateTimesLagLess(self, sequence, lag, msg=None):\n        '''Fail if max element in ``sequence`` is separated from\n        the present by ``lag`` or more as determined by the '<'\n        operator.\n\n        If the max element is a datetime, \"present\" is defined as\n        ``datetime.now()``; if the max element is a date, \"present\"\n        is defined as ``date.today()``.\n\n        This is equivalent to\n        ``self.assertLess(present - max(sequence), lag)``.\n\n        Parameters\n        ----------\n        sequence : iterable\n        lag : timedelta\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``sequence`` is not iterable.\n        TypeError\n            If ``lag`` is not a timedelta object.\n        TypeError\n            If max element in ``sequence`` is not a datetime or date\n            object.\n        '''\n        if not isinstance(sequence, collections.Iterable):\n            raise TypeError('First argument is not iterable')\n        if not isinstance(lag, timedelta):\n            raise TypeError('Second argument is not a timedelta object')\n\n        # Cannot compare datetime to date, so if dates are provided use\n        # date.today(), if datetimes are provided use datetime.today()\n        if isinstance(max(sequence), datetime):\n            target = datetime.today()\n        elif isinstance(max(sequence), date):\n            target = date.today()\n        else:\n            raise TypeError('Expected iterable of datetime or date objects')\n\n        self.assertLess(target - max(sequence), lag, msg=msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfailing if max element in sequence is separated from the present by more than lag as determined by the '<=' operator.", "response": "def assertDateTimesLagLessEqual(self, sequence, lag, msg=None):\n        '''Fail if max element in ``sequence`` is separated from\n        the present by more than ``lag`` as determined by the '<='\n        operator.\n\n        If the max element is a datetime, \"present\" is defined as\n        ``datetime.now()``; if the max element is a date, \"present\"\n        is defined as ``date.today()``.\n\n        This is equivalent to\n        ``self.assertLessEqual(present - max(sequence), lag)``.\n\n        Parameters\n        ----------\n        sequence : iterable\n        lag : timedelta\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``sequence`` is not iterable.\n        TypeError\n            If ``lag`` is not a timedelta object.\n        TypeError\n            If max element in ``sequence`` is not a datetime or date\n            object.\n        '''\n        if not isinstance(sequence, collections.Iterable):\n            raise TypeError('First argument is not iterable')\n        if not isinstance(lag, timedelta):\n            raise TypeError('Second argument is not a timedelta object')\n\n        # Cannot compare datetime to date, so if dates are provided use\n        # date.today(), if datetimes are provided use datetime.today()\n        if isinstance(max(sequence), datetime):\n            target = datetime.today()\n        elif isinstance(max(sequence), date):\n            target = date.today()\n        else:\n            raise TypeError('Expected iterable of datetime or date objects')\n\n        self.assertLessEqual(target - max(sequence), lag, msg=msg)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfail if dt has a non - null tzinfo attribute.", "response": "def assertTimeZoneIsNone(self, dt, msg=None):\n        '''Fail if ``dt`` has a non-null ``tzinfo`` attribute.\n\n        Parameters\n        ----------\n        dt : datetime\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``dt`` is not a datetime object.\n        '''\n        if not isinstance(dt, datetime):\n            raise TypeError('First argument is not a datetime object')\n\n        self.assertIsNone(dt.tzinfo, msg=msg)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef assertTimeZoneIsNotNone(self, dt, msg=None):\n        '''Fail unless ``dt`` has a non-null ``tzinfo`` attribute.\n\n        Parameters\n        ----------\n        dt : datetime\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``dt`` is not a datetime object.\n        '''\n        if not isinstance(dt, datetime):\n            raise TypeError('First argument is not a datetime object')\n\n        self.assertIsNotNone(dt.tzinfo, msg=msg)", "response": "Fail unless dt has a non - null tzinfo attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef assertTimeZoneEqual(self, dt, tz, msg=None):\n        '''Fail unless ``dt``'s ``tzinfo`` attribute equals ``tz`` as\n        determined by the '==' operator.\n\n        Parameters\n        ----------\n        dt : datetime\n        tz : timezone\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``dt`` is not a datetime object.\n        TypeError\n            If ``tz`` is not a timezone object.\n        '''\n        if not isinstance(dt, datetime):\n            raise TypeError('First argument is not a datetime object')\n        if not isinstance(tz, timezone):\n            raise TypeError('Second argument is not a timezone object')\n\n        self.assertEqual(dt.tzinfo, tz, msg=msg)", "response": "Fail unless dt s tzinfoinfo attribute equals tz as\n            is set to tz."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfail if dt s tzinfoinfo attribute equals tz as is not equal to tz as is not provided by the '!=' operator.", "response": "def assertTimeZoneNotEqual(self, dt, tz, msg=None):\n        '''Fail if ``dt``'s ``tzinfo`` attribute equals ``tz`` as\n        determined by the '!=' operator.\n\n        Parameters\n        ----------\n        dt : datetime\n        tz : timezone\n        msg : str\n            If not provided, the :mod:`marbles.mixins` or\n            :mod:`unittest` standard message will be used.\n\n        Raises\n        ------\n        TypeError\n            If ``dt`` is not a datetime object.\n        TypeError\n            If ``tz`` is not a timezone object.\n        '''\n        if not isinstance(dt, datetime):\n            raise TypeError('First argument is not a datetime object')\n        if not isinstance(tz, timezone):\n            raise TypeError('Second argument is not a timezone object')\n\n        self.assertNotEqual(dt.tzinfo, tz, msg=msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the name of the class that defines meth. MimeType", "response": "def _class_defining_method(meth):  # pragma: no cover\n    '''Gets the name of the class that defines meth.\n\n    Adapted from\n    http://stackoverflow.com/questions/3589311/get-defining-class-of-unbound-method-object-in-python-3/25959545#25959545.\n    '''\n    if inspect.ismethod(meth):\n        for cls in inspect.getmro(meth.__self__.__class__):\n            if cls.__dict__.get(meth.__name__) is meth:\n                return '{}.{}'.format(cls.__module__, cls.__name__)\n        meth = meth.__func__\n    if inspect.isfunction(meth):\n        module = meth.__qualname__.split('.<locals>', 1)[0]\n        cls = getattr(inspect.getmodule(meth), module.rsplit('.', 1)[0])\n        if isinstance(cls, type):\n            return '{}.{}'.format(cls.__module__, cls.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef configure(self, **kwargs):\n        '''Configure what assertion logging is done.\n\n        Settings configured with this method are overridden by\n        environment variables.\n\n        Parameters\n        ----------\n        logfile : str or bytes or file object\n            If a string or bytes object, we write to that filename.\n            If an open file object, we just write to it. If None,\n            disable logging. If we open the file, we open it in\n            ``'w'`` mode, so any contents will be overwritten.\n        attrs : list of str\n            Capture these attributes on the TestCase being run when\n            logging an assertion. For example, if you are testing\n            multiple resources, make sure the resource name is a\n            member of your TestCase, and configure marbles logging\n            with that name. These are only captured on failure.\n        verbose_attrs : list of str\n            Similar to attrs, but these attrs are captured even on\n            success.\n        verbose : bool or list of str\n            Fields (within the set {msg, note, locals}) to capture\n            even when the test is successful. By default, those three\n            fields are only captured on failure.\n        '''\n        if 'logfile' in kwargs:\n            # Note that kwargs['logfile'] might be an open file\n            # object, not a string. We deal with this in\n            # _open_if_needed, but refactoring it so that in that case\n            # it gets set on another attribute would be tricky to\n            # handle the lazy opening semantics that let us override\n            # it with MARBLES_LOGFILE, so instead we choose to let\n            # self._logfilename do double-duty: sometimes it's a name,\n            # sometimes it's sneakily a file object.\n            self._logfilename = kwargs['logfile']\n\n        if 'attrs' in kwargs:\n            self._attrs = kwargs['attrs']\n\n        if 'verbose_attrs' in kwargs:\n            self._verbose_attrs = kwargs['verbose_attrs']\n\n        if 'verbose' in kwargs:\n            self._verbose = kwargs['verbose']", "response": "Configure what assertion logging is done."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlocates the msg argument in a function signature.", "response": "def _find_msg_argument(signature):\n    '''Locates the ``msg`` argument in a function signature.\n\n    We need to determine where we expect to find ``msg`` if it's passed\n    positionally, so we can extract it if the user passed it.\n\n    Returns\n    -------\n    tuple\n        The index of the ``msg`` param, the default value for it,\n        and the number of non-``msg`` positional parameters we expect.\n    '''\n    names = signature.parameters.keys()\n    try:\n        msg_idx = list(names).index('msg')\n        default_msg = signature.parameters['msg'].default\n    except ValueError:  # 'msg' is not in list\n        # It's likely that this is a custom assertion that's just\n        # passing all remaining args and kwargs through\n        # (e.g. tests.marbles.ReversingTestCaseMixin). Unfortunately,\n        # we can't inspect its code to find the assert it's wrapping,\n        # so we just have to assume it's of the standard form with msg\n        # in the last position with a default of None.\n        msg_idx = -1\n        default_msg = None\n\n    # We also don't want to steal any actually positional arguments if\n    # we can help it. Therefore, we leave the default msg if there are\n    # fewer than this many args passed. We stop counting at a\n    # parameter named 'msg' or when we hit a varargs or keyword-only\n    # parameter.\n    kinds = (inspect.Parameter.POSITIONAL_ONLY,\n             inspect.Parameter.POSITIONAL_OR_KEYWORD)\n    non_msg_params = itertools.takewhile(\n        lambda param: param.name != 'msg' and param.kind in kinds,\n        signature.parameters.values())\n    non_msg_params = sum(1 for _ in non_msg_params)\n    return msg_idx, default_msg, non_msg_params"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _extract_msg(args, kwargs, msg_idx, default_msg, non_msg_params):\n    '''Extracts the ``msg`` argument from the passed ``args``.\n\n    Returns\n    -------\n    tuple\n        The found ``msg``, the args and kwargs with that ``msg``\n        removed, and any remaining positional args after ``msg``.\n    '''\n    rem_args = []\n    if 'msg' in kwargs:\n        msg = kwargs.pop('msg')\n    elif len(args) > non_msg_params and msg_idx < len(args):\n        msg = args[msg_idx]\n        if 0 <= msg_idx:\n            rem_args = args[msg_idx + 1:]\n        args = args[:msg_idx]\n    else:\n        msg = default_msg\n    return msg, args, rem_args, kwargs", "response": "Extracts the msg argument from the passed args."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wrap(self, text, **kwargs):\n        '''Wraps each paragraph in ``text`` individually.\n\n        Parameters\n        ----------\n        text : str\n\n        Returns\n        -------\n        str\n            Single string containing the wrapped paragraphs.\n        '''\n        pilcrow = re.compile(r'(\\n\\s*\\n)', re.MULTILINE)\n        list_prefix = re.compile(r'\\s*(?:\\w|[0-9]+)[\\.\\)]\\s+')\n\n        paragraphs = pilcrow.split(text)\n        wrapped_lines = []\n        for paragraph in paragraphs:\n            if paragraph.isspace():\n                wrapped_lines.append('')\n            else:\n                wrapper = textwrap.TextWrapper(**vars(self))\n                list_item = re.match(list_prefix, paragraph)\n                if list_item:\n                    wrapper.subsequent_indent += ' ' * len(list_item.group(0))\n                wrapped_lines.extend(wrapper.wrap(paragraph))\n\n        return wrapped_lines", "response": "Wraps each paragraph in text individually."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef assert_stmt(self):\n        '''Returns a string displaying the whole statement that failed,\n        with a '>' indicator on the line starting the expression.\n        '''\n        # This will be used by linecache to read the source of this\n        # module. See the docstring for _find_assert_stmt below which\n        # explains how.\n\n        # We don't have a test for this because automating the\n        # creation of an egg, installation into an environment,\n        # running of tests, and verification that marbles found the\n        # right source and was able to print it is a lot of\n        # automation. We have tested manually, and marbles works with\n        # all check installation mechanisms we know of right now\n        # (setup.py install, setup.py develop, pip install, bdist_egg,\n        # bdist_wheel).\n        module_globals = vars(sys.modules[self.module])\n        line_range, lineno = self._find_assert_stmt(\n            self.filename, self.linenumber, module_globals=module_globals)\n        source = [linecache.getline(self.filename, x,\n                                    module_globals=module_globals)\n                  for x in line_range]\n\n        # Dedent the source, removing the final newline added by dedent\n        dedented_lines = textwrap.dedent(''.join(source)).split('\\n')[:-1]\n\n        formatted_lines = []\n        for i, line in zip(line_range, dedented_lines):\n            prefix = '>' if i == lineno else ' '\n            formatted_lines.append(' {0} {1:4d} {2}'.format(prefix, i, line))\n\n        return '\\n'.join(formatted_lines)", "response": "Returns a string displaying the whole statement that failed and a '>' indicator on the line starting the expression."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _find_assert_stmt(filename, linenumber, leading=1, following=2,\n                          module_globals=None):\n        '''Given a Python module name, filename and line number, find\n        the lines that are part of the statement containing that line.\n\n        Python stacktraces, when reporting which line they're on, always\n        show the last line of the statement. This can be confusing if\n        the statement spans multiple lines. This function helps\n        reconstruct the whole statement, and is used by\n        :meth:`marbles.core.ContextualAssertionError.assert_stmt`.\n\n        Returns a tuple of the range of lines spanned by the source\n        being returned, the number of the line on which the interesting\n        statement starts.\n\n        We may need the ``module_globals`` in order to tell\n        :mod:`linecache` how to find the file, if it comes from inside\n        an egg. In that case, ``module_globals`` should contain a key\n        ``__loader__`` which knows how to read from that file.\n        '''\n        lines = linecache.getlines(\n            filename, module_globals=module_globals)\n        _source = ''.join(lines)\n        _tree = ast.parse(_source)\n\n        finder = _StatementFinder(linenumber)\n        finder.visit(_tree)\n        line_range = range(finder.found - leading, linenumber + following)\n        return line_range, finder.found", "response": "Given a Python module name filename and line number find the lines that are part of the statement containing that line."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nensures that the annotation has the right fields.", "response": "def _validate_annotation(self, annotation):\n        '''Ensures that the annotation has the right fields.'''\n        required_keys = set(self._required_keys)\n        keys = set(key for key, val in annotation.items() if val)\n        missing_keys = required_keys.difference(keys)\n        if missing_keys:\n            error = 'Annotation missing required fields: {0}'.format(\n                missing_keys)\n            raise AnnotationError(error)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _tchelper(tc_deps,evals,deps):\n\tfor e in evals:\n\t\tif e in tc_deps: # we've already included it\n\t\t\tcontinue\n\t\telse:\n\t\t\tif e in deps: # has additional dependnecies\n\t\t\t\ttc_deps[e]=deps[e]\n\t\t\t\t# add to tc_deps the dependencies of the dependencies\n\t\t\t\t_tchelper(tc_deps,deps[e],deps)\n\treturn tc_deps", "response": "This function is used to add the dependencies of evals to tc_deps."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns the debug session", "response": "def run(self, evals, feed_dict=None, breakpoints=None, break_immediately=False):\n\t\t\"\"\"\n\t\tstarts the debug session\n\t\t\"\"\"\n\t\tif not isinstance(evals,list):\n\t\t\tevals=[evals]\n\t\tif feed_dict is None:\n\t\t\tfeed_dict={}\n\t\tif breakpoints is None:\n\t\t\tbreakpoints=[]\n\n\t\tself.state=RUNNING\n\t\tself._original_evals=evals\n\t\tself._original_feed_dict=feed_dict\n\t\tself._exe_order=op_store.compute_exe_order(evals)\n\t\tself._init_evals_bps(evals, breakpoints)\n\n\t\t# convert cache keys to strings\n\t\tfor k,v in feed_dict.items():\n\t\t\tif not isinstance(k,str):\n\t\t\t\tk=k.name\n\t\t\tself._cache[k]=v\n\n\t\top_store.register_dbsession(self)\n\n\t\tif break_immediately:\n\t\t\treturn self._break()\n\t\telse:\n\t\t\treturn self.c()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef s(self):\n\t\tnext_node=self._exe_order[self.step]\n\t\tself._eval(next_node)\n\t\tself.step+=1\n\t\tif self.step==len(self._exe_order):\n\t\t\treturn self._finish()\n\t\telse:\n\t\t\t# if stepping, return the value of the node we just\n\t\t\t# evaled\n\t\t\treturn self._break(value=self._cache.get(next_node.name))", "response": "step to the next node in the execution order\n\tself. step"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_values(self):\n\t\treturn [self._cache.get(i.name,None) for i in self._original_evals]", "response": "Returns the values of the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve a value from the cache", "response": "def get_value(self, node):\n\t\t\"\"\"\n\t\tretrieve a node value from the cache\n\t\t\"\"\"\n\t\tif isinstance(node,tf.Tensor):\n\t\t\treturn self._cache.get(node.name,None)\n\t\telif isinstance(node,tf.Operation):\n\t\t\treturn None\n\t\telse: # handle ascii, unicode strings\n\t\t\treturn self._cache.get(node,None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing the eval and breakpoint sets.", "response": "def _init_evals_bps(self, evals, breakpoints):\n\t\t# If an eval or bp is the tf.Placeholder output of a tdb.PythonOp, replace it with its respective PythonOp node\n\t\tevals2=[op_store.get_op(t) if op_store.is_htop_out(t) else t for t in evals]\n\t\tbreakpoints2=[op_store.get_op(t) if op_store.is_htop_out(t) else t for t in breakpoints]\n\t\t# compute execution order\n\t\tself._exe_order=op_store.compute_exe_order(evals2) # list of nodes\n\t\t# compute evaluation set\n\t\t\"\"\"\n\t\tHTOps may depend on tf.Tensors that are not in eval. We need to have all inputs to HTOps ready\n\t\tupon evaluation. \n\n\t\t1. all evals that were originally specified are added\n\t\t2. each HTOp in the execution closure needs to be in eval (they won't be eval'ed automatically by Session.run)\n\t\t3. if an input to an HTOp is a tf.Tensor (not a HT placeholder tensor), it needs to be in eval as well (it's not\n\t\t\ttensorflow so we'll have to manually evaluate it). Remember, we don't track Placeholders because we instead \n\t\t\trun the HTOps that generate their values.\n\t\t\"\"\"\n\t\tself._evalset=set([e.name for e in evals2])\n\t\tfor e in self._exe_order:\n\t\t\tif isinstance(e,HTOp):\n\t\t\t\tself._evalset.add(e.name)\n\t\t\t\tfor t in e.inputs:\n\t\t\t\t\tif not op_store.is_htop_out(t):\n\t\t\t\t\t\tself._evalset.add(t.name)\n\n\t\t# compute breakpoint set\n\t\tself._bpset=set([bp.name for bp in breakpoints2])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _eval(self, node):\n\t\t# if node.name == 'Momentum':\n\t\t# \tpdb.set_trace()\n\t\tif isinstance(node,HTOp):\n\t\t\t# All Tensors MUST be in the cache.\n\t\t\tfeed_dict=dict((t,self._cache[t.name]) for t in node.inputs)\n\t\t\tnode.run(feed_dict) # this will populate self._cache on its own\n\t\telse: # is a TensorFlow node\n\t\t\tif isinstance(node,tf.Tensor):\n\t\t\t\tresult=self.session.run(node,self._cache)\n\t\t\t\tself._cache[node.name]=result\n\t\t\telse:\n\t\t\t\t# is an operation\n\t\t\t\tif node.type =='Assign' or node.type == 'AssignAdd' or node.type == 'AssignSub':\n\t\t\t\t\t# special operation that takes in a tensor ref and mutates it\n\t\t\t\t\t# unfortunately, we end up having to execute nearly the full graph?\n\t\t\t\t\t# alternatively, find a way to pass the tensor_ref thru the feed_dict\n\t\t\t\t\t# rather than the tensor values.\n\t\t\t\t\tself.session.run(node,self._original_feed_dict)", "response": "node is a TensorFlow Op or Tensor from self._exe_order"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extract_data(filename, num_images):\n  print('Extracting', filename)\n  with gzip.open(filename) as bytestream:\n    bytestream.read(16)\n    buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images)\n    data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n    data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n    data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, 1)\n    return data", "response": "Extract the images into a 4D tensor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding the computation graph consisting of training validation and test data.", "response": "def build_model():\n  \"\"\"\n  Builds the computation graph consisting of training/testing LeNet\n\n  train data - used for learning\n  validation data - used for printing progress (does not impact learning)\n  test data - used for printing final test error\n  \"\"\"\n  # training data\n  train_data_node = tf.placeholder(tf.float32,shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n  train_labels_node = tf.placeholder(tf.float32,shape=(BATCH_SIZE, NUM_LABELS))\n\n  validation_data_node= tf.placeholder(tf.float32,shape=(VALIDATION_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n  test_data_node=tf.placeholder(tf.float32,shape=(TEST_SIZE,IMAGE_SIZE,IMAGE_SIZE,NUM_CHANNELS))\n  # validation dataset held in a single constant node\n  # validation_data_node = tf.constant(validation_data)\n  # test_data_node = tf.constant(test_data)\n\n  # LEARNABLE WEIGHT NODES SHARED BETWEEN\n  conv1_weights = tf.Variable(tf.truncated_normal([5, 5, NUM_CHANNELS, 32],stddev=0.1,seed=SEED))\n  conv1_biases = tf.Variable(tf.zeros([32]))\n  conv2_weights = tf.Variable(tf.truncated_normal([5, 5, 32, 64],stddev=0.1,seed=SEED))\n  conv2_biases = tf.Variable(tf.constant(0.1, shape=[64]))\n  fc1_weights = tf.Variable(tf.truncated_normal([IMAGE_SIZE // 4 * IMAGE_SIZE // 4 * 64, 512],stddev=0.1,seed=SEED))\n  fc1_biases = tf.Variable(tf.constant(0.1, shape=[512]))\n  fc2_weights = tf.Variable(tf.truncated_normal([512, NUM_LABELS],stddev=0.1,seed=SEED))\n  fc2_biases = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS]))\n\n  # LENET\n  def build_lenet(data,train=False):\n    # subroutine for wiring up nodes and weights to training and evaluation LeNets\n    conv1 = tf.nn.conv2d(data,conv1_weights,strides=[1, 1, 1, 1],padding='SAME')\n    relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_biases))\n    pool1 = tf.nn.max_pool(relu1,ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1],padding='SAME')\n    conv2 = tf.nn.conv2d(pool1,conv2_weights,strides=[1, 1, 1, 1],padding='SAME')\n    relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_biases))\n    pool2 = tf.nn.max_pool(relu2,ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1],padding='SAME')\n    # Reshape the feature map cuboid into a 2D matrix to feed it to the\n    # fully connected layers.\n    pool_shape = pool2.get_shape().as_list()\n    reshape = tf.reshape(pool2,[pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]])\n    fc1 = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n    # Add a 50% dropout during training only. Dropout also scales\n    # activations such that no rescaling is needed at evaluation time.\n    if train:\n      fc1 = tf.nn.dropout(fc1, 0.5, seed=SEED)\n      # append summary ops to train\n      _activation_summary(conv1)\n      _activation_summary(fc1)\n\n    fc2 = tf.matmul(fc1, fc2_weights) + fc2_biases\n    return fc2\n\n  # TRAINING LOSS / REGULARIZATION NODES\n  logits = build_lenet(train_data_node, True)\n  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, train_labels_node))\n\n  tf.scalar_summary(loss.op.name,loss)\n\n  regularizers = (tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc1_biases) + tf.nn.l2_loss(fc2_weights) + tf.nn.l2_loss(fc2_biases))\n  # Add the regularization term to the loss.\n  loss += 5e-4 * regularizers\n\n  # OPTIMIZER NODES\n  batch = tf.Variable(0)\n  # Decay once per epoch, using an exponential schedule starting at 0.01.\n  learning_rate = tf.train.exponential_decay(\n    0.01,                # Base learning rate.\n    batch * BATCH_SIZE,  # Current index into the dataset.\n    TRAIN_SIZE,          # Decay step.\n    0.95,                # Decay rate.\n    staircase=True)\n  # Use simple momentum for the optimization.\n  optimizer = tf.train.MomentumOptimizer(learning_rate,0.9).minimize(loss,global_step=batch)\n\n  # # Predictions for the minibatch, validation set and test set.\n  train_prediction = tf.nn.softmax(logits)\n  # # We'll compute them only once in a while by calling their {eval()} method.\n  validation_prediction = tf.nn.softmax(build_lenet(validation_data_node))\n  test_prediction = tf.nn.softmax(build_lenet(test_data_node))\n\n  summaries=tf.merge_all_summaries()\n\n  # return input nodes and output nodes\n  return (train_data_node,\n    train_labels_node,\n    validation_data_node,\n    test_data_node,\n    train_prediction,\n    validation_prediction,\n    test_prediction,\n    conv1_weights,\n    conv2_weights,\n    fc1_weights,\n    fc2_weights,\n    optimizer,\n    loss,\n    learning_rate,\n    summaries)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the error rate based on dense predictions and 1 - hot labels.", "response": "def error_rate(predictions, labels):\n  \"\"\"Return the error rate based on dense predictions and 1-hot labels.\"\"\"\n  return 100.0 - (\n      100.0 *\n      np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) /\n      predictions.shape[0])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_node(name):\n\tif name in _ops:\n\t\treturn _ops[name]\n\telse:\n\t\tg=tf.get_default_graph()\n\t\treturn g.as_graph_element(name)", "response": "Returns HTOp or tf. GraphElement corresponding to requested node name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compute_node_deps():\n\tdeps={}\n\tg=tf.get_default_graph()\n\tfor op in g.get_operations():\n\t\td=set([i.name for i in op.control_inputs])\n\t\tfor t in op.inputs:\n\t\t\tif is_htop_out(t):\n\t\t\t\td.add(get_op(t).name)\n\t\t\telse:\n\t\t\t\td.add(t.name)\n\t\tdeps[op.name]=d\n\t\tfor t in op.outputs:\n\t\t\tdeps[t.name]=set([op.name])\n\t# do the same thing with HTOps\n\tfor op in _ops.values():\n\t\td=set()\n\t\tfor t in op.inputs:\n\t\t\tif is_htop_out(t):\n\t\t\t\td.add(get_op(t).name)\n\t\t\telse:\n\t\t\t\td.add(t.name)\n\t\tdeps[op.name]=d\n\treturn deps", "response": "Computes the full dependency graph of all ops and ALL tensors."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncaches values from the output tensors", "response": "def cache_values(self, results):\n\t\t\"\"\"\n\t\tloads into DebugSession cache\n\t\t\"\"\"\n\t\tif results is None:\n\t\t\t# self.fn was probably only used to compute side effects.\n\t\t\treturn\n\t\telif isinstance(results,np.ndarray):\n\t\t\t# fn returns single np.ndarray.\n\t\t\t# re-format it into a list\n\t\t\tresults=[results]\n\t\t# check validity of fn output\n\t\telif isinstance(results,list):\n\t\t\tif len(results) is not len(self.outputs):\n\t\t\t\traise ValueError('Number of output tensors does not match number of outputs produced by function')\n\t\telif isinstance(results,np.number):\n\t\t\tif len(self.outputs) != 1:\n\t\t\t\traise ValueError('Fn produces scalar but %d outputs expected' % (len(self.outputs)))\n\t\t\tresults=[results]\n\t\t# assign each element in ndarrays to corresponding output tensor\n\t\tfor i,ndarray in enumerate(results):\n\t\t\tself.session._cache_value(self.outputs[i], ndarray)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun a single debug session", "response": "def debug(evals,feed_dict=None,breakpoints=None,break_immediately=False,session=None):\n\t\"\"\"\n\tspawns a new debug session\n\t\"\"\"\n\tglobal _dbsession\n\t_dbsession=debug_session.DebugSession(session)\n\treturn _dbsession.run(evals,feed_dict,breakpoints,break_immediately)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef connect():\n\tif not is_notebook():\n\t\tprint('Python session is not running in a Notebook Kernel')\n\t\treturn\n\t\n\tglobal _comm\n\n\tkernel=get_ipython().kernel\n\tkernel.comm_manager.register_target('tdb',handle_comm_opened)\n\t# initiate connection to frontend.\n\t_comm=Comm(target_name='tdb',data={})\n\t# bind recv handler\n\t_comm.on_msg(None)", "response": "Connect to the frontend notebook."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend an action to the remote server", "response": "def send_action(action, params=None):\n\t\"\"\"\n\thelper method for sending actions\n\t\"\"\"\n\tdata={\"msg_type\":\"action\", \"action\":action}\n\tif params is not None:\n\t\tdata['params']=params\n\t_comm.send(data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_fig(fig,name):\n\timgdata = StringIO.StringIO()\n\tfig.savefig(imgdata, format='png')\n\timgdata.seek(0)  # rewind the data\n\turi = 'data:image/png;base64,' + urllib.quote(b64encode(imgdata.buf))\n\tsend_action(\"update_plot\",params={\"src\":uri, \"name\":name})", "response": "sends figure to frontend\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvisualize the data in a square image.", "response": "def viz_square(data, normalize=True, cmap=plt.cm.gray, padsize=1, padval=0):\n    \"\"\"\n    takes a np.ndarray of shape (n, height, width) or (n, height, width, channels)\n    visualize each (height, width) thing in a grid of size approx. sqrt(n) by sqrt(n)\n    However, this only draws first input channel\n    \"\"\"\n    # normalize to 0-1 range\n    if normalize:\n        data -= data.min()\n        data /= data.max()\n    n = int(np.ceil(np.sqrt(data.shape[0]))) # force square \n    padding = ((0, n ** 2 - data.shape[0]), (0, padsize), (0, padsize)) + ((0, 0),) * (data.ndim - 3)\n    data = np.pad(data, padding, mode='constant', constant_values=(padval, padval))\n    # tile the filters into an image\n    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n    plt.matshow(data,cmap=cmap)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning that creates a python_op and stores it in the internal dictionary of op objects.", "response": "def plot_op(fn, inputs=[], outputs=[]):\n\t\"\"\"\n\tUser-exposed api method for constructing a python_node\n\n\tArgs:\n\tfn: python function that computes some np.ndarrays given np.ndarrays as inputs. it can have arbitrary side effects.\n\tinputs: array of tf.Tensors (optional). These are where fn derives its values from\n\toutputs: tf.Placeholder nodes (optional). These are constructed by the user (which allows the user to\n\t\tplug them into other ht.Ops or tf.Ops). The outputs of fn are mapped to each of the output placeholders.\n\n\traises an Error if fn cannot map\n\t\"\"\"\n\tglobal COUNT, ht\n\t# check outputs\n\tif not isinstance(outputs,list):\n\t\toutputs=[outputs]\n\n\tfor tensor in outputs:\n\t\tif tensor.op.type is not 'Placeholder':\n\t\t\traise Error('Output nodes must be Placeholders')\n\n\top=PlotOp(fn, COUNT, inputs, outputs)\n\n\top_store.add_op(op)\n\tCOUNT+=1 \n\n\t# if node has output, return value for python_op is the first output (placeholder) tensor\n\t# otherwise, return the op\n\tif outputs:\n\t\treturn outputs[0]\n\telse:\n\t\treturn op"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a handler for a query engine based on a URL.", "response": "def create_engine(url, con=None, header=True, show_progress=5.0, clear_progress=True):\n    '''Create a handler for query engine based on a URL.\n\n    The following environment variables are used for default connection:\n\n      TD_API_KEY     API key\n      TD_API_SERVER  API server (default: api.treasuredata.com)\n      HTTP_PROXY     HTTP proxy (optional)\n\n    Parameters\n    ----------\n    url : string\n        Engine descriptor in the form \"type://apikey@host/database?params...\"\n        Use shorthand notation \"type:database?params...\" for the default connection.\n    con : Connection, optional\n        Handler returned by connect. If not given, default connection is used.\n    header : string or boolean, default True\n        Prepend comment strings, in the form \"-- comment\", as a header of queries.\n        Set False to disable header.\n    show_progress : double or boolean, default 5.0\n        Number of seconds to wait before printing progress.\n        Set False to disable progress entirely.\n    clear_progress : boolean, default True\n        If True, clear progress when query completed.\n\n    Returns\n    -------\n    QueryEngine\n    '''\n    url = urlparse(url)\n    engine_type = url.scheme if url.scheme else 'presto'\n    if con is None:\n        if url.netloc:\n            # create connection\n            apikey, host = url.netloc.split('@')\n            con = Connection(apikey=apikey, endpoint=\"https://{0}/\".format(host))\n        else:\n            # default connection\n            con = Connection()\n    database = url.path[1:] if url.path.startswith('/') else url.path\n    params = {\n        'type': engine_type,\n    }\n    params.update(parse_qsl(url.query))\n    return QueryEngine(con, database, params,\n                       header=header,\n                       show_progress=show_progress,\n                       clear_progress=clear_progress)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading Treasure Data query into a DataFrame.", "response": "def read_td_query(query, engine, index_col=None, parse_dates=None, distributed_join=False, params=None):\n    '''Read Treasure Data query into a DataFrame.\n\n    Returns a DataFrame corresponding to the result set of the query string.\n    Optionally provide an index_col parameter to use one of the columns as\n    the index, otherwise default integer index will be used.\n\n    Parameters\n    ----------\n    query : string\n        Query string to be executed.\n    engine : QueryEngine\n        Handler returned by create_engine.\n    index_col : string, optional\n        Column name to use as index for the returned DataFrame object.\n    parse_dates : list or dict, optional\n        - List of column names to parse as dates\n        - Dict of {column_name: format string} where format string is strftime\n          compatible in case of parsing string times or is one of (D, s, ns, ms, us)\n          in case of parsing integer timestamps\n    distributed_join : boolean, default False\n        (Presto only) If True, distributed join is enabled. If False, broadcast join is used.\n        See https://prestodb.io/docs/current/release/release-0.77.html\n    params : dict, optional\n        Parameters to pass to execute method.\n        Available parameters:\n        - result_url (str): result output URL\n        - priority (int or str): priority (e.g. \"NORMAL\", \"HIGH\", etc.)\n        - retry_limit (int): retry limit\n\n    Returns\n    -------\n    DataFrame\n    '''\n    if params is None:\n        params = {}\n    # header\n    header = engine.create_header(\"read_td_query\")\n    if engine.type == 'presto' and distributed_join is not None:\n        header += \"-- set session distributed_join = '{0}'\\n\".format('true' if distributed_join else 'false')\n    # execute\n    r = engine.execute(header + query, **params)\n    return r.to_dataframe(index_col=index_col, parse_dates=parse_dates)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading Treasure Data job result into a DataFrame.", "response": "def read_td_job(job_id, engine, index_col=None, parse_dates=None):\n    '''Read Treasure Data job result into a DataFrame.\n\n    Returns a DataFrame corresponding to the result set of the job.\n    This method waits for job completion if the specified job is still running.\n    Optionally provide an index_col parameter to use one of the columns as\n    the index, otherwise default integer index will be used.\n\n    Parameters\n    ----------\n    job_id : integer\n        Job ID.\n    engine : QueryEngine\n        Handler returned by create_engine.\n    index_col : string, optional\n        Column name to use as index for the returned DataFrame object.\n    parse_dates : list or dict, optional\n        - List of column names to parse as dates\n        - Dict of {column_name: format string} where format string is strftime\n          compatible in case of parsing string times or is one of (D, s, ns, ms, us)\n          in case of parsing integer timestamps\n\n    Returns\n    -------\n    DataFrame\n    '''\n    # get job\n    job = engine.connection.client.job(job_id)\n    # result\n    r = engine.get_result(job, wait=True)\n    return r.to_dataframe(index_col=index_col, parse_dates=parse_dates)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_td_table(table_name, engine, index_col=None, parse_dates=None, columns=None, time_range=None, limit=10000):\n    '''Read Treasure Data table into a DataFrame.\n\n    The number of returned rows is limited by \"limit\" (default 10,000).\n    Setting limit=None means all rows. Be careful when you set limit=None\n    because your table might be very large and the result does not fit into memory.\n\n    Parameters\n    ----------\n    table_name : string\n        Name of Treasure Data table in database.\n    engine : QueryEngine\n        Handler returned by create_engine.\n    index_col : string, optional\n        Column name to use as index for the returned DataFrame object.\n    parse_dates : list or dict, optional\n        - List of column names to parse as dates\n        - Dict of {column_name: format string} where format string is strftime\n          compatible in case of parsing string times or is one of (D, s, ns, ms, us)\n          in case of parsing integer timestamps\n    columns : list, optional\n        List of column names to select from table.\n    time_range : tuple (start, end), optional\n        Limit time range to select. \"start\" and \"end\" are one of None, integers,\n        strings or datetime objects. \"end\" is exclusive, not included in the result.\n    limit : int, default 10,000\n        Maximum number of rows to select.\n\n    Returns\n    -------\n    DataFrame\n    '''\n    # header\n    query = engine.create_header(\"read_td_table('{0}')\".format(table_name))\n    # SELECT\n    query += \"SELECT {0}\\n\".format('*' if columns is None else ', '.join(columns))\n    # FROM\n    query += \"FROM {0}\\n\".format(table_name)\n    # WHERE\n    if time_range is not None:\n        start, end = time_range\n        query += \"WHERE td_time_range(time, {0}, {1})\\n\".format(_convert_time(start), _convert_time(end))\n    # LIMIT\n    if limit is not None:\n        query += \"LIMIT {0}\\n\".format(limit)\n    # execute\n    r = engine.execute(query)\n    return r.to_dataframe(index_col=index_col, parse_dates=parse_dates)", "response": "Read Treasure Data table into a DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites a DataFrame to a Treasure Data table.", "response": "def to_td(frame, name, con, if_exists='fail', time_col=None, time_index=None, index=True, index_label=None, chunksize=10000, date_format=None):\n    '''Write a DataFrame to a Treasure Data table.\n\n    This method converts the dataframe into a series of key-value pairs\n    and send them using the Treasure Data streaming API. The data is divided\n    into chunks of rows (default 10,000) and uploaded separately. If upload\n    failed, the client retries the process for a certain amount of time\n    (max_cumul_retry_delay; default 600 secs). This method may fail and\n    raise an exception when retries did not success, in which case the data\n    may be partially inserted. Use the bulk import utility if you cannot\n    accept partial inserts.\n\n    Parameters\n    ----------\n    frame : DataFrame\n        DataFrame to be written.\n    name : string\n        Name of table to be written, in the form 'database.table'.\n    con : Connection\n        Connection to a Treasure Data account.\n    if_exists: {'fail', 'replace', 'append'}, default 'fail'\n        - fail: If table exists, do nothing.\n        - replace: If table exists, drop it, recreate it, and insert data.\n        - append: If table exists, insert data. Create if does not exist.\n    time_col : string, optional\n        Column name to use as \"time\" column for the table. Column type must be\n        integer (unixtime), datetime, or string. If None is given (default),\n        then the current time is used as time values.\n    time_index : int, optional\n        Level of index to use as \"time\" column for the table. Set 0 for a single index.\n        This parameter implies index=False.\n    index : boolean, default True\n        Write DataFrame index as a column.\n    index_label : string or sequence, default None\n        Column label for index column(s). If None is given (default) and index is True,\n        then the index names are used. A sequence should be given if the DataFrame uses\n        MultiIndex.\n    chunksize : int, default 10,000\n        Number of rows to be inserted in each chunk from the dataframe.\n    date_format : string, default None\n        Format string for datetime objects\n    '''\n    database, table = name.split('.')\n    uploader = StreamingUploader(con.client, database, table, show_progress=True, clear_progress=True)\n    uploader.message('Streaming import into: {0}.{1}'.format(database, table))\n\n    # check existence\n    if if_exists == 'fail':\n        try:\n            con.client.table(database, table)\n        except tdclient.api.NotFoundError:\n            uploader.message('creating new table...')\n            con.client.create_log_table(database, table)\n        else:\n            raise RuntimeError('table \"%s\" already exists' % name)\n    elif if_exists == 'replace':\n        try:\n            con.client.table(database, table)\n        except tdclient.api.NotFoundError:\n            pass\n        else:\n            uploader.message('deleting old table...')\n            con.client.delete_table(database, table)\n        uploader.message('creating new table...')\n        con.client.create_log_table(database, table)\n    elif if_exists == 'append':\n        try:\n            con.client.table(database, table)\n        except tdclient.api.NotFoundError:\n            uploader.message('creating new table...')\n            con.client.create_log_table(database, table)\n    else:\n        raise ValueError('invalid value for if_exists: %s' % if_exists)\n\n    # \"time_index\" implies \"index=False\"\n    if time_index:\n        index = None\n\n    # convert\n    frame = frame.copy()\n    frame = _convert_time_column(frame, time_col, time_index)\n    frame = _convert_index_column(frame, index, index_label)\n    frame = _convert_date_format(frame, date_format)\n\n    # upload\n    uploader.upload_frame(frame, chunksize)\n    uploader.wait_for_import(len(frame))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the primary key of the current object.", "response": "def primary_key(self):\n        \"\"\"https://github.com/frictionlessdata/tableschema-py#schema\n        \"\"\"\n        primary_key = self.__current_descriptor.get('primaryKey', [])\n        if not isinstance(primary_key, list):\n            primary_key = [primary_key]\n        return primary_key"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef foreign_keys(self):\n        foreign_keys = self.__current_descriptor.get('foreignKeys', [])\n        for key in foreign_keys:\n            key.setdefault('fields', [])\n            key.setdefault('reference', {})\n            key['reference'].setdefault('resource', '')\n            key['reference'].setdefault('fields', [])\n            if not isinstance(key['fields'], list):\n                key['fields'] = [key['fields']]\n            if not isinstance(key['reference']['fields'], list):\n                key['reference']['fields'] = [key['reference']['fields']]\n        return foreign_keys", "response": "Returns a list of foreign keys for the current resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a new field to the current object.", "response": "def add_field(self, descriptor):\n        \"\"\"https://github.com/frictionlessdata/tableschema-py#schema\n        \"\"\"\n        self.__current_descriptor.setdefault('fields', [])\n        self.__current_descriptor['fields'].append(descriptor)\n        self.__build()\n        return self.__fields[-1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the value of a field in the next descriptor.", "response": "def update_field(self, name, update):\n        \"\"\"https://github.com/frictionlessdata/tableschema-py#schema\n        \"\"\"\n        for field in self.__next_descriptor['fields']:\n            if field['name'] == name:\n                field.update(update)\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves a field from the current object.", "response": "def remove_field(self, name):\n        \"\"\"https://github.com/frictionlessdata/tableschema-py#schema\n        \"\"\"\n        field = self.get_field(name)\n        if field:\n            predicat = lambda field: field.get('name') != name\n            self.__current_descriptor['fields'] = filter(\n                predicat, self.__current_descriptor['fields'])\n            self.__build()\n        return field"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cast_row(self, row, fail_fast=False):\n\n        # Prepare\n        result = []\n        errors = []\n\n        # Check row length\n        if len(row) != len(self.fields):\n            message = 'Row length %s doesn\\'t match fields count %s'\n            message = message % (len(row), len(self.fields))\n            raise exceptions.CastError(message)\n\n        # Cast row\n        for field, value in zip(self.fields, row):\n            try:\n                result.append(field.cast_value(value))\n            except exceptions.CastError as exception:\n                if fail_fast:\n                    raise\n                errors.append(exception)\n\n        # Raise errors\n        if errors:\n            message = 'There are %s cast errors (see exception.errors)' % len(errors)\n            raise exceptions.CastError(message, errors=errors)\n\n        return result", "response": "Cast a row of data into a list of objects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef infer(self, rows, headers=1, confidence=0.75):\n\n        # Get headers\n        if isinstance(headers, int):\n            headers_row = headers\n            while True:\n                headers_row -= 1\n                headers = rows.pop(0)\n                if not headers_row:\n                    break\n        elif not isinstance(headers, list):\n            headers = []\n\n        # Get descriptor\n        guesser = _TypeGuesser()\n        resolver = _TypeResolver()\n        descriptor = {'fields': []}\n        type_matches = {}\n        for header in headers:\n            descriptor['fields'].append({'name': header})\n        for index, row in enumerate(rows):\n            # Normalize rows with invalid dimensions for sanity\n            row_length = len(row)\n            headers_length = len(headers)\n            if row_length > headers_length:\n                row = row[:len(headers)]\n            if row_length < headers_length:\n                diff = headers_length - row_length\n                fill = [''] * diff\n                row = row + fill\n            # build a column-wise lookup of type matches\n            for index, value in enumerate(row):\n                rv = guesser.cast(value)\n                if type_matches.get(index):\n                    type_matches[index].extend(rv)\n                else:\n                    type_matches[index] = list(rv)\n        # choose a type/format for each column based on the matches\n        for index, results in type_matches.items():\n            rv = resolver.get(results, confidence)\n            descriptor['fields'][index].update(**rv)\n\n        # Save descriptor\n        self.__current_descriptor = descriptor\n        self.__build()\n\n        return descriptor", "response": "Infer the type of the matches in the rows."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the current state of the object to a file.", "response": "def save(self, target, ensure_ascii=True):\n        \"\"\"https://github.com/frictionlessdata/tableschema-py#schema\n        \"\"\"\n        mode = 'w'\n        encoding = 'utf-8'\n        if six.PY2:\n            mode = 'wb'\n            encoding = None\n        helpers.ensure_dir(target)\n        with io.open(target, mode=mode, encoding=encoding) as file:\n            json.dump(self.__current_descriptor, file, indent=4, ensure_ascii=ensure_ascii)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nensure directory exists. Args: path(str): dir path", "response": "def ensure_dir(path):\n    \"\"\"Ensure directory exists.\n\n    Args:\n        path(str): dir path\n\n    \"\"\"\n    dirpath = os.path.dirname(path)\n    if dirpath and not os.path.exists(dirpath):\n        os.makedirs(dirpath)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts value to string and make it lower cased.", "response": "def normalize_value(value):\n    \"\"\"Convert value to string and make it lower cased.\n    \"\"\"\n    cast = str\n    if six.PY2:\n        cast = unicode  # noqa\n    return cast(value).lower()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cast_value(self, value, constraints=True):\n\n        # Null value\n        if value in self.__missing_values:\n            value = None\n\n        # Cast value\n        cast_value = value\n        if value is not None:\n            cast_value = self.__cast_function(value)\n            if cast_value == config.ERROR:\n                raise exceptions.CastError((\n                    'Field \"{field.name}\" can\\'t cast value \"{value}\" '\n                    'for type \"{field.type}\" with format \"{field.format}\"'\n                    ).format(field=self, value=value))\n\n        # Check value\n        if constraints:\n            for name, check in self.__check_functions.items():\n                if isinstance(constraints, list):\n                    if name not in constraints:\n                        continue\n                passed = check(cast_value)\n                if not passed:\n                    raise exceptions.CastError((\n                        'Field \"{field.name}\" has constraint \"{name}\" '\n                        'which is not satisfied for value \"{value}\"'\n                        ).format(field=self, name=name, value=value))\n\n        return cast_value", "response": "Casts the value of the current object to the type of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iter(self, keyed=False, extended=False, cast=True, relations=False):\n\n        # Prepare unique checks\n        if cast:\n            unique_fields_cache = {}\n            if self.schema:\n                unique_fields_cache = _create_unique_fields_cache(self.schema)\n\n        # Open/iterate stream\n        self.__stream.open()\n        iterator = self.__stream.iter(extended=True)\n        iterator = self.__apply_processors(iterator, cast=cast)\n        for row_number, headers, row in iterator:\n\n            # Get headers\n            if not self.__headers:\n                self.__headers = headers\n\n            # Check headers\n            if cast:\n                if self.schema and self.headers:\n                    if self.headers != self.schema.field_names:\n                        self.__stream.close()\n                        message = 'Table headers don\\'t match schema field names'\n                        raise exceptions.CastError(message)\n\n            # Check unique\n            if cast:\n                for indexes, cache in unique_fields_cache.items():\n                    values = tuple(value for i, value in enumerate(row) if i in indexes)\n                    if not all(map(lambda value: value is None, values)):\n                        if values in cache['data']:\n                            self.__stream.close()\n                            message = 'Field(s) \"%s\" duplicates in row \"%s\"'\n                            message = message % (cache['name'], row_number)\n                            raise exceptions.CastError(message)\n                        cache['data'].add(values)\n\n            # Resolve relations\n            if relations:\n                if self.schema:\n                    for foreign_key in self.schema.foreign_keys:\n                        row = _resolve_relations(row, headers, relations, foreign_key)\n                        if row is None:\n                            self.__stream.close()\n                            message = 'Foreign key \"%s\" violation in row \"%s\"'\n                            message = message % (foreign_key['fields'], row_number)\n                            raise exceptions.RelationError(message)\n\n            # Form row\n            if extended:\n                yield (row_number, headers, row)\n            elif keyed:\n                yield dict(zip(headers, row))\n            else:\n                yield row\n\n        # Close stream\n        self.__stream.close()", "response": "Iterate over the table and return a generator of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read(self, keyed=False, extended=False, cast=True, relations=False, limit=None):\n        result = []\n        rows = self.iter(keyed=keyed, extended=extended, cast=cast, relations=relations)\n        for count, row in enumerate(rows, start=1):\n            result.append(row)\n            if count == limit:\n                break\n        return result", "response": "Read the list of all the user s related users."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninfer the schema of the current object.", "response": "def infer(self, limit=100, confidence=0.75):\n        \"\"\"https://github.com/frictionlessdata/tableschema-py#schema\n        \"\"\"\n        if self.__schema is None or self.__headers is None:\n\n            # Infer (tabulator)\n            if not self.__storage:\n                with self.__stream as stream:\n                    if self.__schema is None:\n                        self.__schema = Schema()\n                        self.__schema.infer(stream.sample[:limit],\n                                            headers=stream.headers,\n                                            confidence=confidence)\n                    if self.__headers is None:\n                        self.__headers = stream.headers\n\n            # Infer (storage)\n            else:\n                descriptor = self.__storage.describe(self.__source)\n                if self.__schema is None:\n                    self.__schema = Schema(descriptor)\n                if self.__headers is None:\n                    self.__headers = self.__schema.field_names\n\n        return self.__schema.descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave the current object to the specified file.", "response": "def save(self, target, storage=None, **options):\n        \"\"\"https://github.com/frictionlessdata/tableschema-py#schema\n        \"\"\"\n\n        # Save (tabulator)\n        if storage is None:\n            with Stream(self.iter, headers=self.__schema.headers) as stream:\n                stream.save(target, **options)\n            return True\n\n        # Save (storage)\n        else:\n            if not isinstance(storage, Storage):\n                storage = Storage.connect(storage, **options)\n            storage.create(target, self.__schema.descriptor, force=True)\n            storage.write(target, self.iter(cast=False))\n            return storage"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninferring a schema from data.", "response": "def infer(data, row_limit, confidence, encoding, to_file):\n    \"\"\"Infer a schema from data.\n\n    * data must be a local filepath\n    * data must be CSV\n    * the file encoding is assumed to be UTF-8 unless an encoding is passed\n      with --encoding\n    * the first line of data must be headers\n    * these constraints are just for the CLI\n    \"\"\"\n    descriptor = tableschema.infer(data,\n                                   encoding=encoding,\n                                   limit=row_limit,\n                                   confidence=confidence)\n    if to_file:\n        with io.open(to_file, mode='w+t', encoding='utf-8') as dest:\n            dest.write(json.dumps(descriptor, ensure_ascii=False, indent=4))\n    click.echo(descriptor)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate(schema):\n    try:\n        tableschema.validate(schema)\n        click.echo(\"Schema is valid\")\n        sys.exit(0)\n    except tableschema.exceptions.ValidationError as exception:\n        click.echo(\"Schema is not valid\")\n        click.echo(exception.errors)\n        sys.exit(1)", "response": "Validate that a supposed schema is in fact a Table Schema."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef infer(source, headers=1, limit=100, confidence=0.75, **options):\n\n    # Deprecated arguments order\n    is_string = lambda value: isinstance(value, six.string_types)\n    if isinstance(source, list) and all(map(is_string, source)):\n        warnings.warn('Correct arguments order infer(source, headers)', UserWarning)\n        source, headers = headers, source\n\n    table = Table(source, headers=headers, **options)\n    descriptor = table.infer(limit=limit, confidence=confidence)\n    return descriptor", "response": "infer a single object from a list of strings"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks the key path find specification.", "response": "def _CheckKeyPath(self, registry_key, search_depth):\n    \"\"\"Checks the key path find specification.\n\n    Args:\n      registry_key (WinRegistryKey): Windows Registry key.\n      search_depth (int): number of key path segments to compare.\n\n    Returns:\n      bool: True if the Windows Registry key matches the find specification,\n          False if not.\n    \"\"\"\n    if self._key_path_segments is None:\n      return False\n\n    if search_depth < 0 or search_depth > self._number_of_key_path_segments:\n      return False\n\n    # Note that the root has no entry in the key path segments and\n    # no name to match.\n    if search_depth == 0:\n      segment_name = ''\n    else:\n      segment_name = self._key_path_segments[search_depth - 1]\n\n      if self._is_regex:\n        if isinstance(segment_name, py2to3.STRING_TYPES):\n          # Allow '\\n' to be matched by '.' and make '\\w', '\\W', '\\b', '\\B',\n          # '\\d', '\\D', '\\s' and '\\S' Unicode safe.\n          flags = re.DOTALL | re.IGNORECASE | re.UNICODE\n\n          try:\n            segment_name = r'^{0:s}$'.format(segment_name)\n            segment_name = re.compile(segment_name, flags=flags)\n          except sre_constants.error:\n            # TODO: set self._key_path_segments[search_depth - 1] to None ?\n            return False\n\n          self._key_path_segments[search_depth - 1] = segment_name\n\n      else:\n        segment_name = segment_name.lower()\n        self._key_path_segments[search_depth - 1] = segment_name\n\n    if search_depth > 0:\n      if self._is_regex:\n        # pylint: disable=no-member\n        if not segment_name.match(registry_key.name):\n          return False\n\n      elif segment_name != registry_key.name.lower():\n        return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetermines if the find specification is at maximum depth.", "response": "def AtMaximumDepth(self, search_depth):\n    \"\"\"Determines if the find specification is at maximum depth.\n\n    Args:\n      search_depth (int): number of key path segments to compare.\n\n    Returns:\n      bool: True if at maximum depth, False if not.\n    \"\"\"\n    if self._key_path_segments is not None:\n      if search_depth >= self._number_of_key_path_segments:\n        return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetermining if the Windows Registry key matches the find specification.", "response": "def Matches(self, registry_key, search_depth):\n    \"\"\"Determines if the Windows Registry key matches the find specification.\n\n    Args:\n      registry_key (WinRegistryKey): Windows Registry key.\n      search_depth (int): number of key path segments to compare.\n\n    Returns:\n      tuple: contains:\n\n        bool: True if the Windows Registry key matches the find specification,\n            False otherwise.\n        bool: True if the key path matches, False if not or None if no key path\n            specified.\n    \"\"\"\n    if self._key_path_segments is None:\n      key_path_match = None\n    else:\n      key_path_match = self._CheckKeyPath(registry_key, search_depth)\n      if not key_path_match:\n        return False, key_path_match\n\n      if search_depth != self._number_of_key_path_segments:\n        return False, key_path_match\n\n    return True, key_path_match"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches for matching keys within a Windows Registry key.", "response": "def _FindInKey(self, registry_key, find_specs, search_depth):\n    \"\"\"Searches for matching keys within the Windows Registry key.\n\n    Args:\n      registry_key (WinRegistryKey): Windows Registry key.\n      find_specs (list[FindSpec]): find specifications.\n      search_depth (int): number of key path segments to compare.\n\n    Yields:\n      str: key path of a matching Windows Registry key.\n    \"\"\"\n    sub_find_specs = []\n    for find_spec in find_specs:\n      match, key_path_match = find_spec.Matches(registry_key, search_depth)\n      if match:\n        yield registry_key.path\n\n      # pylint: disable=singleton-comparison\n      if key_path_match != False and not find_spec.AtMaximumDepth(search_depth):\n        sub_find_specs.append(find_spec)\n\n    if sub_find_specs:\n      search_depth += 1\n      for sub_registry_key in registry_key.GetSubkeys():\n        for matching_path in self._FindInKey(\n            sub_registry_key, sub_find_specs, search_depth):\n          yield matching_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches for matching keys within the Windows Registry.", "response": "def Find(self, find_specs=None):\n    \"\"\"Searches for matching keys within the Windows Registry.\n\n    Args:\n      find_specs (list[FindSpec]): find specifications. where None\n          will return all allocated Windows Registry keys.\n\n    Yields:\n      str: key path of a matching Windows Registry key.\n    \"\"\"\n    if not find_specs:\n      find_specs = [FindSpec()]\n\n    registry_key = self._win_registry.GetRootKey()\n    for matching_path in self._FindInKey(registry_key, find_specs, 0):\n      yield matching_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef RecurseKeys(self):\n    root_key = self.GetRootKey()\n    if root_key:\n      for registry_key in root_key.RecurseKeys():\n        yield registry_key", "response": "Recurses the Windows Registry keys starting with the root key."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef SetKeyPathPrefix(self, key_path_prefix):\n    self._key_path_prefix = key_path_prefix\n    self._key_path_prefix_length = len(key_path_prefix)\n    self._key_path_prefix_upper = key_path_prefix.upper()", "response": "Sets the Windows Registry key path prefix."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef DataIsInteger(self):\n    return self.data_type in (\n        definitions.REG_DWORD, definitions.REG_DWORD_BIG_ENDIAN,\n        definitions.REG_QWORD)", "response": "Determines if the data is an integer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a Windows Registry key for a specific key path.", "response": "def AddKeyByPath(self, key_path, registry_key):\n    \"\"\"Adds a Windows Registry key for a specific key path.\n\n    Args:\n      key_path (str): Windows Registry key path to add the key.\n      registry_key (WinRegistryKey): Windows Registry key.\n\n    Raises:\n      KeyError: if the subkey already exists.\n      ValueError: if the Windows Registry key cannot be added.\n    \"\"\"\n    if not key_path.startswith(definitions.KEY_PATH_SEPARATOR):\n      raise ValueError('Key path does not start with: {0:s}'.format(\n          definitions.KEY_PATH_SEPARATOR))\n\n    if not self._root_key:\n      self._root_key = FakeWinRegistryKey(self._key_path_prefix)\n\n    path_segments = key_paths.SplitKeyPath(key_path)\n    parent_key = self._root_key\n    for path_segment in path_segments:\n      try:\n        subkey = FakeWinRegistryKey(path_segment)\n        parent_key.AddSubkey(subkey)\n      except KeyError:\n        subkey = parent_key.GetSubkeyByName(path_segment)\n\n      parent_key = subkey\n\n    parent_key.AddSubkey(registry_key)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the Windows Registry key for a specific path.", "response": "def GetKeyByPath(self, key_path):\n    \"\"\"Retrieves the key for a specific path.\n\n    Args:\n      key_path (str): Windows Registry key path.\n\n    Returns:\n      WinRegistryKey: Windows Registry key or None if not available.\n    \"\"\"\n    key_path_upper = key_path.upper()\n    if key_path_upper.startswith(self._key_path_prefix_upper):\n      relative_key_path = key_path[self._key_path_prefix_length:]\n    elif key_path.startswith(definitions.KEY_PATH_SEPARATOR):\n      relative_key_path = key_path\n      key_path = ''.join([self._key_path_prefix, key_path])\n    else:\n      return None\n\n    path_segments = key_paths.SplitKeyPath(relative_key_path)\n    registry_key = self._root_key\n    if not registry_key:\n      return None\n\n    for path_segment in path_segments:\n      registry_key = registry_key.GetSubkeyByName(path_segment)\n      if not registry_key:\n        return None\n\n    return registry_key"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the last written time in the file.", "response": "def last_written_time(self):\n    \"\"\"dfdatetime.DateTimeValues: last written time.\"\"\"\n    if self._last_written_time is None:\n      return dfdatetime_semantic_time.SemanticTime('Not set')\n\n    return dfdatetime_filetime.Filetime(timestamp=self._last_written_time)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _BuildKeyHierarchy(self, subkeys, values):\n    if subkeys:\n      for registry_key in subkeys:\n        name = registry_key.name.upper()\n        if name in self._subkeys:\n          continue\n        self._subkeys[name] = registry_key\n\n        # pylint: disable=protected-access\n        registry_key._key_path = key_paths.JoinKeyPath([\n            self._key_path, registry_key.name])\n\n    if values:\n      for registry_value in values:\n        name = registry_value.name.upper()\n        if name in self._values:\n          continue\n        self._values[name] = registry_value", "response": "Builds the Windows Registry key hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef AddSubkey(self, registry_key):\n    name = registry_key.name.upper()\n    if name in self._subkeys:\n      raise KeyError(\n          'Subkey: {0:s} already exists.'.format(registry_key.name))\n\n    self._subkeys[name] = registry_key\n\n    key_path = key_paths.JoinKeyPath([self._key_path, registry_key.name])\n    registry_key._key_path = key_path", "response": "Adds a subkey to the internal list of subkeys."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a value to the sequence.", "response": "def AddValue(self, registry_value):\n    \"\"\"Adds a value.\n\n    Args:\n      registry_value (WinRegistryValue): Windows Registry value.\n\n    Raises:\n      KeyError: if the value already exists.\n    \"\"\"\n    name = registry_value.name.upper()\n    if name in self._values:\n      raise KeyError(\n          'Value: {0:s} already exists.'.format(registry_value.name))\n\n    self._values[name] = registry_value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving a subkey by index.", "response": "def GetSubkeyByIndex(self, index):\n    \"\"\"Retrieves a subkey by index.\n\n    Args:\n      index (int): index of the subkey.\n\n    Returns:\n      WinRegistryKey: Windows Registry subkey or None if not found.\n\n    Raises:\n      IndexError: if the index is out of bounds.\n    \"\"\"\n    subkeys = list(self._subkeys.values())\n\n    if index < 0 or index >= len(subkeys):\n      raise IndexError('Index out of bounds.')\n\n    return subkeys[index]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetSubkeyByPath(self, key_path):\n    subkey = self\n    for path_segment in key_paths.SplitKeyPath(key_path):\n      subkey = subkey.GetSubkeyByName(path_segment)\n      if not subkey:\n        break\n\n    return subkey", "response": "Retrieves a subkey by path."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves the data as an object.", "response": "def GetDataAsObject(self):\n    \"\"\"Retrieves the data as an object.\n\n    Returns:\n      object: data as a Python type or None if not available.\n\n    Raises:\n      WinRegistryValueError: if the value data cannot be read.\n    \"\"\"\n    if not self._data:\n      return None\n\n    if self._data_type in self._STRING_VALUE_TYPES:\n      try:\n        return self._data.decode('utf-16-le')\n\n      # AttributeError is raised when self._data has no decode method.\n      except AttributeError as exception:\n        raise errors.WinRegistryValueError((\n            'Unsupported data type: {0!s} of value: {1!s} with error: '\n            '{2!s}').format(type(self._data), self._name, exception))\n\n      except UnicodeError as exception:\n        raise errors.WinRegistryValueError(\n            'Unable to decode data of value: {0!s} with error: {1!s}'.format(\n                self._name, exception))\n\n    elif (self._data_type == definitions.REG_DWORD and\n          self._data_size == 4):\n      return self._INT32_LITTLE_ENDIAN.MapByteStream(self._data)\n\n    elif (self._data_type == definitions.REG_DWORD_BIG_ENDIAN and\n          self._data_size == 4):\n      return self._INT32_BIG_ENDIAN.MapByteStream(self._data)\n\n    elif (self._data_type == definitions.REG_QWORD and\n          self._data_size == 8):\n      return self._INT64_LITTLE_ENDIAN.MapByteStream(self._data)\n\n    elif self._data_type == definitions.REG_MULTI_SZ:\n      try:\n        utf16_string = self._data.decode('utf-16-le')\n        # TODO: evaluate the use of filter here is appropriate behavior.\n        return list(filter(None, utf16_string.split('\\x00')))\n\n      # AttributeError is raised when self._data has no decode method.\n      except AttributeError as exception:\n        raise errors.WinRegistryValueError((\n            'Unsupported data type: {0!s} of value: {1!s} with error: '\n            '{2!s}').format(type(self._data), self._name, exception))\n\n      except UnicodeError as exception:\n        raise errors.WinRegistryValueError(\n            'Unable to read data from value: {0!s} with error: {1!s}'.format(\n                self._name, exception))\n\n    return self._data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _GetCachedFileByPath(self, key_path_upper):\n    longest_key_path_prefix_upper = ''\n    longest_key_path_prefix_length = len(longest_key_path_prefix_upper)\n    for key_path_prefix_upper in self._registry_files:\n      if key_path_upper.startswith(key_path_prefix_upper):\n        key_path_prefix_length = len(key_path_prefix_upper)\n        if key_path_prefix_length > longest_key_path_prefix_length:\n          longest_key_path_prefix_upper = key_path_prefix_upper\n          longest_key_path_prefix_length = key_path_prefix_length\n\n    if not longest_key_path_prefix_upper:\n      return None, None\n\n    registry_file = self._registry_files.get(\n        longest_key_path_prefix_upper, None)\n    return longest_key_path_prefix_upper, registry_file", "response": "Retrieves a Windows Registry file for a key path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _GetFileByPath(self, key_path_upper):\n    # TODO: handle HKEY_USERS in both 9X and NT.\n\n    key_path_prefix, registry_file = self._GetCachedFileByPath(key_path_upper)\n    if not registry_file:\n      for mapping in self._GetFileMappingsByPath(key_path_upper):\n        try:\n          registry_file = self._OpenFile(mapping.windows_path)\n        except IOError:\n          registry_file = None\n\n        if not registry_file:\n          continue\n\n        if not key_path_prefix:\n          key_path_prefix = mapping.key_path_prefix\n\n        self.MapFile(key_path_prefix, registry_file)\n        key_path_prefix = key_path_prefix.upper()\n        break\n\n    return key_path_prefix, registry_file", "response": "Retrieves a Windows Registry file for a specific path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving the Windows Registry file mappings for a specific path.", "response": "def _GetFileMappingsByPath(self, key_path_upper):\n    \"\"\"Retrieves the Windows Registry file mappings for a specific path.\n\n    Args:\n      key_path_upper (str): Windows Registry key path, in upper case with\n          a resolved root key alias.\n\n    Yields:\n      WinRegistryFileMapping: Windows Registry file mapping.\n    \"\"\"\n    candidate_mappings = []\n    for mapping in self._REGISTRY_FILE_MAPPINGS_NT:\n      if key_path_upper.startswith(mapping.key_path_prefix.upper()):\n        candidate_mappings.append(mapping)\n\n    # Sort the candidate mappings by longest (most specific) match first.\n    candidate_mappings.sort(\n        key=lambda mapping: len(mapping.key_path_prefix), reverse=True)\n    for mapping in candidate_mappings:\n      yield mapping"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _OpenFile(self, path):\n    if not self._registry_file_reader:\n      return None\n\n    return self._registry_file_reader.Open(\n        path, ascii_codepage=self._ascii_codepage)", "response": "Opens a Windows Registry file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GetKeyByPath(self, key_path):\n    root_key_path, _, key_path = key_path.partition(\n        definitions.KEY_PATH_SEPARATOR)\n\n    # Resolve a root key alias.\n    root_key_path = root_key_path.upper()\n    root_key_path = self._ROOT_KEY_ALIASES.get(root_key_path, root_key_path)\n\n    if root_key_path not in self._ROOT_KEYS:\n      raise RuntimeError('Unsupported root key: {0:s}'.format(root_key_path))\n\n    key_path = definitions.KEY_PATH_SEPARATOR.join([root_key_path, key_path])\n    key_path_upper = key_path.upper()\n\n    for virtual_key_path, virtual_key_callback in self._VIRTUAL_KEYS:\n      virtual_key_path_upper = virtual_key_path.upper()\n      if key_path_upper.startswith(virtual_key_path_upper):\n        key_path_suffix = key_path[len(virtual_key_path):]\n\n        callback_function = getattr(self, virtual_key_callback)\n        virtual_key = callback_function(key_path_suffix)\n        if not virtual_key:\n          raise RuntimeError('Unable to resolve virtual key: {0:s}.'.format(\n              virtual_key_path))\n\n        return virtual_key\n\n    key_path_prefix_upper, registry_file = self._GetFileByPath(key_path_upper)\n    if not registry_file:\n      return None\n\n    if not key_path_upper.startswith(key_path_prefix_upper):\n      raise RuntimeError('Key path prefix mismatch.')\n\n    key_path_suffix = key_path[len(key_path_prefix_upper):]\n    key_path = key_path_suffix or definitions.KEY_PATH_SEPARATOR\n    return registry_file.GetKeyByPath(key_path)", "response": "Retrieves a Windows Registry key for a specific path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GetRegistryFileMapping(self, registry_file):\n    if not registry_file:\n      return ''\n\n    candidate_mappings = []\n    for mapping in self._REGISTRY_FILE_MAPPINGS_NT:\n      if not mapping.unique_key_paths:\n        continue\n\n      # If all unique key paths are found consider the file to match.\n      match = True\n      for key_path in mapping.unique_key_paths:\n        registry_key = registry_file.GetKeyByPath(key_path)\n        if not registry_key:\n          match = False\n\n      if match:\n        candidate_mappings.append(mapping)\n\n    if not candidate_mappings:\n      return ''\n\n    if len(candidate_mappings) == 1:\n      return candidate_mappings[0].key_path_prefix\n\n    key_path_prefixes = frozenset([\n        mapping.key_path_prefix for mapping in candidate_mappings])\n\n    expected_key_path_prefixes = frozenset([\n        'HKEY_CURRENT_USER',\n        'HKEY_CURRENT_USER\\\\Software\\\\Classes'])\n\n    if key_path_prefixes == expected_key_path_prefixes:\n      return 'HKEY_CURRENT_USER'\n\n    raise RuntimeError('Unable to resolve Windows Registry file mapping.')", "response": "Determines the Registry file mapping based on the content of the file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve the Windows Registry root key.", "response": "def GetRootKey(self):\n    \"\"\"Retrieves the Windows Registry root key.\n\n    Returns:\n      WinRegistryKey: Windows Registry root key.\n\n    Raises:\n      RuntimeError: if there are multiple matching mappings and\n          the correct mapping cannot be resolved.\n    \"\"\"\n    root_registry_key = virtual.VirtualWinRegistryKey('')\n\n    for mapped_key in self._MAPPED_KEYS:\n      key_path_segments = key_paths.SplitKeyPath(mapped_key)\n      if not key_path_segments:\n        continue\n\n      registry_key = root_registry_key\n      for name in key_path_segments[:-1]:\n        sub_registry_key = registry_key.GetSubkeyByName(name)\n        if not sub_registry_key:\n          sub_registry_key = virtual.VirtualWinRegistryKey(name)\n          registry_key.AddSubkey(sub_registry_key)\n\n        registry_key = sub_registry_key\n\n      sub_registry_key = registry_key.GetSubkeyByName(key_path_segments[-1])\n      if (not sub_registry_key and\n          isinstance(registry_key, virtual.VirtualWinRegistryKey)):\n        sub_registry_key = virtual.VirtualWinRegistryKey(\n            key_path_segments[-1], registry=self)\n\n        registry_key.AddSubkey(sub_registry_key)\n\n    return root_registry_key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef MapFile(self, key_path_prefix, registry_file):\n    self._registry_files[key_path_prefix.upper()] = registry_file\n    registry_file.SetKeyPathPrefix(key_path_prefix)", "response": "Maps the Windows Registry file to a specific key path prefix."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef GetKeyByPath(self, key_path):\n    key_path_upper = key_path.upper()\n    if key_path_upper.startswith(self._key_path_prefix_upper):\n      relative_key_path = key_path[self._key_path_prefix_length:]\n    elif key_path.startswith(definitions.KEY_PATH_SEPARATOR):\n      relative_key_path = key_path\n      key_path = ''.join([self._key_path_prefix, key_path])\n    else:\n      return None\n\n    try:\n      regf_key = self._regf_file.get_key_by_path(relative_key_path)\n    except IOError:\n      regf_key = None\n    if not regf_key:\n      return None\n\n    return REGFWinRegistryKey(regf_key, key_path=key_path)", "response": "Retrieves the Windows Registry key for a specific path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve the root key of the Windows Registry file.", "response": "def GetRootKey(self):\n    \"\"\"Retrieves the root key.\n\n    Returns:\n      WinRegistryKey: Windows Registry root key or None if not available.\n    \"\"\"\n    regf_key = self._regf_file.get_root_key()\n    if not regf_key:\n      return None\n\n    return REGFWinRegistryKey(regf_key, key_path=self._key_path_prefix)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening the Windows Registry file using a file - like object.", "response": "def Open(self, file_object):\n    \"\"\"Opens the Windows Registry file using a file-like object.\n\n    Args:\n      file_object (file): file-like object.\n\n    Returns:\n      bool: True if successful or False if not.\n    \"\"\"\n    self._file_object = file_object\n    self._regf_file.open_file_object(self._file_object)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the last written time in the registry.", "response": "def last_written_time(self):\n    \"\"\"dfdatetime.DateTimeValues: last written time.\"\"\"\n    timestamp = self._pyregf_key.get_last_written_time_as_integer()\n    if timestamp == 0:\n      return dfdatetime_semantic_time.SemanticTime('Not set')\n\n    return dfdatetime_filetime.Filetime(timestamp=timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving a subkey by index.", "response": "def GetSubkeyByIndex(self, index):\n    \"\"\"Retrieves a subkey by index.\n\n    Args:\n      index (int): index of the subkey.\n\n    Returns:\n      WinRegistryKey: Windows Registry subkey or None if not found.\n\n    Raises:\n      IndexError: if the index is out of bounds.\n    \"\"\"\n    if index < 0 or index >= self._pyregf_key.number_of_sub_keys:\n      raise IndexError('Index out of bounds.')\n\n    pyregf_key = self._pyregf_key.get_sub_key(index)\n    if not pyregf_key:\n      return None\n\n    key_path = key_paths.JoinKeyPath([self._key_path, pyregf_key.name])\n    return REGFWinRegistryKey(pyregf_key, key_path=key_path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GetSubkeyByName(self, name):\n    pyregf_key = self._pyregf_key.get_sub_key_by_name(name)\n    if not pyregf_key:\n      return None\n\n    key_path = key_paths.JoinKeyPath([self._key_path, pyregf_key.name])\n    return REGFWinRegistryKey(pyregf_key, key_path=key_path)", "response": "Retrieves a subkey by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetSubkeyByPath(self, key_path):\n    pyregf_key = self._pyregf_key.get_sub_key_by_path(key_path)\n    if not pyregf_key:\n      return None\n\n    key_path = key_paths.JoinKeyPath([self._key_path, key_path])\n    return REGFWinRegistryKey(pyregf_key, key_path=key_path)", "response": "Retrieves a subkey by path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving all subkeys within the key.", "response": "def GetSubkeys(self):\n    \"\"\"Retrieves all subkeys within the key.\n\n    Yields:\n      WinRegistryKey: Windows Registry subkey.\n    \"\"\"\n    for pyregf_key in self._pyregf_key.sub_keys:\n      key_path = key_paths.JoinKeyPath([self._key_path, pyregf_key.name])\n      yield REGFWinRegistryKey(pyregf_key, key_path=key_path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving a Windows Registry value by name.", "response": "def GetValueByName(self, name):\n    \"\"\"Retrieves a value by name.\n\n    Value names are not unique and pyregf provides first match for the value.\n\n    Args:\n      name (str): name of the value or an empty string for the default value.\n\n    Returns:\n      WinRegistryValue: Windows Registry value if a corresponding value was\n          found or None if not.\n    \"\"\"\n    pyregf_value = self._pyregf_key.get_value_by_name(name)\n    if not pyregf_value:\n      return None\n\n    return REGFWinRegistryValue(pyregf_value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef data(self):\n    try:\n      return self._pyregf_value.data\n    except IOError as exception:\n      raise errors.WinRegistryValueError(\n          'Unable to read data from value: {0:s} with error: {1!s}'.format(\n              self._pyregf_value.name, exception))", "response": "Returns the value data as a byte string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetDataAsObject(self):\n    if self._pyregf_value.type in self._STRING_VALUE_TYPES:\n      try:\n        return self._pyregf_value.get_data_as_string()\n      except IOError as exception:\n        raise errors.WinRegistryValueError(\n            'Unable to read data from value: {0:s} with error: {1!s}'.format(\n                self._pyregf_value.name, exception))\n\n    if self._pyregf_value.type in self._INTEGER_VALUE_TYPES:\n      try:\n        return self._pyregf_value.get_data_as_integer()\n      except (IOError, OverflowError) as exception:\n        raise errors.WinRegistryValueError(\n            'Unable to read data from value: {0:s} with error: {1!s}'.format(\n                self._pyregf_value.name, exception))\n\n    try:\n      value_data = self._pyregf_value.data\n    except IOError as exception:\n      raise errors.WinRegistryValueError(\n          'Unable to read data from value: {0:s} with error: {1!s}'.format(\n              self._pyregf_value.name, exception))\n\n    if self._pyregf_value.type == definitions.REG_MULTI_SZ:\n      # TODO: Add support for REG_MULTI_SZ to pyregf.\n      if value_data is None:\n        return []\n\n      try:\n        utf16_string = value_data.decode('utf-16-le')\n        return list(filter(None, utf16_string.split('\\x00')))\n\n      except UnicodeError as exception:\n        raise errors.WinRegistryValueError(\n            'Unable to read data from value: {0:s} with error: {1!s}'.format(\n                self._pyregf_value.name, exception))\n\n    return value_data", "response": "Retrieves the data as an object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef JoinKeyPath(path_segments):\n  # This is an optimized way to combine the path segments into a single path\n  # and combine multiple successive path separators to one.\n\n  # Split all the path segments based on the path (segment) separator.\n  path_segments = [\n      segment.split(definitions.KEY_PATH_SEPARATOR)\n      for segment in path_segments]\n\n  # Flatten the sublists into one list.\n  path_segments = [\n      element for sublist in path_segments for element in sublist]\n\n  # Remove empty path segments.\n  path_segments = filter(None, path_segments)\n\n  key_path = definitions.KEY_PATH_SEPARATOR.join(path_segments)\n  if not key_path.startswith('HKEY_'):\n    key_path = '{0:s}{1:s}'.format(definitions.KEY_PATH_SEPARATOR, key_path)\n  return key_path", "response": "Joins the path segments into a key path."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsplit the key path into a list of path segments.", "response": "def SplitKeyPath(key_path, path_separator=definitions.KEY_PATH_SEPARATOR):\n  \"\"\"Splits the key path into path segments.\n\n  Args:\n    key_path (str): key path.\n    path_separator (Optional[str]): path separator.\n\n  Returns:\n    list[str]: key path segments without the root path segment, which is an\n        empty string.\n  \"\"\"\n  # Split the path with the path separator and remove empty path segments.\n  return list(filter(None, key_path.split(path_separator)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef class_name(self):\n    if not self._registry_key and self._registry:\n      self._GetKeyFromRegistry()\n\n    if not self._registry_key:\n      return None\n\n    return self._registry_key.class_name", "response": "str - class name of the key or None if not available."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef last_written_time(self):\n    if not self._registry_key and self._registry:\n      self._GetKeyFromRegistry()\n\n    if not self._registry_key:\n      return None\n\n    return self._registry_key.last_written_time", "response": "Returns the last written time or None if no such time exists."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef number_of_values(self):\n    if not self._registry_key and self._registry:\n      self._GetKeyFromRegistry()\n\n    if self._registry_key:\n      return self._registry_key.number_of_values\n\n    return 0", "response": "int number of values within the key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _GetKeyFromRegistry(self):\n    if not self._registry:\n      return\n\n    try:\n      self._registry_key = self._registry.GetKeyByPath(self._key_path)\n    except RuntimeError:\n      pass\n\n    if not self._registry_key:\n      return\n\n    for sub_registry_key in self._registry_key.GetSubkeys():\n      self.AddSubkey(sub_registry_key)\n\n    if self._key_path == 'HKEY_LOCAL_MACHINE\\\\System':\n      sub_registry_key = VirtualWinRegistryKey(\n          'CurrentControlSet', registry=self._registry)\n      self.AddSubkey(sub_registry_key)\n\n    self._registry = None", "response": "Determines the key from the Windows Registry."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _JoinKeyPath(self, path_segments):\n    # This is an optimized way to combine the path segments into a single path\n    # and combine multiple successive path separators to one.\n\n    # Split all the path segments based on the path (segment) separator.\n    path_segments = [\n        segment.split(definitions.KEY_PATH_SEPARATOR)\n        for segment in path_segments]\n\n    # Flatten the sublists into one list.\n    path_segments = [\n        element for sublist in path_segments for element in sublist]\n\n    # Remove empty path segments.\n    path_segments = filter(None, path_segments)\n\n    return definitions.KEY_PATH_SEPARATOR.join(path_segments)", "response": "Joins the path segments into a key path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef AddSubkey(self, registry_key):\n    name = registry_key.name.upper()\n    if name in self._subkeys:\n      raise KeyError(\n          'Subkey: {0:s} already exists.'.format(registry_key.name))\n\n    self._subkeys[name] = registry_key\n\n    key_path = self._JoinKeyPath([self._key_path, registry_key.name])\n    registry_key._key_path = key_path", "response": "Adds a subkey to the internal list of subkeys."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve a subkey by index.", "response": "def GetSubkeyByIndex(self, index):\n    \"\"\"Retrieves a subkey by index.\n\n    Args:\n      index (int): index of the subkey.\n\n    Returns:\n      WinRegistryKey: Windows Registry subkey or None if not found.\n\n    Raises:\n      IndexError: if the index is out of bounds.\n    \"\"\"\n    if not self._registry_key and self._registry:\n      self._GetKeyFromRegistry()\n\n    subkeys = list(self._subkeys.values())\n\n    if index < 0 or index >= len(subkeys):\n      raise IndexError('Index out of bounds.')\n\n    return subkeys[index]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve a subkey by name.", "response": "def GetSubkeyByName(self, name):\n    \"\"\"Retrieves a subkey by name.\n\n    Args:\n      name (str): name of the subkey.\n\n    Returns:\n      WinRegistryKey: Windows Registry subkey or None if not found.\n    \"\"\"\n    if not self._registry_key and self._registry:\n      self._GetKeyFromRegistry()\n\n    return self._subkeys.get(name.upper(), None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetSubkeyByPath(self, key_path):\n    if not self._registry_key and self._registry:\n      self._GetKeyFromRegistry()\n\n    subkey = self\n    for path_segment in key_paths.SplitKeyPath(key_path):\n      subkey = subkey.GetSubkeyByName(path_segment)\n      if not subkey:\n        break\n\n    return subkey", "response": "Retrieves a subkey by path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetSubkeys(self):\n    if not self._registry_key and self._registry:\n      self._GetKeyFromRegistry()\n\n    return iter(self._subkeys.values())", "response": "Retrieves all subkeys within the key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef GetValueByName(self, name):\n    if not self._registry_key and self._registry:\n      self._GetKeyFromRegistry()\n\n    if not self._registry_key:\n      return None\n\n    return self._registry_key.GetValueByName(name)", "response": "Retrieves a value by name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves all values within the key.", "response": "def GetValues(self):\n    \"\"\"Retrieves all values within the key.\n\n    Returns:\n      generator[WinRegistryValue]: Windows Registry value generator.\n    \"\"\"\n    if not self._registry_key and self._registry:\n      self._GetKeyFromRegistry()\n\n    if self._registry_key:\n      return self._registry_key.GetValues()\n\n    return iter([])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fail(self, exception):\n        fail = failure.create(exception, self._queue, self._payload,\n                              self._worker)\n        fail.save(self.resq)\n        return fail", "response": "This method creates a new failure object and saves it in the resource queue."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reserve(cls, queues, res, worker=None, timeout=10):\n        if isinstance(queues, string_types):\n            queues = [queues]\n        queue, payload = res.pop(queues, timeout=timeout)\n        if payload:\n            return cls(queue, payload, res, worker)", "response": "Reserve a job on one of the queues."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef my_import(name):\n    mod = __import__(name)\n    components = name.split('.')\n    for comp in components[1:]:\n        mod = getattr(mod, comp)\n    return mod", "response": "Helper function for walking for classes by name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef str_to_class(s):\n    lst = s.split(\".\")\n    klass = lst[-1]\n    mod_list = lst[:-1]\n    module = \".\".join(mod_list)\n    try:\n        mod = __import__(module)\n        if hasattr(mod, klass):\n            return getattr(mod, klass)\n        else:\n            return None\n    except ImportError:\n        return None", "response": "Alternate helper function to map string class names to module classes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef enqueue(self, klass, *args):\n        queue = getattr(klass,'queue', None)\n        if queue:\n            class_name = '%s.%s' % (klass.__module__, klass.__name__)\n            self.enqueue_from_string(class_name, queue, *args)\n        else:\n            logger.warning(\"unable to enqueue job with class %s\" % str(klass))", "response": "Enqueue a job into a specific queue."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef info(self):\n        pending = 0\n        for q in self.queues():\n             pending += self.size(q)\n        return {\n            'pending'   : pending,\n            'processed' : Stat('processed',self).get(),\n            'queues'    : len(self.queues()),\n            'workers'   : len(self.workers()),\n            #'working'   : len(self.working()),\n            'failed'    : Stat('failed',self).get(),\n            'servers'   : ['%s:%s' % (self.host, self.port)]\n        }", "response": "Returns a dictionary of the current status of the pending jobs processed workers no. of jobs failed jobs no. of servers no. of failed jobs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _shutdown_minions(self):\n        setproctitle('pyres_manager: Waiting on children to shutdown.')\n        for minion in self._workers.values():\n            minion.terminate()\n            minion.join()", "response": "Terminate all workers and join the pool."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_message(self):\n\n        body = dedent(\"\"\"\\\n        Received exception {exception} on {queue} from worker {worker}:\n\n        {traceback}\n\n        Payload:\n        {payload}\n\n        \"\"\").format(exception=self._exception,\n                   traceback=self._traceback,\n                   queue=self._queue,\n                   payload=self._payload,\n                   worker=self._worker)\n\n        return MIMEText(body)", "response": "Returns a MIMEText object that can be sent in this email. Should be from email. mime."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninvoking by ``run`` method. ``work`` listens on a list of queues and sleeps for ``interval`` time. ``interval`` -- Number of seconds the worker will wait until processing the next job. Default is \"5\". Whenever a worker finds a job on the queue it first calls ``reserve`` on that job to make sure another worker won't run it, then *forks* itself to work on that job.", "response": "def work(self, interval=5):\n        \"\"\"Invoked by ``run`` method. ``work`` listens on a list of queues and sleeps\n        for ``interval`` time.\n\n        ``interval`` -- Number of seconds the worker will wait until processing the next job. Default is \"5\".\n\n        Whenever a worker finds a job on the queue it first calls ``reserve`` on\n        that job to make sure another worker won't run it, then *forks* itself to\n        work on that job.\n\n        \"\"\"\n        self._setproctitle(\"Starting\")\n        logger.info(\"starting\")\n        self.startup()\n\n        while True:\n            if self._shutdown:\n                logger.info('shutdown scheduled')\n                break\n\n            self.register_worker()\n\n            job = self.reserve(interval)\n\n            if job:\n                self.fork_worker(job)\n            else:\n                if interval == 0:\n                    break\n                #procline @paused ? \"Paused\" : \"Waiting for #{@queues.join(',')}\"\n                self._setproctitle(\"Waiting\")\n                #time.sleep(interval)\n        self.unregister_worker()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fork_worker(self, job):\n        logger.debug('picked up job')\n        logger.debug('job details: %s' % job)\n        self.before_fork(job)\n        self.child = os.fork()\n        if self.child:\n            self._setproctitle(\"Forked %s at %s\" %\n                               (self.child,\n                                datetime.datetime.now()))\n            logger.info('Forked %s at %s' % (self.child,\n                                              datetime.datetime.now()))\n\n            try:\n                start = datetime.datetime.now()\n\n                # waits for the result or times out\n                while True:\n                    pid, status = os.waitpid(self.child, os.WNOHANG)\n                    if pid != 0:\n                        if os.WIFEXITED(status) and os.WEXITSTATUS(status) == 0:\n                            break\n                        if os.WIFSTOPPED(status):\n                            logger.warning(\"Process stopped by signal %d\" % os.WSTOPSIG(status))\n                        else:\n                            if os.WIFSIGNALED(status):\n                                raise CrashError(\"Unexpected exit by signal %d\" % os.WTERMSIG(status))\n                            raise CrashError(\"Unexpected exit status %d\" % os.WEXITSTATUS(status))\n\n                    time.sleep(0.5)\n\n                    now = datetime.datetime.now()\n                    if self.timeout and ((now - start).seconds > self.timeout):\n                        os.kill(self.child, signal.SIGKILL)\n                        os.waitpid(-1, os.WNOHANG)\n                        raise TimeoutError(\"Timed out after %d seconds\" % self.timeout)\n\n            except OSError as ose:\n                import errno\n\n                if ose.errno != errno.EINTR:\n                    raise ose\n            except JobError:\n                self._handle_job_exception(job)\n            finally:\n                # If the child process' job called os._exit manually we need to\n                # finish the clean up here.\n                if self.job():\n                    self.done_working(job)\n\n            logger.debug('done waiting')\n        else:\n            self._setproctitle(\"Processing %s since %s\" %\n                               (job,\n                                datetime.datetime.now()))\n            logger.info('Processing %s since %s' %\n                         (job, datetime.datetime.now()))\n            self.after_fork(job)\n\n            # re-seed the Python PRNG after forking, otherwise\n            # all job process will share the same sequence of\n            # random numbers\n            random.seed()\n\n            self.process(job)\n            os._exit(0)\n        self.child = None", "response": "This method is called by the worker thread to create the child process and process the job."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef worker_pids(cls):\n        cmd = \"ps -A -o pid,command | grep pyres_worker | grep -v grep\"\n        output = commands.getoutput(cmd)\n        if output:\n            return map(lambda l: l.strip().split(' ')[0], output.split(\"\\n\"))\n        else:\n            return []", "response": "Returns an array of all pids of the workers on\n        this machine. Used when pruning dead workers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving the failed Job into a failed Redis queue preserving all its original enqueud info.", "response": "def save(self, resq=None):\n        \"\"\"Saves the failed Job into a \"failed\" Redis queue preserving all its original enqueud info.\"\"\"\n        if not resq:\n            resq = ResQ()\n        data = {\n            'failed_at' : datetime.datetime.now().strftime('%Y/%m/%d %H:%M:%S'),\n            'payload'   : self._payload,\n            'exception' : self._exception.__class__.__name__,\n            'error'     : self._parse_message(self._exception),\n            'backtrace' : self._parse_traceback(self._traceback),\n            'queue'     : self._queue\n        }\n        if self._worker:\n            data['worker'] = self._worker\n        data = ResQ.encode(data)\n        resq.redis.rpush('resque:failed', data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts A to CSR or BSR matrix if necessary and return.", "response": "def make_csr(A):\n    \"\"\"\n    Convert A to CSR, if A is not a CSR or BSR matrix already.\n\n    Parameters\n    ----------\n    A : array, matrix, sparse matrix\n        (n x n) matrix to convert to CSR\n\n    Returns\n    -------\n    A : csr_matrix, bsr_matrix\n        If A is csr_matrix or bsr_matrix, then do nothing and return A.\n        Else, convert A to CSR if possible and return.\n\n    Examples\n    --------\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.blackbox import make_csr\n    >>> A = poisson((40,40),format='csc')\n    >>> Acsr = make_csr(A)\n    Implicit conversion of A to CSR in pyamg.blackbox.make_csr\n\n    \"\"\"\n    # Convert to CSR or BSR if necessary\n    if not (isspmatrix_csr(A) or isspmatrix_bsr(A)):\n        try:\n            A = csr_matrix(A)\n            print('Implicit conversion of A to CSR in pyamg.blackbox.make_csr')\n        except BaseException:\n            raise TypeError('Argument A must have type csr_matrix or\\\n                    bsr_matrix, or be convertible to csr_matrix')\n\n    if A.shape[0] != A.shape[1]:\n        raise TypeError('Argument A must be a square')\n\n    A = A.asfptype()\n\n    return A"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef solver_configuration(A, B=None, verb=True):\n    # Ensure acceptable format of A\n    A = make_csr(A)\n    config = {}\n\n    # Detect symmetry\n    if ishermitian(A, fast_check=True):\n        config['symmetry'] = 'hermitian'\n        if verb:\n            print(\"  Detected a Hermitian matrix\")\n    else:\n        config['symmetry'] = 'nonsymmetric'\n        if verb:\n            print(\"  Detected a non-Hermitian matrix\")\n\n    # Symmetry dependent parameters\n    if config['symmetry'] == 'hermitian':\n        config['smooth'] = ('energy', {'krylov': 'cg', 'maxiter': 3,\n                                       'degree': 2, 'weighting': 'local'})\n        config['presmoother'] = ('block_gauss_seidel',\n                                 {'sweep': 'symmetric', 'iterations': 1})\n        config['postsmoother'] = ('block_gauss_seidel',\n                                  {'sweep': 'symmetric', 'iterations': 1})\n    else:\n        config['smooth'] = ('energy', {'krylov': 'gmres', 'maxiter': 3,\n                                       'degree': 2, 'weighting': 'local'})\n        config['presmoother'] = ('gauss_seidel_nr',\n                                 {'sweep': 'symmetric', 'iterations': 2})\n        config['postsmoother'] = ('gauss_seidel_nr',\n                                  {'sweep': 'symmetric', 'iterations': 2})\n\n    # Determine near null-space modes B\n    if B is None:\n        # B is the constant for each variable in a node\n        if isspmatrix_bsr(A) and A.blocksize[0] > 1:\n            bsize = A.blocksize[0]\n            config['B'] = np.kron(np.ones((int(A.shape[0] / bsize), 1),\n                                          dtype=A.dtype), np.eye(bsize))\n        else:\n            config['B'] = np.ones((A.shape[0], 1), dtype=A.dtype)\n    elif (isinstance(B, type(np.zeros((1,)))) or\n            isinstance(B, type(sp.mat(np.zeros((1,)))))):\n        if len(B.shape) == 1:\n            B = B.reshape(-1, 1)\n        if (B.shape[0] != A.shape[0]) or (B.shape[1] == 0):\n            raise TypeError('Invalid dimensions of B, B.shape[0] must equal \\\n                             A.shape[0]')\n        else:\n            config['B'] = np.array(B, dtype=A.dtype)\n    else:\n        raise TypeError('Invalid B')\n\n    if config['symmetry'] == 'hermitian':\n        config['BH'] = None\n    else:\n        config['BH'] = config['B'].copy()\n\n    # Set non-symmetry related parameters\n    config['strength'] = ('evolution', {'k': 2, 'proj_type': 'l2',\n                                        'epsilon': 3.0})\n    config['max_levels'] = 15\n    config['max_coarse'] = 500\n    config['coarse_solver'] = 'pinv'\n    config['aggregate'] = 'standard'\n    config['keep'] = False\n\n    return config", "response": "Generate a dictionary of SA parameters for an arbitray matrix A."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef solver(A, config):\n    # Convert A to acceptable format\n    A = make_csr(A)\n\n    # Generate smoothed aggregation solver\n    try:\n        return \\\n            smoothed_aggregation_solver(A,\n                                        B=config['B'],\n                                        BH=config['BH'],\n                                        smooth=config['smooth'],\n                                        strength=config['strength'],\n                                        max_levels=config['max_levels'],\n                                        max_coarse=config['max_coarse'],\n                                        coarse_solver=config['coarse_solver'],\n                                        symmetry=config['symmetry'],\n                                        aggregate=config['aggregate'],\n                                        presmoother=config['presmoother'],\n                                        postsmoother=config['postsmoother'],\n                                        keep=config['keep'])\n    except BaseException:\n        raise TypeError('Failed generating smoothed_aggregation_solver')", "response": "Generate an SA solver given matrix A and a configuration dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef solve(A, b, x0=None, tol=1e-5, maxiter=400, return_solver=False,\n          existing_solver=None, verb=True, residuals=None):\n    \"\"\"Solve Ax=b.\n\n    Solve the arbitrary system Ax=b with the best out-of-the box choice for a\n    solver.  The matrix A can be non-Hermitian, indefinite, Hermitian\n    positive-definite, complex, etc...  Generic and robust settings for\n    smoothed_aggregation_solver(..) are used to invert A.\n\n\n    Parameters\n    ----------\n    A : array, matrix, csr_matrix, bsr_matrix\n        Matrix to invert, CSR or BSR format preferred for efficiency\n    b : array\n        Right hand side.\n    x0 : array\n        Initial guess (default random vector)\n    tol : float\n        Stopping criteria: relative residual r[k]/r[0] tolerance\n    maxiter : int\n        Stopping criteria: maximum number of allowable iterations\n    return_solver : bool\n        True: return the solver generated\n    existing_solver : smoothed_aggregation_solver\n        If instance of a multilevel solver, then existing_solver is used\n        to invert A, thus saving time on setup cost.\n    verb : bool\n        If True, print verbose output during runtime\n    residuals : list\n        List to contain residual norms at each iteration.\n        The preconditioned norm is used, namely\n        ||r||_M = (M r, r)^(1/2) = (r, r)^(1/2)\n\n    Returns\n    -------\n    x : array\n        Solution to Ax = b\n    ml : multilevel_solver\n        Optional return of the multilevel structure used for the solve\n\n    Notes\n    -----\n    If calling solve(...) multiple times for the same matrix, A, solver reuse\n    is easy and efficient.  Set \"return_solver=True\", and the return value will\n    be a tuple, (x,ml), where ml is the solver used to invert A, and x is the\n    solution to Ax=b.  Then, the next time solve(...) is called, set\n    \"existing_solver=ml\".\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from pyamg import solve\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.util.linalg import norm\n    >>> A = poisson((40,40),format='csr')\n    >>> b = np.array(np.arange(A.shape[0]), dtype=float)\n    >>> x = solve(A,b,verb=False)\n    >>> print \"%1.2e\"%(norm(b - A*x)/norm(b))\n    6.28e-06\n\n    \"\"\"\n    # Convert A to acceptable CSR/BSR format\n    A = make_csr(A)\n\n    # Generate solver if necessary\n    if existing_solver is None:\n\n        # Parameter dictionary for smoothed_aggregation_solver\n        config = solver_configuration(A, B=None, verb=verb)\n        # Generate solver\n        existing_solver = solver(A, config)\n\n    else:\n        if existing_solver.levels[0].A.shape[0] != A.shape[0]:\n            raise TypeError('Argument existing_solver must have level 0 matrix\\\n                             of same size as A')\n\n    # Krylov acceleration depends on symmetry of A\n    if existing_solver.levels[0].A.symmetry == 'hermitian':\n        accel = 'cg'\n    else:\n        accel = 'gmres'\n\n    # Initial guess\n    if x0 is None:\n        x0 = np.array(sp.rand(A.shape[0],), dtype=A.dtype)\n\n    # Callback function to print iteration number\n    if verb:\n        iteration = np.zeros((1,))\n        print(\"    maxiter = %d\" % maxiter)\n\n        def callback(x, iteration):\n            iteration[0] = iteration[0] + 1\n            print(\"    iteration %d\" % iteration[0])\n\n        def callback2(x):\n            return callback(x, iteration)\n    else:\n        callback2 = None\n\n    # Solve with accelerated Krylov method\n    x = existing_solver.solve(b, x0=x0, accel=accel, tol=tol, maxiter=maxiter,\n                              callback=callback2, residuals=residuals)\n\n    if verb:\n        r0 = b - A * x0\n        rk = b - A * x\n        M = existing_solver.aspreconditioner()\n        nr0 = np.sqrt(np.inner(np.conjugate(M * r0), r0))\n        nrk = np.sqrt(np.inner(np.conjugate(M * rk), rk))\n        print(\"  Residuals ||r_k||_M, ||r_0||_M = %1.2e, %1.2e\" % (nrk, nr0))\n        if np.abs(nr0) > 1e-15:\n            print(\"  Residual reduction ||r_k||_M/||r_0||_M = %1.2e\"\n                  % (nrk / nr0))\n\n    if return_solver:\n        return (x.reshape(b.shape), existing_solver)\n    else:\n        return x.reshape(b.shape)", "response": "Solve the arbitrary system Ax = b with the best out - of - box choice for the arbitrary system Ax = b."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the comments for a function in a CppHeaderParser.", "response": "def find_comments(fname, ch):\n    \"\"\"\n    Find the comments for a function.\n\n    fname: filename\n    ch: CppHeaderParser parse tree\n\n    The function must look like\n    /*\n     * comments\n     * comments\n     */\n     template<class I, ...>\n     void somefunc(...){\n\n     -or-\n\n    /*\n     * comments\n     * comments\n     */\n     void somefunc(...){\n\n     -or-\n\n    with // style comments\n\n    Then, take off the first three spaces\n    \"\"\"\n    with open(fname, 'r') as inf:\n        fdata = inf.readlines()\n\n    comments = {}\n    for f in ch.functions:\n        lineno = f['line_number'] - 1  # zero based indexing\n\n        # set starting position\n        lineptr = lineno - 1\n        if f['template']:\n            lineptr -= 1\n        start = lineptr\n\n        # find the top of the comment block\n        while fdata[lineptr].startswith('//') or\\\n            fdata[lineptr].startswith('/*') or\\\n                fdata[lineptr].startswith(' *'):\n            lineptr -= 1\n        lineptr += 1\n        comment = fdata[lineptr:(start + 1)]\n        comment = [c[3:].rstrip() for c in comment]\n        comments[f['name']] = '\\n'.join(comment).strip()\n\n    return comments"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds a function from a templated function.", "response": "def build_function(func):\n    \"\"\"\n    Build a function from a templated function.  The function must look like\n    template<class I, class T, ...>\n    void func(const p[], p_size, ...)\n\n    rules:\n        - a pointer or array p is followed by int p_size\n        - all arrays are templated\n        - non arrays are basic types: int, double, complex, etc\n        - all functions are straight up c++\n    \"\"\"\n\n    indent = '    '\n\n    # temlpate and function name\n\n    if func['template']:\n        fdef = func['template'] + '\\n'\n    else:\n        fdef = ''\n\n    newcall = func['returns'] + ' _' + func['name'] + '('\n    fdef += newcall + '\\n'\n\n    # function parameters\n\n    # for each parameter\n    # if it's an array\n    #   - replace with py::array_t\n    #   - skip the next _size argument\n    #   - save in a list of arrays\n    # else replicate\n\n    i = 0\n    arraylist = []\n    needsize = False\n    while i < len(func['parameters']):\n        p = func['parameters'][i]\n        i += 1\n\n        # check if pointer/array\n        if p['pointer'] or p['array']:\n            paramtype = p['raw_type']\n            const = ''\n            if p['constant']:\n                const = 'const '\n\n            param = 'py::array_t<{}> &'.format(paramtype) + ' ' + p['name']\n            arraylist.append((const, paramtype, p['name']))\n            needsize = True\n        elif '_size' not in p['name'] and needsize:\n            # not a size, but needed one\n            raise ValueError(\n                'Expecting a _size parameter for {}'.format(\n                    p['name']))\n        elif '_size' in p['name']:\n            # just size, skip it\n            needsize = False\n            continue\n        else:\n            # if not a pointer, just copy it\n            param = p['type'] + ' ' + p['name']\n\n        fdef += '{:>25},\\n'.format(param)    # set width to 25\n\n    fdef = fdef.strip()[:-1]  # trim comma and newline\n    fdef += '\\n' + ' ' * len(newcall) + ')'\n    fdef += '\\n{\\n'\n\n    # make a list of python objects\n    for a in arraylist:\n        if 'const' in a[0]:\n            unchecked = '.unchecked();\\n'\n        else:\n            unchecked = '.mutable_unchecked();\\n'\n\n        fdef += indent\n        fdef += \"auto py_\" + a[2] + ' = ' + a[2] + unchecked\n\n    # make a list of pointers to the arrays\n    for a in arraylist:\n        if 'const' in a[0]:\n            data = '.data();\\n'\n        else:\n            data = '.mutable_data();\\n'\n        fdef += indent\n        fdef += a[0] + a[1] + ' *_' + a[2] + ' = py_' + a[2] + data\n\n    # get the template signature\n    if len(arraylist) > 0:\n        fdef += '\\n'\n    if func['template']:\n        template = func['template']\n        template = template.replace('template', '').replace(\n            'class ', '')   # template <class T> ----> <T>\n    else:\n        template = ''\n    newcall = '    return ' + func['name'] + template + '('\n    fdef += newcall + '\\n'\n\n    # function parameters\n    for p in func['parameters']:\n        if '_size' in p['name']:\n            fdef = fdef.strip()\n            name, s = p['name'].split('_size')\n            if s == '':\n                s = '0'\n            fdef += \" {}.shape({})\".format(name, s)\n        else:\n            if p['pointer'] or p['array']:\n                name = '_' + p['name']\n            else:\n                name = p['name']\n            fdef += '{:>25}'.format(name)\n        fdef += ',\\n'\n    fdef = fdef.strip()[:-1]\n    fdef += '\\n' + ' ' * len(newcall) + ');\\n}'\n    return fdef"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a NC plugin from a C ++ header file and a parse tree.", "response": "def build_plugin(headerfile, ch, comments, inst, remaps):\n    \"\"\"\n    Take a header file (headerfile) and a parse tree (ch)\n    and build the pybind11 plugin\n\n    headerfile: somefile.h\n\n    ch: parse tree from CppHeaderParser\n\n    comments: a dictionary of comments\n\n    inst: files to instantiate\n\n    remaps: list of remaps\n    \"\"\"\n    headerfilename = os.path.splitext(headerfile)[0]\n\n    indent = '    '\n    plugin = ''\n\n    # plugin += '#define NC py::arg().noconvert()\\n'\n    # plugin += '#define YC py::arg()\\n'\n    plugin += 'PYBIND11_MODULE({}, m) {{\\n'.format(headerfilename)\n    plugin += indent + 'm.doc() = R\"pbdoc(\\n'\n    plugin += indent + 'Pybind11 bindings for {}\\n\\n'.format(headerfile)\n    plugin += indent + 'Methods\\n'\n    plugin += indent + '-------\\n'\n    for f in ch.functions:\n        for func in inst:\n            if f['name'] in func['functions']:\n                plugin += indent + f['name'] + '\\n'\n    plugin += indent + ')pbdoc\";\\n\\n'\n\n    plugin += indent + 'py::options options;\\n'\n    plugin += indent + 'options.disable_function_signatures();\\n\\n'\n\n    unbound = []\n    bound = []\n    for f in ch.functions:\n        # for each function:\n        #   - find the entry in the instantiation list\n        #   - note any array parameters to the function\n        #   - for each type, instantiate\n        found = False\n        for func in inst:\n            if f['name'] in func['functions']:\n                found = True\n                types = func['types']\n\n        if not found:\n            # print('Could not find {}'.format(f['name']))\n            unbound.append(f['name'])\n            continue\n        else:\n            bound.append(f['name'])\n\n        # find all parameter names and mark if array\n        argnames = []\n        for p in f['parameters']:\n\n            array = False\n            if p['pointer'] or p['array']:\n                array = True\n\n            # skip \"_size\" parameters\n            if '_size' in p['name']:\n                continue\n            else:\n                argnames.append((p['name'], array))\n\n        ntypes = len(types)\n        for i, t in enumerate(types):\n\n            # add the function call with each template\n            instname = f['name']\n\n            # check the remaps\n            for remap in remaps:\n                if f['name'] in remap:\n                    instname = remap[f['name']]\n\n            if t is not None:\n                # templated function\n                typestr = '<' + ', '.join(t) + '>'\n            else:\n                # not a templated function\n                typestr = ''\n\n            plugin += indent + \\\n                'm.def(\"{}\", &_{}{},\\n'.format(instname, f['name'], typestr)\n\n            # name the arguments\n            pyargnames = []\n            for p, array in argnames:\n                convert = ''\n                if array:\n                    convert = '.noconvert()'\n                pyargnames.append('py::arg(\"{}\"){}'.format(p, convert))\n\n            argstring = indent + ', '.join(pyargnames)\n            plugin += indent + argstring\n\n            # add the docstring to the last\n            if i == ntypes - 1:\n                plugin += ',\\nR\"pbdoc(\\n{})pbdoc\");\\n'.format(\n                    comments[f['name']])\n            else:\n                plugin += ');\\n'\n        plugin += '\\n'\n\n    plugin += '}\\n'\n    # plugin += '#undef NC\\n'\n    # plugin += '#undef YC\\n'\n    return plugin, bound, unbound"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fit_candidates(AggOp, B, tol=1e-10):\n    if not isspmatrix_csr(AggOp):\n        raise TypeError('expected csr_matrix for argument AggOp')\n\n    B = np.asarray(B)\n    if B.dtype not in ['float32', 'float64', 'complex64', 'complex128']:\n        B = np.asarray(B, dtype='float64')\n\n    if len(B.shape) != 2:\n        raise ValueError('expected 2d array for argument B')\n\n    if B.shape[0] % AggOp.shape[0] != 0:\n        raise ValueError('dimensions of AggOp %s and B %s are \\\n                          incompatible' % (AggOp.shape, B.shape))\n\n    N_fine, N_coarse = AggOp.shape\n\n    K1 = int(B.shape[0] / N_fine)  # dof per supernode (e.g. 3 for 3d vectors)\n    K2 = B.shape[1]                # candidates\n\n    # the first two dimensions of R and Qx are collapsed later\n    R = np.empty((N_coarse, K2, K2), dtype=B.dtype)    # coarse candidates\n    Qx = np.empty((AggOp.nnz, K1, K2), dtype=B.dtype)  # BSR data array\n\n    AggOp_csc = AggOp.tocsc()\n\n    fn = amg_core.fit_candidates\n    fn(N_fine, N_coarse, K1, K2,\n       AggOp_csc.indptr, AggOp_csc.indices, Qx.ravel(),\n       B.ravel(), R.ravel(), tol)\n\n    Q = bsr_matrix((Qx.swapaxes(1, 2).copy(), AggOp_csc.indices,\n                    AggOp_csc.indptr), shape=(K2*N_coarse, K1*N_fine))\n    Q = Q.T.tobsr()\n    R = R.reshape(-1, K2)\n\n    return Q, R", "response": "Fit near - nullspace candidates to form the tentative prolongator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconstruct base function for sprand sprandn.", "response": "def _rand_sparse(m, n, density, format='csr'):\n    \"\"\"Construct base function for sprand, sprandn.\"\"\"\n    nnz = max(min(int(m*n*density), m*n), 0)\n\n    row = np.random.randint(low=0, high=m-1, size=nnz)\n    col = np.random.randint(low=0, high=n-1, size=nnz)\n    data = np.ones(nnz, dtype=float)\n\n    # duplicate (i,j) entries will be summed together\n    return sp.sparse.csr_matrix((data, (row, col)), shape=(m, n))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sprand(m, n, density, format='csr'):\n    m, n = int(m), int(n)\n\n    # get sparsity pattern\n    A = _rand_sparse(m, n, density, format='csr')\n\n    # replace data with random values\n    A.data = sp.rand(A.nnz)\n\n    return A.asformat(format)", "response": "Return a random sparse matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef q12d(grid, spacing=None, E=1e5, nu=0.3, dirichlet_boundary=True,\n         format=None):\n    \"\"\"Q1 elements in 2 dimensions.\n\n    See Also\n    --------\n    linear_elasticity\n\n    \"\"\"\n    X, Y = tuple(grid)\n\n    if X < 1 or Y < 1:\n        raise ValueError('invalid grid shape')\n\n    if dirichlet_boundary:\n        X += 1\n        Y += 1\n\n    pts = np.mgrid[0:X+1, 0:Y+1]\n    pts = np.hstack((pts[0].T.reshape(-1, 1) - X / 2.0,\n                     pts[1].T.reshape(-1, 1) - Y / 2.0))\n\n    if spacing is None:\n        DX, DY = 1, 1\n    else:\n        DX, DY = tuple(spacing)\n        pts *= [DX, DY]\n\n    # compute local stiffness matrix\n    lame = E * nu / ((1 + nu) * (1 - 2*nu))  # Lame's first parameter\n    mu = E / (2 + 2*nu)                   # shear modulus\n\n    vertices = np.array([[0, 0], [DX, 0], [DX, DY], [0, DY]])\n    K = q12d_local(vertices, lame, mu)\n\n    nodes = np.arange((X+1)*(Y+1)).reshape(X+1, Y+1)\n    LL = nodes[:-1, :-1]\n    Id = (2*LL).repeat(K.size).reshape(-1, 8, 8)\n    J = Id.copy()\n    Id += np.tile([0, 1, 2, 3, 2*X + 4, 2*X + 5, 2*X + 2, 2*X + 3], (8, 1))\n    J += np.tile([0, 1, 2, 3, 2*X + 4, 2*X + 5, 2*X + 2, 2*X + 3], (8, 1)).T\n    V = np.tile(K, (X*Y, 1))\n\n    Id = np.ravel(Id)\n    J = np.ravel(J)\n    V = np.ravel(V)\n\n    # sum duplicates\n    A = coo_matrix((V, (Id, J)), shape=(pts.size, pts.size)).tocsr()\n    A = A.tobsr(blocksize=(2, 2))\n\n    del Id, J, V, LL, nodes\n\n    B = np.zeros((2 * (X+1)*(Y+1), 3))\n    B[0::2, 0] = 1\n    B[1::2, 1] = 1\n    B[0::2, 2] = -pts[:, 1]\n    B[1::2, 2] = pts[:, 0]\n\n    if dirichlet_boundary:\n        mask = np.zeros((X+1, Y+1), dtype='bool')\n        mask[1:-1, 1:-1] = True\n        mask = np.ravel(mask)\n        data = np.zeros(((X-1)*(Y-1), 2, 2))\n        data[:, 0, 0] = 1\n        data[:, 1, 1] = 1\n        indices = np.arange((X-1)*(Y-1))\n        indptr = np.concatenate((np.array([0]), np.cumsum(mask)))\n        P = bsr_matrix((data, indices, indptr),\n                       shape=(2*(X+1)*(Y+1), 2*(X-1)*(Y-1)))\n        Pt = P.T\n        A = P.T * A * P\n\n        B = Pt * B\n\n    return A.asformat(format), B", "response": "Generate a Q1 element - wise version of the grid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef linear_elasticity_p1(vertices, elements, E=1e5, nu=0.3, format=None):\n    # compute local stiffness matrix\n    lame = E * nu / ((1 + nu) * (1 - 2*nu))  # Lame's first parameter\n    mu = E / (2 + 2*nu)                   # shear modulus\n\n    vertices = np.asarray(vertices)\n    elements = np.asarray(elements)\n\n    D = vertices.shape[1]    # spatial dimension\n    DoF = D*vertices.shape[0]  # number of degrees of freedom\n    NE = elements.shape[0]    # number of elements\n\n    if elements.shape[1] != D + 1:\n        raise ValueError('dimension mismatch')\n\n    if D == 2:\n        local_K = p12d_local\n    elif D == 3:\n        local_K = p13d_local\n    else:\n        raise NotImplementedError('only dimension 2 and 3 are supported')\n\n    row = elements.repeat(D).reshape(-1, D)\n    row *= D\n    row += np.arange(D)\n    row = row.reshape(-1, D*(D+1)).repeat(D*(D+1), axis=0)\n    row = row.reshape(-1, D*(D+1), D*(D+1))\n    col = row.swapaxes(1, 2)\n\n    data = np.empty((NE, D*(D+1), D*(D+1)), dtype=float)\n\n    for i in range(NE):\n        element_indices = elements[i, :]\n        element_vertices = vertices[element_indices, :]\n\n        data[i] = local_K(element_vertices, lame, mu)\n\n    row = row.ravel()\n    col = col.ravel()\n    data = data.ravel()\n\n    # sum duplicates\n    A = coo_matrix((data, (row, col)), shape=(DoF, DoF)).tocsr()\n    A = A.tobsr(blocksize=(D, D))\n\n    # compute rigid body modes\n    if D == 2:\n        B = np.zeros((DoF, 3))\n        B[0::2, 0] = 1              # vector field in x direction\n        B[1::2, 1] = 1              # vector field in y direction\n\n        B[0::2, 2] = -vertices[:, 1]  # rotation vector field (-y, x)\n        B[1::2, 2] = vertices[:, 0]\n    else:\n        B = np.zeros((DoF, 6))\n        B[0::3, 0] = 1              # vector field in x direction\n        B[1::3, 1] = 1              # vector field in y direction\n        B[2::3, 2] = 1              # vector field in z direction\n\n        B[0::3, 3] = -vertices[:, 1]  # rotation vector field (-y, x, 0)\n        B[1::3, 3] = vertices[:, 0]\n        B[0::3, 4] = -vertices[:, 2]  # rotation vector field (-z, 0, x)\n        B[2::3, 4] = vertices[:, 0]\n        B[1::3, 5] = -vertices[:, 2]  # rotation vector field (0,-z, y)\n        B[2::3, 5] = vertices[:, 1]\n\n    return A.asformat(format), B", "response": "Linear elasticity of a set of vertices and elements."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef p12d_local(vertices, lame, mu):\n    assert(vertices.shape == (3, 2))\n\n    A = np.vstack((np.ones((1, 3)), vertices.T))\n    PhiGrad = inv(A)[:, 1:]  # gradients of basis functions\n    R = np.zeros((3, 6))\n    R[[[0], [2]], [0, 2, 4]] = PhiGrad.T\n    R[[[2], [1]], [1, 3, 5]] = PhiGrad.T\n    C = mu*np.array([[2, 0, 0], [0, 2, 0], [0, 0, 1]]) +\\\n        lame*np.array([[1, 1, 0], [1, 1, 0], [0, 0, 0]])\n    K = det(A)/2.0*np.dot(np.dot(R.T, C), R)\n    return K", "response": "Local stiffness matrix for P1 elements in 2d."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting a. vtu file in xml format.", "response": "def write_vtu(Verts, Cells, pdata=None, pvdata=None, cdata=None, cvdata=None,\n              fname='output.vtk'):\n    \"\"\"Write a .vtu file in xml format.\n\n    Parameters\n    ----------\n    fname : {string}\n        file to be written, e.g. 'mymesh.vtu'\n    Verts : {array}\n        Ndof x 3 (if 2, then expanded by 0)\n        list of (x,y,z) point coordinates\n    Cells : {dictionary}\n        Dictionary of with the keys\n    pdata : {array}\n        Ndof x Nfields array of scalar values for the vertices\n    pvdata : {array}\n        Nfields*3 x Ndof array of vector values for the vertices\n    cdata : {dictionary}\n        scalar valued cell data\n    cvdata : {dictionary}\n        vector valued cell data\n\n    Returns\n    -------\n     writes a .vtu file for use in Paraview\n\n    Notes\n    -----\n    - Poly data not supported\n    - Non-Poly data is stored in Numpy array: Ncell x vtk_cell_info\n    - Each I1 must be >=3\n    - pdata = Ndof x Nfields\n    - pvdata = 3*Ndof x Nfields\n    - cdata,cvdata = list of dictionaries in the form of Cells\n\n\n    =====  =================== ============= ===\n    keys   type                n points      dim\n    =====  =================== ============= ===\n       1   VTK_VERTEX:         1 point        2d\n       2   VTK_POLY_VERTEX:    n points       2d\n       3   VTK_LINE:           2 points       2d\n       4   VTK_POLY_LINE:      n+1 points     2d\n       5   VTK_TRIANGLE:       3 points       2d\n       6   VTK_TRIANGLE_STRIP: n+2 points     2d\n       7   VTK_POLYGON:        n points       2d\n       8   VTK_PIXEL:          4 points       2d\n       9   VTK_QUAD:           4 points       2d\n       10  VTK_TETRA:          4 points       3d\n       11  VTK_VOXEL:          8 points       3d\n       12  VTK_HEXAHEDRON:     8 points       3d\n       13  VTK_WEDGE:          6 points       3d\n       14  VTK_PYRAMID:        5 points       3d\n    =====  =================== ============= ===\n\n    Examples\n    --------\n    >>> from pyamg.vis import write_vtu\n    >>> import numpy as np\n    >>> Verts = np.array([[0.0,0.0],\n    ...                   [1.0,0.0],\n    ...                   [2.0,0.0],\n    ...                   [0.0,1.0],\n    ...                   [1.0,1.0],\n    ...                   [2.0,1.0],\n    ...                   [0.0,2.0],\n    ...                   [1.0,2.0],\n    ...                   [2.0,2.0],\n    ...                   [0.0,3.0],\n    ...                   [1.0,3.0],\n    ...                   [2.0,3.0]])\n    >>> E2V = np.array([[0,4,3],\n    ...                 [0,1,4],\n    ...                 [1,5,4],\n    ...                 [1,2,5],\n    ...                 [3,7,6],\n    ...                 [3,4,7],\n    ...                 [4,8,7],\n    ...                 [4,5,8],\n    ...                 [6,10,9],\n    ...                 [6,7,10],\n    ...                 [7,11,10],\n    ...                 [7,8,11]])\n    >>> E2edge = np.array([[0,1]])\n    >>> E2point = np.array([2,3,4,5])\n    >>> Cells = {5:E2V,3:E2edge,1:E2point}\n    >>> pdata=np.ones((12,2))\n    >>> pvdata=np.ones((12*3,2))\n    >>> cdata={5:np.ones((12,2)),3:np.ones((1,2)),1:np.ones((4,2))}\n    >>> cvdata={5:np.ones((3*12,2)),3:np.ones((3*1,2)),\n                1:np.ones((3*4,2))}\n    >>> write_vtu(Verts=Verts, Cells=Cells, fname='test.vtu')\n\n    See Also\n    --------\n    write_mesh\n\n    \"\"\"\n    # number of indices per cell for each cell type\n    vtk_cell_info = [-1, 1, None, 2, None, 3, None, None, 4, 4, 4, 8, 8, 6, 5]\n\n    # check fname\n    if isinstance(fname, str):\n        try:\n            fname = open(fname, 'w')\n        except IOError as e:\n            print(\".vtu error (%s): %s\" % (e.errno, e.strerror))\n    else:\n        raise ValueError('fname is assumed to be a string')\n\n    # check Verts\n    # get dimension and verify that it's 3d data\n    Ndof, dim = Verts.shape\n    if dim == 2:\n        # always use 3d coordinates (x,y) -> (x,y,0)\n        Verts = np.hstack((Verts, np.zeros((Ndof, 1))))\n\n    # check Cells\n    # keys must ve valid (integer and not \"None\" in vtk_cell_info)\n    # Cell data can't be empty for a non empty key\n    for key in Cells:\n        if ((not isinstance(key, int)) or (key not in list(range(1, 15)))):\n            raise ValueError('cell array must have positive integer keys\\\n                              in [1,14]')\n        if (vtk_cell_info[key] is None) and (Cells[key] is not None):\n            # Poly data\n            raise NotImplementedError('Poly Data not implemented yet')\n        if Cells[key] is None:\n            raise ValueError('cell array cannot be empty for\\\n                              key %d' % (key))\n        if np.ndim(Cells[key]) != 2:\n            Cells[key] = Cells[key].reshape((Cells[key].size, 1))\n        if vtk_cell_info[key] != Cells[key].shape[1]:\n            raise ValueError('cell array has %d columns, expected %d' %\n                             (Cells[key].shape[1], vtk_cell_info[key]))\n\n    # check pdata\n    # must be Ndof x n_pdata\n    n_pdata = 0\n    if pdata is not None:\n        if np.ndim(pdata) > 1:\n            n_pdata = pdata.shape[1]\n        else:\n            n_pdata = 1\n            pdata = pdata.reshape((pdata.size, 1))\n        if pdata.shape[0] != Ndof:\n            raise ValueError('pdata array should be length %d (it is %d)' %\n                             (Ndof, pdata.shape[0]))\n\n    # check pvdata\n    # must be 3*Ndof x n_pvdata\n    n_pvdata = 0\n    if pvdata is not None:\n        if np.ndim(pvdata) > 1:\n            n_pvdata = pvdata.shape[1]\n        else:\n            n_pvdata = 1\n            pvdata = pvdata.reshape((pvdata.size, 1))\n        if pvdata.shape[0] != 3*Ndof:\n            raise ValueError('pvdata array should be of size %d (or multiples)\\\n                              (it is now %d)' % (Ndof*3, pvdata.shape[0]))\n\n    # check cdata\n    # must be NCells x n_cdata for each key\n    n_cdata = 0\n    if cdata is not None:\n        for key in Cells:   # all valid now\n            if np.ndim(cdata[key]) > 1:\n                if n_cdata == 0:\n                    n_cdata = cdata[key].shape[1]\n                elif n_cdata != cdata[key].shape[1]:\n                    raise ValueError('cdata dimension problem')\n            else:\n                n_cdata = 1\n                cdata[key] = cdata[key].reshape((cdata[key].size, 1))\n            if cdata[key].shape[0] != Cells[key].shape[0]:\n                raise ValueError('size mismatch with cdata %d and Cells %d' %\n                                 (cdata[key].shape[0], Cells[key].shape[0]))\n            if cdata[key] is None:\n                raise ValueError('cdata array cannot be empty for key %d' %\n                                 (key))\n\n    # check cvdata\n    # must be NCells*3 x n_cdata for each key\n    n_cvdata = 0\n    if cvdata is not None:\n        for key in Cells:   # all valid now\n            if np.ndim(cvdata[key]) > 1:\n                if n_cvdata == 0:\n                    n_cvdata = cvdata[key].shape[1]\n                elif n_cvdata != cvdata[key].shape[1]:\n                    raise ValueError('cvdata dimension problem')\n            else:\n                n_cvdata = 1\n                cvdata[key] = cvdata[key].reshape((cvdata[key].size, 1))\n            if cvdata[key].shape[0] != 3*Cells[key].shape[0]:\n                raise ValueError('size mismatch with cvdata and Cells')\n            if cvdata[key] is None:\n                raise ValueError('cvdata array cannot be empty for key %d' %\n                                 (key))\n\n    Ncells = 0\n    cell_ind = []\n    cell_offset = []  # np.zeros((Ncells,1),dtype=uint8) # zero indexed\n    cell_type = []    # np.zeros((Ncells,1),dtype=uint8)\n\n    cdata_all = None\n    cvdata_all = None\n    for key in Cells:\n            # non-Poly data\n        sz = Cells[key].shape[0]\n        offset = Cells[key].shape[1]\n\n        Ncells += sz\n        uu = np.ones((sz,), dtype='uint8')\n        cell_ind = np.hstack((cell_ind, Cells[key].ravel()))\n        cell_offset = np.hstack((cell_offset, offset*uu))\n        cell_type = np.hstack((cell_type, key*uu))\n\n        if cdata is not None:\n            if cdata_all is None:\n                cdata_all = cdata[key]\n            else:\n                cdata_all = np.vstack((cdata_all, cdata[key]))\n\n        if cvdata is not None:\n            if cvdata_all is None:\n                cvdata_all = cvdata[key]\n            else:\n                cvdata_all = np.vstack((cvdata_all, cvdata[key]))\n\n    # doc element\n    doc = xml.dom.minidom.Document()\n\n    # vtk element\n    root = doc.createElementNS('VTK', 'VTKFile')\n    d = {'type': 'UnstructuredGrid', 'version': '0.1',\n         'byte_order': 'LittleEndian'}\n    set_attributes(d, root)\n\n    # unstructured element\n    grid = doc.createElementNS('VTK', 'UnstructuredGrid')\n\n    # piece element\n    piece = doc.createElementNS('VTK', 'Piece')\n    d = {'NumberOfPoints': str(Ndof), 'NumberOfCells': str(Ncells)}\n    set_attributes(d, piece)\n\n    # POINTS\n    # points element\n    points = doc.createElementNS('VTK', 'Points')\n    # data element\n    points_data = doc.createElementNS('VTK', 'DataArray')\n    d = {'type': 'Float32', 'Name': 'vertices', 'NumberOfComponents': '3',\n         'format': 'ascii'}\n    set_attributes(d, points_data)\n    # string for data element\n    points_data_str = doc.createTextNode(a2s(Verts))\n\n    # CELLS\n    # points element\n    cells = doc.createElementNS('VTK', 'Cells')\n    # data element\n    cells_data = doc.createElementNS('VTK', 'DataArray')\n    d = {'type': 'Int32', 'Name': 'connectivity', 'format': 'ascii'}\n    set_attributes(d, cells_data)\n    # string for data element\n    cells_data_str = doc.createTextNode(a2s(cell_ind))\n    # offset data element\n    cells_offset_data = doc.createElementNS('VTK', 'DataArray')\n    d = {'type': 'Int32', 'Name': 'offsets', 'format': 'ascii'}\n    set_attributes(d, cells_offset_data)\n    # string for data element\n    cells_offset_data_str = doc.createTextNode(a2s(cell_offset.cumsum()))\n    # offset data element\n    cells_type_data = doc.createElementNS('VTK', 'DataArray')\n    d = {'type': 'UInt8', 'Name': 'types', 'format': 'ascii'}\n    set_attributes(d, cells_type_data)\n    # string for data element\n    cells_type_data_str = doc.createTextNode(a2s(cell_type))\n\n    # POINT DATA\n    pointdata = doc.createElementNS('VTK', 'PointData')\n    # pdata\n    pdata_obj = []\n    pdata_str = []\n    for i in range(0, n_pdata):\n        pdata_obj.append(doc.createElementNS('VTK', 'DataArray'))\n        d = {'type': 'Float32', 'Name': 'pdata %d' % (i),\n             'NumberOfComponents': '1', 'format': 'ascii'}\n        set_attributes(d, pdata_obj[i])\n        pdata_str.append(doc.createTextNode(a2s(pdata[:, i])))\n    # pvdata\n    pvdata_obj = []\n    pvdata_str = []\n    for i in range(0, n_pvdata):\n        pvdata_obj.append(doc.createElementNS('VTK', 'DataArray'))\n        d = {'type': 'Float32', 'Name': 'pvdata %d' % (i),\n             'NumberOfComponents': '3', 'format': 'ascii'}\n        set_attributes(d, pvdata_obj[i])\n        pvdata_str.append(doc.createTextNode(a2s(pvdata[:, i])))\n\n    # CELL DATA\n    celldata = doc.createElementNS('VTK', 'CellData')\n    # cdata\n    cdata_obj = []\n    cdata_str = []\n    for i in range(0, n_cdata):\n        cdata_obj.append(doc.createElementNS('VTK', 'DataArray'))\n        d = {'type': 'Float32', 'Name': 'cdata %d' % (i),\n             'NumberOfComponents': '1', 'format': 'ascii'}\n        set_attributes(d, cdata_obj[i])\n        cdata_str.append(doc.createTextNode(a2s(cdata_all[:, i])))\n    # cvdata\n    cvdata_obj = []\n    cvdata_str = []\n    for i in range(0, n_cvdata):\n        cvdata_obj.append(doc.createElementNS('VTK', 'DataArray'))\n        d = {'type': 'Float32', 'Name': 'cvdata %d' % (i),\n             'NumberOfComponents': '3', 'format': 'ascii'}\n        set_attributes(d, cvdata_obj[i])\n        cvdata_str.append(doc.createTextNode(a2s(cvdata_all[:, i])))\n\n    doc.appendChild(root)\n    root.appendChild(grid)\n    grid.appendChild(piece)\n\n    piece.appendChild(points)\n    points.appendChild(points_data)\n    points_data.appendChild(points_data_str)\n\n    piece.appendChild(cells)\n    cells.appendChild(cells_data)\n    cells.appendChild(cells_offset_data)\n    cells.appendChild(cells_type_data)\n    cells_data.appendChild(cells_data_str)\n    cells_offset_data.appendChild(cells_offset_data_str)\n    cells_type_data.appendChild(cells_type_data_str)\n\n    piece.appendChild(pointdata)\n    for i in range(0, n_pdata):\n        pointdata.appendChild(pdata_obj[i])\n        pdata_obj[i].appendChild(pdata_str[i])\n    for i in range(0, n_pvdata):\n        pointdata.appendChild(pvdata_obj[i])\n        pvdata_obj[i].appendChild(pvdata_str[i])\n\n    piece.appendChild(celldata)\n    for i in range(0, n_cdata):\n        celldata.appendChild(cdata_obj[i])\n        cdata_obj[i].appendChild(cdata_str[i])\n    for i in range(0, n_cvdata):\n        celldata.appendChild(cvdata_obj[i])\n        cvdata_obj[i].appendChild(cvdata_str[i])\n\n    doc.writexml(fname, newl='\\n')\n    fname.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting a basic mesh file for the given set of vertices.", "response": "def write_basic_mesh(Verts, E2V=None, mesh_type='tri',\n                     pdata=None, pvdata=None,\n                     cdata=None, cvdata=None, fname='output.vtk'):\n    \"\"\"Write mesh file for basic types of elements.\n\n    Parameters\n    ----------\n    fname : {string}\n        file to be written, e.g. 'mymesh.vtu'\n    Verts : {array}\n        coordinate array (N x D)\n    E2V : {array}\n        element index array (Nel x Nelnodes)\n    mesh_type : {string}\n        type of elements: tri, quad, tet, hex (all 3d)\n    pdata : {array}\n        scalar data on vertices (N x Nfields)\n    pvdata : {array}\n        vector data on vertices (3*Nfields x N)\n    cdata : {array}\n        scalar data on cells (Nfields x Nel)\n    cvdata : {array}\n        vector data on cells (3*Nfields x Nel)\n\n    Returns\n    -------\n    writes a .vtu file for use in Paraview\n\n    Notes\n    -----\n    The difference between write_basic_mesh and write_vtu is that write_vtu is\n    more general and requires dictionaries of cell information.\n    write_basic_mesh calls write_vtu\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from pyamg.vis import write_basic_mesh\n    >>> Verts = np.array([[0.0,0.0],\n    ...                   [1.0,0.0],\n    ...                   [2.0,0.0],\n    ...                   [0.0,1.0],\n    ...                   [1.0,1.0],\n    ...                   [2.0,1.0],\n    ...                   [0.0,2.0],\n    ...                   [1.0,2.0],\n    ...                   [2.0,2.0],\n    ...                   [0.0,3.0],\n    ...                   [1.0,3.0],\n    ...                   [2.0,3.0]])\n    >>> E2V = np.array([[0,4,3],\n    ...                 [0,1,4],\n    ...                 [1,5,4],\n    ...                 [1,2,5],\n    ...                 [3,7,6],\n    ...                 [3,4,7],\n    ...                 [4,8,7],\n    ...                 [4,5,8],\n    ...                 [6,10,9],\n    ...                 [6,7,10],\n    ...                 [7,11,10],\n    ...                 [7,8,11]])\n    >>> pdata=np.ones((12,2))\n    >>> pvdata=np.ones((12*3,2))\n    >>> cdata=np.ones((12,2))\n    >>> cvdata=np.ones((3*12,2))\n    >>> write_basic_mesh(Verts, E2V=E2V, mesh_type='tri',pdata=pdata,\n                         pvdata=pvdata, cdata=cdata, cvdata=cvdata,\n                         fname='test.vtu')\n\n    See Also\n    --------\n    write_vtu\n\n    \"\"\"\n    if E2V is None:\n        mesh_type = 'vertex'\n\n    map_type_to_key = {'vertex': 1, 'tri': 5, 'quad': 9, 'tet': 10, 'hex': 12}\n\n    if mesh_type not in map_type_to_key:\n        raise ValueError('unknown mesh_type=%s' % mesh_type)\n\n    key = map_type_to_key[mesh_type]\n\n    if mesh_type == 'vertex':\n        uidx = np.arange(0, Verts.shape[0]).reshape((Verts.shape[0], 1))\n        E2V = {key: uidx}\n    else:\n        E2V = {key: E2V}\n\n    if cdata is not None:\n        cdata = {key: cdata}\n\n    if cvdata is not None:\n        cvdata = {key: cvdata}\n\n    write_vtu(Verts=Verts, Cells=E2V, pdata=pdata, pvdata=pvdata,\n              cdata=cdata, cvdata=cvdata, fname=fname)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_attributes(d, elm):\n    for key in d:\n        elm.setAttribute(key, d[key])", "response": "Set attributes from dictionary of values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cgnr(A, b, x0=None, tol=1e-5, maxiter=None, xtype=None, M=None,\n         callback=None, residuals=None):\n    \"\"\"Conjugate Gradient, Normal Residual algorithm.\n\n    Applies CG to the normal equations, A.H A x = b. Left preconditioning\n    is supported.  Note that unless A is well-conditioned, the use of\n    CGNR is inadvisable\n\n    Parameters\n    ----------\n    A : array, matrix, sparse matrix, LinearOperator\n        n x n, linear system to solve\n    b : array, matrix\n        right hand side, shape is (n,) or (n,1)\n    x0 : array, matrix\n        initial guess, default is a vector of zeros\n    tol : float\n        relative convergence tolerance, i.e. tol is scaled by ||r_0||_2\n    maxiter : int\n        maximum number of allowed iterations\n    xtype : type\n        dtype for the solution, default is automatic type detection\n    M : array, matrix, sparse matrix, LinearOperator\n        n x n, inverted preconditioner, i.e. solve M A.H A x = b.\n    callback : function\n        User-supplied function is called after each iteration as\n        callback(xk), where xk is the current solution vector\n    residuals : list\n        residuals has the residual norm history,\n        including the initial residual, appended to it\n\n    Returns\n    -------\n    (xNew, info)\n    xNew : an updated guess to the solution of Ax = b\n    info : halting status of cgnr\n\n            ==  =======================================\n            0   successful exit\n            >0  convergence to tolerance not achieved,\n                return iteration count instead.\n            <0  numerical breakdown, or illegal input\n            ==  =======================================\n\n\n    Notes\n    -----\n    The LinearOperator class is in scipy.sparse.linalg.interface.\n    Use this class if you prefer to define A or M as a mat-vec routine\n    as opposed to explicitly constructing the matrix.  A.psolve(..) is\n    still supported as a legacy.\n\n    Examples\n    --------\n    >>> from pyamg.krylov.cgnr import cgnr\n    >>> from pyamg.util.linalg import norm\n    >>> import numpy as np\n    >>> from pyamg.gallery import poisson\n    >>> A = poisson((10,10))\n    >>> b = np.ones((A.shape[0],))\n    >>> (x,flag) = cgnr(A,b, maxiter=2, tol=1e-8)\n    >>> print norm(b - A*x)\n    9.3910201849\n\n    References\n    ----------\n    .. [1] Yousef Saad, \"Iterative Methods for Sparse Linear Systems,\n       Second Edition\", SIAM, pp. 276-7, 2003\n       http://www-users.cs.umn.edu/~saad/books.html\n\n    \"\"\"\n    # Store the conjugate transpose explicitly as it will be used much later on\n    if isspmatrix(A):\n        AH = A.H\n    else:\n        # TODO avoid doing this since A may be a different sparse type\n        AH = aslinearoperator(np.asmatrix(A).H)\n\n    # Convert inputs to linear system, with error checking\n    A, M, x, b, postprocess = make_system(A, M, x0, b)\n    dimen = A.shape[0]\n\n    # Ensure that warnings are always reissued from this function\n    import warnings\n    warnings.filterwarnings('always', module='pyamg\\.krylov\\._cgnr')\n\n    # Choose type\n    if not hasattr(A, 'dtype'):\n        Atype = upcast(x.dtype, b.dtype)\n    else:\n        Atype = A.dtype\n    if not hasattr(M, 'dtype'):\n        Mtype = upcast(x.dtype, b.dtype)\n    else:\n        Mtype = M.dtype\n    xtype = upcast(Atype, x.dtype, b.dtype, Mtype)\n\n    # Should norm(r) be kept\n    if residuals == []:\n        keep_r = True\n    else:\n        keep_r = False\n\n    # How often should r be recomputed\n    recompute_r = 8\n\n    # Check iteration numbers. CGNR suffers from loss of orthogonality quite\n    # easily, so we arbitrarily let the method go up to 130% over the\n    # theoretically necessary limit of maxiter=dimen\n    if maxiter is None:\n        maxiter = int(np.ceil(1.3*dimen)) + 2\n    elif maxiter < 1:\n        raise ValueError('Number of iterations must be positive')\n    elif maxiter > (1.3*dimen):\n        warn('maximum allowed inner iterations (maxiter) are the 130% times \\\n              the number of dofs')\n        maxiter = int(np.ceil(1.3*dimen)) + 2\n\n    # Prep for method\n    r = b - A*x\n    rhat = AH*r\n    normr = norm(r)\n    if keep_r:\n        residuals.append(normr)\n\n    # Check initial guess ( scaling by b, if b != 0,\n    #   must account for case when norm(b) is very small)\n    normb = norm(b)\n    if normb == 0.0:\n        normb = 1.0\n    if normr < tol*normb:\n        if callback is not None:\n            callback(x)\n        return (postprocess(x), 0)\n\n    # Scale tol by ||r_0||_2\n    if normr != 0.0:\n        tol = tol*normr\n\n    # Begin CGNR\n\n    # Apply preconditioner and calculate initial search direction\n    z = M*rhat\n    p = z.copy()\n    old_zr = np.inner(z.conjugate(), rhat)\n\n    for iter in range(maxiter):\n\n        # w_j = A p_j\n        w = A*p\n\n        # alpha = (z_j, rhat_j) / (w_j, w_j)\n        alpha = old_zr / np.inner(w.conjugate(), w)\n\n        # x_{j+1} = x_j + alpha*p_j\n        x += alpha*p\n\n        # r_{j+1} = r_j - alpha*w_j\n        if np.mod(iter, recompute_r) and iter > 0:\n            r -= alpha*w\n        else:\n            r = b - A*x\n\n        # rhat_{j+1} = A.H*r_{j+1}\n        rhat = AH*r\n\n        # z_{j+1} = M*r_{j+1}\n        z = M*rhat\n\n        # beta = (z_{j+1}, rhat_{j+1}) / (z_j, rhat_j)\n        new_zr = np.inner(z.conjugate(), rhat)\n        beta = new_zr / old_zr\n        old_zr = new_zr\n\n        # p_{j+1} = A.H*z_{j+1} + beta*p_j\n        p *= beta\n        p += z\n\n        # Allow user access to residual\n        if callback is not None:\n            callback(x)\n\n        # test for convergence\n        normr = norm(r)\n        if keep_r:\n            residuals.append(normr)\n        if normr < tol:\n            return (postprocess(x), 0)\n\n    # end loop\n\n    return (postprocess(x), iter+1)", "response": "Conjugate Gradient Normal Residual algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\neliminating local canidates locally.", "response": "def eliminate_local_candidates(x, AggOp, A, T, Ca=1.0, **kwargs):\n    \"\"\"Eliminate canidates locally.\n\n    Helper function that determines where to eliminate candidates locally\n    on a per aggregate basis.\n\n    Parameters\n    ---------\n    x : array\n        n x 1 vector of new candidate\n    AggOp : CSR or CSC sparse matrix\n        Aggregation operator for the level that x was generated for\n    A : sparse matrix\n        Operator for the level that x was generated for\n    T : sparse matrix\n        Tentative prolongation operator for the level that x was generated for\n    Ca : scalar\n        Constant threshold parameter to decide when to drop candidates\n\n    Returns\n    -------\n    Nothing, x is modified in place\n\n    \"\"\"\n    if not (isspmatrix_csr(AggOp) or isspmatrix_csc(AggOp)):\n        raise TypeError('AggOp must be a CSR or CSC matrix')\n    else:\n        AggOp = AggOp.tocsc()\n        ndof = max(x.shape)\n        nPDEs = int(ndof/AggOp.shape[0])\n\n    def aggregate_wise_inner_product(z, AggOp, nPDEs, ndof):\n        \"\"\"Inner products per aggregate.\n\n        Helper function that calculates <z, z>_i, i.e., the\n        inner product of z only over aggregate i\n        Returns a vector of length num_aggregates where entry i is <z, z>_i\n\n        \"\"\"\n        z = np.ravel(z)*np.ravel(z)\n        innerp = np.zeros((1, AggOp.shape[1]), dtype=z.dtype)\n        for j in range(nPDEs):\n            innerp += z[slice(j, ndof, nPDEs)].reshape(1, -1) * AggOp\n\n        return innerp.reshape(-1, 1)\n\n    def get_aggregate_weights(AggOp, A, z, nPDEs, ndof):\n        \"\"\"Weights per aggregate.\n\n        Calculate local aggregate quantities\n        Return a vector of length num_aggregates where entry i is\n        (card(agg_i)/A.shape[0]) ( <Az, z>/rho(A) )\n\n        \"\"\"\n        rho = approximate_spectral_radius(A)\n        zAz = np.dot(z.reshape(1, -1), A*z.reshape(-1, 1))\n        card = nPDEs*(AggOp.indptr[1:]-AggOp.indptr[:-1])\n        weights = (np.ravel(card)*zAz)/(A.shape[0]*rho)\n        return weights.reshape(-1, 1)\n\n    # Run test 1, which finds where x is small relative to its energy\n    weights = Ca*get_aggregate_weights(AggOp, A, x, nPDEs, ndof)\n    mask1 = aggregate_wise_inner_product(x, AggOp, nPDEs, ndof) <= weights\n\n    # Run test 2, which finds where x is already approximated\n    # accurately by the existing T\n    projected_x = x - T*(T.T*x)\n    mask2 = aggregate_wise_inner_product(projected_x,\n                                         AggOp, nPDEs, ndof) <= weights\n\n    # Combine masks and zero out corresponding aggregates in x\n    mask = np.ravel(mask1 + mask2).nonzero()[0]\n    if mask.shape[0] > 0:\n        mask = nPDEs*AggOp[:, mask].indices\n        for j in range(nPDEs):\n            x[mask+j] = 0.0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef adaptive_sa_solver(A, initial_candidates=None, symmetry='hermitian',\n                       pdef=True, num_candidates=1, candidate_iters=5,\n                       improvement_iters=0, epsilon=0.1,\n                       max_levels=10, max_coarse=10, aggregate='standard',\n                       prepostsmoother=('gauss_seidel',\n                                        {'sweep': 'symmetric'}),\n                       smooth=('jacobi', {}), strength='symmetric',\n                       coarse_solver='pinv2',\n                       eliminate_local=(False, {'Ca': 1.0}), keep=False,\n                       **kwargs):\n    \"\"\"Create a multilevel solver using Adaptive Smoothed Aggregation (aSA).\n\n    Parameters\n    ----------\n    A : csr_matrix, bsr_matrix\n        Square matrix in CSR or BSR format\n    initial_candidates : None, n x m dense matrix\n        If a matrix, then this forms the basis for the first m candidates.\n        Also in this case, the initial setup stage is skipped, because this\n        provides the first candidate(s).  If None, then a random initial guess\n        and relaxation are used to inform the initial candidate.\n    symmetry : string\n        'symmetric' refers to both real and complex symmetric\n        'hermitian' refers to both complex Hermitian and real Hermitian\n        Note that for the strictly real case, these two options are the same\n        Note that this flag does not denote definiteness of the operator\n    pdef : bool\n        True or False, whether A is known to be positive definite.\n    num_candidates : integer\n        Number of near-nullspace candidates to generate\n    candidate_iters : integer\n        Number of smoothing passes/multigrid cycles used at each level of\n        the adaptive setup phase\n    improvement_iters : integer\n        Number of times each candidate is improved\n    epsilon : float\n        Target convergence factor\n    max_levels : integer\n        Maximum number of levels to be used in the multilevel solver.\n    max_coarse : integer\n        Maximum number of variables permitted on the coarse grid.\n    prepostsmoother : string or dict\n        Pre- and post-smoother used in the adaptive method\n    strength : ['symmetric', 'classical', 'evolution', ('predefined', {'C': csr_matrix}), None]\n        Method used to determine the strength of connection between unknowns of\n        the linear system.  See smoothed_aggregation_solver(...) documentation.\n    aggregate : ['standard', 'lloyd', 'naive', ('predefined', {'AggOp': csr_matrix})]\n        Method used to aggregate nodes.  See smoothed_aggregation_solver(...)\n        documentation.\n    smooth : ['jacobi', 'richardson', 'energy', None]\n        Method used used to smooth the tentative prolongator.  See\n        smoothed_aggregation_solver(...) documentation\n    coarse_solver : ['splu', 'lu', 'cholesky, 'pinv', 'gauss_seidel', ... ]\n        Solver used at the coarsest level of the MG hierarchy.\n        Optionally, may be a tuple (fn, args), where fn is a string such as\n        ['splu', 'lu', ...] or a callable function, and args is a dictionary of\n        arguments to be passed to fn.\n    eliminate_local : tuple\n        Length 2 tuple.  If the first entry is True, then eliminate candidates\n        where they aren't needed locally, using the second entry of the tuple\n        to contain arguments to local elimination routine.  Given the rigid\n        sparse data structures, this doesn't help much, if at all, with\n        complexity.  Its more of a diagnostic utility.\n    keep: bool\n        Flag to indicate keeping extra operators in the hierarchy for\n        diagnostics.  For example, if True, then strength of connection (C),\n        tentative prolongation (T), and aggregation (AggOp) are kept.\n\n    Returns\n    -------\n    multilevel_solver : multilevel_solver\n        Smoothed aggregation solver with adaptively generated candidates\n\n    Notes\n    -----\n    - Floating point value representing the \"work\" required to generate\n      the solver.  This value is the total cost of just relaxation, relative\n      to the fine grid.  The relaxation method used is assumed to symmetric\n      Gauss-Seidel.\n\n    - Unlike the standard Smoothed Aggregation (SA) method, adaptive SA does\n      not require knowledge of near-nullspace candidate vectors.  Instead, an\n      adaptive procedure computes one or more candidates 'from scratch'.  This\n      approach is useful when no candidates are known or the candidates have\n      been invalidated due to changes to matrix A.\n\n    Examples\n    --------\n    >>> from pyamg.gallery import stencil_grid\n    >>> from pyamg.aggregation import adaptive_sa_solver\n    >>> import numpy as np\n    >>> A=stencil_grid([[-1,-1,-1],[-1,8.0,-1],[-1,-1,-1]], (31,31),format='csr')\n    >>> [asa,work] = adaptive_sa_solver(A,num_candidates=1)\n    >>> residuals=[]\n    >>> x=asa.solve(b=np.ones((A.shape[0],)), x0=np.ones((A.shape[0],)), residuals=residuals)\n\n    References\n    ----------\n    .. [1] Brezina, Falgout, MacLachlan, Manteuffel, McCormick, and Ruge\n       \"Adaptive Smoothed Aggregation (alpha SA) Multigrid\"\n       SIAM Review Volume 47,  Issue 2  (2005)\n\n    \"\"\"\n    if not (isspmatrix_csr(A) or isspmatrix_bsr(A)):\n        try:\n            A = csr_matrix(A)\n            warn(\"Implicit conversion of A to CSR\", SparseEfficiencyWarning)\n        except BaseException:\n            raise TypeError('Argument A must have type csr_matrix or\\\n                            bsr_matrix, or be convertible to csr_matrix')\n\n    A = A.asfptype()\n    if A.shape[0] != A.shape[1]:\n        raise ValueError('expected square matrix')\n\n    # Track work in terms of relaxation\n    work = np.zeros((1,))\n\n    # Levelize the user parameters, so that they become lists describing the\n    # desired user option on each level.\n    max_levels, max_coarse, strength =\\\n        levelize_strength_or_aggregation(strength, max_levels, max_coarse)\n    max_levels, max_coarse, aggregate =\\\n        levelize_strength_or_aggregation(aggregate, max_levels, max_coarse)\n    smooth = levelize_smooth_or_improve_candidates(smooth, max_levels)\n\n    # Develop initial candidate(s).  Note that any predefined aggregation is\n    # preserved.\n    if initial_candidates is None:\n        B, aggregate, strength =\\\n            initial_setup_stage(A, symmetry, pdef, candidate_iters, epsilon,\n                                max_levels, max_coarse, aggregate,\n                                prepostsmoother, smooth, strength, work)\n        # Normalize B\n        B = (1.0/norm(B, 'inf')) * B\n        num_candidates -= 1\n    else:\n        # Otherwise, use predefined candidates\n        B = initial_candidates\n        num_candidates -= B.shape[1]\n        # Generate Aggregation and Strength Operators (the brute force way)\n        sa = smoothed_aggregation_solver(A, B=B, symmetry=symmetry,\n                                         presmoother=prepostsmoother,\n                                         postsmoother=prepostsmoother,\n                                         smooth=smooth, strength=strength,\n                                         max_levels=max_levels,\n                                         max_coarse=max_coarse,\n                                         aggregate=aggregate,\n                                         coarse_solver=coarse_solver,\n                                         improve_candidates=None, keep=True,\n                                         **kwargs)\n        if len(sa.levels) > 1:\n            # Set strength-of-connection and aggregation\n            aggregate = [('predefined', {'AggOp': sa.levels[i].AggOp.tocsr()})\n                         for i in range(len(sa.levels) - 1)]\n            strength = [('predefined', {'C': sa.levels[i].C.tocsr()})\n                        for i in range(len(sa.levels) - 1)]\n\n    # Develop additional candidates\n    for i in range(num_candidates):\n        x = general_setup_stage(\n            smoothed_aggregation_solver(A, B=B, symmetry=symmetry,\n                                        presmoother=prepostsmoother,\n                                        postsmoother=prepostsmoother,\n                                        smooth=smooth,\n                                        coarse_solver=coarse_solver,\n                                        aggregate=aggregate,\n                                        strength=strength,\n                                        improve_candidates=None,\n                                        keep=True, **kwargs),\n            symmetry, candidate_iters, prepostsmoother, smooth,\n            eliminate_local, coarse_solver, work)\n\n        # Normalize x and add to candidate list\n        x = x/norm(x, 'inf')\n        if np.isinf(x[0]) or np.isnan(x[0]):\n            raise ValueError('Adaptive candidate is all 0.')\n        B = np.hstack((B, x.reshape(-1, 1)))\n\n    # Improve candidates\n    if B.shape[1] > 1 and improvement_iters > 0:\n        b = np.zeros((A.shape[0], 1), dtype=A.dtype)\n        for i in range(improvement_iters):\n            for j in range(B.shape[1]):\n                # Run a V-cycle built on everything except candidate j, while\n                # using candidate j as the initial guess\n                x0 = B[:, 0]\n                B = B[:, 1:]\n                sa_temp =\\\n                    smoothed_aggregation_solver(A, B=B, symmetry=symmetry,\n                                                presmoother=prepostsmoother,\n                                                postsmoother=prepostsmoother,\n                                                smooth=smooth,\n                                                coarse_solver=coarse_solver,\n                                                aggregate=aggregate,\n                                                strength=strength,\n                                                improve_candidates=None,\n                                                keep=True, **kwargs)\n                x = sa_temp.solve(b, x0=x0,\n                                  tol=float(np.finfo(np.float).tiny),\n                                  maxiter=candidate_iters, cycle='V')\n                work[:] += 2 * sa_temp.operator_complexity() *\\\n                    sa_temp.levels[0].A.nnz * candidate_iters\n\n                # Apply local elimination\n                elim, elim_kwargs = unpack_arg(eliminate_local)\n                if elim is True:\n                    x = x/norm(x, 'inf')\n                    eliminate_local_candidates(x, sa_temp.levels[0].AggOp, A,\n                                               sa_temp.levels[0].T,\n                                               **elim_kwargs)\n\n                # Normalize x and add to candidate list\n                x = x/norm(x, 'inf')\n                if np.isinf(x[0]) or np.isnan(x[0]):\n                    raise ValueError('Adaptive candidate is all 0.')\n                B = np.hstack((B, x.reshape(-1, 1)))\n\n    elif improvement_iters > 0:\n        # Special case for improving a single candidate\n        max_levels = len(aggregate) + 1\n        max_coarse = 0\n        for i in range(improvement_iters):\n            B, aggregate, strength =\\\n                initial_setup_stage(A, symmetry, pdef, candidate_iters,\n                                    epsilon, max_levels, max_coarse,\n                                    aggregate, prepostsmoother, smooth,\n                                    strength, work, initial_candidate=B)\n            # Normalize B\n            B = (1.0/norm(B, 'inf'))*B\n\n    return [smoothed_aggregation_solver(A, B=B, symmetry=symmetry,\n                                        presmoother=prepostsmoother,\n                                        postsmoother=prepostsmoother,\n                                        smooth=smooth,\n                                        coarse_solver=coarse_solver,\n                                        aggregate=aggregate, strength=strength,\n                                        improve_candidates=None, keep=keep,\n                                        **kwargs),\n            work[0]/A.nnz]", "response": "Creates a multilevel solver for the given A."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef initial_setup_stage(A, symmetry, pdef, candidate_iters, epsilon,\n                        max_levels, max_coarse, aggregate, prepostsmoother,\n                        smooth, strength, work, initial_candidate=None):\n    \"\"\"Compute aggregation and the first near-nullspace candidate following Algorithm 3 in Brezina et al.\n\n    Parameters\n    ----------\n    candidate_iters\n        number of test relaxation iterations\n    epsilon\n        minimum acceptable relaxation convergence factor\n\n    References\n    ----------\n    .. [1] Brezina, Falgout, MacLachlan, Manteuffel, McCormick, and Ruge\n       \"Adaptive Smoothed Aggregation (aSA) Multigrid\"\n       SIAM Review Volume 47,  Issue 2  (2005)\n       http://www.cs.umn.edu/~maclach/research/aSA2.pdf\n\n    \"\"\"\n    # Define relaxation routine\n    def relax(A, x):\n        fn, kwargs = unpack_arg(prepostsmoother)\n        if fn == 'gauss_seidel':\n            gauss_seidel(A, x, np.zeros_like(x),\n                         iterations=candidate_iters, sweep='symmetric')\n        elif fn == 'gauss_seidel_nr':\n            gauss_seidel_nr(A, x, np.zeros_like(x),\n                            iterations=candidate_iters, sweep='symmetric')\n        elif fn == 'gauss_seidel_ne':\n            gauss_seidel_ne(A, x, np.zeros_like(x),\n                            iterations=candidate_iters, sweep='symmetric')\n        elif fn == 'jacobi':\n            jacobi(A, x, np.zeros_like(x), iterations=1,\n                   omega=1.0 / rho_D_inv_A(A))\n        elif fn == 'richardson':\n            polynomial(A, x, np.zeros_like(x), iterations=1,\n                       coefficients=[1.0/approximate_spectral_radius(A)])\n        elif fn == 'gmres':\n            x[:] = (gmres(A, np.zeros_like(x), x0=x,\n                          maxiter=candidate_iters)[0]).reshape(x.shape)\n        else:\n            raise TypeError('Unrecognized smoother')\n\n    # flag for skipping steps f-i in step 4\n    skip_f_to_i = True\n\n    # step 1\n    A_l = A\n    if initial_candidate is None:\n        x = sp.rand(A_l.shape[0], 1).astype(A_l.dtype)\n        # The following type check matches the usual 'complex' type,\n        # but also numpy data types such as 'complex64', 'complex128'\n        # and 'complex256'.\n        if A_l.dtype.name.startswith('complex'):\n            x = x + 1.0j*sp.rand(A_l.shape[0], 1)\n    else:\n        x = np.array(initial_candidate, dtype=A_l.dtype)\n\n    # step 2\n    relax(A_l, x)\n    work[:] += A_l.nnz * candidate_iters*2\n\n    # step 3\n    # not advised to stop the iteration here: often the first relaxation pass\n    # _is_ good, but the remaining passes are poor\n    # if x_A_x/x_A_x_old < epsilon:\n    #    # relaxation alone is sufficient\n    #    print 'relaxation alone works: %g'%(x_A_x/x_A_x_old)\n    #    return x, []\n\n    # step 4\n    As = [A]\n    xs = [x]\n    Ps = []\n    AggOps = []\n    StrengthOps = []\n\n    while A.shape[0] > max_coarse and max_levels > 1:\n        # The real check to break from the while loop is below\n\n        # Begin constructing next level\n        fn, kwargs = unpack_arg(strength[len(As)-1])  # step 4b\n        if fn == 'symmetric':\n            C_l = symmetric_strength_of_connection(A_l, **kwargs)\n            # Diagonal must be nonzero\n            C_l = C_l + eye(C_l.shape[0], C_l.shape[1], format='csr')\n        elif fn == 'classical':\n            C_l = classical_strength_of_connection(A_l, **kwargs)\n            # Diagonal must be nonzero\n            C_l = C_l + eye(C_l.shape[0], C_l.shape[1], format='csr')\n            if isspmatrix_bsr(A_l):\n                C_l = amalgamate(C_l, A_l.blocksize[0])\n        elif (fn == 'ode') or (fn == 'evolution'):\n            C_l = evolution_strength_of_connection(A_l,\n                                                   np.ones(\n                                                       (A_l.shape[0], 1),\n                                                       dtype=A.dtype),\n                                                   **kwargs)\n        elif fn == 'predefined':\n            C_l = kwargs['C'].tocsr()\n        elif fn is None:\n            C_l = A_l.tocsr()\n        else:\n            raise ValueError('unrecognized strength of connection method: %s' %\n                             str(fn))\n\n        # In SA, strength represents \"distance\", so we take magnitude of\n        # complex values\n        if C_l.dtype.name.startswith('complex'):\n            C_l.data = np.abs(C_l.data)\n\n        # Create a unified strength framework so that large values represent\n        # strong connections and small values represent weak connections\n        if (fn == 'ode') or (fn == 'evolution') or (fn == 'energy_based'):\n            C_l.data = 1.0 / C_l.data\n\n        # aggregation\n        fn, kwargs = unpack_arg(aggregate[len(As) - 1])\n        if fn == 'standard':\n            AggOp = standard_aggregation(C_l, **kwargs)[0]\n        elif fn == 'lloyd':\n            AggOp = lloyd_aggregation(C_l, **kwargs)[0]\n        elif fn == 'predefined':\n            AggOp = kwargs['AggOp'].tocsr()\n        else:\n            raise ValueError('unrecognized aggregation method %s' % str(fn))\n\n        T_l, x = fit_candidates(AggOp, x)  # step 4c\n\n        fn, kwargs = unpack_arg(smooth[len(As)-1])  # step 4d\n        if fn == 'jacobi':\n            P_l = jacobi_prolongation_smoother(A_l, T_l, C_l, x, **kwargs)\n        elif fn == 'richardson':\n            P_l = richardson_prolongation_smoother(A_l, T_l, **kwargs)\n        elif fn == 'energy':\n            P_l = energy_prolongation_smoother(A_l, T_l, C_l, x, None,\n                                               (False, {}), **kwargs)\n        elif fn is None:\n            P_l = T_l\n        else:\n            raise ValueError('unrecognized prolongation smoother method %s' %\n                             str(fn))\n\n        # R should reflect A's structure # step 4e\n        if symmetry == 'symmetric':\n            A_l = P_l.T.asformat(P_l.format) * A_l * P_l\n        elif symmetry == 'hermitian':\n            A_l = P_l.H.asformat(P_l.format) * A_l * P_l\n\n        StrengthOps.append(C_l)\n        AggOps.append(AggOp)\n        Ps.append(P_l)\n        As.append(A_l)\n\n        # skip to step 5 as in step 4e\n        if (A_l.shape[0] <= max_coarse) or (len(AggOps) + 1 >= max_levels):\n            break\n\n        if not skip_f_to_i:\n            x_hat = x.copy()  # step 4g\n            relax(A_l, x)  # step 4h\n            work[:] += A_l.nnz*candidate_iters*2\n            if pdef is True:\n                x_A_x = np.dot(np.conjugate(x).T, A_l*x)\n                xhat_A_xhat = np.dot(np.conjugate(x_hat).T, A_l*x_hat)\n                err_ratio = (x_A_x/xhat_A_xhat)**(1.0/candidate_iters)\n            else:\n                # use A.H A inner-product\n                Ax = A_l * x\n                # Axhat = A_l * x_hat\n                x_A_x = np.dot(np.conjugate(Ax).T, Ax)\n                xhat_A_xhat = np.dot(np.conjugate(x_hat).T, A_l*x_hat)\n                err_ratio = (x_A_x/xhat_A_xhat)**(1.0/candidate_iters)\n\n            if err_ratio < epsilon:  # step 4i\n                # print \"sufficient convergence, skipping\"\n                skip_f_to_i = True\n                if x_A_x == 0:\n                    x = x_hat  # need to restore x\n        else:\n            # just carry out relaxation, don't check for convergence\n            relax(A_l, x)  # step 4h\n            work[:] += 2 * A_l.nnz * candidate_iters\n\n        # store xs for diagnostic use and for use in step 5\n        xs.append(x)\n\n    # step 5\n    # Extend coarse-level candidate to the finest level\n    # --> note that we start with the x from the second coarsest level\n    x = xs[-1]\n    # make sure that xs[-1] has been relaxed by step 4h, i.e. relax(As[-2], x)\n    for lev in range(len(Ps)-2, -1, -1):  # lev = coarsest ... finest-1\n        P = Ps[lev]                     # I: lev --> lev+1\n        A = As[lev]                     # A on lev+1\n        x = P * x\n        relax(A, x)\n        work[:] += A.nnz*candidate_iters*2\n\n    # Set predefined strength of connection and aggregation\n    if len(AggOps) > 1:\n        aggregate = [('predefined', {'AggOp': AggOps[i]})\n                     for i in range(len(AggOps))]\n        strength = [('predefined', {'C': StrengthOps[i]})\n                    for i in range(len(StrengthOps))]\n\n    return x, aggregate, strength", "response": "Initial setup stage for the non - nullspace test."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef general_setup_stage(ml, symmetry, candidate_iters, prepostsmoother,\n                        smooth, eliminate_local, coarse_solver, work):\n    \"\"\"Compute additional candidates and improvements following Algorithm 4 in Brezina et al.\n\n    Parameters\n    ----------\n    candidate_iters\n        number of test relaxation iterations\n    epsilon\n        minimum acceptable relaxation convergence factor\n\n    References\n    ----------\n    .. [1] Brezina, Falgout, MacLachlan, Manteuffel, McCormick, and Ruge\n       \"Adaptive Smoothed Aggregation (alphaSA) Multigrid\"\n       SIAM Review Volume 47,  Issue 2  (2005)\n       http://www.cs.umn.edu/~maclach/research/aSA2.pdf\n\n    \"\"\"\n    def make_bridge(T):\n        M, N = T.shape\n        K = T.blocksize[0]\n        bnnz = T.indptr[-1]\n        # the K+1 represents the new dof introduced by the new candidate.  the\n        # bridge 'T' ignores this new dof and just maps zeros there\n        data = np.zeros((bnnz, K+1, K), dtype=T.dtype)\n        data[:, :-1, :] = T.data\n        return bsr_matrix((data, T.indices, T.indptr),\n                          shape=((K + 1) * int(M / K), N))\n\n    def expand_candidates(B_old, nodesize):\n        # insert a new dof that is always zero, to create NullDim+1 dofs per\n        # node in B\n        NullDim = B_old.shape[1]\n        nnodes = int(B_old.shape[0] / nodesize)\n        Bnew = np.zeros((nnodes, nodesize+1, NullDim), dtype=B_old.dtype)\n        Bnew[:, :-1, :] = B_old.reshape(nnodes, nodesize, NullDim)\n        return Bnew.reshape(-1, NullDim)\n\n    levels = ml.levels\n\n    x = sp.rand(levels[0].A.shape[0], 1)\n    if levels[0].A.dtype.name.startswith('complex'):\n        x = x + 1.0j*sp.rand(levels[0].A.shape[0], 1)\n    b = np.zeros_like(x)\n\n    x = ml.solve(b, x0=x, tol=float(np.finfo(np.float).tiny),\n                 maxiter=candidate_iters)\n    work[:] += ml.operator_complexity()*ml.levels[0].A.nnz*candidate_iters*2\n\n    T0 = levels[0].T.copy()\n\n    # TEST FOR CONVERGENCE HERE\n\n    for i in range(len(ml.levels) - 2):\n        # alpha-SA paper does local elimination here, but after talking\n        # to Marian, its not clear that this helps things\n        # fn, kwargs = unpack_arg(eliminate_local)\n        # if fn == True:\n        #    eliminate_local_candidates(x,levels[i].AggOp,levels[i].A,\n        #    levels[i].T, **kwargs)\n\n        # add candidate to B\n        B = np.hstack((levels[i].B, x.reshape(-1, 1)))\n\n        # construct Ptent\n        T, R = fit_candidates(levels[i].AggOp, B)\n\n        levels[i].T = T\n        x = R[:, -1].reshape(-1, 1)\n\n        # smooth P\n        fn, kwargs = unpack_arg(smooth[i])\n        if fn == 'jacobi':\n            levels[i].P = jacobi_prolongation_smoother(levels[i].A, T,\n                                                       levels[i].C, R,\n                                                       **kwargs)\n        elif fn == 'richardson':\n            levels[i].P = richardson_prolongation_smoother(levels[i].A, T,\n                                                           **kwargs)\n        elif fn == 'energy':\n            levels[i].P = energy_prolongation_smoother(levels[i].A, T,\n                                                       levels[i].C, R, None,\n                                                       (False, {}), **kwargs)\n            x = R[:, -1].reshape(-1, 1)\n        elif fn is None:\n            levels[i].P = T\n        else:\n            raise ValueError('unrecognized prolongation smoother method %s' %\n                             str(fn))\n\n        # construct R\n        if symmetry == 'symmetric':  # R should reflect A's structure\n            levels[i].R = levels[i].P.T.asformat(levels[i].P.format)\n        elif symmetry == 'hermitian':\n            levels[i].R = levels[i].P.H.asformat(levels[i].P.format)\n\n        # construct coarse A\n        levels[i+1].A = levels[i].R * levels[i].A * levels[i].P\n\n        # construct bridging P\n        T_bridge = make_bridge(levels[i+1].T)\n        R_bridge = levels[i+2].B\n\n        # smooth bridging P\n        fn, kwargs = unpack_arg(smooth[i+1])\n        if fn == 'jacobi':\n            levels[i+1].P = jacobi_prolongation_smoother(levels[i+1].A,\n                                                         T_bridge,\n                                                         levels[i+1].C,\n                                                         R_bridge, **kwargs)\n        elif fn == 'richardson':\n            levels[i+1].P = richardson_prolongation_smoother(levels[i+1].A,\n                                                             T_bridge,\n                                                             **kwargs)\n        elif fn == 'energy':\n            levels[i+1].P = energy_prolongation_smoother(levels[i+1].A,\n                                                         T_bridge,\n                                                         levels[i+1].C,\n                                                         R_bridge, None,\n                                                         (False, {}), **kwargs)\n        elif fn is None:\n            levels[i+1].P = T_bridge\n        else:\n            raise ValueError('unrecognized prolongation smoother method %s' %\n                             str(fn))\n\n        # construct the \"bridging\" R\n        if symmetry == 'symmetric':  # R should reflect A's structure\n            levels[i+1].R = levels[i+1].P.T.asformat(levels[i+1].P.format)\n        elif symmetry == 'hermitian':\n            levels[i+1].R = levels[i+1].P.H.asformat(levels[i+1].P.format)\n\n        # run solver on candidate\n        solver = multilevel_solver(levels[i+1:], coarse_solver=coarse_solver)\n        change_smoothers(solver, presmoother=prepostsmoother,\n                         postsmoother=prepostsmoother)\n        x = solver.solve(np.zeros_like(x), x0=x,\n                         tol=float(np.finfo(np.float).tiny),\n                         maxiter=candidate_iters)\n        work[:] += 2 * solver.operator_complexity() * solver.levels[0].A.nnz *\\\n            candidate_iters*2\n\n        # update values on next level\n        levels[i+1].B = R[:, :-1].copy()\n        levels[i+1].T = T_bridge\n\n    # note that we only use the x from the second coarsest level\n    fn, kwargs = unpack_arg(prepostsmoother)\n    for lvl in reversed(levels[:-2]):\n        x = lvl.P * x\n        work[:] += lvl.A.nnz*candidate_iters*2\n\n        if fn == 'gauss_seidel':\n            # only relax at nonzeros, so as not to mess up any locally dropped\n            # candidates\n            indices = np.ravel(x).nonzero()[0]\n            gauss_seidel_indexed(lvl.A, x, np.zeros_like(x), indices,\n                                 iterations=candidate_iters, sweep='symmetric')\n\n        elif fn == 'gauss_seidel_ne':\n            gauss_seidel_ne(lvl.A, x, np.zeros_like(x),\n                            iterations=candidate_iters, sweep='symmetric')\n\n        elif fn == 'gauss_seidel_nr':\n            gauss_seidel_nr(lvl.A, x, np.zeros_like(x),\n                            iterations=candidate_iters, sweep='symmetric')\n\n        elif fn == 'jacobi':\n            jacobi(lvl.A, x, np.zeros_like(x), iterations=1,\n                   omega=1.0 / rho_D_inv_A(lvl.A))\n\n        elif fn == 'richardson':\n            polynomial(lvl.A, x, np.zeros_like(x), iterations=1,\n                       coefficients=[1.0/approximate_spectral_radius(lvl.A)])\n\n        elif fn == 'gmres':\n            x[:] = (gmres(lvl.A, np.zeros_like(x), x0=x,\n                          maxiter=candidate_iters)[0]).reshape(x.shape)\n        else:\n            raise TypeError('Unrecognized smoother')\n\n    # x will be dense again, so we have to drop locally again\n    elim, elim_kwargs = unpack_arg(eliminate_local)\n    if elim is True:\n        x = x/norm(x, 'inf')\n        eliminate_local_candidates(x, levels[0].AggOp, levels[0].A, T0,\n                                   **elim_kwargs)\n\n    return x.reshape(-1, 1)", "response": "General setup stage for the internal stage of the internal stage of the internal stage of the internal stage of the internal stage."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a sparse matrix for the N - dimensional Poisson problem on a regular n - dimensional grid.", "response": "def poisson(grid, spacing=None, dtype=float, format=None, type='FD'):\n    \"\"\"Return a sparse matrix for the N-dimensional Poisson problem.\n\n    The matrix represents a finite Difference approximation to the\n    Poisson problem on a regular n-dimensional grid with unit grid\n    spacing and Dirichlet boundary conditions.\n\n    Parameters\n    ----------\n    grid : tuple of integers\n        grid dimensions e.g. (100,100)\n\n    Notes\n    -----\n    The matrix is symmetric and positive definite (SPD).\n\n    Examples\n    --------\n    >>> from pyamg.gallery import poisson\n    >>> # 4 nodes in one dimension\n    >>> poisson( (4,) ).todense()\n    matrix([[ 2., -1.,  0.,  0.],\n            [-1.,  2., -1.,  0.],\n            [ 0., -1.,  2., -1.],\n            [ 0.,  0., -1.,  2.]])\n\n    >>> # rectangular two dimensional grid\n    >>> poisson( (2,3) ).todense()\n    matrix([[ 4., -1.,  0., -1.,  0.,  0.],\n            [-1.,  4., -1.,  0., -1.,  0.],\n            [ 0., -1.,  4.,  0.,  0., -1.],\n            [-1.,  0.,  0.,  4., -1.,  0.],\n            [ 0., -1.,  0., -1.,  4., -1.],\n            [ 0.,  0., -1.,  0., -1.,  4.]])\n\n    \"\"\"\n    grid = tuple(grid)\n\n    N = len(grid)  # grid dimension\n\n    if N < 1 or min(grid) < 1:\n        raise ValueError('invalid grid shape: %s' % str(grid))\n\n    # create N-dimension Laplacian stencil\n    if type == 'FD':\n        stencil = np.zeros((3,) * N, dtype=dtype)\n        for i in range(N):\n            stencil[(1,)*i + (0,) + (1,)*(N-i-1)] = -1\n            stencil[(1,)*i + (2,) + (1,)*(N-i-1)] = -1\n        stencil[(1,)*N] = 2*N\n\n    if type == 'FE':\n        stencil = -np.ones((3,) * N, dtype=dtype)\n        stencil[(1,)*N] = 3**N - 1\n\n    return stencil_grid(stencil, grid, format=format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gauge_laplacian(npts, spacing=1.0, beta=0.1):\n    # The gauge Laplacian has the same sparsity structure as a normal\n    # Laplacian, so we start out with a Poisson Operator\n    N = npts\n    A = poisson((N, N), format='coo', dtype=complex)\n\n    # alpha is a random function of a point's integer position\n    # on a 1-D grid along the x or y direction.  e.g. the first\n    # point at (0,0) would be evaluate at alpha_*[0], while the\n    # last point at (N*spacing, N*spacing) would evaluate at alpha_*[-1]\n    alpha_x = 1.0j * 2.0 * np.pi * beta * np.random.randn(N*N)\n    alpha_y = 1.0j * 2.0 * np.pi * beta * np.random.randn(N*N)\n\n    # Replace off diagonals of A\n    for i in range(A.nnz):\n        r = A.row[i]\n        c = A.col[i]\n        diff = np.abs(r - c)\n        index = min(r, c)\n        if r > c:\n            s = -1.0\n        else:\n            s = 1.0\n        if diff == 1:\n            # differencing in the x-direction\n            A.data[i] = -1.0 * np.exp(s * alpha_x[index])\n        if diff == N:\n            # differencing in the y-direction\n            A.data[i] = -1.0 * np.exp(s * alpha_y[index])\n\n    # Handle periodic BCs\n    alpha_x = 1.0j * 2.0 * np.pi * beta * np.random.randn(N*N)\n    alpha_y = 1.0j * 2.0 * np.pi * beta * np.random.randn(N*N)\n    new_r = []\n    new_c = []\n    new_data = []\n    new_diff = []\n    for i in range(0, N):\n        new_r.append(i)\n        new_c.append(i + N*N - N)\n        new_diff.append(N)\n\n    for i in range(N*N - N, N*N):\n        new_r.append(i)\n        new_c.append(i - N*N + N)\n        new_diff.append(N)\n\n    for i in range(0, N*N-1, N):\n        new_r.append(i)\n        new_c.append(i + N - 1)\n        new_diff.append(1)\n\n    for i in range(N-1, N*N, N):\n        new_r.append(i)\n        new_c.append(i - N + 1)\n        new_diff.append(1)\n\n    for i in range(len(new_r)):\n        r = new_r[i]\n        c = new_c[i]\n        diff = new_diff[i]\n        index = min(r, c)\n        if r > c:\n            s = -1.0\n        else:\n            s = 1.0\n        if diff == 1:\n            # differencing in the x-direction\n            new_data.append(-1.0 * np.exp(s * alpha_x[index]))\n        if diff == N:\n            # differencing in the y-direction\n            new_data.append(-1.0 * np.exp(s * alpha_y[index]))\n\n    # Construct Final Matrix\n    data = np.hstack((A.data, np.array(new_data)))\n    row = np.hstack((A.row, np.array(new_r)))\n    col = np.hstack((A.col, np.array(new_c)))\n    A = sp.sparse.coo_matrix((data, (row, col)), shape=(N*N, N*N)).tocsr()\n\n    return (1.0/spacing**2)*A", "response": "Construct a Gauge Laplacian from Quantum Chromodynamics for regular 2D grids."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute ||b - A * x ||.", "response": "def residual_norm(A, x, b):\n    \"\"\"Compute ||b - A*x||.\"\"\"\n    return norm(np.ravel(b) - A*np.ravel(x))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef axpy(x, y, a=1.0):\n    from scipy.linalg import get_blas_funcs\n\n    fn = get_blas_funcs(['axpy'], [x, y])[0]\n    fn(x, y, a)", "response": "Quick level - 1 call to BLAS y = a * x + y"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _approximate_eigenvalues(A, tol, maxiter, symmetric=None,\n                             initial_guess=None):\n    \"\"\"Apprixmate eigenvalues.\n\n    Used by approximate_spectral_radius and condest.\n\n    Returns [W, E, H, V, breakdown_flag], where W and E are the eigenvectors\n    and eigenvalues of the Hessenberg matrix H, respectively, and V is the\n    Krylov space.  breakdown_flag denotes whether Lanczos/Arnoldi suffered\n    breakdown.  E is therefore the approximate eigenvalues of A.\n\n    To obtain approximate eigenvectors of A, compute V*W.\n    \"\"\"\n    from scipy.sparse.linalg import aslinearoperator\n\n    A = aslinearoperator(A)  # A could be dense or sparse, or something weird\n\n    # Choose tolerance for deciding if break-down has occurred\n    t = A.dtype.char\n    eps = np.finfo(np.float).eps\n    feps = np.finfo(np.single).eps\n    geps = np.finfo(np.longfloat).eps\n    _array_precision = {'f': 0, 'd': 1, 'g': 2, 'F': 0, 'D': 1, 'G': 2}\n    breakdown = {0: feps*1e3, 1: eps*1e6, 2: geps*1e6}[_array_precision[t]]\n    breakdown_flag = False\n\n    if A.shape[0] != A.shape[1]:\n        raise ValueError('expected square matrix')\n\n    maxiter = min(A.shape[0], maxiter)\n\n    if initial_guess is None:\n        v0 = sp.rand(A.shape[1], 1)\n        if A.dtype == complex:\n            v0 = v0 + 1.0j * sp.rand(A.shape[1], 1)\n    else:\n        v0 = initial_guess\n\n    v0 /= norm(v0)\n\n    # Important to type H based on v0, so that a real nonsymmetric matrix, can\n    # have an imaginary initial guess for its Arnoldi Krylov space\n    H = np.zeros((maxiter+1, maxiter),\n                 dtype=np.find_common_type([v0.dtype, A.dtype], []))\n\n    V = [v0]\n\n    beta = 0.0\n    for j in range(maxiter):\n        w = A * V[-1]\n\n        if symmetric:\n            if j >= 1:\n                H[j-1, j] = beta\n                w -= beta * V[-2]\n\n            alpha = np.dot(np.conjugate(w.ravel()), V[-1].ravel())\n            H[j, j] = alpha\n            w -= alpha * V[-1]  # axpy(V[-1],w,-alpha)\n\n            beta = norm(w)\n            H[j+1, j] = beta\n\n            if (H[j+1, j] < breakdown):\n                breakdown_flag = True\n                break\n\n            w /= beta\n\n            V.append(w)\n            V = V[-2:]  # retain only last two vectors\n\n        else:\n            # orthogonalize against Vs\n            for i, v in enumerate(V):\n                H[i, j] = np.dot(np.conjugate(v.ravel()), w.ravel())\n                w = w - H[i, j]*v\n\n            H[j+1, j] = norm(w)\n\n            if (H[j+1, j] < breakdown):\n                breakdown_flag = True\n                if H[j+1, j] != 0.0:\n                    w = w/H[j+1, j]\n                V.append(w)\n                break\n\n            w = w/H[j+1, j]\n            V.append(w)\n\n            # if upper 2x2 block of Hessenberg matrix H is almost symmetric,\n            # and the user has not explicitly specified symmetric=False,\n            # then switch to symmetric Lanczos algorithm\n            # if symmetric is not False and j == 1:\n            #    if abs(H[1,0] - H[0,1]) < 1e-12:\n            #        #print \"using symmetric mode\"\n            #        symmetric = True\n            #        V = V[1:]\n            #        H[1,0] = H[0,1]\n            #        beta = H[2,1]\n\n    # print \"Approximated spectral radius in %d iterations\" % (j + 1)\n\n    from scipy.linalg import eig\n\n    Eigs, Vects = eig(H[:j+1, :j+1], left=False, right=True)\n\n    return (Vects, Eigs, H, V, breakdown_flag)", "response": "Compute the approximate eigenvalues of A."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef approximate_spectral_radius(A, tol=0.01, maxiter=15, restart=5,\n                                symmetric=None, initial_guess=None,\n                                return_vector=False):\n    \"\"\"Approximate the spectral radius of a matrix.\n\n    Parameters\n    ----------\n    A : {dense or sparse matrix}\n        E.g. csr_matrix, csc_matrix, ndarray, etc.\n    tol : {scalar}\n        Relative tolerance of approximation, i.e., the error divided\n        by the approximate spectral radius is compared to tol.\n    maxiter : {integer}\n        Maximum number of iterations to perform\n    restart : {integer}\n        Number of restarted Arnoldi processes.  For example, a value of 0 will\n        run Arnoldi once, for maxiter iterations, and a value of 1 will restart\n        Arnoldi once, using the maximal eigenvector from the first Arnoldi\n        process as the initial guess.\n    symmetric : {boolean}\n        True  - if A is symmetric Lanczos iteration is used (more efficient)\n        False - if A is non-symmetric Arnoldi iteration is used (less efficient)\n    initial_guess : {array|None}\n        If n x 1 array, then use as initial guess for Arnoldi/Lanczos.\n        If None, then use a random initial guess.\n    return_vector : {boolean}\n        True - return an approximate dominant eigenvector, in addition to the spectral radius.\n        False - Do not return the approximate dominant eigenvector\n\n    Returns\n    -------\n    An approximation to the spectral radius of A, and\n    if return_vector=True, then also return the approximate dominant\n    eigenvector\n\n    Notes\n    -----\n    The spectral radius is approximated by looking at the Ritz eigenvalues.\n    Arnoldi iteration (or Lanczos) is used to project the matrix A onto a\n    Krylov subspace: H = Q* A Q.  The eigenvalues of H (i.e. the Ritz\n    eigenvalues) should represent the eigenvalues of A in the sense that the\n    minimum and maximum values are usually well matched (for the symmetric case\n    it is true since the eigenvalues are real).\n\n    References\n    ----------\n    .. [1] Z. Bai, J. Demmel, J. Dongarra, A. Ruhe, and H. van der Vorst,\n       editors.  \"Templates for the Solution of Algebraic Eigenvalue Problems:\n       A Practical Guide\", SIAM, Philadelphia, 2000.\n\n    Examples\n    --------\n    >>> from pyamg.util.linalg import approximate_spectral_radius\n    >>> import numpy as np\n    >>> from scipy.linalg import eigvals, norm\n    >>> A = np.array([[1.,0.],[0.,1.]])\n    >>> print approximate_spectral_radius(A,maxiter=3)\n    1.0\n    >>> print max([norm(x) for x in eigvals(A)])\n    1.0\n\n    \"\"\"\n    if not hasattr(A, 'rho') or return_vector:\n        # somehow more restart causes a nonsymmetric case to fail...look at\n        # this what about A.dtype=int?  convert somehow?\n\n        # The use of the restart vector v0 requires that the full Krylov\n        # subspace V be stored.  So, set symmetric to False.\n        symmetric = False\n\n        if maxiter < 1:\n            raise ValueError('expected maxiter > 0')\n        if restart < 0:\n            raise ValueError('expected restart >= 0')\n        if A.dtype == int:\n            raise ValueError('expected A to be float (complex or real)')\n        if A.shape[0] != A.shape[1]:\n            raise ValueError('expected square A')\n\n        if initial_guess is None:\n            v0 = sp.rand(A.shape[1], 1)\n            if A.dtype == complex:\n                v0 = v0 + 1.0j * sp.rand(A.shape[1], 1)\n        else:\n            if initial_guess.shape[0] != A.shape[0]:\n                raise ValueError('initial_guess and A must have same shape')\n            if (len(initial_guess.shape) > 1) and (initial_guess.shape[1] > 1):\n                raise ValueError('initial_guess must be an (n,1) or\\\n                                  (n,) vector')\n            v0 = initial_guess.reshape(-1, 1)\n            v0 = np.array(v0, dtype=A.dtype)\n\n        for j in range(restart+1):\n            [evect, ev, H, V, breakdown_flag] =\\\n                _approximate_eigenvalues(A, tol, maxiter,\n                                         symmetric, initial_guess=v0)\n            # Calculate error in dominant eigenvector\n            nvecs = ev.shape[0]\n            max_index = np.abs(ev).argmax()\n            error = H[nvecs, nvecs-1]*evect[-1, max_index]\n\n            # error is a fast way of calculating the following line\n            # error2 = ( A - ev[max_index]*sp.mat(\n            #           sp.eye(A.shape[0],A.shape[1])) )*\\\n            #           ( sp.mat(sp.hstack(V[:-1]))*\\\n            #           evect[:,max_index].reshape(-1,1) )\n            # print str(error) + \"    \" + str(sp.linalg.norm(e2))\n\n            if (np.abs(error)/np.abs(ev[max_index]) < tol) or\\\n               breakdown_flag:\n                # halt if below relative tolerance\n                v0 = np.dot(np.hstack(V[:-1]),\n                            evect[:, max_index].reshape(-1, 1))\n                break\n            else:\n                v0 = np.dot(np.hstack(V[:-1]),\n                            evect[:, max_index].reshape(-1, 1))\n        # end j-loop\n\n        rho = np.abs(ev[max_index])\n        if sparse.isspmatrix(A):\n            A.rho = rho\n\n        if return_vector:\n            return (rho, v0)\n        else:\n            return rho\n\n    else:\n        return A.rho", "response": "Approximate the spectral radius of a matrix A."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef condest(A, tol=0.1, maxiter=25, symmetric=False):\n    [evect, ev, H, V, breakdown_flag] =\\\n        _approximate_eigenvalues(A, tol, maxiter, symmetric)\n\n    return np.max([norm(x) for x in ev])/min([norm(x) for x in ev])", "response": "r Estimates the condition number of A."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the condition number of A.", "response": "def cond(A):\n    \"\"\"Return condition number of A.\n\n    Parameters\n    ----------\n    A   : {dense or sparse matrix}\n        e.g. array, matrix, csr_matrix, ...\n\n    Returns\n    -------\n    2-norm condition number through use of the SVD\n    Use for small to moderate sized dense matrices.\n    For large sparse matrices, use condest.\n\n    Notes\n    -----\n    The condition number measures how large of a change in\n    the problems solution is caused by a change in problem's input.\n    Large condition numbers indicate that small perturbations\n    and numerical errors are magnified greatly when solving the system.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from pyamg.util.linalg import condest\n    >>> c = condest(np.array([[1.0,0.],[0.,2.0]]))\n    >>> print c\n    2.0\n\n    \"\"\"\n    if A.shape[0] != A.shape[1]:\n        raise ValueError('expected square matrix')\n\n    if sparse.isspmatrix(A):\n        A = A.todense()\n\n    # 2-Norm Condition Number\n    from scipy.linalg import svd\n\n    U, Sigma, Vh = svd(A)\n    return np.max(Sigma)/min(Sigma)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pinv_array(a, cond=None):\n    n = a.shape[0]\n    m = a.shape[1]\n\n    if m == 1:\n        # Pseudo-inverse of 1 x 1 matrices is trivial\n        zero_entries = (a == 0.0).nonzero()[0]\n        a[zero_entries] = 1.0\n        a[:] = 1.0/a\n        a[zero_entries] = 0.0\n        del zero_entries\n\n    else:\n        # The block size is greater than 1\n\n        # Create necessary arrays and function pointers for calculating pinv\n        gelss, gelss_lwork = get_lapack_funcs(('gelss', 'gelss_lwork'),\n                                              (np.ones((1,), dtype=a.dtype)))\n        RHS = np.eye(m, dtype=a.dtype)\n        lwork = _compute_lwork(gelss_lwork, m, m, m)\n\n        # Choose tolerance for which singular values are zero in *gelss below\n        if cond is None:\n            t = a.dtype.char\n            eps = np.finfo(np.float).eps\n            feps = np.finfo(np.single).eps\n            geps = np.finfo(np.longfloat).eps\n            _array_precision = {'f': 0, 'd': 1, 'g': 2, 'F': 0, 'D': 1, 'G': 2}\n            cond = {0: feps*1e3, 1: eps*1e6, 2: geps*1e6}[_array_precision[t]]\n\n        # Invert each block of a\n        for kk in range(n):\n            gelssoutput = gelss(a[kk], RHS, cond=cond, lwork=lwork,\n                                overwrite_a=True, overwrite_b=False)\n            a[kk] = gelssoutput[1]", "response": "Calculates the Moore - Penrose pseudo inverse of each element of a."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a multilevel rootnode based Smoothed Aggregation solver.", "response": "def rootnode_solver(A, B=None, BH=None,\n                    symmetry='hermitian', strength='symmetric',\n                    aggregate='standard', smooth='energy',\n                    presmoother=('block_gauss_seidel',\n                                 {'sweep': 'symmetric'}),\n                    postsmoother=('block_gauss_seidel',\n                                  {'sweep': 'symmetric'}),\n                    improve_candidates=('block_gauss_seidel',\n                                        {'sweep': 'symmetric',\n                                         'iterations': 4}),\n                    max_levels=10, max_coarse=10,\n                    diagonal_dominance=False, keep=False, **kwargs):\n    \"\"\"Create a multilevel solver using root-node based Smoothed Aggregation (SA).\n\n    See the notes below, for the major differences with the classical-style\n    smoothed aggregation solver in aggregation.smoothed_aggregation_solver.\n\n    Parameters\n    ----------\n    A : csr_matrix, bsr_matrix\n        Sparse NxN matrix in CSR or BSR format\n\n    B : None, array_like\n        Right near-nullspace candidates stored in the columns of an NxK array.\n        K must be >= the blocksize of A (see reference [2011OlScTu]_). The default value\n        B=None is equivalent to choosing the constant over each block-variable,\n        B=np.kron(np.ones((A.shape[0]/blocksize(A), 1)), np.eye(blocksize(A)))\n\n    BH : None, array_like\n        Left near-nullspace candidates stored in the columns of an NxK array.\n        BH is only used if symmetry is 'nonsymmetric'.  K must be >= the\n        blocksize of A (see reference [2011OlScTu]_). The default value B=None is\n        equivalent to choosing the constant over each block-variable,\n        B=np.kron(np.ones((A.shape[0]/blocksize(A), 1)), np.eye(blocksize(A)))\n\n    symmetry : string\n        'symmetric' refers to both real and complex symmetric\n        'hermitian' refers to both complex Hermitian and real Hermitian\n        'nonsymmetric' i.e. nonsymmetric in a hermitian sense\n        Note that for the strictly real case, symmetric and hermitian are\n        the same\n        Note that this flag does not denote definiteness of the operator.\n\n    strength : list\n        Method used to determine the strength of connection between unknowns of\n        the linear system.  Method-specific parameters may be passed in using a\n        tuple, e.g. strength=('symmetric',{'theta' : 0.25 }). If strength=None,\n        all nonzero entries of the matrix are considered strong.\n\n    aggregate : list\n        Method used to aggregate nodes.\n\n    smooth : list\n        Method used to smooth the tentative prolongator.  Method-specific\n        parameters may be passed in using a tuple, e.g.  smooth=\n        ('energy',{'krylov' : 'gmres'}).  Only 'energy' and None are valid\n        prolongation smoothing options.\n\n    presmoother : tuple, string, list\n        Defines the presmoother for the multilevel cycling.  The default block\n        Gauss-Seidel option defaults to point-wise Gauss-Seidel, if the matrix\n        is CSR or is a BSR matrix with blocksize of 1.  See notes below for\n        varying this parameter on a per level basis.\n\n    postsmoother : tuple, string, list\n        Same as presmoother, except defines the postsmoother.\n\n    improve_candidates : tuple, string, list\n        The ith entry defines the method used to improve the candidates B on\n        level i.  If the list is shorter than max_levels, then the last entry\n        will define the method for all levels lower.  If tuple or string, then\n        this single relaxation descriptor defines improve_candidates on all\n        levels.\n        The list elements are relaxation descriptors of the form used for\n        presmoother and postsmoother.  A value of None implies no action on B.\n\n    max_levels : integer\n        Maximum number of levels to be used in the multilevel solver.\n\n    max_coarse : integer\n        Maximum number of variables permitted on the coarse grid.\n\n    diagonal_dominance : bool, tuple\n        If True (or the first tuple entry is True), then avoid coarsening\n        diagonally dominant rows.  The second tuple entry requires a\n        dictionary, where the key value 'theta' is used to tune the diagonal\n        dominance threshold.\n\n    keep : bool\n        Flag to indicate keeping extra operators in the hierarchy for\n        diagnostics.  For example, if True, then strength of connection (C),\n        tentative prolongation (T), aggregation (AggOp), and arrays\n        storing the C-points (Cpts) and F-points (Fpts) are kept at\n        each level.\n\n    Other Parameters\n    ----------------\n    cycle_type : ['V','W','F']\n        Structrure of multigrid cycle\n    coarse_solver : ['splu', 'lu', 'cholesky, 'pinv', 'gauss_seidel', ... ]\n        Solver used at the coarsest level of the MG hierarchy.\n        Optionally, may be a tuple (fn, args), where fn is a string such as\n        ['splu', 'lu', ...] or a callable function, and args is a dictionary of\n        arguments to be passed to fn.\n\n    Returns\n    -------\n    ml : multilevel_solver\n        Multigrid hierarchy of matrices and prolongation operators\n\n    See Also\n    --------\n    multilevel_solver, aggregation.smoothed_aggregation_solver,\n    classical.ruge_stuben_solver\n\n    Notes\n    -----\n         - Root-node style SA differs from classical SA primarily by preserving\n           and identity block in the interpolation operator, P.  Each aggregate\n           has a \"root-node\" or \"center-node\" associated with it, and this\n           root-node is injected from the coarse grid to the fine grid.  The\n           injection corresponds to the identity block.\n\n         - Only smooth={'energy', None} is supported for prolongation\n           smoothing.  See reference [2011OlScTu]_ below for more details on why the\n           'energy' prolongation smoother is the natural counterpart to\n           root-node style SA.\n\n         - The additional parameters are passed through as arguments to\n           multilevel_solver.  Refer to pyamg.multilevel_solver for additional\n           documentation.\n\n         - At each level, four steps are executed in order to define the coarser\n           level operator.\n\n           1. Matrix A is given and used to derive a strength matrix, C.\n\n           2. Based on the strength matrix, indices are grouped or aggregated.\n\n           3. The aggregates define coarse nodes and a tentative prolongation\n              operator T is defined by injection\n\n           4. The tentative prolongation operator is smoothed by a relaxation\n              scheme to improve the quality and extent of interpolation from the\n              aggregates to fine nodes.\n\n         - The parameters smooth, strength, aggregate, presmoother, postsmoother\n           can be varied on a per level basis.  For different methods on\n           different levels, use a list as input so that the i-th entry defines\n           the method at the i-th level.  If there are more levels in the\n           hierarchy than list entries, the last entry will define the method\n           for all levels lower.\n\n           Examples are:\n           smooth=[('jacobi', {'omega':1.0}), None, 'jacobi']\n           presmoother=[('block_gauss_seidel', {'sweep':symmetric}), 'sor']\n           aggregate=['standard', 'naive']\n           strength=[('symmetric', {'theta':0.25}), ('symmetric', {'theta':0.08})]\n\n         - Predefined strength of connection and aggregation schemes can be\n           specified.  These options are best used together, but aggregation can\n           be predefined while strength of connection is not.\n\n           For predefined strength of connection, use a list consisting of\n           tuples of the form ('predefined', {'C' : C0}), where C0 is a\n           csr_matrix and each degree-of-freedom in C0 represents a supernode.\n           For instance to predefine a three-level hierarchy, use\n           [('predefined', {'C' : C0}), ('predefined', {'C' : C1}) ].\n\n           Similarly for predefined aggregation, use a list of tuples.  For\n           instance to predefine a three-level hierarchy, use [('predefined',\n           {'AggOp' : Agg0}), ('predefined', {'AggOp' : Agg1}) ], where the\n           dimensions of A, Agg0 and Agg1 are compatible, i.e.  Agg0.shape[1] ==\n           A.shape[0] and Agg1.shape[1] == Agg0.shape[0].  Each AggOp is a\n           csr_matrix.\n\n           Because this is a root-nodes solver, if a member of the predefined\n           aggregation list is predefined, it must be of the form\n           ('predefined', {'AggOp' : Agg, 'Cnodes' : Cnodes}).\n\n    Examples\n    --------\n    >>> from pyamg import rootnode_solver\n    >>> from pyamg.gallery import poisson\n    >>> from scipy.sparse.linalg import cg\n    >>> import numpy as np\n    >>> A = poisson((100, 100), format='csr')           # matrix\n    >>> b = np.ones((A.shape[0]))                   # RHS\n    >>> ml = rootnode_solver(A)                     # AMG solver\n    >>> M = ml.aspreconditioner(cycle='V')             # preconditioner\n    >>> x, info = cg(A, b, tol=1e-8, maxiter=30, M=M)   # solve with CG\n\n    References\n    ----------\n    .. [1996VaMa] Vanek, P. and Mandel, J. and Brezina, M.,\n       \"Algebraic Multigrid by Smoothed Aggregation for\n       Second and Fourth Order Elliptic Problems\",\n       Computing, vol. 56, no. 3, pp. 179--196, 1996.\n       http://citeseer.ist.psu.edu/vanek96algebraic.html\n    .. [2011OlScTu] Olson, L. and Schroder, J. and Tuminaro, R.,\n       \"A general interpolation strategy for algebraic\n       multigrid using energy minimization\", SIAM Journal\n       on Scientific Computing (SISC), vol. 33, pp.\n       966--991, 2011.\n\n    \"\"\"\n    if not (isspmatrix_csr(A) or isspmatrix_bsr(A)):\n        try:\n            A = csr_matrix(A)\n            warn(\"Implicit conversion of A to CSR\",\n                 SparseEfficiencyWarning)\n        except BaseException:\n            raise TypeError('Argument A must have type csr_matrix, \\\n                             bsr_matrix, or be convertible to csr_matrix')\n\n    A = A.asfptype()\n\n    if (symmetry != 'symmetric') and (symmetry != 'hermitian') and \\\n            (symmetry != 'nonsymmetric'):\n        raise ValueError('expected \\'symmetric\\', \\'nonsymmetric\\' \\\n                          or \\'hermitian\\' for the symmetry parameter ')\n    A.symmetry = symmetry\n\n    if A.shape[0] != A.shape[1]:\n        raise ValueError('expected square matrix')\n    # Right near nullspace candidates use constant for each variable as default\n    if B is None:\n        B = np.kron(np.ones((int(A.shape[0]/blocksize(A)), 1), dtype=A.dtype),\n                    np.eye(blocksize(A)))\n    else:\n        B = np.asarray(B, dtype=A.dtype)\n        if len(B.shape) == 1:\n            B = B.reshape(-1, 1)\n        if B.shape[0] != A.shape[0]:\n            raise ValueError('The near null-space modes B have incorrect \\\n                              dimensions for matrix A')\n        if B.shape[1] < blocksize(A):\n            raise ValueError('B.shape[1] must be >= the blocksize of A')\n\n    # Left near nullspace candidates\n    if A.symmetry == 'nonsymmetric':\n        if BH is None:\n            BH = B.copy()\n        else:\n            BH = np.asarray(BH, dtype=A.dtype)\n            if len(BH.shape) == 1:\n                BH = BH.reshape(-1, 1)\n            if BH.shape[1] != B.shape[1]:\n                raise ValueError('The number of left and right near \\\n                                  null-space modes B and BH, must be equal')\n            if BH.shape[0] != A.shape[0]:\n                raise ValueError('The near null-space modes BH have \\\n                                  incorrect dimensions for matrix A')\n\n    # Levelize the user parameters, so that they become lists describing the\n    # desired user option on each level.\n    max_levels, max_coarse, strength =\\\n        levelize_strength_or_aggregation(strength, max_levels, max_coarse)\n    max_levels, max_coarse, aggregate =\\\n        levelize_strength_or_aggregation(aggregate, max_levels, max_coarse)\n    improve_candidates =\\\n        levelize_smooth_or_improve_candidates(improve_candidates, max_levels)\n    smooth = levelize_smooth_or_improve_candidates(smooth, max_levels)\n\n    # Construct multilevel structure\n    levels = []\n    levels.append(multilevel_solver.level())\n    levels[-1].A = A          # matrix\n\n    # Append near nullspace candidates\n    levels[-1].B = B          # right candidates\n    if A.symmetry == 'nonsymmetric':\n        levels[-1].BH = BH    # left candidates\n\n    while len(levels) < max_levels and \\\n            int(levels[-1].A.shape[0]/blocksize(levels[-1].A)) > max_coarse:\n        extend_hierarchy(levels, strength, aggregate, smooth,\n                         improve_candidates, diagonal_dominance, keep)\n\n    ml = multilevel_solver(levels, **kwargs)\n    change_smoothers(ml, presmoother, postsmoother)\n    return ml"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extend_hierarchy(levels, strength, aggregate, smooth, improve_candidates,\n                     diagonal_dominance=False, keep=True):\n    \"\"\"Extend the multigrid hierarchy.\n\n    Service routine to implement the strength of connection, aggregation,\n    tentative prolongation construction, and prolongation smoothing.  Called by\n    smoothed_aggregation_solver.\n\n    \"\"\"\n    def unpack_arg(v):\n        if isinstance(v, tuple):\n            return v[0], v[1]\n        else:\n            return v, {}\n\n    A = levels[-1].A\n    B = levels[-1].B\n    if A.symmetry == \"nonsymmetric\":\n        AH = A.H.asformat(A.format)\n        BH = levels[-1].BH\n\n    # Compute the strength-of-connection matrix C, where larger\n    # C[i, j] denote stronger couplings between i and j.\n    fn, kwargs = unpack_arg(strength[len(levels)-1])\n    if fn == 'symmetric':\n        C = symmetric_strength_of_connection(A, **kwargs)\n    elif fn == 'classical':\n        C = classical_strength_of_connection(A, **kwargs)\n    elif fn == 'distance':\n        C = distance_strength_of_connection(A, **kwargs)\n    elif (fn == 'ode') or (fn == 'evolution'):\n        if 'B' in kwargs:\n            C = evolution_strength_of_connection(A, **kwargs)\n        else:\n            C = evolution_strength_of_connection(A, B, **kwargs)\n    elif fn == 'energy_based':\n        C = energy_based_strength_of_connection(A, **kwargs)\n    elif fn == 'predefined':\n        C = kwargs['C'].tocsr()\n    elif fn == 'algebraic_distance':\n        C = algebraic_distance(A, **kwargs)\n    elif fn == 'affinity':\n        C = affinity_distance(A, **kwargs)\n    elif fn is None:\n        C = A.tocsr()\n    else:\n        raise ValueError('unrecognized strength of connection method: %s' %\n                         str(fn))\n\n    # Avoid coarsening diagonally dominant rows\n    flag, kwargs = unpack_arg(diagonal_dominance)\n    if flag:\n        C = eliminate_diag_dom_nodes(A, C, **kwargs)\n\n    # Compute the aggregation matrix AggOp (i.e., the nodal coarsening of A).\n    # AggOp is a boolean matrix, where the sparsity pattern for the k-th column\n    # denotes the fine-grid nodes agglomerated into k-th coarse-grid node.\n    fn, kwargs = unpack_arg(aggregate[len(levels)-1])\n    if fn == 'standard':\n        AggOp, Cnodes = standard_aggregation(C, **kwargs)\n    elif fn == 'naive':\n        AggOp, Cnodes = naive_aggregation(C, **kwargs)\n    elif fn == 'lloyd':\n        AggOp, Cnodes = lloyd_aggregation(C, **kwargs)\n    elif fn == 'predefined':\n        AggOp = kwargs['AggOp'].tocsr()\n        Cnodes = kwargs['Cnodes']\n    else:\n        raise ValueError('unrecognized aggregation method %s' % str(fn))\n\n    # Improve near nullspace candidates by relaxing on A B = 0\n    fn, kwargs = unpack_arg(improve_candidates[len(levels)-1])\n    if fn is not None:\n        b = np.zeros((A.shape[0], 1), dtype=A.dtype)\n        B = relaxation_as_linear_operator((fn, kwargs), A, b) * B\n        levels[-1].B = B\n        if A.symmetry == \"nonsymmetric\":\n            BH = relaxation_as_linear_operator((fn, kwargs), AH, b) * BH\n            levels[-1].BH = BH\n\n    # Compute the tentative prolongator, T, which is a tentative interpolation\n    # matrix from the coarse-grid to the fine-grid.  T exactly interpolates\n    # B_fine[:, 0:blocksize(A)] = T B_coarse[:, 0:blocksize(A)].\n    T, dummy = fit_candidates(AggOp, B[:, 0:blocksize(A)])\n    del dummy\n    if A.symmetry == \"nonsymmetric\":\n        TH, dummyH = fit_candidates(AggOp, BH[:, 0:blocksize(A)])\n        del dummyH\n\n    # Create necessary root node matrices\n    Cpt_params = (True, get_Cpt_params(A, Cnodes, AggOp, T))\n    T = scale_T(T, Cpt_params[1]['P_I'], Cpt_params[1]['I_F'])\n    if A.symmetry == \"nonsymmetric\":\n        TH = scale_T(TH, Cpt_params[1]['P_I'], Cpt_params[1]['I_F'])\n\n    # Set coarse grid near nullspace modes as injected fine grid near\n    # null-space modes\n    B = Cpt_params[1]['P_I'].T*levels[-1].B\n    if A.symmetry == \"nonsymmetric\":\n        BH = Cpt_params[1]['P_I'].T*levels[-1].BH\n\n    # Smooth the tentative prolongator, so that it's accuracy is greatly\n    # improved for algebraically smooth error.\n    fn, kwargs = unpack_arg(smooth[len(levels)-1])\n    if fn == 'energy':\n        P = energy_prolongation_smoother(A, T, C, B, levels[-1].B,\n                                         Cpt_params=Cpt_params, **kwargs)\n    elif fn is None:\n        P = T\n    else:\n        raise ValueError('unrecognized prolongation smoother \\\n                          method %s' % str(fn))\n\n    # Compute the restriction matrix R, which interpolates from the fine-grid\n    # to the coarse-grid.  If A is nonsymmetric, then R must be constructed\n    # based on A.H.  Otherwise R = P.H or P.T.\n    symmetry = A.symmetry\n    if symmetry == 'hermitian':\n        R = P.H\n    elif symmetry == 'symmetric':\n        R = P.T\n    elif symmetry == 'nonsymmetric':\n        fn, kwargs = unpack_arg(smooth[len(levels)-1])\n        if fn == 'energy':\n            R = energy_prolongation_smoother(AH, TH, C, BH, levels[-1].BH,\n                                             Cpt_params=Cpt_params, **kwargs)\n            R = R.H\n        elif fn is None:\n            R = T.H\n        else:\n            raise ValueError('unrecognized prolongation smoother \\\n                              method %s' % str(fn))\n\n    if keep:\n        levels[-1].C = C                      # strength of connection matrix\n        levels[-1].AggOp = AggOp                  # aggregation operator\n        levels[-1].T = T                      # tentative prolongator\n        levels[-1].Fpts = Cpt_params[1]['Fpts']  # Fpts\n        levels[-1].P_I = Cpt_params[1]['P_I']   # Injection operator\n        levels[-1].I_F = Cpt_params[1]['I_F']   # Identity on F-pts\n        levels[-1].I_C = Cpt_params[1]['I_C']   # Identity on C-pts\n\n    levels[-1].P = P                          # smoothed prolongator\n    levels[-1].R = R                          # restriction operator\n    levels[-1].Cpts = Cpt_params[1]['Cpts']      # Cpts (i.e., rootnodes)\n\n    levels.append(multilevel_solver.level())\n    A = R * A * P                                 # Galerkin operator\n    A.symmetry = symmetry\n    levels[-1].A = A\n    levels[-1].B = B                          # right near nullspace candidates\n\n    if A.symmetry == \"nonsymmetric\":\n        levels[-1].BH = BH", "response": "Extend the multigrid hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndistances based strength - of - connection.", "response": "def distance_strength_of_connection(A, V, theta=2.0, relative_drop=True):\n    \"\"\"Distance based strength-of-connection.\n\n    Parameters\n    ----------\n    A : csr_matrix or bsr_matrix\n        Square, sparse matrix in CSR or BSR format\n    V : array\n        Coordinates of the vertices of the graph of A\n    relative_drop : bool\n        If false, then a connection must be within a distance of theta\n        from a point to be strongly connected.\n        If true, then the closest connection is always strong, and other points\n        must be within theta times the smallest distance to be strong\n\n    Returns\n    -------\n    C : csr_matrix\n        C(i,j) = distance(point_i, point_j)\n        Strength of connection matrix where strength values are\n        distances, i.e. the smaller the value, the stronger the connection.\n        Sparsity pattern of C is copied from A.\n\n    Notes\n    -----\n    - theta is a drop tolerance that is applied row-wise\n    - If a BSR matrix given, then the return matrix is still CSR.  The strength\n      is given between super nodes based on the BSR block size.\n\n    Examples\n    --------\n    >>> from pyamg.gallery import load_example\n    >>> from pyamg.strength import distance_strength_of_connection\n    >>> data = load_example('airfoil')\n    >>> A = data['A'].tocsr()\n    >>> S = distance_strength_of_connection(data['A'], data['vertices'])\n\n    \"\"\"\n    # Amalgamate for the supernode case\n    if sparse.isspmatrix_bsr(A):\n        sn = int(A.shape[0] / A.blocksize[0])\n        u = np.ones((A.data.shape[0],))\n        A = sparse.csr_matrix((u, A.indices, A.indptr), shape=(sn, sn))\n\n    if not sparse.isspmatrix_csr(A):\n        warn(\"Implicit conversion of A to csr\", sparse.SparseEfficiencyWarning)\n        A = sparse.csr_matrix(A)\n\n    dim = V.shape[1]\n\n    # Create two arrays for differencing the different coordinates such\n    # that C(i,j) = distance(point_i, point_j)\n    cols = A.indices\n    rows = np.repeat(np.arange(A.shape[0]), A.indptr[1:] - A.indptr[0:-1])\n\n    # Insert difference for each coordinate into C\n    C = (V[rows, 0] - V[cols, 0])**2\n    for d in range(1, dim):\n        C += (V[rows, d] - V[cols, d])**2\n    C = np.sqrt(C)\n    C[C < 1e-6] = 1e-6\n\n    C = sparse.csr_matrix((C, A.indices.copy(), A.indptr.copy()),\n                          shape=A.shape)\n\n    # Apply drop tolerance\n    if relative_drop is True:\n        if theta != np.inf:\n            amg_core.apply_distance_filter(C.shape[0], theta, C.indptr,\n                                           C.indices, C.data)\n    else:\n        amg_core.apply_absolute_distance_filter(C.shape[0], theta, C.indptr,\n                                                C.indices, C.data)\n    C.eliminate_zeros()\n\n    C = C + sparse.eye(C.shape[0], C.shape[1], format='csr')\n\n    # Standardized strength values require small values be weak and large\n    # values be strong.  So, we invert the distances.\n    C.data = 1.0 / C.data\n\n    # Scale C by the largest magnitude entry in each row\n    C = scale_rows_by_largest_entry(C)\n\n    return C"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef classical_strength_of_connection(A, theta=0.0, norm='abs'):\n    if sparse.isspmatrix_bsr(A):\n        blocksize = A.blocksize[0]\n    else:\n        blocksize = 1\n\n    if not sparse.isspmatrix_csr(A):\n        warn(\"Implicit conversion of A to csr\", sparse.SparseEfficiencyWarning)\n        A = sparse.csr_matrix(A)\n\n    if (theta < 0 or theta > 1):\n        raise ValueError('expected theta in [0,1]')\n\n    Sp = np.empty_like(A.indptr)\n    Sj = np.empty_like(A.indices)\n    Sx = np.empty_like(A.data)\n\n    if norm == 'abs':\n        amg_core.classical_strength_of_connection_abs(\n            A.shape[0], theta, A.indptr, A.indices, A.data, Sp, Sj, Sx)\n    elif norm == 'min':\n        amg_core.classical_strength_of_connection_min(\n            A.shape[0], theta, A.indptr, A.indices, A.data, Sp, Sj, Sx)\n    else:\n        raise ValueError('Unknown norm')\n\n    S = sparse.csr_matrix((Sx, Sj, Sp), shape=A.shape)\n\n    if blocksize > 1:\n        S = amalgamate(S, blocksize)\n\n    # Strength represents \"distance\", so take the magnitude\n    S.data = np.abs(S.data)\n\n    # Scale S by the largest magnitude entry in each row\n    S = scale_rows_by_largest_entry(S)\n\n    return S", "response": "Classical Strength Measure.\n\n    Return a strength of connection matrix using the classical AMG measure\n    An off-diagonal entry A[i,j] is a strong connection iff::\n\n             A[i,j] >= theta * max(|A[i,k]|), where k != i     (norm='abs')\n            -A[i,j] >= theta * max(-A[i,k]),  where k != i     (norm='min')\n\n    Parameters\n    ----------\n    A : csr_matrix or bsr_matrix\n        Square, sparse matrix in CSR or BSR format\n    theta : float\n        Threshold parameter in [0,1].\n    norm: 'string'\n        'abs' : to use the absolute value,\n        'min' : to use the negative value (see above)\n\n    Returns\n    -------\n    S : csr_matrix\n        Matrix graph defining strong connections.  S[i,j]=1 if vertex i\n        is strongly influenced by vertex j.\n\n    See Also\n    --------\n    symmetric_strength_of_connection : symmetric measure used in SA\n    evolution_strength_of_connection : relaxation based strength measure\n\n    Notes\n    -----\n    - A symmetric A does not necessarily yield a symmetric strength matrix S\n    - Calls C++ function classical_strength_of_connection\n    - The version as implemented is designed form M-matrices.  Trottenberg et\n      al. use max A[i,k] over all negative entries, which is the same.  A\n      positive edge weight never indicates a strong connection.\n    - See [2000BrHeMc]_ and [2001bTrOoSc]_\n\n    References\n    ----------\n    .. [2000BrHeMc] Briggs, W. L., Henson, V. E., McCormick, S. F., \"A multigrid\n        tutorial\", Second edition. Society for Industrial and Applied\n        Mathematics (SIAM), Philadelphia, PA, 2000. xii+193 pp.\n\n    .. [2001bTrOoSc] Trottenberg, U., Oosterlee, C. W., Schuller, A., \"Multigrid\",\n        Academic Press, Inc., San Diego, CA, 2001. xvi+631 pp.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from pyamg.gallery import stencil_grid\n    >>> from pyamg.strength import classical_strength_of_connection\n    >>> n=3\n    >>> stencil = np.array([[-1.0,-1.0,-1.0],\n    ...                        [-1.0, 8.0,-1.0],\n    ...                        [-1.0,-1.0,-1.0]])\n    >>> A = stencil_grid(stencil, (n,n), format='csr')\n    >>> S = classical_strength_of_connection(A, 0.0)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef symmetric_strength_of_connection(A, theta=0):\n    if theta < 0:\n        raise ValueError('expected a positive theta')\n\n    if sparse.isspmatrix_csr(A):\n        # if theta == 0:\n        #     return A\n\n        Sp = np.empty_like(A.indptr)\n        Sj = np.empty_like(A.indices)\n        Sx = np.empty_like(A.data)\n\n        fn = amg_core.symmetric_strength_of_connection\n        fn(A.shape[0], theta, A.indptr, A.indices, A.data, Sp, Sj, Sx)\n\n        S = sparse.csr_matrix((Sx, Sj, Sp), shape=A.shape)\n\n    elif sparse.isspmatrix_bsr(A):\n        M, N = A.shape\n        R, C = A.blocksize\n\n        if R != C:\n            raise ValueError('matrix must have square blocks')\n\n        if theta == 0:\n            data = np.ones(len(A.indices), dtype=A.dtype)\n            S = sparse.csr_matrix((data, A.indices.copy(), A.indptr.copy()),\n                                  shape=(int(M / R), int(N / C)))\n        else:\n            # the strength of connection matrix is based on the\n            # Frobenius norms of the blocks\n            data = (np.conjugate(A.data) * A.data).reshape(-1, R * C)\n            data = data.sum(axis=1)\n            A = sparse.csr_matrix((data, A.indices, A.indptr),\n                                  shape=(int(M / R), int(N / C)))\n            return symmetric_strength_of_connection(A, theta)\n    else:\n        raise TypeError('expected csr_matrix or bsr_matrix')\n\n    # Strength represents \"distance\", so take the magnitude\n    S.data = np.abs(S.data)\n\n    # Scale S by the largest magnitude entry in each row\n    S = scale_rows_by_largest_entry(S)\n\n    return S", "response": "Symmetric Strength Measure.\n\n    Compute strength of connection matrix using the standard symmetric measure\n\n    An off-diagonal connection A[i,j] is strong iff::\n\n        abs(A[i,j]) >= theta * sqrt( abs(A[i,i]) * abs(A[j,j]) )\n\n    Parameters\n    ----------\n    A : csr_matrix\n        Matrix graph defined in sparse format.  Entry A[i,j] describes the\n        strength of edge [i,j]\n    theta : float\n        Threshold parameter (positive).\n\n    Returns\n    -------\n    S : csr_matrix\n        Matrix graph defining strong connections.  S[i,j]=1 if vertex i\n        is strongly influenced by vertex j.\n\n    See Also\n    --------\n    symmetric_strength_of_connection : symmetric measure used in SA\n    evolution_strength_of_connection : relaxation based strength measure\n\n    Notes\n    -----\n        - For vector problems, standard strength measures may produce\n          undesirable aggregates.  A \"block approach\" from Vanek et al. is used\n          to replace vertex comparisons with block-type comparisons.  A\n          connection between nodes i and j in the block case is strong if::\n\n          ||AB[i,j]|| >= theta * sqrt( ||AB[i,i]||*||AB[j,j]|| ) where AB[k,l]\n\n          is the matrix block (degrees of freedom) associated with nodes k and\n          l and ||.|| is a matrix norm, such a Frobenius.\n\n        - See [1996bVaMaBr]_ for more details.\n\n    References\n    ----------\n    .. [1996bVaMaBr] Vanek, P. and Mandel, J. and Brezina, M.,\n       \"Algebraic Multigrid by Smoothed Aggregation for\n       Second and Fourth Order Elliptic Problems\",\n       Computing, vol. 56, no. 3, pp. 179--196, 1996.\n       http://citeseer.ist.psu.edu/vanek96algebraic.html\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from pyamg.gallery import stencil_grid\n    >>> from pyamg.strength import symmetric_strength_of_connection\n    >>> n=3\n    >>> stencil = np.array([[-1.0,-1.0,-1.0],\n    ...                        [-1.0, 8.0,-1.0],\n    ...                        [-1.0,-1.0,-1.0]])\n    >>> A = stencil_grid(stencil, (n,n), format='csr')\n    >>> S = symmetric_strength_of_connection(A, 0.0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ode_strength_of_connection(A, B=None, epsilon=4.0, k=2, proj_type=\"l2\",\n                               block_flag=False, symmetrize_measure=True):\n    \"\"\"(deprecated) Use evolution_strength_of_connection instead.\"\"\"\n    return evolution_strength_of_connection(A, B, epsilon, k, proj_type,\n                                            block_flag, symmetrize_measure)", "response": "Deprecated use evolution_strength_of_connection instead."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconstructs a new evolution - based connection matrix.", "response": "def evolution_strength_of_connection(A, B=None, epsilon=4.0, k=2,\n                                     proj_type=\"l2\", block_flag=False,\n                                     symmetrize_measure=True):\n    \"\"\"Evolution Strength Measure.\n\n    Construct strength of connection matrix using an Evolution-based measure\n\n    Parameters\n    ----------\n    A : csr_matrix, bsr_matrix\n        Sparse NxN matrix\n    B : string, array\n        If B=None, then the near nullspace vector used is all ones.  If B is\n        an (NxK) array, then B is taken to be the near nullspace vectors.\n    epsilon : scalar\n        Drop tolerance\n    k : integer\n        ODE num time steps, step size is assumed to be 1/rho(DinvA)\n    proj_type : {'l2','D_A'}\n        Define norm for constrained min prob, i.e. define projection\n    block_flag : boolean\n        If True, use a block D inverse as preconditioner for A during\n        weighted-Jacobi\n\n    Returns\n    -------\n    Atilde : csr_matrix\n        Sparse matrix of strength values\n\n    See [2008OlScTu]_ for more details.\n\n    References\n    ----------\n    .. [2008OlScTu] Olson, L. N., Schroder, J., Tuminaro, R. S.,\n       \"A New Perspective on Strength Measures in Algebraic Multigrid\",\n       submitted, June, 2008.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from pyamg.gallery import stencil_grid\n    >>> from pyamg.strength import evolution_strength_of_connection\n    >>> n=3\n    >>> stencil =  np.array([[-1.0,-1.0,-1.0],\n    ...                        [-1.0, 8.0,-1.0],\n    ...                        [-1.0,-1.0,-1.0]])\n    >>> A = stencil_grid(stencil, (n,n), format='csr')\n    >>> S = evolution_strength_of_connection(A,  np.ones((A.shape[0],1)))\n\n    \"\"\"\n    # local imports for evolution_strength_of_connection\n    from pyamg.util.utils import scale_rows, get_block_diag, scale_columns\n    from pyamg.util.linalg import approximate_spectral_radius\n\n    # ====================================================================\n    # Check inputs\n    if epsilon < 1.0:\n        raise ValueError(\"expected epsilon > 1.0\")\n    if k <= 0:\n        raise ValueError(\"number of time steps must be > 0\")\n    if proj_type not in ['l2', 'D_A']:\n        raise ValueError(\"proj_type must be 'l2' or 'D_A'\")\n    if (not sparse.isspmatrix_csr(A)) and (not sparse.isspmatrix_bsr(A)):\n        raise TypeError(\"expected csr_matrix or bsr_matrix\")\n\n    # ====================================================================\n    # Format A and B correctly.\n    # B must be in mat format, this isn't a deep copy\n    if B is None:\n        Bmat = np.mat(np.ones((A.shape[0], 1), dtype=A.dtype))\n    else:\n        Bmat = np.mat(B)\n\n    # Pre-process A.  We need A in CSR, to be devoid of explicit 0's and have\n    # sorted indices\n    if (not sparse.isspmatrix_csr(A)):\n        csrflag = False\n        numPDEs = A.blocksize[0]\n        D = A.diagonal()\n        # Calculate Dinv*A\n        if block_flag:\n            Dinv = get_block_diag(A, blocksize=numPDEs, inv_flag=True)\n            Dinv = sparse.bsr_matrix((Dinv, np.arange(Dinv.shape[0]),\n                                      np.arange(Dinv.shape[0] + 1)),\n                                     shape=A.shape)\n            Dinv_A = (Dinv * A).tocsr()\n        else:\n            Dinv = np.zeros_like(D)\n            mask = (D != 0.0)\n            Dinv[mask] = 1.0 / D[mask]\n            Dinv[D == 0] = 1.0\n            Dinv_A = scale_rows(A, Dinv, copy=True)\n        A = A.tocsr()\n    else:\n        csrflag = True\n        numPDEs = 1\n        D = A.diagonal()\n        Dinv = np.zeros_like(D)\n        mask = (D != 0.0)\n        Dinv[mask] = 1.0 / D[mask]\n        Dinv[D == 0] = 1.0\n        Dinv_A = scale_rows(A, Dinv, copy=True)\n\n    A.eliminate_zeros()\n    A.sort_indices()\n\n    # Handle preliminaries for the algorithm\n    dimen = A.shape[1]\n    NullDim = Bmat.shape[1]\n\n    # Get spectral radius of Dinv*A, this will be used to scale the time step\n    # size for the ODE\n    rho_DinvA = approximate_spectral_radius(Dinv_A)\n\n    # Calculate D_A for later use in the minimization problem\n    if proj_type == \"D_A\":\n        D_A = sparse.spdiags([D], [0], dimen, dimen, format='csr')\n    else:\n        D_A = sparse.eye(dimen, dimen, format=\"csr\", dtype=A.dtype)\n\n    # Calculate (I - delta_t Dinv A)^k\n    #      In order to later access columns, we calculate the transpose in\n    #      CSR format so that columns will be accessed efficiently\n    # Calculate the number of time steps that can be done by squaring, and\n    # the number of time steps that must be done incrementally\n    nsquare = int(np.log2(k))\n    ninc = k - 2**nsquare\n\n    # Calculate one time step\n    Id = sparse.eye(dimen, dimen, format=\"csr\", dtype=A.dtype)\n    Atilde = (Id - (1.0 / rho_DinvA) * Dinv_A)\n    Atilde = Atilde.T.tocsr()\n\n    # Construct a sparsity mask for Atilde that will restrict Atilde^T to the\n    # nonzero pattern of A, with the added constraint that row i of Atilde^T\n    # retains only the nonzeros that are also in the same PDE as i.\n    mask = A.copy()\n\n    # Restrict to same PDE\n    if numPDEs > 1:\n        row_length = np.diff(mask.indptr)\n        my_pde = np.mod(np.arange(dimen), numPDEs)\n        my_pde = np.repeat(my_pde, row_length)\n        mask.data[np.mod(mask.indices, numPDEs) != my_pde] = 0.0\n        del row_length, my_pde\n        mask.eliminate_zeros()\n\n    # If the total number of time steps is a power of two, then there is\n    # a very efficient computational short-cut.  Otherwise, we support\n    # other numbers of time steps, through an inefficient algorithm.\n    if ninc > 0:\n        warn(\"The most efficient time stepping for the Evolution Strength\\\n             Method is done in powers of two.\\nYou have chosen \" + str(k) +\n             \" time steps.\")\n\n        # Calculate (Atilde^nsquare)^T = (Atilde^T)^nsquare\n        for i in range(nsquare):\n            Atilde = Atilde * Atilde\n\n        JacobiStep = (Id - (1.0 / rho_DinvA) * Dinv_A).T.tocsr()\n        for i in range(ninc):\n            Atilde = Atilde * JacobiStep\n        del JacobiStep\n\n        # Apply mask to Atilde, zeros in mask have already been eliminated at\n        # start of routine.\n        mask.data[:] = 1.0\n        Atilde = Atilde.multiply(mask)\n        Atilde.eliminate_zeros()\n        Atilde.sort_indices()\n\n    elif nsquare == 0:\n        if numPDEs > 1:\n            # Apply mask to Atilde, zeros in mask have already been eliminated\n            # at start of routine.\n            mask.data[:] = 1.0\n            Atilde = Atilde.multiply(mask)\n            Atilde.eliminate_zeros()\n            Atilde.sort_indices()\n\n    else:\n        # Use computational short-cut for case (ninc == 0) and (nsquare > 0)\n        # Calculate Atilde^k only at the sparsity pattern of mask.\n        for i in range(nsquare - 1):\n            Atilde = Atilde * Atilde\n\n        # Call incomplete mat-mat mult\n        AtildeCSC = Atilde.tocsc()\n        AtildeCSC.sort_indices()\n        mask.sort_indices()\n        Atilde.sort_indices()\n        amg_core.incomplete_mat_mult_csr(Atilde.indptr, Atilde.indices,\n                                         Atilde.data, AtildeCSC.indptr,\n                                         AtildeCSC.indices, AtildeCSC.data,\n                                         mask.indptr, mask.indices, mask.data,\n                                         dimen)\n\n        del AtildeCSC, Atilde\n        Atilde = mask\n        Atilde.eliminate_zeros()\n        Atilde.sort_indices()\n\n    del Dinv, Dinv_A, mask\n\n    # Calculate strength based on constrained min problem of\n    # min( z - B*x ), such that\n    # (B*x)|_i = z|_i, i.e. they are equal at point i\n    # z = (I - (t/k) Dinv A)^k delta_i\n    #\n    # Strength is defined as the relative point-wise approx. error between\n    # B*x and z.  We don't use the full z in this problem, only that part of\n    # z that is in the sparsity pattern of A.\n    #\n    # Can use either the D-norm, and inner product, or l2-norm and inner-prod\n    # to solve the constrained min problem.  Using D gives scale invariance.\n    #\n    # This is a quadratic minimization problem with a linear constraint, so\n    # we can build a linear system and solve it to find the critical point,\n    # i.e. minimum.\n    #\n    # We exploit a known shortcut for the case of NullDim = 1.  The shortcut is\n    # mathematically equivalent to the longer constrained min. problem\n\n    if NullDim == 1:\n        # Use shortcut to solve constrained min problem if B is only a vector\n        # Strength(i,j) = | 1 - (z(i)/b(j))/(z(j)/b(i)) |\n        # These ratios can be calculated by diagonal row and column scalings\n\n        # Create necessary vectors for scaling Atilde\n        #   Its not clear what to do where B == 0.  This is an\n        #   an easy programming solution, that may make sense.\n        Bmat_forscaling = np.ravel(Bmat)\n        Bmat_forscaling[Bmat_forscaling == 0] = 1.0\n        DAtilde = Atilde.diagonal()\n        DAtildeDivB = np.ravel(DAtilde) / Bmat_forscaling\n\n        # Calculate best approximation, z_tilde, in span(B)\n        #   Importantly, scale_rows and scale_columns leave zero entries\n        #   in the matrix.  For previous implementations this was useful\n        #   because we assume data and Atilde.data are the same length below\n        data = Atilde.data.copy()\n        Atilde.data[:] = 1.0\n        Atilde = scale_rows(Atilde, DAtildeDivB)\n        Atilde = scale_columns(Atilde, np.ravel(Bmat_forscaling))\n\n        # If angle in the complex plane between z and z_tilde is\n        # greater than 90 degrees, then weak.  We can just look at the\n        # dot product to determine if angle is greater than 90 degrees.\n        angle = np.multiply(np.real(Atilde.data), np.real(data)) +\\\n            np.multiply(np.imag(Atilde.data), np.imag(data))\n        angle = angle < 0.0\n        angle = np.array(angle, dtype=bool)\n\n        # Calculate Approximation ratio\n        Atilde.data = Atilde.data / data\n\n        # If approximation ratio is less than tol, then weak connection\n        weak_ratio = (np.abs(Atilde.data) < 1e-4)\n\n        # Calculate Approximation error\n        Atilde.data = abs(1.0 - Atilde.data)\n\n        # Set small ratios and large angles to weak\n        Atilde.data[weak_ratio] = 0.0\n        Atilde.data[angle] = 0.0\n\n        # Set near perfect connections to 1e-4\n        Atilde.eliminate_zeros()\n        Atilde.data[Atilde.data < np.sqrt(np.finfo(float).eps)] = 1e-4\n\n        del data, weak_ratio, angle\n\n    else:\n        # For use in computing local B_i^H*B, precompute the element-wise\n        # multiply of each column of B with each other column.  We also scale\n        # by 2.0 to account for BDB's eventual use in a constrained\n        # minimization problem\n        BDBCols = int(np.sum(np.arange(NullDim + 1)))\n        BDB = np.zeros((dimen, BDBCols), dtype=A.dtype)\n        counter = 0\n        for i in range(NullDim):\n            for j in range(i, NullDim):\n                BDB[:, counter] = 2.0 *\\\n                    (np.conjugate(np.ravel(np.asarray(B[:, i]))) *\n                        np.ravel(np.asarray(D_A * B[:, j])))\n                counter = counter + 1\n\n        # Choose tolerance for dropping \"numerically zero\" values later\n        t = Atilde.dtype.char\n        eps = np.finfo(np.float).eps\n        feps = np.finfo(np.single).eps\n        geps = np.finfo(np.longfloat).eps\n        _array_precision = {'f': 0, 'd': 1, 'g': 2, 'F': 0, 'D': 1, 'G': 2}\n        tol = {0: feps * 1e3, 1: eps * 1e6, 2: geps * 1e6}[_array_precision[t]]\n\n        # Use constrained min problem to define strength\n        amg_core.evolution_strength_helper(Atilde.data,\n                                           Atilde.indptr,\n                                           Atilde.indices,\n                                           Atilde.shape[0],\n                                           np.ravel(np.asarray(B)),\n                                           np.ravel(np.asarray(\n                                               (D_A * np.conjugate(B)).T)),\n                                           np.ravel(np.asarray(BDB)),\n                                           BDBCols, NullDim, tol)\n\n        Atilde.eliminate_zeros()\n\n    # All of the strength values are real by this point, so ditch the complex\n    # part\n    Atilde.data = np.array(np.real(Atilde.data), dtype=float)\n\n    # Apply drop tolerance\n    if epsilon != np.inf:\n        amg_core.apply_distance_filter(dimen, epsilon, Atilde.indptr,\n                                       Atilde.indices, Atilde.data)\n        Atilde.eliminate_zeros()\n\n    # Symmetrize\n    if symmetrize_measure:\n        Atilde = 0.5 * (Atilde + Atilde.T)\n\n    # Set diagonal to 1.0, as each point is strongly connected to itself.\n    Id = sparse.eye(dimen, dimen, format=\"csr\")\n    Id.data -= Atilde.diagonal()\n    Atilde = Atilde + Id\n\n    # If converted BSR to CSR, convert back and return amalgamated matrix,\n    #   i.e. the sparsity structure of the blocks of Atilde\n    if not csrflag:\n        Atilde = Atilde.tobsr(blocksize=(numPDEs, numPDEs))\n\n        n_blocks = Atilde.indices.shape[0]\n        blocksize = Atilde.blocksize[0] * Atilde.blocksize[1]\n        CSRdata = np.zeros((n_blocks,))\n        amg_core.min_blocks(n_blocks, blocksize,\n                            np.ravel(np.asarray(Atilde.data)), CSRdata)\n        # Atilde = sparse.csr_matrix((data, row, col), shape=(*,*))\n        Atilde = sparse.csr_matrix((CSRdata, Atilde.indices, Atilde.indptr),\n                                   shape=(int(Atilde.shape[0] / numPDEs),\n                                          int(Atilde.shape[1] / numPDEs)))\n\n    # Standardized strength values require small values be weak and large\n    # values be strong.  So, we invert the algebraic distances computed here\n    Atilde.data = 1.0 / Atilde.data\n\n    # Scale C by the largest magnitude entry in each row\n    Atilde = scale_rows_by_largest_entry(Atilde)\n\n    return Atilde"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating test vectors by relaxing on Ax = 0 for some random vectors x.", "response": "def relaxation_vectors(A, R, k, alpha):\n    \"\"\"Generate test vectors by relaxing on Ax=0 for some random vectors x.\n\n    Parameters\n    ----------\n    A : csr_matrix\n        Sparse NxN matrix\n    alpha : scalar\n        Weight for Jacobi\n    R : integer\n        Number of random vectors\n    k : integer\n        Number of relaxation passes\n\n    Returns\n    -------\n    x : array\n        Dense array N x k array of relaxation vectors\n\n    \"\"\"\n    # random n x R block in column ordering\n    n = A.shape[0]\n    x = np.random.rand(n * R) - 0.5\n    x = np.reshape(x, (n, R), order='F')\n    # for i in range(R):\n    #     x[:,i] = x[:,i] - np.mean(x[:,i])\n    b = np.zeros((n, 1))\n\n    for r in range(0, R):\n        jacobi(A, x[:, r], b, iterations=k, omega=alpha)\n        # x[:,r] = x[:,r]/norm(x[:,r])\n\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the affinity distance of the given set of random vectors.", "response": "def affinity_distance(A, alpha=0.5, R=5, k=20, epsilon=4.0):\n    \"\"\"Affinity Distance Strength Measure.\n\n    Parameters\n    ----------\n    A : csr_matrix\n        Sparse NxN matrix\n    alpha : scalar\n        Weight for Jacobi\n    R : integer\n        Number of random vectors\n    k : integer\n        Number of relaxation passes\n    epsilon : scalar\n        Drop tolerance\n\n    Returns\n    -------\n    C : csr_matrix\n        Sparse matrix of strength values\n\n    References\n    ----------\n    .. [LiBr] Oren E. Livne and Achi Brandt, \"Lean Algebraic Multigrid\n        (LAMG): Fast Graph Laplacian Linear Solver\"\n\n    Notes\n    -----\n    No unit testing yet.\n\n    Does not handle BSR matrices yet.\n\n    See [LiBr]_ for more details.\n\n    \"\"\"\n    if not sparse.isspmatrix_csr(A):\n        A = sparse.csr_matrix(A)\n\n    if alpha < 0:\n        raise ValueError('expected alpha>0')\n\n    if R <= 0 or not isinstance(R, int):\n        raise ValueError('expected integer R>0')\n\n    if k <= 0 or not isinstance(k, int):\n        raise ValueError('expected integer k>0')\n\n    if epsilon < 1:\n        raise ValueError('expected epsilon>1.0')\n\n    def distance(x):\n        (rows, cols) = A.nonzero()\n        return 1 - np.sum(x[rows] * x[cols], axis=1)**2 / \\\n            (np.sum(x[rows]**2, axis=1) * np.sum(x[cols]**2, axis=1))\n\n    return distance_measure_common(A, distance, alpha, R, k, epsilon)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef distance_measure_common(A, func, alpha, R, k, epsilon):\n    # create test vectors\n    x = relaxation_vectors(A, R, k, alpha)\n\n    # apply distance measure function to vectors\n    d = func(x)\n\n    # drop distances to self\n    (rows, cols) = A.nonzero()\n    weak = np.where(rows == cols)[0]\n    d[weak] = 0\n    C = sparse.csr_matrix((d, (rows, cols)), shape=A.shape)\n    C.eliminate_zeros()\n\n    # remove weak connections\n    # removes entry e from a row if e > theta * min of all entries in the row\n    amg_core.apply_distance_filter(C.shape[0], epsilon, C.indptr,\n                                   C.indices, C.data)\n    C.eliminate_zeros()\n\n    # Standardized strength values require small values be weak and large\n    # values be strong.  So, we invert the distances.\n    C.data = 1.0 / C.data\n\n    # Put an identity on the diagonal\n    C = C + sparse.eye(C.shape[0], C.shape[1], format='csr')\n\n    # Scale C by the largest magnitude entry in each row\n    C = scale_rows_by_largest_entry(C)\n\n    return C", "response": "Create strength of connection matrixfrom a function applied to relaxation vectors."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef richardson_prolongation_smoother(S, T, omega=4.0/3.0, degree=1):\n    weight = omega/approximate_spectral_radius(S)\n\n    P = T\n    for i in range(degree):\n        P = P - weight*(S*P)\n\n    return P", "response": "Richardson prolongation smoother.\n\n    Parameters\n    ----------\n    S : csr_matrix, bsr_matrix\n        Sparse NxN matrix used for smoothing.  Typically, A or the\n        \"filtered matrix\" obtained from A by lumping weak connections\n        onto the diagonal of A.\n    T : csr_matrix, bsr_matrix\n        Tentative prolongator\n    omega : scalar\n        Damping parameter\n\n    Returns\n    -------\n    P : csr_matrix, bsr_matrix\n        Smoothed (final) prolongator defined by P = (I - omega/rho(S) S) * T\n        where rho(S) is an approximation to the spectral radius of S.\n\n    Notes\n    -----\n    Results using Richardson prolongation smoother are not precisely\n    reproducible due to a random initial guess used for the spectral radius\n    approximation.  For precise reproducibility, set numpy.random.seed(..) to\n    the same value before each test.\n\n\n    Examples\n    --------\n    >>> from pyamg.aggregation import richardson_prolongation_smoother\n    >>> from pyamg.gallery import poisson\n    >>> from scipy.sparse import coo_matrix\n    >>> import numpy as np\n    >>> data = np.ones((6,))\n    >>> row = np.arange(0,6)\n    >>> col = np.kron([0,1],np.ones((3,)))\n    >>> T = coo_matrix((data,(row,col)),shape=(6,2)).tocsr()\n    >>> T.todense()\n    matrix([[ 1.,  0.],\n            [ 1.,  0.],\n            [ 1.,  0.],\n            [ 0.,  1.],\n            [ 0.,  1.],\n            [ 0.,  1.]])\n    >>> A = poisson((6,),format='csr')\n    >>> P = richardson_prolongation_smoother(A,T)\n    >>> P.todense()\n    matrix([[ 0.64930164,  0.        ],\n            [ 1.        ,  0.        ],\n            [ 0.64930164,  0.35069836],\n            [ 0.35069836,  0.64930164],\n            [ 0.        ,  1.        ],\n            [ 0.        ,  0.64930164]])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cg_prolongation_smoothing(A, T, B, BtBinv, Sparsity_Pattern, maxiter, tol,\n                              weighting='local', Cpt_params=None):\n    \"\"\"Use CG to smooth T by solving A T = 0, subject to nullspace and sparsity constraints.\n\n    Parameters\n    ----------\n    A : csr_matrix, bsr_matrix\n        SPD sparse NxN matrix\n    T : bsr_matrix\n        Tentative prolongator, a NxM sparse matrix (M < N).\n        This is initial guess for the equation A T = 0.\n        Assumed that T B_c = B_f\n    B : array\n        Near-nullspace modes for coarse grid, i.e., B_c.\n        Has shape (M,k) where k is the number of coarse candidate vectors.\n    BtBinv : array\n        3 dimensional array such that,\n        BtBinv[i] = pinv(B_i.H Bi), and B_i is B restricted\n        to the neighborhood (in the matrix graph) of dof of i.\n    Sparsity_Pattern : csr_matrix, bsr_matrix\n        Sparse NxM matrix\n        This is the sparsity pattern constraint to enforce on the\n        eventual prolongator\n    maxiter : int\n        maximum number of iterations\n    tol : float\n        residual tolerance for A T = 0\n    weighting : string\n        'block', 'diagonal' or 'local' construction of the diagonal\n        preconditioning\n    Cpt_params : tuple\n        Tuple of the form (bool, dict).  If the Cpt_params[0] = False, then\n        the standard SA prolongation smoothing is carried out.  If True, then\n        dict must be a dictionary of parameters containing, (1) P_I: P_I.T is\n        the injection matrix for the Cpts, (2) I_F: an identity matrix\n        for only the F-points (i.e. I, but with zero rows and columns for\n        C-points) and I_C: the C-point analogue to I_F.\n\n    Returns\n    -------\n    T : bsr_matrix\n        Smoothed prolongator using conjugate gradients to solve A T = 0,\n        subject to the constraints, T B_c = B_f, and T has no nonzero\n        outside of the sparsity pattern in Sparsity_Pattern.\n\n    See Also\n    --------\n    The principal calling routine,\n    pyamg.aggregation.smooth.energy_prolongation_smoother\n\n    \"\"\"\n    # Preallocate\n    AP = sparse.bsr_matrix((np.zeros(Sparsity_Pattern.data.shape,\n                                     dtype=T.dtype),\n                            Sparsity_Pattern.indices, Sparsity_Pattern.indptr),\n                           shape=(Sparsity_Pattern.shape))\n\n    # CG will be run with diagonal preconditioning\n    if weighting == 'diagonal':\n        Dinv = get_diagonal(A, norm_eq=False, inv=True)\n    elif weighting == 'block':\n        Dinv = get_block_diag(A, blocksize=A.blocksize[0], inv_flag=True)\n        Dinv = sparse.bsr_matrix((Dinv, np.arange(Dinv.shape[0]),\n                                  np.arange(Dinv.shape[0]+1)),\n                                 shape=A.shape)\n    elif weighting == 'local':\n        # Based on Gershgorin estimate\n        D = np.abs(A)*np.ones((A.shape[0], 1), dtype=A.dtype)\n        Dinv = np.zeros_like(D)\n        Dinv[D != 0] = 1.0 / np.abs(D[D != 0])\n    else:\n        raise ValueError('weighting value is invalid')\n\n    # Calculate initial residual\n    #   Equivalent to R = -A*T;    R = R.multiply(Sparsity_Pattern)\n    #   with the added constraint that R has an explicit 0 wherever\n    #   R is 0 and Sparsity_Pattern is not\n    uones = np.zeros(Sparsity_Pattern.data.shape, dtype=T.dtype)\n    R = sparse.bsr_matrix((uones, Sparsity_Pattern.indices,\n                           Sparsity_Pattern.indptr),\n                          shape=(Sparsity_Pattern.shape))\n    pyamg.amg_core.incomplete_mat_mult_bsr(A.indptr, A.indices,\n                                           np.ravel(A.data),\n                                           T.indptr, T.indices,\n                                           np.ravel(T.data),\n                                           R.indptr, R.indices,\n                                           np.ravel(R.data),\n                                           int(T.shape[0]/T.blocksize[0]),\n                                           int(T.shape[1]/T.blocksize[1]),\n                                           A.blocksize[0], A.blocksize[1],\n                                           T.blocksize[1])\n    R.data *= -1.0\n\n    # Enforce R*B = 0\n    Satisfy_Constraints(R, B, BtBinv)\n\n    if R.nnz == 0:\n        print(\"Error in sa_energy_min(..).  Initial R no nonzeros on a level. \\\n               Returning tentative prolongator\\n\")\n        return T\n\n    # Calculate Frobenius norm of the residual\n    resid = R.nnz  # np.sqrt((R.data.conjugate()*R.data).sum())\n    # print \"Energy Minimization of Prolongator \\\n    #       --- Iteration 0 --- r = \" + str(resid)\n\n    i = 0\n    while i < maxiter and resid > tol:\n        # Apply diagonal preconditioner\n        if weighting == 'local' or weighting == 'diagonal':\n            Z = scale_rows(R, Dinv)\n        else:\n            Z = Dinv*R\n\n        # Frobenius inner-product of (R,Z) = sum( np.conjugate(rk).*zk)\n        newsum = (R.conjugate().multiply(Z)).sum()\n        if newsum < tol:\n            # met tolerance, so halt\n            break\n\n        # P is the search direction, not the prolongator, which is T.\n        if(i == 0):\n            P = Z\n            oldsum = newsum\n        else:\n            beta = newsum / oldsum\n            P = Z + beta*P\n        oldsum = newsum\n\n        # Calculate new direction and enforce constraints\n        #   Equivalent to:  AP = A*P;    AP = AP.multiply(Sparsity_Pattern)\n        #   with the added constraint that explicit zeros are in AP wherever\n        #   AP = 0 and Sparsity_Pattern does not  !!!!\n        AP.data[:] = 0.0\n        pyamg.amg_core.incomplete_mat_mult_bsr(A.indptr, A.indices,\n                                               np.ravel(A.data),\n                                               P.indptr, P.indices,\n                                               np.ravel(P.data),\n                                               AP.indptr, AP.indices,\n                                               np.ravel(AP.data),\n                                               int(T.shape[0]/T.blocksize[0]),\n                                               int(T.shape[1]/T.blocksize[1]),\n                                               A.blocksize[0], A.blocksize[1],\n                                               P.blocksize[1])\n\n        # Enforce AP*B = 0\n        Satisfy_Constraints(AP, B, BtBinv)\n\n        # Frobenius inner-product of (P, AP)\n        alpha = newsum/(P.conjugate().multiply(AP)).sum()\n\n        # Update the prolongator, T\n        T = T + alpha*P\n\n        # Ensure identity at C-pts\n        if Cpt_params[0]:\n            T = Cpt_params[1]['I_F']*T + Cpt_params[1]['P_I']\n\n        # Update residual\n        R = R - alpha*AP\n\n        i += 1\n\n        # Calculate Frobenius norm of the residual\n        resid = R.nnz  # np.sqrt((R.data.conjugate()*R.data).sum())\n        # print \"Energy Minimization of Prolongator \\\n        # --- Iteration \" + str(i) + \" --- r = \" + str(resid)\n\n    return T", "response": "Use CG to smooth A T by solving A T = 0 subject to nullspace and sparsity constraints."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuses CGNR to smooth A T B BtBinv and Sparsity_Pattern to solve A T = 0 subject to nullspace and sparsity constraints.", "response": "def cgnr_prolongation_smoothing(A, T, B, BtBinv, Sparsity_Pattern, maxiter,\n                                tol, weighting='local', Cpt_params=None):\n    \"\"\"Use CGNR to smooth T by solving A T = 0, subject to nullspace and sparsity constraints.\n\n    Parameters\n    ----------\n    A : csr_matrix, bsr_matrix\n        SPD sparse NxN matrix\n        Should be at least nonsymmetric or indefinite\n    T : bsr_matrix\n        Tentative prolongator, a NxM sparse matrix (M < N).\n        This is initial guess for the equation A T = 0.\n        Assumed that T B_c = B_f\n    B : array\n        Near-nullspace modes for coarse grid, i.e., B_c.\n        Has shape (M,k) where k is the number of coarse candidate vectors.\n    BtBinv : array\n        3 dimensional array such that,\n        BtBinv[i] = pinv(B_i.H Bi), and B_i is B restricted\n        to the neighborhood (in the matrix graph) of dof of i.\n    Sparsity_Pattern : csr_matrix, bsr_matrix\n        Sparse NxM matrix\n        This is the sparsity pattern constraint to enforce on the\n        eventual prolongator\n    maxiter : int\n        maximum number of iterations\n    tol : float\n        residual tolerance for A T = 0\n    weighting : string\n        'block', 'diagonal' or 'local' construction of the diagonal\n        preconditioning\n        IGNORED here, only 'diagonal' preconditioning is used.\n    Cpt_params : tuple\n        Tuple of the form (bool, dict).  If the Cpt_params[0] = False, then\n        the standard SA prolongation smoothing is carried out.  If True, then\n        dict must be a dictionary of parameters containing, (1) P_I: P_I.T is\n        the injection matrix for the Cpts, (2) I_F: an identity matrix\n        for only the F-points (i.e. I, but with zero rows and columns for\n        C-points) and I_C: the C-point analogue to I_F.\n\n    Returns\n    -------\n    T : bsr_matrix\n        Smoothed prolongator using CGNR to solve A T = 0,\n        subject to the constraints, T B_c = B_f, and T has no nonzero\n        outside of the sparsity pattern in Sparsity_Pattern.\n\n    See Also\n    --------\n    The principal calling routine,\n    pyamg.aggregation.smooth.energy_prolongation_smoother\n\n    \"\"\"\n    # For non-SPD system, apply CG on Normal Equations with Diagonal\n    # Preconditioning (requires transpose)\n    Ah = A.H\n    Ah.sort_indices()\n\n    # Preallocate\n    uones = np.zeros(Sparsity_Pattern.data.shape, dtype=T.dtype)\n    AP = sparse.bsr_matrix((uones, Sparsity_Pattern.indices,\n                            Sparsity_Pattern.indptr),\n                           shape=(Sparsity_Pattern.shape))\n\n    # D for A.H*A\n    Dinv = get_diagonal(A, norm_eq=1, inv=True)\n\n    # Calculate initial residual\n    #   Equivalent to R = -Ah*(A*T);    R = R.multiply(Sparsity_Pattern)\n    #   with the added constraint that R has an explicit 0 wherever\n    #   R is 0 and Sparsity_Pattern is not\n    uones = np.zeros(Sparsity_Pattern.data.shape, dtype=T.dtype)\n    R = sparse.bsr_matrix((uones, Sparsity_Pattern.indices,\n                           Sparsity_Pattern.indptr),\n                          shape=(Sparsity_Pattern.shape))\n    AT = -1.0*A*T\n    R.data[:] = 0.0\n    pyamg.amg_core.incomplete_mat_mult_bsr(Ah.indptr, Ah.indices,\n                                           np.ravel(Ah.data),\n                                           AT.indptr, AT.indices,\n                                           np.ravel(AT.data),\n                                           R.indptr, R.indices,\n                                           np.ravel(R.data),\n                                           int(T.shape[0]/T.blocksize[0]),\n                                           int(T.shape[1]/T.blocksize[1]),\n                                           Ah.blocksize[0], Ah.blocksize[1],\n                                           T.blocksize[1])\n\n    # Enforce R*B = 0\n    Satisfy_Constraints(R, B, BtBinv)\n\n    if R.nnz == 0:\n        print(\"Error in sa_energy_min(..).  Initial R no nonzeros on a level. \\\n               Returning tentative prolongator\\n\")\n        return T\n\n    # Calculate Frobenius norm of the residual\n    resid = R.nnz  # np.sqrt((R.data.conjugate()*R.data).sum())\n    # print \"Energy Minimization of Prolongator \\\n    # --- Iteration 0 --- r = \" + str(resid)\n\n    i = 0\n    while i < maxiter and resid > tol:\n\n        # vect = np.ravel((A*T).data)\n        # print \"Iteration \" + str(i) + \"   \\\n        # Energy = %1.3e\"%np.sqrt( (vect.conjugate()*vect).sum() )\n\n        # Apply diagonal preconditioner\n        Z = scale_rows(R, Dinv)\n\n        # Frobenius innerproduct of (R,Z) = sum(rk.*zk)\n        newsum = (R.conjugate().multiply(Z)).sum()\n        if newsum < tol:\n            # met tolerance, so halt\n            break\n\n        # P is the search direction, not the prolongator, which is T.\n        if(i == 0):\n            P = Z\n            oldsum = newsum\n        else:\n            beta = newsum/oldsum\n            P = Z + beta*P\n        oldsum = newsum\n\n        # Calculate new direction\n        #  Equivalent to:  AP = Ah*(A*P);    AP = AP.multiply(Sparsity_Pattern)\n        #  with the added constraint that explicit zeros are in AP wherever\n        #  AP = 0 and Sparsity_Pattern does not\n        AP_temp = A*P\n        AP.data[:] = 0.0\n        pyamg.amg_core.incomplete_mat_mult_bsr(Ah.indptr, Ah.indices,\n                                               np.ravel(Ah.data),\n                                               AP_temp.indptr, AP_temp.indices,\n                                               np.ravel(AP_temp.data),\n                                               AP.indptr, AP.indices,\n                                               np.ravel(AP.data),\n                                               int(T.shape[0]/T.blocksize[0]),\n                                               int(T.shape[1]/T.blocksize[1]),\n                                               Ah.blocksize[0],\n                                               Ah.blocksize[1], T.blocksize[1])\n        del AP_temp\n\n        # Enforce AP*B = 0\n        Satisfy_Constraints(AP, B, BtBinv)\n\n        # Frobenius inner-product of (P, AP)\n        alpha = newsum/(P.conjugate().multiply(AP)).sum()\n\n        # Update the prolongator, T\n        T = T + alpha*P\n\n        # Ensure identity at C-pts\n        if Cpt_params[0]:\n            T = Cpt_params[1]['I_F']*T + Cpt_params[1]['P_I']\n\n        # Update residual\n        R = R - alpha*AP\n\n        i += 1\n\n        # Calculate Frobenius norm of the residual\n        resid = R.nnz  # np.sqrt((R.data.conjugate()*R.data).sum())\n        # print \"Energy Minimization of Prolongator \\\n        # --- Iteration \" + str(i) + \" --- r = \" + str(resid)\n\n    # vect = np.ravel((A*T).data)\n    # print \"Final Iteration \" + str(i) + \"   \\\n    # Energy = %1.3e\"%np.sqrt( (vect.conjugate()*vect).sum() )\n\n    return T"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gmres_prolongation_smoothing(A, T, B, BtBinv, Sparsity_Pattern, maxiter,\n                                 tol, weighting='local', Cpt_params=None):\n    \"\"\"Use GMRES to smooth T by solving A T = 0, subject to nullspace and sparsity constraints.\n\n    Parameters\n    ----------\n    A : csr_matrix, bsr_matrix\n        SPD sparse NxN matrix\n        Should be at least nonsymmetric or indefinite\n    T : bsr_matrix\n        Tentative prolongator, a NxM sparse matrix (M < N).\n        This is initial guess for the equation A T = 0.\n        Assumed that T B_c = B_f\n    B : array\n        Near-nullspace modes for coarse grid, i.e., B_c.\n        Has shape (M,k) where k is the number of coarse candidate vectors.\n    BtBinv : array\n        3 dimensional array such that,\n        BtBinv[i] = pinv(B_i.H Bi), and B_i is B restricted\n        to the neighborhood (in the matrix graph) of dof of i.\n    Sparsity_Pattern : csr_matrix, bsr_matrix\n        Sparse NxM matrix\n        This is the sparsity pattern constraint to enforce on the\n        eventual prolongator\n    maxiter : int\n        maximum number of iterations\n    tol : float\n        residual tolerance for A T = 0\n    weighting : string\n        'block', 'diagonal' or 'local' construction of the diagonal\n        preconditioning\n    Cpt_params : tuple\n        Tuple of the form (bool, dict).  If the Cpt_params[0] = False, then\n        the standard SA prolongation smoothing is carried out.  If True, then\n        dict must be a dictionary of parameters containing, (1) P_I: P_I.T is\n        the injection matrix for the Cpts, (2) I_F: an identity matrix\n        for only the F-points (i.e. I, but with zero rows and columns for\n        C-points) and I_C: the C-point analogue to I_F.\n\n    Returns\n    -------\n    T : bsr_matrix\n        Smoothed prolongator using GMRES to solve A T = 0,\n        subject to the constraints, T B_c = B_f, and T has no nonzero\n        outside of the sparsity pattern in Sparsity_Pattern.\n\n    See Also\n    --------\n    The principal calling routine,\n    pyamg.aggregation.smooth.energy_prolongation_smoother\n\n    \"\"\"\n    # For non-SPD system, apply GMRES with Diagonal Preconditioning\n\n    # Preallocate space for new search directions\n    uones = np.zeros(Sparsity_Pattern.data.shape, dtype=T.dtype)\n    AV = sparse.bsr_matrix((uones, Sparsity_Pattern.indices,\n                            Sparsity_Pattern.indptr),\n                           shape=(Sparsity_Pattern.shape))\n\n    # Preallocate for Givens Rotations, Hessenberg matrix and Krylov Space\n    xtype = sparse.sputils.upcast(A.dtype, T.dtype, B.dtype)\n    Q = []      # Givens Rotations\n    V = []      # Krylov Space\n    # vs = []     # vs store the pointers to each column of V for speed\n\n    # Upper Hessenberg matrix, converted to upper tri with Givens Rots\n    H = np.zeros((maxiter+1, maxiter+1), dtype=xtype)\n\n    # GMRES will be run with diagonal preconditioning\n    if weighting == 'diagonal':\n        Dinv = get_diagonal(A, norm_eq=False, inv=True)\n    elif weighting == 'block':\n        Dinv = get_block_diag(A, blocksize=A.blocksize[0], inv_flag=True)\n        Dinv = sparse.bsr_matrix((Dinv, np.arange(Dinv.shape[0]),\n                                  np.arange(Dinv.shape[0]+1)),\n                                 shape=A.shape)\n    elif weighting == 'local':\n        # Based on Gershgorin estimate\n        D = np.abs(A)*np.ones((A.shape[0], 1), dtype=A.dtype)\n        Dinv = np.zeros_like(D)\n        Dinv[D != 0] = 1.0 / np.abs(D[D != 0])\n    else:\n        raise ValueError('weighting value is invalid')\n\n    # Calculate initial residual\n    #   Equivalent to R = -A*T;    R = R.multiply(Sparsity_Pattern)\n    #   with the added constraint that R has an explicit 0 wherever\n    #   R is 0 and Sparsity_Pattern is not\n    uones = np.zeros(Sparsity_Pattern.data.shape, dtype=T.dtype)\n    R = sparse.bsr_matrix((uones, Sparsity_Pattern.indices,\n                           Sparsity_Pattern.indptr),\n                          shape=(Sparsity_Pattern.shape))\n    pyamg.amg_core.incomplete_mat_mult_bsr(A.indptr, A.indices,\n                                           np.ravel(A.data),\n                                           T.indptr, T.indices,\n                                           np.ravel(T.data),\n                                           R.indptr, R.indices,\n                                           np.ravel(R.data),\n                                           int(T.shape[0]/T.blocksize[0]),\n                                           int(T.shape[1]/T.blocksize[1]),\n                                           A.blocksize[0], A.blocksize[1],\n                                           T.blocksize[1])\n    R.data *= -1.0\n\n    # Apply diagonal preconditioner\n    if weighting == 'local' or weighting == 'diagonal':\n        R = scale_rows(R, Dinv)\n    else:\n        R = Dinv*R\n\n    # Enforce R*B = 0\n    Satisfy_Constraints(R, B, BtBinv)\n\n    if R.nnz == 0:\n        print(\"Error in sa_energy_min(..).  Initial R no nonzeros on a level. \\\n               Returning tentative prolongator\\n\")\n        return T\n\n    # This is the RHS vector for the problem in the Krylov Space\n    normr = np.sqrt((R.data.conjugate()*R.data).sum())\n    g = np.zeros((maxiter+1,), dtype=xtype)\n    g[0] = normr\n\n    # First Krylov vector\n    # V[0] = r/normr\n    if normr > 0.0:\n        V.append((1.0/normr)*R)\n\n    # print \"Energy Minimization of Prolongator \\\n    # --- Iteration 0 --- r = \" + str(normr)\n    i = -1\n    # vect = np.ravel((A*T).data)\n    # print \"Iteration \" + str(i+1) + \"   \\\n    # Energy = %1.3e\"%np.sqrt( (vect.conjugate()*vect).sum() )\n    # print \"Iteration \" + str(i+1) + \"   Normr  %1.3e\"%normr\n    while i < maxiter-1 and normr > tol:\n        i = i+1\n\n        # Calculate new search direction\n        #   Equivalent to:  AV = A*V;    AV = AV.multiply(Sparsity_Pattern)\n        #   with the added constraint that explicit zeros are in AP wherever\n        #   AP = 0 and Sparsity_Pattern does not\n        AV.data[:] = 0.0\n        pyamg.amg_core.incomplete_mat_mult_bsr(A.indptr, A.indices,\n                                               np.ravel(A.data),\n                                               V[i].indptr, V[i].indices,\n                                               np.ravel(V[i].data),\n                                               AV.indptr, AV.indices,\n                                               np.ravel(AV.data),\n                                               int(T.shape[0]/T.blocksize[0]),\n                                               int(T.shape[1]/T.blocksize[1]),\n                                               A.blocksize[0], A.blocksize[1],\n                                               T.blocksize[1])\n\n        if weighting == 'local' or weighting == 'diagonal':\n            AV = scale_rows(AV, Dinv)\n        else:\n            AV = Dinv*AV\n\n        # Enforce AV*B = 0\n        Satisfy_Constraints(AV, B, BtBinv)\n        V.append(AV.copy())\n\n        # Modified Gram-Schmidt\n        for j in range(i+1):\n            # Frobenius inner-product\n            H[j, i] = (V[j].conjugate().multiply(V[i+1])).sum()\n            V[i+1] = V[i+1] - H[j, i]*V[j]\n\n        # Frobenius Norm\n        H[i+1, i] = np.sqrt((V[i+1].data.conjugate()*V[i+1].data).sum())\n\n        # Check for breakdown\n        if H[i+1, i] != 0.0:\n            V[i+1] = (1.0 / H[i+1, i]) * V[i+1]\n\n        # Apply previous Givens rotations to H\n        if i > 0:\n            apply_givens(Q, H[:, i], i)\n\n        # Calculate and apply next complex-valued Givens Rotation\n        if H[i+1, i] != 0:\n            h1 = H[i, i]\n            h2 = H[i+1, i]\n            h1_mag = np.abs(h1)\n            h2_mag = np.abs(h2)\n            if h1_mag < h2_mag:\n                mu = h1/h2\n                tau = np.conjugate(mu)/np.abs(mu)\n            else:\n                mu = h2/h1\n                tau = mu/np.abs(mu)\n\n            denom = np.sqrt(h1_mag**2 + h2_mag**2)\n            c = h1_mag/denom\n            s = h2_mag*tau/denom\n            Qblock = np.array([[c, np.conjugate(s)], [-s, c]], dtype=xtype)\n            Q.append(Qblock)\n\n            # Apply Givens Rotation to g,\n            #   the RHS for the linear system in the Krylov Subspace.\n            g[i:i+2] = sp.dot(Qblock, g[i:i+2])\n\n            # Apply effect of Givens Rotation to H\n            H[i, i] = sp.dot(Qblock[0, :], H[i:i+2, i])\n            H[i+1, i] = 0.0\n\n        normr = np.abs(g[i+1])\n        # print \"Iteration \" + str(i+1) + \"   Normr  %1.3e\"%normr\n    # End while loop\n\n    # Find best update to x in Krylov Space, V.  Solve (i x i) system.\n    if i != -1:\n        y = la.solve(H[0:i+1, 0:i+1], g[0:i+1])\n        for j in range(i+1):\n            T = T + y[j]*V[j]\n\n    # vect = np.ravel((A*T).data)\n    # print \"Final Iteration \" + str(i) + \"   \\\n    # Energy = %1.3e\"%np.sqrt( (vect.conjugate()*vect).sum() )\n\n    # Ensure identity at C-pts\n    if Cpt_params[0]:\n        T = Cpt_params[1]['I_F']*T + Cpt_params[1]['P_I']\n\n    return T", "response": "Use GMRES to smooth A T by solving A B BtBinv and Sparsity_Pattern to enforce on the coarse grids of the coarse grids."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nminimizing the energy of the coarse basis functions.", "response": "def energy_prolongation_smoother(A, T, Atilde, B, Bf, Cpt_params,\n                                 krylov='cg', maxiter=4, tol=1e-8,\n                                 degree=1, weighting='local',\n                                 prefilter={}, postfilter={}):\n    \"\"\"Minimize the energy of the coarse basis functions (columns of T).\n\n    Both root-node and non-root-node style prolongation smoothing is available,\n    see Cpt_params description below.\n\n    Parameters\n    ----------\n    A : csr_matrix, bsr_matrix\n        Sparse NxN matrix\n    T : bsr_matrix\n        Tentative prolongator, a NxM sparse matrix (M < N)\n    Atilde : csr_matrix\n        Strength of connection matrix\n    B : array\n        Near-nullspace modes for coarse grid.  Has shape (M,k) where\n        k is the number of coarse candidate vectors.\n    Bf : array\n        Near-nullspace modes for fine grid.  Has shape (N,k) where\n        k is the number of coarse candidate vectors.\n    Cpt_params : tuple\n        Tuple of the form (bool, dict).  If the Cpt_params[0] = False, then the\n        standard SA prolongation smoothing is carried out.  If True, then\n        root-node style prolongation smoothing is carried out.  The dict must\n        be a dictionary of parameters containing, (1) for P_I, P_I.T is the\n        injection matrix for the Cpts, (2) I_F is an identity matrix for only the\n        F-points (i.e. I, but with zero rows and columns for C-points) and I_C is\n        the C-point analogue to I_F.  See Notes below for more information.\n    krylov : string\n        'cg' for SPD systems.  Solve A T = 0 in a constraint space with CG\n        'cgnr' for nonsymmetric and/or indefinite systems.\n        Solve A T = 0 in a constraint space with CGNR\n        'gmres' for nonsymmetric and/or indefinite systems.\n        Solve A T = 0 in a constraint space with GMRES\n    maxiter : integer\n        Number of energy minimization steps to apply to the prolongator\n    tol : scalar\n        Minimization tolerance\n    degree : int\n        Generate sparsity pattern for P based on (Atilde^degree T)\n    weighting : string\n        'block', 'diagonal' or 'local' construction of the diagonal preconditioning\n        'local' Uses a local row-wise weight based on the Gershgorin estimate.\n        Avoids any potential under-damping due to inaccurate spectral\n        radius estimates.\n        'block' Uses a block diagonal inverse of A if A is BSR.\n        'diagonal' Uses the inverse of the diagonal of A\n    prefilter : dictionary\n        Filter elements by row in sparsity pattern for P to reduce operator and\n        setup complexity. If None or an empty dictionary, then no dropping in P\n        is done.  If postfilter has key 'k', then the largest 'k' entries  are\n        kept in each row.  If postfilter has key 'theta', all entries such that\n        :math:`P[i,j] < kwargs['theta']*max(abs(P[i,:]))`\n        are dropped.  If postfilter['k'] and postfiler['theta'] are present,\n        then they are used with the union of their patterns.\n    postfilter : dictionary\n        Filters elements by row in smoothed P to reduce operator complexity.\n        Only supported if using the rootnode_solver. If None or an empty\n        dictionary, no dropping in P is done. If postfilter has key 'k',\n        then the largest 'k' entries  are kept in each row.  If postfilter\n        has key 'theta', all entries such that\n        :math::`P[i,j] < kwargs['theta']*max(abs(P[i,:]))`\n        are dropped.  If postfilter['k'] and postfiler['theta'] are present,\n        then they are used with the union of their patterns.\n\n    Returns\n    -------\n    T : bsr_matrix\n        Smoothed prolongator\n\n    Notes\n    -----\n    Only 'diagonal' weighting is supported for the CGNR method, because\n    we are working with A^* A and not A.\n\n    When Cpt_params[0] == True, root-node style prolongation smoothing is used\n    to minimize the energy of columns of T.  Essentially, an identity block is\n    maintained in T, corresponding to injection from the coarse-grid to the\n    fine-grid root-nodes.  See [2011OlScTu]_ for more details, and see\n    util.utils.get_Cpt_params for the helper function to generate Cpt_params.\n\n    If Cpt_params[0] == False, the energy of columns of T are still\n    minimized, but without maintaining the identity block.\n\n    See [1999cMaBrVa]_ for more details on smoothed aggregation.\n\n    Examples\n    --------\n    >>> from pyamg.aggregation import energy_prolongation_smoother\n    >>> from pyamg.gallery import poisson\n    >>> from scipy.sparse import coo_matrix\n    >>> import numpy as np\n    >>> data = np.ones((6,))\n    >>> row = np.arange(0,6)\n    >>> col = np.kron([0,1],np.ones((3,)))\n    >>> T = coo_matrix((data,(row,col)),shape=(6,2)).tocsr()\n    >>> print T.todense()\n    [[ 1.  0.]\n     [ 1.  0.]\n     [ 1.  0.]\n     [ 0.  1.]\n     [ 0.  1.]\n     [ 0.  1.]]\n    >>> A = poisson((6,),format='csr')\n    >>> B = np.ones((2,1),dtype=float)\n    >>> P = energy_prolongation_smoother(A,T,A,B, None, (False,{}))\n    >>> print P.todense()\n    [[ 1.          0.        ]\n     [ 1.          0.        ]\n     [ 0.66666667  0.33333333]\n     [ 0.33333333  0.66666667]\n     [ 0.          1.        ]\n     [ 0.          1.        ]]\n\n    References\n    ----------\n    .. [1999cMaBrVa] Jan Mandel, Marian Brezina, and Petr Vanek\n       \"Energy Optimization of Algebraic Multigrid Bases\"\n       Computing 62, 205-228, 1999\n       http://dx.doi.org/10.1007/s006070050022\n\n    .. [2011OlScTu] Olson, L. and Schroder, J. and Tuminaro, R.,\n       \"A general interpolation strategy for algebraic\n       multigrid using energy minimization\", SIAM Journal\n       on Scientific Computing (SISC), vol. 33, pp.\n       966--991, 2011.\n\n    \"\"\"\n    # Test Inputs\n    if maxiter < 0:\n        raise ValueError('maxiter must be > 0')\n    if tol > 1:\n        raise ValueError('tol must be <= 1')\n\n    if sparse.isspmatrix_csr(A):\n        A = A.tobsr(blocksize=(1, 1), copy=False)\n    elif sparse.isspmatrix_bsr(A):\n        pass\n    else:\n        raise TypeError(\"A must be csr_matrix or bsr_matrix\")\n\n    if sparse.isspmatrix_csr(T):\n        T = T.tobsr(blocksize=(1, 1), copy=False)\n    elif sparse.isspmatrix_bsr(T):\n        pass\n    else:\n        raise TypeError(\"T must be csr_matrix or bsr_matrix\")\n\n    if T.blocksize[0] != A.blocksize[0]:\n        raise ValueError(\"T row-blocksize should be the same as A blocksize\")\n\n    if B.shape[0] != T.shape[1]:\n        raise ValueError(\"B is the candidates for the coarse grid. \\\n                            num_rows(b) = num_cols(T)\")\n\n    if min(T.nnz, A.nnz) == 0:\n        return T\n\n    if not sparse.isspmatrix_csr(Atilde):\n        raise TypeError(\"Atilde must be csr_matrix\")\n\n    if ('theta' in prefilter) and (prefilter['theta'] == 0):\n        prefilter.pop('theta', None)\n\n    if ('theta' in postfilter) and (postfilter['theta'] == 0):\n        postfilter.pop('theta', None)\n\n    # Prepocess Atilde, the strength matrix\n    if Atilde is None:\n        Atilde = sparse.csr_matrix((np.ones(len(A.indices)),\n                                    A.indices.copy(), A.indptr.copy()),\n                                   shape=(A.shape[0]/A.blocksize[0],\n                                          A.shape[1]/A.blocksize[1]))\n\n    # If Atilde has no nonzeros, then return T\n    if min(T.nnz, A.nnz) == 0:\n        return T\n\n    # Expand allowed sparsity pattern for P through multiplication by Atilde\n    if degree > 0:\n\n        # Construct Sparsity_Pattern by multiplying with Atilde\n        T.sort_indices()\n        shape = (int(T.shape[0]/T.blocksize[0]),\n                 int(T.shape[1]/T.blocksize[1]))\n        Sparsity_Pattern = sparse.csr_matrix((np.ones(T.indices.shape),\n                                              T.indices, T.indptr),\n                                             shape=shape)\n\n        AtildeCopy = Atilde.copy()\n        for i in range(degree):\n            Sparsity_Pattern = AtildeCopy*Sparsity_Pattern\n\n        # Optional filtering of sparsity pattern before smoothing\n        if 'theta' in prefilter and 'k' in prefilter:\n            Sparsity_theta = filter_matrix_rows(Sparsity_Pattern,\n                                                prefilter['theta'])\n            Sparsity_Pattern = truncate_rows(Sparsity_Pattern, prefilter['k'])\n            # Union two sparsity patterns\n            Sparsity_Pattern += Sparsity_theta\n        elif 'k' in prefilter:\n            Sparsity_Pattern = truncate_rows(Sparsity_Pattern, prefilter['k'])\n        elif 'theta' in prefilter:\n            Sparsity_Pattern = filter_matrix_rows(Sparsity_Pattern,\n                                                  prefilter['theta'])\n        elif len(prefilter) > 0:\n            raise ValueError(\"Unrecognized prefilter option\")\n\n        # UnAmal returns a BSR matrix with 1's in the nonzero locations\n        Sparsity_Pattern = UnAmal(Sparsity_Pattern,\n                                  T.blocksize[0], T.blocksize[1])\n        Sparsity_Pattern.sort_indices()\n\n    else:\n        # If degree is 0, just copy T for the sparsity pattern\n        Sparsity_Pattern = T.copy()\n        if 'theta' in prefilter and 'k' in prefilter:\n            Sparsity_theta = filter_matrix_rows(Sparsity_Pattern,\n                                                prefilter['theta'])\n            Sparsity_Pattern = truncate_rows(Sparsity_Pattern, prefilter['k'])\n            # Union two sparsity patterns\n            Sparsity_Pattern += Sparsity_theta\n        elif 'k' in prefilter:\n            Sparsity_Pattern = truncate_rows(Sparsity_Pattern, prefilter['k'])\n        elif 'theta' in prefilter:\n            Sparsity_Pattern = filter_matrix_rows(Sparsity_Pattern,\n                                                  prefilter['theta'])\n        elif len(prefilter) > 0:\n            raise ValueError(\"Unrecognized prefilter option\")\n\n        Sparsity_Pattern.data[:] = 1.0\n        Sparsity_Pattern.sort_indices()\n\n    # If using root nodes, enforce identity at C-points\n    if Cpt_params[0]:\n        Sparsity_Pattern = Cpt_params[1]['I_F'] * Sparsity_Pattern\n        Sparsity_Pattern = Cpt_params[1]['P_I'] + Sparsity_Pattern\n\n    # Construct array of inv(Bi'Bi), where Bi is B restricted to row i's\n    # sparsity pattern in Sparsity Pattern. This array is used multiple times\n    # in Satisfy_Constraints(...).\n    BtBinv = compute_BtBinv(B, Sparsity_Pattern)\n\n    # If using root nodes and B has more columns that A's blocksize, then\n    # T must be updated so that T*B = Bfine.  Note, if this is a 'secondpass'\n    # after dropping entries in P, then we must re-enforce the constraints\n    if ((Cpt_params[0] and (B.shape[1] > A.blocksize[0])) or\n            ('secondpass' in postfilter)):\n        T = filter_operator(T, Sparsity_Pattern, B, Bf, BtBinv)\n        # Ensure identity at C-pts\n        if Cpt_params[0]:\n            T = Cpt_params[1]['I_F']*T + Cpt_params[1]['P_I']\n\n    # Iteratively minimize the energy of T subject to the constraints of\n    # Sparsity_Pattern and maintaining T's effect on B, i.e. T*B =\n    # (T+Update)*B, i.e. Update*B = 0\n    if krylov == 'cg':\n        T = cg_prolongation_smoothing(A, T, B, BtBinv, Sparsity_Pattern,\n                                      maxiter, tol, weighting, Cpt_params)\n    elif krylov == 'cgnr':\n        T = cgnr_prolongation_smoothing(A, T, B, BtBinv, Sparsity_Pattern,\n                                        maxiter, tol, weighting, Cpt_params)\n    elif krylov == 'gmres':\n        T = gmres_prolongation_smoothing(A, T, B, BtBinv, Sparsity_Pattern,\n                                         maxiter, tol, weighting, Cpt_params)\n\n    T.eliminate_zeros()\n\n    # Filter entries in P, only in the rootnode case,\n    # i.e., Cpt_params[0] == True\n    if ((len(postfilter) == 0) or ('secondpass' in postfilter) or\n            (Cpt_params[0] is False)):\n        return T\n    else:\n        if 'theta' in postfilter and 'k' in postfilter:\n            T_theta = filter_matrix_rows(T, postfilter['theta'])\n            T_k = truncate_rows(T, postfilter['k'])\n\n            # Union two sparsity patterns\n            T_theta.data[:] = 1.0\n            T_k.data[:] = 1.0\n            T_filter = T_theta + T_k\n            T_filter.data[:] = 1.0\n            T_filter = T.multiply(T_filter)\n\n        elif 'k' in postfilter:\n            T_filter = truncate_rows(T, postfilter['k'])\n        elif 'theta' in postfilter:\n            T_filter = filter_matrix_rows(T, postfilter['theta'])\n        else:\n            raise ValueError(\"Unrecognized postfilter option\")\n\n        # Re-smooth T_filter and re-fit the modes B into the span.\n        # Note, we set 'secondpass', because this is the second\n        # filtering pass\n        T = energy_prolongation_smoother(A, T_filter,\n                                         Atilde, B, Bf, Cpt_params,\n                                         krylov=krylov, maxiter=1,\n                                         tol=1e-8, degree=0,\n                                         weighting=weighting,\n                                         prefilter={},\n                                         postfilter={'secondpass': True})\n\n    return T"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchanging the pre - and post - smoothers of a multilevel hierarchy.", "response": "def change_smoothers(ml, presmoother, postsmoother):\n    \"\"\"Initialize pre and post smoothers.\n\n    Initialize pre- and post- smoothers throughout a multilevel_solver, with\n    the option of having different smoothers at different levels\n\n    For each level of the multilevel_solver 'ml' (except the coarsest level),\n    initialize the .presmoother() and .postsmoother() methods used in the\n    multigrid cycle.\n\n    Parameters\n    ----------\n    ml : pyamg multilevel hierarchy\n        Data structure that stores the multigrid hierarchy.\n    presmoother : None, string, tuple, list\n        presmoother can be (1) the name of a supported smoother, e.g.\n        \"gauss_seidel\", (2) a tuple of the form ('method','opts') where\n        'method' is the name of a supported smoother and 'opts' a dict of\n        keyword arguments to the smoother, or (3) a list of instances of\n        options 1 or 2.  See the Examples section for illustrations of the\n        format.\n\n        If presmoother is a list, presmoother[i] determines the smoothing\n        strategy for level i.  Else, presmoother defines the same strategy\n        for all levels.\n\n        If len(presmoother) < len(ml.levels), then\n        presmoother[-1] is used for all remaining levels\n\n        If len(presmoother) > len(ml.levels), then\n        the remaining smoothing strategies are ignored\n\n    postsmoother : string, tuple, list\n        Defines postsmoother in identical fashion to presmoother\n\n    Returns\n    -------\n    ml changed in place\n    ml.level[i].presmoother   <===  presmoother[i]\n    ml.level[i].postsmoother  <===  postsmoother[i]\n    ml.symmetric_smoothing is marked True/False depending on whether\n        the smoothing scheme is symmetric.\n\n    Notes\n    -----\n    - Parameter 'omega' of the Jacobi, Richardson, and jacobi_ne\n      methods is scaled by the spectral radius of the matrix on\n      each level.  Therefore 'omega' should be in the interval (0,2).\n    - Parameter 'withrho' (default: True) controls whether the omega is\n      rescaled by the spectral radius in jacobi, block_jacobi, and jacobi_ne\n    - By initializing the smoothers after the hierarchy has been setup, allows\n      for \"algebraically\" directed relaxation, such as strength_based_schwarz,\n      which uses only the strong connections of a degree-of-freedom to define\n      overlapping regions\n    - Available smoother methods::\n\n        gauss_seidel\n        block_gauss_seidel\n        jacobi\n        block_jacobi\n        richardson\n        sor\n        chebyshev\n        gauss_seidel_nr\n        gauss_seidel_ne\n        jacobi_ne\n        cg\n        gmres\n        cgne\n        cgnr\n        schwarz\n        strength_based_schwarz\n        None\n\n    Examples\n    --------\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.aggregation import smoothed_aggregation_solver\n    >>> from pyamg.relaxation.smoothing import change_smoothers\n    >>> from pyamg.util.linalg import norm\n    >>> from scipy import rand, array, mean\n    >>> A = poisson((10,10), format='csr')\n    >>> b = rand(A.shape[0],)\n    >>> ml = smoothed_aggregation_solver(A, max_coarse=10)\n    >>> #\n    >>> # Set all levels to use gauss_seidel's defaults\n    >>> smoothers = 'gauss_seidel'\n    >>> change_smoothers(ml, presmoother=smoothers, postsmoother=smoothers)\n    >>> residuals=[]\n    >>> x = ml.solve(b, tol=1e-8, residuals=residuals)\n    >>> #\n    >>> # Set all levels to use three iterations of gauss_seidel's defaults\n    >>> smoothers = ('gauss_seidel', {'iterations' : 3})\n    >>> change_smoothers(ml, presmoother=smoothers, postsmoother=None)\n    >>> residuals=[]\n    >>> x = ml.solve(b, tol=1e-8, residuals=residuals)\n    >>> #\n    >>> # Set level 0 to use gauss_seidel's defaults, and all\n    >>> # subsequent levels to use 5 iterations of cgnr\n    >>> smoothers = ['gauss_seidel', ('cgnr', {'maxiter' : 5})]\n    >>> change_smoothers(ml, presmoother=smoothers, postsmoother=smoothers)\n    >>> residuals=[]\n    >>> x = ml.solve(b, tol=1e-8, residuals=residuals)\n\n    \"\"\"\n    ml.symmetric_smoothing = True\n\n    # interpret arguments into list\n    if isinstance(presmoother, str) or isinstance(presmoother, tuple) or\\\n       (presmoother is None):\n        presmoother = [presmoother]\n    elif not isinstance(presmoother, list):\n        raise ValueError('Unrecognized presmoother')\n\n    if isinstance(postsmoother, str) or isinstance(postsmoother, tuple) or\\\n       (postsmoother is None):\n        postsmoother = [postsmoother]\n    elif not isinstance(postsmoother, list):\n        raise ValueError('Unrecognized postsmoother')\n\n    # set ml.levels[i].presmoother = presmoother[i],\n    #     ml.levels[i].postsmoother = postsmoother[i]\n    fn1 = None      # Predefine to keep scope beyond first loop\n    fn2 = None\n    kwargs1 = {}\n    kwargs2 = {}\n    min_len = min(len(presmoother), len(postsmoother), len(ml.levels[:-1]))\n    same = (len(presmoother) == len(postsmoother))\n    for i in range(0, min_len):\n        # unpack presmoother[i]\n        fn1, kwargs1 = unpack_arg(presmoother[i])\n        # get function handle\n        try:\n            setup_presmoother = eval('setup_' + str(fn1))\n        except NameError:\n            raise NameError(\"invalid presmoother method: \", fn1)\n        ml.levels[i].presmoother = setup_presmoother(ml.levels[i], **kwargs1)\n\n        # unpack postsmoother[i]\n        fn2, kwargs2 = unpack_arg(postsmoother[i])\n        # get function handle\n        try:\n            setup_postsmoother = eval('setup_' + str(fn2))\n        except NameError:\n            raise NameError(\"invalid postsmoother method: \", fn2)\n        ml.levels[i].postsmoother = setup_postsmoother(ml.levels[i], **kwargs2)\n\n        # Check if symmetric smoothing scheme\n        try:\n            it1 = kwargs1['iterations']\n        except BaseException:\n            it1 = DEFAULT_NITER\n        try:\n            it2 = kwargs2['iterations']\n        except BaseException:\n            it2 = DEFAULT_NITER\n        if (fn1 != fn2) or (it1 != it2):\n            ml.symmetric_smoothing = False\n        elif fn1 not in SYMMETRIC_RELAXATION:\n            try:\n                sweep1 = kwargs1['sweep']\n            except BaseException:\n                sweep1 = DEFAULT_SWEEP\n            try:\n                sweep2 = kwargs2['sweep']\n            except BaseException:\n                sweep2 = DEFAULT_SWEEP\n            if (sweep1 == 'forward' and sweep2 == 'backward') or \\\n               (sweep1 == 'backward' and sweep2 == 'forward') or \\\n               (sweep1 == 'symmetric' and sweep2 == 'symmetric'):\n                pass\n            else:\n                ml.symmetric_smoothing = False\n\n    if len(presmoother) < len(postsmoother):\n        mid_len = min(len(postsmoother), len(ml.levels[:-1]))\n        for i in range(min_len, mid_len):\n            # Set up presmoother\n            ml.levels[i].presmoother =\\\n                setup_presmoother(ml.levels[i], **kwargs1)\n\n            # unpack postsmoother[i]\n            fn2, kwargs2 = unpack_arg(postsmoother[i])\n            # get function handle\n            try:\n                setup_postsmoother = eval('setup_' + str(fn2))\n            except NameError:\n                raise NameError(\"invalid postsmoother method: \", fn2)\n            ml.levels[i].postsmoother =\\\n                setup_postsmoother(ml.levels[i], **kwargs2)\n\n            # Check if symmetric smoothing scheme\n            try:\n                it1 = kwargs1['iterations']\n            except BaseException:\n                it1 = DEFAULT_NITER\n            try:\n                it2 = kwargs2['iterations']\n            except BaseException:\n                it2 = DEFAULT_NITER\n            if (fn1 != fn2) or (it1 != it2):\n                ml.symmetric_smoothing = False\n            elif fn1 not in SYMMETRIC_RELAXATION:\n                try:\n                    sweep1 = kwargs1['sweep']\n                except BaseException:\n                    sweep1 = DEFAULT_SWEEP\n                try:\n                    sweep2 = kwargs2['sweep']\n                except BaseException:\n                    sweep2 = DEFAULT_SWEEP\n                if (sweep1 == 'forward' and sweep2 == 'backward') or \\\n                   (sweep1 == 'backward' and sweep2 == 'forward') or \\\n                   (sweep1 == 'symmetric' and sweep2 == 'symmetric'):\n                    pass\n                else:\n                    ml.symmetric_smoothing = False\n\n    elif len(presmoother) > len(postsmoother):\n        mid_len = min(len(presmoother), len(ml.levels[:-1]))\n        for i in range(min_len, mid_len):\n            # unpack presmoother[i]\n            fn1, kwargs1 = unpack_arg(presmoother[i])\n            # get function handle\n            try:\n                setup_presmoother = eval('setup_' + str(fn1))\n            except NameError:\n                raise NameError(\"invalid presmoother method: \", fn1)\n            ml.levels[i].presmoother =\\\n                setup_presmoother(ml.levels[i], **kwargs1)\n\n            # Set up postsmoother\n            ml.levels[i].postsmoother =\\\n                setup_postsmoother(ml.levels[i], **kwargs2)\n\n            # Check if symmetric smoothing scheme\n            try:\n                it1 = kwargs1['iterations']\n            except BaseException:\n                it1 = DEFAULT_NITER\n            try:\n                it2 = kwargs2['iterations']\n            except BaseException:\n                it2 = DEFAULT_NITER\n            if (fn1 != fn2) or (it1 != it2):\n                ml.symmetric_smoothing = False\n            elif fn1 not in SYMMETRIC_RELAXATION:\n                try:\n                    sweep1 = kwargs1['sweep']\n                except BaseException:\n                    sweep1 = DEFAULT_SWEEP\n                try:\n                    sweep2 = kwargs2['sweep']\n                except BaseException:\n                    sweep2 = DEFAULT_SWEEP\n                if (sweep1 == 'forward' and sweep2 == 'backward') or \\\n                   (sweep1 == 'backward' and sweep2 == 'forward') or \\\n                   (sweep1 == 'symmetric' and sweep2 == 'symmetric'):\n                    pass\n                else:\n                    ml.symmetric_smoothing = False\n\n    else:\n        mid_len = min_len\n\n    # Fill in remaining levels\n    for i in range(mid_len, len(ml.levels[:-1])):\n        ml.levels[i].presmoother = setup_presmoother(ml.levels[i], **kwargs1)\n        ml.levels[i].postsmoother = setup_postsmoother(ml.levels[i], **kwargs2)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the approximate. spectral radius of D^ - 1 * A.", "response": "def rho_D_inv_A(A):\n    \"\"\"Return the (approx.) spectral radius of D^-1 * A.\n\n    Parameters\n    ----------\n    A : sparse-matrix\n\n    Returns\n    -------\n    approximate spectral radius of diag(A)^{-1} A\n\n    Examples\n    --------\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.relaxation.smoothing import rho_D_inv_A\n    >>> from scipy.sparse import csr_matrix\n    >>> import numpy as np\n    >>> A = csr_matrix(np.array([[1.0,0,0],[0,2.0,0],[0,0,3.0]]))\n    >>> print rho_D_inv_A(A)\n    1.0\n\n    \"\"\"\n    if not hasattr(A, 'rho_D_inv'):\n        D_inv = get_diagonal(A, inv=True)\n        D_inv_A = scale_rows(A, D_inv, copy=True)\n        A.rho_D_inv = approximate_spectral_radius(D_inv_A)\n\n    return A.rho_D_inv"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rho_block_D_inv_A(A, Dinv):\n    if not hasattr(A, 'rho_block_D_inv'):\n        from scipy.sparse.linalg import LinearOperator\n\n        blocksize = Dinv.shape[1]\n        if Dinv.shape[1] != Dinv.shape[2]:\n            raise ValueError('Dinv has incorrect dimensions')\n        elif Dinv.shape[0] != int(A.shape[0]/blocksize):\n            raise ValueError('Dinv and A have incompatible dimensions')\n\n        Dinv = sp.sparse.bsr_matrix((Dinv,\n                                     sp.arange(Dinv.shape[0]),\n                                     sp.arange(Dinv.shape[0]+1)),\n                                    shape=A.shape)\n\n        # Don't explicitly form Dinv*A\n        def matvec(x):\n            return Dinv*(A*x)\n        D_inv_A = LinearOperator(A.shape, matvec, dtype=A.dtype)\n\n        A.rho_block_D_inv = approximate_spectral_radius(D_inv_A)\n\n    return A.rho_block_D_inv", "response": "Returns the approximate spectral radius of block D^ - 1 * A."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset a matrix to a specific format.", "response": "def matrix_asformat(lvl, name, format, blocksize=None):\n    \"\"\"Set a matrix to a specific format.\n\n    This routine looks for the matrix \"name\" in the specified format as a\n    member of the level instance, lvl.  For example, if name='A', format='bsr'\n    and blocksize=(4,4), and if lvl.Absr44 exists with the correct blocksize,\n    then lvl.Absr is returned.  If the matrix doesn't already exist, lvl.name\n    is converted to the desired format, and made a member of lvl.\n\n    Only create such persistent copies of a matrix for routines such as\n    presmoothing and postsmoothing, where the matrix conversion is done every\n    cycle.\n\n    Calling this function can _dramatically_ increase your memory costs.\n    Be careful with it's usage.\n\n    \"\"\"\n    desired_matrix = name + format\n    M = getattr(lvl, name)\n\n    if format == 'bsr':\n        desired_matrix += str(blocksize[0])+str(blocksize[1])\n\n    if hasattr(lvl, desired_matrix):\n        # if lvl already contains lvl.name+format\n        pass\n    elif M.format == format and format != 'bsr':\n        # is base_matrix already in the correct format?\n        setattr(lvl, desired_matrix, M)\n    elif M.format == format and format == 'bsr':\n        # convert to bsr with the right blocksize\n        # tobsr() will not do anything extra if this is uneeded\n        setattr(lvl, desired_matrix, M.tobsr(blocksize=blocksize))\n    else:\n        # convert\n        newM = getattr(M, 'to' + format)()\n        setattr(lvl, desired_matrix, newM)\n\n    return getattr(lvl, desired_matrix)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstruct a regular triangular mesh in the unit square.", "response": "def regular_triangle_mesh(nx, ny):\n    \"\"\"Construct a regular triangular mesh in the unit square.\n\n    Parameters\n    ----------\n    nx : int\n       Number of nodes in the x-direction\n    ny : int\n       Number of nodes in the y-direction\n\n    Returns\n    -------\n    Vert : array\n        nx*ny x 2 vertex list\n    E2V : array\n        Nex x 3 element list\n\n    Examples\n    --------\n    >>> from pyamg.gallery import regular_triangle_mesh\n    >>> E2V,Vert = regular_triangle_mesh(3, 2)\n\n    \"\"\"\n    nx, ny = int(nx), int(ny)\n\n    if nx < 2 or ny < 2:\n        raise ValueError('minimum mesh dimension is 2: %s' % ((nx, ny),))\n\n    Vert1 = np.tile(np.arange(0, nx-1), ny - 1) +\\\n        np.repeat(np.arange(0, nx * (ny - 1), nx), nx - 1)\n    Vert3 = np.tile(np.arange(0, nx-1), ny - 1) +\\\n        np.repeat(np.arange(0, nx * (ny - 1), nx), nx - 1) + nx\n    Vert2 = Vert3 + 1\n    Vert4 = Vert1 + 1\n\n    Verttmp = np.meshgrid(np.arange(0, nx, dtype='float'),\n                          np.arange(0, ny, dtype='float'))\n    Verttmp = (Verttmp[0].ravel(), Verttmp[1].ravel())\n    Vert = np.vstack(Verttmp).transpose()\n    Vert[:, 0] = (1.0 / (nx - 1)) * Vert[:, 0]\n    Vert[:, 1] = (1.0 / (ny - 1)) * Vert[:, 1]\n\n    E2V1 = np.vstack((Vert1, Vert2, Vert3)).transpose()\n    E2V2 = np.vstack((Vert1, Vert4, Vert2)).transpose()\n    E2V = np.vstack((E2V1, E2V2))\n\n    return Vert, E2V"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_input(Verts=None, E2V=None, Agg=None, A=None, splitting=None,\n                mesh_type=None):\n    \"\"\"Check input for local functions.\"\"\"\n    if Verts is not None:\n        if not np.issubdtype(Verts.dtype, np.floating):\n            raise ValueError('Verts should be of type float')\n\n    if E2V is not None:\n        if not np.issubdtype(E2V.dtype, np.integer):\n            raise ValueError('E2V should be of type integer')\n        if E2V.min() != 0:\n            warnings.warn('element indices begin at %d' % E2V.min())\n\n    if Agg is not None:\n        if Agg.shape[1] > Agg.shape[0]:\n            raise ValueError('Agg should be of size Npts x Nagg')\n\n    if A is not None:\n        if Agg is not None:\n            if (A.shape[0] != A.shape[1]) or (A.shape[0] != Agg.shape[0]):\n                raise ValueError('expected square matrix A\\\n                                  and compatible with Agg')\n        else:\n            raise ValueError('problem with check_input')\n\n    if splitting is not None:\n        splitting = splitting.ravel()\n        if Verts is not None:\n            if (len(splitting) % Verts.shape[0]) != 0:\n                raise ValueError('splitting must be a multiple of N')\n        else:\n            raise ValueError('problem with check_input')\n\n    if mesh_type is not None:\n        valid_mesh_types = ('vertex', 'tri', 'quad', 'tet', 'hex')\n        if mesh_type not in valid_mesh_types:\n            raise ValueError('mesh_type should be %s' %\n                             ' or '.join(valid_mesh_types))", "response": "Check input for local functions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef RS(S, second_pass=False):\n    if not isspmatrix_csr(S):\n        raise TypeError('expected csr_matrix')\n    S = remove_diagonal(S)\n\n    T = S.T.tocsr()  # transpose S for efficient column access\n    splitting = np.empty(S.shape[0], dtype='intc')\n    influence = np.zeros((S.shape[0],), dtype='intc')\n\n    amg_core.rs_cf_splitting(S.shape[0],\n                             S.indptr, S.indices,\n                             T.indptr, T.indices,\n                             influence,\n                             splitting)\n    if second_pass:\n        amg_core.rs_cf_splitting_pass2(S.shape[0], S.indptr,\n                                       S.indices, splitting)\n\n    return splitting", "response": "Compute a C / F splitting using Ruge - Stuben coarsening."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef PMIS(S):\n    S = remove_diagonal(S)\n    weights, G, S, T = preprocess(S)\n    return MIS(G, weights)", "response": "This method splits the given matrix into a single node MIS with the given strength of connection matrix."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes a CLJP algorithm for a given set of nodes i and j.", "response": "def CLJP(S, color=False):\n    \"\"\"Compute a C/F splitting using the parallel CLJP algorithm.\n\n    Parameters\n    ----------\n    S : csr_matrix\n        Strength of connection matrix indicating the strength between nodes i\n        and j (S_ij)\n    color : bool\n        use the CLJP coloring approach\n\n    Returns\n    -------\n    splitting : array\n        Array of length of S of ones (coarse) and zeros (fine)\n\n    Examples\n    --------\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.classical.split import CLJP\n    >>> S = poisson((7,), format='csr') # 1D mesh with 7 vertices\n    >>> splitting = CLJP(S)\n\n    See Also\n    --------\n    MIS, PMIS, CLJPc\n\n    References\n    ----------\n    .. [8] David M. Alber and Luke N. Olson\n       \"Parallel coarse-grid selection\"\n       Numerical Linear Algebra with Applications 2007; 14:611-643.\n\n    \"\"\"\n    if not isspmatrix_csr(S):\n        raise TypeError('expected csr_matrix')\n    S = remove_diagonal(S)\n\n    colorid = 0\n    if color:\n        colorid = 1\n\n    T = S.T.tocsr()  # transpose S for efficient column access\n    splitting = np.empty(S.shape[0], dtype='intc')\n\n    amg_core.cljp_naive_splitting(S.shape[0],\n                                  S.indptr, S.indices,\n                                  T.indptr, T.indices,\n                                  splitting,\n                                  colorid)\n\n    return splitting"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute a maximal independent set of a graph in parallel.", "response": "def MIS(G, weights, maxiter=None):\n    \"\"\"Compute a maximal independent set of a graph in parallel.\n\n    Parameters\n    ----------\n    G : csr_matrix\n        Matrix graph, G[i,j] != 0 indicates an edge\n    weights : ndarray\n        Array of weights for each vertex in the graph G\n    maxiter : int\n        Maximum number of iterations (default: None)\n\n    Returns\n    -------\n    mis : array\n        Array of length of G of zeros/ones indicating the independent set\n\n    Examples\n    --------\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.classical import MIS\n    >>> import numpy as np\n    >>> G = poisson((7,), format='csr') # 1D mesh with 7 vertices\n    >>> w = np.ones((G.shape[0],1)).ravel()\n    >>> mis = MIS(G,w)\n\n    See Also\n    --------\n    fn = amg_core.maximal_independent_set_parallel\n\n    \"\"\"\n    if not isspmatrix_csr(G):\n        raise TypeError('expected csr_matrix')\n    G = remove_diagonal(G)\n\n    mis = np.empty(G.shape[0], dtype='intc')\n    mis[:] = -1\n\n    fn = amg_core.maximal_independent_set_parallel\n\n    if maxiter is None:\n        fn(G.shape[0], G.indptr, G.indices, -1, 1, 0, mis, weights, -1)\n    else:\n        if maxiter < 0:\n            raise ValueError('maxiter must be >= 0')\n\n        fn(G.shape[0], G.indptr, G.indices, -1, 1, 0, mis, weights, maxiter)\n\n    return mis"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading an example problem by name.", "response": "def load_example(name):\n    \"\"\"Load an example problem by name.\n\n    Parameters\n    ----------\n    name : string (e.g. 'airfoil')\n        Name of the example to load\n\n    Notes\n    -----\n    Each example is stored in a dictionary with the following keys:\n        - 'A'        : sparse matrix\n        - 'B'        : near-nullspace candidates\n        - 'vertices' : dense array of nodal coordinates\n        - 'elements' : dense array of element indices\n\n    Current example names are:%s\n\n    Examples\n    --------\n    >>> from pyamg.gallery import load_example\n    >>> ex = load_example('knot')\n\n    \"\"\"\n    if name not in example_names:\n        raise ValueError('no example with name (%s)' % name)\n    else:\n        return loadmat(os.path.join(example_dir, name + '.mat'),\n                       struct_as_record=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stencil_grid(S, grid, dtype=None, format=None):\n    S = np.asarray(S, dtype=dtype)\n    grid = tuple(grid)\n\n    if not (np.asarray(S.shape) % 2 == 1).all():\n        raise ValueError('all stencil dimensions must be odd')\n\n    if len(grid) != np.ndim(S):\n        raise ValueError('stencil dimension must equal number of grid\\\n                          dimensions')\n\n    if min(grid) < 1:\n        raise ValueError('grid dimensions must be positive')\n\n    N_v = np.prod(grid)  # number of vertices in the mesh\n    N_s = (S != 0).sum()    # number of nonzero stencil entries\n\n    # diagonal offsets\n    diags = np.zeros(N_s, dtype=int)\n\n    # compute index offset of each dof within the stencil\n    strides = np.cumprod([1] + list(reversed(grid)))[:-1]\n    indices = tuple(i.copy() for i in S.nonzero())\n    for i, s in zip(indices, S.shape):\n        i -= s // 2\n        # i = (i - s) // 2\n        # i = i // 2\n        # i = i - (s // 2)\n    for stride, coords in zip(strides, reversed(indices)):\n        diags += stride * coords\n\n    data = S[S != 0].repeat(N_v).reshape(N_s, N_v)\n\n    indices = np.vstack(indices).T\n\n    # zero boundary connections\n    for index, diag in zip(indices, data):\n        diag = diag.reshape(grid)\n        for n, i in enumerate(index):\n            if i > 0:\n                s = [slice(None)] * len(grid)\n                s[n] = slice(0, i)\n                s = tuple(s)\n                diag[s] = 0\n            elif i < 0:\n                s = [slice(None)]*len(grid)\n                s[n] = slice(i, None)\n                s = tuple(s)\n                diag[s] = 0\n\n    # remove diagonals that lie outside matrix\n    mask = abs(diags) < N_v\n    if not mask.all():\n        diags = diags[mask]\n        data = data[mask]\n\n    # sum duplicate diagonals\n    if len(np.unique(diags)) != len(diags):\n        new_diags = np.unique(diags)\n        new_data = np.zeros((len(new_diags), data.shape[1]),\n                            dtype=data.dtype)\n\n        for dia, dat in zip(diags, data):\n            n = np.searchsorted(new_diags, dia)\n            new_data[n, :] += dat\n\n        diags = new_diags\n        data = new_data\n\n    return sparse.dia_matrix((data, diags),\n                             shape=(N_v, N_v)).asformat(format)", "response": "Construct a sparse matrix form a local matrix stencil."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _CRsweep(A, B, Findex, Cindex, nu, thetacr, method):\n    n = A.shape[0]    # problem size\n    numax = nu\n    z = np.zeros((n,))\n    e = deepcopy(B[:, 0])\n    e[Cindex] = 0.0\n    enorm = norm(e)\n    rhok = 1\n    it = 0\n\n    while True:\n        if method == 'habituated':\n            gauss_seidel(A, e, z, iterations=1)\n            e[Cindex] = 0.0\n        elif method == 'concurrent':\n            gauss_seidel_indexed(A, e, z, indices=Findex, iterations=1)\n        else:\n            raise NotImplementedError('method not recognized: need habituated '\n                                      'or concurrent')\n\n        enorm_old = enorm\n        enorm = norm(e)\n        rhok_old = rhok\n        rhok = enorm / enorm_old\n        it += 1\n\n        # criteria 1 -- fast convergence\n        if rhok < 0.1 * thetacr:\n            break\n        # criteria 2 -- at least nu iters, small relative change in CF (<0.1)\n        elif ((abs(rhok - rhok_old) / rhok) < 0.1) and (it >= nu):\n            break\n\n    return rhok, e", "response": "Internal function called by CR sweeps on a target vector."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuses Compatible Relaxation to compute a C - point split.", "response": "def CR(A, method='habituated', B=None, nu=3, thetacr=0.7,\n        thetacs='auto', maxiter=20, verbose=False):\n    \"\"\"Use Compatible Relaxation to compute a C/F splitting.\n\n    Parameters\n    ----------\n    A : csr_matrix\n        sparse matrix (n x n) usually matrix A of Ax=b\n    method : {'habituated','concurrent'}\n        Method used during relaxation:\n            - concurrent: GS relaxation on F-points, leaving e_c = 0\n            - habituated: full relaxation, setting e_c = 0\n    B : array like\n        Target algebraically smooth vector used in CR. If multiple\n        vectors passed in, only first one is used. If B=None, the\n        constant vector is used.\n    nu : int\n        Number of smoothing iterations to apply each CR sweep.\n    thetacr : float\n        Desired convergence factor of relaxations, 0 < thetacr < 1.\n    thetacs : list, float, 'auto'\n        Threshold value, 0 < thetacs < 1, to consider nodes from\n        candidate set for coarse grid. If e[i] > thetacs for relaxed\n        error vector, e, node i is considered for the coarse grid.\n        Can be passed in as float to be used for every iteration,\n        list of floats to be used on progressive iterations, or as\n        string 'auto,' wherein each iteration thetacs = 1 - rho, for\n        convergence factor rho from most recent smoothing.\n    maxiter : int\n        Maximum number of CR iterations (updating of C/F splitting)\n        to do.\n    verbose : bool\n        If true, print iteration number, convergence factor and\n        coarsening factor after each iteration.\n\n    Returns\n    -------\n    splitting : array\n        C/F list of 1's (coarse pt) and 0's (fine pt) (n x 1)\n\n    References\n    ----------\n    [1] Brannick, James J., and Robert D. Falgout. \"Compatible\n    relaxation and coarsening in algebraic multigrid.\" SIAM Journal\n    on Scientific Computing 32.3 (2010): 1393-1416.\n\n    Examples\n    --------\n    >>> from pyamg.gallery import poisson\n    >>> from cr import CR\n    >>> A = poisson((20,20),format='csr')\n    >>> splitting = CR(A)\n\n    \"\"\"\n    n = A.shape[0]    # problem size\n\n    if thetacs == 'auto':\n        pass\n    else:\n        if isinstance(thetacs, list):\n            thetacs.reverse()\n        elif isinstance(thetacs, float):\n            thetacs = list(thetacs)\n\n        if (np.max(thetacs) >= 1) or (np.min(thetacs) <= 0):\n            raise ValueError(\"Must have 0 < thetacs < 1\")\n\n    if (thetacr >= 1) or (thetacr <= 0):\n        raise ValueError(\"Must have 0 < thetacr < 1\")\n\n    if not isspmatrix_csr(A):\n        raise TypeError('expecting csr sparse matrix A')\n\n    if A.dtype == complex:\n        raise NotImplementedError('complex A not implemented')\n\n    # Set initial vector. If none provided, set default\n    # initial vector of ones\n    if B is None:\n        B = np.ones((n, 1))\n    elif (B.ndim == 1):\n        B = B.reshape((len(B), 1))\n\n    target = B[:, 0]\n\n    # 3.1a - Initialize all nodes as F points\n    splitting = np.zeros((n,), dtype='intc')\n    indices = np.zeros((n+1,), dtype='intc')\n    indices[0] = n\n    indices[1:] = np.arange(0, n, dtype='intc')\n    Findex = indices[1:]\n    Cindex = np.empty((0,), dtype='intc')\n    gamma = np.zeros((n,))\n\n    # 3.1b - Run initial smoothing sweep\n    rho, e = _CRsweep(A, B, Findex, Cindex, nu, thetacr, method=method)\n\n    # 3.1c - Loop until desired convergence or maximum iterations reached\n    for it in range(0, maxiter):\n\n        # Set thetacs value\n        if thetacs == 'auto':\n            tcs = 1-rho\n        else:\n            tcs = thetacs[-1]\n            if len(thetacs) > 1:\n                thetacs.pop()\n\n        # 3.1d - 3.1f, see amg_core.ruge_stuben\n        fn = amg_core.cr_helper\n        fn(A.indptr,\n           A.indices,\n           target,\n           e,\n           indices,\n           splitting,\n           gamma,\n           tcs)\n\n        # Separate F indices and C indices\n        num_F = indices[0]\n        Findex = indices[1:(num_F+1)]\n        Cindex = indices[(num_F+1):]\n\n        # 3.1g - Call CR smoothing iteration\n        rho, e = _CRsweep(A, B, Findex, Cindex, nu, thetacr, method=method)\n\n        # Print details on current iteration\n        if verbose:\n            print(\"CR Iteration \", it, \", CF = \", rho,\n                  \", Coarsening factor = \", float(n-indices[0])/n)\n\n        # If convergence factor satisfactory, break loop\n        if rho < thetacr:\n            break\n\n    return splitting"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rowsum_stdev(x, beta):\n    n = x.size\n    betabar = (1.0/n) * np.dot(x, beta)\n    stdev = np.sqrt((1.0/n) *\n                    np.sum(np.power(np.multiply(x, beta) - betabar, 2)))\n    return stdev/betabar", "response": "Compute for approximation x the std dev of the row sums\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef chebyshev_polynomial_coefficients(a, b, degree):\n    if a >= b or a <= 0:\n        raise ValueError('invalid interval [%s,%s]' % (a, b))\n\n    # Chebyshev roots for the interval [-1,1]\n    std_roots = np.cos(np.pi * (np.arange(degree) + 0.5) / degree)\n\n    # Chebyshev roots for the interval [a,b]\n    scaled_roots = 0.5 * (b-a) * (1 + std_roots) + a\n\n    # Compute monic polynomial coefficients of polynomial with scaled roots\n    scaled_poly = np.poly(scaled_roots)\n\n    # Scale coefficients to enforce C(0) = 1.0\n    scaled_poly /= np.polyval(scaled_poly, 0)\n\n    return scaled_poly", "response": "Returns the Chebyshev polynomial coefficients for the given interval a and b."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the coefficients for a MLS polynomial smoother.", "response": "def mls_polynomial_coefficients(rho, degree):\n    \"\"\"Determine the coefficients for a MLS polynomial smoother.\n\n    Parameters\n    ----------\n    rho : float\n        Spectral radius of the matrix in question\n    degree : int\n        Degree of polynomial coefficients to generate\n\n    Returns\n    -------\n    Tuple of arrays (coeffs,roots) containing the\n    coefficients for the (symmetric) polynomial smoother and\n    the roots of polynomial prolongation smoother.\n\n    The coefficients of the polynomial are in descending order\n\n    References\n    ----------\n    .. [1] Parallel multigrid smoothing: polynomial versus Gauss--Seidel\n       M. F. Adams, M. Brezina, J. J. Hu, and R. S. Tuminaro\n       J. Comp. Phys., 188 (2003), pp. 593--610\n\n    Examples\n    --------\n    >>> from pyamg.relaxation.chebyshev import mls_polynomial_coefficients\n    >>> mls = mls_polynomial_coefficients(2.0, 2)\n    >>> print mls[0] # coefficients\n    [   6.4  -48.   144.  -220.   180.   -75.8   14.5]\n    >>> print mls[1] # roots\n    [ 1.4472136  0.5527864]\n\n    \"\"\"\n    # std_roots = np.cos(np.pi * (np.arange(degree) + 0.5)/ degree)\n    # print std_roots\n\n    roots = rho/2.0 * \\\n        (1.0 - np.cos(2*np.pi*(np.arange(degree, dtype='float64') + 1)/(2.0*degree+1.0)))\n    # print roots\n    roots = 1.0/roots\n\n    # S_coeffs = list(-np.poly(roots)[1:][::-1])\n\n    S = np.poly(roots)[::-1]  # monomial coefficients of S error propagator\n\n    SSA_max = rho/((2.0*degree+1.0)**2)  # upper bound spectral radius of S^2A\n    S_hat = np.polymul(S, S)  # monomial coefficients of \\hat{S} propagator\n    S_hat = np.hstack(((-1.0/SSA_max)*S_hat, [1]))\n\n    # coeff for combined error propagator \\hat{S}S\n    coeffs = np.polymul(S_hat, S)\n    coeffs = -coeffs[:-1]             # coeff for smoother\n\n    return (coeffs, roots)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a multilevel solver for Classical AMG.", "response": "def ruge_stuben_solver(A,\n                       strength=('classical', {'theta': 0.25}),\n                       CF='RS',\n                       presmoother=('gauss_seidel', {'sweep': 'symmetric'}),\n                       postsmoother=('gauss_seidel', {'sweep': 'symmetric'}),\n                       max_levels=10, max_coarse=10, keep=False, **kwargs):\n    \"\"\"Create a multilevel solver using Classical AMG (Ruge-Stuben AMG).\n\n    Parameters\n    ----------\n    A : csr_matrix\n        Square matrix in CSR format\n    strength : ['symmetric', 'classical', 'evolution', 'distance', 'algebraic_distance','affinity', 'energy_based', None]\n        Method used to determine the strength of connection between unknowns\n        of the linear system.  Method-specific parameters may be passed in\n        using a tuple, e.g. strength=('symmetric',{'theta' : 0.25 }). If\n        strength=None, all nonzero entries of the matrix are considered strong.\n    CF : string\n        Method used for coarse grid selection (C/F splitting)\n        Supported methods are RS, PMIS, PMISc, CLJP, CLJPc, and CR.\n    presmoother : string or dict\n        Method used for presmoothing at each level.  Method-specific parameters\n        may be passed in using a tuple, e.g.\n        presmoother=('gauss_seidel',{'sweep':'symmetric}), the default.\n    postsmoother : string or dict\n        Postsmoothing method with the same usage as presmoother\n    max_levels: integer\n        Maximum number of levels to be used in the multilevel solver.\n    max_coarse: integer\n        Maximum number of variables permitted on the coarse grid.\n    keep: bool\n        Flag to indicate keeping extra operators in the hierarchy for\n        diagnostics.  For example, if True, then strength of connection (C) and\n        tentative prolongation (T) are kept.\n\n    Returns\n    -------\n    ml : multilevel_solver\n        Multigrid hierarchy of matrices and prolongation operators\n\n    Examples\n    --------\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg import ruge_stuben_solver\n    >>> A = poisson((10,),format='csr')\n    >>> ml = ruge_stuben_solver(A,max_coarse=3)\n\n    Notes\n    -----\n    \"coarse_solver\" is an optional argument and is the solver used at the\n    coarsest grid.  The default is a pseudo-inverse.  Most simply,\n    coarse_solver can be one of ['splu', 'lu', 'cholesky, 'pinv',\n    'gauss_seidel', ... ].  Additionally, coarse_solver may be a tuple\n    (fn, args), where fn is a string such as ['splu', 'lu', ...] or a callable\n    function, and args is a dictionary of arguments to be passed to fn.\n    See [2001TrOoSc]_ for additional details.\n\n\n    References\n    ----------\n    .. [2001TrOoSc] Trottenberg, U., Oosterlee, C. W., and Schuller, A.,\n       \"Multigrid\" San Diego: Academic Press, 2001.  Appendix A\n\n    See Also\n    --------\n    aggregation.smoothed_aggregation_solver, multilevel_solver,\n    aggregation.rootnode_solver\n\n    \"\"\"\n    levels = [multilevel_solver.level()]\n\n    # convert A to csr\n    if not isspmatrix_csr(A):\n        try:\n            A = csr_matrix(A)\n            warn(\"Implicit conversion of A to CSR\",\n                 SparseEfficiencyWarning)\n        except BaseException:\n            raise TypeError('Argument A must have type csr_matrix, \\\n                             or be convertible to csr_matrix')\n    # preprocess A\n    A = A.asfptype()\n    if A.shape[0] != A.shape[1]:\n        raise ValueError('expected square matrix')\n\n    levels[-1].A = A\n\n    while len(levels) < max_levels and levels[-1].A.shape[0] > max_coarse:\n        extend_hierarchy(levels, strength, CF, keep)\n\n    ml = multilevel_solver(levels, **kwargs)\n    change_smoothers(ml, presmoother, postsmoother)\n    return ml"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extend_hierarchy(levels, strength, CF, keep):\n    def unpack_arg(v):\n        if isinstance(v, tuple):\n            return v[0], v[1]\n        else:\n            return v, {}\n\n    A = levels[-1].A\n\n    # Compute the strength-of-connection matrix C, where larger\n    # C[i,j] denote stronger couplings between i and j.\n    fn, kwargs = unpack_arg(strength)\n    if fn == 'symmetric':\n        C = symmetric_strength_of_connection(A, **kwargs)\n    elif fn == 'classical':\n        C = classical_strength_of_connection(A, **kwargs)\n    elif fn == 'distance':\n        C = distance_strength_of_connection(A, **kwargs)\n    elif (fn == 'ode') or (fn == 'evolution'):\n        C = evolution_strength_of_connection(A, **kwargs)\n    elif fn == 'energy_based':\n        C = energy_based_strength_of_connection(A, **kwargs)\n    elif fn == 'algebraic_distance':\n        C = algebraic_distance(A, **kwargs)\n    elif fn == 'affinity':\n        C = affinity_distance(A, **kwargs)\n    elif fn is None:\n        C = A\n    else:\n        raise ValueError('unrecognized strength of connection method: %s' %\n                         str(fn))\n\n    # Generate the C/F splitting\n    fn, kwargs = unpack_arg(CF)\n    if fn == 'RS':\n        splitting = split.RS(C, **kwargs)\n    elif fn == 'PMIS':\n        splitting = split.PMIS(C, **kwargs)\n    elif fn == 'PMISc':\n        splitting = split.PMISc(C, **kwargs)\n    elif fn == 'CLJP':\n        splitting = split.CLJP(C, **kwargs)\n    elif fn == 'CLJPc':\n        splitting = split.CLJPc(C, **kwargs)\n    elif fn == 'CR':\n        splitting = CR(C, **kwargs)\n    else:\n        raise ValueError('unknown C/F splitting method (%s)' % CF)\n\n    # Generate the interpolation matrix that maps from the coarse-grid to the\n    # fine-grid\n    P = direct_interpolation(A, C, splitting)\n\n    # Generate the restriction matrix that maps from the fine-grid to the\n    # coarse-grid\n    R = P.T.tocsr()\n\n    # Store relevant information for this level\n    if keep:\n        levels[-1].C = C                  # strength of connection matrix\n        levels[-1].splitting = splitting  # C/F splitting\n\n    levels[-1].P = P                  # prolongation operator\n    levels[-1].R = R                  # restriction operator\n\n    levels.append(multilevel_solver.level())\n\n    # Form next level through Galerkin product\n    A = R * A * P\n    levels[-1].A = A", "response": "Extend the multigrid hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ensure_dirs(filename):\n    dirname = os.path.dirname(filename)\n    if dirname and not os.path.exists(dirname):\n        os.makedirs(dirname)", "response": "Make sure the directories exist for filename."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the sparsity pattern of the tentative prolongator.", "response": "def standard_aggregation(C):\n    \"\"\"Compute the sparsity pattern of the tentative prolongator.\n\n    Parameters\n    ----------\n    C : csr_matrix\n        strength of connection matrix\n\n    Returns\n    -------\n    AggOp : csr_matrix\n        aggregation operator which determines the sparsity pattern\n        of the tentative prolongator\n    Cpts : array\n        array of Cpts, i.e., Cpts[i] = root node of aggregate i\n\n    Examples\n    --------\n    >>> from scipy.sparse import csr_matrix\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.aggregation.aggregate import standard_aggregation\n    >>> A = poisson((4,), format='csr')   # 1D mesh with 4 vertices\n    >>> A.todense()\n    matrix([[ 2., -1.,  0.,  0.],\n            [-1.,  2., -1.,  0.],\n            [ 0., -1.,  2., -1.],\n            [ 0.,  0., -1.,  2.]])\n    >>> standard_aggregation(A)[0].todense() # two aggregates\n    matrix([[1, 0],\n            [1, 0],\n            [0, 1],\n            [0, 1]], dtype=int8)\n    >>> A = csr_matrix([[1,0,0],[0,1,1],[0,1,1]])\n    >>> A.todense()                      # first vertex is isolated\n    matrix([[1, 0, 0],\n            [0, 1, 1],\n            [0, 1, 1]])\n    >>> standard_aggregation(A)[0].todense() # one aggregate\n    matrix([[0],\n            [1],\n            [1]], dtype=int8)\n\n    See Also\n    --------\n    amg_core.standard_aggregation\n\n    \"\"\"\n    if not isspmatrix_csr(C):\n        raise TypeError('expected csr_matrix')\n\n    if C.shape[0] != C.shape[1]:\n        raise ValueError('expected square matrix')\n\n    index_type = C.indptr.dtype\n    num_rows = C.shape[0]\n\n    Tj = np.empty(num_rows, dtype=index_type)  # stores the aggregate #s\n    Cpts = np.empty(num_rows, dtype=index_type)  # stores the Cpts\n\n    fn = amg_core.standard_aggregation\n\n    num_aggregates = fn(num_rows, C.indptr, C.indices, Tj, Cpts)\n    Cpts = Cpts[:num_aggregates]\n\n    if num_aggregates == 0:\n        # return all zero matrix and no Cpts\n        return csr_matrix((num_rows, 1), dtype='int8'),\\\n            np.array([], dtype=index_type)\n    else:\n\n        shape = (num_rows, num_aggregates)\n        if Tj.min() == -1:\n            # some nodes not aggregated\n            mask = Tj != -1\n            row = np.arange(num_rows, dtype=index_type)[mask]\n            col = Tj[mask]\n            data = np.ones(len(col), dtype='int8')\n            return coo_matrix((data, (row, col)), shape=shape).tocsr(), Cpts\n        else:\n            # all nodes aggregated\n            Tp = np.arange(num_rows+1, dtype=index_type)\n            Tx = np.ones(len(Tj), dtype='int8')\n            return csr_matrix((Tx, Tj, Tp), shape=shape), Cpts"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the sparsity pattern of the tentative prolongator.", "response": "def naive_aggregation(C):\n    \"\"\"Compute the sparsity pattern of the tentative prolongator.\n\n    Parameters\n    ----------\n    C : csr_matrix\n        strength of connection matrix\n\n    Returns\n    -------\n    AggOp : csr_matrix\n        aggregation operator which determines the sparsity pattern\n        of the tentative prolongator\n    Cpts : array\n        array of Cpts, i.e., Cpts[i] = root node of aggregate i\n\n    Examples\n    --------\n    >>> from scipy.sparse import csr_matrix\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.aggregation.aggregate import naive_aggregation\n    >>> A = poisson((4,), format='csr')   # 1D mesh with 4 vertices\n    >>> A.todense()\n    matrix([[ 2., -1.,  0.,  0.],\n            [-1.,  2., -1.,  0.],\n            [ 0., -1.,  2., -1.],\n            [ 0.,  0., -1.,  2.]])\n    >>> naive_aggregation(A)[0].todense() # two aggregates\n    matrix([[1, 0],\n            [1, 0],\n            [0, 1],\n            [0, 1]], dtype=int8)\n    >>> A = csr_matrix([[1,0,0],[0,1,1],[0,1,1]])\n    >>> A.todense()                      # first vertex is isolated\n    matrix([[1, 0, 0],\n            [0, 1, 1],\n            [0, 1, 1]])\n    >>> naive_aggregation(A)[0].todense() # two aggregates\n    matrix([[1, 0],\n            [0, 1],\n            [0, 1]], dtype=int8)\n\n    See Also\n    --------\n    amg_core.naive_aggregation\n\n    Notes\n    -----\n    Differs from standard aggregation.  Each dof is considered.  If it has been\n    aggregated, skip over.  Otherwise, put dof and any unaggregated neighbors\n    in an aggregate.  Results in possibly much higher complexities than\n    standard aggregation.\n\n    \"\"\"\n    if not isspmatrix_csr(C):\n        raise TypeError('expected csr_matrix')\n\n    if C.shape[0] != C.shape[1]:\n        raise ValueError('expected square matrix')\n\n    index_type = C.indptr.dtype\n    num_rows = C.shape[0]\n\n    Tj = np.empty(num_rows, dtype=index_type)  # stores the aggregate #s\n    Cpts = np.empty(num_rows, dtype=index_type)  # stores the Cpts\n\n    fn = amg_core.naive_aggregation\n\n    num_aggregates = fn(num_rows, C.indptr, C.indices, Tj, Cpts)\n    Cpts = Cpts[:num_aggregates]\n    Tj = Tj - 1\n\n    if num_aggregates == 0:\n        # all zero matrix\n        return csr_matrix((num_rows, 1), dtype='int8'), Cpts\n    else:\n        shape = (num_rows, num_aggregates)\n        # all nodes aggregated\n        Tp = np.arange(num_rows+1, dtype=index_type)\n        Tx = np.ones(len(Tj), dtype='int8')\n        return csr_matrix((Tx, Tj, Tp), shape=shape), Cpts"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lloyd_aggregation(C, ratio=0.03, distance='unit', maxiter=10):\n    if ratio <= 0 or ratio > 1:\n        raise ValueError('ratio must be > 0.0 and <= 1.0')\n\n    if not (isspmatrix_csr(C) or isspmatrix_csc(C)):\n        raise TypeError('expected csr_matrix or csc_matrix')\n\n    if distance == 'unit':\n        data = np.ones_like(C.data).astype(float)\n    elif distance == 'abs':\n        data = abs(C.data)\n    elif distance == 'inv':\n        data = 1.0/abs(C.data)\n    elif distance is 'same':\n        data = C.data\n    elif distance is 'min':\n        data = C.data - C.data.min()\n    else:\n        raise ValueError('unrecognized value distance=%s' % distance)\n\n    if C.dtype == complex:\n        data = np.real(data)\n\n    assert(data.min() >= 0)\n\n    G = C.__class__((data, C.indices, C.indptr), shape=C.shape)\n\n    num_seeds = int(min(max(ratio * G.shape[0], 1), G.shape[0]))\n\n    distances, clusters, seeds = lloyd_cluster(G, num_seeds, maxiter=maxiter)\n\n    row = (clusters >= 0).nonzero()[0]\n    col = clusters[row]\n    data = np.ones(len(row), dtype='int8')\n    AggOp = coo_matrix((data, (row, col)),\n                       shape=(G.shape[0], num_seeds)).tocsr()\n    return AggOp, seeds", "response": "Aggregate nodes using Lloyd Clustering."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconjugate Residual algorithm. Solves the linear system Ax = b. Left preconditioning is supported. The matrix A must be Hermitian symmetric (but not necessarily definite). Parameters ---------- A : array, matrix, sparse matrix, LinearOperator n x n, linear system to solve b : array, matrix right hand side, shape is (n,) or (n,1) x0 : array, matrix initial guess, default is a vector of zeros tol : float relative convergence tolerance, i.e. tol is scaled by the preconditioner norm of r_0, or ||r_0||_M. maxiter : int maximum number of allowed iterations xtype : type dtype for the solution, default is automatic type detection M : array, matrix, sparse matrix, LinearOperator n x n, inverted preconditioner, i.e. solve M A x = M b. callback : function User-supplied function is called after each iteration as callback(xk), where xk is the current solution vector residuals : list residuals contains the residual norm history, including the initial residual. The preconditioner norm is used, instead of the Euclidean norm. Returns ------- (xNew, info) xNew : an updated guess to the solution of Ax = b info : halting status of cr == ======================================= 0 successful exit >0 convergence to tolerance not achieved, return iteration count instead. <0 numerical breakdown, or illegal input == ======================================= Notes ----- The LinearOperator class is in scipy.sparse.linalg.interface. Use this class if you prefer to define A or M as a mat-vec routine as opposed to explicitly constructing the matrix. A.psolve(..) is still supported as a legacy. The 2-norm of the preconditioned residual is used both for halting and returned in the residuals list. Examples -------- >>> from pyamg.krylov.cr import cr >>> from pyamg.util.linalg import norm >>> import numpy as np >>> from pyamg.gallery import poisson >>> A = poisson((10,10)) >>> b = np.ones((A.shape[0],)) >>> (x,flag) = cr(A,b, maxiter=2, tol=1e-8) >>> print norm(b - A*x) 10.9370700187 References ---------- .. [1] Yousef Saad, \"Iterative Methods for Sparse Linear Systems, Second Edition\", SIAM, pp. 262-67, 2003 http://www-users.cs.umn.edu/~saad/books.html", "response": "def cr(A, b, x0=None, tol=1e-5, maxiter=None, xtype=None, M=None,\n       callback=None, residuals=None):\n    \"\"\"Conjugate Residual algorithm.\n\n    Solves the linear system Ax = b. Left preconditioning is supported.\n    The matrix A must be Hermitian symmetric (but not necessarily definite).\n\n    Parameters\n    ----------\n    A : array, matrix, sparse matrix, LinearOperator\n        n x n, linear system to solve\n    b : array, matrix\n        right hand side, shape is (n,) or (n,1)\n    x0 : array, matrix\n        initial guess, default is a vector of zeros\n    tol : float\n        relative convergence tolerance, i.e. tol is scaled by the\n        preconditioner norm of r_0, or ||r_0||_M.\n    maxiter : int\n        maximum number of allowed iterations\n    xtype : type\n        dtype for the solution, default is automatic type detection\n    M : array, matrix, sparse matrix, LinearOperator\n        n x n, inverted preconditioner, i.e. solve M A x = M b.\n    callback : function\n        User-supplied function is called after each iteration as\n        callback(xk), where xk is the current solution vector\n    residuals : list\n        residuals contains the residual norm history,\n        including the initial residual.  The preconditioner norm\n        is used, instead of the Euclidean norm.\n\n    Returns\n    -------\n    (xNew, info)\n    xNew : an updated guess to the solution of Ax = b\n    info : halting status of cr\n\n            ==  =======================================\n            0   successful exit\n            >0  convergence to tolerance not achieved,\n                return iteration count instead.\n            <0  numerical breakdown, or illegal input\n            ==  =======================================\n\n    Notes\n    -----\n    The LinearOperator class is in scipy.sparse.linalg.interface.\n    Use this class if you prefer to define A or M as a mat-vec routine\n    as opposed to explicitly constructing the matrix.  A.psolve(..) is\n    still supported as a legacy.\n\n    The 2-norm of the preconditioned residual is used both for halting and\n    returned in the residuals list.\n\n    Examples\n    --------\n    >>> from pyamg.krylov.cr import cr\n    >>> from pyamg.util.linalg import norm\n    >>> import numpy as np\n    >>> from pyamg.gallery import poisson\n    >>> A = poisson((10,10))\n    >>> b = np.ones((A.shape[0],))\n    >>> (x,flag) = cr(A,b, maxiter=2, tol=1e-8)\n    >>> print norm(b - A*x)\n    10.9370700187\n\n    References\n    ----------\n    .. [1] Yousef Saad, \"Iterative Methods for Sparse Linear Systems,\n       Second Edition\", SIAM, pp. 262-67, 2003\n       http://www-users.cs.umn.edu/~saad/books.html\n\n    \"\"\"\n    A, M, x, b, postprocess = make_system(A, M, x0, b)\n    # n = len(b)\n    # Ensure that warnings are always reissued from this function\n    import warnings\n    warnings.filterwarnings('always', module='pyamg\\.krylov\\._cr')\n\n    # determine maxiter\n    if maxiter is None:\n        maxiter = int(1.3*len(b)) + 2\n    elif maxiter < 1:\n        raise ValueError('Number of iterations must be positive')\n\n    # choose tolerance for numerically zero values\n    # t = A.dtype.char\n    # eps = np.finfo(np.float).eps\n    # feps = np.finfo(np.single).eps\n    # geps = np.finfo(np.longfloat).eps\n    # _array_precision = {'f': 0, 'd': 1, 'g': 2, 'F': 0, 'D': 1, 'G': 2}\n    # numerically_zero = {0: feps*1e3, 1: eps*1e6,\n    #                     2: geps*1e6}[_array_precision[t]]\n\n    # setup method\n    r = b - A*x\n    z = M*r\n    p = z.copy()\n    zz = np.inner(z.conjugate(), z)\n\n    # use preconditioner norm\n    normr = np.sqrt(zz)\n\n    if residuals is not None:\n        residuals[:] = [normr]  # initial residual\n\n    # Check initial guess ( scaling by b, if b != 0,\n    #   must account for case when norm(b) is very small)\n    normb = norm(b)\n    if normb == 0.0:\n        normb = 1.0\n    if normr < tol*normb:\n        return (postprocess(x), 0)\n\n    # Scale tol by ||r_0||_M\n    if normr != 0.0:\n        tol = tol*normr\n\n    # How often should r be recomputed\n    recompute_r = 8\n\n    iter = 0\n\n    Az = A*z\n    rAz = np.inner(r.conjugate(), Az)\n    Ap = A*p\n\n    while True:\n\n        rAz_old = rAz\n\n        alpha = rAz / np.inner(Ap.conjugate(), Ap)       # 3\n        x += alpha * p                           # 4\n\n        if np.mod(iter, recompute_r) and iter > 0:       # 5\n            r -= alpha * Ap\n        else:\n            r = b - A*x\n\n        z = M*r\n\n        Az = A*z\n        rAz = np.inner(r.conjugate(), Az)\n\n        beta = rAz/rAz_old                        # 6\n\n        p *= beta                               # 7\n        p += z\n\n        Ap *= beta                               # 8\n        Ap += Az\n\n        iter += 1\n\n        zz = np.inner(z.conjugate(), z)\n        normr = np.sqrt(zz)                          # use preconditioner norm\n\n        if residuals is not None:\n            residuals.append(normr)\n\n        if callback is not None:\n            callback(x)\n\n        if normr < tol:\n            return (postprocess(x), 0)\n        elif zz == 0.0:\n            # important to test after testing normr < tol. rz == 0.0 is an\n            # indicator of convergence when r = 0.0\n            warn(\"\\nSingular preconditioner detected in CR, ceasing \\\n                  iterations\\n\")\n            return (postprocess(x), -1)\n\n        if iter == maxiter:\n            return (postprocess(x), iter)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gmres_householder(A, b, x0=None, tol=1e-5, restrt=None, maxiter=None,\n                      xtype=None, M=None, callback=None, residuals=None):\n    \"\"\"Generalized Minimum Residual Method (GMRES) based on Housholder.\n\n    GMRES iteratively refines the initial solution guess to the\n    system Ax = b\n    Householder reflections are used for orthogonalization\n\n    Parameters\n    ----------\n    A : array, matrix, sparse matrix, LinearOperator\n        n x n, linear system to solve\n    b : array, matrix\n        right hand side, shape is (n,) or (n, 1)\n    x0 : array, matrix\n        initial guess, default is a vector of zeros\n    tol : float\n        relative convergence tolerance, i.e. tol is scaled by the norm\n        of the initial preconditioned residual\n    restrt : None, int\n        - if int, restrt is max number of inner iterations\n          and maxiter is the max number of outer iterations\n        - if None, do not restart GMRES, and max number of inner iterations\n          is maxiter\n    maxiter : None, int\n        - if restrt is None, maxiter is the max number of inner iterations\n          and GMRES does not restart\n        - if restrt is int, maxiter is the max number of outer iterations,\n          and restrt is the max number of inner iterations\n    xtype : type\n        dtype for the solution, default is automatic type detection\n    M : array, matrix, sparse matrix, LinearOperator\n        n x n, inverted preconditioner, i.e. solve M A x = M b.\n    callback : function\n        User-supplied function is called after each iteration as\n        callback(xk), where xk is the current solution vector\n    residuals : list\n        residuals contains the preconditioned residual norm history,\n        including the initial residual.\n\n    Returns\n    -------\n    (xNew, info)\n    xNew : an updated guess to the solution of Ax = b\n    info : halting status of gmres\n\n            ==  =============================================\n            0   successful exit\n            >0  convergence to tolerance not achieved,\n                return iteration count instead.  This value\n                is precisely the order of the Krylov space.\n            <0  numerical breakdown, or illegal input\n            ==  =============================================\n\n    Notes\n    -----\n        - The LinearOperator class is in scipy.sparse.linalg.interface.\n          Use this class if you prefer to define A or M as a mat-vec routine\n          as opposed to explicitly constructing the matrix.  A.psolve(..) is\n          still supported as a legacy.\n        - For robustness, Householder reflections are used to orthonormalize\n          the Krylov Space\n          Givens Rotations are used to provide the residual norm each iteration\n\n    Examples\n    --------\n    >>> from pyamg.krylov import gmres\n    >>> from pyamg.util.linalg import norm\n    >>> import numpy as np\n    >>> from pyamg.gallery import poisson\n    >>> A = poisson((10, 10))\n    >>> b = np.ones((A.shape[0],))\n    >>> (x, flag) = gmres(A, b, maxiter=2, tol=1e-8, orthog='householder')\n    >>> print norm(b - A*x)\n    6.5428213057\n\n    References\n    ----------\n    .. [1] Yousef Saad, \"Iterative Methods for Sparse Linear Systems,\n       Second Edition\", SIAM, pp. 151-172, pp. 272-275, 2003\n       http://www-users.cs.umn.edu/~saad/books.html\n\n    \"\"\"\n    # Convert inputs to linear system, with error checking\n    A, M, x, b, postprocess = make_system(A, M, x0, b)\n    dimen = A.shape[0]\n\n    # Ensure that warnings are always reissued from this function\n    import warnings\n    warnings.filterwarnings('always',\n                            module='pyamg\\.krylov\\._gmres_householder')\n\n    # Choose type\n    if not hasattr(A, 'dtype'):\n        Atype = upcast(x.dtype, b.dtype)\n    else:\n        Atype = A.dtype\n    if not hasattr(M, 'dtype'):\n        Mtype = upcast(x.dtype, b.dtype)\n    else:\n        Mtype = M.dtype\n    xtype = upcast(Atype, x.dtype, b.dtype, Mtype)\n\n    if restrt is not None:\n        restrt = int(restrt)\n    if maxiter is not None:\n        maxiter = int(maxiter)\n\n    # Should norm(r) be kept\n    if residuals == []:\n        keep_r = True\n    else:\n        keep_r = False\n\n    # Set number of outer and inner iterations\n    if restrt:\n        if maxiter:\n            max_outer = maxiter\n        else:\n            max_outer = 1\n        if restrt > dimen:\n            warn('Setting number of inner iterations (restrt) to maximum \\\n                  allowed, which is A.shape[0] ')\n            restrt = dimen\n        max_inner = restrt\n    else:\n        max_outer = 1\n        if maxiter > dimen:\n            warn('Setting number of inner iterations (maxiter) to maximum \\\n                  allowed, which is A.shape[0] ')\n            maxiter = dimen\n        elif maxiter is None:\n            maxiter = min(dimen, 40)\n        max_inner = maxiter\n\n    # Get fast access to underlying LAPACK routine\n    [lartg] = get_lapack_funcs(['lartg'], [x])\n\n    # Is this a one dimensional matrix?\n    if dimen == 1:\n        entry = np.ravel(A*np.array([1.0], dtype=xtype))\n        return (postprocess(b/entry), 0)\n\n    # Prep for method\n    r = b - np.ravel(A*x)\n\n    # Apply preconditioner\n    r = np.ravel(M*r)\n    normr = norm(r)\n    if keep_r:\n        residuals.append(normr)\n    # Check for nan, inf\n    # if isnan(r).any() or isinf(r).any():\n    #    warn('inf or nan after application of preconditioner')\n    #    return(postprocess(x), -1)\n\n    # Check initial guess ( scaling by b, if b != 0,\n    #   must account for case when norm(b) is very small)\n    normb = norm(b)\n    if normb == 0.0:\n        normb = 1.0\n    if normr < tol*normb:\n        return (postprocess(x), 0)\n\n    # Scale tol by ||r_0||_2, we use the preconditioned residual\n    # because this is left preconditioned GMRES.\n    if normr != 0.0:\n        tol = tol*normr\n\n    # Use separate variable to track iterations.  If convergence fails, we\n    # cannot simply report niter = (outer-1)*max_outer + inner.  Numerical\n    # error could cause the inner loop to halt while the actual ||r|| > tol.\n    niter = 0\n\n    # Begin GMRES\n    for outer in range(max_outer):\n\n        # Calculate vector w, which defines the Householder reflector\n        #    Take shortcut in calculating,\n        #    w = r + sign(r[1])*||r||_2*e_1\n        w = r\n        beta = mysign(w[0])*normr\n        w[0] = w[0] + beta\n        w[:] = w / norm(w)\n\n        # Preallocate for Krylov vectors, Householder reflectors and\n        # Hessenberg matrix\n        # Space required is O(dimen*max_inner)\n        # Givens Rotations\n        Q = np.zeros((4*max_inner,), dtype=xtype)\n        # upper Hessenberg matrix (made upper tri with Givens Rotations)\n        H = np.zeros((max_inner, max_inner), dtype=xtype)\n        # Householder reflectors\n        W = np.zeros((max_inner+1, dimen), dtype=xtype)\n        W[0, :] = w\n\n        # Multiply r with (I - 2*w*w.T), i.e. apply the Householder reflector\n        # This is the RHS vector for the problem in the Krylov Space\n        g = np.zeros((dimen,), dtype=xtype)\n        g[0] = -beta\n\n        for inner in range(max_inner):\n            # Calculate Krylov vector in two steps\n            # (1) Calculate v = P_j = (I - 2*w*w.T)v, where k = inner\n            v = -2.0*np.conjugate(w[inner])*w\n            v[inner] = v[inner] + 1.0\n            # (2) Calculate the rest, v = P_1*P_2*P_3...P_{j-1}*ej.\n            # for j in range(inner-1,-1,-1):\n            #    v -= 2.0*dot(conjugate(W[j,:]), v)*W[j,:]\n            amg_core.apply_householders(v, np.ravel(W), dimen, inner-1, -1, -1)\n\n            # Calculate new search direction\n            v = np.ravel(A*v)\n\n            # Apply preconditioner\n            v = np.ravel(M*v)\n            # Check for nan, inf\n            # if isnan(v).any() or isinf(v).any():\n            #    warn('inf or nan after application of preconditioner')\n            #    return(postprocess(x), -1)\n\n            # Factor in all Householder orthogonal reflections on new search\n            # direction\n            # for j in range(inner+1):\n            #    v -= 2.0*dot(conjugate(W[j,:]), v)*W[j,:]\n            amg_core.apply_householders(v, np.ravel(W), dimen, 0, inner+1, 1)\n\n            # Calculate next Householder reflector, w\n            #  w = v[inner+1:] + sign(v[inner+1])*||v[inner+1:]||_2*e_{inner+1)\n            #  Note that if max_inner = dimen, then this is unnecessary for the\n            #  last inner iteration, when inner = dimen-1.  Here we do not need\n            #  to calculate a Householder reflector or Givens rotation because\n            #  nnz(v) is already the desired length, i.e. we do not need to\n            #  zero anything out.\n            if inner != dimen-1:\n                if inner < (max_inner-1):\n                    w = W[inner+1, :]\n                vslice = v[inner+1:]\n                alpha = norm(vslice)\n                if alpha != 0:\n                    alpha = mysign(vslice[0])*alpha\n                    # do not need the final reflector for future calculations\n                    if inner < (max_inner-1):\n                        w[inner+1:] = vslice\n                        w[inner+1] += alpha\n                        w[:] = w / norm(w)\n\n                    # Apply new reflector to v\n                    #  v = v - 2.0*w*(w.T*v)\n                    v[inner+1] = -alpha\n                    v[inner+2:] = 0.0\n\n            if inner > 0:\n                # Apply all previous Givens Rotations to v\n                amg_core.apply_givens(Q, v, dimen, inner)\n\n            # Calculate the next Givens rotation, where j = inner Note that if\n            # max_inner = dimen, then this is unnecessary for the last inner\n            # iteration, when inner = dimen-1.  Here we do not need to\n            # calculate a Householder reflector or Givens rotation because\n            # nnz(v) is already the desired length, i.e. we do not need to zero\n            # anything out.\n            if inner != dimen-1:\n                if v[inner+1] != 0:\n                    [c, s, r] = lartg(v[inner], v[inner+1])\n                    Qblock = np.array([[c, s], [-np.conjugate(s), c]],\n                                      dtype=xtype)\n                    Q[(inner*4): ((inner+1)*4)] = np.ravel(Qblock).copy()\n\n                    # Apply Givens Rotation to g, the RHS for the linear system\n                    # in the Krylov Subspace.  Note that this dot does a matrix\n                    # multiply, not an actual dot product where a conjugate\n                    # transpose is taken\n                    g[inner:inner+2] = np.dot(Qblock, g[inner:inner+2])\n\n                    # Apply effect of Givens Rotation to v\n                    v[inner] = np.dot(Qblock[0, :], v[inner:inner+2])\n                    v[inner+1] = 0.0\n\n            # Write to upper Hessenberg Matrix,\n            #   the LHS for the linear system in the Krylov Subspace\n            H[:, inner] = v[0:max_inner]\n\n            niter += 1\n\n            # Don't update normr if last inner iteration, because\n            # normr is calculated directly after this loop ends.\n            if inner < max_inner-1:\n                normr = np.abs(g[inner+1])\n                if normr < tol:\n                    break\n\n                # Allow user access to the iterates\n                if callback is not None:\n                    callback(x)\n                if keep_r:\n                    residuals.append(normr)\n\n        # end inner loop, back to outer loop\n\n        # Find best update to x in Krylov Space, V.  Solve inner+1 x inner+1\n        # system.  Apparently this is the best way to solve a triangular system\n        # in the magical world of scipy\n        # piv = arange(inner+1)\n        # y = lu_solve((H[0:(inner+1), 0:(inner+1)], piv), g[0:(inner+1)],\n        #             trans=0)\n        y = sp.linalg.solve(H[0:(inner+1), 0:(inner+1)], g[0:(inner+1)])\n\n        # Use Horner like Scheme to map solution, y, back to original space.\n        # Note that we do not use the last reflector.\n        update = np.zeros(x.shape, dtype=xtype)\n        # for j in range(inner,-1,-1):\n        #    update[j] += y[j]\n        #    # Apply j-th reflector, (I - 2.0*w_j*w_j.T)*upadate\n        #    update -= 2.0*dot(conjugate(W[j,:]), update)*W[j,:]\n        amg_core.householder_hornerscheme(update, np.ravel(W), np.ravel(y),\n                                          dimen, inner, -1, -1)\n\n        x[:] = x + update\n        r = b - np.ravel(A*x)\n\n        # Apply preconditioner\n        r = np.ravel(M*r)\n        normr = norm(r)\n        # Check for nan, inf\n        # if isnan(r).any() or isinf(r).any():\n        #    warn('inf or nan after application of preconditioner')\n        #    return(postprocess(x), -1)\n\n        # Allow user access to the iterates\n        if callback is not None:\n            callback(x)\n        if keep_r:\n            residuals.append(normr)\n\n        # Has GMRES stagnated?\n        indices = (x != 0)\n        if indices.any():\n            change = np.max(np.abs(update[indices] / x[indices]))\n            if change < 1e-12:\n                # No change, halt\n                return (postprocess(x), -1)\n\n        # test for convergence\n        if normr < tol:\n            return (postprocess(x), 0)\n\n    # end outer loop\n\n    return (postprocess(x), niter)", "response": "Generalized Minimum Residual Method for Housholder."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns row i in BSR matrix A.", "response": "def BSR_Get_Row(A, i):\n    \"\"\"Return row i in BSR matrix A.\n\n    Only nonzero entries are returned\n\n    Parameters\n    ----------\n    A : bsr_matrix\n        Input matrix\n    i : int\n        Row number\n\n    Returns\n    -------\n    z : array\n        Actual nonzero values for row i colindx Array of column indices for the\n        nonzeros of row i\n\n    Examples\n    --------\n    >>> from numpy import array\n    >>> from scipy.sparse import bsr_matrix\n    >>> from pyamg.util.BSR_utils import BSR_Get_Row\n    >>> indptr  = array([0,2,3,6])\n    >>> indices = array([0,2,2,0,1,2])\n    >>> data    = array([1,2,3,4,5,6]).repeat(4).reshape(6,2,2)\n    >>> B = bsr_matrix( (data,indices,indptr), shape=(6,6) )\n    >>> Brow = BSR_Get_Row(B,2)\n    >>> print Brow[1]\n    [4 5]\n\n    \"\"\"\n    blocksize = A.blocksize[0]\n    BlockIndx = int(i/blocksize)\n    rowstart = A.indptr[BlockIndx]\n    rowend = A.indptr[BlockIndx+1]\n    localRowIndx = i % blocksize\n\n    # Get z\n    indys = A.data[rowstart:rowend, localRowIndx, :].nonzero()\n    z = A.data[rowstart:rowend, localRowIndx, :][indys[0], indys[1]]\n\n    colindx = np.zeros((1, z.__len__()), dtype=np.int32)\n    counter = 0\n\n    for j in range(rowstart, rowend):\n        coloffset = blocksize*A.indices[j]\n        indys = A.data[j, localRowIndx, :].nonzero()[0]\n        increment = indys.shape[0]\n        colindx[0, counter:(counter+increment)] = coloffset + indys\n        counter += increment\n\n    return np.mat(z).T, colindx[0, :]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef BSR_Row_WriteScalar(A, i, x):\n    blocksize = A.blocksize[0]\n    BlockIndx = int(i/blocksize)\n    rowstart = A.indptr[BlockIndx]\n    rowend = A.indptr[BlockIndx+1]\n    localRowIndx = i % blocksize\n\n    # for j in range(rowstart, rowend):\n    #   indys = A.data[j,localRowIndx,:].nonzero()[0]\n    #   increment = indys.shape[0]\n    #   A.data[j,localRowIndx,indys] = x\n\n    indys = A.data[rowstart:rowend, localRowIndx, :].nonzero()\n    A.data[rowstart:rowend, localRowIndx, :][indys[0], indys[1]] = x", "response": "Write a scalar at each nonzero location in row i of BSR matrix A."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef BSR_Row_WriteVect(A, i, x):\n    blocksize = A.blocksize[0]\n    BlockIndx = int(i/blocksize)\n    rowstart = A.indptr[BlockIndx]\n    rowend = A.indptr[BlockIndx+1]\n    localRowIndx = i % blocksize\n\n    # like matlab slicing:\n    x = x.__array__().reshape((max(x.shape),))\n\n    # counter = 0\n    # for j in range(rowstart, rowend):\n    #   indys = A.data[j,localRowIndx,:].nonzero()[0]\n    #   increment = min(indys.shape[0], blocksize)\n    #   A.data[j,localRowIndx,indys] = x[counter:(counter+increment), 0]\n    #   counter += increment\n\n    indys = A.data[rowstart:rowend, localRowIndx, :].nonzero()\n    A.data[rowstart:rowend, localRowIndx, :][indys[0], indys[1]] = x", "response": "This routine writes the vector x to the row i of A in BSR format."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a prolongator using direct interpolation.", "response": "def direct_interpolation(A, C, splitting):\n    \"\"\"Create prolongator using direct interpolation.\n\n    Parameters\n    ----------\n    A : csr_matrix\n        NxN matrix in CSR format\n    C : csr_matrix\n        Strength-of-Connection matrix\n        Must have zero diagonal\n    splitting : array\n        C/F splitting stored in an array of length N\n\n    Returns\n    -------\n    P : csr_matrix\n        Prolongator using direct interpolation\n\n    Examples\n    --------\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.classical import direct_interpolation\n    >>> import numpy as np\n    >>> A = poisson((5,),format='csr')\n    >>> splitting = np.array([1,0,1,0,1], dtype='intc')\n    >>> P = direct_interpolation(A, A, splitting)\n    >>> print P.todense()\n    [[ 1.   0.   0. ]\n     [ 0.5  0.5  0. ]\n     [ 0.   1.   0. ]\n     [ 0.   0.5  0.5]\n     [ 0.   0.   1. ]]\n\n    \"\"\"\n    if not isspmatrix_csr(A):\n        raise TypeError('expected csr_matrix for A')\n\n    if not isspmatrix_csr(C):\n        raise TypeError('expected csr_matrix for C')\n\n    # Interpolation weights are computed based on entries in A, but subject to\n    # the sparsity pattern of C.  So, copy the entries of A into the\n    # sparsity pattern of C.\n    C = C.copy()\n    C.data[:] = 1.0\n    C = C.multiply(A)\n\n    Pp = np.empty_like(A.indptr)\n\n    amg_core.rs_direct_interpolation_pass1(A.shape[0],\n                                           C.indptr, C.indices, splitting, Pp)\n\n    nnz = Pp[-1]\n    Pj = np.empty(nnz, dtype=Pp.dtype)\n    Px = np.empty(nnz, dtype=A.dtype)\n\n    amg_core.rs_direct_interpolation_pass2(A.shape[0],\n                                           A.indptr, A.indices, A.data,\n                                           C.indptr, C.indices, C.data,\n                                           splitting,\n                                           Pp, Pj, Px)\n\n    return csr_matrix((Px, Pj, Pp))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply_givens(Q, v, k):\n    for j in range(k):\n        Qloc = Q[j]\n        v[j:j+2] = np.dot(Qloc, v[j:j+2])", "response": "Applies the first k Givens rotations in Q to v."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngeneralizing Minimum Residual Method for the GMRES algorithm.", "response": "def gmres_mgs(A, b, x0=None, tol=1e-5, restrt=None, maxiter=None, xtype=None,\n              M=None, callback=None, residuals=None, reorth=False):\n    \"\"\"Generalized Minimum Residual Method (GMRES) based on MGS.\n\n    GMRES iteratively refines the initial solution guess to the system\n    Ax = b\n    Modified Gram-Schmidt version\n\n    Parameters\n    ----------\n    A : array, matrix, sparse matrix, LinearOperator\n        n x n, linear system to solve\n    b : array, matrix\n        right hand side, shape is (n,) or (n,1)\n    x0 : array, matrix\n        initial guess, default is a vector of zeros\n    tol : float\n        relative convergence tolerance, i.e. tol is scaled by the norm\n        of the initial preconditioned residual\n    restrt : None, int\n        - if int, restrt is max number of inner iterations\n          and maxiter is the max number of outer iterations\n        - if None, do not restart GMRES, and max number of inner iterations\n          is maxiter\n    maxiter : None, int\n        - if restrt is None, maxiter is the max number of inner iterations\n          and GMRES does not restart\n        - if restrt is int, maxiter is the max number of outer iterations,\n          and restrt is the max number of inner iterations\n    xtype : type\n        dtype for the solution, default is automatic type detection\n    M : array, matrix, sparse matrix, LinearOperator\n        n x n, inverted preconditioner, i.e. solve M A x = M b.\n    callback : function\n        User-supplied function is called after each iteration as\n        callback(xk), where xk is the current solution vector\n    residuals : list\n        residuals contains the preconditioned residual norm history,\n        including the initial residual.\n    reorth : boolean\n        If True, then a check is made whether to re-orthogonalize the Krylov\n        space each GMRES iteration\n\n    Returns\n    -------\n    (xNew, info)\n    xNew : an updated guess to the solution of Ax = b\n    info : halting status of gmres\n\n            ==  =============================================\n            0   successful exit\n            >0  convergence to tolerance not achieved,\n                return iteration count instead.  This value\n                is precisely the order of the Krylov space.\n            <0  numerical breakdown, or illegal input\n            ==  =============================================\n\n    Notes\n    -----\n        - The LinearOperator class is in scipy.sparse.linalg.interface.\n          Use this class if you prefer to define A or M as a mat-vec routine\n          as opposed to explicitly constructing the matrix.  A.psolve(..) is\n          still supported as a legacy.\n        - For robustness, modified Gram-Schmidt is used to orthogonalize the\n          Krylov Space Givens Rotations are used to provide the residual norm\n          each iteration\n\n    Examples\n    --------\n    >>> from pyamg.krylov import gmres\n    >>> from pyamg.util.linalg import norm\n    >>> import numpy as np\n    >>> from pyamg.gallery import poisson\n    >>> A = poisson((10,10))\n    >>> b = np.ones((A.shape[0],))\n    >>> (x,flag) = gmres(A,b, maxiter=2, tol=1e-8, orthog='mgs')\n    >>> print norm(b - A*x)\n    >>> 6.5428213057\n\n    References\n    ----------\n    .. [1] Yousef Saad, \"Iterative Methods for Sparse Linear Systems,\n       Second Edition\", SIAM, pp. 151-172, pp. 272-275, 2003\n       http://www-users.cs.umn.edu/~saad/books.html\n\n    .. [2] C. T. Kelley, http://www4.ncsu.edu/~ctk/matlab_roots.html\n\n    \"\"\"\n    # Convert inputs to linear system, with error checking\n    A, M, x, b, postprocess = make_system(A, M, x0, b)\n    dimen = A.shape[0]\n\n    # Ensure that warnings are always reissued from this function\n    import warnings\n    warnings.filterwarnings('always', module='pyamg\\.krylov\\._gmres_mgs')\n\n    # Choose type\n    if not hasattr(A, 'dtype'):\n        Atype = upcast(x.dtype, b.dtype)\n    else:\n        Atype = A.dtype\n    if not hasattr(M, 'dtype'):\n        Mtype = upcast(x.dtype, b.dtype)\n    else:\n        Mtype = M.dtype\n    xtype = upcast(Atype, x.dtype, b.dtype, Mtype)\n\n    if restrt is not None:\n        restrt = int(restrt)\n    if maxiter is not None:\n        maxiter = int(maxiter)\n\n    # Get fast access to underlying BLAS routines\n    # dotc is the conjugate dot, dotu does no conjugation\n    [lartg] = get_lapack_funcs(['lartg'], [x])\n    if np.iscomplexobj(np.zeros((1,), dtype=xtype)):\n        [axpy, dotu, dotc, scal] =\\\n            get_blas_funcs(['axpy', 'dotu', 'dotc', 'scal'], [x])\n    else:\n        # real type\n        [axpy, dotu, dotc, scal] =\\\n            get_blas_funcs(['axpy', 'dot', 'dot', 'scal'], [x])\n\n    # Make full use of direct access to BLAS by defining own norm\n    def norm(z):\n        return np.sqrt(np.real(dotc(z, z)))\n\n    # Should norm(r) be kept\n    if residuals == []:\n        keep_r = True\n    else:\n        keep_r = False\n\n    # Set number of outer and inner iterations\n    if restrt:\n        if maxiter:\n            max_outer = maxiter\n        else:\n            max_outer = 1\n        if restrt > dimen:\n            warn('Setting number of inner iterations (restrt) to maximum\\\n                  allowed, which is A.shape[0] ')\n            restrt = dimen\n        max_inner = restrt\n    else:\n        max_outer = 1\n        if maxiter > dimen:\n            warn('Setting number of inner iterations (maxiter) to maximum\\\n                  allowed, which is A.shape[0] ')\n            maxiter = dimen\n        elif maxiter is None:\n            maxiter = min(dimen, 40)\n        max_inner = maxiter\n\n    # Is this a one dimensional matrix?\n    if dimen == 1:\n        entry = np.ravel(A*np.array([1.0], dtype=xtype))\n        return (postprocess(b/entry), 0)\n\n    # Prep for method\n    r = b - np.ravel(A*x)\n\n    # Apply preconditioner\n    r = np.ravel(M*r)\n    normr = norm(r)\n    if keep_r:\n        residuals.append(normr)\n    # Check for nan, inf\n    # if isnan(r).any() or isinf(r).any():\n    #    warn('inf or nan after application of preconditioner')\n    #    return(postprocess(x), -1)\n\n    # Check initial guess ( scaling by b, if b != 0,\n    #   must account for case when norm(b) is very small)\n    normb = norm(b)\n    if normb == 0.0:\n        normb = 1.0\n    if normr < tol*normb:\n        return (postprocess(x), 0)\n\n    # Scale tol by ||r_0||_2, we use the preconditioned residual\n    # because this is left preconditioned GMRES.\n    if normr != 0.0:\n        tol = tol*normr\n\n    # Use separate variable to track iterations.  If convergence fails, we\n    # cannot simply report niter = (outer-1)*max_outer + inner.  Numerical\n    # error could cause the inner loop to halt while the actual ||r|| > tol.\n    niter = 0\n\n    # Begin GMRES\n    for outer in range(max_outer):\n\n        # Preallocate for Givens Rotations, Hessenberg matrix and Krylov Space\n        # Space required is O(dimen*max_inner).\n        # NOTE:  We are dealing with row-major matrices, so we traverse in a\n        #        row-major fashion,\n        #        i.e., H and V's transpose is what we store.\n        Q = []  # Givens Rotations\n        # Upper Hessenberg matrix, which is then\n        #   converted to upper tri with Givens Rots\n        H = np.zeros((max_inner+1, max_inner+1), dtype=xtype)\n        V = np.zeros((max_inner+1, dimen), dtype=xtype)  # Krylov Space\n        # vs store the pointers to each column of V.\n        #   This saves a considerable amount of time.\n        vs = []\n        # v = r/normr\n        V[0, :] = scal(1.0/normr, r)\n        vs.append(V[0, :])\n\n        # This is the RHS vector for the problem in the Krylov Space\n        g = np.zeros((dimen,), dtype=xtype)\n        g[0] = normr\n\n        for inner in range(max_inner):\n\n            # New Search Direction\n            v = V[inner+1, :]\n            v[:] = np.ravel(M*(A*vs[-1]))\n            vs.append(v)\n            normv_old = norm(v)\n\n            # Check for nan, inf\n            # if isnan(V[inner+1, :]).any() or isinf(V[inner+1, :]).any():\n            #    warn('inf or nan after application of preconditioner')\n            #    return(postprocess(x), -1)\n\n            #  Modified Gram Schmidt\n            for k in range(inner+1):\n                vk = vs[k]\n                alpha = dotc(vk, v)\n                H[inner, k] = alpha\n                v[:] = axpy(vk, v, dimen, -alpha)\n\n            normv = norm(v)\n            H[inner, inner+1] = normv\n\n            # Re-orthogonalize\n            if (reorth is True) and (normv_old == normv_old + 0.001*normv):\n                for k in range(inner+1):\n                    vk = vs[k]\n                    alpha = dotc(vk, v)\n                    H[inner, k] = H[inner, k] + alpha\n                    v[:] = axpy(vk, v, dimen, -alpha)\n\n            # Check for breakdown\n            if H[inner, inner+1] != 0.0:\n                v[:] = scal(1.0/H[inner, inner+1], v)\n\n            # Apply previous Givens rotations to H\n            if inner > 0:\n                apply_givens(Q, H[inner, :], inner)\n\n            # Calculate and apply next complex-valued Givens Rotation\n            # ==> Note that if max_inner = dimen, then this is unnecessary\n            # for the last inner\n            #     iteration, when inner = dimen-1.\n            if inner != dimen-1:\n                if H[inner, inner+1] != 0:\n                    [c, s, r] = lartg(H[inner, inner], H[inner, inner+1])\n                    Qblock = np.array([[c, s], [-np.conjugate(s), c]],\n                                      dtype=xtype)\n                    Q.append(Qblock)\n\n                    # Apply Givens Rotation to g,\n                    #   the RHS for the linear system in the Krylov Subspace.\n                    g[inner:inner+2] = np.dot(Qblock, g[inner:inner+2])\n\n                    # Apply effect of Givens Rotation to H\n                    H[inner, inner] = dotu(Qblock[0, :],\n                                           H[inner, inner:inner+2])\n                    H[inner, inner+1] = 0.0\n\n            niter += 1\n\n            # Don't update normr if last inner iteration, because\n            # normr is calculated directly after this loop ends.\n            if inner < max_inner-1:\n                normr = np.abs(g[inner+1])\n                if normr < tol:\n                    break\n\n                # Allow user access to the iterates\n                if callback is not None:\n                    callback(x)\n                if keep_r:\n                    residuals.append(normr)\n\n        # end inner loop, back to outer loop\n\n        # Find best update to x in Krylov Space V.  Solve inner x inner system.\n        y = sp.linalg.solve(H[0:inner+1, 0:inner+1].T, g[0:inner+1])\n        update = np.ravel(np.mat(V[:inner+1, :]).T*y.reshape(-1, 1))\n        x = x + update\n        r = b - np.ravel(A*x)\n\n        # Apply preconditioner\n        r = np.ravel(M*r)\n        normr = norm(r)\n        # Check for nan, inf\n        # if isnan(r).any() or isinf(r).any():\n        #    warn('inf or nan after application of preconditioner')\n        #    return(postprocess(x), -1)\n\n        # Allow user access to the iterates\n        if callback is not None:\n            callback(x)\n        if keep_r:\n            residuals.append(normr)\n\n        # Has GMRES stagnated?\n        indices = (x != 0)\n        if indices.any():\n            change = np.max(np.abs(update[indices] / x[indices]))\n            if change < 1e-12:\n                # No change, halt\n                return (postprocess(x), -1)\n\n        # test for convergence\n        if normr < tol:\n            return (postprocess(x), 0)\n\n    # end outer loop\n\n    return (postprocess(x), niter)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngeneralizes Minimum Residual Method GMRES iteratively refines the initial guess to the system Ax = b.", "response": "def gmres(A, b, x0=None, tol=1e-5, restrt=None, maxiter=None, xtype=None,\n          M=None, callback=None, residuals=None, orthog='householder',\n          **kwargs):\n    \"\"\"Generalized Minimum Residual Method (GMRES).\n\n    GMRES iteratively refines the initial solution guess to the\n    system Ax = b\n\n    Parameters\n    ----------\n    A : array, matrix, sparse matrix, LinearOperator\n        n x n, linear system to solve\n    b : array, matrix\n        right hand side, shape is (n,) or (n,1)\n    x0 : array, matrix\n        initial guess, default is a vector of zeros\n    tol : float\n        relative convergence tolerance, i.e. tol is scaled by the norm\n        of the initial preconditioned residual\n    restrt : None, int\n        - if int, restrt is max number of inner iterations\n          and maxiter is the max number of outer iterations\n        - if None, do not restart GMRES, and max number of inner iterations\n          is maxiter\n    maxiter : None, int\n        - if restrt is None, maxiter is the max number of inner iterations\n          and GMRES does not restart\n        - if restrt is int, maxiter is the max number of outer iterations,\n          and restrt is the max number of inner iterations\n    xtype : type\n        dtype for the solution, default is automatic type detection\n    M : array, matrix, sparse matrix, LinearOperator\n        n x n, inverted preconditioner, i.e. solve M A x = M b.\n    callback : function\n        User-supplied function is called after each iteration as\n        callback( ||rk||_2 ), where rk is the current preconditioned residual\n        vector\n    residuals : list\n        residuals contains the preconditioned residual norm history,\n        including the initial residual.\n    orthog : string\n        'householder' calls _gmres_householder which uses Householder\n        reflections to find the orthogonal basis for the Krylov space.\n        'mgs' calls _gmres_mgs which uses modified Gram-Schmidt to find the\n        orthogonal basis for the Krylov space\n\n    Returns\n    -------\n    (xNew, info)\n    xNew : an updated guess to the solution of Ax = b\n    info : halting status of gmres\n\n            ==  =============================================\n            0   successful exit\n            >0  convergence to tolerance not achieved,\n                return iteration count instead.  This value\n                is precisely the order of the Krylov space.\n            <0  numerical breakdown, or illegal input\n            ==  =============================================\n\n    Notes\n    -----\n        - The LinearOperator class is in scipy.sparse.linalg.interface.\n          Use this class if you prefer to define A or M as a mat-vec routine\n          as opposed to explicitly constructing the matrix.  A.psolve(..) is\n          still supported as a legacy.\n        - The orthogonalization method, orthog='householder', is more robust\n          than orthog='mgs', however for the majority of problems your\n          problem will converge before 'mgs' loses orthogonality in your basis.\n        - orthog='householder' has been more rigorously tested, and is\n          therefore currently the default\n\n\n    Examples\n    --------\n    >>> from pyamg.krylov import gmres\n    >>> from pyamg.util.linalg import norm\n    >>> import numpy as np\n    >>> from pyamg.gallery import poisson\n    >>> A = poisson((10,10))\n    >>> b = np.ones((A.shape[0],))\n    >>> (x,flag) = gmres(A,b, maxiter=2, tol=1e-8)\n    >>> print norm(b - A*x)\n    6.5428213057\n\n    References\n    ----------\n    .. [1] Yousef Saad, \"Iterative Methods for Sparse Linear Systems,\n       Second Edition\", SIAM, pp. 151-172, pp. 272-275, 2003\n       http://www-users.cs.umn.edu/~saad/books.html\n\n    \"\"\"\n    # pass along **kwargs\n    if orthog == 'householder':\n        (x, flag) = gmres_householder(A, b, x0=x0, tol=tol, restrt=restrt,\n                                      maxiter=maxiter, xtype=xtype, M=M,\n                                      callback=callback, residuals=residuals,\n                                      **kwargs)\n    elif orthog == 'mgs':\n        (x, flag) = gmres_mgs(A, b, x0=x0, tol=tol, restrt=restrt,\n                              maxiter=maxiter, xtype=xtype, M=M,\n                              callback=callback, residuals=residuals, **kwargs)\n\n    return (x, flag)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef diffusion_stencil_2d(epsilon=1.0, theta=0.0, type='FE'):\n    eps = float(epsilon)  # for brevity\n    theta = float(theta)\n\n    C = np.cos(theta)\n    S = np.sin(theta)\n    CS = C*S\n    CC = C**2\n    SS = S**2\n\n    if(type == 'FE'):\n        \"\"\"FE approximation to::\n\n            - (eps c^2 +     s^2) u_xx +\n            -2(eps - 1) c s       u_xy +\n            - (    c^2 + eps s^2) u_yy\n\n            [ -c^2*eps-s^2+3*c*s*(eps-1)-c^2-s^2*eps,\n              2*c^2*eps+2*s^2-4*c^2-4*s^2*eps,\n              -c^2*eps-s^2-3*c*s*(eps-1)-c^2-s^2*eps]\n\n            [-4*c^2*eps-4*s^2+2*c^2+2*s^2*eps,\n             8*c^2*eps+8*s^2+8*c^2+8*s^2*eps,\n             -4*c^2*eps-4*s^2+2*c^2+2*s^2*eps]\n\n            [-c^2*eps-s^2-3*c*s*(eps-1)-c^2-s^2*eps,\n             2*c^2*eps+2*s^2-4*c^2-4*s^2*eps,\n             -c^2*eps-s^2+3*c*s*(eps-1)-c^2-s^2*eps]\n\n            c = cos(theta)\n            s = sin(theta)\n        \"\"\"\n\n        a = (-1*eps - 1)*CC + (-1*eps - 1)*SS + (3*eps - 3)*CS\n        b = (2*eps - 4)*CC + (-4*eps + 2)*SS\n        c = (-1*eps - 1)*CC + (-1*eps - 1)*SS + (-3*eps + 3)*CS\n        d = (-4*eps + 2)*CC + (2*eps - 4)*SS\n        e = (8*eps + 8)*CC + (8*eps + 8)*SS\n\n        stencil = np.array([[a, b, c],\n                            [d, e, d],\n                            [c, b, a]]) / 6.0\n\n    elif type == 'FD':\n        \"\"\"FD approximation to:\n\n        - (eps c^2 +     s^2) u_xx +\n        -2(eps - 1) c s       u_xy +\n        - (    c^2 + eps s^2) u_yy\n\n          c = cos(theta)\n          s = sin(theta)\n\n        A = [ 1/2(eps - 1) c s    -(c^2 + eps s^2)    -1/2(eps - 1) c s  ]\n            [                                                            ]\n            [ -(eps c^2 + s^2)       2 (eps + 1)    -(eps c^2 + s^2)     ]\n            [                                                            ]\n            [  -1/2(eps - 1) c s    -(c^2 + eps s^2)  1/2(eps - 1) c s   ]\n        \"\"\"\n\n        a = 0.5*(eps - 1)*CS\n        b = -(eps*SS + CC)\n        c = -a\n        d = -(eps*CC + SS)\n        e = 2.0*(eps + 1)\n\n        stencil = np.array([[a, b, c],\n                            [d, e, d],\n                            [c, b, a]])\n\n    return stencil", "response": "Rotated Anisotropic diffusion in 2d of the form."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _symbolic_rotation_helper():\n    from sympy import symbols, Matrix\n\n    cpsi, spsi = symbols('cpsi, spsi')\n    cth, sth = symbols('cth, sth')\n    cphi, sphi = symbols('cphi, sphi')\n    Rpsi = Matrix([[cpsi, spsi, 0], [-spsi, cpsi, 0], [0, 0, 1]])\n    Rth = Matrix([[1, 0, 0], [0, cth, sth], [0, -sth, cth]])\n    Rphi = Matrix([[cphi, sphi, 0], [-sphi, cphi, 0], [0, 0, 1]])\n\n    Q = Rpsi * Rth * Rphi\n\n    epsy, epsz = symbols('epsy, epsz')\n    A = Matrix([[1, 0, 0], [0, epsy, 0], [0, 0, epsz]])\n\n    D = Q * A * Q.T\n\n    for i in range(3):\n        for j in range(3):\n            print('D[%d, %d] = %s' % (i, j, D[i, j]))", "response": "Use SymPy to generate the 3D rotation matrix and products for diffusion_stencil_3d."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing SymPy to generate the 3D products for diffusion_stencil_3d.", "response": "def _symbolic_product_helper():\n    \"\"\"Use SymPy to generate the 3D products for diffusion_stencil_3d.\"\"\"\n    from sympy import symbols, Matrix\n\n    D11, D12, D13, D21, D22, D23, D31, D32, D33 =\\\n        symbols('D11, D12, D13, D21, D22, D23, D31, D32, D33')\n\n    D = Matrix([[D11, D12, D13], [D21, D22, D23], [D31, D32, D33]])\n    grad = Matrix([['dx', 'dy', 'dz']]).T\n    div = grad.T\n\n    a = div * D * grad\n\n    print(a[0])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef diffusion_stencil_3d(epsilony=1.0, epsilonz=1.0, theta=0.0, phi=0.0,\n                         psi=0.0, type='FD'):\n    \"\"\"Rotated Anisotropic diffusion in 3d of the form.\n\n    -div Q A Q^T grad u\n\n    Q = Rpsi Rtheta Rphi\n\n    Rpsi = [ c   s   0 ]\n           [-s   c   0 ]\n           [ 0   0   1 ]\n           c = cos(psi)\n           s = sin(psi)\n\n    Rtheta = [ 1   0   0 ]\n             [ 0   c   s ]\n             [ 0  -s   c ]\n           c = cos(theta)\n           s = sin(theta)\n\n    Rphi = [ c   s   0 ]\n           [-s   c   0 ]\n           [ 0   0   1 ]\n           c = cos(phi)\n           s = sin(phi)\n\n    Here Euler Angles are used:\n    http://en.wikipedia.org/wiki/Euler_angles\n\n    This results in\n\n    Q = [   cphi*cpsi - cth*sphi*spsi, cpsi*sphi + cphi*cth*spsi, spsi*sth]\n        [ - cphi*spsi - cpsi*cth*sphi, cphi*cpsi*cth - sphi*spsi, cpsi*sth]\n        [                    sphi*sth,                 -cphi*sth,      cth]\n\n    A = [1          0            ]\n        [0          epsy         ]\n        [0          0        epsz]\n\n    D = Q A Q^T\n\n    Parameters\n    ----------\n    epsilony  : float, optional\n        Anisotropic diffusion coefficient in the y-direction\n        where A = [1 0 0; 0 epsilon_y 0; 0 0 epsilon_z].  The default is\n        isotropic, epsilon=1.0\n    epsilonz  : float, optional\n        Anisotropic diffusion coefficient in the z-direction\n        where A = [1 0 0; 0 epsilon_y 0; 0 0 epsilon_z].  The default is\n        isotropic, epsilon=1.0\n    theta : float, optional\n        Euler rotation angle `theta` in radians. The default is 0.0.\n    phi : float, optional\n        Euler rotation angle `phi` in radians. The default is 0.0.\n    psi : float, optional\n        Euler rotation angle `psi` in radians. The default is 0.0.\n    type : {'FE','FD'}\n        Specifies the discretization as Q1 finite element (FE) or 2nd order\n        finite difference (FD)\n\n    Returns\n    -------\n    stencil : numpy array\n        A 3x3 diffusion stencil\n\n    See Also\n    --------\n    stencil_grid, poisson, _symbolic_rotation_helper, _symbolic_product_helper\n\n    Notes\n    -----\n    Not all combinations are supported.\n\n    Examples\n    --------\n    >>> import scipy as sp\n    >>> from pyamg.gallery.diffusion import diffusion_stencil_2d\n    >>> sten = diffusion_stencil_2d(epsilon=0.0001,theta=sp.pi/6,type='FD')\n    >>> print sten\n    [[-0.2164847 -0.750025   0.2164847]\n     [-0.250075   2.0002    -0.250075 ]\n     [ 0.2164847 -0.750025  -0.2164847]]\n\n    \"\"\"\n    epsy = float(epsilony)  # for brevity\n    epsz = float(epsilonz)  # for brevity\n    theta = float(theta)\n    phi = float(phi)\n    psi = float(psi)\n\n    D = np.zeros((3, 3))\n    cphi = np.cos(phi)\n    sphi = np.sin(phi)\n    cth = np.cos(theta)\n    sth = np.sin(theta)\n    cpsi = np.cos(psi)\n    spsi = np.sin(psi)\n\n    # from _symbolic_rotation_helper\n    D[0, 0] = epsy*(cphi*cth*spsi + cpsi*sphi)**2 + epsz*spsi**2*sth**2 +\\\n        (cphi*cpsi - cth*sphi*spsi)**2\n    D[0, 1] = cpsi*epsz*spsi*sth**2 +\\\n        epsy*(cphi*cpsi*cth - sphi*spsi)*(cphi*cth*spsi + cpsi*sphi) +\\\n        (cphi*cpsi - cth*sphi*spsi)*(-cphi*spsi - cpsi*cth*sphi)\n    D[0, 2] = -cphi*epsy*sth*(cphi*cth*spsi + cpsi*sphi) +\\\n        cth*epsz*spsi*sth + sphi*sth*(cphi*cpsi - cth*sphi*spsi)\n    D[1, 0] = cpsi*epsz*spsi*sth**2 +\\\n        epsy*(cphi*cpsi*cth - sphi*spsi)*(cphi*cth*spsi + cpsi*sphi) +\\\n        (cphi*cpsi - cth*sphi*spsi)*(-cphi*spsi - cpsi*cth*sphi)\n    D[1, 1] = cpsi**2*epsz*sth**2 + epsy*(cphi*cpsi*cth - sphi*spsi)**2 +\\\n        (-cphi*spsi - cpsi*cth*sphi)**2\n    D[1, 2] = -cphi*epsy*sth*(cphi*cpsi*cth - sphi*spsi) +\\\n        cpsi*cth*epsz*sth + sphi*sth*(-cphi*spsi - cpsi*cth*sphi)\n    D[2, 0] = -cphi*epsy*sth*(cphi*cth*spsi + cpsi*sphi) + cth*epsz*spsi*sth +\\\n        sphi*sth*(cphi*cpsi - cth*sphi*spsi)\n    D[2, 1] = -cphi*epsy*sth*(cphi*cpsi*cth - sphi*spsi) + cpsi*cth*epsz*sth +\\\n        sphi*sth*(-cphi*spsi - cpsi*cth*sphi)\n    D[2, 2] = cphi**2*epsy*sth**2 + cth**2*epsz + sphi**2*sth**2\n\n    stencil = np.zeros((3, 3, 3))\n\n    if type == 'FD':\n        # from _symbolic_product_helper\n        # dx*(D11*dx + D21*dy + D31*dz) +\n        # dy*(D12*dx + D22*dy + D32*dz) +\n        # dz*(D13*dx + D23*dy + D33*dz)\n        #\n        # D00*dxx +\n        # (D10+D01)*dxy +\n        # (D20+D02)*dxz +\n        # D11*dyy +\n        # (D21+D12)*dyz +\n        # D22*dzz\n\n        i, j, k = (1, 1, 1)\n\n        # dxx\n        stencil[[i-1, i, i+1], j, k] += np.array([-1, 2, -1]) * D[0, 0]\n\n        # dyy\n        stencil[i, [j-1, j, j+1], k] += np.array([-1, 2, -1]) * D[1, 1]\n\n        # dzz\n        stencil[i, j, [k-1, k, k+1]] += np.array([-1, 2, -1]) * D[2, 2]\n\n        L = np.array([-1, -1, 1, 1])\n        M = np.array([-1, 1, -1, 1])\n        # dxy\n        stencil[i + L, j + M, k] \\\n            += 0.25 * np.array([1, -1, -1, 1]) * (D[1, 0] + D[0, 1])\n\n        # dxz\n        stencil[i + L, j, k + M] \\\n            += 0.25 * np.array([1, -1, -1, 1]) * (D[2, 0] + D[0, 2])\n\n        # dyz\n        stencil[i, j + L, k + M] \\\n            += 0.25 * np.array([1, -1, -1, 1]) * (D[2, 1] + D[1, 2])\n\n        return stencil\n\n    if type == 'FE':\n        raise NotImplementedError('FE not implemented yet')", "response": "Rotated Anisotropic diffusion in 3d of the form."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_system(A, x, b, formats=None):\n    if formats is None:\n        pass\n    elif formats == ['csr']:\n        if sparse.isspmatrix_csr(A):\n            pass\n        elif sparse.isspmatrix_bsr(A):\n            A = A.tocsr()\n        else:\n            warn('implicit conversion to CSR', sparse.SparseEfficiencyWarning)\n            A = sparse.csr_matrix(A)\n    else:\n        if sparse.isspmatrix(A) and A.format in formats:\n            pass\n        else:\n            A = sparse.csr_matrix(A).asformat(formats[0])\n\n    if not isinstance(x, np.ndarray):\n        raise ValueError('expected numpy array for argument x')\n    if not isinstance(b, np.ndarray):\n        raise ValueError('expected numpy array for argument b')\n\n    M, N = A.shape\n\n    if M != N:\n        raise ValueError('expected square matrix')\n\n    if x.shape not in [(M,), (M, 1)]:\n        raise ValueError('x has invalid dimensions')\n    if b.shape not in [(M,), (M, 1)]:\n        raise ValueError('b has invalid dimensions')\n\n    if A.dtype != x.dtype or A.dtype != b.dtype:\n        raise TypeError('arguments A, x, and b must have the same dtype')\n\n    if not x.flags.carray:\n        raise ValueError('x must be contiguous in memory')\n\n    x = np.ravel(x)\n    b = np.ravel(b)\n\n    return A, x, b", "response": "Make a new system A x b suitable for relaxation or raise an exception."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sor(A, x, b, omega, iterations=1, sweep='forward'):\n    A, x, b = make_system(A, x, b, formats=['csr', 'bsr'])\n\n    x_old = np.empty_like(x)\n\n    for i in range(iterations):\n        x_old[:] = x\n\n        gauss_seidel(A, x, b, iterations=1, sweep=sweep)\n\n        x *= omega\n        x_old *= (1-omega)\n        x += x_old", "response": "Perform SOR iteration on the linear system Ax = b."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming Overlapping multiplicative Schwarz on the linear system Ax = A.", "response": "def schwarz(A, x, b, iterations=1, subdomain=None, subdomain_ptr=None,\n            inv_subblock=None, inv_subblock_ptr=None, sweep='forward'):\n    \"\"\"Perform Overlapping multiplicative Schwarz on the linear system Ax=b.\n\n    Parameters\n    ----------\n    A : csr_matrix, bsr_matrix\n        Sparse NxN matrix\n    x : ndarray\n        Approximate solution (length N)\n    b : ndarray\n        Right-hand side (length N)\n    iterations : int\n        Number of iterations to perform\n    subdomain : int array\n        Linear array containing each subdomain's elements\n    subdomain_ptr : int array\n        Pointer in subdomain, such that\n        subdomain[subdomain_ptr[i]:subdomain_ptr[i+1]]]\n        contains the _sorted_ indices in subdomain i\n    inv_subblock : int_array\n        Linear array containing each subdomain's\n        inverted diagonal block of A\n    inv_subblock_ptr : int array\n        Pointer in inv_subblock, such that\n        inv_subblock[inv_subblock_ptr[i]:inv_subblock_ptr[i+1]]]\n        contains the inverted diagonal block of A for the\n        i-th subdomain in _row_ major order\n    sweep : {'forward','backward','symmetric'}\n        Direction of sweep\n\n    Returns\n    -------\n    Nothing, x will be modified in place.\n\n    Notes\n    -----\n    If subdomains is None, then a point-wise iteration takes place,\n    with the overlapping region defined by each degree-of-freedom's\n    neighbors in the matrix graph.\n\n    If subdomains is not None, but subblocks is, then the subblocks\n    are formed internally.\n\n    Currently only supports CSR matrices\n\n    Examples\n    --------\n    >>> # Use Overlapping Schwarz as a Stand-Alone Solver\n    >>> from pyamg.relaxation.relaxation import schwarz\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.util.linalg import norm\n    >>> import numpy as np\n    >>> A = poisson((10,10), format='csr')\n    >>> x0 = np.zeros((A.shape[0],1))\n    >>> b = np.ones((A.shape[0],1))\n    >>> schwarz(A, x0, b, iterations=10)\n    >>> print norm(b-A*x0)\n    0.126326160522\n    >>> #\n    >>> # Schwarz as the Multigrid Smoother\n    >>> from pyamg import smoothed_aggregation_solver\n    >>> sa = smoothed_aggregation_solver(A, B=np.ones((A.shape[0],1)),\n    ...         coarse_solver='pinv2', max_coarse=50,\n    ...         presmoother='schwarz',\n    ...         postsmoother='schwarz')\n    >>> x0=np.zeros((A.shape[0],1))\n    >>> residuals=[]\n    >>> x = sa.solve(b, x0=x0, tol=1e-8, residuals=residuals)\n\n    \"\"\"\n    A, x, b = make_system(A, x, b, formats=['csr'])\n    A.sort_indices()\n\n    if subdomain is None and inv_subblock is not None:\n        raise ValueError(\"inv_subblock must be None if subdomain is None\")\n\n    # If no subdomains are defined, default is to use the sparsity pattern of A\n    # to define the overlapping regions\n    (subdomain, subdomain_ptr, inv_subblock, inv_subblock_ptr) = \\\n        schwarz_parameters(A, subdomain, subdomain_ptr,\n                           inv_subblock, inv_subblock_ptr)\n\n    if sweep == 'forward':\n        row_start, row_stop, row_step = 0, subdomain_ptr.shape[0]-1, 1\n    elif sweep == 'backward':\n        row_start, row_stop, row_step = subdomain_ptr.shape[0]-2, -1, -1\n    elif sweep == 'symmetric':\n        for iter in range(iterations):\n            schwarz(A, x, b, iterations=1, subdomain=subdomain,\n                    subdomain_ptr=subdomain_ptr, inv_subblock=inv_subblock,\n                    inv_subblock_ptr=inv_subblock_ptr, sweep='forward')\n            schwarz(A, x, b, iterations=1, subdomain=subdomain,\n                    subdomain_ptr=subdomain_ptr, inv_subblock=inv_subblock,\n                    inv_subblock_ptr=inv_subblock_ptr, sweep='backward')\n        return\n    else:\n        raise ValueError(\"valid sweep directions are 'forward',\\\n                          'backward', and 'symmetric'\")\n\n    # Call C code, need to make sure that subdomains are sorted and unique\n    for iter in range(iterations):\n        amg_core.overlapping_schwarz_csr(A.indptr, A.indices, A.data,\n                                         x, b, inv_subblock, inv_subblock_ptr,\n                                         subdomain, subdomain_ptr,\n                                         subdomain_ptr.shape[0]-1, A.shape[0],\n                                         row_start, row_stop, row_step)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform Gauss - Seidel iteration on the linear system Ax = b.", "response": "def gauss_seidel(A, x, b, iterations=1, sweep='forward'):\n    \"\"\"Perform Gauss-Seidel iteration on the linear system Ax=b.\n\n    Parameters\n    ----------\n    A : csr_matrix, bsr_matrix\n        Sparse NxN matrix\n    x : ndarray\n        Approximate solution (length N)\n    b : ndarray\n        Right-hand side (length N)\n    iterations : int\n        Number of iterations to perform\n    sweep : {'forward','backward','symmetric'}\n        Direction of sweep\n\n    Returns\n    -------\n    Nothing, x will be modified in place.\n\n    Examples\n    --------\n    >>> # Use Gauss-Seidel as a Stand-Alone Solver\n    >>> from pyamg.relaxation.relaxation import gauss_seidel\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.util.linalg import norm\n    >>> import numpy as np\n    >>> A = poisson((10,10), format='csr')\n    >>> x0 = np.zeros((A.shape[0],1))\n    >>> b = np.ones((A.shape[0],1))\n    >>> gauss_seidel(A, x0, b, iterations=10)\n    >>> print norm(b-A*x0)\n    4.00733716236\n    >>> #\n    >>> # Use Gauss-Seidel as the Multigrid Smoother\n    >>> from pyamg import smoothed_aggregation_solver\n    >>> sa = smoothed_aggregation_solver(A, B=np.ones((A.shape[0],1)),\n    ...         coarse_solver='pinv2', max_coarse=50,\n    ...         presmoother=('gauss_seidel', {'sweep':'symmetric'}),\n    ...         postsmoother=('gauss_seidel', {'sweep':'symmetric'}))\n    >>> x0=np.zeros((A.shape[0],1))\n    >>> residuals=[]\n    >>> x = sa.solve(b, x0=x0, tol=1e-8, residuals=residuals)\n\n    \"\"\"\n    A, x, b = make_system(A, x, b, formats=['csr', 'bsr'])\n\n    if sparse.isspmatrix_csr(A):\n        blocksize = 1\n    else:\n        R, C = A.blocksize\n        if R != C:\n            raise ValueError('BSR blocks must be square')\n        blocksize = R\n\n    if sweep == 'forward':\n        row_start, row_stop, row_step = 0, int(len(x)/blocksize), 1\n    elif sweep == 'backward':\n        row_start, row_stop, row_step = int(len(x)/blocksize)-1, -1, -1\n    elif sweep == 'symmetric':\n        for iter in range(iterations):\n            gauss_seidel(A, x, b, iterations=1, sweep='forward')\n            gauss_seidel(A, x, b, iterations=1, sweep='backward')\n        return\n    else:\n        raise ValueError(\"valid sweep directions are 'forward',\\\n                          'backward', and 'symmetric'\")\n\n    if sparse.isspmatrix_csr(A):\n        for iter in range(iterations):\n            amg_core.gauss_seidel(A.indptr, A.indices, A.data, x, b,\n                                  row_start, row_stop, row_step)\n    else:\n        for iter in range(iterations):\n            amg_core.bsr_gauss_seidel(A.indptr, A.indices, np.ravel(A.data),\n                                      x, b, row_start, row_stop, row_step, R)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming Jacobi iteration on the linear system Ax = b.", "response": "def jacobi(A, x, b, iterations=1, omega=1.0):\n    \"\"\"Perform Jacobi iteration on the linear system Ax=b.\n\n    Parameters\n    ----------\n    A : csr_matrix\n        Sparse NxN matrix\n    x : ndarray\n        Approximate solution (length N)\n    b : ndarray\n        Right-hand side (length N)\n    iterations : int\n        Number of iterations to perform\n    omega : scalar\n        Damping parameter\n\n    Returns\n    -------\n    Nothing, x will be modified in place.\n\n    Examples\n    --------\n    >>> # Use Jacobi as a Stand-Alone Solver\n    >>> from pyamg.relaxation.relaxation.relaxation import jacobi\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.util.linalg import norm\n    >>> import numpy as np\n    >>> A = poisson((10,10), format='csr')\n    >>> x0 = np.zeros((A.shape[0],1))\n    >>> b = np.ones((A.shape[0],1))\n    >>> jacobi(A, x0, b, iterations=10, omega=1.0)\n    >>> print norm(b-A*x0)\n    5.83475132751\n    >>> #\n    >>> # Use Jacobi as the Multigrid Smoother\n    >>> from pyamg import smoothed_aggregation_solver\n    >>> sa = smoothed_aggregation_solver(A, B=np.ones((A.shape[0],1)),\n    ...         coarse_solver='pinv2', max_coarse=50,\n    ...         presmoother=('jacobi', {'omega': 4.0/3.0, 'iterations' : 2}),\n    ...         postsmoother=('jacobi', {'omega': 4.0/3.0, 'iterations' : 2}))\n    >>> x0=np.zeros((A.shape[0],1))\n    >>> residuals=[]\n    >>> x = sa.solve(b, x0=x0, tol=1e-8, residuals=residuals)\n\n    \"\"\"\n    A, x, b = make_system(A, x, b, formats=['csr', 'bsr'])\n\n    sweep = slice(None)\n    (row_start, row_stop, row_step) = sweep.indices(A.shape[0])\n\n    if (row_stop - row_start) * row_step <= 0:  # no work to do\n        return\n\n    temp = np.empty_like(x)\n\n    # Create uniform type, convert possibly complex scalars to length 1 arrays\n    [omega] = type_prep(A.dtype, [omega])\n\n    if sparse.isspmatrix_csr(A):\n        for iter in range(iterations):\n            amg_core.jacobi(A.indptr, A.indices, A.data, x, b, temp,\n                            row_start, row_stop, row_step, omega)\n    else:\n        R, C = A.blocksize\n        if R != C:\n            raise ValueError('BSR blocks must be square')\n        row_start = int(row_start / R)\n        row_stop = int(row_stop / R)\n        for iter in range(iterations):\n            amg_core.bsr_jacobi(A.indptr, A.indices, np.ravel(A.data),\n                                x, b, temp, row_start, row_stop,\n                                row_step, R, omega)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef block_jacobi(A, x, b, Dinv=None, blocksize=1, iterations=1, omega=1.0):\n    A, x, b = make_system(A, x, b, formats=['csr', 'bsr'])\n    A = A.tobsr(blocksize=(blocksize, blocksize))\n\n    if Dinv is None:\n        Dinv = get_block_diag(A, blocksize=blocksize, inv_flag=True)\n    elif Dinv.shape[0] != int(A.shape[0]/blocksize):\n        raise ValueError('Dinv and A have incompatible dimensions')\n    elif (Dinv.shape[1] != blocksize) or (Dinv.shape[2] != blocksize):\n        raise ValueError('Dinv and blocksize are incompatible')\n\n    sweep = slice(None)\n    (row_start, row_stop, row_step) = sweep.indices(int(A.shape[0]/blocksize))\n\n    if (row_stop - row_start) * row_step <= 0:  # no work to do\n        return\n\n    temp = np.empty_like(x)\n\n    # Create uniform type, convert possibly complex scalars to length 1 arrays\n    [omega] = type_prep(A.dtype, [omega])\n\n    for iter in range(iterations):\n        amg_core.block_jacobi(A.indptr, A.indices, np.ravel(A.data),\n                              x, b, np.ravel(Dinv), temp,\n                              row_start, row_stop, row_step,\n                              omega, blocksize)", "response": "Perform block Jacobi iteration on the linear system Ax = b."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms block Gauss - Seidel iteration on the linear system Ax = A.", "response": "def block_gauss_seidel(A, x, b, iterations=1, sweep='forward', blocksize=1,\n                       Dinv=None):\n    \"\"\"Perform block Gauss-Seidel iteration on the linear system Ax=b.\n\n    Parameters\n    ----------\n    A : csr_matrix, bsr_matrix\n        Sparse NxN matrix\n    x : ndarray\n        Approximate solution (length N)\n    b : ndarray\n        Right-hand side (length N)\n    iterations : int\n        Number of iterations to perform\n    sweep : {'forward','backward','symmetric'}\n        Direction of sweep\n    Dinv : array\n        Array holding block diagonal inverses of A\n        size (N/blocksize, blocksize, blocksize)\n    blocksize : int\n        Desired dimension of blocks\n\n\n    Returns\n    -------\n    Nothing, x will be modified in place.\n\n    Examples\n    --------\n    >>> # Use Gauss-Seidel as a Stand-Alone Solver\n    >>> from pyamg.relaxation.relaxation import block_gauss_seidel\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.util.linalg import norm\n    >>> import numpy as np\n    >>> A = poisson((10,10), format='csr')\n    >>> x0 = np.zeros((A.shape[0],1))\n    >>> b = np.ones((A.shape[0],1))\n    >>> block_gauss_seidel(A, x0, b, iterations=10, blocksize=4,\n                           sweep='symmetric')\n    >>> print norm(b-A*x0)\n    0.958333817624\n    >>> #\n    >>> # Use Gauss-Seidel as the Multigrid Smoother\n    >>> from pyamg import smoothed_aggregation_solver\n    >>> opts = {'sweep':'symmetric', 'blocksize' : 4}\n    >>> sa = smoothed_aggregation_solver(A, B=np.ones((A.shape[0],1)),\n    ...        coarse_solver='pinv2', max_coarse=50,\n    ...        presmoother=('block_gauss_seidel', opts),\n    ...        postsmoother=('block_gauss_seidel', opts))\n    >>> x0=np.zeros((A.shape[0],1))\n    >>> residuals=[]\n    >>> x = sa.solve(b, x0=x0, tol=1e-8, residuals=residuals)\n\n    \"\"\"\n    A, x, b = make_system(A, x, b, formats=['csr', 'bsr'])\n    A = A.tobsr(blocksize=(blocksize, blocksize))\n\n    if Dinv is None:\n        Dinv = get_block_diag(A, blocksize=blocksize, inv_flag=True)\n    elif Dinv.shape[0] != int(A.shape[0]/blocksize):\n        raise ValueError('Dinv and A have incompatible dimensions')\n    elif (Dinv.shape[1] != blocksize) or (Dinv.shape[2] != blocksize):\n        raise ValueError('Dinv and blocksize are incompatible')\n\n    if sweep == 'forward':\n        row_start, row_stop, row_step = 0, int(len(x)/blocksize), 1\n    elif sweep == 'backward':\n        row_start, row_stop, row_step = int(len(x)/blocksize)-1, -1, -1\n    elif sweep == 'symmetric':\n        for iter in range(iterations):\n            block_gauss_seidel(A, x, b, iterations=1, sweep='forward',\n                               blocksize=blocksize, Dinv=Dinv)\n            block_gauss_seidel(A, x, b, iterations=1, sweep='backward',\n                               blocksize=blocksize, Dinv=Dinv)\n        return\n    else:\n        raise ValueError(\"valid sweep directions are 'forward',\\\n                          'backward', and 'symmetric'\")\n\n    for iter in range(iterations):\n        amg_core.block_gauss_seidel(A.indptr, A.indices, np.ravel(A.data),\n                                    x, b, np.ravel(Dinv),\n                                    row_start, row_stop, row_step, blocksize)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying a polynomial smoother to the system Ax = b.", "response": "def polynomial(A, x, b, coefficients, iterations=1):\n    \"\"\"Apply a polynomial smoother to the system Ax=b.\n\n    Parameters\n    ----------\n    A : sparse matrix\n        Sparse NxN matrix\n    x : ndarray\n        Approximate solution (length N)\n    b : ndarray\n        Right-hand side (length N)\n    coefficients : array_like\n        Coefficients of the polynomial.  See Notes section for details.\n    iterations : int\n        Number of iterations to perform\n\n    Returns\n    -------\n    Nothing, x will be modified in place.\n\n    Notes\n    -----\n    The smoother has the form  x[:] = x + p(A) (b - A*x) where p(A) is a\n    polynomial in A whose scalar coefficients are specified (in descending\n    order) by argument 'coefficients'.\n\n    - Richardson iteration p(A) = c_0:\n        polynomial_smoother(A, x, b, [c_0])\n\n    - Linear smoother p(A) = c_1*A + c_0:\n        polynomial_smoother(A, x, b, [c_1, c_0])\n\n    - Quadratic smoother p(A) = c_2*A^2 + c_1*A + c_0:\n        polynomial_smoother(A, x, b, [c_2, c_1, c_0])\n\n    Here, Horner's Rule is applied to avoid computing A^k directly.\n\n    For efficience, the method detects the case x = 0 one matrix-vector\n    product is avoided (since (b - A*x) is b).\n\n    Examples\n    --------\n    >>> # The polynomial smoother is not currently used directly\n    >>> # in PyAMG.  It is only used by the chebyshev smoothing option,\n    >>> # which automatically calculates the correct coefficients.\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.util.linalg import norm\n    >>> import numpy as np\n    >>> from pyamg.aggregation import smoothed_aggregation_solver\n    >>> A = poisson((10,10), format='csr')\n    >>> b = np.ones((A.shape[0],1))\n    >>> sa = smoothed_aggregation_solver(A, B=np.ones((A.shape[0],1)),\n    ...         coarse_solver='pinv2', max_coarse=50,\n    ...         presmoother=('chebyshev', {'degree':3, 'iterations':1}),\n    ...         postsmoother=('chebyshev', {'degree':3, 'iterations':1}))\n    >>> x0=np.zeros((A.shape[0],1))\n    >>> residuals=[]\n    >>> x = sa.solve(b, x0=x0, tol=1e-8, residuals=residuals)\n\n    \"\"\"\n    A, x, b = make_system(A, x, b, formats=None)\n\n    for i in range(iterations):\n        from pyamg.util.linalg import norm\n\n        if norm(x) == 0:\n            residual = b\n        else:\n            residual = (b - A*x)\n\n        h = coefficients[0]*residual\n\n        for c in coefficients[1:]:\n            h = c*residual + A*h\n\n        x += h"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gauss_seidel_indexed(A, x, b, indices, iterations=1, sweep='forward'):\n    A, x, b = make_system(A, x, b, formats=['csr'])\n\n    indices = np.asarray(indices, dtype='intc')\n\n    # if indices.min() < 0:\n    #     raise ValueError('row index (%d) is invalid' % indices.min())\n    # if indices.max() >= A.shape[0]\n    #     raise ValueError('row index (%d) is invalid' % indices.max())\n\n    if sweep == 'forward':\n        row_start, row_stop, row_step = 0, len(indices), 1\n    elif sweep == 'backward':\n        row_start, row_stop, row_step = len(indices)-1, -1, -1\n    elif sweep == 'symmetric':\n        for iter in range(iterations):\n            gauss_seidel_indexed(A, x, b, indices, iterations=1,\n                                 sweep='forward')\n            gauss_seidel_indexed(A, x, b, indices, iterations=1,\n                                 sweep='backward')\n        return\n    else:\n        raise ValueError(\"valid sweep directions are 'forward',\\\n                          'backward', and 'symmetric'\")\n\n    for iter in range(iterations):\n        amg_core.gauss_seidel_indexed(A.indptr, A.indices, A.data,\n                                      x, b, indices,\n                                      row_start, row_stop, row_step)", "response": "Perform indexed Gauss - Seidel iteration on the linear system Ax = A."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef jacobi_ne(A, x, b, iterations=1, omega=1.0):\n    A, x, b = make_system(A, x, b, formats=['csr'])\n\n    sweep = slice(None)\n    (row_start, row_stop, row_step) = sweep.indices(A.shape[0])\n\n    temp = np.zeros_like(x)\n\n    # Dinv for A*A.H\n    Dinv = get_diagonal(A, norm_eq=2, inv=True)\n\n    # Create uniform type, convert possibly complex scalars to length 1 arrays\n    [omega] = type_prep(A.dtype, [omega])\n\n    for i in range(iterations):\n        delta = (np.ravel(b - A*x)*np.ravel(Dinv)).astype(A.dtype)\n        amg_core.jacobi_ne(A.indptr, A.indices, A.data,\n                           x, b, delta, temp, row_start,\n                           row_stop, row_step, omega)", "response": "Perform Jacobi iterations on the linear system A A. H x = A. H b."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform Gauss - Seidel iterations on the linear system A A. H x = b.", "response": "def gauss_seidel_ne(A, x, b, iterations=1, sweep='forward', omega=1.0,\n                    Dinv=None):\n    \"\"\"Perform Gauss-Seidel iterations on the linear system A A.H x = b.\n\n    Also known as Kaczmarz relaxation\n\n    Parameters\n    ----------\n    A : csr_matrix\n        Sparse NxN matrix\n    x : ndarray\n        Approximate solution (length N)\n    b : ndarray\n        Right-hand side (length N)\n    iterations : int\n        Number of iterations to perform\n    sweep : {'forward','backward','symmetric'}\n        Direction of sweep\n    omega : float\n        Relaxation parameter typically in (0, 2)\n        if omega != 1.0, then algorithm becomes SOR on A A.H\n    Dinv : ndarray\n        Inverse of diag(A A.H),  (length N)\n\n    Returns\n    -------\n    Nothing, x will be modified in place.\n\n    References\n    ----------\n    .. [1] Brandt, Ta'asan.\n       \"Multigrid Method For Nearly Singular And Slightly Indefinite Problems.\"\n       1985.  NASA Technical Report Numbers: ICASE-85-57; NAS 1.26:178026;\n       NASA-CR-178026;\n\n    .. [2] Kaczmarz.  Angenaeherte Aufloesung von Systemen Linearer\n       Gleichungen. Bull. Acad.  Polon. Sci. Lett. A 35, 355-57.  1937\n\n    Examples\n    --------\n    >>> # Use NE Gauss-Seidel as a Stand-Alone Solver\n    >>> from pyamg.relaxation.relaxation import gauss_seidel_ne\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.util.linalg import norm\n    >>> import numpy as np\n    >>> A = poisson((10,10), format='csr')\n    >>> x0 = np.zeros((A.shape[0],1))\n    >>> b = np.ones((A.shape[0],1))\n    >>> gauss_seidel_ne(A, x0, b, iterations=10, sweep='symmetric')\n    >>> print norm(b-A*x0)\n    8.47576806771\n    >>> #\n    >>> # Use NE Gauss-Seidel as the Multigrid Smoother\n    >>> from pyamg import smoothed_aggregation_solver\n    >>> sa = smoothed_aggregation_solver(A, B=np.ones((A.shape[0],1)),\n    ...         coarse_solver='pinv2', max_coarse=50,\n    ...         presmoother=('gauss_seidel_ne', {'sweep' : 'symmetric'}),\n    ...         postsmoother=('gauss_seidel_ne', {'sweep' : 'symmetric'}))\n    >>> x0=np.zeros((A.shape[0],1))\n    >>> residuals=[]\n    >>> x = sa.solve(b, x0=x0, tol=1e-8, residuals=residuals)\n\n    \"\"\"\n    A, x, b = make_system(A, x, b, formats=['csr'])\n\n    # Dinv for A*A.H\n    if Dinv is None:\n        Dinv = np.ravel(get_diagonal(A, norm_eq=2, inv=True))\n\n    if sweep == 'forward':\n        row_start, row_stop, row_step = 0, len(x), 1\n    elif sweep == 'backward':\n        row_start, row_stop, row_step = len(x)-1, -1, -1\n    elif sweep == 'symmetric':\n        for iter in range(iterations):\n            gauss_seidel_ne(A, x, b, iterations=1, sweep='forward',\n                            omega=omega, Dinv=Dinv)\n            gauss_seidel_ne(A, x, b, iterations=1, sweep='backward',\n                            omega=omega, Dinv=Dinv)\n        return\n    else:\n        raise ValueError(\"valid sweep directions are 'forward',\\\n                          'backward', and 'symmetric'\")\n\n    for i in range(iterations):\n        amg_core.gauss_seidel_ne(A.indptr, A.indices, A.data,\n                                 x, b, row_start,\n                                 row_stop, row_step, Dinv, omega)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform Gauss-Seidel iterations on the linear system A.H A x = A.H b. Parameters ---------- A : csr_matrix Sparse NxN matrix x : ndarray Approximate solution (length N) b : ndarray Right-hand side (length N) iterations : int Number of iterations to perform sweep : {'forward','backward','symmetric'} Direction of sweep omega : float Relaxation parameter typically in (0, 2) if omega != 1.0, then algorithm becomes SOR on A.H A Dinv : ndarray Inverse of diag(A.H A), (length N) Returns ------- Nothing, x will be modified in place. References ---------- .. [1] Yousef Saad, \"Iterative Methods for Sparse Linear Systems, Second Edition\", SIAM, pp. 247-9, 2003 http://www-users.cs.umn.edu/~saad/books.html Examples -------- >>> # Use NR Gauss-Seidel as a Stand-Alone Solver >>> from pyamg.relaxation.relaxation import gauss_seidel_nr >>> from pyamg.gallery import poisson >>> from pyamg.util.linalg import norm >>> import numpy as np >>> A = poisson((10,10), format='csr') >>> x0 = np.zeros((A.shape[0],1)) >>> b = np.ones((A.shape[0],1)) >>> gauss_seidel_nr(A, x0, b, iterations=10, sweep='symmetric') >>> print norm(b-A*x0) 8.45044864352 >>> # >>> # Use NR Gauss-Seidel as the Multigrid Smoother >>> from pyamg import smoothed_aggregation_solver >>> sa = smoothed_aggregation_solver(A, B=np.ones((A.shape[0],1)), ... coarse_solver='pinv2', max_coarse=50, ... presmoother=('gauss_seidel_nr', {'sweep' : 'symmetric'}), ... postsmoother=('gauss_seidel_nr', {'sweep' : 'symmetric'})) >>> x0=np.zeros((A.shape[0],1)) >>> residuals=[] >>> x = sa.solve(b, x0=x0, tol=1e-8, residuals=residuals)", "response": "def gauss_seidel_nr(A, x, b, iterations=1, sweep='forward', omega=1.0,\n                    Dinv=None):\n    \"\"\"Perform Gauss-Seidel iterations on the linear system A.H A x = A.H b.\n\n    Parameters\n    ----------\n    A : csr_matrix\n        Sparse NxN matrix\n    x : ndarray\n        Approximate solution (length N)\n    b : ndarray\n        Right-hand side (length N)\n    iterations : int\n        Number of iterations to perform\n    sweep : {'forward','backward','symmetric'}\n        Direction of sweep\n    omega : float\n        Relaxation parameter typically in (0, 2)\n        if omega != 1.0, then algorithm becomes SOR on A.H A\n    Dinv : ndarray\n        Inverse of diag(A.H A),  (length N)\n\n    Returns\n    -------\n    Nothing, x will be modified in place.\n\n    References\n    ----------\n    .. [1] Yousef Saad, \"Iterative Methods for Sparse Linear Systems,\n       Second Edition\", SIAM, pp. 247-9, 2003\n       http://www-users.cs.umn.edu/~saad/books.html\n\n\n    Examples\n    --------\n    >>> # Use NR Gauss-Seidel as a Stand-Alone Solver\n    >>> from pyamg.relaxation.relaxation import gauss_seidel_nr\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.util.linalg import norm\n    >>> import numpy as np\n    >>> A = poisson((10,10), format='csr')\n    >>> x0 = np.zeros((A.shape[0],1))\n    >>> b = np.ones((A.shape[0],1))\n    >>> gauss_seidel_nr(A, x0, b, iterations=10, sweep='symmetric')\n    >>> print norm(b-A*x0)\n    8.45044864352\n    >>> #\n    >>> # Use NR Gauss-Seidel as the Multigrid Smoother\n    >>> from pyamg import smoothed_aggregation_solver\n    >>> sa = smoothed_aggregation_solver(A, B=np.ones((A.shape[0],1)),\n    ...      coarse_solver='pinv2', max_coarse=50,\n    ...      presmoother=('gauss_seidel_nr', {'sweep' : 'symmetric'}),\n    ...      postsmoother=('gauss_seidel_nr', {'sweep' : 'symmetric'}))\n    >>> x0=np.zeros((A.shape[0],1))\n    >>> residuals=[]\n    >>> x = sa.solve(b, x0=x0, tol=1e-8, residuals=residuals)\n\n    \"\"\"\n    A, x, b = make_system(A, x, b, formats=['csc'])\n\n    # Dinv for A.H*A\n    if Dinv is None:\n        Dinv = np.ravel(get_diagonal(A, norm_eq=1, inv=True))\n\n    if sweep == 'forward':\n        col_start, col_stop, col_step = 0, len(x), 1\n    elif sweep == 'backward':\n        col_start, col_stop, col_step = len(x)-1, -1, -1\n    elif sweep == 'symmetric':\n        for iter in range(iterations):\n            gauss_seidel_nr(A, x, b, iterations=1, sweep='forward',\n                            omega=omega, Dinv=Dinv)\n            gauss_seidel_nr(A, x, b, iterations=1, sweep='backward',\n                            omega=omega, Dinv=Dinv)\n        return\n    else:\n        raise ValueError(\"valid sweep directions are 'forward',\\\n                          'backward', and 'symmetric'\")\n\n    # Calculate initial residual\n    r = b - A*x\n\n    for i in range(iterations):\n        amg_core.gauss_seidel_nr(A.indptr, A.indices, A.data,\n                                 x, r, col_start,\n                                 col_stop, col_step, Dinv, omega)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets Schwarz parameters. Helper function for setting up Schwarz relaxation. This function avoids recomputing the subdomains and block inverses manytimes, e.g., it avoids a costly double computation when setting up pre and post smoothing with Schwarz. Parameters ---------- A {csr_matrix} Returns ------- A.schwarz_parameters[0] is subdomain A.schwarz_parameters[1] is subdomain_ptr A.schwarz_parameters[2] is inv_subblock A.schwarz_parameters[3] is inv_subblock_ptr", "response": "def schwarz_parameters(A, subdomain=None, subdomain_ptr=None,\n                       inv_subblock=None, inv_subblock_ptr=None):\n    \"\"\"Set Schwarz parameters.\n\n    Helper function for setting up Schwarz relaxation.  This function avoids\n    recomputing the subdomains and block inverses manytimes, e.g., it avoids a\n    costly double computation when setting up pre and post smoothing with\n    Schwarz.\n\n    Parameters\n    ----------\n    A {csr_matrix}\n\n    Returns\n    -------\n    A.schwarz_parameters[0] is subdomain\n    A.schwarz_parameters[1] is subdomain_ptr\n    A.schwarz_parameters[2] is inv_subblock\n    A.schwarz_parameters[3] is inv_subblock_ptr\n\n    \"\"\"\n    # Check if A has a pre-existing set of Schwarz parameters\n    if hasattr(A, 'schwarz_parameters'):\n        if subdomain is not None and subdomain_ptr is not None:\n            # check that the existing parameters correspond to the same\n            # subdomains\n            if np.array(A.schwarz_parameters[0] == subdomain).all() and \\\n               np.array(A.schwarz_parameters[1] == subdomain_ptr).all():\n                return A.schwarz_parameters\n        else:\n            return A.schwarz_parameters\n\n    # Default is to use the overlapping regions defined by A's sparsity pattern\n    if subdomain is None or subdomain_ptr is None:\n        subdomain_ptr = A.indptr.copy()\n        subdomain = A.indices.copy()\n\n    # Extract each subdomain's block from the matrix\n    if inv_subblock is None or inv_subblock_ptr is None:\n        inv_subblock_ptr = np.zeros(subdomain_ptr.shape,\n                                    dtype=A.indices.dtype)\n        blocksize = (subdomain_ptr[1:] - subdomain_ptr[:-1])\n        inv_subblock_ptr[1:] = np.cumsum(blocksize*blocksize)\n\n        # Extract each block column from A\n        inv_subblock = np.zeros((inv_subblock_ptr[-1],), dtype=A.dtype)\n        amg_core.extract_subblocks(A.indptr, A.indices, A.data, inv_subblock,\n                                   inv_subblock_ptr, subdomain, subdomain_ptr,\n                                   int(subdomain_ptr.shape[0]-1), A.shape[0])\n        # Choose tolerance for which singular values are zero in *gelss below\n        t = A.dtype.char\n        eps = np.finfo(np.float).eps\n        feps = np.finfo(np.single).eps\n        geps = np.finfo(np.longfloat).eps\n        _array_precision = {'f': 0, 'd': 1, 'g': 2, 'F': 0, 'D': 1, 'G': 2}\n        cond = {0: feps*1e3, 1: eps*1e6, 2: geps*1e6}[_array_precision[t]]\n\n        # Invert each block column\n        my_pinv, = la.get_lapack_funcs(['gelss'],\n                                       (np.ones((1,), dtype=A.dtype)))\n        for i in range(subdomain_ptr.shape[0]-1):\n            m = blocksize[i]\n            rhs = sp.eye(m, m, dtype=A.dtype)\n            j0 = inv_subblock_ptr[i]\n            j1 = inv_subblock_ptr[i+1]\n            gelssoutput = my_pinv(inv_subblock[j0:j1].reshape(m, m),\n                                  rhs, cond=cond, overwrite_a=True,\n                                  overwrite_b=True)\n            inv_subblock[j0:j1] = np.ravel(gelssoutput[1])\n\n    A.schwarz_parameters = (subdomain, subdomain_ptr, inv_subblock,\n                            inv_subblock_ptr)\n    return A.schwarz_parameters"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconjugate Gradient algorithm. Solves the linear system Ax = b. Left preconditioning is supported. Parameters ---------- A : array, matrix, sparse matrix, LinearOperator n x n, linear system to solve b : array, matrix right hand side, shape is (n,) or (n,1) x0 : array, matrix initial guess, default is a vector of zeros tol : float relative convergence tolerance, i.e. tol is scaled by the preconditioner norm of r_0, or ||r_0||_M. maxiter : int maximum number of allowed iterations xtype : type dtype for the solution, default is automatic type detection M : array, matrix, sparse matrix, LinearOperator n x n, inverted preconditioner, i.e. solve M A x = M b. callback : function User-supplied function is called after each iteration as callback(xk), where xk is the current solution vector residuals : list residuals contains the residual norm history, including the initial residual. The preconditioner norm is used, instead of the Euclidean norm. Returns ------- (xNew, info) xNew : an updated guess to the solution of Ax = b info : halting status of cg == ======================================= 0 successful exit >0 convergence to tolerance not achieved, return iteration count instead. <0 numerical breakdown, or illegal input == ======================================= Notes ----- The LinearOperator class is in scipy.sparse.linalg.interface. Use this class if you prefer to define A or M as a mat-vec routine as opposed to explicitly constructing the matrix. A.psolve(..) is still supported as a legacy. The residual in the preconditioner norm is both used for halting and returned in the residuals list. Examples -------- >>> from pyamg.krylov.cg import cg >>> from pyamg.util.linalg import norm >>> import numpy as np >>> from pyamg.gallery import poisson >>> A = poisson((10,10)) >>> b = np.ones((A.shape[0],)) >>> (x,flag) = cg(A,b, maxiter=2, tol=1e-8) >>> print norm(b - A*x) 10.9370700187 References ---------- .. [1] Yousef Saad, \"Iterative Methods for Sparse Linear Systems, Second Edition\", SIAM, pp. 262-67, 2003 http://www-users.cs.umn.edu/~saad/books.html", "response": "def cg(A, b, x0=None, tol=1e-5, maxiter=None, xtype=None, M=None,\n       callback=None, residuals=None):\n    \"\"\"Conjugate Gradient algorithm.\n\n    Solves the linear system Ax = b. Left preconditioning is supported.\n\n    Parameters\n    ----------\n    A : array, matrix, sparse matrix, LinearOperator\n        n x n, linear system to solve\n    b : array, matrix\n        right hand side, shape is (n,) or (n,1)\n    x0 : array, matrix\n        initial guess, default is a vector of zeros\n    tol : float\n        relative convergence tolerance, i.e. tol is scaled by the\n        preconditioner norm of r_0, or ||r_0||_M.\n    maxiter : int\n        maximum number of allowed iterations\n    xtype : type\n        dtype for the solution, default is automatic type detection\n    M : array, matrix, sparse matrix, LinearOperator\n        n x n, inverted preconditioner, i.e. solve M A x = M b.\n    callback : function\n        User-supplied function is called after each iteration as\n        callback(xk), where xk is the current solution vector\n    residuals : list\n        residuals contains the residual norm history,\n        including the initial residual.  The preconditioner norm\n        is used, instead of the Euclidean norm.\n\n    Returns\n    -------\n    (xNew, info)\n    xNew : an updated guess to the solution of Ax = b\n    info : halting status of cg\n\n            ==  =======================================\n            0   successful exit\n            >0  convergence to tolerance not achieved,\n                return iteration count instead.\n            <0  numerical breakdown, or illegal input\n            ==  =======================================\n\n    Notes\n    -----\n    The LinearOperator class is in scipy.sparse.linalg.interface.\n    Use this class if you prefer to define A or M as a mat-vec routine\n    as opposed to explicitly constructing the matrix.  A.psolve(..) is\n    still supported as a legacy.\n\n    The residual in the preconditioner norm is both used for halting and\n    returned in the residuals list.\n\n    Examples\n    --------\n    >>> from pyamg.krylov.cg import cg\n    >>> from pyamg.util.linalg import norm\n    >>> import numpy as np\n    >>> from pyamg.gallery import poisson\n    >>> A = poisson((10,10))\n    >>> b = np.ones((A.shape[0],))\n    >>> (x,flag) = cg(A,b, maxiter=2, tol=1e-8)\n    >>> print norm(b - A*x)\n    10.9370700187\n\n    References\n    ----------\n    .. [1] Yousef Saad, \"Iterative Methods for Sparse Linear Systems,\n       Second Edition\", SIAM, pp. 262-67, 2003\n       http://www-users.cs.umn.edu/~saad/books.html\n\n    \"\"\"\n    A, M, x, b, postprocess = make_system(A, M, x0, b)\n\n    # Ensure that warnings are always reissued from this function\n    import warnings\n    warnings.filterwarnings('always', module='pyamg\\.krylov\\._cg')\n\n    # determine maxiter\n    if maxiter is None:\n        maxiter = int(1.3*len(b)) + 2\n    elif maxiter < 1:\n        raise ValueError('Number of iterations must be positive')\n\n    # choose tolerance for numerically zero values\n    # t = A.dtype.char\n    # eps = np.finfo(np.float).eps\n    # feps = np.finfo(np.single).eps\n    # geps = np.finfo(np.longfloat).eps\n    # _array_precision = {'f': 0, 'd': 1, 'g': 2, 'F': 0, 'D': 1, 'G': 2}\n    # numerically_zero = {0: feps*1e3, 1: eps*1e6,\n    #                    2: geps*1e6}[_array_precision[t]]\n\n    # setup method\n    r = b - A*x\n    z = M*r\n    p = z.copy()\n    rz = np.inner(r.conjugate(), z)\n\n    # use preconditioner norm\n    normr = np.sqrt(rz)\n\n    if residuals is not None:\n        residuals[:] = [normr]  # initial residual\n\n    # Check initial guess ( scaling by b, if b != 0,\n    #   must account for case when norm(b) is very small)\n    normb = norm(b)\n    if normb == 0.0:\n        normb = 1.0\n    if normr < tol*normb:\n        return (postprocess(x), 0)\n\n    # Scale tol by ||r_0||_M\n    if normr != 0.0:\n        tol = tol*normr\n\n    # How often should r be recomputed\n    recompute_r = 8\n\n    iter = 0\n\n    while True:\n        Ap = A*p\n\n        rz_old = rz\n        # Step number in Saad's pseudocode\n        pAp = np.inner(Ap.conjugate(), p)            # check curvature of A\n        if pAp < 0.0:\n            warn(\"\\nIndefinite matrix detected in CG, aborting\\n\")\n            return (postprocess(x), -1)\n\n        alpha = rz/pAp                            # 3\n        x += alpha * p                            # 4\n\n        if np.mod(iter, recompute_r) and iter > 0:   # 5\n            r -= alpha * Ap\n        else:\n            r = b - A*x\n\n        z = M*r                                   # 6\n        rz = np.inner(r.conjugate(), z)\n\n        if rz < 0.0:                              # check curvature of M\n            warn(\"\\nIndefinite preconditioner detected in CG, aborting\\n\")\n            return (postprocess(x), -1)\n\n        beta = rz/rz_old                          # 7\n        p *= beta                                 # 8\n        p += z\n\n        iter += 1\n\n        normr = np.sqrt(rz)                          # use preconditioner norm\n\n        if residuals is not None:\n            residuals.append(normr)\n\n        if callback is not None:\n            callback(x)\n\n        if normr < tol:\n            return (postprocess(x), 0)\n        elif rz == 0.0:\n            # important to test after testing normr < tol. rz == 0.0 is an\n            # indicator of convergence when r = 0.0\n            warn(\"\\nSingular preconditioner detected in CG, ceasing \\\n                  iterations\\n\")\n            return (postprocess(x), -1)\n\n        if iter == maxiter:\n            return (postprocess(x), iter)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a coarse grid solver suitable for multilevel_solver.", "response": "def coarse_grid_solver(solver):\n    \"\"\"Return a coarse grid solver suitable for multilevel_solver.\n\n    Parameters\n    ----------\n    solver : string, callable, tuple\n        The solver method is either (1) a string such as 'splu' or 'pinv' of a\n        callable object which receives only parameters (A, b) and returns an\n        (approximate or exact) solution to the linear system Ax = b, or (2) a\n        callable object that takes parameters (A,b) and returns an (approximate\n        or exact) solution to Ax = b, or (3) a tuple of the form\n        (string|callable, args), where args is a dictionary of arguments to\n        be passed to the function denoted by string or callable.\n\n        The set of valid string arguments is:\n            - Sparse direct methods:\n                + splu : sparse LU solver\n            - Sparse iterative methods:\n                + the name of any method in scipy.sparse.linalg.isolve or\n                  pyamg.krylov (e.g. 'cg').\n                  Methods in pyamg.krylov take precedence.\n                + relaxation method, such as 'gauss_seidel' or 'jacobi',\n                  present in pyamg.relaxation\n            - Dense methods:\n                + pinv     : pseudoinverse (QR)\n                + pinv2    : pseudoinverse (SVD)\n                + lu       : LU factorization\n                + cholesky : Cholesky factorization\n\n    Returns\n    -------\n    ptr : generic_solver\n        A class for use as a standalone or coarse grids solver\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from scipy.sparse import spdiags\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg import coarse_grid_solver\n    >>> A = poisson((10, 10), format='csr')\n    >>> b = A * np.ones(A.shape[0])\n    >>> cgs = coarse_grid_solver('lu')\n    >>> x = cgs(A, b)\n\n    \"\"\"\n    def unpack_arg(v):\n        if isinstance(v, tuple):\n            return v[0], v[1]\n        else:\n            return v, {}\n\n    solver, kwargs = unpack_arg(solver)\n\n    if solver in ['pinv', 'pinv2']:\n        def solve(self, A, b):\n            if not hasattr(self, 'P'):\n                self.P = getattr(sp.linalg, solver)(A.todense(), **kwargs)\n            return np.dot(self.P, b)\n\n    elif solver == 'lu':\n        def solve(self, A, b):\n            if not hasattr(self, 'LU'):\n                self.LU = sp.linalg.lu_factor(A.todense(), **kwargs)\n            return sp.linalg.lu_solve(self.LU, b)\n\n    elif solver == 'cholesky':\n        def solve(self, A, b):\n            if not hasattr(self, 'L'):\n                self.L = sp.linalg.cho_factor(A.todense(), **kwargs)\n            return sp.linalg.cho_solve(self.L, b)\n\n    elif solver == 'splu':\n        def solve(self, A, b):\n            if not hasattr(self, 'LU'):\n                # for multiple candidates in B, A will often have a couple zero\n                # rows/columns that must be removed\n                Acsc = A.tocsc()\n                Acsc.eliminate_zeros()\n                diffptr = Acsc.indptr[:-1] - Acsc.indptr[1:]\n                nonzero_cols = (diffptr != 0).nonzero()[0]\n                Map = sp.sparse.eye(Acsc.shape[0], Acsc.shape[1], format='csc')\n                Map = Map[:, nonzero_cols]\n                Acsc = Map.T.tocsc() * Acsc * Map\n                self.LU = sp.sparse.linalg.splu(Acsc, **kwargs)\n                self.LU_Map = Map\n\n            return self.LU_Map * self.LU.solve(np.ravel(self.LU_Map.T * b))\n\n    elif solver in ['bicg', 'bicgstab', 'cg', 'cgs', 'gmres', 'qmr', 'minres']:\n        from pyamg import krylov\n        if hasattr(krylov, solver):\n            fn = getattr(krylov, solver)\n        else:\n            fn = getattr(sp.sparse.linalg.isolve, solver)\n\n        def solve(self, A, b):\n            if 'tol' not in kwargs:\n                eps = np.finfo(np.float).eps\n                feps = np.finfo(np.single).eps\n                geps = np.finfo(np.longfloat).eps\n                _array_precision = {'f': 0, 'd': 1, 'g': 2,\n                                    'F': 0, 'D': 1, 'G': 2}\n                kwargs['tol'] = {0: feps * 1e3, 1: eps * 1e6,\n                                 2: geps * 1e6}[_array_precision[A.dtype.char]]\n\n            return fn(A, b, **kwargs)[0]\n\n    elif solver in ['gauss_seidel', 'jacobi', 'block_gauss_seidel', 'schwarz',\n                    'block_jacobi', 'richardson', 'sor', 'chebyshev',\n                    'jacobi_ne', 'gauss_seidel_ne', 'gauss_seidel_nr']:\n\n        if 'iterations' not in kwargs:\n            kwargs['iterations'] = 10\n\n        def solve(self, A, b):\n            from pyamg.relaxation import smoothing\n            from pyamg import multilevel_solver\n\n            lvl = multilevel_solver.level()\n            lvl.A = A\n            fn = getattr(smoothing, 'setup_' + str(solver))\n            relax = fn(lvl, **kwargs)\n            x = np.zeros_like(b)\n            relax(A, x, b)\n\n            return x\n\n    elif solver is None:\n        # No coarse grid solve\n        def solve(self, A, b):\n            return 0 * b  # should this return b instead?\n\n    elif callable(solver):\n        def solve(self, A, b):\n            return solver(A, b, **kwargs)\n\n    else:\n        raise ValueError('unknown solver: %s' % solver)\n\n    class generic_solver:\n        def __call__(self, A, b):\n            # make sure x is same dimensions and type as b\n            b = np.asanyarray(b)\n\n            if A.nnz == 0:\n                # if A.nnz = 0, then we expect no correction\n                x = np.zeros(b.shape)\n            else:\n                x = solve(self, A, b)\n\n            if isinstance(b, np.ndarray):\n                x = np.asarray(x)\n            elif isinstance(b, np.matrix):\n                x = np.asmatrix(x)\n            else:\n                raise ValueError('unrecognized type')\n\n            return x.reshape(b.shape)\n\n        def __repr__(self):\n            return 'coarse_grid_solver(' + repr(solver) + ')'\n\n        def name(self):\n            return repr(solver)\n\n    return generic_solver()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cycle_complexity(self, cycle='V'):\n        cycle = str(cycle).upper()\n\n        nnz = [level.A.nnz for level in self.levels]\n\n        def V(level):\n            if len(self.levels) == 1:\n                return nnz[0]\n            elif level == len(self.levels) - 2:\n                return 2 * nnz[level] + nnz[level + 1]\n            else:\n                return 2 * nnz[level] + V(level + 1)\n\n        def W(level):\n            if len(self.levels) == 1:\n                return nnz[0]\n            elif level == len(self.levels) - 2:\n                return 2 * nnz[level] + nnz[level + 1]\n            else:\n                return 2 * nnz[level] + 2 * W(level + 1)\n\n        def F(level):\n            if len(self.levels) == 1:\n                return nnz[0]\n            elif level == len(self.levels) - 2:\n                return 2 * nnz[level] + nnz[level + 1]\n            else:\n                return 2 * nnz[level] + F(level + 1) + V(level + 1)\n\n        if cycle == 'V':\n            flops = V(0)\n        elif (cycle == 'W') or (cycle == 'AMLI'):\n            flops = W(0)\n        elif cycle == 'F':\n            flops = F(0)\n        else:\n            raise TypeError('Unrecognized cycle type (%s)' % cycle)\n\n        return float(flops) / float(nnz[0])", "response": "Return the cycle complexity of the multigrid cycle."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef operator_complexity(self):\n        return sum([level.A.nnz for level in self.levels]) /\\\n            float(self.levels[0].A.nnz)", "response": "Calculates the operator complexity of this multigrid hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the grid complexity of this multigrid hierarchy.", "response": "def grid_complexity(self):\n        \"\"\"Grid complexity of this multigrid hierarchy.\n\n        Defined as:\n            Number of unknowns on all levels /\n            Number of unknowns on the finest level\n\n        \"\"\"\n        return sum([level.A.shape[0] for level in self.levels]) /\\\n            float(self.levels[0].A.shape[0])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a preconditioner using this multigrid cycle.", "response": "def aspreconditioner(self, cycle='V'):\n        \"\"\"Create a preconditioner using this multigrid cycle.\n\n        Parameters\n        ----------\n        cycle : {'V','W','F','AMLI'}\n            Type of multigrid cycle to perform in each iteration.\n\n        Returns\n        -------\n        precond : LinearOperator\n            Preconditioner suitable for the iterative solvers in defined in\n            the scipy.sparse.linalg module (e.g. cg, gmres) and any other\n            solver that uses the LinearOperator interface.  Refer to the\n            LinearOperator documentation in scipy.sparse.linalg\n\n        See Also\n        --------\n        multilevel_solver.solve, scipy.sparse.linalg.LinearOperator\n\n        Examples\n        --------\n        >>> from pyamg.aggregation import smoothed_aggregation_solver\n        >>> from pyamg.gallery import poisson\n        >>> from scipy.sparse.linalg import cg\n        >>> import scipy as sp\n        >>> A = poisson((100, 100), format='csr')          # matrix\n        >>> b = sp.rand(A.shape[0])                        # random RHS\n        >>> ml = smoothed_aggregation_solver(A)            # AMG solver\n        >>> M = ml.aspreconditioner(cycle='V')             # preconditioner\n        >>> x, info = cg(A, b, tol=1e-8, maxiter=30, M=M)  # solve with CG\n\n        \"\"\"\n        from scipy.sparse.linalg import LinearOperator\n\n        shape = self.levels[0].A.shape\n        dtype = self.levels[0].A.dtype\n\n        def matvec(b):\n            return self.solve(b, maxiter=1, cycle=cycle, tol=1e-12)\n\n        return LinearOperator(shape, matvec, dtype=dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef solve(self, b, x0=None, tol=1e-5, maxiter=100, cycle='V', accel=None,\n              callback=None, residuals=None, return_residuals=False):\n        \"\"\"Execute multigrid cycling.\n\n        Parameters\n        ----------\n        b : array\n            Right hand side.\n        x0 : array\n            Initial guess.\n        tol : float\n            Stopping criteria: relative residual r[k]/r[0] tolerance.\n        maxiter : int\n            Stopping criteria: maximum number of allowable iterations.\n        cycle : {'V','W','F','AMLI'}\n            Type of multigrid cycle to perform in each iteration.\n        accel : string, function\n            Defines acceleration method.  Can be a string such as 'cg'\n            or 'gmres' which is the name of an iterative solver in\n            pyamg.krylov (preferred) or scipy.sparse.linalg.isolve.\n            If accel is not a string, it will be treated like a function\n            with the same interface provided by the iterative solvers in SciPy.\n        callback : function\n            User-defined function called after each iteration.  It is\n            called as callback(xk) where xk is the k-th iterate vector.\n        residuals : list\n            List to contain residual norms at each iteration.\n\n        Returns\n        -------\n        x : array\n            Approximate solution to Ax=b\n\n        See Also\n        --------\n        aspreconditioner\n\n        Examples\n        --------\n        >>> from numpy import ones\n        >>> from pyamg import ruge_stuben_solver\n        >>> from pyamg.gallery import poisson\n        >>> A = poisson((100, 100), format='csr')\n        >>> b = A * ones(A.shape[0])\n        >>> ml = ruge_stuben_solver(A, max_coarse=10)\n        >>> residuals = []\n        >>> x = ml.solve(b, tol=1e-12, residuals=residuals) # standalone solver\n\n        \"\"\"\n        from pyamg.util.linalg import residual_norm, norm\n\n        if x0 is None:\n            x = np.zeros_like(b)\n        else:\n            x = np.array(x0)  # copy\n\n        cycle = str(cycle).upper()\n\n        # AMLI cycles require hermitian matrix\n        if (cycle == 'AMLI') and hasattr(self.levels[0].A, 'symmetry'):\n            if self.levels[0].A.symmetry != 'hermitian':\n                raise ValueError('AMLI cycles require \\\n                    symmetry to be hermitian')\n\n        if accel is not None:\n\n            # Check for symmetric smoothing scheme when using CG\n            if (accel is 'cg') and (not self.symmetric_smoothing):\n                warn('Incompatible non-symmetric multigrid preconditioner '\n                     'detected, due to presmoother/postsmoother combination. '\n                     'CG requires SPD preconditioner, not just SPD matrix.')\n\n            # Check for AMLI compatability\n            if (accel != 'fgmres') and (cycle == 'AMLI'):\n                raise ValueError('AMLI cycles require acceleration (accel) '\n                                 'to be fgmres, or no acceleration')\n\n            # py23 compatibility:\n            try:\n                basestring\n            except NameError:\n                basestring = str\n\n            # Acceleration is being used\n            if isinstance(accel, basestring):\n                from pyamg import krylov\n                from scipy.sparse.linalg import isolve\n                if hasattr(krylov, accel):\n                    accel = getattr(krylov, accel)\n                else:\n                    accel = getattr(isolve, accel)\n\n            A = self.levels[0].A\n            M = self.aspreconditioner(cycle=cycle)\n\n            try:  # try PyAMG style interface which has a residuals parameter\n                return accel(A, b, x0=x0, tol=tol, maxiter=maxiter, M=M,\n                             callback=callback, residuals=residuals)[0]\n            except BaseException:\n                # try the scipy.sparse.linalg.isolve style interface,\n                # which requires a call back function if a residual\n                # history is desired\n\n                cb = callback\n                if residuals is not None:\n                    residuals[:] = [residual_norm(A, x, b)]\n\n                    def callback(x):\n                        if sp.isscalar(x):\n                            residuals.append(x)\n                        else:\n                            residuals.append(residual_norm(A, x, b))\n                        if cb is not None:\n                            cb(x)\n\n                return accel(A, b, x0=x0, tol=tol, maxiter=maxiter, M=M,\n                             callback=callback)[0]\n\n        else:\n            # Scale tol by normb\n            # Don't scale tol earlier. The accel routine should also scale tol\n            normb = norm(b)\n            if normb != 0:\n                tol = tol * normb\n\n        if return_residuals:\n            warn('return_residuals is deprecated.  Use residuals instead')\n            residuals = []\n        if residuals is None:\n            residuals = []\n        else:\n            residuals[:] = []\n\n        # Create uniform types for A, x and b\n        # Clearly, this logic doesn't handle the case of real A and complex b\n        from scipy.sparse.sputils import upcast\n        from pyamg.util.utils import to_type\n        tp = upcast(b.dtype, x.dtype, self.levels[0].A.dtype)\n        [b, x] = to_type(tp, [b, x])\n        b = np.ravel(b)\n        x = np.ravel(x)\n\n        A = self.levels[0].A\n\n        residuals.append(residual_norm(A, x, b))\n\n        self.first_pass = True\n\n        while len(residuals) <= maxiter and residuals[-1] > tol:\n            if len(self.levels) == 1:\n                # hierarchy has only 1 level\n                x = self.coarse_solver(A, b)\n            else:\n                self.__solve(0, x, b, cycle)\n\n            residuals.append(residual_norm(A, x, b))\n\n            self.first_pass = False\n\n            if callback is not None:\n                callback(x)\n\n        if return_residuals:\n            return x, residuals\n        else:\n            return x", "response": "Execute multigrid cycling.\n\n        Parameters\n        ----------\n        b : array\n            Right hand side.\n        x0 : array\n            Initial guess.\n        tol : float\n            Stopping criteria: relative residual r[k]/r[0] tolerance.\n        maxiter : int\n            Stopping criteria: maximum number of allowable iterations.\n        cycle : {'V','W','F','AMLI'}\n            Type of multigrid cycle to perform in each iteration.\n        accel : string, function\n            Defines acceleration method.  Can be a string such as 'cg'\n            or 'gmres' which is the name of an iterative solver in\n            pyamg.krylov (preferred) or scipy.sparse.linalg.isolve.\n            If accel is not a string, it will be treated like a function\n            with the same interface provided by the iterative solvers in SciPy.\n        callback : function\n            User-defined function called after each iteration.  It is\n            called as callback(xk) where xk is the k-th iterate vector.\n        residuals : list\n            List to contain residual norms at each iteration.\n\n        Returns\n        -------\n        x : array\n            Approximate solution to Ax=b\n\n        See Also\n        --------\n        aspreconditioner\n\n        Examples\n        --------\n        >>> from numpy import ones\n        >>> from pyamg import ruge_stuben_solver\n        >>> from pyamg.gallery import poisson\n        >>> A = poisson((100, 100), format='csr')\n        >>> b = A * ones(A.shape[0])\n        >>> ml = ruge_stuben_solver(A, max_coarse=10)\n        >>> residuals = []\n        >>> x = ml.solve(b, tol=1e-12, residuals=residuals) # standalone solver"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __solve(self, lvl, x, b, cycle):\n        A = self.levels[lvl].A\n\n        self.levels[lvl].presmoother(A, x, b)\n\n        residual = b - A * x\n\n        coarse_b = self.levels[lvl].R * residual\n        coarse_x = np.zeros_like(coarse_b)\n\n        if lvl == len(self.levels) - 2:\n            coarse_x[:] = self.coarse_solver(self.levels[-1].A, coarse_b)\n        else:\n            if cycle == 'V':\n                self.__solve(lvl + 1, coarse_x, coarse_b, 'V')\n            elif cycle == 'W':\n                self.__solve(lvl + 1, coarse_x, coarse_b, cycle)\n                self.__solve(lvl + 1, coarse_x, coarse_b, cycle)\n            elif cycle == 'F':\n                self.__solve(lvl + 1, coarse_x, coarse_b, cycle)\n                self.__solve(lvl + 1, coarse_x, coarse_b, 'V')\n            elif cycle == \"AMLI\":\n                # Run nAMLI AMLI cycles, which compute \"optimal\" corrections by\n                # orthogonalizing the coarse-grid corrections in the A-norm\n                nAMLI = 2\n                Ac = self.levels[lvl + 1].A\n                p = np.zeros((nAMLI, coarse_b.shape[0]), dtype=coarse_b.dtype)\n                beta = np.zeros((nAMLI, nAMLI), dtype=coarse_b.dtype)\n                for k in range(nAMLI):\n                    # New search direction --> M^{-1}*residual\n                    p[k, :] = 1\n                    self.__solve(lvl + 1, p[k, :].reshape(coarse_b.shape),\n                                 coarse_b, cycle)\n\n                    # Orthogonalize new search direction to old directions\n                    for j in range(k):  # loops from j = 0...(k-1)\n                        beta[k, j] = np.inner(p[j, :].conj(), Ac * p[k, :]) /\\\n                            np.inner(p[j, :].conj(), Ac * p[j, :])\n                        p[k, :] -= beta[k, j] * p[j, :]\n\n                    # Compute step size\n                    Ap = Ac * p[k, :]\n                    alpha = np.inner(p[k, :].conj(), np.ravel(coarse_b)) /\\\n                        np.inner(p[k, :].conj(), Ap)\n\n                    # Update solution\n                    coarse_x += alpha * p[k, :].reshape(coarse_x.shape)\n\n                    # Update residual\n                    coarse_b -= alpha * Ap.reshape(coarse_b.shape)\n            else:\n                raise TypeError('Unrecognized cycle type (%s)' % cycle)\n\n        x += self.levels[lvl].P * coarse_x   # coarse grid correction\n\n        self.levels[lvl].postsmoother(A, x, b)", "response": "Solve problem on level lvl x b and cycle"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef minimal_residual(A, b, x0=None, tol=1e-5, maxiter=None, xtype=None, M=None,\n                     callback=None, residuals=None):\n    \"\"\"Minimal residual (MR) algorithm.\n\n    Solves the linear system Ax = b. Left preconditioning is supported.\n\n    Parameters\n    ----------\n    A : array, matrix, sparse matrix, LinearOperator\n        n x n, linear system to solve\n    b : array, matrix\n        right hand side, shape is (n,) or (n,1)\n    x0 : array, matrix\n        initial guess, default is a vector of zeros\n    tol : float\n        relative convergence tolerance, i.e. tol is scaled by the\n        preconditioner norm of r_0, or ||r_0||_M.\n    maxiter : int\n        maximum number of allowed iterations\n    xtype : type\n        dtype for the solution, default is automatic type detection\n    M : array, matrix, sparse matrix, LinearOperator\n        n x n, inverted preconditioner, i.e. solve M A x = M b.\n    callback : function\n        User-supplied function is called after each iteration as\n        callback(xk), where xk is the current solution vector\n    residuals : list\n        residuals contains the residual norm history,\n        including the initial residual.  The preconditioner norm\n        is used, instead of the Euclidean norm.\n\n    Returns\n    -------\n    (xNew, info)\n    xNew : an updated guess to the solution of Ax = b\n    info : halting status of cg\n\n            ==  =======================================\n            0   successful exit\n            >0  convergence to tolerance not achieved,\n                return iteration count instead.\n            <0  numerical breakdown, or illegal input\n            ==  =======================================\n\n    Notes\n    -----\n    The LinearOperator class is in scipy.sparse.linalg.interface.\n    Use this class if you prefer to define A or M as a mat-vec routine\n    as opposed to explicitly constructing the matrix.  A.psolve(..) is\n    still supported as a legacy.\n\n    The residual in the preconditioner norm is both used for halting and\n    returned in the residuals list.\n\n    Examples\n    --------\n    >>> from pyamg.krylov import minimal_residual\n    >>> from pyamg.util.linalg import norm\n    >>> import numpy as np\n    >>> from pyamg.gallery import poisson\n    >>> A = poisson((10,10))\n    >>> b = np.ones((A.shape[0],))\n    >>> (x,flag) = minimal_residual(A,b, maxiter=2, tol=1e-8)\n    >>> print norm(b - A*x)\n    7.26369350856\n\n    References\n    ----------\n    .. [1] Yousef Saad, \"Iterative Methods for Sparse Linear Systems,\n       Second Edition\", SIAM, pp. 137--142, 2003\n       http://www-users.cs.umn.edu/~saad/books.html\n\n    \"\"\"\n    A, M, x, b, postprocess = make_system(A, M, x0, b)\n\n    # Ensure that warnings are always reissued from this function\n    import warnings\n    warnings.filterwarnings('always',\n                            module='pyamg\\.krylov\\._minimal_residual')\n\n    # determine maxiter\n    if maxiter is None:\n        maxiter = int(len(b))\n    elif maxiter < 1:\n        raise ValueError('Number of iterations must be positive')\n\n    # setup method\n    r = M*(b - A*x)\n    normr = norm(r)\n\n    # store initial residual\n    if residuals is not None:\n        residuals[:] = [normr]\n\n    # Check initial guess ( scaling by b, if b != 0,\n    #   must account for case when norm(b) is very small)\n    normb = norm(b)\n    if normb == 0.0:\n        normb = 1.0\n    if normr < tol*normb:\n        return (postprocess(x), 0)\n\n    # Scale tol by ||r_0||_M\n    if normr != 0.0:\n        tol = tol*normr\n\n    # How often should r be recomputed\n    recompute_r = 50\n\n    iter = 0\n\n    while True:\n        iter = iter+1\n\n        p = M*(A*r)\n\n        rMAr = np.inner(p.conjugate(), r)  # check curvature of M^-1 A\n        if rMAr < 0.0:\n            warn(\"\\nIndefinite matrix detected in minimal residual,\\\n                  aborting\\n\")\n            return (postprocess(x), -1)\n\n        alpha = rMAr / np.inner(p.conjugate(), p)\n        x = x + alpha*r\n\n        if np.mod(iter, recompute_r) and iter > 0:\n            r = M*(b - A*x)\n        else:\n            r = r - alpha*p\n\n        normr = norm(r)\n        if residuals is not None:\n            residuals.append(normr)\n\n        if callback is not None:\n            callback(x)\n\n        if normr < tol:\n            return (postprocess(x), 0)\n\n        if iter == maxiter:\n            return (postprocess(x), iter)", "response": "Minimal residual (MR) algorithm.\n\n    Solves the linear system Ax = b. Left preconditioning is supported.\n\n    Parameters\n    ----------\n    A : array, matrix, sparse matrix, LinearOperator\n        n x n, linear system to solve\n    b : array, matrix\n        right hand side, shape is (n,) or (n,1)\n    x0 : array, matrix\n        initial guess, default is a vector of zeros\n    tol : float\n        relative convergence tolerance, i.e. tol is scaled by the\n        preconditioner norm of r_0, or ||r_0||_M.\n    maxiter : int\n        maximum number of allowed iterations\n    xtype : type\n        dtype for the solution, default is automatic type detection\n    M : array, matrix, sparse matrix, LinearOperator\n        n x n, inverted preconditioner, i.e. solve M A x = M b.\n    callback : function\n        User-supplied function is called after each iteration as\n        callback(xk), where xk is the current solution vector\n    residuals : list\n        residuals contains the residual norm history,\n        including the initial residual.  The preconditioner norm\n        is used, instead of the Euclidean norm.\n\n    Returns\n    -------\n    (xNew, info)\n    xNew : an updated guess to the solution of Ax = b\n    info : halting status of cg\n\n            ==  =======================================\n            0   successful exit\n            >0  convergence to tolerance not achieved,\n                return iteration count instead.\n            <0  numerical breakdown, or illegal input\n            ==  =======================================\n\n    Notes\n    -----\n    The LinearOperator class is in scipy.sparse.linalg.interface.\n    Use this class if you prefer to define A or M as a mat-vec routine\n    as opposed to explicitly constructing the matrix.  A.psolve(..) is\n    still supported as a legacy.\n\n    The residual in the preconditioner norm is both used for halting and\n    returned in the residuals list.\n\n    Examples\n    --------\n    >>> from pyamg.krylov import minimal_residual\n    >>> from pyamg.util.linalg import norm\n    >>> import numpy as np\n    >>> from pyamg.gallery import poisson\n    >>> A = poisson((10,10))\n    >>> b = np.ones((A.shape[0],))\n    >>> (x,flag) = minimal_residual(A,b, maxiter=2, tol=1e-8)\n    >>> print norm(b - A*x)\n    7.26369350856\n\n    References\n    ----------\n    .. [1] Yousef Saad, \"Iterative Methods for Sparse Linear Systems,\n       Second Edition\", SIAM, pp. 137--142, 2003\n       http://www-users.cs.umn.edu/~saad/books.html"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute a maximal independent vertex set for a graph.", "response": "def maximal_independent_set(G, algo='serial', k=None):\n    \"\"\"Compute a maximal independent vertex set for a graph.\n\n    Parameters\n    ----------\n    G : sparse matrix\n        Symmetric matrix, preferably in sparse CSR or CSC format\n        The nonzeros of G represent the edges of an undirected graph.\n    algo : {'serial', 'parallel'}\n        Algorithm used to compute the MIS\n            * serial   : greedy serial algorithm\n            * parallel : variant of Luby's parallel MIS algorithm\n\n    Returns\n    -------\n    S : array\n        S[i] = 1 if vertex i is in the MIS\n        S[i] = 0 otherwise\n\n    Notes\n    -----\n    Diagonal entries in the G (self loops) will be ignored.\n\n    Luby's algorithm is significantly more expensive than the\n    greedy serial algorithm.\n\n    \"\"\"\n    G = asgraph(G)\n    N = G.shape[0]\n\n    mis = np.empty(N, dtype='intc')\n    mis[:] = -1\n\n    if k is None:\n        if algo == 'serial':\n            fn = amg_core.maximal_independent_set_serial\n            fn(N, G.indptr, G.indices, -1, 1, 0, mis)\n        elif algo == 'parallel':\n            fn = amg_core.maximal_independent_set_parallel\n            fn(N, G.indptr, G.indices, -1, 1, 0, mis, sp.rand(N), -1)\n        else:\n            raise ValueError('unknown algorithm (%s)' % algo)\n    else:\n        fn = amg_core.maximal_independent_set_k_parallel\n        fn(N, G.indptr, G.indices, k, mis, sp.rand(N), -1)\n\n    return mis"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute a vertex coloring of a graph.", "response": "def vertex_coloring(G, method='MIS'):\n    \"\"\"Compute a vertex coloring of a graph.\n\n    Parameters\n    ----------\n    G : sparse matrix\n        Symmetric matrix, preferably in sparse CSR or CSC format\n        The nonzeros of G represent the edges of an undirected graph.\n    method : string\n        Algorithm used to compute the vertex coloring:\n\n            * 'MIS' - Maximal Independent Set\n            * 'JP'  - Jones-Plassmann (parallel)\n            * 'LDF' - Largest-Degree-First (parallel)\n\n    Returns\n    -------\n    coloring : array\n        An array of vertex colors (integers beginning at 0)\n\n    Notes\n    -----\n    Diagonal entries in the G (self loops) will be ignored.\n\n    \"\"\"\n    G = asgraph(G)\n    N = G.shape[0]\n\n    coloring = np.empty(N, dtype='intc')\n\n    if method == 'MIS':\n        fn = amg_core.vertex_coloring_mis\n        fn(N, G.indptr, G.indices, coloring)\n    elif method == 'JP':\n        fn = amg_core.vertex_coloring_jones_plassmann\n        fn(N, G.indptr, G.indices, coloring, sp.rand(N))\n    elif method == 'LDF':\n        fn = amg_core.vertex_coloring_LDF\n        fn(N, G.indptr, G.indices, coloring, sp.rand(N))\n    else:\n        raise ValueError('unknown method (%s)' % method)\n\n    return coloring"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bellman_ford(G, seeds, maxiter=None):\n    G = asgraph(G)\n    N = G.shape[0]\n\n    if maxiter is not None and maxiter < 0:\n        raise ValueError('maxiter must be positive')\n    if G.dtype == complex:\n        raise ValueError('Bellman-Ford algorithm only defined for real\\\n                          weights')\n\n    seeds = np.asarray(seeds, dtype='intc')\n\n    distances = np.empty(N, dtype=G.dtype)\n    distances[:] = max_value(G.dtype)\n    distances[seeds] = 0\n\n    nearest_seed = np.empty(N, dtype='intc')\n    nearest_seed[:] = -1\n    nearest_seed[seeds] = seeds\n\n    old_distances = np.empty_like(distances)\n\n    iter = 0\n    while maxiter is None or iter < maxiter:\n        old_distances[:] = distances\n\n        amg_core.bellman_ford(N, G.indptr, G.indices, G.data, distances,\n                              nearest_seed)\n\n        if (old_distances == distances).all():\n            break\n\n    return (distances, nearest_seed)", "response": "Bellman - Ford algorithm for real - length graph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lloyd_cluster(G, seeds, maxiter=10):\n    G = asgraph(G)\n    N = G.shape[0]\n\n    if G.dtype.kind == 'c':\n        # complex dtype\n        G = np.abs(G)\n\n    # interpret seeds argument\n    if np.isscalar(seeds):\n        seeds = np.random.permutation(N)[:seeds]\n        seeds = seeds.astype('intc')\n    else:\n        seeds = np.array(seeds, dtype='intc')\n\n    if len(seeds) < 1:\n        raise ValueError('at least one seed is required')\n\n    if seeds.min() < 0:\n        raise ValueError('invalid seed index (%d)' % seeds.min())\n    if seeds.max() >= N:\n        raise ValueError('invalid seed index (%d)' % seeds.max())\n\n    clusters = np.empty(N, dtype='intc')\n    distances = np.empty(N, dtype=G.dtype)\n\n    for i in range(maxiter):\n        last_seeds = seeds.copy()\n\n        amg_core.lloyd_cluster(N, G.indptr, G.indices, G.data,\n                               len(seeds), distances, clusters, seeds)\n\n        if (seeds == last_seeds).all():\n            break\n\n    return (distances, clusters, seeds)", "response": "Perform Lloyd clustering on a graph with weighted edges."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connected_components(G):\n    G = asgraph(G)\n    N = G.shape[0]\n\n    components = np.empty(N, G.indptr.dtype)\n\n    fn = amg_core.connected_components\n    fn(N, G.indptr, G.indices, components)\n\n    return components", "response": "Compute the connected components of a graph G."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef symmetric_rcm(A):\n    n = A.shape[0]\n\n    root, order, level = pseudo_peripheral_node(A)\n\n    Perm = sparse.identity(n, format='csr')\n    p = level.argsort()\n    Perm = Perm[p, :]\n\n    return Perm * A * Perm.T", "response": "Symmetric Reverse Cutthill - McKee."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pseudo_peripheral_node(A):\n    from pyamg.graph import breadth_first_search\n    n = A.shape[0]\n\n    valence = np.diff(A.indptr)\n\n    # select an initial node x, set delta = 0\n    x = int(np.random.rand() * n)\n    delta = 0\n\n    while True:\n        # do a level-set traversal from x\n        order, level = breadth_first_search(A, x)\n\n        # select a node y in the last level with min degree\n        maxlevel = level.max()\n        lastnodes = np.where(level == maxlevel)[0]\n        lastnodesvalence = valence[lastnodes]\n        minlastnodesvalence = lastnodesvalence.min()\n        y = np.where(lastnodesvalence == minlastnodesvalence)[0][0]\n        y = lastnodes[y]\n\n        # if d(x,y)>delta, set, and go to bfs above\n        if level[y] > delta:\n            x = y\n            delta = level[y]\n        else:\n            return x, order, level", "response": "Find a pseudo peripheral node."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprofiles a particular multilevel object.", "response": "def profile_solver(ml, accel=None, **kwargs):\n    \"\"\"Profile a particular multilevel object.\n\n    Parameters\n    ----------\n    ml : multilevel\n        Fully constructed multilevel object\n    accel : function pointer\n        Pointer to a valid Krylov solver (e.g. gmres, cg)\n\n    Returns\n    -------\n    residuals : array\n        Array of residuals for each iteration\n\n    See Also\n    --------\n    multilevel.psolve, multilevel.solve\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from scipy.sparse import spdiags, csr_matrix\n    >>> from scipy.sparse.linalg import cg\n    >>> from pyamg.classical import ruge_stuben_solver\n    >>> from pyamg.util.utils import profile_solver\n    >>> n=100\n    >>> e = np.ones((n,1)).ravel()\n    >>> data = [ -1*e, 2*e, -1*e ]\n    >>> A = csr_matrix(spdiags(data,[-1,0,1],n,n))\n    >>> b = A*np.ones(A.shape[0])\n    >>> ml = ruge_stuben_solver(A, max_coarse=10)\n    >>> res = profile_solver(ml,accel=cg)\n\n    \"\"\"\n    A = ml.levels[0].A\n    b = A * sp.rand(A.shape[0], 1)\n    residuals = []\n\n    if accel is None:\n        ml.solve(b, residuals=residuals, **kwargs)\n    else:\n        def callback(x):\n            residuals.append(norm(np.ravel(b) - np.ravel(A*x)))\n        M = ml.aspreconditioner(cycle=kwargs.get('cycle', 'V'))\n        accel(A, b, M=M, callback=callback, **kwargs)\n\n    return np.asarray(residuals)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef diag_sparse(A):\n    if isspmatrix(A):\n        return A.diagonal()\n    else:\n        if(np.ndim(A) != 1):\n            raise ValueError('input diagonal array expected to be 1d')\n        return csr_matrix((np.asarray(A), np.arange(len(A)),\n                           np.arange(len(A)+1)), (len(A), len(A)))", "response": "Return a diagonal matrix of A."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nscaling the sparse rows of a matrix.", "response": "def scale_rows(A, v, copy=True):\n    \"\"\"Scale the sparse rows of a matrix.\n\n    Parameters\n    ----------\n    A : sparse matrix\n        Sparse matrix with M rows\n    v : array_like\n        Array of M scales\n    copy : {True,False}\n        - If copy=True, then the matrix is copied to a new and different return\n          matrix (e.g. B=scale_rows(A,v))\n        - If copy=False, then the matrix is overwritten deeply (e.g.\n          scale_rows(A,v,copy=False) overwrites A)\n\n    Returns\n    -------\n    A : sparse matrix\n        Scaled sparse matrix in original format\n\n    See Also\n    --------\n    scipy.sparse._sparsetools.csr_scale_rows, scale_columns\n\n    Notes\n    -----\n    - if A is a csc_matrix, the transpose A.T is passed to scale_columns\n    - if A is not csr, csc, or bsr, it is converted to csr and sent\n      to scale_rows\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from scipy.sparse import spdiags\n    >>> from pyamg.util.utils import scale_rows\n    >>> n=5\n    >>> e = np.ones((n,1)).ravel()\n    >>> data = [ -1*e, 2*e, -1*e ]\n    >>> A = spdiags(data,[-1,0,1],n,n-1).tocsr()\n    >>> B = scale_rows(A,5*np.ones((A.shape[0],1)))\n\n    \"\"\"\n    v = np.ravel(v)\n\n    M, N = A.shape\n\n    if not isspmatrix(A):\n        raise ValueError('scale rows needs a sparse matrix')\n\n    if M != len(v):\n        raise ValueError('scale vector has incompatible shape')\n\n    if copy:\n        A = A.copy()\n        A.data = np.asarray(A.data, dtype=upcast(A.dtype, v.dtype))\n    else:\n        v = np.asarray(v, dtype=A.dtype)\n\n    if isspmatrix_csr(A):\n        csr_scale_rows(M, N, A.indptr, A.indices, A.data, v)\n    elif isspmatrix_bsr(A):\n        R, C = A.blocksize\n        bsr_scale_rows(int(M/R), int(N/C), R, C, A.indptr, A.indices,\n                       np.ravel(A.data), v)\n    elif isspmatrix_csc(A):\n        pyamg.amg_core.csc_scale_rows(M, N, A.indptr, A.indices, A.data, v)\n    else:\n        fmt = A.format\n        A = scale_rows(csr_matrix(A), v).asformat(fmt)\n\n    return A"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nscaling the sparse columns of a matrix.", "response": "def scale_columns(A, v, copy=True):\n    \"\"\"Scale the sparse columns of a matrix.\n\n    Parameters\n    ----------\n    A : sparse matrix\n        Sparse matrix with N rows\n    v : array_like\n        Array of N scales\n    copy : {True,False}\n        - If copy=True, then the matrix is copied to a new and different return\n          matrix (e.g. B=scale_columns(A,v))\n        - If copy=False, then the matrix is overwritten deeply (e.g.\n          scale_columns(A,v,copy=False) overwrites A)\n\n    Returns\n    -------\n    A : sparse matrix\n        Scaled sparse matrix in original format\n\n    See Also\n    --------\n    scipy.sparse._sparsetools.csr_scale_columns, scale_rows\n\n    Notes\n    -----\n    - if A is a csc_matrix, the transpose A.T is passed to scale_rows\n    - if A is not csr, csc, or bsr, it is converted to csr and sent to\n      scale_rows\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from scipy.sparse import spdiags\n    >>> from pyamg.util.utils import scale_columns\n    >>> n=5\n    >>> e = np.ones((n,1)).ravel()\n    >>> data = [ -1*e, 2*e, -1*e ]\n    >>> A = spdiags(data,[-1,0,1],n,n-1).tocsr()\n    >>> print scale_columns(A,5*np.ones((A.shape[1],1))).todense()\n    [[ 10.  -5.   0.   0.]\n     [ -5.  10.  -5.   0.]\n     [  0.  -5.  10.  -5.]\n     [  0.   0.  -5.  10.]\n     [  0.   0.   0.  -5.]]\n\n    \"\"\"\n    v = np.ravel(v)\n\n    M, N = A.shape\n\n    if not isspmatrix(A):\n        raise ValueError('scale columns needs a sparse matrix')\n\n    if N != len(v):\n        raise ValueError('scale vector has incompatible shape')\n\n    if copy:\n        A = A.copy()\n        A.data = np.asarray(A.data, dtype=upcast(A.dtype, v.dtype))\n    else:\n        v = np.asarray(v, dtype=A.dtype)\n\n    if isspmatrix_csr(A):\n        csr_scale_columns(M, N, A.indptr, A.indices, A.data, v)\n    elif isspmatrix_bsr(A):\n        R, C = A.blocksize\n        bsr_scale_columns(int(M/R), int(N/C), R, C, A.indptr, A.indices,\n                          np.ravel(A.data), v)\n    elif isspmatrix_csc(A):\n        pyamg.amg_core.csc_scale_columns(M, N, A.indptr, A.indices, A.data, v)\n    else:\n        fmt = A.format\n        A = scale_columns(csr_matrix(A), v).asformat(fmt)\n\n    return A"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nscaling the matrix A symmetrically.", "response": "def symmetric_rescaling(A, copy=True):\n    \"\"\"Scale the matrix symmetrically.\n\n        A = D^{-1/2} A D^{-1/2}\n\n    where D=diag(A).\n\n    The left multiplication is accomplished through scale_rows and the right\n    multiplication is done through scale columns.\n\n    Parameters\n    ----------\n    A : sparse matrix\n        Sparse matrix with N rows\n    copy : {True,False}\n        - If copy=True, then the matrix is copied to a new and different return\n          matrix (e.g. B=symmetric_rescaling(A))\n        - If copy=False, then the matrix is overwritten deeply (e.g.\n          symmetric_rescaling(A,copy=False) overwrites A)\n\n    Returns\n    -------\n    D_sqrt : array\n        Array of sqrt(diag(A))\n    D_sqrt_inv : array\n        Array of 1/sqrt(diag(A))\n    DAD    : csr_matrix\n        Symmetrically scaled A\n\n    Notes\n    -----\n    - if A is not csr, it is converted to csr and sent to scale_rows\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from scipy.sparse import spdiags\n    >>> from pyamg.util.utils import symmetric_rescaling\n    >>> n=5\n    >>> e = np.ones((n,1)).ravel()\n    >>> data = [ -1*e, 2*e, -1*e ]\n    >>> A = spdiags(data,[-1,0,1],n,n).tocsr()\n    >>> Ds, Dsi, DAD = symmetric_rescaling(A)\n    >>> print DAD.todense()\n    [[ 1.  -0.5  0.   0.   0. ]\n     [-0.5  1.  -0.5  0.   0. ]\n     [ 0.  -0.5  1.  -0.5  0. ]\n     [ 0.   0.  -0.5  1.  -0.5]\n     [ 0.   0.   0.  -0.5  1. ]]\n\n    \"\"\"\n    if isspmatrix_csr(A) or isspmatrix_csc(A) or isspmatrix_bsr(A):\n        if A.shape[0] != A.shape[1]:\n            raise ValueError('expected square matrix')\n\n        D = diag_sparse(A)\n        mask = (D != 0)\n\n        if A.dtype != complex:\n            D_sqrt = np.sqrt(abs(D))\n        else:\n            # We can take square roots of negative numbers\n            D_sqrt = np.sqrt(D)\n\n        D_sqrt_inv = np.zeros_like(D_sqrt)\n        D_sqrt_inv[mask] = 1.0/D_sqrt[mask]\n\n        DAD = scale_rows(A, D_sqrt_inv, copy=copy)\n        DAD = scale_columns(DAD, D_sqrt_inv, copy=False)\n\n        return D_sqrt, D_sqrt_inv, DAD\n\n    else:\n        return symmetric_rescaling(csr_matrix(A))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nscales the matrix symmetrically.", "response": "def symmetric_rescaling_sa(A, B, BH=None):\n    \"\"\"Scale the matrix symmetrically.\n\n        A = D^{-1/2} A D^{-1/2}\n\n    where D=diag(A).  The left multiplication is accomplished through\n    scale_rows and the right multiplication is done through scale columns.\n\n    The candidates B and BH are scaled accordingly::\n\n        B = D^{1/2} B\n        BH = D^{1/2} BH\n\n    Parameters\n    ----------\n    A : {sparse matrix}\n        Sparse matrix with N rows\n    B : {array}\n        N x m array\n    BH : {None, array}\n        If A.symmetry == 'nonsymmetric, then BH must be an N x m array.\n        Otherwise, BH is ignored.\n\n    Returns\n    -------\n    Appropriately scaled A, B and BH, i.e.,\n    A = D^{-1/2} A D^{-1/2},  B = D^{1/2} B,  and BH = D^{1/2} BH\n\n    Notes\n    -----\n    - if A is not csr, it is converted to csr and sent to scale_rows\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from scipy.sparse import spdiags\n    >>> from pyamg.util.utils import symmetric_rescaling_sa\n    >>> n=5\n    >>> e = np.ones((n,1)).ravel()\n    >>> data = [ -1*e, 2*e, -1*e ]\n    >>> A = spdiags(data,[-1,0,1],n,n).tocsr()\n    >>> B = e.copy().reshape(-1,1)\n    >>> [DAD, DB, DBH] = symmetric_rescaling_sa(A,B,BH=None)\n    >>> print DAD.todense()\n    [[ 1.  -0.5  0.   0.   0. ]\n     [-0.5  1.  -0.5  0.   0. ]\n     [ 0.  -0.5  1.  -0.5  0. ]\n     [ 0.   0.  -0.5  1.  -0.5]\n     [ 0.   0.   0.  -0.5  1. ]]\n    >>> print DB\n    [[ 1.41421356]\n     [ 1.41421356]\n     [ 1.41421356]\n     [ 1.41421356]\n     [ 1.41421356]]\n\n    \"\"\"\n    # rescale A\n    [D_sqrt, D_sqrt_inv, A] = symmetric_rescaling(A, copy=False)\n    # scale candidates\n    for i in range(B.shape[1]):\n        B[:, i] = np.ravel(B[:, i])*np.ravel(D_sqrt)\n\n    if hasattr(A, 'symmetry'):\n        if A.symmetry == 'nonsymmetric':\n            if BH is None:\n                raise ValueError(\"BH should be an n x m array\")\n            else:\n                for i in range(BH.shape[1]):\n                    BH[:, i] = np.ravel(BH[:, i])*np.ravel(D_sqrt)\n\n    return [A, B, BH]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts all elements of varlist to upcast_type.", "response": "def to_type(upcast_type, varlist):\n    \"\"\"Loop over all elements of varlist and convert them to upcasttype.\n\n    Parameters\n    ----------\n    upcast_type : data type\n        e.g. complex, float64 or complex128\n    varlist : list\n        list may contain arrays, mat's, sparse matrices, or scalars\n        the elements may be float, int or complex\n\n    Returns\n    -------\n    Returns upcast-ed varlist to upcast_type\n\n    Notes\n    -----\n    Useful when harmonizing the types of variables, such as\n    if A and b are complex, but x,y and z are not.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from pyamg.util.utils import to_type\n    >>> from scipy.sparse.sputils import upcast\n    >>> x = np.ones((5,1))\n    >>> y = 2.0j*np.ones((5,1))\n    >>> varlist = to_type(upcast(x.dtype, y.dtype), [x, y])\n\n    \"\"\"\n    # convert_type = type(np.array([0], upcast_type)[0])\n\n    for i in range(len(varlist)):\n\n        # convert scalars to complex\n        if np.isscalar(varlist[i]):\n            varlist[i] = np.array([varlist[i]], upcast_type)[0]\n        else:\n            # convert sparse and dense mats to complex\n            try:\n                if varlist[i].dtype != upcast_type:\n                    varlist[i] = varlist[i].astype(upcast_type)\n            except AttributeError:\n                warn('Failed to cast in to_type')\n                pass\n\n    return varlist"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_diagonal(A, norm_eq=False, inv=False):\n    # if not isspmatrix(A):\n    if not (isspmatrix_csr(A) or isspmatrix_csc(A) or isspmatrix_bsr(A)):\n        warn('Implicit conversion to sparse matrix')\n        A = csr_matrix(A)\n\n    # critical to sort the indices of A\n    A.sort_indices()\n    if norm_eq == 1:\n        # This transpose involves almost no work, use csr data structures as\n        # csc, or vice versa\n        At = A.T\n        D = (At.multiply(At.conjugate()))*np.ones((At.shape[0],))\n    elif norm_eq == 2:\n        D = (A.multiply(A.conjugate()))*np.ones((A.shape[0],))\n    else:\n        D = A.diagonal()\n\n    if inv:\n        Dinv = np.zeros_like(D)\n        mask = (D != 0.0)\n        Dinv[mask] = 1.0 / D[mask]\n        return Dinv\n    else:\n        return D", "response": "Returns the diagonal or inverse of diagonal for A."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_block_diag(A, blocksize, inv_flag=True):\n    if not isspmatrix(A):\n        raise TypeError('Expected sparse matrix')\n    if A.shape[0] != A.shape[1]:\n        raise ValueError(\"Expected square matrix\")\n    if sp.mod(A.shape[0], blocksize) != 0:\n        raise ValueError(\"blocksize and A.shape must be compatible\")\n\n    # If the block diagonal of A already exists, return that\n    if hasattr(A, 'block_D_inv') and inv_flag:\n        if (A.block_D_inv.shape[1] == blocksize) and\\\n           (A.block_D_inv.shape[2] == blocksize) and \\\n           (A.block_D_inv.shape[0] == int(A.shape[0]/blocksize)):\n            return A.block_D_inv\n    elif hasattr(A, 'block_D') and (not inv_flag):\n        if (A.block_D.shape[1] == blocksize) and\\\n           (A.block_D.shape[2] == blocksize) and \\\n           (A.block_D.shape[0] == int(A.shape[0]/blocksize)):\n            return A.block_D\n\n    # Convert to BSR\n    if not isspmatrix_bsr(A):\n        A = bsr_matrix(A, blocksize=(blocksize, blocksize))\n    if A.blocksize != (blocksize, blocksize):\n        A = A.tobsr(blocksize=(blocksize, blocksize))\n\n    # Peel off block diagonal by extracting block entries from the now BSR\n    # matrix A\n    A = A.asfptype()\n    block_diag = sp.zeros((int(A.shape[0]/blocksize), blocksize, blocksize),\n                          dtype=A.dtype)\n\n    AAIJ = (sp.arange(1, A.indices.shape[0]+1), A.indices, A.indptr)\n    shape = (int(A.shape[0]/blocksize), int(A.shape[0]/blocksize))\n    diag_entries = csr_matrix(AAIJ, shape=shape).diagonal()\n    diag_entries -= 1\n    nonzero_mask = (diag_entries != -1)\n    diag_entries = diag_entries[nonzero_mask]\n    if diag_entries.shape != (0,):\n        block_diag[nonzero_mask, :, :] = A.data[diag_entries, :, :]\n\n    if inv_flag:\n        # Invert each block\n        if block_diag.shape[1] < 7:\n            # This specialized routine lacks robustness for large matrices\n            pyamg.amg_core.pinv_array(block_diag.ravel(), block_diag.shape[0],\n                                      block_diag.shape[1], 'T')\n        else:\n            pinv_array(block_diag)\n        A.block_D_inv = block_diag\n    else:\n        A.block_D = block_diag\n\n    return block_diag", "response": "Returns the block diagonal of A in array form."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef amalgamate(A, blocksize):\n    if blocksize == 1:\n        return A\n    elif sp.mod(A.shape[0], blocksize) != 0:\n        raise ValueError(\"Incompatible blocksize\")\n\n    A = A.tobsr(blocksize=(blocksize, blocksize))\n    A.sort_indices()\n    subI = (np.ones(A.indices.shape), A.indices, A.indptr)\n    shape = (int(A.shape[0]/A.blocksize[0]),\n             int(A.shape[1]/A.blocksize[1]))\n    return csr_matrix(subI, shape=shape)", "response": "Amalgamate matrix A.\n\n    Parameters\n    ----------\n    A : csr_matrix\n        Matrix to amalgamate\n    blocksize : int\n        blocksize to use while amalgamating\n\n    Returns\n    -------\n    A_amal : csr_matrix\n        Amalgamated  matrix A, first, convert A to BSR with square blocksize\n        and then return a CSR matrix of ones using the resulting BSR indptr and\n        indices\n\n    Notes\n    -----\n    inverse operation of UnAmal for square matrices\n\n    Examples\n    --------\n    >>> from numpy import array\n    >>> from scipy.sparse import csr_matrix\n    >>> from pyamg.util.utils import amalgamate\n    >>> row = array([0,0,1])\n    >>> col = array([0,2,1])\n    >>> data = array([1,2,3])\n    >>> A = csr_matrix( (data,(row,col)), shape=(4,4) )\n    >>> A.todense()\n    matrix([[1, 0, 2, 0],\n            [0, 3, 0, 0],\n            [0, 0, 0, 0],\n            [0, 0, 0, 0]])\n    >>> amalgamate(A,2).todense()\n    matrix([[ 1.,  1.],\n            [ 0.,  0.]])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints a table from a list of lists.", "response": "def print_table(table, title='', delim='|', centering='center', col_padding=2,\n                header=True, headerchar='-'):\n    \"\"\"Print a table from a list of lists representing the rows of a table.\n\n    Parameters\n    ----------\n    table : list\n        list of lists, e.g. a table with 3 columns and 2 rows could be\n        [ ['0,0', '0,1', '0,2'], ['1,0', '1,1', '1,2'] ]\n    title : string\n        Printed centered above the table\n    delim : string\n        character to delimit columns\n    centering : {'left', 'right', 'center'}\n        chooses justification for columns\n    col_padding : int\n        number of blank spaces to add to each column\n    header : {True, False}\n        Does the first entry of table contain column headers?\n    headerchar : {string}\n        character to separate column headers from rest of table\n\n    Returns\n    -------\n    string representing table that's ready to be printed\n\n    Notes\n    -----\n    The string for the table will have correctly justified columns\n    with extra padding added into each column entry to ensure columns align.\n    The characters to delimit the columns can be user defined.  This\n    should be useful for printing convergence data from tests.\n\n\n    Examples\n    --------\n    >>> from pyamg.util.utils import print_table\n    >>> table = [ ['cos(0)', 'cos(pi/2)', 'cos(pi)'], ['0.0', '1.0', '0.0'] ]\n    >>> table1 = print_table(table)                 # string to print\n    >>> table2 = print_table(table, delim='||')\n    >>> table3 = print_table(table, headerchar='*')\n    >>> table4 = print_table(table, col_padding=6, centering='left')\n\n    \"\"\"\n    table_str = '\\n'\n\n    # sometimes, the table will be passed in as (title, table)\n    if isinstance(table, tuple):\n        title = table[0]\n        table = table[1]\n\n    # Calculate each column's width\n    colwidths = []\n    for i in range(len(table)):\n        # extend colwidths for row i\n        for k in range(len(table[i]) - len(colwidths)):\n            colwidths.append(-1)\n\n        # Update colwidths if table[i][j] is wider than colwidth[j]\n        for j in range(len(table[i])):\n            if len(table[i][j]) > colwidths[j]:\n                colwidths[j] = len(table[i][j])\n\n    # Factor in extra column padding\n    for i in range(len(colwidths)):\n        colwidths[i] += col_padding\n\n    # Total table width\n    ttwidth = sum(colwidths) + len(delim)*(len(colwidths)-1)\n\n    # Print Title\n    if len(title) > 0:\n        title = title.split(\"\\n\")\n        for i in range(len(title)):\n            table_str += str.center(title[i], ttwidth) + '\\n'\n        table_str += \"\\n\"\n\n    # Choose centering scheme\n    centering = centering.lower()\n    if centering == 'center':\n        centering = str.center\n    if centering == 'right':\n        centering = str.rjust\n    if centering == 'left':\n        centering = str.ljust\n\n    if header:\n        # Append Column Headers\n        for elmt, elmtwidth in zip(table[0], colwidths):\n            table_str += centering(str(elmt), elmtwidth) + delim\n        if table[0] != []:\n            table_str = table_str[:-len(delim)] + '\\n'\n\n        # Append Header Separator\n        #              Total Column Width            Total Col Delimiter Widths\n        if len(headerchar) == 0:\n            headerchar = ' '\n        table_str += headerchar *\\\n            int(sp.ceil(float(ttwidth)/float(len(headerchar)))) + '\\n'\n\n        table = table[1:]\n\n    for row in table:\n        for elmt, elmtwidth in zip(row, colwidths):\n            table_str += centering(str(elmt), elmtwidth) + delim\n        if row != []:\n            table_str = table_str[:-len(delim)] + '\\n'\n        else:\n            table_str += '\\n'\n\n    return table_str"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexamine a multilevel hierarchy s spectrum.", "response": "def hierarchy_spectrum(mg, filter=True, plot=False):\n    \"\"\"Examine a multilevel hierarchy's spectrum.\n\n    Parameters\n    ----------\n    mg { pyamg multilevel hierarchy }\n        e.g. generated with smoothed_aggregation_solver(...) or\n        ruge_stuben_solver(...)\n\n    Returns\n    -------\n    (1) table to standard out detailing the spectrum of each level in mg\n    (2) if plot==True, a sequence of plots in the complex plane of the\n        spectrum at each level\n\n    Notes\n    -----\n    This can be useful for troubleshooting and when examining how your\n    problem's nature changes from level to level\n\n    Examples\n    --------\n    >>> from pyamg import smoothed_aggregation_solver\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.util.utils import hierarchy_spectrum\n    >>> A = poisson( (1,), format='csr' )\n    >>> ml = smoothed_aggregation_solver(A)\n    >>> hierarchy_spectrum(ml)\n    <BLANKLINE>\n     Level min(re(eig)) max(re(eig)) num re(eig) < 0 num re(eig) > 0 cond_2(A)\n    ---------------------------------------------------------------------------\n       0      2.000        2.000            0               1         1.00e+00\n    <BLANKLINE>\n    <BLANKLINE>\n     Level min(im(eig)) max(im(eig)) num im(eig) < 0 num im(eig) > 0 cond_2(A)\n    ---------------------------------------------------------------------------\n       0      0.000        0.000            0               0         1.00e+00\n    <BLANKLINE>\n\n    \"\"\"\n    real_table = [['Level', 'min(re(eig))', 'max(re(eig))', 'num re(eig) < 0',\n                   'num re(eig) > 0', 'cond_2(A)']]\n    imag_table = [['Level', 'min(im(eig))', 'max(im(eig))', 'num im(eig) < 0',\n                   'num im(eig) > 0', 'cond_2(A)']]\n\n    for i in range(len(mg.levels)):\n        A = mg.levels[i].A.tocsr()\n\n        if filter is True:\n            # Filter out any zero rows and columns of A\n            A.eliminate_zeros()\n            nnz_per_row = A.indptr[0:-1] - A.indptr[1:]\n            nonzero_rows = (nnz_per_row != 0).nonzero()[0]\n            A = A.tocsc()\n            nnz_per_col = A.indptr[0:-1] - A.indptr[1:]\n            nonzero_cols = (nnz_per_col != 0).nonzero()[0]\n            nonzero_rowcols = sp.union1d(nonzero_rows, nonzero_cols)\n            A = np.mat(A.todense())\n            A = A[nonzero_rowcols, :][:, nonzero_rowcols]\n        else:\n            A = np.mat(A.todense())\n\n        e = eigvals(A)\n        c = cond(A)\n        lambda_min = min(sp.real(e))\n        lambda_max = max(sp.real(e))\n        num_neg = max(e[sp.real(e) < 0.0].shape)\n        num_pos = max(e[sp.real(e) > 0.0].shape)\n        real_table.append([str(i), ('%1.3f' % lambda_min),\n                           ('%1.3f' % lambda_max),\n                           str(num_neg), str(num_pos), ('%1.2e' % c)])\n\n        lambda_min = min(sp.imag(e))\n        lambda_max = max(sp.imag(e))\n        num_neg = max(e[sp.imag(e) < 0.0].shape)\n        num_pos = max(e[sp.imag(e) > 0.0].shape)\n        imag_table.append([str(i), ('%1.3f' % lambda_min),\n                           ('%1.3f' % lambda_max),\n                           str(num_neg), str(num_pos), ('%1.2e' % c)])\n\n        if plot:\n            import pylab\n            pylab.figure(i+1)\n            pylab.plot(sp.real(e), sp.imag(e), 'kx')\n            handle = pylab.title('Level %d Spectrum' % i)\n            handle.set_fontsize(19)\n            handle = pylab.xlabel('real(eig)')\n            handle.set_fontsize(17)\n            handle = pylab.ylabel('imag(eig)')\n            handle.set_fontsize(17)\n\n    print(print_table(real_table))\n    print(print_table(imag_table))\n\n    if plot:\n        pylab.show()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts 2D or 3D coordinates into Rigid body modes.", "response": "def Coord2RBM(numNodes, numPDEs, x, y, z):\n    \"\"\"Convert 2D or 3D coordinates into Rigid body modes.\n\n    For use as near nullspace modes in elasticity AMG solvers.\n\n    Parameters\n    ----------\n    numNodes : int\n        Number of nodes\n    numPDEs :\n        Number of dofs per node\n    x,y,z : array_like\n        Coordinate vectors\n\n    Returns\n    -------\n    rbm : matrix\n        A matrix of size (numNodes*numPDEs) x (1 | 6) containing the 6 rigid\n        body modes\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from pyamg.util.utils import Coord2RBM\n    >>> a = np.array([0,1,2])\n    >>> Coord2RBM(3,6,a,a,a)\n    matrix([[ 1.,  0.,  0.,  0.,  0., -0.],\n            [ 0.,  1.,  0., -0.,  0.,  0.],\n            [ 0.,  0.,  1.,  0., -0.,  0.],\n            [ 0.,  0.,  0.,  1.,  0.,  0.],\n            [ 0.,  0.,  0.,  0.,  1.,  0.],\n            [ 0.,  0.,  0.,  0.,  0.,  1.],\n            [ 1.,  0.,  0.,  0.,  1., -1.],\n            [ 0.,  1.,  0., -1.,  0.,  1.],\n            [ 0.,  0.,  1.,  1., -1.,  0.],\n            [ 0.,  0.,  0.,  1.,  0.,  0.],\n            [ 0.,  0.,  0.,  0.,  1.,  0.],\n            [ 0.,  0.,  0.,  0.,  0.,  1.],\n            [ 1.,  0.,  0.,  0.,  2., -2.],\n            [ 0.,  1.,  0., -2.,  0.,  2.],\n            [ 0.,  0.,  1.,  2., -2.,  0.],\n            [ 0.,  0.,  0.,  1.,  0.,  0.],\n            [ 0.,  0.,  0.,  0.,  1.,  0.],\n            [ 0.,  0.,  0.,  0.,  0.,  1.]])\n\n    \"\"\"\n    # check inputs\n    if(numPDEs == 1):\n        numcols = 1\n    elif((numPDEs == 3) or (numPDEs == 6)):\n        numcols = 6\n    else:\n        raise ValueError(\"Coord2RBM(...) only supports 1, 3 or 6 PDEs per\\\n                          spatial location,i.e. numPDEs = [1 | 3 | 6].\\\n                          You've entered \" + str(numPDEs) + \".\")\n\n    if((max(x.shape) != numNodes) or\n       (max(y.shape) != numNodes) or\n       (max(z.shape) != numNodes)):\n        raise ValueError(\"Coord2RBM(...) requires coordinate vectors of equal\\\n                          length.  Length must be numNodes = \" + str(numNodes))\n\n    # if( (min(x.shape) != 1) or (min(y.shape) != 1) or (min(z.shape) != 1) ):\n    #    raise ValueError(\"Coord2RBM(...) requires coordinate vectors that are\n    #    (numNodes x 1) or (1 x numNodes).\")\n\n    # preallocate rbm\n    rbm = np.mat(np.zeros((numNodes*numPDEs, numcols)))\n\n    for node in range(numNodes):\n        dof = node*numPDEs\n\n        if(numPDEs == 1):\n            rbm[node] = 1.0\n\n        if(numPDEs == 6):\n            for ii in range(3, 6):  # lower half = [ 0 I ]\n                for jj in range(0, 6):\n                    if(ii == jj):\n                        rbm[dof+ii, jj] = 1.0\n                    else:\n                        rbm[dof+ii, jj] = 0.0\n\n        if((numPDEs == 3) or (numPDEs == 6)):\n            for ii in range(0, 3):  # upper left = [ I ]\n                for jj in range(0, 3):\n                    if(ii == jj):\n                        rbm[dof+ii, jj] = 1.0\n                    else:\n                        rbm[dof+ii, jj] = 0.0\n\n            for ii in range(0, 3):  # upper right = [ Q ]\n                for jj in range(3, 6):\n                    if(ii == (jj-3)):\n                        rbm[dof+ii, jj] = 0.0\n                    else:\n                        if((ii+jj) == 4):\n                            rbm[dof+ii, jj] = z[node]\n                        elif((ii+jj) == 5):\n                            rbm[dof+ii, jj] = y[node]\n                        elif((ii+jj) == 6):\n                            rbm[dof+ii, jj] = x[node]\n                        else:\n                            rbm[dof+ii, jj] = 0.0\n\n            ii = 0\n            jj = 5\n            rbm[dof+ii, jj] *= -1.0\n\n            ii = 1\n            jj = 3\n            rbm[dof+ii, jj] *= -1.0\n\n            ii = 2\n            jj = 4\n            rbm[dof+ii, jj] *= -1.0\n\n    return rbm"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef relaxation_as_linear_operator(method, A, b):\n    from pyamg import relaxation\n    from scipy.sparse.linalg.interface import LinearOperator\n    import pyamg.multilevel\n\n    def unpack_arg(v):\n        if isinstance(v, tuple):\n            return v[0], v[1]\n        else:\n            return v, {}\n\n    # setup variables\n    accepted_methods = ['gauss_seidel', 'block_gauss_seidel', 'sor',\n                        'gauss_seidel_ne', 'gauss_seidel_nr', 'jacobi',\n                        'block_jacobi', 'richardson', 'schwarz',\n                        'strength_based_schwarz', 'jacobi_ne']\n\n    b = np.array(b, dtype=A.dtype)\n    fn, kwargs = unpack_arg(method)\n    lvl = pyamg.multilevel_solver.level()\n    lvl.A = A\n\n    # Retrieve setup call from relaxation.smoothing for this relaxation method\n    if not accepted_methods.__contains__(fn):\n        raise NameError(\"invalid relaxation method: \", fn)\n    try:\n        setup_smoother = getattr(relaxation.smoothing, 'setup_' + fn)\n    except NameError:\n        raise NameError(\"invalid presmoother method: \", fn)\n    # Get relaxation routine that takes only (A, x, b) as parameters\n    relax = setup_smoother(lvl, **kwargs)\n\n    # Define matvec\n    def matvec(x):\n        xcopy = x.copy()\n        relax(A, xcopy, b)\n        return xcopy\n\n    return LinearOperator(A.shape, matvec, dtype=A.dtype)", "response": "Create a linear operator that applies a relaxation method to the given vector A and b."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter_operator(A, C, B, Bf, BtBinv=None):\n    # First preprocess the parameters\n    Nfine = A.shape[0]\n    if A.shape[0] != C.shape[0]:\n        raise ValueError('A and C must be the same size')\n    if A.shape[1] != C.shape[1]:\n        raise ValueError('A and C must be the same size')\n\n    if isspmatrix_bsr(C):\n        isBSR = True\n        ColsPerBlock = C.blocksize[1]\n        RowsPerBlock = C.blocksize[0]\n        Nnodes = int(Nfine/RowsPerBlock)\n        if not isspmatrix_bsr(A):\n            raise ValueError('A and C must either both be CSR or BSR')\n        elif (ColsPerBlock != A.blocksize[1]) or\\\n             (RowsPerBlock != A.blocksize[0]):\n            raise ValueError('A and C must have same BSR blocksizes')\n    elif isspmatrix_csr(C):\n        isBSR = False\n        ColsPerBlock = 1\n        RowsPerBlock = 1\n        Nnodes = int(Nfine/RowsPerBlock)\n        if not isspmatrix_csr(A):\n            raise ValueError('A and C must either both be CSR or BSR')\n    else:\n        raise ValueError('A and C must either both be CSR or BSR')\n\n    if len(Bf.shape) == 1:\n        Bf = Bf.reshape(-1, 1)\n    if Bf.shape[0] != A.shape[0]:\n        raise ValueError('A and Bf must have the same first dimension')\n\n    if len(B.shape) == 1:\n        B = B.reshape(-1, 1)\n    if B.shape[0] != A.shape[1]:\n        raise ValueError('A and B must have matching dimensions such\\\n                          that A*B is computable')\n\n    if B.shape[1] != Bf.shape[1]:\n        raise ValueError('B and Bf must have the same second\\\n                          dimension')\n    else:\n        NullDim = B.shape[1]\n\n    if A.dtype == int:\n        A.data = np.array(A.data, dtype=float)\n    if B.dtype == int:\n        B.data = np.array(B.data, dtype=float)\n    if Bf.dtype == int:\n        Bf.data = np.array(Bf.data, dtype=float)\n    if (A.dtype != B.dtype) or (A.dtype != Bf.dtype):\n        raise TypeError('A, B and Bf must of the same dtype')\n\n    # First, preprocess some values for filtering.  Construct array of\n    # inv(Bi'Bi), where Bi is B restricted to row i's sparsity pattern in\n    # C. This array is used multiple times in Satisfy_Constraints(...).\n    if BtBinv is None:\n        BtBinv = compute_BtBinv(B, C)\n\n    # Filter A according to C's matrix graph\n    C = C.copy()\n    C.data[:] = 1\n    A = A.multiply(C)\n    # add explicit zeros to A wherever C is nonzero, but A is zero\n    A = A.tocoo()\n    C = C.tocoo()\n    A.data = np.hstack((np.zeros(C.data.shape, dtype=A.dtype), A.data))\n    A.row = np.hstack((C.row, A.row))\n    A.col = np.hstack((C.col, A.col))\n    if isBSR:\n        A = A.tobsr((RowsPerBlock, ColsPerBlock))\n    else:\n        A = A.tocsr()\n\n    # Calculate difference between A*B and Bf\n    diff = A*B - Bf\n\n    # Right multiply each row i of A with\n    # A_i <--- A_i - diff_i*inv(B_i.T B_i)*Bi.T\n    # where A_i, and diff_i denote restriction to just row i, and B_i denotes\n    # restriction to multiple rows corresponding to the the allowed nz's for\n    # row i in A_i.  A_i also represents just the nonzeros for row i.\n    pyamg.amg_core.satisfy_constraints_helper(RowsPerBlock, ColsPerBlock,\n                                              Nnodes, NullDim,\n                                              np.conjugate(np.ravel(B)),\n                                              np.ravel(diff),\n                                              np.ravel(BtBinv), A.indptr,\n                                              A.indices, np.ravel(A.data))\n\n    A.eliminate_zeros()\n    return A", "response": "Filter the matrix A according to the matrix graph C B and Bf."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scale_T(T, P_I, I_F):\n    if not isspmatrix_bsr(T):\n        raise TypeError('Expected BSR matrix T')\n    elif T.blocksize[0] != T.blocksize[1]:\n        raise TypeError('Expected BSR matrix T with square blocks')\n    if not isspmatrix_bsr(P_I):\n        raise TypeError('Expected BSR matrix P_I')\n    elif P_I.blocksize[0] != P_I.blocksize[1]:\n        raise TypeError('Expected BSR matrix P_I with square blocks')\n    if not isspmatrix_bsr(I_F):\n        raise TypeError('Expected BSR matrix I_F')\n    elif I_F.blocksize[0] != I_F.blocksize[1]:\n        raise TypeError('Expected BSR matrix I_F with square blocks')\n    if (I_F.blocksize[0] != P_I.blocksize[0]) or\\\n       (I_F.blocksize[0] != T.blocksize[0]):\n        raise TypeError('Expected identical blocksize in I_F, P_I and T')\n\n    # Only do if we have a non-trivial coarse-grid\n    if P_I.nnz > 0:\n        # Construct block diagonal inverse D\n        D = P_I.T*T\n        if D.nnz > 0:\n            # changes D in place\n            pinv_array(D.data)\n\n        # Scale T to be identity at root-nodes\n        T = T*D\n\n        # Ensure coarse-grid injection\n        T = I_F*T + P_I\n\n    return T", "response": "Scale T with a right multiplication by a block diagonal matrix."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_Cpt_params(A, Cnodes, AggOp, T):\n    if not isspmatrix_bsr(A) and not isspmatrix_csr(A):\n        raise TypeError('Expected BSR or CSR matrix A')\n    if not isspmatrix_csr(AggOp):\n        raise TypeError('Expected CSR matrix AggOp')\n    if not isspmatrix_bsr(T):\n        raise TypeError('Expected BSR matrix T')\n    if T.blocksize[0] != T.blocksize[1]:\n        raise TypeError('Expected square blocksize for BSR matrix T')\n    if A.shape[0] != A.shape[1]:\n        raise TypeError('Expected square matrix A')\n    if T.shape[0] != A.shape[0]:\n        raise TypeError('Expected compatible dimensions for T and A,\\\n                         T.shape[0] = A.shape[0]')\n    if Cnodes.shape[0] != AggOp.shape[1]:\n        if AggOp.shape[1] > 1:\n            raise TypeError('Number of columns in AggOp must equal number\\\n                             of Cnodes')\n\n    if isspmatrix_bsr(A) and A.blocksize[0] > 1:\n        # Expand the list of Cpt nodes to a list of Cpt dofs\n        blocksize = A.blocksize[0]\n        Cpts = np.repeat(blocksize*Cnodes, blocksize)\n        for k in range(1, blocksize):\n            Cpts[list(range(k, Cpts.shape[0], blocksize))] += k\n    else:\n        blocksize = 1\n        Cpts = Cnodes\n    Cpts = np.array(Cpts, dtype=int)\n\n    # More input checking\n    if Cpts.shape[0] != T.shape[1]:\n        if T.shape[1] > blocksize:\n            raise ValueError('Expected number of Cpts to match T.shape[1]')\n    if blocksize != T.blocksize[0]:\n        raise ValueError('Expected identical blocksize in A and T')\n    if AggOp.shape[0] != int(T.shape[0]/blocksize):\n        raise ValueError('Number of rows in AggOp must equal number of\\\n                          fine-grid nodes')\n\n    # Create two maps, one for F points and one for C points\n    ncoarse = T.shape[1]\n    I_C = eye(A.shape[0], A.shape[1], format='csr')\n    I_F = I_C.copy()\n    I_F.data[Cpts] = 0.0\n    I_F.eliminate_zeros()\n    I_C = I_C - I_F\n    I_C.eliminate_zeros()\n\n    # Find Fpts, the complement of Cpts\n    Fpts = I_F.indices.copy()\n\n    # P_I only injects from Cpts on the coarse grid to the fine grid, but\n    # because of it's later uses, it must have the CSC indices ordered as\n    # in Cpts\n    if I_C.nnz > 0:\n        indices = Cpts.copy()\n        indptr = np.arange(indices.shape[0]+1)\n    else:\n        indices = np.zeros((0,), dtype=T.indices.dtype)\n        indptr = np.zeros((ncoarse+1,), dtype=T.indptr.dtype)\n\n    P_I = csc_matrix((I_C.data.copy(), indices, indptr),\n                     shape=(I_C.shape[0], ncoarse))\n    P_I = P_I.tobsr(T.blocksize)\n\n    # Use same blocksize as A\n    if isspmatrix_bsr(A):\n        I_C = I_C.tobsr(A.blocksize)\n        I_F = I_F.tobsr(A.blocksize)\n    else:\n        I_C = I_C.tobsr(blocksize=(1, 1))\n        I_F = I_F.tobsr(blocksize=(1, 1))\n\n    return {'P_I': P_I, 'I_F': I_F, 'I_C': I_C, 'Cpts': Cpts, 'Fpts': Fpts}", "response": "Returns the parameters of the get_Cpt_params function for the base class of the base class."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates block inverses for a non - null space grid.", "response": "def compute_BtBinv(B, C):\n    \"\"\"Create block inverses.\n\n    Helper function that creates inv(B_i.T B_i) for each block row i in C,\n    where B_i is B restricted to the sparsity pattern of block row i.\n\n    Parameters\n    ----------\n    B : {array}\n        (M,k) array, typically near-nullspace modes for coarse grid, i.e., B_c.\n    C : {csr_matrix, bsr_matrix}\n        Sparse NxM matrix, whose sparsity structure (i.e., matrix graph)\n        is used to determine BtBinv.\n\n    Returns\n    -------\n    BtBinv : {array}\n        BtBinv[i] = inv(B_i.T B_i), where B_i is B restricted to the nonzero\n        pattern of block row i in C.\n\n    Examples\n    --------\n    >>> from numpy import array\n    >>> from scipy.sparse import bsr_matrix\n    >>> from pyamg.util.utils import compute_BtBinv\n    >>> T = array([[ 1.,  0.],\n    ...            [ 1.,  0.],\n    ...            [ 0.,  .5],\n    ...            [ 0.,  .25]])\n    >>> T = bsr_matrix(T)\n    >>> B = array([[1.],[2.]])\n    >>> compute_BtBinv(B, T)\n    array([[[ 1.  ]],\n    <BLANKLINE>\n           [[ 1.  ]],\n    <BLANKLINE>\n           [[ 0.25]],\n    <BLANKLINE>\n           [[ 0.25]]])\n\n    Notes\n    -----\n    The principal calling routines are\n    aggregation.smooth.energy_prolongation_smoother, and\n    util.utils.filter_operator.\n\n    BtBinv is used in the prolongation smoothing process that incorporates B\n    into the span of prolongation with row-wise projection operators.  It is\n    these projection operators that BtBinv is part of.\n\n    \"\"\"\n    if not isspmatrix_bsr(C) and not isspmatrix_csr(C):\n        raise TypeError('Expected bsr_matrix or csr_matrix for C')\n    if C.shape[1] != B.shape[0]:\n        raise TypeError('Expected matching dimensions such that C*B')\n\n    # Problem parameters\n    if isspmatrix_bsr(C):\n        ColsPerBlock = C.blocksize[1]\n        RowsPerBlock = C.blocksize[0]\n    else:\n        ColsPerBlock = 1\n        RowsPerBlock = 1\n    Ncoarse = C.shape[1]\n    Nfine = C.shape[0]\n    NullDim = B.shape[1]\n    Nnodes = int(Nfine/RowsPerBlock)\n\n    # Construct BtB\n    BtBinv = np.zeros((Nnodes, NullDim, NullDim), dtype=B.dtype)\n    BsqCols = sum(range(NullDim+1))\n    Bsq = np.zeros((Ncoarse, BsqCols), dtype=B.dtype)\n    counter = 0\n    for i in range(NullDim):\n        for j in range(i, NullDim):\n            Bsq[:, counter] = np.conjugate(np.ravel(np.asarray(B[:, i]))) * \\\n                np.ravel(np.asarray(B[:, j]))\n            counter = counter + 1\n    # This specialized C-routine calculates (B.T B) for each row using Bsq\n    pyamg.amg_core.calc_BtB(NullDim, Nnodes, ColsPerBlock,\n                            np.ravel(np.asarray(Bsq)),\n                            BsqCols, np.ravel(np.asarray(BtBinv)),\n                            C.indptr, C.indices)\n\n    # Invert each block of BtBinv, noting that amg_core.calc_BtB(...) returns\n    # values in column-major form, thus necessitating the deep transpose\n    #   This is the old call to a specialized routine, but lacks robustness\n    #   pyamg.amg_core.pinv_array(np.ravel(BtBinv), Nnodes, NullDim, 'F')\n    BtBinv = BtBinv.transpose((0, 2, 1)).copy()\n    pinv_array(BtBinv)\n\n    return BtBinv"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove the diagonal of the matrix S.", "response": "def remove_diagonal(S):\n    \"\"\"Remove the diagonal of the matrix S.\n\n    Parameters\n    ----------\n    S : csr_matrix\n        Square matrix\n\n    Returns\n    -------\n    S : csr_matrix\n        Strength matrix with the diagonal removed\n\n    Notes\n    -----\n    This is needed by all the splitting routines which operate on matrix graphs\n    with an assumed zero diagonal\n\n\n    Examples\n    --------\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.util.utils import remove_diagonal\n    >>> A = poisson( (4,), format='csr' )\n    >>> C = remove_diagonal(A)\n    >>> C.todense()\n    matrix([[ 0., -1.,  0.,  0.],\n            [-1.,  0., -1.,  0.],\n            [ 0., -1.,  0., -1.],\n            [ 0.,  0., -1.,  0.]])\n\n    \"\"\"\n    if not isspmatrix_csr(S):\n        raise TypeError('expected csr_matrix')\n\n    if S.shape[0] != S.shape[1]:\n        raise ValueError('expected square matrix, shape=%s' % (S.shape,))\n\n    S = coo_matrix(S)\n    mask = S.row != S.col\n    S.row = S.row[mask]\n    S.col = S.col[mask]\n    S.data = S.data[mask]\n\n    return S.tocsr()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nscale each row in S by its largest in magnitude entry.", "response": "def scale_rows_by_largest_entry(S):\n    \"\"\"Scale each row in S by it's largest in magnitude entry.\n\n    Parameters\n    ----------\n    S : csr_matrix\n\n    Returns\n    -------\n    S : csr_matrix\n        Each row has been scaled by it's largest in magnitude entry\n\n    Examples\n    --------\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.util.utils import scale_rows_by_largest_entry\n    >>> A = poisson( (4,), format='csr' )\n    >>> A.data[1] = 5.0\n    >>> A = scale_rows_by_largest_entry(A)\n    >>> A.todense()\n    matrix([[ 0.4,  1. ,  0. ,  0. ],\n            [-0.5,  1. , -0.5,  0. ],\n            [ 0. , -0.5,  1. , -0.5],\n            [ 0. ,  0. , -0.5,  1. ]])\n\n    \"\"\"\n    if not isspmatrix_csr(S):\n        raise TypeError('expected csr_matrix')\n\n    # Scale S by the largest magnitude entry in each row\n    largest_row_entry = np.zeros((S.shape[0],), dtype=S.dtype)\n    pyamg.amg_core.maximum_row_value(S.shape[0], largest_row_entry,\n                                     S.indptr, S.indices, S.data)\n\n    largest_row_entry[largest_row_entry != 0] =\\\n        1.0 / largest_row_entry[largest_row_entry != 0]\n    S = scale_rows(S, largest_row_entry, copy=True)\n\n    return S"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nturn parameter into a list per level.", "response": "def levelize_strength_or_aggregation(to_levelize, max_levels, max_coarse):\n    \"\"\"Turn parameter into a list per level.\n\n    Helper function to preprocess the strength and aggregation parameters\n    passed to smoothed_aggregation_solver and rootnode_solver.\n\n    Parameters\n    ----------\n    to_levelize : {string, tuple, list}\n        Parameter to preprocess, i.e., levelize and convert to a level-by-level\n        list such that entry i specifies the parameter at level i\n    max_levels : int\n        Defines the maximum number of levels considered\n    max_coarse : int\n        Defines the maximum coarse grid size allowed\n\n    Returns\n    -------\n    (max_levels, max_coarse, to_levelize) : tuple\n        New max_levels and max_coarse values and then the parameter list\n        to_levelize, such that entry i specifies the parameter choice at level\n        i.  max_levels and max_coarse are returned, because they may be updated\n        if strength or aggregation set a predefined coarsening and possibly\n        change these values.\n\n    Notes\n    --------\n    This routine is needed because the user will pass in a parameter option\n    such as smooth='jacobi', or smooth=['jacobi', None], and this option must\n    be \"levelized\", or converted to a list of length max_levels such that entry\n    [i] in that list is the parameter choice for level i.\n\n    The parameter choice in to_levelize can be a string, tuple or list.  If\n    it is a string or tuple, then that option is assumed to be the\n    parameter setting at every level.  If to_levelize is inititally a list,\n    if the length of the list is less than max_levels, the last entry in the\n    list defines that parameter for all subsequent levels.\n\n\n    Examples\n    --------\n    >>> from pyamg.util.utils import levelize_strength_or_aggregation\n    >>> strength = ['evolution', 'classical']\n    >>> levelize_strength_or_aggregation(strength, 4, 10)\n    (4, 10, ['evolution', 'classical', 'classical'])\n\n    \"\"\"\n    if isinstance(to_levelize, tuple):\n        if to_levelize[0] == 'predefined':\n            to_levelize = [to_levelize]\n            max_levels = 2\n            max_coarse = 0\n        else:\n            to_levelize = [to_levelize for i in range(max_levels-1)]\n\n    elif isinstance(to_levelize, str):\n        if to_levelize == 'predefined':\n            raise ValueError('predefined to_levelize requires a user-provided\\\n                              CSR matrix representing strength or aggregation\\\n                              i.e., (\\'predefined\\', {\\'C\\' : CSR_MAT}).')\n        else:\n            to_levelize = [to_levelize for i in range(max_levels-1)]\n\n    elif isinstance(to_levelize, list):\n        if isinstance(to_levelize[-1], tuple) and\\\n           (to_levelize[-1][0] == 'predefined'):\n            # to_levelize is a list that ends with a predefined operator\n            max_levels = len(to_levelize) + 1\n            max_coarse = 0\n        else:\n            # to_levelize a list that __doesn't__ end with 'predefined'\n            if len(to_levelize) < max_levels-1:\n                mlz = max_levels - 1 - len(to_levelize)\n                toext = [to_levelize[-1] for i in range(mlz)]\n                to_levelize.extend(toext)\n\n    elif to_levelize is None:\n        to_levelize = [(None, {}) for i in range(max_levels-1)]\n    else:\n        raise ValueError('invalid to_levelize')\n\n    return max_levels, max_coarse, to_levelize"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef levelize_smooth_or_improve_candidates(to_levelize, max_levels):\n    if isinstance(to_levelize, tuple) or isinstance(to_levelize, str):\n        to_levelize = [to_levelize for i in range(max_levels)]\n    elif isinstance(to_levelize, list):\n        if len(to_levelize) < max_levels:\n            mlz = max_levels - len(to_levelize)\n            toext = [to_levelize[-1] for i in range(mlz)]\n            to_levelize.extend(toext)\n    elif to_levelize is None:\n        to_levelize = [(None, {}) for i in range(max_levels)]\n\n    return to_levelize", "response": "This function will levelize the given parameter in to a list per level."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfilters each column of A with tol. i. e. drop all entries in column k where theta < max ( abs ( A [ i k ] )", "response": "def filter_matrix_columns(A, theta):\n    \"\"\"Filter each column of A with tol.\n\n    i.e., drop all entries in column k where\n        abs(A[i,k]) < tol max( abs(A[:,k]) )\n\n    Parameters\n    ----------\n    A : sparse_matrix\n\n    theta : float\n        In range [0,1) and defines drop-tolerance used to filter the columns\n        of A\n\n    Returns\n    -------\n    A_filter : sparse_matrix\n        Each column has been filtered by dropping all entries where\n        abs(A[i,k]) < tol max( abs(A[:,k]) )\n\n    Examples\n    --------\n    >>> from pyamg.gallery import poisson\n    >>> from pyamg.util.utils import filter_matrix_columns\n    >>> from scipy import array\n    >>> from scipy.sparse import csr_matrix\n    >>> A = csr_matrix( array([[ 0.24,  1.  ,  0.  ],\n    ...                        [-0.5 ,  1.  , -0.5 ],\n    ...                        [ 0.  ,  0.49,  1.  ],\n    ...                        [ 0.  ,  0.  , -0.5 ]]) )\n    >>> filter_matrix_columns(A, 0.5).todense()\n    matrix([[ 0. ,  1. ,  0. ],\n            [-0.5,  1. , -0.5],\n            [ 0. ,  0. ,  1. ],\n            [ 0. ,  0. , -0.5]])\n\n    \"\"\"\n    if not isspmatrix(A):\n        raise ValueError(\"Sparse matrix input needed\")\n    if isspmatrix_bsr(A):\n        blocksize = A.blocksize\n    Aformat = A.format\n\n    if (theta < 0) or (theta >= 1.0):\n        raise ValueError(\"theta must be in [0,1)\")\n\n    # Apply drop-tolerance to each column of A, which is most easily\n    # accessed by converting to CSC.  We apply the drop-tolerance with\n    # amg_core.classical_strength_of_connection(), which ignores\n    # diagonal entries, thus necessitating the trick where we add\n    # A.shape[1] to each of the column indices\n    A = A.copy().tocsc()\n    A_filter = A.copy()\n    A.indices += A.shape[1]\n    A_filter.indices += A.shape[1]\n    # classical_strength_of_connection takes an absolute value internally\n    pyamg.amg_core.classical_strength_of_connection_abs(\n        A.shape[1],\n        theta,\n        A.indptr,\n        A.indices,\n        A.data,\n        A_filter.indptr,\n        A_filter.indices,\n        A_filter.data)\n    A_filter.indices[:A_filter.indptr[-1]] -= A_filter.shape[1]\n    A_filter = csc_matrix((A_filter.data[:A_filter.indptr[-1]],\n                           A_filter.indices[:A_filter.indptr[-1]],\n                           A_filter.indptr), shape=A_filter.shape)\n    del A\n\n    if Aformat == 'bsr':\n        A_filter = A_filter.tobsr(blocksize)\n    else:\n        A_filter = A_filter.asformat(Aformat)\n\n    return A_filter"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter_matrix_rows(A, theta):\n    if not isspmatrix(A):\n        raise ValueError(\"Sparse matrix input needed\")\n    if isspmatrix_bsr(A):\n        blocksize = A.blocksize\n    Aformat = A.format\n    A = A.tocsr()\n\n    if (theta < 0) or (theta >= 1.0):\n        raise ValueError(\"theta must be in [0,1)\")\n\n    # Apply drop-tolerance to each row of A.  We apply the drop-tolerance with\n    # amg_core.classical_strength_of_connection(), which ignores diagonal\n    # entries, thus necessitating the trick where we add A.shape[0] to each of\n    # the row indices\n    A_filter = A.copy()\n    A.indices += A.shape[0]\n    A_filter.indices += A.shape[0]\n    # classical_strength_of_connection takes an absolute value internally\n    pyamg.amg_core.classical_strength_of_connection_abs(\n        A.shape[0],\n        theta,\n        A.indptr,\n        A.indices,\n        A.data,\n        A_filter.indptr,\n        A_filter.indices,\n        A_filter.data)\n    A_filter.indices[:A_filter.indptr[-1]] -= A_filter.shape[0]\n    A_filter = csr_matrix((A_filter.data[:A_filter.indptr[-1]],\n                           A_filter.indices[:A_filter.indptr[-1]],\n                           A_filter.indptr), shape=A_filter.shape)\n\n    if Aformat == 'bsr':\n        A_filter = A_filter.tobsr(blocksize)\n    else:\n        A_filter = A_filter.asformat(Aformat)\n\n    A.indices -= A.shape[0]\n    return A_filter", "response": "Filter each row of A with tol.\n    i. e. drop all entries in row k where theta < max ( abs ( A [ i k ] )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef truncate_rows(A, nz_per_row):\n    if not isspmatrix(A):\n        raise ValueError(\"Sparse matrix input needed\")\n    if isspmatrix_bsr(A):\n        blocksize = A.blocksize\n    if isspmatrix_csr(A):\n        A = A.copy()    # don't modify A in-place\n    Aformat = A.format\n    A = A.tocsr()\n    nz_per_row = int(nz_per_row)\n\n    # Truncate rows of A, and then convert A back to original format\n    pyamg.amg_core.truncate_rows_csr(A.shape[0], nz_per_row, A.indptr,\n                                     A.indices, A.data)\n\n    A.eliminate_zeros()\n    if Aformat == 'bsr':\n        A = A.tobsr(blocksize)\n    else:\n        A = A.asformat(Aformat)\n\n    return A", "response": "Truncate the rows of A by keeping only the largest in magnitude entries in each row."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_profile(self):\n        r = self._session.get(API_URL + \"/logins/me\")\n        r.raise_for_status()\n\n        return r.json()", "response": "Get my own profile"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_calendar(self, listing_id, starting_month=datetime.datetime.now().month, starting_year=datetime.datetime.now().year, calendar_months=12):\n        params = {\n            'year': str(starting_year),\n            'listing_id': str(listing_id),\n            '_format': 'with_conditions',\n            'count': str(calendar_months),\n            'month': str(starting_month)\n        }\n\n        r = self._session.get(API_URL + \"/calendar_months\", params=params)\n        r.raise_for_status()\n\n        return r.json()", "response": "Get availability calendar for a given listing"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_reviews(self, listing_id, offset=0, limit=20):\n        params = {\n            '_order': 'language_country',\n            'listing_id': str(listing_id),\n            '_offset': str(offset),\n            'role': 'all',\n            '_limit': str(limit),\n            '_format': 'for_mobile_client',\n        }\n\n        print(self._session.headers)\n\n        r = self._session.get(API_URL + \"/reviews\", params=params)\n        r.raise_for_status()\n\n        return r.json()", "response": "Get reviews for a given listing"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the host availability calendar for a given listing.", "response": "def get_listing_calendar(self, listing_id, starting_date=datetime.datetime.now(), calendar_months=6):\n        \"\"\"\n        Get host availability calendar for a given listing\n        \"\"\"\n        params = {\n            '_format': 'host_calendar_detailed'\n        }\n\n        starting_date_str = starting_date.strftime(\"%Y-%m-%d\")\n        ending_date_str = (\n            starting_date + datetime.timedelta(days=30)).strftime(\"%Y-%m-%d\")\n\n        r = self._session.get(API_URL + \"/calendars/{}/{}/{}\".format(\n            str(listing_id), starting_date_str, ending_date_str), params=params)\n        r.raise_for_status()\n\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a list of homes from the explore tabs API.", "response": "def get_homes(self, query=None, gps_lat=None, gps_lng=None, offset=0, items_per_grid=8):\n        \"\"\"\n        Search listings with\n            * Query (e.g. query=\"Lisbon, Portugal\") or\n            * Location (e.g. gps_lat=55.6123352&gps_lng=37.7117917)\n        \"\"\"\n        params = {\n            'is_guided_search': 'true',\n            'version': '1.3.9',\n            'section_offset': '0',\n            'items_offset': str(offset),\n            'adults': '0',\n            'screen_size': 'small',\n            'source': 'explore_tabs',\n            'items_per_grid': str(items_per_grid),\n            '_format': 'for_explore_search_native',\n            'metadata_only': 'false',\n            'refinement_paths[]': '/homes',\n            'timezone': 'Europe/Lisbon',\n            'satori_version': '1.0.7'\n        }\n\n        if not query and not (gps_lat and gps_lng):\n            raise MissingParameterError(\"Missing query or gps coordinates\")\n\n        if query:\n            params['query'] = query\n\n        if gps_lat and gps_lng:\n            params['gps_lat'] = gps_lat\n            params['gps_lng'] = gps_lng\n\n        r = self._session.get(API_URL + '/explore_tabs', params=params)\n        r.raise_for_status()\n\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the shellcode to a base64 - encoded version of the ISO - 8601 format.", "response": "def convert(self, code):\n        '''\n        Note:\n\n        If the shellcode starts with '66' controls, it needs to be changed to add [BITS 32] or\n        [BITS 64] to the start.\n\n        To use:\n\n        convert(\"\"\"\n            55\n            53\n            50\n            BDE97F071E\n            FFD5\n            BDD67B071E\n            FFD5\n            5D\n            5B\n            58\n            C3\n            \"\"\")\n        '''\n        code = code.replace(' ', '')\n        lines = []\n        for l in code.splitlines(False):\n            lines.append(l)\n        code = ''.join(lines)  # Remove new lines\n        return code.decode('hex')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a list of completions for the current action token.", "response": "def generate_completions(frame, act_tok):\n    '''\n    :return list(tuple(method_name, docstring, parameters, completion_type))\n\n    method_name: str\n    docstring: str\n    parameters: str -- i.e.: \"(a, b)\"\n    completion_type is an int\n        See: _pydev_bundle._pydev_imports_tipper for TYPE_ constants\n    '''\n    if frame is None:\n        return []\n\n    # Not using frame.f_globals because of https://sourceforge.net/tracker2/?func=detail&aid=2541355&group_id=85796&atid=577329\n    # (Names not resolved in generator expression in method)\n    # See message: http://mail.python.org/pipermail/python-list/2009-January/526522.html\n    updated_globals = {}\n    updated_globals.update(frame.f_globals)\n    updated_globals.update(frame.f_locals)  # locals later because it has precedence over the actual globals\n\n    if pydevconsole.IPYTHON:\n        completions = pydevconsole.get_completions(act_tok, act_tok, updated_globals, frame.f_locals)\n    else:\n        completer = Completer(updated_globals, None)\n        # list(tuple(name, descr, parameters, type))\n        completions = completer.complete(act_tok)\n\n    return completions"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_token_and_qualifier(text, line=0, column=0):\n    '''\n    Extracts the token a qualifier from the text given the line/colum\n    (see test_extract_token_and_qualifier for examples).\n\n    :param unicode text:\n    :param int line: 0-based\n    :param int column: 0-based\n    '''\n    # Note: not using the tokenize module because text should be unicode and\n    # line/column refer to the unicode text (otherwise we'd have to know\n    # those ranges after converted to bytes).\n    if line < 0:\n        line = 0\n    if column < 0:\n        column = 0\n\n    if isinstance(text, bytes):\n        text = text.decode('utf-8')\n\n    lines = text.splitlines()\n    try:\n        text = lines[line]\n    except IndexError:\n        return TokenAndQualifier(u'', u'')\n\n    if column >= len(text):\n        column = len(text)\n\n    text = text[:column]\n    token = u''\n    qualifier = u''\n\n    temp_token = []\n    for i in range(column - 1, -1, -1):\n        c = text[i]\n        if c in identifier_part or isidentifier(c) or c == u'.':\n            temp_token.append(c)\n        else:\n            break\n    temp_token = u''.join(reversed(temp_token))\n    if u'.' in temp_token:\n        temp_token = temp_token.split(u'.')\n        token = u'.'.join(temp_token[:-1])\n        qualifier = temp_token[-1]\n    else:\n        qualifier = temp_token\n\n    return TokenAndQualifier(token, qualifier)", "response": "Extracts the token and qualifier from the text given the line and column."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef complete(self, text):\n        if self.use_main_ns:\n            # In pydev this option should never be used\n            raise RuntimeError('Namespace must be provided!')\n            self.namespace = __main__.__dict__  # @UndefinedVariable\n\n        if \".\" in text:\n            return self.attr_matches(text)\n        else:\n            return self.global_matches(text)", "response": "Return the next possible completion for text."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute matches when text is a simple name.", "response": "def global_matches(self, text):\n        \"\"\"Compute matches when text is a simple name.\n\n        Return a list of all keywords, built-in functions and names currently\n        defined in self.namespace or self.global_namespace that match.\n\n        \"\"\"\n\n        def get_item(obj, attr):\n            return obj[attr]\n\n        a = {}\n\n        for dict_with_comps in [__builtin__.__dict__, self.namespace, self.global_namespace]:  # @UndefinedVariable\n            a.update(dict_with_comps)\n\n        filter = _StartsWithFilter(text)\n\n        return dir2(a, a.keys(), get_item, filter)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute matches when text contains a dot.", "response": "def attr_matches(self, text):\n        \"\"\"Compute matches when text contains a dot.\n\n        Assuming the text is of the form NAME.NAME....[NAME], and is\n        evaluatable in self.namespace or self.global_namespace, it will be\n        evaluated and its attributes (as revealed by dir()) are used as\n        possible completions.  (For class instances, class members are are\n        also considered.)\n\n        WARNING: this can still invoke arbitrary C code, if an object\n        with a __getattr__ hook is evaluated.\n\n        \"\"\"\n        import re\n\n        # Another option, seems to work great. Catches things like ''.<tab>\n        m = re.match(r\"(\\S+(\\.\\w+)*)\\.(\\w*)$\", text)  # @UndefinedVariable\n\n        if not m:\n            return []\n\n        expr, attr = m.group(1, 3)\n        try:\n            obj = eval(expr, self.namespace)\n        except:\n            try:\n                obj = eval(expr, self.global_namespace)\n            except:\n                return []\n\n        filter = _StartsWithFilter(attr)\n\n        words = dir2(obj, filter=filter)\n\n        return words"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_var_data(self, fmt=None):\n        '''\n        :param dict fmt:\n            Format expected by the DAP (keys: 'hex': bool, 'rawString': bool)\n        '''\n        safe_repr = SafeRepr()\n        if fmt is not None:\n            safe_repr.convert_to_hex = fmt.get('hex', False)\n            safe_repr.raw_value = fmt.get('rawString', False)\n\n        type_name, _type_qualifier, _is_exception_on_eval, resolver, value = get_variable_details(\n            self.value, to_string=safe_repr)\n\n        is_raw_string = type_name in ('str', 'unicode', 'bytes', 'bytearray')\n\n        attributes = []\n\n        if is_raw_string:\n            attributes.append('rawString')\n\n        name = self.name\n\n        if self._is_return_value:\n            attributes.append('readOnly')\n            name = '(return) %s' % (name,)\n\n        var_data = {\n            'name': name,\n            'value': value,\n            'type': type_name,\n        }\n\n        if self.evaluate_name is not None:\n            var_data['evaluateName'] = self.evaluate_name\n\n        if resolver is not None:  # I.e.: it's a container\n            var_data['variablesReference'] = self.get_variable_reference()\n\n        if len(attributes) > 0:\n            var_data['presentationHint'] = {'attributes': attributes}\n\n        return var_data", "response": "Returns a dict containing the variable data for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a new frame to the list of thread_id_to_lineno and frame_id_to_lineno.", "response": "def track(self, thread_id, frame, frame_id_to_lineno, frame_custom_thread_id=None):\n        '''\n        :param thread_id:\n            The thread id to be used for this frame.\n\n        :param frame:\n            The topmost frame which is suspended at the given thread.\n\n        :param frame_id_to_lineno:\n            If available, the line number for the frame will be gotten from this dict,\n            otherwise frame.f_lineno will be used (needed for unhandled exceptions as\n            the place where we report may be different from the place where it's raised).\n\n        :param frame_custom_thread_id:\n            If None this this is the id of the thread id for the custom frame (i.e.: coroutine).\n        '''\n        with self._lock:\n            coroutine_or_main_thread_id = frame_custom_thread_id or thread_id\n\n            if coroutine_or_main_thread_id in self._suspended_frames_manager._thread_id_to_tracker:\n                sys.stderr.write('pydevd: Something is wrong. Tracker being added twice to the same thread id.\\n')\n\n            self._suspended_frames_manager._thread_id_to_tracker[coroutine_or_main_thread_id] = self\n            self._main_thread_id = thread_id\n            self._frame_id_to_lineno = frame_id_to_lineno\n\n            frame_ids_from_thread = self._thread_id_to_frame_ids.setdefault(\n                coroutine_or_main_thread_id, [])\n\n            while frame is not None:\n                frame_id = id(frame)\n                self._frame_id_to_frame[frame_id] = frame\n                _FrameVariable(frame, self._register_variable)  # Instancing is enough to register.\n                self._suspended_frames_manager._variable_reference_to_frames_tracker[frame_id] = self\n                frame_ids_from_thread.append(frame_id)\n\n                self._frame_id_to_main_thread_id[frame_id] = thread_id\n\n                frame = frame.f_back"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_thread_id_for_variable_reference(self, variable_reference):\n        '''\n        We can't evaluate variable references values on any thread, only in the suspended\n        thread (the main reason for this is that in UI frameworks inspecting a UI object\n        from a different thread can potentially crash the application).\n\n        :param int variable_reference:\n            The variable reference (can be either a frame id or a reference to a previously\n            gotten variable).\n\n        :return str:\n            The thread id for the thread to be used to inspect the given variable reference or\n            None if the thread was already resumed.\n        '''\n        frames_tracker = self._get_tracker_for_variable_reference(variable_reference)\n        if frames_tracker is not None:\n            return frames_tracker.get_main_thread_id()\n        return None", "response": "This method returns the thread id for the given variable reference."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_variable(self, variable_reference):\n        '''\n        :raises KeyError\n        '''\n        frames_tracker = self._get_tracker_for_variable_reference(variable_reference)\n        if frames_tracker is None:\n            raise KeyError()\n        return frames_tracker.get_variable(variable_reference)", "response": "Gets the value of a variable from the frames tracker."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_gui_and_backend():\n    matplotlib = sys.modules['matplotlib']\n    # WARNING: this assumes matplotlib 1.1 or newer!!\n    backend = matplotlib.rcParams['backend']\n    # In this case, we need to find what the appropriate gui selection call\n    # should be for IPython, so we can activate inputhook accordingly\n    gui = backend2gui.get(backend, None)\n    return gui, backend", "response": "Return the gui and mpl backend."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if backend is interactive", "response": "def is_interactive_backend(backend):\n    \"\"\" Check if backend is interactive \"\"\"\n    matplotlib = sys.modules['matplotlib']\n    from matplotlib.rcsetup import interactive_bk, non_interactive_bk  # @UnresolvedImport\n    if backend in interactive_bk:\n        return True\n    elif backend in non_interactive_bk:\n        return False\n    else:\n        return matplotlib.is_interactive()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef patch_use(enable_gui_function):\n    matplotlib = sys.modules['matplotlib']\n\n    def patched_use(*args, **kwargs):\n        matplotlib.real_use(*args, **kwargs)\n        gui, backend = find_gui_and_backend()\n        enable_gui_function(gui)\n\n    matplotlib.real_use = matplotlib.use\n    matplotlib.use = patched_use", "response": "Patch matplotlib function use to enable the GUI."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npatching matplotlib function use to return the interactive version of the current object.", "response": "def patch_is_interactive():\n    \"\"\" Patch matplotlib function 'use' \"\"\"\n    matplotlib = sys.modules['matplotlib']\n\n    def patched_is_interactive():\n        return matplotlib.rcParams['interactive']\n\n    matplotlib.real_is_interactive = matplotlib.is_interactive\n    matplotlib.is_interactive = patched_is_interactive"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets interactive to True for interactive backends. enable_gui_function - Function which enables gui, should be run in the main thread.", "response": "def activate_matplotlib(enable_gui_function):\n    \"\"\"Set interactive to True for interactive backends.\n    enable_gui_function - Function which enables gui, should be run in the main thread.\n    \"\"\"\n    matplotlib = sys.modules['matplotlib']\n    gui, backend = find_gui_and_backend()\n    is_interactive = is_interactive_backend(backend)\n    if is_interactive:\n        enable_gui_function(gui)\n        if not matplotlib.is_interactive():\n            sys.stdout.write(\"Backend %s is interactive backend. Turning interactive mode on.\\n\" % backend)\n        matplotlib.interactive(True)\n    else:\n        if matplotlib.is_interactive():\n            sys.stdout.write(\"Backend %s is non-interactive backend. Turning interactive mode off.\\n\" % backend)\n        matplotlib.interactive(False)\n    patch_use(enable_gui_function)\n    patch_is_interactive()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef flag_calls(func):\n\n    # don't wrap twice\n    if hasattr(func, 'called'):\n        return func\n\n    def wrapper(*args, **kw):\n        wrapper.called = False\n        out = func(*args, **kw)\n        wrapper.called = True\n        return out\n\n    wrapper.called = False\n    wrapper.__doc__ = func.__doc__\n    return wrapper", "response": "A decorator that marks a function as called when it gets called."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_valid_py_file(path):\n    '''\n    Checks whether the file can be read by the coverage module. This is especially\n    needed for .pyx files and .py files with syntax errors.\n    '''\n    import os\n\n    is_valid = False\n    if os.path.isfile(path) and not os.path.splitext(path)[1] == '.pyx':\n        try:\n            with open(path, 'rb') as f:\n                compile(f.read(), path, 'exec')\n                is_valid = True\n        except:\n            pass\n    return is_valid", "response": "Checks whether the file is valid by the coverage module."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_process(self):\n        pid     = self.get_pid()\n        system  = self.debug.system\n        if system.has_process(pid):\n            process = system.get_process(pid)\n        else:\n            # XXX HACK\n            # The process object was missing for some reason, so make a new one.\n            process = Process(pid)\n            system._add_process(process)\n##            process.scan_threads()    # not needed\n            process.scan_modules()\n        return process", "response": "Returns the process object that was created for the event."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_thread(self):\n        tid     = self.get_tid()\n        process = self.get_process()\n        if process.has_thread(tid):\n            thread = process.get_thread(tid)\n        else:\n            # XXX HACK\n            # The thread object was missing for some reason, so make a new one.\n            thread = Thread(tid)\n            process._add_thread(thread)\n        return thread", "response": "Returns the Thread object that was created for this event."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns C { True if the exception is noncontinuable.", "response": "def is_noncontinuable(self):\n        \"\"\"\n        @see: U{http://msdn.microsoft.com/en-us/library/aa363082(VS.85).aspx}\n\n        @rtype:  bool\n        @return: C{True} if the exception is noncontinuable,\n            C{False} otherwise.\n\n            Attempting to continue a noncontinuable exception results in an\n            EXCEPTION_NONCONTINUABLE_EXCEPTION exception to be raised.\n        \"\"\"\n        return bool( self.raw.u.Exception.ExceptionRecord.ExceptionFlags & \\\n                                            win32.EXCEPTION_NONCONTINUABLE )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the exception information block at the specified index.", "response": "def get_exception_information(self, index):\n        \"\"\"\n        @type  index: int\n        @param index: Index into the exception information block.\n\n        @rtype:  int\n        @return: Exception information DWORD.\n        \"\"\"\n        if index < 0 or index > win32.EXCEPTION_MAXIMUM_PARAMETERS:\n            raise IndexError(\"Array index out of range: %s\" % repr(index))\n        info = self.raw.u.Exception.ExceptionRecord.ExceptionInformation\n        value = info[index]\n        if value is None:\n            value = 0\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_fault_type(self):\n        if self.get_exception_code() not in (win32.EXCEPTION_ACCESS_VIOLATION,\n                    win32.EXCEPTION_IN_PAGE_ERROR, win32.EXCEPTION_GUARD_PAGE):\n            msg = \"This method is not meaningful for %s.\"\n            raise NotImplementedError(msg % self.get_exception_name())\n        return self.get_exception_information(0)", "response": "Returns the type of exception that is related to the exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_ntstatus_code(self):\n        if self.get_exception_code() != win32.EXCEPTION_IN_PAGE_ERROR:\n            msg = \"This method is only meaningful \"\\\n                  \"for in-page memory error exceptions.\"\n            raise NotImplementedError(msg)\n        return self.get_exception_information(2)", "response": "Returns the NTSTATUS code that caused the exception."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of raw exception record structures that are used by Win32 API.", "response": "def get_raw_exception_record_list(self):\n        \"\"\"\n        Traverses the exception record linked list and builds a Python list.\n\n        Nested exception records are received for nested exceptions. This\n        happens when an exception is raised in the debugee while trying to\n        handle a previous exception.\n\n        @rtype:  list( L{win32.EXCEPTION_RECORD} )\n        @return:\n            List of raw exception record structures as used by the Win32 API.\n\n            There is always at least one exception record, so the list is\n            never empty. All other methods of this class read from the first\n            exception record only, that is, the most recent exception.\n        \"\"\"\n        # The first EXCEPTION_RECORD is contained in EXCEPTION_DEBUG_INFO.\n        # The remaining EXCEPTION_RECORD structures are linked by pointers.\n        nested = list()\n        record = self.raw.u.Exception\n        while True:\n            record = record.ExceptionRecord\n            if not record:\n                break\n            nested.append(record)\n        return nested"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_nested_exceptions(self):\n        # The list always begins with ourselves.\n        # Just put a reference to \"self\" as the first element,\n        # and start looping from the second exception record.\n        nested = [ self ]\n        raw = self.raw\n        dwDebugEventCode = raw.dwDebugEventCode\n        dwProcessId      = raw.dwProcessId\n        dwThreadId       = raw.dwThreadId\n        dwFirstChance    = raw.u.Exception.dwFirstChance\n        record           = raw.u.Exception.ExceptionRecord\n        while True:\n            record = record.ExceptionRecord\n            if not record:\n                break\n            raw = win32.DEBUG_EVENT()\n            raw.dwDebugEventCode            = dwDebugEventCode\n            raw.dwProcessId                 = dwProcessId\n            raw.dwThreadId                  = dwThreadId\n            raw.u.Exception.ExceptionRecord = record\n            raw.u.Exception.dwFirstChance   = dwFirstChance\n            event = EventFactory.get(self.debug, raw)\n            nested.append(event)\n        return nested", "response": "Returns a list of nested exception records."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an event object or one of its subclasses depending on the event type.", "response": "def get(cls, debug, raw):\n        \"\"\"\n        @type  debug: L{Debug}\n        @param debug: Debug object that received the event.\n\n        @type  raw: L{DEBUG_EVENT}\n        @param raw: Raw DEBUG_EVENT structure as used by the Win32 API.\n\n        @rtype: L{Event}\n        @returns: An Event object or one of it's subclasses,\n            depending on the event type.\n        \"\"\"\n        eventClass = cls.eventClasses.get(raw.dwDebugEventCode, cls.baseEvent)\n        return eventClass(debug, raw)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __get_hooks_for_dll(self, event):\n        result = []\n        if self.__apiHooks:\n            path = event.get_module().get_filename()\n            if path:\n                lib_name = PathOperations.pathname_to_filename(path).lower()\n                for hook_lib, hook_api_list in compat.iteritems(self.__apiHooks):\n                    if hook_lib == lib_name:\n                        result.extend(hook_api_list)\n        return result", "response": "Get the API hooks for the current DLL."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __hook_dll(self, event):\n        debug = event.debug\n        pid   = event.get_pid()\n        for hook_api_stub in self.__get_hooks_for_dll(event):\n            hook_api_stub.hook(debug, pid)", "response": "Hook the requested API calls."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nunhooks the requested API calls.", "response": "def __unhook_dll(self, event):\n        \"\"\"\n        Unhook the requested API calls (in self.apiHooks).\n\n        This method is called automatically whenever a DLL is unloaded.\n        \"\"\"\n        debug = event.debug\n        pid   = event.get_pid()\n        for hook_api_stub in self.__get_hooks_for_dll(event):\n            hook_api_stub.unhook(debug, pid)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef event(self, event):\n        eventCode = event.get_event_code()\n        pid = event.get_pid()\n        handler = self.forward.get(pid, None)\n        if handler is None:\n            handler = self.cls(*self.argv, **self.argd)\n            if eventCode != win32.EXIT_PROCESS_DEBUG_EVENT:\n                self.forward[pid] = handler\n        elif eventCode == win32.EXIT_PROCESS_DEBUG_EVENT:\n            del self.forward[pid]\n        return handler(event)", "response": "Forwards events to the corresponding instance of the appropriate handler."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the event handler.", "response": "def set_event_handler(self, eventHandler):\n        \"\"\"\n        Set the event handler.\n\n        @warn: This is normally not needed. Use with care!\n\n        @type  eventHandler: L{EventHandler}\n        @param eventHandler: New event handler object, or C{None}.\n\n        @rtype:  L{EventHandler}\n        @return: Previous event handler object, or C{None}.\n\n        @raise TypeError: The event handler is of an incorrect type.\n\n        @note: The L{eventHandler} parameter may be any callable Python object\n            (for example a function, or an instance method).\n            However you'll probably find it more convenient to use an instance\n            of a subclass of L{EventHandler} here.\n        \"\"\"\n        if eventHandler is not None and not callable(eventHandler):\n            raise TypeError(\"Event handler must be a callable object\")\n        try:\n            wrong_type = issubclass(eventHandler, EventHandler)\n        except TypeError:\n            wrong_type = False\n        if wrong_type:\n            classname = str(eventHandler)\n            msg  = \"Event handler must be an instance of class %s\"\n            msg += \"rather than the %s class itself. (Missing parens?)\"\n            msg  = msg % (classname, classname)\n            raise TypeError(msg)\n        try:\n            previous = self.__eventHandler\n        except AttributeError:\n            previous = None\n        self.__eventHandler = eventHandler\n        return previous"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the appropriate callback method that will handle the given event.", "response": "def get_handler_method(eventHandler, event, fallback=None):\n        \"\"\"\n        Retrieves the appropriate callback method from an L{EventHandler}\n        instance for the given L{Event} object.\n\n        @type  eventHandler: L{EventHandler}\n        @param eventHandler:\n            Event handler object whose methods we are examining.\n\n        @type  event: L{Event}\n        @param event: Debugging event to be handled.\n\n        @type  fallback: callable\n        @param fallback: (Optional) If no suitable method is found in the\n            L{EventHandler} instance, return this value.\n\n        @rtype:  callable\n        @return: Bound method that will handle the debugging event.\n            Returns C{None} if no such method is defined.\n        \"\"\"\n        eventCode = event.get_event_code()\n        method = getattr(eventHandler, 'event', fallback)\n        if eventCode == win32.EXCEPTION_DEBUG_EVENT:\n            method = getattr(eventHandler, 'exception', method)\n        method = getattr(eventHandler, event.eventMethod, method)\n        return method"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dispatch(self, event):\n        returnValue  = None\n        bCallHandler = True\n        pre_handler  = None\n        post_handler = None\n        eventCode    = event.get_event_code()\n\n        # Get the pre and post notification methods for exceptions.\n        # If not found, the following steps take care of that.\n        if eventCode == win32.EXCEPTION_DEBUG_EVENT:\n            exceptionCode = event.get_exception_code()\n            pre_name      = self.__preExceptionNotifyCallbackName.get(\n                                                           exceptionCode, None)\n            post_name     = self.__postExceptionNotifyCallbackName.get(\n                                                           exceptionCode, None)\n            if  pre_name     is not None:\n                pre_handler  = getattr(self, pre_name,  None)\n            if  post_name    is not None:\n                post_handler = getattr(self, post_name, None)\n\n        # Get the pre notification method for all other events.\n        # This includes the exception event if no notify method was found\n        # for this exception code.\n        if pre_handler is None:\n            pre_name = self.__preEventNotifyCallbackName.get(eventCode, None)\n            if  pre_name is not None:\n                pre_handler = getattr(self, pre_name, pre_handler)\n\n        # Get the post notification method for all other events.\n        # This includes the exception event if no notify method was found\n        # for this exception code.\n        if post_handler is None:\n            post_name = self.__postEventNotifyCallbackName.get(eventCode, None)\n            if  post_name is not None:\n                post_handler = getattr(self, post_name, post_handler)\n\n        # Call the pre-notify method only if it was defined.\n        # If an exception is raised don't call the other methods.\n        if pre_handler is not None:\n            bCallHandler = pre_handler(event)\n\n        # Call the user-defined event handler only if the pre-notify\n        #  method was not defined, or was and it returned True.\n        try:\n            if bCallHandler and self.__eventHandler is not None:\n                try:\n                    returnValue = self.__eventHandler(event)\n                except Exception:\n                    e = sys.exc_info()[1]\n                    msg = (\"Event handler pre-callback %r\"\n                           \" raised an exception: %s\")\n                    msg = msg % (self.__eventHandler, traceback.format_exc(e))\n                    warnings.warn(msg, EventCallbackWarning)\n                    returnValue = None\n\n        # Call the post-notify method if defined, even if an exception is\n        #  raised by the user-defined event handler.\n        finally:\n            if post_handler is not None:\n                post_handler(event)\n\n        # Return the value from the call to the user-defined event handler.\n        # If not defined return None.\n        return returnValue", "response": "Dispatches the given event to the contained debug object and returns the object that was created."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef should_skip(filename, config, path='/'):\n    for skip_path in config['skip']:\n        if posixpath.abspath(posixpath.join(path, filename)) == posixpath.abspath(skip_path.replace('\\\\', '/')):\n            return True\n\n    position = os.path.split(filename)\n    while position[1]:\n        if position[1] in config['skip']:\n            return True\n        position = os.path.split(position[0])\n\n    for glob in config['skip_glob']:\n        if fnmatch.fnmatch(filename, glob):\n            return True\n\n    return False", "response": "Returns True if the file should be skipped based on the passed in settings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nformatting an argument to be shown", "response": "def format_arg(arg):\n    '''formats an argument to be shown\n    '''\n\n    s = str(arg)\n    dot = s.rfind('.')\n    if dot >= 0:\n        s = s[dot + 1:]\n\n    s = s.replace(';', '')\n    s = s.replace('[]', 'Array')\n    if len(s) > 0:\n        c = s[0].lower()\n        s = c + s[1:]\n\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning a function as a pydevd daemon thread.", "response": "def run_as_pydevd_daemon_thread(func, *args, **kwargs):\n    '''\n    Runs a function as a pydevd daemon thread (without any tracing in place).\n    '''\n    t = PyDBDaemonThread(target_and_args=(func, args, kwargs))\n    t.name = '%s (pydevd daemon thread)' % (func.__name__,)\n    t.start()\n    return t"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start_server(port):\n    ''' binds to a port, waits for the debugger to connect '''\n    s = socket(AF_INET, SOCK_STREAM)\n    s.settimeout(None)\n\n    try:\n        from socket import SO_REUSEPORT\n        s.setsockopt(SOL_SOCKET, SO_REUSEPORT, 1)\n    except ImportError:\n        s.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1)\n\n    s.bind(('', port))\n    pydev_log.info(\"Bound to port :%s\", port)\n\n    try:\n        s.listen(1)\n        newSock, _addr = s.accept()\n        pydev_log.info(\"Connection accepted\")\n        # closing server socket is not necessary but we don't need it\n        s.shutdown(SHUT_RDWR)\n        s.close()\n        return newSock\n\n    except:\n        pydev_log.exception(\"Could not bind to port: %s\\n\", port)", "response": "binds to a port waits for the debugger to connect"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconnecting to a host and port and returns a new socket object.", "response": "def start_client(host, port):\n    ''' connects to a host/port '''\n    pydev_log.info(\"Connecting to %s:%s\", host, port)\n\n    s = socket(AF_INET, SOCK_STREAM)\n\n    #  Set TCP keepalive on an open socket.\n    #  It activates after 1 second (TCP_KEEPIDLE,) of idleness,\n    #  then sends a keepalive ping once every 3 seconds (TCP_KEEPINTVL),\n    #  and closes the connection after 5 failed ping (TCP_KEEPCNT), or 15 seconds\n    try:\n        from socket import IPPROTO_TCP, SO_KEEPALIVE, TCP_KEEPIDLE, TCP_KEEPINTVL, TCP_KEEPCNT\n        s.setsockopt(SOL_SOCKET, SO_KEEPALIVE, 1)\n        s.setsockopt(IPPROTO_TCP, TCP_KEEPIDLE, 1)\n        s.setsockopt(IPPROTO_TCP, TCP_KEEPINTVL, 3)\n        s.setsockopt(IPPROTO_TCP, TCP_KEEPCNT, 5)\n    except ImportError:\n        pass  # May not be available everywhere.\n\n    try:\n        # 10 seconds default timeout\n        timeout = int(os.environ.get('PYDEVD_CONNECT_TIMEOUT', 10))\n        s.settimeout(timeout)\n        s.connect((host, port))\n        s.settimeout(None)  # no timeout after connected\n        pydev_log.info(\"Connected.\")\n        return s\n    except:\n        pydev_log.exception(\"Could not connect to %s: %s\", host, port)\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchanging the value of a variable in a virtual environment.", "response": "def internal_change_variable(dbg, seq, thread_id, frame_id, scope, attr, value):\n    ''' Changes the value of a variable '''\n    try:\n        frame = dbg.find_frame(thread_id, frame_id)\n        if frame is not None:\n            result = pydevd_vars.change_attr_expression(frame, attr, value, dbg)\n        else:\n            result = None\n        xml = \"<xml>\"\n        xml += pydevd_xml.var_to_xml(result, \"\")\n        xml += \"</xml>\"\n        cmd = dbg.cmd_factory.make_variable_changed_message(seq, xml)\n        dbg.writer.add_command(cmd)\n    except Exception:\n        cmd = dbg.cmd_factory.make_error_message(seq, \"Error changing variable attr:%s expression:%s traceback:%s\" % (attr, value, get_exception_traceback_str()))\n        dbg.writer.add_command(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef internal_change_variable_json(py_db, request):\n    '''\n    The pydevd_vars.change_attr_expression(thread_id, frame_id, attr, value, dbg) can only\n    deal with changing at a frame level, so, currently changing the contents of something\n    in a different scope is currently not supported.\n\n    TODO: make the resolvers structure resolve the name and change accordingly -- for instance, the\n    list resolver should change the value considering the index.\n\n    :param SetVariableRequest request:\n    '''\n    # : :type arguments: SetVariableArguments\n    arguments = request.arguments\n    variables_reference = arguments.variablesReference\n    fmt = arguments.format\n    if hasattr(fmt, 'to_dict'):\n        fmt = fmt.to_dict()\n\n    # : :type frame: _FrameVariable\n    frame_variable = py_db.suspended_frames_manager.get_variable(variables_reference)\n    if hasattr(frame_variable, 'frame'):\n        frame = frame_variable.frame\n\n        pydevd_vars.change_attr_expression(frame, arguments.name, arguments.value, py_db)\n\n        for child_var in frame_variable.get_children_variables(fmt=fmt):\n            if child_var.get_name() == arguments.name:\n                var_data = child_var.get_var_data(fmt=fmt)\n                body = SetVariableResponseBody(\n                    value=var_data['value'],\n                    type=var_data['type'],\n                    variablesReference=var_data.get('variablesReference'),\n                    namedVariables=var_data.get('namedVariables'),\n                    indexedVariables=var_data.get('indexedVariables'),\n                )\n                variables_response = pydevd_base_schema.build_response(request, kwargs={'body':body})\n                py_db.writer.add_command(NetCommand(CMD_RETURN, 0, variables_response, is_json=True))\n                break\n\n    # If it's gotten here we haven't been able to evaluate it properly. Let the client know.\n    body = SetVariableResponseBody('')\n    variables_response = pydevd_base_schema.build_response(\n        request,\n        kwargs={\n            'body':body,\n            'success': False,\n            'message': 'Unable to change: %s.' % (arguments.name,)\n    })\n    return NetCommand(CMD_RETURN, 0, variables_response, is_json=True)", "response": "Internal function to change the value of a variable in a thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts request into python variable", "response": "def internal_get_frame(dbg, seq, thread_id, frame_id):\n    ''' Converts request into python variable '''\n    try:\n        frame = dbg.find_frame(thread_id, frame_id)\n        if frame is not None:\n            hidden_ns = pydevconsole.get_ipython_hidden_vars()\n            xml = \"<xml>\"\n            xml += pydevd_xml.frame_vars_to_xml(frame.f_locals, hidden_ns)\n            del frame\n            xml += \"</xml>\"\n            cmd = dbg.cmd_factory.make_get_frame_message(seq, xml)\n            dbg.writer.add_command(cmd)\n        else:\n            # pydevd_vars.dump_frames(thread_id)\n            # don't print this error: frame not found: means that the client is not synchronized (but that's ok)\n            cmd = dbg.cmd_factory.make_error_message(seq, \"Frame not found: %s from thread: %s\" % (frame_id, thread_id))\n            dbg.writer.add_command(cmd)\n    except:\n        cmd = dbg.cmd_factory.make_error_message(seq, \"Error resolving frame: %s from thread: %s\" % (frame_id, thread_id))\n        dbg.writer.add_command(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef internal_get_next_statement_targets(dbg, seq, thread_id, frame_id):\n    ''' gets the valid line numbers for use with set next statement '''\n    try:\n        frame = dbg.find_frame(thread_id, frame_id)\n        if frame is not None:\n            code = frame.f_code\n            xml = \"<xml>\"\n            if hasattr(code, 'co_lnotab'):\n                lineno = code.co_firstlineno\n                lnotab = code.co_lnotab\n                for i in itertools.islice(lnotab, 1, len(lnotab), 2):\n                    if isinstance(i, int):\n                        lineno = lineno + i\n                    else:\n                        # in python 2 elements in co_lnotab are of type str\n                        lineno = lineno + ord(i)\n                    xml += \"<line>%d</line>\" % (lineno,)\n            else:\n                xml += \"<line>%d</line>\" % (frame.f_lineno,)\n            del frame\n            xml += \"</xml>\"\n            cmd = dbg.cmd_factory.make_get_next_statement_targets_message(seq, xml)\n            dbg.writer.add_command(cmd)\n        else:\n            cmd = dbg.cmd_factory.make_error_message(seq, \"Frame not found: %s from thread: %s\" % (frame_id, thread_id))\n            dbg.writer.add_command(cmd)\n    except:\n        cmd = dbg.cmd_factory.make_error_message(seq, \"Error resolving frame: %s from thread: %s\" % (frame_id, thread_id))\n        dbg.writer.add_command(cmd)", "response": "gets the valid line numbers for use with set next statement"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef internal_evaluate_expression_json(py_db, request, thread_id):\n    '''\n    :param EvaluateRequest request:\n    '''\n    # : :type arguments: EvaluateArguments\n\n    arguments = request.arguments\n    expression = arguments.expression\n    frame_id = arguments.frameId\n    context = arguments.context\n    fmt = arguments.format\n    if hasattr(fmt, 'to_dict'):\n        fmt = fmt.to_dict()\n\n    if IS_PY2 and isinstance(expression, unicode):\n        try:\n            expression = expression.encode('utf-8')\n        except:\n            _evaluate_response(py_db, request, '', error_message='Expression is not valid utf-8.')\n            raise\n\n    frame = py_db.find_frame(thread_id, frame_id)\n    result = pydevd_vars.evaluate_expression(py_db, frame, expression, is_exec=False)\n    is_error = isinstance(result, ExceptionOnEvaluate)\n\n    if is_error:\n        if context == 'hover':\n            _evaluate_response(py_db, request, result='')\n            return\n\n        elif context == 'repl':\n            try:\n                pydevd_vars.evaluate_expression(py_db, frame, expression, is_exec=True)\n            except Exception as ex:\n                err = ''.join(traceback.format_exception_only(type(ex), ex))\n                _evaluate_response(py_db, request, result='', error_message=err)\n                return\n            # No result on exec.\n            _evaluate_response(py_db, request, result='')\n            return\n\n    # Ok, we have the result (could be an error), let's put it into the saved variables.\n    frame_tracker = py_db.suspended_frames_manager.get_frame_tracker(thread_id)\n    if frame_tracker is None:\n        # This is not really expected.\n        _evaluate_response(py_db, request, result, error_message='Thread id: %s is not current thread id.' % (thread_id,))\n        return\n\n    variable = frame_tracker.obtain_as_variable(expression, result)\n    var_data = variable.get_var_data(fmt=fmt)\n\n    body = pydevd_schema.EvaluateResponseBody(\n        result=var_data['value'],\n        variablesReference=var_data.get('variablesReference', 0),\n        type=var_data.get('type'),\n        presentationHint=var_data.get('presentationHint'),\n        namedVariables=var_data.get('namedVariables'),\n        indexedVariables=var_data.get('indexedVariables'),\n    )\n    variables_response = pydevd_base_schema.build_response(request, kwargs={'body':body})\n    py_db.writer.add_command(NetCommand(CMD_RETURN, 0, variables_response, is_json=True))", "response": "Evaluate an expression on a single frame and return the result."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef internal_evaluate_expression(dbg, seq, thread_id, frame_id, expression, is_exec, trim_if_too_big, attr_to_set_result):\n    ''' gets the value of a variable '''\n    try:\n        frame = dbg.find_frame(thread_id, frame_id)\n        if frame is not None:\n            result = pydevd_vars.evaluate_expression(dbg, frame, expression, is_exec)\n            if attr_to_set_result != \"\":\n                pydevd_vars.change_attr_expression(frame, attr_to_set_result, expression, dbg, result)\n        else:\n            result = None\n\n        xml = \"<xml>\"\n        xml += pydevd_xml.var_to_xml(result, expression, trim_if_too_big)\n        xml += \"</xml>\"\n        cmd = dbg.cmd_factory.make_evaluate_expression_message(seq, xml)\n        dbg.writer.add_command(cmd)\n    except:\n        exc = get_exception_traceback_str()\n        cmd = dbg.cmd_factory.make_error_message(seq, \"Error evaluating expression \" + exc)\n        dbg.writer.add_command(cmd)", "response": "evaluate the expression of a variable in a thread"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nnoting that if the column is >= 0, the act_tok is considered text and the actual activation token/qualifier is computed in this command.", "response": "def internal_get_completions(dbg, seq, thread_id, frame_id, act_tok, line=-1, column=-1):\n    '''\n    Note that if the column is >= 0, the act_tok is considered text and the actual\n    activation token/qualifier is computed in this command.\n    '''\n    try:\n        remove_path = None\n        try:\n            qualifier = u''\n            if column >= 0:\n                token_and_qualifier = extract_token_and_qualifier(act_tok, line, column)\n                act_tok = token_and_qualifier[0]\n                if act_tok:\n                    act_tok += u'.'\n                qualifier = token_and_qualifier[1]\n\n            frame = dbg.find_frame(thread_id, frame_id)\n            if frame is not None:\n                if IS_PY2:\n                    if not isinstance(act_tok, bytes):\n                        act_tok = act_tok.encode('utf-8')\n                    if not isinstance(qualifier, bytes):\n                        qualifier = qualifier.encode('utf-8')\n\n                completions = _pydev_completer.generate_completions(frame, act_tok)\n\n                # Note that qualifier and start are only actually valid for the\n                # Debug Adapter Protocol (for the line-based protocol, the IDE\n                # is required to filter the completions returned).\n                cmd = dbg.cmd_factory.make_get_completions_message(\n                    seq, completions, qualifier, start=column - len(qualifier))\n                dbg.writer.add_command(cmd)\n            else:\n                cmd = dbg.cmd_factory.make_error_message(seq, \"internal_get_completions: Frame not found: %s from thread: %s\" % (frame_id, thread_id))\n                dbg.writer.add_command(cmd)\n\n        finally:\n            if remove_path is not None:\n                sys.path.remove(remove_path)\n\n    except:\n        exc = get_exception_traceback_str()\n        sys.stderr.write('%s\\n' % (exc,))\n        cmd = dbg.cmd_factory.make_error_message(seq, \"Error evaluating expression \" + exc)\n        dbg.writer.add_command(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef internal_get_description(dbg, seq, thread_id, frame_id, expression):\n    ''' Fetch the variable description stub from the debug console\n    '''\n    try:\n        frame = dbg.find_frame(thread_id, frame_id)\n        description = pydevd_console.get_description(frame, thread_id, frame_id, expression)\n        description = pydevd_xml.make_valid_xml_value(quote(description, '/>_= \\t'))\n        description_xml = '<xml><var name=\"\" type=\"\" value=\"%s\"/></xml>' % description\n        cmd = dbg.cmd_factory.make_get_description_message(seq, description_xml)\n        dbg.writer.add_command(cmd)\n    except:\n        exc = get_exception_traceback_str()\n        cmd = dbg.cmd_factory.make_error_message(seq, \"Error in fetching description\" + exc)\n        dbg.writer.add_command(cmd)", "response": "Fetch the variable description stub from the debug console\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding an exception info response from the thread.", "response": "def build_exception_info_response(dbg, thread_id, request_seq, set_additional_thread_info, iter_visible_frames_info, max_frames):\n    '''\n    :return ExceptionInfoResponse\n    '''\n    thread = pydevd_find_thread_by_id(thread_id)\n    additional_info = set_additional_thread_info(thread)\n    topmost_frame = additional_info.get_topmost_frame(thread)\n\n    frames = []\n    exc_type = None\n    exc_desc = None\n    if topmost_frame is not None:\n        frame_id_to_lineno = {}\n        try:\n            trace_obj = None\n            frame = topmost_frame\n            while frame is not None:\n                if frame.f_code.co_name == 'do_wait_suspend' and frame.f_code.co_filename.endswith('pydevd.py'):\n                    arg = frame.f_locals.get('arg', None)\n                    if arg is not None:\n                        exc_type, exc_desc, trace_obj = arg\n                        break\n                frame = frame.f_back\n\n            while trace_obj.tb_next is not None:\n                trace_obj = trace_obj.tb_next\n\n            info = dbg.suspended_frames_manager.get_topmost_frame_and_frame_id_to_line(thread_id)\n            if info is not None:\n                topmost_frame, frame_id_to_lineno = info\n\n            if trace_obj is not None:\n                for frame_id, frame, method_name, original_filename, filename_in_utf8, lineno in iter_visible_frames_info(\n                        dbg, trace_obj.tb_frame, frame_id_to_lineno):\n\n                    line_text = linecache.getline(original_filename, lineno)\n\n                    # Never filter out plugin frames!\n                    if not getattr(frame, 'IS_PLUGIN_FRAME', False):\n                        if dbg.is_files_filter_enabled and dbg.apply_files_filter(frame, original_filename, False):\n                            continue\n                    frames.append((filename_in_utf8, lineno, method_name, line_text))\n        finally:\n            topmost_frame = None\n\n    name = 'exception: type unknown'\n    if exc_type is not None:\n        try:\n            name = exc_type.__qualname__\n        except:\n            try:\n                name = exc_type.__name__\n            except:\n                try:\n                    name = str(exc_type)\n                except:\n                    pass\n\n    description = 'exception: no description'\n    if exc_desc is not None:\n        try:\n            description = str(exc_desc)\n        except:\n            pass\n\n    stack_str = ''.join(traceback.format_list(frames[-max_frames:]))\n\n    # This is an extra bit of data used by Visual Studio\n    source_path = frames[0][0] if frames else ''\n\n    if thread.stop_reason == CMD_STEP_CAUGHT_EXCEPTION:\n        break_mode = pydevd_schema.ExceptionBreakMode.ALWAYS\n    else:\n        break_mode = pydevd_schema.ExceptionBreakMode.UNHANDLED\n\n    response = pydevd_schema.ExceptionInfoResponse(\n        request_seq=request_seq,\n        success=True,\n        command='exceptionInfo',\n        body=pydevd_schema.ExceptionInfoResponseBody(\n            exceptionId=name,\n            description=description,\n            breakMode=break_mode,\n            details=pydevd_schema.ExceptionDetails(\n                message=description,\n                typeName=name,\n                stackTrace=stack_str,\n                source=source_path\n            )\n        )\n    )\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfetch exception details as json", "response": "def internal_get_exception_details_json(dbg, request, thread_id, max_frames, set_additional_thread_info=None, iter_visible_frames_info=None):\n    ''' Fetch exception details\n    '''\n    try:\n        response = build_exception_info_response(dbg, thread_id, request.seq, set_additional_thread_info, iter_visible_frames_info, max_frames)\n    except:\n        exc = get_exception_traceback_str()\n        response = pydevd_base_schema.build_response(request, kwargs={\n            'success': False,\n            'message': exc,\n            'body':{}\n        })\n    dbg.writer.add_command(NetCommand(CMD_RETURN, 0, response, is_json=True))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _on_run(self):\n        ''' just loop and write responses '''\n\n        try:\n            while True:\n                try:\n                    try:\n                        cmd = self.cmdQueue.get(1, 0.1)\n                    except _queue.Empty:\n                        if self.killReceived:\n                            try:\n                                self.sock.shutdown(SHUT_WR)\n                                self.sock.close()\n                            except:\n                                pass\n\n                            return  # break if queue is empty and killReceived\n                        else:\n                            continue\n                except:\n                    # pydev_log.info('Finishing debug communication...(1)')\n                    # when liberating the thread here, we could have errors because we were shutting down\n                    # but the thread was still not liberated\n                    return\n                cmd.send(self.sock)\n\n                if cmd.id == CMD_EXIT:\n                    break\n                if time is None:\n                    break  # interpreter shutdown\n                time.sleep(self.timeout)\n        except Exception:\n            GlobalDebuggerHolder.global_dbg.finish_debugging_session()\n            if DebugInfoHolder.DEBUG_TRACE_LEVEL >= 0:\n                pydev_log_exception()", "response": "loop and write responses"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef can_be_executed_by(self, thread_id):\n        '''By default, it must be in the same thread to be executed\n        '''\n        return self.thread_id == thread_id or self.thread_id.endswith('|' + thread_id)", "response": "By default it must be in the same thread to be executed\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert request into python variable", "response": "def do_it(self, dbg):\n        ''' Converts request into python variable '''\n        try:\n            xml = StringIO.StringIO()\n            xml.write(\"<xml>\")\n            _typeName, val_dict = pydevd_vars.resolve_compound_variable_fields(\n                dbg, self.thread_id, self.frame_id, self.scope, self.attributes)\n            if val_dict is None:\n                val_dict = {}\n\n            # assume properly ordered if resolver returns 'OrderedDict'\n            # check type as string to support OrderedDict backport for older Python\n            keys = dict_keys(val_dict)\n            if not (_typeName == \"OrderedDict\" or val_dict.__class__.__name__ == \"OrderedDict\" or IS_PY36_OR_GREATER):\n                keys.sort(key=compare_object_attrs_key)\n\n            for k in keys:\n                val = val_dict[k]\n                evaluate_full_value = pydevd_xml.should_evaluate_full_value(val)\n                xml.write(pydevd_xml.var_to_xml(val, k, evaluate_full_value=evaluate_full_value))\n\n            xml.write(\"</xml>\")\n            cmd = dbg.cmd_factory.make_get_variable_message(self.sequence, xml.getvalue())\n            xml.close()\n            dbg.writer.add_command(cmd)\n        except Exception:\n            cmd = dbg.cmd_factory.make_error_message(\n                self.sequence, \"Error resolving variables %s\" % (get_exception_traceback_str(),))\n            dbg.writer.add_command(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating an XML for console output error and more", "response": "def do_it(self, dbg):\n        ''' Create an XML for console output, error and more (true/false)\n        <xml>\n            <output message=output_message></output>\n            <error message=error_message></error>\n            <more>true/false</more>\n        </xml>\n        '''\n        try:\n            frame = dbg.find_frame(self.thread_id, self.frame_id)\n            if frame is not None:\n                console_message = pydevd_console.execute_console_command(\n                    frame, self.thread_id, self.frame_id, self.line, self.buffer_output)\n\n                cmd = dbg.cmd_factory.make_send_console_message(self.sequence, console_message.to_xml())\n            else:\n                from _pydevd_bundle.pydevd_console import ConsoleMessage\n                console_message = ConsoleMessage()\n                console_message.add_console_message(\n                    pydevd_console.CONSOLE_ERROR,\n                    \"Select the valid frame in the debug view (thread: %s, frame: %s invalid)\" % (self.thread_id, self.frame_id),\n                )\n                cmd = dbg.cmd_factory.make_error_message(self.sequence, console_message.to_xml())\n        except:\n            exc = get_exception_traceback_str()\n            cmd = dbg.cmd_factory.make_error_message(self.sequence, \"Error evaluating expression \" + exc)\n        dbg.writer.add_command(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget completions and write back to the client", "response": "def do_it(self, dbg):\n        ''' Get completions and write back to the client\n        '''\n        try:\n            frame = dbg.find_frame(self.thread_id, self.frame_id)\n            completions_xml = pydevd_console.get_completions(frame, self.act_tok)\n            cmd = dbg.cmd_factory.make_send_console_message(self.sequence, completions_xml)\n            dbg.writer.add_command(cmd)\n        except:\n            exc = get_exception_traceback_str()\n            cmd = dbg.cmd_factory.make_error_message(self.sequence, \"Error in fetching completions\" + exc)\n            dbg.writer.add_command(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting request into python variable", "response": "def do_it(self, dbg):\n        ''' Converts request into python variable '''\n        try:\n            try:\n                # don't trace new threads created by console command\n                disable_trace_thread_modules()\n\n                result = pydevconsole.console_exec(self.thread_id, self.frame_id, self.expression, dbg)\n                xml = \"<xml>\"\n                xml += pydevd_xml.var_to_xml(result, \"\")\n                xml += \"</xml>\"\n                cmd = dbg.cmd_factory.make_evaluate_expression_message(self.sequence, xml)\n                dbg.writer.add_command(cmd)\n            except:\n                exc = get_exception_traceback_str()\n                sys.stderr.write('%s\\n' % (exc,))\n                cmd = dbg.cmd_factory.make_error_message(self.sequence, \"Error evaluating console expression \" + exc)\n                dbg.writer.add_command(cmd)\n        finally:\n            enable_trace_thread_modules()\n\n            sys.stderr.flush()\n            sys.stdout.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_it(self, dbg):\n        '''Starts a thread that will load values asynchronously'''\n        try:\n            var_objects = []\n            for variable in self.vars:\n                variable = variable.strip()\n                if len(variable) > 0:\n                    if '\\t' in variable:  # there are attributes beyond scope\n                        scope, attrs = variable.split('\\t', 1)\n                        name = attrs[0]\n                    else:\n                        scope, attrs = (variable, None)\n                        name = scope\n                    var_obj = pydevd_vars.getVariable(dbg, self.thread_id, self.frame_id, scope, attrs)\n                    var_objects.append((var_obj, name))\n\n            t = GetValueAsyncThreadDebug(dbg, self.sequence, var_objects)\n            t.start()\n        except:\n            exc = get_exception_traceback_str()\n            sys.stderr.write('%s\\n' % (exc,))\n            cmd = dbg.cmd_factory.make_error_message(self.sequence, \"Error evaluating variable %s \" % exc)\n            dbg.writer.add_command(cmd)", "response": "Starts a thread that will load values asynchronously"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef RaiseIfLastError(result, func = None, arguments = ()):\n    code = GetLastError()\n    if code != ERROR_SUCCESS:\n        raise ctypes.WinError(code)\n    return result", "response": "Raises an exception if the last error code is not C { ERROR_SUCCESS }."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nclosing the Win32 handle.", "response": "def close(self):\n        \"\"\"\n        Closes the Win32 handle.\n        \"\"\"\n        if self.bOwnership and self.value not in (None, INVALID_HANDLE_VALUE):\n            if Handle.__bLeakDetection:     # XXX DEBUG\n                print(\"CLOSE HANDLE (%d) %r\" % (self.value, self))\n            try:\n                self._close()\n            finally:\n                self._value = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wait(self, dwMilliseconds = None):\n        if self.value is None:\n            raise ValueError(\"Handle is already closed!\")\n        if dwMilliseconds is None:\n            dwMilliseconds = INFINITE\n        r = WaitForSingleObject(self.value, dwMilliseconds)\n        if r != WAIT_OBJECT_0:\n            raise ctypes.WinError(r)", "response": "Wait for the Win32 object to be signaled."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_fixer(self, fixer):\n        self.fixers.append(fixer)\n        tree = reduce_tree(fixer.pattern_tree)\n        linear = tree.get_linear_subpattern()\n        match_nodes = self.add(linear, start=self.root)\n        for match_node in match_nodes:\n            match_node.fixers.append(fixer)", "response": "Adds a fixer to the matcher."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add(self, pattern, start):\n        \"Recursively adds a linear pattern to the AC automaton\"\n        #print(\"adding pattern\", pattern, \"to\", start)\n        if not pattern:\n            #print(\"empty pattern\")\n            return [start]\n        if isinstance(pattern[0], tuple):\n            #alternatives\n            #print(\"alternatives\")\n            match_nodes = []\n            for alternative in pattern[0]:\n                #add all alternatives, and add the rest of the pattern\n                #to each end node\n                end_nodes = self.add(alternative, start=start)\n                for end in end_nodes:\n                    match_nodes.extend(self.add(pattern[1:], end))\n            return match_nodes\n        else:\n            #single token\n            #not last\n            if pattern[0] not in start.transition_table:\n                #transition did not exist, create new\n                next_node = BMNode()\n                start.transition_table[pattern[0]] = next_node\n            else:\n                #transition exists already, follow\n                next_node = start.transition_table[pattern[0]]\n\n            if pattern[1:]:\n                end_nodes = self.add(pattern[1:], start=next_node)\n            else:\n                end_nodes = [next_node]\n            return end_nodes", "response": "Recursively adds a linear pattern to the AC automaton"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint a graphviz diagram of the BM automaton ( for debugging )", "response": "def print_ac(self):\n        \"Prints a graphviz diagram of the BM automaton(for debugging)\"\n        print(\"digraph g{\")\n        def print_node(node):\n            for subnode_key in node.transition_table.keys():\n                subnode = node.transition_table[subnode_key]\n                print(\"%d -> %d [label=%s] //%s\" %\n                      (node.id, subnode.id, type_repr(subnode_key), str(subnode.fixers)))\n                if subnode_key == 1:\n                    print(subnode.content)\n                print_node(subnode)\n        print_node(self.root)\n        print(\"}\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn current Python interpreter globals namespace", "response": "def _get_globals():\n    \"\"\"Return current Python interpreter globals namespace\"\"\"\n    if _get_globals_callback is not None:\n        return _get_globals_callback()\n    else:\n        try:\n            from __main__ import __dict__ as namespace\n        except ImportError:\n            try:\n                # The import fails on IronPython\n                import __main__\n                namespace = __main__.__dict__\n            except:\n                namespace\n        shell = namespace.get('__ipythonshell__')\n        if shell is not None and hasattr(shell, 'user_ns'):\n            # IPython 0.12+ kernel\n            return shell.user_ns\n        else:\n            # Python interpreter\n            return namespace\n        return namespace"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun a file and return the next available entry in the system.", "response": "def runfile(filename, args=None, wdir=None, namespace=None):\n    \"\"\"\n    Run filename\n    args: command line arguments (string)\n    wdir: working directory\n    \"\"\"\n    try:\n        if hasattr(filename, 'decode'):\n            filename = filename.decode('utf-8')\n    except (UnicodeError, TypeError):\n        pass\n    global __umd__\n    if os.environ.get(\"PYDEV_UMD_ENABLED\", \"\").lower() == \"true\":\n        if __umd__ is None:\n            namelist = os.environ.get(\"PYDEV_UMD_NAMELIST\", None)\n            if namelist is not None:\n                namelist = namelist.split(',')\n            __umd__ = UserModuleDeleter(namelist=namelist)\n        else:\n            verbose = os.environ.get(\"PYDEV_UMD_VERBOSE\", \"\").lower() == \"true\"\n            __umd__.run(verbose=verbose)\n    if args is not None and not isinstance(args, basestring):\n        raise TypeError(\"expected a character buffer object\")\n    if namespace is None:\n        namespace = _get_globals()\n    if '__file__' in namespace:\n        old_file = namespace['__file__']\n    else:\n        old_file = None\n    namespace['__file__'] = filename\n    sys.argv = [filename]\n    if args is not None:\n        for arg in args.split():\n            sys.argv.append(arg)\n    if wdir is not None:\n        try:\n            if hasattr(wdir, 'decode'):\n                wdir = wdir.decode('utf-8')\n        except (UnicodeError, TypeError):\n            pass\n        os.chdir(wdir)\n    execfile(filename, namespace)\n    sys.argv = ['']\n    if old_file is None:\n        del namespace['__file__']\n    else:\n        namespace['__file__'] = old_file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self, verbose=False):\n        log = []\n        modules_copy = dict(sys.modules)\n        for modname, module in modules_copy.items():\n            if modname == 'aaaaa':\n                print(modname, module)\n                print(self.previous_modules)\n            if modname not in self.previous_modules:\n                modpath = getattr(module, '__file__', None)\n                if modpath is None:\n                    # *module* is a C module that is statically linked into the\n                    # interpreter. There is no way to know its path, so we\n                    # choose to ignore it.\n                    continue\n                if not self.is_module_blacklisted(modname, modpath):\n                    log.append(modname)\n                    del sys.modules[modname]\n        if verbose and log:\n            print(\"\\x1b[4;33m%s\\x1b[24m%s\\x1b[0m\" % (\"UMD has deleted\",\n                                                     \": \" + \", \".join(log)))", "response": "This function is called by the interpreter when the user has deleted the user modules."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the path to the standard lib for the current path installation.", "response": "def get_stdlib_path():\n    \"\"\"Returns the path to the standard lib for the current path installation.\n\n    This function can be dropped and \"sysconfig.get_paths()\" used directly once Python 2.6 support is dropped.\n    \"\"\"\n    if sys.version_info >= (2, 7):\n        import sysconfig\n        return sysconfig.get_paths()['stdlib']\n    else:\n        return os.path.join(sys.prefix, 'lib')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn if the given path exists and also matches the case on Windows.", "response": "def exists_case_sensitive(path):\n    \"\"\"\n    Returns if the given path exists and also matches the case on Windows.\n\n    When finding files that can be imported, it is important for the cases to match because while\n    file os.path.exists(\"module.py\") and os.path.exists(\"MODULE.py\") both return True on Windows, Python\n    can only import using the case of the real file.\n    \"\"\"\n    result = os.path.exists(path)\n    if sys.platform.startswith('win') and result:\n        directory, basename = os.path.split(path)\n        result = basename in os.listdir(directory)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstrip comments that exist at the top of the given lines", "response": "def _strip_top_comments(lines):\n        \"\"\"Strips # comments that exist at the top of the given lines\"\"\"\n        lines = copy.copy(lines)\n        while lines and lines[0].startswith(\"#\"):\n            lines = lines[1:]\n        return \"\\n\".join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntry to place a module in sys. path.", "response": "def place_module(self, module_name):\n        \"\"\"Tries to determine if a module is a python std import, third party import, or project code:\n\n        if it can't determine - it assumes it is project code\n\n        \"\"\"\n        for forced_separate in self.config['forced_separate']:\n            # Ensure all forced_separate patterns will match to end of string\n            path_glob = forced_separate\n            if not forced_separate.endswith('*'):\n                path_glob = '%s*' % forced_separate\n\n            if fnmatch(module_name, path_glob) or fnmatch(module_name, '.' + path_glob):\n                return forced_separate\n\n        if module_name.startswith(\".\"):\n            return self.sections.LOCALFOLDER\n\n        # Try to find most specific placement instruction match (if any)\n        parts = module_name.split('.')\n        module_names_to_check = ['.'.join(parts[:first_k]) for first_k in range(len(parts), 0, -1)]\n        for module_name_to_check in module_names_to_check:\n            for pattern, placement in self.known_patterns:\n                if pattern.match(module_name_to_check):\n                    return placement\n\n        # Use a copy of sys.path to avoid any unintended modifications\n        # to it - e.g. `+=` used below will change paths in place and\n        # if not copied, consequently sys.path, which will grow unbounded\n        # with duplicates on every call to this method.\n        paths = list(sys.path)\n        virtual_env = self.config.get('virtual_env') or os.environ.get('VIRTUAL_ENV')\n        virtual_env_src = False\n        if virtual_env:\n            paths += [path for path in glob('{0}/lib/python*/site-packages'.format(virtual_env))\n                      if path not in paths]\n            paths += [path for path in glob('{0}/src/*'.format(virtual_env)) if os.path.isdir(path)]\n            virtual_env_src = '{0}/src/'.format(virtual_env)\n\n        # handle case-insensitive paths on windows\n        stdlib_lib_prefix = os.path.normcase(get_stdlib_path())\n\n        for prefix in paths:\n            module_path = \"/\".join((prefix, module_name.replace(\".\", \"/\")))\n            package_path = \"/\".join((prefix, module_name.split(\".\")[0]))\n            is_module = (exists_case_sensitive(module_path + \".py\") or\n                         exists_case_sensitive(module_path + \".so\"))\n            is_package = exists_case_sensitive(package_path) and os.path.isdir(package_path)\n            if is_module or is_package:\n                if ('site-packages' in prefix or 'dist-packages' in prefix or\n                        (virtual_env and virtual_env_src in prefix)):\n                    return self.sections.THIRDPARTY\n                elif os.path.normcase(prefix).startswith(stdlib_lib_prefix):\n                    return self.sections.STDLIB\n                else:\n                    return self.config['default_section']\n\n        return self.config['default_section']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding comments to the string", "response": "def _add_comments(self, comments, original_string=\"\"):\n        \"\"\"\n            Returns a string with comments added\n        \"\"\"\n        return comments and \"{0}  # {1}\".format(self._strip_comments(original_string)[0],\n                                                \"; \".join(comments)) or original_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _strip_comments(line, comments=None):\n        if comments is None:\n            comments = []\n\n        new_comments = False\n        comment_start = line.find(\"#\")\n        if comment_start != -1:\n            comments.append(line[comment_start + 1:].strip())\n            new_comments = True\n            line = line[:comment_start]\n\n        return line, comments, new_comments", "response": "Removes comments from import line."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef settrace(\n    host=None,\n    stdoutToServer=False,\n    stderrToServer=False,\n    port=5678,\n    suspend=True,\n    trace_only_current_thread=False,\n    overwrite_prev_trace=False,\n    patch_multiprocessing=False,\n    stop_at_frame=None,\n    ):\n    '''Sets the tracing function with the pydev debug function and initializes needed facilities.\n\n    @param host: the user may specify another host, if the debug server is not in the same machine (default is the local\n        host)\n\n    @param stdoutToServer: when this is true, the stdout is passed to the debug server\n\n    @param stderrToServer: when this is true, the stderr is passed to the debug server\n        so that they are printed in its console and not in this process console.\n\n    @param port: specifies which port to use for communicating with the server (note that the server must be started\n        in the same port). @note: currently it's hard-coded at 5678 in the client\n\n    @param suspend: whether a breakpoint should be emulated as soon as this function is called.\n\n    @param trace_only_current_thread: determines if only the current thread will be traced or all current and future\n        threads will also have the tracing enabled.\n\n    @param overwrite_prev_trace: deprecated\n\n    @param patch_multiprocessing: if True we'll patch the functions which create new processes so that launched\n        processes are debugged.\n\n    @param stop_at_frame: if passed it'll stop at the given frame, otherwise it'll stop in the function which\n        called this method.\n    '''\n    _set_trace_lock.acquire()\n    try:\n        _locked_settrace(\n            host,\n            stdoutToServer,\n            stderrToServer,\n            port,\n            suspend,\n            trace_only_current_thread,\n            patch_multiprocessing,\n            stop_at_frame,\n        )\n    finally:\n        _set_trace_lock.release()", "response": "Sets the tracing function with the pydev debug function and initializes needed facilities."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the current debugger environment to be used for debugging.", "response": "def settrace_forked():\n    '''\n    When creating a fork from a process in the debugger, we need to reset the whole debugger environment!\n    '''\n    from _pydevd_bundle.pydevd_constants import GlobalDebuggerHolder\n    GlobalDebuggerHolder.global_dbg = None\n    threading.current_thread().additional_info = None\n\n    from _pydevd_frame_eval.pydevd_frame_eval_main import clear_thread_local_info\n    host, port = dispatch()\n\n    import pydevd_tracing\n    pydevd_tracing.restore_sys_set_trace_func()\n\n    if port is not None:\n        global connected\n        connected = False\n        global forked\n        forked = True\n\n        custom_frames_container_init()\n\n        if clear_thread_local_info is not None:\n            clear_thread_local_info()\n\n        settrace(\n                host,\n                port=port,\n                suspend=False,\n                trace_only_current_thread=False,\n                overwrite_prev_trace=True,\n                patch_multiprocessing=True,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the file type from the given absolute path.", "response": "def get_file_type(self, abs_real_path_and_basename, _cache_file_type=_CACHE_FILE_TYPE):\n        '''\n        :param abs_real_path_and_basename:\n            The result from get_abs_path_real_path_and_base_from_file or\n            get_abs_path_real_path_and_base_from_frame.\n\n        :return\n            _pydevd_bundle.pydevd_dont_trace_files.PYDEV_FILE:\n                If it's a file internal to the debugger which shouldn't be\n                traced nor shown to the user.\n\n            _pydevd_bundle.pydevd_dont_trace_files.LIB_FILE:\n                If it's a file in a library which shouldn't be traced.\n\n            None:\n                If it's a regular user file which should be traced.\n        '''\n        try:\n            return _cache_file_type[abs_real_path_and_basename[0]]\n        except:\n            file_type = self._internal_get_file_type(abs_real_path_and_basename)\n            if file_type is None:\n                file_type = PYDEV_FILE if self.dont_trace_external_files(abs_real_path_and_basename[0]) else None\n            _cache_file_type[abs_real_path_and_basename[0]] = file_type\n            return file_type"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef enable_tracing(self, thread_trace_func=None):\n        '''\n        Enables tracing.\n\n        If in regular mode (tracing), will set the tracing function to the tracing\n        function for this thread -- by default it's `PyDB.trace_dispatch`, but after\n        `PyDB.enable_tracing` is called with a `thread_trace_func`, the given function will\n        be the default for the given thread.\n        '''\n        if self.frame_eval_func is not None:\n            self.frame_eval_func()\n            pydevd_tracing.SetTrace(self.dummy_trace_dispatch)\n            return\n\n        if thread_trace_func is None:\n            thread_trace_func = self.get_thread_local_trace_func()\n        else:\n            self._local_thread_trace_func.thread_trace_func = thread_trace_func\n\n        pydevd_tracing.SetTrace(thread_trace_func)", "response": "Enables tracing for the current thread."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling when the breakpoints have changed.", "response": "def on_breakpoints_changed(self, removed=False):\n        '''\n        When breakpoints change, we have to re-evaluate all the assumptions we've made so far.\n        '''\n        if not self.ready_to_run:\n            # No need to do anything if we're still not running.\n            return\n\n        self.mtime += 1\n        if not removed:\n            # When removing breakpoints we can leave tracing as was, but if a breakpoint was added\n            # we have to reset the tracing for the existing functions to be re-evaluated.\n            self.set_tracing_for_untraced_contexts()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef in_project_scope(self, filename):\n        '''\n        Note: in general this method should not be used (apply_files_filter should be used\n        in most cases as it also handles the project scope check).\n        '''\n        try:\n            return self._in_project_scope_cache[filename]\n        except KeyError:\n            cache = self._in_project_scope_cache\n            abs_real_path_and_basename = get_abs_path_real_path_and_base_from_file(filename)\n            # pydevd files are never considered to be in the project scope.\n            if self.get_file_type(abs_real_path_and_basename) == self.PYDEV_FILE:\n                cache[filename] = False\n            else:\n                cache[filename] = self._files_filtering.in_project_roots(filename)\n\n            return cache[filename]", "response": "Returns True if the file is in the project scope."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if the file should be excluded False if it should be included None if no rule matched the given file.", "response": "def _exclude_by_filter(self, frame, filename):\n        '''\n        :param str filename:\n            The filename to filter.\n\n        :return: True if it should be excluded, False if it should be included and None\n            if no rule matched the given file.\n        '''\n        try:\n            return self._exclude_by_filter_cache[filename]\n        except KeyError:\n            cache = self._exclude_by_filter_cache\n\n            abs_real_path_and_basename = get_abs_path_real_path_and_base_from_file(filename)\n            # pydevd files are always filtered out\n            if self.get_file_type(abs_real_path_and_basename) == self.PYDEV_FILE:\n                cache[filename] = True\n            else:\n                module_name = None\n                if self._files_filtering.require_module:\n                    module_name = frame.f_globals.get('__name__')\n                cache[filename] = self._files_filtering.exclude_by_filter(filename, module_name)\n\n            return cache[filename]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef apply_files_filter(self, frame, filename, force_check_project_scope):\n        '''\n        Should only be called if `self.is_files_filter_enabled == True`.\n\n        Note that it covers both the filter by specific paths includes/excludes as well\n        as the check which filters out libraries if not in the project scope.\n\n        :param force_check_project_scope:\n            Check that the file is in the project scope even if the global setting\n            is off.\n\n        :return bool:\n            True if it should be excluded when stepping and False if it should be\n            included.\n        '''\n        cache_key = (frame.f_code.co_firstlineno, frame.f_code.co_name, filename, force_check_project_scope)\n        try:\n            return self._apply_filter_cache[cache_key]\n        except KeyError:\n            if self.plugin is not None and (self.has_plugin_line_breaks or self.has_plugin_exception_breaks):\n                # If it's explicitly needed by some plugin, we can't skip it.\n                if not self.plugin.can_skip(self, frame):\n                    # print('include (include by plugins): %s' % filename)\n                    self._apply_filter_cache[cache_key] = False\n                    return False\n\n            if self._exclude_filters_enabled:\n                exclude_by_filter = self._exclude_by_filter(frame, filename)\n                if exclude_by_filter is not None:\n                    if exclude_by_filter:\n                        # ignore files matching stepping filters\n                        # print('exclude (filtered out): %s' % filename)\n                        self._apply_filter_cache[cache_key] = True\n                        return True\n                    else:\n                        # print('include (explicitly included): %s' % filename)\n                        self._apply_filter_cache[cache_key] = False\n                        return False\n\n            if (self._is_libraries_filter_enabled or force_check_project_scope) and not self.in_project_scope(filename):\n                # print('exclude (not on project): %s' % filename)\n                # ignore library files while stepping\n                self._apply_filter_cache[cache_key] = True\n                return True\n\n            # print('include (on project): %s' % filename)\n            self._apply_filter_cache[cache_key] = False\n            return False", "response": "Returns True if the file should be included False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_internal_queue(self, thread_id):\n        if thread_id.startswith('__frame__'):\n            thread_id = thread_id[thread_id.rfind('|') + 1:]\n        return self._cmd_queue[thread_id]", "response": "returns internal command queue for a given thread"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npost an internal command to the specified thread", "response": "def post_internal_command(self, int_cmd, thread_id):\n        \"\"\" if thread_id is *, post to the '*' queue\"\"\"\n        queue = self.get_internal_queue(thread_id)\n        queue.put(int_cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nnotify thread that thread is not alive.", "response": "def notify_thread_not_alive(self, thread_id, use_lock=True):\n        \"\"\" if thread is not alive, cancel trace_dispatch processing \"\"\"\n        if self.writer is None:\n            return\n\n        with self._lock_running_thread_ids if use_lock else NULL:\n            if not self._enable_thread_notifications:\n                return\n\n            thread = self._running_thread_ids.pop(thread_id, None)\n            if thread is None:\n                return\n\n            was_notified = thread.additional_info.pydev_notify_kill\n            if not was_notified:\n                thread.additional_info.pydev_notify_kill = True\n\n        self.writer.add_command(self.cmd_factory.make_thread_killed_message(thread_id))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_internal_commands(self):\n        '''This function processes internal commands\n        '''\n        with self._main_lock:\n            self.check_output_redirect()\n\n            program_threads_alive = {}\n            all_threads = threadingEnumerate()\n            program_threads_dead = []\n            with self._lock_running_thread_ids:\n                reset_cache = not self._running_thread_ids\n\n                for t in all_threads:\n                    if getattr(t, 'is_pydev_daemon_thread', False):\n                        pass  # I.e.: skip the DummyThreads created from pydev daemon threads\n                    elif isinstance(t, PyDBDaemonThread):\n                        pydev_log.error_once('Error in debugger: Found PyDBDaemonThread not marked with is_pydev_daemon_thread=True.')\n\n                    elif is_thread_alive(t):\n                        if reset_cache:\n                            # Fix multiprocessing debug with breakpoints in both main and child processes\n                            # (https://youtrack.jetbrains.com/issue/PY-17092) When the new process is created, the main\n                            # thread in the new process already has the attribute 'pydevd_id', so the new thread doesn't\n                            # get new id with its process number and the debugger loses access to both threads.\n                            # Therefore we should update thread_id for every main thread in the new process.\n                            clear_cached_thread_id(t)\n\n                        thread_id = get_thread_id(t)\n                        program_threads_alive[thread_id] = t\n\n                        self.notify_thread_created(thread_id, t, use_lock=False)\n\n                # Compute and notify about threads which are no longer alive.\n                thread_ids = list(self._running_thread_ids.keys())\n                for thread_id in thread_ids:\n                    if thread_id not in program_threads_alive:\n                        program_threads_dead.append(thread_id)\n\n                for thread_id in program_threads_dead:\n                    self.notify_thread_not_alive(thread_id, use_lock=False)\n\n            # Without self._lock_running_thread_ids\n            if len(program_threads_alive) == 0:\n                self.finish_debugging_session()\n                for t in all_threads:\n                    if hasattr(t, 'do_kill_pydev_thread'):\n                        t.do_kill_pydev_thread()\n            else:\n                # Actually process the commands now (make sure we don't have a lock for _lock_running_thread_ids\n                # acquired at this point as it could lead to a deadlock if some command evaluated tried to\n                # create a thread and wait for it -- which would try to notify about it getting that lock).\n                curr_thread_id = get_current_thread_id(threadingCurrentThread())\n\n                for thread_id in (curr_thread_id, '*'):\n                    queue = self.get_internal_queue(thread_id)\n\n                    # some commands must be processed by the thread itself... if that's the case,\n                    # we will re-add the commands to the queue after executing.\n                    cmds_to_add_back = []\n\n                    try:\n                        while True:\n                            int_cmd = queue.get(False)\n\n                            if not self.mpl_hooks_in_debug_console and isinstance(int_cmd, InternalConsoleExec):\n                                # add import hooks for matplotlib patches if only debug console was started\n                                try:\n                                    self.init_matplotlib_in_debug_console()\n                                    self.mpl_in_use = True\n                                except:\n                                    pydev_log.debug(\"Matplotlib support in debug console failed\", traceback.format_exc())\n                                self.mpl_hooks_in_debug_console = True\n\n                            if int_cmd.can_be_executed_by(curr_thread_id):\n                                pydev_log.verbose(\"processing internal command \", int_cmd)\n                                int_cmd.do_it(self)\n                            else:\n                                pydev_log.verbose(\"NOT processing internal command \", int_cmd)\n                                cmds_to_add_back.append(int_cmd)\n\n                    except _queue.Empty:  # @UndefinedVariable\n                        # this is how we exit\n                        for int_cmd in cmds_to_add_back:\n                            queue.put(int_cmd)", "response": "This function processes internal commands."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the state of a thread to suspend.", "response": "def set_suspend(self, thread, stop_reason, suspend_other_threads=False, is_pause=False):\n        '''\n        :param thread:\n            The thread which should be suspended.\n\n        :param stop_reason:\n            Reason why the thread was suspended.\n\n        :param suspend_other_threads:\n            Whether to force other threads to be suspended (i.e.: when hitting a breakpoint\n            with a suspend all threads policy).\n\n        :param is_pause:\n            If this is a pause to suspend all threads, any thread can be considered as the 'main'\n            thread paused.\n        '''\n        self._threads_suspended_single_notification.increment_suspend_time()\n        if is_pause:\n            self._threads_suspended_single_notification.on_pause()\n\n        info = self._mark_suspend(thread, stop_reason)\n\n        if is_pause:\n            # Must set tracing after setting the state to suspend.\n            frame = info.get_topmost_frame(thread)\n            if frame is not None:\n                try:\n                    self.set_trace_for_frame_and_parents(frame)\n                finally:\n                    frame = None\n\n        # If conditional breakpoint raises any exception during evaluation send the details to the client.\n        if stop_reason == CMD_SET_BREAK and info.conditional_breakpoint_exception is not None:\n            conditional_breakpoint_exception_tuple = info.conditional_breakpoint_exception\n            info.conditional_breakpoint_exception = None\n            self._send_breakpoint_condition_exception(thread, conditional_breakpoint_exception_tuple)\n\n        if not suspend_other_threads and self.multi_threads_single_notification:\n            # In the mode which gives a single notification when all threads are\n            # stopped, stop all threads whenever a set_suspend is issued.\n            suspend_other_threads = True\n\n        if suspend_other_threads:\n            # Suspend all other threads.\n            all_threads = pydevd_utils.get_non_pydevd_threads()\n            for t in all_threads:\n                if getattr(t, 'pydev_do_not_trace', None):\n                    pass  # skip some other threads, i.e. ipython history saving thread from debug console\n                else:\n                    if t is thread:\n                        continue\n                    info = self._mark_suspend(t, CMD_THREAD_SUSPEND)\n                    frame = info.get_topmost_frame(t)\n\n                    # Reset the time as in this case this was not the main thread suspended.\n                    if frame is not None:\n                        try:\n                            self.set_trace_for_frame_and_parents(frame)\n                        finally:\n                            frame = None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _send_breakpoint_condition_exception(self, thread, conditional_breakpoint_exception_tuple):\n        thread_id = get_thread_id(thread)\n        # conditional_breakpoint_exception_tuple - should contain 2 values (exception_type, stacktrace)\n        if conditional_breakpoint_exception_tuple and len(conditional_breakpoint_exception_tuple) == 2:\n            exc_type, stacktrace = conditional_breakpoint_exception_tuple\n            int_cmd = InternalGetBreakpointException(thread_id, exc_type, stacktrace)\n            self.post_internal_command(int_cmd, thread_id)", "response": "If conditional breakpoint raises an exception send exception details to java\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend details on the exception which was caught and where we stopped.", "response": "def send_caught_exception_stack(self, thread, arg, curr_frame_id):\n        \"\"\"Sends details on the exception which was caught (and where we stopped) to the java side.\n\n        arg is: exception type, description, traceback object\n        \"\"\"\n        thread_id = get_thread_id(thread)\n        int_cmd = InternalSendCurrExceptionTrace(thread_id, arg, curr_frame_id)\n        self.post_internal_command(int_cmd, thread_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend that some thread has no longer showing an exception trace.", "response": "def send_caught_exception_stack_proceeded(self, thread):\n        \"\"\"Sends that some thread was resumed and is no longer showing an exception trace.\n        \"\"\"\n        thread_id = get_thread_id(thread)\n        int_cmd = InternalSendCurrExceptionTraceProceeded(thread_id)\n        self.post_internal_command(int_cmd, thread_id)\n        self.process_internal_commands()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a message that a new process has been created.", "response": "def send_process_created_message(self):\n        \"\"\"Sends a message that a new process has been created.\n        \"\"\"\n        cmd = self.cmd_factory.make_process_created_message()\n        self.writer.add_command(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_wait_suspend(self, thread, frame, event, arg, is_unhandled_exception=False):  # @UnusedVariable\n        # print('do_wait_suspend %s %s %s %s' % (frame.f_lineno, frame.f_code.co_name, frame.f_code.co_filename, event))\n        self.process_internal_commands()\n\n        thread_id = get_current_thread_id(thread)\n\n        # Send the suspend message\n        message = thread.additional_info.pydev_message\n        suspend_type = thread.additional_info.trace_suspend_type\n        thread.additional_info.trace_suspend_type = 'trace'  # Reset to trace mode for next call.\n        frame_id_to_lineno = {}\n        stop_reason = thread.stop_reason\n        if is_unhandled_exception:\n            # arg must be the exception info (tuple(exc_type, exc, traceback))\n            tb = arg[2]\n            while tb is not None:\n                frame_id_to_lineno[id(tb.tb_frame)] = tb.tb_lineno\n                tb = tb.tb_next\n\n        with self.suspended_frames_manager.track_frames(self) as frames_tracker:\n            frames_tracker.track(thread_id, frame, frame_id_to_lineno)\n            cmd = frames_tracker.create_thread_suspend_command(thread_id, stop_reason, message, suspend_type)\n            self.writer.add_command(cmd)\n\n            with CustomFramesContainer.custom_frames_lock:  # @UndefinedVariable\n                from_this_thread = []\n\n                for frame_custom_thread_id, custom_frame in dict_iter_items(CustomFramesContainer.custom_frames):\n                    if custom_frame.thread_id == thread.ident:\n                        frames_tracker.track(thread_id, custom_frame.frame, frame_id_to_lineno, frame_custom_thread_id=frame_custom_thread_id)\n                        # print('Frame created as thread: %s' % (frame_custom_thread_id,))\n\n                        self.writer.add_command(self.cmd_factory.make_custom_frame_created_message(\n                            frame_custom_thread_id, custom_frame.name))\n\n                        self.writer.add_command(\n                            frames_tracker.create_thread_suspend_command(frame_custom_thread_id, CMD_THREAD_SUSPEND, \"\", suspend_type))\n\n                    from_this_thread.append(frame_custom_thread_id)\n\n            with self._threads_suspended_single_notification.notify_thread_suspended(thread_id, stop_reason):\n                keep_suspended = self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\n        if keep_suspended:\n            # This means that we should pause again after a set next statement.\n            self._threads_suspended_single_notification.increment_suspend_time()\n            self.do_wait_suspend(thread, frame, event, arg, is_unhandled_exception)", "response": "This method is used to wait until the thread state changes to RUN\n       . It will process any outstanding Stepping commands and send them to the writer."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _exec(self, is_module, entry_point_fn, module_name, file, globals, locals):\n        '''\n        This function should have frames tracked by unhandled exceptions (the `_exec` name is important).\n        '''\n        if not is_module:\n            pydev_imports.execfile(file, globals, locals)  # execute the script\n        else:\n            # treat ':' as a separator between module and entry point function\n            # if there is no entry point we run we same as with -m switch. Otherwise we perform\n            # an import and execute the entry point\n            if entry_point_fn:\n                mod = __import__(module_name, level=0, fromlist=[entry_point_fn], globals=globals, locals=locals)\n                func = getattr(mod, entry_point_fn)\n                func()\n            else:\n                # Run with the -m switch\n                import runpy\n                if hasattr(runpy, '_run_module_as_main'):\n                    # Newer versions of Python actually use this when the -m switch is used.\n                    if sys.version_info[:2] <= (2, 6):\n                        runpy._run_module_as_main(module_name, set_argv0=False)\n                    else:\n                        runpy._run_module_as_main(module_name, alter_argv=False)\n                else:\n                    runpy.run_module(module_name)\n        return globals", "response": "Execute the script or function in the specified entry point."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_arch():\n    try:\n        si = GetNativeSystemInfo()\n    except Exception:\n        si = GetSystemInfo()\n    try:\n        return _arch_map[si.id.w.wProcessorArchitecture]\n    except KeyError:\n        return ARCH_UNKNOWN", "response": "Determines the architecture of the current virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetermines if the current process is running in Windows - On - Windows 64 bits.", "response": "def _get_wow64():\n    \"\"\"\n    Determines if the current process is running in Windows-On-Windows 64 bits.\n\n    @rtype:  bool\n    @return: C{True} of the current process is a 32 bit program running in a\n        64 bit version of Windows, C{False} if it's either a 32 bit program\n        in a 32 bit Windows or a 64 bit program in a 64 bit Windows.\n    \"\"\"\n    # Try to determine if the debugger itself is running on WOW64.\n    # On error assume False.\n    if bits == 64:\n        wow64 = False\n    else:\n        try:\n            wow64 = IsWow64Process( GetCurrentProcess() )\n        except Exception:\n            wow64 = False\n    return wow64"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_os(osvi = None):\n    # rough port of http://msdn.microsoft.com/en-us/library/ms724429%28VS.85%29.aspx\n    if not osvi:\n        osvi = GetVersionEx()\n    if osvi.dwPlatformId == VER_PLATFORM_WIN32_NT and osvi.dwMajorVersion > 4:\n        if osvi.dwMajorVersion == 6:\n            if osvi.dwMinorVersion == 0:\n                if osvi.wProductType == VER_NT_WORKSTATION:\n                    if bits == 64 or wow64:\n                        return 'Windows Vista (64 bits)'\n                    return 'Windows Vista'\n                else:\n                    if bits == 64 or wow64:\n                        return 'Windows 2008 (64 bits)'\n                    return 'Windows 2008'\n            if osvi.dwMinorVersion == 1:\n                if osvi.wProductType == VER_NT_WORKSTATION:\n                    if bits == 64 or wow64:\n                        return 'Windows 7 (64 bits)'\n                    return 'Windows 7'\n                else:\n                    if bits == 64 or wow64:\n                        return 'Windows 2008 R2 (64 bits)'\n                    return 'Windows 2008 R2'\n        if osvi.dwMajorVersion == 5:\n            if osvi.dwMinorVersion == 2:\n                if GetSystemMetrics(SM_SERVERR2):\n                    if bits == 64 or wow64:\n                        return 'Windows 2003 R2 (64 bits)'\n                    return 'Windows 2003 R2'\n                if osvi.wSuiteMask in (VER_SUITE_STORAGE_SERVER, VER_SUITE_WH_SERVER):\n                    if bits == 64 or wow64:\n                        return 'Windows 2003 (64 bits)'\n                    return 'Windows 2003'\n                if osvi.wProductType == VER_NT_WORKSTATION and arch == ARCH_AMD64:\n                    return 'Windows XP (64 bits)'\n                else:\n                    if bits == 64 or wow64:\n                        return 'Windows 2003 (64 bits)'\n                    return 'Windows 2003'\n            if osvi.dwMinorVersion == 1:\n                return 'Windows XP'\n            if osvi.dwMinorVersion == 0:\n                return 'Windows 2000'\n        if osvi.dwMajorVersion == 4:\n            return 'Windows NT'\n    return 'Unknown'", "response": "Returns the current operating system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the NTDDI version number of the current operating system.", "response": "def _get_ntddi(osvi):\n    \"\"\"\n    Determines the current operating system.\n\n    This function allows you to quickly tell apart major OS differences.\n    For more detailed information call L{kernel32.GetVersionEx} instead.\n\n    @note:\n        Wine reports itself as Windows XP 32 bits\n        (even if the Linux host is 64 bits).\n        ReactOS may report itself as Windows 2000 or Windows XP,\n        depending on the version of ReactOS.\n\n    @type  osvi: L{OSVERSIONINFOEXA}\n    @param osvi: Optional. The return value from L{kernel32.GetVersionEx}.\n\n    @rtype:  int\n    @return: NTDDI version number.\n    \"\"\"\n    if not osvi:\n        osvi = GetVersionEx()\n    ntddi = 0\n    ntddi += (osvi.dwMajorVersion & 0xFF)    << 24\n    ntddi += (osvi.dwMinorVersion & 0xFF)    << 16\n    ntddi += (osvi.wServicePackMajor & 0xFF) << 8\n    ntddi += (osvi.wServicePackMinor & 0xFF)\n    return ntddi"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _pydevd_log(level, msg, *args):\n    '''\n    Levels are:\n\n    0 most serious warnings/errors (always printed)\n    1 warnings/significant events\n    2 informational trace\n    3 verbose mode\n    '''\n    if level <= DebugInfoHolder.DEBUG_TRACE_LEVEL:\n        # yes, we can have errors printing if the console of the program has been finished (and we're still trying to print something)\n        try:\n            try:\n                if args:\n                    msg = msg % args\n            except:\n                msg = '%s - %s' % (msg, args)\n            DebugInfoHolder.DEBUG_STREAM.write('%s\\n' % (msg,))\n            DebugInfoHolder.DEBUG_STREAM.flush()\n        except:\n            pass\n        return True", "response": "Log a message to the debug stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef in_project_roots(self, filename):\n        '''\n        Note: don't call directly. Use PyDb.in_project_scope (no caching here).\n        '''\n        project_roots = self._get_project_roots()\n        if not filename.endswith('>'):\n            filename = self._normpath(filename)\n\n        found_in_project = []\n        for root in project_roots:\n            if root and filename.startswith(root):\n                found_in_project.append(root)\n\n        found_in_library = []\n        library_roots = self._get_library_roots()\n        for root in library_roots:\n            if root and filename.startswith(root):\n                found_in_library.append(root)\n\n        if not project_roots:\n            # If we have no project roots configured, consider it being in the project\n            # roots if it's not found in site-packages (because we have defaults for those\n            # and not the other way around).\n            if filename.endswith('>'):\n                # This is a dummy filename that is usually used for eval or exec. Assume\n                # that it is user code, with one exception: <frozen ...> is used in the\n                # standard library.\n                in_project = not filename.startswith('<frozen ')\n            else:\n                in_project = not found_in_library\n        else:\n            in_project = False\n            if found_in_project:\n                if not found_in_library:\n                    in_project = True\n                else:\n                    # Found in both, let's see which one has the bigger path matched.\n                    if max(len(x) for x in found_in_project) > max(len(x) for x in found_in_library):\n                        in_project = True\n\n        return in_project", "response": "Return True if the file is in the project and False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if the file should be excluded False if it should be included and None if no rule matched the given file.", "response": "def exclude_by_filter(self, filename, module_name):\n        '''\n        :return: True if it should be excluded, False if it should be included and None\n            if no rule matched the given file.\n        '''\n        for exclude_filter in self._exclude_filters:  # : :type exclude_filter: ExcludeFilter\n            if exclude_filter.is_path:\n                if glob_matches_path(filename, exclude_filter.name):\n                    if exclude_filter.exclude:\n                        pydev_log.debug(\"File %s ignored by filter %s\" % (filename, exclude_filter.name))\n                    return exclude_filter.exclude\n            else:\n                # Module filter.\n                if exclude_filter.name == module_name or module_name.startswith(exclude_filter.name + '.'):\n                    return exclude_filter.exclude\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the exclude_filters attribute of the object.", "response": "def set_exclude_filters(self, exclude_filters):\n        '''\n        :param list(ExcludeFilter) exclude_filters:\n        '''\n        self._exclude_filters = exclude_filters\n        self.require_module = False\n        for exclude_filter in exclude_filters:\n            if not exclude_filter.is_path:\n                self.require_module = True\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_string_buffer(init, size=None):\n    if isinstance(init, (str, unicode)):\n        if size is None:\n            size = len(init) + 1\n        buftype = c_char * size\n        buf = buftype()\n        buf.value = init\n        return buf\n    elif isinstance(init, (int, long)):\n        buftype = c_char * init\n        buf = buftype()\n        return buf\n    raise TypeError, init", "response": "create_string_buffer - create a character array\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef CFUNCTYPE(restype, *argtypes):\n    try:\n        return _c_functype_cache[(restype, argtypes)]\n    except KeyError:\n        class CFunctionType(_CFuncPtr):\n            _argtypes_ = argtypes\n            _restype_ = restype\n            _flags_ = _FUNCFLAG_CDECL\n        _c_functype_cache[(restype, argtypes)] = CFunctionType\n        return CFunctionType", "response": "CFUNCTYPE returns a C function type that can be used to create a C function from a C function prototype."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfetch extra data from the event object.", "response": "def fetch_extra_data(self, event, takeMemorySnapshot = 0):\n        \"\"\"\n        Fetch extra data from the L{Event} object.\n\n        @note: Since this method may take a little longer to run, it's best to\n            call it only after you've determined the crash is interesting and\n            you want to save it.\n\n        @type  event: L{Event}\n        @param event: Event object for crash.\n\n        @type  takeMemorySnapshot: int\n        @param takeMemorySnapshot:\n            Memory snapshot behavior:\n             - C{0} to take no memory information (default).\n             - C{1} to take only the memory map.\n               See L{Process.get_memory_map}.\n             - C{2} to take a full memory snapshot.\n               See L{Process.take_memory_snapshot}.\n             - C{3} to take a live memory snapshot.\n               See L{Process.generate_memory_snapshot}.\n        \"\"\"\n\n        # Get the process and thread, we'll use them below.\n        process = event.get_process()\n        thread  = event.get_thread()\n\n        # Get the command line for the target process.\n        try:\n            self.commandLine = process.get_command_line()\n        except Exception:\n            e = sys.exc_info()[1]\n            warnings.warn(\"Cannot get command line, reason: %s\" % str(e),\n                          CrashWarning)\n\n        # Get the environment variables for the target process.\n        try:\n            self.environmentData = process.get_environment_data()\n            self.environment     = process.parse_environment_data(\n                                                        self.environmentData)\n        except Exception:\n            e = sys.exc_info()[1]\n            warnings.warn(\"Cannot get environment, reason: %s\" % str(e),\n                          CrashWarning)\n\n        # Data pointed to by registers.\n        self.registersPeek = thread.peek_pointers_in_registers()\n\n        # Module where execution is taking place.\n        aModule = process.get_module_at_address(self.pc)\n        if aModule is not None:\n            self.modFileName = aModule.get_filename()\n            self.lpBaseOfDll = aModule.get_base()\n\n        # Contents of the stack frame.\n        try:\n            self.stackRange = thread.get_stack_range()\n        except Exception:\n            e = sys.exc_info()[1]\n            warnings.warn(\"Cannot get stack range, reason: %s\" % str(e),\n                          CrashWarning)\n        try:\n            self.stackFrame = thread.get_stack_frame()\n            stackFrame = self.stackFrame\n        except Exception:\n            self.stackFrame = thread.peek_stack_data()\n            stackFrame = self.stackFrame[:64]\n        if stackFrame:\n            self.stackPeek = process.peek_pointers_in_data(stackFrame)\n\n        # Code being executed.\n        self.faultCode   = thread.peek_code_bytes()\n        try:\n            self.faultDisasm = thread.disassemble_around_pc(32)\n        except Exception:\n            e = sys.exc_info()[1]\n            warnings.warn(\"Cannot disassemble, reason: %s\" % str(e),\n                          CrashWarning)\n\n        # For memory related exceptions, get the memory contents\n        # of the location that caused the exception to be raised.\n        if self.eventCode == win32.EXCEPTION_DEBUG_EVENT:\n            if self.pc != self.exceptionAddress and self.exceptionCode in (\n                        win32.EXCEPTION_ACCESS_VIOLATION,\n                        win32.EXCEPTION_ARRAY_BOUNDS_EXCEEDED,\n                        win32.EXCEPTION_DATATYPE_MISALIGNMENT,\n                        win32.EXCEPTION_IN_PAGE_ERROR,\n                        win32.EXCEPTION_STACK_OVERFLOW,\n                        win32.EXCEPTION_GUARD_PAGE,\n                        ):\n                self.faultMem = process.peek(self.exceptionAddress, 64)\n                if self.faultMem:\n                    self.faultPeek = process.peek_pointers_in_data(\n                                                                 self.faultMem)\n\n        # TODO: maybe add names and versions of DLLs and EXE?\n\n        # Take a snapshot of the process memory. Additionally get the\n        # memory contents if requested.\n        if takeMemorySnapshot == 1:\n            self.memoryMap = process.get_memory_map()\n            mappedFilenames = process.get_mapped_filenames(self.memoryMap)\n            for mbi in self.memoryMap:\n                mbi.filename = mappedFilenames.get(mbi.BaseAddress, None)\n                mbi.content  = None\n        elif takeMemorySnapshot == 2:\n            self.memoryMap = process.take_memory_snapshot()\n        elif takeMemorySnapshot == 3:\n            self.memoryMap = process.generate_memory_snapshot()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef isExploitable(self):\n\n        # Terminal rules\n\n        if self.eventCode != win32.EXCEPTION_DEBUG_EVENT:\n            return (\"Not an exception\", \"NotAnException\", \"The event is not an exception.\")\n\n        if self.stackRange and self.pc is not None and self.stackRange[0] <= self.pc < self.stackRange[1]:\n            return (\"Exploitable\", \"StackCodeExecution\", \"Code execution from the stack is considered exploitable.\")\n\n        # This rule is NOT from !exploitable\n        if self.stackRange and self.sp is not None and not (self.stackRange[0] <= self.sp < self.stackRange[1]):\n            return (\"Exploitable\", \"StackPointerCorruption\", \"Stack pointer corruption is considered exploitable.\")\n\n        if self.exceptionCode == win32.EXCEPTION_ILLEGAL_INSTRUCTION:\n            return (\"Exploitable\", \"IllegalInstruction\", \"An illegal instruction exception indicates that the attacker controls execution flow.\")\n\n        if self.exceptionCode == win32.EXCEPTION_PRIV_INSTRUCTION:\n            return (\"Exploitable\", \"PrivilegedInstruction\", \"A privileged instruction exception indicates that the attacker controls execution flow.\")\n\n        if self.exceptionCode == win32.EXCEPTION_GUARD_PAGE:\n            return (\"Exploitable\", \"GuardPage\", \"A guard page violation indicates a stack overflow has occured, and the stack of another thread was reached (possibly the overflow length is not controlled by the attacker).\")\n\n        if self.exceptionCode == win32.STATUS_STACK_BUFFER_OVERRUN:\n            return (\"Exploitable\", \"GSViolation\", \"An overrun of a protected stack buffer has been detected. This is considered exploitable, and must be fixed.\")\n\n        if self.exceptionCode == win32.STATUS_HEAP_CORRUPTION:\n            return (\"Exploitable\", \"HeapCorruption\", \"Heap Corruption has been detected. This is considered exploitable, and must be fixed.\")\n\n        if self.exceptionCode == win32.EXCEPTION_ACCESS_VIOLATION:\n            nearNull      = self.faultAddress is None or MemoryAddresses.align_address_to_page_start(self.faultAddress) == 0\n            controlFlow   = self.__is_control_flow()\n            blockDataMove = self.__is_block_data_move()\n            if self.faultType == win32.EXCEPTION_EXECUTE_FAULT:\n                if nearNull:\n                    return (\"Probably exploitable\", \"DEPViolation\", \"User mode DEP access violations are probably exploitable if near NULL.\")\n                else:\n                    return (\"Exploitable\", \"DEPViolation\", \"User mode DEP access violations are exploitable.\")\n            elif self.faultType == win32.EXCEPTION_WRITE_FAULT:\n                if nearNull:\n                    return (\"Probably exploitable\", \"WriteAV\", \"User mode write access violations that are near NULL are probably exploitable.\")\n                else:\n                    return (\"Exploitable\", \"WriteAV\", \"User mode write access violations that are not near NULL are exploitable.\")\n            elif self.faultType == win32.EXCEPTION_READ_FAULT:\n                if self.faultAddress == self.pc:\n                    if nearNull:\n                        return (\"Probably exploitable\", \"ReadAVonIP\", \"Access violations at the instruction pointer are probably exploitable if near NULL.\")\n                    else:\n                        return (\"Exploitable\", \"ReadAVonIP\", \"Access violations at the instruction pointer are exploitable if not near NULL.\")\n                if controlFlow:\n                    if nearNull:\n                        return (\"Probably exploitable\", \"ReadAVonControlFlow\", \"Access violations near null in control flow instructions are considered probably exploitable.\")\n                    else:\n                        return (\"Exploitable\", \"ReadAVonControlFlow\", \"Access violations not near null in control flow instructions are considered exploitable.\")\n                if blockDataMove:\n                    return (\"Probably exploitable\", \"ReadAVonBlockMove\", \"This is a read access violation in a block data move, and is therefore classified as probably exploitable.\")\n\n                # Rule: Tainted information used to control branch addresses is considered probably exploitable\n                # Rule: Tainted information used to control the target of a later write is probably exploitable\n\n        # Non terminal rules\n\n        # XXX TODO add rule to check if code is in writeable memory (probably exploitable)\n\n        # XXX TODO maybe we should be returning a list of tuples instead?\n\n        result = (\"Unknown\", \"Unknown\", \"Exploitability unknown.\")\n\n        if self.exceptionCode == win32.EXCEPTION_ACCESS_VIOLATION:\n            if self.faultType == win32.EXCEPTION_READ_FAULT:\n                if nearNull:\n                    result = (\"Not likely exploitable\", \"ReadAVNearNull\", \"This is a user mode read access violation near null, and is probably not exploitable.\")\n\n        elif self.exceptionCode == win32.EXCEPTION_INT_DIVIDE_BY_ZERO:\n            result = (\"Not likely exploitable\", \"DivideByZero\", \"This is an integer divide by zero, and is probably not exploitable.\")\n\n        elif self.exceptionCode == win32.EXCEPTION_FLT_DIVIDE_BY_ZERO:\n            result = (\"Not likely exploitable\", \"DivideByZero\", \"This is a floating point divide by zero, and is probably not exploitable.\")\n\n        elif self.exceptionCode in (win32.EXCEPTION_BREAKPOINT, win32.STATUS_WX86_BREAKPOINT):\n            result = (\"Unknown\", \"Breakpoint\", \"While a breakpoint itself is probably not exploitable, it may also be an indication that an attacker is testing a target. In either case breakpoints should not exist in production code.\")\n\n        # Rule: If the stack contains unknown symbols in user mode, call that out\n        # Rule: Tainted information used to control the source of a later block move unknown, but called out explicitly\n        # Rule: Tainted information used as an argument to a function is an unknown risk, but called out explicitly\n        # Rule: Tainted information used to control branch selection is an unknown risk, but called out explicitly\n\n        return result", "response": "Guess how likely the most exploitable version of the current exception is."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a string containing the full log of the current state of the object.", "response": "def fullReport(self, bShowNotes = True):\n        \"\"\"\n        @type  bShowNotes: bool\n        @param bShowNotes: C{True} to show the user notes, C{False} otherwise.\n\n        @rtype:  str\n        @return: Long description of the event.\n        \"\"\"\n        msg  = self.briefReport()\n        msg += '\\n'\n\n        if self.bits == 32:\n            width = 16\n        else:\n            width = 8\n\n        if self.eventCode == win32.EXCEPTION_DEBUG_EVENT:\n            (exploitability, expcode, expdescription) = self.isExploitable()\n            msg += '\\nSecurity risk level: %s\\n' % exploitability\n            msg += '  %s\\n' % expdescription\n\n        if bShowNotes and self.notes:\n            msg += '\\nNotes:\\n'\n            msg += self.notesReport()\n\n        if self.commandLine:\n            msg += '\\nCommand line: %s\\n' % self.commandLine\n\n        if self.environment:\n            msg += '\\nEnvironment:\\n'\n            msg += self.environmentReport()\n\n        if not self.labelPC:\n            base = HexDump.address(self.lpBaseOfDll, self.bits)\n            if self.modFileName:\n                fn   = PathOperations.pathname_to_filename(self.modFileName)\n                msg += '\\nRunning in %s (%s)\\n' % (fn, base)\n            else:\n                msg += '\\nRunning in module at %s\\n' % base\n\n        if self.registers:\n            msg += '\\nRegisters:\\n'\n            msg += CrashDump.dump_registers(self.registers)\n            if self.registersPeek:\n                msg += '\\n'\n                msg += CrashDump.dump_registers_peek(self.registers,\n                                                     self.registersPeek,\n                                                     width = width)\n\n        if self.faultDisasm:\n            msg += '\\nCode disassembly:\\n'\n            msg += CrashDump.dump_code(self.faultDisasm, self.pc,\n                                       bits = self.bits)\n\n        if self.stackTrace:\n            msg += '\\nStack trace:\\n'\n            if self.stackTracePretty:\n                msg += CrashDump.dump_stack_trace_with_labels(\n                                        self.stackTracePretty,\n                                        bits = self.bits)\n            else:\n                msg += CrashDump.dump_stack_trace(self.stackTrace,\n                                                  bits = self.bits)\n\n        if self.stackFrame:\n            if self.stackPeek:\n                msg += '\\nStack pointers:\\n'\n                msg += CrashDump.dump_stack_peek(self.stackPeek, width = width)\n            msg += '\\nStack dump:\\n'\n            msg += HexDump.hexblock(self.stackFrame, self.sp,\n                                    bits = self.bits, width = width)\n\n        if self.faultCode and not self.modFileName:\n            msg += '\\nCode dump:\\n'\n            msg += HexDump.hexblock(self.faultCode, self.pc,\n                                    bits = self.bits, width = width)\n\n        if self.faultMem:\n            if self.faultPeek:\n                msg += '\\nException address pointers:\\n'\n                msg += CrashDump.dump_data_peek(self.faultPeek,\n                                                self.exceptionAddress,\n                                                bits  = self.bits,\n                                                width = width)\n            msg += '\\nException address dump:\\n'\n            msg += HexDump.hexblock(self.faultMem, self.exceptionAddress,\n                                    bits = self.bits, width = width)\n\n        if self.memoryMap:\n            msg += '\\nMemory map:\\n'\n            mappedFileNames = dict()\n            for mbi in self.memoryMap:\n                if hasattr(mbi, 'filename') and mbi.filename:\n                    mappedFileNames[mbi.BaseAddress] = mbi.filename\n            msg += CrashDump.dump_memory_map(self.memoryMap, mappedFileNames,\n                                             bits = self.bits)\n\n        if not msg.endswith('\\n\\n'):\n            if not msg.endswith('\\n'):\n                msg += '\\n'\n            msg += '\\n'\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unmarshall_value(self, value):\n        value = str(value)\n        if self.escapeValues:\n            value = value.decode('hex')\n        if self.compressValues:\n            value = zlib.decompress(value)\n        value = pickle.loads(value)\n        return value", "response": "Unmarshalls a Crash object read from the database."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a new crash to the container.", "response": "def add(self, crash):\n        \"\"\"\n        Adds a new crash to the container.\n        If the crash appears to be already known, it's ignored.\n\n        @see: L{Crash.key}\n\n        @type  crash: L{Crash}\n        @param crash: Crash object to add.\n        \"\"\"\n        if crash not in self:\n            key  = crash.key()\n            skey = self.marshall_key(key)\n            data = self.marshall_value(crash, storeMemoryMap = True)\n            self.__db[skey] = data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, key):\n        skey  = self.marshall_key(key)\n        data  = self.__db[skey]\n        crash = self.unmarshall_value(data)\n        return crash", "response": "Get a crash from the container."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, key):\n        found = self._dao.find(signature=key, limit=1, order=-1)\n        if not found:\n            raise KeyError(key)\n        return found[0]", "response": "Get a crash from the container."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add(self, crash):\n        self.__keys.add( crash.signature )\n        self.__count += 1", "response": "Adds a new crash to the container."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _schedule_callback(prev, next):\n    '''\n    Called when a context is stopped or a new context is made runnable.\n    '''\n    try:\n        if not prev and not next:\n            return\n\n        current_frame = sys._getframe()\n\n        if next:\n            register_tasklet_info(next)\n\n            # Ok, making next runnable: set the tracing facility in it.\n            debugger = get_global_debugger()\n            if debugger is not None:\n                next.trace_function = debugger.get_thread_local_trace_func()\n                frame = next.frame\n                if frame is current_frame:\n                    frame = frame.f_back\n                if hasattr(frame, 'f_trace'):  # Note: can be None (but hasattr should cover for that too).\n                    frame.f_trace = debugger.get_thread_local_trace_func()\n\n            debugger = None\n\n        if prev:\n            register_tasklet_info(prev)\n\n        try:\n            for tasklet_ref, tasklet_info in dict_items(_weak_tasklet_registered_to_info):  # Make sure it's a copy!\n                tasklet = tasklet_ref()\n                if tasklet is None or not tasklet.alive:\n                    # Garbage-collected already!\n                    try:\n                        del _weak_tasklet_registered_to_info[tasklet_ref]\n                    except KeyError:\n                        pass\n                    if tasklet_info.frame_id is not None:\n                        remove_custom_frame(tasklet_info.frame_id)\n                else:\n                    is_running = stackless.get_thread_info(tasklet.thread_id)[1] is tasklet\n                    if tasklet is prev or (tasklet is not next and not is_running):\n                        # the tasklet won't run after this scheduler action:\n                        # - the tasklet is the previous tasklet\n                        # - it is not the next tasklet and it is not an already running tasklet\n                        frame = tasklet.frame\n                        if frame is current_frame:\n                            frame = frame.f_back\n                        if frame is not None:\n                            abs_real_path_and_base = get_abs_path_real_path_and_base_from_frame(frame)\n                            # print >>sys.stderr, \"SchedCB: %r, %d, '%s', '%s'\" % (tasklet, frame.f_lineno, _filename, base)\n                            if debugger.get_file_type(abs_real_path_and_base) is None:\n                                tasklet_info.update_name()\n                                if tasklet_info.frame_id is None:\n                                    tasklet_info.frame_id = add_custom_frame(frame, tasklet_info.tasklet_name, tasklet.thread_id)\n                                else:\n                                    update_custom_frame(tasklet_info.frame_id, frame, tasklet.thread_id, name=tasklet_info.tasklet_name)\n\n                    elif tasklet is next or is_running:\n                        if tasklet_info.frame_id is not None:\n                            # Remove info about stackless suspended when it starts to run.\n                            remove_custom_frame(tasklet_info.frame_id)\n                            tasklet_info.frame_id = None\n\n        finally:\n            tasklet = None\n            tasklet_info = None\n            frame = None\n\n    except:\n        pydev_log.exception()\n\n    if _application_set_schedule_callback is not None:\n        return _application_set_schedule_callback(prev, next)", "response": "Called when a new context is made runnable."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef patch_stackless():\n    '''\n    This function should be called to patch the stackless module so that new tasklets are properly tracked in the\n    debugger.\n    '''\n    global _application_set_schedule_callback\n    _application_set_schedule_callback = stackless.set_schedule_callback(_schedule_callback)\n\n    def set_schedule_callback(callable):\n        global _application_set_schedule_callback\n        old = _application_set_schedule_callback\n        _application_set_schedule_callback = callable\n        return old\n\n    def get_schedule_callback():\n        global _application_set_schedule_callback\n        return _application_set_schedule_callback\n\n    set_schedule_callback.__doc__ = stackless.set_schedule_callback.__doc__\n    if hasattr(stackless, \"get_schedule_callback\"):\n        get_schedule_callback.__doc__ = stackless.get_schedule_callback.__doc__\n    stackless.set_schedule_callback = set_schedule_callback\n    stackless.get_schedule_callback = get_schedule_callback\n\n    if not hasattr(stackless.tasklet, \"trace_function\"):\n        # Older versions of Stackless, released before 2014\n        __call__.__doc__ = stackless.tasklet.__call__.__doc__\n        stackless.tasklet.__call__ = __call__\n\n        setup.__doc__ = stackless.tasklet.setup.__doc__\n        stackless.tasklet.setup = setup\n\n        run.__doc__ = stackless.run.__doc__\n        stackless.run = run", "response": "This function should be called to patch the stackless module so that new tasklets are properly tracked in the debugger."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nattach to an existing process for debugging.", "response": "def attach(self, dwProcessId):\n        \"\"\"\n        Attaches to an existing process for debugging.\n\n        @see: L{detach}, L{execv}, L{execl}\n\n        @type  dwProcessId: int\n        @param dwProcessId: Global ID of a process to attach to.\n\n        @rtype:  L{Process}\n        @return: A new Process object. Normally you don't need to use it now,\n            it's best to interact with the process from the event handler.\n\n        @raise WindowsError: Raises an exception on error.\n            Depending on the circumstances, the debugger may or may not have\n            attached to the target process.\n        \"\"\"\n\n        # Get the Process object from the snapshot,\n        # if missing create a new one.\n        try:\n            aProcess = self.system.get_process(dwProcessId)\n        except KeyError:\n            aProcess = Process(dwProcessId)\n\n        # Warn when mixing 32 and 64 bits.\n        # This also allows the user to stop attaching altogether,\n        # depending on how the warnings are configured.\n        if System.bits != aProcess.get_bits():\n            msg = \"Mixture of 32 and 64 bits is considered experimental.\" \\\n                  \" Use at your own risk!\"\n            warnings.warn(msg, MixedBitsWarning)\n\n        # Attach to the process.\n        win32.DebugActiveProcess(dwProcessId)\n\n        # Add the new PID to the set of debugees.\n        self.__attachedDebugees.add(dwProcessId)\n\n        # Match the system kill-on-exit flag to our own.\n        self.__setSystemKillOnExitMode()\n\n        # If the Process object was not in the snapshot, add it now.\n        if not self.system.has_process(dwProcessId):\n            self.system._add_process(aProcess)\n\n        # Scan the process threads and loaded modules.\n        # This is prefered because the thread and library events do not\n        # properly give some information, like the filename for each module.\n        aProcess.scan_threads()\n        aProcess.scan_modules()\n\n        # Return the Process object, like the execv() and execl() methods.\n        return aProcess"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execv(self, argv, **kwargs):\n        if type(argv) in (str, compat.unicode):\n            raise TypeError(\"Debug.execv expects a list, not a string\")\n        lpCmdLine = self.system.argv_to_cmdline(argv)\n        return self.execl(lpCmdLine, **kwargs)", "response": "This method starts a new process for debugging."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting a command line string and returns a new process ID.", "response": "def execl(self, lpCmdLine, **kwargs):\n        \"\"\"\n        Starts a new process for debugging.\n\n        This method uses a command line string. To use a list of arguments\n        instead, use L{execv}.\n\n        @see: L{attach}, L{detach}\n\n        @type  lpCmdLine: str\n        @param lpCmdLine: Command line string to execute.\n            The first token must be the debugee executable filename.\n            Tokens with spaces must be enclosed in double quotes.\n            Tokens including double quote characters must be escaped with a\n            backslash.\n\n        @type    bBreakOnEntryPoint: bool\n        @keyword bBreakOnEntryPoint: C{True} to automatically set a breakpoint\n            at the program entry point. Defaults to C{False}.\n\n        @type    bConsole: bool\n        @keyword bConsole: True to inherit the console of the debugger.\n            Defaults to C{False}.\n\n        @type    bFollow: bool\n        @keyword bFollow: C{True} to automatically attach to child processes.\n            Defaults to C{False}.\n\n        @type    bInheritHandles: bool\n        @keyword bInheritHandles: C{True} if the new process should inherit\n            it's parent process' handles. Defaults to C{False}.\n\n        @type    bSuspended: bool\n        @keyword bSuspended: C{True} to suspend the main thread before any code\n            is executed in the debugee. Defaults to C{False}.\n\n        @type    dwParentProcessId: int or None\n        @keyword dwParentProcessId: C{None} or C{0} if the debugger process\n            should be the parent process (default), or a process ID to\n            forcefully set as the debugee's parent (only available for Windows\n            Vista and above).\n\n            In hostile mode, the default is not the debugger process but the\n            process ID for \"explorer.exe\".\n\n        @type    iTrustLevel: int\n        @keyword iTrustLevel: Trust level.\n            Must be one of the following values:\n             - 0: B{No trust}. May not access certain resources, such as\n                  cryptographic keys and credentials. Only available since\n                  Windows XP and 2003, desktop editions. This is the default\n                  in hostile mode.\n             - 1: B{Normal trust}. Run with the same privileges as a normal\n                  user, that is, one that doesn't have the I{Administrator} or\n                  I{Power User} user rights. Only available since Windows XP\n                  and 2003, desktop editions.\n             - 2: B{Full trust}. Run with the exact same privileges as the\n                  current user. This is the default in normal mode.\n\n        @type    bAllowElevation: bool\n        @keyword bAllowElevation: C{True} to allow the child process to keep\n            UAC elevation, if the debugger itself is running elevated. C{False}\n            to ensure the child process doesn't run with elevation. Defaults to\n            C{True} in normal mode and C{False} in hostile mode.\n\n            This flag is only meaningful on Windows Vista and above, and if the\n            debugger itself is running with elevation. It can be used to make\n            sure the child processes don't run elevated as well.\n\n            This flag DOES NOT force an elevation prompt when the debugger is\n            not running with elevation.\n\n            Note that running the debugger with elevation (or the Python\n            interpreter at all for that matter) is not normally required.\n            You should only need to if the target program requires elevation\n            to work properly (for example if you try to debug an installer).\n\n        @rtype:  L{Process}\n        @return: A new Process object. Normally you don't need to use it now,\n            it's best to interact with the process from the event handler.\n\n        @raise WindowsError: Raises an exception on error.\n        \"\"\"\n        if type(lpCmdLine) not in (str, compat.unicode):\n            warnings.warn(\"Debug.execl expects a string\")\n\n        # Set the \"debug\" flag to True.\n        kwargs['bDebug'] = True\n\n        # Pop the \"break on entry point\" flag.\n        bBreakOnEntryPoint = kwargs.pop('bBreakOnEntryPoint', False)\n\n        # Set the default trust level if requested.\n        if 'iTrustLevel' not in kwargs:\n            if self.__bHostileCode:\n                kwargs['iTrustLevel'] = 0\n            else:\n                kwargs['iTrustLevel'] = 2\n\n        # Set the default UAC elevation flag if requested.\n        if 'bAllowElevation' not in kwargs:\n            kwargs['bAllowElevation'] = not self.__bHostileCode\n\n        # In hostile mode the default parent process is explorer.exe.\n        # Only supported for Windows Vista and above.\n        if self.__bHostileCode and not kwargs.get('dwParentProcessId', None):\n            try:\n                vista_and_above = self.__vista_and_above\n            except AttributeError:\n                osi = win32.OSVERSIONINFOEXW()\n                osi.dwMajorVersion = 6\n                osi.dwMinorVersion = 0\n                osi.dwPlatformId   = win32.VER_PLATFORM_WIN32_NT\n                mask = 0\n                mask = win32.VerSetConditionMask(mask,\n                                          win32.VER_MAJORVERSION,\n                                          win32.VER_GREATER_EQUAL)\n                mask = win32.VerSetConditionMask(mask,\n                                          win32.VER_MAJORVERSION,\n                                          win32.VER_GREATER_EQUAL)\n                mask = win32.VerSetConditionMask(mask,\n                                          win32.VER_PLATFORMID,\n                                          win32.VER_EQUAL)\n                vista_and_above = win32.VerifyVersionInfoW(osi,\n                                          win32.VER_MAJORVERSION | \\\n                                          win32.VER_MINORVERSION | \\\n                                          win32.VER_PLATFORMID,\n                                          mask)\n                self.__vista_and_above = vista_and_above\n            if vista_and_above:\n                dwParentProcessId = self.system.get_explorer_pid()\n                if dwParentProcessId:\n                    kwargs['dwParentProcessId'] = dwParentProcessId\n                else:\n                    msg = (\"Failed to find \\\"explorer.exe\\\"!\"\n                           \" Using the debugger as parent process.\")\n                    warnings.warn(msg, RuntimeWarning)\n\n        # Start the new process.\n        aProcess = None\n        try:\n            aProcess = self.system.start_process(lpCmdLine, **kwargs)\n            dwProcessId = aProcess.get_pid()\n\n            # Match the system kill-on-exit flag to our own.\n            self.__setSystemKillOnExitMode()\n\n            # Warn when mixing 32 and 64 bits.\n            # This also allows the user to stop attaching altogether,\n            # depending on how the warnings are configured.\n            if System.bits != aProcess.get_bits():\n                msg = \"Mixture of 32 and 64 bits is considered experimental.\" \\\n                      \" Use at your own risk!\"\n                warnings.warn(msg, MixedBitsWarning)\n\n            # Add the new PID to the set of debugees.\n            self.__startedDebugees.add(dwProcessId)\n\n            # Add the new PID to the set of \"break on EP\" debugees if needed.\n            if bBreakOnEntryPoint:\n                self.__breakOnEP.add(dwProcessId)\n\n            # Return the Process object.\n            return aProcess\n\n        # On error kill the new process and raise an exception.\n        except:\n            if aProcess is not None:\n                try:\n                    try:\n                        self.__startedDebugees.remove(aProcess.get_pid())\n                    except KeyError:\n                        pass\n                finally:\n                    try:\n                        try:\n                            self.__breakOnEP.remove(aProcess.get_pid())\n                        except KeyError:\n                            pass\n                    finally:\n                        try:\n                            aProcess.kill()\n                        except Exception:\n                            pass\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_existing_session(self, dwProcessId, bStarted = False):\n\n        # Register the process object with the snapshot.\n        if not self.system.has_process(dwProcessId):\n            aProcess = Process(dwProcessId)\n            self.system._add_process(aProcess)\n        else:\n            aProcess = self.system.get_process(dwProcessId)\n\n        # Test for debug privileges on the target process.\n        # Raises WindowsException on error.\n        aProcess.get_handle()\n\n        # Register the process ID with the debugger.\n        if bStarted:\n            self.__attachedDebugees.add(dwProcessId)\n        else:\n            self.__startedDebugees.add(dwProcessId)\n\n        # Match the system kill-on-exit flag to our own.\n        self.__setSystemKillOnExitMode()\n\n        # Scan the process threads and loaded modules.\n        # This is prefered because the thread and library events do not\n        # properly give some information, like the filename for each module.\n        aProcess.scan_threads()\n        aProcess.scan_modules()", "response": "Add an existing debugger session to the target process."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming the necessary cleanup of a process about to be killed or detached from. This private method is called by L{kill} and L{detach}. @type dwProcessId: int @param dwProcessId: Global ID of a process to kill. @type bIgnoreExceptions: bool @param bIgnoreExceptions: C{True} to ignore any exceptions that may be raised when killing the process. @raise WindowsError: Raises an exception on error, unless C{bIgnoreExceptions} is C{True}.", "response": "def __cleanup_process(self, dwProcessId, bIgnoreExceptions = False):\n        \"\"\"\n        Perform the necessary cleanup of a process about to be killed or\n        detached from.\n\n        This private method is called by L{kill} and L{detach}.\n\n        @type  dwProcessId: int\n        @param dwProcessId: Global ID of a process to kill.\n\n        @type  bIgnoreExceptions: bool\n        @param bIgnoreExceptions: C{True} to ignore any exceptions that may be\n            raised when killing the process.\n\n        @raise WindowsError: Raises an exception on error, unless\n            C{bIgnoreExceptions} is C{True}.\n        \"\"\"\n        # If the process is being debugged...\n        if self.is_debugee(dwProcessId):\n\n            # Make sure a Process object exists or the following calls fail.\n            if not self.system.has_process(dwProcessId):\n                aProcess = Process(dwProcessId)\n                try:\n                    aProcess.get_handle()\n                except WindowsError:\n                    pass    # fails later on with more specific reason\n                self.system._add_process(aProcess)\n\n            # Erase all breakpoints in the process.\n            try:\n                self.erase_process_breakpoints(dwProcessId)\n            except Exception:\n                if not bIgnoreExceptions:\n                    raise\n                e = sys.exc_info()[1]\n                warnings.warn(str(e), RuntimeWarning)\n\n            # Stop tracing all threads in the process.\n            try:\n                self.stop_tracing_process(dwProcessId)\n            except Exception:\n                if not bIgnoreExceptions:\n                    raise\n                e = sys.exc_info()[1]\n                warnings.warn(str(e), RuntimeWarning)\n\n            # The process is no longer a debugee.\n            try:\n                if dwProcessId in self.__attachedDebugees:\n                    self.__attachedDebugees.remove(dwProcessId)\n                if dwProcessId in self.__startedDebugees:\n                    self.__startedDebugees.remove(dwProcessId)\n            except Exception:\n                if not bIgnoreExceptions:\n                    raise\n                e = sys.exc_info()[1]\n                warnings.warn(str(e), RuntimeWarning)\n\n        # Clear and remove the process from the snapshot.\n        # If the user wants to do something with it after detaching\n        # a new Process instance should be created.\n        try:\n            if self.system.has_process(dwProcessId):\n                try:\n                    self.system.get_process(dwProcessId).clear()\n                finally:\n                    self.system._del_process(dwProcessId)\n        except Exception:\n            if not bIgnoreExceptions:\n                raise\n            e = sys.exc_info()[1]\n            warnings.warn(str(e), RuntimeWarning)\n\n        # If the last debugging event is related to this process, forget it.\n        try:\n            if self.lastEvent and self.lastEvent.get_pid() == dwProcessId:\n                self.lastEvent = None\n        except Exception:\n            if not bIgnoreExceptions:\n                raise\n            e = sys.exc_info()[1]\n            warnings.warn(str(e), RuntimeWarning)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef kill(self, dwProcessId, bIgnoreExceptions = False):\n\n        # Keep a reference to the process. We'll need it later.\n        try:\n            aProcess = self.system.get_process(dwProcessId)\n        except KeyError:\n            aProcess = Process(dwProcessId)\n\n        # Cleanup all data referring to the process.\n        self.__cleanup_process(dwProcessId,\n                               bIgnoreExceptions = bIgnoreExceptions)\n\n        # Kill the process.\n        try:\n            try:\n                if self.is_debugee(dwProcessId):\n                    try:\n                        if aProcess.is_alive():\n                            aProcess.suspend()\n                    finally:\n                        self.detach(dwProcessId,\n                                    bIgnoreExceptions = bIgnoreExceptions)\n            finally:\n                aProcess.kill()\n        except Exception:\n            if not bIgnoreExceptions:\n                raise\n            e = sys.exc_info()[1]\n            warnings.warn(str(e), RuntimeWarning)\n\n        # Cleanup what remains of the process data.\n        try:\n            aProcess.clear()\n        except Exception:\n            if not bIgnoreExceptions:\n                raise\n            e = sys.exc_info()[1]\n            warnings.warn(str(e), RuntimeWarning)", "response": "Kills a process currently being debugged."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef kill_all(self, bIgnoreExceptions = False):\n        for pid in self.get_debugee_pids():\n            self.kill(pid, bIgnoreExceptions = bIgnoreExceptions)", "response": "Kills all debugee processes currently being debugged."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetaching from a process.", "response": "def detach(self, dwProcessId, bIgnoreExceptions = False):\n        \"\"\"\n        Detaches from a process currently being debugged.\n\n        @note: On Windows 2000 and below the process is killed.\n\n        @see: L{attach}, L{detach_from_all}\n\n        @type  dwProcessId: int\n        @param dwProcessId: Global ID of a process to detach from.\n\n        @type  bIgnoreExceptions: bool\n        @param bIgnoreExceptions: C{True} to ignore any exceptions that may be\n            raised when detaching. C{False} to stop and raise an exception when\n            encountering an error.\n\n        @raise WindowsError: Raises an exception on error, unless\n            C{bIgnoreExceptions} is C{True}.\n        \"\"\"\n\n        # Keep a reference to the process. We'll need it later.\n        try:\n            aProcess = self.system.get_process(dwProcessId)\n        except KeyError:\n            aProcess = Process(dwProcessId)\n\n        # Determine if there is support for detaching.\n        # This check should only fail on Windows 2000 and older.\n        try:\n            win32.DebugActiveProcessStop\n            can_detach = True\n        except AttributeError:\n            can_detach = False\n\n        # Continue the last event before detaching.\n        # XXX not sure about this...\n        try:\n            if can_detach and self.lastEvent and \\\n                                    self.lastEvent.get_pid() == dwProcessId:\n                self.cont(self.lastEvent)\n        except Exception:\n            if not bIgnoreExceptions:\n                raise\n            e = sys.exc_info()[1]\n            warnings.warn(str(e), RuntimeWarning)\n\n        # Cleanup all data referring to the process.\n        self.__cleanup_process(dwProcessId,\n                               bIgnoreExceptions = bIgnoreExceptions)\n\n        try:\n            # Detach from the process.\n            # On Windows 2000 and before, kill the process.\n            if can_detach:\n                try:\n                    win32.DebugActiveProcessStop(dwProcessId)\n                except Exception:\n                    if not bIgnoreExceptions:\n                        raise\n                    e = sys.exc_info()[1]\n                    warnings.warn(str(e), RuntimeWarning)\n            else:\n                try:\n                    aProcess.kill()\n                except Exception:\n                    if not bIgnoreExceptions:\n                        raise\n                    e = sys.exc_info()[1]\n                    warnings.warn(str(e), RuntimeWarning)\n\n        finally:\n\n            # Cleanup what remains of the process data.\n            aProcess.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef detach_from_all(self, bIgnoreExceptions = False):\n        for pid in self.get_debugee_pids():\n            self.detach(pid, bIgnoreExceptions = bIgnoreExceptions)", "response": "Detaches from all processes currently being debugged."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwait for the next debug event.", "response": "def wait(self, dwMilliseconds = None):\n        \"\"\"\n        Waits for the next debug event.\n\n        @see: L{cont}, L{dispatch}, L{loop}\n\n        @type  dwMilliseconds: int\n        @param dwMilliseconds: (Optional) Timeout in milliseconds.\n            Use C{INFINITE} or C{None} for no timeout.\n\n        @rtype:  L{Event}\n        @return: An event that occured in one of the debugees.\n\n        @raise WindowsError: Raises an exception on error.\n            If no target processes are left to debug,\n            the error code is L{win32.ERROR_INVALID_HANDLE}.\n        \"\"\"\n\n        # Wait for the next debug event.\n        raw   = win32.WaitForDebugEvent(dwMilliseconds)\n        event = EventFactory.get(self, raw)\n\n        # Remember it.\n        self.lastEvent = event\n\n        # Return it.\n        return event"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndispatch the debug event to the debug event notify callbacks.", "response": "def dispatch(self, event = None):\n        \"\"\"\n        Calls the debug event notify callbacks.\n\n        @see: L{cont}, L{loop}, L{wait}\n\n        @type  event: L{Event}\n        @param event: (Optional) Event object returned by L{wait}.\n\n        @raise WindowsError: Raises an exception on error.\n        \"\"\"\n\n        # If no event object was given, use the last event.\n        if event is None:\n            event = self.lastEvent\n\n        # Ignore dummy events.\n        if not event:\n            return\n\n        # Determine the default behaviour for this event.\n        # XXX HACK\n        # Some undocumented flags are used, but as far as I know in those\n        # versions of Windows that don't support them they should behave\n        # like DGB_CONTINUE.\n\n        code = event.get_event_code()\n        if code == win32.EXCEPTION_DEBUG_EVENT:\n\n            # At this point, by default some exception types are swallowed by\n            # the debugger, because we don't know yet if it was caused by the\n            # debugger itself or the debugged process.\n            #\n            # Later on (see breakpoint.py) if we determined the exception was\n            # not caused directly by the debugger itself, we set the default\n            # back to passing the exception to the debugee.\n            #\n            # The \"invalid handle\" exception is also swallowed by the debugger\n            # because it's not normally generated by the debugee. But in\n            # hostile mode we want to pass it to the debugee, as it may be the\n            # result of an anti-debug trick. In that case it's best to disable\n            # bad handles detection with Microsoft's gflags.exe utility. See:\n            # http://msdn.microsoft.com/en-us/library/windows/hardware/ff549557(v=vs.85).aspx\n\n            exc_code = event.get_exception_code()\n            if exc_code in (\n                    win32.EXCEPTION_BREAKPOINT,\n                    win32.EXCEPTION_WX86_BREAKPOINT,\n                    win32.EXCEPTION_SINGLE_STEP,\n                    win32.EXCEPTION_GUARD_PAGE,\n                ):\n                event.continueStatus = win32.DBG_CONTINUE\n            elif exc_code == win32.EXCEPTION_INVALID_HANDLE:\n                if self.__bHostileCode:\n                    event.continueStatus = win32.DBG_EXCEPTION_NOT_HANDLED\n                else:\n                    event.continueStatus = win32.DBG_CONTINUE\n            else:\n                event.continueStatus = win32.DBG_EXCEPTION_NOT_HANDLED\n\n        elif code == win32.RIP_EVENT and \\\n                   event.get_rip_type() == win32.SLE_ERROR:\n\n            # RIP events that signal fatal events should kill the process.\n            event.continueStatus = win32.DBG_TERMINATE_PROCESS\n\n        else:\n\n            # Other events need this continue code.\n            # Sometimes other codes can be used and are ignored, sometimes not.\n            # For example, when using the DBG_EXCEPTION_NOT_HANDLED code,\n            # debug strings are sent twice (!)\n            event.continueStatus = win32.DBG_CONTINUE\n\n        # Dispatch the debug event.\n        return EventDispatcher.dispatch(self, event)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncontinuing execution after processing a debug event.", "response": "def cont(self, event = None):\n        \"\"\"\n        Resumes execution after processing a debug event.\n\n        @see: dispatch(), loop(), wait()\n\n        @type  event: L{Event}\n        @param event: (Optional) Event object returned by L{wait}.\n\n        @raise WindowsError: Raises an exception on error.\n        \"\"\"\n\n        # If no event object was given, use the last event.\n        if event is None:\n            event = self.lastEvent\n\n        # Ignore dummy events.\n        if not event:\n            return\n\n        # Get the event continue status information.\n        dwProcessId      = event.get_pid()\n        dwThreadId       = event.get_tid()\n        dwContinueStatus = event.continueStatus\n\n        # Check if the process is still being debugged.\n        if self.is_debugee(dwProcessId):\n\n            # Try to flush the instruction cache.\n            try:\n                if self.system.has_process(dwProcessId):\n                    aProcess = self.system.get_process(dwProcessId)\n                else:\n                    aProcess = Process(dwProcessId)\n                aProcess.flush_instruction_cache()\n            except WindowsError:\n                pass\n\n            # XXX TODO\n            #\n            # Try to execute the UnhandledExceptionFilter for second chance\n            # exceptions, at least when in hostile mode (in normal mode it\n            # would be breaking compatibility, as users may actually expect\n            # second chance exceptions to be raised again).\n            #\n            # Reportedly in Windows 7 (maybe in Vista too) this seems to be\n            # happening already. In XP and below the UnhandledExceptionFilter\n            # was never called for processes being debugged.\n\n            # Continue execution of the debugee.\n            win32.ContinueDebugEvent(dwProcessId, dwThreadId, dwContinueStatus)\n\n        # If the event is the last event, forget it.\n        if event == self.lastEvent:\n            self.lastEvent = None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop(self, bIgnoreExceptions = True):\n\n        # Determine if we have a last debug event that we need to continue.\n        try:\n            event = self.lastEvent\n            has_event = bool(event)\n        except Exception:\n            if not bIgnoreExceptions:\n                raise\n            e = sys.exc_info()[1]\n            warnings.warn(str(e), RuntimeWarning)\n            has_event = False\n\n        # If we do...\n        if has_event:\n\n            # Disable all breakpoints in the process before resuming execution.\n            try:\n                pid = event.get_pid()\n                self.disable_process_breakpoints(pid)\n            except Exception:\n                if not bIgnoreExceptions:\n                    raise\n                e = sys.exc_info()[1]\n                warnings.warn(str(e), RuntimeWarning)\n\n            # Disable all breakpoints in the thread before resuming execution.\n            try:\n                tid = event.get_tid()\n                self.disable_thread_breakpoints(tid)\n            except Exception:\n                if not bIgnoreExceptions:\n                    raise\n                e = sys.exc_info()[1]\n                warnings.warn(str(e), RuntimeWarning)\n\n            # Resume execution.\n            try:\n                event.continueDebugEvent = win32.DBG_CONTINUE\n                self.cont(event)\n            except Exception:\n                if not bIgnoreExceptions:\n                    raise\n                e = sys.exc_info()[1]\n                warnings.warn(str(e), RuntimeWarning)\n\n        # Detach from or kill all debuggees.\n        try:\n            if self.__bKillOnExit:\n                self.kill_all(bIgnoreExceptions)\n            else:\n                self.detach_from_all(bIgnoreExceptions)\n        except Exception:\n            if not bIgnoreExceptions:\n                raise\n            e = sys.exc_info()[1]\n            warnings.warn(str(e), RuntimeWarning)\n\n        # Cleanup the process snapshots.\n        try:\n            self.system.clear()\n        except Exception:\n            if not bIgnoreExceptions:\n                raise\n            e = sys.exc_info()[1]\n            warnings.warn(str(e), RuntimeWarning)\n\n        # Close all Win32 handles the Python garbage collector failed to close.\n        self.force_garbage_collection(bIgnoreExceptions)", "response": "Stops debugging all processes and threads."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef next(self):\n        try:\n            event = self.wait()\n        except Exception:\n            self.stop()\n            raise\n        try:\n            self.dispatch()\n        finally:\n            self.cont()", "response": "Handles the next debug event."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts an interactive debugging session.", "response": "def interactive(self, bConfirmQuit = True, bShowBanner = True):\n        \"\"\"\n        Start an interactive debugging session.\n\n        @type  bConfirmQuit: bool\n        @param bConfirmQuit: Set to C{True} to ask the user for confirmation\n            before closing the session, C{False} otherwise.\n\n        @type  bShowBanner: bool\n        @param bShowBanner: Set to C{True} to show a banner before entering\n            the session and after leaving it, C{False} otherwise.\n\n        @warn: This will temporarily disable the user-defined event handler!\n\n        This method returns when the user closes the session.\n        \"\"\"\n        print('')\n        print(\"-\" * 79)\n        print(\"Interactive debugging session started.\")\n        print(\"Use the \\\"help\\\" command to list all available commands.\")\n        print(\"Use the \\\"quit\\\" command to close this session.\")\n        print(\"-\" * 79)\n        if self.lastEvent is None:\n            print('')\n        console = ConsoleDebugger()\n        console.confirm_quit = bConfirmQuit\n        console.load_history()\n        try:\n            console.start_using_debugger(self)\n            console.loop()\n        finally:\n            console.stop_using_debugger()\n            console.save_history()\n        print('')\n        print(\"-\" * 79)\n        print(\"Interactive debugging session closed.\")\n        print(\"-\" * 79)\n        print('')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef force_garbage_collection(bIgnoreExceptions = True):\n        try:\n            import gc\n            gc.collect()\n            bRecollect = False\n            for obj in list(gc.garbage):\n                try:\n                    if isinstance(obj, win32.Handle):\n                        obj.close()\n                    elif isinstance(obj, Event):\n                        obj.debug = None\n                    elif isinstance(obj, Process):\n                        obj.clear()\n                    elif isinstance(obj, Thread):\n                        obj.set_process(None)\n                        obj.clear()\n                    elif isinstance(obj, Module):\n                        obj.set_process(None)\n                    elif isinstance(obj, Window):\n                        obj.set_process(None)\n                    else:\n                        continue\n                    gc.garbage.remove(obj)\n                    del obj\n                    bRecollect = True\n                except Exception:\n                    if not bIgnoreExceptions:\n                        raise\n                    e = sys.exc_info()[1]\n                    warnings.warn(str(e), RuntimeWarning)\n            if bRecollect:\n                gc.collect()\n        except Exception:\n            if not bIgnoreExceptions:\n                raise\n            e = sys.exc_info()[1]\n            warnings.warn(str(e), RuntimeWarning)", "response": "Force the garbage collector to close all Win32 handles the Python garbage collector failed to close."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _notify_create_process(self, event):\n        dwProcessId = event.get_pid()\n        if dwProcessId not in self.__attachedDebugees:\n            if dwProcessId not in self.__startedDebugees:\n                self.__startedDebugees.add(dwProcessId)\n\n        retval = self.system._notify_create_process(event)\n\n        # Set a breakpoint on the program's entry point if requested.\n        # Try not to use the Event object's entry point value, as in some cases\n        # it may be wrong. See: http://pferrie.host22.com/misc/lowlevel3.htm\n        if dwProcessId in self.__breakOnEP:\n            try:\n                lpEntryPoint = event.get_process().get_entry_point()\n            except Exception:\n                lpEntryPoint = event.get_start_address()\n\n            # It'd be best to use a hardware breakpoint instead, at least in\n            # hostile mode. But since the main thread's context gets smashed\n            # by the loader, I haven't found a way to make it work yet.\n            self.break_at(dwProcessId, lpEntryPoint)\n\n        # Defeat isDebuggerPresent by patching PEB->BeingDebugged.\n        # When we do this, some debugging APIs cease to work as expected.\n        # For example, the system breakpoint isn't hit when we attach.\n        # For that reason we need to define a code breakpoint at the\n        # code location where a new thread is spawned by the debugging\n        # APIs, ntdll!DbgUiRemoteBreakin.\n        if self.__bHostileCode:\n            aProcess = event.get_process()\n            try:\n                hProcess = aProcess.get_handle(win32.PROCESS_QUERY_INFORMATION)\n                pbi = win32.NtQueryInformationProcess(\n                                       hProcess, win32.ProcessBasicInformation)\n                ptr = pbi.PebBaseAddress + 2\n                if aProcess.peek(ptr, 1) == '\\x01':\n                    aProcess.poke(ptr, '\\x00')\n            except WindowsError:\n                e = sys.exc_info()[1]\n                warnings.warn(\n                    \"Cannot patch PEB->BeingDebugged, reason: %s\" % e.strerror)\n\n        return retval", "response": "Notify the creation of a new process."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _notify_load_dll(self, event):\n\n        # Pass the event to the breakpoint container.\n        bCallHandler = _BreakpointContainer._notify_load_dll(self, event)\n\n        # Get the process where the DLL was loaded.\n        aProcess = event.get_process()\n\n        # Pass the event to the process.\n        bCallHandler = aProcess._notify_load_dll(event) and bCallHandler\n\n        # Anti-anti-debugging tricks on ntdll.dll.\n        if self.__bHostileCode:\n            aModule = event.get_module()\n            if aModule.match_name('ntdll.dll'):\n\n                # Since we've overwritten the PEB to hide\n                # ourselves, we no longer have the system\n                # breakpoint when attaching to the process.\n                # Set a breakpoint at ntdll!DbgUiRemoteBreakin\n                # instead (that's where the debug API spawns\n                # it's auxiliary threads). This also defeats\n                # a simple anti-debugging trick: the hostile\n                # process could have overwritten the int3\n                # instruction at the system breakpoint.\n                self.break_at(aProcess.get_pid(),\n                        aProcess.resolve_label('ntdll!DbgUiRemoteBreakin'))\n\n        return bCallHandler", "response": "Notify the user - defined handle of a load of a new module."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _notify_exit_process(self, event):\n        bCallHandler1 = _BreakpointContainer._notify_exit_process(self, event)\n        bCallHandler2 = self.system._notify_exit_process(event)\n\n        try:\n            self.detach( event.get_pid() )\n        except WindowsError:\n            e = sys.exc_info()[1]\n            if e.winerror != win32.ERROR_INVALID_PARAMETER:\n                warnings.warn(\n                    \"Failed to detach from dead process, reason: %s\" % str(e),\n                    RuntimeWarning)\n        except Exception:\n            e = sys.exc_info()[1]\n            warnings.warn(\n                \"Failed to detach from dead process, reason: %s\" % str(e),\n                RuntimeWarning)\n\n        return bCallHandler1 and bCallHandler2", "response": "Notify the termination of a process."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nnotify the termination of a thread.", "response": "def _notify_exit_thread(self, event):\n        \"\"\"\n        Notify the termination of a thread.\n\n        @warning: This method is meant to be used internally by the debugger.\n\n        @type  event: L{ExitThreadEvent}\n        @param event: Exit thread event.\n\n        @rtype:  bool\n        @return: C{True} to call the user-defined handle, C{False} otherwise.\n        \"\"\"\n        bCallHandler1 = _BreakpointContainer._notify_exit_thread(self, event)\n        bCallHandler2 = event.get_process()._notify_exit_thread(event)\n        return bCallHandler1 and bCallHandler2"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nnotifies the user - defined handle of a unload of a module.", "response": "def _notify_unload_dll(self, event):\n        \"\"\"\n        Notify the unload of a module.\n\n        @warning: This method is meant to be used internally by the debugger.\n\n        @type  event: L{UnloadDLLEvent}\n        @param event: Unload DLL event.\n\n        @rtype:  bool\n        @return: C{True} to call the user-defined handle, C{False} otherwise.\n        \"\"\"\n        bCallHandler1 = _BreakpointContainer._notify_unload_dll(self, event)\n        bCallHandler2 = event.get_process()._notify_unload_dll(event)\n        return bCallHandler1 and bCallHandler2"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nnotify the user - defined handle of a Debug Ctrl - C exception.", "response": "def _notify_debug_control_c(self, event):\n        \"\"\"\n        Notify of a Debug Ctrl-C exception.\n\n        @warning: This method is meant to be used internally by the debugger.\n\n        @note: This exception is only raised when a debugger is attached, and\n            applications are not supposed to handle it, so we need to handle it\n            ourselves or the application may crash.\n\n        @see: U{http://msdn.microsoft.com/en-us/library/aa363082(VS.85).aspx}\n\n        @type  event: L{ExceptionEvent}\n        @param event: Debug Ctrl-C exception event.\n\n        @rtype:  bool\n        @return: C{True} to call the user-defined handle, C{False} otherwise.\n        \"\"\"\n        if event.is_first_chance():\n            event.continueStatus = win32.DBG_EXCEPTION_HANDLED\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nnotify user - defined handle of an exception.", "response": "def _notify_ms_vc_exception(self, event):\n        \"\"\"\n        Notify of a Microsoft Visual C exception.\n\n        @warning: This method is meant to be used internally by the debugger.\n\n        @note: This allows the debugger to understand the\n            Microsoft Visual C thread naming convention.\n\n        @see: U{http://msdn.microsoft.com/en-us/library/xcb2z8hs.aspx}\n\n        @type  event: L{ExceptionEvent}\n        @param event: Microsoft Visual C exception event.\n\n        @rtype:  bool\n        @return: C{True} to call the user-defined handle, C{False} otherwise.\n        \"\"\"\n        dwType = event.get_exception_information(0)\n        if dwType == 0x1000:\n            pszName     = event.get_exception_information(1)\n            dwThreadId  = event.get_exception_information(2)\n            dwFlags     = event.get_exception_information(3)\n\n            aProcess = event.get_process()\n            szName   = aProcess.peek_string(pszName, fUnicode = False)\n            if szName:\n\n                if dwThreadId == -1:\n                    dwThreadId = event.get_tid()\n\n                if aProcess.has_thread(dwThreadId):\n                    aThread = aProcess.get_thread(dwThreadId)\n                else:\n                    aThread = Thread(dwThreadId)\n                    aProcess._add_thread(aThread)\n\n##                if aThread.get_name() is None:\n##                    aThread.set_name(szName)\n                aThread.set_name(szName)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the grammar from a pickle file.", "response": "def load_grammar(gt=\"Grammar.txt\", gp=None,\n                 save=True, force=False, logger=None):\n    \"\"\"Load the grammar (maybe from a pickle).\"\"\"\n    if logger is None:\n        logger = logging.getLogger()\n    if gp is None:\n        head, tail = os.path.splitext(gt)\n        if tail == \".txt\":\n            tail = \"\"\n        gp = head + tail + \".\".join(map(str, sys.version_info)) + \".pickle\"\n    if force or not _newer(gp, gt):\n        logger.info(\"Generating grammar tables from %s\", gt)\n        g = pgen.generate_grammar(gt)\n        if save:\n            logger.info(\"Writing grammar tables to %s\", gp)\n            try:\n                g.dump(gp)\n            except IOError, e:\n                logger.info(\"Writing failed:\"+str(e))\n    else:\n        g = grammar.Grammar()\n        g.load(gp)\n    return g"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninquires whether file a was written since file b.", "response": "def _newer(a, b):\n    \"\"\"Inquire whether file a was written since file b.\"\"\"\n    if not os.path.exists(a):\n        return False\n    if not os.path.exists(b):\n        return True\n    return os.path.getmtime(a) >= os.path.getmtime(b)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main(*args):\n    if not args:\n        args = sys.argv[1:]\n    logging.basicConfig(level=logging.INFO, stream=sys.stdout,\n                        format='%(message)s')\n    for gt in args:\n        load_grammar(gt, save=True, force=True)\n    return True", "response": "Main function for grammar pickle."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a series of tokens and return the syntax tree.", "response": "def parse_tokens(self, tokens, debug=False):\n        \"\"\"Parse a series of tokens and return the syntax tree.\"\"\"\n        # XXX Move the prefix computation into a wrapper around tokenize.\n        p = parse.Parser(self.grammar, self.convert)\n        p.setup()\n        lineno = 1\n        column = 0\n        type = value = start = end = line_text = None\n        prefix = u\"\"\n        for quintuple in tokens:\n            type, value, start, end, line_text = quintuple\n            if start != (lineno, column):\n                assert (lineno, column) <= start, ((lineno, column), start)\n                s_lineno, s_column = start\n                if lineno < s_lineno:\n                    prefix += \"\\n\" * (s_lineno - lineno)\n                    lineno = s_lineno\n                    column = 0\n                if column < s_column:\n                    prefix += line_text[column:s_column]\n                    column = s_column\n            if type in (tokenize.COMMENT, tokenize.NL):\n                prefix += value\n                lineno, column = end\n                if value.endswith(\"\\n\"):\n                    lineno += 1\n                    column = 0\n                continue\n            if type == token.OP:\n                type = grammar.opmap[value]\n            if debug:\n                self.logger.debug(\"%s %r (prefix=%r)\",\n                                  token.tok_name[type], value, prefix)\n            if p.addtoken(type, value, (prefix, start)):\n                if debug:\n                    self.logger.debug(\"Stop.\")\n                break\n            prefix = \"\"\n            lineno, column = end\n            if value.endswith(\"\\n\"):\n                lineno += 1\n                column = 0\n        else:\n            # We never broke out -- EOF is too soon (how can this happen???)\n            raise parse.ParseError(\"incomplete input\",\n                                   type, value, (prefix, start))\n        return p.rootnode"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a stream and return the syntax tree.", "response": "def parse_stream_raw(self, stream, debug=False):\n        \"\"\"Parse a stream and return the syntax tree.\"\"\"\n        tokens = tokenize.generate_tokens(stream.readline)\n        return self.parse_tokens(tokens, debug)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a file and return the syntax tree.", "response": "def parse_file(self, filename, encoding=None, debug=False):\n        \"\"\"Parse a file and return the syntax tree.\"\"\"\n        stream = codecs.open(filename, \"r\", encoding)\n        try:\n            return self.parse_stream(stream, debug)\n        finally:\n            stream.close()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_string(self, text, debug=False):\n        tokens = tokenize.generate_tokens(StringIO.StringIO(text).readline)\n        return self.parse_tokens(tokens, debug)", "response": "Parse a string and return the syntax tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dump_threads(stream=None):\n    '''\n    Helper to dump thread info.\n    '''\n    if stream is None:\n        stream = sys.stderr\n    thread_id_to_name = {}\n    try:\n        for t in threading.enumerate():\n            thread_id_to_name[t.ident] = '%s  (daemon: %s, pydevd thread: %s)' % (\n                t.name, t.daemon, getattr(t, 'is_pydev_daemon_thread', False))\n    except:\n        pass\n\n    from _pydevd_bundle.pydevd_additional_thread_info_regular import _current_frames\n\n    stream.write('===============================================================================\\n')\n    stream.write('Threads running\\n')\n    stream.write('================================= Thread Dump =================================\\n')\n    stream.flush()\n\n    for thread_id, stack in _current_frames().items():\n        stream.write('\\n-------------------------------------------------------------------------------\\n')\n        stream.write(\" Thread %s\" % thread_id_to_name.get(thread_id, thread_id))\n        stream.write('\\n\\n')\n\n        for i, (filename, lineno, name, line) in enumerate(traceback.extract_stack(stack)):\n\n            stream.write(' File \"%s\", line %d, in %s\\n' % (filename, lineno, name))\n            if line:\n                stream.write(\"   %s\\n\" % (line.strip()))\n\n            if i == 0 and 'self' in stack.f_locals:\n                stream.write('   self: ')\n                try:\n                    stream.write(str(stack.f_locals['self']))\n                except:\n                    stream.write('Unable to get str of: %s' % (type(stack.f_locals['self']),))\n                stream.write('\\n')\n        stream.flush()\n\n    stream.write('\\n=============================== END Thread Dump ===============================')\n    stream.flush()", "response": "Helper to dump thread info."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the first top - level window in the current desktop to match the given class name and or window name.", "response": "def find_window(className = None, windowName = None):\n        \"\"\"\n        Find the first top-level window in the current desktop to match the\n        given class name and/or window name. If neither are provided any\n        top-level window will match.\n\n        @see: L{get_window_at}\n\n        @type  className: str\n        @param className: (Optional) Class name of the window to find.\n            If C{None} or not used any class name will match the search.\n\n        @type  windowName: str\n        @param windowName: (Optional) Caption text of the window to find.\n            If C{None} or not used any caption text will match the search.\n\n        @rtype:  L{Window} or None\n        @return: A window that matches the request. There may be more matching\n            windows, but this method only returns one. If no matching window\n            is found, the return value is C{None}.\n\n        @raise WindowsError: An error occured while processing this request.\n        \"\"\"\n        # I'd love to reverse the order of the parameters\n        # but that might create some confusion. :(\n        hWnd = win32.FindWindow(className, windowName)\n        if hWnd:\n            return Window(hWnd)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrequest debug privileges for the current system and returns C { True } on success False on failure.", "response": "def request_debug_privileges(cls, bIgnoreExceptions = False):\n        \"\"\"\n        Requests debug privileges.\n\n        This may be needed to debug processes running as SYSTEM\n        (such as services) since Windows XP.\n\n        @type  bIgnoreExceptions: bool\n        @param bIgnoreExceptions: C{True} to ignore any exceptions that may be\n            raised when requesting debug privileges.\n\n        @rtype:  bool\n        @return: C{True} on success, C{False} on failure.\n\n        @raise WindowsError: Raises an exception on error, unless\n            C{bIgnoreExceptions} is C{True}.\n        \"\"\"\n        try:\n            cls.request_privileges(win32.SE_DEBUG_NAME)\n            return True\n        except Exception:\n            if not bIgnoreExceptions:\n                raise\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef drop_debug_privileges(cls, bIgnoreExceptions = False):\n        try:\n            cls.drop_privileges(win32.SE_DEBUG_NAME)\n            return True\n        except Exception:\n            if not bIgnoreExceptions:\n                raise\n        return False", "response": "Drops debug privileges.\n\n        This may be needed to avoid being detected\n        by certain anti-debug tricks.\n\n        @type  bIgnoreExceptions: bool\n        @param bIgnoreExceptions: C{True} to ignore any exceptions that may be\n            raised when dropping debug privileges.\n\n        @rtype:  bool\n        @return: C{True} on success, C{False} on failure.\n\n        @raise WindowsError: Raises an exception on error, unless\n            C{bIgnoreExceptions} is C{True}."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef adjust_privileges(state, privileges):\n        with win32.OpenProcessToken(win32.GetCurrentProcess(),\n                                win32.TOKEN_ADJUST_PRIVILEGES) as hToken:\n            NewState = ( (priv, state) for priv in privileges )\n            win32.AdjustTokenPrivileges(hToken, NewState)", "response": "Adjusts the set of privileges for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the program version information from an executable file.", "response": "def get_file_version_info(cls, filename):\n        \"\"\"\n        Get the program version from an executable file, if available.\n\n        @type  filename: str\n        @param filename: Pathname to the executable file to query.\n\n        @rtype: tuple(str, str, bool, bool, str, str)\n        @return: Tuple with version information extracted from the executable\n            file metadata, containing the following:\n             - File version number (C{\"major.minor\"}).\n             - Product version number (C{\"major.minor\"}).\n             - C{True} for debug builds, C{False} for production builds.\n             - C{True} for legacy OS builds (DOS, OS/2, Win16),\n               C{False} for modern OS builds.\n             - Binary file type.\n               May be one of the following values:\n                - \"application\"\n                - \"dynamic link library\"\n                - \"static link library\"\n                - \"font\"\n                - \"raster font\"\n                - \"TrueType font\"\n                - \"vector font\"\n                - \"driver\"\n                - \"communications driver\"\n                - \"display driver\"\n                - \"installable driver\"\n                - \"keyboard driver\"\n                - \"language driver\"\n                - \"legacy driver\"\n                - \"mouse driver\"\n                - \"network driver\"\n                - \"printer driver\"\n                - \"sound driver\"\n                - \"system driver\"\n                - \"versioned printer driver\"\n             - Binary creation timestamp.\n            Any of the fields may be C{None} if not available.\n\n        @raise WindowsError: Raises an exception on error.\n        \"\"\"\n\n        # Get the file version info structure.\n        pBlock = win32.GetFileVersionInfo(filename)\n        pBuffer, dwLen = win32.VerQueryValue(pBlock, \"\\\\\")\n        if dwLen != ctypes.sizeof(win32.VS_FIXEDFILEINFO):\n            raise ctypes.WinError(win32.ERROR_BAD_LENGTH)\n        pVersionInfo = ctypes.cast(pBuffer,\n                                   ctypes.POINTER(win32.VS_FIXEDFILEINFO))\n        VersionInfo = pVersionInfo.contents\n        if VersionInfo.dwSignature != 0xFEEF04BD:\n            raise ctypes.WinError(win32.ERROR_BAD_ARGUMENTS)\n\n        # File and product versions.\n        FileVersion = \"%d.%d\" % (VersionInfo.dwFileVersionMS,\n                                 VersionInfo.dwFileVersionLS)\n        ProductVersion = \"%d.%d\" % (VersionInfo.dwProductVersionMS,\n                                    VersionInfo.dwProductVersionLS)\n\n        # Debug build?\n        if VersionInfo.dwFileFlagsMask & win32.VS_FF_DEBUG:\n            DebugBuild = (VersionInfo.dwFileFlags & win32.VS_FF_DEBUG) != 0\n        else:\n            DebugBuild = None\n\n        # Legacy OS build?\n        LegacyBuild = (VersionInfo.dwFileOS != win32.VOS_NT_WINDOWS32)\n\n        # File type.\n        FileType = cls.__binary_types.get(VersionInfo.dwFileType)\n        if VersionInfo.dwFileType == win32.VFT_DRV:\n            FileType = cls.__driver_types.get(VersionInfo.dwFileSubtype)\n        elif VersionInfo.dwFileType == win32.VFT_FONT:\n            FileType = cls.__font_types.get(VersionInfo.dwFileSubtype)\n\n        # Timestamp, ex: \"Monday, July 7, 2013 (12:20:50.126)\".\n        # FIXME: how do we know the time zone?\n        FileDate = (VersionInfo.dwFileDateMS << 32) + VersionInfo.dwFileDateLS\n        if FileDate:\n            CreationTime = win32.FileTimeToSystemTime(FileDate)\n            CreationTimestamp = \"%s, %s %d, %d (%d:%d:%d.%d)\" % (\n                cls.__days_of_the_week[CreationTime.wDayOfWeek],\n                cls.__months[CreationTime.wMonth],\n                CreationTime.wDay,\n                CreationTime.wYear,\n                CreationTime.wHour,\n                CreationTime.wMinute,\n                CreationTime.wSecond,\n                CreationTime.wMilliseconds,\n            )\n        else:\n            CreationTimestamp = None\n\n        # Return the file version info.\n        return (\n            FileVersion,\n            ProductVersion,\n            DebugBuild,\n            LegacyBuild,\n            FileType,\n            CreationTimestamp,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_dbghelp(cls, pathname = None):\n\n        # If an explicit pathname was not given, search for the library.\n        if not pathname:\n\n            # Under WOW64 we'll treat AMD64 as I386.\n            arch = win32.arch\n            if arch == win32.ARCH_AMD64 and win32.bits == 32:\n                arch = win32.ARCH_I386\n\n            # Check if the architecture is supported.\n            if not arch in cls.__dbghelp_locations:\n                msg = \"Architecture %s is not currently supported.\"\n                raise NotImplementedError(msg  % arch)\n\n            # Grab all versions of the library we can find.\n            found = []\n            for pathname in cls.__dbghelp_locations[arch]:\n                if path.isfile(pathname):\n                    try:\n                        f_ver, p_ver = cls.get_file_version_info(pathname)[:2]\n                    except WindowsError:\n                        msg = \"Failed to parse file version metadata for: %s\"\n                        warnings.warn(msg % pathname)\n                    if not f_ver:\n                        f_ver = p_ver\n                    elif p_ver and p_ver > f_ver:\n                        f_ver = p_ver\n                    found.append( (f_ver, pathname) )\n\n            # If we found any, use the newest version.\n            if found:\n                found.sort()\n                pathname = found.pop()[1]\n\n            # If we didn't find any, trust the default DLL search algorithm.\n            else:\n                pathname = \"dbghelp.dll\"\n\n        # Load the library.\n        dbghelp = ctypes.windll.LoadLibrary(pathname)\n\n        # Set it globally as the library to be used.\n        ctypes.windll.dbghelp = dbghelp\n\n        # Return the library.\n        return dbghelp", "response": "Load the specified version of the Debugging Tools for Windows and return a WinDLL object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfixing the symbol store path. Equivalent to the C{.symfix} command in Microsoft WinDbg. If the symbol store path environment variable hasn't been set, this method will provide a default one. @type symbol_store_path: str or None @param symbol_store_path: (Optional) Symbol store path to set. @type remote: bool @param remote: (Optional) Defines the symbol store path to set when the C{symbol_store_path} is C{None}. If C{True} the default symbol store path is set to the Microsoft symbol server. Debug symbols will be downloaded through HTTP. This gives the best results but is also quite slow. If C{False} the default symbol store path is set to the local cache only. This prevents debug symbols from being downloaded and is faster, but unless you've installed the debug symbols on this machine or downloaded them in a previous debugging session, some symbols may be missing. If the C{symbol_store_path} argument is not C{None}, this argument is ignored entirely. @type force: bool @param force: (Optional) If C{True} the new symbol store path is set always. If C{False} the new symbol store path is only set if missing. This allows you to call this method preventively to ensure the symbol server is always set up correctly when running your script, but without messing up whatever configuration the user has. Example:: from winappdbg import Debug, System def simple_debugger( argv ): # Instance a Debug object debug = Debug( MyEventHandler() ) try: # Make sure the remote symbol store is set System.fix_symbol_store_path(remote = True, force = False) # Start a new process for debugging debug.execv( argv ) # Wait for the debugee to finish debug.loop() # Stop the debugger finally: debug.stop() @rtype: str or None @return: The previously set symbol store path if any, otherwise returns C{None}.", "response": "def fix_symbol_store_path(symbol_store_path = None,\n                              remote = True,\n                              force = False):\n        \"\"\"\n        Fix the symbol store path. Equivalent to the C{.symfix} command in\n        Microsoft WinDbg.\n\n        If the symbol store path environment variable hasn't been set, this\n        method will provide a default one.\n\n        @type  symbol_store_path: str or None\n        @param symbol_store_path: (Optional) Symbol store path to set.\n\n        @type  remote: bool\n        @param remote: (Optional) Defines the symbol store path to set when the\n            C{symbol_store_path} is C{None}.\n\n            If C{True} the default symbol store path is set to the Microsoft\n            symbol server. Debug symbols will be downloaded through HTTP.\n            This gives the best results but is also quite slow.\n\n            If C{False} the default symbol store path is set to the local\n            cache only. This prevents debug symbols from being downloaded and\n            is faster, but unless you've installed the debug symbols on this\n            machine or downloaded them in a previous debugging session, some\n            symbols may be missing.\n\n            If the C{symbol_store_path} argument is not C{None}, this argument\n            is ignored entirely.\n\n        @type  force: bool\n        @param force: (Optional) If C{True} the new symbol store path is set\n            always. If C{False} the new symbol store path is only set if\n            missing.\n\n            This allows you to call this method preventively to ensure the\n            symbol server is always set up correctly when running your script,\n            but without messing up whatever configuration the user has.\n\n            Example::\n                from winappdbg import Debug, System\n\n                def simple_debugger( argv ):\n\n                    # Instance a Debug object\n                    debug = Debug( MyEventHandler() )\n                    try:\n\n                        # Make sure the remote symbol store is set\n                        System.fix_symbol_store_path(remote = True,\n                                                      force = False)\n\n                        # Start a new process for debugging\n                        debug.execv( argv )\n\n                        # Wait for the debugee to finish\n                        debug.loop()\n\n                    # Stop the debugger\n                    finally:\n                        debug.stop()\n\n        @rtype:  str or None\n        @return: The previously set symbol store path if any,\n            otherwise returns C{None}.\n        \"\"\"\n        try:\n            if symbol_store_path is None:\n                local_path = \"C:\\\\SYMBOLS\"\n                if not path.isdir(local_path):\n                    local_path = \"C:\\\\Windows\\\\Symbols\"\n                    if not path.isdir(local_path):\n                        local_path = path.abspath(\".\")\n                if remote:\n                    symbol_store_path = (\n                        \"cache*;SRV*\"\n                        + local_path +\n                        \"*\"\n                        \"http://msdl.microsoft.com/download/symbols\"\n                    )\n                else:\n                    symbol_store_path = \"cache*;SRV*\" + local_path\n            previous = os.environ.get(\"_NT_SYMBOL_PATH\", None)\n            if not previous or force:\n                os.environ[\"_NT_SYMBOL_PATH\"] = symbol_store_path\n            return previous\n        except Exception:\n            e = sys.exc_info()[1]\n            warnings.warn(\"Cannot fix symbol path, reason: %s\" % str(e),\n                          RuntimeWarning)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the behavior of the debugged processes when the debugger thread dies.", "response": "def set_kill_on_exit_mode(bKillOnExit = False):\n        \"\"\"\n        Defines the behavior of the debugged processes when the debugging\n        thread dies. This method only affects the calling thread.\n\n        Works on the following platforms:\n\n         - Microsoft Windows XP and above.\n         - Wine (Windows Emulator).\n\n        Fails on the following platforms:\n\n         - Microsoft Windows 2000 and below.\n         - ReactOS.\n\n        @type  bKillOnExit: bool\n        @param bKillOnExit: C{True} to automatically kill processes when the\n            debugger thread dies. C{False} to automatically detach from\n            processes when the debugger thread dies.\n\n        @rtype:  bool\n        @return: C{True} on success, C{False} on error.\n\n        @note:\n            This call will fail if a debug port was not created. That is, if\n            the debugger isn't attached to at least one process. For more info\n            see: U{http://msdn.microsoft.com/en-us/library/ms679307.aspx}\n        \"\"\"\n        try:\n            # won't work before calling CreateProcess or DebugActiveProcess\n            win32.DebugSetProcessKillOnExit(bKillOnExit)\n        except (AttributeError, WindowsError):\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the contents of the specified MSR.", "response": "def read_msr(address):\n        \"\"\"\n        Read the contents of the specified MSR (Machine Specific Register).\n\n        @type  address: int\n        @param address: MSR to read.\n\n        @rtype:  int\n        @return: Value of the specified MSR.\n\n        @raise WindowsError:\n            Raises an exception on error.\n\n        @raise NotImplementedError:\n            Current architecture is not C{i386} or C{amd64}.\n\n        @warning:\n            It could potentially brick your machine.\n            It works on my machine, but your mileage may vary.\n        \"\"\"\n        if win32.arch not in (win32.ARCH_I386, win32.ARCH_AMD64):\n            raise NotImplementedError(\n                \"MSR reading is only supported on i386 or amd64 processors.\")\n        msr         = win32.SYSDBG_MSR()\n        msr.Address = address\n        msr.Data    = 0\n        win32.NtSystemDebugControl(win32.SysDbgReadMsr,\n                                   InputBuffer  = msr,\n                                   OutputBuffer = msr)\n        return msr.Data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting an MSR to the specified address and returns the contents of the MSR.", "response": "def write_msr(address, value):\n        \"\"\"\n        Set the contents of the specified MSR (Machine Specific Register).\n\n        @type  address: int\n        @param address: MSR to write.\n\n        @type  value: int\n        @param value: Contents to write on the MSR.\n\n        @raise WindowsError:\n            Raises an exception on error.\n\n        @raise NotImplementedError:\n            Current architecture is not C{i386} or C{amd64}.\n\n        @warning:\n            It could potentially brick your machine.\n            It works on my machine, but your mileage may vary.\n        \"\"\"\n        if win32.arch not in (win32.ARCH_I386, win32.ARCH_AMD64):\n            raise NotImplementedError(\n                \"MSR writing is only supported on i386 or amd64 processors.\")\n        msr         = win32.SYSDBG_MSR()\n        msr.Address = address\n        msr.Data    = value\n        win32.NtSystemDebugControl(win32.SysDbgWriteMsr, InputBuffer = msr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef enable_step_on_branch_mode(cls):\n        cls.write_msr(DebugRegister.DebugCtlMSR,\n                DebugRegister.BranchTrapFlag | DebugRegister.LastBranchRecord)", "response": "Enable single step on branch mode."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the source and destination addresses of the last taken branch.", "response": "def get_last_branch_location(cls):\n        \"\"\"\n        Returns the source and destination addresses of the last taken branch.\n\n        @rtype: tuple( int, int )\n        @return: Source and destination addresses of the last taken branch.\n\n        @raise WindowsError:\n            Raises an exception on error.\n\n        @raise NotImplementedError:\n            Current architecture is not C{i386} or C{amd64}.\n\n        @warning:\n            This method uses the processor's machine specific registers (MSR).\n            It could potentially brick your machine.\n            It works on my machine, but your mileage may vary.\n\n        @note:\n            It doesn't seem to work in VMWare or VirtualBox machines.\n            Maybe it fails in other virtualization/emulation environments,\n            no extensive testing was made so far.\n        \"\"\"\n        LastBranchFromIP = cls.read_msr(DebugRegister.LastBranchFromIP)\n        LastBranchToIP   = cls.read_msr(DebugRegister.LastBranchToIP)\n        return ( LastBranchFromIP, LastBranchToIP )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_postmortem_debugger(cls, bits = None):\n        if bits is None:\n            bits = cls.bits\n        elif bits not in (32, 64):\n            raise NotImplementedError(\"Unknown architecture (%r bits)\" % bits)\n\n        if bits == 32 and cls.bits == 64:\n            keyname = 'HKLM\\\\SOFTWARE\\\\Wow6432Node\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\AeDebug'\n        else:\n            keyname = 'HKLM\\\\SOFTWARE\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\AeDebug'\n\n        key = cls.registry[keyname]\n\n        debugger = key.get('Debugger')\n        auto     = key.get('Auto')\n        hotkey   = key.get('UserDebuggerHotkey')\n\n        if auto is not None:\n            auto = bool(auto)\n\n        return (debugger, auto, hotkey)", "response": "Returns the postmortem debugging settings from the Registry."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the exclusion list for the postmortem debugger.", "response": "def get_postmortem_exclusion_list(cls, bits = None):\n        \"\"\"\n        Returns the exclusion list for the postmortem debugger.\n\n        @see: L{get_postmortem_debugger}\n\n        @type  bits: int\n        @param bits: Set to C{32} for the 32 bits debugger, or C{64} for the\n            64 bits debugger. Set to {None} for the default (L{System.bits}).\n\n        @rtype:  list( str )\n        @return: List of excluded application filenames.\n\n        @raise WindowsError:\n            Raises an exception on error.\n        \"\"\"\n        if bits is None:\n            bits = cls.bits\n        elif bits not in (32, 64):\n            raise NotImplementedError(\"Unknown architecture (%r bits)\" % bits)\n\n        if bits == 32 and cls.bits == 64:\n            keyname = 'HKLM\\\\SOFTWARE\\\\Wow6432Node\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\AeDebug\\\\AutoExclusionList'\n        else:\n            keyname = 'HKLM\\\\SOFTWARE\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\AeDebug\\\\AutoExclusionList'\n\n        try:\n            key = cls.registry[keyname]\n        except KeyError:\n            return []\n\n        return [name for (name, enabled) in key.items() if enabled]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_postmortem_debugger(cls, cmdline,\n                                auto = None, hotkey = None, bits = None):\n        \"\"\"\n        Sets the postmortem debugging settings in the Registry.\n\n        @warning: This method requires administrative rights.\n\n        @see: L{get_postmortem_debugger}\n\n        @type  cmdline: str\n        @param cmdline: Command line to the new postmortem debugger.\n            When the debugger is invoked, the first \"%ld\" is replaced with the\n            process ID and the second \"%ld\" is replaced with the event handle.\n            Don't forget to enclose the program filename in double quotes if\n            the path contains spaces.\n\n        @type  auto: bool\n        @param auto: Set to C{True} if no user interaction is allowed, C{False}\n            to prompt a confirmation dialog before attaching.\n            Use C{None} to leave this value unchanged.\n\n        @type  hotkey: int\n        @param hotkey: Virtual key scan code for the user defined hotkey.\n            Use C{0} to disable the hotkey.\n            Use C{None} to leave this value unchanged.\n\n        @type  bits: int\n        @param bits: Set to C{32} for the 32 bits debugger, or C{64} for the\n            64 bits debugger. Set to {None} for the default (L{System.bits}).\n\n        @rtype:  tuple( str, bool, int )\n        @return: Previously defined command line and auto flag.\n\n        @raise WindowsError:\n            Raises an exception on error.\n        \"\"\"\n        if bits is None:\n            bits = cls.bits\n        elif bits not in (32, 64):\n            raise NotImplementedError(\"Unknown architecture (%r bits)\" % bits)\n\n        if bits == 32 and cls.bits == 64:\n            keyname = 'HKLM\\\\SOFTWARE\\\\Wow6432Node\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\AeDebug'\n        else:\n            keyname = 'HKLM\\\\SOFTWARE\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\AeDebug'\n\n        key = cls.registry[keyname]\n\n        if cmdline is not None:\n            key['Debugger'] = cmdline\n        if auto is not None:\n            key['Auto'] = int(bool(auto))\n        if hotkey is not None:\n            key['UserDebuggerHotkey'] = int(hotkey)", "response": "Sets the postmortem debugging settings in the Registry."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds the given filename to the exclusion list for postmortem debugging.", "response": "def add_to_postmortem_exclusion_list(cls, pathname, bits = None):\n        \"\"\"\n        Adds the given filename to the exclusion list for postmortem debugging.\n\n        @warning: This method requires administrative rights.\n\n        @see: L{get_postmortem_exclusion_list}\n\n        @type  pathname: str\n        @param pathname:\n            Application pathname to exclude from postmortem debugging.\n\n        @type  bits: int\n        @param bits: Set to C{32} for the 32 bits debugger, or C{64} for the\n            64 bits debugger. Set to {None} for the default (L{System.bits}).\n\n        @raise WindowsError:\n            Raises an exception on error.\n        \"\"\"\n        if bits is None:\n            bits = cls.bits\n        elif bits not in (32, 64):\n            raise NotImplementedError(\"Unknown architecture (%r bits)\" % bits)\n\n        if bits == 32 and cls.bits == 64:\n            keyname = 'HKLM\\\\SOFTWARE\\\\Wow6432Node\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\AeDebug\\\\AutoExclusionList'\n        else:\n            keyname = 'HKLM\\\\SOFTWARE\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\AeDebug\\\\AutoExclusionList'\n\n        try:\n            key = cls.registry[keyname]\n        except KeyError:\n            key = cls.registry.create(keyname)\n\n        key[pathname] = 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove the given filename from the debug exclusion list for the given architecture.", "response": "def remove_from_postmortem_exclusion_list(cls, pathname, bits = None):\n        \"\"\"\n        Removes the given filename to the exclusion list for postmortem\n        debugging from the Registry.\n\n        @warning: This method requires administrative rights.\n\n        @warning: Don't ever delete entries you haven't created yourself!\n            Some entries are set by default for your version of Windows.\n            Deleting them might deadlock your system under some circumstances.\n\n            For more details see:\n            U{http://msdn.microsoft.com/en-us/library/bb204634(v=vs.85).aspx}\n\n        @see: L{get_postmortem_exclusion_list}\n\n        @type  pathname: str\n        @param pathname: Application pathname to remove from the postmortem\n            debugging exclusion list.\n\n        @type  bits: int\n        @param bits: Set to C{32} for the 32 bits debugger, or C{64} for the\n            64 bits debugger. Set to {None} for the default (L{System.bits}).\n\n        @raise WindowsError:\n            Raises an exception on error.\n        \"\"\"\n        if bits is None:\n            bits = cls.bits\n        elif bits not in (32, 64):\n            raise NotImplementedError(\"Unknown architecture (%r bits)\" % bits)\n\n        if bits == 32 and cls.bits == 64:\n            keyname = 'HKLM\\\\SOFTWARE\\\\Wow6432Node\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\AeDebug\\\\AutoExclusionList'\n        else:\n            keyname = 'HKLM\\\\SOFTWARE\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\AeDebug\\\\AutoExclusionList'\n\n        try:\n            key = cls.registry[keyname]\n        except KeyError:\n            return\n\n        try:\n            del key[pathname]\n        except KeyError:\n            return"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_services():\n        with win32.OpenSCManager(\n            dwDesiredAccess = win32.SC_MANAGER_ENUMERATE_SERVICE\n            ) as hSCManager:\n                try:\n                    return win32.EnumServicesStatusEx(hSCManager)\n                except AttributeError:\n                    return win32.EnumServicesStatus(hSCManager)", "response": "Retrieve a list of all system services."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve a list of all active system services.", "response": "def get_active_services():\n        \"\"\"\n        Retrieve a list of all active system services.\n\n        @see: L{get_services},\n            L{start_service}, L{stop_service},\n            L{pause_service}, L{resume_service}\n\n        @rtype:  list( L{win32.ServiceStatusProcessEntry} )\n        @return: List of service status descriptors.\n        \"\"\"\n        with win32.OpenSCManager(\n            dwDesiredAccess = win32.SC_MANAGER_ENUMERATE_SERVICE\n        ) as hSCManager:\n            return [ entry for entry in win32.EnumServicesStatusEx(hSCManager,\n                        dwServiceType  = win32.SERVICE_WIN32,\n                        dwServiceState = win32.SERVICE_ACTIVE) \\\n                    if entry.ProcessId ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the service descriptor for the given service name.", "response": "def get_service(name):\n        \"\"\"\n        Get the service descriptor for the given service name.\n\n        @see: L{start_service}, L{stop_service},\n            L{pause_service}, L{resume_service}\n\n        @type  name: str\n        @param name: Service unique name. You can get this value from the\n            C{ServiceName} member of the service descriptors returned by\n            L{get_services} or L{get_active_services}.\n\n        @rtype:  L{win32.ServiceStatusProcess}\n        @return: Service status descriptor.\n        \"\"\"\n        with win32.OpenSCManager(\n            dwDesiredAccess = win32.SC_MANAGER_ENUMERATE_SERVICE\n        ) as hSCManager:\n            with win32.OpenService(hSCManager, name,\n                                   dwDesiredAccess = win32.SERVICE_QUERY_STATUS\n            ) as hService:\n                try:\n                    return win32.QueryServiceStatusEx(hService)\n                except AttributeError:\n                    return win32.QueryServiceStatus(hService)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_service_display_name(name):\n        with win32.OpenSCManager(\n            dwDesiredAccess = win32.SC_MANAGER_ENUMERATE_SERVICE\n        ) as hSCManager:\n            return win32.GetServiceDisplayName(hSCManager, name)", "response": "Get the service display name for the given service name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the service unique name given its display name.", "response": "def get_service_from_display_name(displayName):\n        \"\"\"\n        Get the service unique name given its display name.\n\n        @see: L{get_service}\n\n        @type  displayName: str\n        @param displayName: Service display name. You can get this value from\n            the C{DisplayName} member of the service descriptors returned by\n            L{get_services} or L{get_active_services}.\n\n        @rtype:  str\n        @return: Service unique name.\n        \"\"\"\n        with win32.OpenSCManager(\n            dwDesiredAccess = win32.SC_MANAGER_ENUMERATE_SERVICE\n        ) as hSCManager:\n            return win32.GetServiceKeyName(hSCManager, displayName)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start_service(name, argv = None):\n        with win32.OpenSCManager(\n            dwDesiredAccess = win32.SC_MANAGER_CONNECT\n        ) as hSCManager:\n            with win32.OpenService(hSCManager, name,\n                                   dwDesiredAccess = win32.SERVICE_START\n            ) as hService:\n                win32.StartService(hService)", "response": "Start the service given by name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstopping the service given by name.", "response": "def stop_service(name):\n        \"\"\"\n        Stop the service given by name.\n\n        @warn: This method requires UAC elevation in Windows Vista and above.\n\n        @see: L{get_services}, L{get_active_services},\n            L{start_service}, L{pause_service}, L{resume_service}\n        \"\"\"\n        with win32.OpenSCManager(\n            dwDesiredAccess = win32.SC_MANAGER_CONNECT\n        ) as hSCManager:\n            with win32.OpenService(hSCManager, name,\n                                   dwDesiredAccess = win32.SERVICE_STOP\n            ) as hService:\n                win32.ControlService(hService, win32.SERVICE_CONTROL_STOP)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pause_service(name):\n        with win32.OpenSCManager(\n            dwDesiredAccess = win32.SC_MANAGER_CONNECT\n        ) as hSCManager:\n            with win32.OpenService(hSCManager, name,\n                                dwDesiredAccess = win32.SERVICE_PAUSE_CONTINUE\n            ) as hService:\n                win32.ControlService(hService, win32.SERVICE_CONTROL_PAUSE)", "response": "Pause the service given by name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresumes the service given by name.", "response": "def resume_service(name):\n        \"\"\"\n        Resume the service given by name.\n\n        @warn: This method requires UAC elevation in Windows Vista and above.\n\n        @note: Not all services support this.\n\n        @see: L{get_services}, L{get_active_services},\n            L{start_service}, L{stop_service}, L{pause_service}\n        \"\"\"\n        with win32.OpenSCManager(\n            dwDesiredAccess = win32.SC_MANAGER_CONNECT\n        ) as hSCManager:\n            with win32.OpenService(hSCManager, name,\n                                dwDesiredAccess = win32.SERVICE_PAUSE_CONTINUE\n            ) as hService:\n                win32.ControlService(hService, win32.SERVICE_CONTROL_CONTINUE)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the hardware address on Unix by running ifconfig.", "response": "def _ifconfig_getnode():\n    \"\"\"Get the hardware address on Unix by running ifconfig.\"\"\"\n\n    # This works on Linux ('' or '-a'), Tru64 ('-av'), but not all Unixes.\n    for args in ('', '-a', '-av'):\n        mac = _find_mac('ifconfig', args, ['hwaddr', 'ether'], lambda i: i+1)\n        if mac:\n            return mac\n\n    import socket\n    ip_addr = socket.gethostbyname(socket.gethostname())\n\n    # Try getting the MAC addr from arp based on our IP address (Solaris).\n    mac = _find_mac('arp', '-an', [ip_addr], lambda i: -1)\n    if mac:\n        return mac\n\n    # This might work on HP-UX.\n    mac = _find_mac('lanscan', '-ai', ['lan0'], lambda i: 0)\n    if mac:\n        return mac\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _ipconfig_getnode():\n    import os, re\n    dirs = ['', r'c:\\windows\\system32', r'c:\\winnt\\system32']\n    try:\n        import ctypes\n        buffer = ctypes.create_string_buffer(300)\n        ctypes.windll.kernel32.GetSystemDirectoryA(buffer, 300)  # @UndefinedVariable\n        dirs.insert(0, buffer.value.decode('mbcs'))\n    except:\n        pass\n    for dir in dirs:\n        try:\n            pipe = os.popen(os.path.join(dir, 'ipconfig') + ' /all')\n        except IOError:\n            continue\n        for line in pipe:\n            value = line.split(':')[-1].strip().lower()\n            if re.match('([0-9a-f][0-9a-f]-){5}[0-9a-f][0-9a-f]', value):\n                return int(value.replace('-', ''), 16)", "response": "Get the hardware address on Windows by running ipconfig. exe."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _netbios_getnode():\n    import win32wnet, netbios\n    ncb = netbios.NCB()\n    ncb.Command = netbios.NCBENUM\n    ncb.Buffer = adapters = netbios.LANA_ENUM()\n    adapters._pack()\n    if win32wnet.Netbios(ncb) != 0:\n        return\n    adapters._unpack()\n    for i in range(adapters.length):\n        ncb.Reset()\n        ncb.Command = netbios.NCBRESET\n        ncb.Lana_num = ord(adapters.lana[i])\n        if win32wnet.Netbios(ncb) != 0:\n            continue\n        ncb.Reset()\n        ncb.Command = netbios.NCBASTAT\n        ncb.Lana_num = ord(adapters.lana[i])\n        ncb.Callname = '*'.ljust(16)\n        ncb.Buffer = status = netbios.ADAPTER_STATUS()\n        if win32wnet.Netbios(ncb) != 0:\n            continue\n        status._unpack()\n        bytes = map(ord, status.adapter_address)\n        return ((bytes[0]<<40L) + (bytes[1]<<32L) + (bytes[2]<<24L) +\n                (bytes[3]<<16L) + (bytes[4]<<8L) + bytes[5])", "response": "Get the hardware address on Windows using NetBIOS calls."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the hardware address as a 48 - bit positive integer.", "response": "def getnode():\n    \"\"\"Get the hardware address as a 48-bit positive integer.\n\n    The first time this runs, it may launch a separate program, which could\n    be quite slow.  If all attempts to obtain the hardware address fail, we\n    choose a random 48-bit number with its eighth bit set to 1 as recommended\n    in RFC 4122.\n    \"\"\"\n\n    global _node\n    if _node is not None:\n        return _node\n\n    import sys\n    if sys.platform == 'win32':\n        getters = [_windll_getnode, _netbios_getnode, _ipconfig_getnode]\n    else:\n        getters = [_unixdll_getnode, _ifconfig_getnode]\n\n    for getter in getters + [_random_getnode]:\n        try:\n            _node = getter()\n        except:\n            continue\n        if _node is not None:\n            return _node"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a UUID from a host ID sequence number and the current time.", "response": "def uuid1(node=None, clock_seq=None):\n    \"\"\"Generate a UUID from a host ID, sequence number, and the current time.\n    If 'node' is not given, getnode() is used to obtain the hardware\n    address.  If 'clock_seq' is given, it is used as the sequence number;\n    otherwise a random 14-bit sequence number is chosen.\"\"\"\n\n    # When the system provides a version-1 UUID generator, use it (but don't\n    # use UuidCreate here because its UUIDs don't conform to RFC 4122).\n    if _uuid_generate_time and node is clock_seq is None:\n        _uuid_generate_time(_buffer)\n        return UUID(bytes=_buffer.raw)\n\n    global _last_timestamp\n    import time\n    nanoseconds = int(time.time() * 1e9)\n    # 0x01b21dd213814000 is the number of 100-ns intervals between the\n    # UUID epoch 1582-10-15 00:00:00 and the Unix epoch 1970-01-01 00:00:00.\n    timestamp = int(nanoseconds/100) + 0x01b21dd213814000L\n    if timestamp <= _last_timestamp:\n        timestamp = _last_timestamp + 1\n    _last_timestamp = timestamp\n    if clock_seq is None:\n        import random\n        clock_seq = random.randrange(1<<14L) # instead of stable storage\n    time_low = timestamp & 0xffffffffL\n    time_mid = (timestamp >> 32L) & 0xffffL\n    time_hi_version = (timestamp >> 48L) & 0x0fffL\n    clock_seq_low = clock_seq & 0xffL\n    clock_seq_hi_variant = (clock_seq >> 8L) & 0x3fL\n    if node is None:\n        node = getnode()\n    return UUID(fields=(time_low, time_mid, time_hi_version,\n                        clock_seq_hi_variant, clock_seq_low, node), version=1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a UUID from the MD5 hash of a namespace UUID and a name.", "response": "def uuid3(namespace, name):\n    \"\"\"Generate a UUID from the MD5 hash of a namespace UUID and a name.\"\"\"\n    import md5\n    hash = md5.md5(namespace.bytes + name).digest()\n    return UUID(bytes=hash[:16], version=3)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a random UUID.", "response": "def uuid4():\n    \"\"\"Generate a random UUID.\"\"\"\n\n    # When the system provides a version-4 UUID generator, use it.\n    if _uuid_generate_random:\n        _uuid_generate_random(_buffer)\n        return UUID(bytes=_buffer.raw)\n\n    # Otherwise, get randomness from urandom or the 'random' module.\n    try:\n        import os\n        return UUID(bytes=os.urandom(16), version=4)\n    except:\n        import random\n        bytes = [chr(random.randrange(256)) for i in range(16)]\n        return UUID(bytes=bytes, version=4)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a UUID from the SHA - 1 hash of a namespace UUID and a name.", "response": "def uuid5(namespace, name):\n    \"\"\"Generate a UUID from the SHA-1 hash of a namespace UUID and a name.\"\"\"\n    import sha\n    hash = sha.sha(namespace.bytes + name).digest()\n    return UUID(bytes=hash[:16], version=5)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef default_should_trace_hook(frame, filename):\n    '''\n    Return True if this frame should be traced, False if tracing should be blocked.\n    '''\n    # First, check whether this code object has a cached value\n    ignored_lines = _filename_to_ignored_lines.get(filename)\n    if ignored_lines is None:\n        # Now, look up that line of code and check for a @DontTrace\n        # preceding or on the same line as the method.\n        # E.g.:\n        # #@DontTrace\n        # def test():\n        #     pass\n        #  ... or ...\n        # def test(): #@DontTrace\n        #     pass\n        ignored_lines = {}\n        lines = linecache.getlines(filename)\n        for i_line, line in enumerate(lines):\n            j = line.find('#')\n            if j >= 0:\n                comment = line[j:]\n                if DONT_TRACE_TAG in comment:\n                    ignored_lines[i_line] = 1\n                    \n                    #Note: when it's found in the comment, mark it up and down for the decorator lines found.\n                    k = i_line - 1\n                    while k >= 0:\n                        if RE_DECORATOR.match(lines[k]):\n                            ignored_lines[k] = 1\n                            k -= 1\n                        else:\n                            break\n                        \n                    k = i_line + 1\n                    while k <= len(lines):\n                        if RE_DECORATOR.match(lines[k]):\n                            ignored_lines[k] = 1\n                            k += 1\n                        else:\n                            break\n                        \n\n        _filename_to_ignored_lines[filename] = ignored_lines\n\n    func_line = frame.f_code.co_firstlineno - 1 # co_firstlineno is 1-based, so -1 is needed\n    return not (\n        func_line - 1 in ignored_lines or #-1 to get line before method \n        func_line in ignored_lines)", "response": "Return True if this frame should be traced False if tracing should be blocked."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear_trace_filter_cache():\n    '''\n    Clear the trace filter cache.\n    Call this after reloading.\n    '''\n    global should_trace_hook\n    try:\n        # Need to temporarily disable a hook because otherwise\n        # _filename_to_ignored_lines.clear() will never complete.\n        old_hook = should_trace_hook\n        should_trace_hook = None\n\n        # Clear the linecache\n        linecache.clearcache()\n        _filename_to_ignored_lines.clear()\n\n    finally:\n        should_trace_hook = old_hook", "response": "Clear the trace filter cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trace_filter(mode):\n    '''\n    Set the trace filter mode.\n\n    mode: Whether to enable the trace hook.\n      True: Trace filtering on (skipping methods tagged @DontTrace)\n      False: Trace filtering off (trace methods tagged @DontTrace)\n      None/default: Toggle trace filtering.\n    '''\n    global should_trace_hook\n    if mode is None:\n        mode = should_trace_hook is None\n\n    if mode:\n        should_trace_hook = default_should_trace_hook\n    else:\n        should_trace_hook = None\n\n    return mode", "response": "Sets the trace filter mode."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlints the file. Return an array of error dicts if appropriate.", "response": "def run(self, path, **meta):\n        \"\"\"Lint the file. Return an array of error dicts if appropriate.\"\"\"\n        with open(os.devnull, 'w') as devnull:\n            # Suppress isort messages\n            sys.stdout = devnull\n\n            if SortImports(path, check=True).incorrectly_sorted:\n                return [{\n                    'lnum': 0,\n                    'col': 0,\n                    'text': 'Incorrectly sorted imports.',\n                    'type': 'ISORT'\n                }]\n            else:\n                return []"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dump(self, filename):\n        f = open(filename, \"wb\")\n        pickle.dump(self.__dict__, f, 2)\n        f.close()", "response": "Dump the grammar tables to a pickle file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(self, filename):\n        f = open(filename, \"rb\")\n        d = pickle.load(f)\n        f.close()\n        self.__dict__.update(d)", "response": "Load the grammar tables from a pickle file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint the grammar tables to standard output for debugging.", "response": "def report(self):\n        \"\"\"Dump the grammar tables to standard output, for debugging.\"\"\"\n        from pprint import pprint\n        print \"s2n\"\n        pprint(self.symbol2number)\n        print \"n2s\"\n        pprint(self.number2symbol)\n        print \"states\"\n        pprint(self.states)\n        print \"dfas\"\n        pprint(self.dfas)\n        print \"labels\"\n        pprint(self.labels)\n        print \"start\", self.start"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dyld_image_suffix_search(iterator, env=None):\n    suffix = dyld_image_suffix(env)\n    if suffix is None:\n        return iterator\n    def _inject(iterator=iterator, suffix=suffix):\n        for path in iterator:\n            if path.endswith('.dylib'):\n                yield path[:-len('.dylib')] + suffix + '.dylib'\n            else:\n                yield path + suffix\n            yield path\n    return _inject()", "response": "Given an iterator and a DYLD_IMAGE_SUFFIX add DYLD_IMAGE_SUFFIX semantics to the end of the path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmean to be used as class B: @overrides(A.m1) def m1(self): pass", "response": "def overrides(method):\n    '''\n    Meant to be used as\n    \n    class B:\n        @overrides(A.m1)\n        def m1(self):\n            pass\n    '''\n    def wrapper(func):\n        if func.__name__ != method.__name__:\n            msg = \"Wrong @override: %r expected, but overwriting %r.\"\n            msg = msg % (func.__name__, method.__name__)\n            raise AssertionError(msg)\n\n        if func.__doc__ is None:\n            func.__doc__ = method.__doc__\n\n        return func\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef traverse_imports(names):\n    pending = [names]\n    while pending:\n        node = pending.pop()\n        if node.type == token.NAME:\n            yield node.value\n        elif node.type == syms.dotted_name:\n            yield \"\".join([ch.value for ch in node.children])\n        elif node.type == syms.dotted_as_name:\n            pending.append(node.children[0])\n        elif node.type == syms.dotted_as_names:\n            pending.extend(node.children[::-2])\n        else:\n            raise AssertionError(\"unkown node type\")", "response": "Walks over all the names imported in a dotted_as_names node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unmodified_isinstance(*bases):\n    class UnmodifiedIsInstance(type):\n        if sys.version_info[0] == 2 and sys.version_info[1] <= 6:\n\n            @classmethod\n            def __instancecheck__(cls, instance):\n                if cls.__name__ in (str(base.__name__) for base in bases):\n                    return isinstance(instance, bases)\n\n                subclass = getattr(instance, '__class__', None)\n                subtype = type(instance)\n                instance_type = getattr(abc, '_InstanceType', None)\n                if not instance_type:\n                    class test_object:\n                        pass\n                    instance_type = type(test_object)\n                if subtype is instance_type:\n                    subtype = subclass\n                if subtype is subclass or subclass is None:\n                    return cls.__subclasscheck__(subtype)\n                return (cls.__subclasscheck__(subclass) or cls.__subclasscheck__(subtype))\n        else:\n            @classmethod\n            def __instancecheck__(cls, instance):\n                if cls.__name__ in (str(base.__name__) for base in bases):\n                    return isinstance(instance, bases)\n\n                return type.__instancecheck__(cls, instance)\n\n    return with_metaclass(UnmodifiedIsInstance, *bases)", "response": "This is a class decorator that allows for unmodified_isinstance calls against built in instances."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do(self, arg):\n    \".exchain - Show the SEH chain\"\n    thread = self.get_thread_from_prefix()\n    print \"Exception handlers for thread %d\" % thread.get_tid()\n    print\n    table = Table()\n    table.addRow(\"Block\", \"Function\")\n    bits = thread.get_bits()\n    for (seh, seh_func) in thread.get_seh_chain():\n        if seh is not None:\n            seh      = HexDump.address(seh, bits)\n        if seh_func is not None:\n            seh_func = HexDump.address(seh_func, bits)\n        table.addRow(seh, seh_func)\n    print table.getOutput()", "response": ". exchain - Show the SEH chain"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_debug_options(opts):\n    options = {}\n    if not opts:\n        return options\n\n    for opt in opts.split(';'):\n        try:\n            key, value = opt.split('=')\n        except ValueError:\n            continue\n        try:\n            options[key] = DEBUG_OPTIONS_PARSER[key](value)\n        except KeyError:\n            continue\n\n    return options", "response": "Parses debug options from the command line."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _compile_varchar_mysql(element, compiler, **kw):\n    if not element.length or element.length == 'max':\n        return \"TEXT\"\n    else:\n        return compiler.visit_VARCHAR(element, **kw)", "response": "MySQL hack to avoid the VARCHAR requires a length error."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Transactional(fn, self, *argv, **argd):\n    return self._transactional(fn, *argv, **argd)", "response": "Decorator that wraps DAO methods to handle transactions automatically."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconnect to the SQLAlchemy database.", "response": "def connect(dbapi_connection, connection_record):\n        \"\"\"\n        Called once by SQLAlchemy for each new SQLite DB-API connection.\n\n        Here is where we issue some PRAGMA statements to configure how we're\n        going to access the SQLite database.\n\n        @param dbapi_connection:\n            A newly connected raw SQLite DB-API connection.\n\n        @param connection_record:\n            Unused by this method.\n        \"\"\"\n        try:\n            cursor = dbapi_connection.cursor()\n            try:\n                cursor.execute(\"PRAGMA foreign_keys = ON;\")\n                cursor.execute(\"PRAGMA foreign_keys;\")\n                if cursor.fetchone()[0] != 1:\n                    raise Exception()\n            finally:\n                cursor.close()\n        except Exception:\n            dbapi_connection.close()\n            raise sqlite3.Error()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls a method in a transaction and returns the result.", "response": "def _transactional(self, method, *argv, **argd):\n        \"\"\"\n        Begins a transaction and calls the given DAO method.\n\n        If the method executes successfully the transaction is commited.\n\n        If the method fails, the transaction is rolled back.\n\n        @type  method: callable\n        @param method: Bound method of this class or one of its subclasses.\n            The first argument will always be C{self}.\n\n        @return: The return value of the method call.\n\n        @raise Exception: Any exception raised by the method.\n        \"\"\"\n        self._session.begin(subtransactions = True)\n        try:\n            result = method(self, *argv, **argd)\n            self._session.commit()\n            return result\n        except:\n            self._session.rollback()\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef toMBI(self, getMemoryDump = False):\n        mbi = win32.MemoryBasicInformation()\n        mbi.BaseAddress = self.address\n        mbi.RegionSize  = self.size\n        mbi.State       = self._parse_state(self.state)\n        mbi.Protect     = self._parse_access(self.access)\n        mbi.Type        = self._parse_type(self.type)\n        if self.alloc_base is not None:\n            mbi.AllocationBase = self.alloc_base\n        else:\n            mbi.AllocationBase = mbi.BaseAddress\n        if self.alloc_access is not None:\n            mbi.AllocationProtect = self._parse_access(self.alloc_access)\n        else:\n            mbi.AllocationProtect = mbi.Protect\n        if self.filename is not None:\n            mbi.filename = self.filename\n        if getMemoryDump and self.content is not None:\n            mbi.content  = self.content\n        return mbi", "response": "Converts this object into a Memory Basic Information object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef toCrash(self, getMemoryDump = False):\n        crash = Marshaller.loads(str(self.data))\n        if not isinstance(crash, Crash):\n            raise TypeError(\n                \"Expected Crash instance, got %s instead\" % type(crash))\n        crash._rowid = self.id\n        if not crash.memoryMap:\n            memory = getattr(self, \"memory\", [])\n            if memory:\n                crash.memoryMap = [dto.toMBI(getMemoryDump) for dto in memory]\n        return crash", "response": "Converts the object to a Crash object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a new crash dump to the database optionally filtering out duplicate crashes.", "response": "def add(self, crash, allow_duplicates = True):\n        \"\"\"\n        Add a new crash dump to the database, optionally filtering them by\n        signature to avoid duplicates.\n\n        @type  crash: L{Crash}\n        @param crash: Crash object.\n\n        @type  allow_duplicates: bool\n        @param allow_duplicates: (Optional)\n            C{True} to always add the new crash dump.\n            C{False} to only add the crash dump if no other crash with the\n            same signature is found in the database.\n\n            Sometimes, your fuzzer turns out to be I{too} good. Then you find\n            youself browsing through gigabytes of crash dumps, only to find\n            a handful of actual bugs in them. This simple heuristic filter\n            saves you the trouble by discarding crashes that seem to be similar\n            to another one you've already found.\n        \"\"\"\n\n        # Filter out duplicated crashes, if requested.\n        if not allow_duplicates:\n            signature = pickle.dumps(crash.signature, protocol = 0)\n            if self._session.query(CrashDTO.id)                \\\n                            .filter_by(signature = signature) \\\n                            .count() > 0:\n                return\n\n        # Fill out a new row for the crashes table.\n        crash_id = self.__add_crash(crash)\n\n        # Fill out new rows for the memory dump.\n        self.__add_memory(crash_id, crash.memoryMap)\n\n        # On success set the row ID for the Crash object.\n        # WARNING: In nested calls, make sure to delete\n        # this property before a session rollback!\n        crash._rowid = crash_id"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find(self,\n             signature = None, order = 0,\n             since     = None, until = None,\n             offset    = None, limit = None):\n        \"\"\"\n        Retrieve all crash dumps in the database, optionally filtering them by\n        signature and timestamp, and/or sorting them by timestamp.\n\n        Results can be paged to avoid consuming too much memory if the database\n        is large.\n\n        @see: L{find_by_example}\n\n        @type  signature: object\n        @param signature: (Optional) Return only through crashes matching\n            this signature. See L{Crash.signature} for more details.\n\n        @type  order: int\n        @param order: (Optional) Sort by timestamp.\n            If C{== 0}, results are not sorted.\n            If C{> 0}, results are sorted from older to newer.\n            If C{< 0}, results are sorted from newer to older.\n\n        @type  since: datetime\n        @param since: (Optional) Return only the crashes after and\n            including this date and time.\n\n        @type  until: datetime\n        @param until: (Optional) Return only the crashes before this date\n            and time, not including it.\n\n        @type  offset: int\n        @param offset: (Optional) Skip the first I{offset} results.\n\n        @type  limit: int\n        @param limit: (Optional) Return at most I{limit} results.\n\n        @rtype:  list(L{Crash})\n        @return: List of Crash objects.\n        \"\"\"\n\n        # Validate the parameters.\n        if since and until and since > until:\n            warnings.warn(\"CrashDAO.find() got the 'since' and 'until'\"\n                          \" arguments reversed, corrected automatically.\")\n            since, until = until, since\n        if limit is not None and not limit:\n            warnings.warn(\"CrashDAO.find() was set a limit of 0 results,\"\n                          \" returning without executing a query.\")\n            return []\n\n        # Build the SQL query.\n        query = self._session.query(CrashDTO)\n        if signature is not None:\n            sig_pickled = pickle.dumps(signature, protocol = 0)\n            query = query.filter(CrashDTO.signature == sig_pickled)\n        if since:\n            query = query.filter(CrashDTO.timestamp >= since)\n        if until:\n            query = query.filter(CrashDTO.timestamp < until)\n        if order:\n            if order > 0:\n                query = query.order_by(asc(CrashDTO.timestamp))\n            else:\n                query = query.order_by(desc(CrashDTO.timestamp))\n        else:\n            # Default ordering is by row ID, to get consistent results.\n            # Also some database engines require ordering when using offsets.\n            query = query.order_by(asc(CrashDTO.id))\n        if offset:\n            query = query.offset(offset)\n        if limit:\n            query = query.limit(limit)\n\n        # Execute the SQL query and convert the results.\n        try:\n            return [dto.toCrash() for dto in query.all()]\n        except NoResultFound:\n            return []", "response": "Retrieve all crashes in the database optionally filtering them by signature and timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_by_example(self, crash, offset = None, limit = None):\n\n        # Validate the parameters.\n        if limit is not None and not limit:\n            warnings.warn(\"CrashDAO.find_by_example() was set a limit of 0\"\n                          \" results, returning without executing a query.\")\n            return []\n\n        # Build the query.\n        query = self._session.query(CrashDTO)\n\n        # Order by row ID to get consistent results.\n        # Also some database engines require ordering when using offsets.\n        query = query.asc(CrashDTO.id)\n\n        # Build a CrashDTO from the Crash object.\n        dto = CrashDTO(crash)\n\n        # Filter all the fields in the crashes table that are present in the\n        # CrashDTO object and not set to None, except for the row ID.\n        for name, column in compat.iteritems(CrashDTO.__dict__):\n            if not name.startswith('__') and name not in ('id',\n                                                          'signature',\n                                                          'data'):\n                if isinstance(column, Column):\n                    value = getattr(dto, name, None)\n                    if value is not None:\n                        query = query.filter(column == value)\n\n        # Page the query.\n        if offset:\n            query = query.offset(offset)\n        if limit:\n            query = query.limit(limit)\n\n        # Execute the SQL query and convert the results.\n        try:\n            return [dto.toCrash() for dto in query.all()]\n        except NoResultFound:\n            return []", "response": "Find all common properties with the crash dump that are not in the database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef count(self, signature = None):\n        query = self._session.query(CrashDTO.id)\n        if signature:\n            sig_pickled = pickle.dumps(signature, protocol = 0)\n            query = query.filter_by(signature = sig_pickled)\n        return query.count()", "response": "Returns the number of crash dumps stored in this database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove the given crash dump from the database.", "response": "def delete(self, crash):\n        \"\"\"\n        Remove the given crash dump from the database.\n\n        @type  crash: L{Crash}\n        @param crash: Crash dump to remove.\n        \"\"\"\n        query = self._session.query(CrashDTO).filter_by(id = crash._rowid)\n        query.delete(synchronize_session = False)\n        del crash._rowid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an iterable of the parts in the final repr string.", "response": "def _repr(self, obj, level):\n        '''Returns an iterable of the parts in the final repr string.'''\n\n        try:\n            obj_repr = type(obj).__repr__\n        except Exception:\n            obj_repr = None\n\n        def has_obj_repr(t):\n            r = t.__repr__\n            try:\n                return obj_repr == r\n            except Exception:\n                return obj_repr is r\n\n        for t, prefix, suffix, comma in self.collection_types:\n            if isinstance(obj, t) and has_obj_repr(t):\n                return self._repr_iter(obj, level, prefix, suffix, comma)\n\n        for t, prefix, suffix, item_prefix, item_sep, item_suffix in self.dict_types:  # noqa\n            if isinstance(obj, t) and has_obj_repr(t):\n                return self._repr_dict(obj, level, prefix, suffix,\n                                       item_prefix, item_sep, item_suffix)\n\n        for t in self.string_types:\n            if isinstance(obj, t) and has_obj_repr(t):\n                return self._repr_str(obj, level)\n\n        if self._is_long_iter(obj):\n            return self._repr_long_iter(obj)\n\n        return self._repr_other(obj, level)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreducing a compiled pattern tree to an anonymized intermediate representation suitable for feeding the pattern elements.", "response": "def reduce_tree(node, parent=None):\n    \"\"\"\n    Internal function. Reduces a compiled pattern tree to an\n    intermediate representation suitable for feeding the\n    automaton. This also trims off any optional pattern elements(like\n    [a], a*).\n    \"\"\"\n\n    new_node = None\n    #switch on the node type\n    if node.type == syms.Matcher:\n        #skip\n        node = node.children[0]\n\n    if node.type == syms.Alternatives  :\n        #2 cases\n        if len(node.children) <= 2:\n            #just a single 'Alternative', skip this node\n            new_node = reduce_tree(node.children[0], parent)\n        else:\n            #real alternatives\n            new_node = MinNode(type=TYPE_ALTERNATIVES)\n            #skip odd children('|' tokens)\n            for child in node.children:\n                if node.children.index(child)%2:\n                    continue\n                reduced = reduce_tree(child, new_node)\n                if reduced is not None:\n                    new_node.children.append(reduced)\n    elif node.type == syms.Alternative:\n        if len(node.children) > 1:\n\n            new_node = MinNode(type=TYPE_GROUP)\n            for child in node.children:\n                reduced = reduce_tree(child, new_node)\n                if reduced:\n                    new_node.children.append(reduced)\n            if not new_node.children:\n                # delete the group if all of the children were reduced to None\n                new_node = None\n\n        else:\n            new_node = reduce_tree(node.children[0], parent)\n\n    elif node.type == syms.Unit:\n        if (isinstance(node.children[0], pytree.Leaf) and\n            node.children[0].value == '('):\n            #skip parentheses\n            return reduce_tree(node.children[1], parent)\n        if ((isinstance(node.children[0], pytree.Leaf) and\n               node.children[0].value == '[')\n               or\n               (len(node.children)>1 and\n               hasattr(node.children[1], \"value\") and\n               node.children[1].value == '[')):\n            #skip whole unit if its optional\n            return None\n\n        leaf = True\n        details_node = None\n        alternatives_node = None\n        has_repeater = False\n        repeater_node = None\n        has_variable_name = False\n\n        for child in node.children:\n            if child.type == syms.Details:\n                leaf = False\n                details_node = child\n            elif child.type == syms.Repeater:\n                has_repeater = True\n                repeater_node = child\n            elif child.type == syms.Alternatives:\n                alternatives_node = child\n            if hasattr(child, 'value') and child.value == '=': # variable name\n                has_variable_name = True\n\n        #skip variable name\n        if has_variable_name:\n            #skip variable name, '='\n            name_leaf = node.children[2]\n            if hasattr(name_leaf, 'value') and name_leaf.value == '(':\n                # skip parenthesis\n                name_leaf = node.children[3]\n        else:\n            name_leaf = node.children[0]\n\n        #set node type\n        if name_leaf.type == token_labels.NAME:\n            #(python) non-name or wildcard\n            if name_leaf.value == 'any':\n                new_node = MinNode(type=TYPE_ANY)\n            else:\n                if hasattr(token_labels, name_leaf.value):\n                    new_node = MinNode(type=getattr(token_labels, name_leaf.value))\n                else:\n                    new_node = MinNode(type=getattr(pysyms, name_leaf.value))\n\n        elif name_leaf.type == token_labels.STRING:\n            #(python) name or character; remove the apostrophes from\n            #the string value\n            name = name_leaf.value.strip(\"'\")\n            if name in tokens:\n                new_node = MinNode(type=tokens[name])\n            else:\n                new_node = MinNode(type=token_labels.NAME, name=name)\n        elif name_leaf.type == syms.Alternatives:\n            new_node = reduce_tree(alternatives_node, parent)\n\n        #handle repeaters\n        if has_repeater:\n            if repeater_node.children[0].value == '*':\n                #reduce to None\n                new_node = None\n            elif repeater_node.children[0].value == '+':\n                #reduce to a single occurence i.e. do nothing\n                pass\n            else:\n                #TODO: handle {min, max} repeaters\n                raise NotImplementedError\n                pass\n\n        #add children\n        if details_node and new_node is not None:\n            for child in details_node.children[1:-1]:\n                #skip '<', '>' markers\n                reduced = reduce_tree(child, new_node)\n                if reduced is not None:\n                    new_node.children.append(reduced)\n    if new_node:\n        new_node.parent = parent\n    return new_node"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npick the most characteristic from a list of linear patterns", "response": "def get_characteristic_subpattern(subpatterns):\n    \"\"\"Picks the most characteristic from a list of linear patterns\n    Current order used is:\n    names > common_names > common_chars\n    \"\"\"\n    if not isinstance(subpatterns, list):\n        return subpatterns\n    if len(subpatterns)==1:\n        return subpatterns[0]\n\n    # first pick out the ones containing variable names\n    subpatterns_with_names = []\n    subpatterns_with_common_names = []\n    common_names = ['in', 'for', 'if' , 'not', 'None']\n    subpatterns_with_common_chars = []\n    common_chars = \"[]().,:\"\n    for subpattern in subpatterns:\n        if any(rec_test(subpattern, lambda x: type(x) is str)):\n            if any(rec_test(subpattern,\n                            lambda x: isinstance(x, str) and x in common_chars)):\n                subpatterns_with_common_chars.append(subpattern)\n            elif any(rec_test(subpattern,\n                              lambda x: isinstance(x, str) and x in common_names)):\n                subpatterns_with_common_names.append(subpattern)\n\n            else:\n                subpatterns_with_names.append(subpattern)\n\n    if subpatterns_with_names:\n        subpatterns = subpatterns_with_names\n    elif subpatterns_with_common_names:\n        subpatterns = subpatterns_with_common_names\n    elif subpatterns_with_common_chars:\n        subpatterns = subpatterns_with_common_chars\n    # of the remaining subpatterns pick out the longest one\n    return max(subpatterns, key=len)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef leaf_to_root(self):\n        node = self\n        subp = []\n        while node:\n            if node.type == TYPE_ALTERNATIVES:\n                node.alternatives.append(subp)\n                if len(node.alternatives) == len(node.children):\n                    #last alternative\n                    subp = [tuple(node.alternatives)]\n                    node.alternatives = []\n                    node = node.parent\n                    continue\n                else:\n                    node = node.parent\n                    subp = None\n                    break\n\n            if node.type == TYPE_GROUP:\n                node.group.append(subp)\n                #probably should check the number of leaves\n                if len(node.group) == len(node.children):\n                    subp = get_characteristic_subpattern(node.group)\n                    node.group = []\n                    node = node.parent\n                    continue\n                else:\n                    node = node.parent\n                    subp = None\n                    break\n\n            if node.type == token_labels.NAME and node.name:\n                #in case of type=name, use the name instead\n                subp.append(node.name)\n            else:\n                subp.append(node.type)\n\n            node = node.parent\n        return subp", "response": "Internal method. Returns a characteristic path of the\n            pattern tree. This method must be run for all leaves until the\n            pattern tree is merged into a single characteristic path. This method must be run for all leaves until the\n            pattern tree is merged into a single characteristic path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndrive the leaf_to_root method.", "response": "def get_linear_subpattern(self):\n        \"\"\"Drives the leaf_to_root method. The reason that\n        leaf_to_root must be run multiple times is because we need to\n        reject 'group' matches; for example the alternative form\n        (a | b c) creates a group [b c] that needs to be matched. Since\n        matching multiple linear patterns overcomes the automaton's\n        capabilities, leaf_to_root merges each group into a single\n        choice based on 'characteristic'ity,\n\n        i.e. (a|b c) -> (a|b) if b more characteristic than c\n\n        Returns: The most 'characteristic'(as defined by\n          get_characteristic_subpattern) path for the compiled pattern\n          tree.\n        \"\"\"\n\n        for l in self.leaves():\n            subp = l.leaf_to_root()\n            if subp:\n                return subp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tokenize_wrapper(input):\n    skip = set((token.NEWLINE, token.INDENT, token.DEDENT))\n    tokens = tokenize.generate_tokens(StringIO.StringIO(input).readline)\n    for quintuple in tokens:\n        type, value, start, end, line_text = quintuple\n        if type not in skip:\n            yield quintuple", "response": "Tokenizes a string suppressing significant whitespace."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pattern_convert(grammar, raw_node_info):\n    type, value, context, children = raw_node_info\n    if children or type in grammar.number2symbol:\n        return pytree.Node(type, children, context=context)\n    else:\n        return pytree.Leaf(type, value, context=context)", "response": "Converts raw node information to a Node or Leaf instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compile_pattern(self, input, debug=False, with_tree=False):\n        tokens = tokenize_wrapper(input)\n        try:\n            root = self.driver.parse_tokens(tokens, debug=debug)\n        except parse.ParseError as e:\n            raise PatternSyntaxError(str(e))\n        if with_tree:\n            return self.compile_node(root), root\n        else:\n            return self.compile_node(root)", "response": "Compiles a pattern string to a nested pytree. Pattern object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compile_node(self, node):\n        # XXX Optimize certain Wildcard-containing-Wildcard patterns\n        # that can be merged\n        if node.type == self.syms.Matcher:\n            node = node.children[0] # Avoid unneeded recursion\n\n        if node.type == self.syms.Alternatives:\n            # Skip the odd children since they are just '|' tokens\n            alts = [self.compile_node(ch) for ch in node.children[::2]]\n            if len(alts) == 1:\n                return alts[0]\n            p = pytree.WildcardPattern([[a] for a in alts], min=1, max=1)\n            return p.optimize()\n\n        if node.type == self.syms.Alternative:\n            units = [self.compile_node(ch) for ch in node.children]\n            if len(units) == 1:\n                return units[0]\n            p = pytree.WildcardPattern([units], min=1, max=1)\n            return p.optimize()\n\n        if node.type == self.syms.NegatedUnit:\n            pattern = self.compile_basic(node.children[1:])\n            p = pytree.NegatedPattern(pattern)\n            return p.optimize()\n\n        assert node.type == self.syms.Unit\n\n        name = None\n        nodes = node.children\n        if len(nodes) >= 3 and nodes[1].type == token.EQUAL:\n            name = nodes[0].value\n            nodes = nodes[2:]\n        repeat = None\n        if len(nodes) >= 2 and nodes[-1].type == self.syms.Repeater:\n            repeat = nodes[-1]\n            nodes = nodes[:-1]\n\n        # Now we've reduced it to: STRING | NAME [Details] | (...) | [...]\n        pattern = self.compile_basic(nodes, repeat)\n\n        if repeat is not None:\n            assert repeat.type == self.syms.Repeater\n            children = repeat.children\n            child = children[0]\n            if child.type == token.STAR:\n                min = 0\n                max = pytree.HUGE\n            elif child.type == token.PLUS:\n                min = 1\n                max = pytree.HUGE\n            elif child.type == token.LBRACE:\n                assert children[-1].type == token.RBRACE\n                assert  len(children) in (3, 5)\n                min = max = self.get_int(children[1])\n                if len(children) == 5:\n                    max = self.get_int(children[3])\n            else:\n                assert False\n            if min != 1 or max != 1:\n                pattern = pattern.optimize()\n                pattern = pytree.WildcardPattern([[pattern]], min=min, max=max)\n\n        if name is not None:\n            pattern.name = name\n        return pattern.optimize()", "response": "Compiles a node recursively."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef MAKE_WPARAM(wParam):\n    wParam = ctypes.cast(wParam, LPVOID).value\n    if wParam is None:\n        wParam = 0\n    return wParam", "response": "Convert arguments to the WPARAM type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntranslating coordinates from one window to another.", "response": "def translate(self, hWndFrom = HWND_DESKTOP, hWndTo = HWND_DESKTOP):\n        \"\"\"\n        Translate coordinates from one window to another.\n\n        @note: To translate multiple points it's more efficient to use the\n            L{MapWindowPoints} function instead.\n\n        @see: L{client_to_screen}, L{screen_to_client}\n\n        @type  hWndFrom: int or L{HWND} or L{system.Window}\n        @param hWndFrom: Window handle to translate from.\n            Use C{HWND_DESKTOP} for screen coordinates.\n\n        @type  hWndTo: int or L{HWND} or L{system.Window}\n        @param hWndTo: Window handle to translate to.\n            Use C{HWND_DESKTOP} for screen coordinates.\n\n        @rtype:  L{Point}\n        @return: New object containing the translated coordinates.\n        \"\"\"\n        return MapWindowPoints(hWndFrom, hWndTo, [self])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a RECT object as specified by ctypes.", "response": "def _as_parameter_(self):\n        \"\"\"\n        Compatibility with ctypes.\n        Allows passing transparently a Point object to an API call.\n        \"\"\"\n        return RECT(self.left, self.top, self.right, self.bottom)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef screen_to_client(self, hWnd):\n        topleft     = ScreenToClient(hWnd, (self.left,   self.top))\n        bottomright = ScreenToClient(hWnd, (self.bottom, self.right))\n        return Rect( topleft.x, topleft.y, bottomright.x, bottomright.y )", "response": "Translate screen coordinates to client coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntranslating the client coordinates to screen coordinates.", "response": "def client_to_screen(self, hWnd):\n        \"\"\"\n        Translates window client coordinates to screen coordinates.\n\n        @see: L{screen_to_client}, L{translate}\n\n        @type  hWnd: int or L{HWND} or L{system.Window}\n        @param hWnd: Window handle.\n\n        @rtype:  L{Rect}\n        @return: New object containing the translated coordinates.\n        \"\"\"\n        topleft     = ClientToScreen(hWnd, (self.left,   self.top))\n        bottomright = ClientToScreen(hWnd, (self.bottom, self.right))\n        return Rect( topleft.x, topleft.y, bottomright.x, bottomright.y )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntranslate coordinates from one window to another.", "response": "def translate(self, hWndFrom = HWND_DESKTOP, hWndTo = HWND_DESKTOP):\n        \"\"\"\n        Translate coordinates from one window to another.\n\n        @see: L{client_to_screen}, L{screen_to_client}\n\n        @type  hWndFrom: int or L{HWND} or L{system.Window}\n        @param hWndFrom: Window handle to translate from.\n            Use C{HWND_DESKTOP} for screen coordinates.\n\n        @type  hWndTo: int or L{HWND} or L{system.Window}\n        @param hWndTo: Window handle to translate to.\n            Use C{HWND_DESKTOP} for screen coordinates.\n\n        @rtype:  L{Rect}\n        @return: New object containing the translated coordinates.\n        \"\"\"\n        points = [ (self.left, self.top), (self.right, self.bottom) ]\n        return MapWindowPoints(hWndFrom, hWndTo, points)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a copy of the object as a parameter for the API call.", "response": "def _as_parameter_(self):\n        \"\"\"\n        Compatibility with ctypes.\n        Allows passing transparently a Point object to an API call.\n        \"\"\"\n        wp                          = WINDOWPLACEMENT()\n        wp.length                   = sizeof(wp)\n        wp.flags                    = self.flags\n        wp.showCmd                  = self.showCmd\n        wp.ptMinPosition.x          = self.ptMinPosition.x\n        wp.ptMinPosition.y          = self.ptMinPosition.y\n        wp.ptMaxPosition.x          = self.ptMaxPosition.x\n        wp.ptMaxPosition.y          = self.ptMaxPosition.y\n        wp.rcNormalPosition.left    = self.rcNormalPosition.left\n        wp.rcNormalPosition.top     = self.rcNormalPosition.top\n        wp.rcNormalPosition.right   = self.rcNormalPosition.right\n        wp.rcNormalPosition.bottom  = self.rcNormalPosition.bottom\n        return wp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __getfilesystemencoding():\n    '''\n    Note: there's a copy of this method in interpreterInfo.py\n    '''\n    try:\n        ret = sys.getfilesystemencoding()\n        if not ret:\n            raise RuntimeError('Unable to get encoding.')\n        return ret\n    except:\n        try:\n            #Handle Jython\n            from java.lang import System  # @UnresolvedImport\n            env = System.getProperty(\"os.name\").lower()\n            if env.find('win') != -1:\n                return 'ISO-8859-1'  #mbcs does not work on Jython, so, use a (hopefully) suitable replacement\n            return 'utf-8'\n        except:\n            pass\n\n        #Only available from 2.3 onwards.\n        if sys.platform == 'win32':\n            return 'mbcs'\n        return 'utf-8'", "response": "Get the filesystem encoding for the current system."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\niterate the children of this Registry key.", "response": "def iterchildren(self):\n        \"\"\"\n        Iterates the subkeys for this Registry key.\n\n        @rtype:  iter of L{RegistryKey}\n        @return: Iterator of subkeys.\n        \"\"\"\n        handle = self.handle\n        index = 0\n        while 1:\n            subkey = win32.RegEnumKey(handle, index)\n            if subkey is None:\n                break\n            yield self.child(subkey)\n            index += 1"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of subkeys for this Registry key.", "response": "def children(self):\n        \"\"\"\n        Returns a list of subkeys for this Registry key.\n\n        @rtype:  list(L{RegistryKey})\n        @return: List of subkeys.\n        \"\"\"\n        # return list(self.iterchildren()) # that can't be optimized by psyco\n        handle = self.handle\n        result = []\n        index = 0\n        while 1:\n            subkey = win32.RegEnumKey(handle, index)\n            if subkey is None:\n                break\n            result.append( self.child(subkey) )\n            index += 1\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a child RegistryKey given its name.", "response": "def child(self, subkey):\n        \"\"\"\n        Retrieves a subkey for this Registry key, given its name.\n\n        @type  subkey: str\n        @param subkey: Name of the subkey.\n\n        @rtype:  L{RegistryKey}\n        @return: Subkey.\n        \"\"\"\n        path = self._path + '\\\\' + subkey\n        handle = win32.RegOpenKey(self.handle, subkey)\n        return RegistryKey(path, handle)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsplit a Registry path and returns the hive and subkey path.", "response": "def _split_path(self, path):\n        \"\"\"\n        Splits a Registry path and returns the hive and key.\n\n        @type  path: str\n        @param path: Registry path.\n\n        @rtype:  tuple( int, str )\n        @return: Tuple containing the hive handle and the subkey path.\n            The hive handle is always one of the following integer constants:\n             - L{win32.HKEY_CLASSES_ROOT}\n             - L{win32.HKEY_CURRENT_USER}\n             - L{win32.HKEY_LOCAL_MACHINE}\n             - L{win32.HKEY_USERS}\n             - L{win32.HKEY_PERFORMANCE_DATA}\n             - L{win32.HKEY_CURRENT_CONFIG}\n        \"\"\"\n        if '\\\\' in path:\n            p = path.find('\\\\')\n            hive = path[:p]\n            path = path[p+1:]\n        else:\n            hive = path\n            path = None\n        handle = self._hives_by_name[ hive.upper() ]\n        return handle, path"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a Registry path and returns the hive and subkey path.", "response": "def _parse_path(self, path):\n        \"\"\"\n        Parses a Registry path and returns the hive and key.\n\n        @type  path: str\n        @param path: Registry path.\n\n        @rtype:  tuple( int, str )\n        @return: Tuple containing the hive handle and the subkey path.\n            For a local Registry, the hive handle is an integer.\n            For a remote Registry, the hive handle is a L{RegistryKeyHandle}.\n        \"\"\"\n        handle, path = self._split_path(path)\n        if self._machine is not None:\n            handle = self._connect_hive(handle)\n        return handle, path"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\njoin the hive and key to make a Registry path.", "response": "def _join_path(self, hive, subkey):\n        \"\"\"\n        Joins the hive and key to make a Registry path.\n\n        @type  hive: int\n        @param hive: Registry hive handle.\n            The hive handle must be one of the following integer constants:\n             - L{win32.HKEY_CLASSES_ROOT}\n             - L{win32.HKEY_CURRENT_USER}\n             - L{win32.HKEY_LOCAL_MACHINE}\n             - L{win32.HKEY_USERS}\n             - L{win32.HKEY_PERFORMANCE_DATA}\n             - L{win32.HKEY_CURRENT_CONFIG}\n\n        @type  subkey: str\n        @param subkey: Subkey path.\n\n        @rtype:  str\n        @return: Registry path.\n        \"\"\"\n        path = self._hives_by_value[hive]\n        if subkey:\n            path = path + '\\\\' + subkey\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconnect to the specified remote Registry key handle.", "response": "def _connect_hive(self, hive):\n        \"\"\"\n        Connect to the specified hive of a remote Registry.\n\n        @note: The connection will be cached, to close all connections and\n            erase this cache call the L{close} method.\n\n        @type  hive: int\n        @param hive: Hive to connect to.\n\n        @rtype:  L{win32.RegistryKeyHandle}\n        @return: Open handle to the remote Registry hive.\n        \"\"\"\n        try:\n            handle = self._remote_hives[hive]\n        except KeyError:\n            handle = win32.RegConnectRegistry(self._machine, hive)\n            self._remote_hives[hive] = handle\n        return handle"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nclosing all open connections to the remote Registry.", "response": "def close(self):\n        \"\"\"\n        Closes all open connections to the remote Registry.\n\n        No exceptions are raised, even if an error occurs.\n\n        This method has no effect when opening the local Registry.\n\n        The remote Registry will still be accessible after calling this method\n        (new connections will be opened automatically on access).\n        \"\"\"\n        while self._remote_hives:\n            hive = self._remote_hives.popitem()[1]\n            try:\n                hive.close()\n            except Exception:\n                try:\n                    e = sys.exc_info()[1]\n                    msg = \"Cannot close registry hive handle %s, reason: %s\"\n                    msg %= (hive.value, str(e))\n                    warnings.warn(msg)\n                except Exception:\n                    pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new Registry key.", "response": "def create(self, path):\n        \"\"\"\n        Creates a new Registry key.\n\n        @type  path: str\n        @param path: Registry key path.\n\n        @rtype:  L{RegistryKey}\n        @return: The newly created Registry key.\n        \"\"\"\n        path = self._sanitize_path(path)\n        hive, subpath = self._parse_path(path)\n        handle = win32.RegCreateKey(hive, subpath)\n        return RegistryKey(path, handle)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef subkeys(self, path):\n        result = list()\n        hive, subpath = self._parse_path(path)\n        with win32.RegOpenKey(hive, subpath) as handle:\n            index = 0\n            while 1:\n                name = win32.RegEnumKey(handle, index)\n                if name is None:\n                    break\n                result.append(name)\n                index += 1\n        return result", "response": "Returns a list of subkeys for the given Registry key path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a recursive iterator on the specified key and its subkeys.", "response": "def iterate(self, path):\n        \"\"\"\n        Returns a recursive iterator on the specified key and its subkeys.\n\n        @type  path: str\n        @param path: Registry key path.\n\n        @rtype:  iterator\n        @return: Recursive iterator that returns Registry key paths.\n\n        @raise KeyError: The specified path does not exist.\n        \"\"\"\n        if path.endswith('\\\\'):\n            path = path[:-1]\n        if not self.has_key(path):\n            raise KeyError(path)\n        stack = collections.deque()\n        stack.appendleft(path)\n        return self.__iterate(stack)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iterkeys(self):\n        stack = collections.deque(self._hives)\n        stack.reverse()\n        return self.__iterate(stack)", "response": "Returns an iterator that crawls the entire Windows Registry."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the IDE OS and breakpoints by the given sequence", "response": "def set_ide_os_and_breakpoints_by(self, py_db, seq, ide_os, breakpoints_by):\n        '''\n        :param ide_os: 'WINDOWS' or 'UNIX'\n        :param breakpoints_by: 'ID' or 'LINE'\n        '''\n        if breakpoints_by == 'ID':\n            py_db._set_breakpoints_with_id = True\n        else:\n            py_db._set_breakpoints_with_id = False\n\n        pydevd_file_utils.set_ide_os(ide_os)\n\n        return py_db.cmd_factory.make_version_message(seq)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nchange the value of a variable in a thread.", "response": "def request_change_variable(self, py_db, seq, thread_id, frame_id, scope, attr, value):\n        '''\n        :param scope: 'FRAME' or 'GLOBAL'\n        '''\n        py_db.post_method_as_internal_command(\n            thread_id, internal_change_variable, seq, thread_id, frame_id, scope, attr, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrequesting a variable from the thread.", "response": "def request_get_variable(self, py_db, seq, thread_id, frame_id, scope, attrs):\n        '''\n        :param scope: 'FRAME' or 'GLOBAL'\n        '''\n        int_cmd = InternalGetVariable(seq, thread_id, frame_id, scope, attrs)\n        py_db.post_internal_command(int_cmd, thread_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a unicode object to str using utf - 8.", "response": "def to_str(self, s):\n        '''\n        In py2 converts a unicode to str (bytes) using utf-8.\n        -- in py3 raises an error if it's not str already.\n        '''\n        if s.__class__ != str:\n            if not IS_PY3K:\n                s = s.encode('utf-8')\n            else:\n                raise AssertionError('Expected to have str on Python 3. Found: %s (%s)' % (s, s.__class__))\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filename_to_str(self, filename):\n        '''\n        In py2 converts a unicode to str (bytes) using the file system encoding.\n        -- in py3 raises an error if it's not str already.\n        '''\n        if filename.__class__ != str:\n            if not IS_PY3K:\n                filename = filename.encode(file_system_encoding)\n            else:\n                raise AssertionError('Expected to have str on Python 3. Found: %s (%s)' % (filename, filename.__class__))\n        return filename", "response": "Convert a filename to str using the file system encoding."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a breakpoint to the current breakpoint set.", "response": "def add_breakpoint(\n            self, py_db, filename, breakpoint_type, breakpoint_id, line, condition, func_name, expression, suspend_policy, hit_condition, is_logpoint):\n        '''\n        :param str filename:\n            Note: must be already translated for the server.\n\n        :param str breakpoint_type:\n            One of: 'python-line', 'django-line', 'jinja2-line'.\n\n        :param int breakpoint_id:\n\n        :param int line:\n\n        :param condition:\n            Either None or the condition to activate the breakpoint.\n\n        :param str func_name:\n            If \"None\" (str), may hit in any context.\n            Empty string will hit only top level.\n            Any other value must match the scope of the method to be matched.\n\n        :param str expression:\n            None or the expression to be evaluated.\n\n        :param suspend_policy:\n            Either \"NONE\" (to suspend only the current thread when the breakpoint is hit) or\n            \"ALL\" (to suspend all threads when a breakpoint is hit).\n\n        :param str hit_condition:\n            An expression where `@HIT@` will be replaced by the number of hits.\n            i.e.: `@HIT@ == x` or `@HIT@ >= x`\n\n        :param bool is_logpoint:\n            If True and an expression is passed, pydevd will create an io message command with the\n            result of the evaluation.\n        '''\n        assert filename.__class__ == str  # i.e.: bytes on py2 and str on py3\n        assert func_name.__class__ == str  # i.e.: bytes on py2 and str on py3\n\n        if not pydevd_file_utils.exists(filename):\n            pydev_log.critical('pydev debugger: warning: trying to add breakpoint'\\\n                ' to file that does not exist: %s (will have no effect)\\n' % (filename,))\n            return\n\n        if breakpoint_type == 'python-line':\n            added_breakpoint = LineBreakpoint(line, condition, func_name, expression, suspend_policy, hit_condition=hit_condition, is_logpoint=is_logpoint)\n            breakpoints = py_db.breakpoints\n            file_to_id_to_breakpoint = py_db.file_to_id_to_line_breakpoint\n            supported_type = True\n\n        else:\n            result = None\n            plugin = py_db.get_plugin_lazy_init()\n            if plugin is not None:\n                result = plugin.add_breakpoint('add_line_breakpoint', py_db, breakpoint_type, filename, line, condition, expression, func_name, hit_condition=hit_condition, is_logpoint=is_logpoint)\n            if result is not None:\n                supported_type = True\n                added_breakpoint, breakpoints = result\n                file_to_id_to_breakpoint = py_db.file_to_id_to_plugin_breakpoint\n            else:\n                supported_type = False\n\n        if not supported_type:\n            raise NameError(breakpoint_type)\n\n        if DebugInfoHolder.DEBUG_TRACE_BREAKPOINTS > 0:\n            pydev_log.debug('Added breakpoint:%s - line:%s - func_name:%s\\n', filename, line, func_name)\n\n        if filename in file_to_id_to_breakpoint:\n            id_to_pybreakpoint = file_to_id_to_breakpoint[filename]\n        else:\n            id_to_pybreakpoint = file_to_id_to_breakpoint[filename] = {}\n\n        id_to_pybreakpoint[breakpoint_id] = added_breakpoint\n        py_db.consolidate_breakpoints(filename, id_to_pybreakpoint, breakpoints)\n        if py_db.plugin is not None:\n            py_db.has_plugin_line_breaks = py_db.plugin.has_line_breaks()\n\n        py_db.on_breakpoints_changed()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_all_breakpoints(self, py_db, filename):\n        '''\n        Removes all the breakpoints from a given file or from all files if filename == '*'.\n        '''\n        changed = False\n        lst = [\n            py_db.file_to_id_to_line_breakpoint,\n            py_db.file_to_id_to_plugin_breakpoint,\n            py_db.breakpoints\n        ]\n        if hasattr(py_db, 'django_breakpoints'):\n            lst.append(py_db.django_breakpoints)\n\n        if hasattr(py_db, 'jinja2_breakpoints'):\n            lst.append(py_db.jinja2_breakpoints)\n\n        for file_to_id_to_breakpoint in lst:\n            if filename == '*':\n                if file_to_id_to_breakpoint:\n                    file_to_id_to_breakpoint.clear()\n                    changed = True\n            else:\n                if filename in file_to_id_to_breakpoint:\n                    del file_to_id_to_breakpoint[filename]\n                    changed = True\n\n        if changed:\n            py_db.on_breakpoints_changed(removed=True)", "response": "Removes all the breakpoints from a given file or from all files."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove a breakpoint from the debug info.", "response": "def remove_breakpoint(self, py_db, filename, breakpoint_type, breakpoint_id):\n        '''\n        :param str filename:\n            Note: must be already translated for the server.\n\n        :param str breakpoint_type:\n            One of: 'python-line', 'django-line', 'jinja2-line'.\n\n        :param int breakpoint_id:\n        '''\n        file_to_id_to_breakpoint = None\n\n        if breakpoint_type == 'python-line':\n            breakpoints = py_db.breakpoints\n            file_to_id_to_breakpoint = py_db.file_to_id_to_line_breakpoint\n\n        elif py_db.plugin is not None:\n            result = py_db.plugin.get_breakpoints(py_db, breakpoint_type)\n            if result is not None:\n                file_to_id_to_breakpoint = py_db.file_to_id_to_plugin_breakpoint\n                breakpoints = result\n\n        if file_to_id_to_breakpoint is None:\n            pydev_log.critical('Error removing breakpoint. Cannot handle breakpoint of type %s', breakpoint_type)\n\n        else:\n            try:\n                id_to_pybreakpoint = file_to_id_to_breakpoint.get(filename, {})\n                if DebugInfoHolder.DEBUG_TRACE_BREAKPOINTS > 0:\n                    existing = id_to_pybreakpoint[breakpoint_id]\n                    pydev_log.info('Removed breakpoint:%s - line:%s - func_name:%s (id: %s)\\n' % (\n                        filename, existing.line, existing.func_name.encode('utf-8'), breakpoint_id))\n\n                del id_to_pybreakpoint[breakpoint_id]\n                py_db.consolidate_breakpoints(filename, id_to_pybreakpoint, breakpoints)\n                if py_db.plugin is not None:\n                    py_db.has_plugin_line_breaks = py_db.plugin.has_line_breaks()\n\n            except KeyError:\n                pydev_log.info(\"Error removing breakpoint: Breakpoint id not found: %s id: %s. Available ids: %s\\n\",\n                    filename, breakpoint_id, dict_keys(id_to_pybreakpoint))\n\n        py_db.on_breakpoints_changed(removed=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef request_load_source(self, py_db, seq, filename):\n        '''\n        :param str filename:\n            Note: must be already translated for the server.\n        '''\n        try:\n            assert filename.__class__ == str  # i.e.: bytes on py2 and str on py3\n\n            with open(filename, 'r') as stream:\n                source = stream.read()\n            cmd = py_db.cmd_factory.make_load_source_message(seq, source)\n        except:\n            cmd = py_db.cmd_factory.make_error_message(seq, get_exception_traceback_str())\n\n        py_db.writer.add_command(cmd)", "response": "Request load source from file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef request_get_variable_json(self, py_db, request, thread_id):\n        '''\n        :param VariablesRequest request:\n        '''\n        py_db.post_method_as_internal_command(\n            thread_id, internal_get_variable_json, request)", "response": "This method is called by the server to get the json data for a specific variable."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nchange the variable of a specific resource.", "response": "def request_change_variable_json(self, py_db, request, thread_id):\n        '''\n        :param SetVariableRequest request:\n        '''\n        py_db.post_method_as_internal_command(\n            thread_id, internal_change_variable_json, request)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a dictionary of setup to a list of command line arguments.", "response": "def setup_to_argv(setup):\n    '''\n    :param dict setup:\n        A dict previously gotten from process_command_line.\n\n    :note: does not handle --file nor --DEBUG.\n    '''\n    ret = [get_pydevd_file()]\n\n    for handler in ACCEPTED_ARG_HANDLERS:\n        if handler.arg_name in setup:\n            handler.to_argv(ret, setup)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the command line arguments and returns a dictionary of the parameters.", "response": "def process_command_line(argv):\n    \"\"\" parses the arguments.\n        removes our arguments from the command line \"\"\"\n    setup = {}\n    for handler in ACCEPTED_ARG_HANDLERS:\n        setup[handler.arg_name] = handler.default_val\n    setup['file'] = ''\n    setup['qt-support'] = ''\n\n    i = 0\n    del argv[0]\n    while i < len(argv):\n        handler = ARGV_REP_TO_HANDLER.get(argv[i])\n        if handler is not None:\n            handler.handle_argv(argv, i, setup)\n\n        elif argv[i].startswith('--qt-support'):\n            # The --qt-support is special because we want to keep backward compatibility:\n            # Previously, just passing '--qt-support' meant that we should use the auto-discovery mode\n            # whereas now, if --qt-support is passed, it should be passed as --qt-support=<mode>, where\n            # mode can be one of 'auto', 'none', 'pyqt5', 'pyqt4', 'pyside'.\n            if argv[i] == '--qt-support':\n                setup['qt-support'] = 'auto'\n\n            elif argv[i].startswith('--qt-support='):\n                qt_support = argv[i][len('--qt-support='):]\n                valid_modes = ('none', 'auto', 'pyqt5', 'pyqt4', 'pyside')\n                if qt_support not in valid_modes:\n                    raise ValueError(\"qt-support mode invalid: \" + qt_support)\n                if qt_support == 'none':\n                    # On none, actually set an empty string to evaluate to False.\n                    setup['qt-support'] = ''\n                else:\n                    setup['qt-support'] = qt_support\n            else:\n                raise ValueError(\"Unexpected definition for qt-support flag: \" + argv[i])\n\n            del argv[i]\n\n        elif argv[i] == '--file':\n            # --file is special because it's the last one (so, no handler for it).\n            del argv[i]\n            setup['file'] = argv[i]\n            i = len(argv) # pop out, file is our last argument\n\n        elif argv[i] == '--DEBUG':\n            from pydevd import set_debug\n            del argv[i]\n            set_debug(setup)\n\n        else:\n            raise ValueError(\"Unexpected option: \" + argv[i])\n    return setup"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_py_dictionary(self, var, names=None, used___dict__=False):\n        '''\n        :return tuple(names, used___dict__), where used___dict__ means we have to access\n        using obj.__dict__[name] instead of getattr(obj, name)\n        '''\n\n        # TODO: Those should be options (would fix https://github.com/Microsoft/ptvsd/issues/66).\n        filter_private = False\n        filter_special = True\n        filter_function = True\n        filter_builtin = True\n\n        if not names:\n            names, used___dict__ = self.get_names(var)\n        d = {}\n\n        # Be aware that the order in which the filters are applied attempts to\n        # optimize the operation by removing as many items as possible in the\n        # first filters, leaving fewer items for later filters\n\n        if filter_builtin or filter_function:\n            for name in names:\n                try:\n                    name_as_str = name\n                    if name_as_str.__class__ != str:\n                        name_as_str = '%r' % (name_as_str,)\n\n                    if filter_special:\n                        if name_as_str.startswith('__') and name_as_str.endswith('__'):\n                            continue\n\n                    if filter_private:\n                        if name_as_str.startswith('_') or name_as_str.endswith('__'):\n                            continue\n                    if not used___dict__:\n                        attr = getattr(var, name)\n                    else:\n                        attr = var.__dict__[name]\n\n                    # filter builtins?\n                    if filter_builtin:\n                        if inspect.isbuiltin(attr):\n                            continue\n\n                    # filter functions?\n                    if filter_function:\n                        if inspect.isroutine(attr) or isinstance(attr, MethodWrapperType):\n                            continue\n                except:\n                    # if some error occurs getting it, let's put it to the user.\n                    strIO = StringIO.StringIO()\n                    traceback.print_exc(file=strIO)\n                    attr = strIO.getvalue()\n\n                d[name_as_str] = attr\n\n        return d, used___dict__", "response": "Get a dictionary of the names and used___dict__ values."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_contents_debug_adapter_protocol(self, dct, fmt=None):\n        '''\n        This method is to be used in the case where the variables are all saved by its id (and as\n        such don't need to have the `resolve` method called later on, so, keys don't need to\n        embed the reference in the key).\n\n        Note that the return should be ordered.\n\n        :return list(tuple(name:str, value:object, evaluateName:str))\n        '''\n        ret = []\n\n        i = 0\n        for key, val in dict_iter_items(dct):\n            i += 1\n            key_as_str = self.key_to_str(key, fmt)\n            eval_key_str = self.key_to_str(key)  # do not format the key\n            ret.append((key_as_str, val, '[%s]' % (eval_key_str,)))\n            if i > MAX_ITEMS_TO_HANDLE:\n                ret.append((TOO_LARGE_ATTR, TOO_LARGE_MSG, None))\n                break\n\n        ret.append(('__len__', len(dct), partial(_apply_evaluate_name, evaluate_name='len(%s)')))\n        # in case the class extends built-in type and has some additional fields\n        from_default_resolver = defaultResolver.get_contents_debug_adapter_protocol(dct, fmt)\n\n        if from_default_resolver:\n            ret = from_default_resolver + ret\n\n        return sorted(ret, key=lambda tup: sorted_attributes_key(tup[0]))", "response": "This method returns a list of tuples that are used to resolve the contents of a class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _other_endian(typ):\n    try:\n        return getattr(typ, _OTHER_ENDIAN)\n    except AttributeError:\n        if type(typ) == _array_type:\n            return _other_endian(typ._type_) * typ._length_\n        raise TypeError(\"This type does not support other endian: %s\" % typ)", "response": "Return the type with the other byte order."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the value of a variable in a thread.", "response": "def getVariable(dbg, thread_id, frame_id, scope, attrs):\n    \"\"\"\n    returns the value of a variable\n\n    :scope: can be BY_ID, EXPRESSION, GLOBAL, LOCAL, FRAME\n\n    BY_ID means we'll traverse the list of all objects alive to get the object.\n\n    :attrs: after reaching the proper scope, we have to get the attributes until we find\n            the proper location (i.e.: obj\\tattr1\\tattr2)\n\n    :note: when BY_ID is used, the frame_id is considered the id of the object to find and\n           not the frame (as we don't care about the frame in this case).\n    \"\"\"\n    if scope == 'BY_ID':\n        if thread_id != get_current_thread_id(threading.currentThread()):\n            raise VariableError(\"getVariable: must execute on same thread\")\n\n        try:\n            import gc\n            objects = gc.get_objects()\n        except:\n            pass  # Not all python variants have it.\n        else:\n            frame_id = int(frame_id)\n            for var in objects:\n                if id(var) == frame_id:\n                    if attrs is not None:\n                        attrList = attrs.split('\\t')\n                        for k in attrList:\n                            _type, _typeName, resolver = get_type(var)\n                            var = resolver.resolve(var, k)\n\n                    return var\n\n        # If it didn't return previously, we coudn't find it by id (i.e.: alrceady garbage collected).\n        sys.stderr.write('Unable to find object with id: %s\\n' % (frame_id,))\n        return None\n\n    frame = dbg.find_frame(thread_id, frame_id)\n    if frame is None:\n        return {}\n\n    if attrs is not None:\n        attrList = attrs.split('\\t')\n    else:\n        attrList = []\n\n    for attr in attrList:\n        attr.replace(\"@_@TAB_CHAR@_@\", '\\t')\n\n    if scope == 'EXPRESSION':\n        for count in xrange(len(attrList)):\n            if count == 0:\n                # An Expression can be in any scope (globals/locals), therefore it needs to evaluated as an expression\n                var = evaluate_expression(dbg, frame, attrList[count], False)\n            else:\n                _type, _typeName, resolver = get_type(var)\n                var = resolver.resolve(var, attrList[count])\n    else:\n        if scope == \"GLOBAL\":\n            var = frame.f_globals\n            del attrList[0]  # globals are special, and they get a single dummy unused attribute\n        else:\n            # in a frame access both locals and globals as Python does\n            var = {}\n            var.update(frame.f_globals)\n            var.update(frame.f_locals)\n\n        for k in attrList:\n            _type, _typeName, resolver = get_type(var)\n            var = resolver.resolve(var, k)\n\n    return var"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resolve_compound_variable_fields(dbg, thread_id, frame_id, scope, attrs):\n\n    var = getVariable(dbg, thread_id, frame_id, scope, attrs)\n\n    try:\n        _type, _typeName, resolver = get_type(var)\n        return _typeName, resolver.get_dictionary(var)\n    except:\n        pydev_log.exception('Error evaluating: thread_id: %s\\nframe_id: %s\\nscope: %s\\nattrs: %s.',\n            thread_id, frame_id, scope, attrs)", "response": "Resolve a compound variable in debugger scopes by its name and attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresolves variable s attribute", "response": "def resolve_var_object(var, attrs):\n    \"\"\"\n    Resolve variable's attribute\n\n    :param var: an object of variable\n    :param attrs: a sequence of variable's attributes separated by \\t (i.e.: obj\\tattr1\\tattr2)\n    :return: a value of resolved variable's attribute\n    \"\"\"\n    if attrs is not None:\n        attr_list = attrs.split('\\t')\n    else:\n        attr_list = []\n    for k in attr_list:\n        type, _typeName, resolver = get_type(var)\n        var = resolver.resolve(var, k)\n    return var"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resolve_compound_var_object_fields(var, attrs):\n    attr_list = attrs.split('\\t')\n\n    for k in attr_list:\n        type, _typeName, resolver = get_type(var)\n        var = resolver.resolve(var, k)\n\n    try:\n        type, _typeName, resolver = get_type(var)\n        return resolver.get_dictionary(var)\n    except:\n        pydev_log.exception()", "response": "Resolve a compound variable by its object and attributes"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef custom_operation(dbg, thread_id, frame_id, scope, attrs, style, code_or_file, operation_fn_name):\n    expressionValue = getVariable(dbg, thread_id, frame_id, scope, attrs)\n\n    try:\n        namespace = {'__name__': '<custom_operation>'}\n        if style == \"EXECFILE\":\n            namespace['__file__'] = code_or_file\n            execfile(code_or_file, namespace, namespace)\n        else:  # style == EXEC\n            namespace['__file__'] = '<customOperationCode>'\n            Exec(code_or_file, namespace, namespace)\n\n        return str(namespace[operation_fn_name](expressionValue))\n    except:\n        pydev_log.exception()", "response": "This function will execute the code_or_file and then execute the operation_fn_name in the namespace of the thread."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the result of the evaluated expression", "response": "def evaluate_expression(dbg, frame, expression, is_exec):\n    '''returns the result of the evaluated expression\n    @param is_exec: determines if we should do an exec or an eval\n    '''\n    if frame is None:\n        return\n\n    # Not using frame.f_globals because of https://sourceforge.net/tracker2/?func=detail&aid=2541355&group_id=85796&atid=577329\n    # (Names not resolved in generator expression in method)\n    # See message: http://mail.python.org/pipermail/python-list/2009-January/526522.html\n    updated_globals = {}\n    updated_globals.update(frame.f_globals)\n    updated_globals.update(frame.f_locals)  # locals later because it has precedence over the actual globals\n\n    try:\n        expression = str(expression.replace('@LINE@', '\\n'))\n\n        if is_exec:\n            try:\n                # try to make it an eval (if it is an eval we can print it, otherwise we'll exec it and\n                # it will have whatever the user actually did)\n                compiled = compile(expression, '<string>', 'eval')\n            except:\n                Exec(expression, updated_globals, frame.f_locals)\n                pydevd_save_locals.save_locals(frame)\n            else:\n                result = eval(compiled, updated_globals, frame.f_locals)\n                if result is not None:  # Only print if it's not None (as python does)\n                    sys.stdout.write('%s\\n' % (result,))\n            return\n\n        else:\n            return eval_in_context(expression, updated_globals, frame.f_locals)\n    finally:\n        # Should not be kept alive if an exception happens and this frame is kept in the stack.\n        del updated_globals\n        del frame"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchanging some attribute in a given frame.", "response": "def change_attr_expression(frame, attr, expression, dbg, value=SENTINEL_VALUE):\n    '''Changes some attribute in a given frame.\n    '''\n    if frame is None:\n        return\n\n    try:\n        expression = expression.replace('@LINE@', '\\n')\n\n        if dbg.plugin and value is SENTINEL_VALUE:\n            result = dbg.plugin.change_variable(frame, attr, expression)\n            if result:\n                return result\n\n        if attr[:7] == \"Globals\":\n            attr = attr[8:]\n            if attr in frame.f_globals:\n                if value is SENTINEL_VALUE:\n                    value = eval(expression, frame.f_globals, frame.f_locals)\n                frame.f_globals[attr] = value\n                return frame.f_globals[attr]\n        else:\n            if '.' not in attr:  # i.e.: if we have a '.', we're changing some attribute of a local var.\n                if pydevd_save_locals.is_save_locals_available():\n                    if value is SENTINEL_VALUE:\n                        value = eval(expression, frame.f_globals, frame.f_locals)\n                    frame.f_locals[attr] = value\n                    pydevd_save_locals.save_locals(frame)\n                    return frame.f_locals[attr]\n\n            # default way (only works for changing it in the topmost frame)\n            if value is SENTINEL_VALUE:\n                value = eval(expression, frame.f_globals, frame.f_locals)\n            result = value\n            Exec('%s=%s' % (attr, expression), frame.f_globals, frame.f_locals)\n            return result\n\n    except Exception:\n        pydev_log.exception()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dataframe_to_xml(df, name, roffset, coffset, rows, cols, format):\n    num_rows = min(df.shape[0], MAX_SLICE_SIZE)\n    num_cols = min(df.shape[1], MAX_SLICE_SIZE)\n    if (num_rows, num_cols) != df.shape:\n        df = df.iloc[0:num_rows, 0: num_cols]\n        slice = '.iloc[0:%s, 0:%s]' % (num_rows, num_cols)\n    else:\n        slice = ''\n    slice = name + slice\n    xml = '<array slice=\\\"%s\\\" rows=\\\"%s\\\" cols=\\\"%s\\\" format=\\\"\\\" type=\\\"\\\" max=\\\"0\\\" min=\\\"0\\\"/>\\n' % \\\n          (slice, num_rows, num_cols)\n\n    if (rows, cols) == (-1, -1):\n        rows, cols = num_rows, num_cols\n\n    rows = min(rows, MAXIMUM_ARRAY_SIZE)\n    cols = min(min(cols, MAXIMUM_ARRAY_SIZE), num_cols)\n    # need to precompute column bounds here before slicing!\n    col_bounds = [None] * cols\n    for col in xrange(cols):\n        dtype = df.dtypes.iloc[coffset + col].kind\n        if dtype in \"biufc\":\n            cvalues = df.iloc[:, coffset + col]\n            bounds = (cvalues.min(), cvalues.max())\n        else:\n            bounds = (0, 0)\n        col_bounds[col] = bounds\n\n    df = df.iloc[roffset: roffset + rows, coffset: coffset + cols]\n    rows, cols = df.shape\n\n    xml += \"<headerdata rows=\\\"%s\\\" cols=\\\"%s\\\">\\n\" % (rows, cols)\n    format = format.replace('%', '')\n    col_formats = []\n\n    get_label = lambda label: str(label) if not isinstance(label, tuple) else '/'.join(map(str, label))\n\n    for col in xrange(cols):\n        dtype = df.dtypes.iloc[col].kind\n        if dtype == 'f' and format:\n            fmt = format\n        elif dtype == 'f':\n            fmt = '.5f'\n        elif dtype == 'i' or dtype == 'u':\n            fmt = 'd'\n        else:\n            fmt = 's'\n        col_formats.append('%' + fmt)\n        bounds = col_bounds[col]\n\n        xml += '<colheader index=\\\"%s\\\" label=\\\"%s\\\" type=\\\"%s\\\" format=\\\"%s\\\" max=\\\"%s\\\" min=\\\"%s\\\" />\\n' % \\\n               (str(col), get_label(df.axes[1].values[col]), dtype, fmt, bounds[1], bounds[0])\n    for row, label in enumerate(iter(df.axes[0])):\n        xml += \"<rowheader index=\\\"%s\\\" label = \\\"%s\\\"/>\\n\" % \\\n               (str(row), get_label(label))\n    xml += \"</headerdata>\\n\"\n    xml += \"<arraydata rows=\\\"%s\\\" cols=\\\"%s\\\"/>\\n\" % (rows, cols)\n    for row in xrange(rows):\n        xml += \"<row index=\\\"%s\\\"/>\\n\" % str(row)\n        for col in xrange(cols):\n            value = df.iat[row, col]\n            value = col_formats[col] % value\n            xml += var_to_xml(value, '')\n    return xml", "response": "Convert a pandas. core. frame. DataFrame to XML."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gnu_getopt(args, shortopts, longopts=[]):\n\n    opts = []\n    prog_args = []\n    if type('') == type(longopts):\n        longopts = [longopts]\n    else:\n        longopts = list(longopts)\n\n    # Allow options after non-option arguments?\n    all_options_first = False\n    if shortopts.startswith('+'):\n        shortopts = shortopts[1:]\n        all_options_first = True\n\n    while args:\n        if args[0] == '--':\n            prog_args += args[1:]\n            break\n\n        if args[0][:2] == '--':\n            opts, args = do_longs(opts, args[0][2:], longopts, args[1:])\n        elif args[0][:1] == '-':\n            opts, args = do_shorts(opts, args[0][1:], shortopts, args[1:])\n        else:\n            if all_options_first:\n                prog_args += args\n                break\n            else:\n                prog_args.append(args[0])\n                args = args[1:]\n\n    return opts, prog_args", "response": "This function is used by GNU to parse GNU command line options."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset a new condition callback for the breakpoint.", "response": "def set_condition(self, condition = True):\n        \"\"\"\n        Sets a new condition callback for the breakpoint.\n\n        @see: L{__init__}\n\n        @type  condition: function\n        @param condition: (Optional) Condition callback function.\n        \"\"\"\n        if condition is None:\n            self.__condition = True\n        else:\n            self.__condition = condition"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nevaluates the breakpoint condition.", "response": "def eval_condition(self, event):\n        \"\"\"\n        Evaluates the breakpoint condition, if any was set.\n\n        @type  event: L{Event}\n        @param event: Debug event triggered by the breakpoint.\n\n        @rtype:  bool\n        @return: C{True} to dispatch the event, C{False} otherwise.\n        \"\"\"\n        condition = self.get_condition()\n        if condition is True:   # shortcut for unconditional breakpoints\n            return True\n        if callable(condition):\n            try:\n                return bool( condition(event) )\n            except Exception:\n                e = sys.exc_info()[1]\n                msg = (\"Breakpoint condition callback %r\"\n                       \" raised an exception: %s\")\n                msg = msg % (condition, traceback.format_exc(e))\n                warnings.warn(msg, BreakpointCallbackWarning)\n                return False\n        return bool( condition )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_action(self, event):\n        action = self.get_action()\n        if action is not None:\n            try:\n                return bool( action(event) )\n            except Exception:\n                e = sys.exc_info()[1]\n                msg = (\"Breakpoint action callback %r\"\n                       \" raised an exception: %s\")\n                msg = msg % (action, traceback.format_exc(e))\n                warnings.warn(msg, BreakpointCallbackWarning)\n                return False\n        return True", "response": "Executes the breakpoint action callback if any was set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nraise an AssertionError if an invalid state transition.", "response": "def __bad_transition(self, state):\n        \"\"\"\n        Raises an C{AssertionError} exception for an invalid state transition.\n\n        @see: L{stateNames}\n\n        @type  state: int\n        @param state: Intended breakpoint state.\n\n        @raise Exception: Always.\n        \"\"\"\n        statemsg = \"\"\n        oldState = self.stateNames[ self.get_state() ]\n        newState = self.stateNames[ state ]\n        msg = \"Invalid state transition (%s -> %s)\" \\\n              \" for breakpoint at address %s\"\n        msg = msg % (oldState, newState, HexDump.address(self.get_address()))\n        raise AssertionError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntransitioning to L { RUNNING } state.", "response": "def running(self, aProcess, aThread):\n        \"\"\"\n        Transition to L{RUNNING} state.\n          - When hit: Enabled S{->} Running\n\n        @type  aProcess: L{Process}\n        @param aProcess: Process object.\n\n        @type  aThread: L{Thread}\n        @param aThread: Thread object.\n        \"\"\"\n        if self.__state != self.ENABLED:\n            self.__bad_transition(self.RUNNING)\n        self.__state = self.RUNNING"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hit(self, event):\n        aProcess = event.get_process()\n        aThread  = event.get_thread()\n        state    = self.get_state()\n\n        event.breakpoint = self\n\n        if state == self.ENABLED:\n            self.running(aProcess, aThread)\n\n        elif state == self.RUNNING:\n            self.enable(aProcess, aThread)\n\n        elif state == self.ONESHOT:\n            self.disable(aProcess, aThread)\n\n        elif state == self.DISABLED:\n            # this should not happen\n            msg = \"Hit a disabled breakpoint at address %s\"\n            msg = msg % HexDump.address( self.get_address() )\n            warnings.warn(msg, BreakpointWarning)", "response": "Notify that a breakpoint is hit."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites a breakpoint instruction at the target address.", "response": "def __set_bp(self, aProcess):\n        \"\"\"\n        Writes a breakpoint instruction at the target address.\n\n        @type  aProcess: L{Process}\n        @param aProcess: Process object.\n        \"\"\"\n        address = self.get_address()\n        self.__previousValue = aProcess.read(address, len(self.bpInstruction))\n        if self.__previousValue == self.bpInstruction:\n            msg = \"Possible overlapping code breakpoints at %s\"\n            msg = msg % HexDump.address(address)\n            warnings.warn(msg, BreakpointWarning)\n        aProcess.write(address, self.bpInstruction)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __set_bp(self, aProcess):\n        lpAddress    = self.get_address()\n        dwSize       = self.get_size()\n        flNewProtect = aProcess.mquery(lpAddress).Protect\n        flNewProtect = flNewProtect | win32.PAGE_GUARD\n        aProcess.mprotect(lpAddress, dwSize, flNewProtect)", "response": "Sets the target pages as guard pages."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nclears the permissions of the target pages.", "response": "def __clear_bp(self, aProcess):\n        \"\"\"\n        Restores the original permissions of the target pages.\n\n        @type  aProcess: L{Process}\n        @param aProcess: Process object.\n        \"\"\"\n        lpAddress    = self.get_address()\n        flNewProtect = aProcess.mquery(lpAddress).Protect\n        flNewProtect = flNewProtect & (0xFFFFFFFF ^ win32.PAGE_GUARD)   # DWORD\n        aProcess.mprotect(lpAddress, self.get_size(), flNewProtect)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __clear_bp(self, aThread):\n        if self.__slot is not None:\n            aThread.suspend()\n            try:\n                ctx = aThread.get_context(win32.CONTEXT_DEBUG_REGISTERS)\n                DebugRegister.clear_bp(ctx, self.__slot)\n                aThread.set_context(ctx)\n                self.__slot = None\n            finally:\n                aThread.resume()", "response": "Clears this breakpoint from the debug registers."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __set_bp(self, aThread):\n        if self.__slot is None:\n            aThread.suspend()\n            try:\n                ctx = aThread.get_context(win32.CONTEXT_DEBUG_REGISTERS)\n                self.__slot = DebugRegister.find_slot(ctx)\n                if self.__slot is None:\n                    msg = \"No available hardware breakpoint slots for thread ID %d\"\n                    msg = msg % aThread.get_tid()\n                    raise RuntimeError(msg)\n                DebugRegister.set_bp(ctx, self.__slot, self.get_address(),\n                                                       self.__trigger, self.__watch)\n                aThread.set_context(ctx)\n            finally:\n                aThread.resume()", "response": "Sets this breakpoint in the debug registers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __postCallAction_hwbp(self, event):\n\n        # Remove the one shot hardware breakpoint\n        # at the return address location in the stack.\n        tid     = event.get_tid()\n        address = event.breakpoint.get_address()\n        event.debug.erase_hardware_breakpoint(tid, address)\n\n        # Call the \"post\" callback.\n        try:\n            self.__postCallAction(event)\n\n        # Forget the parameters.\n        finally:\n            self.__pop_params(tid)", "response": "Handles post call action on return from the function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling code breakpoint events on return from the function.", "response": "def __postCallAction_codebp(self, event):\n        \"\"\"\n        Handles code breakpoint events on return from the function.\n\n        @type  event: L{ExceptionEvent}\n        @param event: Breakpoint hit event.\n        \"\"\"\n\n        # If the breakpoint was accidentally hit by another thread,\n        # pass it to the debugger instead of calling the \"post\" callback.\n        #\n        # XXX FIXME:\n        # I suppose this check will fail under some weird conditions...\n        #\n        tid = event.get_tid()\n        if tid not in self.__paramStack:\n            return True\n\n        # Remove the code breakpoint at the return address.\n        pid     = event.get_pid()\n        address = event.breakpoint.get_address()\n        event.debug.dont_break_at(pid, address)\n\n        # Call the \"post\" callback.\n        try:\n            self.__postCallAction(event)\n\n        # Forget the parameters.\n        finally:\n            self.__pop_params(tid)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __postCallAction(self, event):\n        aThread = event.get_thread()\n        retval  = self._get_return_value(aThread)\n        self.__callHandler(self.__postCB, event, retval)", "response": "Calls the post callback."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling a callback function if set. is not None.", "response": "def __callHandler(self, callback, event, *params):\n        \"\"\"\n        Calls a \"pre\" or \"post\" handler, if set.\n\n        @type  callback: function\n        @param callback: Callback function to call.\n\n        @type  event: L{ExceptionEvent}\n        @param event: Breakpoint hit event.\n\n        @type  params: tuple\n        @param params: Parameters for the callback function.\n        \"\"\"\n        if callback is not None:\n            event.hook = self\n            callback(event, *params)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __push_params(self, tid, params):\n        stack = self.__paramStack.get( tid, [] )\n        stack.append(params)\n        self.__paramStack[tid] = stack", "response": "Pushes the arguments tuple for the last call to the hooked function\n        from this thread."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nforgets the arguments tuple for the last call to the hooked function from this thread.", "response": "def __pop_params(self, tid):\n        \"\"\"\n        Forgets the arguments tuple for the last call to the hooked function\n        from this thread.\n\n        @type  tid: int\n        @param tid: Thread global ID.\n        \"\"\"\n        stack = self.__paramStack[tid]\n        stack.pop()\n        if not stack:\n            del self.__paramStack[tid]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_params(self, tid):\n        try:\n            params = self.get_params_stack(tid)[-1]\n        except IndexError:\n            msg = \"Hooked function called from thread %d already returned\"\n            raise IndexError(msg % tid)\n        return params", "response": "Returns the parameters found in the stack when the hooked function\n        was last called by this thread."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the parameters found in the stack each time the hooked function was called by this thread and hasn t returned yet.", "response": "def get_params_stack(self, tid):\n        \"\"\"\n        Returns the parameters found in the stack each time the hooked function\n        was called by this thread and hasn't returned yet.\n\n        @type  tid: int\n        @param tid: Thread global ID.\n\n        @rtype:  list of tuple( arg, arg, arg... )\n        @return: List of argument tuples.\n        \"\"\"\n        try:\n            stack = self.__paramStack[tid]\n        except KeyError:\n            msg = \"Hooked function was not called from thread %d\"\n            raise KeyError(msg % tid)\n        return stack"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninstall the function hook at a given process and address.", "response": "def hook(self, debug, pid, address):\n        \"\"\"\n        Installs the function hook at a given process and address.\n\n        @see: L{unhook}\n\n        @warning: Do not call from an function hook callback.\n\n        @type  debug: L{Debug}\n        @param debug: Debug object.\n\n        @type  pid: int\n        @param pid: Process ID.\n\n        @type  address: int\n        @param address: Function address.\n        \"\"\"\n        return debug.break_at(pid, address, self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hook(self, debug, pid):\n        label = \"%s!%s\" % (self.__modName, self.__procName)\n        try:\n            hook = self.__hook[pid]\n        except KeyError:\n            try:\n                aProcess = debug.system.get_process(pid)\n            except KeyError:\n                aProcess = Process(pid)\n            hook = Hook(self.__preCB, self.__postCB,\n                        self.__paramCount, self.__signature,\n                        aProcess.get_arch() )\n            self.__hook[pid] = hook\n        hook.hook(debug, pid, label)", "response": "Installs the API hook on a given process and module."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unhook(self, debug, pid):\n        try:\n            hook = self.__hook[pid]\n        except KeyError:\n            return\n        label = \"%s!%s\" % (self.__modName, self.__procName)\n        hook.unhook(debug, pid, label)\n        del self.__hook[pid]", "response": "Removes the API hook from the given process and module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving a buffer watch identifier from the list of available buffer watches.", "response": "def remove(self, bw):\n        \"\"\"\n        Removes a buffer watch identifier.\n\n        @type  bw: L{BufferWatch}\n        @param bw:\n            Buffer watch identifier.\n\n        @raise KeyError: The buffer watch identifier was already removed.\n        \"\"\"\n        try:\n            self.__ranges.remove(bw)\n        except KeyError:\n            if not bw.oneshot:\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_last_match(self, address, size):\n        count = 0\n        start = address\n        end   = address + size - 1\n        matched = None\n        for item in self.__ranges:\n            if item.match(start) and item.match(end):\n                matched = item\n                count += 1\n        self.__ranges.remove(matched)\n        return count", "response": "Removes the last buffer from the watch object\n            to match the given address and size."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __cleanup_process(self, event):\n        pid     = event.get_pid()\n        process = event.get_process()\n\n        # Cleanup code breakpoints\n        for (bp_pid, bp_address) in compat.keys(self.__codeBP):\n            if bp_pid == pid:\n                bp = self.__codeBP[ (bp_pid, bp_address) ]\n                self.__cleanup_breakpoint(event, bp)\n                del self.__codeBP[ (bp_pid, bp_address) ]\n\n        # Cleanup page breakpoints\n        for (bp_pid, bp_address) in compat.keys(self.__pageBP):\n            if bp_pid == pid:\n                bp = self.__pageBP[ (bp_pid, bp_address) ]\n                self.__cleanup_breakpoint(event, bp)\n                del self.__pageBP[ (bp_pid, bp_address) ]\n\n        # Cleanup deferred code breakpoints\n        try:\n            del self.__deferredBP[pid]\n        except KeyError:\n            pass", "response": "Cleanup process breakpoints and deferred code breakpoints."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __cleanup_module(self, event):\n        pid     = event.get_pid()\n        process = event.get_process()\n        module  = event.get_module()\n\n        # Cleanup thread breakpoints on this module\n        for tid in process.iter_thread_ids():\n            thread = process.get_thread(tid)\n\n            # Running breakpoints\n            if tid in self.__runningBP:\n                bplist = list(self.__runningBP[tid])\n                for bp in bplist:\n                    bp_address = bp.get_address()\n                    if process.get_module_at_address(bp_address) == module:\n                        self.__cleanup_breakpoint(event, bp)\n                        self.__runningBP[tid].remove(bp)\n\n            # Hardware breakpoints\n            if tid in self.__hardwareBP:\n                bplist = list(self.__hardwareBP[tid])\n                for bp in bplist:\n                    bp_address = bp.get_address()\n                    if process.get_module_at_address(bp_address) == module:\n                        self.__cleanup_breakpoint(event, bp)\n                        self.__hardwareBP[tid].remove(bp)\n\n        # Cleanup code breakpoints on this module\n        for (bp_pid, bp_address) in compat.keys(self.__codeBP):\n            if bp_pid == pid:\n                if process.get_module_at_address(bp_address) == module:\n                    bp = self.__codeBP[ (bp_pid, bp_address) ]\n                    self.__cleanup_breakpoint(event, bp)\n                    del self.__codeBP[ (bp_pid, bp_address) ]\n\n        # Cleanup page breakpoints on this module\n        for (bp_pid, bp_address) in compat.keys(self.__pageBP):\n            if bp_pid == pid:\n                if process.get_module_at_address(bp_address) == module:\n                    bp = self.__pageBP[ (bp_pid, bp_address) ]\n                    self.__cleanup_breakpoint(event, bp)\n                    del self.__pageBP[ (bp_pid, bp_address) ]", "response": "Auxiliary method for L{_notify_unload_dll}."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndefines a code breakpoint at the given address.", "response": "def define_code_breakpoint(self, dwProcessId, address,   condition = True,\n                                                                action = None):\n        \"\"\"\n        Creates a disabled code breakpoint at the given address.\n\n        @see:\n            L{has_code_breakpoint},\n            L{get_code_breakpoint},\n            L{enable_code_breakpoint},\n            L{enable_one_shot_code_breakpoint},\n            L{disable_code_breakpoint},\n            L{erase_code_breakpoint}\n\n        @type  dwProcessId: int\n        @param dwProcessId: Process global ID.\n\n        @type  address: int\n        @param address: Memory address of the code instruction to break at.\n\n        @type  condition: function\n        @param condition: (Optional) Condition callback function.\n\n            The callback signature is::\n\n                def condition_callback(event):\n                    return True     # returns True or False\n\n            Where B{event} is an L{Event} object,\n            and the return value is a boolean\n            (C{True} to dispatch the event, C{False} otherwise).\n\n        @type  action: function\n        @param action: (Optional) Action callback function.\n            If specified, the event is handled by this callback instead of\n            being dispatched normally.\n\n            The callback signature is::\n\n                def action_callback(event):\n                    pass        # no return value\n\n            Where B{event} is an L{Event} object,\n            and the return value is a boolean\n            (C{True} to dispatch the event, C{False} otherwise).\n\n        @rtype:  L{CodeBreakpoint}\n        @return: The code breakpoint object.\n        \"\"\"\n        process = self.system.get_process(dwProcessId)\n        bp = CodeBreakpoint(address, condition, action)\n\n        key = (dwProcessId, bp.get_address())\n        if key in self.__codeBP:\n            msg = \"Already exists (PID %d) : %r\"\n            raise KeyError(msg % (dwProcessId, self.__codeBP[key]))\n        self.__codeBP[key] = bp\n        return bp"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef define_page_breakpoint(self, dwProcessId, address,       pages = 1,\n                                                             condition = True,\n                                                                action = None):\n        \"\"\"\n        Creates a disabled page breakpoint at the given address.\n\n        @see:\n            L{has_page_breakpoint},\n            L{get_page_breakpoint},\n            L{enable_page_breakpoint},\n            L{enable_one_shot_page_breakpoint},\n            L{disable_page_breakpoint},\n            L{erase_page_breakpoint}\n\n        @type  dwProcessId: int\n        @param dwProcessId: Process global ID.\n\n        @type  address: int\n        @param address: Memory address of the first page to watch.\n\n        @type  pages: int\n        @param pages: Number of pages to watch.\n\n        @type  condition: function\n        @param condition: (Optional) Condition callback function.\n\n            The callback signature is::\n\n                def condition_callback(event):\n                    return True     # returns True or False\n\n            Where B{event} is an L{Event} object,\n            and the return value is a boolean\n            (C{True} to dispatch the event, C{False} otherwise).\n\n        @type  action: function\n        @param action: (Optional) Action callback function.\n            If specified, the event is handled by this callback instead of\n            being dispatched normally.\n\n            The callback signature is::\n\n                def action_callback(event):\n                    pass        # no return value\n\n            Where B{event} is an L{Event} object,\n            and the return value is a boolean\n            (C{True} to dispatch the event, C{False} otherwise).\n\n        @rtype:  L{PageBreakpoint}\n        @return: The page breakpoint object.\n        \"\"\"\n        process = self.system.get_process(dwProcessId)\n        bp      = PageBreakpoint(address, pages, condition, action)\n        begin   = bp.get_address()\n        end     = begin + bp.get_size()\n\n        address  = begin\n        pageSize = MemoryAddresses.pageSize\n        while address < end:\n            key = (dwProcessId, address)\n            if key in self.__pageBP:\n                msg = \"Already exists (PID %d) : %r\"\n                msg = msg % (dwProcessId, self.__pageBP[key])\n                raise KeyError(msg)\n            address = address + pageSize\n\n        address = begin\n        while address < end:\n            key = (dwProcessId, address)\n            self.__pageBP[key] = bp\n            address = address + pageSize\n        return bp", "response": "Define a page breakpoint at the given address."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef define_hardware_breakpoint(self, dwThreadId, address,\n                                              triggerFlag = BP_BREAK_ON_ACCESS,\n                                                 sizeFlag = BP_WATCH_DWORD,\n                                                condition = True,\n                                                   action = None):\n        \"\"\"\n        Creates a disabled hardware breakpoint at the given address.\n\n        @see:\n            L{has_hardware_breakpoint},\n            L{get_hardware_breakpoint},\n            L{enable_hardware_breakpoint},\n            L{enable_one_shot_hardware_breakpoint},\n            L{disable_hardware_breakpoint},\n            L{erase_hardware_breakpoint}\n\n        @note:\n            Hardware breakpoints do not seem to work properly on VirtualBox.\n            See U{http://www.virtualbox.org/ticket/477}.\n\n        @type  dwThreadId: int\n        @param dwThreadId: Thread global ID.\n\n        @type  address: int\n        @param address: Memory address to watch.\n\n        @type  triggerFlag: int\n        @param triggerFlag: Trigger of breakpoint. Must be one of the following:\n\n             - L{BP_BREAK_ON_EXECUTION}\n\n               Break on code execution.\n\n             - L{BP_BREAK_ON_WRITE}\n\n               Break on memory read or write.\n\n             - L{BP_BREAK_ON_ACCESS}\n\n               Break on memory write.\n\n        @type  sizeFlag: int\n        @param sizeFlag: Size of breakpoint. Must be one of the following:\n\n             - L{BP_WATCH_BYTE}\n\n               One (1) byte in size.\n\n             - L{BP_WATCH_WORD}\n\n               Two (2) bytes in size.\n\n             - L{BP_WATCH_DWORD}\n\n               Four (4) bytes in size.\n\n             - L{BP_WATCH_QWORD}\n\n               Eight (8) bytes in size.\n\n        @type  condition: function\n        @param condition: (Optional) Condition callback function.\n\n            The callback signature is::\n\n                def condition_callback(event):\n                    return True     # returns True or False\n\n            Where B{event} is an L{Event} object,\n            and the return value is a boolean\n            (C{True} to dispatch the event, C{False} otherwise).\n\n        @type  action: function\n        @param action: (Optional) Action callback function.\n            If specified, the event is handled by this callback instead of\n            being dispatched normally.\n\n            The callback signature is::\n\n                def action_callback(event):\n                    pass        # no return value\n\n            Where B{event} is an L{Event} object,\n            and the return value is a boolean\n            (C{True} to dispatch the event, C{False} otherwise).\n\n        @rtype:  L{HardwareBreakpoint}\n        @return: The hardware breakpoint object.\n        \"\"\"\n        thread  = self.system.get_thread(dwThreadId)\n        bp      = HardwareBreakpoint(address, triggerFlag, sizeFlag, condition,\n                                                                        action)\n        begin   = bp.get_address()\n        end     = begin + bp.get_size()\n\n        if dwThreadId in self.__hardwareBP:\n            bpSet = self.__hardwareBP[dwThreadId]\n            for oldbp in bpSet:\n                old_begin = oldbp.get_address()\n                old_end   = old_begin + oldbp.get_size()\n                if MemoryAddresses.do_ranges_intersect(begin, end, old_begin,\n                                                                     old_end):\n                    msg = \"Already exists (TID %d) : %r\" % (dwThreadId, oldbp)\n                    raise KeyError(msg)\n        else:\n            bpSet = set()\n            self.__hardwareBP[dwThreadId] = bpSet\n        bpSet.add(bp)\n        return bp", "response": "Define a hardware breakpoint at the given address."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if a hardware breakpoint is defined at the given address.", "response": "def has_hardware_breakpoint(self, dwThreadId, address):\n        \"\"\"\n        Checks if a hardware breakpoint is defined at the given address.\n\n        @see:\n            L{define_hardware_breakpoint},\n            L{get_hardware_breakpoint},\n            L{erase_hardware_breakpoint},\n            L{enable_hardware_breakpoint},\n            L{enable_one_shot_hardware_breakpoint},\n            L{disable_hardware_breakpoint}\n\n        @type  dwThreadId: int\n        @param dwThreadId: Thread global ID.\n\n        @type  address: int\n        @param address: Memory address of breakpoint.\n\n        @rtype:  bool\n        @return: C{True} if the breakpoint is defined, C{False} otherwise.\n        \"\"\"\n        if dwThreadId in self.__hardwareBP:\n            bpSet = self.__hardwareBP[dwThreadId]\n            for bp in bpSet:\n                if bp.get_address() == address:\n                    return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_code_breakpoint(self, dwProcessId, address):\n        key = (dwProcessId, address)\n        if key not in self.__codeBP:\n            msg = \"No breakpoint at process %d, address %s\"\n            address = HexDump.address(address)\n            raise KeyError(msg % (dwProcessId, address))\n        return self.__codeBP[key]", "response": "Returns the code breakpoint object at the given address."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_page_breakpoint(self, dwProcessId, address):\n        key = (dwProcessId, address)\n        if key not in self.__pageBP:\n            msg = \"No breakpoint at process %d, address %s\"\n            address = HexDump.addresS(address)\n            raise KeyError(msg % (dwProcessId, address))\n        return self.__pageBP[key]", "response": "Returns the page breakpoint object at the given address."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the object that represents the given hardware breakpoint at the given address.", "response": "def get_hardware_breakpoint(self, dwThreadId, address):\n        \"\"\"\n        Returns the internally used breakpoint object,\n        for the code breakpoint defined at the given address.\n\n        @warning: It's usually best to call the L{Debug} methods\n            instead of accessing the breakpoint objects directly.\n\n        @see:\n            L{define_hardware_breakpoint},\n            L{has_hardware_breakpoint},\n            L{get_code_breakpoint},\n            L{enable_hardware_breakpoint},\n            L{enable_one_shot_hardware_breakpoint},\n            L{disable_hardware_breakpoint},\n            L{erase_hardware_breakpoint}\n\n        @type  dwThreadId: int\n        @param dwThreadId: Thread global ID.\n\n        @type  address: int\n        @param address: Memory address where the breakpoint is defined.\n\n        @rtype:  L{HardwareBreakpoint}\n        @return: The hardware breakpoint object.\n        \"\"\"\n        if dwThreadId not in self.__hardwareBP:\n            msg = \"No hardware breakpoints set for thread %d\"\n            raise KeyError(msg % dwThreadId)\n        for bp in self.__hardwareBP[dwThreadId]:\n            if bp.is_here(address):\n                return bp\n        msg = \"No hardware breakpoint at thread %d, address %s\"\n        raise KeyError(msg % (dwThreadId, HexDump.address(address)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enable_code_breakpoint(self, dwProcessId, address):\n        p  = self.system.get_process(dwProcessId)\n        bp = self.get_code_breakpoint(dwProcessId, address)\n        if bp.is_running():\n            self.__del_running_bp_from_all_threads(bp)\n        bp.enable(p, None)", "response": "Enables the code breakpoint at the given address."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef enable_page_breakpoint(self, dwProcessId, address):\n        p  = self.system.get_process(dwProcessId)\n        bp = self.get_page_breakpoint(dwProcessId, address)\n        if bp.is_running():\n            self.__del_running_bp_from_all_threads(bp)\n        bp.enable(p, None)", "response": "Enables the page breakpoint at the given address."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef enable_hardware_breakpoint(self, dwThreadId, address):\n        t  = self.system.get_thread(dwThreadId)\n        bp = self.get_hardware_breakpoint(dwThreadId, address)\n        if bp.is_running():\n            self.__del_running_bp_from_all_threads(bp)\n        bp.enable(None, t)", "response": "Enables the hardware breakpoint at the given address."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef enable_one_shot_code_breakpoint(self, dwProcessId, address):\n        p  = self.system.get_process(dwProcessId)\n        bp = self.get_code_breakpoint(dwProcessId, address)\n        if bp.is_running():\n            self.__del_running_bp_from_all_threads(bp)\n        bp.one_shot(p, None)", "response": "Enables the code breakpoint at the given address for only one shot."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef enable_one_shot_page_breakpoint(self, dwProcessId, address):\n        p  = self.system.get_process(dwProcessId)\n        bp = self.get_page_breakpoint(dwProcessId, address)\n        if bp.is_running():\n            self.__del_running_bp_from_all_threads(bp)\n        bp.one_shot(p, None)", "response": "Enables the page breakpoint at the given address for only one shot."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef enable_one_shot_hardware_breakpoint(self, dwThreadId, address):\n        t  = self.system.get_thread(dwThreadId)\n        bp = self.get_hardware_breakpoint(dwThreadId, address)\n        if bp.is_running():\n            self.__del_running_bp_from_all_threads(bp)\n        bp.one_shot(None, t)", "response": "Enables the hardware breakpoint at the given address for only one shot."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndisabling the code breakpoint at the given address.", "response": "def disable_code_breakpoint(self, dwProcessId, address):\n        \"\"\"\n        Disables the code breakpoint at the given address.\n\n        @see:\n            L{define_code_breakpoint},\n            L{has_code_breakpoint},\n            L{get_code_breakpoint},\n            L{enable_code_breakpoint}\n            L{enable_one_shot_code_breakpoint},\n            L{erase_code_breakpoint},\n\n        @type  dwProcessId: int\n        @param dwProcessId: Process global ID.\n\n        @type  address: int\n        @param address: Memory address of breakpoint.\n        \"\"\"\n        p  = self.system.get_process(dwProcessId)\n        bp = self.get_code_breakpoint(dwProcessId, address)\n        if bp.is_running():\n            self.__del_running_bp_from_all_threads(bp)\n        bp.disable(p, None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef disable_page_breakpoint(self, dwProcessId, address):\n        p  = self.system.get_process(dwProcessId)\n        bp = self.get_page_breakpoint(dwProcessId, address)\n        if bp.is_running():\n            self.__del_running_bp_from_all_threads(bp)\n        bp.disable(p, None)", "response": "Disables the page breakpoint at the given address."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef disable_hardware_breakpoint(self, dwThreadId, address):\n        t  = self.system.get_thread(dwThreadId)\n        p  = t.get_process()\n        bp = self.get_hardware_breakpoint(dwThreadId, address)\n        if bp.is_running():\n            self.__del_running_bp(dwThreadId, bp)\n        bp.disable(p, t)", "response": "Disables the hardware breakpoint at the given address."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nerase the code breakpoint at the given address.", "response": "def erase_code_breakpoint(self, dwProcessId, address):\n        \"\"\"\n        Erases the code breakpoint at the given address.\n\n        @see:\n            L{define_code_breakpoint},\n            L{has_code_breakpoint},\n            L{get_code_breakpoint},\n            L{enable_code_breakpoint},\n            L{enable_one_shot_code_breakpoint},\n            L{disable_code_breakpoint}\n\n        @type  dwProcessId: int\n        @param dwProcessId: Process global ID.\n\n        @type  address: int\n        @param address: Memory address of breakpoint.\n        \"\"\"\n        bp = self.get_code_breakpoint(dwProcessId, address)\n        if not bp.is_disabled():\n            self.disable_code_breakpoint(dwProcessId, address)\n        del self.__codeBP[ (dwProcessId, address) ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nerase the page breakpoint at the given address.", "response": "def erase_page_breakpoint(self, dwProcessId, address):\n        \"\"\"\n        Erases the page breakpoint at the given address.\n\n        @see:\n            L{define_page_breakpoint},\n            L{has_page_breakpoint},\n            L{get_page_breakpoint},\n            L{enable_page_breakpoint},\n            L{enable_one_shot_page_breakpoint},\n            L{disable_page_breakpoint}\n\n        @type  dwProcessId: int\n        @param dwProcessId: Process global ID.\n\n        @type  address: int\n        @param address: Memory address of breakpoint.\n        \"\"\"\n        bp    = self.get_page_breakpoint(dwProcessId, address)\n        begin = bp.get_address()\n        end   = begin + bp.get_size()\n        if not bp.is_disabled():\n            self.disable_page_breakpoint(dwProcessId, address)\n        address  = begin\n        pageSize = MemoryAddresses.pageSize\n        while address < end:\n            del self.__pageBP[ (dwProcessId, address) ]\n            address = address + pageSize"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nerases the hardware breakpoint at the given address.", "response": "def erase_hardware_breakpoint(self, dwThreadId, address):\n        \"\"\"\n        Erases the hardware breakpoint at the given address.\n\n        @see:\n            L{define_hardware_breakpoint},\n            L{has_hardware_breakpoint},\n            L{get_hardware_breakpoint},\n            L{enable_hardware_breakpoint},\n            L{enable_one_shot_hardware_breakpoint},\n            L{disable_hardware_breakpoint}\n\n        @type  dwThreadId: int\n        @param dwThreadId: Thread global ID.\n\n        @type  address: int\n        @param address: Memory address of breakpoint.\n        \"\"\"\n        bp = self.get_hardware_breakpoint(dwThreadId, address)\n        if not bp.is_disabled():\n            self.disable_hardware_breakpoint(dwThreadId, address)\n        bpSet = self.__hardwareBP[dwThreadId]\n        bpSet.remove(bp)\n        if not bpSet:\n            del self.__hardwareBP[dwThreadId]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning all breakpoints as a list of tuples.", "response": "def get_all_breakpoints(self):\n        \"\"\"\n        Returns all breakpoint objects as a list of tuples.\n\n        Each tuple contains:\n         - Process global ID to which the breakpoint applies.\n         - Thread global ID to which the breakpoint applies, or C{None}.\n         - The L{Breakpoint} object itself.\n\n        @note: If you're only interested in a specific breakpoint type, or in\n            breakpoints for a specific process or thread, it's probably faster\n            to call one of the following methods:\n             - L{get_all_code_breakpoints}\n             - L{get_all_page_breakpoints}\n             - L{get_all_hardware_breakpoints}\n             - L{get_process_code_breakpoints}\n             - L{get_process_page_breakpoints}\n             - L{get_process_hardware_breakpoints}\n             - L{get_thread_hardware_breakpoints}\n\n        @rtype:  list of tuple( pid, tid, bp )\n        @return: List of all breakpoints.\n        \"\"\"\n        bplist = list()\n\n        # Get the code breakpoints.\n        for (pid, bp) in self.get_all_code_breakpoints():\n            bplist.append( (pid, None, bp) )\n\n        # Get the page breakpoints.\n        for (pid, bp) in self.get_all_page_breakpoints():\n            bplist.append( (pid, None, bp) )\n\n        # Get the hardware breakpoints.\n        for (tid, bp) in self.get_all_hardware_breakpoints():\n            pid = self.system.get_thread(tid).get_pid()\n            bplist.append( (pid, tid, bp) )\n\n        # Return the list of breakpoints.\n        return bplist"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_process_breakpoints(self, dwProcessId):\n        bplist = list()\n\n        # Get the code breakpoints.\n        for bp in self.get_process_code_breakpoints(dwProcessId):\n            bplist.append( (dwProcessId, None, bp) )\n\n        # Get the page breakpoints.\n        for bp in self.get_process_page_breakpoints(dwProcessId):\n            bplist.append( (dwProcessId, None, bp) )\n\n        # Get the hardware breakpoints.\n        for (tid, bp) in self.get_process_hardware_breakpoints(dwProcessId):\n            pid = self.system.get_thread(tid).get_pid()\n            bplist.append( (dwProcessId, tid, bp) )\n\n        # Return the list of breakpoints.\n        return bplist", "response": "Returns all the breakpoints for the given process as a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_process_code_breakpoints(self, dwProcessId):\n        return [ bp for ((pid, address), bp) in compat.iteritems(self.__codeBP) \\\n                if pid == dwProcessId ]", "response": "Returns a list of code breakpoints for the given process."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_process_page_breakpoints(self, dwProcessId):\n        return [ bp for ((pid, address), bp) in compat.iteritems(self.__pageBP) \\\n                if pid == dwProcessId ]", "response": "Returns a list of page breakpoints for the given process."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of hardware breakpoints for the given thread.", "response": "def get_thread_hardware_breakpoints(self, dwThreadId):\n        \"\"\"\n        @see: L{get_process_hardware_breakpoints}\n\n        @type  dwThreadId: int\n        @param dwThreadId: Thread global ID.\n\n        @rtype:  list of L{HardwareBreakpoint}\n        @return: All hardware breakpoints for the given thread.\n        \"\"\"\n        result = list()\n        for (tid, bplist) in compat.iteritems(self.__hardwareBP):\n            if tid == dwThreadId:\n                for bp in bplist:\n                    result.append(bp)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_process_hardware_breakpoints(self, dwProcessId):\n        result = list()\n        aProcess = self.system.get_process(dwProcessId)\n        for dwThreadId in aProcess.iter_thread_ids():\n            if dwThreadId in self.__hardwareBP:\n                bplist = self.__hardwareBP[dwThreadId]\n                for bp in bplist:\n                    result.append( (dwThreadId, bp) )\n        return result", "response": "Returns a list of hardware breakpoints for each thread in the given process."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef enable_all_breakpoints(self):\n\n        # disable code breakpoints\n        for (pid, bp) in self.get_all_code_breakpoints():\n            if bp.is_disabled():\n                self.enable_code_breakpoint(pid, bp.get_address())\n\n        # disable page breakpoints\n        for (pid, bp) in self.get_all_page_breakpoints():\n            if bp.is_disabled():\n                self.enable_page_breakpoint(pid, bp.get_address())\n\n        # disable hardware breakpoints\n        for (tid, bp) in self.get_all_hardware_breakpoints():\n            if bp.is_disabled():\n                self.enable_hardware_breakpoint(tid, bp.get_address())", "response": "Enables all disabled breakpoints in all processes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef enable_one_shot_all_breakpoints(self):\n\n        # disable code breakpoints for one shot\n        for (pid, bp) in self.get_all_code_breakpoints():\n            if bp.is_disabled():\n                self.enable_one_shot_code_breakpoint(pid, bp.get_address())\n\n        # disable page breakpoints for one shot\n        for (pid, bp) in self.get_all_page_breakpoints():\n            if bp.is_disabled():\n                self.enable_one_shot_page_breakpoint(pid, bp.get_address())\n\n        # disable hardware breakpoints for one shot\n        for (tid, bp) in self.get_all_hardware_breakpoints():\n            if bp.is_disabled():\n                self.enable_one_shot_hardware_breakpoint(tid, bp.get_address())", "response": "Enables one shot all disabled breakpoints in all processes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef disable_all_breakpoints(self):\n\n        # disable code breakpoints\n        for (pid, bp) in self.get_all_code_breakpoints():\n            self.disable_code_breakpoint(pid, bp.get_address())\n\n        # disable page breakpoints\n        for (pid, bp) in self.get_all_page_breakpoints():\n            self.disable_page_breakpoint(pid, bp.get_address())\n\n        # disable hardware breakpoints\n        for (tid, bp) in self.get_all_hardware_breakpoints():\n            self.disable_hardware_breakpoint(tid, bp.get_address())", "response": "Disables all breakpoints in all processes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef erase_all_breakpoints(self):\n\n        # This should be faster but let's not trust the GC so much :P\n        # self.disable_all_breakpoints()\n        # self.__codeBP       = dict()\n        # self.__pageBP       = dict()\n        # self.__hardwareBP   = dict()\n        # self.__runningBP    = dict()\n        # self.__hook_objects = dict()\n\n##        # erase hooks\n##        for (pid, address, hook) in self.get_all_hooks():\n##            self.dont_hook_function(pid, address)\n\n        # erase code breakpoints\n        for (pid, bp) in self.get_all_code_breakpoints():\n            self.erase_code_breakpoint(pid, bp.get_address())\n\n        # erase page breakpoints\n        for (pid, bp) in self.get_all_page_breakpoints():\n            self.erase_page_breakpoint(pid, bp.get_address())\n\n        # erase hardware breakpoints\n        for (tid, bp) in self.get_all_hardware_breakpoints():\n            self.erase_hardware_breakpoint(tid, bp.get_address())", "response": "Erases all breakpoints in all processes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nenable all disabled breakpoints for the given process.", "response": "def enable_process_breakpoints(self, dwProcessId):\n        \"\"\"\n        Enables all disabled breakpoints for the given process.\n\n        @type  dwProcessId: int\n        @param dwProcessId: Process global ID.\n        \"\"\"\n\n        # enable code breakpoints\n        for bp in self.get_process_code_breakpoints(dwProcessId):\n            if bp.is_disabled():\n                self.enable_code_breakpoint(dwProcessId, bp.get_address())\n\n        # enable page breakpoints\n        for bp in self.get_process_page_breakpoints(dwProcessId):\n            if bp.is_disabled():\n                self.enable_page_breakpoint(dwProcessId, bp.get_address())\n\n        # enable hardware breakpoints\n        if self.system.has_process(dwProcessId):\n            aProcess = self.system.get_process(dwProcessId)\n        else:\n            aProcess = Process(dwProcessId)\n            aProcess.scan_threads()\n        for aThread in aProcess.iter_threads():\n            dwThreadId = aThread.get_tid()\n            for bp in self.get_thread_hardware_breakpoints(dwThreadId):\n                if bp.is_disabled():\n                    self.enable_hardware_breakpoint(dwThreadId, bp.get_address())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nenables all disabled code page and hardware breakpoints for the given process.", "response": "def enable_one_shot_process_breakpoints(self, dwProcessId):\n        \"\"\"\n        Enables for one shot all disabled breakpoints for the given process.\n\n        @type  dwProcessId: int\n        @param dwProcessId: Process global ID.\n        \"\"\"\n\n        # enable code breakpoints for one shot\n        for bp in self.get_process_code_breakpoints(dwProcessId):\n            if bp.is_disabled():\n                self.enable_one_shot_code_breakpoint(dwProcessId, bp.get_address())\n\n        # enable page breakpoints for one shot\n        for bp in self.get_process_page_breakpoints(dwProcessId):\n            if bp.is_disabled():\n                self.enable_one_shot_page_breakpoint(dwProcessId, bp.get_address())\n\n        # enable hardware breakpoints for one shot\n        if self.system.has_process(dwProcessId):\n            aProcess = self.system.get_process(dwProcessId)\n        else:\n            aProcess = Process(dwProcessId)\n            aProcess.scan_threads()\n        for aThread in aProcess.iter_threads():\n            dwThreadId = aThread.get_tid()\n            for bp in self.get_thread_hardware_breakpoints(dwThreadId):\n                if bp.is_disabled():\n                    self.enable_one_shot_hardware_breakpoint(dwThreadId, bp.get_address())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef disable_process_breakpoints(self, dwProcessId):\n\n        # disable code breakpoints\n        for bp in self.get_process_code_breakpoints(dwProcessId):\n            self.disable_code_breakpoint(dwProcessId, bp.get_address())\n\n        # disable page breakpoints\n        for bp in self.get_process_page_breakpoints(dwProcessId):\n            self.disable_page_breakpoint(dwProcessId, bp.get_address())\n\n        # disable hardware breakpoints\n        if self.system.has_process(dwProcessId):\n            aProcess = self.system.get_process(dwProcessId)\n        else:\n            aProcess = Process(dwProcessId)\n            aProcess.scan_threads()\n        for aThread in aProcess.iter_threads():\n            dwThreadId = aThread.get_tid()\n            for bp in self.get_thread_hardware_breakpoints(dwThreadId):\n                self.disable_hardware_breakpoint(dwThreadId, bp.get_address())", "response": "Disables all breakpoints for the given process."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nerasing all breakpoints for the given process.", "response": "def erase_process_breakpoints(self, dwProcessId):\n        \"\"\"\n        Erases all breakpoints for the given process.\n\n        @type  dwProcessId: int\n        @param dwProcessId: Process global ID.\n        \"\"\"\n\n        # disable breakpoints first\n        # if an error occurs, no breakpoint is erased\n        self.disable_process_breakpoints(dwProcessId)\n\n##        # erase hooks\n##        for address, hook in self.get_process_hooks(dwProcessId):\n##            self.dont_hook_function(dwProcessId, address)\n\n        # erase code breakpoints\n        for bp in self.get_process_code_breakpoints(dwProcessId):\n            self.erase_code_breakpoint(dwProcessId, bp.get_address())\n\n        # erase page breakpoints\n        for bp in self.get_process_page_breakpoints(dwProcessId):\n            self.erase_page_breakpoint(dwProcessId, bp.get_address())\n\n        # erase hardware breakpoints\n        if self.system.has_process(dwProcessId):\n            aProcess = self.system.get_process(dwProcessId)\n        else:\n            aProcess = Process(dwProcessId)\n            aProcess.scan_threads()\n        for aThread in aProcess.iter_threads():\n            dwThreadId = aThread.get_tid()\n            for bp in self.get_thread_hardware_breakpoints(dwThreadId):\n                self.erase_hardware_breakpoint(dwThreadId, bp.get_address())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nnotifying the user - defined handle of a guard page exception event.", "response": "def _notify_guard_page(self, event):\n        \"\"\"\n        Notify breakpoints of a guard page exception event.\n\n        @type  event: L{ExceptionEvent}\n        @param event: Guard page exception event.\n\n        @rtype:  bool\n        @return: C{True} to call the user-defined handle, C{False} otherwise.\n        \"\"\"\n        address         = event.get_fault_address()\n        pid             = event.get_pid()\n        bCallHandler    = True\n\n        # Align address to page boundary.\n        mask = ~(MemoryAddresses.pageSize - 1)\n        address = address & mask\n\n        # Do we have an active page breakpoint there?\n        key = (pid, address)\n        if key in self.__pageBP:\n            bp = self.__pageBP[key]\n            if bp.is_enabled() or bp.is_one_shot():\n\n                # Breakpoint is ours.\n                event.continueStatus = win32.DBG_CONTINUE\n##                event.continueStatus = win32.DBG_EXCEPTION_HANDLED\n\n                # Hit the breakpoint.\n                bp.hit(event)\n\n                # Remember breakpoints in RUNNING state.\n                if bp.is_running():\n                    tid = event.get_tid()\n                    self.__add_running_bp(tid, bp)\n\n                # Evaluate the breakpoint condition.\n                bCondition = bp.eval_condition(event)\n\n                # If the breakpoint is automatic, run the action.\n                # If not, notify the user.\n                if bCondition and bp.is_automatic():\n                    bp.run_action(event)\n                    bCallHandler = False\n                else:\n                    bCallHandler = bCondition\n\n        # If we don't have a breakpoint here pass the exception to the debugee.\n        # This is a normally occurring exception so we shouldn't swallow it.\n        else:\n            event.continueStatus = win32.DBG_EXCEPTION_NOT_HANDLED\n\n        return bCallHandler"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _notify_breakpoint(self, event):\n        address         = event.get_exception_address()\n        pid             = event.get_pid()\n        bCallHandler    = True\n\n        # Do we have an active code breakpoint there?\n        key = (pid, address)\n        if key in self.__codeBP:\n            bp = self.__codeBP[key]\n            if not bp.is_disabled():\n\n                # Change the program counter (PC) to the exception address.\n                # This accounts for the change in PC caused by\n                # executing the breakpoint instruction, no matter\n                # the size of it.\n                aThread = event.get_thread()\n                aThread.set_pc(address)\n\n                # Swallow the exception.\n                event.continueStatus = win32.DBG_CONTINUE\n\n                # Hit the breakpoint.\n                bp.hit(event)\n\n                # Remember breakpoints in RUNNING state.\n                if bp.is_running():\n                    tid = event.get_tid()\n                    self.__add_running_bp(tid, bp)\n\n                # Evaluate the breakpoint condition.\n                bCondition = bp.eval_condition(event)\n\n                # If the breakpoint is automatic, run the action.\n                # If not, notify the user.\n                if bCondition and bp.is_automatic():\n                    bCallHandler = bp.run_action(event)\n                else:\n                    bCallHandler = bCondition\n\n        # Handle the system breakpoint.\n        # TODO: examine the stack trace to figure out if it's really a\n        # system breakpoint or an antidebug trick. The caller should be\n        # inside ntdll if it's legit.\n        elif event.get_process().is_system_defined_breakpoint(address):\n            event.continueStatus = win32.DBG_CONTINUE\n\n        # In hostile mode, if we don't have a breakpoint here pass the\n        # exception to the debugee. In normal mode assume all breakpoint\n        # exceptions are to be handled by the debugger.\n        else:\n            if self.in_hostile_mode():\n                event.continueStatus = win32.DBG_EXCEPTION_NOT_HANDLED\n            else:\n                event.continueStatus = win32.DBG_CONTINUE\n\n        return bCallHandler", "response": "Notify the user of a breakpoint exception event."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _notify_single_step(self, event):\n        pid             = event.get_pid()\n        tid             = event.get_tid()\n        aThread         = event.get_thread()\n        aProcess        = event.get_process()\n        bCallHandler    = True\n        bIsOurs         = False\n\n        # In hostile mode set the default to pass the exception to the debugee.\n        # If we later determine the exception is ours, hide it instead.\n        old_continueStatus = event.continueStatus\n        try:\n            if self.in_hostile_mode():\n                event.continueStatus = win32.DBG_EXCEPTION_NOT_HANDLED\n\n            # Single step support is implemented on x86/x64 architectures only.\n            if self.system.arch not in (win32.ARCH_I386, win32.ARCH_AMD64):\n                return bCallHandler\n\n            # In hostile mode, read the last executed bytes to try to detect\n            # some antidebug tricks. Skip this check in normal mode because\n            # it'd slow things down.\n            #\n            # FIXME: weird opcode encodings may bypass this check!\n            #\n            # bFakeSingleStep: Ice Breakpoint undocumented instruction.\n            # bHideTrapFlag: Don't let pushf instructions get the real value of\n            #                the trap flag.\n            # bNextIsPopFlags: Don't let popf instructions clear the trap flag.\n            #\n            bFakeSingleStep  = False\n            bLastIsPushFlags = False\n            bNextIsPopFlags  = False\n            if self.in_hostile_mode():\n                pc = aThread.get_pc()\n                c = aProcess.read_char(pc - 1)\n                if c == 0xF1:               # int1\n                    bFakeSingleStep  = True\n                elif c == 0x9C:             # pushf\n                    bLastIsPushFlags = True\n                c = aProcess.peek_char(pc)\n                if c == 0x66:           # the only valid prefix for popf\n                    c = aProcess.peek_char(pc + 1)\n                if c == 0x9D:           # popf\n                    if bLastIsPushFlags:\n                        bLastIsPushFlags = False  # they cancel each other out\n                    else:\n                        bNextIsPopFlags  = True\n\n            # When the thread is in tracing mode,\n            # don't pass the exception to the debugee\n            # and set the trap flag again.\n            if self.is_tracing(tid):\n                bIsOurs = True\n                if not bFakeSingleStep:\n                    event.continueStatus = win32.DBG_CONTINUE\n                aThread.set_tf()\n\n                # Don't let the debugee read or write the trap flag.\n                # This code works in 32 and 64 bits thanks to the endianness.\n                if bLastIsPushFlags or bNextIsPopFlags:\n                    sp = aThread.get_sp()\n                    flags = aProcess.read_dword(sp)\n                    if bLastIsPushFlags:\n                        flags &= ~Thread.Flags.Trap\n                    else: # if bNextIsPopFlags:\n                        flags |= Thread.Flags.Trap\n                    aProcess.write_dword(sp, flags)\n\n            # Handle breakpoints in RUNNING state.\n            running = self.__get_running_bp_set(tid)\n            if running:\n                bIsOurs = True\n                if not bFakeSingleStep:\n                    event.continueStatus = win32.DBG_CONTINUE\n                bCallHandler = False\n                while running:\n                    try:\n                        running.pop().hit(event)\n                    except Exception:\n                        e = sys.exc_info()[1]\n                        warnings.warn(str(e), BreakpointWarning)\n\n            # Handle hardware breakpoints.\n            if tid in self.__hardwareBP:\n                ctx     = aThread.get_context(win32.CONTEXT_DEBUG_REGISTERS)\n                Dr6     = ctx['Dr6']\n                ctx['Dr6'] = Dr6 & DebugRegister.clearHitMask\n                aThread.set_context(ctx)\n                bFoundBreakpoint = False\n                bCondition       = False\n                hwbpList = [ bp for bp in self.__hardwareBP[tid] ]\n                for bp in hwbpList:\n                    if not bp in self.__hardwareBP[tid]:\n                        continue    # it was removed by a user-defined callback\n                    slot = bp.get_slot()\n                    if (slot is not None) and \\\n                                           (Dr6 & DebugRegister.hitMask[slot]):\n                        if not bFoundBreakpoint: #set before actions are called\n                            if not bFakeSingleStep:\n                                event.continueStatus = win32.DBG_CONTINUE\n                        bFoundBreakpoint = True\n                        bIsOurs = True\n                        bp.hit(event)\n                        if bp.is_running():\n                            self.__add_running_bp(tid, bp)\n                        bThisCondition = bp.eval_condition(event)\n                        if bThisCondition and bp.is_automatic():\n                            bp.run_action(event)\n                            bThisCondition = False\n                        bCondition = bCondition or bThisCondition\n                if bFoundBreakpoint:\n                    bCallHandler = bCondition\n\n            # Always call the user-defined handler\n            # when the thread is in tracing mode.\n            if self.is_tracing(tid):\n                bCallHandler = True\n\n            # If we're not in hostile mode, by default we assume all single\n            # step exceptions are caused by the debugger.\n            if not bIsOurs and not self.in_hostile_mode():\n                aThread.clear_tf()\n\n        # If the user hit Control-C while we were inside the try block,\n        # set the default continueStatus back.\n        except:\n            event.continueStatus = old_continueStatus\n            raise\n\n        return bCallHandler", "response": "Notify breakpoints of a single step exception event."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nnotify the termination of a process.", "response": "def _notify_exit_process(self, event):\n        \"\"\"\n        Notify the termination of a process.\n\n        @type  event: L{ExitProcessEvent}\n        @param event: Exit process event.\n\n        @rtype:  bool\n        @return: C{True} to call the user-defined handler, C{False} otherwise.\n        \"\"\"\n        self.__cleanup_process(event)\n        self.__cleanup_thread(event)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the breakpoint at the given address.", "response": "def __set_break(self, pid, address, action, oneshot):\n        \"\"\"\n        Used by L{break_at} and L{stalk_at}.\n\n        @type  pid: int\n        @param pid: Process global ID.\n\n        @type  address: int or str\n        @param address:\n            Memory address of code instruction to break at. It can be an\n            integer value for the actual address or a string with a label\n            to be resolved.\n\n        @type  action: function\n        @param action: (Optional) Action callback function.\n\n            See L{define_code_breakpoint} for more details.\n\n        @type  oneshot: bool\n        @param oneshot: C{True} for one-shot breakpoints, C{False} otherwise.\n\n        @rtype:  L{Breakpoint}\n        @return: Returns the new L{Breakpoint} object, or C{None} if the label\n            couldn't be resolved and the breakpoint was deferred. Deferred\n            breakpoints are set when the DLL they point to is loaded.\n        \"\"\"\n        if type(address) not in (int, long):\n            label = address\n            try:\n                address = self.system.get_process(pid).resolve_label(address)\n                if not address:\n                    raise Exception()\n            except Exception:\n                try:\n                    deferred = self.__deferredBP[pid]\n                except KeyError:\n                    deferred = dict()\n                    self.__deferredBP[pid] = deferred\n                if label in deferred:\n                    msg = \"Redefined deferred code breakpoint at %s in process ID %d\"\n                    msg = msg % (label, pid)\n                    warnings.warn(msg, BreakpointWarning)\n                deferred[label] = (action, oneshot)\n                return None\n        if self.has_code_breakpoint(pid, address):\n            bp = self.get_code_breakpoint(pid, address)\n            if bp.get_action() != action:   # can't use \"is not\", fails for bound methods\n                bp.set_action(action)\n                msg = \"Redefined code breakpoint at %s in process ID %d\"\n                msg = msg % (label, pid)\n                warnings.warn(msg, BreakpointWarning)\n        else:\n            self.define_code_breakpoint(pid, address, True, action)\n            bp = self.get_code_breakpoint(pid, address)\n        if oneshot:\n            if not bp.is_one_shot():\n                self.enable_one_shot_code_breakpoint(pid, address)\n        else:\n            if not bp.is_enabled():\n                self.enable_code_breakpoint(pid, address)\n        return bp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclearing the code breakpoint at the given address.", "response": "def __clear_break(self, pid, address):\n        \"\"\"\n        Used by L{dont_break_at} and L{dont_stalk_at}.\n\n        @type  pid: int\n        @param pid: Process global ID.\n\n        @type  address: int or str\n        @param address:\n            Memory address of code instruction to break at. It can be an\n            integer value for the actual address or a string with a label\n            to be resolved.\n        \"\"\"\n        if type(address) not in (int, long):\n            unknown = True\n            label = address\n            try:\n                deferred = self.__deferredBP[pid]\n                del deferred[label]\n                unknown = False\n            except KeyError:\n##                traceback.print_last()      # XXX DEBUG\n                pass\n            aProcess = self.system.get_process(pid)\n            try:\n                address = aProcess.resolve_label(label)\n                if not address:\n                    raise Exception()\n            except Exception:\n##                traceback.print_last()      # XXX DEBUG\n                if unknown:\n                    msg = (\"Can't clear unknown code breakpoint\"\n                           \" at %s in process ID %d\")\n                    msg = msg % (label, pid)\n                    warnings.warn(msg, BreakpointWarning)\n                return\n        if self.has_code_breakpoint(pid, address):\n            self.erase_code_breakpoint(pid, address)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nuse internally. Sets all deferred breakpoints for a DLL when it s loaded.", "response": "def __set_deferred_breakpoints(self, event):\n        \"\"\"\n        Used internally. Sets all deferred breakpoints for a DLL when it's\n        loaded.\n\n        @type  event: L{LoadDLLEvent}\n        @param event: Load DLL event.\n        \"\"\"\n        pid = event.get_pid()\n        try:\n            deferred = self.__deferredBP[pid]\n        except KeyError:\n            return\n        aProcess = event.get_process()\n        for (label, (action, oneshot)) in deferred.items():\n            try:\n                address = aProcess.resolve_label(label)\n            except Exception:\n                continue\n            del deferred[label]\n            try:\n                self.__set_break(pid, address, action, oneshot)\n            except Exception:\n                msg = \"Can't set deferred breakpoint %s at process ID %d\"\n                msg = msg % (label, pid)\n                warnings.warn(msg, BreakpointWarning)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_all_deferred_code_breakpoints(self):\n        result = []\n        for pid, deferred in compat.iteritems(self.__deferredBP):\n            for (label, (action, oneshot)) in compat.iteritems(deferred):\n                result.add( (pid, label, action, oneshot) )\n        return result", "response": "Returns a list of all deferred code breakpoints."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_process_deferred_code_breakpoints(self, dwProcessId):\n        return [ (label, action, oneshot)\n                  for (label, (action, oneshot))\n                  in compat.iteritems(self.__deferredBP.get(dwProcessId, {})) ]", "response": "Returns a list of deferred code breakpoints."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset a one shot code breakpoint at the given process and address.", "response": "def stalk_at(self, pid, address, action = None):\n        \"\"\"\n        Sets a one shot code breakpoint at the given process and address.\n\n        If instead of an address you pass a label, the breakpoint may be\n        deferred until the DLL it points to is loaded.\n\n        @see: L{break_at}, L{dont_stalk_at}\n\n        @type  pid: int\n        @param pid: Process global ID.\n\n        @type  address: int or str\n        @param address:\n            Memory address of code instruction to break at. It can be an\n            integer value for the actual address or a string with a label\n            to be resolved.\n\n        @type  action: function\n        @param action: (Optional) Action callback function.\n\n            See L{define_code_breakpoint} for more details.\n\n        @rtype:  bool\n        @return: C{True} if the breakpoint was set immediately, or C{False} if\n            it was deferred.\n        \"\"\"\n        bp = self.__set_break(pid, address, action, oneshot = True)\n        return bp is not None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef break_at(self, pid, address, action = None):\n        bp = self.__set_break(pid, address, action, oneshot = False)\n        return bp is not None", "response": "Sets a code breakpoint at the given process and address."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hook_function(self, pid, address,\n                      preCB = None, postCB = None,\n                      paramCount = None, signature = None):\n        \"\"\"\n        Sets a function hook at the given address.\n\n        If instead of an address you pass a label, the hook may be\n        deferred until the DLL it points to is loaded.\n\n        @type  pid: int\n        @param pid: Process global ID.\n\n        @type  address: int or str\n        @param address:\n            Memory address of code instruction to break at. It can be an\n            integer value for the actual address or a string with a label\n            to be resolved.\n\n        @type  preCB: function\n        @param preCB: (Optional) Callback triggered on function entry.\n\n            The signature for the callback should be something like this::\n\n                def pre_LoadLibraryEx(event, ra, lpFilename, hFile, dwFlags):\n\n                    # return address\n                    ra = params[0]\n\n                    # function arguments start from here...\n                    szFilename = event.get_process().peek_string(lpFilename)\n\n                    # (...)\n\n            Note that all pointer types are treated like void pointers, so your\n            callback won't get the string or structure pointed to by it, but\n            the remote memory address instead. This is so to prevent the ctypes\n            library from being \"too helpful\" and trying to dereference the\n            pointer. To get the actual data being pointed to, use one of the\n            L{Process.read} methods.\n\n        @type  postCB: function\n        @param postCB: (Optional) Callback triggered on function exit.\n\n            The signature for the callback should be something like this::\n\n                def post_LoadLibraryEx(event, return_value):\n\n                    # (...)\n\n        @type  paramCount: int\n        @param paramCount:\n            (Optional) Number of parameters for the C{preCB} callback,\n            not counting the return address. Parameters are read from\n            the stack and assumed to be DWORDs in 32 bits and QWORDs in 64.\n\n            This is a faster way to pull stack parameters in 32 bits, but in 64\n            bits (or with some odd APIs in 32 bits) it won't be useful, since\n            not all arguments to the hooked function will be of the same size.\n\n            For a more reliable and cross-platform way of hooking use the\n            C{signature} argument instead.\n\n        @type  signature: tuple\n        @param signature:\n            (Optional) Tuple of C{ctypes} data types that constitute the\n            hooked function signature. When the function is called, this will\n            be used to parse the arguments from the stack. Overrides the\n            C{paramCount} argument.\n\n        @rtype:  bool\n        @return: C{True} if the hook was set immediately, or C{False} if\n            it was deferred.\n        \"\"\"\n        try:\n            aProcess = self.system.get_process(pid)\n        except KeyError:\n            aProcess = Process(pid)\n        arch = aProcess.get_arch()\n        hookObj = Hook(preCB, postCB, paramCount, signature, arch)\n        bp = self.break_at(pid, address, hookObj)\n        return bp is not None", "response": "Sets a function hook at the given address."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the watch for a variable in a thread.", "response": "def __set_variable_watch(self, tid, address, size, action):\n        \"\"\"\n        Used by L{watch_variable} and L{stalk_variable}.\n\n        @type  tid: int\n        @param tid: Thread global ID.\n\n        @type  address: int\n        @param address: Memory address of variable to watch.\n\n        @type  size: int\n        @param size: Size of variable to watch. The only supported sizes are:\n            byte (1), word (2), dword (4) and qword (8).\n\n        @type  action: function\n        @param action: (Optional) Action callback function.\n\n            See L{define_hardware_breakpoint} for more details.\n\n        @rtype:  L{HardwareBreakpoint}\n        @return: Hardware breakpoint at the requested address.\n        \"\"\"\n\n        # TODO\n        # We should merge the breakpoints instead of overwriting them.\n        # We'll have the same problem as watch_buffer and we'll need to change\n        # the API again.\n\n        if size == 1:\n            sizeFlag = self.BP_WATCH_BYTE\n        elif size == 2:\n            sizeFlag = self.BP_WATCH_WORD\n        elif size == 4:\n            sizeFlag = self.BP_WATCH_DWORD\n        elif size == 8:\n            sizeFlag = self.BP_WATCH_QWORD\n        else:\n            raise ValueError(\"Bad size for variable watch: %r\" % size)\n\n        if self.has_hardware_breakpoint(tid, address):\n            warnings.warn(\n                \"Hardware breakpoint in thread %d at address %s was overwritten!\" \\\n                % (tid, HexDump.address(address,\n                                   self.system.get_thread(tid).get_bits())),\n                BreakpointWarning)\n\n            bp = self.get_hardware_breakpoint(tid, address)\n            if  bp.get_trigger() != self.BP_BREAK_ON_ACCESS or \\\n                bp.get_watch()   != sizeFlag:\n                    self.erase_hardware_breakpoint(tid, address)\n                    self.define_hardware_breakpoint(tid, address,\n                               self.BP_BREAK_ON_ACCESS, sizeFlag, True, action)\n                    bp = self.get_hardware_breakpoint(tid, address)\n\n        else:\n            self.define_hardware_breakpoint(tid, address,\n                               self.BP_BREAK_ON_ACCESS, sizeFlag, True, action)\n            bp = self.get_hardware_breakpoint(tid, address)\n\n        return bp"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __clear_variable_watch(self, tid, address):\n        if self.has_hardware_breakpoint(tid, address):\n            self.erase_hardware_breakpoint(tid, address)", "response": "Clear the watch for the given thread s variable."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef watch_variable(self, tid, address, size, action = None):\n        bp = self.__set_variable_watch(tid, address, size, action)\n        if not bp.is_enabled():\n            self.enable_hardware_breakpoint(tid, address)", "response": "Sets a hardware breakpoint at the given thread address and size."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset a one - shot hardware breakpoint at the given thread address and size.", "response": "def stalk_variable(self, tid, address, size, action = None):\n        \"\"\"\n        Sets a one-shot hardware breakpoint at the given thread,\n        address and size.\n\n        @see: L{dont_watch_variable}\n\n        @type  tid: int\n        @param tid: Thread global ID.\n\n        @type  address: int\n        @param address: Memory address of variable to watch.\n\n        @type  size: int\n        @param size: Size of variable to watch. The only supported sizes are:\n            byte (1), word (2), dword (4) and qword (8).\n\n        @type  action: function\n        @param action: (Optional) Action callback function.\n\n            See L{define_hardware_breakpoint} for more details.\n        \"\"\"\n        bp = self.__set_variable_watch(tid, address, size, action)\n        if not bp.is_one_shot():\n            self.enable_one_shot_hardware_breakpoint(tid, address)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __set_buffer_watch(self, pid, address, size, action, bOneShot):\n\n        # Check the size isn't zero or negative.\n        if size < 1:\n            raise ValueError(\"Bad size for buffer watch: %r\" % size)\n\n        # Create the buffer watch identifier.\n        bw = BufferWatch(pid, address, address + size, action, bOneShot)\n\n        # Get the base address and size in pages required for this buffer.\n        base  = MemoryAddresses.align_address_to_page_start(address)\n        limit = MemoryAddresses.align_address_to_page_end(address + size)\n        pages = MemoryAddresses.get_buffer_size_in_pages(address, size)\n\n        try:\n\n            # For each page:\n            #  + if a page breakpoint exists reuse it\n            #  + if it doesn't exist define it\n\n            bset = set()     # all breakpoints used\n            nset = set()     # newly defined breakpoints\n            cset = set()     # condition objects\n\n            page_addr = base\n            pageSize  = MemoryAddresses.pageSize\n            while page_addr < limit:\n\n                # If a breakpoints exists, reuse it.\n                if self.has_page_breakpoint(pid, page_addr):\n                    bp = self.get_page_breakpoint(pid, page_addr)\n                    if bp not in bset:\n                        condition = bp.get_condition()\n                        if not condition in cset:\n                            if not isinstance(condition,_BufferWatchCondition):\n                                # this shouldn't happen unless you tinkered\n                                # with it or defined your own page breakpoints\n                                # manually.\n                                msg = \"Can't watch buffer at page %s\"\n                                msg = msg % HexDump.address(page_addr)\n                                raise RuntimeError(msg)\n                            cset.add(condition)\n                        bset.add(bp)\n\n                # If it doesn't, define it.\n                else:\n                    condition = _BufferWatchCondition()\n                    bp = self.define_page_breakpoint(pid, page_addr, 1,\n                                                     condition = condition)\n                    bset.add(bp)\n                    nset.add(bp)\n                    cset.add(condition)\n\n                # Next page.\n                page_addr = page_addr + pageSize\n\n            # For each breakpoint, enable it if needed.\n            aProcess = self.system.get_process(pid)\n            for bp in bset:\n                if bp.is_disabled() or bp.is_one_shot():\n                    bp.enable(aProcess, None)\n\n        # On error...\n        except:\n\n            # Erase the newly defined breakpoints.\n            for bp in nset:\n                try:\n                    self.erase_page_breakpoint(pid, bp.get_address())\n                except:\n                    pass\n\n            # Pass the exception to the caller\n            raise\n\n        # For each condition object, add the new buffer.\n        for condition in cset:\n            condition.add(bw)", "response": "Set the buffer watch identifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclear the buffer watch condition.", "response": "def __clear_buffer_watch_old_method(self, pid, address, size):\n        \"\"\"\n        Used by L{dont_watch_buffer} and L{dont_stalk_buffer}.\n\n        @warn: Deprecated since WinAppDbg 1.5.\n\n        @type  pid: int\n        @param pid: Process global ID.\n\n        @type  address: int\n        @param address: Memory address of buffer to stop watching.\n\n        @type  size: int\n        @param size: Size in bytes of buffer to stop watching.\n        \"\"\"\n        warnings.warn(\"Deprecated since WinAppDbg 1.5\", DeprecationWarning)\n\n        # Check the size isn't zero or negative.\n        if size < 1:\n            raise ValueError(\"Bad size for buffer watch: %r\" % size)\n\n        # Get the base address and size in pages required for this buffer.\n        base  = MemoryAddresses.align_address_to_page_start(address)\n        limit = MemoryAddresses.align_address_to_page_end(address + size)\n        pages = MemoryAddresses.get_buffer_size_in_pages(address, size)\n\n        # For each page, get the breakpoint and it's condition object.\n        # For each condition, remove the buffer.\n        # For each breakpoint, if no buffers are on watch, erase it.\n        cset = set()     # condition objects\n        page_addr = base\n        pageSize = MemoryAddresses.pageSize\n        while page_addr < limit:\n            if self.has_page_breakpoint(pid, page_addr):\n                bp = self.get_page_breakpoint(pid, page_addr)\n                condition = bp.get_condition()\n                if condition not in cset:\n                    if not isinstance(condition, _BufferWatchCondition):\n                        # this shouldn't happen unless you tinkered with it\n                        # or defined your own page breakpoints manually.\n                        continue\n                    cset.add(condition)\n                    condition.remove_last_match(address, size)\n                    if condition.count() == 0:\n                        try:\n                            self.erase_page_breakpoint(pid, bp.get_address())\n                        except WindowsError:\n                            pass\n            page_addr = page_addr + pageSize"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __clear_buffer_watch(self, bw):\n\n        # Get the PID and the start and end addresses of the buffer.\n        pid   = bw.pid\n        start = bw.start\n        end   = bw.end\n\n        # Get the base address and size in pages required for the buffer.\n        base  = MemoryAddresses.align_address_to_page_start(start)\n        limit = MemoryAddresses.align_address_to_page_end(end)\n        pages = MemoryAddresses.get_buffer_size_in_pages(start, end - start)\n\n        # For each page, get the breakpoint and it's condition object.\n        # For each condition, remove the buffer.\n        # For each breakpoint, if no buffers are on watch, erase it.\n        cset = set()     # condition objects\n        page_addr = base\n        pageSize = MemoryAddresses.pageSize\n        while page_addr < limit:\n            if self.has_page_breakpoint(pid, page_addr):\n                bp = self.get_page_breakpoint(pid, page_addr)\n                condition = bp.get_condition()\n                if condition not in cset:\n                    if not isinstance(condition, _BufferWatchCondition):\n                        # this shouldn't happen unless you tinkered with it\n                        # or defined your own page breakpoints manually.\n                        continue\n                    cset.add(condition)\n                    condition.remove(bw)\n                    if condition.count() == 0:\n                        try:\n                            self.erase_page_breakpoint(pid, bp.get_address())\n                        except WindowsError:\n                            msg = \"Cannot remove page breakpoint at address %s\"\n                            msg = msg % HexDump.address( bp.get_address() )\n                            warnings.warn(msg, BreakpointWarning)\n            page_addr = page_addr + pageSize", "response": "Clear the buffer watch condition."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef watch_buffer(self, pid, address, size, action = None):\n        self.__set_buffer_watch(pid, address, size, action, False)", "response": "Sets a page breakpoint and notifies when the given buffer is accessed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset a one - shot page breakpoint and notifies when the given buffer is accessed.", "response": "def stalk_buffer(self, pid, address, size, action = None):\n        \"\"\"\n        Sets a one-shot page breakpoint and notifies\n        when the given buffer is accessed.\n\n        @see: L{dont_watch_variable}\n\n        @type  pid: int\n        @param pid: Process global ID.\n\n        @type  address: int\n        @param address: Memory address of buffer to watch.\n\n        @type  size: int\n        @param size: Size in bytes of buffer to watch.\n\n        @type  action: function\n        @param action: (Optional) Action callback function.\n\n            See L{define_page_breakpoint} for more details.\n\n        @rtype:  L{BufferWatch}\n        @return: Buffer watch identifier.\n        \"\"\"\n        self.__set_buffer_watch(pid, address, size, action, True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dont_watch_buffer(self, bw, *argv, **argd):\n\n        # The sane way to do it.\n        if not (argv or argd):\n            self.__clear_buffer_watch(bw)\n\n        # Backwards compatibility with WinAppDbg 1.4.\n        else:\n            argv = list(argv)\n            argv.insert(0, bw)\n            if 'pid' in argd:\n                argv.insert(0, argd.pop('pid'))\n            if 'address' in argd:\n                argv.insert(1, argd.pop('address'))\n            if 'size' in argd:\n                argv.insert(2, argd.pop('size'))\n            if argd:\n                raise TypeError(\"Wrong arguments for dont_watch_buffer()\")\n            try:\n                pid, address, size = argv\n            except ValueError:\n                raise TypeError(\"Wrong arguments for dont_watch_buffer()\")\n            self.__clear_buffer_watch_old_method(pid, address, size)", "response": "Clear a page breakpoint set by L { watch_buffer. dont_watch_buffer"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dont_stalk_buffer(self, bw, *argv, **argd):\n        self.dont_watch_buffer(bw, *argv, **argd)", "response": "Called by the buffer manager to clear the page breakpoint set by the buffer manager."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstarting tracing mode in the given thread.", "response": "def start_tracing(self, tid):\n        \"\"\"\n        Start tracing mode in the given thread.\n\n        @type  tid: int\n        @param tid: Global ID of thread to start tracing.\n        \"\"\"\n        if not self.is_tracing(tid):\n            thread = self.system.get_thread(tid)\n            self.__start_tracing(thread)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstopping tracing mode in the given thread.", "response": "def stop_tracing(self, tid):\n        \"\"\"\n        Stop tracing mode in the given thread.\n\n        @type  tid: int\n        @param tid: Global ID of thread to stop tracing.\n        \"\"\"\n        if self.is_tracing(tid):\n            thread = self.system.get_thread(tid)\n            self.__stop_tracing(thread)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstarting tracing mode for all threads in the given process.", "response": "def start_tracing_process(self, pid):\n        \"\"\"\n        Start tracing mode for all threads in the given process.\n\n        @type  pid: int\n        @param pid: Global ID of process to start tracing.\n        \"\"\"\n        for thread in self.system.get_process(pid).iter_threads():\n            self.__start_tracing(thread)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stop_tracing_process(self, pid):\n        for thread in self.system.get_process(pid).iter_threads():\n            self.__stop_tracing(thread)", "response": "Stop tracing mode for all threads in the given process."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset or clears the system breakpoint for a given Win32 error code.", "response": "def break_on_error(self, pid, errorCode):\n        \"\"\"\n        Sets or clears the system breakpoint for a given Win32 error code.\n\n        Use L{Process.is_system_defined_breakpoint} to tell if a breakpoint\n        exception was caused by a system breakpoint or by the application\n        itself (for example because of a failed assertion in the code).\n\n        @note: This functionality is only available since Windows Server 2003.\n            In 2003 it only breaks on error values set externally to the\n            kernel32.dll library, but this was fixed in Windows Vista.\n\n        @warn: This method will fail if the debug symbols for ntdll (kernel32\n            in Windows 2003) are not present. For more information see:\n            L{System.fix_symbol_store_path}.\n\n        @see: U{http://www.nynaeve.net/?p=147}\n\n        @type  pid: int\n        @param pid: Process ID.\n\n        @type  errorCode: int\n        @param errorCode: Win32 error code to stop on. Set to C{0} or\n            C{ERROR_SUCCESS} to clear the breakpoint instead.\n\n        @raise NotImplementedError:\n            The functionality is not supported in this system.\n\n        @raise WindowsError:\n            An error occurred while processing this request.\n        \"\"\"\n        aProcess = self.system.get_process(pid)\n        address  = aProcess.get_break_on_error_ptr()\n        if not address:\n            raise NotImplementedError(\n                        \"The functionality is not supported in this system.\")\n        aProcess.write_dword(address, errorCode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef resolve_exported_function(self, pid, modName, procName):\n        aProcess = self.system.get_process(pid)\n        aModule = aProcess.get_module_by_name(modName)\n        if not aModule:\n            aProcess.scan_modules()\n            aModule = aProcess.get_module_by_name(modName)\n        if aModule:\n            address = aModule.resolve(procName)\n            return address\n        return None", "response": "Resolves the exported DLL function for the given process."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_net_command(self, py_db, cmd_id, seq, text):\n        '''Processes a command received from the Java side\n\n        @param cmd_id: the id of the command\n        @param seq: the sequence of the command\n        @param text: the text received in the command\n        '''\n        meaning = ID_TO_MEANING[str(cmd_id)]\n\n        # print('Handling %s (%s)' % (meaning, text))\n\n        method_name = meaning.lower()\n\n        on_command = getattr(self, method_name.lower(), None)\n        if on_command is None:\n            # I have no idea what this is all about\n            cmd = py_db.cmd_factory.make_error_message(seq, \"unexpected command \" + str(cmd_id))\n            py_db.writer.add_command(cmd)\n            return\n\n        py_db._main_lock.acquire()\n        try:\n            cmd = on_command(py_db, cmd_id, seq, text)\n            if cmd is not None:\n                py_db.writer.add_command(cmd)\n        except:\n            if traceback is not None and sys is not None and pydev_log_exception is not None:\n                pydev_log_exception()\n\n                stream = StringIO()\n                traceback.print_exc(file=stream)\n                cmd = py_db.cmd_factory.make_error_message(\n                    seq,\n                    \"Unexpected exception in process_net_command.\\nInitial params: %s. Exception: %s\" % (\n                        ((cmd_id, seq, text), stream.getvalue())\n                    )\n                )\n                if cmd is not None:\n                    py_db.writer.add_command(cmd)\n\n        finally:\n            py_db._main_lock.release()", "response": "Processes a command received from the Java side."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompile self. PATTERN into self. pattern.", "response": "def compile_pattern(self):\n        \"\"\"Compiles self.PATTERN into self.pattern.\n\n        Subclass may override if it doesn't want to use\n        self.{pattern,PATTERN} in .match().\n        \"\"\"\n        if self.PATTERN is not None:\n            PC = PatternCompiler()\n            self.pattern, self.pattern_tree = PC.compile_pattern(self.PATTERN,\n                                                                 with_tree=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the filename and a logger derived from it.", "response": "def set_filename(self, filename):\n        \"\"\"Set the filename, and a logger derived from it.\n\n        The main refactoring tool should call this.\n        \"\"\"\n        self.filename = filename\n        self.logger = logging.getLogger(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef match(self, node):\n        results = {\"node\": node}\n        return self.pattern.match(node, results) and results", "response": "Returns a match for a given parse tree node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a string suitable for use as an identifier.", "response": "def new_name(self, template=u\"xxx_todo_changeme\"):\n        \"\"\"Return a string suitable for use as an identifier\n\n        The new name is guaranteed not to conflict with other identifiers.\n        \"\"\"\n        name = template\n        while name in self.used_names:\n            name = template + unicode(self.numbers.next())\n        self.used_names.add(name)\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwarning the user that a given chunk of code is not valid Python 3 and that it cannot be converted automatically.", "response": "def cannot_convert(self, node, reason=None):\n        \"\"\"Warn the user that a given chunk of code is not valid Python 3,\n        but that it cannot be converted automatically.\n\n        First argument is the top-level node for the code in question.\n        Optional second argument is why it can't be converted.\n        \"\"\"\n        lineno = node.get_lineno()\n        for_output = node.clone()\n        for_output.prefix = u\"\"\n        msg = \"Line %d: could not convert: %s\"\n        self.log_message(msg % (lineno, for_output))\n        if reason:\n            self.log_message(reason)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef warning(self, node, reason):\n        lineno = node.get_lineno()\n        self.log_message(\"Line %d: %s\" % (lineno, reason))", "response": "Used for warning the user about possible uncertainty in the translation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start_tree(self, tree, filename):\n        self.used_names = tree.used_names\n        self.set_filename(filename)\n        self.numbers = itertools.count(1)\n        self.first_log = True", "response": "This method is called once at the start of the tree fix - up."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_help(self, arg):\n        if not arg:\n            Cmd.do_help(self, arg)\n        elif arg in ('?', 'help'):\n            # An easter egg :)\n            print(\"  Help! I need somebody...\")\n            print(\"  Help! Not just anybody...\")\n            print(\"  Help! You know, I need someone...\")\n            print(\"  Heeelp!\")\n        else:\n            if arg == '*':\n                commands = self.get_names()\n                commands = [ x for x in commands if x.startswith('do_') ]\n            else:\n                commands = set()\n                for x in arg.split(' '):\n                    x = x.strip()\n                    if x:\n                        for n in self.completenames(x):\n                            commands.add( 'do_%s' % n )\n                commands = list(commands)\n                commands.sort()\n            print(self.get_help(commands))", "response": "Show help for the given command"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes a single shell command", "response": "def do_shell(self, arg):\n        \"\"\"\n        ! - spawn a system shell\n        shell - spawn a system shell\n        ! <command> [arguments...] - execute a single shell command\n        shell <command> [arguments...] - execute a single shell command\n        \"\"\"\n        if self.cmdprefix:\n            raise CmdError(\"prefix not allowed\")\n\n        # Try to use the environment to locate cmd.exe.\n        # If not found, it's usually OK to just use the filename,\n        # since cmd.exe is one of those \"magic\" programs that\n        # can be automatically found by CreateProcess.\n        shell = os.getenv('ComSpec', 'cmd.exe')\n\n        # When given a command, run it and return.\n        # When no command is given, spawn a shell.\n        if arg:\n            arg = '%s /c %s' % (shell, arg)\n        else:\n            arg = shell\n        process = self.debug.system.start_process(arg, bConsole = True)\n        process.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_python(self, arg):\n        if self.cmdprefix:\n            raise CmdError(\"prefix not allowed\")\n\n        # When given a Python statement, execute it directly.\n        if arg:\n            try:\n                compat.exec_(arg, globals(), locals())\n            except Exception:\n                traceback.print_exc()\n\n        # When no statement is given, spawn a Python interpreter.\n        else:\n            try:\n                self._spawn_python_shell(arg)\n            except Exception:\n                e = sys.exc_info()[1]\n                raise CmdError(\n                    \"unhandled exception when running Python console: %s\" % e)", "response": "Execute a Python statement and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_plugin(self, arg):\n        pos = arg.find(' ')\n        if pos < 0:\n            name = arg\n            arg  = ''\n        else:\n            name = arg[:pos]\n            arg  = arg[pos:].strip()\n        if not name:\n            raise CmdError(\"missing plugin name\")\n        for c in name:\n            if c not in self.valid_plugin_name_chars:\n                raise CmdError(\"invalid plugin name: %r\" % name)\n        name = 'winappdbg.plugins.do_%s' % name\n        try:\n            plugin = __import__(name)\n            components = name.split('.')\n            for comp in components[1:]:\n                plugin = getattr(plugin, comp)\n                reload(plugin)\n        except ImportError:\n            raise CmdError(\"plugin not found: %s\" % name)\n        try:\n            return plugin.do(self, arg)\n        except CmdError:\n            raise\n        except Exception:\n            e = sys.exc_info()[1]\n##            traceback.print_exc(e)      # XXX DEBUG\n            raise CmdError(\"unhandled exception in plugin: %s\" % e)", "response": "run a plugin command"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_quit(self, arg):\n        if self.cmdprefix:\n            raise CmdError(\"prefix not allowed\")\n        if arg:\n            raise CmdError(\"too many arguments\")\n        if self.confirm_quit:\n            count = self.debug.get_debugee_count()\n            if count > 0:\n                if count == 1:\n                    msg = \"There's a program still running.\"\n                else:\n                    msg = \"There are %s programs still running.\" % count\n                if not self.ask_user(msg):\n                    return False\n        self.debuggerExit = True\n        return True", "response": "quit - quit the debugging session"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nattaches to a process", "response": "def do_attach(self, arg):\n        \"\"\"\n        attach <target> [target...] - attach to the given process(es)\n        \"\"\"\n        if self.cmdprefix:\n            raise CmdError(\"prefix not allowed\")\n        targets = self.input_process_list( self.split_tokens(arg, 1) )\n        if not targets:\n            print(\"Error: missing parameters\")\n        else:\n            debug = self.debug\n            for pid in targets:\n                try:\n                    debug.attach(pid)\n                    print(\"Attached to process (%d)\" % pid)\n                except Exception:\n                    print(\"Error: can't attach to process (%d)\" % pid)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndetaching from the current process", "response": "def do_detach(self, arg):\n        \"\"\"\n        [~process] detach - detach from the current process\n        detach - detach from the current process\n        detach <target> [target...] - detach from the given process(es)\n        \"\"\"\n        debug   = self.debug\n        token_list = self.split_tokens(arg)\n        if self.cmdprefix:\n            token_list.insert(0, self.cmdprefix)\n        targets = self.input_process_list(token_list)\n        if not targets:\n            if self.lastEvent is None:\n                raise CmdError(\"no current process set\")\n            targets = [ self.lastEvent.get_pid() ]\n        for pid in targets:\n            try:\n                debug.detach(pid)\n                print(\"Detached from process (%d)\" % pid)\n            except Exception:\n                print(\"Error: can't detach from process (%d)\" % pid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns a windowed command", "response": "def do_windowed(self, arg):\n        \"\"\"\n        windowed <target> [arguments...] - run a windowed program for debugging\n        \"\"\"\n        if self.cmdprefix:\n            raise CmdError(\"prefix not allowed\")\n        cmdline = self.input_command_line(arg)\n        try:\n            process = self.debug.execl(arg,\n                                                bConsole = False,\n                                                 bFollow = self.options.follow)\n            print(\"Spawned process (%d)\" % process.get_pid())\n        except Exception:\n            raise CmdError(\"can't execute\")\n        self.set_fake_last_event(process)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_continue(self, arg):\n        if self.cmdprefix:\n            raise CmdError(\"prefix not allowed\")\n        if arg:\n            raise CmdError(\"too many arguments\")\n        if self.debug.get_debugee_count() > 0:\n            return True", "response": "continue - continue execution"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_gn(self, arg):\n        if self.cmdprefix:\n            raise CmdError(\"prefix not allowed\")\n        if arg:\n            raise CmdError(\"too many arguments\")\n        if self.lastEvent:\n            self.lastEvent.continueStatus = win32.DBG_EXCEPTION_NOT_HANDLED\n        return self.do_go(arg)", "response": "gn - go with exception not handled\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_refresh(self, arg):\n        if arg:\n            raise CmdError(\"too many arguments\")\n        if self.cmdprefix:\n            process = self.get_process_from_prefix()\n            process.scan()\n        else:\n            self.debug.system.scan()", "response": "refresh - refresh the list of running processes and threads"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshowing the processes being debugged", "response": "def do_processlist(self, arg):\n        \"\"\"\n        pl - show the processes being debugged\n        processlist - show the processes being debugged\n        \"\"\"\n        if self.cmdprefix:\n            raise CmdError(\"prefix not allowed\")\n        if arg:\n            raise CmdError(\"too many arguments\")\n        system   = self.debug.system\n        pid_list = self.debug.get_debugee_pids()\n        if pid_list:\n            print(\"Process ID   File name\")\n            for pid in pid_list:\n                if   pid == 0:\n                    filename = \"System Idle Process\"\n                elif pid == 4:\n                    filename = \"System\"\n                else:\n                    filename = system.get_process(pid).get_filename()\n                    filename = PathOperations.pathname_to_filename(filename)\n                print(\"%-12d %s\" % (pid, filename))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nshow the threads being debugged", "response": "def do_threadlist(self, arg):\n        \"\"\"\n        tl - show the threads being debugged\n        threadlist - show the threads being debugged\n        \"\"\"\n        if arg:\n            raise CmdError(\"too many arguments\")\n        if self.cmdprefix:\n            process = self.get_process_from_prefix()\n            for thread in process.iter_threads():\n                tid  = thread.get_tid()\n                name = thread.get_name()\n                print(\"%-12d %s\" % (tid, name))\n        else:\n            system   = self.debug.system\n            pid_list = self.debug.get_debugee_pids()\n            if pid_list:\n                print(\"Thread ID    Thread name\")\n                for pid in pid_list:\n                    process = system.get_process(pid)\n                    for thread in process.iter_threads():\n                        tid  = thread.get_tid()\n                        name = thread.get_name()\n                        print(\"%-12d %s\" % (tid, name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nkills the processes and threads.", "response": "def do_kill(self, arg):\n        \"\"\"\n        [~process] kill - kill a process\n        [~thread] kill - kill a thread\n        kill - kill the current process\n        kill * - kill all debugged processes\n        kill <processes and/or threads...> - kill the given processes and threads\n        \"\"\"\n        if arg:\n            if arg == '*':\n                target_pids = self.debug.get_debugee_pids()\n                target_tids = list()\n            else:\n                target_pids = set()\n                target_tids = set()\n                if self.cmdprefix:\n                    pid, tid = self.get_process_and_thread_ids_from_prefix()\n                    if tid is None:\n                        target_tids.add(tid)\n                    else:\n                        target_pids.add(pid)\n                for token in self.split_tokens(arg):\n                    try:\n                        pid = self.input_process(token)\n                        target_pids.add(pid)\n                    except CmdError:\n                        try:\n                            tid = self.input_process(token)\n                            target_pids.add(pid)\n                        except CmdError:\n                            msg = \"unknown process or thread (%s)\" % token\n                            raise CmdError(msg)\n                target_pids = list(target_pids)\n                target_tids = list(target_tids)\n                target_pids.sort()\n                target_tids.sort()\n            msg = \"You are about to kill %d processes and %d threads.\"\n            msg = msg % ( len(target_pids), len(target_tids) )\n            if self.ask_user(msg):\n                for pid in target_pids:\n                    self.kill_process(pid)\n                for tid in target_tids:\n                    self.kill_thread(tid)\n        else:\n            if self.cmdprefix:\n                pid, tid = self.get_process_and_thread_ids_from_prefix()\n                if tid is None:\n                    if self.lastEvent is not None and pid == self.lastEvent.get_pid():\n                        msg = \"You are about to kill the current process.\"\n                    else:\n                        msg = \"You are about to kill process %d.\" % pid\n                    if self.ask_user(msg):\n                        self.kill_process(pid)\n                else:\n                    if self.lastEvent is not None and tid == self.lastEvent.get_tid():\n                        msg = \"You are about to kill the current thread.\"\n                    else:\n                        msg = \"You are about to kill thread %d.\" % tid\n                    if self.ask_user(msg):\n                        self.kill_thread(tid)\n            else:\n                if self.lastEvent is None:\n                    raise CmdError(\"no current process set\")\n                pid = self.lastEvent.get_pid()\n                if self.ask_user(\"You are about to kill the current process.\"):\n                    self.kill_process(pid)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_stack(self, arg):\n        if arg:     # XXX TODO add depth parameter\n            raise CmdError(\"too many arguments\")\n        pid, tid        = self.get_process_and_thread_ids_from_prefix()\n        process         = self.get_process(pid)\n        thread          = process.get_thread(tid)\n        try:\n            stack_trace = thread.get_stack_trace_with_labels()\n            if stack_trace:\n                print(CrashDump.dump_stack_trace_with_labels(stack_trace),)\n            else:\n                print(\"No stack trace available for thread (%d)\" % tid)\n        except WindowsError:\n            print(\"Can't get stack trace for thread (%d)\" % tid)", "response": "show the stack trace"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_break(self, arg):\n        debug   = self.debug\n        system  = debug.system\n        targets = self.input_process_list( self.split_tokens(arg) )\n        if not targets:\n            targets = debug.get_debugee_pids()\n            targets.sort()\n        if self.lastEvent:\n            current = self.lastEvent.get_pid()\n        else:\n            current = None\n        for pid in targets:\n            if pid != current and debug.is_debugee(pid):\n                process = system.get_process(pid)\n                try:\n                    process.debug_break()\n                except WindowsError:\n                    print(\"Can't force a debug break on process (%d)\")", "response": "Force a debug break in all debugees"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_step(self, arg):\n        if self.cmdprefix:\n            raise CmdError(\"prefix not allowed\")\n        if self.lastEvent is None:\n            raise CmdError(\"no current process set\")\n        if arg:     # XXX this check is to be removed\n            raise CmdError(\"too many arguments\")\n        pid     = self.lastEvent.get_pid()\n        thread  = self.lastEvent.get_thread()\n        pc      = thread.get_pc()\n        code    = thread.disassemble(pc, 16)[0]\n        size    = code[1]\n        opcode  = code[2].lower()\n        if ' ' in opcode:\n            opcode  = opcode[ : opcode.find(' ') ]\n        if opcode in self.jump_instructions or opcode in ('int', 'ret', 'retn'):\n            return self.do_trace(arg)\n        address = pc + size\n##        print(hex(pc), hex(address), size   # XXX DEBUG\n        self.debug.stalk_at(pid, address)\n        return True", "response": "do_step - do a single step of the current assembly instruction"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntracing at the current assembly", "response": "def do_trace(self, arg):\n        \"\"\"\n        t - trace at the current assembly instruction\n        trace - trace at the current assembly instruction\n        \"\"\"\n        if arg:     # XXX this check is to be removed\n            raise CmdError(\"too many arguments\")\n        if self.lastEvent is None:\n            raise CmdError(\"no current thread set\")\n        self.lastEvent.get_thread().set_tf()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting a code breakpoint at a specific address", "response": "def do_bp(self, arg):\n        \"\"\"\n        [~process] bp <address> - set a code breakpoint\n        \"\"\"\n        pid = self.get_process_id_from_prefix()\n        if not self.debug.is_debugee(pid):\n            raise CmdError(\"target process is not being debugged\")\n        process     = self.get_process(pid)\n        token_list  = self.split_tokens(arg, 1, 1)\n        try:\n            address = self.input_address(token_list[0], pid)\n            deferred = False\n        except Exception:\n            address = token_list[0]\n            deferred = True\n        if not address:\n            address = token_list[0]\n            deferred = True\n        self.debug.break_at(pid, address)\n        if deferred:\n            print(\"Deferred breakpoint set at %s\" % address)\n        else:\n            print(\"Breakpoint set at %s\" % address)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_ba(self, arg):\n        debug      = self.debug\n        thread     = self.get_thread_from_prefix()\n        pid        = thread.get_pid()\n        tid        = thread.get_tid()\n        if not debug.is_debugee(pid):\n            raise CmdError(\"target thread is not being debugged\")\n        token_list = self.split_tokens(arg, 3, 3)\n        access     = token_list[0].lower()\n        size       = token_list[1]\n        address    = token_list[2]\n        if   access == 'a':\n            access = debug.BP_BREAK_ON_ACCESS\n        elif access == 'w':\n            access = debug.BP_BREAK_ON_WRITE\n        elif access == 'e':\n            access = debug.BP_BREAK_ON_EXECUTION\n        else:\n            raise CmdError(\"bad access type: %s\" % token_list[0])\n        if   size == '1':\n            size = debug.BP_WATCH_BYTE\n        elif size == '2':\n            size = debug.BP_WATCH_WORD\n        elif size == '4':\n            size = debug.BP_WATCH_DWORD\n        elif size == '8':\n            size = debug.BP_WATCH_QWORD\n        else:\n            raise CmdError(\"bad breakpoint size: %s\" % size)\n        thread  = self.get_thread_from_prefix()\n        tid     = thread.get_tid()\n        pid     = thread.get_pid()\n        if not debug.is_debugee(pid):\n            raise CmdError(\"target process is not being debugged\")\n        address = self.input_address(address, pid)\n        if debug.has_hardware_breakpoint(tid, address):\n            debug.erase_hardware_breakpoint(tid, address)\n        debug.define_hardware_breakpoint(tid, address, access, size)\n        debug.enable_hardware_breakpoint(tid, address)", "response": "\\ x1b [ 1mNAME \\ x1b [ 0m ba - Set hardware breakpoint"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling the bl command.", "response": "def do_bl(self, arg):\n        \"\"\"\n        bl - list the breakpoints for the current process\n        bl * - list the breakpoints for all processes\n        [~process] bl - list the breakpoints for the given process\n        bl <process> [process...] - list the breakpoints for each given process\n        \"\"\"\n        debug = self.debug\n        if arg == '*':\n            if self.cmdprefix:\n                raise CmdError(\"prefix not supported\")\n            breakpoints = debug.get_debugee_pids()\n        else:\n            targets = self.input_process_list( self.split_tokens(arg) )\n            if self.cmdprefix:\n                targets.insert(0, self.input_process(self.cmdprefix))\n            if not targets:\n                if self.lastEvent is None:\n                    raise CmdError(\"no current process is set\")\n                targets = [ self.lastEvent.get_pid() ]\n        for pid in targets:\n            bplist = debug.get_process_code_breakpoints(pid)\n            printed_process_banner = False\n            if bplist:\n                if not printed_process_banner:\n                    print(\"Process %d:\" % pid)\n                    printed_process_banner = True\n                for bp in bplist:\n                    address = repr(bp)[1:-1].replace('remote address ','')\n                    print(\"  %s\" % address)\n            dbplist = debug.get_process_deferred_code_breakpoints(pid)\n            if dbplist:\n                if not printed_process_banner:\n                    print(\"Process %d:\" % pid)\n                    printed_process_banner = True\n                for (label, action, oneshot) in dbplist:\n                    if oneshot:\n                        address = \"  Deferred unconditional one-shot\" \\\n                              \" code breakpoint at %s\"\n                    else:\n                        address = \"  Deferred unconditional\" \\\n                              \" code breakpoint at %s\"\n                    address = address % label\n                    print(\"  %s\" % address)\n            bplist = debug.get_process_page_breakpoints(pid)\n            if bplist:\n                if not printed_process_banner:\n                    print(\"Process %d:\" % pid)\n                    printed_process_banner = True\n                for bp in bplist:\n                    address = repr(bp)[1:-1].replace('remote address ','')\n                    print(\"  %s\" % address)\n            for tid in debug.system.get_process(pid).iter_thread_ids():\n                bplist = debug.get_thread_hardware_breakpoints(tid)\n                if bplist:\n                    print(\"Thread %d:\" % tid)\n                    for bp in bplist:\n                        address = repr(bp)[1:-1].replace('remote address ','')\n                        print(\"  %s\" % address)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_be(self, arg):\n        token_list = self.split_tokens(arg, 1, 2)\n        pid, tid, address, size = self.input_breakpoint(token_list)\n        debug = self.debug\n        found = False\n        if size is None:\n            if tid is not None:\n                if debug.has_hardware_breakpoint(tid, address):\n                    debug.enable_hardware_breakpoint(tid, address)\n                    found = True\n            if pid is not None:\n                if debug.has_code_breakpoint(pid, address):\n                    debug.enable_code_breakpoint(pid, address)\n                    found = True\n        else:\n            if debug.has_page_breakpoint(pid, address):\n                debug.enable_page_breakpoint(pid, address)\n                found = True\n        if not found:\n            print(\"Error: breakpoint not found.\")", "response": "Enable a code breakpoint."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_disassemble(self, arg):\n        if not arg:\n            arg = self.default_disasm_target\n        token_list      = self.split_tokens(arg, 1, 1)\n        pid, tid        = self.get_process_and_thread_ids_from_prefix()\n        process         = self.get_process(pid)\n        address         = self.input_address(token_list[0], pid, tid)\n        try:\n            code = process.disassemble(address, 15*8)[:8]\n        except Exception:\n            msg = \"can't disassemble address %s\"\n            msg = msg % HexDump.address(address)\n            raise CmdError(msg)\n        if code:\n            label        = process.get_label_at_address(address)\n            last_code    = code[-1]\n            next_address = last_code[0] + last_code[1]\n            next_address = HexOutput.integer(next_address)\n            self.default_disasm_target = next_address\n            print(\"%s:\" % label)\n##            print(CrashDump.dump_code(code))\n            for line in code:\n                print(CrashDump.dump_code_line(line, bShowDump = False))", "response": "disassemble a single object from the memory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_search(self, arg):\n        token_list = self.split_tokens(arg, 1, 3)\n        pid, tid   = self.get_process_and_thread_ids_from_prefix()\n        process    = self.get_process(pid)\n        if len(token_list) == 1:\n            pattern = token_list[0]\n            minAddr = None\n            maxAddr = None\n        else:\n            pattern = token_list[-1]\n            addr, size = self.input_address_range(token_list[:-1], pid, tid)\n            minAddr = addr\n            maxAddr = addr + size\n        iter = process.search_bytes(pattern)\n        if process.get_bits() == 32:\n            addr_width = 8\n        else:\n            addr_width = 16\n        # TODO: need a prettier output here!\n        for addr in iter:\n            print(HexDump.address(addr, addr_width))", "response": "\\ x1b [ 1mNAME \\ x1b [ 0m search - Searches for the log entry."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_db(self, arg):\n        self.print_memory_display(arg, HexDump.hexblock)\n        self.last_display_command = self.do_db", "response": "show the current memory contents as bytes\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_dw(self, arg):\n        self.print_memory_display(arg, HexDump.hexblock_word)\n        self.last_display_command = self.do_dw", "response": "display the contents of the memory contents of the current process"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshowing the contents of the available memory entries as dwords", "response": "def do_dd(self, arg):\n        \"\"\"\n        [~thread] dd <register> - show memory contents as dwords\n        [~thread] dd <register-register> - show memory contents as dwords\n        [~thread] dd <register> <size> - show memory contents as dwords\n        [~process] dd <address> - show memory contents as dwords\n        [~process] dd <address-address> - show memory contents as dwords\n        [~process] dd <address> <size> - show memory contents as dwords\n        \"\"\"\n        self.print_memory_display(arg, HexDump.hexblock_dword)\n        self.last_display_command = self.do_dd"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshow the contents of the set of memory contents as qwords", "response": "def do_dq(self, arg):\n        \"\"\"\n        [~thread] dq <register> - show memory contents as qwords\n        [~thread] dq <register-register> - show memory contents as qwords\n        [~thread] dq <register> <size> - show memory contents as qwords\n        [~process] dq <address> - show memory contents as qwords\n        [~process] dq <address-address> - show memory contents as qwords\n        [~process] dq <address> <size> - show memory contents as qwords\n        \"\"\"\n        self.print_memory_display(arg, HexDump.hexblock_qword)\n        self.last_display_command = self.do_dq"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_du(self, arg):\n        if not arg:\n            arg = self.default_display_target\n        token_list              = self.split_tokens(arg, 1, 2)\n        pid, tid, address, size = self.input_display(token_list, 256)\n        process                 = self.get_process(pid)\n        data                    = process.peek_string(address, True, size)\n        if data:\n            print(repr(data))\n        self.last_display_command = self.do_du", "response": "do_du - show memory contents as Unicode string"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_eb(self, arg):\n        # TODO\n        # data parameter should be optional, use a child Cmd here\n        pid        = self.get_process_id_from_prefix()\n        token_list = self.split_tokens(arg, 2)\n        address    = self.input_address(token_list[0], pid)\n        data       = HexInput.hexadecimal(' '.join(token_list[1:]))\n        self.write_memory(address, data, pid)", "response": "eb <address > data - write the data to the specified address"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshow the memory information for the current process", "response": "def do_memory(self, arg):\n        \"\"\"\n        [~process] m - show the process memory map\n        [~process] memory - show the process memory map\n        \"\"\"\n        if arg:     # TODO: take min and max addresses\n            raise CmdError(\"too many arguments\")\n        process = self.get_process_from_prefix()\n        try:\n            memoryMap       = process.get_memory_map()\n            mappedFilenames = process.get_mapped_filenames()\n            print('')\n            print(CrashDump.dump_memory_map(memoryMap, mappedFilenames))\n        except WindowsError:\n            msg = \"can't get memory information for process (%d)\"\n            raise CmdError(msg % process.get_pid())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search_process(process, pattern, minAddr = None,\n                                         maxAddr = None,\n                                         bufferPages = None,\n                                         overlapping = False):\n        \"\"\"\n        Search for the given pattern within the process memory.\n\n        @type  process: L{Process}\n        @param process: Process to search.\n\n        @type  pattern: L{Pattern}\n        @param pattern: Pattern to search for.\n            It must be an instance of a subclass of L{Pattern}.\n\n            The following L{Pattern} subclasses are provided by WinAppDbg:\n             - L{BytePattern}\n             - L{TextPattern}\n             - L{RegExpPattern}\n             - L{HexPattern}\n\n            You can also write your own subclass of L{Pattern} for customized\n            searches.\n\n        @type  minAddr: int\n        @param minAddr: (Optional) Start the search at this memory address.\n\n        @type  maxAddr: int\n        @param maxAddr: (Optional) Stop the search at this memory address.\n\n        @type  bufferPages: int\n        @param bufferPages: (Optional) Number of memory pages to buffer when\n            performing the search. Valid values are:\n             - C{0} or C{None}:\n               Automatically determine the required buffer size. May not give\n               complete results for regular expressions that match variable\n               sized strings.\n             - C{> 0}: Set the buffer size, in memory pages.\n             - C{< 0}: Disable buffering entirely. This may give you a little\n               speed gain at the cost of an increased memory usage. If the\n               target process has very large contiguous memory regions it may\n               actually be slower or even fail. It's also the only way to\n               guarantee complete results for regular expressions that match\n               variable sized strings.\n\n        @type  overlapping: bool\n        @param overlapping: C{True} to allow overlapping results, C{False}\n            otherwise.\n\n            Overlapping results yield the maximum possible number of results.\n\n            For example, if searching for \"AAAA\" within \"AAAAAAAA\" at address\n            C{0x10000}, when overlapping is turned off the following matches\n            are yielded::\n                (0x10000, 4, \"AAAA\")\n                (0x10004, 4, \"AAAA\")\n\n            If overlapping is turned on, the following matches are yielded::\n                (0x10000, 4, \"AAAA\")\n                (0x10001, 4, \"AAAA\")\n                (0x10002, 4, \"AAAA\")\n                (0x10003, 4, \"AAAA\")\n                (0x10004, 4, \"AAAA\")\n\n            As you can see, the middle results are overlapping the last two.\n\n        @rtype:  iterator of tuple( int, int, str )\n        @return: An iterator of tuples. Each tuple contains the following:\n             - The memory address where the pattern was found.\n             - The size of the data that matches the pattern.\n             - The data that matches the pattern.\n\n        @raise WindowsError: An error occurred when querying or reading the\n            process memory.\n        \"\"\"\n\n        # Do some namespace lookups of symbols we'll be using frequently.\n        MEM_COMMIT = win32.MEM_COMMIT\n        PAGE_GUARD = win32.PAGE_GUARD\n        page = MemoryAddresses.pageSize\n        read = pattern.read\n        find = pattern.find\n\n        # Calculate the address range.\n        if minAddr is None:\n            minAddr = 0\n        if maxAddr is None:\n            maxAddr = win32.LPVOID(-1).value  # XXX HACK\n\n        # Calculate the buffer size from the number of pages.\n        if bufferPages is None:\n            try:\n                size = MemoryAddresses.\\\n                            align_address_to_page_end(len(pattern)) + page\n            except NotImplementedError:\n                size = None\n        elif bufferPages > 0:\n                size = page * (bufferPages + 1)\n        else:\n                size = None\n\n        # Get the memory map of the process.\n        memory_map = process.iter_memory_map(minAddr, maxAddr)\n\n        # Perform search with buffering enabled.\n        if size:\n\n            # Loop through all memory blocks containing data.\n            buffer     = \"\" # buffer to hold the memory data\n            prev_addr  = 0  # previous memory block address\n            last       = 0  # position of the last match\n            delta      = 0  # delta of last read address and start of buffer\n            for mbi in memory_map:\n\n                # Skip blocks with no data to search on.\n                if not mbi.has_content():\n                    continue\n\n                # Get the address and size of this block.\n                address    = mbi.BaseAddress    # current address to search on\n                block_size = mbi.RegionSize     # total size of the block\n                if address >= maxAddr:\n                    break\n                end = address + block_size      # end address of the block\n\n                # If the block is contiguous to the previous block,\n                # coalesce the new data in the buffer.\n                if delta and address == prev_addr:\n                    buffer += read(process, address, page)\n\n                # If not, clear the buffer and read new data.\n                else:\n                    buffer = read(process, address, min(size, block_size))\n                    last   = 0\n                    delta  = 0\n\n                # Search for the pattern in this block.\n                while 1:\n\n                    # Yield each match of the pattern in the buffer.\n                    pos, length = find(buffer, last)\n                    while pos >= last:\n                        match_addr = address + pos - delta\n                        if minAddr <= match_addr < maxAddr:\n                            result = pattern.found(\n                                            match_addr, length,\n                                            buffer [ pos : pos + length ] )\n                            if result is not None:\n                                yield result\n                        if overlapping:\n                            last = pos + 1\n                        else:\n                            last = pos + length\n                        pos, length = find(buffer, last)\n\n                    # Advance to the next page.\n                    address    = address + page\n                    block_size = block_size - page\n                    prev_addr  = address\n\n                    # Fix the position of the last match.\n                    last = last - page\n                    if last < 0:\n                        last = 0\n\n                    # Remove the first page in the buffer.\n                    buffer = buffer[ page : ]\n                    delta  = page\n\n                    # If we haven't reached the end of the block yet,\n                    # read the next page in the block and keep seaching.\n                    if address < end:\n                        buffer = buffer + read(process, address, page)\n\n                    # Otherwise, we're done searching this block.\n                    else:\n                        break\n\n        # Perform search with buffering disabled.\n        else:\n\n            # Loop through all memory blocks containing data.\n            for mbi in memory_map:\n\n                # Skip blocks with no data to search on.\n                if not mbi.has_content():\n                    continue\n\n                # Get the address and size of this block.\n                address    = mbi.BaseAddress\n                block_size = mbi.RegionSize\n                if address >= maxAddr:\n                    break;\n\n                # Read the whole memory region.\n                buffer = process.read(address, block_size)\n\n                # Search for the pattern in this region.\n                pos, length = find(buffer)\n                last = 0\n                while pos >= last:\n                    match_addr = address + pos\n                    if minAddr <= match_addr < maxAddr:\n                        result = pattern.found(\n                                        match_addr, length,\n                                        buffer [ pos : pos + length ] )\n                        if result is not None:\n                            yield result\n                    if overlapping:\n                        last = pos + 1\n                    else:\n                        last = pos + length\n                    pos, length = find(buffer, last)", "response": "Search for a given pattern within a process memory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting ASCII strings from the process memory.", "response": "def extract_ascii_strings(cls, process, minSize = 4, maxSize = 1024):\n        \"\"\"\n        Extract ASCII strings from the process memory.\n\n        @type  process: L{Process}\n        @param process: Process to search.\n\n        @type  minSize: int\n        @param minSize: (Optional) Minimum size of the strings to search for.\n\n        @type  maxSize: int\n        @param maxSize: (Optional) Maximum size of the strings to search for.\n\n        @rtype:  iterator of tuple(int, int, str)\n        @return: Iterator of strings extracted from the process memory.\n            Each tuple contains the following:\n             - The memory address where the string was found.\n             - The size of the string.\n             - The string.\n        \"\"\"\n        regexp = r\"[\\s\\w\\!\\@\\#\\$\\%%\\^\\&\\*\\(\\)\\{\\}\\[\\]\\~\\`\\'\\\"\\:\\;\\.\\,\\\\\\/\\-\\+\\=\\_\\<\\>]{%d,%d}\\0\" % (minSize, maxSize)\n        pattern = RegExpPattern(regexp, 0, maxSize)\n        return cls.search_process(process, pattern, overlapping = False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts numeric strings into integers.", "response": "def integer(token):\n        \"\"\"\n        Convert numeric strings into integers.\n\n        @type  token: str\n        @param token: String to parse.\n\n        @rtype:  int\n        @return: Parsed integer value.\n        \"\"\"\n        token = token.strip()\n        neg = False\n        if token.startswith(compat.b('-')):\n            token = token[1:]\n            neg = True\n        if token.startswith(compat.b('0x')):\n            result = int(token, 16)     # hexadecimal\n        elif token.startswith(compat.b('0b')):\n            result = int(token[2:], 2)  # binary\n        elif token.startswith(compat.b('0o')):\n            result = int(token, 8)      # octal\n        else:\n            try:\n                result = int(token)     # decimal\n            except ValueError:\n                result = int(token, 16) # hexadecimal (no \"0x\" prefix)\n        if neg:\n            result = -result\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a strip of hexadecimal numbers into binary data.", "response": "def hexadecimal(token):\n        \"\"\"\n        Convert a strip of hexadecimal numbers into binary data.\n\n        @type  token: str\n        @param token: String to parse.\n\n        @rtype:  str\n        @return: Parsed string value.\n        \"\"\"\n        token = ''.join([ c for c in token if c.isalnum() ])\n        if len(token) % 2 != 0:\n            raise ValueError(\"Missing characters in hex data\")\n        data = ''\n        for i in compat.xrange(0, len(token), 2):\n            x = token[i:i+2]\n            d = int(x, 16)\n            s = struct.pack('<B', d)\n            data += s\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pattern(token):\n        token = ''.join([ c for c in token if c == '?' or c.isalnum() ])\n        if len(token) % 2 != 0:\n            raise ValueError(\"Missing characters in hex data\")\n        regexp = ''\n        for i in compat.xrange(0, len(token), 2):\n            x = token[i:i+2]\n            if x == '??':\n                regexp += '.'\n            elif x[0] == '?':\n                f = '\\\\x%%.1x%s' % x[1]\n                x = ''.join([ f % c for c in compat.xrange(0, 0x10) ])\n                regexp = '%s[%s]' % (regexp, x)\n            elif x[1] == '?':\n                f = '\\\\x%s%%.1x' % x[0]\n                x = ''.join([ f % c for c in compat.xrange(0, 0x10) ])\n                regexp = '%s[%s]' % (regexp, x)\n            else:\n                regexp = '%s\\\\x%s' % (regexp, x)\n        return regexp", "response": "Convert an hexadecimal search pattern into a POSIX regular expression."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef integer_list_file(cls, filename):\n        count  = 0\n        result = list()\n        fd     = open(filename, 'r')\n        for line in fd:\n            count = count + 1\n            if '#' in line:\n                line = line[ : line.find('#') ]\n            line = line.strip()\n            if line:\n                try:\n                    value = cls.integer(line)\n                except ValueError:\n                    e = sys.exc_info()[1]\n                    msg = \"Error in line %d of %s: %s\"\n                    msg = msg % (count, filename, str(e))\n                    raise ValueError(msg)\n                result.append(value)\n        return result", "response": "Read a list of integers from a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading a list of string values from a file.", "response": "def string_list_file(cls, filename):\n        \"\"\"\n        Read a list of string values from a file.\n\n        The file format is:\n\n         - # anywhere in the line begins a comment\n         - leading and trailing spaces are ignored\n         - empty lines are ignored\n         - strings cannot span over a single line\n\n        @type  filename: str\n        @param filename: Name of the file to read.\n\n        @rtype:  list\n        @return: List of integers and strings read from the file.\n        \"\"\"\n        count  = 0\n        result = list()\n        fd     = open(filename, 'r')\n        for line in fd:\n            count = count + 1\n            if '#' in line:\n                line = line[ : line.find('#') ]\n            line = line.strip()\n            if line:\n                result.append(line)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading a list of mixed values from a file.", "response": "def mixed_list_file(cls, filename):\n        \"\"\"\n        Read a list of mixed values from a file.\n\n        The file format is:\n\n         - # anywhere in the line begins a comment\n         - leading and trailing spaces are ignored\n         - empty lines are ignored\n         - strings cannot span over a single line\n         - integers can be specified as:\n            - decimal numbers (\"100\" is 100)\n            - hexadecimal numbers (\"0x100\" is 256)\n            - binary numbers (\"0b100\" is 4)\n            - octal numbers (\"0100\" is 64)\n\n        @type  filename: str\n        @param filename: Name of the file to read.\n\n        @rtype:  list\n        @return: List of integers and strings read from the file.\n        \"\"\"\n        count  = 0\n        result = list()\n        fd     = open(filename, 'r')\n        for line in fd:\n            count = count + 1\n            if '#' in line:\n                line = line[ : line.find('#') ]\n            line = line.strip()\n            if line:\n                try:\n                    value = cls.integer(line)\n                except ValueError:\n                    value = line\n                result.append(value)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite a list of integers to a file.", "response": "def integer_list_file(cls, filename, values, bits = None):\n        \"\"\"\n        Write a list of integers to a file.\n        If a file of the same name exists, it's contents are replaced.\n\n        See L{HexInput.integer_list_file} for a description of the file format.\n\n        @type  filename: str\n        @param filename: Name of the file to write.\n\n        @type  values: list( int )\n        @param values: List of integers to write to the file.\n\n        @type  bits: int\n        @param bits:\n            (Optional) Number of bits of the target architecture.\n            The default is platform dependent. See: L{HexOutput.integer_size}\n        \"\"\"\n        fd = open(filename, 'w')\n        for integer in values:\n            print >> fd, cls.integer(integer, bits)\n        fd.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting a list of strings to a file.", "response": "def string_list_file(cls, filename, values):\n        \"\"\"\n        Write a list of strings to a file.\n        If a file of the same name exists, it's contents are replaced.\n\n        See L{HexInput.string_list_file} for a description of the file format.\n\n        @type  filename: str\n        @param filename: Name of the file to write.\n\n        @type  values: list( int )\n        @param values: List of strings to write to the file.\n        \"\"\"\n        fd = open(filename, 'w')\n        for string in values:\n            print >> fd, string\n        fd.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites a list of mixed values to a file.", "response": "def mixed_list_file(cls, filename, values, bits):\n        \"\"\"\n        Write a list of mixed values to a file.\n        If a file of the same name exists, it's contents are replaced.\n\n        See L{HexInput.mixed_list_file} for a description of the file format.\n\n        @type  filename: str\n        @param filename: Name of the file to write.\n\n        @type  values: list( int )\n        @param values: List of mixed values to write to the file.\n\n        @type  bits: int\n        @param bits:\n            (Optional) Number of bits of the target architecture.\n            The default is platform dependent. See: L{HexOutput.integer_size}\n        \"\"\"\n        fd = open(filename, 'w')\n        for original in values:\n            try:\n                parsed = cls.integer(original, bits)\n            except TypeError:\n                parsed = repr(original)\n            print >> fd, parsed\n        fd.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef integer(cls, integer, bits = None):\n        if bits is None:\n            integer_size = cls.integer_size\n        else:\n            integer_size = bits / 4\n        return ('%%.%dX' % integer_size) % integer", "response": "Return the string representation of an integer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef address(cls, address, bits = None):\n        if bits is None:\n            address_size = cls.address_size\n            bits = win32.bits\n        else:\n            address_size = bits / 4\n        if address < 0:\n            address = ((2 ** bits) - 1) ^ ~address\n        return ('%%.%dX' % address_size) % address", "response": "Return the name of the current naculian memory address."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreplacing unprintable characters with dots.", "response": "def printable(data):\n        \"\"\"\n        Replace unprintable characters with dots.\n\n        @type  data: str\n        @param data: Binary data.\n\n        @rtype:  str\n        @return: Printable text.\n        \"\"\"\n        result = ''\n        for c in data:\n            if 32 < ord(c) < 128:\n                result += c\n            else:\n                result += '.'\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hexa_word(data, separator = ' '):\n        if len(data) & 1 != 0:\n            data += '\\0'\n        return separator.join( [ '%.4x' % struct.unpack('<H', data[i:i+2])[0] \\\n                                           for i in compat.xrange(0, len(data), 2) ] )", "response": "Convert binary data to a string of hexadecimal WORDs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping a line of hexadecimal numbers from binary data.", "response": "def hexline(cls, data, separator = ' ', width = None):\n        \"\"\"\n        Dump a line of hexadecimal numbers from binary data.\n\n        @type  data: str\n        @param data: Binary data.\n\n        @type  separator: str\n        @param separator:\n            Separator between the hexadecimal representation of each character.\n\n        @type  width: int\n        @param width:\n            (Optional) Maximum number of characters to convert per text line.\n            This value is also used for padding.\n\n        @rtype:  str\n        @return: Multiline output text.\n        \"\"\"\n        if width is None:\n            fmt = '%s  %s'\n        else:\n            fmt = '%%-%ds  %%-%ds' % ((len(separator)+2)*width-1, width)\n        return fmt % (cls.hexadecimal(data, separator), cls.printable(data))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping a block of hexadecimal numbers from binary data.", "response": "def hexblock(cls, data,                                    address = None,\n                                                                  bits = None,\n                                                             separator = ' ',\n                                                                 width = 8):\n        \"\"\"\n        Dump a block of hexadecimal numbers from binary data.\n        Also show a printable text version of the data.\n\n        @type  data: str\n        @param data: Binary data.\n\n        @type  address: str\n        @param address: Memory address where the data was read from.\n\n        @type  bits: int\n        @param bits:\n            (Optional) Number of bits of the target architecture.\n            The default is platform dependent. See: L{HexDump.address_size}\n\n        @type  separator: str\n        @param separator:\n            Separator between the hexadecimal representation of each character.\n\n        @type  width: int\n        @param width:\n            (Optional) Maximum number of characters to convert per text line.\n\n        @rtype:  str\n        @return: Multiline output text.\n        \"\"\"\n        return cls.hexblock_cb(cls.hexline, data, address, bits, width,\n                 cb_kwargs = {'width' : width, 'separator' : separator})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hexblock_cb(cls, callback, data,                        address = None,\n                                                                   bits = None,\n                                                                  width = 16,\n                                                                cb_args = (),\n                                                              cb_kwargs = {}):\n        \"\"\"\n        Dump a block of binary data using a callback function to convert each\n        line of text.\n\n        @type  callback: function\n        @param callback: Callback function to convert each line of data.\n\n        @type  data: str\n        @param data: Binary data.\n\n        @type  address: str\n        @param address:\n            (Optional) Memory address where the data was read from.\n\n        @type  bits: int\n        @param bits:\n            (Optional) Number of bits of the target architecture.\n            The default is platform dependent. See: L{HexDump.address_size}\n\n        @type  cb_args: str\n        @param cb_args:\n            (Optional) Arguments to pass to the callback function.\n\n        @type  cb_kwargs: str\n        @param cb_kwargs:\n            (Optional) Keyword arguments to pass to the callback function.\n\n        @type  width: int\n        @param width:\n            (Optional) Maximum number of bytes to convert per text line.\n\n        @rtype:  str\n        @return: Multiline output text.\n        \"\"\"\n        result = ''\n        if address is None:\n            for i in compat.xrange(0, len(data), width):\n                result = '%s%s\\n' % ( result, \\\n                             callback(data[i:i+width], *cb_args, **cb_kwargs) )\n        else:\n            for i in compat.xrange(0, len(data), width):\n                result = '%s%s: %s\\n' % (\n                             result,\n                             cls.address(address, bits),\n                             callback(data[i:i+width], *cb_args, **cb_kwargs)\n                             )\n                address += width\n        return result", "response": "Dump a block of binary data using a callback function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndumping a block of hexadecimal BYTEs from binary data.", "response": "def hexblock_byte(cls, data,                                address = None,\n                                                                   bits = None,\n                                                              separator = ' ',\n                                                                  width = 16):\n        \"\"\"\n        Dump a block of hexadecimal BYTEs from binary data.\n\n        @type  data: str\n        @param data: Binary data.\n\n        @type  address: str\n        @param address: Memory address where the data was read from.\n\n        @type  bits: int\n        @param bits:\n            (Optional) Number of bits of the target architecture.\n            The default is platform dependent. See: L{HexDump.address_size}\n\n        @type  separator: str\n        @param separator:\n            Separator between the hexadecimal representation of each BYTE.\n\n        @type  width: int\n        @param width:\n            (Optional) Maximum number of BYTEs to convert per text line.\n\n        @rtype:  str\n        @return: Multiline output text.\n        \"\"\"\n        return cls.hexblock_cb(cls.hexadecimal, data,\n                               address, bits, width,\n                               cb_kwargs = {'separator': separator})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef hexblock_word(cls, data,                                address = None,\n                                                                   bits = None,\n                                                              separator = ' ',\n                                                                  width = 8):\n        \"\"\"\n        Dump a block of hexadecimal WORDs from binary data.\n\n        @type  data: str\n        @param data: Binary data.\n\n        @type  address: str\n        @param address: Memory address where the data was read from.\n\n        @type  bits: int\n        @param bits:\n            (Optional) Number of bits of the target architecture.\n            The default is platform dependent. See: L{HexDump.address_size}\n\n        @type  separator: str\n        @param separator:\n            Separator between the hexadecimal representation of each WORD.\n\n        @type  width: int\n        @param width:\n            (Optional) Maximum number of WORDs to convert per text line.\n\n        @rtype:  str\n        @return: Multiline output text.\n        \"\"\"\n        return cls.hexblock_cb(cls.hexa_word, data,\n                               address, bits, width * 2,\n                               cb_kwargs = {'separator': separator})", "response": "Dump a block of hexadecimal WORDs from binary data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndumps a block of hexadecimal DWORDs from binary data.", "response": "def hexblock_dword(cls, data,                               address = None,\n                                                                   bits = None,\n                                                              separator = ' ',\n                                                                  width = 4):\n        \"\"\"\n        Dump a block of hexadecimal DWORDs from binary data.\n\n        @type  data: str\n        @param data: Binary data.\n\n        @type  address: str\n        @param address: Memory address where the data was read from.\n\n        @type  bits: int\n        @param bits:\n            (Optional) Number of bits of the target architecture.\n            The default is platform dependent. See: L{HexDump.address_size}\n\n        @type  separator: str\n        @param separator:\n            Separator between the hexadecimal representation of each DWORD.\n\n        @type  width: int\n        @param width:\n            (Optional) Maximum number of DWORDs to convert per text line.\n\n        @rtype:  str\n        @return: Multiline output text.\n        \"\"\"\n        return cls.hexblock_cb(cls.hexa_dword, data,\n                               address, bits, width * 4,\n                               cb_kwargs = {'separator': separator})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hexblock_qword(cls, data,                               address = None,\n                                                                   bits = None,\n                                                              separator = ' ',\n                                                                  width = 2):\n        \"\"\"\n        Dump a block of hexadecimal QWORDs from binary data.\n\n        @type  data: str\n        @param data: Binary data.\n\n        @type  address: str\n        @param address: Memory address where the data was read from.\n\n        @type  bits: int\n        @param bits:\n            (Optional) Number of bits of the target architecture.\n            The default is platform dependent. See: L{HexDump.address_size}\n\n        @type  separator: str\n        @param separator:\n            Separator between the hexadecimal representation of each QWORD.\n\n        @type  width: int\n        @param width:\n            (Optional) Maximum number of QWORDs to convert per text line.\n\n        @rtype:  str\n        @return: Multiline output text.\n        \"\"\"\n        return cls.hexblock_cb(cls.hexa_qword, data,\n                               address, bits, width * 8,\n                               cb_kwargs = {'separator': separator})", "response": "Dump a block of hexadecimal QWORDs from binary data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes the current foreground color the default.", "response": "def default(cls):\n        \"Make the current foreground color the default.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.FOREGROUND_MASK\n        wAttributes |=  win32.FOREGROUND_GREY\n        wAttributes &= ~win32.FOREGROUND_INTENSITY\n        cls._set_text_attributes(wAttributes)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef light(cls):\n        \"Make the current foreground color light.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes |= win32.FOREGROUND_INTENSITY\n        cls._set_text_attributes(wAttributes)", "response": "Make the current foreground color light."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dark(cls):\n        \"Make the current foreground color dark.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.FOREGROUND_INTENSITY\n        cls._set_text_attributes(wAttributes)", "response": "Make the current foreground color dark."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef black(cls):\n        \"Make the text foreground color black.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.FOREGROUND_MASK\n        #wAttributes |=  win32.FOREGROUND_BLACK\n        cls._set_text_attributes(wAttributes)", "response": "Make the text foreground color black."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef white(cls):\n        \"Make the text foreground color white.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.FOREGROUND_MASK\n        wAttributes |=  win32.FOREGROUND_GREY\n        cls._set_text_attributes(wAttributes)", "response": "Make the text foreground color white."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef red(cls):\n        \"Make the text foreground color red.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.FOREGROUND_MASK\n        wAttributes |=  win32.FOREGROUND_RED\n        cls._set_text_attributes(wAttributes)", "response": "Make the text foreground color red."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef green(cls):\n        \"Make the text foreground color green.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.FOREGROUND_MASK\n        wAttributes |=  win32.FOREGROUND_GREEN\n        cls._set_text_attributes(wAttributes)", "response": "Make the text foreground color green."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef blue(cls):\n        \"Make the text foreground color blue.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.FOREGROUND_MASK\n        wAttributes |=  win32.FOREGROUND_BLUE\n        cls._set_text_attributes(wAttributes)", "response": "Make the text foreground color blue."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cyan(cls):\n        \"Make the text foreground color cyan.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.FOREGROUND_MASK\n        wAttributes |=  win32.FOREGROUND_CYAN\n        cls._set_text_attributes(wAttributes)", "response": "Make the text foreground color cyan."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef magenta(cls):\n        \"Make the text foreground color magenta.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.FOREGROUND_MASK\n        wAttributes |=  win32.FOREGROUND_MAGENTA\n        cls._set_text_attributes(wAttributes)", "response": "Make the text foreground color magenta."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef yellow(cls):\n        \"Make the text foreground color yellow.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.FOREGROUND_MASK\n        wAttributes |=  win32.FOREGROUND_YELLOW\n        cls._set_text_attributes(wAttributes)", "response": "Make the text foreground color yellow."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bk_default(cls):\n        \"Make the current background color the default.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.BACKGROUND_MASK\n        #wAttributes |= win32.BACKGROUND_BLACK\n        wAttributes &= ~win32.BACKGROUND_INTENSITY\n        cls._set_text_attributes(wAttributes)", "response": "Make the current background color the default."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bk_light(cls):\n        \"Make the current background color light.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes |= win32.BACKGROUND_INTENSITY\n        cls._set_text_attributes(wAttributes)", "response": "Make the current background color light."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bk_dark(cls):\n        \"Make the current background color dark.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.BACKGROUND_INTENSITY\n        cls._set_text_attributes(wAttributes)", "response": "Make the current background color dark."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes the text background color black.", "response": "def bk_black(cls):\n        \"Make the text background color black.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.BACKGROUND_MASK\n        #wAttributes |= win32.BACKGROUND_BLACK\n        cls._set_text_attributes(wAttributes)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake the text background color white.", "response": "def bk_white(cls):\n        \"Make the text background color white.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.BACKGROUND_MASK\n        wAttributes |=  win32.BACKGROUND_GREY\n        cls._set_text_attributes(wAttributes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes the text background color red.", "response": "def bk_red(cls):\n        \"Make the text background color red.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.BACKGROUND_MASK\n        wAttributes |=  win32.BACKGROUND_RED\n        cls._set_text_attributes(wAttributes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bk_green(cls):\n        \"Make the text background color green.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.BACKGROUND_MASK\n        wAttributes |=  win32.BACKGROUND_GREEN\n        cls._set_text_attributes(wAttributes)", "response": "Make the text background color green."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes the text background color blue.", "response": "def bk_blue(cls):\n        \"Make the text background color blue.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.BACKGROUND_MASK\n        wAttributes |=  win32.BACKGROUND_BLUE\n        cls._set_text_attributes(wAttributes)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bk_cyan(cls):\n        \"Make the text background color cyan.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.BACKGROUND_MASK\n        wAttributes |=  win32.BACKGROUND_CYAN\n        cls._set_text_attributes(wAttributes)", "response": "Make the text background color cyan."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bk_magenta(cls):\n        \"Make the text background color magenta.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.BACKGROUND_MASK\n        wAttributes |=  win32.BACKGROUND_MAGENTA\n        cls._set_text_attributes(wAttributes)", "response": "Make the text background color magenta."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bk_yellow(cls):\n        \"Make the text background color yellow.\"\n        wAttributes = cls._get_text_attributes()\n        wAttributes &= ~win32.BACKGROUND_MASK\n        wAttributes |=  win32.BACKGROUND_YELLOW\n        cls._set_text_attributes(wAttributes)", "response": "Make the text background color yellow."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addRow(self, *row):\n        row     = [ str(item) for item in row ]\n        len_row = [ len(item) for item in row ]\n        width   = self.__width\n        len_old = len(width)\n        len_new = len(row)\n        known   = min(len_old, len_new)\n        missing = len_new - len_old\n        if missing > 0:\n            width.extend( len_row[ -missing : ] )\n        elif missing < 0:\n            len_row.extend( [0] * (-missing) )\n        self.__width = [ max( width[i], len_row[i] ) for i in compat.xrange(len(len_row)) ]\n        self.__cols.append(row)", "response": "Adds a row to the table. All items are converted to strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef justify(self, column, direction):\n        if direction == -1:\n            self.__width[column] =   abs(self.__width[column])\n        elif direction == 1:\n            self.__width[column] = - abs(self.__width[column])\n        else:\n            raise ValueError(\"Bad direction value.\")", "response": "Justify the text in a column left or right justified."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the width of the text output for the table.", "response": "def getWidth(self):\n        \"\"\"\n        Get the width of the text output for the table.\n\n        @rtype:  int\n        @return: Width in characters for the text output,\n            including the newline character.\n        \"\"\"\n        width = 0\n        if self.__width:\n            width = sum( abs(x) for x in self.__width )\n            width = width + len(self.__width) * len(self.__sep) + 1\n        return width"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef yieldOutput(self):\n        width = self.__width\n        if width:\n            num_cols = len(width)\n            fmt = ['%%%ds' % -w for w in width]\n            if width[-1] > 0:\n                fmt[-1] = '%s'\n            fmt = self.__sep.join(fmt)\n            for row in self.__cols:\n                row.extend( [''] * (num_cols - len(row)) )\n                yield fmt % tuple(row)", "response": "Generate the text output for the table."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dump_flags(efl):\n        if efl is None:\n            return ''\n        efl_dump = 'iopl=%1d' % ((efl & 0x3000) >> 12)\n        if efl & 0x100000:\n            efl_dump += ' vip'\n        else:\n            efl_dump += '    '\n        if efl & 0x80000:\n            efl_dump += ' vif'\n        else:\n            efl_dump += '    '\n        # 0x20000 ???\n        if efl & 0x800:\n            efl_dump += ' ov'       # Overflow\n        else:\n            efl_dump += ' no'       # No overflow\n        if efl & 0x400:\n            efl_dump += ' dn'       # Downwards\n        else:\n            efl_dump += ' up'       # Upwards\n        if efl & 0x200:\n            efl_dump += ' ei'       # Enable interrupts\n        else:\n            efl_dump += ' di'       # Disable interrupts\n        # 0x100 trap flag\n        if efl & 0x80:\n            efl_dump += ' ng'       # Negative\n        else:\n            efl_dump += ' pl'       # Positive\n        if efl & 0x40:\n            efl_dump += ' zr'       # Zero\n        else:\n            efl_dump += ' nz'       # Nonzero\n        if efl & 0x10:\n            efl_dump += ' ac'       # Auxiliary carry\n        else:\n            efl_dump += ' na'       # No auxiliary carry\n        # 0x8 ???\n        if efl & 0x4:\n            efl_dump += ' pe'       # Parity odd\n        else:\n            efl_dump += ' po'       # Parity even\n        # 0x2 ???\n        if efl & 0x1:\n            efl_dump += ' cy'       # Carry\n        else:\n            efl_dump += ' nc'       # No carry\n        return efl_dump", "response": "Dump the x86 processor flags."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndumping the x86 or x64 processor registers.", "response": "def dump_registers(cls, registers, arch = None):\n        \"\"\"\n        Dump the x86/x64 processor register values.\n        The output mimics that of the WinDBG debugger.\n\n        @type  registers: dict( str S{->} int )\n        @param registers: Dictionary mapping register names to their values.\n\n        @type  arch: str\n        @param arch: Architecture of the machine whose registers were dumped.\n            Defaults to the current architecture.\n            Currently only the following architectures are supported:\n             - L{win32.ARCH_I386}\n             - L{win32.ARCH_AMD64}\n\n        @rtype:  str\n        @return: Text suitable for logging.\n        \"\"\"\n        if registers is None:\n            return ''\n        if arch is None:\n            if 'Eax' in registers:\n                arch = win32.ARCH_I386\n            elif 'Rax' in registers:\n                arch = win32.ARCH_AMD64\n            else:\n                arch = 'Unknown'\n        if arch not in cls.reg_template:\n            msg = \"Don't know how to dump the registers for architecture: %s\"\n            raise NotImplementedError(msg % arch)\n        registers = registers.copy()\n        registers['efl_dump'] = cls.dump_flags( registers['EFlags'] )\n        return cls.reg_template[arch] % registers"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dump_registers_peek(registers, data, separator = ' ', width = 16):\n        if None in (registers, data):\n            return ''\n        names = compat.keys(data)\n        names.sort()\n        result = ''\n        for reg_name in names:\n            tag     = reg_name.lower()\n            dumped  = HexDump.hexline(data[reg_name], separator, width)\n            result += '%s -> %s\\n' % (tag, dumped)\n        return result", "response": "Dump the data pointed to by the given registers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dump_data_peek(data,                                      base = 0,\n                                                             separator = ' ',\n                                                                 width = 16,\n                                                                  bits = None):\n        \"\"\"\n        Dump data from pointers guessed within the given binary data.\n\n        @type  data: str\n        @param data: Dictionary mapping offsets to the data they point to.\n\n        @type  base: int\n        @param base: Base offset.\n\n        @type  bits: int\n        @param bits:\n            (Optional) Number of bits of the target architecture.\n            The default is platform dependent. See: L{HexDump.address_size}\n\n        @rtype:  str\n        @return: Text suitable for logging.\n        \"\"\"\n        if data is None:\n            return ''\n        pointers = compat.keys(data)\n        pointers.sort()\n        result = ''\n        for offset in pointers:\n            dumped  = HexDump.hexline(data[offset], separator, width)\n            address = HexDump.address(base + offset, bits)\n            result += '%s -> %s\\n' % (address, dumped)\n        return result", "response": "Dump the data from pointers guessed within the given binary data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dump_stack_peek(data, separator = ' ', width = 16, arch = None):\n        if data is None:\n            return ''\n        if arch is None:\n            arch = win32.arch\n        pointers = compat.keys(data)\n        pointers.sort()\n        result = ''\n        if pointers:\n            if arch == win32.ARCH_I386:\n                spreg = 'esp'\n            elif arch == win32.ARCH_AMD64:\n                spreg = 'rsp'\n            else:\n                spreg = 'STACK' # just a generic tag\n            tag_fmt = '[%s+0x%%.%dx]' % (spreg, len( '%x' % pointers[-1] ) )\n            for offset in pointers:\n                dumped  = HexDump.hexline(data[offset], separator, width)\n                tag     = tag_fmt % offset\n                result += '%s -> %s\\n' % (tag, dumped)\n        return result", "response": "Dump data from pointers guessed within the given stack dump."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dump_stack_trace(stack_trace, bits = None):\n        if not stack_trace:\n            return ''\n        table = Table()\n        table.addRow('Frame', 'Origin', 'Module')\n        for (fp, ra, mod) in stack_trace:\n            fp_d = HexDump.address(fp, bits)\n            ra_d = HexDump.address(ra, bits)\n            table.addRow(fp_d, ra_d, mod)\n        return table.getOutput()", "response": "Dump a stack trace as suitable for logging."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndumping a stack trace as returned by Thread. get_stack_trace_with_labels.", "response": "def dump_stack_trace_with_labels(stack_trace, bits = None):\n        \"\"\"\n        Dump a stack trace,\n        as returned by L{Thread.get_stack_trace_with_labels}.\n\n        @type  stack_trace: list( int, int, str )\n        @param stack_trace: Stack trace as a list of tuples of\n            ( return address, frame pointer, module filename )\n\n        @type  bits: int\n        @param bits:\n            (Optional) Number of bits of the target architecture.\n            The default is platform dependent. See: L{HexDump.address_size}\n\n        @rtype:  str\n        @return: Text suitable for logging.\n        \"\"\"\n        if not stack_trace:\n            return ''\n        table = Table()\n        table.addRow('Frame', 'Origin')\n        for (fp, label) in stack_trace:\n            table.addRow( HexDump.address(fp, bits), label )\n        return table.getOutput()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dump_code(disassembly,                                      pc = None,\n                                                            bLowercase = True,\n                                                                  bits = None):\n        \"\"\"\n        Dump a disassembly. Optionally mark where the program counter is.\n\n        @type  disassembly: list of tuple( int, int, str, str )\n        @param disassembly: Disassembly dump as returned by\n            L{Process.disassemble} or L{Thread.disassemble_around_pc}.\n\n        @type  pc: int\n        @param pc: (Optional) Program counter.\n\n        @type  bLowercase: bool\n        @param bLowercase: (Optional) If C{True} convert the code to lowercase.\n\n        @type  bits: int\n        @param bits:\n            (Optional) Number of bits of the target architecture.\n            The default is platform dependent. See: L{HexDump.address_size}\n\n        @rtype:  str\n        @return: Text suitable for logging.\n        \"\"\"\n        if not disassembly:\n            return ''\n        table = Table(sep = ' | ')\n        for (addr, size, code, dump) in disassembly:\n            if bLowercase:\n                code = code.lower()\n            if addr == pc:\n                addr = ' * %s' % HexDump.address(addr, bits)\n            else:\n                addr = '   %s' % HexDump.address(addr, bits)\n            table.addRow(addr, dump, code)\n        table.justify(1, 1)\n        return table.getOutput()", "response": "Dump a disassembly dump."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dump_code_line(disassembly_line,                  bShowAddress = True,\n                                                             bShowDump = True,\n                                                            bLowercase = True,\n                                                           dwDumpWidth = None,\n                                                           dwCodeWidth = None,\n                                                                  bits = None):\n        \"\"\"\n        Dump a single line of code. To dump a block of code use L{dump_code}.\n\n        @type  disassembly_line: tuple( int, int, str, str )\n        @param disassembly_line: Single item of the list returned by\n            L{Process.disassemble} or L{Thread.disassemble_around_pc}.\n\n        @type  bShowAddress: bool\n        @param bShowAddress: (Optional) If C{True} show the memory address.\n\n        @type  bShowDump: bool\n        @param bShowDump: (Optional) If C{True} show the hexadecimal dump.\n\n        @type  bLowercase: bool\n        @param bLowercase: (Optional) If C{True} convert the code to lowercase.\n\n        @type  dwDumpWidth: int or None\n        @param dwDumpWidth: (Optional) Width in characters of the hex dump.\n\n        @type  dwCodeWidth: int or None\n        @param dwCodeWidth: (Optional) Width in characters of the code.\n\n        @type  bits: int\n        @param bits:\n            (Optional) Number of bits of the target architecture.\n            The default is platform dependent. See: L{HexDump.address_size}\n\n        @rtype:  str\n        @return: Text suitable for logging.\n        \"\"\"\n        if bits is None:\n            address_size = HexDump.address_size\n        else:\n            address_size = bits / 4\n        (addr, size, code, dump) = disassembly_line\n        dump = dump.replace(' ', '')\n        result = list()\n        fmt = ''\n        if bShowAddress:\n            result.append( HexDump.address(addr, bits) )\n            fmt += '%%%ds:' % address_size\n        if bShowDump:\n            result.append(dump)\n            if dwDumpWidth:\n                fmt += ' %%-%ds' % dwDumpWidth\n            else:\n                fmt += ' %s'\n        if bLowercase:\n            code = code.lower()\n        result.append(code)\n        if dwCodeWidth:\n            fmt += ' %%-%ds' % dwCodeWidth\n        else:\n            fmt += ' %s'\n        return fmt % tuple(result)", "response": "Dump a single line of code."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping the memory map of a process. Optionally show the filenames for the memory mapped files as well.", "response": "def dump_memory_map(memoryMap, mappedFilenames = None, bits = None):\n        \"\"\"\n        Dump the memory map of a process. Optionally show the filenames for\n        memory mapped files as well.\n\n        @type  memoryMap: list( L{win32.MemoryBasicInformation} )\n        @param memoryMap: Memory map returned by L{Process.get_memory_map}.\n\n        @type  mappedFilenames: dict( int S{->} str )\n        @param mappedFilenames: (Optional) Memory mapped filenames\n            returned by L{Process.get_mapped_filenames}.\n\n        @type  bits: int\n        @param bits:\n            (Optional) Number of bits of the target architecture.\n            The default is platform dependent. See: L{HexDump.address_size}\n\n        @rtype:  str\n        @return: Text suitable for logging.\n        \"\"\"\n        if not memoryMap:\n            return ''\n\n        table = Table()\n        if mappedFilenames:\n            table.addRow(\"Address\", \"Size\", \"State\", \"Access\", \"Type\", \"File\")\n        else:\n            table.addRow(\"Address\", \"Size\", \"State\", \"Access\", \"Type\")\n\n        # For each memory block in the map...\n        for mbi in memoryMap:\n\n            # Address and size of memory block.\n            BaseAddress = HexDump.address(mbi.BaseAddress, bits)\n            RegionSize  = HexDump.address(mbi.RegionSize,  bits)\n\n            # State (free or allocated).\n            mbiState = mbi.State\n            if   mbiState == win32.MEM_RESERVE:\n                State   = \"Reserved\"\n            elif mbiState == win32.MEM_COMMIT:\n                State   = \"Commited\"\n            elif mbiState == win32.MEM_FREE:\n                State   = \"Free\"\n            else:\n                State   = \"Unknown\"\n\n            # Page protection bits (R/W/X/G).\n            if mbiState != win32.MEM_COMMIT:\n                Protect = \"\"\n            else:\n                mbiProtect = mbi.Protect\n                if   mbiProtect & win32.PAGE_NOACCESS:\n                    Protect = \"--- \"\n                elif mbiProtect & win32.PAGE_READONLY:\n                    Protect = \"R-- \"\n                elif mbiProtect & win32.PAGE_READWRITE:\n                    Protect = \"RW- \"\n                elif mbiProtect & win32.PAGE_WRITECOPY:\n                    Protect = \"RC- \"\n                elif mbiProtect & win32.PAGE_EXECUTE:\n                    Protect = \"--X \"\n                elif mbiProtect & win32.PAGE_EXECUTE_READ:\n                    Protect = \"R-X \"\n                elif mbiProtect & win32.PAGE_EXECUTE_READWRITE:\n                    Protect = \"RWX \"\n                elif mbiProtect & win32.PAGE_EXECUTE_WRITECOPY:\n                    Protect = \"RCX \"\n                else:\n                    Protect = \"??? \"\n                if   mbiProtect & win32.PAGE_GUARD:\n                    Protect += \"G\"\n                else:\n                    Protect += \"-\"\n                if   mbiProtect & win32.PAGE_NOCACHE:\n                    Protect += \"N\"\n                else:\n                    Protect += \"-\"\n                if   mbiProtect & win32.PAGE_WRITECOMBINE:\n                    Protect += \"W\"\n                else:\n                    Protect += \"-\"\n\n            # Type (file mapping, executable image, or private memory).\n            mbiType = mbi.Type\n            if   mbiType == win32.MEM_IMAGE:\n                Type    = \"Image\"\n            elif mbiType == win32.MEM_MAPPED:\n                Type    = \"Mapped\"\n            elif mbiType == win32.MEM_PRIVATE:\n                Type    = \"Private\"\n            elif mbiType == 0:\n                Type    = \"\"\n            else:\n                Type    = \"Unknown\"\n\n            # Output a row in the table.\n            if mappedFilenames:\n                FileName = mappedFilenames.get(mbi.BaseAddress, '')\n                table.addRow( BaseAddress, RegionSize, State, Protect, Type, FileName )\n            else:\n                table.addRow( BaseAddress, RegionSize, State, Protect, Type )\n\n        # Return the table output.\n        return table.getOutput()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlogs lines of text inserting a timestamp.", "response": "def log_text(text):\n        \"\"\"\n        Log lines of text, inserting a timestamp.\n\n        @type  text: str\n        @param text: Text to log.\n\n        @rtype:  str\n        @return: Log line.\n        \"\"\"\n        if text.endswith('\\n'):\n            text = text[:-len('\\n')]\n        #text  = text.replace('\\n', '\\n\\t\\t')           # text CSV\n        ltime = time.strftime(\"%X\")\n        msecs = (time.time() % 1) * 1000\n        return '[%s.%04d] %s' % (ltime, msecs, text)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlog lines of text associated with a debug event.", "response": "def log_event(cls, event, text = None):\n        \"\"\"\n        Log lines of text associated with a debug event.\n\n        @type  event: L{Event}\n        @param event: Event object.\n\n        @type  text: str\n        @param text: (Optional) Text to log. If no text is provided the default\n            is to show a description of the event itself.\n\n        @rtype:  str\n        @return: Log line.\n        \"\"\"\n        if not text:\n            if event.get_event_code() == win32.EXCEPTION_DEBUG_EVENT:\n                what = event.get_exception_description()\n                if event.is_first_chance():\n                    what = '%s (first chance)' % what\n                else:\n                    what = '%s (second chance)' % what\n                try:\n                    address = event.get_fault_address()\n                except NotImplementedError:\n                    address = event.get_exception_address()\n            else:\n                what    = event.get_event_name()\n                address = event.get_thread().get_pc()\n            process = event.get_process()\n            label = process.get_label_at_address(address)\n            address = HexDump.address(address, process.get_bits())\n            if label:\n                where = '%s (%s)' % (address, label)\n            else:\n                where = address\n            text = '%s at %s' % (what, where)\n        text = 'pid %d tid %d: %s' % (event.get_pid(), event.get_tid(), text)\n        #text = 'pid %d tid %d:\\t%s' % (event.get_pid(), event.get_tid(), text)     # text CSV\n        return cls.log_text(text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nshows an error message to standard error if the log file can t be written to.", "response": "def __logfile_error(self, e):\n        \"\"\"\n        Shows an error message to standard error\n        if the log file can't be written to.\n\n        Used internally.\n\n        @type  e: Exception\n        @param e: Exception raised when trying to write to the log file.\n        \"\"\"\n        from sys import stderr\n        msg = \"Warning, error writing log file %s: %s\\n\"\n        msg = msg % (self.logfile, str(e))\n        stderr.write(DebugLog.log_text(msg))\n        self.logfile = None\n        self.fd      = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the given text verbatim into the log file.", "response": "def __do_log(self, text):\n        \"\"\"\n        Writes the given text verbatim into the log file (if any)\n        and/or standard input (if the verbose flag is turned on).\n\n        Used internally.\n\n        @type  text: str\n        @param text: Text to print.\n        \"\"\"\n        if isinstance(text, compat.unicode):\n            text = text.encode('cp1252')\n        if self.verbose:\n            print(text)\n        if self.logfile:\n            try:\n                self.fd.writelines('%s\\n' % text)\n            except IOError:\n                e = sys.exc_info()[1]\n                self.__logfile_error(e)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef log_event(self, event, text = None):\n        self.__do_log( DebugLog.log_event(event, text) )", "response": "Log lines of text associated with a debug event.\n\n        @type  event: L{Event}\n        @param event: Event object.\n\n        @type  text: str\n        @param text: (Optional) Text to log. If no text is provided the default\n            is to show a description of the event itself."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndispatch an XML - RPC method from the marshalled data.", "response": "def _marshaled_dispatch(self, data, dispatch_method=None):\n        \"\"\"Dispatches an XML-RPC method from marshalled (XML) data.\n\n        XML-RPC methods are dispatched from the marshalled (XML) data\n        using the _dispatch method and the result is returned as\n        marshalled data. For backwards compatibility, a dispatch\n        function can be provided as an argument (see comment in\n        SimpleXMLRPCRequestHandler.do_POST) but overriding the\n        existing method through subclassing is the prefered means\n        of changing method dispatch behavior.\n        \"\"\"\n        try:\n            params, method = xmlrpclib.loads(data)\n\n            # generate response\n            if dispatch_method is not None:\n                response = dispatch_method(method, params)\n            else:\n                response = self._dispatch(method, params)\n            # wrap response in a singleton tuple\n            response = (response,)\n            response = xmlrpclib.dumps(response, methodresponse=1,\n                                       allow_none=self.allow_none, encoding=self.encoding)\n        except Fault, fault:\n            response = xmlrpclib.dumps(fault, allow_none=self.allow_none,\n                                       encoding=self.encoding)\n        except:\n            # report exception back to server\n            response = xmlrpclib.dumps(\n                xmlrpclib.Fault(1, \"%s:%s\" % (sys.exc_type, sys.exc_value)), #@UndefinedVariable exc_value only available when we actually have an exception\n                encoding=self.encoding, allow_none=self.allow_none,\n                )\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef system_listMethods(self):\n\n        methods = self.funcs.keys()\n        if self.instance is not None:\n            # Instance can implement _listMethod to return a list of\n            # methods\n            if hasattr(self.instance, '_listMethods'):\n                methods = remove_duplicates(\n                        methods + self.instance._listMethods()\n                    )\n            # if the instance has a _dispatch method then we\n            # don't have enough information to provide a list\n            # of methods\n            elif not hasattr(self.instance, '_dispatch'):\n                methods = remove_duplicates(\n                        methods + list_public_methods(self.instance)\n                    )\n        methods.sort()\n        return methods", "response": "System. listMethods - Returns a list of the methods supported by the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle the HTTP POST request.", "response": "def do_POST(self):\n        \"\"\"Handles the HTTP POST request.\n\n        Attempts to interpret all HTTP POST requests as XML-RPC calls,\n        which are forwarded to the server's _dispatch method for handling.\n        \"\"\"\n\n        # Check that the path is legal\n        if not self.is_rpc_path_valid():\n            self.report_404()\n            return\n\n        try:\n            # Get arguments by reading body of request.\n            # We read this in chunks to avoid straining\n            # socket.read(); around the 10 or 15Mb mark, some platforms\n            # begin to have problems (bug #792570).\n            max_chunk_size = 10 * 1024 * 1024\n            size_remaining = int(self.headers[\"content-length\"])\n            L = []\n            while size_remaining:\n                chunk_size = min(size_remaining, max_chunk_size)\n                L.append(self.rfile.read(chunk_size))\n                size_remaining -= len(L[-1])\n            data = ''.join(L)\n\n            # In previous versions of SimpleXMLRPCServer, _dispatch\n            # could be overridden in this class, instead of in\n            # SimpleXMLRPCDispatcher. To maintain backwards compatibility,\n            # check to see if a subclass implements _dispatch and dispatch\n            # using that method if present.\n            response = self.server._marshaled_dispatch(\n                    data, getattr(self, '_dispatch', None)\n                )\n        except: # This should only happen if the module is buggy\n            # internal error, report as HTTP server error\n            self.send_response(500)\n            self.end_headers()\n        else:\n            # got a valid XML RPC response\n            self.send_response(200)\n            self.send_header(\"Content-type\", \"text/xml\")\n            self.send_header(\"Content-length\", str(len(response)))\n            self.end_headers()\n            self.wfile.write(response)\n\n            # shut down the connection\n            self.wfile.flush()\n            self.connection.shutdown(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef log_request(self, code='-', size='-'):\n\n        if self.server.logRequests:\n            BaseHTTPServer.BaseHTTPRequestHandler.log_request(self, code, size)", "response": "Selectively log an accepted request."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles a single XML - RPC request", "response": "def handle_xmlrpc(self, request_text):\n        \"\"\"Handle a single XML-RPC request\"\"\"\n\n        response = self._marshaled_dispatch(request_text)\n\n        sys.stdout.write('Content-Type: text/xml\\n')\n        sys.stdout.write('Content-Length: %d\\n' % len(response))\n        sys.stdout.write('\\n')\n\n        sys.stdout.write(response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle_get(self):\n\n        code = 400\n        message, explain = \\\n                 BaseHTTPServer.BaseHTTPRequestHandler.responses[code]\n\n        response = BaseHTTPServer.DEFAULT_ERROR_MESSAGE % { #@UndefinedVariable\n             'code' : code,\n             'message' : message,\n             'explain' : explain\n            }\n        sys.stdout.write('Status: %d %s\\n' % (code, message))\n        sys.stdout.write('Content-Type: text/html\\n')\n        sys.stdout.write('Content-Length: %d\\n' % len(response))\n        sys.stdout.write('\\n')\n\n        sys.stdout.write(response)", "response": "Handle a single HTTP GET request."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle a single XML - RPC request.", "response": "def handle_request(self, request_text=None):\n        \"\"\"Handle a single XML-RPC request passed through a CGI post method.\n\n        If no XML data is given then it is read from stdin. The resulting\n        XML-RPC response is printed to stdout along with the correct HTTP\n        headers.\n        \"\"\"\n\n        if request_text is None and \\\n            os.environ.get('REQUEST_METHOD', None) == 'GET':\n            self.handle_get()\n        else:\n            # POST data is normally available through stdin\n            if request_text is None:\n                request_text = sys.stdin.read()\n\n            self.handle_xmlrpc(request_text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef versionok_for_gui():\n    ''' Return True if running Python is suitable for GUI Event Integration and deeper IPython integration '''\n    # We require Python 2.6+ ...\n    if sys.hexversion < 0x02060000:\n        return False\n    # Or Python 3.2+\n    if sys.hexversion >= 0x03000000 and sys.hexversion < 0x03020000:\n        return False\n    # Not supported under Jython nor IronPython\n    if sys.platform.startswith(\"java\") or sys.platform.startswith('cli'):\n        return False\n\n    return True", "response": "Return True if running Python is suitable for GUI Event Integration and deeper IPython integration"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef RaiseIfNotErrorSuccess(result, func = None, arguments = ()):\n    if result != ERROR_SUCCESS:\n        raise ctypes.WinError(result)\n    return result", "response": "Raises an exception if the result is not a Win32 error code."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_process(self, process = None):\n        if process is None:\n            self.dwProcessId = None\n            self.__process   = None\n        else:\n            self.__load_Process_class()\n            if not isinstance(process, Process):\n                msg  = \"Parent process must be a Process instance, \"\n                msg += \"got %s instead\" % type(process)\n                raise TypeError(msg)\n            self.dwProcessId = process.get_pid()\n            self.__process = process", "response": "Manually set the parent Process object. Use with care!"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_pid(self):\n        if self.dwProcessId is None:\n            if self.__process is not None:\n                # Infinite loop if self.__process is None\n                self.dwProcessId = self.get_process().get_pid()\n            else:\n                try:\n                    # I wish this had been implemented before Vista...\n                    # XXX TODO find the real ntdll call under this api\n                    hThread = self.get_handle(\n                                        win32.THREAD_QUERY_LIMITED_INFORMATION)\n                    self.dwProcessId = win32.GetProcessIdOfThread(hThread)\n                except AttributeError:\n                    # This method really sucks :P\n                    self.dwProcessId = self.__get_pid_by_scanning()\n        return self.dwProcessId", "response": "Get the parent process ID of the current process."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __get_pid_by_scanning(self):\n        'Internally used by get_pid().'\n        dwProcessId = None\n        dwThreadId = self.get_tid()\n        with win32.CreateToolhelp32Snapshot(win32.TH32CS_SNAPTHREAD) as hSnapshot:\n            te = win32.Thread32First(hSnapshot)\n            while te is not None:\n                if te.th32ThreadID == dwThreadId:\n                    dwProcessId = te.th32OwnerProcessID\n                    break\n                te = win32.Thread32Next(hSnapshot)\n        if dwProcessId is None:\n            msg = \"Cannot find thread ID %d in any process\" % dwThreadId\n            raise RuntimeError(msg)\n        return dwProcessId", "response": "Internally used by get_pid()."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef open_handle(self, dwDesiredAccess = win32.THREAD_ALL_ACCESS):\n        hThread = win32.OpenThread(dwDesiredAccess, win32.FALSE, self.dwThreadId)\n\n        # In case hThread was set to an actual handle value instead of a Handle\n        # object. This shouldn't happen unless the user tinkered with it.\n        if not hasattr(self.hThread, '__del__'):\n            self.close_handle()\n\n        self.hThread = hThread", "response": "Opens a new handle to the thread and sets the self. hThread property to the thread object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef close_handle(self):\n        try:\n            if hasattr(self.hThread, 'close'):\n                self.hThread.close()\n            elif self.hThread not in (None, win32.INVALID_HANDLE_VALUE):\n                win32.CloseHandle(self.hThread)\n        finally:\n            self.hThread = None", "response": "Closes the handle to the thread."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a handle to the thread with the requested access rights.", "response": "def get_handle(self, dwDesiredAccess = win32.THREAD_ALL_ACCESS):\n        \"\"\"\n        Returns a handle to the thread with I{at least} the access rights\n        requested.\n\n        @note:\n            If a handle was previously opened and has the required access\n            rights, it's reused. If not, a new handle is opened with the\n            combination of the old and new access rights.\n\n        @type  dwDesiredAccess: int\n        @param dwDesiredAccess: Desired access rights.\n            See: U{http://msdn.microsoft.com/en-us/library/windows/desktop/ms686769(v=vs.85).aspx}\n\n        @rtype:  ThreadHandle\n        @return: Handle to the thread.\n\n        @raise WindowsError: It's not possible to open a handle to the thread\n            with the requested access rights. This tipically happens because\n            the target thread belongs to system process and the debugger is not\n            runnning with administrative rights.\n        \"\"\"\n        if self.hThread in (None, win32.INVALID_HANDLE_VALUE):\n            self.open_handle(dwDesiredAccess)\n        else:\n            dwAccess = self.hThread.dwAccess\n            if (dwAccess | dwDesiredAccess) != dwAccess:\n                self.open_handle(dwAccess | dwDesiredAccess)\n        return self.hThread"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nterminate the thread execution.", "response": "def kill(self, dwExitCode = 0):\n        \"\"\"\n        Terminates the thread execution.\n\n        @note: If the C{lpInjectedMemory} member contains a valid pointer,\n        the memory is freed.\n\n        @type  dwExitCode: int\n        @param dwExitCode: (Optional) Thread exit code.\n        \"\"\"\n        hThread = self.get_handle(win32.THREAD_TERMINATE)\n        win32.TerminateThread(hThread, dwExitCode)\n\n        # Ugliest hack ever, won't work if many pieces of code are injected.\n        # Seriously, what was I thinking? Lame! :(\n        if self.pInjectedMemory is not None:\n            try:\n                self.get_process().free(self.pInjectedMemory)\n                self.pInjectedMemory = None\n            except Exception:\n##                raise           # XXX DEBUG\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef suspend(self):\n        hThread = self.get_handle(win32.THREAD_SUSPEND_RESUME)\n        if self.is_wow64():\n            # FIXME this will be horribly slow on XP 64\n            # since it'll try to resolve a missing API every time\n            try:\n                return win32.Wow64SuspendThread(hThread)\n            except AttributeError:\n                pass\n        return win32.SuspendThread(hThread)", "response": "Suspends the thread execution. If zero the thread is running."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resume(self):\n        hThread = self.get_handle(win32.THREAD_SUSPEND_RESUME)\n        return win32.ResumeThread(hThread)", "response": "Resumes the thread execution."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the execution context for the current thread.", "response": "def get_context(self, ContextFlags = None, bSuspend = False):\n        \"\"\"\n        Retrieves the execution context (i.e. the registers values) for this\n        thread.\n\n        @type  ContextFlags: int\n        @param ContextFlags: Optional, specify which registers to retrieve.\n            Defaults to C{win32.CONTEXT_ALL} which retrieves all registes\n            for the current platform.\n\n        @type  bSuspend: bool\n        @param bSuspend: C{True} to automatically suspend the thread before\n            getting its context, C{False} otherwise.\n\n            Defaults to C{False} because suspending the thread during some\n            debug events (like thread creation or destruction) may lead to\n            strange errors.\n\n            Note that WinAppDbg 1.4 used to suspend the thread automatically\n            always. This behavior was changed in version 1.5.\n\n        @rtype:  dict( str S{->} int )\n        @return: Dictionary mapping register names to their values.\n\n        @see: L{set_context}\n        \"\"\"\n\n        # Some words on the \"strange errors\" that lead to the bSuspend\n        # parameter. Peter Van Eeckhoutte and I were working on a fix\n        # for some bugs he found in the 1.5 betas when we stumbled upon\n        # what seemed to be a deadlock in the debug API that caused the\n        # GetThreadContext() call never to return. Since removing the\n        # call to SuspendThread() solved the problem, and a few Google\n        # searches showed a handful of problems related to these two\n        # APIs and Wow64 environments, I decided to break compatibility.\n        #\n        # Here are some pages about the weird behavior of SuspendThread:\n        # http://zachsaw.blogspot.com.es/2010/11/wow64-bug-getthreadcontext-may-return.html\n        # http://stackoverflow.com/questions/3444190/windows-suspendthread-doesnt-getthreadcontext-fails\n\n        # Get the thread handle.\n        dwAccess = win32.THREAD_GET_CONTEXT\n        if bSuspend:\n            dwAccess = dwAccess | win32.THREAD_SUSPEND_RESUME\n        hThread = self.get_handle(dwAccess)\n\n        # Suspend the thread if requested.\n        if bSuspend:\n            try:\n                self.suspend()\n            except WindowsError:\n                # Threads can't be suspended when the exit process event\n                # arrives, but you can still get the context.\n                bSuspend = False\n\n        # If an exception is raised, make sure the thread execution is resumed.\n        try:\n\n            if win32.bits == self.get_bits():\n\n                # 64 bit debugger attached to 64 bit process, or\n                # 32 bit debugger attached to 32 bit process.\n                ctx = win32.GetThreadContext(hThread,\n                                             ContextFlags = ContextFlags)\n\n            else:\n                if self.is_wow64():\n\n                    # 64 bit debugger attached to 32 bit process.\n                    if ContextFlags is not None:\n                        ContextFlags &= ~win32.ContextArchMask\n                        ContextFlags |=  win32.WOW64_CONTEXT_i386\n                    ctx = win32.Wow64GetThreadContext(hThread, ContextFlags)\n\n                else:\n\n                    # 32 bit debugger attached to 64 bit process.\n                    # XXX only i386/AMD64 is supported in this particular case\n                    if win32.arch not in (win32.ARCH_I386, win32.ARCH_AMD64):\n                        raise NotImplementedError()\n                    if ContextFlags is not None:\n                        ContextFlags &= ~win32.ContextArchMask\n                        ContextFlags |=  win32.context_amd64.CONTEXT_AMD64\n                    ctx = win32.context_amd64.GetThreadContext(hThread,\n                                                 ContextFlags = ContextFlags)\n\n        finally:\n\n            # Resume the thread if we suspended it.\n            if bSuspend:\n                self.resume()\n\n        # Return the context.\n        return ctx"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the values of the registers in the current thread.", "response": "def set_context(self, context, bSuspend = False):\n        \"\"\"\n        Sets the values of the registers.\n\n        @see: L{get_context}\n\n        @type  context:  dict( str S{->} int )\n        @param context: Dictionary mapping register names to their values.\n\n        @type  bSuspend: bool\n        @param bSuspend: C{True} to automatically suspend the thread before\n            setting its context, C{False} otherwise.\n\n            Defaults to C{False} because suspending the thread during some\n            debug events (like thread creation or destruction) may lead to\n            strange errors.\n\n            Note that WinAppDbg 1.4 used to suspend the thread automatically\n            always. This behavior was changed in version 1.5.\n        \"\"\"\n\n        # Get the thread handle.\n        dwAccess = win32.THREAD_SET_CONTEXT\n        if bSuspend:\n            dwAccess = dwAccess | win32.THREAD_SUSPEND_RESUME\n        hThread = self.get_handle(dwAccess)\n\n        # Suspend the thread if requested.\n        if bSuspend:\n            self.suspend()\n            # No fix for the exit process event bug.\n            # Setting the context of a dead thread is pointless anyway.\n\n        # Set the thread context.\n        try:\n            if win32.bits == 64 and self.is_wow64():\n                win32.Wow64SetThreadContext(hThread, context)\n            else:\n                win32.SetThreadContext(hThread, context)\n\n        # Resume the thread if we suspended it.\n        finally:\n            if bSuspend:\n                self.resume()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the value of a specific register.", "response": "def set_register(self, register, value):\n        \"\"\"\n        Sets the value of a specific register.\n\n        @type  register: str\n        @param register: Register name.\n\n        @rtype:  int\n        @return: Register value.\n        \"\"\"\n        context = self.get_context()\n        context[register] = value\n        self.set_context(context)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine if the thread is running under WOW64.", "response": "def is_wow64(self):\n        \"\"\"\n        Determines if the thread is running under WOW64.\n\n        @rtype:  bool\n        @return:\n            C{True} if the thread is running under WOW64. That is, it belongs\n            to a 32-bit application running in a 64-bit Windows.\n\n            C{False} if the thread belongs to either a 32-bit application\n            running in a 32-bit Windows, or a 64-bit application running in a\n            64-bit Windows.\n\n        @raise WindowsError: On error an exception is raised.\n\n        @see: U{http://msdn.microsoft.com/en-us/library/aa384249(VS.85).aspx}\n        \"\"\"\n        try:\n            wow64 = self.__wow64\n        except AttributeError:\n            if (win32.bits == 32 and not win32.wow64):\n                wow64 = False\n            else:\n                wow64 = self.get_process().is_wow64()\n            self.__wow64 = wow64\n        return wow64"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a remote pointer to the TEB.", "response": "def get_teb_address(self):\n        \"\"\"\n        Returns a remote pointer to the TEB.\n\n        @rtype:  int\n        @return: Remote pointer to the L{TEB} structure.\n        @raise WindowsError: An exception is raised on error.\n        \"\"\"\n        try:\n            return self._teb_ptr\n        except AttributeError:\n            try:\n                hThread = self.get_handle(win32.THREAD_QUERY_INFORMATION)\n                tbi = win32.NtQueryInformationThread( hThread,\n                                                win32.ThreadBasicInformation)\n                address = tbi.TebBaseAddress\n            except WindowsError:\n                address = self.get_linear_address('SegFs', 0)   # fs:[0]\n                if not address:\n                    raise\n            self._teb_ptr = address\n            return address"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntranslating segment - relative addresses to linear addresses.", "response": "def get_linear_address(self, segment, address):\n        \"\"\"\n        Translates segment-relative addresses to linear addresses.\n\n        Linear addresses can be used to access a process memory,\n        calling L{Process.read} and L{Process.write}.\n\n        @type  segment: str\n        @param segment: Segment register name.\n\n        @type  address: int\n        @param address: Segment relative memory address.\n\n        @rtype:  int\n        @return: Linear memory address.\n\n        @raise ValueError: Address is too large for selector.\n\n        @raise WindowsError:\n            The current architecture does not support selectors.\n            Selectors only exist in x86-based systems.\n        \"\"\"\n        hThread  = self.get_handle(win32.THREAD_QUERY_INFORMATION)\n        selector = self.get_register(segment)\n        ldt      = win32.GetThreadSelectorEntry(hThread, selector)\n        BaseLow  = ldt.BaseLow\n        BaseMid  = ldt.HighWord.Bytes.BaseMid << 16\n        BaseHi   = ldt.HighWord.Bytes.BaseHi  << 24\n        Base     = BaseLow | BaseMid | BaseHi\n        LimitLow = ldt.LimitLow\n        LimitHi  = ldt.HighWord.Bits.LimitHi  << 16\n        Limit    = LimitLow | LimitHi\n        if address > Limit:\n            msg = \"Address %s too large for segment %s (selector %d)\"\n            msg = msg % (HexDump.address(address, self.get_bits()),\n                         segment, selector)\n            raise ValueError(msg)\n        return Base + address"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_seh_chain_pointer(self):\n        if win32.arch != win32.ARCH_I386:\n            raise NotImplementedError(\n                \"SEH chain parsing is only supported in 32-bit Windows.\")\n\n        process = self.get_process()\n        address = self.get_linear_address( 'SegFs', 0 )\n        return process.read_pointer( address )", "response": "Get the pointer to the first structured exception handler block in the linked list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nchange the pointer to the first structured exception handler block.", "response": "def set_seh_chain_pointer(self, value):\n        \"\"\"\n        Change the pointer to the first structured exception handler block.\n\n        @type  value: int\n        @param value: Value of the remote pointer to the first block of the\n            structured exception handlers linked list. To disable SEH set the\n            value C{0xFFFFFFFF}.\n\n        @raise NotImplementedError:\n            This method is only supported in 32 bits versions of Windows.\n        \"\"\"\n        if win32.arch != win32.ARCH_I386:\n            raise NotImplementedError(\n                \"SEH chain parsing is only supported in 32-bit Windows.\")\n\n        process = self.get_process()\n        address = self.get_linear_address( 'SegFs', 0 )\n        process.write_pointer( address, value )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the stack trace for the current process.", "response": "def __get_stack_trace(self, depth = 16, bUseLabels = True,\n                                                           bMakePretty = True):\n        \"\"\"\n        Tries to get a stack trace for the current function using the debug\n        helper API (dbghelp.dll).\n\n        @type  depth: int\n        @param depth: Maximum depth of stack trace.\n\n        @type  bUseLabels: bool\n        @param bUseLabels: C{True} to use labels, C{False} to use addresses.\n\n        @type  bMakePretty: bool\n        @param bMakePretty:\n            C{True} for user readable labels,\n            C{False} for labels that can be passed to L{Process.resolve_label}.\n\n            \"Pretty\" labels look better when producing output for the user to\n            read, while pure labels are more useful programatically.\n\n        @rtype:  tuple of tuple( int, int, str )\n        @return: Stack trace of the thread as a tuple of\n            ( return address, frame pointer address, module filename )\n            when C{bUseLabels} is C{True}, or a tuple of\n            ( return address, frame pointer label )\n            when C{bUseLabels} is C{False}.\n\n        @raise WindowsError: Raises an exception on error.\n        \"\"\"\n\n        aProcess = self.get_process()\n        arch = aProcess.get_arch()\n        bits = aProcess.get_bits()\n\n        if arch == win32.ARCH_I386:\n            MachineType = win32.IMAGE_FILE_MACHINE_I386\n        elif arch == win32.ARCH_AMD64:\n            MachineType = win32.IMAGE_FILE_MACHINE_AMD64\n        elif arch == win32.ARCH_IA64:\n            MachineType = win32.IMAGE_FILE_MACHINE_IA64\n        else:\n            msg = \"Stack walking is not available for this architecture: %s\"\n            raise NotImplementedError(msg % arch)\n\n        hProcess = aProcess.get_handle( win32.PROCESS_VM_READ |\n                                        win32.PROCESS_QUERY_INFORMATION )\n        hThread  = self.get_handle( win32.THREAD_GET_CONTEXT |\n                                    win32.THREAD_QUERY_INFORMATION )\n\n        StackFrame = win32.STACKFRAME64()\n        StackFrame.AddrPC    = win32.ADDRESS64( self.get_pc() )\n        StackFrame.AddrFrame = win32.ADDRESS64( self.get_fp() )\n        StackFrame.AddrStack = win32.ADDRESS64( self.get_sp() )\n\n        trace = list()\n        while win32.StackWalk64(MachineType, hProcess, hThread, StackFrame):\n            if depth <= 0:\n                break\n            fp = StackFrame.AddrFrame.Offset\n            ra = aProcess.peek_pointer(fp + 4)\n            if ra == 0:\n                break\n            lib = aProcess.get_module_at_address(ra)\n            if lib is None:\n                lib = \"\"\n            else:\n                if lib.fileName:\n                    lib = lib.fileName\n                else:\n                    lib = \"%s\" % HexDump.address(lib.lpBaseOfDll, bits)\n            if bUseLabels:\n                label = aProcess.get_label_at_address(ra)\n                if bMakePretty:\n                    label = '%s (%s)' % (HexDump.address(ra, bits), label)\n                trace.append( (fp, label) )\n            else:\n                trace.append( (fp, ra, lib) )\n            fp = aProcess.peek_pointer(fp)\n        return tuple(trace)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __get_stack_trace_manually(self, depth = 16, bUseLabels = True,\n                                                           bMakePretty = True):\n        \"\"\"\n        Tries to get a stack trace for the current function.\n        Only works for functions with standard prologue and epilogue.\n\n        @type  depth: int\n        @param depth: Maximum depth of stack trace.\n\n        @type  bUseLabels: bool\n        @param bUseLabels: C{True} to use labels, C{False} to use addresses.\n\n        @type  bMakePretty: bool\n        @param bMakePretty:\n            C{True} for user readable labels,\n            C{False} for labels that can be passed to L{Process.resolve_label}.\n\n            \"Pretty\" labels look better when producing output for the user to\n            read, while pure labels are more useful programatically.\n\n        @rtype:  tuple of tuple( int, int, str )\n        @return: Stack trace of the thread as a tuple of\n            ( return address, frame pointer address, module filename )\n            when C{bUseLabels} is C{True}, or a tuple of\n            ( return address, frame pointer label )\n            when C{bUseLabels} is C{False}.\n\n        @raise WindowsError: Raises an exception on error.\n        \"\"\"\n        aProcess = self.get_process()\n        st, sb   = self.get_stack_range()   # top, bottom\n        fp       = self.get_fp()\n        trace    = list()\n        if aProcess.get_module_count() == 0:\n            aProcess.scan_modules()\n        bits = aProcess.get_bits()\n        while depth > 0:\n            if fp == 0:\n                break\n            if not st <= fp < sb:\n                break\n            ra  = aProcess.peek_pointer(fp + 4)\n            if ra == 0:\n                break\n            lib = aProcess.get_module_at_address(ra)\n            if lib is None:\n                lib = \"\"\n            else:\n                if lib.fileName:\n                    lib = lib.fileName\n                else:\n                    lib = \"%s\" % HexDump.address(lib.lpBaseOfDll, bits)\n            if bUseLabels:\n                label = aProcess.get_label_at_address(ra)\n                if bMakePretty:\n                    label = '%s (%s)' % (HexDump.address(ra, bits), label)\n                trace.append( (fp, label) )\n            else:\n                trace.append( (fp, ra, lib) )\n            fp = aProcess.peek_pointer(fp)\n        return tuple(trace)", "response": "This method attempts to get a stack trace for the current function."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntries to get a stack trace for the current function.", "response": "def get_stack_trace(self, depth = 16):\n        \"\"\"\n        Tries to get a stack trace for the current function.\n        Only works for functions with standard prologue and epilogue.\n\n        @type  depth: int\n        @param depth: Maximum depth of stack trace.\n\n        @rtype:  tuple of tuple( int, int, str )\n        @return: Stack trace of the thread as a tuple of\n            ( return address, frame pointer address, module filename ).\n\n        @raise WindowsError: Raises an exception on error.\n        \"\"\"\n        try:\n            trace = self.__get_stack_trace(depth, False)\n        except Exception:\n            import traceback\n            traceback.print_exc()\n            trace = ()\n        if not trace:\n            trace = self.__get_stack_trace_manually(depth, False)\n        return trace"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrying to get a stack trace for the current function.", "response": "def get_stack_trace_with_labels(self, depth = 16, bMakePretty = True):\n        \"\"\"\n        Tries to get a stack trace for the current function.\n        Only works for functions with standard prologue and epilogue.\n\n        @type  depth: int\n        @param depth: Maximum depth of stack trace.\n\n        @type  bMakePretty: bool\n        @param bMakePretty:\n            C{True} for user readable labels,\n            C{False} for labels that can be passed to L{Process.resolve_label}.\n\n            \"Pretty\" labels look better when producing output for the user to\n            read, while pure labels are more useful programatically.\n\n        @rtype:  tuple of tuple( int, int, str )\n        @return: Stack trace of the thread as a tuple of\n            ( return address, frame pointer label ).\n\n        @raise WindowsError: Raises an exception on error.\n        \"\"\"\n        try:\n            trace = self.__get_stack_trace(depth, True, bMakePretty)\n        except Exception:\n            trace = ()\n        if not trace:\n            trace = self.__get_stack_trace_manually(depth, True, bMakePretty)\n        return trace"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_stack_frame_range(self):\n        st, sb   = self.get_stack_range()   # top, bottom\n        sp       = self.get_sp()\n        fp       = self.get_fp()\n        size     = fp - sp\n        if not st <= sp < sb:\n            raise RuntimeError('Stack pointer lies outside the stack')\n        if not st <= fp < sb:\n            raise RuntimeError('Frame pointer lies outside the stack')\n        if sp > fp:\n            raise RuntimeError('No valid stack frame found')\n        return (sp, fp)", "response": "Returns the starting and ending addresses of the stack frame."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_stack_frame(self, max_size = None):\n        sp, fp   = self.get_stack_frame_range()\n        size     = fp - sp\n        if max_size and size > max_size:\n            size = max_size\n        return self.get_process().peek(sp, size)", "response": "Reads the contents of the current stack frame."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the contents of the top of the stack.", "response": "def read_stack_data(self, size = 128, offset = 0):\n        \"\"\"\n        Reads the contents of the top of the stack.\n\n        @type  size: int\n        @param size: Number of bytes to read.\n\n        @type  offset: int\n        @param offset: Offset from the stack pointer to begin reading.\n\n        @rtype:  str\n        @return: Stack data.\n\n        @raise WindowsError: Could not read the requested data.\n        \"\"\"\n        aProcess = self.get_process()\n        return aProcess.read(self.get_sp() + offset, size)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef peek_stack_data(self, size = 128, offset = 0):\n        aProcess = self.get_process()\n        return aProcess.peek(self.get_sp() + offset, size)", "response": "Reads the contents of the top of the stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_stack_dwords(self, count, offset = 0):\n        if count > 0:\n            stackData = self.read_stack_data(count * 4, offset)\n            return struct.unpack('<'+('L'*count), stackData)\n        return ()", "response": "Reads DWORDs from the top of the stack."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef peek_stack_dwords(self, count, offset = 0):\n        stackData = self.peek_stack_data(count * 4, offset)\n        if len(stackData) & 3:\n            stackData = stackData[:-len(stackData) & 3]\n        if not stackData:\n            return ()\n        return struct.unpack('<'+('L'*count), stackData)", "response": "Reads count DWORDs from the top of the stack and returns them as a tuple."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading count QWORDs from the top of the stack.", "response": "def read_stack_qwords(self, count, offset = 0):\n        \"\"\"\n        Reads QWORDs from the top of the stack.\n\n        @type  count: int\n        @param count: Number of QWORDs to read.\n\n        @type  offset: int\n        @param offset: Offset from the stack pointer to begin reading.\n\n        @rtype:  tuple( int... )\n        @return: Tuple of integers read from the stack.\n\n        @raise WindowsError: Could not read the requested data.\n        \"\"\"\n        stackData = self.read_stack_data(count * 8, offset)\n        return struct.unpack('<'+('Q'*count), stackData)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_stack_structure(self, structure, offset = 0):\n        aProcess  = self.get_process()\n        stackData = aProcess.read_structure(self.get_sp() + offset, structure)\n        return tuple([ stackData.__getattribute__(name)\n                       for (name, type) in stackData._fields_ ])", "response": "Reads the given structure at the top of the stack."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the stack frame of the thread.", "response": "def read_stack_frame(self, structure, offset = 0):\n        \"\"\"\n        Reads the stack frame of the thread.\n\n        @type  structure: ctypes.Structure\n        @param structure: Structure of the stack frame.\n\n        @type  offset: int\n        @param offset: Offset from the frame pointer to begin reading.\n            The frame pointer is the same returned by the L{get_fp} method.\n\n        @rtype:  tuple\n        @return: Tuple of elements read from the stack frame. The type of each\n            element matches the types in the stack frame structure.\n        \"\"\"\n        aProcess  = self.get_process()\n        stackData = aProcess.read_structure(self.get_fp() + offset, structure)\n        return tuple([ stackData.__getattribute__(name)\n                       for (name, type) in stackData._fields_ ])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_code_bytes(self, size = 128, offset = 0):\n        return self.get_process().read(self.get_pc() + offset, size)", "response": "Reads some bytes of the code currently being executed from the process memory."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads some bytes of the code currently being executed in the process memory.", "response": "def peek_code_bytes(self, size = 128, offset = 0):\n        \"\"\"\n        Tries to read some bytes of the code currently being executed.\n\n        @type  size: int\n        @param size: Number of bytes to read.\n\n        @type  offset: int\n        @param offset: Offset from the program counter to begin reading.\n\n        @rtype:  str\n        @return: Bytes read from the process memory.\n            May be less than the requested number of bytes.\n        \"\"\"\n        return self.get_process().peek(self.get_pc() + offset, size)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to read some data from each of the registers in the current thread.", "response": "def peek_pointers_in_registers(self, peekSize = 16, context = None):\n        \"\"\"\n        Tries to guess which values in the registers are valid pointers,\n        and reads some data from them.\n\n        @type  peekSize: int\n        @param peekSize: Number of bytes to read from each pointer found.\n\n        @type  context: dict( str S{->} int )\n        @param context: (Optional)\n            Dictionary mapping register names to their values.\n            If not given, the current thread context will be used.\n\n        @rtype:  dict( str S{->} str )\n        @return: Dictionary mapping register names to the data they point to.\n        \"\"\"\n        peekable_registers = (\n            'Eax', 'Ebx', 'Ecx', 'Edx', 'Esi', 'Edi', 'Ebp'\n        )\n        if not context:\n            context = self.get_context(win32.CONTEXT_CONTROL | \\\n                                       win32.CONTEXT_INTEGER)\n        aProcess    = self.get_process()\n        data        = dict()\n        for (reg_name, reg_value) in compat.iteritems(context):\n            if reg_name not in peekable_registers:\n                continue\n##            if reg_name == 'Ebp':\n##                stack_begin, stack_end = self.get_stack_range()\n##                print hex(stack_end), hex(reg_value), hex(stack_begin)\n##                if stack_begin and stack_end and stack_end < stack_begin and \\\n##                   stack_begin <= reg_value <= stack_end:\n##                      continue\n            reg_data = aProcess.peek(reg_value, peekSize)\n            if reg_data:\n                data[reg_name] = reg_data\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef peek_pointers_in_data(self, data, peekSize = 16, peekStep = 1):\n        aProcess = self.get_process()\n        return aProcess.peek_pointers_in_data(data, peekSize, peekStep)", "response": "Given a binary data string and a size of 16 and a step of size 1 reads some data from them and returns a dictionary mapping stack offsets to the data they point to."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef disassemble_string(self, lpAddress, code):\n        aProcess = self.get_process()\n        return aProcess.disassemble_string(lpAddress, code)", "response": "Disassemble instructions from a block of binary code."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndisassembles the binary code from the memory of the process.", "response": "def disassemble(self, lpAddress, dwSize):\n        \"\"\"\n        Disassemble instructions from the address space of the process.\n\n        @type  lpAddress: int\n        @param lpAddress: Memory address where to read the code from.\n\n        @type  dwSize: int\n        @param dwSize: Size of binary code to disassemble.\n\n        @rtype:  list of tuple( long, int, str, str )\n        @return: List of tuples. Each tuple represents an assembly instruction\n            and contains:\n             - Memory address of instruction.\n             - Size of instruction in bytes.\n             - Disassembly line of instruction.\n             - Hexadecimal dump of instruction.\n        \"\"\"\n        aProcess = self.get_process()\n        return aProcess.disassemble(lpAddress, dwSize)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisassemble the code from the given memory address and return a list of tuples.", "response": "def disassemble_around(self, lpAddress, dwSize = 64):\n        \"\"\"\n        Disassemble around the given address.\n\n        @type  lpAddress: int\n        @param lpAddress: Memory address where to read the code from.\n\n        @type  dwSize: int\n        @param dwSize: Delta offset.\n            Code will be read from lpAddress - dwSize to lpAddress + dwSize.\n\n        @rtype:  list of tuple( long, int, str, str )\n        @return: List of tuples. Each tuple represents an assembly instruction\n            and contains:\n             - Memory address of instruction.\n             - Size of instruction in bytes.\n             - Disassembly line of instruction.\n             - Hexadecimal dump of instruction.\n        \"\"\"\n        aProcess = self.get_process()\n        return aProcess.disassemble_around(lpAddress, dwSize)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisassemble the instruction at the given PC.", "response": "def disassemble_around_pc(self, dwSize = 64):\n        \"\"\"\n        Disassemble around the program counter of the given thread.\n\n        @type  dwSize: int\n        @param dwSize: Delta offset.\n            Code will be read from pc - dwSize to pc + dwSize.\n\n        @rtype:  list of tuple( long, int, str, str )\n        @return: List of tuples. Each tuple represents an assembly instruction\n            and contains:\n             - Memory address of instruction.\n             - Size of instruction in bytes.\n             - Disassembly line of instruction.\n             - Hexadecimal dump of instruction.\n        \"\"\"\n        aProcess = self.get_process()\n        return aProcess.disassemble_around(self.get_pc(), dwSize)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the Thread object with the given global ID.", "response": "def get_thread(self, dwThreadId):\n        \"\"\"\n        @type  dwThreadId: int\n        @param dwThreadId: Global ID of the thread to look for.\n\n        @rtype:  L{Thread}\n        @return: Thread object with the given global ID.\n        \"\"\"\n        self.__initialize_snapshot()\n        if dwThreadId not in self.__threadDict:\n            msg = \"Unknown thread ID: %d\" % dwThreadId\n            raise KeyError(msg)\n        return self.__threadDict[dwThreadId]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding threads by name using different search methods.", "response": "def find_threads_by_name(self, name, bExactMatch = True):\n        \"\"\"\n        Find threads by name, using different search methods.\n\n        @type  name: str, None\n        @param name: Name to look for. Use C{None} to find nameless threads.\n\n        @type  bExactMatch: bool\n        @param bExactMatch: C{True} if the name must be\n            B{exactly} as given, C{False} if the name can be\n            loosely matched.\n\n            This parameter is ignored when C{name} is C{None}.\n\n        @rtype:  list( L{Thread} )\n        @return: All threads matching the given name.\n        \"\"\"\n        found_threads = list()\n\n        # Find threads with no name.\n        if name is None:\n            for aThread in self.iter_threads():\n                if aThread.get_name() is None:\n                    found_threads.append(aThread)\n\n        # Find threads matching the given name exactly.\n        elif bExactMatch:\n            for aThread in self.iter_threads():\n                if aThread.get_name() == name:\n                    found_threads.append(aThread)\n\n        # Find threads whose names match the given substring.\n        else:\n            for aThread in self.iter_threads():\n                t_name = aThread.get_name()\n                if t_name is not None and name in t_name:\n                    found_threads.append(aThread)\n\n        return found_threads"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new thread in the process.", "response": "def start_thread(self, lpStartAddress, lpParameter=0,  bSuspended = False):\n        \"\"\"\n        Remotely creates a new thread in the process.\n\n        @type  lpStartAddress: int\n        @param lpStartAddress: Start address for the new thread.\n\n        @type  lpParameter: int\n        @param lpParameter: Optional argument for the new thread.\n\n        @type  bSuspended: bool\n        @param bSuspended: C{True} if the new thread should be suspended.\n            In that case use L{Thread.resume} to start execution.\n        \"\"\"\n        if bSuspended:\n            dwCreationFlags = win32.CREATE_SUSPENDED\n        else:\n            dwCreationFlags = 0\n        hProcess = self.get_handle( win32.PROCESS_CREATE_THREAD     |\n                                    win32.PROCESS_QUERY_INFORMATION |\n                                    win32.PROCESS_VM_OPERATION      |\n                                    win32.PROCESS_VM_WRITE          |\n                                    win32.PROCESS_VM_READ           )\n        hThread, dwThreadId = win32.CreateRemoteThread(\n                hProcess, 0, 0, lpStartAddress, lpParameter, dwCreationFlags)\n        aThread = Thread(dwThreadId, hThread, self)\n        self._add_thread(aThread)\n        return aThread"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scan_threads(self):\n\n        # Ignore special process IDs.\n        # PID 0: System Idle Process. Also has a special meaning to the\n        #        toolhelp APIs (current process).\n        # PID 4: System Integrity Group. See this forum post for more info:\n        #        http://tinyurl.com/ycza8jo\n        #        (points to social.technet.microsoft.com)\n        #        Only on XP and above\n        # PID 8: System (?) only in Windows 2000 and below AFAIK.\n        #        It's probably the same as PID 4 in XP and above.\n        dwProcessId = self.get_pid()\n        if dwProcessId in (0, 4, 8):\n            return\n\n##        dead_tids   = set( self.get_thread_ids() ) # XXX triggers a scan\n        dead_tids   = self._get_thread_ids()\n        dwProcessId = self.get_pid()\n        hSnapshot   = win32.CreateToolhelp32Snapshot(win32.TH32CS_SNAPTHREAD,\n                                                                 dwProcessId)\n        try:\n            te = win32.Thread32First(hSnapshot)\n            while te is not None:\n                if te.th32OwnerProcessID == dwProcessId:\n                    dwThreadId = te.th32ThreadID\n                    if dwThreadId in dead_tids:\n                        dead_tids.remove(dwThreadId)\n##                    if not self.has_thread(dwThreadId): # XXX triggers a scan\n                    if not self._has_thread_id(dwThreadId):\n                        aThread = Thread(dwThreadId, process = self)\n                        self._add_thread(aThread)\n                te = win32.Thread32Next(hSnapshot)\n        finally:\n            win32.CloseHandle(hSnapshot)\n        for tid in dead_tids:\n            self._del_thread(tid)", "response": "Populates the snapshot with running threads."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear_dead_threads(self):\n        for tid in self.get_thread_ids():\n            aThread = self.get_thread(tid)\n            if not aThread.is_alive():\n                self._del_thread(aThread)", "response": "Remove Thread objects from the snapshot\n        referring to threads no longer running."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clear_threads(self):\n        for aThread in compat.itervalues(self.__threadDict):\n            aThread.clear()\n        self.__threadDict = dict()", "response": "Clears the threads snapshot."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nclosing all open handles to threads in the snapshot.", "response": "def close_thread_handles(self):\n        \"\"\"\n        Closes all open handles to threads in the snapshot.\n        \"\"\"\n        for aThread in self.iter_threads():\n            try:\n                aThread.close_handle()\n            except Exception:\n                try:\n                    e = sys.exc_info()[1]\n                    msg = \"Cannot close thread handle %s, reason: %s\"\n                    msg %= (aThread.hThread.value, str(e))\n                    warnings.warn(msg)\n                except Exception:\n                    pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _notify_exit_thread(self, event):\n        dwThreadId = event.get_tid()\n##        if self.has_thread(dwThreadId):   # XXX this would trigger a scan\n        if self._has_thread_id(dwThreadId):\n            self._del_thread(dwThreadId)\n        return True", "response": "Notify the user - defined handle of the termination of a thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmodifies the new lines of a node.", "response": "def _modify_new_lines(code_to_modify, offset, code_to_insert):\n    \"\"\"\n    Update new lines: the bytecode inserted should be the last instruction of the previous line.\n    :return: bytes sequence of code with updated lines offsets\n    \"\"\"\n    # There's a nice overview of co_lnotab in\n    # https://github.com/python/cpython/blob/3.6/Objects/lnotab_notes.txt\n\n    new_list = list(code_to_modify.co_lnotab)\n    if not new_list:\n        # Could happen on a lambda (in this case, a breakpoint in the lambda should fallback to\n        # tracing).\n        return None\n\n    # As all numbers are relative, what we want is to hide the code we inserted in the previous line\n    # (it should be the last thing right before we increment the line so that we have a line event\n    # right after the inserted code).\n    bytecode_delta = len(code_to_insert)\n\n    byte_increments = code_to_modify.co_lnotab[0::2]\n    line_increments = code_to_modify.co_lnotab[1::2]\n\n    if offset == 0:\n        new_list[0] += bytecode_delta\n    else:\n        addr = 0\n        it = zip(byte_increments, line_increments)\n        for i, (byte_incr, _line_incr) in enumerate(it):\n            addr += byte_incr\n            if addr == offset:\n                new_list[i * 2] += bytecode_delta\n                break\n\n    return bytes(new_list)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nyields the tuple of the code and the extended_arg.", "response": "def _unpack_opargs(code, inserted_code_list, current_index):\n    \"\"\"\n    Modified version of `_unpack_opargs` function from module `dis`.\n    We have to use it, because sometimes code can be in an inconsistent state: if EXTENDED_ARG\n    operator was introduced into the code, but it hasn't been inserted into `code_list` yet.\n    In this case we can't use standard `_unpack_opargs` and we should check whether there are\n    some new operators in `inserted_code_list`.\n    \"\"\"\n    extended_arg = 0\n    for i in range(0, len(code), 2):\n        op = code[i]\n        if op >= HAVE_ARGUMENT:\n            if not extended_arg:\n                # in case if we added EXTENDED_ARG, but haven't inserted it to the source code yet.\n                for code_index in range(current_index, len(inserted_code_list)):\n                    inserted_offset, inserted_code = inserted_code_list[code_index]\n                    if inserted_offset == i and inserted_code[0] == EXTENDED_ARG:\n                        extended_arg = inserted_code[1] << 8\n            arg = code[i + 1] | extended_arg\n            extended_arg = (arg << 8) if op == EXTENDED_ARG else 0\n        else:\n            arg = None\n        yield (i, op, arg)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the labels for relative and absolute jump targets.", "response": "def _update_label_offsets(code_obj, breakpoint_offset, breakpoint_code_list):\n    \"\"\"\n    Update labels for the relative and absolute jump targets\n    :param code_obj: code to modify\n    :param breakpoint_offset: offset for the inserted code\n    :param breakpoint_code_list: size of the inserted code\n    :return: bytes sequence with modified labels; list of tuples (resulting offset, list of code instructions) with\n    information about all inserted pieces of code\n    \"\"\"\n    inserted_code = list()\n    # the list with all inserted pieces of code\n    inserted_code.append((breakpoint_offset, breakpoint_code_list))\n    code_list = list(code_obj)\n    j = 0\n\n    while j < len(inserted_code):\n        current_offset, current_code_list = inserted_code[j]\n        offsets_for_modification = []\n\n        for offset, op, arg in _unpack_opargs(code_list, inserted_code, j):\n            if arg is not None:\n                if op in dis.hasjrel:\n                    # has relative jump target\n                    label = offset + 2 + arg\n                    if offset < current_offset < label:\n                        # change labels for relative jump targets if code was inserted inside\n                        offsets_for_modification.append(offset)\n                elif op in dis.hasjabs:\n                    # change label for absolute jump if code was inserted before it\n                    if current_offset < arg:\n                        offsets_for_modification.append(offset)\n        for i in range(0, len(code_list), 2):\n            op = code_list[i]\n            if i in offsets_for_modification and op >= dis.HAVE_ARGUMENT:\n                new_arg = code_list[i + 1] + len(current_code_list)\n                if new_arg <= MAX_BYTE:\n                    code_list[i + 1] = new_arg\n                else:\n                    # handle bytes overflow\n                    if i - 2 > 0 and code_list[i - 2] == EXTENDED_ARG and code_list[i - 1] < MAX_BYTE:\n                        # if new argument > 255 and EXTENDED_ARG already exists we need to increase it's argument\n                        code_list[i - 1] += 1\n                    else:\n                        # if there isn't EXTENDED_ARG operator yet we have to insert the new operator\n                        extended_arg_code = [EXTENDED_ARG, new_arg >> 8]\n                        inserted_code.append((i, extended_arg_code))\n                    code_list[i + 1] = new_arg & MAX_BYTE\n\n        code_list = code_list[:current_offset] + current_code_list + code_list[current_offset:]\n\n        for k in range(len(inserted_code)):\n            offset, inserted_code_list = inserted_code[k]\n            if current_offset < offset:\n                inserted_code[k] = (offset + len(current_code_list), inserted_code_list)\n        j += 1\n\n    return bytes(code_list), inserted_code"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a jump instruction to the base code.", "response": "def add_jump_instruction(jump_arg, code_to_insert):\n    \"\"\"\n    Note: although it's adding a POP_JUMP_IF_TRUE, it's actually no longer used now\n    (we could only return the return and possibly the load of the 'None' before the\n    return -- not done yet because it needs work to fix all related tests).\n    \"\"\"\n    extended_arg_list = []\n    if jump_arg > MAX_BYTE:\n        extended_arg_list += [EXTENDED_ARG, jump_arg >> 8]\n        jump_arg = jump_arg & MAX_BYTE\n\n    # remove 'RETURN_VALUE' instruction and add 'POP_JUMP_IF_TRUE' with (if needed) 'EXTENDED_ARG'\n    return list(code_to_insert.co_code[:-RETURN_VALUE_SIZE]) + extended_arg_list + [opmap['POP_JUMP_IF_TRUE'], jump_arg]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninserting code into the current code object.", "response": "def insert_code(code_to_modify, code_to_insert, before_line, all_lines_with_breaks=()):\n    '''\n    :param all_lines_with_breaks:\n        tuple(int) a tuple with all the breaks in the given code object (this method is expected\n        to be called multiple times with different lines to add multiple breakpoints, so, the\n        variable `before_line` should have the current breakpoint an the all_lines_with_breaks\n        should have all the breakpoints added so far (including the `before_line`).\n    '''\n    if not all_lines_with_breaks:\n        # Backward-compatibility with signature which received only one line.\n        all_lines_with_breaks = (before_line,)\n\n    # The cache is needed for generator functions, because after each yield a new frame\n    # is created but the former code object is used (so, check if code_to_modify is\n    # already there and if not cache based on the new code generated).\n\n    # print('inserting code', before_line, all_lines_with_breaks)\n    # dis.dis(code_to_modify)\n\n    ok_and_new_code = _created.get((code_to_modify, all_lines_with_breaks))\n    if ok_and_new_code is not None:\n        return ok_and_new_code\n\n    ok, new_code = _insert_code(code_to_modify, code_to_insert, before_line)\n\n    # print('insert code ok', ok)\n    # dis.dis(new_code)\n\n    # Note: caching with new code!\n    cache_key = new_code, all_lines_with_breaks\n    _created[cache_key] = (ok, new_code)\n    return _created[cache_key]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _insert_code(code_to_modify, code_to_insert, before_line):\n    linestarts = dict(dis.findlinestarts(code_to_modify))\n    if not linestarts:\n        return False, code_to_modify\n\n    if code_to_modify.co_name == '<module>':\n        # There's a peculiarity here: if a breakpoint is added in the first line of a module, we\n        # can't replace the code because we require a line event to stop and the line event\n        # was already generated, so, fallback to tracing.\n        if before_line == min(linestarts.values()):\n            return False, code_to_modify\n\n    if before_line not in linestarts.values():\n        return False, code_to_modify\n\n    offset = None\n    for off, line_no in linestarts.items():\n        if line_no == before_line:\n            offset = off\n            break\n\n    code_to_insert_list = add_jump_instruction(offset, code_to_insert)\n    try:\n        code_to_insert_list, new_names = \\\n            _add_attr_values_from_insert_to_original(code_to_modify, code_to_insert, code_to_insert_list, 'co_names',\n                                                     dis.hasname)\n        code_to_insert_list, new_consts = \\\n            _add_attr_values_from_insert_to_original(code_to_modify, code_to_insert, code_to_insert_list, 'co_consts',\n                                                     [opmap['LOAD_CONST']])\n        code_to_insert_list, new_vars = \\\n            _add_attr_values_from_insert_to_original(code_to_modify, code_to_insert, code_to_insert_list, 'co_varnames',\n                                                     dis.haslocal)\n        new_bytes, all_inserted_code = _update_label_offsets(code_to_modify.co_code, offset, list(code_to_insert_list))\n\n        new_lnotab = _modify_new_lines(code_to_modify, offset, code_to_insert_list)\n        if new_lnotab is None:\n            return False, code_to_modify\n\n    except ValueError:\n        pydev_log.exception()\n        return False, code_to_modify\n\n    new_code = CodeType(\n        code_to_modify.co_argcount,  # integer\n        code_to_modify.co_kwonlyargcount,  # integer\n        len(new_vars),  # integer\n        code_to_modify.co_stacksize,  # integer\n        code_to_modify.co_flags,  # integer\n        new_bytes,  # bytes\n        new_consts,  # tuple\n        new_names,  # tuple\n        new_vars,  # tuple\n        code_to_modify.co_filename,  # string\n        code_to_modify.co_name,  # string\n        code_to_modify.co_firstlineno,  # integer\n        new_lnotab,  # bytes\n        code_to_modify.co_freevars,  # tuple\n        code_to_modify.co_cellvars  # tuple\n    )\n    return True, new_code", "response": "Insert piece of code code_to_insert to code_to_modify right inside the line before_line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __get_pid_and_tid(self):\n        \"Internally used by get_pid() and get_tid().\"\n        self.dwThreadId, self.dwProcessId = \\\n                            win32.GetWindowThreadProcessId(self.get_handle())", "response": "Internally used by get_pid and get_tid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_thread(self, thread = None):\n        if thread is None:\n            self.__thread = None\n        else:\n            self.__load_Thread_class()\n            if not isinstance(thread, Thread):\n                msg  = \"Parent thread must be a Thread instance, \"\n                msg += \"got %s instead\" % type(thread)\n                raise TypeError(msg)\n            self.dwThreadId = thread.get_tid()\n            self.__thread = thread", "response": "Manually set the thread process. Use with care!"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the window s client area coordinates in the desktop.", "response": "def get_client_rect(self):\n        \"\"\"\n        Get the window's client area coordinates in the desktop.\n\n        @rtype:  L{win32.Rect}\n        @return: Rectangle occupied by the window's client area in the desktop.\n\n        @raise WindowsError: An error occured while processing this request.\n        \"\"\"\n        cr = win32.GetClientRect( self.get_handle() )\n        cr.left, cr.top     = self.client_to_screen(cr.left, cr.top)\n        cr.right, cr.bottom = self.client_to_screen(cr.right, cr.bottom)\n        return cr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef client_to_screen(self, x, y):\n        return tuple( win32.ClientToScreen( self.get_handle(), (x, y) ) )", "response": "Translate the client coordinates to screen coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntranslates the screen coordinates to client coordinates.", "response": "def screen_to_client(self, x, y):\n        \"\"\"\n        Translates window screen coordinates to client coordinates.\n\n        @note: This is a simplified interface to some of the functionality of\n            the L{win32.Point} class.\n\n        @see: {win32.Point.screen_to_client}\n\n        @type  x: int\n        @param x: Horizontal coordinate.\n        @type  y: int\n        @param y: Vertical coordinate.\n\n        @rtype:  tuple( int, int )\n        @return: Translated coordinates in a tuple (x, y).\n\n        @raise WindowsError: An error occured while processing this request.\n        \"\"\"\n        return tuple( win32.ScreenToClient( self.get_handle(), (x, y) ) )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the child window located at the given coordinates.", "response": "def get_child_at(self, x, y, bAllowTransparency = True):\n        \"\"\"\n        Get the child window located at the given coordinates. If no such\n        window exists an exception is raised.\n\n        @see: L{get_children}\n\n        @type  x: int\n        @param x: Horizontal coordinate.\n\n        @type  y: int\n        @param y: Vertical coordinate.\n\n        @type  bAllowTransparency: bool\n        @param bAllowTransparency: If C{True} transparent areas in windows are\n            ignored, returning the window behind them. If C{False} transparent\n            areas are treated just like any other area.\n\n        @rtype:  L{Window}\n        @return: Child window at the requested position, or C{None} if there\n            is no window at those coordinates.\n        \"\"\"\n        try:\n            if bAllowTransparency:\n                hWnd = win32.RealChildWindowFromPoint( self.get_handle(), (x, y) )\n            else:\n                hWnd = win32.ChildWindowFromPoint( self.get_handle(), (x, y) )\n            if hWnd:\n                return self.__get_window(hWnd)\n        except WindowsError:\n            pass\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef show(self, bAsync = True):\n        if bAsync:\n            win32.ShowWindowAsync( self.get_handle(), win32.SW_SHOW )\n        else:\n            win32.ShowWindow( self.get_handle(), win32.SW_SHOW )", "response": "Make the window visible."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake the window invisible.", "response": "def hide(self, bAsync = True):\n        \"\"\"\n        Make the window invisible.\n\n        @see: L{show}\n\n        @type  bAsync: bool\n        @param bAsync: Perform the request asynchronously.\n\n        @raise WindowsError: An error occured while processing this request.\n        \"\"\"\n        if bAsync:\n            win32.ShowWindowAsync( self.get_handle(), win32.SW_HIDE )\n        else:\n            win32.ShowWindow( self.get_handle(), win32.SW_HIDE )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef maximize(self, bAsync = True):\n        if bAsync:\n            win32.ShowWindowAsync( self.get_handle(), win32.SW_MAXIMIZE )\n        else:\n            win32.ShowWindow( self.get_handle(), win32.SW_MAXIMIZE )", "response": "Maximize the window.\n\n        @see: L{minimize}, L{restore}\n\n        @type  bAsync: bool\n        @param bAsync: Perform the request asynchronously.\n\n        @raise WindowsError: An error occured while processing this request."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef minimize(self, bAsync = True):\n        if bAsync:\n            win32.ShowWindowAsync( self.get_handle(), win32.SW_MINIMIZE )\n        else:\n            win32.ShowWindow( self.get_handle(), win32.SW_MINIMIZE )", "response": "Minimize the window.\n\n        @see: L{maximize}, L{restore}\n\n        @type  bAsync: bool\n        @param bAsync: Perform the request asynchronously.\n\n        @raise WindowsError: An error occured while processing this request."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef restore(self, bAsync = True):\n        if bAsync:\n            win32.ShowWindowAsync( self.get_handle(), win32.SW_RESTORE )\n        else:\n            win32.ShowWindow( self.get_handle(), win32.SW_RESTORE )", "response": "Unmaximize and unminimize the window."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmoves or resizes the window.", "response": "def move(self, x = None, y = None, width = None, height = None,\n                                                            bRepaint = True):\n        \"\"\"\n        Moves and/or resizes the window.\n\n        @note: This is request is performed syncronously.\n\n        @type  x: int\n        @param x: (Optional) New horizontal coordinate.\n\n        @type  y: int\n        @param y: (Optional) New vertical coordinate.\n\n        @type  width: int\n        @param width: (Optional) Desired window width.\n\n        @type  height: int\n        @param height: (Optional) Desired window height.\n\n        @type  bRepaint: bool\n        @param bRepaint:\n            (Optional) C{True} if the window should be redrawn afterwards.\n\n        @raise WindowsError: An error occured while processing this request.\n        \"\"\"\n        if None in (x, y, width, height):\n            rect = self.get_screen_rect()\n            if x is None:\n                x = rect.left\n            if y is None:\n                y = rect.top\n            if width is None:\n                width = rect.right - rect.left\n            if height is None:\n                height = rect.bottom - rect.top\n        win32.MoveWindow(self.get_handle(), x, y, width, height, bRepaint)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send(self, uMsg, wParam = None, lParam = None, dwTimeout = None):\n        if dwTimeout is None:\n            return win32.SendMessage(self.get_handle(), uMsg, wParam, lParam)\n        return win32.SendMessageTimeout(\n            self.get_handle(), uMsg, wParam, lParam,\n            win32.SMTO_ABORTIFHUNG | win32.SMTO_ERRORONEXIT, dwTimeout)", "response": "Send a low - level window message syncronically."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npost a low - level window message asyncronically.", "response": "def post(self, uMsg, wParam = None, lParam = None):\n        \"\"\"\n        Post a low-level window message asyncronically.\n\n        @type  uMsg: int\n        @param uMsg: Message code.\n\n        @param wParam:\n            The type and meaning of this parameter depends on the message.\n\n        @param lParam:\n            The type and meaning of this parameter depends on the message.\n\n        @raise WindowsError: An error occured while sending the message.\n        \"\"\"\n        win32.PostMessage(self.get_handle(), uMsg, wParam, lParam)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_net_command_json(self, py_db, json_contents):\n        '''\n        Processes a debug adapter protocol json command.\n        '''\n\n        DEBUG = False\n\n        try:\n            request = self.from_json(json_contents, update_ids_from_dap=True)\n        except KeyError as e:\n            request = self.from_json(json_contents, update_ids_from_dap=False)\n            error_msg = str(e)\n            if error_msg.startswith(\"'\") and error_msg.endswith(\"'\"):\n                error_msg = error_msg[1:-1]\n\n            # This means a failure updating ids from the DAP (the client sent a key we didn't send).\n            def on_request(py_db, request):\n                error_response = {\n                    'type': 'response',\n                    'request_seq': request.seq,\n                    'success': False,\n                    'command': request.command,\n                    'message': error_msg,\n                }\n                return NetCommand(CMD_RETURN, 0, error_response, is_json=True)\n\n        else:\n            if DebugInfoHolder.DEBUG_RECORD_SOCKET_READS and DebugInfoHolder.DEBUG_TRACE_LEVEL >= 1:\n                pydev_log.info('Process %s: %s\\n' % (\n                    request.__class__.__name__, json.dumps(request.to_dict(), indent=4, sort_keys=True),))\n\n            assert request.type == 'request'\n            method_name = 'on_%s_request' % (request.command.lower(),)\n            on_request = getattr(self, method_name, None)\n            if on_request is None:\n                print('Unhandled: %s not available in _PyDevJsonCommandProcessor.\\n' % (method_name,))\n                return\n\n            if DEBUG:\n                print('Handled in pydevd: %s (in _PyDevJsonCommandProcessor).\\n' % (method_name,))\n\n        py_db._main_lock.acquire()\n        try:\n\n            cmd = on_request(py_db, request)\n            if cmd is not None:\n                py_db.writer.add_command(cmd)\n        finally:\n            py_db._main_lock.release()", "response": "Processes a debug adapter protocol json command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of the threads that have been processed by the server.", "response": "def on_threads_request(self, py_db, request):\n        '''\n        :param ThreadsRequest request:\n        '''\n        return self.api.list_threads(py_db, request.seq)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsuspends thread with the specified id", "response": "def on_pause_request(self, py_db, request):\n        '''\n        :param PauseRequest request:\n        '''\n        arguments = request.arguments  # : :type arguments: PauseArguments\n        thread_id = arguments.threadId\n\n        self.api.request_suspend_thread(py_db, thread_id=thread_id)\n\n        response = pydevd_base_schema.build_response(request)\n        return NetCommand(CMD_RETURN, 0, response, is_json=True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_continue_request(self, py_db, request):\n        '''\n        :param ContinueRequest request:\n        '''\n        arguments = request.arguments  # : :type arguments: ContinueArguments\n        thread_id = arguments.threadId\n\n        def on_resumed():\n            body = {'allThreadsContinued': thread_id == '*'}\n            response = pydevd_base_schema.build_response(request, kwargs={'body': body})\n            cmd = NetCommand(CMD_RETURN, 0, response, is_json=True)\n            py_db.writer.add_command(cmd)\n\n        # Only send resumed notification when it has actually resumed!\n        # (otherwise the user could send a continue, receive the notification and then\n        # request a new pause which would be paused without sending any notification as\n        # it didn't really run in the first place).\n        py_db.threads_suspended_single_notification.add_on_resumed_callback(on_resumed)\n        self.api.request_resume_thread(thread_id)", "response": "Handle a continue request."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_stepin_request(self, py_db, request):\n        '''\n        :param StepInRequest request:\n        '''\n        arguments = request.arguments  # : :type arguments: StepInArguments\n        thread_id = arguments.threadId\n\n        if py_db.get_use_libraries_filter():\n            step_cmd_id = CMD_STEP_INTO_MY_CODE\n        else:\n            step_cmd_id = CMD_STEP_INTO\n\n        self.api.request_step(py_db, thread_id, step_cmd_id)\n\n        response = pydevd_base_schema.build_response(request)\n        return NetCommand(CMD_RETURN, 0, response, is_json=True)", "response": "This function is called when a step in request is received."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_stepout_request(self, py_db, request):\n        '''\n        :param StepOutRequest request:\n        '''\n        arguments = request.arguments  # : :type arguments: StepOutArguments\n        thread_id = arguments.threadId\n\n        if py_db.get_use_libraries_filter():\n            step_cmd_id = CMD_STEP_RETURN_MY_CODE\n        else:\n            step_cmd_id = CMD_STEP_RETURN\n\n        self.api.request_step(py_db, thread_id, step_cmd_id)\n\n        response = pydevd_base_schema.build_response(request)\n        return NetCommand(CMD_RETURN, 0, response, is_json=True)", "response": "This function is called when a step out request is received."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_hit_condition_expression(self, hit_condition):\n        '''Following hit condition values are supported\n\n        * x or == x when breakpoint is hit x times\n        * >= x when breakpoint is hit more than or equal to x times\n        * % x when breakpoint is hit multiple of x times\n\n        Returns '@HIT@ == x' where @HIT@ will be replaced by number of hits\n        '''\n        if not hit_condition:\n            return None\n\n        expr = hit_condition.strip()\n        try:\n            int(expr)\n            return '@HIT@ == {}'.format(expr)\n        except ValueError:\n            pass\n\n        if expr.startswith('%'):\n            return '@HIT@ {} == 0'.format(expr)\n\n        if expr.startswith('==') or \\\n            expr.startswith('>') or \\\n            expr.startswith('<'):\n            return '@HIT@ {}'.format(expr)\n\n        return hit_condition", "response": "Returns the expression that should be used to evaluate the hit condition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_disconnect_request(self, py_db, request):\n        '''\n        :param DisconnectRequest request:\n        '''\n        self.api.set_enable_thread_notifications(py_db, False)\n        self.api.remove_all_breakpoints(py_db, filename='*')\n        self.api.remove_all_exception_breakpoints(py_db)\n        self.api.request_resume_thread(thread_id='*')\n\n        response = pydevd_base_schema.build_response(request)\n        return NetCommand(CMD_RETURN, 0, response, is_json=True)", "response": "Called when a disconnect request is received."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_setbreakpoints_request(self, py_db, request):\n        '''\n        :param SetBreakpointsRequest request:\n        '''\n        arguments = request.arguments  # : :type arguments: SetBreakpointsArguments\n        # TODO: Path is optional here it could be source reference.\n        filename = arguments.source.path\n        filename = self.api.filename_to_server(filename)\n        func_name = 'None'\n\n        self.api.remove_all_breakpoints(py_db, filename)\n\n        # Validate breakpoints and adjust their positions.\n        try:\n            lines = sorted(_get_code_lines(filename))\n        except Exception:\n            pass\n        else:\n            for bp in arguments.breakpoints:\n                line = bp['line']\n                if line not in lines:\n                    # Adjust to the first preceding valid line.\n                    idx = bisect.bisect_left(lines, line)\n                    if idx > 0:\n                        bp['line'] = lines[idx - 1]\n\n        btype = 'python-line'\n        suspend_policy = 'ALL'\n\n        if not filename.lower().endswith('.py'):\n            if self._debug_options.get('DJANGO_DEBUG', False):\n                btype = 'django-line'\n            elif self._debug_options.get('FLASK_DEBUG', False):\n                btype = 'jinja2-line'\n\n        breakpoints_set = []\n\n        for source_breakpoint in arguments.breakpoints:\n            source_breakpoint = SourceBreakpoint(**source_breakpoint)\n            line = source_breakpoint.line\n            condition = source_breakpoint.condition\n            breakpoint_id = line\n\n            hit_condition = self._get_hit_condition_expression(source_breakpoint.hitCondition)\n            log_message = source_breakpoint.logMessage\n            if not log_message:\n                is_logpoint = None\n                expression = None\n            else:\n                is_logpoint = True\n                expression = convert_dap_log_message_to_expression(log_message)\n\n            self.api.add_breakpoint(\n                py_db, filename, btype, breakpoint_id, line, condition, func_name, expression, suspend_policy, hit_condition, is_logpoint)\n\n            # Note that the id is made up (the id for pydevd is unique only within a file, so, the\n            # line is used for it).\n            # Also, the id is currently not used afterwards, so, we don't even keep a mapping.\n            breakpoints_set.append({'id': self._next_breakpoint_id(), 'verified': True, 'line': line})\n\n        body = {'breakpoints': breakpoints_set}\n        set_breakpoints_response = pydevd_base_schema.build_response(request, kwargs={'body': body})\n        return NetCommand(CMD_RETURN, 0, set_breakpoints_response, is_json=True)", "response": "Handles the SetBreakpointsRequest event."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_setexceptionbreakpoints_request(self, py_db, request):\n        '''\n        :param SetExceptionBreakpointsRequest request:\n        '''\n        # : :type arguments: SetExceptionBreakpointsArguments\n        arguments = request.arguments\n        filters = arguments.filters\n        exception_options = arguments.exceptionOptions\n        self.api.remove_all_exception_breakpoints(py_db)\n\n        # Can't set these in the DAP.\n        condition = None\n        expression = None\n        notify_on_first_raise_only = False\n\n        ignore_libraries = 1 if py_db.get_use_libraries_filter() else 0\n\n        if exception_options:\n            break_raised = True\n            break_uncaught = True\n\n            for option in exception_options:\n                option = ExceptionOptions(**option)\n                if not option.path:\n                    continue\n\n                notify_on_handled_exceptions = 1 if option.breakMode == 'always' else 0\n                notify_on_unhandled_exceptions = 1 if option.breakMode in ('unhandled', 'userUnhandled') else 0\n                exception_paths = option.path\n\n                exception_names = []\n                if len(exception_paths) == 0:\n                    continue\n\n                elif len(exception_paths) == 1:\n                    if 'Python Exceptions' in exception_paths[0]['names']:\n                        exception_names = ['BaseException']\n\n                else:\n                    path_iterator = iter(exception_paths)\n                    if 'Python Exceptions' in next(path_iterator)['names']:\n                        for path in path_iterator:\n                            for ex_name in path['names']:\n                                exception_names.append(ex_name)\n\n                for exception_name in exception_names:\n                    self.api.add_python_exception_breakpoint(\n                        py_db,\n                        exception_name,\n                        condition,\n                        expression,\n                        notify_on_handled_exceptions,\n                        notify_on_unhandled_exceptions,\n                        notify_on_first_raise_only,\n                        ignore_libraries\n                    )\n\n        else:\n            break_raised = 'raised' in filters\n            break_uncaught = 'uncaught' in filters\n            if break_raised or break_uncaught:\n                notify_on_handled_exceptions = 1 if break_raised else 0\n                notify_on_unhandled_exceptions = 1 if break_uncaught else 0\n                exception = 'BaseException'\n\n                self.api.add_python_exception_breakpoint(\n                    py_db,\n                    exception,\n                    condition,\n                    expression,\n                    notify_on_handled_exceptions,\n                    notify_on_unhandled_exceptions,\n                    notify_on_first_raise_only,\n                    ignore_libraries\n                )\n\n        if break_raised or break_uncaught:\n            btype = None\n            if self._debug_options.get('DJANGO_DEBUG', False):\n                btype = 'django'\n            elif self._debug_options.get('FLASK_DEBUG', False):\n                btype = 'jinja2'\n\n            if btype:\n                self.api.add_plugins_exception_breakpoint(\n                    py_db, btype, 'BaseException')  # Note: Exception name could be anything here.\n\n        # Note: no body required on success.\n        set_breakpoints_response = pydevd_base_schema.build_response(request)\n        return NetCommand(CMD_RETURN, 0, set_breakpoints_response, is_json=True)", "response": "Called when the request to set exception breakpoints."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_stacktrace_request(self, py_db, request):\n        '''\n        :param StackTraceRequest request:\n        '''\n        # : :type stack_trace_arguments: StackTraceArguments\n        stack_trace_arguments = request.arguments\n        thread_id = stack_trace_arguments.threadId\n        start_frame = stack_trace_arguments.startFrame\n        levels = stack_trace_arguments.levels\n\n        fmt = stack_trace_arguments.format\n        if hasattr(fmt, 'to_dict'):\n            fmt = fmt.to_dict()\n        self.api.request_stack(py_db, request.seq, thread_id, fmt=fmt, start_frame=start_frame, levels=levels)", "response": "Called when a stack trace request is received."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_exceptioninfo_request(self, py_db, request):\n        '''\n        :param ExceptionInfoRequest request:\n        '''\n        # : :type exception_into_arguments: ExceptionInfoArguments\n        exception_into_arguments = request.arguments\n        thread_id = exception_into_arguments.threadId\n        max_frames = int(self._debug_options['args'].get('maxExceptionStackFrames', 0))\n        self.api.request_exception_info_json(py_db, request, thread_id, max_frames)", "response": "Called when an exception info request is received."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nscope are the top-level items which appear for a frame (so, we receive the frame id and provide the scopes it has). :param ScopesRequest request:", "response": "def on_scopes_request(self, py_db, request):\n        '''\n        Scopes are the top-level items which appear for a frame (so, we receive the frame id\n        and provide the scopes it has).\n\n        :param ScopesRequest request:\n        '''\n        frame_id = request.arguments.frameId\n\n        variables_reference = frame_id\n        scopes = [Scope('Locals', int(variables_reference), False).to_dict()]\n        body = ScopesResponseBody(scopes)\n        scopes_response = pydevd_base_schema.build_response(request, kwargs={'body':body})\n        return NetCommand(CMD_RETURN, 0, scopes_response, is_json=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nevaluates the object in the context of the current thread.", "response": "def on_evaluate_request(self, py_db, request):\n        '''\n        :param EvaluateRequest request:\n        '''\n        # : :type arguments: EvaluateArguments\n        arguments = request.arguments\n\n        thread_id = py_db.suspended_frames_manager.get_thread_id_for_variable_reference(\n            arguments.frameId)\n\n        self.api.request_exec_or_evaluate_json(\n            py_db, request, thread_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef inputhook_wx1():\n    try:\n        app = wx.GetApp()  # @UndefinedVariable\n        if app is not None:\n            assert wx.Thread_IsMain()  # @UndefinedVariable\n\n            # Make a temporary event loop and process system events until\n            # there are no more waiting, then allow idle events (which\n            # will also deal with pending or posted wx events.)\n            evtloop = wx.EventLoop()  # @UndefinedVariable\n            ea = wx.EventLoopActivator(evtloop)  # @UndefinedVariable\n            while evtloop.Pending():\n                evtloop.Dispatch()\n            app.ProcessIdle()\n            del ea\n    except KeyboardInterrupt:\n        pass\n    return 0", "response": "Run the wx event loop by processing pending events only."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef inputhook_wx2():\n    try:\n        app = wx.GetApp()  # @UndefinedVariable\n        if app is not None:\n            assert wx.Thread_IsMain()  # @UndefinedVariable\n            elr = EventLoopRunner()\n            # As this time is made shorter, keyboard response improves, but idle\n            # CPU load goes up.  10 ms seems like a good compromise.\n            elr.Run(time=10)  # CHANGE time here to control polling interval\n    except KeyboardInterrupt:\n        pass\n    return 0", "response": "This version runs the wx event loop polling for stdin."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inputhook_wx3():\n    # We need to protect against a user pressing Control-C when IPython is\n    # idle and this is running. We trap KeyboardInterrupt and pass.\n    try:\n        app = wx.GetApp()  # @UndefinedVariable\n        if app is not None:\n            assert wx.Thread_IsMain()  # @UndefinedVariable\n\n            # The import of wx on Linux sets the handler for signal.SIGINT\n            # to 0.  This is a bug in wx or gtk.  We fix by just setting it\n            # back to the Python default.\n            if not callable(signal.getsignal(signal.SIGINT)):\n                signal.signal(signal.SIGINT, signal.default_int_handler)\n\n            evtloop = wx.EventLoop()  # @UndefinedVariable\n            ea = wx.EventLoopActivator(evtloop)  # @UndefinedVariable\n            t = clock()\n            while not stdin_ready():\n                while evtloop.Pending():\n                    t = clock()\n                    evtloop.Dispatch()\n                app.ProcessIdle()\n                # We need to sleep at this point to keep the idle CPU load\n                # low.  However, if sleep to long, GUI response is poor.  As\n                # a compromise, we watch how often GUI events are being processed\n                # and switch between a short and long sleep time.  Here are some\n                # stats useful in helping to tune this.\n                # time    CPU load\n                # 0.001   13%\n                # 0.005   3%\n                # 0.01    1.5%\n                # 0.05    0.5%\n                used_time = clock() - t\n                if used_time > 10.0:\n                    # print 'Sleep for 1 s'  # dbg\n                    time.sleep(1.0)\n                elif used_time > 0.1:\n                    # Few GUI events coming in, so we can sleep longer\n                    # print 'Sleep for 0.05 s'  # dbg\n                    time.sleep(0.05)\n                else:\n                    # Many GUI events coming in, so sleep only very little\n                    time.sleep(0.001)\n            del ea\n    except KeyboardInterrupt:\n        pass\n    return 0", "response": "Run wx event loop by processing pending events and dispatching them to the wx event loop."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a plausible module name for the path", "response": "def _modname(path):\n    \"\"\"Return a plausible module name for the path\"\"\"\n    base = os.path.basename(path)\n    filename, ext = os.path.splitext(base)\n    return filename"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_custom_frame(frame, name, thread_id):\n    '''\n    It's possible to show paused frames by adding a custom frame through this API (it's\n    intended to be used for coroutines, but could potentially be used for generators too).\n\n    :param frame:\n        The topmost frame to be shown paused when a thread with thread.ident == thread_id is paused.\n\n    :param name:\n        The name to be shown for the custom thread in the UI.\n\n    :param thread_id:\n        The thread id to which this frame is related (must match thread.ident).\n\n    :return: str\n        Returns the custom thread id which will be used to show the given frame paused.\n    '''\n    with CustomFramesContainer.custom_frames_lock:\n        curr_thread_id = get_current_thread_id(threading.currentThread())\n        next_id = CustomFramesContainer._next_frame_id = CustomFramesContainer._next_frame_id + 1\n\n        # Note: the frame id kept contains an id and thread information on the thread where the frame was added\n        # so that later on we can check if the frame is from the current thread by doing frame_id.endswith('|'+thread_id).\n        frame_custom_thread_id = '__frame__:%s|%s' % (next_id, curr_thread_id)\n        if DEBUG:\n            sys.stderr.write('add_custom_frame: %s (%s) %s %s\\n' % (\n                frame_custom_thread_id, get_abs_path_real_path_and_base_from_frame(frame)[-1], frame.f_lineno, frame.f_code.co_name))\n\n        CustomFramesContainer.custom_frames[frame_custom_thread_id] = CustomFrame(name, frame, thread_id)\n        CustomFramesContainer._py_db_command_thread_event.set()\n        return frame_custom_thread_id", "response": "Adds a custom frame to the internal list of custom frames."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef enable_gui(gui=None, app=None):\n\n    if get_return_control_callback() is None:\n        raise ValueError(\"A return_control_callback must be supplied as a reference before a gui can be enabled\")\n\n    guis = {GUI_NONE: clear_inputhook,\n            GUI_OSX: enable_mac,\n            GUI_TK: enable_tk,\n            GUI_GTK: enable_gtk,\n            GUI_WX: enable_wx,\n            GUI_QT: enable_qt,\n            GUI_QT4: enable_qt4,\n            GUI_QT5: enable_qt5,\n            GUI_GLUT: enable_glut,\n            GUI_PYGLET: enable_pyglet,\n            GUI_GTK3: enable_gtk3,\n            }\n    try:\n        gui_hook = guis[gui]\n    except KeyError:\n        if gui is None or gui == '':\n            gui_hook = clear_inputhook\n        else:\n            e = \"Invalid GUI request %r, valid ones are:%s\" % (gui, guis.keys())\n            raise ValueError(e)\n    return gui_hook(app)", "response": "Enables the given GUI input hook."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclearing the internal reference to an application instance.", "response": "def clear_app_refs(self, gui=None):\n        \"\"\"Clear IPython's internal reference to an application instance.\n\n        Whenever we create an app for a user on qt4 or wx, we hold a\n        reference to the app.  This is needed because in some cases bad things\n        can happen if a user doesn't hold a reference themselves.  This\n        method is provided to clear the references we are holding.\n\n        Parameters\n        ----------\n        gui : None or str\n            If None, clear all app references.  If ('wx', 'qt4') clear\n            the app for that toolkit.  References are not held for gtk or tk\n            as those toolkits don't have the notion of an app.\n        \"\"\"\n        if gui is None:\n            self._apps = {}\n        elif gui in self._apps:\n            del self._apps[gui]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef enable_gtk(self, app=None):\n        from pydev_ipython.inputhookgtk import create_inputhook_gtk\n        self.set_inputhook(create_inputhook_gtk(self._stdin_file))\n        self._current_gui = GUI_GTK", "response": "Enable event loop integration with PyGTK."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nenabling event loop integration with Tk.", "response": "def enable_tk(self, app=None):\n        \"\"\"Enable event loop integration with Tk.\n\n        Parameters\n        ----------\n        app : toplevel :class:`Tkinter.Tk` widget, optional.\n            Running toplevel widget to use.  If not given, we probe Tk for an\n            existing one, and create a new one if none is found.\n\n        Notes\n        -----\n        If you have already created a :class:`Tkinter.Tk` object, the only\n        thing done by this method is to register with the\n        :class:`InputHookManager`, since creating that object automatically\n        sets ``PyOS_InputHook``.\n        \"\"\"\n        self._current_gui = GUI_TK\n        if app is None:\n            try:\n                import Tkinter as _TK\n            except:\n                # Python 3\n                import tkinter as _TK  # @UnresolvedImport\n            app = _TK.Tk()\n            app.withdraw()\n            self._apps[GUI_TK] = app\n\n        from pydev_ipython.inputhooktk import create_inputhook_tk\n        self.set_inputhook(create_inputhook_tk(app))\n        return app"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nenabling event loop integration with GLUT.", "response": "def enable_glut(self, app=None):\n        \"\"\" Enable event loop integration with GLUT.\n\n        Parameters\n        ----------\n\n        app : ignored\n            Ignored, it's only a placeholder to keep the call signature of all\n            gui activation methods consistent, which simplifies the logic of\n            supporting magics.\n\n        Notes\n        -----\n\n        This methods sets the PyOS_InputHook for GLUT, which allows the GLUT to\n        integrate with terminal based applications like IPython. Due to GLUT\n        limitations, it is currently not possible to start the event loop\n        without first creating a window. You should thus not create another\n        window but use instead the created one. See 'gui-glut.py' in the\n        docs/examples/lib directory.\n\n        The default screen mode is set to:\n        glut.GLUT_DOUBLE | glut.GLUT_RGBA | glut.GLUT_DEPTH\n        \"\"\"\n\n        import OpenGL.GLUT as glut  # @UnresolvedImport\n        from pydev_ipython.inputhookglut import glut_display_mode, \\\n                                              glut_close, glut_display, \\\n                                              glut_idle, inputhook_glut\n\n        if GUI_GLUT not in self._apps:\n            glut.glutInit(sys.argv)\n            glut.glutInitDisplayMode(glut_display_mode)\n            # This is specific to freeglut\n            if bool(glut.glutSetOption):\n                glut.glutSetOption(glut.GLUT_ACTION_ON_WINDOW_CLOSE,\n                                    glut.GLUT_ACTION_GLUTMAINLOOP_RETURNS)\n            glut.glutCreateWindow(sys.argv[0])\n            glut.glutReshapeWindow(1, 1)\n            glut.glutHideWindow()\n            glut.glutWMCloseFunc(glut_close)\n            glut.glutDisplayFunc(glut_display)\n            glut.glutIdleFunc(glut_idle)\n        else:\n            glut.glutWMCloseFunc(glut_close)\n            glut.glutDisplayFunc(glut_display)\n            glut.glutIdleFunc(glut_idle)\n        self.set_inputhook(inputhook_glut)\n        self._current_gui = GUI_GLUT\n        self._apps[GUI_GLUT] = True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisable event loop integration with glut.", "response": "def disable_glut(self):\n        \"\"\"Disable event loop integration with glut.\n\n        This sets PyOS_InputHook to NULL and set the display function to a\n        dummy one and set the timer to a dummy timer that will be triggered\n        very far in the future.\n        \"\"\"\n        import OpenGL.GLUT as glut  # @UnresolvedImport\n        from glut_support import glutMainLoopEvent  # @UnresolvedImport\n\n        glut.glutHideWindow()  # This is an event to be processed below\n        glutMainLoopEvent()\n        self.clear_inputhook()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef enable_pyglet(self, app=None):\n        from pydev_ipython.inputhookpyglet import inputhook_pyglet\n        self.set_inputhook(inputhook_pyglet)\n        self._current_gui = GUI_PYGLET\n        return app", "response": "Enable event loop integration with pyglet."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nenabling event loop integration with Gtk3.", "response": "def enable_gtk3(self, app=None):\n        \"\"\"Enable event loop integration with Gtk3 (gir bindings).\n\n        Parameters\n        ----------\n        app : ignored\n           Ignored, it's only a placeholder to keep the call signature of all\n           gui activation methods consistent, which simplifies the logic of\n           supporting magics.\n\n        Notes\n        -----\n        This methods sets the PyOS_InputHook for Gtk3, which allows\n        the Gtk3 to integrate with terminal based applications like\n        IPython.\n        \"\"\"\n        from pydev_ipython.inputhookgtk3 import create_inputhook_gtk3\n        self.set_inputhook(create_inputhook_gtk3(self._stdin_file))\n        self._current_gui = GUI_GTK"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef enable_mac(self, app=None):\n        def inputhook_mac(app=None):\n            if self.pyplot_imported:\n                pyplot = sys.modules['matplotlib.pyplot']\n                try:\n                    pyplot.pause(0.01)\n                except:\n                    pass\n            else:\n                if 'matplotlib.pyplot' in sys.modules:\n                    self.pyplot_imported = True\n\n        self.set_inputhook(inputhook_mac)\n        self._current_gui = GUI_OSX", "response": "Enable event loop integration with MacOSX."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _thread_to_xml(self, thread):\n        name = pydevd_xml.make_valid_xml_value(thread.getName())\n        cmdText = '<thread name=\"%s\" id=\"%s\" />' % (quote(name), get_thread_id(thread))\n        return cmdText", "response": "thread information as XML"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns thread listing as XML", "response": "def make_list_threads_message(self, py_db, seq):\n        \"\"\" returns thread listing as XML \"\"\"\n        try:\n            threads = get_non_pydevd_threads()\n            cmd_text = [\"<xml>\"]\n            append = cmd_text.append\n            for thread in threads:\n                if is_thread_alive(thread):\n                    append(self._thread_to_xml(thread))\n            append(\"</xml>\")\n            return NetCommand(CMD_RETURN, seq, ''.join(cmd_text))\n        except:\n            return self.make_error_message(seq, get_exception_traceback_str())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_get_thread_stack_message(self, py_db, seq, thread_id, topmost_frame, fmt, must_be_suspended=False, start_frame=0, levels=0):\n        try:\n            # If frame is None, the return is an empty frame list.\n            cmd_text = ['<xml><thread id=\"%s\">' % (thread_id,)]\n\n            if topmost_frame is not None:\n                frame_id_to_lineno = {}\n                try:\n                    # : :type suspended_frames_manager: SuspendedFramesManager\n                    suspended_frames_manager = py_db.suspended_frames_manager\n                    info = suspended_frames_manager.get_topmost_frame_and_frame_id_to_line(thread_id)\n                    if info is None:\n                        # Could not find stack of suspended frame...\n                        if must_be_suspended:\n                            return None\n                    else:\n                        # Note: we have to use the topmost frame where it was suspended (it may\n                        # be different if it was an exception).\n                        topmost_frame, frame_id_to_lineno = info\n\n                    cmd_text.append(self.make_thread_stack_str(topmost_frame, frame_id_to_lineno))\n                finally:\n                    topmost_frame = None\n            cmd_text.append('</thread></xml>')\n            return NetCommand(CMD_GET_THREAD_STACK, seq, ''.join(cmd_text))\n        except:\n            return self.make_error_message(seq, get_exception_traceback_str())", "response": "Makes a get thread stack message."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_thread_stack_str(self, frame, frame_id_to_lineno=None):\n        '''\n        :param frame_id_to_lineno:\n            If available, the line number for the frame will be gotten from this dict,\n            otherwise frame.f_lineno will be used (needed for unhandled exceptions as\n            the place where we report may be different from the place where it's raised).\n        '''\n        if frame_id_to_lineno is None:\n            frame_id_to_lineno = {}\n        make_valid_xml_value = pydevd_xml.make_valid_xml_value\n        cmd_text_list = []\n        append = cmd_text_list.append\n\n        curr_frame = frame\n        frame = None  # Clear frame reference\n        try:\n            py_db = get_global_debugger()\n            for frame_id, frame, method_name, _original_filename, filename_in_utf8, lineno in self._iter_visible_frames_info(\n                    py_db, curr_frame, frame_id_to_lineno\n                ):\n\n                # print(\"file is \", filename_in_utf8)\n                # print(\"line is \", lineno)\n\n                # Note: variables are all gotten 'on-demand'.\n                append('<frame id=\"%s\" name=\"%s\" ' % (frame_id , make_valid_xml_value(method_name)))\n                append('file=\"%s\" line=\"%s\">' % (quote(make_valid_xml_value(filename_in_utf8), '/>_= \\t'), lineno))\n                append(\"</frame>\")\n        except:\n            pydev_log.exception()\n\n        curr_frame = None  # Clear frame reference\n        return ''.join(cmd_text_list)", "response": "This function returns a string that contains the thread stack."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning exception details as XML", "response": "def make_get_exception_details_message(self, seq, thread_id, topmost_frame):\n        \"\"\"Returns exception details as XML \"\"\"\n        try:\n            # If the debugger is not suspended, just return the thread and its id.\n            cmd_text = ['<xml><thread id=\"%s\" ' % (thread_id,)]\n\n            if topmost_frame is not None:\n                try:\n                    frame = topmost_frame\n                    topmost_frame = None\n                    while frame is not None:\n                        if frame.f_code.co_name == 'do_wait_suspend' and frame.f_code.co_filename.endswith('pydevd.py'):\n                            arg = frame.f_locals.get('arg', None)\n                            if arg is not None:\n                                exc_type, exc_desc, _thread_suspend_str, thread_stack_str = self._make_send_curr_exception_trace_str(\n                                    thread_id, *arg)\n                                cmd_text.append('exc_type=\"%s\" ' % (exc_type,))\n                                cmd_text.append('exc_desc=\"%s\" ' % (exc_desc,))\n                                cmd_text.append('>')\n                                cmd_text.append(thread_stack_str)\n                                break\n                        frame = frame.f_back\n                    else:\n                        cmd_text.append('>')\n                finally:\n                    frame = None\n            cmd_text.append('</thread></xml>')\n            return NetCommand(CMD_GET_EXCEPTION_DETAILS, seq, ''.join(cmd_text))\n        except:\n            return self.make_error_message(seq, get_exception_traceback_str())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the size and entry point of the module using the Win32 API.", "response": "def __get_size_and_entry_point(self):\n        \"Get the size and entry point of the module using the Win32 API.\"\n        process = self.get_process()\n        if process:\n            try:\n                handle = process.get_handle( win32.PROCESS_VM_READ |\n                                             win32.PROCESS_QUERY_INFORMATION )\n                base   = self.get_base()\n                mi     = win32.GetModuleInformation(handle, base)\n                self.SizeOfImage = mi.SizeOfImage\n                self.EntryPoint  = mi.EntryPoint\n            except WindowsError:\n                e = sys.exc_info()[1]\n                warnings.warn(\n                    \"Cannot get size and entry point of module %s, reason: %s\"\\\n                    % (self.get_name(), e.strerror), RuntimeWarning)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __filename_to_modname(self, pathname):\n        filename = PathOperations.pathname_to_filename(pathname)\n        if filename:\n            filename = filename.lower()\n            filepart, extpart = PathOperations.split_extension(filename)\n            if filepart and extpart:\n                modName = filepart\n            else:\n                modName = filename\n        else:\n            modName = pathname\n        return modName", "response": "Converts a filename to a module name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_name(self):\n        pathname = self.get_filename()\n        if pathname:\n            modName = self.__filename_to_modname(pathname)\n            if isinstance(modName, compat.unicode):\n                try:\n                    modName = modName.encode('cp1252')\n                except UnicodeEncodeError:\n                    e = sys.exc_info()[1]\n                    warnings.warn(str(e))\n        else:\n            modName = \"0x%x\" % self.get_base()\n        return modName", "response": "Returns the name of the module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening a new handle to the module.", "response": "def open_handle(self):\n        \"\"\"\n        Opens a new handle to the module.\n\n        The new handle is stored in the L{hFile} property.\n        \"\"\"\n\n        if not self.get_filename():\n            msg = \"Cannot retrieve filename for module at %s\"\n            msg = msg % HexDump.address( self.get_base() )\n            raise Exception(msg)\n\n        hFile = win32.CreateFile(self.get_filename(),\n                                           dwShareMode = win32.FILE_SHARE_READ,\n                                 dwCreationDisposition = win32.OPEN_EXISTING)\n\n        # In case hFile was set to an actual handle value instead of a Handle\n        # object. This shouldn't happen unless the user tinkered with hFile.\n        if not hasattr(self.hFile, '__del__'):\n            self.close_handle()\n\n        self.hFile = hFile"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncloses the handle to the module.", "response": "def close_handle(self):\n        \"\"\"\n        Closes the handle to the module.\n\n        @note: Normally you don't need to call this method. All handles\n            created by I{WinAppDbg} are automatically closed when the garbage\n            collector claims them. So unless you've been tinkering with it,\n            setting L{hFile} to C{None} should be enough.\n        \"\"\"\n        try:\n            if hasattr(self.hFile, 'close'):\n                self.hFile.close()\n            elif self.hFile not in (None, win32.INVALID_HANDLE_VALUE):\n                win32.CloseHandle(self.hFile)\n        finally:\n            self.hFile = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading the debugging symbols for a module.", "response": "def load_symbols(self):\n        \"\"\"\n        Loads the debugging symbols for a module.\n        Automatically called by L{get_symbols}.\n        \"\"\"\n        if win32.PROCESS_ALL_ACCESS == win32.PROCESS_ALL_ACCESS_VISTA:\n            dwAccess = win32.PROCESS_QUERY_LIMITED_INFORMATION\n        else:\n            dwAccess = win32.PROCESS_QUERY_INFORMATION\n        hProcess     = self.get_process().get_handle(dwAccess)\n        hFile        = self.hFile\n        BaseOfDll    = self.get_base()\n        SizeOfDll    = self.get_size()\n        Enumerator   = self._SymbolEnumerator()\n        try:\n            win32.SymInitialize(hProcess)\n            SymOptions = win32.SymGetOptions()\n            SymOptions |= (\n                win32.SYMOPT_ALLOW_ZERO_ADDRESS     |\n                win32.SYMOPT_CASE_INSENSITIVE       |\n                win32.SYMOPT_FAVOR_COMPRESSED       |\n                win32.SYMOPT_INCLUDE_32BIT_MODULES  |\n                win32.SYMOPT_UNDNAME\n            )\n            SymOptions &= ~(\n                win32.SYMOPT_LOAD_LINES         |\n                win32.SYMOPT_NO_IMAGE_SEARCH    |\n                win32.SYMOPT_NO_CPP             |\n                win32.SYMOPT_IGNORE_NT_SYMPATH\n            )\n            win32.SymSetOptions(SymOptions)\n            try:\n                win32.SymSetOptions(\n                    SymOptions | win32.SYMOPT_ALLOW_ABSOLUTE_SYMBOLS)\n            except WindowsError:\n                pass\n            try:\n                try:\n                    success = win32.SymLoadModule64(\n                        hProcess, hFile, None, None, BaseOfDll, SizeOfDll)\n                except WindowsError:\n                    success = 0\n                if not success:\n                    ImageName = self.get_filename()\n                    success = win32.SymLoadModule64(\n                        hProcess, None, ImageName, None, BaseOfDll, SizeOfDll)\n                if success:\n                    try:\n                        win32.SymEnumerateSymbols64(\n                            hProcess, BaseOfDll, Enumerator)\n                    finally:\n                        win32.SymUnloadModule64(hProcess, BaseOfDll)\n            finally:\n                win32.SymCleanup(hProcess)\n        except WindowsError:\n            e = sys.exc_info()[1]\n            msg = \"Cannot load debug symbols for process ID %d, reason:\\n%s\"\n            msg = msg % (self.get_pid(), traceback.format_exc(e))\n            warnings.warn(msg, DebugSymbolsWarning)\n        self.__symbols = Enumerator.symbols"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nresolve a debugging symbol s address.", "response": "def resolve_symbol(self, symbol, bCaseSensitive = False):\n        \"\"\"\n        Resolves a debugging symbol's address.\n\n        @type  symbol: str\n        @param symbol: Name of the symbol to resolve.\n\n        @type  bCaseSensitive: bool\n        @param bCaseSensitive: C{True} for case sensitive matches,\n            C{False} for case insensitive.\n\n        @rtype:  int or None\n        @return: Memory address of symbol. C{None} if not found.\n        \"\"\"\n        if bCaseSensitive:\n            for (SymbolName, SymbolAddress, SymbolSize) in self.iter_symbols():\n                if symbol == SymbolName:\n                    return SymbolAddress\n            for (SymbolName, SymbolAddress, SymbolSize) in self.iter_symbols():\n                try:\n                    SymbolName = win32.UnDecorateSymbolName(SymbolName)\n                except Exception:\n                    continue\n                if symbol == SymbolName:\n                    return SymbolAddress\n        else:\n            symbol = symbol.lower()\n            for (SymbolName, SymbolAddress, SymbolSize) in self.iter_symbols():\n                if symbol == SymbolName.lower():\n                    return SymbolAddress\n            for (SymbolName, SymbolAddress, SymbolSize) in self.iter_symbols():\n                try:\n                    SymbolName = win32.UnDecorateSymbolName(SymbolName)\n                except Exception:\n                    continue\n                if symbol == SymbolName.lower():\n                    return SymbolAddress"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the label for the given function of this module or the module base address plus the offset.", "response": "def get_label(self, function = None, offset = None):\n        \"\"\"\n        Retrieves the label for the given function of this module or the module\n        base address if no function name is given.\n\n        @type  function: str\n        @param function: (Optional) Exported function name.\n\n        @type  offset: int\n        @param offset: (Optional) Offset from the module base address.\n\n        @rtype:  str\n        @return: Label for the module base address, plus the offset if given.\n        \"\"\"\n        return _ModuleContainer.parse_label(self.get_name(), function, offset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_label_at_address(self, address, offset = None):\n\n        # Add the offset to the address.\n        if offset:\n            address = address + offset\n\n        # Make the label relative to the base address if no match is found.\n        module      = self.get_name()\n        function    = None\n        offset      = address - self.get_base()\n\n        # Make the label relative to the entrypoint if no other match is found.\n        # Skip if the entry point is unknown.\n        start = self.get_entry_point()\n        if start and start <= address:\n            function    = \"start\"\n            offset      = address - start\n\n        # Enumerate exported functions and debug symbols,\n        # then find the closest match, if possible.\n        try:\n            symbol = self.get_symbol_at_address(address)\n            if symbol:\n                (SymbolName, SymbolAddress, SymbolSize) = symbol\n                new_offset = address - SymbolAddress\n                if new_offset <= offset:\n                    function    = SymbolName\n                    offset      = new_offset\n        except WindowsError:\n            pass\n\n        # Parse the label and return it.\n        return _ModuleContainer.parse_label(module, function, offset)", "response": "Returns the label pointing to the given memory address."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_address_here(self, address):\n        base = self.get_base()\n        size = self.get_size()\n        if base and size:\n            return base <= address < (base + size)\n        return None", "response": "Tries to determine if the given address belongs to this module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nresolving a function exported by this module.", "response": "def resolve(self, function):\n        \"\"\"\n        Resolves a function exported by this module.\n\n        @type  function: str or int\n        @param function:\n            str: Name of the function.\n            int: Ordinal of the function.\n\n        @rtype:  int\n        @return: Memory address of the exported function in the process.\n            Returns None on error.\n        \"\"\"\n\n        # Unknown DLL filename, there's nothing we can do.\n        filename = self.get_filename()\n        if not filename:\n            return None\n\n        # If the DLL is already mapped locally, resolve the function.\n        try:\n            hlib    = win32.GetModuleHandle(filename)\n            address = win32.GetProcAddress(hlib, function)\n        except WindowsError:\n\n            # Load the DLL locally, resolve the function and unload it.\n            try:\n                hlib = win32.LoadLibraryEx(filename,\n                                           win32.DONT_RESOLVE_DLL_REFERENCES)\n                try:\n                    address = win32.GetProcAddress(hlib, function)\n                finally:\n                    win32.FreeLibrary(hlib)\n            except WindowsError:\n                return None\n\n        # A NULL pointer means the function was not found.\n        if address in (None, 0):\n            return None\n\n        # Compensate for DLL base relocations locally and remotely.\n        return address - hlib + self.lpBaseOfDll"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resolve_label(self, label):\n\n        # Split the label into it's components.\n        # Use the fuzzy mode whenever possible.\n        aProcess = self.get_process()\n        if aProcess is not None:\n            (module, procedure, offset) = aProcess.split_label(label)\n        else:\n            (module, procedure, offset) = _ModuleContainer.split_label(label)\n\n        # If a module name is given that doesn't match ours,\n        # raise an exception.\n        if module and not self.match_name(module):\n            raise RuntimeError(\"Label does not belong to this module\")\n\n        # Resolve the procedure if given.\n        if procedure:\n            address = self.resolve(procedure)\n            if address is None:\n\n                # If it's a debug symbol, use the symbol.\n                address = self.resolve_symbol(procedure)\n\n                # If it's the keyword \"start\" use the entry point.\n                if address is None and procedure == \"start\":\n                    address = self.get_entry_point()\n\n                # The procedure was not found.\n                if address is None:\n                    if not module:\n                        module = self.get_name()\n                    msg = \"Can't find procedure %s in module %s\"\n                    raise RuntimeError(msg % (procedure, module))\n\n        # If no procedure is given use the base address of the module.\n        else:\n            address = self.get_base()\n\n        # Add the offset if given and return the resolved address.\n        if offset:\n            address = address + offset\n        return address", "response": "Resolves a label for this module only."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the module object with the given base address.", "response": "def get_module(self, lpBaseOfDll):\n        \"\"\"\n        @type  lpBaseOfDll: int\n        @param lpBaseOfDll: Base address of the DLL to look for.\n\n        @rtype:  L{Module}\n        @return: Module object with the given base address.\n        \"\"\"\n        self.__initialize_snapshot()\n        if lpBaseOfDll not in self.__moduleDict:\n            msg = \"Unknown DLL base address %s\"\n            msg = msg % HexDump.address(lpBaseOfDll)\n            raise KeyError(msg)\n        return self.__moduleDict[lpBaseOfDll]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_module_by_name(self, modName):\n\n        # Convert modName to lowercase.\n        # This helps make case insensitive string comparisons.\n        modName = modName.lower()\n\n        # modName is an absolute pathname.\n        if PathOperations.path_is_absolute(modName):\n            for lib in self.iter_modules():\n                if modName == lib.get_filename().lower():\n                    return lib\n            return None     # Stop trying to match the name.\n\n        # Get all the module names.\n        # This prevents having to iterate through the module list\n        #  more than once.\n        modDict = [ ( lib.get_name(), lib ) for lib in self.iter_modules() ]\n        modDict = dict(modDict)\n\n        # modName is a base filename.\n        if modName in modDict:\n            return modDict[modName]\n\n        # modName is a base filename without extension.\n        filepart, extpart = PathOperations.split_extension(modName)\n        if filepart and extpart:\n            if filepart in modDict:\n                return modDict[filepart]\n\n        # modName is a base address.\n        try:\n            baseAddress = HexInput.integer(modName)\n        except ValueError:\n            return None\n        if self.has_module(baseAddress):\n            return self.get_module(baseAddress)\n\n        # Module not found.\n        return None", "response": "Returns the module object that matches the given name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the module object that best matches the given memory address.", "response": "def get_module_at_address(self, address):\n        \"\"\"\n        @type  address: int\n        @param address: Memory address to query.\n\n        @rtype:  L{Module}\n        @return: C{Module} object that best matches the given address.\n            Returns C{None} if no C{Module} can be found.\n        \"\"\"\n        bases = self.get_module_bases()\n        bases.sort()\n        bases.append(long(0x10000000000000000))  # max. 64 bit address + 1\n        if address >= bases[0]:\n            i = 0\n            max_i = len(bases) - 1\n            while i < max_i:\n                begin, end = bases[i:i+2]\n                if begin <= address < end:\n                    module = self.get_module(begin)\n                    here   = module.is_address_here(address)\n                    if here is False:\n                        break\n                    else:   # True or None\n                        return module\n                i = i + 1\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npopulates the snapshot with loaded modules.", "response": "def scan_modules(self):\n        \"\"\"\n        Populates the snapshot with loaded modules.\n        \"\"\"\n\n        # The module filenames may be spoofed by malware,\n        # since this information resides in usermode space.\n        # See: http://www.ragestorm.net/blogs/?p=163\n\n        # Ignore special process IDs.\n        # PID 0: System Idle Process. Also has a special meaning to the\n        #        toolhelp APIs (current process).\n        # PID 4: System Integrity Group. See this forum post for more info:\n        #        http://tinyurl.com/ycza8jo\n        #        (points to social.technet.microsoft.com)\n        #        Only on XP and above\n        # PID 8: System (?) only in Windows 2000 and below AFAIK.\n        #        It's probably the same as PID 4 in XP and above.\n        dwProcessId = self.get_pid()\n        if dwProcessId in (0, 4, 8):\n            return\n\n        # It would seem easier to clear the snapshot first.\n        # But then all open handles would be closed.\n        found_bases = set()\n        with win32.CreateToolhelp32Snapshot(win32.TH32CS_SNAPMODULE,\n                                            dwProcessId) as hSnapshot:\n            me = win32.Module32First(hSnapshot)\n            while me is not None:\n                lpBaseAddress = me.modBaseAddr\n                fileName      = me.szExePath    # full pathname\n                if not fileName:\n                    fileName  = me.szModule     # filename only\n                    if not fileName:\n                        fileName = None\n                else:\n                    fileName = PathOperations.native_to_win32_pathname(fileName)\n                found_bases.add(lpBaseAddress)\n##                if not self.has_module(lpBaseAddress): # XXX triggers a scan\n                if lpBaseAddress not in self.__moduleDict:\n                    aModule = Module(lpBaseAddress, fileName = fileName,\n                                           SizeOfImage = me.modBaseSize,\n                                           process = self)\n                    self._add_module(aModule)\n                else:\n                    aModule = self.get_module(lpBaseAddress)\n                    if not aModule.fileName:\n                        aModule.fileName    = fileName\n                    if not aModule.SizeOfImage:\n                        aModule.SizeOfImage = me.modBaseSize\n                    if not aModule.process:\n                        aModule.process     = self\n                me = win32.Module32Next(hSnapshot)\n##        for base in self.get_module_bases(): # XXX triggers a scan\n        for base in compat.keys(self.__moduleDict):\n            if base not in found_bases:\n                self._del_module(base)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclear the modules snapshot.", "response": "def clear_modules(self):\n        \"\"\"\n        Clears the modules snapshot.\n        \"\"\"\n        for aModule in compat.itervalues(self.__moduleDict):\n            aModule.clear()\n        self.__moduleDict = dict()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_label(module = None, function = None, offset = None):\n\n        # TODO\n        # Invalid characters should be escaped or filtered.\n\n        # Convert ordinals to strings.\n        try:\n            function = \"#0x%x\" % function\n        except TypeError:\n            pass\n\n        # Validate the parameters.\n        if module is not None and ('!' in module or '+' in module):\n            raise ValueError(\"Invalid module name: %s\" % module)\n        if function is not None and ('!' in function or '+' in function):\n            raise ValueError(\"Invalid function name: %s\" % function)\n\n        # Parse the label.\n        if module:\n            if function:\n                if offset:\n                    label = \"%s!%s+0x%x\" % (module, function, offset)\n                else:\n                    label = \"%s!%s\" % (module, function)\n            else:\n                if offset:\n##                    label = \"%s+0x%x!\" % (module, offset)\n                    label = \"%s!0x%x\" % (module, offset)\n                else:\n                    label = \"%s!\" % module\n        else:\n            if function:\n                if offset:\n                    label = \"!%s+0x%x\" % (function, offset)\n                else:\n                    label = \"!%s\" % function\n            else:\n                if offset:\n                    label = \"0x%x\" % offset\n                else:\n                    label = \"0x0\"\n\n        return label", "response": "This method parses the label from a module name function name and offset."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsplit a label created with L { parse_label_fuzzy } into two parts.", "response": "def split_label_strict(label):\n        \"\"\"\n        Splits a label created with L{parse_label}.\n\n        To parse labels with a less strict syntax, use the L{split_label_fuzzy}\n        method instead.\n\n        @warning: This method only parses the label, it doesn't make sure the\n            label actually points to a valid memory location.\n\n        @type  label: str\n        @param label: Label to split.\n\n        @rtype:  tuple( str or None, str or int or None, int or None )\n        @return: Tuple containing the C{module} name,\n            the C{function} name or ordinal, and the C{offset} value.\n\n            If the label doesn't specify a module,\n            then C{module} is C{None}.\n\n            If the label doesn't specify a function,\n            then C{function} is C{None}.\n\n            If the label doesn't specify an offset,\n            then C{offset} is C{0}.\n\n        @raise ValueError: The label is malformed.\n        \"\"\"\n        module = function = None\n        offset = 0\n\n        # Special case: None\n        if not label:\n            label = \"0x0\"\n        else:\n\n            # Remove all blanks.\n            label = label.replace(' ', '')\n            label = label.replace('\\t', '')\n            label = label.replace('\\r', '')\n            label = label.replace('\\n', '')\n\n            # Special case: empty label.\n            if not label:\n                label = \"0x0\"\n\n        # * ! *\n        if '!' in label:\n            try:\n                module, function = label.split('!')\n            except ValueError:\n                raise ValueError(\"Malformed label: %s\" % label)\n\n            # module ! function\n            if function:\n                if '+' in module:\n                    raise ValueError(\"Malformed label: %s\" % label)\n\n                # module ! function + offset\n                if '+' in function:\n                    try:\n                        function, offset = function.split('+')\n                    except ValueError:\n                        raise ValueError(\"Malformed label: %s\" % label)\n                    try:\n                        offset = HexInput.integer(offset)\n                    except ValueError:\n                        raise ValueError(\"Malformed label: %s\" % label)\n                else:\n\n                    # module ! offset\n                    try:\n                        offset   = HexInput.integer(function)\n                        function = None\n                    except ValueError:\n                        pass\n            else:\n\n                # module + offset !\n                if '+' in module:\n                    try:\n                        module, offset = module.split('+')\n                    except ValueError:\n                        raise ValueError(\"Malformed label: %s\" % label)\n                    try:\n                        offset = HexInput.integer(offset)\n                    except ValueError:\n                        raise ValueError(\"Malformed label: %s\" % label)\n\n                else:\n\n                    # module !\n                    try:\n                        offset = HexInput.integer(module)\n                        module = None\n\n                    # offset !\n                    except ValueError:\n                        pass\n\n            if not module:\n                module   = None\n            if not function:\n                function = None\n\n        # *\n        else:\n\n            # offset\n            try:\n                offset = HexInput.integer(label)\n\n            # # ordinal\n            except ValueError:\n                if label.startswith('#'):\n                    function = label\n                    try:\n                        HexInput.integer(function[1:])\n\n                    # module?\n                    # function?\n                    except ValueError:\n                        raise ValueError(\"Ambiguous label: %s\" % label)\n\n                # module?\n                # function?\n                else:\n                    raise ValueError(\"Ambiguous label: %s\" % label)\n\n        # Convert function ordinal strings into integers.\n        if function and function.startswith('#'):\n            try:\n                function = HexInput.integer(function[1:])\n            except ValueError:\n                pass\n\n        # Convert null offsets to None.\n        if not offset:\n            offset = None\n\n        return (module, function, offset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef split_label_fuzzy(self, label):\n        module = function = None\n        offset = 0\n\n        # Special case: None\n        if not label:\n            label = compat.b(\"0x0\")\n        else:\n\n            # Remove all blanks.\n            label = label.replace(compat.b(' '), compat.b(''))\n            label = label.replace(compat.b('\\t'), compat.b(''))\n            label = label.replace(compat.b('\\r'), compat.b(''))\n            label = label.replace(compat.b('\\n'), compat.b(''))\n\n            # Special case: empty label.\n            if not label:\n                label = compat.b(\"0x0\")\n\n        # If an exclamation sign is present, we know we can parse it strictly.\n        if compat.b('!') in label:\n            return self.split_label_strict(label)\n\n##        # Try to parse it strictly, on error do it the fuzzy way.\n##        try:\n##            return self.split_label(label)\n##        except ValueError:\n##            pass\n\n        # * + offset\n        if compat.b('+') in label:\n            try:\n                prefix, offset = label.split(compat.b('+'))\n            except ValueError:\n                raise ValueError(\"Malformed label: %s\" % label)\n            try:\n                offset = HexInput.integer(offset)\n            except ValueError:\n                raise ValueError(\"Malformed label: %s\" % label)\n            label = prefix\n\n        # This parses both filenames and base addresses.\n        modobj = self.get_module_by_name(label)\n        if modobj:\n\n            # module\n            # module + offset\n            module = modobj.get_name()\n\n        else:\n\n            # TODO\n            # If 0xAAAAAAAA + 0xBBBBBBBB is given,\n            # A is interpreted as a module base address,\n            # and B as an offset.\n            # If that fails, it'd be good to add A+B and try to\n            # use the nearest loaded module.\n\n            # offset\n            # base address + offset (when no module has that base address)\n            try:\n                address = HexInput.integer(label)\n\n                if offset:\n                    # If 0xAAAAAAAA + 0xBBBBBBBB is given,\n                    # A is interpreted as a module base address,\n                    # and B as an offset.\n                    # If that fails, we get here, meaning no module was found\n                    # at A. Then add up A+B and work with that as a hardcoded\n                    # address.\n                    offset = address + offset\n                else:\n                    # If the label is a hardcoded address, we get here.\n                    offset = address\n\n                # If only a hardcoded address is given,\n                # rebuild the label using get_label_at_address.\n                # Then parse it again, but this time strictly,\n                # both because there is no need for fuzzy syntax and\n                # to prevent an infinite recursion if there's a bug here.\n                try:\n                    new_label = self.get_label_at_address(offset)\n                    module, function, offset = \\\n                                             self.split_label_strict(new_label)\n                except ValueError:\n                    pass\n\n            # function\n            # function + offset\n            except ValueError:\n                function = label\n\n        # Convert function ordinal strings into integers.\n        if function and function.startswith(compat.b('#')):\n            try:\n                function = HexInput.integer(function[1:])\n            except ValueError:\n                pass\n\n        # Convert null offsets to None.\n        if not offset:\n            offset = None\n\n        return (module, function, offset)", "response": "Splits a label into two elements."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a label taken from user input into a well - formed label.", "response": "def sanitize_label(self, label):\n        \"\"\"\n        Converts a label taken from user input into a well-formed label.\n\n        @type  label: str\n        @param label: Label taken from user input.\n\n        @rtype:  str\n        @return: Sanitized label.\n        \"\"\"\n        (module, function, offset) = self.split_label_fuzzy(label)\n        label = self.parse_label(module, function, offset)\n        return label"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresolving the memory address of the given label.", "response": "def resolve_label(self, label):\n        \"\"\"\n        Resolve the memory address of the given label.\n\n        @note:\n            If multiple modules with the same name are loaded,\n            the label may be resolved at any of them. For a more precise\n            way to resolve functions use the base address to get the L{Module}\n            object (see L{Process.get_module}) and then call L{Module.resolve}.\n\n            If no module name is specified in the label, the function may be\n            resolved in any loaded module. If you want to resolve all functions\n            with that name in all processes, call L{Process.iter_modules} to\n            iterate through all loaded modules, and then try to resolve the\n            function in each one of them using L{Module.resolve}.\n\n        @type  label: str\n        @param label: Label to resolve.\n\n        @rtype:  int\n        @return: Memory address pointed to by the label.\n\n        @raise ValueError: The label is malformed or impossible to resolve.\n        @raise RuntimeError: Cannot resolve the module or function.\n        \"\"\"\n\n        # Split the label into module, function and offset components.\n        module, function, offset = self.split_label_fuzzy(label)\n\n        # Resolve the components into a memory address.\n        address = self.resolve_label_components(module, function, offset)\n\n        # Return the memory address.\n        return address"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresolving the label components of the given module function and offset.", "response": "def resolve_label_components(self, module   = None,\n                                       function = None,\n                                       offset   = None):\n        \"\"\"\n        Resolve the memory address of the given module, function and/or offset.\n\n        @note:\n            If multiple modules with the same name are loaded,\n            the label may be resolved at any of them. For a more precise\n            way to resolve functions use the base address to get the L{Module}\n            object (see L{Process.get_module}) and then call L{Module.resolve}.\n\n            If no module name is specified in the label, the function may be\n            resolved in any loaded module. If you want to resolve all functions\n            with that name in all processes, call L{Process.iter_modules} to\n            iterate through all loaded modules, and then try to resolve the\n            function in each one of them using L{Module.resolve}.\n\n        @type  module: None or str\n        @param module: (Optional) Module name.\n\n        @type  function: None, str or int\n        @param function: (Optional) Function name or ordinal.\n\n        @type  offset: None or int\n        @param offset: (Optional) Offset value.\n\n            If C{function} is specified, offset from the function.\n\n            If C{function} is C{None}, offset from the module.\n\n        @rtype:  int\n        @return: Memory address pointed to by the label.\n\n        @raise ValueError: The label is malformed or impossible to resolve.\n        @raise RuntimeError: Cannot resolve the module or function.\n        \"\"\"\n        # Default address if no module or function are given.\n        # An offset may be added later.\n        address = 0\n\n        # Resolve the module.\n        # If the module is not found, check for the special symbol \"main\".\n        if module:\n            modobj = self.get_module_by_name(module)\n            if not modobj:\n                if module == \"main\":\n                    modobj = self.get_main_module()\n                else:\n                    raise RuntimeError(\"Module %r not found\" % module)\n\n            # Resolve the exported function or debugging symbol.\n            # If all else fails, check for the special symbol \"start\".\n            if function:\n                address = modobj.resolve(function)\n                if address is None:\n                    address = modobj.resolve_symbol(function)\n                    if address is None:\n                        if function == \"start\":\n                            address = modobj.get_entry_point()\n                        if address is None:\n                            msg = \"Symbol %r not found in module %s\"\n                            raise RuntimeError(msg % (function, module))\n\n            # No function, use the base address.\n            else:\n                address = modobj.get_base()\n\n        # Resolve the function in any module.\n        # If all else fails, check for the special symbols \"main\" and \"start\".\n        elif function:\n            for modobj in self.iter_modules():\n                address = modobj.resolve(function)\n                if address is not None:\n                    break\n            if address is None:\n                if function == \"start\":\n                    modobj = self.get_main_module()\n                    address = modobj.get_entry_point()\n                elif function == \"main\":\n                    modobj = self.get_main_module()\n                    address = modobj.get_base()\n                else:\n                    msg = \"Function %r not found in any module\" % function\n                    raise RuntimeError(msg)\n\n        # Return the address plus the offset.\n        if offset:\n            address = address + offset\n        return address"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_label_at_address(self, address, offset = None):\n        if offset:\n            address = address + offset\n        modobj = self.get_module_at_address(address)\n        if modobj:\n            label = modobj.get_label_at_address(address)\n        else:\n            label = self.parse_label(None, None, address)\n        return label", "response": "Returns the label pointing to the given memory address."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_system_defined_breakpoint(self, address):\n        if address:\n            module = self.get_module_at_address(address)\n            if module:\n                return module.match_name(\"ntdll\")    or \\\n                       module.match_name(\"kernel32\")\n        return False", "response": "C { True } if the given address points to a system defined\n            breakpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_symbols(self):\n        symbols = list()\n        for aModule in self.iter_modules():\n            for symbol in aModule.iter_symbols():\n                symbols.append(symbol)\n        return symbols", "response": "Returns the debugging symbols for all modules in this snapshot."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resolve_symbol(self, symbol, bCaseSensitive = False):\n        if bCaseSensitive:\n            for (SymbolName, SymbolAddress, SymbolSize) in self.iter_symbols():\n                if symbol == SymbolName:\n                    return SymbolAddress\n        else:\n            symbol = symbol.lower()\n            for (SymbolName, SymbolAddress, SymbolSize) in self.iter_symbols():\n                if symbol == SymbolName.lower():\n                    return SymbolAddress", "response": "Resolves a debugging symbol s address."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntry to find the closest matching symbol for the given memory address. Returns None if no match was found.", "response": "def get_symbol_at_address(self, address):\n        \"\"\"\n        Tries to find the closest matching symbol for the given address.\n\n        @type  address: int\n        @param address: Memory address to query.\n\n        @rtype: None or tuple( str, int, int )\n        @return: Returns a tuple consisting of:\n             - Name\n             - Address\n             - Size (in bytes)\n            Returns C{None} if no symbol could be matched.\n        \"\"\"\n        # Any module may have symbols pointing anywhere in memory, so there's\n        # no easy way to optimize this. I guess we're stuck with brute force.\n        found = None\n        for (SymbolName, SymbolAddress, SymbolSize) in self.iter_symbols():\n            if SymbolAddress > address:\n                continue\n\n            if SymbolAddress == address:\n                found = (SymbolName, SymbolAddress, SymbolSize)\n                break\n\n            if SymbolAddress < address:\n                if found and (address - found[1]) < (address - SymbolAddress):\n                    continue\n                else:\n                    found = (SymbolName, SymbolAddress, SymbolSize)\n        return found"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _add_module(self, aModule):\n##        if not isinstance(aModule, Module):\n##            if hasattr(aModule, '__class__'):\n##                typename = aModule.__class__.__name__\n##            else:\n##                typename = str(type(aModule))\n##            msg = \"Expected Module, got %s instead\" % typename\n##            raise TypeError(msg)\n        lpBaseOfDll = aModule.get_base()\n##        if lpBaseOfDll in self.__moduleDict:\n##            msg = \"Module already exists: %d\" % lpBaseOfDll\n##            raise KeyError(msg)\n        aModule.set_process(self)\n        self.__moduleDict[lpBaseOfDll] = aModule", "response": "Private method to add a module object to the snapshot."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _del_module(self, lpBaseOfDll):\n        try:\n            aModule = self.__moduleDict[lpBaseOfDll]\n            del self.__moduleDict[lpBaseOfDll]\n        except KeyError:\n            aModule = None\n            msg = \"Unknown base address %d\" % HexDump.address(lpBaseOfDll)\n            warnings.warn(msg, RuntimeWarning)\n        if aModule:\n            aModule.clear()", "response": "Private method to remove a module object from the snapshot."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __add_loaded_module(self, event):\n        lpBaseOfDll = event.get_module_base()\n        hFile       = event.get_file_handle()\n##        if not self.has_module(lpBaseOfDll):  # XXX this would trigger a scan\n        if lpBaseOfDll not in self.__moduleDict:\n            fileName = event.get_filename()\n            if not fileName:\n                fileName = None\n            if hasattr(event, 'get_start_address'):\n                EntryPoint = event.get_start_address()\n            else:\n                EntryPoint = None\n            aModule  = Module(lpBaseOfDll, hFile, fileName = fileName,\n                                                EntryPoint = EntryPoint,\n                                                   process = self)\n            self._add_module(aModule)\n        else:\n            aModule = self.get_module(lpBaseOfDll)\n            if not aModule.hFile and hFile not in (None, 0,\n                                                   win32.INVALID_HANDLE_VALUE):\n                aModule.hFile = hFile\n            if not aModule.process:\n                aModule.process = self\n            if aModule.EntryPoint is None and \\\n                                           hasattr(event, 'get_start_address'):\n                aModule.EntryPoint = event.get_start_address()\n            if not aModule.fileName:\n                fileName = event.get_filename()\n                if fileName:\n                    aModule.fileName = fileName", "response": "Private method to automatically add new module objects from debug events."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nnotify the user of a loaded module.", "response": "def _notify_unload_dll(self, event):\n        \"\"\"\n        Notify the release of a loaded module.\n\n        This is done automatically by the L{Debug} class, you shouldn't need\n        to call it yourself.\n\n        @type  event: L{UnloadDLLEvent}\n        @param event: Unload DLL event.\n\n        @rtype:  bool\n        @return: C{True} to call the user-defined handle, C{False} otherwise.\n        \"\"\"\n        lpBaseOfDll = event.get_module_base()\n##        if self.has_module(lpBaseOfDll):  # XXX this would trigger a scan\n        if lpBaseOfDll in self.__moduleDict:\n            self._del_module(lpBaseOfDll)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef loadFullValue(self, seq, scope_attrs):\n        frame_variables = self.get_namespace()\n        var_objects = []\n        vars = scope_attrs.split(NEXT_VALUE_SEPARATOR)\n        for var_attrs in vars:\n            if '\\t' in var_attrs:\n                name, attrs = var_attrs.split('\\t', 1)\n\n            else:\n                name = var_attrs\n                attrs = None\n            if name in frame_variables:\n                var_object = pydevd_vars.resolve_var_object(frame_variables[name], attrs)\n                var_objects.append((var_object, name))\n            else:\n                var_object = pydevd_vars.eval_in_context(name, frame_variables, frame_variables)\n                var_objects.append((var_object, name))\n\n        from _pydevd_bundle.pydevd_comm import GetValueAsyncThreadConsole\n        t = GetValueAsyncThreadConsole(self.get_server(), seq, var_objects)\n        t.start()", "response": "Evaluate full value for async Console variables in a separate thread and send results to IDE side\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef connectToDebugger(self, debuggerPort, debugger_options=None):\n        '''\n        Used to show console with variables connection.\n        Mainly, monkey-patches things in the debugger structure so that the debugger protocol works.\n        '''\n\n        if debugger_options is None:\n            debugger_options = {}\n        env_key = \"PYDEVD_EXTRA_ENVS\"\n        if env_key in debugger_options:\n            for (env_name, value) in dict_iter_items(debugger_options[env_key]):\n                existing_value = os.environ.get(env_name, None)\n                if existing_value:\n                    os.environ[env_name] = \"%s%c%s\" % (existing_value, os.path.pathsep, value)\n                else:\n                    os.environ[env_name] = value\n                if env_name == \"PYTHONPATH\":\n                    sys.path.append(value)\n\n            del debugger_options[env_key]\n\n        def do_connect_to_debugger():\n            try:\n                # Try to import the packages needed to attach the debugger\n                import pydevd\n                from _pydev_imps._pydev_saved_modules import threading\n\n            except:\n                # This happens on Jython embedded in host eclipse\n                traceback.print_exc()\n                sys.stderr.write('pydevd is not available, cannot connect\\n', )\n\n            from _pydevd_bundle.pydevd_constants import set_thread_id\n            from _pydev_bundle import pydev_localhost\n            set_thread_id(threading.currentThread(), \"console_main\")\n\n            VIRTUAL_FRAME_ID = \"1\"  # matches PyStackFrameConsole.java\n            VIRTUAL_CONSOLE_ID = \"console_main\"  # matches PyThreadConsole.java\n            f = FakeFrame()\n            f.f_back = None\n            f.f_globals = {}  # As globals=locals here, let's simply let it empty (and save a bit of network traffic).\n            f.f_locals = self.get_namespace()\n\n            self.debugger = pydevd.PyDB()\n            self.debugger.add_fake_frame(thread_id=VIRTUAL_CONSOLE_ID, frame_id=VIRTUAL_FRAME_ID, frame=f)\n            try:\n                pydevd.apply_debugger_options(debugger_options)\n                self.debugger.connect(pydev_localhost.get_localhost(), debuggerPort)\n                self.debugger.prepare_to_run()\n                self.debugger.disable_tracing()\n            except:\n                traceback.print_exc()\n                sys.stderr.write('Failed to connect to target debugger.\\n')\n\n            # Register to process commands when idle\n            self.debugrunning = False\n            try:\n                import pydevconsole\n                pydevconsole.set_debug_hook(self.debugger.process_internal_commands)\n            except:\n                traceback.print_exc()\n                sys.stderr.write('Version of Python does not support debuggable Interactive Console.\\n')\n\n        # Important: it has to be really enabled in the main thread, so, schedule\n        # it to run in the main thread.\n        self.exec_queue.put(do_connect_to_debugger)\n\n        return ('connect complete',)", "response": "Connect to the debugger."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nenable the GUI specified in guiname.", "response": "def enableGui(self, guiname):\n        ''' Enable the GUI specified in guiname (see inputhook for list).\n            As with IPython, enabling multiple GUIs isn't an error, but\n            only the last one's main loop runs and it may not work\n        '''\n        def do_enable_gui():\n            from _pydev_bundle.pydev_versioncheck import versionok_for_gui\n            if versionok_for_gui():\n                try:\n                    from pydev_ipython.inputhook import enable_gui\n                    enable_gui(guiname)\n                except:\n                    sys.stderr.write(\"Failed to enable GUI event loop integration for '%s'\\n\" % guiname)\n                    traceback.print_exc()\n            elif guiname not in ['none', '', None]:\n                # Only print a warning if the guiname was going to do something\n                sys.stderr.write(\"PyDev console: Python version does not support GUI event loop integration for '%s'\\n\" % guiname)\n            # Return value does not matter, so return back what was sent\n            return guiname\n\n        # Important: it has to be really enabled in the main thread, so, schedule\n        # it to run in the main thread.\n        self.exec_queue.put(do_enable_gui)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_localhost():\n    '''\n    Should return 127.0.0.1 in ipv4 and ::1 in ipv6\n\n    localhost is not used because on windows vista/windows 7, there can be issues where the resolving doesn't work\n    properly and takes a lot of time (had this issue on the pyunit server).\n\n    Using the IP directly solves the problem.\n    '''\n    # TODO: Needs better investigation!\n\n    global _cache\n    if _cache is None:\n        try:\n            for addr_info in socket.getaddrinfo(\"localhost\", 80, 0, 0, socket.SOL_TCP):\n                config = addr_info[4]\n                if config[0] == '127.0.0.1':\n                    _cache = '127.0.0.1'\n                    return _cache\n        except:\n            # Ok, some versions of Python don't have getaddrinfo or SOL_TCP... Just consider it 127.0.0.1 in this case.\n            _cache = '127.0.0.1'\n        else:\n            _cache = 'localhost'\n\n    return _cache", "response": "Returns the localhost address of the node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _validate_arch(self, arch = None):\n\n        # Use the default architecture if none specified.\n        if not arch:\n            arch = win32.arch\n\n        # Validate the architecture.\n        if arch not in self.supported:\n            msg = \"The %s engine cannot decode %s code.\"\n            msg = msg % (self.name, arch)\n            raise NotImplementedError(msg)\n\n        # Return the architecture.\n        return arch", "response": "Validate the architecture and return the name of the current architecture."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncommit to a particular API and trigger ImportErrors on subsequent dangerous imports", "response": "def commit_api(api):\n    \"\"\"Commit to a particular API, and trigger ImportErrors on subsequent\n       dangerous imports\"\"\"\n\n    if api == QT_API_PYSIDE:\n        ID.forbid('PyQt4')\n        ID.forbid('PyQt5')\n    else:\n        ID.forbid('PySide')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef loaded_api():\n    if 'PyQt4.QtCore' in sys.modules:\n        if qtapi_version() == 2:\n            return QT_API_PYQT\n        else:\n            return QT_API_PYQTv1\n    elif 'PySide.QtCore' in sys.modules:\n        return QT_API_PYSIDE\n    elif 'PyQt5.QtCore' in sys.modules:\n        return QT_API_PYQT5\n    return None", "response": "Return which API is loaded if any\n    returns None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef import_pyqt4(version=2):\n    # The new-style string API (version=2) automatically\n    # converts QStrings to Unicode Python strings. Also, automatically unpacks\n    # QVariants to their underlying objects.\n    import sip\n\n    if version is not None:\n        sip.setapi('QString', version)\n        sip.setapi('QVariant', version)\n\n    from PyQt4 import QtGui, QtCore, QtSvg\n\n    if not check_version(QtCore.PYQT_VERSION_STR, '4.7'):\n        raise ImportError(\"IPython requires PyQt4 >= 4.7, found %s\" %\n                          QtCore.PYQT_VERSION_STR)\n\n    # Alias PyQt-specific functions for PySide compatibility.\n    QtCore.Signal = QtCore.pyqtSignal\n    QtCore.Slot = QtCore.pyqtSlot\n\n    # query for the API version (in case version == None)\n    version = sip.getapi('QString')\n    api = QT_API_PYQTv1 if version == 1 else QT_API_PYQT\n    return QtCore, QtGui, QtSvg, api", "response": "Imports PyQt4 and returns a tuple of QtCore QtGui QtSvg api and system\n     "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef import_pyqt5():\n    from PyQt5 import QtGui, QtCore, QtSvg\n\n    # Alias PyQt-specific functions for PySide compatibility.\n    QtCore.Signal = QtCore.pyqtSignal\n    QtCore.Slot = QtCore.pyqtSlot\n\n    return QtCore, QtGui, QtSvg, QT_API_PYQT5", "response": "Imports PyQt5 and returns a tuple of the QtCore QtGui and QT_API_PYQT5"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nattempts to import Qt given a preference list of API options and returns the base base", "response": "def load_qt(api_options):\n    \"\"\"\n    Attempt to import Qt, given a preference list\n    of permissible bindings\n\n    It is safe to call this function multiple times.\n\n    Parameters\n    ----------\n    api_options: List of strings\n        The order of APIs to try. Valid items are 'pyside',\n        'pyqt', and 'pyqtv1'\n\n    Returns\n    -------\n\n    A tuple of QtCore, QtGui, QtSvg, QT_API\n    The first three are the Qt modules. The last is the\n    string indicating which module was loaded.\n\n    Raises\n    ------\n    ImportError, if it isn't possible to import any requested\n    bindings (either becaues they aren't installed, or because\n    an incompatible library has already been installed)\n    \"\"\"\n    loaders = {QT_API_PYSIDE: import_pyside,\n               QT_API_PYQT: import_pyqt4,\n               QT_API_PYQTv1: partial(import_pyqt4, version=1),\n               QT_API_PYQT_DEFAULT: partial(import_pyqt4, version=None),\n               QT_API_PYQT5: import_pyqt5,\n               }\n\n    for api in api_options:\n\n        if api not in loaders:\n            raise RuntimeError(\n                \"Invalid Qt API %r, valid values are: %r, %r, %r, %r, %r\" %\n                (api, QT_API_PYSIDE, QT_API_PYQT,\n                 QT_API_PYQTv1, QT_API_PYQT_DEFAULT, QT_API_PYQT5))\n\n        if not can_import(api):\n            continue\n\n        #cannot safely recover from an ImportError during this\n        result = loaders[api]()\n        api = result[-1]  # changed if api = QT_API_PYQT_DEFAULT\n        commit_api(api)\n        return result\n    else:\n        raise ImportError(\"\"\"\n    Could not load requested Qt binding. Please ensure that\n    PyQt4 >= 4.7 or PySide >= 1.0.3 is available,\n    and only one is imported per session.\n\n    Currently-imported Qt library:   %r\n    PyQt4 installed:                 %s\n    PyQt5 installed:                 %s\n    PySide >= 1.0.3 installed:       %s\n    Tried to load:                   %r\n    \"\"\" % (loaded_api(),\n           has_binding(QT_API_PYQT),\n           has_binding(QT_API_PYQT5),\n           has_binding(QT_API_PYSIDE),\n           api_options))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_c_option_index(args):\n    try:\n        ind_c = args.index('-c')\n    except ValueError:\n        return -1\n    else:\n        for i in range(1, ind_c):\n            if not args[i].startswith('-'):\n                # there is an arg without \"-\" before \"-c\", so it's not an interpreter's option\n                return -1\n        return ind_c", "response": "Get index of \"-c\" argument and check if it s an interpreter s option and - 1 if it doesn t exist or program s option\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_execve(original_name):\n\n    def new_execve(path, args, env):\n        import os\n        send_process_created_message()\n        return getattr(os, original_name)(path, patch_args(args), env)\n\n    return new_execve", "response": "Create a new execve function that will be used by the process manager."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new spawnve function that will send process created message to the master process.", "response": "def create_spawnve(original_name):\n    \"\"\"\n    os.spawnve(mode, path, args, env)\n    os.spawnvpe(mode, file, args, env)\n    \"\"\"\n\n    def new_spawnve(mode, path, args, env):\n        import os\n        send_process_created_message()\n        return getattr(os, original_name)(mode, path, patch_args(args), env)\n\n    return new_spawnve"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_fork_exec(original_name):\n\n    def new_fork_exec(args, *other_args):\n        import _posixsubprocess  # @UnresolvedImport\n        args = patch_args(args)\n        send_process_created_message()\n        return getattr(_posixsubprocess, original_name)(args, *other_args)\n\n    return new_fork_exec", "response": "Create a fork exec function that returns a new process."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new fork_exec function that will warn the user if the fork_exec fails.", "response": "def create_warn_fork_exec(original_name):\n    \"\"\"\n    _posixsubprocess.fork_exec(args, executable_list, close_fds, ... (13 more))\n    \"\"\"\n\n    def new_warn_fork_exec(*args):\n        try:\n            import _posixsubprocess\n            warn_multiproc()\n            return getattr(_posixsubprocess, original_name)(*args)\n        except:\n            pass\n\n    return new_warn_fork_exec"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_CreateProcess(original_name):\n\n    def new_CreateProcess(app_name, cmd_line, *args):\n        try:\n            import _subprocess\n        except ImportError:\n            import _winapi as _subprocess\n        send_process_created_message()\n        return getattr(_subprocess, original_name)(app_name, patch_arg_str_win(cmd_line), *args)\n\n    return new_CreateProcess", "response": "Create a new process that will be run in the win32 process."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_CreateProcessWarnMultiproc(original_name):\n\n    def new_CreateProcess(*args):\n        try:\n            import _subprocess\n        except ImportError:\n            import _winapi as _subprocess\n        warn_multiproc()\n        return getattr(_subprocess, original_name)(*args)\n\n    return new_CreateProcess", "response": "Create process with warning_multiproc function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef open_with_encoding(filename,\n                       encoding=None, mode='r', limit_byte_check=-1):\n    \"\"\"Return opened file with a specific encoding.\"\"\"\n    if not encoding:\n        encoding = detect_encoding(filename, limit_byte_check=limit_byte_check)\n\n    return io.open(filename, mode=mode, encoding=encoding,\n                   newline='')", "response": "Return opened file with a specific encoding."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking for missing blank lines after class declaration and method declaration.", "response": "def extended_blank_lines(logical_line,\n                         blank_lines,\n                         blank_before,\n                         indent_level,\n                         previous_logical):\n    \"\"\"Check for missing blank lines after class declaration.\"\"\"\n    if previous_logical.startswith('def '):\n        if blank_lines and pycodestyle.DOCSTRING_REGEX.match(logical_line):\n            yield (0, 'E303 too many blank lines ({0})'.format(blank_lines))\n    elif pycodestyle.DOCSTRING_REGEX.match(previous_logical):\n        # Missing blank line between class docstring and method declaration.\n        if (\n            indent_level and\n            not blank_lines and\n            not blank_before and\n            logical_line.startswith(('def ')) and\n            '(self' in logical_line\n        ):\n            yield (0, 'E301 expected 1 blank line, found 0')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef refactor(source, fixer_names, ignore=None, filename=''):\n    check_lib2to3()\n    from lib2to3 import pgen2\n    try:\n        new_text = refactor_with_2to3(source,\n                                      fixer_names=fixer_names,\n                                      filename=filename)\n    except (pgen2.parse.ParseError,\n            SyntaxError,\n            UnicodeDecodeError,\n            UnicodeEncodeError):\n        return source\n\n    if ignore:\n        if ignore in new_text and ignore not in source:\n            return source\n\n    return new_text", "response": "Return refactored code using lib2to3."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fix_2to3(source,\n             aggressive=True, select=None, ignore=None, filename=''):\n    \"\"\"Fix various deprecated code (via lib2to3).\"\"\"\n    if not aggressive:\n        return source\n\n    select = select or []\n    ignore = ignore or []\n\n    return refactor(source,\n                    code_to_2to3(select=select,\n                                 ignore=ignore),\n                    filename=filename)", "response": "Fix various deprecated code via lib2to3."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the key for sorting PEP8 results.", "response": "def _priority_key(pep8_result):\n    \"\"\"Key for sorting PEP8 results.\n\n    Global fixes should be done first. This is important for things like\n    indentation.\n\n    \"\"\"\n    priority = [\n        # Fix multiline colon-based before semicolon based.\n        'e701',\n        # Break multiline statements early.\n        'e702',\n        # Things that make lines longer.\n        'e225', 'e231',\n        # Remove extraneous whitespace before breaking lines.\n        'e201',\n        # Shorten whitespace in comment before resorting to wrapping.\n        'e262'\n    ]\n    middle_index = 10000\n    lowest_priority = [\n        # We need to shorten lines last since the logical fixer can get in a\n        # loop, which causes us to exit early.\n        'e501'\n    ]\n    key = pep8_result['id'].lower()\n    try:\n        return priority.index(key)\n    except ValueError:\n        try:\n            return middle_index + lowest_priority.index(key) + 1\n        except ValueError:\n            return middle_index"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nnormalizing multiline - related code that will cause syntax error.", "response": "def normalize_multiline(line):\n    \"\"\"Normalize multiline-related code that will cause syntax error.\n\n    This is for purposes of checking syntax.\n\n    \"\"\"\n    if line.startswith('def ') and line.rstrip().endswith(':'):\n        return line + ' pass'\n    elif line.startswith('return '):\n        return 'def _(): ' + line\n    elif line.startswith('@'):\n        return line + 'def _(): pass'\n    elif line.startswith('class '):\n        return line + ' pass'\n    elif line.startswith(('if ', 'elif ', 'for ', 'while ')):\n        return line + ' pass'\n    else:\n        return line"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fix_whitespace(line, offset, replacement):\n    # Replace escaped newlines too\n    left = line[:offset].rstrip('\\n\\r \\t\\\\')\n    right = line[offset:].lstrip('\\n\\r \\t\\\\')\n    if right.startswith('#'):\n        return line\n    else:\n        return left + replacement + right", "response": "Replace whitespace at offset and return fixed line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn fixed source code.", "response": "def fix_lines(source_lines, options, filename=''):\n    \"\"\"Return fixed source code.\"\"\"\n    # Transform everything to line feed. Then change them back to original\n    # before returning fixed source code.\n    original_newline = find_newline(source_lines)\n    tmp_source = ''.join(normalize_line_endings(source_lines, '\\n'))\n\n    # Keep a history to break out of cycles.\n    previous_hashes = set()\n\n    if options.line_range:\n        # Disable \"apply_local_fixes()\" for now due to issue #175.\n        fixed_source = tmp_source\n    else:\n        # Apply global fixes only once (for efficiency).\n        fixed_source = apply_global_fixes(tmp_source,\n                                          options,\n                                          filename=filename)\n\n    passes = 0\n    long_line_ignore_cache = set()\n    while hash(fixed_source) not in previous_hashes:\n        if options.pep8_passes >= 0 and passes > options.pep8_passes:\n            break\n        passes += 1\n\n        previous_hashes.add(hash(fixed_source))\n\n        tmp_source = copy.copy(fixed_source)\n\n        fix = FixPEP8(\n            filename,\n            options,\n            contents=tmp_source,\n            long_line_ignore_cache=long_line_ignore_cache)\n\n        fixed_source = fix.fix()\n\n    sio = io.StringIO(fixed_source)\n    return ''.join(normalize_line_endings(sio.readlines(), original_newline))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply_global_fixes(source, options, where='global', filename=''):\n    if any(code_match(code, select=options.select, ignore=options.ignore)\n           for code in ['E101', 'E111']):\n        source = reindent(source,\n                          indent_size=options.indent_size)\n\n    for (code, function) in global_fixes():\n        if code_match(code, select=options.select, ignore=options.ignore):\n            if options.verbose:\n                print('--->  Applying {0} fix for {1}'.format(where,\n                                                              code.upper()),\n                      file=sys.stderr)\n            source = function(source,\n                              aggressive=options.aggressive)\n\n    source = fix_2to3(source,\n                      aggressive=options.aggressive,\n                      select=options.select,\n                      ignore=options.ignore,\n                      filename=filename)\n\n    return source", "response": "Apply global fixes on source code."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_args(arguments, apply_config=False):\n    parser = create_parser()\n    args = parser.parse_args(arguments)\n\n    if not args.files and not args.list_fixes:\n        parser.error('incorrect number of arguments')\n\n    args.files = [decode_filename(name) for name in args.files]\n\n    if apply_config:\n        parser = read_config(args, parser)\n        args = parser.parse_args(arguments)\n        args.files = [decode_filename(name) for name in args.files]\n\n    if '-' in args.files:\n        if len(args.files) > 1:\n            parser.error('cannot mix stdin and regular files')\n\n        if args.diff:\n            parser.error('--diff cannot be used with standard input')\n\n        if args.in_place:\n            parser.error('--in-place cannot be used with standard input')\n\n        if args.recursive:\n            parser.error('--recursive cannot be used with standard input')\n\n    if len(args.files) > 1 and not (args.in_place or args.diff):\n        parser.error('autopep8 only takes one filename as argument '\n                     'unless the \"--in-place\" or \"--diff\" args are '\n                     'used')\n\n    if args.recursive and not (args.in_place or args.diff):\n        parser.error('--recursive must be used with --in-place or --diff')\n\n    if args.in_place and args.diff:\n        parser.error('--in-place and --diff are mutually exclusive')\n\n    if args.max_line_length <= 0:\n        parser.error('--max-line-length must be greater than 0')\n\n    if args.select:\n        args.select = _split_comma_separated(args.select)\n\n    if args.ignore:\n        args.ignore = _split_comma_separated(args.ignore)\n    elif not args.select:\n        if args.aggressive:\n            # Enable everything by default if aggressive.\n            args.select = set(['E', 'W'])\n        else:\n            args.ignore = _split_comma_separated(DEFAULT_IGNORE)\n\n    if args.exclude:\n        args.exclude = _split_comma_separated(args.exclude)\n    else:\n        args.exclude = set([])\n\n    if args.jobs < 1:\n        # Do not import multiprocessing globally in case it is not supported\n        # on the platform.\n        import multiprocessing\n        args.jobs = multiprocessing.cpu_count()\n\n    if args.jobs > 1 and not args.in_place:\n        parser.error('parallel jobs requires --in-place')\n\n    if args.line_range:\n        if args.line_range[0] <= 0:\n            parser.error('--range must be positive numbers')\n        if args.line_range[0] > args.line_range[1]:\n            parser.error('First value of --range should be less than or equal '\n                         'to the second')\n\n    return args", "response": "Parse command - line options."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfixing list of files.", "response": "def fix_multiple_files(filenames, options, output=None):\n    \"\"\"Fix list of files.\n\n    Optionally fix files recursively.\n\n    \"\"\"\n    filenames = find_files(filenames, options.recursive, options.exclude)\n    if options.jobs > 1:\n        import multiprocessing\n        pool = multiprocessing.Pool(options.jobs)\n        pool.map(_fix_file,\n                 [(name, options) for name in filenames])\n    else:\n        for name in filenames:\n            _fix_file((name, options, output))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main(argv=None, apply_config=True):\n    if argv is None:\n        argv = sys.argv\n\n    try:\n        # Exit on broken pipe.\n        signal.signal(signal.SIGPIPE, signal.SIG_DFL)\n    except AttributeError:  # pragma: no cover\n        # SIGPIPE is not available on Windows.\n        pass\n\n    try:\n        args = parse_args(argv[1:], apply_config=apply_config)\n\n        if args.list_fixes:\n            for code, description in sorted(supported_fixes()):\n                print('{code} - {description}'.format(\n                    code=code, description=description))\n            return 0\n\n        if args.files == ['-']:\n            assert not args.in_place\n\n            encoding = sys.stdin.encoding or get_encoding()\n\n            # LineEndingWrapper is unnecessary here due to the symmetry between\n            # standard in and standard out.\n            wrap_output(sys.stdout, encoding=encoding).write(\n                fix_code(sys.stdin.read(), args, encoding=encoding))\n        else:\n            if args.in_place or args.diff:\n                args.files = list(set(args.files))\n            else:\n                assert len(args.files) == 1\n                assert not args.recursive\n\n            fix_multiple_files(args.files, args, sys.stdout)\n    except KeyboardInterrupt:\n        return 1", "response": "Command - line entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfix missing whitespace around operator.", "response": "def fix_e225(self, result):\n        \"\"\"Fix missing whitespace around operator.\"\"\"\n        target = self.source[result['line'] - 1]\n        offset = result['column'] - 1\n        fixed = target[:offset] + ' ' + target[offset:]\n\n        # Only proceed if non-whitespace characters match.\n        # And make sure we don't break the indentation.\n        if (\n            fixed.replace(' ', '') == target.replace(' ', '') and\n            _get_indentation(fixed) == _get_indentation(target)\n        ):\n            self.source[result['line'] - 1] = fixed\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfix missing blank lines after end of function or class.", "response": "def fix_e305(self, result):\n        \"\"\"Add missing 2 blank lines after end of function or class.\"\"\"\n        cr = '\\n'\n        # check comment line\n        offset = result['line'] - 2\n        while True:\n            if offset < 0:\n                break\n            line = self.source[offset].lstrip()\n            if len(line) == 0:\n                break\n            if line[0] != '#':\n                break\n            offset -= 1\n        offset += 1\n        self.source[offset] = cr + self.source[offset]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrying to make lines fit within max - line - length characters.", "response": "def fix_long_line_logically(self, result, logical):\n        \"\"\"Try to make lines fit within --max-line-length characters.\"\"\"\n        if (\n            not logical or\n            len(logical[2]) == 1 or\n            self.source[result['line'] - 1].lstrip().startswith('#')\n        ):\n            return self.fix_long_line_physically(result)\n\n        start_line_index = logical[0][0]\n        end_line_index = logical[1][0]\n        logical_lines = logical[2]\n\n        previous_line = get_item(self.source, start_line_index - 1, default='')\n        next_line = get_item(self.source, end_line_index + 1, default='')\n\n        single_line = join_logical_line(''.join(logical_lines))\n\n        try:\n            fixed = self.fix_long_line(\n                target=single_line,\n                previous_line=previous_line,\n                next_line=next_line,\n                original=''.join(logical_lines))\n        except (SyntaxError, tokenize.TokenError):\n            return self.fix_long_line_physically(result)\n\n        if fixed:\n            for line_index in range(start_line_index, end_line_index + 1):\n                self.source[line_index] = ''\n            self.source[start_line_index] = fixed\n            return range(start_line_index + 1, end_line_index + 1)\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fix_long_line_physically(self, result):\n        line_index = result['line'] - 1\n        target = self.source[line_index]\n\n        previous_line = get_item(self.source, line_index - 1, default='')\n        next_line = get_item(self.source, line_index + 1, default='')\n\n        try:\n            fixed = self.fix_long_line(\n                target=target,\n                previous_line=previous_line,\n                next_line=next_line,\n                original=target)\n        except (SyntaxError, tokenize.TokenError):\n            return []\n\n        if fixed:\n            self.source[line_index] = fixed\n            return [line_index + 1]\n        else:\n            return []", "response": "Try to make lines fit within max - line - length characters."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fix_e712(self, result):\n        (line_index, offset, target) = get_index_offset_contents(result,\n                                                                 self.source)\n\n        # Handle very easy \"not\" special cases.\n        if re.match(r'^\\s*if [\\w.]+ == False:$', target):\n            self.source[line_index] = re.sub(r'if ([\\w.]+) == False:',\n                                             r'if not \\1:', target, count=1)\n        elif re.match(r'^\\s*if [\\w.]+ != True:$', target):\n            self.source[line_index] = re.sub(r'if ([\\w.]+) != True:',\n                                             r'if not \\1:', target, count=1)\n        else:\n            right_offset = offset + 2\n            if right_offset >= len(target):\n                return []\n\n            left = target[:offset].rstrip()\n            center = target[offset:right_offset]\n            right = target[right_offset:].lstrip()\n\n            # Handle simple cases only.\n            new_right = None\n            if center.strip() == '==':\n                if re.match(r'\\bTrue\\b', right):\n                    new_right = re.sub(r'\\bTrue\\b *', '', right, count=1)\n            elif center.strip() == '!=':\n                if re.match(r'\\bFalse\\b', right):\n                    new_right = re.sub(r'\\bFalse\\b *', '', right, count=1)\n\n            if new_right is None:\n                return []\n\n            if new_right[0].isalnum():\n                new_right = ' ' + new_right\n\n            self.source[line_index] = left + new_right", "response": "Fix comparison with boolean."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fix_e713(self, result):\n        (line_index, _, target) = get_index_offset_contents(result,\n                                                            self.source)\n\n        match = COMPARE_NEGATIVE_REGEX.search(target)\n        if match:\n            if match.group(3) == 'in':\n                pos_start = match.start(1)\n                self.source[line_index] = '{0}{1} {2} {3} {4}'.format(\n                    target[:pos_start], match.group(2), match.group(1),\n                    match.group(3), target[match.end():])", "response": "Fix ( trivial case of ) non - membership check."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _split_after_delimiter(self, item, indent_amt):\n        self._delete_whitespace()\n\n        if self.fits_on_current_line(item.size):\n            return\n\n        last_space = None\n        for item in reversed(self._lines):\n            if (\n                last_space and\n                (not isinstance(item, Atom) or not item.is_colon)\n            ):\n                break\n            else:\n                last_space = None\n            if isinstance(item, self._Space):\n                last_space = item\n            if isinstance(item, (self._LineBreak, self._Indent)):\n                return\n\n        if not last_space:\n            return\n\n        self.add_line_break_at(self._lines.index(last_space), indent_amt)", "response": "Split the line only after a delimiter."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompile and run some source in the interpreter.", "response": "def runsource(self, source, filename=\"<input>\", symbol=\"single\"):\n        \"\"\"Compile and run some source in the interpreter.\n\n        Arguments are as for compile_command().\n\n        One several things can happen:\n\n        1) The input is incorrect; compile_command() raised an\n        exception (SyntaxError or OverflowError).  A syntax traceback\n        will be printed by calling the showsyntaxerror() method.\n\n        2) The input is incomplete, and more input is required;\n        compile_command() returned None.  Nothing happens.\n\n        3) The input is complete; compile_command() returned a code\n        object.  The code is executed by calling self.runcode() (which\n        also handles run-time exceptions, except for SystemExit).\n\n        The return value is True in case 2, False in the other cases (unless\n        an exception is raised).  The return value can be used to\n        decide whether to use sys.ps1 or sys.ps2 to prompt the next\n        line.\n\n        \"\"\"\n        try:\n            code = self.compile(source, filename, symbol)\n        except (OverflowError, SyntaxError, ValueError):\n            # Case 1\n            self.showsyntaxerror(filename)\n            return False\n\n        if code is None:\n            # Case 2\n            return True\n\n        # Case 3\n        self.runcode(code)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes a code object.", "response": "def runcode(self, code):\n        \"\"\"Execute a code object.\n\n        When an exception occurs, self.showtraceback() is called to\n        display a traceback.  All exceptions are caught except\n        SystemExit, which is reraised.\n\n        A note about KeyboardInterrupt: this exception may occur\n        elsewhere in this code, and may not always be caught.  The\n        caller should be prepared to deal with it.\n\n        \"\"\"\n        try:\n            exec code in self.locals\n        except SystemExit:\n            raise\n        except:\n            self.showtraceback()\n        else:\n            if softspace(sys.stdout, 0):\n                sys.stdout.write('\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndisplay the syntax error that just occurred.", "response": "def showsyntaxerror(self, filename=None):\n        \"\"\"Display the syntax error that just occurred.\n\n        This doesn't display a stack trace because there isn't one.\n\n        If a filename is given, it is stuffed in the exception instead\n        of what was there before (because Python's parser always uses\n        \"<string>\" when reading from a string).\n\n        The output is written by self.write(), below.\n\n        \"\"\"\n        type, value, sys.last_traceback = sys.exc_info()\n        sys.last_type = type\n        sys.last_value = value\n        if filename and type is SyntaxError:\n            # Work hard to stuff the correct filename in the exception\n            try:\n                msg, (dummy_filename, lineno, offset, line) = value\n            except:\n                # Not the format we expect; leave it alone\n                pass\n            else:\n                # Stuff in the right filename\n                value = SyntaxError(msg, (filename, lineno, offset, line))\n                sys.last_value = value\n        list = traceback.format_exception_only(type, value)\n        map(self.write, list)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef showtraceback(self, *args, **kwargs):\n        try:\n            type, value, tb = sys.exc_info()\n            sys.last_type = type\n            sys.last_value = value\n            sys.last_traceback = tb\n            tblist = traceback.extract_tb(tb)\n            del tblist[:1]\n            list = traceback.format_list(tblist)\n            if list:\n                list.insert(0, \"Traceback (most recent call last):\\n\")\n            list[len(list):] = traceback.format_exception_only(type, value)\n        finally:\n            tblist = tb = None\n        map(self.write, list)", "response": "Display the exception that just occurred."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef push(self, line):\n        self.buffer.append(line)\n        source = \"\\n\".join(self.buffer)\n        more = self.runsource(source, self.filename)\n        if not more:\n            self.resetbuffer()\n        return more", "response": "Push a line to the interpreter."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef show_in_pager(self, strng, *args, **kwargs):\n    # On PyDev we just output the string, there are scroll bars in the console\n    # to handle \"paging\". This is the same behaviour as when TERM==dump (see\n    # page.py)\n    # for compatibility with mime-bundle form:\n    if isinstance(strng, dict):\n        strng = strng.get('text/plain', strng)\n    print(strng)", "response": "Run a string through pager"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef matchers(self):\n        # To remove python_matches we now have to override it as it's now a property in the superclass.\n        return [\n            self.file_matches,\n            self.magic_matches,\n            self.python_func_kw_matches,\n            self.dict_key_matches,\n        ]", "response": "All active matcher routines for completion"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef enable_gui(gui=None, app=None):\n        # Deferred import\n        from pydev_ipython.inputhook import enable_gui as real_enable_gui\n        try:\n            return real_enable_gui(gui, app)\n        except ValueError as e:\n            raise UsageError(\"%s\" % e)", "response": "Switch amongst GUI input hooks by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef init_completer(self):\n        # PyDev uses its own completer and custom hooks so that it uses\n        # most completions from PyDev's core completer which provides\n        # extra information.\n        # See getCompletions for where the two sets of results are merged\n\n        if IPythonRelease._version_major >= 6:\n            self.Completer = self._new_completer_600()\n        elif IPythonRelease._version_major >= 5:\n            self.Completer = self._new_completer_500()\n        elif IPythonRelease._version_major >= 2:\n            self.Completer = self._new_completer_234()\n        elif IPythonRelease._version_major >= 1:\n            self.Completer = self._new_completer_100()\n\n        if hasattr(self.Completer, 'use_jedi'):\n            self.Completer.use_jedi = False\n\n        self.add_completer_hooks()\n\n        if IPythonRelease._version_major <= 3:\n            # Only configure readline if we truly are using readline.  IPython can\n            # do tab-completion over the network, in GUIs, etc, where readline\n            # itself may be absent\n            if self.has_readline:\n                self.set_readline_completer()", "response": "Initialize the completer machinery."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef open_handle(self, dwDesiredAccess = win32.PROCESS_ALL_ACCESS):\n        hProcess = win32.OpenProcess(dwDesiredAccess, win32.FALSE, self.dwProcessId)\n\n        try:\n            self.close_handle()\n        except Exception:\n            warnings.warn(\n                \"Failed to close process handle: %s\" % traceback.format_exc())\n\n        self.hProcess = hProcess", "response": "Opens a new handle to the process and sets the process s process property to the process s handle."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncloses the handle to the process.", "response": "def close_handle(self):\n        \"\"\"\n        Closes the handle to the process.\n\n        @note: Normally you don't need to call this method. All handles\n            created by I{WinAppDbg} are automatically closed when the garbage\n            collector claims them. So unless you've been tinkering with it,\n            setting L{hProcess} to C{None} should be enough.\n        \"\"\"\n        try:\n            if hasattr(self.hProcess, 'close'):\n                self.hProcess.close()\n            elif self.hProcess not in (None, win32.INVALID_HANDLE_VALUE):\n                win32.CloseHandle(self.hProcess)\n        finally:\n            self.hProcess = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a handle to the process with I { at least } the access rights requested.", "response": "def get_handle(self, dwDesiredAccess = win32.PROCESS_ALL_ACCESS):\n        \"\"\"\n        Returns a handle to the process with I{at least} the access rights\n        requested.\n\n        @note:\n            If a handle was previously opened and has the required access\n            rights, it's reused. If not, a new handle is opened with the\n            combination of the old and new access rights.\n\n        @type  dwDesiredAccess: int\n        @param dwDesiredAccess: Desired access rights.\n            Defaults to L{win32.PROCESS_ALL_ACCESS}.\n            See: U{http://msdn.microsoft.com/en-us/library/windows/desktop/ms684880(v=vs.85).aspx}\n\n        @rtype:  L{ProcessHandle}\n        @return: Handle to the process.\n\n        @raise WindowsError: It's not possible to open a handle to the process\n            with the requested access rights. This tipically happens because\n            the target process is a system process and the debugger is not\n            runnning with administrative rights.\n        \"\"\"\n        if self.hProcess in (None, win32.INVALID_HANDLE_VALUE):\n            self.open_handle(dwDesiredAccess)\n        else:\n            dwAccess = self.hProcess.dwAccess\n            if (dwAccess | dwDesiredAccess) != dwAccess:\n                self.open_handle(dwAccess | dwDesiredAccess)\n        return self.hProcess"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nterminate the execution of the process.", "response": "def kill(self, dwExitCode = 0):\n        \"\"\"\n        Terminates the execution of the process.\n\n        @raise WindowsError: On error an exception is raised.\n        \"\"\"\n        hProcess = self.get_handle(win32.PROCESS_TERMINATE)\n        win32.TerminateProcess(hProcess, dwExitCode)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsuspend execution on all threads of the process.", "response": "def suspend(self):\n        \"\"\"\n        Suspends execution on all threads of the process.\n\n        @raise WindowsError: On error an exception is raised.\n        \"\"\"\n        self.scan_threads() # force refresh the snapshot\n        suspended = list()\n        try:\n            for aThread in self.iter_threads():\n                aThread.suspend()\n                suspended.append(aThread)\n        except Exception:\n            for aThread in suspended:\n                try:\n                    aThread.resume()\n                except Exception:\n                    pass\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresumes execution on all threads of the process.", "response": "def resume(self):\n        \"\"\"\n        Resumes execution on all threads of the process.\n\n        @raise WindowsError: On error an exception is raised.\n        \"\"\"\n        if self.get_thread_count() == 0:\n            self.scan_threads() # only refresh the snapshot if empty\n        resumed = list()\n        try:\n            for aThread in self.iter_threads():\n                aThread.resume()\n                resumed.append(aThread)\n        except Exception:\n            for aThread in resumed:\n                try:\n                    aThread.suspend()\n                except Exception:\n                    pass\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking to see if the process is being debugged by another process.", "response": "def is_debugged(self):\n        \"\"\"\n        Tries to determine if the process is being debugged by another process.\n        It may detect other debuggers besides WinAppDbg.\n\n        @rtype:  bool\n        @return: C{True} if the process has a debugger attached.\n\n        @warning:\n            May return inaccurate results when some anti-debug techniques are\n            used by the target process.\n\n        @note: To know if a process currently being debugged by a L{Debug}\n            object, call L{Debug.is_debugee} instead.\n        \"\"\"\n        # FIXME the MSDN docs don't say what access rights are needed here!\n        hProcess = self.get_handle(win32.PROCESS_QUERY_INFORMATION)\n        return win32.CheckRemoteDebuggerPresent(hProcess)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the exit code of the process with the given object.", "response": "def get_exit_code(self):\n        \"\"\"\n        @rtype:  int\n        @return: Process exit code, or C{STILL_ACTIVE} if it's still alive.\n\n        @warning: If a process returns C{STILL_ACTIVE} as it's exit code,\n            you may not be able to determine if it's active or not with this\n            method. Use L{is_alive} to check if the process is still active.\n            Alternatively you can call L{get_handle} to get the handle object\n            and then L{ProcessHandle.wait} on it to wait until the process\n            finishes running.\n        \"\"\"\n        if win32.PROCESS_ALL_ACCESS == win32.PROCESS_ALL_ACCESS_VISTA:\n            dwAccess = win32.PROCESS_QUERY_LIMITED_INFORMATION\n        else:\n            dwAccess = win32.PROCESS_QUERY_INFORMATION\n        return win32.GetExitCodeProcess( self.get_handle(dwAccess) )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndisassembles instructions from a block of binary code.", "response": "def disassemble_string(self, lpAddress, code):\n        \"\"\"\n        Disassemble instructions from a block of binary code.\n\n        @type  lpAddress: int\n        @param lpAddress: Memory address where the code was read from.\n\n        @type  code: str\n        @param code: Binary code to disassemble.\n\n        @rtype:  list of tuple( long, int, str, str )\n        @return: List of tuples. Each tuple represents an assembly instruction\n            and contains:\n             - Memory address of instruction.\n             - Size of instruction in bytes.\n             - Disassembly line of instruction.\n             - Hexadecimal dump of instruction.\n\n        @raise NotImplementedError:\n            No compatible disassembler was found for the current platform.\n        \"\"\"\n        try:\n            disasm = self.__disasm\n        except AttributeError:\n            disasm = self.__disasm = Disassembler( self.get_arch() )\n        return disasm.decode(lpAddress, code)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndisassembling the binary code from the memory of the process.", "response": "def disassemble(self, lpAddress, dwSize):\n        \"\"\"\n        Disassemble instructions from the address space of the process.\n\n        @type  lpAddress: int\n        @param lpAddress: Memory address where to read the code from.\n\n        @type  dwSize: int\n        @param dwSize: Size of binary code to disassemble.\n\n        @rtype:  list of tuple( long, int, str, str )\n        @return: List of tuples. Each tuple represents an assembly instruction\n            and contains:\n             - Memory address of instruction.\n             - Size of instruction in bytes.\n             - Disassembly line of instruction.\n             - Hexadecimal dump of instruction.\n        \"\"\"\n        data   = self.read(lpAddress, dwSize)\n        disasm = self.disassemble_string(lpAddress, data)\n        self.__fixup_labels(disasm)\n        return disasm"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef disassemble_around(self, lpAddress, dwSize = 64):\n        dwDelta  = int(float(dwSize) / 2.0)\n        addr_1   = lpAddress - dwDelta\n        addr_2   = lpAddress\n        size_1   = dwDelta\n        size_2   = dwSize - dwDelta\n        data     = self.read(addr_1, dwSize)\n        data_1   = data[:size_1]\n        data_2   = data[size_1:]\n        disasm_1 = self.disassemble_string(addr_1, data_1)\n        disasm_2 = self.disassemble_string(addr_2, data_2)\n        disasm   = disasm_1 + disasm_2\n        self.__fixup_labels(disasm)\n        return disasm", "response": "Disassemble a set of code from the memory around the given address."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef disassemble_around_pc(self, dwThreadId, dwSize = 64):\n        aThread = self.get_thread(dwThreadId)\n        return self.disassemble_around(aThread.get_pc(), dwSize)", "response": "Disassemble the instruction at the given program counter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef disassemble_current(self, dwThreadId):\n        aThread = self.get_thread(dwThreadId)\n        return self.disassemble_instruction(aThread.get_pc())", "response": "Disassemble the current instruction at the given program counter."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines if the process is running under WOW64.", "response": "def is_wow64(self):\n        \"\"\"\n        Determines if the process is running under WOW64.\n\n        @rtype:  bool\n        @return:\n            C{True} if the process is running under WOW64. That is, a 32-bit\n            application running in a 64-bit Windows.\n\n            C{False} if the process is either a 32-bit application running in\n            a 32-bit Windows, or a 64-bit application running in a 64-bit\n            Windows.\n\n        @raise WindowsError: On error an exception is raised.\n\n        @see: U{http://msdn.microsoft.com/en-us/library/aa384249(VS.85).aspx}\n        \"\"\"\n        try:\n            wow64 = self.__wow64\n        except AttributeError:\n            if (win32.bits == 32 and not win32.wow64):\n                wow64 = False\n            else:\n                if win32.PROCESS_ALL_ACCESS == win32.PROCESS_ALL_ACCESS_VISTA:\n                    dwAccess = win32.PROCESS_QUERY_LIMITED_INFORMATION\n                else:\n                    dwAccess = win32.PROCESS_QUERY_INFORMATION\n                hProcess = self.get_handle(dwAccess)\n                try:\n                    wow64 = win32.IsWow64Process(hProcess)\n                except AttributeError:\n                    wow64 = False\n            self.__wow64 = wow64\n        return wow64"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_start_time(self):\n        if win32.PROCESS_ALL_ACCESS == win32.PROCESS_ALL_ACCESS_VISTA:\n            dwAccess = win32.PROCESS_QUERY_LIMITED_INFORMATION\n        else:\n            dwAccess = win32.PROCESS_QUERY_INFORMATION\n        hProcess = self.get_handle(dwAccess)\n        CreationTime = win32.GetProcessTimes(hProcess)[0]\n        return win32.FileTimeToSystemTime(CreationTime)", "response": "Determines when has this process started running."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetermines when has this process finished running.", "response": "def get_exit_time(self):\n        \"\"\"\n        Determines when has this process finished running.\n        If the process is still alive, the current time is returned instead.\n\n        @rtype:  win32.SYSTEMTIME\n        @return: Process exit time.\n        \"\"\"\n        if self.is_alive():\n            ExitTime = win32.GetSystemTimeAsFileTime()\n        else:\n            if win32.PROCESS_ALL_ACCESS == win32.PROCESS_ALL_ACCESS_VISTA:\n                dwAccess = win32.PROCESS_QUERY_LIMITED_INFORMATION\n            else:\n                dwAccess = win32.PROCESS_QUERY_INFORMATION\n            hProcess = self.get_handle(dwAccess)\n            ExitTime = win32.GetProcessTimes(hProcess)[1]\n        return win32.FileTimeToSystemTime(ExitTime)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_running_time(self):\n        if win32.PROCESS_ALL_ACCESS == win32.PROCESS_ALL_ACCESS_VISTA:\n            dwAccess = win32.PROCESS_QUERY_LIMITED_INFORMATION\n        else:\n            dwAccess = win32.PROCESS_QUERY_INFORMATION\n        hProcess = self.get_handle(dwAccess)\n        (CreationTime, ExitTime, _, _) = win32.GetProcessTimes(hProcess)\n        if self.is_alive():\n            ExitTime = win32.GetSystemTimeAsFileTime()\n        CreationTime = CreationTime.dwLowDateTime + (CreationTime.dwHighDateTime << 32)\n        ExitTime     =     ExitTime.dwLowDateTime + (    ExitTime.dwHighDateTime << 32)\n        RunningTime  = ExitTime - CreationTime\n        return RunningTime / 10000", "response": "Determines how long has this process been running."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_services(self):\n        self.__load_System_class()\n        pid = self.get_pid()\n        return [d for d in System.get_active_services() if d.ProcessId == pid]", "response": "Returns the list of system services that are currently running in\n        this process."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the DEP policy for this process.", "response": "def get_dep_policy(self):\n        \"\"\"\n        Retrieves the DEP (Data Execution Prevention) policy for this process.\n\n        @note: This method is only available in Windows XP SP3 and above, and\n            only for 32 bit processes. It will fail in any other circumstance.\n\n        @see: U{http://msdn.microsoft.com/en-us/library/bb736297(v=vs.85).aspx}\n\n        @rtype:  tuple(int, int)\n        @return:\n            The first member of the tuple is the DEP flags. It can be a\n            combination of the following values:\n             - 0: DEP is disabled for this process.\n             - 1: DEP is enabled for this process. (C{PROCESS_DEP_ENABLE})\n             - 2: DEP-ATL thunk emulation is disabled for this process.\n                  (C{PROCESS_DEP_DISABLE_ATL_THUNK_EMULATION})\n\n            The second member of the tuple is the permanent flag. If C{TRUE}\n            the DEP settings cannot be changed in runtime for this process.\n\n        @raise WindowsError: On error an exception is raised.\n        \"\"\"\n        hProcess = self.get_handle(win32.PROCESS_QUERY_INFORMATION)\n        try:\n            return win32.kernel32.GetProcessDEPPolicy(hProcess)\n        except AttributeError:\n            msg = \"This method is only available in Windows XP SP3 and above.\"\n            raise NotImplementedError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_peb(self):\n        self.get_handle( win32.PROCESS_VM_READ |\n                         win32.PROCESS_QUERY_INFORMATION )\n        return self.read_structure(self.get_peb_address(), win32.PEB)", "response": "Returns a copy of the PEB."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_peb_address(self):\n        try:\n            return self._peb_ptr\n        except AttributeError:\n            hProcess = self.get_handle(win32.PROCESS_QUERY_INFORMATION)\n            pbi = win32.NtQueryInformationProcess(hProcess,\n                                                win32.ProcessBasicInformation)\n            address = pbi.PebBaseAddress\n            self._peb_ptr = address\n            return address", "response": "Returns a remote pointer to the PEB."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the command line block memory address and size.", "response": "def get_command_line_block(self):\n        \"\"\"\n        Retrieves the command line block memory address and size.\n\n        @rtype:  tuple(int, int)\n        @return: Tuple with the memory address of the command line block\n            and it's maximum size in Unicode characters.\n\n        @raise WindowsError: On error an exception is raised.\n        \"\"\"\n        peb = self.get_peb()\n        pp = self.read_structure(peb.ProcessParameters,\n                                             win32.RTL_USER_PROCESS_PARAMETERS)\n        s = pp.CommandLine\n        return (s.Buffer, s.MaximumLength)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves the environment block memory address for the process.", "response": "def get_environment_block(self):\n        \"\"\"\n        Retrieves the environment block memory address for the process.\n\n        @note: The size is always enough to contain the environment data, but\n            it may not be an exact size. It's best to read the memory and\n            scan for two null wide chars to find the actual size.\n\n        @rtype:  tuple(int, int)\n        @return: Tuple with the memory address of the environment block\n            and it's size.\n\n        @raise WindowsError: On error an exception is raised.\n        \"\"\"\n        peb = self.get_peb()\n        pp = self.read_structure(peb.ProcessParameters,\n                                             win32.RTL_USER_PROCESS_PARAMETERS)\n        Environment = pp.Environment\n        try:\n            EnvironmentSize = pp.EnvironmentSize\n        except AttributeError:\n            mbi = self.mquery(Environment)\n            EnvironmentSize = mbi.RegionSize + mbi.BaseAddress - Environment\n        return (Environment, EnvironmentSize)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve the command line of the current user.", "response": "def get_command_line(self):\n        \"\"\"\n        Retrieves the command line with wich the program was started.\n\n        @rtype:  str\n        @return: Command line string.\n\n        @raise WindowsError: On error an exception is raised.\n        \"\"\"\n        (Buffer, MaximumLength) = self.get_command_line_block()\n        CommandLine = self.peek_string(Buffer, dwMaxSize=MaximumLength,\n                                                            fUnicode=True)\n        gst = win32.GuessStringType\n        if gst.t_default == gst.t_ansi:\n            CommandLine = CommandLine.encode('cp1252')\n        return CommandLine"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_environment_variables(self):\n\n        # Note: the first bytes are garbage and must be skipped. Then the first\n        # two environment entries are the current drive and directory as key\n        # and value pairs, followed by the ExitCode variable (it's what batch\n        # files know as \"errorlevel\"). After that, the real environment vars\n        # are there in alphabetical order. In theory that's where it stops,\n        # but I've always seen one more \"variable\" tucked at the end which\n        # may be another environment block but in ANSI. I haven't examined it\n        # yet, I'm just skipping it because if it's parsed as Unicode it just\n        # renders garbage.\n\n        # Read the environment block contents.\n        data = self.peek( *self.get_environment_block() )\n\n        # Put them into a Unicode buffer.\n        tmp = ctypes.create_string_buffer(data)\n        buffer = ctypes.create_unicode_buffer(len(data))\n        ctypes.memmove(buffer, tmp, len(data))\n        del tmp\n\n        # Skip until the first Unicode null char is found.\n        pos = 0\n        while buffer[pos] != u'\\0':\n            pos += 1\n        pos += 1\n\n        # Loop for each environment variable...\n        environment = []\n        while buffer[pos] != u'\\0':\n\n            # Until we find a null char...\n            env_name_pos = pos\n            env_name = u''\n            found_name = False\n            while buffer[pos] != u'\\0':\n\n                # Get the current char.\n                char = buffer[pos]\n\n                # Is it an equal sign?\n                if char == u'=':\n\n                    # Skip leading equal signs.\n                    if env_name_pos == pos:\n                        env_name_pos += 1\n                        pos += 1\n                        continue\n\n                    # Otherwise we found the separator equal sign.\n                    pos += 1\n                    found_name = True\n                    break\n\n                # Add the char to the variable name.\n                env_name += char\n\n                # Next char.\n                pos += 1\n\n            # If the name was not parsed properly, stop.\n            if not found_name:\n                break\n\n            # Read the variable value until we find a null char.\n            env_value = u''\n            while buffer[pos] != u'\\0':\n                env_value += buffer[pos]\n                pos += 1\n\n            # Skip the null char.\n            pos += 1\n\n            # Add to the list of environment variables found.\n            environment.append( (env_name, env_value) )\n\n        # Remove the last entry, it's garbage.\n        if environment:\n            environment.pop()\n\n        # Return the environment variables.\n        return environment", "response": "Retrieves the environment variables that are set in the process memory."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the environment block data with wich the program is running.", "response": "def get_environment_data(self, fUnicode = None):\n        \"\"\"\n        Retrieves the environment block data with wich the program is running.\n\n        @warn: Deprecated since WinAppDbg 1.5.\n\n        @see: L{win32.GuessStringType}\n\n        @type  fUnicode: bool or None\n        @param fUnicode: C{True} to return a list of Unicode strings, C{False}\n            to return a list of ANSI strings, or C{None} to return whatever\n            the default is for string types.\n\n        @rtype:  list of str\n        @return: Environment keys and values separated by a (C{=}) character,\n            as found in the process memory.\n\n        @raise WindowsError: On error an exception is raised.\n        \"\"\"\n\n        # Issue a deprecation warning.\n        warnings.warn(\n            \"Process.get_environment_data() is deprecated\" \\\n            \" since WinAppDbg 1.5.\",\n            DeprecationWarning)\n\n        # Get the environment variables.\n        block = [ key + u'=' + value for (key, value) \\\n                                     in self.get_environment_variables() ]\n\n        # Convert the data to ANSI if requested.\n        if fUnicode is None:\n            gst = win32.GuessStringType\n            fUnicode = gst.t_default == gst.t_unicode\n        if not fUnicode:\n            block = [x.encode('cp1252') for x in block]\n\n        # Return the environment data.\n        return block"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the environment data into a Python dictionary.", "response": "def parse_environment_data(block):\n        \"\"\"\n        Parse the environment block into a Python dictionary.\n\n        @warn: Deprecated since WinAppDbg 1.5.\n\n        @note: Values of duplicated keys are joined using null characters.\n\n        @type  block: list of str\n        @param block: List of strings as returned by L{get_environment_data}.\n\n        @rtype:  dict(str S{->} str)\n        @return: Dictionary of environment keys and values.\n        \"\"\"\n\n        # Issue a deprecation warning.\n        warnings.warn(\n            \"Process.parse_environment_data() is deprecated\" \\\n            \" since WinAppDbg 1.5.\",\n            DeprecationWarning)\n\n        # Create an empty environment dictionary.\n        environment = dict()\n\n        # End here if the environment block is empty.\n        if not block:\n            return environment\n\n        # Prepare the tokens (ANSI or Unicode).\n        gst = win32.GuessStringType\n        if type(block[0]) == gst.t_ansi:\n            equals = '='\n            terminator = '\\0'\n        else:\n            equals = u'='\n            terminator = u'\\0'\n\n        # Split the blocks into key/value pairs.\n        for chunk in block:\n            sep = chunk.find(equals, 1)\n            if sep < 0:\n##                raise Exception()\n                continue    # corrupted environment block?\n            key, value = chunk[:sep], chunk[sep+1:]\n\n            # For duplicated keys, append the value.\n            # Values are separated using null terminators.\n            if key not in environment:\n                environment[key] = value\n            else:\n                environment[key] += terminator + value\n\n        # Return the environment dictionary.\n        return environment"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_environment(self, fUnicode = None):\n\n        # Get the environment variables.\n        variables = self.get_environment_variables()\n\n        # Convert the strings to ANSI if requested.\n        if fUnicode is None:\n            gst = win32.GuessStringType\n            fUnicode = gst.t_default == gst.t_unicode\n        if not fUnicode:\n            variables = [ ( key.encode('cp1252'), value.encode('cp1252') ) \\\n                        for (key, value) in variables ]\n\n        # Add the variables to a dictionary, concatenating duplicates.\n        environment = dict()\n        for key, value in variables:\n            if key in environment:\n                environment[key] = environment[key] + u'\\0' + value\n            else:\n                environment[key] = value\n\n        # Return the dictionary.\n        return environment", "response": "Returns the environment variables and values for the current process."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search(self, pattern, minAddr = None, maxAddr = None):\n        if isinstance(pattern, str):\n            return self.search_bytes(pattern, minAddr, maxAddr)\n        if isinstance(pattern, compat.unicode):\n            return self.search_bytes(pattern.encode(\"utf-16le\"),\n                                     minAddr, maxAddr)\n        if isinstance(pattern, Pattern):\n            return Search.search_process(self, pattern, minAddr, maxAddr)\n        raise TypeError(\"Unknown pattern type: %r\" % type(pattern))", "response": "Search for the given pattern within the process memory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search_bytes(self, bytes, minAddr = None, maxAddr = None):\n        pattern = BytePattern(bytes)\n        matches = Search.search_process(self, pattern, minAddr, maxAddr)\n        for addr, size, data in matches:\n            yield addr", "response": "Search for the given byte pattern within the process memory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search_text(self, text, encoding = \"utf-16le\",\n                                caseSensitive = False,\n                                minAddr = None,\n                                maxAddr = None):\n        \"\"\"\n        Search for the given text within the process memory.\n\n        @type  text: str or compat.unicode\n        @param text: Text to search for.\n\n        @type  encoding: str\n        @param encoding: (Optional) Encoding for the text parameter.\n            Only used when the text to search for is a Unicode string.\n            Don't change unless you know what you're doing!\n\n        @type  caseSensitive: bool\n        @param caseSensitive: C{True} of the search is case sensitive,\n            C{False} otherwise.\n\n        @type  minAddr: int\n        @param minAddr: (Optional) Start the search at this memory address.\n\n        @type  maxAddr: int\n        @param maxAddr: (Optional) Stop the search at this memory address.\n\n        @rtype:  iterator of tuple( int, str )\n        @return: An iterator of tuples. Each tuple contains the following:\n             - The memory address where the pattern was found.\n             - The text that matches the pattern.\n\n        @raise WindowsError: An error occurred when querying or reading the\n            process memory.\n        \"\"\"\n        pattern = TextPattern(text, encoding, caseSensitive)\n        matches = Search.search_process(self, pattern, minAddr, maxAddr)\n        for addr, size, data in matches:\n            yield addr, data", "response": "Search for the given text within the process memory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search_regexp(self, regexp, flags = 0,\n                                    minAddr = None,\n                                    maxAddr = None,\n                                    bufferPages = -1):\n        \"\"\"\n        Search for the given regular expression within the process memory.\n\n        @type  regexp: str\n        @param regexp: Regular expression string.\n\n        @type  flags: int\n        @param flags: Regular expression flags.\n\n        @type  minAddr: int\n        @param minAddr: (Optional) Start the search at this memory address.\n\n        @type  maxAddr: int\n        @param maxAddr: (Optional) Stop the search at this memory address.\n\n        @type  bufferPages: int\n        @param bufferPages: (Optional) Number of memory pages to buffer when\n            performing the search. Valid values are:\n             - C{0} or C{None}:\n               Automatically determine the required buffer size. May not give\n               complete results for regular expressions that match variable\n               sized strings.\n             - C{> 0}: Set the buffer size, in memory pages.\n             - C{< 0}: Disable buffering entirely. This may give you a little\n               speed gain at the cost of an increased memory usage. If the\n               target process has very large contiguous memory regions it may\n               actually be slower or even fail. It's also the only way to\n               guarantee complete results for regular expressions that match\n               variable sized strings.\n\n        @rtype:  iterator of tuple( int, int, str )\n        @return: An iterator of tuples. Each tuple contains the following:\n             - The memory address where the pattern was found.\n             - The size of the data that matches the pattern.\n             - The data that matches the pattern.\n\n        @raise WindowsError: An error occurred when querying or reading the\n            process memory.\n        \"\"\"\n        pattern = RegExpPattern(regexp, flags)\n        return Search.search_process(self, pattern,\n                                     minAddr, maxAddr,\n                                     bufferPages)", "response": "Search for the given regular expression within the process memory."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches for the given hexadecimal pattern within the process memory.", "response": "def search_hexa(self, hexa, minAddr = None, maxAddr = None):\n        \"\"\"\n        Search for the given hexadecimal pattern within the process memory.\n\n        Hex patterns must be in this form::\n            \"68 65 6c 6c 6f 20 77 6f 72 6c 64\"  # \"hello world\"\n\n        Spaces are optional. Capitalization of hex digits doesn't matter.\n        This is exactly equivalent to the previous example::\n            \"68656C6C6F20776F726C64\"            # \"hello world\"\n\n        Wildcards are allowed, in the form of a C{?} sign in any hex digit::\n            \"5? 5? c3\"          # pop register / pop register / ret\n            \"b8 ?? ?? ?? ??\"    # mov eax, immediate value\n\n        @type  hexa: str\n        @param hexa: Pattern to search for.\n\n        @type  minAddr: int\n        @param minAddr: (Optional) Start the search at this memory address.\n\n        @type  maxAddr: int\n        @param maxAddr: (Optional) Stop the search at this memory address.\n\n        @rtype:  iterator of tuple( int, str )\n        @return: An iterator of tuples. Each tuple contains the following:\n             - The memory address where the pattern was found.\n             - The bytes that match the pattern.\n\n        @raise WindowsError: An error occurred when querying or reading the\n            process memory.\n        \"\"\"\n        pattern = HexPattern(hexa)\n        matches = Search.search_process(self, pattern, minAddr, maxAddr)\n        for addr, size, data in matches:\n            yield addr, data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting ASCII strings from the process memory.", "response": "def strings(self, minSize = 4, maxSize = 1024):\n        \"\"\"\n        Extract ASCII strings from the process memory.\n\n        @type  minSize: int\n        @param minSize: (Optional) Minimum size of the strings to search for.\n\n        @type  maxSize: int\n        @param maxSize: (Optional) Maximum size of the strings to search for.\n\n        @rtype:  iterator of tuple(int, int, str)\n        @return: Iterator of strings extracted from the process memory.\n            Each tuple contains the following:\n             - The memory address where the string was found.\n             - The size of the string.\n             - The string.\n        \"\"\"\n        return Search.extract_ascii_strings(self, minSize = minSize,\n                                                  maxSize = maxSize)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read(self, lpBaseAddress, nSize):\n        hProcess = self.get_handle( win32.PROCESS_VM_READ |\n                                    win32.PROCESS_QUERY_INFORMATION )\n        if not self.is_buffer(lpBaseAddress, nSize):\n            raise ctypes.WinError(win32.ERROR_INVALID_ADDRESS)\n        data = win32.ReadProcessMemory(hProcess, lpBaseAddress, nSize)\n        if len(data) != nSize:\n            raise ctypes.WinError()\n        return data", "response": "Reads from the memory of the process."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write(self, lpBaseAddress, lpBuffer):\n        r = self.poke(lpBaseAddress, lpBuffer)\n        if r != len(lpBuffer):\n            raise ctypes.WinError()", "response": "Writes to the memory of the process s base memory."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading an integer from the memory of the process.", "response": "def read_int(self, lpBaseAddress):\n        \"\"\"\n        Reads a signed integer from the memory of the process.\n\n        @see: L{peek_int}\n\n        @type  lpBaseAddress: int\n        @param lpBaseAddress: Memory address to begin reading.\n\n        @rtype:  int\n        @return: Integer value read from the process memory.\n\n        @raise WindowsError: On error an exception is raised.\n        \"\"\"\n        return self.__read_c_type(lpBaseAddress, compat.b('@l'), ctypes.c_int)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_structure(self, lpBaseAddress, stype):\n        if type(lpBaseAddress) not in (type(0), type(long(0))):\n            lpBaseAddress = ctypes.cast(lpBaseAddress, ctypes.c_void_p)\n        data = self.read(lpBaseAddress, ctypes.sizeof(stype))\n        buff = ctypes.create_string_buffer(data)\n        ptr  = ctypes.cast(ctypes.pointer(buff), ctypes.POINTER(stype))\n        return ptr.contents", "response": "Reads a ctypes structure from the process memory of the process."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_string(self, lpBaseAddress, nChars, fUnicode = False):\n        if fUnicode:\n            nChars = nChars * 2\n        szString = self.read(lpBaseAddress, nChars)\n        if fUnicode:\n            szString = compat.unicode(szString, 'U16', 'ignore')\n        return szString", "response": "Reads an ASCII or Unicode string from the memory space of the process."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef peek(self, lpBaseAddress, nSize):\n        # XXX TODO\n        # + Maybe change page permissions before trying to read?\n        # + Maybe use mquery instead of get_memory_map?\n        #   (less syscalls if we break out of the loop earlier)\n        data = ''\n        if nSize > 0:\n            try:\n                hProcess = self.get_handle( win32.PROCESS_VM_READ |\n                                            win32.PROCESS_QUERY_INFORMATION )\n                for mbi in self.get_memory_map(lpBaseAddress,\n                                               lpBaseAddress + nSize):\n                    if not mbi.is_readable():\n                        nSize = mbi.BaseAddress - lpBaseAddress\n                        break\n                if nSize > 0:\n                    data = win32.ReadProcessMemory(\n                                    hProcess, lpBaseAddress, nSize)\n            except WindowsError:\n                e = sys.exc_info()[1]\n                msg = \"Error reading process %d address %s: %s\"\n                msg %= (self.get_pid(),\n                        HexDump.address(lpBaseAddress),\n                        e.strerror)\n                warnings.warn(msg)\n        return data", "response": "Reads the memory of the process."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef poke(self, lpBaseAddress, lpBuffer):\n        assert isinstance(lpBuffer, compat.bytes)\n        hProcess = self.get_handle( win32.PROCESS_VM_WRITE |\n                                    win32.PROCESS_VM_OPERATION |\n                                    win32.PROCESS_QUERY_INFORMATION )\n        mbi = self.mquery(lpBaseAddress)\n        if not mbi.has_content():\n            raise ctypes.WinError(win32.ERROR_INVALID_ADDRESS)\n        if mbi.is_image() or mbi.is_mapped():\n            prot = win32.PAGE_WRITECOPY\n        elif mbi.is_writeable():\n            prot = None\n        elif mbi.is_executable():\n            prot = win32.PAGE_EXECUTE_READWRITE\n        else:\n            prot = win32.PAGE_READWRITE\n        if prot is not None:\n            try:\n                self.mprotect(lpBaseAddress, len(lpBuffer), prot)\n            except Exception:\n                prot = None\n                msg = (\"Failed to adjust page permissions\"\n                       \" for process %s at address %s: %s\")\n                msg = msg % (self.get_pid(),\n                             HexDump.address(lpBaseAddress, self.get_bits()),\n                             traceback.format_exc())\n                warnings.warn(msg, RuntimeWarning)\n        try:\n            r = win32.WriteProcessMemory(hProcess, lpBaseAddress, lpBuffer)\n        finally:\n            if prot is not None:\n                self.mprotect(lpBaseAddress, len(lpBuffer), mbi.Protect)\n        return r", "response": "Writes to the memory of the process."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef peek_char(self, lpBaseAddress):\n        char = self.peek(lpBaseAddress, 1)\n        if char:\n            return ord(char)\n        return 0", "response": "Reads a single character from the memory of the process."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads an ASCII or Unicode string from the process memory space.", "response": "def peek_string(self, lpBaseAddress, fUnicode = False, dwMaxSize = 0x1000):\n        \"\"\"\n        Tries to read an ASCII or Unicode string\n        from the address space of the process.\n\n        @see: L{read_string}\n\n        @type  lpBaseAddress: int\n        @param lpBaseAddress: Memory address to begin reading.\n\n        @type  fUnicode: bool\n        @param fUnicode: C{True} is the string is expected to be Unicode,\n            C{False} if it's expected to be ANSI.\n\n        @type  dwMaxSize: int\n        @param dwMaxSize: Maximum allowed string length to read, in bytes.\n\n        @rtype:  str, compat.unicode\n        @return: String read from the process memory space.\n            It B{doesn't} include the terminating null character.\n            Returns an empty string on failure.\n        \"\"\"\n\n        # Validate the parameters.\n        if not lpBaseAddress or dwMaxSize == 0:\n            if fUnicode:\n                return u''\n            return ''\n        if not dwMaxSize:\n            dwMaxSize = 0x1000\n\n        # Read the string.\n        szString = self.peek(lpBaseAddress, dwMaxSize)\n\n        # If the string is Unicode...\n        if fUnicode:\n\n            # Decode the string.\n            szString = compat.unicode(szString, 'U16', 'replace')\n##            try:\n##                szString = compat.unicode(szString, 'U16')\n##            except UnicodeDecodeError:\n##                szString = struct.unpack('H' * (len(szString) / 2), szString)\n##                szString = [ unichr(c) for c in szString ]\n##                szString = u''.join(szString)\n\n            # Truncate the string when the first null char is found.\n            szString = szString[ : szString.find(u'\\0') ]\n\n        # If the string is ANSI...\n        else:\n\n            # Truncate the string when the first null char is found.\n            szString = szString[ : szString.find('\\0') ]\n\n        # Return the decoded string.\n        return szString"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef peek_pointers_in_data(self, data, peekSize = 16, peekStep = 1):\n        result = dict()\n        ptrSize = win32.sizeof(win32.LPVOID)\n        if ptrSize == 4:\n            ptrFmt = '<L'\n        else:\n            ptrFmt = '<Q'\n        if len(data) > 0:\n            for i in compat.xrange(0, len(data), peekStep):\n                packed          = data[i:i+ptrSize]\n                if len(packed) == ptrSize:\n                    address     = struct.unpack(ptrFmt, packed)[0]\n##                    if not address & (~0xFFFF): continue\n                    peek_data   = self.peek(address, peekSize)\n                    if peek_data:\n                        result[i] = peek_data\n        return result", "response": "Given a binary data string and a size of size of size 4 and a size of size 4 read some data from them and return a dictionary mapping stack offsets to the data they point to."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nallocating memory into the address space of the process.", "response": "def malloc(self, dwSize, lpAddress = None):\n        \"\"\"\n        Allocates memory into the address space of the process.\n\n        @see: L{free}\n\n        @type  dwSize: int\n        @param dwSize: Number of bytes to allocate.\n\n        @type  lpAddress: int\n        @param lpAddress: (Optional)\n            Desired address for the newly allocated memory.\n            This is only a hint, the memory could still be allocated somewhere\n            else.\n\n        @rtype:  int\n        @return: Address of the newly allocated memory.\n\n        @raise WindowsError: On error an exception is raised.\n        \"\"\"\n        hProcess = self.get_handle(win32.PROCESS_VM_OPERATION)\n        return win32.VirtualAllocEx(hProcess, lpAddress, dwSize)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets memory protection in the address space of the process.", "response": "def mprotect(self, lpAddress, dwSize, flNewProtect):\n        \"\"\"\n        Set memory protection in the address space of the process.\n\n        @see: U{http://msdn.microsoft.com/en-us/library/aa366899.aspx}\n\n        @type  lpAddress: int\n        @param lpAddress: Address of memory to protect.\n\n        @type  dwSize: int\n        @param dwSize: Number of bytes to protect.\n\n        @type  flNewProtect: int\n        @param flNewProtect: New protect flags.\n\n        @rtype:  int\n        @return: Old protect flags.\n\n        @raise WindowsError: On error an exception is raised.\n        \"\"\"\n        hProcess = self.get_handle(win32.PROCESS_VM_OPERATION)\n        return win32.VirtualProtectEx(hProcess, lpAddress, dwSize, flNewProtect)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nquery the memory region of the process at the given address space.", "response": "def mquery(self, lpAddress):\n        \"\"\"\n        Query memory information from the address space of the process.\n        Returns a L{win32.MemoryBasicInformation} object.\n\n        @see: U{http://msdn.microsoft.com/en-us/library/aa366907(VS.85).aspx}\n\n        @type  lpAddress: int\n        @param lpAddress: Address of memory to query.\n\n        @rtype:  L{win32.MemoryBasicInformation}\n        @return: Memory region information.\n\n        @raise WindowsError: On error an exception is raised.\n        \"\"\"\n        hProcess = self.get_handle(win32.PROCESS_QUERY_INFORMATION)\n        return win32.VirtualQueryEx(hProcess, lpAddress)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef free(self, lpAddress):\n        hProcess = self.get_handle(win32.PROCESS_VM_OPERATION)\n        win32.VirtualFreeEx(hProcess, lpAddress)", "response": "Free memory from the address space of the process."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines if an address is a valid code or data pointer.", "response": "def is_pointer(self, address):\n        \"\"\"\n        Determines if an address is a valid code or data pointer.\n\n        That is, the address must be valid and must point to code or data in\n        the target process.\n\n        @type  address: int\n        @param address: Memory address to query.\n\n        @rtype:  bool\n        @return: C{True} if the address is a valid code or data pointer.\n\n        @raise WindowsError: An exception is raised on error.\n        \"\"\"\n        try:\n            mbi = self.mquery(address)\n        except WindowsError:\n            e = sys.exc_info()[1]\n            if e.winerror == win32.ERROR_INVALID_PARAMETER:\n                return False\n            raise\n        return mbi.has_content()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_address_valid(self, address):\n        try:\n            mbi = self.mquery(address)\n        except WindowsError:\n            e = sys.exc_info()[1]\n            if e.winerror == win32.ERROR_INVALID_PARAMETER:\n                return False\n            raise\n        return True", "response": "Determines if an address is a valid user mode address."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_address_free(self, address):\n        try:\n            mbi = self.mquery(address)\n        except WindowsError:\n            e = sys.exc_info()[1]\n            if e.winerror == win32.ERROR_INVALID_PARAMETER:\n                return False\n            raise\n        return mbi.is_free()", "response": "Determines if an address belongs to a free page."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining if an address belongs to a reserved page.", "response": "def is_address_reserved(self, address):\n        \"\"\"\n        Determines if an address belongs to a reserved page.\n\n        @note: Returns always C{False} for kernel mode addresses.\n\n        @type  address: int\n        @param address: Memory address to query.\n\n        @rtype:  bool\n        @return: C{True} if the address belongs to a reserved page.\n\n        @raise WindowsError: An exception is raised on error.\n        \"\"\"\n        try:\n            mbi = self.mquery(address)\n        except WindowsError:\n            e = sys.exc_info()[1]\n            if e.winerror == win32.ERROR_INVALID_PARAMETER:\n                return False\n            raise\n        return mbi.is_reserved()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_address_commited(self, address):\n        try:\n            mbi = self.mquery(address)\n        except WindowsError:\n            e = sys.exc_info()[1]\n            if e.winerror == win32.ERROR_INVALID_PARAMETER:\n                return False\n            raise\n        return mbi.is_commited()", "response": "Determines if an address belongs to a commited page."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetermine if an address belongs to a guard page.", "response": "def is_address_guard(self, address):\n        \"\"\"\n        Determines if an address belongs to a guard page.\n\n        @note: Returns always C{False} for kernel mode addresses.\n\n        @type  address: int\n        @param address: Memory address to query.\n\n        @rtype:  bool\n        @return: C{True} if the address belongs to a guard page.\n\n        @raise WindowsError: An exception is raised on error.\n        \"\"\"\n        try:\n            mbi = self.mquery(address)\n        except WindowsError:\n            e = sys.exc_info()[1]\n            if e.winerror == win32.ERROR_INVALID_PARAMETER:\n                return False\n            raise\n        return mbi.is_guard()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_address_readable(self, address):\n        try:\n            mbi = self.mquery(address)\n        except WindowsError:\n            e = sys.exc_info()[1]\n            if e.winerror == win32.ERROR_INVALID_PARAMETER:\n                return False\n            raise\n        return mbi.is_readable()", "response": "Determines if an address belongs to a commited and readable page."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine if an address belongs to a commited and writeable page.", "response": "def is_address_writeable(self, address):\n        \"\"\"\n        Determines if an address belongs to a commited and writeable page.\n        The page may or may not have additional permissions.\n\n        @note: Returns always C{False} for kernel mode addresses.\n\n        @type  address: int\n        @param address: Memory address to query.\n\n        @rtype:  bool\n        @return:\n            C{True} if the address belongs to a commited and writeable page.\n\n        @raise WindowsError: An exception is raised on error.\n        \"\"\"\n        try:\n            mbi = self.mquery(address)\n        except WindowsError:\n            e = sys.exc_info()[1]\n            if e.winerror == win32.ERROR_INVALID_PARAMETER:\n                return False\n            raise\n        return mbi.is_writeable()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine if an address belongs to a commited copy - on - write page.", "response": "def is_address_copy_on_write(self, address):\n        \"\"\"\n        Determines if an address belongs to a commited, copy-on-write page.\n        The page may or may not have additional permissions.\n\n        @note: Returns always C{False} for kernel mode addresses.\n\n        @type  address: int\n        @param address: Memory address to query.\n\n        @rtype:  bool\n        @return:\n            C{True} if the address belongs to a commited, copy-on-write page.\n\n        @raise WindowsError: An exception is raised on error.\n        \"\"\"\n        try:\n            mbi = self.mquery(address)\n        except WindowsError:\n            e = sys.exc_info()[1]\n            if e.winerror == win32.ERROR_INVALID_PARAMETER:\n                return False\n            raise\n        return mbi.is_copy_on_write()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_address_executable(self, address):\n        try:\n            mbi = self.mquery(address)\n        except WindowsError:\n            e = sys.exc_info()[1]\n            if e.winerror == win32.ERROR_INVALID_PARAMETER:\n                return False\n            raise\n        return mbi.is_executable()", "response": "Determines if an address belongs to a commited and executable page."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines if an address belongs to a commited writeable and executable page.", "response": "def is_address_executable_and_writeable(self, address):\n        \"\"\"\n        Determines if an address belongs to a commited, writeable and\n        executable page. The page may or may not have additional permissions.\n\n        Looking for writeable and executable pages is important when\n        exploiting a software vulnerability.\n\n        @note: Returns always C{False} for kernel mode addresses.\n\n        @type  address: int\n        @param address: Memory address to query.\n\n        @rtype:  bool\n        @return:\n            C{True} if the address belongs to a commited, writeable and\n            executable page.\n\n        @raise WindowsError: An exception is raised on error.\n        \"\"\"\n        try:\n            mbi = self.mquery(address)\n        except WindowsError:\n            e = sys.exc_info()[1]\n            if e.winerror == win32.ERROR_INVALID_PARAMETER:\n                return False\n            raise\n        return mbi.is_executable_and_writeable()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_buffer(self, address, size):\n        if size <= 0:\n            raise ValueError(\"The size argument must be greater than zero\")\n        while size > 0:\n            try:\n                mbi = self.mquery(address)\n            except WindowsError:\n                e = sys.exc_info()[1]\n                if e.winerror == win32.ERROR_INVALID_PARAMETER:\n                    return False\n                raise\n            if not mbi.has_content():\n                return False\n            size = size - mbi.RegionSize\n        return True", "response": "Determines if the given memory area is a valid code or data buffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iter_memory_map(self, minAddr = None, maxAddr = None):\n        minAddr, maxAddr = MemoryAddresses.align_address_range(minAddr,maxAddr)\n        prevAddr    = minAddr - 1\n        currentAddr = minAddr\n        while prevAddr < currentAddr < maxAddr:\n            try:\n                mbi = self.mquery(currentAddr)\n            except WindowsError:\n                e = sys.exc_info()[1]\n                if e.winerror == win32.ERROR_INVALID_PARAMETER:\n                    break\n                raise\n            yield mbi\n            prevAddr    = currentAddr\n            currentAddr = mbi.BaseAddress + mbi.RegionSize", "response": "Returns an iterator over the memory map to the process address space."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_mapped_filenames(self, memoryMap = None):\n        hProcess = self.get_handle( win32.PROCESS_VM_READ |\n                                    win32.PROCESS_QUERY_INFORMATION )\n        if not memoryMap:\n            memoryMap = self.get_memory_map()\n        mappedFilenames = dict()\n        for mbi in memoryMap:\n            if mbi.Type not in (win32.MEM_IMAGE, win32.MEM_MAPPED):\n                continue\n            baseAddress = mbi.BaseAddress\n            fileName    = \"\"\n            try:\n                fileName = win32.GetMappedFileName(hProcess, baseAddress)\n                fileName = PathOperations.native_to_win32_pathname(fileName)\n            except WindowsError:\n                #e = sys.exc_info()[1]\n                #try:\n                #    msg = \"Can't get mapped file name at address %s in process \" \\\n                #          \"%d, reason: %s\" % (HexDump.address(baseAddress),\n                #                              self.get_pid(),\n                #                              e.strerror)\n                #    warnings.warn(msg, Warning)\n                #except Exception:\n                pass\n            mappedFilenames[baseAddress] = fileName\n        return mappedFilenames", "response": "Returns the filenames for memory mapped files in the debugee."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an iterator that allows you to iterate through the memory contents of a process.", "response": "def iter_memory_snapshot(self, minAddr = None, maxAddr = None):\n        \"\"\"\n        Returns an iterator that allows you to go through the memory contents\n        of a process.\n\n        It's basically the same as the L{take_memory_snapshot} method, but it\n        takes the snapshot of each memory region as it goes, as opposed to\n        taking the whole snapshot at once. This allows you to work with very\n        large snapshots without a significant performance penalty.\n\n        Example::\n            # Print the memory contents of a process.\n            process.suspend()\n            try:\n                snapshot = process.generate_memory_snapshot()\n                for mbi in snapshot:\n                    print HexDump.hexblock(mbi.content, mbi.BaseAddress)\n            finally:\n                process.resume()\n\n        The downside of this is the process must remain suspended while\n        iterating the snapshot, otherwise strange things may happen.\n\n        The snapshot can only iterated once. To be able to iterate indefinitely\n        call the L{generate_memory_snapshot} method instead.\n\n        You can also iterate the memory of a dead process, just as long as the\n        last open handle to it hasn't been closed.\n\n        @see: L{take_memory_snapshot}\n\n        @type  minAddr: int\n        @param minAddr: (Optional) Starting address in address range to query.\n\n        @type  maxAddr: int\n        @param maxAddr: (Optional) Ending address in address range to query.\n\n        @rtype:  iterator of L{win32.MemoryBasicInformation}\n        @return: Iterator of memory region information objects.\n            Two extra properties are added to these objects:\n             - C{filename}: Mapped filename, or C{None}.\n             - C{content}: Memory contents, or C{None}.\n        \"\"\"\n\n        # One may feel tempted to include calls to self.suspend() and\n        # self.resume() here, but that wouldn't work on a dead process.\n        # It also wouldn't be needed when debugging since the process is\n        # already suspended when the debug event arrives. So it's up to\n        # the user to suspend the process if needed.\n\n        # Get the memory map.\n        memory = self.get_memory_map(minAddr, maxAddr)\n\n        # Abort if the map couldn't be retrieved.\n        if not memory:\n            return\n\n        # Get the mapped filenames.\n        # Don't fail on access denied errors.\n        try:\n            filenames = self.get_mapped_filenames(memory)\n        except WindowsError:\n            e = sys.exc_info()[1]\n            if e.winerror != win32.ERROR_ACCESS_DENIED:\n                raise\n            filenames = dict()\n\n        # Trim the first memory information block if needed.\n        if minAddr is not None:\n            minAddr = MemoryAddresses.align_address_to_page_start(minAddr)\n            mbi = memory[0]\n            if mbi.BaseAddress < minAddr:\n                mbi.RegionSize  = mbi.BaseAddress + mbi.RegionSize - minAddr\n                mbi.BaseAddress = minAddr\n\n        # Trim the last memory information block if needed.\n        if maxAddr is not None:\n            if maxAddr != MemoryAddresses.align_address_to_page_start(maxAddr):\n                maxAddr = MemoryAddresses.align_address_to_page_end(maxAddr)\n            mbi = memory[-1]\n            if mbi.BaseAddress + mbi.RegionSize > maxAddr:\n                mbi.RegionSize = maxAddr - mbi.BaseAddress\n\n        # Read the contents of each block and yield it.\n        while memory:\n            mbi = memory.pop(0) # so the garbage collector can take it\n            mbi.filename = filenames.get(mbi.BaseAddress, None)\n            if mbi.has_content():\n                mbi.content = self.read(mbi.BaseAddress, mbi.RegionSize)\n            else:\n                mbi.content = None\n            yield mbi"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef restore_memory_snapshot(self, snapshot,\n                                bSkipMappedFiles = True,\n                                bSkipOnError = False):\n        \"\"\"\n        Attempts to restore the memory state as it was when the given snapshot\n        was taken.\n\n        @warning: Currently only the memory contents, state and protect bits\n            are restored. Under some circumstances this method may fail (for\n            example if memory was freed and then reused by a mapped file).\n\n        @type  snapshot: list( L{win32.MemoryBasicInformation} )\n        @param snapshot: Memory snapshot returned by L{take_memory_snapshot}.\n            Snapshots returned by L{generate_memory_snapshot} don't work here.\n\n        @type  bSkipMappedFiles: bool\n        @param bSkipMappedFiles: C{True} to avoid restoring the contents of\n            memory mapped files, C{False} otherwise. Use with care! Setting\n            this to C{False} can cause undesired side effects - changes to\n            memory mapped files may be written to disk by the OS. Also note\n            that most mapped files are typically executables and don't change,\n            so trying to restore their contents is usually a waste of time.\n\n        @type  bSkipOnError: bool\n        @param bSkipOnError: C{True} to issue a warning when an error occurs\n            during the restoration of the snapshot, C{False} to stop and raise\n            an exception instead. Use with care! Setting this to C{True} will\n            cause the debugger to falsely believe the memory snapshot has been\n            correctly restored.\n\n        @raise WindowsError: An error occured while restoring the snapshot.\n        @raise RuntimeError: An error occured while restoring the snapshot.\n        @raise TypeError: A snapshot of the wrong type was passed.\n        \"\"\"\n        if not snapshot or not isinstance(snapshot, list) \\\n                or not isinstance(snapshot[0], win32.MemoryBasicInformation):\n            raise TypeError( \"Only snapshots returned by \" \\\n                             \"take_memory_snapshot() can be used here.\" )\n\n        # Get the process handle.\n        hProcess = self.get_handle( win32.PROCESS_VM_WRITE          |\n                                    win32.PROCESS_VM_OPERATION      |\n                                    win32.PROCESS_SUSPEND_RESUME    |\n                                    win32.PROCESS_QUERY_INFORMATION )\n\n        # Freeze the process.\n        self.suspend()\n        try:\n\n            # For each memory region in the snapshot...\n            for old_mbi in snapshot:\n\n                # If the region matches, restore it directly.\n                new_mbi = self.mquery(old_mbi.BaseAddress)\n                if new_mbi.BaseAddress == old_mbi.BaseAddress and \\\n                                    new_mbi.RegionSize == old_mbi.RegionSize:\n                    self.__restore_mbi(hProcess, new_mbi, old_mbi,\n                                       bSkipMappedFiles)\n\n                # If the region doesn't match, restore it page by page.\n                else:\n\n                    # We need a copy so we don't corrupt the snapshot.\n                    old_mbi = win32.MemoryBasicInformation(old_mbi)\n\n                    # Get the overlapping range of pages.\n                    old_start = old_mbi.BaseAddress\n                    old_end   = old_start + old_mbi.RegionSize\n                    new_start = new_mbi.BaseAddress\n                    new_end   = new_start + new_mbi.RegionSize\n                    if old_start > new_start:\n                        start = old_start\n                    else:\n                        start = new_start\n                    if old_end < new_end:\n                        end = old_end\n                    else:\n                        end = new_end\n\n                    # Restore each page in the overlapping range.\n                    step = MemoryAddresses.pageSize\n                    old_mbi.RegionSize = step\n                    new_mbi.RegionSize = step\n                    address = start\n                    while address < end:\n                        old_mbi.BaseAddress = address\n                        new_mbi.BaseAddress = address\n                        self.__restore_mbi(hProcess, new_mbi, old_mbi,\n                                           bSkipMappedFiles, bSkipOnError)\n                        address = address + step\n\n        # Resume execution.\n        finally:\n            self.resume()", "response": "Restores the memory state of the given snapshot."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrestores the memory region.", "response": "def __restore_mbi(self, hProcess, new_mbi, old_mbi, bSkipMappedFiles,\n                      bSkipOnError):\n        \"\"\"\n        Used internally by L{restore_memory_snapshot}.\n        \"\"\"\n\n##        print \"Restoring %s-%s\" % (\n##            HexDump.address(old_mbi.BaseAddress, self.get_bits()),\n##            HexDump.address(old_mbi.BaseAddress + old_mbi.RegionSize,\n##                            self.get_bits()))\n\n        try:\n\n            # Restore the region state.\n            if new_mbi.State != old_mbi.State:\n                if new_mbi.is_free():\n                    if old_mbi.is_reserved():\n\n                        # Free -> Reserved\n                        address = win32.VirtualAllocEx(hProcess,\n                                                       old_mbi.BaseAddress,\n                                                       old_mbi.RegionSize,\n                                                       win32.MEM_RESERVE,\n                                                       old_mbi.Protect)\n                        if address != old_mbi.BaseAddress:\n                            self.free(address)\n                            msg = \"Error restoring region at address %s\"\n                            msg = msg % HexDump(old_mbi.BaseAddress,\n                                                self.get_bits())\n                            raise RuntimeError(msg)\n                        # permissions already restored\n                        new_mbi.Protect = old_mbi.Protect\n\n                    else:   # elif old_mbi.is_commited():\n\n                        # Free -> Commited\n                        address = win32.VirtualAllocEx(hProcess,\n                                                       old_mbi.BaseAddress,\n                                                       old_mbi.RegionSize,\n                                                       win32.MEM_RESERVE | \\\n                                                       win32.MEM_COMMIT,\n                                                       old_mbi.Protect)\n                        if address != old_mbi.BaseAddress:\n                            self.free(address)\n                            msg = \"Error restoring region at address %s\"\n                            msg = msg % HexDump(old_mbi.BaseAddress,\n                                                self.get_bits())\n                            raise RuntimeError(msg)\n                        # permissions already restored\n                        new_mbi.Protect = old_mbi.Protect\n\n                elif new_mbi.is_reserved():\n                    if old_mbi.is_commited():\n\n                        # Reserved -> Commited\n                        address = win32.VirtualAllocEx(hProcess,\n                                                       old_mbi.BaseAddress,\n                                                       old_mbi.RegionSize,\n                                                       win32.MEM_COMMIT,\n                                                       old_mbi.Protect)\n                        if address != old_mbi.BaseAddress:\n                            self.free(address)\n                            msg = \"Error restoring region at address %s\"\n                            msg = msg % HexDump(old_mbi.BaseAddress,\n                                                self.get_bits())\n                            raise RuntimeError(msg)\n                        # permissions already restored\n                        new_mbi.Protect = old_mbi.Protect\n\n                    else:   # elif old_mbi.is_free():\n\n                        # Reserved -> Free\n                        win32.VirtualFreeEx(hProcess,\n                                            old_mbi.BaseAddress,\n                                            old_mbi.RegionSize,\n                                            win32.MEM_RELEASE)\n\n                else:   # elif new_mbi.is_commited():\n                    if old_mbi.is_reserved():\n\n                        # Commited -> Reserved\n                        win32.VirtualFreeEx(hProcess,\n                                            old_mbi.BaseAddress,\n                                            old_mbi.RegionSize,\n                                            win32.MEM_DECOMMIT)\n\n                    else:   # elif old_mbi.is_free():\n\n                        # Commited -> Free\n                        win32.VirtualFreeEx(hProcess,\n                                            old_mbi.BaseAddress,\n                                            old_mbi.RegionSize,\n                                            win32.MEM_DECOMMIT | win32.MEM_RELEASE)\n\n            new_mbi.State = old_mbi.State\n\n            # Restore the region permissions.\n            if old_mbi.is_commited() and old_mbi.Protect != new_mbi.Protect:\n                win32.VirtualProtectEx(hProcess, old_mbi.BaseAddress,\n                                       old_mbi.RegionSize, old_mbi.Protect)\n                new_mbi.Protect = old_mbi.Protect\n\n            # Restore the region data.\n            # Ignore write errors when the region belongs to a mapped file.\n            if old_mbi.has_content():\n                if old_mbi.Type != 0:\n                    if not bSkipMappedFiles:\n                        self.poke(old_mbi.BaseAddress, old_mbi.content)\n                else:\n                    self.write(old_mbi.BaseAddress, old_mbi.content)\n                new_mbi.content = old_mbi.content\n\n        # On error, skip this region or raise an exception.\n        except Exception:\n            if not bSkipOnError:\n                raise\n            msg = \"Error restoring region at address %s: %s\"\n            msg = msg % (\n                HexDump(old_mbi.BaseAddress, self.get_bits()),\n                traceback.format_exc())\n            warnings.warn(msg, RuntimeWarning)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninject relocatable code into the process memory and executes it.", "response": "def inject_code(self, payload, lpParameter = 0):\n        \"\"\"\n        Injects relocatable code into the process memory and executes it.\n\n        @warning: Don't forget to free the memory when you're done with it!\n            Otherwise you'll be leaking memory in the target process.\n\n        @see: L{inject_dll}\n\n        @type  payload: str\n        @param payload: Relocatable code to run in a new thread.\n\n        @type  lpParameter: int\n        @param lpParameter: (Optional) Parameter to be pushed in the stack.\n\n        @rtype:  tuple( L{Thread}, int )\n        @return: The injected Thread object\n            and the memory address where the code was written.\n\n        @raise WindowsError: An exception is raised on error.\n        \"\"\"\n\n        # Uncomment for debugging...\n##        payload = '\\xCC' + payload\n\n        # Allocate the memory for the shellcode.\n        lpStartAddress = self.malloc(len(payload))\n\n        # Catch exceptions so we can free the memory on error.\n        try:\n\n            # Write the shellcode to our memory location.\n            self.write(lpStartAddress, payload)\n\n            # Start a new thread for the shellcode to run.\n            aThread = self.start_thread(lpStartAddress, lpParameter,\n                                                            bSuspended = False)\n\n            # Remember the shellcode address.\n            #  It will be freed ONLY by the Thread.kill() method\n            #  and the EventHandler class, otherwise you'll have to\n            #  free it in your code, or have your shellcode clean up\n            #  after itself (recommended).\n            aThread.pInjectedMemory = lpStartAddress\n\n        # Free the memory on error.\n        except Exception:\n            self.free(lpStartAddress)\n            raise\n\n        # Return the Thread object and the shellcode address.\n        return aThread, lpStartAddress"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef inject_dll(self, dllname, procname = None, lpParameter = 0,\n                                               bWait = True, dwTimeout = None):\n        \"\"\"\n        Injects a DLL into the process memory.\n\n        @warning: Setting C{bWait} to C{True} when the process is frozen by a\n            debug event will cause a deadlock in your debugger.\n\n        @warning: This involves allocating memory in the target process.\n            This is how the freeing of this memory is handled:\n\n             - If the C{bWait} flag is set to C{True} the memory will be freed\n               automatically before returning from this method.\n             - If the C{bWait} flag is set to C{False}, the memory address is\n               set as the L{Thread.pInjectedMemory} property of the returned\n               thread object.\n             - L{Debug} objects free L{Thread.pInjectedMemory} automatically\n               both when it detaches from a process and when the injected\n               thread finishes its execution.\n             - The {Thread.kill} method also frees L{Thread.pInjectedMemory}\n               automatically, even if you're not attached to the process.\n\n            You could still be leaking memory if not careful. For example, if\n            you inject a dll into a process you're not attached to, you don't\n            wait for the thread's completion and you don't kill it either, the\n            memory would be leaked.\n\n        @see: L{inject_code}\n\n        @type  dllname: str\n        @param dllname: Name of the DLL module to load.\n\n        @type  procname: str\n        @param procname: (Optional) Procedure to call when the DLL is loaded.\n\n        @type  lpParameter: int\n        @param lpParameter: (Optional) Parameter to the C{procname} procedure.\n\n        @type  bWait: bool\n        @param bWait: C{True} to wait for the process to finish.\n            C{False} to return immediately.\n\n        @type  dwTimeout: int\n        @param dwTimeout: (Optional) Timeout value in milliseconds.\n            Ignored if C{bWait} is C{False}.\n\n        @rtype: L{Thread}\n        @return: Newly created thread object. If C{bWait} is set to C{True} the\n            thread will be dead, otherwise it will be alive.\n\n        @raise NotImplementedError: The target platform is not supported.\n            Currently calling a procedure in the library is only supported in\n            the I{i386} architecture.\n\n        @raise WindowsError: An exception is raised on error.\n        \"\"\"\n\n        # Resolve kernel32.dll\n        aModule = self.get_module_by_name(compat.b('kernel32.dll'))\n        if aModule is None:\n            self.scan_modules()\n            aModule = self.get_module_by_name(compat.b('kernel32.dll'))\n        if aModule is None:\n            raise RuntimeError(\n                \"Cannot resolve kernel32.dll in the remote process\")\n\n        # Old method, using shellcode.\n        if procname:\n            if self.get_arch() != win32.ARCH_I386:\n                raise NotImplementedError()\n            dllname = compat.b(dllname)\n\n            # Resolve kernel32.dll!LoadLibraryA\n            pllib = aModule.resolve(compat.b('LoadLibraryA'))\n            if not pllib:\n                raise RuntimeError(\n                    \"Cannot resolve kernel32.dll!LoadLibraryA\"\n                    \" in the remote process\")\n\n            # Resolve kernel32.dll!GetProcAddress\n            pgpad = aModule.resolve(compat.b('GetProcAddress'))\n            if not pgpad:\n                raise RuntimeError(\n                    \"Cannot resolve kernel32.dll!GetProcAddress\"\n                    \" in the remote process\")\n\n            # Resolve kernel32.dll!VirtualFree\n            pvf = aModule.resolve(compat.b('VirtualFree'))\n            if not pvf:\n                raise RuntimeError(\n                    \"Cannot resolve kernel32.dll!VirtualFree\"\n                    \" in the remote process\")\n\n            # Shellcode follows...\n            code  = compat.b('')\n\n            # push dllname\n            code += compat.b('\\xe8') + struct.pack('<L', len(dllname) + 1) + dllname + compat.b('\\0')\n\n            # mov eax, LoadLibraryA\n            code += compat.b('\\xb8') + struct.pack('<L', pllib)\n\n            # call eax\n            code += compat.b('\\xff\\xd0')\n\n            if procname:\n\n                # push procname\n                code += compat.b('\\xe8') + struct.pack('<L', len(procname) + 1)\n                code += procname + compat.b('\\0')\n\n                # push eax\n                code += compat.b('\\x50')\n\n                # mov eax, GetProcAddress\n                code += compat.b('\\xb8') + struct.pack('<L', pgpad)\n\n                # call eax\n                code += compat.b('\\xff\\xd0')\n\n                # mov ebp, esp      ; preserve stack pointer\n                code += compat.b('\\x8b\\xec')\n\n                # push lpParameter\n                code += compat.b('\\x68') + struct.pack('<L', lpParameter)\n\n                # call eax\n                code += compat.b('\\xff\\xd0')\n\n                # mov esp, ebp      ; restore stack pointer\n                code += compat.b('\\x8b\\xe5')\n\n            # pop edx       ; our own return address\n            code += compat.b('\\x5a')\n\n            # push MEM_RELEASE  ; dwFreeType\n            code += compat.b('\\x68') + struct.pack('<L', win32.MEM_RELEASE)\n\n            # push 0x1000       ; dwSize, shellcode max size 4096 bytes\n            code += compat.b('\\x68') + struct.pack('<L', 0x1000)\n\n            # call $+5\n            code += compat.b('\\xe8\\x00\\x00\\x00\\x00')\n\n            # and dword ptr [esp], 0xFFFFF000   ; align to page boundary\n            code += compat.b('\\x81\\x24\\x24\\x00\\xf0\\xff\\xff')\n\n            # mov eax, VirtualFree\n            code += compat.b('\\xb8') + struct.pack('<L', pvf)\n\n            # push edx      ; our own return address\n            code += compat.b('\\x52')\n\n            # jmp eax   ; VirtualFree will return to our own return address\n            code += compat.b('\\xff\\xe0')\n\n            # Inject the shellcode.\n            # There's no need to free the memory,\n            # because the shellcode will free it itself.\n            aThread, lpStartAddress = self.inject_code(code, lpParameter)\n\n        # New method, not using shellcode.\n        else:\n\n            # Resolve kernel32.dll!LoadLibrary (A/W)\n            if type(dllname) == type(u''):\n                pllibname = compat.b('LoadLibraryW')\n                bufferlen = (len(dllname) + 1) * 2\n                dllname = win32.ctypes.create_unicode_buffer(dllname).raw[:bufferlen + 1]\n            else:\n                pllibname = compat.b('LoadLibraryA')\n                dllname   = compat.b(dllname) + compat.b('\\x00')\n                bufferlen = len(dllname)\n            pllib = aModule.resolve(pllibname)\n            if not pllib:\n                msg = \"Cannot resolve kernel32.dll!%s in the remote process\"\n                raise RuntimeError(msg % pllibname)\n\n            # Copy the library name into the process memory space.\n            pbuffer = self.malloc(bufferlen)\n            try:\n                self.write(pbuffer, dllname)\n\n                # Create a new thread to load the library.\n                try:\n                    aThread = self.start_thread(pllib, pbuffer)\n                except WindowsError:\n                    e = sys.exc_info()[1]\n                    if e.winerror != win32.ERROR_NOT_ENOUGH_MEMORY:\n                        raise\n\n                    # This specific error is caused by trying to spawn a new\n                    # thread in a process belonging to a different Terminal\n                    # Services session (for example a service).\n                    raise NotImplementedError(\n                        \"Target process belongs to a different\"\n                        \" Terminal Services session, cannot inject!\"\n                    )\n\n                # Remember the buffer address.\n                #  It will be freed ONLY by the Thread.kill() method\n                #  and the EventHandler class, otherwise you'll have to\n                #  free it in your code.\n                aThread.pInjectedMemory = pbuffer\n\n            # Free the memory on error.\n            except Exception:\n                self.free(pbuffer)\n                raise\n\n        # Wait for the thread to finish.\n        if bWait:\n            aThread.wait(dwTimeout)\n            self.free(aThread.pInjectedMemory)\n            del aThread.pInjectedMemory\n\n        # Return the thread object.\n        return aThread", "response": "Injects a DLL into the process memory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninjecting a new thread to call ExitProcess(). Optionally waits for the injected thread to finish. @warning: Setting C{bWait} to C{True} when the process is frozen by a debug event will cause a deadlock in your debugger. @type dwExitCode: int @param dwExitCode: Process exit code. @type bWait: bool @param bWait: C{True} to wait for the process to finish. C{False} to return immediately. @type dwTimeout: int @param dwTimeout: (Optional) Timeout value in milliseconds. Ignored if C{bWait} is C{False}. @raise WindowsError: An exception is raised on error.", "response": "def clean_exit(self, dwExitCode = 0, bWait = False, dwTimeout = None):\n        \"\"\"\n        Injects a new thread to call ExitProcess().\n        Optionally waits for the injected thread to finish.\n\n        @warning: Setting C{bWait} to C{True} when the process is frozen by a\n            debug event will cause a deadlock in your debugger.\n\n        @type  dwExitCode: int\n        @param dwExitCode: Process exit code.\n\n        @type  bWait: bool\n        @param bWait: C{True} to wait for the process to finish.\n            C{False} to return immediately.\n\n        @type  dwTimeout: int\n        @param dwTimeout: (Optional) Timeout value in milliseconds.\n            Ignored if C{bWait} is C{False}.\n\n        @raise WindowsError: An exception is raised on error.\n        \"\"\"\n        if not dwExitCode:\n            dwExitCode = 0\n        pExitProcess = self.resolve_label('kernel32!ExitProcess')\n        aThread = self.start_thread(pExitProcess, dwExitCode)\n        if bWait:\n            aThread.wait(dwTimeout)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _notify_create_process(self, event):\n        # Do not use super() here.\n        bCallHandler = _ThreadContainer._notify_create_process(self, event)\n        bCallHandler = bCallHandler and \\\n                           _ModuleContainer._notify_create_process(self, event)\n        return bCallHandler", "response": "Notify the creation of a new process."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __initialize_snapshot(self):\n        if not self.__processDict:\n            try:\n                self.scan_processes()       # remote desktop api (relative fn)\n            except Exception:\n                self.scan_processes_fast()  # psapi (no filenames)\n            self.scan_process_filenames()", "response": "Private method to automatically initialize the snapshot of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the process object with the given global ID.", "response": "def get_process(self, dwProcessId):\n        \"\"\"\n        @type  dwProcessId: int\n        @param dwProcessId: Global ID of the process to look for.\n\n        @rtype:  L{Process}\n        @return: Process object with the given global ID.\n        \"\"\"\n        self.__initialize_snapshot()\n        if dwProcessId not in self.__processDict:\n            msg = \"Unknown process ID %d\" % dwProcessId\n            raise KeyError(msg)\n        return self.__processDict[dwProcessId]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_pid_from_tid(self, dwThreadId):\n        try:\n\n            # No good, because in XP and below it tries to get the PID\n            # through the toolhelp API, and that's slow. We don't want\n            # to scan for threads over and over for each call.\n##            dwProcessId = Thread(dwThreadId).get_pid()\n\n            # This API only exists in Windows 2003, Vista and above.\n            try:\n                hThread = win32.OpenThread(\n                    win32.THREAD_QUERY_LIMITED_INFORMATION, False, dwThreadId)\n            except WindowsError:\n                e = sys.exc_info()[1]\n                if e.winerror != win32.ERROR_ACCESS_DENIED:\n                    raise\n                hThread = win32.OpenThread(\n                    win32.THREAD_QUERY_INFORMATION, False, dwThreadId)\n            try:\n                return win32.GetProcessIdOfThread(hThread)\n            finally:\n                hThread.close()\n\n        # If all else fails, go through all processes in the snapshot\n        # looking for the one that owns the thread we're looking for.\n        # If the snapshot was empty the iteration should trigger an\n        # automatic scan. Otherwise, it'll look for the thread in what\n        # could possibly be an outdated snapshot.\n        except Exception:\n            for aProcess in self.iter_processes():\n                if aProcess.has_thread(dwThreadId):\n                    return aProcess.get_pid()\n\n        # The thread wasn't found, so let's refresh the snapshot and retry.\n        # Normally this shouldn't happen since this function is only useful\n        # for the debugger, so the thread should already exist in the snapshot.\n        self.scan_processes_and_threads()\n        for aProcess in self.iter_processes():\n            if aProcess.has_thread(dwThreadId):\n                return aProcess.get_pid()\n\n        # No luck! It appears to be the thread doesn't exist after all.\n        msg = \"Unknown thread ID %d\" % dwThreadId\n        raise KeyError(msg)", "response": "Get the process ID of the thread that owns the thread."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef argv_to_cmdline(argv):\n        cmdline = list()\n        for token in argv:\n            if not token:\n                token = '\"\"'\n            else:\n                if '\"' in token:\n                    token = token.replace('\"', '\\\\\"')\n                if  ' ' in token  or \\\n                    '\\t' in token or \\\n                    '\\n' in token or \\\n                    '\\r' in token:\n                        token = '\"%s\"' % token\n            cmdline.append(token)\n        return ' '.join(cmdline)", "response": "Convert a list of arguments to a single command line string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart a new process for instrumenting or debugging.", "response": "def start_process(self, lpCmdLine, **kwargs):\n        \"\"\"\n        Starts a new process for instrumenting (or debugging).\n\n        @type  lpCmdLine: str\n        @param lpCmdLine: Command line to execute. Can't be an empty string.\n\n        @type    bConsole: bool\n        @keyword bConsole: True to inherit the console of the debugger.\n            Defaults to C{False}.\n\n        @type    bDebug: bool\n        @keyword bDebug: C{True} to attach to the new process.\n            To debug a process it's best to use the L{Debug} class instead.\n            Defaults to C{False}.\n\n        @type    bFollow: bool\n        @keyword bFollow: C{True} to automatically attach to the child\n            processes of the newly created process. Ignored unless C{bDebug} is\n            C{True}. Defaults to C{False}.\n\n        @type    bInheritHandles: bool\n        @keyword bInheritHandles: C{True} if the new process should inherit\n            it's parent process' handles. Defaults to C{False}.\n\n        @type    bSuspended: bool\n        @keyword bSuspended: C{True} to suspend the main thread before any code\n            is executed in the debugee. Defaults to C{False}.\n\n        @type    dwParentProcessId: int or None\n        @keyword dwParentProcessId: C{None} if the debugger process should be\n            the parent process (default), or a process ID to forcefully set as\n            the debugee's parent (only available for Windows Vista and above).\n\n        @type    iTrustLevel: int\n        @keyword iTrustLevel: Trust level.\n            Must be one of the following values:\n             - 0: B{No trust}. May not access certain resources, such as\n                  cryptographic keys and credentials. Only available since\n                  Windows XP and 2003, desktop editions.\n             - 1: B{Normal trust}. Run with the same privileges as a normal\n                  user, that is, one that doesn't have the I{Administrator} or\n                  I{Power User} user rights. Only available since Windows XP\n                  and 2003, desktop editions.\n             - 2: B{Full trust}. Run with the exact same privileges as the\n                  current user. This is the default value.\n\n        @type    bAllowElevation: bool\n        @keyword bAllowElevation: C{True} to allow the child process to keep\n            UAC elevation, if the debugger itself is running elevated. C{False}\n            to ensure the child process doesn't run with elevation. Defaults to\n            C{True}.\n\n            This flag is only meaningful on Windows Vista and above, and if the\n            debugger itself is running with elevation. It can be used to make\n            sure the child processes don't run elevated as well.\n\n            This flag DOES NOT force an elevation prompt when the debugger is\n            not running with elevation.\n\n            Note that running the debugger with elevation (or the Python\n            interpreter at all for that matter) is not normally required.\n            You should only need to if the target program requires elevation\n            to work properly (for example if you try to debug an installer).\n\n        @rtype:  L{Process}\n        @return: Process object.\n        \"\"\"\n\n        # Get the flags.\n        bConsole            = kwargs.pop('bConsole', False)\n        bDebug              = kwargs.pop('bDebug', False)\n        bFollow             = kwargs.pop('bFollow', False)\n        bSuspended          = kwargs.pop('bSuspended', False)\n        bInheritHandles     = kwargs.pop('bInheritHandles', False)\n        dwParentProcessId   = kwargs.pop('dwParentProcessId', None)\n        iTrustLevel         = kwargs.pop('iTrustLevel', 2)\n        bAllowElevation     = kwargs.pop('bAllowElevation', True)\n        if kwargs:\n            raise TypeError(\"Unknown keyword arguments: %s\" % compat.keys(kwargs))\n        if not lpCmdLine:\n            raise ValueError(\"Missing command line to execute!\")\n\n        # Sanitize the trust level flag.\n        if iTrustLevel is None:\n            iTrustLevel = 2\n\n        # The UAC elevation flag is only meaningful if we're running elevated.\n        try:\n            bAllowElevation = bAllowElevation or not self.is_admin()\n        except AttributeError:\n            bAllowElevation = True\n            warnings.warn(\n                \"UAC elevation is only available in Windows Vista and above\",\n                RuntimeWarning)\n\n        # Calculate the process creation flags.\n        dwCreationFlags  = 0\n        dwCreationFlags |= win32.CREATE_DEFAULT_ERROR_MODE\n        dwCreationFlags |= win32.CREATE_BREAKAWAY_FROM_JOB\n        ##dwCreationFlags |= win32.CREATE_UNICODE_ENVIRONMENT\n        if not bConsole:\n            dwCreationFlags |= win32.DETACHED_PROCESS\n            #dwCreationFlags |= win32.CREATE_NO_WINDOW   # weird stuff happens\n        if bSuspended:\n            dwCreationFlags |= win32.CREATE_SUSPENDED\n        if bDebug:\n            dwCreationFlags |= win32.DEBUG_PROCESS\n            if not bFollow:\n                dwCreationFlags |= win32.DEBUG_ONLY_THIS_PROCESS\n\n        # Change the parent process if requested.\n        # May fail on old versions of Windows.\n        lpStartupInfo = None\n        if dwParentProcessId is not None:\n            myPID = win32.GetCurrentProcessId()\n            if dwParentProcessId != myPID:\n                if self.has_process(dwParentProcessId):\n                    ParentProcess = self.get_process(dwParentProcessId)\n                else:\n                    ParentProcess = Process(dwParentProcessId)\n                ParentProcessHandle = ParentProcess.get_handle(\n                                        win32.PROCESS_CREATE_PROCESS)\n                AttributeListData = (\n                    (\n                        win32.PROC_THREAD_ATTRIBUTE_PARENT_PROCESS,\n                        ParentProcessHandle._as_parameter_\n                    ),\n                )\n                AttributeList = win32.ProcThreadAttributeList(AttributeListData)\n                StartupInfoEx           = win32.STARTUPINFOEX()\n                StartupInfo             = StartupInfoEx.StartupInfo\n                StartupInfo.cb          = win32.sizeof(win32.STARTUPINFOEX)\n                StartupInfo.lpReserved  = 0\n                StartupInfo.lpDesktop   = 0\n                StartupInfo.lpTitle     = 0\n                StartupInfo.dwFlags     = 0\n                StartupInfo.cbReserved2 = 0\n                StartupInfo.lpReserved2 = 0\n                StartupInfoEx.lpAttributeList = AttributeList.value\n                lpStartupInfo = StartupInfoEx\n                dwCreationFlags |= win32.EXTENDED_STARTUPINFO_PRESENT\n\n        pi = None\n        try:\n\n            # Create the process the easy way.\n            if iTrustLevel >= 2 and bAllowElevation:\n                pi = win32.CreateProcess(None, lpCmdLine,\n                                            bInheritHandles = bInheritHandles,\n                                            dwCreationFlags = dwCreationFlags,\n                                            lpStartupInfo   = lpStartupInfo)\n\n            # Create the process the hard way...\n            else:\n\n                # If we allow elevation, use the current process token.\n                # If not, get the token from the current shell process.\n                hToken = None\n                try:\n                    if not bAllowElevation:\n                        if bFollow:\n                            msg = (\n                                \"Child processes can't be autofollowed\"\n                                \" when dropping UAC elevation.\")\n                            raise NotImplementedError(msg)\n                        if bConsole:\n                            msg = (\n                                \"Child processes can't inherit the debugger's\"\n                                \" console when dropping UAC elevation.\")\n                            raise NotImplementedError(msg)\n                        if bInheritHandles:\n                            msg = (\n                                \"Child processes can't inherit the debugger's\"\n                                \" handles when dropping UAC elevation.\")\n                            raise NotImplementedError(msg)\n                        try:\n                            hWnd = self.get_shell_window()\n                        except WindowsError:\n                            hWnd = self.get_desktop_window()\n                        shell = hWnd.get_process()\n                        try:\n                            hShell = shell.get_handle(\n                                            win32.PROCESS_QUERY_INFORMATION)\n                            with win32.OpenProcessToken(hShell) as hShellToken:\n                                hToken = win32.DuplicateTokenEx(hShellToken)\n                        finally:\n                            shell.close_handle()\n\n                    # Lower trust level if requested.\n                    if iTrustLevel < 2:\n                        if iTrustLevel > 0:\n                            dwLevelId = win32.SAFER_LEVELID_NORMALUSER\n                        else:\n                            dwLevelId = win32.SAFER_LEVELID_UNTRUSTED\n                        with win32.SaferCreateLevel(dwLevelId = dwLevelId) as hSafer:\n                            hSaferToken = win32.SaferComputeTokenFromLevel(\n                                                            hSafer, hToken)[0]\n                            try:\n                                if hToken is not None:\n                                    hToken.close()\n                            except:\n                                hSaferToken.close()\n                                raise\n                            hToken = hSaferToken\n\n                    # If we have a computed token, call CreateProcessAsUser().\n                    if bAllowElevation:\n                        pi = win32.CreateProcessAsUser(\n                                    hToken          = hToken,\n                                    lpCommandLine   = lpCmdLine,\n                                    bInheritHandles = bInheritHandles,\n                                    dwCreationFlags = dwCreationFlags,\n                                    lpStartupInfo   = lpStartupInfo)\n\n                    # If we have a primary token call CreateProcessWithToken().\n                    # The problem is, there are many flags CreateProcess() and\n                    # CreateProcessAsUser() accept but CreateProcessWithToken()\n                    # and CreateProcessWithLogonW() don't, so we need to work\n                    # around them.\n                    else:\n\n                        # Remove the debug flags.\n                        dwCreationFlags &= ~win32.DEBUG_PROCESS\n                        dwCreationFlags &= ~win32.DEBUG_ONLY_THIS_PROCESS\n\n                        # Remove the console flags.\n                        dwCreationFlags &= ~win32.DETACHED_PROCESS\n\n                        # The process will be created suspended.\n                        dwCreationFlags |= win32.CREATE_SUSPENDED\n\n                        # Create the process using the new primary token.\n                        pi = win32.CreateProcessWithToken(\n                                    hToken          = hToken,\n                                    dwLogonFlags    = win32.LOGON_WITH_PROFILE,\n                                    lpCommandLine   = lpCmdLine,\n                                    dwCreationFlags = dwCreationFlags,\n                                    lpStartupInfo   = lpStartupInfo)\n\n                        # Attach as a debugger, if requested.\n                        if bDebug:\n                            win32.DebugActiveProcess(pi.dwProcessId)\n\n                        # Resume execution, if requested.\n                        if not bSuspended:\n                            win32.ResumeThread(pi.hThread)\n\n                # Close the token when we're done with it.\n                finally:\n                    if hToken is not None:\n                        hToken.close()\n\n            # Wrap the new process and thread in Process and Thread objects,\n            # and add them to the corresponding snapshots.\n            aProcess = Process(pi.dwProcessId, pi.hProcess)\n            aThread  = Thread (pi.dwThreadId,  pi.hThread)\n            aProcess._add_thread(aThread)\n            self._add_process(aProcess)\n\n        # Clean up on error.\n        except:\n            if pi is not None:\n                try:\n                    win32.TerminateProcess(pi.hProcess)\n                except WindowsError:\n                    pass\n                pi.hThread.close()\n                pi.hProcess.close()\n            raise\n\n        # Return the new Process object.\n        return aProcess"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to find the process ID for explorer. exe.", "response": "def get_explorer_pid(self):\n        \"\"\"\n        Tries to find the process ID for \"explorer.exe\".\n\n        @rtype:  int or None\n        @return: Returns the process ID, or C{None} on error.\n        \"\"\"\n        try:\n            exp = win32.SHGetFolderPath(win32.CSIDL_WINDOWS)\n        except Exception:\n            exp = None\n        if not exp:\n            exp = os.getenv('SystemRoot')\n        if exp:\n            exp = os.path.join(exp, 'explorer.exe')\n            exp_list = self.find_processes_by_filename(exp)\n            if exp_list:\n                return exp_list[0][0].get_pid()\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef scan(self):\n        has_threads = True\n        try:\n            try:\n\n                # Try using the Toolhelp API\n                # to scan for processes and threads.\n                self.scan_processes_and_threads()\n\n            except Exception:\n\n                # On error, try using the PSAPI to scan for process IDs only.\n                self.scan_processes_fast()\n\n                # Now try using the Toolhelp again to get the threads.\n                for aProcess in self.__processDict.values():\n                    if aProcess._get_thread_ids():\n                        try:\n                            aProcess.scan_threads()\n                        except WindowsError:\n                            has_threads = False\n\n        finally:\n\n            # Try using the Remote Desktop API to scan for processes only.\n            # This will update the filenames when it's not possible\n            # to obtain them from the Toolhelp API.\n            self.scan_processes()\n\n        # When finished scanning for processes, try modules too.\n        has_modules = self.scan_modules()\n\n        # Try updating the process filenames when possible.\n        has_full_names = self.scan_process_filenames()\n\n        # Return the completion status.\n        return has_threads and has_modules and has_full_names", "response": "Populates the snapshot with running processes threads and loaded modules."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scan_processes_and_threads(self):\n\n        # The main module filename may be spoofed by malware,\n        # since this information resides in usermode space.\n        # See: http://www.ragestorm.net/blogs/?p=163\n\n        our_pid    = win32.GetCurrentProcessId()\n        dead_pids  = set( compat.iterkeys(self.__processDict) )\n        found_tids = set()\n\n        # Ignore our own process if it's in the snapshot for some reason\n        if our_pid in dead_pids:\n            dead_pids.remove(our_pid)\n\n        # Take a snapshot of all processes and threads\n        dwFlags   = win32.TH32CS_SNAPPROCESS | win32.TH32CS_SNAPTHREAD\n        with win32.CreateToolhelp32Snapshot(dwFlags) as hSnapshot:\n\n            # Add all the processes (excluding our own)\n            pe = win32.Process32First(hSnapshot)\n            while pe is not None:\n                dwProcessId = pe.th32ProcessID\n                if dwProcessId != our_pid:\n                    if dwProcessId in dead_pids:\n                        dead_pids.remove(dwProcessId)\n                    if dwProcessId not in self.__processDict:\n                        aProcess = Process(dwProcessId, fileName=pe.szExeFile)\n                        self._add_process(aProcess)\n                    elif pe.szExeFile:\n                        aProcess = self.get_process(dwProcessId)\n                        if not aProcess.fileName:\n                            aProcess.fileName = pe.szExeFile\n                pe = win32.Process32Next(hSnapshot)\n\n            # Add all the threads\n            te = win32.Thread32First(hSnapshot)\n            while te is not None:\n                dwProcessId = te.th32OwnerProcessID\n                if dwProcessId != our_pid:\n                    if dwProcessId in dead_pids:\n                        dead_pids.remove(dwProcessId)\n                    if dwProcessId in self.__processDict:\n                        aProcess = self.get_process(dwProcessId)\n                    else:\n                        aProcess = Process(dwProcessId)\n                        self._add_process(aProcess)\n                    dwThreadId = te.th32ThreadID\n                    found_tids.add(dwThreadId)\n                    if not aProcess._has_thread_id(dwThreadId):\n                        aThread = Thread(dwThreadId, process = aProcess)\n                        aProcess._add_thread(aThread)\n                te = win32.Thread32Next(hSnapshot)\n\n        # Remove dead processes\n        for pid in dead_pids:\n            self._del_process(pid)\n\n        # Remove dead threads\n        for aProcess in compat.itervalues(self.__processDict):\n            dead_tids = set( aProcess._get_thread_ids() )\n            dead_tids.difference_update(found_tids)\n            for tid in dead_tids:\n                aProcess._del_thread(tid)", "response": "Takes a snapshot of all processes and threads and returns a set of the current process and thread names."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef scan_modules(self):\n        complete = True\n        for aProcess in compat.itervalues(self.__processDict):\n            try:\n                aProcess.scan_modules()\n            except WindowsError:\n                complete = False\n        return complete", "response": "Populates the snapshot with loaded modules."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef scan_processes(self):\n\n        # Get the previous list of PIDs.\n        # We'll be removing live PIDs from it as we find them.\n        our_pid   = win32.GetCurrentProcessId()\n        dead_pids  = set( compat.iterkeys(self.__processDict) )\n\n        # Ignore our own PID.\n        if our_pid in dead_pids:\n            dead_pids.remove(our_pid)\n\n        # Get the list of processes from the Remote Desktop API.\n        pProcessInfo = None\n        try:\n            pProcessInfo, dwCount = win32.WTSEnumerateProcesses(\n                                            win32.WTS_CURRENT_SERVER_HANDLE)\n\n            # For each process found...\n            for index in compat.xrange(dwCount):\n                sProcessInfo = pProcessInfo[index]\n\n##                # Ignore processes belonging to other sessions.\n##                if sProcessInfo.SessionId != win32.WTS_CURRENT_SESSION:\n##                    continue\n\n                # Ignore our own PID.\n                pid = sProcessInfo.ProcessId\n                if pid == our_pid:\n                    continue\n\n                # Remove the PID from the dead PIDs list.\n                if pid in dead_pids:\n                    dead_pids.remove(pid)\n\n                # Get the \"process name\".\n                # Empirically, this seems to be the filename without the path.\n                # (The MSDN docs aren't very clear about this API call).\n                fileName = sProcessInfo.pProcessName\n\n                # If the process is new, add a new Process object.\n                if pid not in self.__processDict:\n                    aProcess = Process(pid, fileName = fileName)\n                    self._add_process(aProcess)\n\n                # If the process was already in the snapshot, and the\n                # filename is missing, update the Process object.\n                elif fileName:\n                    aProcess = self.__processDict.get(pid)\n                    if not aProcess.fileName:\n                        aProcess.fileName = fileName\n\n        # Free the memory allocated by the Remote Desktop API.\n        finally:\n            if pProcessInfo is not None:\n                try:\n                    win32.WTSFreeMemory(pProcessInfo)\n                except WindowsError:\n                    pass\n\n        # At this point the only remaining PIDs from the old list are dead.\n        # Remove them from the snapshot.\n        for pid in dead_pids:\n            self._del_process(pid)", "response": "Populates the snapshot with running processes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nscan the processes in the process dictionary.", "response": "def scan_processes_fast(self):\n        \"\"\"\n        Populates the snapshot with running processes.\n        Only the PID is retrieved for each process.\n\n        Dead processes are removed.\n        Threads and modules of living processes are ignored.\n\n        Tipically you don't need to call this method directly, if unsure use\n        L{scan} instead.\n\n        @note: This method uses the PSAPI. It may be faster for scanning,\n            but some information may be missing, outdated or slower to obtain.\n            This could be a good tradeoff under some circumstances.\n        \"\"\"\n\n        # Get the new and old list of pids\n        new_pids = set( win32.EnumProcesses() )\n        old_pids = set( compat.iterkeys(self.__processDict) )\n\n        # Ignore our own pid\n        our_pid  = win32.GetCurrentProcessId()\n        if our_pid in new_pids:\n            new_pids.remove(our_pid)\n        if our_pid in old_pids:\n            old_pids.remove(our_pid)\n\n        # Add newly found pids\n        for pid in new_pids.difference(old_pids):\n            self._add_process( Process(pid) )\n\n        # Remove missing pids\n        for pid in old_pids.difference(new_pids):\n            self._del_process(pid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scan_process_filenames(self):\n        complete = True\n        for aProcess in self.__processDict.values():\n            try:\n                new_name = None\n                old_name = aProcess.fileName\n                try:\n                    aProcess.fileName = None\n                    new_name = aProcess.get_filename()\n                finally:\n                    if not new_name:\n                        aProcess.fileName = old_name\n                        complete = False\n            except Exception:\n                complete = False\n        return complete", "response": "Update the filename for each process in the snapshot when possible."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves all dead processes from the snapshot.", "response": "def clear_dead_processes(self):\n        \"\"\"\n        Removes Process objects from the snapshot\n        referring to processes no longer running.\n        \"\"\"\n        for pid in self.get_process_ids():\n            aProcess = self.get_process(pid)\n            if not aProcess.is_alive():\n                self._del_process(aProcess)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove all unattached Process objects from the snapshot.", "response": "def clear_unattached_processes(self):\n        \"\"\"\n        Removes Process objects from the snapshot\n        referring to processes not being debugged.\n        \"\"\"\n        for pid in self.get_process_ids():\n            aProcess = self.get_process(pid)\n            if not aProcess.is_being_debugged():\n                self._del_process(aProcess)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclose all open handles to processes in this snapshot.", "response": "def close_process_handles(self):\n        \"\"\"\n        Closes all open handles to processes in this snapshot.\n        \"\"\"\n        for pid in self.get_process_ids():\n            aProcess = self.get_process(pid)\n            try:\n                aProcess.close_handle()\n            except Exception:\n                e = sys.exc_info()[1]\n                try:\n                    msg = \"Cannot close process handle %s, reason: %s\"\n                    msg %= (aProcess.hProcess.value, str(e))\n                    warnings.warn(msg)\n                except Exception:\n                    pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef close_process_and_thread_handles(self):\n        for aProcess in self.iter_processes():\n            aProcess.close_thread_handles()\n            try:\n                aProcess.close_handle()\n            except Exception:\n                e = sys.exc_info()[1]\n                try:\n                    msg = \"Cannot close process handle %s, reason: %s\"\n                    msg %= (aProcess.hProcess.value, str(e))\n                    warnings.warn(msg)\n                except Exception:\n                    pass", "response": "Closes all open handles to processes and threads in this snapshot."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclear all processes and threads in this snapshot.", "response": "def clear_processes(self):\n        \"\"\"\n        Removes all L{Process}, L{Thread} and L{Module} objects in this snapshot.\n        \"\"\"\n        #self.close_process_and_thread_handles()\n        for aProcess in self.iter_processes():\n            aProcess.clear()\n        self.__processDict = dict()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __find_processes_by_filename(self, filename):\n        found    = list()\n        filename = filename.lower()\n        if PathOperations.path_is_absolute(filename):\n            for aProcess in self.iter_processes():\n                imagename = aProcess.get_filename()\n                if imagename and imagename.lower() == filename:\n                    found.append( (aProcess, imagename) )\n        else:\n            for aProcess in self.iter_processes():\n                imagename = aProcess.get_filename()\n                if imagename:\n                    imagename = PathOperations.pathname_to_filename(imagename)\n                    if imagename.lower() == filename:\n                        found.append( (aProcess, imagename) )\n        return found", "response": "Find processes with the given filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_processes_by_filename(self, fileName):\n        found = self.__find_processes_by_filename(fileName)\n        if not found:\n            fn, ext = PathOperations.split_extension(fileName)\n            if not ext:\n                fileName = '%s.exe' % fn\n                found    = self.__find_processes_by_filename(fileName)\n        return found", "response": "Search for processes matching the given main module filename."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_process(self, aProcess):\n##        if not isinstance(aProcess, Process):\n##            if hasattr(aProcess, '__class__'):\n##                typename = aProcess.__class__.__name__\n##            else:\n##                typename = str(type(aProcess))\n##            msg = \"Expected Process, got %s instead\" % typename\n##            raise TypeError(msg)\n        dwProcessId = aProcess.dwProcessId\n##        if dwProcessId in self.__processDict:\n##            msg = \"Process already exists: %d\" % dwProcessId\n##            raise KeyError(msg)\n        self.__processDict[dwProcessId] = aProcess", "response": "Private method to add a process object to the snapshot."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _del_process(self, dwProcessId):\n        try:\n            aProcess = self.__processDict[dwProcessId]\n            del self.__processDict[dwProcessId]\n        except KeyError:\n            aProcess = None\n            msg = \"Unknown process ID %d\" % dwProcessId\n            warnings.warn(msg, RuntimeWarning)\n        if aProcess:\n            aProcess.clear()", "response": "Private method to remove a process object from the snapshot."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _notify_create_process(self, event):\n        dwProcessId = event.get_pid()\n        dwThreadId  = event.get_tid()\n        hProcess    = event.get_process_handle()\n##        if not self.has_process(dwProcessId): # XXX this would trigger a scan\n        if dwProcessId not in self.__processDict:\n            aProcess = Process(dwProcessId, hProcess)\n            self._add_process(aProcess)\n            aProcess.fileName = event.get_filename()\n        else:\n            aProcess = self.get_process(dwProcessId)\n            #if hProcess != win32.INVALID_HANDLE_VALUE:\n            #    aProcess.hProcess = hProcess    # may have more privileges\n            if not aProcess.fileName:\n                fileName = event.get_filename()\n                if fileName:\n                    aProcess.fileName = fileName\n        return aProcess._notify_create_process(event)", "response": "Notify the creation of a new process."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nnotify the user - defined handle of the termination of a process.", "response": "def _notify_exit_process(self, event):\n        \"\"\"\n        Notify the termination of a process.\n\n        This is done automatically by the L{Debug} class, you shouldn't need\n        to call it yourself.\n\n        @type  event: L{ExitProcessEvent}\n        @param event: Exit process event.\n\n        @rtype:  bool\n        @return: C{True} to call the user-defined handle, C{False} otherwise.\n        \"\"\"\n        dwProcessId = event.get_pid()\n##        if self.has_process(dwProcessId): # XXX this would trigger a scan\n        if dwProcessId in self.__processDict:\n            self._del_process(dwProcessId)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a naturally sorted list of items.", "response": "def nsorted(to_sort, key=None):\n    \"\"\"Returns a naturally sorted list\"\"\"\n    if key is None:\n        key_callback = _natural_keys\n    else:\n        def key_callback(item):\n            return _natural_keys(key(item))\n\n    return sorted(to_sort, key=key_callback)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the object is a method descriptor.", "response": "def ismethoddescriptor(object):\n    \"\"\"Return true if the object is a method descriptor.\n\n    But not if ismethod() or isclass() or isfunction() are true.\n\n    This is new in Python 2.2, and, for example, is true of int.__add__.\n    An object passing this test has a __get__ attribute but not a __set__\n    attribute, but beyond that the set of attributes varies.  __name__ is\n    usually sensible, and __doc__ often is.\n\n    Methods implemented via descriptors that also pass one of the other\n    tests return false from the ismethoddescriptor() test, simply because\n    the other tests promise more -- you can, e.g., count on having the\n    im_func attribute (etc) when an object passes ismethod().\"\"\"\n    return (hasattr(object, \"__get__\")\n            and not hasattr(object, \"__set__\") # else it's a data descriptor\n            and not ismethod(object)           # mutual exclusion\n            and not isfunction(object)\n            and not isclass(object))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns true if the object is any kind of function or method.", "response": "def isroutine(object):\n    \"\"\"Return true if the object is any kind of function or method.\"\"\"\n    return (isbuiltin(object)\n            or isfunction(object)\n            or ismethod(object)\n            or ismethoddescriptor(object))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getmembers(object, predicate=None):\n    results = []\n    for key in dir(object):\n        value = getattr(object, key)\n        if not predicate or predicate(value):\n            results.append((key, value))\n    results.sort()\n    return results", "response": "Return all members of an object sorted by name. Optionally only return members that satisfy a given predicate. Optionally only return members that satisfy a given predicate."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef classify_class_attrs(cls):\n\n    mro = getmro(cls)\n    names = dir(cls)\n    result = []\n    for name in names:\n        # Get the object associated with the name.\n        # Getting an obj from the __dict__ sometimes reveals more than\n        # using getattr.  Static and class methods are dramatic examples.\n        if name in cls.__dict__:\n            obj = cls.__dict__[name]\n        else:\n            obj = getattr(cls, name)\n\n        # Figure out where it was defined.\n        homecls = getattr(obj, \"__objclass__\", None)\n        if homecls is None:\n            # search the dicts.\n            for base in mro:\n                if name in base.__dict__:\n                    homecls = base\n                    break\n\n        # Get the object again, in order to get it from the defining\n        # __dict__ instead of via getattr (if possible).\n        if homecls is not None and name in homecls.__dict__:\n            obj = homecls.__dict__[name]\n\n        # Also get the object via getattr.\n        obj_via_getattr = getattr(cls, name)\n\n        # Classify the object.\n        if isinstance(obj, staticmethod):\n            kind = \"static method\"\n        elif isinstance(obj, classmethod):\n            kind = \"class method\"\n        elif isinstance(obj, property):\n            kind = \"property\"\n        elif (ismethod(obj_via_getattr) or\n              ismethoddescriptor(obj_via_getattr)):\n            kind = \"method\"\n        else:\n            kind = \"data\"\n\n        result.append((name, kind, homecls, obj))\n\n    return result", "response": "Classify the class attributes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn tuple of base classes including cls in method resolution order.", "response": "def getmro(cls):\n    \"Return tuple of base classes (including cls) in method resolution order.\"\n    if hasattr(cls, \"__mro__\"):\n        return cls.__mro__\n    else:\n        result = []\n        _searchbases(cls, result)\n        return tuple(result)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef indentsize(line):\n    expline = string.expandtabs(line)\n    return len(expline) - len(string.lstrip(expline))", "response": "Return the indent size in spaces at the start of a line of text."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getdoc(object):\n    try:\n        doc = object.__doc__\n    except AttributeError:\n        return None\n    if not isinstance(doc, (str, unicode)):\n        return None\n    try:\n        lines = string.split(string.expandtabs(doc), '\\n')\n    except UnicodeError:\n        return None\n    else:\n        margin = None\n        for line in lines[1:]:\n            content = len(string.lstrip(line))\n            if not content: continue\n            indent = len(line) - content\n            if margin is None: margin = indent\n            else: margin = min(margin, indent)\n        if margin is not None:\n            for i in range(1, len(lines)): lines[i] = lines[i][margin:]\n        return string.join(lines, '\\n')", "response": "Get the documentation string for an object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nworks out which source or compiled file an object was defined in.", "response": "def getfile(object):\n    \"\"\"Work out which source or compiled file an object was defined in.\"\"\"\n    if ismodule(object):\n        if hasattr(object, '__file__'):\n            return object.__file__\n        raise TypeError, 'arg is a built-in module'\n    if isclass(object):\n        object = sys.modules.get(object.__module__)\n        if hasattr(object, '__file__'):\n            return object.__file__\n        raise TypeError, 'arg is a built-in class'\n    if ismethod(object):\n        object = object.im_func\n    if isfunction(object):\n        object = object.func_code\n    if istraceback(object):\n        object = object.tb_frame\n    if isframe(object):\n        object = object.f_code\n    if iscode(object):\n        return object.co_filename\n    raise TypeError, 'arg is not a module, class, method, ' \\\n                     'function, traceback, frame, or code object'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the module name suffix mode mtype for a given file.", "response": "def getmoduleinfo(path):\n    \"\"\"Get the module name, suffix, mode, and module type for a given file.\"\"\"\n    filename = os.path.basename(path)\n    suffixes = map(lambda (suffix, mode, mtype):\n                   (-len(suffix), suffix, mode, mtype), imp.get_suffixes())\n    suffixes.sort() # try longest suffixes first, in case they overlap\n    for neglen, suffix, mode, mtype in suffixes:\n        if filename[neglen:] == suffix:\n            return filename[:neglen], suffix, mode, mtype"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getsourcefile(object):\n    filename = getfile(object)\n    if string.lower(filename[-4:]) in ['.pyc', '.pyo']:\n        filename = filename[:-4] + '.py'\n    for suffix, mode, kind in imp.get_suffixes():\n        if 'b' in mode and string.lower(filename[-len(suffix):]) == suffix:\n            # Looks like a binary file.  We want to only return a text file.\n            return None\n    if os.path.exists(filename):\n        return filename", "response": "Return the Python source file an object was defined in if it exists."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getabsfile(object):\n    return os.path.normcase(\n        os.path.abspath(getsourcefile(object) or getfile(object)))", "response": "Return an absolute path to the source or compiled file for an object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getmodule(object):\n    if ismodule(object):\n        return object\n    if isclass(object):\n        return sys.modules.get(object.__module__)\n    try:\n        file = getabsfile(object)\n    except TypeError:\n        return None\n    if modulesbyfile.has_key(file):\n        return sys.modules[modulesbyfile[file]]\n    for module in sys.modules.values():\n        if hasattr(module, '__file__'):\n            modulesbyfile[getabsfile(module)] = module.__name__\n    if modulesbyfile.has_key(file):\n        return sys.modules[modulesbyfile[file]]\n    main = sys.modules['__main__']\n    if hasattr(main, object.__name__):\n        mainobject = getattr(main, object.__name__)\n        if mainobject is object:\n            return main\n    builtin = sys.modules['__builtin__']\n    if hasattr(builtin, object.__name__):\n        builtinobject = getattr(builtin, object.__name__)\n        if builtinobject is object:\n            return builtin", "response": "Return the module an object was defined in or None if not found."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the entire source file and starting line number for an object.", "response": "def findsource(object):\n    \"\"\"Return the entire source file and starting line number for an object.\n\n    The argument may be a module, class, method, function, traceback, frame,\n    or code object.  The source code is returned as a list of all the lines\n    in the file and the line number indexes a line in that list.  An IOError\n    is raised if the source code cannot be retrieved.\"\"\"\n    try:\n        file = open(getsourcefile(object))\n    except (TypeError, IOError):\n        raise IOError, 'could not get source code'\n    lines = file.readlines()\n    file.close()\n\n    if ismodule(object):\n        return lines, 0\n\n    if isclass(object):\n        name = object.__name__\n        pat = re.compile(r'^\\s*class\\s*' + name + r'\\b')\n        for i in range(len(lines)):\n            if pat.match(lines[i]): return lines, i\n        else: raise IOError, 'could not find class definition'\n\n    if ismethod(object):\n        object = object.im_func\n    if isfunction(object):\n        object = object.func_code\n    if istraceback(object):\n        object = object.tb_frame\n    if isframe(object):\n        object = object.f_code\n    if iscode(object):\n        if not hasattr(object, 'co_firstlineno'):\n            raise IOError, 'could not find function definition'\n        lnum = object.co_firstlineno - 1\n        pat = re.compile(r'^(\\s*def\\s)|(.*\\slambda(:|\\s))')\n        while lnum > 0:\n            if pat.match(lines[lnum]): break\n            lnum = lnum - 1\n        return lines, lnum\n    raise IOError, 'could not find code object'"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getcomments(object):\n    try: lines, lnum = findsource(object)\n    except IOError: return None\n\n    if ismodule(object):\n        # Look for a comment block at the top of the file.\n        start = 0\n        if lines and lines[0][:2] == '#!': start = 1\n        while start < len(lines) and string.strip(lines[start]) in ['', '#']:\n            start = start + 1\n        if start < len(lines) and lines[start][:1] == '#':\n            comments = []\n            end = start\n            while end < len(lines) and lines[end][:1] == '#':\n                comments.append(string.expandtabs(lines[end]))\n                end = end + 1\n            return string.join(comments, '')\n\n    # Look for a preceding block of comments at the same indentation.\n    elif lnum > 0:\n        indent = indentsize(lines[lnum])\n        end = lnum - 1\n        if end >= 0 and string.lstrip(lines[end])[:1] == '#' and \\\n            indentsize(lines[end]) == indent:\n            comments = [string.lstrip(string.expandtabs(lines[end]))]\n            if end > 0:\n                end = end - 1\n                comment = string.lstrip(string.expandtabs(lines[end]))\n                while comment[:1] == '#' and indentsize(lines[end]) == indent:\n                    comments[:0] = [comment]\n                    end = end - 1\n                    if end < 0: break\n                    comment = string.lstrip(string.expandtabs(lines[end]))\n            while comments and string.strip(comments[0]) == '#':\n                comments[:1] = []\n            while comments and string.strip(comments[-1]) == '#':\n                comments[-1:] = []\n            return string.join(comments, '')", "response": "Get lines of comments immediately preceding an object s source code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getblock(lines):\n    try:\n        tokenize.tokenize(ListReader(lines).readline, BlockFinder().tokeneater)\n    except EndOfBlock, eob:\n        return lines[:eob.args[0]]\n    # Fooling the indent/dedent logic implies a one-line definition\n    return lines[:1]", "response": "Extract the block of code at the top of the given list of lines."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of source lines and starting line number for an object.", "response": "def getsourcelines(object):\n    \"\"\"Return a list of source lines and starting line number for an object.\n\n    The argument may be a module, class, method, function, traceback, frame,\n    or code object.  The source code is returned as a list of the lines\n    corresponding to the object and the line number indicates where in the\n    original source file the first line of code was found.  An IOError is\n    raised if the source code cannot be retrieved.\"\"\"\n    lines, lnum = findsource(object)\n\n    if ismodule(object): return lines, 0\n    else: return getblock(lines[lnum:]), lnum + 1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef walktree(classes, children, parent):\n    results = []\n    classes.sort(lambda a, b: cmp(a.__name__, b.__name__))\n    for c in classes:\n        results.append((c, c.__bases__))\n        if children.has_key(c):\n            results.append(walktree(children[c], children, c))\n    return results", "response": "Recursive helper function for getclasstree ("}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getclasstree(classes, unique=0):\n    children = {}\n    roots = []\n    for c in classes:\n        if c.__bases__:\n            for parent in c.__bases__:\n                if not children.has_key(parent):\n                    children[parent] = []\n                children[parent].append(c)\n                if unique and parent in classes: break\n        elif c not in roots:\n            roots.append(c)\n    for parent in children.keys():\n        if parent not in classes:\n            roots.append(parent)\n    return walktree(roots, children, None)", "response": "Arrange the given list of classes into a hierarchy of nested lists."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets information about the arguments accepted by a code object.", "response": "def getargs(co):\n    \"\"\"Get information about the arguments accepted by a code object.\n\n    Three things are returned: (args, varargs, varkw), where 'args' is\n    a list of argument names (possibly containing nested lists), and\n    'varargs' and 'varkw' are the names of the * and ** arguments or None.\"\"\"\n    if not iscode(co): raise TypeError, 'arg is not a code object'\n\n    nargs = co.co_argcount\n    names = co.co_varnames\n    args = list(names[:nargs])\n    step = 0\n\n    # The following acrobatics are for anonymous (tuple) arguments.\n    if not sys.platform.startswith('java'):#Jython doesn't have co_code\n        code = co.co_code\n        import dis\n        for i in range(nargs):\n            if args[i][:1] in ['', '.']:\n                stack, remain, count = [], [], []\n                while step < len(code):\n                    op = ord(code[step])\n                    step = step + 1\n                    if op >= dis.HAVE_ARGUMENT:\n                        opname = dis.opname[op]\n                        value = ord(code[step]) + ord(code[step + 1]) * 256\n                        step = step + 2\n                        if opname in ['UNPACK_TUPLE', 'UNPACK_SEQUENCE']:\n                            remain.append(value)\n                            count.append(value)\n                        elif opname == 'STORE_FAST':\n                            stack.append(names[value])\n                            remain[-1] = remain[-1] - 1\n                            while remain[-1] == 0:\n                                remain.pop()\n                                size = count.pop()\n                                stack[-size:] = [stack[-size:]]\n                                if not remain: break\n                                remain[-1] = remain[-1] - 1\n                            if not remain: break\n                args[i] = stack[0]\n\n    varargs = None\n    if co.co_flags & CO_VARARGS:\n        varargs = co.co_varnames[nargs]\n        nargs = nargs + 1\n    varkw = None\n    if co.co_flags & CO_VARKEYWORDS:\n        varkw = co.co_varnames[nargs]\n    return args, varargs, varkw"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getargspec(func):\n    if ismethod(func):\n        func = func.im_func\n    if not isfunction(func): raise TypeError, 'arg is not a Python function'\n    args, varargs, varkw = getargs(func.func_code)\n    return args, varargs, varkw, func.func_defaults", "response": "Get the names and default values of a Python function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting information about arguments passed into a particular frame.", "response": "def getargvalues(frame):\n    \"\"\"Get information about arguments passed into a particular frame.\n\n    A tuple of four things is returned: (args, varargs, varkw, locals).\n    'args' is a list of the argument names (it may contain nested lists).\n    'varargs' and 'varkw' are the names of the * and ** arguments or None.\n    'locals' is the locals dictionary of the given frame.\"\"\"\n    args, varargs, varkw = getargs(frame.f_code)\n    return args, varargs, varkw, frame.f_locals"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef strseq(object, convert, join=joinseq):\n    if type(object) in [types.ListType, types.TupleType]:\n        return join(map(lambda o, c=convert, j=join: strseq(o, c, j), object))\n    else:\n        return convert(object)", "response": "Recursively walk a sequence stringifying each element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef formatargspec(args, varargs=None, varkw=None, defaults=None,\n                  formatarg=str,\n                  formatvarargs=lambda name: '*' + name,\n                  formatvarkw=lambda name: '**' + name,\n                  formatvalue=lambda value: '=' + repr(value),\n                  join=joinseq):\n    \"\"\"Format an argument spec from the 4 values returned by getargspec.\n\n    The first four arguments are (args, varargs, varkw, defaults).  The\n    other four arguments are the corresponding optional formatting functions\n    that are called to turn names and values into strings.  The ninth\n    argument is an optional function to format the sequence of arguments.\"\"\"\n    specs = []\n    if defaults:\n        firstdefault = len(args) - len(defaults)\n    for i in range(len(args)):\n        spec = strseq(args[i], formatarg, join)\n        if defaults and i >= firstdefault:\n            spec = spec + formatvalue(defaults[i - firstdefault])\n        specs.append(spec)\n    if varargs:\n        specs.append(formatvarargs(varargs))\n    if varkw:\n        specs.append(formatvarkw(varkw))\n    return '(' + string.join(specs, ', ') + ')'", "response": "Format an argument spec from the 4 values returned by getargspec."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats an argument spec from the 4 values returned by getargvalues.", "response": "def formatargvalues(args, varargs, varkw, locals,\n                    formatarg=str,\n                    formatvarargs=lambda name: '*' + name,\n                    formatvarkw=lambda name: '**' + name,\n                    formatvalue=lambda value: '=' + repr(value),\n                    join=joinseq):\n    \"\"\"Format an argument spec from the 4 values returned by getargvalues.\n\n    The first four arguments are (args, varargs, varkw, locals).  The\n    next four arguments are the corresponding optional formatting functions\n    that are called to turn names and values into strings.  The ninth\n    argument is an optional function to format the sequence of arguments.\"\"\"\n    def convert(name, locals=locals,\n                formatarg=formatarg, formatvalue=formatvalue):\n        return formatarg(name) + formatvalue(locals[name])\n    specs = []\n    for i in range(len(args)):\n        specs.append(strseq(args[i], convert, join))\n    if varargs:\n        specs.append(formatvarargs(varargs) + formatvalue(locals[varargs]))\n    if varkw:\n        specs.append(formatvarkw(varkw) + formatvalue(locals[varkw]))\n    return '(' + string.join(specs, ', ') + ')'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getlineno(frame):\n    # Written by Marc-Andr Lemburg; revised by Jim Hugunin and Fredrik Lundh.\n    lineno = frame.f_lineno\n    code = frame.f_code\n    if hasattr(code, 'co_lnotab'):\n        table = code.co_lnotab\n        lineno = code.co_firstlineno\n        addr = 0\n        for i in range(0, len(table), 2):\n            addr = addr + ord(table[i])\n            if addr > frame.f_lasti: break\n            lineno = lineno + ord(table[i + 1])\n    return lineno", "response": "Get the line number from a frame object allowing for optimization."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getouterframes(frame, context=1):\n    framelist = []\n    while frame:\n        framelist.append((frame,) + getframeinfo(frame, context))\n        frame = frame.f_back\n    return framelist", "response": "Get a list of records for a frame and all higher ( calling ) frames."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a list of records for a traceback s frame and all lower frames.", "response": "def getinnerframes(tb, context=1):\n    \"\"\"Get a list of records for a traceback's frame and all lower frames.\n\n    Each record contains a frame object, filename, line number, function\n    name, a list of lines of context, and index within the context.\"\"\"\n    framelist = []\n    while tb:\n        framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n        tb = tb.tb_next\n    return framelist"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert(gr, raw_node):\n    type, value, context, children = raw_node\n    if children or type in gr.number2symbol:\n        # If there's exactly one child, return that child instead of\n        # creating a new node.\n        if len(children) == 1:\n            return children[0]\n        return Node(type, children, context=context)\n    else:\n        return Leaf(type, value, context=context)", "response": "Convert raw node information to a Node or Leaf instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_matches(patterns, nodes):\n    if not patterns:\n        yield 0, {}\n    else:\n        p, rest = patterns[0], patterns[1:]\n        for c0, r0 in p.generate_matches(nodes):\n            if not rest:\n                yield c0, r0\n            else:\n                for c1, r1 in generate_matches(rest, nodes[c0:]):\n                    r = {}\n                    r.update(r0)\n                    r.update(r1)\n                    yield c0 + c1, r", "response": "Generator yielding matches for a sequence of patterns and nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_prefix(self, prefix):\n        warnings.warn(\"set_prefix() is deprecated; use the prefix property\",\n                      DeprecationWarning, stacklevel=2)\n        self.prefix = prefix", "response": "Set the prefix for the node."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreplaces this node with a new one in the parent.", "response": "def replace(self, new):\n        \"\"\"Replace this node with a new one in the parent.\"\"\"\n        assert self.parent is not None, str(self)\n        assert new is not None\n        if not isinstance(new, list):\n            new = [new]\n        l_children = []\n        found = False\n        for ch in self.parent.children:\n            if ch is self:\n                assert not found, (self.parent.children, self, new)\n                if new is not None:\n                    l_children.extend(new)\n                found = True\n            else:\n                l_children.append(ch)\n        assert found, (self.children, self, new)\n        self.parent.changed()\n        self.parent.children = l_children\n        for x in new:\n            x.parent = self.parent\n        self.parent = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the line number which generated the invocant node.", "response": "def get_lineno(self):\n        \"\"\"Return the line number which generated the invocant node.\"\"\"\n        node = self\n        while not isinstance(node, Leaf):\n            if not node.children:\n                return\n            node = node.children[0]\n        return node.lineno"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove the node from the tree. Returns the position of the node in the parent s children before it was removed.", "response": "def remove(self):\n        \"\"\"\n        Remove the node from the tree. Returns the position of the node in its\n        parent's children before it was removed.\n        \"\"\"\n        if self.parent:\n            for i, node in enumerate(self.parent.children):\n                if node is self:\n                    self.parent.changed()\n                    del self.parent.children[i]\n                    self.parent = None\n                    return i"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the next sibling of the node in the children of this node.", "response": "def next_sibling(self):\n        \"\"\"\n        The node immediately following the invocant in their parent's children\n        list. If the invocant does not have a next sibling, it is None\n        \"\"\"\n        if self.parent is None:\n            return None\n\n        # Can't use index(); we need to test by identity\n        for i, child in enumerate(self.parent.children):\n            if child is self:\n                try:\n                    return self.parent.children[i+1]\n                except IndexError:\n                    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the previous sibling of the node in the parent s children list.", "response": "def prev_sibling(self):\n        \"\"\"\n        The node immediately preceding the invocant in their parent's children\n        list. If the invocant does not have a previous sibling, it is None.\n        \"\"\"\n        if self.parent is None:\n            return None\n\n        # Can't use index(); we need to test by identity\n        for i, child in enumerate(self.parent.children):\n            if child is self:\n                if i == 0:\n                    return None\n                return self.parent.children[i-1]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _eq(self, other):\n        return (self.type, self.children) == (other.type, other.children)", "response": "Compare two nodes for equality."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clone(self):\n        return Node(self.type, [ch.clone() for ch in self.children],\n                    fixers_applied=self.fixers_applied)", "response": "Return a deep copy of self."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an iterator for the tree.", "response": "def post_order(self):\n        \"\"\"Return a post-order iterator for the tree.\"\"\"\n        for child in self.children:\n            for node in child.post_order():\n                yield node\n        yield self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a pre - order iterator for the tree.", "response": "def pre_order(self):\n        \"\"\"Return a pre-order iterator for the tree.\"\"\"\n        yield self\n        for child in self.children:\n            for node in child.pre_order():\n                yield node"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_child(self, i, child):\n        child.parent = self\n        self.children[i].parent = None\n        self.children[i] = child\n        self.changed()", "response": "Equivalent to node. children [ i ] = child."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef insert_child(self, i, child):\n        child.parent = self\n        self.children.insert(i, child)\n        self.changed()", "response": "Equivalent to node. children. insert."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncompares two nodes for equality.", "response": "def _eq(self, other):\n        \"\"\"Compare two nodes for equality.\"\"\"\n        return (self.type, self.value) == (other.type, other.value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clone(self):\n        return Leaf(self.type, self.value,\n                    (self.prefix, (self.lineno, self.column)),\n                    fixers_applied=self.fixers_applied)", "response": "Return a deep copy of self."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmatch a node with this pattern. Returns True if it matches False otherwise.", "response": "def match(self, node, results=None):\n        \"\"\"\n        Does this pattern exactly match a node?\n\n        Returns True if it matches, False if not.\n\n        If results is not None, it must be a dict which will be\n        updated with the nodes matching named subpatterns.\n\n        Default implementation for non-wildcard patterns.\n        \"\"\"\n        if self.type is not None and node.type != self.type:\n            return False\n        if self.content is not None:\n            r = None\n            if results is not None:\n                r = {}\n            if not self._submatch(node, r):\n                return False\n            if r:\n                results.update(r)\n        if results is not None and self.name:\n            results[self.name] = node\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndo this pattern exactly match a sequence of nodes?", "response": "def match_seq(self, nodes, results=None):\n        \"\"\"\n        Does this pattern exactly match a sequence of nodes?\n\n        Default implementation for non-wildcard patterns.\n        \"\"\"\n        if len(nodes) != 1:\n            return False\n        return self.match(nodes[0], results)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef match(self, node, results=None):\n        if not isinstance(node, Leaf):\n            return False\n        return BasePattern.match(self, node, results)", "response": "Override match to insist on a leaf node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _submatch(self, node, results=None):\n        if self.wildcards:\n            for c, r in generate_matches(self.content, node.children):\n                if c == len(node.children):\n                    if results is not None:\n                        results.update(r)\n                    return True\n            return False\n        if len(self.content) != len(node.children):\n            return False\n        for subpattern, child in zip(self.content, node.children):\n            if not subpattern.match(child, results):\n                return False\n        return True", "response": "Match the pattern s content to the node s children. Returns True if it matches False if it does not match."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noptimizing certain stacked wildcard patterns.", "response": "def optimize(self):\n        \"\"\"Optimize certain stacked wildcard patterns.\"\"\"\n        subpattern = None\n        if (self.content is not None and\n            len(self.content) == 1 and len(self.content[0]) == 1):\n            subpattern = self.content[0][0]\n        if self.min == 1 and self.max == 1:\n            if self.content is None:\n                return NodePattern(name=self.name)\n            if subpattern is not None and  self.name == subpattern.name:\n                return subpattern.optimize()\n        if (self.min <= 1 and isinstance(subpattern, WildcardPattern) and\n            subpattern.min <= 1 and self.name == subpattern.name):\n            return WildcardPattern(subpattern.content,\n                                   self.min*subpattern.min,\n                                   self.max*subpattern.max,\n                                   subpattern.name)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndoing this pattern exactly match a sequence of nodes?", "response": "def match_seq(self, nodes, results=None):\n        \"\"\"Does this pattern exactly match a sequence of nodes?\"\"\"\n        for c, r in self.generate_matches(nodes):\n            if c == len(nodes):\n                if results is not None:\n                    results.update(r)\n                    if self.name:\n                        results[self.name] = list(nodes)\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _iterative_matches(self, nodes):\n        nodelen = len(nodes)\n        if 0 >= self.min:\n            yield 0, {}\n\n        results = []\n        # generate matches that use just one alt from self.content\n        for alt in self.content:\n            for c, r in generate_matches(alt, nodes):\n                yield c, r\n                results.append((c, r))\n\n        # for each match, iterate down the nodes\n        while results:\n            new_results = []\n            for c0, r0 in results:\n                # stop if the entire set of nodes has been matched\n                if c0 < nodelen and c0 <= self.max:\n                    for alt in self.content:\n                        for c1, r1 in generate_matches(alt, nodes[c0:]):\n                            if c1 > 0:\n                                r = {}\n                                r.update(r0)\n                                r.update(r1)\n                                yield c0 + c1, r\n                                new_results.append((c0 + c1, r))\n            results = new_results", "response": "Helper to iteratively yield the matches."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _recursive_matches(self, nodes, count):\n        assert self.content is not None\n        if count >= self.min:\n            yield 0, {}\n        if count < self.max:\n            for alt in self.content:\n                for c0, r0 in generate_matches(alt, nodes):\n                    for c1, r1 in self._recursive_matches(nodes[c0:], count+1):\n                        r = {}\n                        r.update(r0)\n                        r.update(r1)\n                        yield c0 + c1, r", "response": "Helper to recursively yield the matches."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef xreload(mod):\n    r = Reload(mod)\n    r.apply()\n    found_change = r.found_change\n    r = None\n    pydevd_dont_trace.clear_trace_filter_cache()\n    return found_change", "response": "Reload a module in place updating classes methods and functions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _update(self, namespace, name, oldobj, newobj, is_class_namespace=False):\n        try:\n            notify_info2('Updating: ', oldobj)\n            if oldobj is newobj:\n                # Probably something imported\n                return\n\n            if type(oldobj) is not type(newobj):\n                # Cop-out: if the type changed, give up\n                notify_error('Type of: %s changed... Skipping.' % (oldobj,))\n                return\n\n            if isinstance(newobj, types.FunctionType):\n                self._update_function(oldobj, newobj)\n                return\n\n            if isinstance(newobj, types.MethodType):\n                self._update_method(oldobj, newobj)\n                return\n\n            if isinstance(newobj, classmethod):\n                self._update_classmethod(oldobj, newobj)\n                return\n\n            if isinstance(newobj, staticmethod):\n                self._update_staticmethod(oldobj, newobj)\n                return\n\n            if hasattr(types, 'ClassType'):\n                classtype = (types.ClassType, type)  # object is not instance of types.ClassType.\n            else:\n                classtype = type\n\n            if isinstance(newobj, classtype):\n                self._update_class(oldobj, newobj)\n                return\n\n            # New: dealing with metaclasses.\n            if hasattr(newobj, '__metaclass__') and hasattr(newobj, '__class__') and newobj.__metaclass__ == newobj.__class__:\n                self._update_class(oldobj, newobj)\n                return\n\n            if namespace is not None:\n\n                if oldobj != newobj and str(oldobj) != str(newobj) and repr(oldobj) != repr(newobj):\n                    xreload_old_new = None\n                    if is_class_namespace:\n                        xreload_old_new = getattr(namespace, '__xreload_old_new__', None)\n                        if xreload_old_new is not None:\n                            self.found_change = True\n                            xreload_old_new(name, oldobj, newobj)\n\n                    elif '__xreload_old_new__' in namespace:\n                        xreload_old_new = namespace['__xreload_old_new__']\n                        xreload_old_new(namespace, name, oldobj, newobj)\n                        self.found_change = True\n\n                    # Too much information to the user...\n                    # else:\n                    #     notify_info0('%s NOT updated. Create __xreload_old_new__(name, old, new) for custom reload' % (name,))\n\n        except:\n            notify_error('Exception found when updating %s. Proceeding for other items.' % (name,))\n            pydev_log.exception()", "response": "Update the object with the new object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates a function object.", "response": "def _update_function(self, oldfunc, newfunc):\n        \"\"\"Update a function object.\"\"\"\n        oldfunc.__doc__ = newfunc.__doc__\n        oldfunc.__dict__.update(newfunc.__dict__)\n\n        try:\n            newfunc.__code__\n            attr_name = '__code__'\n        except AttributeError:\n            newfunc.func_code\n            attr_name = 'func_code'\n\n        old_code = getattr(oldfunc, attr_name)\n        new_code = getattr(newfunc, attr_name)\n        if not code_objects_equal(old_code, new_code):\n            notify_info0('Updated function code:', oldfunc)\n            setattr(oldfunc, attr_name, new_code)\n            self.found_change = True\n\n        try:\n            oldfunc.__defaults__ = newfunc.__defaults__\n        except AttributeError:\n            oldfunc.func_defaults = newfunc.func_defaults\n\n        return oldfunc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate a method object.", "response": "def _update_method(self, oldmeth, newmeth):\n        \"\"\"Update a method object.\"\"\"\n        # XXX What if im_func is not a function?\n        if hasattr(oldmeth, 'im_func') and hasattr(newmeth, 'im_func'):\n            self._update(None, None, oldmeth.im_func, newmeth.im_func)\n        elif hasattr(oldmeth, '__func__') and hasattr(newmeth, '__func__'):\n            self._update(None, None, oldmeth.__func__, newmeth.__func__)\n        return oldmeth"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating a class object.", "response": "def _update_class(self, oldclass, newclass):\n        \"\"\"Update a class object.\"\"\"\n        olddict = oldclass.__dict__\n        newdict = newclass.__dict__\n\n        oldnames = set(olddict)\n        newnames = set(newdict)\n\n        for name in newnames - oldnames:\n            setattr(oldclass, name, newdict[name])\n            notify_info0('Added:', name, 'to', oldclass)\n            self.found_change = True\n\n        # Note: not removing old things...\n        # for name in oldnames - newnames:\n        #    notify_info('Removed:', name, 'from', oldclass)\n        #    delattr(oldclass, name)\n\n        for name in (oldnames & newnames) - set(['__dict__', '__doc__']):\n            self._update(oldclass, name, olddict[name], newdict[name], is_class_namespace=True)\n\n        old_bases = getattr(oldclass, '__bases__', None)\n        new_bases = getattr(newclass, '__bases__', None)\n        if str(old_bases) != str(new_bases):\n            notify_error('Changing the hierarchy of a class is not supported. %s may be inconsistent.' % (oldclass,))\n\n        self._handle_namespace(oldclass, is_class_namespace=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates a classmethod update.", "response": "def _update_classmethod(self, oldcm, newcm):\n        \"\"\"Update a classmethod update.\"\"\"\n        # While we can't modify the classmethod object itself (it has no\n        # mutable attributes), we *can* extract the underlying function\n        # (by calling __get__(), which returns a method object) and update\n        # it in-place.  We don't have the class available to pass to\n        # __get__() but any object except None will do.\n        self._update(None, None, oldcm.__get__(0), newcm.__get__(0))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate a staticmethod update.", "response": "def _update_staticmethod(self, oldsm, newsm):\n        \"\"\"Update a staticmethod update.\"\"\"\n        # While we can't modify the staticmethod object itself (it has no\n        # mutable attributes), we *can* extract the underlying function\n        # (by calling __get__(), which returns it) and update it in-place.\n        # We don't have the class available to pass to __get__() but any\n        # object except None will do.\n        self._update(None, None, oldsm.__get__(0), newsm.__get__(0))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a save_locals_impl method that imports the entire tree of modules and returns the save_locals_impl function.", "response": "def make_save_locals_impl():\n    \"\"\"\n    Factory for the 'save_locals_impl' method. This may seem like a complicated pattern but it is essential that the method is created at\n    module load time. Inner imports after module load time would cause an occasional debugger deadlock due to the importer lock and debugger\n    lock being taken in different order in  different threads.\n    \"\"\"\n    try:\n        if '__pypy__' in sys.builtin_module_names:\n            import __pypy__  # @UnresolvedImport\n            save_locals = __pypy__.locals_to_fast\n    except:\n        pass\n    else:\n        if '__pypy__' in sys.builtin_module_names:\n            def save_locals_pypy_impl(frame):\n                save_locals(frame)\n\n            return save_locals_pypy_impl\n\n    try:\n        import ctypes\n        locals_to_fast = ctypes.pythonapi.PyFrame_LocalsToFast\n    except:\n        pass\n    else:\n        def save_locals_ctypes_impl(frame):\n            locals_to_fast(ctypes.py_object(frame), ctypes.c_int(0))\n\n        return save_locals_ctypes_impl\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Assign(target, source):\n    if not isinstance(target, list):\n        target = [target]\n    if not isinstance(source, list):\n        source.prefix = u\" \"\n        source = [source]\n\n    return Node(syms.atom,\n                target + [Leaf(token.EQUAL, u\"=\", prefix=u\" \")] + source)", "response": "Build an assignment statement"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ArgList(args, lparen=LParen(), rparen=RParen()):\n    node = Node(syms.trailer, [lparen.clone(), rparen.clone()])\n    if args:\n        node.insert_child(1, Node(syms.arglist, args))\n    return node", "response": "A parenthesised argument list used by Call."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ListComp(xp, fp, it, test=None):\n    xp.prefix = u\"\"\n    fp.prefix = u\" \"\n    it.prefix = u\" \"\n    for_leaf = Leaf(token.NAME, u\"for\")\n    for_leaf.prefix = u\" \"\n    in_leaf = Leaf(token.NAME, u\"in\")\n    in_leaf.prefix = u\" \"\n    inner_args = [for_leaf, fp, in_leaf, it]\n    if test:\n        test.prefix = u\" \"\n        if_leaf = Leaf(token.NAME, u\"if\")\n        if_leaf.prefix = u\" \"\n        inner_args.append(Node(syms.comp_if, [if_leaf, test]))\n    inner = Node(syms.listmaker, [xp, Node(syms.comp_for, inner_args)])\n    return Node(syms.atom,\n                       [Leaf(token.LBRACE, u\"[\"),\n                        inner,\n                        Leaf(token.RBRACE, u\"]\")])", "response": "A list comprehension of the form [ xp fp it test ]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an import statement in the form of a tree of trees that are imported from a given package.", "response": "def FromImport(package_name, name_leafs):\n    \"\"\" Return an import statement in the form:\n        from package import name_leafs\"\"\"\n    # XXX: May not handle dotted imports properly (eg, package_name='foo.bar')\n    #assert package_name == '.' or '.' not in package_name, \"FromImport has \"\\\n    #       \"not been tested with dotted package names -- use at your own \"\\\n    #       \"peril!\"\n\n    for leaf in name_leafs:\n        # Pull the leaves out of their old tree\n        leaf.remove()\n\n    children = [Leaf(token.NAME, u\"from\"),\n                Leaf(token.NAME, package_name, prefix=u\" \"),\n                Leaf(token.NAME, u\"import\", prefix=u\" \"),\n                Node(syms.import_as_names, name_leafs)]\n    imp = Node(syms.import_from, children)\n    return imp"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndoing the node represent a tuple literal?", "response": "def is_tuple(node):\n    \"\"\"Does the node represent a tuple literal?\"\"\"\n    if isinstance(node, Node) and node.children == [LParen(), RParen()]:\n        return True\n    return (isinstance(node, Node)\n            and len(node.children) == 3\n            and isinstance(node.children[0], Leaf)\n            and isinstance(node.children[1], Node)\n            and isinstance(node.children[2], Leaf)\n            and node.children[0].value == u\"(\"\n            and node.children[2].value == u\")\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndoes the node represent a list literal?", "response": "def is_list(node):\n    \"\"\"Does the node represent a list literal?\"\"\"\n    return (isinstance(node, Node)\n            and len(node.children) > 1\n            and isinstance(node.children[0], Leaf)\n            and isinstance(node.children[-1], Leaf)\n            and node.children[0].value == u\"[\"\n            and node.children[-1].value == u\"]\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfollowing an attribute chain.", "response": "def attr_chain(obj, attr):\n    \"\"\"Follow an attribute chain.\n\n    If you have a chain of objects where a.foo -> b, b.foo-> c, etc,\n    use this to iterate over all objects in the chain. Iteration is\n    terminated by getattr(x, attr) is None.\n\n    Args:\n        obj: the starting object\n        attr: the name of the chaining attribute\n\n    Yields:\n        Each successive object in the chain.\n    \"\"\"\n    next = getattr(obj, attr)\n    while next:\n        yield next\n        next = getattr(next, attr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef in_special_context(node):\n    global p0, p1, p2, pats_built\n    if not pats_built:\n        p0 = patcomp.compile_pattern(p0)\n        p1 = patcomp.compile_pattern(p1)\n        p2 = patcomp.compile_pattern(p2)\n        pats_built = True\n    patterns = [p0, p1, p2]\n    for pattern, parent in zip(patterns, attr_chain(node, \"parent\")):\n        results = {}\n        if pattern.match(parent, results) and results[\"node\"] is node:\n            return True\n    return False", "response": "Returns true if the node is in a special context."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_probably_builtin(node):\n    prev = node.prev_sibling\n    if prev is not None and prev.type == token.DOT:\n        # Attribute lookup.\n        return False\n    parent = node.parent\n    if parent.type in (syms.funcdef, syms.classdef):\n        return False\n    if parent.type == syms.expr_stmt and parent.children[0] is node:\n        # Assignment.\n        return False\n    if parent.type == syms.parameters or \\\n            (parent.type == syms.typedargslist and (\n            (prev is not None and prev.type == token.COMMA) or\n            parent.children[0] is node\n            )):\n        # The name of an argument.\n        return False\n    return True", "response": "Check that something isn t a builtin function or attribute."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_indentation(node):\n    while node is not None:\n        if node.type == syms.suite and len(node.children) > 2:\n            indent = node.children[1]\n            if indent.type == token.INDENT:\n                return indent.value\n        node = node.parent\n    return u\"\"", "response": "Find the indentation of a node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding the top level namespace.", "response": "def find_root(node):\n    \"\"\"Find the top level namespace.\"\"\"\n    # Scamper up to the top level namespace\n    while node.type != syms.file_input:\n        node = node.parent\n        if not node:\n            raise ValueError(\"root found before file_input node was found.\")\n    return node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning true if name is imported from package at the top level of the tree which is not a tree root.", "response": "def does_tree_import(package, name, node):\n    \"\"\" Returns true if name is imported from package at the\n        top level of the tree which node belongs to.\n        To cover the case of an import like 'import foo', use\n        None for the package and 'foo' for the name. \"\"\"\n    binding = find_binding(name, find_root(node), package)\n    return bool(binding)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef touch_import(package, name, node):\n    def is_import_stmt(node):\n        return (node.type == syms.simple_stmt and node.children and\n                is_import(node.children[0]))\n\n    root = find_root(node)\n\n    if does_tree_import(package, name, root):\n        return\n\n    # figure out where to insert the new import.  First try to find\n    # the first import and then skip to the last one.\n    insert_pos = offset = 0\n    for idx, node in enumerate(root.children):\n        if not is_import_stmt(node):\n            continue\n        for offset, node2 in enumerate(root.children[idx:]):\n            if not is_import_stmt(node2):\n                break\n        insert_pos = idx + offset\n        break\n\n    # if there are no imports where we can insert, find the docstring.\n    # if that also fails, we stick to the beginning of the file\n    if insert_pos == 0:\n        for idx, node in enumerate(root.children):\n            if (node.type == syms.simple_stmt and node.children and\n               node.children[0].type == token.STRING):\n                insert_pos = idx + 1\n                break\n\n    if package is None:\n        import_ = Node(syms.import_name, [\n            Leaf(token.NAME, u\"import\"),\n            Leaf(token.NAME, name, prefix=u\" \")\n        ])\n    else:\n        import_ = FromImport(package, [Leaf(token.NAME, name, prefix=u\" \")])\n\n    children = [import_, Newline()]\n    root.insert_child(insert_pos, Node(syms.simple_stmt, children))", "response": "Creates a new import statement if it was not imported."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the node which binds variable name otherwise None.", "response": "def find_binding(name, node, package=None):\n    \"\"\" Returns the node which binds variable name, otherwise None.\n        If optional argument package is supplied, only imports will\n        be returned.\n        See test cases for examples.\"\"\"\n    for child in node.children:\n        ret = None\n        if child.type == syms.for_stmt:\n            if _find(name, child.children[1]):\n                return child\n            n = find_binding(name, make_suite(child.children[-1]), package)\n            if n: ret = n\n        elif child.type in (syms.if_stmt, syms.while_stmt):\n            n = find_binding(name, make_suite(child.children[-1]), package)\n            if n: ret = n\n        elif child.type == syms.try_stmt:\n            n = find_binding(name, make_suite(child.children[2]), package)\n            if n:\n                ret = n\n            else:\n                for i, kid in enumerate(child.children[3:]):\n                    if kid.type == token.COLON and kid.value == \":\":\n                        # i+3 is the colon, i+4 is the suite\n                        n = find_binding(name, make_suite(child.children[i+4]), package)\n                        if n: ret = n\n        elif child.type in _def_syms and child.children[1].value == name:\n            ret = child\n        elif _is_import_binding(child, name, package):\n            ret = child\n        elif child.type == syms.simple_stmt:\n            ret = find_binding(name, child, package)\n        elif child.type == syms.expr_stmt:\n            if _find(name, child.children[0]):\n                ret = child\n\n        if ret:\n            if not package:\n                return ret\n            if is_import(ret):\n                return ret\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _is_import_binding(node, name, package=None):\n\n    if node.type == syms.import_name and not package:\n        imp = node.children[1]\n        if imp.type == syms.dotted_as_names:\n            for child in imp.children:\n                if child.type == syms.dotted_as_name:\n                    if child.children[2].value == name:\n                        return node\n                elif child.type == token.NAME and child.value == name:\n                    return node\n        elif imp.type == syms.dotted_as_name:\n            last = imp.children[-1]\n            if last.type == token.NAME and last.value == name:\n                return node\n        elif imp.type == token.NAME and imp.value == name:\n            return node\n    elif node.type == syms.import_from:\n        # unicode(...) is used to make life easier here, because\n        # from a.b import parses to ['import', ['a', '.', 'b'], ...]\n        if package and unicode(node.children[1]).strip() != package:\n            return None\n        n = node.children[3]\n        if package and _find(u\"as\", n):\n            # See test_from_import_as for explanation\n            return None\n        elif n.type == syms.import_as_names and _find(name, n):\n            return node\n        elif n.type == syms.import_as_name:\n            child = n.children[2]\n            if child.type == token.NAME and child.value == name:\n                return node\n        elif n.type == token.NAME and n.value == name:\n            return node\n        elif package and n.type == token.STAR:\n            return node\n    return None", "response": "Checks if a node is import binding."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_interactive_console(thread_id, frame_id, frame, console_message):\n    if InteractiveConsoleCache.thread_id == thread_id and InteractiveConsoleCache.frame_id == frame_id:\n        return InteractiveConsoleCache.interactive_console_instance\n\n    InteractiveConsoleCache.interactive_console_instance = DebugConsole()\n    InteractiveConsoleCache.thread_id = thread_id\n    InteractiveConsoleCache.frame_id = frame_id\n\n    console_stacktrace = traceback.extract_stack(frame, limit=1)\n    if console_stacktrace:\n        current_context = console_stacktrace[0] # top entry from stacktrace\n        context_message = 'File \"%s\", line %s, in %s' % (current_context[0], current_context[1], current_context[2])\n        console_message.add_console_message(CONSOLE_OUTPUT, \"[Current context]: %s\" % (context_message,))\n    return InteractiveConsoleCache.interactive_console_instance", "response": "returns the global interactive console."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes a console command on the console", "response": "def execute_console_command(frame, thread_id, frame_id, line, buffer_output=True):\n    \"\"\"fetch an interactive console instance from the cache and\n    push the received command to the console.\n\n    create and return an instance of console_message\n    \"\"\"\n    console_message = ConsoleMessage()\n\n    interpreter = get_interactive_console(thread_id, frame_id, frame, console_message)\n    more, output_messages, error_messages = interpreter.push(line, frame, buffer_output)\n    console_message.update_more(more)\n\n    for message in output_messages:\n        console_message.add_console_message(CONSOLE_OUTPUT, message)\n\n    for message in error_messages:\n        console_message.add_console_message(CONSOLE_ERROR, message)\n\n    return console_message"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_console_message(self, message_type, message):\n        for m in message.split(\"\\n\"):\n            if m.strip():\n                self.console_messages.append((message_type, m))", "response": "add a message to the console_messages list"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an XML for the current locale.", "response": "def to_xml(self):\n        \"\"\"Create an XML for console message_list, error and more (true/false)\n        <xml>\n            <message_list>console message_list</message_list>\n            <error>console error</error>\n            <more>true/false</more>\n        </xml>\n        \"\"\"\n        makeValid = make_valid_xml_value\n\n        xml = '<xml><more>%s</more>' % (self.more)\n\n        for message_type, message in self.console_messages:\n            xml += '<%s message=\"%s\"></%s>' % (message_type, makeValid(message), message_type)\n\n        xml += '</xml>'\n\n        return xml"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute the InteractiveConsole. push method.", "response": "def push(self, line, frame, buffer_output=True):\n        \"\"\"Change built-in stdout and stderr methods by the\n        new custom StdMessage.\n        execute the InteractiveConsole.push.\n        Change the stdout and stderr back be the original built-ins\n\n        :param buffer_output: if False won't redirect the output.\n\n        Return boolean (True if more input is required else False),\n        output_messages and input_messages\n        \"\"\"\n        self.__buffer_output = buffer_output\n        more = False\n        if buffer_output:\n            original_stdout = sys.stdout\n            original_stderr = sys.stderr\n        try:\n            try:\n                self.frame = frame\n                if buffer_output:\n                    out = sys.stdout = IOBuf()\n                    err = sys.stderr = IOBuf()\n                more = self.add_exec(line)\n            except Exception:\n                exc = get_exception_traceback_str()\n                if buffer_output:\n                    err.buflist.append(\"Internal Error: %s\" % (exc,))\n                else:\n                    sys.stderr.write(\"Internal Error: %s\\n\" % (exc,))\n        finally:\n            #Remove frame references.\n            self.frame = None\n            frame = None\n            if buffer_output:\n                sys.stdout = original_stdout\n                sys.stderr = original_stderr\n\n        if buffer_output:\n            return more, out.buflist, err.buflist\n        else:\n            return more, [], []"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef runcode(self, code):\n        try:\n            Exec(code, self.frame.f_globals, self.frame.f_locals)\n            pydevd_save_locals.save_locals(self.frame)\n        except SystemExit:\n            raise\n        except:\n            # In case sys.excepthook called, use original excepthook #PyDev-877: Debug console freezes with Python 3.5+\n            # (showtraceback does it on python 3.5 onwards)\n            sys.excepthook = sys.__excepthook__\n            try:\n                self.showtraceback()\n            finally:\n                sys.__excepthook__ = sys.excepthook", "response": "Execute a code object and display a traceback."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_dict(cls, fsa):\n        'Instance a new structure from a Python dictionary.'\n        fsa = dict(fsa)\n        s = cls()\n        for key in cls._integer_members:\n            setattr(s, key, fsa.get(key))\n        ra = fsa.get('RegisterArea', None)\n        if ra is not None:\n            for index in compat.xrange(0, SIZE_OF_80387_REGISTERS):\n                s.RegisterArea[index] = ra[index]\n        return s", "response": "Instance a new structure from a Python dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a structure into a Python dictionary.", "response": "def to_dict(self):\n        'Convert a structure into a Python dictionary.'\n        fsa = dict()\n        for key in self._integer_members:\n            fsa[key] = getattr(self, key)\n        ra = [ self.RegisterArea[index] for index in compat.xrange(0, SIZE_OF_80387_REGISTERS) ]\n        ra = tuple(ra)\n        fsa['RegisterArea'] = ra\n        return fsa"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_dict(cls, ctx):\n        'Instance a new structure from a Python dictionary.'\n        ctx = Context(ctx)\n        s = cls()\n        ContextFlags = ctx['ContextFlags']\n        setattr(s, 'ContextFlags', ContextFlags)\n        if (ContextFlags & CONTEXT_DEBUG_REGISTERS) == CONTEXT_DEBUG_REGISTERS:\n            for key in s._ctx_debug:\n                setattr(s, key, ctx[key])\n        if (ContextFlags & CONTEXT_FLOATING_POINT) == CONTEXT_FLOATING_POINT:\n            fsa = ctx['FloatSave']\n            s.FloatSave = FLOATING_SAVE_AREA.from_dict(fsa)\n        if (ContextFlags & CONTEXT_SEGMENTS) == CONTEXT_SEGMENTS:\n            for key in s._ctx_segs:\n                setattr(s, key, ctx[key])\n        if (ContextFlags & CONTEXT_INTEGER) == CONTEXT_INTEGER:\n            for key in s._ctx_int:\n                setattr(s, key, ctx[key])\n        if (ContextFlags & CONTEXT_CONTROL) == CONTEXT_CONTROL:\n            for key in s._ctx_ctrl:\n                setattr(s, key, ctx[key])\n        if (ContextFlags & CONTEXT_EXTENDED_REGISTERS) == CONTEXT_EXTENDED_REGISTERS:\n            er = ctx['ExtendedRegisters']\n            for index in compat.xrange(0, MAXIMUM_SUPPORTED_EXTENSION):\n                s.ExtendedRegisters[index] = er[index]\n        return s", "response": "Instance a new structure from a Python dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_dict(self):\n        'Convert a structure into a Python native type.'\n        ctx = Context()\n        ContextFlags = self.ContextFlags\n        ctx['ContextFlags'] = ContextFlags\n        if (ContextFlags & CONTEXT_DEBUG_REGISTERS) == CONTEXT_DEBUG_REGISTERS:\n            for key in self._ctx_debug:\n                ctx[key] = getattr(self, key)\n        if (ContextFlags & CONTEXT_FLOATING_POINT) == CONTEXT_FLOATING_POINT:\n            ctx['FloatSave'] = self.FloatSave.to_dict()\n        if (ContextFlags & CONTEXT_SEGMENTS) == CONTEXT_SEGMENTS:\n            for key in self._ctx_segs:\n                ctx[key] = getattr(self, key)\n        if (ContextFlags & CONTEXT_INTEGER) == CONTEXT_INTEGER:\n            for key in self._ctx_int:\n                ctx[key] = getattr(self, key)\n        if (ContextFlags & CONTEXT_CONTROL) == CONTEXT_CONTROL:\n            for key in self._ctx_ctrl:\n                ctx[key] = getattr(self, key)\n        if (ContextFlags & CONTEXT_EXTENDED_REGISTERS) == CONTEXT_EXTENDED_REGISTERS:\n            er = [ self.ExtendedRegisters[index] for index in compat.xrange(0, MAXIMUM_SUPPORTED_EXTENSION) ]\n            er = tuple(er)\n            ctx['ExtendedRegisters'] = er\n        return ctx", "response": "Convert a structure into a Python native type."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nimitate get_normal_name in tokenizer. c.", "response": "def _get_normal_name(orig_enc):\n    \"\"\"Imitates get_normal_name in tokenizer.c.\"\"\"\n    # Only care about the first 12 characters.\n    enc = orig_enc[:12].lower().replace(\"_\", \"-\")\n    if enc == \"utf-8\" or enc.startswith(\"utf-8-\"):\n        return \"utf-8\"\n    if enc in (\"latin-1\", \"iso-8859-1\", \"iso-latin-1\") or \\\n       enc.startswith((\"latin-1-\", \"iso-8859-1-\", \"iso-latin-1-\")):\n        return \"iso-8859-1\"\n    return orig_enc"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns a command and return lines of output by command", "response": "def get_lines(command):\n    \"\"\"\n    Run a command and return lines of output\n\n    :param str command: the command to run\n    :returns: list of whitespace-stripped lines output by command\n    \"\"\"\n    stdout = get_output(command)\n    return [line.strip().decode('utf-8') for line in stdout.splitlines()]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the command line and returns a list of test directories test filter and test suites.", "response": "def parse_cmdline(argv=None):\n    \"\"\"\n    Parses command line and returns test directories, verbosity, test filter and test suites\n\n    usage:\n        runfiles.py  -v|--verbosity <level>  -t|--tests <Test.test1,Test2>  dirs|files\n\n    Multiprocessing options:\n    jobs=number (with the number of jobs to be used to run the tests)\n    split_jobs='module'|'tests'\n        if == module, a given job will always receive all the tests from a module\n        if == tests, the tests will be split independently of their originating module (default)\n\n    --exclude_files  = comma-separated list of patterns with files to exclude (fnmatch style)\n    --include_files = comma-separated list of patterns with files to include (fnmatch style)\n    --exclude_tests = comma-separated list of patterns with test names to exclude (fnmatch style)\n\n    Note: if --tests is given, --exclude_files, --include_files and --exclude_tests are ignored!\n    \"\"\"\n    if argv is None:\n        argv = sys.argv\n\n    verbosity = 2\n    include_tests = None\n    tests = None\n    port = None\n    jobs = 1\n    split_jobs = 'tests'\n    files_to_tests = {}\n    coverage_output_dir = None\n    coverage_include = None\n    exclude_files = None\n    exclude_tests = None\n    include_files = None\n    django = False\n\n    from _pydev_bundle._pydev_getopt import gnu_getopt\n    optlist, dirs = gnu_getopt(\n        argv[1:], \"\",\n        [\n            \"verbosity=\",\n            \"tests=\",\n\n            \"port=\",\n            \"config_file=\",\n\n            \"jobs=\",\n            \"split_jobs=\",\n\n            \"include_tests=\",\n            \"include_files=\",\n\n            \"exclude_files=\",\n            \"exclude_tests=\",\n\n            \"coverage_output_dir=\",\n            \"coverage_include=\",\n\n            \"django=\"\n        ]\n    )\n\n    for opt, value in optlist:\n        if opt in (\"-v\", \"--verbosity\"):\n            verbosity = value\n\n        elif opt in (\"-p\", \"--port\"):\n            port = int(value)\n\n        elif opt in (\"-j\", \"--jobs\"):\n            jobs = int(value)\n\n        elif opt in (\"-s\", \"--split_jobs\"):\n            split_jobs = value\n            if split_jobs not in ('module', 'tests'):\n                raise AssertionError('Expected split to be either \"module\" or \"tests\". Was :%s' % (split_jobs,))\n\n        elif opt in (\"-d\", \"--coverage_output_dir\",):\n            coverage_output_dir = value.strip()\n\n        elif opt in (\"-i\", \"--coverage_include\",):\n            coverage_include = value.strip()\n\n        elif opt in (\"-I\", \"--include_tests\"):\n            include_tests = value.split(',')\n\n        elif opt in (\"-E\", \"--exclude_files\"):\n            exclude_files = value.split(',')\n\n        elif opt in (\"-F\", \"--include_files\"):\n            include_files = value.split(',')\n\n        elif opt in (\"-e\", \"--exclude_tests\"):\n            exclude_tests = value.split(',')\n\n        elif opt in (\"-t\", \"--tests\"):\n            tests = value.split(',')\n\n        elif opt in (\"--django\",):\n            django = value.strip() in ['true', 'True', '1']\n\n        elif opt in (\"-c\", \"--config_file\"):\n            config_file = value.strip()\n            if os.path.exists(config_file):\n                f = open(config_file, 'rU')\n                try:\n                    config_file_contents = f.read()\n                finally:\n                    f.close()\n\n                if config_file_contents:\n                    config_file_contents = config_file_contents.strip()\n\n                if config_file_contents:\n                    for line in config_file_contents.splitlines():\n                        file_and_test = line.split('|')\n                        if len(file_and_test) == 2:\n                            file, test = file_and_test\n                            if file in files_to_tests:\n                                files_to_tests[file].append(test)\n                            else:\n                                files_to_tests[file] = [test]\n\n            else:\n                sys.stderr.write('Could not find config file: %s\\n' % (config_file,))\n\n    if type([]) != type(dirs):\n        dirs = [dirs]\n\n    ret_dirs = []\n    for d in dirs:\n        if '|' in d:\n            #paths may come from the ide separated by |\n            ret_dirs.extend(d.split('|'))\n        else:\n            ret_dirs.append(d)\n\n    verbosity = int(verbosity)\n\n    if tests:\n        if verbosity > 4:\n            sys.stdout.write('--tests provided. Ignoring --exclude_files, --exclude_tests and --include_files\\n')\n        exclude_files = exclude_tests = include_files = None\n\n    config = Configuration(\n        ret_dirs,\n        verbosity,\n        include_tests,\n        tests,\n        port,\n        files_to_tests,\n        jobs,\n        split_jobs,\n        coverage_output_dir,\n        coverage_include,\n        exclude_files=exclude_files,\n        exclude_tests=exclude_tests,\n        include_files=include_files,\n        django=django,\n    )\n\n    if verbosity > 5:\n        sys.stdout.write(str(config) + '\\n')\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef new_consolidate(self, result, batch_result):\n    '''\n    Used so that it can work with the multiprocess plugin.\n    Monkeypatched because nose seems a bit unsupported at this time (ideally\n    the plugin would have this support by default).\n    '''\n    ret = original(self, result, batch_result)\n\n    parent_frame = sys._getframe().f_back\n    # addr is something as D:\\pytesting1\\src\\mod1\\hello.py:TestCase.testMet4\n    # so, convert it to what report_cond expects\n    addr = parent_frame.f_locals['addr']\n    i = addr.rindex(':')\n    addr = [addr[:i], addr[i + 1:]]\n\n    output, testsRun, failures, errors, errorClasses = batch_result\n    if failures or errors:\n        for failure in failures:\n            PYDEV_NOSE_PLUGIN_SINGLETON.report_cond('fail', addr, output, failure)\n\n        for error in errors:\n            PYDEV_NOSE_PLUGIN_SINGLETON.report_cond('error', addr, output, error)\n    else:\n        PYDEV_NOSE_PLUGIN_SINGLETON.report_cond('ok', addr, output)\n\n\n    return ret", "response": "This function is used to consolidate a new node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle_one_request(self):\n        try:\n            self.raw_requestline = self.rfile.readline(65537)\n            if len(self.raw_requestline) > 65536:\n                self.requestline = ''\n                self.request_version = ''\n                self.command = ''\n                self.send_error(414)\n                return\n            if not self.raw_requestline:\n                self.close_connection = 1\n                return\n            if not self.parse_request():\n                # An error code has been sent, just exit\n                return\n            mname = 'do_' + self.command\n            if not hasattr(self, mname):\n                self.send_error(501, \"Unsupported method (%r)\" % self.command)\n                return\n            method = getattr(self, mname)\n            method()\n            self.wfile.flush() #actually send the response if not already done.\n        except socket.timeout:\n            #a read or a write timed out.  Discard this connection\n            self.log_error(\"Request timed out: %r\", sys.exc_info()[1])\n            self.close_connection = 1\n            return", "response": "Handle a single HTTP request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend an error response and log it.", "response": "def send_error(self, code, message=None):\n        \"\"\"Send and log an error reply.\n\n        Arguments are the error code, and a detailed message.\n        The detailed message defaults to the short entry matching the\n        response code.\n\n        This sends an error response (so it must be called before any\n        output has been generated), logs the error, and finally sends\n        a piece of HTML explaining the error to the user.\n\n        \"\"\"\n\n        try:\n            short, long = self.responses[code]\n        except KeyError:\n            short, long = '???', '???'\n        if message is None:\n            message = short\n        explain = long\n        self.log_error(\"code %d, message %s\", code, message)\n        # using _quote_html to prevent Cross Site Scripting attacks (see bug #1100201)\n        content = (self.error_message_format %\n                   {'code': code, 'message': _quote_html(message), 'explain': explain})\n        self.send_response(code, message)\n        self.send_header(\"Content-Type\", self.error_content_type)\n        self.send_header('Connection', 'close')\n        self.end_headers()\n        if self.command != 'HEAD' and code >= 200 and code not in (204, 304):\n            self.wfile.write(content)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend the response header and log the response code.", "response": "def send_response(self, code, message=None):\n        \"\"\"Send the response header and log the response code.\n\n        Also send two standard headers with the server software\n        version and the current date.\n\n        \"\"\"\n        self.log_request(code)\n        if message is None:\n            if code in self.responses:\n                message = self.responses[code][0]\n            else:\n                message = ''\n        if self.request_version != 'HTTP/0.9':\n            self.wfile.write(\"%s %d %s\\r\\n\" %\n                             (self.protocol_version, code, message))\n            # print (self.protocol_version, code, message)\n        self.send_header('Server', self.version_string())\n        self.send_header('Date', self.date_time_string())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_header(self, keyword, value):\n        if self.request_version != 'HTTP/0.9':\n            self.wfile.write(\"%s: %s\\r\\n\" % (keyword, value))\n\n        if keyword.lower() == 'connection':\n            if value.lower() == 'close':\n                self.close_connection = 1\n            elif value.lower() == 'keep-alive':\n                self.close_connection = 0", "response": "Send a MIME header."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a unified diff of two strings.", "response": "def diff_texts(a, b, filename):\n    \"\"\"Return a unified diff of two strings.\"\"\"\n    a = a.splitlines()\n    b = b.splitlines()\n    return difflib.unified_diff(a, b, filename, filename,\n                                \"(original)\", \"(refactored)\",\n                                lineterm=\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an inputhook for running Qt5 application event loop.", "response": "def create_inputhook_qt5(mgr, app=None):\n    \"\"\"Create an input hook for running the Qt5 application event loop.\n\n    Parameters\n    ----------\n    mgr : an InputHookManager\n\n    app : Qt Application, optional.\n        Running application to use.  If not given, we probe Qt for an\n        existing application object, and create a new one if none is found.\n\n    Returns\n    -------\n    A pair consisting of a Qt Application (either the one given or the\n    one found or created) and a inputhook.\n\n    Notes\n    -----\n    We use a custom input hook instead of PyQt5's default one, as it\n    interacts better with the readline packages (issue #481).\n\n    The inputhook function works in tandem with a 'pre_prompt_hook'\n    which automatically restores the hook as an inputhook in case the\n    latter has been temporarily disabled after having intercepted a\n    KeyboardInterrupt.\n    \"\"\"\n\n    if app is None:\n        app = QtCore.QCoreApplication.instance()\n        if app is None:\n            from PyQt5 import QtWidgets\n            app = QtWidgets.QApplication([\" \"])\n\n    # Re-use previously created inputhook if any\n    ip = InteractiveShell.instance()\n    if hasattr(ip, '_inputhook_qt5'):\n        return app, ip._inputhook_qt5\n\n    # Otherwise create the inputhook_qt5/preprompthook_qt5 pair of\n    # hooks (they both share the got_kbdint flag)\n\n    def inputhook_qt5():\n        \"\"\"PyOS_InputHook python hook for Qt5.\n\n        Process pending Qt events and if there's no pending keyboard\n        input, spend a short slice of time (50ms) running the Qt event\n        loop.\n\n        As a Python ctypes callback can't raise an exception, we catch\n        the KeyboardInterrupt and temporarily deactivate the hook,\n        which will let a *second* CTRL+C be processed normally and go\n        back to a clean prompt line.\n        \"\"\"\n        try:\n            allow_CTRL_C()\n            app = QtCore.QCoreApplication.instance()\n            if not app: # shouldn't happen, but safer if it happens anyway...\n                return 0\n            app.processEvents(QtCore.QEventLoop.AllEvents, 300)\n            if not stdin_ready():\n                # Generally a program would run QCoreApplication::exec()\n                # from main() to enter and process the Qt event loop until\n                # quit() or exit() is called and the program terminates.\n                #\n                # For our input hook integration, we need to repeatedly\n                # enter and process the Qt event loop for only a short\n                # amount of time (say 50ms) to ensure that Python stays\n                # responsive to other user inputs.\n                #\n                # A naive approach would be to repeatedly call\n                # QCoreApplication::exec(), using a timer to quit after a\n                # short amount of time. Unfortunately, QCoreApplication\n                # emits an aboutToQuit signal before stopping, which has\n                # the undesirable effect of closing all modal windows.\n                #\n                # To work around this problem, we instead create a\n                # QEventLoop and call QEventLoop::exec(). Other than\n                # setting some state variables which do not seem to be\n                # used anywhere, the only thing QCoreApplication adds is\n                # the aboutToQuit signal which is precisely what we are\n                # trying to avoid.\n                timer = QtCore.QTimer()\n                event_loop = QtCore.QEventLoop()\n                timer.timeout.connect(event_loop.quit)\n                while not stdin_ready():\n                    timer.start(50)\n                    event_loop.exec_()\n                    timer.stop()\n        except KeyboardInterrupt:\n            global got_kbdint, sigint_timer\n\n            ignore_CTRL_C()\n            got_kbdint = True\n            mgr.clear_inputhook()\n\n            # This generates a second SIGINT so the user doesn't have to\n            # press CTRL+C twice to get a clean prompt.\n            #\n            # Since we can't catch the resulting KeyboardInterrupt here\n            # (because this is a ctypes callback), we use a timer to\n            # generate the SIGINT after we leave this callback.\n            #\n            # Unfortunately this doesn't work on Windows (SIGINT kills\n            # Python and CTRL_C_EVENT doesn't work).\n            if(os.name == 'posix'):\n                pid = os.getpid()\n                if(not sigint_timer):\n                    sigint_timer = threading.Timer(.01, os.kill,\n                                         args=[pid, signal.SIGINT] )\n                    sigint_timer.start()\n            else:\n                print(\"\\nKeyboardInterrupt - Ctrl-C again for new prompt\")\n\n\n        except: # NO exceptions are allowed to escape from a ctypes callback\n            ignore_CTRL_C()\n            from traceback import print_exc\n            print_exc()\n            print(\"Got exception from inputhook_qt5, unregistering.\")\n            mgr.clear_inputhook()\n        finally:\n            allow_CTRL_C()\n        return 0\n\n    def preprompthook_qt5(ishell):\n        \"\"\"'pre_prompt_hook' used to restore the Qt5 input hook\n\n        (in case the latter was temporarily deactivated after a\n        CTRL+C)\n        \"\"\"\n        global got_kbdint, sigint_timer\n\n        if(sigint_timer):\n            sigint_timer.cancel()\n            sigint_timer = None\n\n        if got_kbdint:\n            mgr.set_inputhook(inputhook_qt5)\n        got_kbdint = False\n\n    ip._inputhook_qt5 = inputhook_qt5\n    ip.set_hook('pre_prompt_hook', preprompthook_qt5)\n\n    return app, inputhook_qt5"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake a command (either a single command or list of arguments) and return the environment created after running that command. Note that if the command must be a batch file or .cmd file, or the changes to the environment will not be captured. If initial is supplied, it is used as the initial environment passed to the child process.", "response": "def get_environment_from_batch_command(env_cmd, initial=None):\n    \"\"\"\n    Take a command (either a single command or list of arguments)\n    and return the environment created after running that command.\n    Note that if the command must be a batch file or .cmd file, or the\n    changes to the environment will not be captured.\n\n    If initial is supplied, it is used as the initial environment passed\n    to the child process.\n    \"\"\"\n    if not isinstance(env_cmd, (list, tuple)):\n        env_cmd = [env_cmd]\n    if not os.path.exists(env_cmd[0]):\n        raise RuntimeError('Error: %s does not exist' % (env_cmd[0],))\n\n    # construct the command that will alter the environment\n    env_cmd = subprocess.list2cmdline(env_cmd)\n    # create a tag so we can tell in the output when the proc is done\n    tag = 'Done running command'\n    # construct a cmd.exe command to do accomplish this\n    cmd = 'cmd.exe /s /c \"{env_cmd} && echo \"{tag}\" && set\"'.format(**vars())\n    # launch the process\n    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, env=initial)\n    # parse the output sent to stdout\n    lines = proc.stdout\n    # consume whatever output occurs until the tag is reached\n    for line in lines:\n        line = line.decode('utf-8')\n        if 'The specified configuration type is missing.' in line:\n            raise AssertionError('Error executing %s. View http://blog.ionelmc.ro/2014/12/21/compiling-python-extensions-on-windows/ for details.' % (env_cmd))\n        if tag in line:\n            break\n    if sys.version_info[0] > 2:\n        # define a way to handle each KEY=VALUE line\n        handle_line = lambda l: l.decode('utf-8').rstrip().split('=', 1)\n    else:\n        # define a way to handle each KEY=VALUE line\n        handle_line = lambda l: l.rstrip().split('=', 1)\n    # parse key/values into pairs\n    pairs = map(handle_line, lines)\n    # make sure the pairs are valid\n    valid_pairs = filter(validate_pair, pairs)\n    # construct a dictionary of the pairs\n    result = dict(valid_pairs)\n    # let the process finish\n    proc.communicate()\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninstancing a new structure from a Python native type.", "response": "def from_dict(cls, ctx):\n        'Instance a new structure from a Python native type.'\n        ctx = Context(ctx)\n        s = cls()\n        ContextFlags = ctx['ContextFlags']\n        s.ContextFlags = ContextFlags\n        for key in cls._others:\n            if key != 'VectorRegister':\n                setattr(s, key, ctx[key])\n            else:\n                w = ctx[key]\n                v = (M128A * len(w))()\n                i = 0\n                for x in w:\n                    y = M128A()\n                    y.High = x >> 64\n                    y.Low = x - (x >> 64)\n                    v[i] = y\n                    i += 1\n                setattr(s, key, v)\n        if (ContextFlags & CONTEXT_CONTROL) == CONTEXT_CONTROL:\n            for key in cls._control:\n                setattr(s, key, ctx[key])\n        if (ContextFlags & CONTEXT_INTEGER) == CONTEXT_INTEGER:\n            for key in cls._integer:\n                setattr(s, key, ctx[key])\n        if (ContextFlags & CONTEXT_SEGMENTS) == CONTEXT_SEGMENTS:\n            for key in cls._segments:\n                setattr(s, key, ctx[key])\n        if (ContextFlags & CONTEXT_DEBUG_REGISTERS) == CONTEXT_DEBUG_REGISTERS:\n            for key in cls._debug:\n                setattr(s, key, ctx[key])\n        if (ContextFlags & CONTEXT_MMX_REGISTERS) == CONTEXT_MMX_REGISTERS:\n            xmm = s.FltSave.xmm\n            for key in cls._mmx:\n                y = M128A()\n                y.High = x >> 64\n                y.Low = x - (x >> 64)\n                setattr(xmm, key, y)\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a structure into a Python dictionary.", "response": "def to_dict(self):\n        'Convert a structure into a Python dictionary.'\n        ctx = Context()\n        ContextFlags = self.ContextFlags\n        ctx['ContextFlags'] = ContextFlags\n        for key in self._others:\n            if key != 'VectorRegister':\n                ctx[key] = getattr(self, key)\n            else:\n                ctx[key] = tuple([ (x.Low + (x.High << 64)) for x in getattr(self, key) ])\n        if (ContextFlags & CONTEXT_CONTROL) == CONTEXT_CONTROL:\n            for key in self._control:\n                ctx[key] = getattr(self, key)\n        if (ContextFlags & CONTEXT_INTEGER) == CONTEXT_INTEGER:\n            for key in self._integer:\n                ctx[key] = getattr(self, key)\n        if (ContextFlags & CONTEXT_SEGMENTS) == CONTEXT_SEGMENTS:\n            for key in self._segments:\n                ctx[key] = getattr(self, key)\n        if (ContextFlags & CONTEXT_DEBUG_REGISTERS) == CONTEXT_DEBUG_REGISTERS:\n            for key in self._debug:\n                ctx[key] = getattr(self, key)\n        if (ContextFlags & CONTEXT_MMX_REGISTERS) == CONTEXT_MMX_REGISTERS:\n            xmm = self.FltSave.xmm.to_dict()\n            for key in self._mmx:\n                ctx[key] = xmm.get(key)\n        return ctx"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_exit(*args):\n    '''\n        We have to override the exit because calling sys.exit will only actually exit the main thread,\n        and as we're in a Xml-rpc server, that won't work.\n    '''\n\n    try:\n        import java.lang.System\n\n        java.lang.System.exit(1)\n    except ImportError:\n        if len(args) == 1:\n            os._exit(args[0])\n        else:\n            os._exit(0)", "response": "Override the exit method to override sys. exit to exit the main thread."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef console_exec(thread_id, frame_id, expression, dbg):\n    frame = dbg.find_frame(thread_id, frame_id)\n\n    is_multiline = expression.count('@LINE@') > 1\n    expression = str(expression.replace('@LINE@', '\\n'))\n\n    # Not using frame.f_globals because of https://sourceforge.net/tracker2/?func=detail&aid=2541355&group_id=85796&atid=577329\n    # (Names not resolved in generator expression in method)\n    # See message: http://mail.python.org/pipermail/python-list/2009-January/526522.html\n    updated_globals = {}\n    updated_globals.update(frame.f_globals)\n    updated_globals.update(frame.f_locals)  # locals later because it has precedence over the actual globals\n\n    if IPYTHON:\n        need_more = exec_code(CodeFragment(expression), updated_globals, frame.f_locals, dbg)\n        if not need_more:\n            pydevd_save_locals.save_locals(frame)\n        return need_more\n\n    interpreter = ConsoleWriter()\n\n    if not is_multiline:\n        try:\n            code = compile_command(expression)\n        except (OverflowError, SyntaxError, ValueError):\n            # Case 1\n            interpreter.showsyntaxerror()\n            return False\n        if code is None:\n            # Case 2\n            return True\n    else:\n        code = expression\n\n    # Case 3\n\n    try:\n        Exec(code, updated_globals, frame.f_locals)\n\n    except SystemExit:\n        raise\n    except:\n        interpreter.showtraceback()\n    else:\n        pydevd_save_locals.save_locals(frame)\n    return False", "response": "returns True if expression is partially correct\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndisplay the syntax error that just occurred.", "response": "def showsyntaxerror(self, filename=None):\n        \"\"\"Display the syntax error that just occurred.\"\"\"\n        # Override for avoid using sys.excepthook PY-12600\n        type, value, tb = sys.exc_info()\n        sys.last_type = type\n        sys.last_value = value\n        sys.last_traceback = tb\n        if filename and type is SyntaxError:\n            # Work hard to stuff the correct filename in the exception\n            try:\n                msg, (dummy_filename, lineno, offset, line) = value.args\n            except ValueError:\n                # Not the format we expect; leave it alone\n                pass\n            else:\n                # Stuff in the right filename\n                value = SyntaxError(msg, (filename, lineno, offset, line))\n                sys.last_value = value\n        list = traceback.format_exception_only(type, value)\n        sys.stderr.write(''.join(list))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef showtraceback(self, *args, **kwargs):\n        # Override for avoid using sys.excepthook PY-12600\n        try:\n            type, value, tb = sys.exc_info()\n            sys.last_type = type\n            sys.last_value = value\n            sys.last_traceback = tb\n            tblist = traceback.extract_tb(tb)\n            del tblist[:1]\n            lines = traceback.format_list(tblist)\n            if lines:\n                lines.insert(0, \"Traceback (most recent call last):\\n\")\n            lines.extend(traceback.format_exception_only(type, value))\n        finally:\n            tblist = tb = None\n        sys.stderr.write(''.join(lines))", "response": "Display the exception that just occurred."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef split_extension(pathname):\n        filepart = win32.PathRemoveExtension(pathname)\n        extpart  = win32.PathFindExtension(pathname)\n        return (filepart, extpart)", "response": "Split the file and extension of the filename."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef split_filename(pathname):\n        filepart = win32.PathFindFileName(pathname)\n        pathpart = win32.PathRemoveFileSpec(pathname)\n        return (pathpart, filepart)", "response": "Split the filename into the base filename and the path to the file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef split_path(path):\n        components = list()\n        while path:\n            next = win32.PathFindNextComponent(path)\n            if next:\n                prev = path[ : -len(next) ]\n                components.append(prev)\n            path = next\n        return components", "response": "Split a path into a list of path components."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef native_to_win32_pathname(name):\n        # XXX TODO\n        # There are probably some native paths that\n        # won't be converted by this naive approach.\n        if name.startswith(compat.b(\"\\\\\")):\n            if name.startswith(compat.b(\"\\\\??\\\\\")):\n                name = name[4:]\n            elif name.startswith(compat.b(\"\\\\SystemRoot\\\\\")):\n                system_root_path = os.environ['SYSTEMROOT']\n                if system_root_path.endswith('\\\\'):\n                    system_root_path = system_root_path[:-1]\n                name = system_root_path + name[11:]\n            else:\n                for drive_number in compat.xrange(ord('A'), ord('Z') + 1):\n                    drive_letter = '%c:' % drive_number\n                    try:\n                        device_native_path = win32.QueryDosDevice(drive_letter)\n                    except WindowsError:\n                        e = sys.exc_info()[1]\n                        if e.winerror in (win32.ERROR_FILE_NOT_FOUND, \\\n                                                 win32.ERROR_PATH_NOT_FOUND):\n                            continue\n                        raise\n                    if not device_native_path.endswith(compat.b('\\\\')):\n                        device_native_path += compat.b('\\\\')\n                    if name.startswith(device_native_path):\n                        name = drive_letter + compat.b('\\\\') + \\\n                                              name[ len(device_native_path) : ]\n                        break\n        return name", "response": "Convert native pathname to Win32 absolute pathname."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntry to get the pageSize value on runtime.", "response": "def pageSize(cls):\n        \"\"\"\n        Try to get the pageSize value on runtime.\n        \"\"\"\n        try:\n            try:\n                pageSize = win32.GetSystemInfo().dwPageSize\n            except WindowsError:\n                pageSize = 0x1000\n        except NameError:\n            pageSize = 0x1000\n        cls.pageSize = pageSize     # now this function won't be called again\n        return pageSize"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef align_address_range(cls, begin, end):\n        if begin is None:\n            begin = 0\n        if end is None:\n            end = win32.LPVOID(-1).value  # XXX HACK\n        if end < begin:\n            begin, end = end, begin\n        begin = cls.align_address_to_page_start(begin)\n        if end != cls.align_address_to_page_start(end):\n            end = cls.align_address_to_page_end(end)\n        return (begin, end)", "response": "Align the given address range to the start and end of the page ( s ) it occupies."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_buffer_size_in_pages(cls, address, size):\n        if size < 0:\n            size    = -size\n            address = address - size\n        begin, end = cls.align_address_range(address, address + size)\n        # XXX FIXME\n        # I think this rounding fails at least for address 0xFFFFFFFF size 1\n        return int(float(end - begin) / float(cls.pageSize))", "response": "Get the number of pages in use by the given buffer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetermine if two memory address ranges intersect.", "response": "def do_ranges_intersect(begin, end, old_begin, old_end):\n        \"\"\"\n        Determine if the two given memory address ranges intersect.\n\n        @type  begin: int\n        @param begin: Start address of the first range.\n\n        @type  end: int\n        @param end: End address of the first range.\n\n        @type  old_begin: int\n        @param old_begin: Start address of the second range.\n\n        @type  old_end: int\n        @param old_end: End address of the second range.\n\n        @rtype:  bool\n        @return: C{True} if the two ranges intersect, C{False} otherwise.\n        \"\"\"\n        return  (old_begin <= begin < old_end) or \\\n                (old_begin < end <= old_end)   or \\\n                (begin <= old_begin < end)     or \\\n                (begin < old_end <= end)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear_bp(cls, ctx, register):\n        ctx['Dr7'] &= cls.clearMask[register]\n        ctx['Dr%d' % register] = 0", "response": "Clears a hardware breakpoint."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_bp(cls, ctx, register, address, trigger, watch):\n        Dr7 = ctx['Dr7']\n        Dr7 |= cls.enableMask[register]\n        orMask, andMask = cls.triggerMask[register][trigger]\n        Dr7 &= andMask\n        Dr7 |= orMask\n        orMask, andMask = cls.watchMask[register][watch]\n        Dr7 &= andMask\n        Dr7 |= orMask\n        ctx['Dr7'] = Dr7\n        ctx['Dr%d' % register] = address", "response": "Sets a hardware breakpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_slot(cls, ctx):\n        Dr7  = ctx['Dr7']\n        slot = 0\n        for m in cls.enableMask:\n            if (Dr7 & m) == 0:\n                return slot\n            slot += 1\n        return None", "response": "Find an empty slot to set a hardware breakpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads the grammar tables from the text files written by pgen.", "response": "def run(self, graminit_h, graminit_c):\n        \"\"\"Load the grammar tables from the text files written by pgen.\"\"\"\n        self.parse_graminit_h(graminit_h)\n        self.parse_graminit_c(graminit_c)\n        self.finish_off()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the. h file written by pgen.", "response": "def parse_graminit_h(self, filename):\n        \"\"\"Parse the .h file written by pgen.  (Internal)\n\n        This file is a sequence of #define statements defining the\n        nonterminals of the grammar as numbers.  We build two tables\n        mapping the numbers to names and back.\n\n        \"\"\"\n        try:\n            f = open(filename)\n        except IOError, err:\n            print \"Can't open %s: %s\" % (filename, err)\n            return False\n        self.symbol2number = {}\n        self.number2symbol = {}\n        lineno = 0\n        for line in f:\n            lineno += 1\n            mo = re.match(r\"^#define\\s+(\\w+)\\s+(\\d+)$\", line)\n            if not mo and line.strip():\n                print \"%s(%s): can't parse %s\" % (filename, lineno,\n                                                  line.strip())\n            else:\n                symbol, number = mo.groups()\n                number = int(number)\n                assert symbol not in self.symbol2number\n                assert number not in self.number2symbol\n                self.symbol2number[symbol] = number\n                self.number2symbol[number] = symbol\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the. c file written by pgen.", "response": "def parse_graminit_c(self, filename):\n        \"\"\"Parse the .c file written by pgen.  (Internal)\n\n        The file looks as follows.  The first two lines are always this:\n\n        #include \"pgenheaders.h\"\n        #include \"grammar.h\"\n\n        After that come four blocks:\n\n        1) one or more state definitions\n        2) a table defining dfas\n        3) a table defining labels\n        4) a struct defining the grammar\n\n        A state definition has the following form:\n        - one or more arc arrays, each of the form:\n          static arc arcs_<n>_<m>[<k>] = {\n                  {<i>, <j>},\n                  ...\n          };\n        - followed by a state array, of the form:\n          static state states_<s>[<t>] = {\n                  {<k>, arcs_<n>_<m>},\n                  ...\n          };\n\n        \"\"\"\n        try:\n            f = open(filename)\n        except IOError, err:\n            print \"Can't open %s: %s\" % (filename, err)\n            return False\n        # The code below essentially uses f's iterator-ness!\n        lineno = 0\n\n        # Expect the two #include lines\n        lineno, line = lineno+1, f.next()\n        assert line == '#include \"pgenheaders.h\"\\n', (lineno, line)\n        lineno, line = lineno+1, f.next()\n        assert line == '#include \"grammar.h\"\\n', (lineno, line)\n\n        # Parse the state definitions\n        lineno, line = lineno+1, f.next()\n        allarcs = {}\n        states = []\n        while line.startswith(\"static arc \"):\n            while line.startswith(\"static arc \"):\n                mo = re.match(r\"static arc arcs_(\\d+)_(\\d+)\\[(\\d+)\\] = {$\",\n                              line)\n                assert mo, (lineno, line)\n                n, m, k = map(int, mo.groups())\n                arcs = []\n                for _ in range(k):\n                    lineno, line = lineno+1, f.next()\n                    mo = re.match(r\"\\s+{(\\d+), (\\d+)},$\", line)\n                    assert mo, (lineno, line)\n                    i, j = map(int, mo.groups())\n                    arcs.append((i, j))\n                lineno, line = lineno+1, f.next()\n                assert line == \"};\\n\", (lineno, line)\n                allarcs[(n, m)] = arcs\n                lineno, line = lineno+1, f.next()\n            mo = re.match(r\"static state states_(\\d+)\\[(\\d+)\\] = {$\", line)\n            assert mo, (lineno, line)\n            s, t = map(int, mo.groups())\n            assert s == len(states), (lineno, line)\n            state = []\n            for _ in range(t):\n                lineno, line = lineno+1, f.next()\n                mo = re.match(r\"\\s+{(\\d+), arcs_(\\d+)_(\\d+)},$\", line)\n                assert mo, (lineno, line)\n                k, n, m = map(int, mo.groups())\n                arcs = allarcs[n, m]\n                assert k == len(arcs), (lineno, line)\n                state.append(arcs)\n            states.append(state)\n            lineno, line = lineno+1, f.next()\n            assert line == \"};\\n\", (lineno, line)\n            lineno, line = lineno+1, f.next()\n        self.states = states\n\n        # Parse the dfas\n        dfas = {}\n        mo = re.match(r\"static dfa dfas\\[(\\d+)\\] = {$\", line)\n        assert mo, (lineno, line)\n        ndfas = int(mo.group(1))\n        for i in range(ndfas):\n            lineno, line = lineno+1, f.next()\n            mo = re.match(r'\\s+{(\\d+), \"(\\w+)\", (\\d+), (\\d+), states_(\\d+),$',\n                          line)\n            assert mo, (lineno, line)\n            symbol = mo.group(2)\n            number, x, y, z = map(int, mo.group(1, 3, 4, 5))\n            assert self.symbol2number[symbol] == number, (lineno, line)\n            assert self.number2symbol[number] == symbol, (lineno, line)\n            assert x == 0, (lineno, line)\n            state = states[z]\n            assert y == len(state), (lineno, line)\n            lineno, line = lineno+1, f.next()\n            mo = re.match(r'\\s+(\"(?:\\\\\\d\\d\\d)*\")},$', line)\n            assert mo, (lineno, line)\n            first = {}\n            rawbitset = eval(mo.group(1))\n            for i, c in enumerate(rawbitset):\n                byte = ord(c)\n                for j in range(8):\n                    if byte & (1<<j):\n                        first[i*8 + j] = 1\n            dfas[number] = (state, first)\n        lineno, line = lineno+1, f.next()\n        assert line == \"};\\n\", (lineno, line)\n        self.dfas = dfas\n\n        # Parse the labels\n        labels = []\n        lineno, line = lineno+1, f.next()\n        mo = re.match(r\"static label labels\\[(\\d+)\\] = {$\", line)\n        assert mo, (lineno, line)\n        nlabels = int(mo.group(1))\n        for i in range(nlabels):\n            lineno, line = lineno+1, f.next()\n            mo = re.match(r'\\s+{(\\d+), (0|\"\\w+\")},$', line)\n            assert mo, (lineno, line)\n            x, y = mo.groups()\n            x = int(x)\n            if y == \"0\":\n                y = None\n            else:\n                y = eval(y)\n            labels.append((x, y))\n        lineno, line = lineno+1, f.next()\n        assert line == \"};\\n\", (lineno, line)\n        self.labels = labels\n\n        # Parse the grammar struct\n        lineno, line = lineno+1, f.next()\n        assert line == \"grammar _PyParser_Grammar = {\\n\", (lineno, line)\n        lineno, line = lineno+1, f.next()\n        mo = re.match(r\"\\s+(\\d+),$\", line)\n        assert mo, (lineno, line)\n        ndfas = int(mo.group(1))\n        assert ndfas == len(self.dfas)\n        lineno, line = lineno+1, f.next()\n        assert line == \"\\tdfas,\\n\", (lineno, line)\n        lineno, line = lineno+1, f.next()\n        mo = re.match(r\"\\s+{(\\d+), labels},$\", line)\n        assert mo, (lineno, line)\n        nlabels = int(mo.group(1))\n        assert nlabels == len(self.labels), (lineno, line)\n        lineno, line = lineno+1, f.next()\n        mo = re.match(r\"\\s+(\\d+)$\", line)\n        assert mo, (lineno, line)\n        start = int(mo.group(1))\n        assert start in self.number2symbol, (lineno, line)\n        self.start = start\n        lineno, line = lineno+1, f.next()\n        assert line == \"};\\n\", (lineno, line)\n        try:\n            lineno, line = lineno+1, f.next()\n        except StopIteration:\n            pass\n        else:\n            assert 0, (lineno, line)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef finish_off(self):\n        self.keywords = {} # map from keyword strings to arc labels\n        self.tokens = {}   # map from numeric token values to arc labels\n        for ilabel, (type, value) in enumerate(self.labels):\n            if type == token.NAME and value is not None:\n                self.keywords[value] = ilabel\n            elif value is None:\n                self.tokens[type] = ilabel", "response": "Create additional useful structures. ( Internal )."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_ide_os(os):\n    '''\n    We need to set the IDE os because the host where the code is running may be\n    actually different from the client (and the point is that we want the proper\n    paths to translate from the client to the server).\n\n    :param os:\n        'UNIX' or 'WINDOWS'\n    '''\n    global _ide_os\n    global _normcase_from_client\n    prev = _ide_os\n    if os == 'WIN':  # Apparently PyCharm uses 'WIN' (https://github.com/fabioz/PyDev.Debugger/issues/116)\n        os = 'WINDOWS'\n\n    assert os in ('WINDOWS', 'UNIX')\n\n    if DEBUG_CLIENT_SERVER_TRANSLATION:\n        print('pydev debugger: client OS: %s' % (os,))\n\n    _normcase_from_client = normcase\n    if os == 'WINDOWS':\n\n        # Client in Windows and server in Unix, we need to normalize the case.\n        if not IS_WINDOWS:\n            _normcase_from_client = _normcase_windows\n\n    else:\n        # Client in Unix and server in Windows, we can't normalize the case.\n        if IS_WINDOWS:\n            _normcase_from_client = _normcase_linux\n\n    if prev != os:\n        _ide_os = os\n        # We need to (re)setup how the client <-> server translation works to provide proper separators.\n        setup_client_server_paths(_last_client_server_paths_set)", "response": "Set the IDE os."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setup_client_server_paths(paths):\n    '''paths is the same format as PATHS_FROM_ECLIPSE_TO_PYTHON'''\n\n    global norm_file_to_client\n    global norm_file_to_server\n    global _last_client_server_paths_set\n    global _next_source_reference\n\n    _last_client_server_paths_set = paths[:]\n\n    _source_reference_to_server_filename.clear()\n    _client_filename_in_utf8_to_source_reference.clear()\n    _next_source_reference = partial(next, itertools.count(1))\n\n    # Work on the client and server slashes.\n    python_sep = '\\\\' if IS_WINDOWS else '/'\n    eclipse_sep = '\\\\' if _ide_os == 'WINDOWS' else '/'\n\n    norm_filename_to_server_container = {}\n    norm_filename_to_client_container = {}\n    initial_paths = list(paths)\n    paths_from_eclipse_to_python = initial_paths[:]\n\n    # Apply normcase to the existing paths to follow the os preferences.\n\n    for i, (path0, path1) in enumerate(paths_from_eclipse_to_python[:]):\n        if IS_PY2:\n            if isinstance(path0, unicode):  # noqa\n                path0 = path0.encode(sys.getfilesystemencoding())\n            if isinstance(path1, unicode):  # noqa\n                path1 = path1.encode(sys.getfilesystemencoding())\n\n        path0 = _fix_path(path0, eclipse_sep)\n        path1 = _fix_path(path1, python_sep)\n        initial_paths[i] = (path0, path1)\n\n        paths_from_eclipse_to_python[i] = (_normcase_from_client(path0), normcase(path1))\n\n    if not paths_from_eclipse_to_python:\n        # no translation step needed (just inline the calls)\n        norm_file_to_client = _original_file_to_client\n        norm_file_to_server = _original_file_to_server\n        return\n\n    # only setup translation functions if absolutely needed!\n    def _norm_file_to_server(filename, cache=norm_filename_to_server_container):\n        # Eclipse will send the passed filename to be translated to the python process\n        # So, this would be 'NormFileFromEclipseToPython'\n        try:\n            return cache[filename]\n        except KeyError:\n            if eclipse_sep != python_sep:\n                # Make sure that the separators are what we expect from the IDE.\n                filename = filename.replace(python_sep, eclipse_sep)\n\n            # used to translate a path from the client to the debug server\n            translated = filename\n            translated_normalized = _normcase_from_client(filename)\n            for eclipse_prefix, server_prefix in paths_from_eclipse_to_python:\n                if translated_normalized.startswith(eclipse_prefix):\n                    found_translation = True\n                    if DEBUG_CLIENT_SERVER_TRANSLATION:\n                        sys.stderr.write('pydev debugger: replacing to server: %s\\n' % (filename,))\n                    translated = server_prefix + filename[len(eclipse_prefix):]\n                    if DEBUG_CLIENT_SERVER_TRANSLATION:\n                        sys.stderr.write('pydev debugger: sent to server: %s\\n' % (translated,))\n                    break\n            else:\n                found_translation = False\n\n            # Note that when going to the server, we do the replace first and only later do the norm file.\n            if eclipse_sep != python_sep:\n                translated = translated.replace(eclipse_sep, python_sep)\n\n            if found_translation:\n                translated = _NormFile(translated)\n            else:\n                if not os.path.exists(translated):\n                    if not translated.startswith('<'):\n                        # This is a configuration error, so, write it always so\n                        # that the user can fix it.\n                        error_once('pydev debugger: unable to find translation for: \"%s\" in [%s] (please revise your path mappings).\\n' %\n                            (filename, ', '.join(['\"%s\"' % (x[0],) for x in paths_from_eclipse_to_python])))\n                else:\n                    # It's possible that we had some round trip (say, we sent /usr/lib and received\n                    # it back, so, having no translation is ok too).\n                    translated = _NormFile(translated)\n\n            cache[filename] = translated\n            return translated\n\n    def _norm_file_to_client(filename, cache=norm_filename_to_client_container):\n        # The result of this method will be passed to eclipse\n        # So, this would be 'NormFileFromPythonToEclipse'\n        try:\n            return cache[filename]\n        except KeyError:\n            # used to translate a path from the debug server to the client\n            translated = _NormFile(filename)\n\n            # After getting the real path, let's get it with the path with\n            # the real case and then obtain a new normalized copy, just in case\n            # the path is different now.\n            translated_proper_case = get_path_with_real_case(translated)\n            translated = _NormFile(translated_proper_case)\n\n            path_mapping_applied = False\n\n            if IS_WINDOWS:\n                if translated.lower() != translated_proper_case.lower():\n                    translated_proper_case = translated\n                    if DEBUG_CLIENT_SERVER_TRANSLATION:\n                        sys.stderr.write(\n                            'pydev debugger: _NormFile changed path (from: %s to %s)\\n' % (\n                                translated_proper_case, translated))\n\n            for i, (eclipse_prefix, python_prefix) in enumerate(paths_from_eclipse_to_python):\n                if translated.startswith(python_prefix):\n                    if DEBUG_CLIENT_SERVER_TRANSLATION:\n                        sys.stderr.write('pydev debugger: replacing to client: %s\\n' % (translated,))\n\n                    # Note: use the non-normalized version.\n                    eclipse_prefix = initial_paths[i][0]\n                    translated = eclipse_prefix + translated_proper_case[len(python_prefix):]\n                    if DEBUG_CLIENT_SERVER_TRANSLATION:\n                        sys.stderr.write('pydev debugger: sent to client: %s\\n' % (translated,))\n                    path_mapping_applied = True\n                    break\n            else:\n                if DEBUG_CLIENT_SERVER_TRANSLATION:\n                    sys.stderr.write('pydev debugger: to client: unable to find matching prefix for: %s in %s\\n' % \\\n                        (translated, [x[1] for x in paths_from_eclipse_to_python]))\n                    translated = translated_proper_case\n\n            if eclipse_sep != python_sep:\n                translated = translated.replace(python_sep, eclipse_sep)\n\n            translated = _path_to_expected_str(translated)\n\n            # The resulting path is not in the python process, so, we cannot do a _NormFile here,\n            # only at the beginning of this method.\n            cache[filename] = translated\n\n            if translated not in _client_filename_in_utf8_to_source_reference:\n                if path_mapping_applied:\n                    source_reference = 0\n                else:\n                    source_reference = _next_source_reference()\n                _client_filename_in_utf8_to_source_reference[translated] = source_reference\n                _source_reference_to_server_filename[source_reference] = filename\n\n            return translated\n\n    norm_file_to_server = _norm_file_to_server\n    norm_file_to_client = _norm_file_to_client", "response": "Setups the client and server paths for the current project."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\niterate over all Python source files defined in paths.", "response": "def iter_source_code(paths, config, skipped):\n    \"\"\"Iterate over all Python source files defined in paths.\"\"\"\n    for path in paths:\n        if os.path.isdir(path):\n            if should_skip(path, config, os.getcwd()):\n                skipped.append(path)\n                continue\n\n            for dirpath, dirnames, filenames in os.walk(path, topdown=True):\n                for dirname in list(dirnames):\n                    if should_skip(dirname, config, dirpath):\n                        skipped.append(dirname)\n                        dirnames.remove(dirname)\n                for filename in filenames:\n                    if filename.endswith('.py'):\n                        if should_skip(filename, config, dirpath):\n                            skipped.append(filename)\n                        else:\n                            yield os.path.join(dirpath, filename)\n        else:\n            yield path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef complete_from_dir(directory):\n    '''\n    This is necessary so that we get the imports from the same directory where the file\n    we are completing is located.\n    '''\n    global currDirModule\n    if currDirModule is not None:\n        if len(sys.path) > 0 and sys.path[0] == currDirModule:\n            del sys.path[0]\n\n    currDirModule = directory\n    sys.path.insert(0, directory)", "response": "This function is used to complete the current directory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef change_python_path(pythonpath):\n    '''Changes the pythonpath (clears all the previous pythonpath)\n\n    @param pythonpath: string with paths separated by |\n    '''\n\n    split = pythonpath.split('|')\n    sys.path = []\n    for path in split:\n        path = path.strip()\n        if len(path) > 0:\n            sys.path.append(path)", "response": "Changes the pythonpath (clears all the previous pythonpath)\n\n    @param pythonpath: string with paths separated by |"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef format_completion_message(self, defFile, completionsList):\n        '''\n        Format the completions suggestions in the following format:\n        @@COMPLETIONS(modFile(token,description),(token,description),(token,description))END@@\n        '''\n        compMsg = []\n        compMsg.append('%s' % defFile)\n        for tup in completionsList:\n            compMsg.append(',')\n\n            compMsg.append('(')\n            compMsg.append(str(self.remove_invalid_chars(tup[0])))  # token\n            compMsg.append(',')\n            compMsg.append(self.remove_invalid_chars(tup[1]))  # description\n\n            if(len(tup) > 2):\n                compMsg.append(',')\n                compMsg.append(self.remove_invalid_chars(tup[2]))  # args - only if function.\n\n            if(len(tup) > 3):\n                compMsg.append(',')\n                compMsg.append(self.remove_invalid_chars(tup[3]))  # TYPE\n\n            compMsg.append(')')\n\n        return '%s(%s)%s' % (MSG_COMPLETIONS, ''.join(compMsg), MSG_END)", "response": "Format the completion message for the given file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_token_and_data(self, data):\n        '''\n        When we receive this, we have 'token):data'\n        '''\n        token = ''\n        for c in data:\n            if c != ')':\n                token = token + c\n            else:\n                break;\n\n        return token, data.lstrip(token + '):')", "response": "Get the token and data from the data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling one request possibly blocking.", "response": "def handle_request(self):\n        \"\"\"Handle one request, possibly blocking.\n\n        Respects self.timeout.\n        \"\"\"\n        # Support people who used socket.settimeout() to escape\n        # handle_request before self.timeout was available.\n        timeout = self.socket.gettimeout()\n        if timeout is None:\n            timeout = self.timeout\n        elif self.timeout is not None:\n            timeout = min(timeout, self.timeout)\n        fd_sets = select.select([self], [], [], timeout)\n        if not fd_sets[0]:\n            self.handle_timeout()\n            return\n        self._handle_request_noblock()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle an error gracefully.", "response": "def handle_error(self, request, client_address):\n        \"\"\"Handle an error gracefully.  May be overridden.\n\n        The default is to print a traceback and continue.\n\n        \"\"\"\n        print '-'*40\n        print 'Exception happened during processing of request from',\n        print client_address\n        import traceback\n        traceback.print_exc() # XXX But this goes to stderr!\n        print '-'*40"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef collect_children(self):\n        if self.active_children is None: return\n        while len(self.active_children) >= self.max_children:\n            # XXX: This will wait for any child process, not just ones\n            # spawned by this library. This could confuse other\n            # libraries that expect to be able to wait for their own\n            # children.\n            try:\n                pid, status = os.waitpid(0, 0)\n            except os.error:\n                pid = None\n            if pid not in self.active_children: continue\n            self.active_children.remove(pid)\n\n        # XXX: This loop runs more system calls than it ought\n        # to. There should be a way to put the active_children into a\n        # process group and then use os.waitpid(-pgid) to wait for any\n        # of that set, but I couldn't find a way to allocate pgids\n        # that couldn't collide.\n        for child in self.active_children:\n            try:\n                pid, status = os.waitpid(child, os.WNOHANG)  # @UndefinedVariable\n            except os.error:\n                pid = None\n            if not pid: continue\n            try:\n                self.active_children.remove(pid)\n            except ValueError, e:\n                raise ValueError('%s. x=%d and list=%r' % (e.message, pid,\n                                                           self.active_children))", "response": "Internal routine to wait for children that have exited."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_request(self, request, client_address):\n        self.collect_children()\n        pid = os.fork()  # @UndefinedVariable\n        if pid:\n            # Parent process\n            if self.active_children is None:\n                self.active_children = []\n            self.active_children.append(pid)\n            self.close_request(request) #close handle in parent process\n            return\n        else:\n            # Child process.\n            # This must never return, hence os._exit()!\n            try:\n                self.finish_request(request, client_address)\n                self.shutdown_request(request)\n                os._exit(0)\n            except:\n                try:\n                    self.handle_error(request, client_address)\n                    self.shutdown_request(request)\n                finally:\n                    os._exit(1)", "response": "Fork a new process to process the request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_request_thread(self, request, client_address):\n        try:\n            self.finish_request(request, client_address)\n            self.shutdown_request(request)\n        except:\n            self.handle_error(request, client_address)\n            self.shutdown_request(request)", "response": "This method is called by the thread that processes the request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of acceptable QT APIs in decreasing order of preference", "response": "def get_options():\n    \"\"\"Return a list of acceptable QT APIs, in decreasing order of\n    preference\n    \"\"\"\n    #already imported Qt somewhere. Use that\n    loaded = loaded_api()\n    if loaded is not None:\n        return [loaded]\n\n    mpl = sys.modules.get('matplotlib', None)\n\n    if mpl is not None and not check_version(mpl.__version__, '1.0.2'):\n        #1.0.1 only supports PyQt4 v1\n        return [QT_API_PYQT_DEFAULT]\n\n    if os.environ.get('QT_API', None) is None:\n        #no ETS variable. Ask mpl, then use either\n        return matplotlib_options(mpl) or [QT_API_PYQT_DEFAULT, QT_API_PYSIDE, QT_API_PYQT5]\n\n    #ETS variable present. Will fallback to external.qt\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tabs_or_spaces(physical_line, indent_char):\n    indent = INDENT_REGEX.match(physical_line).group(1)\n    for offset, char in enumerate(indent):\n        if char != indent_char:\n            return offset, \"E101 indentation contains mixed spaces and tabs\"", "response": "Never mix tabs and spaces."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef trailing_whitespace(physical_line):\n    physical_line = physical_line.rstrip('\\n')    # chr(10), newline\n    physical_line = physical_line.rstrip('\\r')    # chr(13), carriage return\n    physical_line = physical_line.rstrip('\\x0c')  # chr(12), form feed, ^L\n    stripped = physical_line.rstrip(' \\t\\v')\n    if physical_line != stripped:\n        if stripped:\n            return len(stripped), \"W291 trailing whitespace\"\n        else:\n            return 0, \"W293 blank line contains whitespace\"", "response": "r Trailing whitespace is superfluous."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef blank_lines(logical_line, blank_lines, indent_level, line_number,\n                blank_before, previous_logical,\n                previous_unindented_logical_line, previous_indent_level,\n                lines):\n    r\"\"\"Separate top-level function and class definitions with two blank lines.\n\n    Method definitions inside a class are separated by a single blank line.\n\n    Extra blank lines may be used (sparingly) to separate groups of related\n    functions.  Blank lines may be omitted between a bunch of related\n    one-liners (e.g. a set of dummy implementations).\n\n    Use blank lines in functions, sparingly, to indicate logical sections.\n\n    Okay: def a():\\n    pass\\n\\n\\ndef b():\\n    pass\n    Okay: def a():\\n    pass\\n\\n\\nasync def b():\\n    pass\n    Okay: def a():\\n    pass\\n\\n\\n# Foo\\n# Bar\\n\\ndef b():\\n    pass\n    Okay: default = 1\\nfoo = 1\n    Okay: classify = 1\\nfoo = 1\n\n    E301: class Foo:\\n    b = 0\\n    def bar():\\n        pass\n    E302: def a():\\n    pass\\n\\ndef b(n):\\n    pass\n    E302: def a():\\n    pass\\n\\nasync def b(n):\\n    pass\n    E303: def a():\\n    pass\\n\\n\\n\\ndef b(n):\\n    pass\n    E303: def a():\\n\\n\\n\\n    pass\n    E304: @decorator\\n\\ndef a():\\n    pass\n    E305: def a():\\n    pass\\na()\n    E306: def a():\\n    def b():\\n        pass\\n    def c():\\n        pass\n    \"\"\"\n    if line_number < 3 and not previous_logical:\n        return  # Don't expect blank lines before the first line\n    if previous_logical.startswith('@'):\n        if blank_lines:\n            yield 0, \"E304 blank lines found after function decorator\"\n    elif blank_lines > 2 or (indent_level and blank_lines == 2):\n        yield 0, \"E303 too many blank lines (%d)\" % blank_lines\n    elif STARTSWITH_TOP_LEVEL_REGEX.match(logical_line):\n        if indent_level:\n            if not (blank_before or previous_indent_level < indent_level or\n                    DOCSTRING_REGEX.match(previous_logical)):\n                ancestor_level = indent_level\n                nested = False\n                # Search backwards for a def ancestor or tree root (top level).\n                for line in lines[line_number - 2::-1]:\n                    if line.strip() and expand_indent(line) < ancestor_level:\n                        ancestor_level = expand_indent(line)\n                        nested = line.lstrip().startswith('def ')\n                        if nested or ancestor_level == 0:\n                            break\n                if nested:\n                    yield 0, \"E306 expected 1 blank line before a \" \\\n                        \"nested definition, found 0\"\n                else:\n                    yield 0, \"E301 expected 1 blank line, found 0\"\n        elif blank_before != 2:\n            yield 0, \"E302 expected 2 blank lines, found %d\" % blank_before\n    elif (logical_line and not indent_level and blank_before != 2 and\n          previous_unindented_logical_line.startswith(('def ', 'class '))):\n        yield 0, \"E305 expected 2 blank lines after \" \\\n            \"class or function definition, found %d\" % blank_before", "response": "r Separate top - level function and class definitions with two blank lines."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extraneous_whitespace(logical_line):\n    line = logical_line\n    for match in EXTRANEOUS_WHITESPACE_REGEX.finditer(line):\n        text = match.group()\n        char = text.strip()\n        found = match.start()\n        if text == char + ' ':\n            # assert char in '([{'\n            yield found + 1, \"E201 whitespace after '%s'\" % char\n        elif line[found - 1] != ',':\n            code = ('E202' if char in '}])' else 'E203')  # if char in ',;:'\n            yield found, \"%s whitespace before '%s'\" % (code, char)", "response": "rAvoid extraneous whitespace in these situations."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nyield a list of lines where the first line is missing whitespace after the import keyword.", "response": "def missing_whitespace_after_import_keyword(logical_line):\n    r\"\"\"Multiple imports in form from x import (a, b, c) should have space\n    between import statement and parenthesised name list.\n\n    Okay: from foo import (bar, baz)\n    E275: from foo import(bar, baz)\n    E275: from importable.module import(bar, baz)\n    \"\"\"\n    line = logical_line\n    indicator = ' import('\n    if line.startswith('from '):\n        found = line.find(indicator)\n        if -1 < found:\n            pos = found + len(indicator) - 1\n            yield pos, \"E275 missing whitespace after keyword\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef whitespace_before_parameters(logical_line, tokens):\n    prev_type, prev_text, __, prev_end, __ = tokens[0]\n    for index in range(1, len(tokens)):\n        token_type, text, start, end, __ = tokens[index]\n        if (token_type == tokenize.OP and\n            text in '([' and\n            start != prev_end and\n            (prev_type == tokenize.NAME or prev_text in '}])') and\n            # Syntax \"class A (B):\" is allowed, but avoid it\n            (index < 2 or tokens[index - 2][1] != 'class') and\n                # Allow \"return (a.foo for a in range(5))\"\n                not keyword.iskeyword(prev_text)):\n            yield prev_end, \"E211 whitespace before '%s'\" % text\n        prev_type = token_type\n        prev_text = text\n        prev_end = end", "response": "r A generator that yields whitespace before parameters."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef whitespace_around_operator(logical_line):\n    for match in OPERATOR_REGEX.finditer(logical_line):\n        before, after = match.groups()\n\n        if '\\t' in before:\n            yield match.start(1), \"E223 tab before operator\"\n        elif len(before) > 1:\n            yield match.start(1), \"E221 multiple spaces before operator\"\n\n        if '\\t' in after:\n            yield match.start(2), \"E224 tab after operator\"\n        elif len(after) > 1:\n            yield match.start(2), \"E222 multiple spaces after operator\"", "response": "rAvoid extraneous whitespace around an operator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef whitespace_around_comma(logical_line):\n    line = logical_line\n    for m in WHITESPACE_AFTER_COMMA_REGEX.finditer(line):\n        found = m.start() + 1\n        if '\\t' in m.group():\n            yield found, \"E242 tab after '%s'\" % m.group()[0]\n        else:\n            yield found, \"E241 multiple spaces after '%s'\" % m.group()[0]", "response": "rAvoid extraneous whitespace after a comma or a colon."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef whitespace_around_named_parameter_equals(logical_line, tokens):\n    parens = 0\n    no_space = False\n    prev_end = None\n    annotated_func_arg = False\n    in_def = bool(STARTSWITH_DEF_REGEX.match(logical_line))\n    message = \"E251 unexpected spaces around keyword / parameter equals\"\n    for token_type, text, start, end, line in tokens:\n        if token_type == tokenize.NL:\n            continue\n        if no_space:\n            no_space = False\n            if start != prev_end:\n                yield (prev_end, message)\n        if token_type == tokenize.OP:\n            if text in '([':\n                parens += 1\n            elif text in ')]':\n                parens -= 1\n            elif in_def and text == ':' and parens == 1:\n                annotated_func_arg = True\n            elif parens and text == ',' and parens == 1:\n                annotated_func_arg = False\n            elif parens and text == '=' and not annotated_func_arg:\n                no_space = True\n                if start != prev_end:\n                    yield (prev_end, message)\n            if not parens:\n                annotated_func_arg = False\n\n        prev_end = end", "response": "r Whitespace around named parameter equals."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef module_imports_on_top_of_file(\n        logical_line, indent_level, checker_state, noqa):\n    r\"\"\"Place imports at the top of the file.\n\n    Always put imports at the top of the file, just after any module comments\n    and docstrings, and before module globals and constants.\n\n    Okay: import os\n    Okay: # this is a comment\\nimport os\n    Okay: '''this is a module docstring'''\\nimport os\n    Okay: r'''this is a module docstring'''\\nimport os\n    Okay:\n    try:\\n\\timport x\\nexcept ImportError:\\n\\tpass\\nelse:\\n\\tpass\\nimport y\n    Okay:\n    try:\\n\\timport x\\nexcept ImportError:\\n\\tpass\\nfinally:\\n\\tpass\\nimport y\n    E402: a=1\\nimport os\n    E402: 'One string'\\n\"Two string\"\\nimport os\n    E402: a=1\\nfrom sys import x\n\n    Okay: if x:\\n    import os\n    \"\"\"\n    def is_string_literal(line):\n        if line[0] in 'uUbB':\n            line = line[1:]\n        if line and line[0] in 'rR':\n            line = line[1:]\n        return line and (line[0] == '\"' or line[0] == \"'\")\n\n    allowed_try_keywords = ('try', 'except', 'else', 'finally')\n\n    if indent_level:  # Allow imports in conditional statements or functions\n        return\n    if not logical_line:  # Allow empty lines or comments\n        return\n    if noqa:\n        return\n    line = logical_line\n    if line.startswith('import ') or line.startswith('from '):\n        if checker_state.get('seen_non_imports', False):\n            yield 0, \"E402 module level import not at top of file\"\n    elif re.match(DUNDER_REGEX, line):\n        return\n    elif any(line.startswith(kw) for kw in allowed_try_keywords):\n        # Allow try, except, else, finally keywords intermixed with imports in\n        # order to support conditional importing\n        return\n    elif is_string_literal(line):\n        # The first literal is a docstring, allow it. Otherwise, report error.\n        if checker_state.get('seen_docstring', False):\n            checker_state['seen_non_imports'] = True\n        else:\n            checker_state['seen_docstring'] = True\n    else:\n        checker_state['seen_non_imports'] = True", "response": "r Place imports at the top of the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef explicit_line_join(logical_line, tokens):\n    prev_start = prev_end = parens = 0\n    comment = False\n    backslash = None\n    for token_type, text, start, end, line in tokens:\n        if token_type == tokenize.COMMENT:\n            comment = True\n        if start[0] != prev_start and parens and backslash and not comment:\n            yield backslash, \"E502 the backslash is redundant between brackets\"\n        if end[0] != prev_end:\n            if line.rstrip('\\r\\n').endswith('\\\\'):\n                backslash = (end[0], len(line.splitlines()[-1]) - 1)\n            else:\n                backslash = None\n            prev_start = prev_end = end[0]\n        else:\n            prev_start = start[0]\n        if token_type == tokenize.OP:\n            if text in '([{':\n                parens += 1\n            elif text in ')]}':\n                parens -= 1", "response": "rAvoid explicit line join between brackets."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef break_around_binary_operator(logical_line, tokens):\n    def is_binary_operator(token_type, text):\n        # The % character is strictly speaking a binary operator, but the\n        # common usage seems to be to put it next to the format parameters,\n        # after a line break.\n        return ((token_type == tokenize.OP or text in ['and', 'or']) and\n                text not in \"()[]{},:.;@=%~\")\n\n    line_break = False\n    unary_context = True\n    # Previous non-newline token types and text\n    previous_token_type = None\n    previous_text = None\n    for token_type, text, start, end, line in tokens:\n        if token_type == tokenize.COMMENT:\n            continue\n        if ('\\n' in text or '\\r' in text) and token_type != tokenize.STRING:\n            line_break = True\n        else:\n            if (is_binary_operator(token_type, text) and line_break and\n                    not unary_context and\n                    not is_binary_operator(previous_token_type,\n                                           previous_text)):\n                yield start, \"W503 line break before binary operator\"\n            unary_context = text in '([{,;'\n            line_break = False\n            previous_token_type = token_type\n            previous_text = text", "response": "r Avoid breaks before binary operators."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef comparison_to_singleton(logical_line, noqa):\n    match = not noqa and COMPARE_SINGLETON_REGEX.search(logical_line)\n    if match:\n        singleton = match.group(1) or match.group(3)\n        same = (match.group(2) == '==')\n\n        msg = \"'if cond is %s:'\" % (('' if same else 'not ') + singleton)\n        if singleton in ('None',):\n            code = 'E711'\n        else:\n            code = 'E712'\n            nonzero = ((singleton == 'True' and same) or\n                       (singleton == 'False' and not same))\n            msg += \" or 'if %scond:'\" % ('' if nonzero else 'not ')\n        yield match.start(2), (\"%s comparison to %s should be %s\" %\n                               (code, singleton, msg))", "response": "r A function that compares a logical line to a single singleton."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef comparison_type(logical_line, noqa):\n    match = COMPARE_TYPE_REGEX.search(logical_line)\n    if match and not noqa:\n        inst = match.group(1)\n        if inst and isidentifier(inst) and inst not in SINGLETONS:\n            return  # Allow comparison for types which are not obvious\n        yield match.start(), \"E721 do not compare types, use 'isinstance()'\"", "response": "r Check if object is of type 1 or basestring."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bare_except(logical_line, noqa):\n    if noqa:\n        return\n\n    regex = re.compile(r\"except\\s*:\")\n    match = regex.match(logical_line)\n    if match:\n        yield match.start(), \"E722 do not use bare except'\"", "response": "A bare except statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef python_3000_raise_comma(logical_line):\n    match = RAISE_COMMA_REGEX.match(logical_line)\n    if match and not RERAISE_COMMA_REGEX.match(logical_line):\n        yield match.end() - 1, \"W602 deprecated form of raising exception\"", "response": "rWhen raising an exception use raise ValueError."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmute a string in the alphabetical order.", "response": "def mute_string(text):\n    \"\"\"Replace contents with 'xxx' to prevent syntax matching.\n\n    >>> mute_string('\"abc\"')\n    '\"xxx\"'\n    >>> mute_string(\"'''abc'''\")\n    \"'''xxx'''\"\n    >>> mute_string(\"r'abc'\")\n    \"r'xxx'\"\n    \"\"\"\n    # String modifiers (e.g. u or r)\n    start = text.index(text[-1]) + 1\n    end = len(text) - 1\n    # Triple quotes\n    if text[-3:] in ('\"\"\"', \"'''\"):\n        start += 2\n        end -= 2\n    return text[:start] + 'x' * (end - start) + text[end:]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_udiff(diff, patterns=None, parent='.'):\n    # For each file of the diff, the entry key is the filename,\n    # and the value is a set of row numbers to consider.\n    rv = {}\n    path = nrows = None\n    for line in diff.splitlines():\n        if nrows:\n            if line[:1] != '-':\n                nrows -= 1\n            continue\n        if line[:3] == '@@ ':\n            hunk_match = HUNK_REGEX.match(line)\n            (row, nrows) = [int(g or '1') for g in hunk_match.groups()]\n            rv[path].update(range(row, row + nrows))\n        elif line[:3] == '+++':\n            path = line[4:].split('\\t', 1)[0]\n            if path[:2] == 'b/':\n                path = path[2:]\n            rv[path] = set()\n    return dict([(os.path.join(parent, path), rows)\n                 for (path, rows) in rv.items()\n                 if rows and filename_match(path, patterns)])", "response": "Parse a diff file into a dictionary of matching lines."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a comma - separated list of paths. Return a list of absolute paths.", "response": "def normalize_paths(value, parent=os.curdir):\n    \"\"\"Parse a comma-separated list of paths.\n\n    Return a list of absolute paths.\n    \"\"\"\n    if not value:\n        return []\n    if isinstance(value, list):\n        return value\n    paths = []\n    for path in value.split(','):\n        path = path.strip()\n        if '/' in path:\n            path = os.path.abspath(os.path.join(parent, path))\n        paths.append(path.rstrip('/'))\n    return paths"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if patterns contains a pattern that matches filename.", "response": "def filename_match(filename, patterns, default=True):\n    \"\"\"Check if patterns contains a pattern that matches filename.\n\n    If patterns is unspecified, this always returns True.\n    \"\"\"\n    if not patterns:\n        return default\n    return any(fnmatch(filename, pattern) for pattern in patterns)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a new check object.", "response": "def register_check(check, codes=None):\n    \"\"\"Register a new check object.\"\"\"\n    def _add_check(check, kind, codes, args):\n        if check in _checks[kind]:\n            _checks[kind][check][0].extend(codes or [])\n        else:\n            _checks[kind][check] = (codes or [''], args)\n    if inspect.isfunction(check):\n        args = _get_parameters(check)\n        if args and args[0] in ('physical_line', 'logical_line'):\n            if codes is None:\n                codes = ERRORCODE_REGEX.findall(check.__doc__ or '')\n            _add_check(check, args[0], codes, args)\n    elif inspect.isclass(check):\n        if _get_parameters(check.__init__)[:2] == ['self', 'tree']:\n            _add_check(check, 'tree', codes, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters all globally visible functions.", "response": "def init_checks_registry():\n    \"\"\"Register all globally visible functions.\n\n    The first argument name is either 'physical_line' or 'logical_line'.\n    \"\"\"\n    mod = inspect.getmodule(register_check)\n    for (name, function) in inspect.getmembers(mod, inspect.isfunction):\n        register_check(function)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_parser(prog='pycodestyle', version=__version__):\n    parser = OptionParser(prog=prog, version=version,\n                          usage=\"%prog [options] input ...\")\n    parser.config_options = [\n        'exclude', 'filename', 'select', 'ignore', 'max-line-length',\n        'hang-closing', 'count', 'format', 'quiet', 'show-pep8',\n        'show-source', 'statistics', 'verbose']\n    parser.add_option('-v', '--verbose', default=0, action='count',\n                      help=\"print status messages, or debug with -vv\")\n    parser.add_option('-q', '--quiet', default=0, action='count',\n                      help=\"report only file names, or nothing with -qq\")\n    parser.add_option('-r', '--repeat', default=True, action='store_true',\n                      help=\"(obsolete) show all occurrences of the same error\")\n    parser.add_option('--first', action='store_false', dest='repeat',\n                      help=\"show first occurrence of each error\")\n    parser.add_option('--exclude', metavar='patterns', default=DEFAULT_EXCLUDE,\n                      help=\"exclude files or directories which match these \"\n                           \"comma separated patterns (default: %default)\")\n    parser.add_option('--filename', metavar='patterns', default='*.py',\n                      help=\"when parsing directories, only check filenames \"\n                           \"matching these comma separated patterns \"\n                           \"(default: %default)\")\n    parser.add_option('--select', metavar='errors', default='',\n                      help=\"select errors and warnings (e.g. E,W6)\")\n    parser.add_option('--ignore', metavar='errors', default='',\n                      help=\"skip errors and warnings (e.g. E4,W) \"\n                           \"(default: %s)\" % DEFAULT_IGNORE)\n    parser.add_option('--show-source', action='store_true',\n                      help=\"show source code for each error\")\n    parser.add_option('--show-pep8', action='store_true',\n                      help=\"show text of PEP 8 for each error \"\n                           \"(implies --first)\")\n    parser.add_option('--statistics', action='store_true',\n                      help=\"count errors and warnings\")\n    parser.add_option('--count', action='store_true',\n                      help=\"print total number of errors and warnings \"\n                           \"to standard error and set exit code to 1 if \"\n                           \"total is not null\")\n    parser.add_option('--max-line-length', type='int', metavar='n',\n                      default=MAX_LINE_LENGTH,\n                      help=\"set maximum allowed line length \"\n                           \"(default: %default)\")\n    parser.add_option('--hang-closing', action='store_true',\n                      help=\"hang closing bracket instead of matching \"\n                           \"indentation of opening bracket's line\")\n    parser.add_option('--format', metavar='format', default='default',\n                      help=\"set the error format [default|pylint|<custom>]\")\n    parser.add_option('--diff', action='store_true',\n                      help=\"report changes only within line number ranges in \"\n                           \"the unified diff received on STDIN\")\n    group = parser.add_option_group(\"Testing Options\")\n    if os.path.exists(TESTSUITE_PATH):\n        group.add_option('--testsuite', metavar='dir',\n                         help=\"run regression tests from dir\")\n        group.add_option('--doctest', action='store_true',\n                         help=\"run doctest on myself\")\n    group.add_option('--benchmark', action='store_true',\n                     help=\"measure processing speed\")\n    return parser", "response": "Create the parser for the program."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading and parse the configuration files.", "response": "def read_config(options, args, arglist, parser):\n    \"\"\"Read and parse configurations.\n\n    If a config file is specified on the command line with the \"--config\"\n    option, then only it is used for configuration.\n\n    Otherwise, the user configuration (~/.config/pycodestyle) and any local\n    configurations in the current directory or above will be merged together\n    (in that order) using the read method of ConfigParser.\n    \"\"\"\n    config = RawConfigParser()\n\n    cli_conf = options.config\n\n    local_dir = os.curdir\n\n    if USER_CONFIG and os.path.isfile(USER_CONFIG):\n        if options.verbose:\n            print('user configuration: %s' % USER_CONFIG)\n        config.read(USER_CONFIG)\n\n    parent = tail = args and os.path.abspath(os.path.commonprefix(args))\n    while tail:\n        if config.read(os.path.join(parent, fn) for fn in PROJECT_CONFIG):\n            local_dir = parent\n            if options.verbose:\n                print('local configuration: in %s' % parent)\n            break\n        (parent, tail) = os.path.split(parent)\n\n    if cli_conf and os.path.isfile(cli_conf):\n        if options.verbose:\n            print('cli configuration: %s' % cli_conf)\n        config.read(cli_conf)\n\n    pycodestyle_section = None\n    if config.has_section(parser.prog):\n        pycodestyle_section = parser.prog\n    elif config.has_section('pep8'):\n        pycodestyle_section = 'pep8'  # Deprecated\n        warnings.warn('[pep8] section is deprecated. Use [pycodestyle].')\n\n    if pycodestyle_section:\n        option_list = dict([(o.dest, o.type or o.action)\n                            for o in parser.option_list])\n\n        # First, read the default values\n        (new_options, __) = parser.parse_args([])\n\n        # Second, parse the configuration\n        for opt in config.options(pycodestyle_section):\n            if opt.replace('_', '-') not in parser.config_options:\n                print(\"  unknown option '%s' ignored\" % opt)\n                continue\n            if options.verbose > 1:\n                print(\"  %s = %s\" % (opt,\n                                     config.get(pycodestyle_section, opt)))\n            normalized_opt = opt.replace('-', '_')\n            opt_type = option_list[normalized_opt]\n            if opt_type in ('int', 'count'):\n                value = config.getint(pycodestyle_section, opt)\n            elif opt_type in ('store_true', 'store_false'):\n                value = config.getboolean(pycodestyle_section, opt)\n            else:\n                value = config.get(pycodestyle_section, opt)\n                if normalized_opt == 'exclude':\n                    value = normalize_paths(value, local_dir)\n            setattr(new_options, normalized_opt, value)\n\n        # Third, overwrite with the command-line options\n        (options, __) = parser.parse_args(arglist, values=new_options)\n    options.doctest = options.testsuite = False\n    return options"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprocess options passed in via command line args.", "response": "def process_options(arglist=None, parse_argv=False, config_file=None,\n                    parser=None):\n    \"\"\"Process options passed either via arglist or via command line args.\n\n    Passing in the ``config_file`` parameter allows other tools, such as flake8\n    to specify their own options to be processed in pycodestyle.\n    \"\"\"\n    if not parser:\n        parser = get_parser()\n    if not parser.has_option('--config'):\n        group = parser.add_option_group(\"Configuration\", description=(\n            \"The project options are read from the [%s] section of the \"\n            \"tox.ini file or the setup.cfg file located in any parent folder \"\n            \"of the path(s) being processed.  Allowed options are: %s.\" %\n            (parser.prog, ', '.join(parser.config_options))))\n        group.add_option('--config', metavar='path', default=config_file,\n                         help=\"user config file location\")\n    # Don't read the command line if the module is used as a library.\n    if not arglist and not parse_argv:\n        arglist = []\n    # If parse_argv is True and arglist is None, arguments are\n    # parsed from the command line (sys.argv)\n    (options, args) = parser.parse_args(arglist)\n    options.reporter = None\n\n    if options.ensure_value('testsuite', False):\n        args.append(options.testsuite)\n    elif not options.ensure_value('doctest', False):\n        if parse_argv and not args:\n            if options.diff or any(os.path.exists(name)\n                                   for name in PROJECT_CONFIG):\n                args = ['.']\n            else:\n                parser.error('input not specified')\n        options = read_config(options, args, arglist, parser)\n        options.reporter = parse_argv and options.quiet == 1 and FileReport\n\n    options.filename = _parse_multi_options(options.filename)\n    options.exclude = normalize_paths(options.exclude)\n    options.select = _parse_multi_options(options.select)\n    options.ignore = _parse_multi_options(options.ignore)\n\n    if options.diff:\n        options.reporter = DiffReport\n        stdin = stdin_get_value()\n        options.selected_lines = parse_udiff(stdin, options.filename, args[0])\n        args = sorted(options.selected_lines)\n\n    return options, args"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing options and run checks on Python source.", "response": "def _main():\n    \"\"\"Parse options and run checks on Python source.\"\"\"\n    import signal\n\n    # Handle \"Broken pipe\" gracefully\n    try:\n        signal.signal(signal.SIGPIPE, lambda signum, frame: sys.exit(1))\n    except AttributeError:\n        pass    # not supported on Windows\n\n    style_guide = StyleGuide(parse_argv=True)\n    options = style_guide.options\n\n    if options.doctest or options.testsuite:\n        from testsuite.support import run_tests\n        report = run_tests(style_guide)\n    else:\n        report = style_guide.check_files()\n\n    if options.statistics:\n        report.print_statistics()\n\n    if options.benchmark:\n        report.print_benchmark()\n\n    if options.testsuite and not options.quiet:\n        report.print_results()\n\n    if report.total_errors:\n        if options.count:\n            sys.stderr.write(str(report.total_errors) + '\\n')\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef report_invalid_syntax(self):\n        (exc_type, exc) = sys.exc_info()[:2]\n        if len(exc.args) > 1:\n            offset = exc.args[1]\n            if len(offset) > 2:\n                offset = offset[1:3]\n        else:\n            offset = (1, 0)\n        self.report_error(offset[0], offset[1] or 0,\n                          'E901 %s: %s' % (exc_type.__name__, exc.args[0]),\n                          self.report_invalid_syntax)", "response": "Check if the syntax is valid."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef readline(self):\n        if self.line_number >= self.total_lines:\n            return ''\n        line = self.lines[self.line_number]\n        self.line_number += 1\n        if self.indent_char is None and line[:1] in WHITESPACE:\n            self.indent_char = line[0]\n        return line", "response": "Get the next line from the input buffer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning a check plugin.", "response": "def run_check(self, check, argument_names):\n        \"\"\"Run a check plugin.\"\"\"\n        arguments = []\n        for name in argument_names:\n            arguments.append(getattr(self, name))\n        return check(*arguments)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprepare custom state for the specific checker plugin.", "response": "def init_checker_state(self, name, argument_names):\n        \"\"\"Prepare custom state for the specific checker plugin.\"\"\"\n        if 'checker_state' in argument_names:\n            self.checker_state = self._checker_states.setdefault(name, {})"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun all physical checks on a raw input line.", "response": "def check_physical(self, line):\n        \"\"\"Run all physical checks on a raw input line.\"\"\"\n        self.physical_line = line\n        for name, check, argument_names in self._physical_checks:\n            self.init_checker_state(name, argument_names)\n            result = self.run_check(check, argument_names)\n            if result is not None:\n                (offset, text) = result\n                self.report_error(self.line_number, offset, text, check)\n                if text[:4] == 'E101':\n                    self.indent_char = line[0]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_tokens_line(self):\n        logical = []\n        comments = []\n        length = 0\n        prev_row = prev_col = mapping = None\n        for token_type, text, start, end, line in self.tokens:\n            if token_type in SKIP_TOKENS:\n                continue\n            if not mapping:\n                mapping = [(0, start)]\n            if token_type == tokenize.COMMENT:\n                comments.append(text)\n                continue\n            if token_type == tokenize.STRING:\n                text = mute_string(text)\n            if prev_row:\n                (start_row, start_col) = start\n                if prev_row != start_row:    # different row\n                    prev_text = self.lines[prev_row - 1][prev_col - 1]\n                    if prev_text == ',' or (prev_text not in '{[(' and\n                                            text not in '}])'):\n                        text = ' ' + text\n                elif prev_col != start_col:  # different column\n                    text = line[prev_col:start_col] + text\n            logical.append(text)\n            length += len(text)\n            mapping.append((length, end))\n            (prev_row, prev_col) = end\n        self.logical_line = ''.join(logical)\n        self.noqa = comments and noqa(''.join(comments))\n        return mapping", "response": "Build a logical line from tokens."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_logical(self):\n        self.report.increment_logical_line()\n        mapping = self.build_tokens_line()\n\n        if not mapping:\n            return\n\n        (start_row, start_col) = mapping[0][1]\n        start_line = self.lines[start_row - 1]\n        self.indent_level = expand_indent(start_line[:start_col])\n        if self.blank_before < self.blank_lines:\n            self.blank_before = self.blank_lines\n        if self.verbose >= 2:\n            print(self.logical_line[:80].rstrip())\n        for name, check, argument_names in self._logical_checks:\n            if self.verbose >= 4:\n                print('   ' + name)\n            self.init_checker_state(name, argument_names)\n            for offset, text in self.run_check(check, argument_names) or ():\n                if not isinstance(offset, tuple):\n                    for token_offset, pos in mapping:\n                        if offset <= token_offset:\n                            break\n                    offset = (pos[0], pos[1] + offset - token_offset)\n                self.report_error(offset[0], offset[1], text, check)\n        if self.logical_line:\n            self.previous_indent_level = self.indent_level\n            self.previous_logical = self.logical_line\n            if not self.indent_level:\n                self.previous_unindented_logical_line = self.logical_line\n        self.blank_lines = 0\n        self.tokens = []", "response": "Build a line from tokens and run all logical checks on it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_ast(self):\n        try:\n            tree = compile(''.join(self.lines), '', 'exec', PyCF_ONLY_AST)\n        except (ValueError, SyntaxError, TypeError):\n            return self.report_invalid_syntax()\n        for name, cls, __ in self._ast_checks:\n            checker = cls(tree, self.filename)\n            for lineno, offset, text, check in checker.run():\n                if not self.lines or not noqa(self.lines[lineno - 1]):\n                    self.report_error(lineno, offset, text, check)", "response": "Build the file s AST and run all AST checks."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the current physical line is correct.", "response": "def maybe_check_physical(self, token):\n        \"\"\"If appropriate (based on token), check current physical line(s).\"\"\"\n        # Called after every token, but act only on end of line.\n        if _is_eol_token(token):\n            # Obviously, a newline token ends a single physical line.\n            self.check_physical(token[4])\n        elif token[0] == tokenize.STRING and '\\n' in token[1]:\n            # Less obviously, a string that contains newlines is a\n            # multiline string, either triple-quoted or with internal\n            # newlines backslash-escaped. Check every physical line in the\n            # string *except* for the last one: its newline is outside of\n            # the multiline string, so we consider it a regular physical\n            # line, and will check it like any other physical line.\n            #\n            # Subtleties:\n            # - we don't *completely* ignore the last line; if it contains\n            #   the magical \"# noqa\" comment, we disable all physical\n            #   checks for the entire multiline string\n            # - have to wind self.line_number back because initially it\n            #   points to the last line of the string, and we want\n            #   check_physical() to give accurate feedback\n            if noqa(token[4]):\n                return\n            self.multiline = True\n            self.line_number = token[2][0]\n            for line in token[1].split('\\n')[:-1]:\n                self.check_physical(line + '\\n')\n                self.line_number += 1\n            self.multiline = False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_all(self, expected=None, line_offset=0):\n        self.report.init_file(self.filename, self.lines, expected, line_offset)\n        self.total_lines = len(self.lines)\n        if self._ast_checks:\n            self.check_ast()\n        self.line_number = 0\n        self.indent_char = None\n        self.indent_level = self.previous_indent_level = 0\n        self.previous_logical = ''\n        self.previous_unindented_logical_line = ''\n        self.tokens = []\n        self.blank_lines = self.blank_before = 0\n        parens = 0\n        for token in self.generate_tokens():\n            self.tokens.append(token)\n            token_type, text = token[0:2]\n            if self.verbose >= 3:\n                if token[2][0] == token[3][0]:\n                    pos = '[%s:%s]' % (token[2][1] or '', token[3][1])\n                else:\n                    pos = 'l.%s' % token[3][0]\n                print('l.%s\\t%s\\t%s\\t%r' %\n                      (token[2][0], pos, tokenize.tok_name[token[0]], text))\n            if token_type == tokenize.OP:\n                if text in '([{':\n                    parens += 1\n                elif text in '}])':\n                    parens -= 1\n            elif not parens:\n                if token_type in NEWLINE:\n                    if token_type == tokenize.NEWLINE:\n                        self.check_logical()\n                        self.blank_before = 0\n                    elif len(self.tokens) == 1:\n                        # The physical line contains only this token.\n                        self.blank_lines += 1\n                        del self.tokens[0]\n                    else:\n                        self.check_logical()\n                elif COMMENT_WITH_NL and token_type == tokenize.COMMENT:\n                    if len(self.tokens) == 1:\n                        # The comment also ends a physical line\n                        token = list(token)\n                        token[1] = text.rstrip('\\r\\n')\n                        token[3] = (token[2][0], token[2][1] + len(token[1]))\n                        self.tokens = [tuple(token)]\n                        self.check_logical()\n        if self.tokens:\n            self.check_physical(self.lines[-1])\n            self.check_logical()\n        return self.report.get_file_results()", "response": "Run all checks on the input file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init_file(self, filename, lines, expected, line_offset):\n        self.filename = filename\n        self.lines = lines\n        self.expected = expected or ()\n        self.line_offset = line_offset\n        self.file_errors = 0\n        self.counters['files'] += 1\n        self.counters['physical lines'] += len(lines)", "response": "Signal a new file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef error(self, line_number, offset, text, check):\n        code = text[:4]\n        if self._ignore_code(code):\n            return\n        if code in self.counters:\n            self.counters[code] += 1\n        else:\n            self.counters[code] = 1\n            self.messages[code] = text[5:]\n        # Don't care about expected errors or warnings\n        if code in self.expected:\n            return\n        if self.print_filename and not self.file_errors:\n            print(self.filename)\n        self.file_errors += 1\n        self.total_errors += 1\n        return code", "response": "Report an error according to options."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the total count of errors and warnings.", "response": "def get_count(self, prefix=''):\n        \"\"\"Return the total count of errors and warnings.\"\"\"\n        return sum([self.counters[key]\n                    for key in self.messages if key.startswith(prefix)])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget statistics for all message codes that start with the prefix.", "response": "def get_statistics(self, prefix=''):\n        \"\"\"Get statistics for message codes that start with the prefix.\n\n        prefix='' matches all errors and warnings\n        prefix='E' matches all errors\n        prefix='W' matches all warnings\n        prefix='E4' matches all errors that have to do with imports\n        \"\"\"\n        return ['%-7s %s %s' % (self.counters[key], key, self.messages[key])\n                for key in sorted(self.messages) if key.startswith(prefix)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init_file(self, filename, lines, expected, line_offset):\n        self._deferred_print = []\n        return super(StandardReport, self).init_file(\n            filename, lines, expected, line_offset)", "response": "Signal a new file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreporting an error according to options.", "response": "def error(self, line_number, offset, text, check):\n        \"\"\"Report an error, according to options.\"\"\"\n        code = super(StandardReport, self).error(line_number, offset,\n                                                 text, check)\n        if code and (self.counters[code] == 1 or self._repeat):\n            self._deferred_print.append(\n                (line_number, offset, code, text[5:], check.__doc__))\n        return code"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprint the result and return the overall count for this file.", "response": "def get_file_results(self):\n        \"\"\"Print the result and return the overall count for this file.\"\"\"\n        self._deferred_print.sort()\n        for line_number, offset, code, text, doc in self._deferred_print:\n            print(self._fmt % {\n                'path': self.filename,\n                'row': self.line_offset + line_number, 'col': offset + 1,\n                'code': code, 'text': text,\n            })\n            if self._show_source:\n                if line_number > len(self.lines):\n                    line = ''\n                else:\n                    line = self.lines[line_number - 1]\n                print(line.rstrip())\n                print(re.sub(r'\\S', ' ', line[:offset]) + '^')\n            if self._show_pep8 and doc:\n                print('    ' + doc.strip())\n\n            # stdout is block buffered when not stdout.isatty().\n            # line can be broken where buffer boundary since other processes\n            # write to same file.\n            # flush() after print() to avoid buffer boundary.\n            # Typical buffer size is 8192. line written safely when\n            # len(line) < 8192.\n            sys.stdout.flush()\n        return self.file_errors"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize the report instance.", "response": "def init_report(self, reporter=None):\n        \"\"\"Initialize the report instance.\"\"\"\n        self.options.report = (reporter or self.options.reporter)(self.options)\n        return self.options.report"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning all checks on the paths.", "response": "def check_files(self, paths=None):\n        \"\"\"Run all checks on the paths.\"\"\"\n        if paths is None:\n            paths = self.paths\n        report = self.options.report\n        runner = self.runner\n        report.start()\n        try:\n            for path in paths:\n                if os.path.isdir(path):\n                    self.input_dir(path)\n                elif not self.excluded(path):\n                    runner(path)\n        except KeyboardInterrupt:\n            print('... stopped')\n        report.stop()\n        return report"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning all checks on a Python source file.", "response": "def input_file(self, filename, lines=None, expected=None, line_offset=0):\n        \"\"\"Run all checks on a Python source file.\"\"\"\n        if self.options.verbose:\n            print('checking %s' % filename)\n        fchecker = self.checker_class(\n            filename, lines=lines, options=self.options)\n        return fchecker.check_all(expected=expected, line_offset=line_offset)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef input_dir(self, dirname):\n        dirname = dirname.rstrip('/')\n        if self.excluded(dirname):\n            return 0\n        counters = self.options.report.counters\n        verbose = self.options.verbose\n        filepatterns = self.options.filename\n        runner = self.runner\n        for root, dirs, files in os.walk(dirname):\n            if verbose:\n                print('directory ' + root)\n            counters['directories'] += 1\n            for subdir in sorted(dirs):\n                if self.excluded(subdir, root):\n                    dirs.remove(subdir)\n            for filename in sorted(files):\n                # contain a pattern that matches?\n                if ((filename_match(filename, filepatterns) and\n                     not self.excluded(filename, root))):\n                    runner(os.path.join(root, filename))", "response": "Check all files in this directory and all subdirectories."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the file should be excluded.", "response": "def excluded(self, filename, parent=None):\n        \"\"\"Check if the file should be excluded.\n\n        Check if 'options.exclude' contains a pattern that matches filename.\n        \"\"\"\n        if not self.options.exclude:\n            return False\n        basename = os.path.basename(filename)\n        if filename_match(basename, self.options.exclude):\n            return True\n        if parent:\n            filename = os.path.join(parent, filename)\n        filename = os.path.abspath(filename)\n        return filename_match(filename, self.options.exclude)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ignore_code(self, code):\n        if len(code) < 4 and any(s.startswith(code)\n                                 for s in self.options.select):\n            return False\n        return (code.startswith(self.options.ignore) and\n                not code.startswith(self.options.select))", "response": "Check if the error code should be ignored."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting all the checks for this category.", "response": "def get_checks(self, argument_name):\n        \"\"\"Get all the checks for this category.\n\n        Find all globally visible functions where the first argument name\n        starts with argument_name and which contain selected tests.\n        \"\"\"\n        checks = []\n        for check, attrs in _checks[argument_name].items():\n            (codes, args) = attrs\n            if any(not (code and self.ignore_code(code)) for code in codes):\n                checks.append((check.__name__, check, args))\n        return sorted(checks)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getparser(use_datetime=0):\n    if use_datetime and not datetime:\n        raise ValueError(\"the datetime module is not available\")\n    if FastParser and FastUnmarshaller:\n        if use_datetime:\n            mkdatetime = _datetime_type\n        else:\n            mkdatetime = _datetime\n        target = FastUnmarshaller(True, False, _binary, mkdatetime, Fault)\n        parser = FastParser(target)\n    else:\n        target = Unmarshaller(use_datetime=use_datetime)\n        if FastParser:\n            parser = FastParser(target)\n        elif SgmlopParser:\n            parser = SgmlopParser(target)\n        elif ExpatParser:\n            parser = ExpatParser(target)\n        else:\n            parser = SlowParser(target)\n    return parser, target", "response": "getparser - Returns a parser and a unmarshaller object for the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef loads(data, use_datetime=0):\n    p, u = getparser(use_datetime=use_datetime)\n    p.feed(data)\n    p.close()\n    return u.close(), u.getmethodname()", "response": "data -> unmarshalled data method name - > method name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transform_import(self, node, results):\n        import_mod = results.get(\"module\")\n        pref = import_mod.prefix\n\n        names = []\n\n        # create a Node list of the replacement modules\n        for name in MAPPING[import_mod.value][:-1]:\n            names.extend([Name(name[0], prefix=pref), Comma()])\n        names.append(Name(MAPPING[import_mod.value][-1][0], prefix=pref))\n        import_mod.replace(names)", "response": "Transform for the basic import case. Replaces the old\n           import name with a comma separated list of its\n            replacements."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transform_member(self, node, results):\n        mod_member = results.get(\"mod_member\")\n        pref = mod_member.prefix\n        member = results.get(\"member\")\n\n        # Simple case with only a single member being imported\n        if member:\n            # this may be a list of length one, or just a node\n            if isinstance(member, list):\n                member = member[0]\n            new_name = None\n            for change in MAPPING[mod_member.value]:\n                if member.value in change[1]:\n                    new_name = change[0]\n                    break\n            if new_name:\n                mod_member.replace(Name(new_name, prefix=pref))\n            else:\n                self.cannot_convert(node, \"This is an invalid module element\")\n\n        # Multiple members being imported\n        else:\n            # a dictionary for replacements, order matters\n            modules = []\n            mod_dict = {}\n            members = results[\"members\"]\n            for member in members:\n                # we only care about the actual members\n                if member.type == syms.import_as_name:\n                    as_name = member.children[2].value\n                    member_name = member.children[0].value\n                else:\n                    member_name = member.value\n                    as_name = None\n                if member_name != u\",\":\n                    for change in MAPPING[mod_member.value]:\n                        if member_name in change[1]:\n                            if change[0] not in mod_dict:\n                                modules.append(change[0])\n                            mod_dict.setdefault(change[0], []).append(member)\n\n            new_nodes = []\n            indentation = find_indentation(node)\n            first = True\n            def handle_name(name, prefix):\n                if name.type == syms.import_as_name:\n                    kids = [Name(name.children[0].value, prefix=prefix),\n                            name.children[1].clone(),\n                            name.children[2].clone()]\n                    return [Node(syms.import_as_name, kids)]\n                return [Name(name.value, prefix=prefix)]\n            for module in modules:\n                elts = mod_dict[module]\n                names = []\n                for elt in elts[:-1]:\n                    names.extend(handle_name(elt, pref))\n                    names.append(Comma())\n                names.extend(handle_name(elts[-1], pref))\n                new = FromImport(module, names)\n                if not first or node.parent.prefix.endswith(indentation):\n                    new.prefix = indentation\n                new_nodes.append(new)\n                first = False\n            if new_nodes:\n                nodes = []\n                for new_node in new_nodes[:-1]:\n                    nodes.extend([new_node, Newline()])\n                nodes.append(new_nodes[-1])\n                node.replace(nodes)\n            else:\n                self.cannot_convert(node, \"All module elements are invalid\")", "response": "Transform for imports of specific module elements."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntransform for calls to module members in code.", "response": "def transform_dot(self, node, results):\n        \"\"\"Transform for calls to module members in code.\"\"\"\n        module_dot = results.get(\"bare_with_attr\")\n        member = results.get(\"member\")\n        new_name = None\n        if isinstance(member, list):\n            member = member[0]\n        for change in MAPPING[module_dot.value]:\n            if member.value in change[1]:\n                new_name = change[0]\n                break\n        if new_name:\n            module_dot.replace(Name(new_name,\n                                    prefix=module_dot.prefix))\n        else:\n            self.cannot_convert(node, \"This is an invalid module element\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef protect_libraries_from_patching():\n    patched = ['threading', 'thread', '_thread', 'time', 'socket', 'Queue', 'queue', 'select',\n               'xmlrpclib', 'SimpleXMLRPCServer', 'BaseHTTPServer', 'SocketServer',\n               'xmlrpc.client', 'xmlrpc.server', 'http.server', 'socketserver']\n\n    for name in patched:\n        try:\n            __import__(name)\n        except:\n            pass\n\n    patched_modules = dict([(k, v) for k, v in sys.modules.items()\n                            if k in patched])\n\n    for name in patched_modules:\n        del sys.modules[name]\n\n    # import for side effects\n    import _pydev_imps._pydev_saved_modules\n\n    for name in patched_modules:\n        sys.modules[name] = patched_modules[name]", "response": "This function protects libraries from patching by external libraries."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_current_thread_id(thread):\n    '''\n    Note: the difference from get_current_thread_id to get_thread_id is that\n    for the current thread we can get the thread id while the thread.ident\n    is still not set in the Thread instance.\n    '''\n    try:\n        # Fast path without getting lock.\n        tid = thread.__pydevd_id__\n        if tid is None:\n            # Fix for https://www.brainwy.com/tracker/PyDev/645\n            # if __pydevd_id__ is None, recalculate it... also, use an heuristic\n            # that gives us always the same id for the thread (using thread.ident or id(thread)).\n            raise AttributeError()\n    except AttributeError:\n        tid = _get_or_compute_thread_id_with_lock(thread, is_current_thread=True)\n\n    return tid", "response": "Get the thread id for the current thread."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef call_only_once(func):\n    '''\n    To be used as a decorator\n\n    @call_only_once\n    def func():\n        print 'Calling func only this time'\n\n    Actually, in PyDev it must be called as:\n\n    func = call_only_once(func) to support older versions of Python.\n    '''\n\n    def new_func(*args, **kwargs):\n        if not new_func._called:\n            new_func._called = True\n            return func(*args, **kwargs)\n\n    new_func._called = False\n    return new_func", "response": "Decorator to call only once a function."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a sorted list of all available fix names in the given package.", "response": "def get_all_fix_names(fixer_pkg, remove_prefix=True):\n    \"\"\"Return a sorted list of all available fix names in the given package.\"\"\"\n    pkg = __import__(fixer_pkg, [], [], [\"*\"])\n    fixer_dir = os.path.dirname(pkg.__file__)\n    fix_names = []\n    for name in sorted(os.listdir(fixer_dir)):\n        if name.startswith(\"fix_\") and name.endswith(\".py\"):\n            if remove_prefix:\n                name = name[4:]\n            fix_names.append(name[:-3])\n    return fix_names"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_head_types(pat):\n\n    if isinstance(pat, (pytree.NodePattern, pytree.LeafPattern)):\n        # NodePatters must either have no type and no content\n        #   or a type and content -- so they don't get any farther\n        # Always return leafs\n        if pat.type is None:\n            raise _EveryNode\n        return set([pat.type])\n\n    if isinstance(pat, pytree.NegatedPattern):\n        if pat.content:\n            return _get_head_types(pat.content)\n        raise _EveryNode # Negated Patterns don't have a type\n\n    if isinstance(pat, pytree.WildcardPattern):\n        # Recurse on each node in content\n        r = set()\n        for p in pat.content:\n            for x in p:\n                r.update(_get_head_types(x))\n        return r\n\n    raise Exception(\"Oh no! I don't understand pattern %s\" %(pat))", "response": "Given a pytree Pattern Node and returns a set of the pattern types which will match first."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_headnode_dict(fixer_list):\n    head_nodes = collections.defaultdict(list)\n    every = []\n    for fixer in fixer_list:\n        if fixer.pattern:\n            try:\n                heads = _get_head_types(fixer.pattern)\n            except _EveryNode:\n                every.append(fixer)\n            else:\n                for node_type in heads:\n                    head_nodes[node_type].append(fixer)\n        else:\n            if fixer._accept_type is not None:\n                head_nodes[fixer._accept_type].append(fixer)\n            else:\n                every.append(fixer)\n    for node_type in chain(pygram.python_grammar.symbol2number.itervalues(),\n                           pygram.python_grammar.tokens):\n        head_nodes[node_type].extend(every)\n    return dict(head_nodes)", "response": "Takes a list of fixers and returns a dictionary\n    of head node type --> fixer list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninspect the options to load the requested patterns and handlers.", "response": "def get_fixers(self):\n        \"\"\"Inspects the options to load the requested patterns and handlers.\n\n        Returns:\n          (pre_order, post_order), where pre_order is the list of fixers that\n          want a pre-order AST traversal, and post_order is the list that want\n          post-order traversal.\n        \"\"\"\n        pre_order_fixers = []\n        post_order_fixers = []\n        for fix_mod_path in self.fixers:\n            mod = __import__(fix_mod_path, {}, {}, [\"*\"])\n            fix_name = fix_mod_path.rsplit(\".\", 1)[-1]\n            if fix_name.startswith(self.FILE_PREFIX):\n                fix_name = fix_name[len(self.FILE_PREFIX):]\n            parts = fix_name.split(\"_\")\n            class_name = self.CLASS_PREFIX + \"\".join([p.title() for p in parts])\n            try:\n                fix_class = getattr(mod, class_name)\n            except AttributeError:\n                raise FixerError(\"Can't find %s.%s\" % (fix_name, class_name))\n            fixer = fix_class(self.options, self.fixer_log)\n            if fixer.explicit and self.explicit is not True and \\\n                    fix_mod_path not in self.explicit:\n                self.log_message(\"Skipping implicit fixer: %s\", fix_name)\n                continue\n\n            self.log_debug(\"Adding transformation: %s\", fix_name)\n            if fixer.order == \"pre\":\n                pre_order_fixers.append(fixer)\n            elif fixer.order == \"post\":\n                post_order_fixers.append(fixer)\n            else:\n                raise FixerError(\"Illegal fixer order: %r\" % fixer.order)\n\n        key_func = operator.attrgetter(\"run_order\")\n        pre_order_fixers.sort(key=key_func)\n        post_order_fixers.sort(key=key_func)\n        return (pre_order_fixers, post_order_fixers)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhooking to log a message.", "response": "def log_message(self, msg, *args):\n        \"\"\"Hook to log a message.\"\"\"\n        if args:\n            msg = msg % args\n        self.logger.info(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef refactor(self, items, write=False, doctests_only=False):\n\n        for dir_or_file in items:\n            if os.path.isdir(dir_or_file):\n                self.refactor_dir(dir_or_file, write, doctests_only)\n            else:\n                self.refactor_file(dir_or_file, write, doctests_only)", "response": "Refactor a list of files and directories."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef refactor_dir(self, dir_name, write=False, doctests_only=False):\n        py_ext = os.extsep + \"py\"\n        for dirpath, dirnames, filenames in os.walk(dir_name):\n            self.log_debug(\"Descending into %s\", dirpath)\n            dirnames.sort()\n            filenames.sort()\n            for name in filenames:\n                if (not name.startswith(\".\") and\n                    os.path.splitext(name)[1] == py_ext):\n                    fullname = os.path.join(dirpath, name)\n                    self.refactor_file(fullname, write, doctests_only)\n            # Modify dirnames in-place to remove subdirs with leading dots\n            dirnames[:] = [dn for dn in dirnames if not dn.startswith(\".\")]", "response": "Descends down a directory and refactor every Python file found."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a Python source file and return a tuple of the first line and the encoding.", "response": "def _read_python_source(self, filename):\n        \"\"\"\n        Do our best to decode a Python source file correctly.\n        \"\"\"\n        try:\n            f = open(filename, \"rb\")\n        except IOError as err:\n            self.log_error(\"Can't open %s: %s\", filename, err)\n            return None, None\n        try:\n            encoding = tokenize.detect_encoding(f.readline)[0]\n        finally:\n            f.close()\n        with _open_with_encoding(filename, \"r\", encoding=encoding) as f:\n            return _from_system_newlines(f.read()), encoding"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef refactor_string(self, data, name):\n        features = _detect_future_features(data)\n        if \"print_function\" in features:\n            self.driver.grammar = pygram.python_grammar_no_print_statement\n        try:\n            tree = self.driver.parse_string(data)\n        except Exception as err:\n            self.log_error(\"Can't parse %s: %s: %s\",\n                           name, err.__class__.__name__, err)\n            return\n        finally:\n            self.driver.grammar = self.grammar\n        tree.future_features = features\n        self.log_debug(\"Refactoring %s\", name)\n        self.refactor_tree(tree, name)\n        return tree", "response": "Refactor a given input string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef refactor_tree(self, tree, name):\n\n        for fixer in chain(self.pre_order, self.post_order):\n            fixer.start_tree(tree, name)\n\n        #use traditional matching for the incompatible fixers\n        self.traverse_by(self.bmi_pre_order_heads, tree.pre_order())\n        self.traverse_by(self.bmi_post_order_heads, tree.post_order())\n\n        # obtain a set of candidate nodes\n        match_set = self.BM.run(tree.leaves())\n\n        while any(match_set.values()):\n            for fixer in self.BM.fixers:\n                if fixer in match_set and match_set[fixer]:\n                    #sort by depth; apply fixers from bottom(of the AST) to top\n                    match_set[fixer].sort(key=pytree.Base.depth, reverse=True)\n\n                    if fixer.keep_line_order:\n                        #some fixers(eg fix_imports) must be applied\n                        #with the original file's line order\n                        match_set[fixer].sort(key=pytree.Base.get_lineno)\n\n                    for node in list(match_set[fixer]):\n                        if node in match_set[fixer]:\n                            match_set[fixer].remove(node)\n\n                        try:\n                            find_root(node)\n                        except ValueError:\n                            # this node has been cut off from a\n                            # previous transformation ; skip\n                            continue\n\n                        if node.fixers_applied and fixer in node.fixers_applied:\n                            # do not apply the same fixer again\n                            continue\n\n                        results = fixer.match(node)\n\n                        if results:\n                            new = fixer.transform(node, results)\n                            if new is not None:\n                                node.replace(new)\n                                #new.fixers_applied.append(fixer)\n                                for node in new.post_order():\n                                    # do not apply the fixer again to\n                                    # this or any subnode\n                                    if not node.fixers_applied:\n                                        node.fixers_applied = []\n                                    node.fixers_applied.append(fixer)\n\n                                # update the original match set for\n                                # the added code\n                                new_matches = self.BM.run(new.leaves())\n                                for fxr in new_matches:\n                                    if not fxr in match_set:\n                                        match_set[fxr]=[]\n\n                                    match_set[fxr].extend(new_matches[fxr])\n\n        for fixer in chain(self.pre_order, self.post_order):\n            fixer.finish_tree(tree, name)\n        return tree.was_changed", "response": "Refactors a parse tree in place."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntraverse an AST applying a set of fixers to each node.", "response": "def traverse_by(self, fixers, traversal):\n        \"\"\"Traverse an AST, applying a set of fixers to each node.\n\n        This is a helper method for refactor_tree().\n\n        Args:\n            fixers: a list of fixer instances.\n            traversal: a generator that yields AST nodes.\n\n        Returns:\n            None\n        \"\"\"\n        if not fixers:\n            return\n        for node in traversal:\n            for fixer in fixers[node.type]:\n                results = fixer.match(node)\n                if results:\n                    new = fixer.transform(node, results)\n                    if new is not None:\n                        node.replace(new)\n                        node = new"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls when a file has been refactored and there may be changes.", "response": "def processed_file(self, new_text, filename, old_text=None, write=False,\n                       encoding=None):\n        \"\"\"\n        Called when a file has been refactored and there may be changes.\n        \"\"\"\n        self.files.append(filename)\n        if old_text is None:\n            old_text = self._read_python_source(filename)[0]\n            if old_text is None:\n                return\n        equal = old_text == new_text\n        self.print_output(old_text, new_text, filename, equal)\n        if equal:\n            self.log_debug(\"No changes to %s\", filename)\n            if not self.write_unchanged_files:\n                return\n        if write:\n            self.write_file(new_text, filename, old_text, encoding)\n        else:\n            self.log_debug(\"Not writing changes to %s\", filename)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_file(self, new_text, filename, old_text, encoding=None):\n        try:\n            f = _open_with_encoding(filename, \"w\", encoding=encoding)\n        except os.error as err:\n            self.log_error(\"Can't create %s: %s\", filename, err)\n            return\n        try:\n            f.write(_to_system_newlines(new_text))\n        except os.error as err:\n            self.log_error(\"Can't write %s: %s\", filename, err)\n        finally:\n            f.close()\n        self.log_debug(\"Wrote changes to %s\", filename)\n        self.wrote = True", "response": "Writes a string to a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef refactor_docstring(self, input, filename):\n        result = []\n        block = None\n        block_lineno = None\n        indent = None\n        lineno = 0\n        for line in input.splitlines(True):\n            lineno += 1\n            if line.lstrip().startswith(self.PS1):\n                if block is not None:\n                    result.extend(self.refactor_doctest(block, block_lineno,\n                                                        indent, filename))\n                block_lineno = lineno\n                block = [line]\n                i = line.find(self.PS1)\n                indent = line[:i]\n            elif (indent is not None and\n                  (line.startswith(indent + self.PS2) or\n                   line == indent + self.PS2.rstrip() + u\"\\n\")):\n                block.append(line)\n            else:\n                if block is not None:\n                    result.extend(self.refactor_doctest(block, block_lineno,\n                                                        indent, filename))\n                block = None\n                indent = None\n                result.append(line)\n        if block is not None:\n            result.extend(self.refactor_doctest(block, block_lineno,\n                                                indent, filename))\n        return u\"\".join(result)", "response": "Refactors a docstring by looking for doctests. This returns a modified version of the input string."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a block into a tree.", "response": "def parse_block(self, block, lineno, indent):\n        \"\"\"Parses a block into a tree.\n\n        This is necessary to get correct line number / offset information\n        in the parser diagnostics and embedded into the parse tree.\n        \"\"\"\n        tree = self.driver.parse_tokens(self.wrap_toks(block, lineno, indent))\n        tree.future_features = frozenset()\n        return tree"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wrap_toks(self, block, lineno, indent):\n        tokens = tokenize.generate_tokens(self.gen_lines(block, indent).next)\n        for type, value, (line0, col0), (line1, col1), line_text in tokens:\n            line0 += lineno - 1\n            line1 += lineno - 1\n            # Don't bother updating the columns; this is too complicated\n            # since line_text would also have to be updated and it would\n            # still break for tokens spanning lines.  Let the user guess\n            # that the column numbers for doctests are relative to the\n            # end of the prompt string (PS1 or PS2).\n            yield type, value, (line0, col0), (line1, col1), line_text", "response": "Wraps a tokenize stream to systematically modify start and end."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating lines as expected by tokenize from a list of lines.", "response": "def gen_lines(self, block, indent):\n        \"\"\"Generates lines as expected by tokenize from a list of lines.\n\n        This strips the first len(indent + self.PS1) characters off each line.\n        \"\"\"\n        prefix1 = indent + self.PS1\n        prefix2 = indent + self.PS2\n        prefix = prefix1\n        for line in block:\n            if line.startswith(prefix):\n                yield line[len(prefix):]\n            elif line == prefix.rstrip() + u\"\\n\":\n                yield u\"\\n\"\n            else:\n                raise AssertionError(\"line=%r, prefix=%r\" % (line, prefix))\n            prefix = prefix2\n        while True:\n            yield \"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef frame_vars_to_xml(frame_f_locals, hidden_ns=None):\n    xml = \"\"\n\n    keys = dict_keys(frame_f_locals)\n    if hasattr(keys, 'sort'):\n        keys.sort()  # Python 3.0 does not have it\n    else:\n        keys = sorted(keys)  # Jython 2.1 does not have it\n\n    return_values_xml = ''\n\n    for k in keys:\n        try:\n            v = frame_f_locals[k]\n            eval_full_val = should_evaluate_full_value(v)\n\n            if k == RETURN_VALUES_DICT:\n                for name, val in dict_iter_items(v):\n                    return_values_xml += var_to_xml(val, name, additional_in_xml=' isRetVal=\"True\"')\n\n            else:\n                if hidden_ns is not None and k in hidden_ns:\n                    xml += var_to_xml(v, str(k), additional_in_xml=' isIPythonHidden=\"True\"',\n                                      evaluate_full_value=eval_full_val)\n                else:\n                    xml += var_to_xml(v, str(k), evaluate_full_value=eval_full_val)\n        except Exception:\n            pydev_log.exception(\"Unexpected error, recovered safely.\")\n\n    # Show return values as the first entry.\n    return return_values_xml + xml", "response": "dumps frame variables to XML"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef var_to_xml(val, name, trim_if_too_big=True, additional_in_xml='', evaluate_full_value=True):\n\n    type_name, type_qualifier, is_exception_on_eval, resolver, value = get_variable_details(\n        val, evaluate_full_value)\n\n    try:\n        name = quote(name, '/>_= ')  # TODO: Fix PY-5834 without using quote\n    except:\n        pass\n\n    xml = '<var name=\"%s\" type=\"%s\" ' % (make_valid_xml_value(name), make_valid_xml_value(type_name))\n\n    if type_qualifier:\n        xml_qualifier = 'qualifier=\"%s\"' % make_valid_xml_value(type_qualifier)\n    else:\n        xml_qualifier = ''\n\n    if value:\n        # cannot be too big... communication may not handle it.\n        if len(value) > MAXIMUM_VARIABLE_REPRESENTATION_SIZE and trim_if_too_big:\n            value = value[0:MAXIMUM_VARIABLE_REPRESENTATION_SIZE]\n            value += '...'\n\n        xml_value = ' value=\"%s\"' % (make_valid_xml_value(quote(value, '/>_= ')))\n    else:\n        xml_value = ''\n\n    if is_exception_on_eval:\n        xml_container = ' isErrorOnEval=\"True\"'\n    else:\n        if resolver is not None:\n            xml_container = ' isContainer=\"True\"'\n        else:\n            xml_container = ''\n\n    return ''.join((xml, xml_qualifier, xml_value, xml_container, additional_in_xml, ' />\\n'))", "response": "converts a single variable or dictionary to xml representation"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do(self, arg):\n    \".exploitable - Determine the approximate exploitability rating\"\n\n    from winappdbg import Crash\n\n    event = self.debug.lastEvent\n    crash = Crash(event)\n    crash.fetch_extra_data(event)\n\n    status, rule, description = crash.isExploitable()\n\n    print \"-\" * 79\n    print \"Exploitability: %s\" % status\n    print \"Matched rule:   %s\" % rule\n    print \"Description:    %s\" % description\n    print \"-\" * 79", "response": ". exploitable - Determine the approximate exploitability rating"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncleaning up the internal state of the object.", "response": "def _cleanup(self):\n        \"\"\"\n        Frees lots of non-textual information, such as the fonts\n        and images and the objects that were needed to parse the\n        PDF.\n        \"\"\"\n        self.device = None\n        self.doc = None\n        self.parser = None\n        self.resmgr = None\n        self.interpreter = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef text(self, clean=True):\n        if clean:\n            return utils.normalise_whitespace(''.join(self).replace('\\n', ' '))\n        else:\n            return ''.join(self)", "response": "Returns the text of the PDF as a single string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef camelToSnake(s):\n    _underscorer1 = re.compile(r'(.)([A-Z][a-z]+)')\n    _underscorer2 = re.compile('([a-z0-9])([A-Z])')\n\n    subbed = _underscorer1.sub(r'\\1_\\2', s)\n    return _underscorer2.sub(r'\\1_\\2', subbed).lower()", "response": "Convert a string from camel case to snake case."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_app_name(app_name):\n    type_ = locate(app_name)\n    if inspect.isclass(type_):\n        return type_.name\n    return app_name", "response": "Returns a new app name from a new app config if is\n    a class or the same app name if is\n    a class or the same app name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if a user has any of the given roles.", "response": "def has_role(user, roles):\n    \"\"\"Check if a user has any of the given roles.\"\"\"\n    if user and user.is_superuser:\n        return True\n\n    if not isinstance(roles, list):\n        roles = [roles]\n\n    normalized_roles = []\n    for role in roles:\n        if not inspect.isclass(role):\n            role = RolesManager.retrieve_role(role)\n\n        normalized_roles.append(role)\n\n    user_roles = get_user_roles(user)\n\n    return any([role in user_roles for role in normalized_roles])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_permission(user, permission_name):\n    if user and user.is_superuser:\n        return True\n\n    return permission_name in available_perm_names(user)", "response": "Check if a user has a given permission."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if a user has permission to perform an action on an object.", "response": "def has_object_permission(checker_name, user, obj):\n    \"\"\"Check if a user has permission to perform an action on an object.\"\"\"\n    if user and user.is_superuser:\n        return True\n\n    checker = PermissionsManager.retrieve_checker(checker_name)\n    user_roles = get_user_roles(user)\n\n    if not user_roles:\n        user_roles = [None]\n\n    return any([checker(user_role, user, obj) for user_role in user_roles])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a Permission object from a permission name.", "response": "def get_or_create_permission(codename, name=camel_or_snake_to_title):\n    \"\"\"\n    Get a Permission object from a permission name.\n    @:param codename: permission code name\n    @:param name: human-readable permissions name (str) or callable that takes codename as\n                  argument and returns str\n    \"\"\"\n    user_ct = ContentType.objects.get_for_model(get_user_model())\n    return Permission.objects.get_or_create(content_type=user_ct, codename=codename,\n                                            defaults={'name': name(codename) if callable(name) else name})"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_user_roles(user):\n    if user:\n        groups = user.groups.all()   # Important! all() query may be cached on User with prefetch_related.\n        roles = (RolesManager.retrieve_role(group.name) for group in groups if group.name in RolesManager.get_roles_names())\n        return sorted(roles, key=lambda r: r.get_name() )\n    else:\n        return []", "response": "Get a list of a users s roles."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear_roles(user):\n    roles = get_user_roles(user)\n\n    for role in roles:\n        role.remove_role_from_user(user)\n\n    return roles", "response": "Remove all roles from a user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef available_perm_status(user):\n    roles = get_user_roles(user)\n    permission_hash = {}\n\n    for role in roles:\n        permission_names = role.permission_names_list()\n\n        for permission_name in permission_names:\n            permission_hash[permission_name] = get_permission(\n                permission_name) in user.user_permissions.all()\n\n    return permission_hash", "response": "Get a boolean map of the permissions available to a user\n    based on that user s roles."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of codenames available to a user based on that user s roles.", "response": "def available_perm_names(user):\n    \"\"\"\n    Return a list of permissions codenames available to a user, based on that user's roles.\n      i.e., keys for all \"True\" permissions from available_perm_status(user):\n       Assert: set(available_perm_names(user)) == set(perm for perm,has_perm in available_perm_status(user) if has_perm)\n       Query efficient; especially when prefetch_related('group', 'user_permissions') on user object.\n       No side-effects; permissions are not created in DB as side-effect.\n    \"\"\"\n    roles = get_user_roles(user)\n    perm_names = set(p for role in roles for p in role.permission_names_list())\n    return [p.codename for p in user.user_permissions.all() if p.codename in perm_names] \\\n                                                                        if roles else []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngrant a permission to a user.", "response": "def grant_permission(user, permission_name):\n    \"\"\"\n    Grant a user a specified permission.\n\n    Permissions are only granted if they are in the scope any of the\n    user's roles. If the permission is out of scope,\n    a RolePermissionScopeException is raised.\n    \"\"\"\n    roles = get_user_roles(user)\n\n    for role in roles:\n        if permission_name in role.permission_names_list():\n            permission = get_permission(permission_name)\n            user.user_permissions.add(permission)\n            return\n\n    raise RolePermissionScopeException(\n        \"This permission isn't in the scope of \"\n        \"any of this user's roles.\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrevoke a specified permission from a user.", "response": "def revoke_permission(user, permission_name):\n    \"\"\"\n    Revoke a specified permission from a user.\n\n    Permissions are only revoked if they are in the scope any of the user's\n    roles. If the permission is out of scope, a RolePermissionScopeException\n    is raised.\n    \"\"\"\n    roles = get_user_roles(user)\n\n    for role in roles:\n        if permission_name in role.permission_names_list():\n            permission = get_permission(permission_name)\n            user.user_permissions.remove(permission)\n            return\n\n    raise RolePermissionScopeException(\n        \"This permission isn't in the scope of \"\n        \"any of this user's roles.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fetch_data(dataset_name, return_X_y=False, local_cache_dir=None):\n    if dataset_name in classification_dataset_names:\n        data_type = 'classification'\n    elif dataset_name in regression_dataset_names:\n        data_type = 'regression'\n    else:\n        raise ValueError('Dataset not found in PMLB.')\n\n    dataset_url = '{GITHUB_URL}/{DATA_TYPE}/{DATASET_NAME}/{DATASET_NAME}{SUFFIX}'.format(\n                                GITHUB_URL=GITHUB_URL,\n                                DATA_TYPE=data_type,\n                                DATASET_NAME=dataset_name,\n                                SUFFIX=suffix\n                                )\n\n    if local_cache_dir is None:\n        dataset = pd.read_csv(dataset_url, sep='\\t', compression='gzip')\n    else:\n        dataset_path = os.path.join(local_cache_dir, dataset_name) + suffix\n\n        # Use the local cache if the file already exists there\n        if os.path.exists(dataset_path):\n            dataset = pd.read_csv(dataset_path, sep='\\t', compression='gzip')\n        # Download the data to the local cache if it is not already there\n        else:\n            dataset = pd.read_csv(dataset_url, sep='\\t', compression='gzip')\n            dataset.to_csv(dataset_path, sep='\\t', compression='gzip', index=False)\n\n    if return_X_y:\n        X = dataset.drop('target', axis=1).values\n        y = dataset['target'].values\n        return (X, y)\n    else:\n        return dataset", "response": "Download a data set from the PMLB store it locally and return the data set."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute imbalance metric for a given dataset.", "response": "def imbalance_metrics(data):\n    \"\"\" Computes imbalance metric for a given dataset. \n    Imbalance metric is equal to 0 when a dataset is perfectly balanced (i.e. number of in each class is exact).\n    :param data : pandas.DataFrame \n        A dataset in a panda's data frame\n    :returns int \n        A value of imbalance metric, where zero means that the dataset is perfectly balanced and the higher the value, the more imbalanced the dataset.\n    \"\"\"\n    if not data:\n        return 0\n    #imb - shows measure of inbalance within a dataset\n    imb = 0 \n    num_classes=float(len(Counter(data)))\n    for x in Counter(data).values():\n        p_x = float(x)/len(data)\n        if p_x > 0:\n            imb += (p_x - 1/num_classes)*(p_x - 1/num_classes)\n    #worst case scenario: all but 1 examplars in 1st class, the remaining one in 2nd class\n    worst_case=(num_classes-1)*pow(1/num_classes,2) + pow(1-1/num_classes,2)\n    return (num_classes,imb/worst_case)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine the type of an endpoint by parsing the data frame.", "response": "def determine_endpoint_type(features):\n    \"\"\" Determines the type of an endpoint\n    :param features: pandas.DataFrame\n        A dataset in a panda's data frame\n    :returns string\n        string with a name of a dataset\n    \"\"\"    \n    counter={k.name: v for k, v in features.columns.to_series().groupby(features.dtypes).groups.items()}\n    if(len(features.groupby('class').apply(list))==2):\n        return('binary')\n    if ('float64' in counter):\n        return ('float')\n    return ('integer')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef count_features_type(features):\n    counter={k.name: v for k, v in features.columns.to_series().groupby(features.dtypes)}\n    binary=0\n    if ('int64' in counter):\n        binary=len(set(features.loc[:, (features<=1).all(axis=0)].columns.values) \n                & set(features.loc[:, (features>=0).all(axis=0)].columns.values) \n                & set(counter['int64']))    \n    return (binary,len(counter['int64'])-binary if 'int64' in counter else 0,len(counter['float64']) if 'float64' in counter else 0)", "response": "Counts the number of features in a panda s data frame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_description(dataset_name, local_cache_dir=None):\n    \n    assert (local_cache_dir!=None)\n    readme_file = open(os.path.join(local_cache_dir,'datasets',dataset_name,'README.md'), 'wt')\n    try:\n        df = fetch_data(dataset_name)\n        fnames = [col for col in df.columns if col!='class']\n        #determine all required values\n        types = get_types(df.ix[:, df.columns != 'class'])\n        feat=count_features_type(df.ix[:, df.columns != 'class'])\n        endpoint=determine_endpoint_type(df.ix[:, df.columns == 'class'])\n        mse=imbalance_metrics(df['class'].tolist())\n        #proceed with writing\n        readme_file.write('# %s\\n\\n' % dataset_name)\n        readme_file.write('## Summary Stats\\n\\n')\n        readme_file.write('#instances: %s\\n\\n' % str(len(df.axes[0])))\n        readme_file.write(\"#features: %s\\n\\n\" % str(len(df.axes[1])-1))\n        readme_file.write(\"  #binary_features: %s\\n\\n\" % feat[0])\n        readme_file.write(\"  #integer_features: %s\\n\\n\" % feat[1])\n        readme_file.write(\"  #float_features: %s\\n\\n\" % feat[2])\n        readme_file.write(\"Endpoint type: %s\\n\\n\" % endpoint)\n        readme_file.write(\"#Classes: %s\\n\\n\" % int(mse[0]))\n        readme_file.write(\"Imbalance metric: %s\\n\\n\" % mse[1])\n        readme_file.write('## Feature Types\\n\\n %s\\n\\n' % '\\n\\n'.join([f + ':' + t for f,t in\n                                                              zip(fnames,types)]))\n\n    except IOError as err:\n        print(err)\n    finally:\n        readme_file.close()", "response": "Generates a description of a given dataset in its README. md file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a summary report for all datasets in PMLB", "response": "def generate_pmlb_summary(local_cache_dir=None):\n    \"\"\"Generates a summary report for all dataset in PMLB\n    :param local_cache_dir: str (required)\n        The directory on your local machine to store the data files.\n    \"\"\"\n    report_filename = open(os.path.join(local_cache_dir, 'report.csv'), 'wt')\n    assert (local_cache_dir!=None)\n    try:\n        writer = csv.writer(report_filename, delimiter='\\t')\n        writer.writerow(['Dataset','#instances','#features','#binary_features','#integer_features','#float_features',\\\n                     'Endpoint_type','#classes','Imbalance_metric'])\n\n        for dataset in dataset_names:\n            df=fetch_data(dataset)\n            print( \"Dataset:\", dataset)\n            assert 'class' in df.columns, \"no class column\"\n            #removing class column\n            print( \"SIZE: \"+ str(len(df.axes[0]))+ \" x \" + str(len(df.axes[1])-1))\n            feat=count_features_type(df.ix[:, df.columns != 'class'])\n            endpoint=determine_endpoint_type(df.ix[:, df.columns == 'class'])\n            mse=imbalance_metrics(df['class'].tolist())\n            #writer.writerow([file,str(len(df.axes[0])),str(len(df.axes[1])-1),feat[0],feat[1],feat[2],endpoint,mse[0],mse[1],mse[2]])\n            writer.writerow([dataset,str(len(df.axes[0])),str(len(df.axes[1])-1),feat[0],feat[1],feat[2],endpoint,int(mse[0]),mse[1]])\n    finally:\n        report_filename.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntargeting the url to receive the payload. payload: a python primitive data structure instance: a possibly null \"trigger\" instance hook: the defining Hook object (useful for removing)", "response": "def run(self, target, payload, instance=None, hook_id=None, **kwargs):\n        \"\"\"\n        target:     the url to receive the payload.\n        payload:    a python primitive data structure\n        instance:   a possibly null \"trigger\" instance\n        hook:       the defining Hook object (useful for removing)\n        \"\"\"\n        response = requests.post(\n            url=target,\n            data=json.dumps(payload, cls=DjangoJSONEncoder),\n            headers={'Content-Type': 'application/json'}\n        )\n\n        if response.status_code == 410 and hook_id:\n            HookModel = get_hook_model()\n            hook = HookModel.object.get(id=hook_id)\n            hook.delete()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef model_saved(sender, instance,\n                        created,\n                        raw,\n                        using,\n                        **kwargs):\n    \"\"\"\n    Automatically triggers \"created\" and \"updated\" actions.\n    \"\"\"\n    opts = get_opts(instance)\n    model = '.'.join([opts.app_label, opts.object_name])\n    action = 'created' if created else 'updated'\n    distill_model_event(instance, model, action)", "response": "Called when a new object is saved."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef custom_action(sender, action,\n                          instance,\n                          user=None,\n                          **kwargs):\n    \"\"\"\n    Manually trigger a custom action (or even a standard action).\n    \"\"\"\n    opts = get_opts(instance)\n    model = '.'.join([opts.app_label, opts.object_name])\n    distill_model_event(instance, model, action, user_override=user)", "response": "Trigger a custom action or even a standard action."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef raw_custom_event(sender, event_name,\n                             payload,\n                             user,\n                             send_hook_meta=True,\n                             instance=None,\n                             **kwargs):\n    \"\"\"\n    Give a full payload\n    \"\"\"\n    HookModel = get_hook_model()\n    hooks = HookModel.objects.filter(user=user, event=event_name)\n\n    for hook in hooks:\n        new_payload = payload\n        if send_hook_meta:\n            new_payload = {\n                'hook': hook.dict(),\n                'data': payload\n            }\n\n        hook.deliver_hook(instance, payload_override=new_payload)", "response": "Send a custom event to all the hooks that have been delivered."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clean(self):\n        if self.event not in HOOK_EVENTS.keys():\n            raise ValidationError(\n                \"Invalid hook event {evt}.\".format(evt=self.event)\n            )", "response": "Validate that the hook event is valid."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef serialize_hook(self, instance):\n        if getattr(instance, 'serialize_hook', None) and callable(instance.serialize_hook):\n            return instance.serialize_hook(hook=self)\n        if getattr(settings, 'HOOK_SERIALIZER', None):\n            serializer = get_module(settings.HOOK_SERIALIZER)\n            return serializer(instance, hook=self)\n        # if no user defined serializers, fallback to the django builtin!\n        data = serializers.serialize('python', [instance])[0]\n        for k, v in data.items():\n            if isinstance(v, OrderedDict):\n                data[k] = dict(v)\n\n        if isinstance(data, OrderedDict):\n            data = dict(data)\n\n        return {\n            'hook': self.dict(),\n            'data': data,\n        }", "response": "Serialize the object down to Python primitives."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndelivers the payload to the target URL.", "response": "def deliver_hook(self, instance, payload_override=None):\n        \"\"\"\n        Deliver the payload to the target URL.\n\n        By default it serializes to JSON and POSTs.\n        \"\"\"\n        payload = payload_override or self.serialize_hook(instance)\n        if getattr(settings, 'HOOK_DELIVERER', None):\n            deliverer = get_module(settings.HOOK_DELIVERER)\n            deliverer(self.target, payload, instance=instance, hook=self)\n        else:\n            client.post(\n                url=self.target,\n                data=json.dumps(payload, cls=DjangoJSONEncoder),\n                headers={'Content-Type': 'application/json'}\n            )\n\n        signals.hook_sent_event.send_robust(sender=self.__class__, payload=payload, instance=instance, hook=self)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a module object from a path.", "response": "def get_module(path):\n    \"\"\"\n    A modified duplicate from Django's built in backend\n    retriever.\n\n        slugify = get_module('django.template.defaultfilters.slugify')\n    \"\"\"\n    try:\n        from importlib import import_module\n    except ImportError as e:\n        from django.utils.importlib import import_module\n\n    try:\n        mod_name, func_name = path.rsplit('.', 1)\n        mod = import_module(mod_name)\n    except ImportError as e:\n        raise ImportError(\n            'Error importing alert function {0}: \"{1}\"'.format(mod_name, e))\n\n    try:\n        func = getattr(mod, func_name)\n    except AttributeError:\n        raise ImportError(\n            ('Module \"{0}\" does not define a \"{1}\" function'\n                            ).format(mod_name, func_name))\n\n    return func"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_hook_model():\n    from rest_hooks.models import Hook\n    HookModel = Hook\n    if getattr(settings, 'HOOK_CUSTOM_MODEL', None):\n        HookModel = get_module(settings.HOOK_CUSTOM_MODEL)\n    return HookModel", "response": "Returns the custom Hook model if defined in settings otherwise the default Hook model."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind and fire a specific hook for a specific event.", "response": "def find_and_fire_hook(event_name, instance, user_override=None):\n    \"\"\"\n    Look up Hooks that apply\n    \"\"\"\n    try:\n        from django.contrib.auth import get_user_model\n        User = get_user_model()\n    except ImportError:\n        from django.contrib.auth.models import User\n    from rest_hooks.models import HOOK_EVENTS\n\n    if not event_name in HOOK_EVENTS.keys():\n        raise Exception(\n            '\"{}\" does not exist in `settings.HOOK_EVENTS`.'.format(event_name)\n        )\n\n    filters = {'event': event_name}\n\n    # Ignore the user if the user_override is False\n    if user_override is not False:\n        if user_override:\n            filters['user'] = user_override\n        elif hasattr(instance, 'user'):\n            filters['user'] = instance.user\n        elif isinstance(instance, User):\n            filters['user'] = instance\n        else:\n            raise Exception(\n                '{} has no `user` property. REST Hooks needs this.'.format(repr(instance))\n            )\n    # NOTE: This is probably up for discussion, but I think, in this\n    # case, instead of raising an error, we should fire the hook for\n    # all users/accounts it is subscribed to. That would be a genuine\n    # usecase rather than erroring because no user is associated with\n    # this event.\n\n    HookModel = get_hook_model()\n\n    hooks = HookModel.objects.filter(**filters)\n    for hook in hooks:\n        hook.deliver_hook(instance)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef distill_model_event(instance, model, action, user_override=None):\n    from rest_hooks.models import HOOK_EVENTS\n\n    event_name = None\n    for maybe_event_name, auto in HOOK_EVENTS.items():\n        if auto:\n            # break auto into App.Model, Action\n            maybe_model, maybe_action = auto.rsplit('.', 1)\n            maybe_action = maybe_action.rsplit('+', 1)\n            if model == maybe_model and action == maybe_action[0]:\n                event_name = maybe_event_name\n                if len(maybe_action) == 2:\n                    user_override = False\n\n    if event_name:\n        finder = find_and_fire_hook\n        if getattr(settings, 'HOOK_FINDER', None):\n            finder = get_module(settings.HOOK_FINDER)\n        finder(event_name, instance, user_override=user_override)", "response": "Distills an event from a model to a specific action."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting plot data out of an input object.", "response": "def _get_plot_data(data, ndim=None):\n    \"\"\"Get plot data out of an input object\n\n    Parameters\n    ----------\n    data : array-like, `phate.PHATE` or `scanpy.AnnData`\n    ndim : int, optional (default: None)\n        Minimum number of dimensions\n    \"\"\"\n    out = data\n    if isinstance(data, PHATE):\n        out = data.transform()\n    else:\n        try:\n            if isinstance(data, anndata.AnnData):\n                try:\n                    out = data.obsm['X_phate']\n                except KeyError:\n                    raise RuntimeError(\n                        \"data.obsm['X_phate'] not found. \"\n                        \"Please run `sc.tl.phate(adata)` before plotting.\")\n        except NameError:\n            # anndata not installed\n            pass\n    if ndim is not None and out[0].shape[0] < ndim:\n        if isinstance(data, PHATE):\n            data.set_params(n_components=ndim)\n            out = data.transform()\n        else:\n            raise ValueError(\n                \"Expected at least {}-dimensional data, got {}\".format(\n                    ndim, out[0].shape[0]))\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a scatter plot of the key - term store.", "response": "def scatter(x, y, z=None,\n            c=None, cmap=None, s=None, discrete=None,\n            ax=None, legend=None, figsize=None,\n            xticks=False,\n            yticks=False,\n            zticks=False,\n            xticklabels=True,\n            yticklabels=True,\n            zticklabels=True,\n            label_prefix=\"PHATE\",\n            xlabel=None,\n            ylabel=None,\n            zlabel=None,\n            title=None,\n            legend_title=\"\",\n            legend_loc='best',\n            filename=None,\n            dpi=None,\n            **plot_kwargs):\n    \"\"\"Create a scatter plot\n\n    Builds upon `matplotlib.pyplot.scatter` with nice defaults\n    and handles categorical colors / legends better. For easy access, use\n    `scatter2d` or `scatter3d`.\n\n    Parameters\n    ----------\n    x : list-like\n        data for x axis\n    y : list-like\n        data for y axis\n    z : list-like, optional (default: None)\n        data for z axis\n    c : list-like or None, optional (default: None)\n        Color vector. Can be a single color value (RGB, RGBA, or named\n        matplotlib colors), an array of these of length n_samples, or a list of\n        discrete or continuous values of any data type. If `c` is not a single\n        or list of matplotlib colors, the values in `c` will be used to\n        populate the legend / colorbar with colors from `cmap`\n    cmap : `matplotlib` colormap, str, dict or None, optional (default: None)\n        matplotlib colormap. If None, uses `tab20` for discrete data and\n        `inferno` for continuous data. If a dictionary, expects one key\n        for every unique value in `c`, where values are valid matplotlib colors\n        (hsv, rbg, rgba, or named colors)\n    s : float, optional (default: 1)\n        Point size.\n    discrete : bool or None, optional (default: None)\n        If True, the legend is categorical. If False, the legend is a colorbar.\n        If None, discreteness is detected automatically. Data containing\n        non-numeric `c` is always discrete, and numeric data with 20 or less\n        unique values is discrete.\n    ax : `matplotlib.Axes` or None, optional (default: None)\n        axis on which to plot. If None, an axis is created\n    legend : bool, optional (default: True)\n        States whether or not to create a legend. If data is continuous,\n        the legend is a colorbar.\n    figsize : tuple, optional (default: None)\n        Tuple of floats for creation of new `matplotlib` figure. Only used if\n        `ax` is None.\n    xticks : True, False, or list-like (default: False)\n        If True, keeps default x ticks. If False, removes x ticks.\n        If a list, sets custom x ticks\n    yticks : True, False, or list-like (default: False)\n        If True, keeps default y ticks. If False, removes y ticks.\n        If a list, sets custom y ticks\n    zticks : True, False, or list-like (default: False)\n        If True, keeps default z ticks. If False, removes z ticks.\n        If a list, sets custom z ticks.  Only used for 3D plots.\n    xticklabels : True, False, or list-like (default: True)\n        If True, keeps default x tick labels. If False, removes x tick labels.\n        If a list, sets custom x tick labels\n    yticklabels : True, False, or list-like (default: True)\n        If True, keeps default y tick labels. If False, removes y tick labels.\n        If a list, sets custom y tick labels\n    zticklabels : True, False, or list-like (default: True)\n        If True, keeps default z tick labels. If False, removes z tick labels.\n        If a list, sets custom z tick labels. Only used for 3D plots.\n    label_prefix : str or None (default: \"PHATE\")\n        Prefix for all axis labels. Axes will be labelled `label_prefix`1,\n        `label_prefix`2, etc. Can be overriden by setting `xlabel`,\n        `ylabel`, and `zlabel`.\n    xlabel : str or None (default : None)\n        Label for the x axis. Overrides the automatic label given by\n        label_prefix. If None and label_prefix is None, no label is set.\n    ylabel : str or None (default : None)\n        Label for the y axis. Overrides the automatic label given by\n        label_prefix. If None and label_prefix is None, no label is set.\n    zlabel : str or None (default : None)\n        Label for the z axis. Overrides the automatic label given by\n        label_prefix. If None and label_prefix is None, no label is set.\n        Only used for 3D plots.\n    title : str or None (default: None)\n        axis title. If None, no title is set.\n    legend_title : str (default: \"\")\n        title for the colorbar of legend. Only used for discrete data.\n    legend_loc : int or string or pair of floats, default: 'best'\n        Matplotlib legend location. Only used for discrete data.\n        See <https://matplotlib.org/api/_as_gen/matplotlib.pyplot.legend.html>\n        for details.\n    filename : str or None (default: None)\n        file to which the output is saved\n    dpi : int or None, optional (default: None)\n        The resolution in dots per inch. If None it will default to the value\n        savefig.dpi in the matplotlibrc file. If 'figure' it will set the dpi\n        to be the value of the figure. Only used if filename is not None.\n    **plot_kwargs : keyword arguments\n        Extra arguments passed to `matplotlib.pyplot.scatter`.\n\n    Returns\n    -------\n    ax : `matplotlib.Axes`\n        axis on which plot was drawn\n\n    Examples\n    --------\n    >>> import phate\n    >>> import matplotlib.pyplot as plt\n    >>> ###\n    >>> # Running PHATE\n    >>> ###\n    >>> tree_data, tree_clusters = phate.tree.gen_dla(n_dim=100, n_branch=20,\n    ...                                               branch_length=100)\n    >>> tree_data.shape\n    (2000, 100)\n    >>> phate_operator = phate.PHATE(k=5, a=20, t=150)\n    >>> tree_phate = phate_operator.fit_transform(tree_data)\n    >>> tree_phate.shape\n    (2000, 2)\n    >>> ###\n    >>> # Plotting using phate.plot\n    >>> ###\n    >>> phate.plot.scatter2d(tree_phate, c=tree_clusters)\n    >>> # You can also pass the PHATE operator instead of data\n    >>> phate.plot.scatter2d(phate_operator, c=tree_clusters)\n    >>> phate.plot.scatter3d(phate_operator, c=tree_clusters)\n    >>> ###\n    >>> # Using a cmap dictionary\n    >>> ###\n    >>> import numpy as np\n    >>> X = np.random.normal(0,1,[1000,2])\n    >>> c = np.random.choice(['a','b'], 1000, replace=True)\n    >>> X[c=='a'] += 10\n    >>> phate.plot.scatter2d(X, c=c, cmap={'a' : [1,0,0,1], 'b' : 'xkcd:sky blue'})\n    \"\"\"\n    warnings.warn(\"`phate.plot.scatter` is deprecated. \"\n                  \"Use `scprep.plot.scatter` instead.\",\n                  FutureWarning)\n    return scprep.plot.scatter(x=x, y=y, z=z,\n                               c=c, cmap=cmap, s=s, discrete=discrete,\n                               ax=ax, legend=legend, figsize=figsize,\n                               xticks=xticks,\n                               yticks=yticks,\n                               zticks=zticks,\n                               xticklabels=xticklabels,\n                               yticklabels=yticklabels,\n                               zticklabels=zticklabels,\n                               label_prefix=label_prefix,\n                               xlabel=xlabel,\n                               ylabel=ylabel,\n                               zlabel=zlabel,\n                               title=title,\n                               legend_title=legend_title,\n                               legend_loc=legend_loc,\n                               filename=filename,\n                               dpi=dpi,\n                               **plot_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scatter2d(data, **kwargs):\n    warnings.warn(\"`phate.plot.scatter2d` is deprecated. \"\n                  \"Use `scprep.plot.scatter2d` instead.\",\n                  FutureWarning)\n    data = _get_plot_data(data, ndim=2)\n    return scprep.plot.scatter2d(data, **kwargs)", "response": "Create a 2D scatter plot of the current key - store."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a 3D scatter plot with nice defaults and handles categorical colors and legends better.", "response": "def rotate_scatter3d(data,\n                     filename=None,\n                     elev=30,\n                     rotation_speed=30,\n                     fps=10,\n                     ax=None,\n                     figsize=None,\n                     dpi=None,\n                     ipython_html=\"jshtml\",\n                     **kwargs):\n    \"\"\"Create a rotating 3D scatter plot\n\n    Builds upon `matplotlib.pyplot.scatter` with nice defaults\n    and handles categorical colors / legends better.\n\n    Parameters\n    ----------\n    data : array-like, `phate.PHATE` or `scanpy.AnnData`\n        Input data. Only the first three dimensions are used.\n    filename : str, optional (default: None)\n        If not None, saves a .gif or .mp4 with the output\n    elev : float, optional (default: 30)\n        Elevation of viewpoint from horizontal, in degrees\n    rotation_speed : float, optional (default: 30)\n        Speed of axis rotation, in degrees per second\n    fps : int, optional (default: 10)\n        Frames per second. Increase this for a smoother animation\n    ax : `matplotlib.Axes` or None, optional (default: None)\n        axis on which to plot. If None, an axis is created\n    figsize : tuple, optional (default: None)\n        Tuple of floats for creation of new `matplotlib` figure. Only used if\n        `ax` is None.\n    dpi : number, optional (default: None)\n        Controls the dots per inch for the movie frames. This combined with\n        the figure's size in inches controls the size of the movie.\n        If None, defaults to rcParams[\"savefig.dpi\"]\n    ipython_html : {'html5', 'jshtml'}\n        which html writer to use if using a Jupyter Notebook\n    **kwargs : keyword arguments\n        See :~func:`phate.plot.scatter3d`.\n\n    Returns\n    -------\n    ani : `matplotlib.animation.FuncAnimation`\n        animation object\n\n    Examples\n    --------\n    >>> import phate\n    >>> import matplotlib.pyplot as plt\n    >>> tree_data, tree_clusters = phate.tree.gen_dla(n_dim=100, n_branch=20,\n    ...                                               branch_length=100)\n    >>> tree_data.shape\n    (2000, 100)\n    >>> phate_operator = phate.PHATE(n_components=3, k=5, a=20, t=150)\n    >>> tree_phate = phate_operator.fit_transform(tree_data)\n    >>> tree_phate.shape\n    (2000, 2)\n    >>> phate.plot.rotate_scatter3d(tree_phate, c=tree_clusters)\n    \"\"\"\n    warnings.warn(\"`phate.plot.rotate_scatter3d` is deprecated. \"\n                  \"Use `scprep.plot.rotate_scatter3d` instead.\",\n                  FutureWarning)\n    return scprep.plot.rotate_scatter3d(data,\n                                        filename=filename,\n                                        elev=elev,\n                                        rotation_speed=rotation_speed,\n                                        fps=fps,\n                                        ax=ax,\n                                        figsize=figsize,\n                                        dpi=dpi,\n                                        ipython_html=ipython_html,\n                                        **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef kmeans(phate_op, k=8, random_state=None):\n    if phate_op.graph is not None:\n        diff_potential = phate_op.calculate_potential()\n        if isinstance(phate_op.graph, graphtools.graphs.LandmarkGraph):\n            diff_potential = phate_op.graph.interpolate(diff_potential)\n        return cluster.KMeans(k, random_state=random_state).fit_predict(diff_potential)\n    else:\n        raise exceptions.NotFittedError(\n            \"This PHATE instance is not fitted yet. Call \"\n            \"'fit' with appropriate arguments before \"\n            \"using this method.\")", "response": "This method calculates the k - means of the given PHATE operator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfasting CMDS using random SVD", "response": "def cmdscale_fast(D, ndim):\n    \"\"\"Fast CMDS using random SVD\n\n    Parameters\n    ----------\n    D : array-like, input data [n_samples, n_dimensions]\n\n    ndim : int, number of dimensions in which to embed `D`\n\n    Returns\n    -------\n    Y : array-like, embedded data [n_sample, ndim]\n    \"\"\"\n    tasklogger.log_debug(\"Performing classic MDS on {} of shape {}...\".format(\n        type(D).__name__, D.shape))\n    D = D**2\n    D = D - D.mean(axis=0)[None, :]\n    D = D - D.mean(axis=1)[:, None]\n    pca = PCA(n_components=ndim, svd_solver='randomized')\n    Y = pca.fit_transform(D)\n    return Y"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef embed_MDS(X, ndim=2, how='metric', distance_metric='euclidean',\n              n_jobs=1, seed=None, verbose=0):\n    \"\"\"Performs classic, metric, and non-metric MDS\n\n    Metric MDS is initialized using classic MDS,\n    non-metric MDS is initialized using metric MDS.\n\n    Parameters\n    ----------\n    X: ndarray [n_samples, n_samples]\n        2 dimensional input data array with n_samples\n        embed_MDS does not check for matrix squareness,\n        but this is necessary for PHATE\n\n    n_dim : int, optional, default: 2\n        number of dimensions in which the data will be embedded\n\n    how : string, optional, default: 'classic'\n        choose from ['classic', 'metric', 'nonmetric']\n        which MDS algorithm is used for dimensionality reduction\n\n    distance_metric : string, optional, default: 'euclidean'\n        choose from ['cosine', 'euclidean']\n        distance metric for MDS\n\n    n_jobs : integer, optional, default: 1\n        The number of jobs to use for the computation.\n        If -1 all CPUs are used. If 1 is given, no parallel computing code is\n        used at all, which is useful for debugging.\n        For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. Thus for\n        n_jobs = -2, all CPUs but one are used\n\n    seed: integer or numpy.RandomState, optional\n        The generator used to initialize SMACOF (metric, nonmetric) MDS\n        If an integer is given, it fixes the seed\n        Defaults to the global numpy random number generator\n\n    Returns\n    -------\n    Y : ndarray [n_samples, n_dim]\n        low dimensional embedding of X using MDS\n    \"\"\"\n    if how not in ['classic', 'metric', 'nonmetric']:\n        raise ValueError(\"Allowable 'how' values for MDS: 'classic', \"\n                         \"'metric', or 'nonmetric'. \"\n                         \"'{}' was passed.\".format(how))\n\n    # MDS embeddings, each gives a different output.\n    X_dist = squareform(pdist(X, distance_metric))\n\n    # initialize all by CMDS\n    Y = cmdscale_fast(X_dist, ndim)\n    if how in ['metric', 'nonmetric']:\n        tasklogger.log_debug(\"Performing metric MDS on \"\n                             \"{} of shape {}...\".format(type(X_dist),\n                                                        X_dist.shape))\n        # Metric MDS from sklearn\n        Y, _ = smacof(X_dist, n_components=ndim, metric=True, max_iter=3000,\n                      eps=1e-6, random_state=seed, n_jobs=n_jobs,\n                      n_init=1, init=Y, verbose=verbose)\n    if how == 'nonmetric':\n        tasklogger.log_debug(\n            \"Performing non-metric MDS on \"\n            \"{} of shape {}...\".format(type(X_dist),\n                                       X_dist.shape))\n        # Nonmetric MDS from sklearn using metric MDS as an initialization\n        Y, _ = smacof(X_dist, n_components=ndim, metric=True, max_iter=3000,\n                      eps=1e-6, random_state=seed, n_jobs=n_jobs,\n                      n_init=1, init=Y, verbose=verbose)\n    return Y", "response": "Performs classic metric and non - metric MDS embedding of X using MDS."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the Von Neumann entropy of a data set.", "response": "def compute_von_neumann_entropy(data, t_max=100):\n    \"\"\"\n    Determines the Von Neumann entropy of data\n    at varying matrix powers. The user should select a value of t\n    around the \"knee\" of the entropy curve.\n\n    Parameters\n    ----------\n    t_max : int, default: 100\n        Maximum value of t to test\n\n    Returns\n    -------\n    entropy : array, shape=[t_max]\n        The entropy of the diffusion affinities for each value of t\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> import phate\n    >>> X = np.eye(10)\n    >>> X[0,0] = 5\n    >>> X[3,2] = 4\n    >>> h = phate.vne.compute_von_neumann_entropy(X)\n    >>> phate.vne.find_knee_point(h)\n    23\n\n    \"\"\"\n    _, eigenvalues, _ = svd(data)\n    entropy = []\n    eigenvalues_t = np.copy(eigenvalues)\n    for _ in range(t_max):\n        prob = eigenvalues_t / np.sum(eigenvalues_t)\n        prob = prob + np.finfo(float).eps\n        entropy.append(-np.sum(prob * np.log(prob)))\n        eigenvalues_t = eigenvalues_t * eigenvalues\n    entropy = np.array(entropy)\n\n    return np.array(entropy)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_knee_point(y, x=None):\n    try:\n        y.shape\n    except AttributeError:\n        y = np.array(y)\n\n    if len(y) < 3:\n        raise ValueError(\"Cannot find knee point on vector of length 3\")\n    elif len(y.shape) > 1:\n        raise ValueError(\"y must be 1-dimensional\")\n\n    if x is None:\n        x = np.arange(len(y))\n    else:\n        try:\n            x.shape\n        except AttributeError:\n            x = np.array(x)\n        if not x.shape == y.shape:\n            raise ValueError(\"x and y must be the same shape\")\n        else:\n            # ensure x is sorted float\n            idx = np.argsort(x)\n            x = x[idx]\n            y = y[idx]\n\n    n = np.arange(2, len(y) + 1).astype(np.float32)\n    # figure out the m and b (in the y=mx+b sense) for the \"left-of-knee\"\n    sigma_xy = np.cumsum(x * y)[1:]\n    sigma_x = np.cumsum(x)[1:]\n    sigma_y = np.cumsum(y)[1:]\n    sigma_xx = np.cumsum(x * x)[1:]\n    det = (n * sigma_xx - sigma_x * sigma_x)\n    mfwd = (n * sigma_xy - sigma_x * sigma_y) / det\n    bfwd = -(sigma_x * sigma_xy - sigma_xx * sigma_y) / det\n\n    # figure out the m and b (in the y=mx+b sense) for the \"right-of-knee\"\n    sigma_xy = np.cumsum(x[::-1] * y[::-1])[1:]\n    sigma_x = np.cumsum(x[::-1])[1:]\n    sigma_y = np.cumsum(y[::-1])[1:]\n    sigma_xx = np.cumsum(x[::-1] * x[::-1])[1:]\n    det = (n * sigma_xx - sigma_x * sigma_x)\n    mbck = ((n * sigma_xy - sigma_x * sigma_y) / det)[::-1]\n    bbck = (-(sigma_x * sigma_xy - sigma_xx * sigma_y) / det)[::-1]\n\n    # figure out the sum of per-point errors for left- and right- of-knee fits\n    error_curve = np.full_like(y, np.float('nan'))\n    for breakpt in np.arange(1, len(y) - 1):\n        delsfwd = (mfwd[breakpt - 1] * x[:breakpt + 1] +\n                   bfwd[breakpt - 1]) - y[:breakpt + 1]\n        delsbck = (mbck[breakpt - 1] * x[breakpt:] +\n                   bbck[breakpt - 1]) - y[breakpt:]\n\n        error_curve[breakpt] = np.sum(np.abs(delsfwd)) + \\\n            np.sum(np.abs(delsbck))\n\n    # find location of the min of the error curve\n    loc = np.argmin(error_curve[1:-1]) + 1\n    knee_point = x[loc]\n    return knee_point", "response": "Returns the x - location of a knee of curve y = f ( x )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_positive(**params):\n    for p in params:\n        if not isinstance(params[p], numbers.Number) or params[p] <= 0:\n            raise ValueError(\n                \"Expected {} > 0, got {}\".format(p, params[p]))", "response": "Check that the parameters are positive as expected\nWorkItem"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_int(**params):\n    for p in params:\n        if not isinstance(params[p], numbers.Integral):\n            raise ValueError(\n                \"Expected {} integer, got {}\".format(p, params[p]))", "response": "Checks that the parameters are integers as expected\nWorkItem Raises a ValueError if not"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns checks only if parameters are not equal to a specified value", "response": "def check_if_not(x, *checks, **params):\n    \"\"\"Run checks only if parameters are not equal to a specified value\n\n    Parameters\n    ----------\n\n    x : excepted value\n        Checks not run if parameters equal x\n\n    checks : function\n        Unnamed arguments, check functions to be run\n\n    params : object\n        Named arguments, parameters to be checked\n\n    Raises\n    ------\n    ValueError : unacceptable choice of parameters\n    \"\"\"\n    for p in params:\n        if params[p] is not x and params[p] != x:\n            [check(**{p: params[p]}) for check in checks]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if parameters are in a list of accepted values", "response": "def check_in(choices, **params):\n    \"\"\"Checks parameters are in a list of allowed parameters\n\n    Parameters\n    ----------\n\n    choices : array-like, accepted values\n\n    params : object\n        Named arguments, parameters to be checked\n\n    Raises\n    ------\n    ValueError : unacceptable choice of parameters\n    \"\"\"\n    for p in params:\n        if params[p] not in choices:\n            raise ValueError(\n                \"{} value {} not recognized. Choose from {}\".format(\n                    p, params[p], choices))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck that the parameters are in a specified range oment", "response": "def check_between(v_min, v_max, **params):\n    \"\"\"Checks parameters are in a specified range\n\n    Parameters\n    ----------\n\n    v_min : float, minimum allowed value (inclusive)\n\n    v_max : float, maximum allowed value (inclusive)\n\n    params : object\n        Named arguments, parameters to be checked\n\n    Raises\n    ------\n    ValueError : unacceptable choice of parameters\n    \"\"\"\n    for p in params:\n        if params[p] < v_min or params[p] > v_max:\n            raise ValueError(\"Expected {} between {} and {}, \"\n                             \"got {}\".format(p, v_min, v_max, params[p]))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if matrix X is equivalent with numpy scipy and pandas", "response": "def matrix_is_equivalent(X, Y):\n    \"\"\"\n    Checks matrix equivalence with numpy, scipy and pandas\n    \"\"\"\n    return X is Y or (isinstance(X, Y.__class__) and X.shape == Y.shape and\n                      np.sum((X != Y).sum()) == 0)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_params(self):\n        utils.check_positive(n_components=self.n_components,\n                             k=self.knn)\n        utils.check_int(n_components=self.n_components,\n                        k=self.knn,\n                        n_jobs=self.n_jobs)\n        utils.check_between(0, 1, gamma=self.gamma)\n        utils.check_if_not(None, utils.check_positive, a=self.decay)\n        utils.check_if_not(None, utils.check_positive, utils.check_int,\n                           n_landmark=self.n_landmark,\n                           n_pca=self.n_pca)\n        utils.check_if_not('auto', utils.check_positive, utils.check_int,\n                           t=self.t)\n        if not callable(self.knn_dist):\n            utils.check_in(['euclidean', 'precomputed', 'cosine',\n                            'correlation', 'cityblock', 'l1', 'l2',\n                            'manhattan', 'braycurtis', 'canberra',\n                            'chebyshev', 'dice', 'hamming', 'jaccard',\n                            'kulsinski', 'mahalanobis', 'matching',\n                            'minkowski', 'rogerstanimoto', 'russellrao',\n                            'seuclidean', 'sokalmichener', 'sokalsneath',\n                            'sqeuclidean', 'yule',\n                            'precomputed_affinity', 'precomputed_distance'],\n                           knn_dist=self.knn_dist)\n        if not callable(self.mds_dist):\n            utils.check_in(['euclidean', 'cosine', 'correlation', 'braycurtis',\n                            'canberra', 'chebyshev', 'cityblock', 'dice',\n                            'hamming', 'jaccard', 'kulsinski', 'mahalanobis',\n                            'matching', 'minkowski', 'rogerstanimoto',\n                            'russellrao', 'seuclidean', 'sokalmichener',\n                            'sokalsneath', 'sqeuclidean', 'yule'],\n                           mds_dist=self.mds_dist)\n        utils.check_in(['classic', 'metric', 'nonmetric'],\n                       mds=self.mds)", "response": "Checks PHATE parameters and returns a list of unique identifiers."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_params(self, **params):\n        reset_kernel = False\n        reset_potential = False\n        reset_embedding = False\n\n        # mds parameters\n        if 'n_components' in params and \\\n                params['n_components'] != self.n_components:\n            self.n_components = params['n_components']\n            reset_embedding = True\n            del params['n_components']\n        if 'mds' in params and params['mds'] != self.mds:\n            self.mds = params['mds']\n            reset_embedding = True\n            del params['mds']\n        if 'mds_dist' in params and params['mds_dist'] != self.mds_dist:\n            self.mds_dist = params['mds_dist']\n            reset_embedding = True\n            del params['mds_dist']\n\n        # diff potential parameters\n        if 't' in params and params['t'] != self.t:\n            self.t = params['t']\n            reset_potential = True\n            del params['t']\n        if 'potential_method' in params:\n            if params['potential_method'] == 'log':\n                params['gamma'] = 1\n            elif params['potential_method'] == 'sqrt':\n                params['gamma'] = 0\n            else:\n                raise ValueError(\"potential_method {} not recognized. Please \"\n                                 \"use gamma between -1 and 1\".format(\n                                     params['potential_method']))\n            warnings.warn(\n                \"potential_method is deprecated. Setting gamma to {} to \"\n                \"achieve {} transformation.\".format(\n                    params['gamma'],\n                    params['potential_method']),\n                FutureWarning)\n            del params['potential_method']\n        if 'gamma' in params and \\\n                params['gamma'] != self.gamma:\n            self.gamma = params['gamma']\n            reset_potential = True\n            del params['gamma']\n\n        # kernel parameters\n        if 'k' in params and params['k'] != self.knn:\n            self.knn = params['k']\n            reset_kernel = True\n            del params['k']\n        if 'a' in params and params['a'] != self.decay:\n            self.decay = params['a']\n            reset_kernel = True\n            del params['a']\n        if 'knn' in params and params['knn'] != self.knn:\n            self.knn = params['knn']\n            reset_kernel = True\n            del params['knn']\n        if 'decay' in params and params['decay'] != self.decay:\n            self.decay = params['decay']\n            reset_kernel = True\n            del params['decay']\n        if 'n_pca' in params:\n            if self.X is not None and params['n_pca'] >= np.min(self.X.shape):\n                params['n_pca'] = None\n            if params['n_pca'] != self.n_pca:\n                self.n_pca = params['n_pca']\n                reset_kernel = True\n                del params['n_pca']\n        if 'knn_dist' in params and params['knn_dist'] != self.knn_dist:\n            self.knn_dist = params['knn_dist']\n            reset_kernel = True\n            del params['knn_dist']\n        if 'n_landmark' in params and params['n_landmark'] != self.n_landmark:\n            if self.n_landmark is None or params['n_landmark'] is None:\n                # need a different type of graph, reset entirely\n                self._reset_graph()\n            else:\n                self._set_graph_params(n_landmark=params['n_landmark'])\n            self.n_landmark = params['n_landmark']\n            del params['n_landmark']\n\n        # parameters that don't change the embedding\n        if 'n_jobs' in params:\n            self.n_jobs = params['n_jobs']\n            self._set_graph_params(n_jobs=params['n_jobs'])\n            del params['n_jobs']\n        if 'random_state' in params:\n            self.random_state = params['random_state']\n            self._set_graph_params(random_state=params['random_state'])\n            del params['random_state']\n        if 'verbose' in params:\n            self.verbose = params['verbose']\n            tasklogger.set_level(self.verbose)\n            self._set_graph_params(verbose=params['verbose'])\n            del params['verbose']\n\n        if reset_kernel:\n            # can't reset the graph kernel without making a new graph\n            self._reset_graph()\n        if reset_potential:\n            self._reset_potential()\n        if reset_embedding:\n            self._reset_embedding()\n\n        self._set_graph_params(**params)\n\n        self._check_params()\n        return self", "response": "Set the parameters of the kNN graph for the given estimator."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the diffusion operator for a single object of the class.", "response": "def fit(self, X):\n        \"\"\"Computes the diffusion operator\n\n        Parameters\n        ----------\n        X : array, shape=[n_samples, n_features]\n            input data with `n_samples` samples and `n_dimensions`\n            dimensions. Accepted data types: `numpy.ndarray`,\n            `scipy.sparse.spmatrix`, `pd.DataFrame`, `anndata.AnnData`. If\n            `knn_dist` is 'precomputed', `data` should be a n_samples x\n            n_samples distance or affinity matrix\n\n        Returns\n        -------\n        phate_operator : PHATE\n        The estimator object\n        \"\"\"\n        X, n_pca, precomputed, update_graph = self._parse_input(X)\n\n        if precomputed is None:\n            tasklogger.log_info(\n                \"Running PHATE on {} cells and {} genes.\".format(\n                    X.shape[0], X.shape[1]))\n        else:\n            tasklogger.log_info(\n                \"Running PHATE on precomputed {} matrix with {} cells.\".format(\n                    precomputed, X.shape[0]))\n\n        if self.n_landmark is None or X.shape[0] <= self.n_landmark:\n            n_landmark = None\n        else:\n            n_landmark = self.n_landmark\n\n        if self.graph is not None and update_graph:\n            self._update_graph(X, precomputed, n_pca, n_landmark)\n\n        self.X = X\n\n        if self.graph is None:\n            tasklogger.log_start(\"graph and diffusion operator\")\n            self.graph = graphtools.Graph(\n                X,\n                n_pca=n_pca,\n                n_landmark=n_landmark,\n                distance=self.knn_dist,\n                precomputed=precomputed,\n                knn=self.knn,\n                decay=self.decay,\n                thresh=1e-4,\n                n_jobs=self.n_jobs,\n                verbose=self.verbose,\n                random_state=self.random_state,\n                **(self.kwargs))\n            tasklogger.log_complete(\"graph and diffusion operator\")\n\n        # landmark op doesn't build unless forced\n        self.diff_op\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the position of the cells in the embedding space using the PHATE.", "response": "def transform(self, X=None, t_max=100, plot_optimal_t=False, ax=None):\n        \"\"\"Computes the position of the cells in the embedding space\n\n        Parameters\n        ----------\n        X : array, optional, shape=[n_samples, n_features]\n            input data with `n_samples` samples and `n_dimensions`\n            dimensions. Not required, since PHATE does not currently embed\n            cells not given in the input matrix to `PHATE.fit()`.\n            Accepted data types: `numpy.ndarray`,\n            `scipy.sparse.spmatrix`, `pd.DataFrame`, `anndata.AnnData`. If\n            `knn_dist` is 'precomputed', `data` should be a n_samples x\n            n_samples distance or affinity matrix\n\n        t_max : int, optional, default: 100\n            maximum t to test if `t` is set to 'auto'\n\n        plot_optimal_t : boolean, optional, default: False\n            If true and `t` is set to 'auto', plot the Von Neumann\n            entropy used to select t\n\n        ax : matplotlib.axes.Axes, optional\n            If given and `plot_optimal_t` is true, plot will be drawn\n            on the given axis.\n\n        Returns\n        -------\n        embedding : array, shape=[n_samples, n_dimensions]\n        The cells embedded in a lower dimensional space using PHATE\n        \"\"\"\n        if self.graph is None:\n            raise NotFittedError(\"This PHATE instance is not fitted yet. Call \"\n                                 \"'fit' with appropriate arguments before \"\n                                 \"using this method.\")\n        elif X is not None and not utils.matrix_is_equivalent(X, self.X):\n            # fit to external data\n            warnings.warn(\"Pre-fit PHATE cannot be used to transform a \"\n                          \"new data matrix. Please fit PHATE to the new\"\n                          \" data by running 'fit' with the new data.\",\n                          RuntimeWarning)\n            if isinstance(self.graph, graphtools.graphs.TraditionalGraph) and \\\n                    self.graph.precomputed is not None:\n                raise ValueError(\"Cannot transform additional data using a \"\n                                 \"precomputed distance matrix.\")\n            else:\n                transitions = self.graph.extend_to_data(X)\n                return self.graph.interpolate(self.embedding,\n                                              transitions)\n        else:\n            diff_potential = self.calculate_potential(\n                t_max=t_max, plot_optimal_t=plot_optimal_t, ax=ax)\n            if self.embedding is None:\n                tasklogger.log_start(\"{} MDS\".format(self.mds))\n                self.embedding = mds.embed_MDS(\n                    diff_potential, ndim=self.n_components, how=self.mds,\n                    distance_metric=self.mds_dist, n_jobs=self.n_jobs,\n                    seed=self.random_state, verbose=max(self.verbose - 1, 0))\n                tasklogger.log_complete(\"{} MDS\".format(self.mds))\n            if isinstance(self.graph, graphtools.graphs.LandmarkGraph):\n                tasklogger.log_debug(\"Extending to original data...\")\n                return self.graph.interpolate(self.embedding)\n            else:\n                return self.embedding"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the diffusion operator and the position of the cells in the cluster space using PHATE. transform.", "response": "def fit_transform(self, X, **kwargs):\n        \"\"\"Computes the diffusion operator and the position of the cells in the\n        embedding space\n\n        Parameters\n        ----------\n        X : array, shape=[n_samples, n_features]\n            input data with `n_samples` samples and `n_dimensions`\n            dimensions. Accepted data types: `numpy.ndarray`,\n            `scipy.sparse.spmatrix`, `pd.DataFrame`, `anndata.AnnData` If\n            `knn_dist` is 'precomputed', `data` should be a n_samples x\n            n_samples distance or affinity matrix\n\n        kwargs : further arguments for `PHATE.transform()`\n            Keyword arguments as specified in :func:`~phate.PHATE.transform`\n\n        Returns\n        -------\n        embedding : array, shape=[n_samples, n_dimensions]\n            The cells embedded in a lower dimensional space using PHATE\n        \"\"\"\n        tasklogger.log_start('PHATE')\n        self.fit(X)\n        embedding = self.transform(**kwargs)\n        tasklogger.log_complete('PHATE')\n        return embedding"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calculate_potential(self, t=None,\n                            t_max=100, plot_optimal_t=False, ax=None):\n        \"\"\"Calculates the diffusion potential\n\n        Parameters\n        ----------\n\n        t : int\n            power to which the diffusion operator is powered\n            sets the level of diffusion\n\n        t_max : int, default: 100\n            Maximum value of `t` to test\n\n        plot_optimal_t : boolean, default: False\n            If true, plots the Von Neumann Entropy and knee point\n\n        ax : matplotlib.Axes, default: None\n            If plot=True and ax is not None, plots the VNE on the given axis\n            Otherwise, creates a new axis and displays the plot\n\n        Returns\n        -------\n\n        diff_potential : array-like, shape=[n_samples, n_samples]\n            The diffusion potential fit on the input data\n        \"\"\"\n        if t is None:\n            t = self.t\n        if self.diff_potential is None:\n            if t == 'auto':\n                t = self.optimal_t(t_max=t_max, plot=plot_optimal_t, ax=ax)\n            else:\n                t = self.t\n            tasklogger.log_start(\"diffusion potential\")\n            # diffused diffusion operator\n            diff_op_t = np.linalg.matrix_power(self.diff_op, t)\n            if self.gamma == 1:\n                # handling small values\n                diff_op_t = diff_op_t + 1e-7\n                self.diff_potential = -1 * np.log(diff_op_t)\n            elif self.gamma == -1:\n                self.diff_potential = diff_op_t\n            else:\n                c = (1 - self.gamma) / 2\n                self.diff_potential = ((diff_op_t)**c) / c\n            tasklogger.log_complete(\"diffusion potential\")\n        elif plot_optimal_t:\n            self.optimal_t(t_max=t_max, plot=plot_optimal_t, ax=ax)\n\n        return self.diff_potential", "response": "Calculates the diffusion potential of the diffusion operator with the given power t."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef von_neumann_entropy(self, t_max=100):\n        t = np.arange(t_max)\n        return t, vne.compute_von_neumann_entropy(self.diff_op, t_max=t_max)", "response": "Calculate the Von Neumann Entropy of the diffusion affinities at varying levels of t."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind the optimal value of t based on the knee point of the diffusion operator.", "response": "def optimal_t(self, t_max=100, plot=False, ax=None):\n        \"\"\"Find the optimal value of t\n\n        Selects the optimal value of t based on the knee point of the\n        Von Neumann Entropy of the diffusion operator.\n\n        Parameters\n        ----------\n        t_max : int, default: 100\n            Maximum value of t to test\n\n        plot : boolean, default: False\n            If true, plots the Von Neumann Entropy and knee point\n\n        ax : matplotlib.Axes, default: None\n            If plot=True and ax is not None, plots the VNE on the given axis\n            Otherwise, creates a new axis and displays the plot\n\n        Returns\n        -------\n        t_opt : int\n            The optimal value of t\n        \"\"\"\n        tasklogger.log_start(\"optimal t\")\n        t, h = self.von_neumann_entropy(t_max=t_max)\n        t_opt = vne.find_knee_point(y=h, x=t)\n        tasklogger.log_info(\"Automatically selected t = {}\".format(t_opt))\n        tasklogger.log_complete(\"optimal t\")\n\n        if plot:\n            if ax is None:\n                fig, ax = plt.subplots()\n                show = True\n            else:\n                show = False\n            ax.plot(t, h)\n            ax.scatter(t_opt, h[t == t_opt], marker='*', c='k', s=50)\n            ax.set_xlabel(\"t\")\n            ax.set_ylabel(\"Von Neumann Entropy\")\n            ax.set_title(\"Optimal t = {}\".format(t_opt))\n            if show:\n                plt.show()\n\n        return t_opt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload a theme from a dictionary.", "response": "def load_theme_from_dict(dict_theme):\n    \"\"\"\n    Load a theme from a dict.\n    Expected format:\n    {\n        \"Question\": {\n            \"mark_color\": \"yellow\",\n            \"brackets_color\": \"normal\",\n            ...\n        },\n        \"List\": {\n            \"selection_color\": \"bold_blue\",\n            \"selection_cursor\": \"->\"\n        }\n    }\n\n    Color values should be string representing valid blessings.Terminal colors.\n    \"\"\"\n    t = Default()\n    for question_type, settings in dict_theme.items():\n        if question_type not in vars(t):\n            raise ThemeError('Error while parsing theme. Question type '\n                             '`{}` not found or not customizable.'\n                             .format(question_type))\n\n        # calculating fields of namedtuple, hence the filtering\n        question_fields = list(filter(lambda x: not x.startswith('_'),\n                                      vars(getattr(t, question_type))))\n\n        for field, value in settings.items():\n            if field not in question_fields:\n                raise ThemeError('Error while parsing theme. Field '\n                                 '`{}` invalid for question type `{}`'\n                                 .format(field, question_type))\n            actual_value = getattr(term, value) or value\n            setattr(getattr(t, question_type), field, actual_value)\n    return t"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading Questions from a JSON string.", "response": "def load_from_json(question_json):\n    \"\"\"\n    Load Questions from a JSON string.\n    :return: A list of Question objects with associated data if the JSON\n             contains a list or a Question if the JSON contains a dict.\n    :return type: List or Dict\n    \"\"\"\n    data = json.loads(question_json)\n    if isinstance(data, list):\n        return load_from_list(data)\n    if isinstance(data, dict):\n        return load_from_dict(data)\n    raise TypeError(\n        'Json contained a %s variable when a dict or list was expected',\n        type(data))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef a2bits(chars: str) -> str:\n    return bin(reduce(lambda x, y: (x << 8) + y, (ord(c) for c in chars), 1))[\n        3:\n    ]", "response": "Converts a string to its bits representation as a string of 0 s and 1 s."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef a2bits_list(chars: str, encoding: str = \"UTF-8\") -> List[str]:\n    return [bin(ord(x))[2:].rjust(ENCODINGS[encoding], \"0\") for x in chars]", "response": "Convert a string to its bits representation as a list of 0 s and 1 s."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert an int to its bits representation as a string of 0 s and 1 s.", "response": "def bs(s: int) -> str:\n    \"\"\"Converts an int to its bits representation as a string of 0's and 1's.\n    \"\"\"\n    return str(s) if s <= 1 else bs(s >> 1) + str(s & 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an iterator which groups n items at a time.", "response": "def n_at_a_time(\n    items: List[int], n: int, fillvalue: str\n) -> Iterator[Tuple[Union[int, str]]]:\n    \"\"\"Returns an iterator which groups n items at a time.\n    Any final partial tuple will be padded with the fillvalue\n\n    >>> list(n_at_a_time([1, 2, 3, 4, 5], 2, 'X'))\n    [(1, 2), (3, 4), (5, 'X')]\n    \"\"\"\n    it = iter(items)\n    return itertools.zip_longest(*[it] * n, fillvalue=fillvalue)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a binary file to base64 string.", "response": "def binary2base64(binary_file: str) -> str:\n    \"\"\"Convert a binary file (OGG, executable, etc.) to a\n    printable string.\n    \"\"\"\n    # Use mode = \"rb\" to read binary file\n    with open(binary_file, \"rb\") as bin_file:\n        encoded_string = base64.b64encode(bin_file.read())\n    return encoded_string.decode()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef open_image(fname_or_instance: Union[str, IO[bytes]]):\n    if isinstance(fname_or_instance, Image.Image):\n        return fname_or_instance\n\n    return Image.open(fname_or_instance)", "response": "Opens an Image and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhiding a message in an image.", "response": "def hide(\n    input_image_file,\n    img_enc,\n    secret_message=None,\n    secret_file=None,\n    img_format=None,\n):\n    \"\"\"Hide a message (string) in an image.\n    \"\"\"\n    from zlib import compress\n    from base64 import b64encode\n\n    if secret_file != None:\n        with open(secret_file, \"r\") as f:\n            secret_message = f.read()\n\n    try:\n        text = compress(b64encode(bytes(secret_message, \"utf-8\")))\n    except:\n        text = compress(b64encode(secret_message))\n\n    img = tools.open_image(input_image_file)\n\n    if img_format is None:\n        img_format = img.format\n\n    if \"exif\" in img.info:\n        exif_dict = piexif.load(img.info[\"exif\"])\n    else:\n        exif_dict = {}\n        exif_dict[\"0th\"] = {}\n    exif_dict[\"0th\"][piexif.ImageIFD.ImageDescription] = text\n    exif_bytes = piexif.dump(exif_dict)\n    img.save(img_enc, format=img_format, exif=exif_bytes)\n    img.close()\n    return img"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding a message in an image.", "response": "def reveal(input_image_file):\n    \"\"\"Find a message in an image.\n    \"\"\"\n    from base64 import b64decode\n    from zlib import decompress\n\n    img = tools.open_image(input_image_file)\n\n    try:\n        if img.format in [\"JPEG\", \"TIFF\"]:\n            if \"exif\" in img.info:\n                exif_dict = piexif.load(img.info.get(\"exif\", b\"\"))\n                description_key = piexif.ImageIFD.ImageDescription\n                encoded_message = exif_dict[\"0th\"][description_key]\n            else:\n                encoded_message = b\"\"\n        else:\n            raise ValueError(\"Given file is neither JPEG nor TIFF.\")\n    finally:\n        img.close()\n\n    return b64decode(decompress(encoded_message))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the most common colours of the image.", "response": "def steganalyse(img):\n    \"\"\"\n    Steganlysis of the LSB technique.\n    \"\"\"\n    encoded = img.copy()\n    width, height = img.size\n    colours_counter = Counter() # type: Counter[int]\n    for row in range(height):\n        for col in range(width):\n            r, g, b = img.getpixel((col, row))\n            colours_counter[r] += 1\n\n    most_common = colours_counter.most_common(10)\n    dict_colours = OrderedDict(sorted(list(colours_counter.items()),\n                                key=lambda t: t[1]))\n\n    colours = 0 # type: float\n    for colour in list(dict_colours.keys()):\n        colours += colour\n    colours = colours / len(dict_colours)\n\n    #return colours.most_common(10)\n    return list(dict_colours.keys())[:30], most_common"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating the prime numbers with the sieve of Eratosthenes.", "response": "def eratosthenes() -> Iterator[int]:\n    \"\"\"Generate the prime numbers with the sieve of Eratosthenes.\n    https://oeis.org/A000040\n    \"\"\"\n    d = {}  # type: Dict[int, List[int]]\n    for i in itertools.count(2):\n        if i in d:\n            for j in d[i]:\n                d[i + j] = d.get(i + j, []) + [j]\n            del d[i]\n        else:\n            d[i * i] = [i]\n            yield i"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate the composite numbers of the Eratosthenes.", "response": "def composite() -> Iterator[int]:\n    \"\"\"Generate the composite numbers using the sieve of Eratosthenes.\n    https://oeis.org/A002808\n    \"\"\"\n    p1 = 3\n    for p2 in eratosthenes():\n        for n in range(p1 + 1, p2):\n            yield n\n        p1 = p2"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef carmichael() -> Iterator[int]:\n    for m in composite():\n        for a in range(2, m):\n            if pow(a, m, m) != a:\n                break\n        else:\n            yield m", "response": "Iterator that yields all the carmichael numbers in the composite number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating the sequence of Fibonacci objects.", "response": "def fibonacci() -> Iterator[int]:\n    \"\"\"Generate the sequence of Fibonacci.\n    https://oeis.org/A000045\n    \"\"\"\n    a, b = 1, 2\n    while True:\n        yield a\n        a, b = b, a + b"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhide a message in an image.", "response": "def hide(input_image: Union[str, IO[bytes]], message: str):\n    \"\"\"\n    Hide a message (string) in an image.\n\n    Use the red portion of a pixel (r, g, b) tuple to\n    hide the message string characters as ASCII values.\n    The red value of the first pixel is used for message_length of the string.\n    \"\"\"\n    message_length = len(message)\n    assert message_length != 0, \"message message_length is zero\"\n    assert message_length < 255, \"message is too long\"\n    img = tools.open_image(input_image)\n    # Use a copy of image to hide the text in\n    encoded = img.copy()\n    width, height = img.size\n    index = 0\n    for row in range(height):\n        for col in range(width):\n            (r, g, b) = img.getpixel((col, row))\n            # first value is message_length of message\n            if row == 0 and col == 0 and index < message_length:\n                asc = message_length\n            elif index <= message_length:\n                c = message[index - 1]\n                asc = ord(c)\n            else:\n                asc = r\n            encoded.putpixel((col, row), (asc, g, b))\n            index += 1\n    img.close()\n    return encoded"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreveal a message in an image.", "response": "def reveal(input_image: Union[str, IO[bytes]]):\n    \"\"\"\n    Find a message in an image.\n\n    Check the red portion of an pixel (r, g, b) tuple for\n    hidden message characters (ASCII values).\n    The red value of the first pixel is used for message_length of string.\n    \"\"\"\n    img = tools.open_image(input_image)\n    width, height = img.size\n    message = \"\"\n    index = 0\n    for row in range(height):\n        for col in range(width):\n            r, g, b = img.getpixel((col, row))\n            # First pixel r value is length of message\n            if row == 0 and col == 0:\n                message_length = r\n            elif index <= message_length:\n                message += chr(r)\n            index += 1\n    img.close()\n    return message"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhiding a message in an image with the highest significant bit.", "response": "def hide(\n    input_image: Union[str, IO[bytes]],\n    message: str,\n    encoding: str = \"UTF-8\",\n    auto_convert_rgb: bool = False,\n):\n    \"\"\"Hide a message (string) in an image with the\n    LSB (Least Significant Bit) technique.\n    \"\"\"\n    message_length = len(message)\n    assert message_length != 0, \"message length is zero\"\n\n    img = tools.open_image(input_image)\n\n    if img.mode not in [\"RGB\", \"RGBA\"]:\n        if not auto_convert_rgb:\n            print(\n                \"The mode of the image is not RGB. Mode is {}\".format(img.mode)\n            )\n            answer = input(\"Convert the image to RGB ? [Y / n]\\n\") or \"Y\"\n            if answer.lower() == \"n\":\n                raise Exception(\"Not a RGB image.\")\n        img = img.convert(\"RGB\")\n\n    encoded = img.copy()\n    width, height = img.size\n    index = 0\n\n    message = str(message_length) + \":\" + str(message)\n    message_bits = \"\".join(tools.a2bits_list(message, encoding))\n    message_bits += \"0\" * ((3 - (len(message_bits) % 3)) % 3)\n\n    npixels = width * height\n    len_message_bits = len(message_bits)\n    if len_message_bits > npixels * 3:\n        raise Exception(\n            \"The message you want to hide is too long: {}\".format(\n                message_length\n            )\n        )\n    for row in range(height):\n        for col in range(width):\n            if index + 3 <= len_message_bits:\n\n                # Get the colour component.\n                pixel = img.getpixel((col, row))\n                r = pixel[0]\n                g = pixel[1]\n                b = pixel[2]\n\n                # Change the Least Significant Bit of each colour component.\n                r = tools.setlsb(r, message_bits[index])\n                g = tools.setlsb(g, message_bits[index + 1])\n                b = tools.setlsb(b, message_bits[index + 2])\n\n                # Save the new pixel\n                if img.mode == \"RGBA\":\n                    encoded.putpixel((col, row), (r, g, b, pixel[3]))\n                else:\n                    encoded.putpixel((col, row), (r, g, b))\n\n                index += 3\n            else:\n                img.close()\n                return encoded"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind a message in an image.", "response": "def reveal(input_image: Union[str, IO[bytes]], encoding=\"UTF-8\"):\n    \"\"\"Find a message in an image (with the LSB technique).\n    \"\"\"\n    img = tools.open_image(input_image)\n    width, height = img.size\n    buff, count = 0, 0\n    bitab = []\n    limit = None\n    for row in range(height):\n        for col in range(width):\n\n            # pixel = [r, g, b] or [r,g,b,a]\n            pixel = img.getpixel((col, row))\n            if img.mode == \"RGBA\":\n                pixel = pixel[:3]  # ignore the alpha\n            for color in pixel:\n                buff += (color & 1) << (tools.ENCODINGS[encoding] - 1 - count)\n                count += 1\n                if count == tools.ENCODINGS[encoding]:\n                    bitab.append(chr(buff))\n                    buff, count = 0, 0\n                    if bitab[-1] == \":\" and limit is None:\n                        try:\n                            limit = int(\"\".join(bitab[:-1]))\n                        except:\n                            pass\n\n            if len(bitab) - len(str(limit)) - 1 == limit:\n                img.close()\n                return \"\".join(bitab)[len(str(limit)) + 1 :]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef hide(\n    input_image: Union[str, IO[bytes]],\n    message: str,\n    generator: Iterator[int],\n    shift: int = 0,\n    encoding: str = \"UTF-8\",\n    auto_convert_rgb: bool = False,\n):\n    \"\"\"Hide a message (string) in an image with the\n    LSB (Least Significant Bit) technique.\n    \"\"\"\n    message_length = len(message)\n    assert message_length != 0, \"message length is zero\"\n\n    img = tools.open_image(input_image)\n\n    if img.mode not in [\"RGB\", \"RGBA\"]:\n        if not auto_convert_rgb:\n            print(\n                \"The mode of the image is not RGB. Mode is {}\".format(img.mode)\n            )\n            answer = input(\"Convert the image to RGB ? [Y / n]\\n\") or \"Y\"\n            if answer.lower() == \"n\":\n                raise Exception(\"Not a RGB image.\")\n        img = img.convert(\"RGB\")\n\n    img_list = list(img.getdata())\n    width, height = img.size\n    index = 0\n\n    message = str(message_length) + \":\" + str(message)\n    message_bits = \"\".join(tools.a2bits_list(message, encoding))\n    message_bits += \"0\" * ((3 - (len(message_bits) % 3)) % 3)\n\n    npixels = width * height\n    len_message_bits = len(message_bits)\n    if len_message_bits > npixels * 3:\n        raise Exception(\n            \"The message you want to hide is too long: {}\".format(\n                message_length\n            )\n        )\n    while shift != 0:\n        next(generator)\n        shift -= 1\n\n    while index + 3 <= len_message_bits:\n        generated_number = next(generator)\n        r, g, b, *a = img_list[generated_number]\n\n        # Change the Least Significant Bit of each colour component.\n        r = tools.setlsb(r, message_bits[index])\n        g = tools.setlsb(g, message_bits[index + 1])\n        b = tools.setlsb(b, message_bits[index + 2])\n\n        # Save the new pixel\n        if img.mode == \"RGBA\":\n            img_list[generated_number] = (r, g, b, a[0])\n        else:\n            img_list[generated_number] = (r, g, b)\n\n        index += 3\n\n    # create empty new image of appropriate format\n    encoded = Image.new(\"RGB\", (img.size))\n\n    # insert saved data into the image\n    encoded.putdata(img_list)\n\n    return encoded", "response": "Hide a message in an image with the highest significant bit."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reveal(\n    input_image: Union[str, IO[bytes]],\n    generator: Iterator[int],\n    shift: int = 0,\n    encoding: str = \"UTF-8\",\n):\n    \"\"\"Find a message in an image (with the LSB technique).\n    \"\"\"\n    img = tools.open_image(input_image)\n    img_list = list(img.getdata())\n    width, height = img.size\n    buff, count = 0, 0\n    bitab = []\n    limit = None\n\n    while shift != 0:\n        next(generator)\n        shift -= 1\n\n    while True:\n        generated_number = next(generator)\n        # color = [r, g, b]\n        for color in img_list[generated_number]:\n            buff += (color & 1) << (tools.ENCODINGS[encoding] - 1 - count)\n            count += 1\n            if count == tools.ENCODINGS[encoding]:\n                bitab.append(chr(buff))\n                buff, count = 0, 0\n                if bitab[-1] == \":\" and limit == None:\n                    if \"\".join(bitab[:-1]).isdigit():\n                        limit = int(\"\".join(bitab[:-1]))\n                    else:\n                        raise IndexError(\"Impossible to detect message.\")\n        if len(bitab) - len(str(limit)) - 1 == limit:\n            return \"\".join(bitab)[len(str(limit)) + 1 :]", "response": "Reveal a message in an image."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef steganalyse(img):\n    encoded = img.copy()\n    width, height = img.size\n    bits = \"\"\n    for row in range(height):\n        for col in range(width):\n            r, g, b = img.getpixel((col, row))\n            if r % 2 == 0:\n                r = 0\n            else:\n                r = 255\n            if g % 2 == 0:\n                g = 0\n            else:\n                g = 255\n            if b % 2 == 0:\n                b = 0\n            else:\n                b = 255\n            encoded.putpixel((col, row), (r, g , b))\n    return encoded", "response": "Steganalyse the image into a single node."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a string representing the identity of the passed object", "response": "def identity(obj):\n    \"\"\"\n    returns a string representing \"<pk>,<version>\" of the passed object\n    \"\"\"\n    if hasattr(obj, '_concurrencymeta'):\n        return mark_safe(\"{0},{1}\".format(unlocalize(obj.pk),\n                                          get_revision_of_object(obj)))\n    else:\n        return mark_safe(unlocalize(obj.pk))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the classname of an object r a class", "response": "def get_classname(o):\n    \"\"\" Returns the classname of an object r a class\n\n    :param o:\n    :return:\n    \"\"\"\n    if inspect.isclass(o):\n        target = o\n    elif callable(o):\n        target = o\n    else:\n        target = o.__class__\n    try:\n        return target.__qualname__\n    except AttributeError:  # pragma: no cover\n        return target.__name__"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the fully qualified class name of an object or a class", "response": "def fqn(o):\n    \"\"\"Returns the fully qualified class name of an object or a class\n\n    :param o: object or class\n    :return: class name\n\n    >>> import concurrency.fields\n    >>> fqn('str')\n    Traceback (most recent call last):\n    ...\n    ValueError: Invalid argument `str`\n    >>> class A(object):\n    ...     def method(self):\n    ...         pass\n    >>> str(fqn(A))\n    'concurrency.utils.A'\n\n    >>> str(fqn(A()))\n    'concurrency.utils.A'\n\n    >>> str(fqn(concurrency.fields))\n    'concurrency.fields'\n\n    >>> str(fqn(A.method))\n    'concurrency.utils.A.method'\n\n\n    \"\"\"\n    parts = []\n\n    # if inspect.ismethod(o):\n    #     try:\n    #         cls = o.im_class\n    #     except AttributeError:\n    #         # Python 3 eliminates im_class, substitutes __module__ and\n    #         # __qualname__ to provide similar information.\n    #         parts = (o.__module__, o.__qualname__)\n    #     else:\n    #         parts = (fqn(cls), get_classname(o))\n    if hasattr(o, '__module__'):\n        parts.append(o.__module__)\n        parts.append(get_classname(o))\n    elif inspect.ismodule(o):\n        return o.__name__\n    if not parts:\n        raise ValueError(\"Invalid argument `%s`\" % o)\n    return \".\".join(parts)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a single list which contains all elements retrieved from the sequence and all recursively contained sub - sequences retrieved from the sequence.", "response": "def flatten(iterable):\n    \"\"\"\n    flatten(sequence) -> list\n\n    Returns a single, flat list which contains all elements retrieved\n    from the sequence and all recursively contained sub-sequences\n    (iterables).\n\n    :param sequence: any object that implements iterable protocol (see: :ref:`typeiter`)\n    :return: list\n\n    Examples:\n\n    >>> from adminactions.utils import flatten\n    >>> [1, 2, [3,4], (5,6)]\n    [1, 2, [3, 4], (5, 6)]\n\n    >>> flatten([[[1,2,3], (42,None)], [4,5], [6], 7, (8,9,10)])\n    [1, 2, 3, 42, None, 4, 5, 6, 7, 8, 9, 10]\"\"\"\n\n    result = list()\n    for el in iterable:\n        if hasattr(el, \"__iter__\") and not isinstance(el, str):\n            result.extend(flatten(el))\n        else:\n            result.append(el)\n    return list(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _handler(self, sender, setting, value, **kwargs):\n        if setting.startswith(self.prefix):\n            self._set_attr(setting, value)", "response": "handler for setting_changed signal."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_changed(obj):\n    revision_field = get_version_fieldname(obj)\n    version = get_revision_of_object(obj)\n    return not obj.__class__.objects.filter(**{obj._meta.pk.name: obj.pk,\n                                               revision_field: version}).exists()", "response": "Returns True if obj is changed or deleted on the database\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_version(model_instance, version):\n    version_field = get_version_fieldname(model_instance)\n    kwargs = {'pk': model_instance.pk, version_field: version}\n    return model_instance.__class__.objects.get(**kwargs)", "response": "try go load from the database one object with specific version"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_arguments(self, parser):\n        subparsers = parser.add_subparsers(help='sub-command help',\n                                           dest='command')\n\n        add_parser = partial(_add_subparser, subparsers, parser)\n\n        add_parser('list', help=\"list concurrency triggers\")\n        add_parser('drop', help=\"drop  concurrency triggers\")\n        add_parser('create', help=\"create concurrency triggers\")\n\n        parser.add_argument('-d', '--database',\n                            action='store',\n                            dest='database',\n                            default=None,\n                            help='limit to this database')\n\n        parser.add_argument('-t', '--trigger',\n                            action='store',\n                            dest='trigger',\n                            default=None,\n                            help='limit to this trigger name')", "response": "Add command line arguments for\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef action_checkbox(self, obj):\n        if self.check_concurrent_action:\n            return helpers.checkbox.render(helpers.ACTION_CHECKBOX_NAME,\n                                           force_text(\"%s,%s\" % (obj.pk,\n                                                                 get_revision_of_object(obj))))\n        else:  # pragma: no cover\n            return super(ConcurrencyActionMixin, self).action_checkbox(obj)", "response": "A list_display column containing a checkbox widget."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles an admin action. This is called by the admin_view method of the admin view. It returns an HttpResponse if the action was handled and None otherwise.", "response": "def response_action(self, request, queryset):  # noqa\n        \"\"\"\n        Handle an admin action. This is called if a request is POSTed to the\n        changelist; it returns an HttpResponse if the action was handled, and\n        None otherwise.\n        \"\"\"\n        # There can be multiple action forms on the page (at the top\n        # and bottom of the change list, for example). Get the action\n        # whose button was pushed.\n        try:\n            action_index = int(request.POST.get('index', 0))\n        except ValueError:  # pragma: no cover\n            action_index = 0\n\n        # Construct the action form.\n        data = request.POST.copy()\n        data.pop(helpers.ACTION_CHECKBOX_NAME, None)\n        data.pop(\"index\", None)\n\n        # Use the action whose button was pushed\n        try:\n            data.update({'action': data.getlist('action')[action_index]})\n        except IndexError:  # pragma: no cover\n            # If we didn't get an action from the chosen form that's invalid\n            # POST data, so by deleting action it'll fail the validation check\n            # below. So no need to do anything here\n            pass\n\n        action_form = self.action_form(data, auto_id=None)\n        action_form.fields['action'].choices = self.get_action_choices(request)\n\n        # If the form's valid we can handle the action.\n        if action_form.is_valid():\n            action = action_form.cleaned_data['action']\n            func, name, description = self.get_actions(request)[action]\n\n            # Get the list of selected PKs. If nothing's selected, we can't\n            # perform an action on it, so bail.\n            if action_form.cleaned_data['select_across']:\n                selected = ALL\n            else:\n                selected = request.POST.getlist(helpers.ACTION_CHECKBOX_NAME)\n\n            if not selected:\n                return None\n\n            revision_field = self.model._concurrencymeta.field\n\n            if self.check_concurrent_action:\n                self.delete_selected_confirmation_template = self.get_confirmation_template()\n\n                # If select_across we have to avoid the use of concurrency\n                if selected is not ALL:\n                    filters = []\n                    for x in selected:\n                        try:\n                            pk, version = x.split(\",\")\n                        except ValueError:  # pragma: no cover\n                            raise ImproperlyConfigured('`ConcurrencyActionMixin` error.'\n                                                       'A tuple with `primary_key, version_number` '\n                                                       'expected:  `%s` found' % x)\n                        filters.append(Q(**{'pk': pk,\n                                            revision_field.attname: version}))\n\n                    queryset = queryset.filter(reduce(operator.or_, filters))\n                    if len(selected) != queryset.count():\n                        messages.error(request, 'One or more record were updated. '\n                                                '(Probably by other user) '\n                                                'The execution was aborted.')\n                        return HttpResponseRedirect(\".\")\n                else:\n                    messages.warning(request, 'Selecting all records, you will avoid the concurrency check')\n\n            response = func(self, request, queryset)\n\n            # Actions may return an HttpResponse, which will be used as the\n            # response from the POST. If not, we'll be a good little HTTP\n            # citizen and redirect back to the changelist page.\n            if isinstance(response, HttpResponse):\n                return response\n            else:\n                return HttpResponseRedirect(\".\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the ManagementForm instance for this FormSet.", "response": "def _management_form(self):\n        \"\"\"Returns the ManagementForm instance for this FormSet.\"\"\"\n        if self.is_bound:\n            form = ConcurrentManagementForm(self.data, auto_id=self.auto_id,\n                                            prefix=self.prefix)\n            if not form.is_valid():\n                raise ValidationError('ManagementForm data is missing or has been tampered with')\n        else:\n            form = ConcurrentManagementForm(auto_id=self.auto_id,\n                                            prefix=self.prefix,\n                                            initial={TOTAL_FORM_COUNT: self.total_form_count(),\n                                                     INITIAL_FORM_COUNT: self.initial_form_count(),\n                                                     MAX_NUM_FORM_COUNT: self.max_num},\n                                            versions=[(form.instance.pk, get_revision_of_object(form.instance)) for form\n                                                      in self.initial_forms])\n        return form"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exportable(self):\n        if 'ExportableCertification' in self._signature.subpackets:\n            return bool(next(iter(self._signature.subpackets['ExportableCertification'])))\n\n        return True", "response": "Returns True if this signature is exportable. Otherwise False."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_expired(self):\n        expires_at = self.expires_at\n        if expires_at is not None and expires_at != self.created:\n            return expires_at < datetime.utcnow()\n\n        return False", "response": "Returns True if the signature has an expiration date. Otherwise False."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef key_flags(self):\n        if 'KeyFlags' in self._signature.subpackets:\n            return next(iter(self._signature.subpackets['h_KeyFlags'])).flags\n        return set()", "response": "A set of all key flags that are set in this signature if any. Otherwise an empty set."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef keyserver(self):\n        if 'PreferredKeyServer' in self._signature.subpackets:\n            return next(iter(self._signature.subpackets['h_PreferredKeyServer'])).uri\n        return ''", "response": "Returns the preferred key server specified in this signature if any. Otherwise an empty string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef notation(self):\n        return dict((nd.name, nd.value) for nd in self._signature.subpackets['NotationData'])", "response": "A dict of notation data in this signature if any. Otherwise an empty dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the policy URI specified in this signature if any. Otherwise an empty string.", "response": "def policy_uri(self):\n        \"\"\"\n        The policy URI specified in this signature, if any. Otherwise, an empty ``str``.\n        \"\"\"\n        if 'Policy' in self._signature.subpackets:\n            return next(iter(self._signature.subpackets['Policy'])).uri\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef revocable(self):\n        if 'Revocable' in self._signature.subpackets:\n            return bool(next(iter(self._signature.subpackets['Revocable'])))\n        return True", "response": "Returns True if this signature is marked as revocable. Otherwise False."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the image of the user attribute.", "response": "def image(self):\n        \"\"\"\n        If this is a User Attribute, this will be the stored image. If this is not a User Attribute, this will be ``None``.\n        \"\"\"\n        return self._uid.image.image if isinstance(self._uid, UserAttribute) else None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the most recent valid self - signature specifies this as primary False otherwise.", "response": "def is_primary(self):\n        \"\"\"\n        If the most recent, valid self-signature specifies this as being primary, this will be True. Otherwise, Faqlse.\n        \"\"\"\n        return bool(next(iter(self.selfsig._signature.subpackets['h_PrimaryUserID']), False))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the self - signature of this User ID or Attribute.", "response": "def selfsig(self):\n        \"\"\"\n        This will be the most recent, self-signature of this User ID or Attribute. If there isn't one, this will be ``None``.\n        \"\"\"\n        if self.parent is not None:\n            return next((sig for sig in reversed(self._signatures) if sig.signer == self.parent.fingerprint.keyid), None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef new(cls, pn, comment=\"\", email=\"\"):\n        uid = PGPUID()\n        if isinstance(pn, bytearray):\n            uid._uid = UserAttribute()\n            uid._uid.image.image = pn\n            uid._uid.image.iencoding = ImageEncoding.encodingof(pn)\n            uid._uid.update_hlen()\n\n        else:\n            uid._uid = UserID()\n            uid._uid.name = pn\n            uid._uid.comment = comment\n            uid._uid.email = email\n            uid._uid.update_hlen()\n\n        return uid", "response": "Create a new User ID or photo."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encrypters(self):\n        return set(m.encrypter for m in self._sessionkeys if isinstance(m, PKESessionKey))", "response": "A set containing all key ids to which this message was encrypted."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new PGPMessage object.", "response": "def new(cls, message, **kwargs):\n        \"\"\"\n        Create a new PGPMessage object.\n\n        :param message: The message to be stored.\n        :type message: ``str``, ``unicode``, ``bytes``, ``bytearray``\n        :returns: :py:obj:`PGPMessage`\n\n        The following optional keyword arguments can be used with :py:meth:`PGPMessage.new`:\n\n        :keyword file: if True, ``message`` should be a path to a file. The contents of that file will be read and used\n                       as the contents of the message.\n        :type file: ``bool``\n        :keyword cleartext: if True, the message will be cleartext with inline signatures.\n        :type cleartext: ``bool``\n        :keyword sensitive: if True, the filename will be set to '_CONSOLE' to signal other OpenPGP clients to treat\n                            this message as being 'for your eyes only'. Ignored if cleartext is True.\n        :type sensitive: ``bool``\n        :keyword format: Set the message format identifier. Ignored if cleartext is True.\n        :type format: ``str``\n        :keyword compression: Set the compression algorithm for the new message.\n                              Defaults to :py:obj:`CompressionAlgorithm.ZIP`. Ignored if cleartext is True.\n        :keyword encoding: Set the Charset header for the message.\n        :type encoding: ``str`` representing a valid codec in codecs\n        \"\"\"\n        # TODO: have 'codecs' above (in :type encoding:) link to python documentation page on codecs\n        cleartext = kwargs.pop('cleartext', False)\n        format = kwargs.pop('format', None)\n        sensitive = kwargs.pop('sensitive', False)\n        compression = kwargs.pop('compression', CompressionAlgorithm.ZIP)\n        file = kwargs.pop('file', False)\n        charset = kwargs.pop('encoding', None)\n\n        filename = ''\n        mtime = datetime.utcnow()\n\n        msg = PGPMessage()\n\n        if charset:\n            msg.charset = charset\n\n        # if format in 'tu' and isinstance(message, (six.binary_type, bytearray)):\n        #     # if message format is text or unicode and we got binary data, we'll need to transcode it to UTF-8\n        #     message =\n\n        if file and os.path.isfile(message):\n            filename = message\n            message = bytearray(os.path.getsize(filename))\n            mtime = datetime.utcfromtimestamp(os.path.getmtime(filename))\n\n            with open(filename, 'rb') as mf:\n                mf.readinto(message)\n\n        # if format is None, we can try to detect it\n        if format is None:\n            if isinstance(message, six.text_type):\n                # message is definitely UTF-8 already\n                format = 'u'\n\n            elif cls.is_ascii(message):\n                # message is probably text\n                format = 't'\n\n            else:\n                # message is probably binary\n                format = 'b'\n\n        # if message is a binary type and we're building a textual message, we need to transcode the bytes to UTF-8\n        if isinstance(message, (six.binary_type, bytearray)) and (cleartext or format in 'tu'):\n            message = message.decode(charset or 'utf-8')\n\n        if cleartext:\n            msg |= message\n\n        else:\n            # load literal data\n            lit = LiteralData()\n            lit._contents = bytearray(msg.text_to_bytes(message))\n            lit.filename = '_CONSOLE' if sensitive else os.path.basename(filename)\n            lit.mtime = mtime\n            lit.format = format\n\n            # if cls.is_ascii(message):\n            #     lit.format = 't'\n\n            lit.update_hlen()\n\n            msg |= lit\n            msg._compression = compression\n\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encrypt(self, passphrase, sessionkey=None, **prefs):\n        cipher_algo = prefs.pop('cipher', SymmetricKeyAlgorithm.AES256)\n        hash_algo = prefs.pop('hash', HashAlgorithm.SHA256)\n\n        # set up a new SKESessionKeyV4\n        skesk = SKESessionKeyV4()\n        skesk.s2k.usage = 255\n        skesk.s2k.specifier = 3\n        skesk.s2k.halg = hash_algo\n        skesk.s2k.encalg = cipher_algo\n        skesk.s2k.count = skesk.s2k.halg.tuned_count\n\n        if sessionkey is None:\n            sessionkey = cipher_algo.gen_key()\n        skesk.encrypt_sk(passphrase, sessionkey)\n        del passphrase\n\n        msg = PGPMessage() | skesk\n\n        if not self.is_encrypted:\n            skedata = IntegrityProtectedSKEDataV1()\n            skedata.encrypt(sessionkey, cipher_algo, self.__bytes__())\n            msg |= skedata\n\n        else:\n            msg |= self\n\n        return msg", "response": "Encrypt the contents of this message using a passphrase and a session key."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decrypt(self, passphrase):\n        if not self.is_encrypted:\n            raise PGPError(\"This message is not encrypted!\")\n\n        for skesk in iter(sk for sk in self._sessionkeys if isinstance(sk, SKESessionKey)):\n            try:\n                symalg, key = skesk.decrypt_sk(passphrase)\n                decmsg = PGPMessage()\n                decmsg.parse(self.message.decrypt(key, symalg))\n\n            except (TypeError, ValueError, NotImplementedError, PGPDecryptionError):\n                continue\n\n            else:\n                del passphrase\n                break\n\n        else:\n            raise PGPDecryptionError(\"Decryption failed\")\n\n        return decmsg", "response": "Attempt to decrypt this message using a passphrase."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef expires_at(self):\n        try:\n            expires = min(sig.key_expiration for sig in itertools.chain(iter(uid.selfsig for uid in self.userids), self.self_signatures)\n                          if sig.key_expiration is not None)\n\n        except ValueError:\n            return None\n\n        else:\n            return (self.created + expires)", "response": "A datetime. datetime object of when this key is to be considered expired. If any of the userids in self_signatures are not None return None."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if this key is expired False otherwise.", "response": "def is_expired(self):\n        \"\"\"``True`` if this key is expired, otherwise ``False``\"\"\"\n        expires = self.expires_at\n        if expires is not None:\n            return expires <= datetime.utcnow()\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if this is a primary key ; False otherwise.", "response": "def is_primary(self):\n        \"\"\"``True`` if this is a primary key; ``False`` if this is a subkey\"\"\"\n        return isinstance(self._key, Primary) and not isinstance(self._key, Sub)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if this is a public key otherwise False.", "response": "def is_public(self):\n        \"\"\"``True`` if this is a public key, otherwise ``False``\"\"\"\n        return isinstance(self._key, Public) and not isinstance(self._key, Private)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the key is unlocked False otherwise.", "response": "def is_unlocked(self):\n        \"\"\"``False`` if this is a private key that is protected with a passphrase and has not yet been unlocked, otherwise ``True``\"\"\"\n        if self.is_public:\n            return True\n\n        if not self.is_protected:\n            return True\n\n        return self._key.unlocked"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the size of the key material.", "response": "def key_size(self):\n        \"\"\"*new in 0.4.1*\n        The size pertaining to this key. ``int`` for non-EC key algorithms; :py:obj:`constants.EllipticCurveOID` for EC keys.\n        \"\"\"\n        if self.key_algorithm in {PubKeyAlgorithm.ECDSA, PubKeyAlgorithm.ECDH}:\n            return self._key.keymaterial.oid\n        return next(iter(self._key.keymaterial)).bit_length()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a corresponding public key object with xid all the trimmings.", "response": "def pubkey(self):\n        \"\"\"If the :py:obj:`PGPKey` object is a private key, this method returns a corresponding public key object with\n        all the trimmings. Otherwise, returns ``None``\n        \"\"\"\n        if not self.is_public:\n            if self._sibling is None or isinstance(self._sibling, weakref.ref):\n                # create a new key shell\n                pub = PGPKey()\n                pub.ascii_headers = self.ascii_headers.copy()\n\n                # get the public half of the primary key\n                pub._key = self._key.pubkey()\n\n                # get the public half of each subkey\n                for skid, subkey in self.subkeys.items():\n                    pub |= subkey.pubkey\n\n                # copy user ids and user attributes\n                for uid in self._uids:\n                    pub |= copy.copy(uid)\n\n                # copy signatures that weren't copied with uids\n                for sig in self._signatures:\n                    if sig.parent is None:\n                        pub |= copy.copy(sig)\n\n                # keep connect the two halves using a weak reference\n                self._sibling = weakref.ref(pub)\n                pub._sibling = weakref.ref(self)\n\n            return self._sibling()\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a new PGP key with the specified algorithm and size.", "response": "def new(cls, key_algorithm, key_size):\n        \"\"\"\n        Generate a new PGP key\n\n        :param key_algorithm: Key algorithm to use.\n        :type key_algorithm: A :py:obj:`~constants.PubKeyAlgorithm`\n        :param key_size: Key size in bits, unless `key_algorithm` is :py:obj:`~constants.PubKeyAlgorithm.ECDSA` or\n               :py:obj:`~constants.PubKeyAlgorithm.ECDH`, in which case it should be the Curve OID to use.\n        :type key_size: ``int`` or :py:obj:`~constants.EllipticCurveOID`\n        :return: A newly generated :py:obj:`PGPKey`\n        \"\"\"\n        # new private key shell first\n        key = PGPKey()\n\n        if key_algorithm in {PubKeyAlgorithm.RSAEncrypt, PubKeyAlgorithm.RSASign}:  # pragma: no cover\n            warnings.warn('{:s} is deprecated - generating key using RSAEncryptOrSign'.format(key_algorithm.name))\n            key_algorithm = PubKeyAlgorithm.RSAEncryptOrSign\n\n        # generate some key data to match key_algorithm and key_size\n        key._key = PrivKeyV4.new(key_algorithm, key_size)\n\n        return key"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef protect(self, passphrase, enc_alg, hash_alg):\n        ##TODO: specify strong defaults for enc_alg and hash_alg\n        if self.is_public:\n            # we can't protect public keys because only private key material is ever protected\n            warnings.warn(\"Public keys cannot be passphrase-protected\", stacklevel=2)\n            return\n\n        if self.is_protected and not self.is_unlocked:\n            # we can't protect a key that is already protected unless it is unlocked first\n            warnings.warn(\"This key is already protected with a passphrase - \"\n                          \"please unlock it before attempting to specify a new passphrase\", stacklevel=2)\n            return\n\n        for sk in itertools.chain([self], self.subkeys.values()):\n            sk._key.protect(passphrase, enc_alg, hash_alg)\n\n        del passphrase", "response": "Add a passphrase to a private key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unlock(self, passphrase):\n        if self.is_public:\n            # we can't unprotect public keys because only private key material is ever protected\n            warnings.warn(\"Public keys cannot be passphrase-protected\", stacklevel=3)\n            yield self\n            return\n\n        if not self.is_protected:\n            # we can't unprotect private keys that are not protected, because there is no ciphertext to decrypt\n            warnings.warn(\"This key is not protected with a passphrase\", stacklevel=3)\n            yield self\n            return\n\n        try:\n            for sk in itertools.chain([self], self.subkeys.values()):\n                sk._key.unprotect(passphrase)\n            del passphrase\n            yield self\n\n        finally:\n            # clean up here by deleting the previously decrypted secret key material\n            for sk in itertools.chain([self], self.subkeys.values()):\n                sk._key.keymaterial.clear()", "response": "Context manager method for unlocking passphrase - protected private keys."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_uid(self, uid, selfsign=True, **prefs):\n        uid._parent = self\n        if selfsign:\n            uid |= self.certify(uid, SignatureType.Positive_Cert, **prefs)\n\n        self |= uid", "response": "Add a User ID to this key."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_uid(self, search):\n        if self.is_primary:\n            return next((u for u in self._uids if search in filter(lambda a: a is not None, (u.name, u.comment, u.email))), None)\n        return self.parent.get_uid(search)", "response": "Find and return a User ID that matches the search string given."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef del_uid(self, search):\n        u = self.get_uid(search)\n\n        if u is None:\n            raise KeyError(\"uid '{:s}' not found\".format(search))\n\n        u._parent = None\n        self._uids.remove(u)", "response": "Removes a user id that matches the search string given."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a key as a subkey to this key.", "response": "def add_subkey(self, key, **prefs):\n        \"\"\"\n        Add a key as a subkey to this key.\n        :param key: A private :py:obj:`~pgpy.PGPKey` that does not have any subkeys of its own\n\n        :keyword usage: A ``set`` of key usage flags, as :py:obj:`~constants.KeyFlags` for the subkey to be added.\n        :type usage: ``set``\n\n        Other valid optional keyword arguments are identical to those of self-signatures for :py:meth:`PGPKey.certify`\n        \"\"\"\n        if self.is_public:\n            raise PGPError(\"Cannot add a subkey to a public key. Add the subkey to the private component first!\")\n\n        if key.is_public:\n            raise PGPError(\"Cannot add a public key as a subkey to this key\")\n\n        if key.is_primary:\n            if len(key._children) > 0:\n                raise PGPError(\"Cannot add a key that already has subkeys as a subkey!\")\n\n            # convert key into a subkey\n            npk = PrivSubKeyV4()\n            npk.pkalg = key._key.pkalg\n            npk.created = key._key.created\n            npk.keymaterial = key._key.keymaterial\n            key._key = npk\n            key._key.update_hlen()\n\n        self._children[key.fingerprint.keyid] = key\n        key._parent = self\n\n        ##TODO: skip this step if the key already has a subkey binding signature\n        bsig = self.bind(key, **prefs)\n        key |= bsig"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _sign(self, subject, sig, **prefs):\n        user = prefs.pop('user', None)\n        uid = None\n        if user is not None:\n            uid = self.get_uid(user)\n\n        else:\n            uid = next(iter(self.userids), None)\n            if uid is None and self.parent is not None:\n                uid = next(iter(self.parent.userids), None)\n\n        if sig.hash_algorithm is None:\n            sig._signature.halg = uid.selfsig.hashprefs[0]\n\n        if uid is not None and sig.hash_algorithm not in uid.selfsig.hashprefs:\n            warnings.warn(\"Selected hash algorithm not in key preferences\", stacklevel=4)\n\n        # signature options that can be applied at any level\n        expires = prefs.pop('expires', None)\n        notation = prefs.pop('notation', None)\n        revocable = prefs.pop('revocable', True)\n        policy_uri = prefs.pop('policy_uri', None)\n\n        if expires is not None:\n            # expires should be a timedelta, so if it's a datetime, turn it into a timedelta\n            if isinstance(expires, datetime):\n                expires = expires - self.created\n\n            sig._signature.subpackets.addnew('SignatureExpirationTime', hashed=True, expires=expires)\n\n        if revocable is False:\n            sig._signature.subpackets.addnew('Revocable', hashed=True, bflag=revocable)\n\n        if notation is not None:\n            for name, value in notation.items():\n                # mark all notations as human readable unless value is a bytearray\n                flags = NotationDataFlags.HumanReadable\n                if isinstance(value, bytearray):\n                    flags = 0x00\n\n                sig._signature.subpackets.addnew('NotationData', hashed=True, flags=flags, name=name, value=value)\n\n        if policy_uri is not None:\n            sig._signature.subpackets.addnew('Policy', hashed=True, uri=policy_uri)\n\n        if user is not None and uid is not None:\n            signers_uid = \"{:s}\".format(uid)\n            sig._signature.subpackets.addnew('SignersUserID', hashed=True, userid=signers_uid)\n\n        # handle an edge case for timestamp signatures vs standalone signatures\n        if sig.type == SignatureType.Timestamp and len(sig._signature.subpackets._hashed_sp) > 1:\n            sig._signature.sigtype = SignatureType.Standalone\n\n        sigdata = sig.hashdata(subject)\n        h2 = sig.hash_algorithm.hasher\n        h2.update(sigdata)\n        sig._signature.hash2 = bytearray(h2.digest()[:2])\n\n        _sig = self._key.sign(sigdata, getattr(hashes, sig.hash_algorithm.name)())\n        if _sig is NotImplemented:\n            raise NotImplementedError(self.key_algorithm)\n\n        sig._signature.signature.from_signer(_sig)\n        sig._signature.update_hlen()\n\n        return sig", "response": "This method is used to sign a subject with a signature."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsigning text a message or a timestamp using this key.", "response": "def sign(self, subject, **prefs):\n        \"\"\"\n        Sign text, a message, or a timestamp using this key.\n\n        :param subject: The text to be signed\n        :type subject: ``str``, :py:obj:`~pgpy.PGPMessage`, ``None``\n        :raises: :py:exc:`~pgpy.errors.PGPError` if the key is passphrase-protected and has not been unlocked\n        :raises: :py:exc:`~pgpy.errors.PGPError` if the key is public\n        :returns: :py:obj:`PGPSignature`\n\n        The following optional keyword arguments can be used with :py:meth:`PGPKey.sign`, as well as\n        :py:meth:`PGPKey.certify`,  :py:meth:`PGPKey.revoke`, and :py:meth:`PGPKey.bind`:\n\n        :keyword expires: Set an expiration date for this signature\n        :type expires: :py:obj:`~datetime.datetime`, :py:obj:`~datetime.timedelta`\n        :keyword notation: Add arbitrary notation data to this signature.\n        :type notation: ``dict``\n        :keyword policy_uri: Add a URI to the signature that should describe the policy under which the signature\n                             was issued.\n        :type policy_uri: ``str``\n        :keyword revocable: If ``False``, this signature will be marked non-revocable\n        :type revocable: ``bool``\n        :keyword user: Specify which User ID to use when creating this signature. Also adds a \"Signer's User ID\"\n                       to the signature.\n        :type user: ``str``\n        \"\"\"\n        sig_type = SignatureType.BinaryDocument\n        hash_algo = prefs.pop('hash', None)\n\n        if subject is None:\n            sig_type = SignatureType.Timestamp\n\n        if isinstance(subject, PGPMessage):\n            if subject.type == 'cleartext':\n                sig_type = SignatureType.CanonicalDocument\n\n            subject = subject.message\n\n        sig = PGPSignature.new(sig_type, self.key_algorithm, hash_algo, self.fingerprint.keyid)\n\n        return self._sign(subject, sig, **prefs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef certify(self, subject, level=SignatureType.Generic_Cert, **prefs):\n        hash_algo = prefs.pop('hash', None)\n        sig_type = level\n        if isinstance(subject, PGPKey):\n            sig_type = SignatureType.DirectlyOnKey\n\n        sig = PGPSignature.new(sig_type, self.key_algorithm, hash_algo, self.fingerprint.keyid)\n\n        # signature options that only make sense in certifications\n        usage = prefs.pop('usage', None)\n        exportable = prefs.pop('exportable', None)\n\n        if usage is not None:\n            sig._signature.subpackets.addnew('KeyFlags', hashed=True, flags=usage)\n\n        if exportable is not None:\n            sig._signature.subpackets.addnew('ExportableCertification', hashed=True, bflag=exportable)\n\n        keyfp = self.fingerprint\n        if isinstance(subject, PGPKey):\n            keyfp = subject.fingerprint\n        if isinstance(subject, PGPUID) and subject._parent is not None:\n            keyfp = subject._parent.fingerprint\n\n        if keyfp == self.fingerprint:\n            # signature options that only make sense in self-certifications\n            cipher_prefs = prefs.pop('ciphers', None)\n            hash_prefs = prefs.pop('hashes', None)\n            compression_prefs = prefs.pop('compression', None)\n            key_expires = prefs.pop('key_expiration', None)\n            keyserver_flags = prefs.pop('keyserver_flags', None)\n            keyserver = prefs.pop('keyserver', None)\n            primary_uid = prefs.pop('primary', None)\n\n            if key_expires is not None:\n                # key expires should be a timedelta, so if it's a datetime, turn it into a timedelta\n                if isinstance(key_expires, datetime):\n                    key_expires = key_expires - self.created\n\n                sig._signature.subpackets.addnew('KeyExpirationTime', hashed=True, expires=key_expires)\n\n            if cipher_prefs is not None:\n                sig._signature.subpackets.addnew('PreferredSymmetricAlgorithms', hashed=True, flags=cipher_prefs)\n\n            if hash_prefs is not None:\n                sig._signature.subpackets.addnew('PreferredHashAlgorithms', hashed=True, flags=hash_prefs)\n                if sig.hash_algorithm is None:\n                    sig._signature.halg = hash_prefs[0]\n\n            if compression_prefs is not None:\n                sig._signature.subpackets.addnew('PreferredCompressionAlgorithms', hashed=True, flags=compression_prefs)\n\n            if keyserver_flags is not None:\n                sig._signature.subpackets.addnew('KeyServerPreferences', hashed=True, flags=keyserver_flags)\n\n            if keyserver is not None:\n                sig._signature.subpackets.addnew('PreferredKeyServer', hashed=True, uri=keyserver)\n\n            if primary_uid is not None:\n                sig._signature.subpackets.addnew('PrimaryUserID', hashed=True, primary=primary_uid)\n\n            # Features is always set on self-signatures\n            sig._signature.subpackets.addnew('Features', hashed=True, flags=Features.pgpy_features)\n\n        else:\n            # signature options that only make sense in non-self-certifications\n            trust = prefs.pop('trust', None)\n            regex = prefs.pop('regex', None)\n\n            if trust is not None:\n                sig._signature.subpackets.addnew('TrustSignature', hashed=True, level=trust[0], amount=trust[1])\n\n                if regex is not None:\n                    sig._signature.subpackets.addnew('RegularExpression', hashed=True, regex=regex)\n\n        return self._sign(subject, sig, **prefs)", "response": "Sign a key or a user id within a key."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrevoke a key a subkey or all current certification signatures of a User ID.", "response": "def revoke(self, target, **prefs):\n        \"\"\"\n        Revoke a key, a subkey, or all current certification signatures of a User ID that were generated by this key so far.\n\n        :param target: The key to revoke\n        :type target: :py:obj:`PGPKey`, :py:obj:`PGPUID`\n        :raises: :py:exc:`~pgpy.errors.PGPError` if the key is passphrase-protected and has not been unlocked\n        :raises: :py:exc:`~pgpy.errors.PGPError` if the key is public\n        :returns: :py:obj:`PGPSignature`\n\n        In addition to the optional keyword arguments accepted by :py:meth:`PGPKey.sign`, the following optional\n        keyword arguments can be used with :py:meth:`PGPKey.revoke`.\n\n        :keyword reason: Defaults to :py:obj:`constants.RevocationReason.NotSpecified`\n        :type reason: One of :py:obj:`constants.RevocationReason`.\n        :keyword comment: Defaults to an empty string.\n        :type comment: ``str``\n        \"\"\"\n        hash_algo = prefs.pop('hash', None)\n        if isinstance(target, PGPUID):\n            sig_type = SignatureType.CertRevocation\n\n        elif isinstance(target, PGPKey):\n            ##TODO: check to make sure that the key that is being revoked:\n            #        - is this key\n            #        - is one of this key's subkeys\n            #        - specifies this key as its revocation key\n            if target.is_primary:\n                sig_type = SignatureType.KeyRevocation\n\n            else:\n                sig_type = SignatureType.SubkeyRevocation\n\n        else:  # pragma: no cover\n            raise TypeError\n\n        sig = PGPSignature.new(sig_type, self.key_algorithm, hash_algo, self.fingerprint.keyid)\n\n        # signature options that only make sense when revoking\n        reason = prefs.pop('reason', RevocationReason.NotSpecified)\n        comment = prefs.pop('comment', \"\")\n        sig._signature.subpackets.addnew('ReasonForRevocation', hashed=True, code=reason, string=comment)\n\n        return self._sign(target, sig, **prefs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a signature that specifies another key as being valid for revocationing this key.", "response": "def revoker(self, revoker, **prefs):\n        \"\"\"\n        Generate a signature that specifies another key as being valid for revoking this key.\n\n        :param revoker: The :py:obj:`PGPKey` to specify as a valid revocation key.\n        :type revoker: :py:obj:`PGPKey`\n        :raises: :py:exc:`~pgpy.errors.PGPError` if the key is passphrase-protected and has not been unlocked\n        :raises: :py:exc:`~pgpy.errors.PGPError` if the key is public\n        :returns: :py:obj:`PGPSignature`\n\n        In addition to the optional keyword arguments accepted by :py:meth:`PGPKey.sign`, the following optional\n        keyword arguments can be used with :py:meth:`PGPKey.revoker`.\n\n        :keyword sensitive: If ``True``, this sets the sensitive flag on the RevocationKey subpacket. Currently,\n                            this has no other effect.\n        :type sensitive: ``bool``\n        \"\"\"\n        hash_algo = prefs.pop('hash', None)\n\n        sig = PGPSignature.new(SignatureType.DirectlyOnKey, self.key_algorithm, hash_algo, self.fingerprint.keyid)\n\n        # signature options that only make sense when adding a revocation key\n        sensitive = prefs.pop('sensitive', False)\n        keyclass = RevocationKeyClass.Normal | (RevocationKeyClass.Sensitive if sensitive else 0x00)\n\n        sig._signature.subpackets.addnew('RevocationKey',\n                                         hashed=True,\n                                         algorithm=revoker.key_algorithm,\n                                         fingerprint=revoker.fingerprint,\n                                         keyclass=keyclass)\n\n        # revocation keys should really not be revocable themselves\n        prefs['revocable'] = False\n        return self._sign(self, sig, **prefs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bind(self, key, **prefs):\n        hash_algo = prefs.pop('hash', None)\n\n        if self.is_primary and not key.is_primary:\n            sig_type = SignatureType.Subkey_Binding\n\n        elif key.is_primary and not self.is_primary:\n            sig_type = SignatureType.PrimaryKey_Binding\n\n        else:  # pragma: no cover\n            raise PGPError\n\n        sig = PGPSignature.new(sig_type, self.key_algorithm, hash_algo, self.fingerprint.keyid)\n\n        if sig_type == SignatureType.Subkey_Binding:\n            # signature options that only make sense in subkey binding signatures\n            usage = prefs.pop('usage', None)\n\n            if usage is not None:\n                sig._signature.subpackets.addnew('KeyFlags', hashed=True, flags=usage)\n\n            # if possible, have the subkey create a primary key binding signature\n            if key.key_algorithm.can_sign:\n                subkeyid = key.fingerprint.keyid\n                esig = None\n\n                if not key.is_public:\n                    esig = key.bind(self)\n\n                elif subkeyid in self.subkeys:  # pragma: no cover\n                    esig = self.subkeys[subkeyid].bind(self)\n\n                if esig is not None:\n                    sig._signature.subpackets.addnew('EmbeddedSignature', hashed=False, _sig=esig._signature)\n\n        return self._sign(key, sig, **prefs)", "response": "Bind a subkey to this key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nverifying a subject with a signature using this key.", "response": "def verify(self, subject, signature=None):\n        \"\"\"\n        Verify a subject with a signature using this key.\n\n        :param subject: The subject to verify\n        :type subject: ``str``, ``unicode``, ``None``, :py:obj:`PGPMessage`, :py:obj:`PGPKey`, :py:obj:`PGPUID`\n        :param signature: If the signature is detached, it should be specified here.\n        :type signature: :py:obj:`PGPSignature`\n        :returns: :py:obj:`~pgpy.types.SignatureVerification`\n        \"\"\"\n        sspairs = []\n\n        # some type checking\n        if not isinstance(subject, (type(None), PGPMessage, PGPKey, PGPUID, PGPSignature, six.string_types, bytes, bytearray)):\n            raise TypeError(\"Unexpected subject value: {:s}\".format(str(type(subject))))\n        if not isinstance(signature, (type(None), PGPSignature)):\n            raise TypeError(\"Unexpected signature value: {:s}\".format(str(type(signature))))\n\n        def _filter_sigs(sigs):\n            _ids = {self.fingerprint.keyid} | set(self.subkeys)\n            return [ sig for sig in sigs if sig.signer in _ids ]\n\n        # collect signature(s)\n        if signature is None:\n            if isinstance(subject, PGPMessage):\n                sspairs += [ (sig, subject.message) for sig in _filter_sigs(subject.signatures) ]\n\n            if isinstance(subject, (PGPUID, PGPKey)):\n                sspairs += [ (sig, subject) for sig in _filter_sigs(subject.__sig__) ]\n\n            if isinstance(subject, PGPKey):\n                # user ids\n                sspairs += [ (sig, uid) for uid in subject.userids for sig in _filter_sigs(uid.__sig__) ]\n                # user attributes\n                sspairs += [ (sig, ua) for ua in subject.userattributes for sig in _filter_sigs(ua.__sig__) ]\n                # subkey binding signatures\n                sspairs += [ (sig, subkey) for subkey in subject.subkeys.values() for sig in _filter_sigs(subkey.__sig__) ]\n\n        elif signature.signer in {self.fingerprint.keyid} | set(self.subkeys):\n            sspairs += [(signature, subject)]\n\n        if len(sspairs) == 0:\n            raise PGPError(\"No signatures to verify\")\n\n        # finally, start verifying signatures\n        sigv = SignatureVerification()\n        for sig, subj in sspairs:\n            if self.fingerprint.keyid != sig.signer and sig.signer in self.subkeys:\n                warnings.warn(\"Signature was signed with this key's subkey: {:s}. \"\n                              \"Verifying with subkey...\".format(sig.signer),\n                              stacklevel=2)\n                sigv &= self.subkeys[sig.signer].verify(subj, sig)\n\n            else:\n                verified = self._key.verify(sig.hashdata(subj), sig.__sig__, getattr(hashes, sig.hash_algorithm.name)())\n                if verified is NotImplemented:\n                    raise NotImplementedError(sig.key_algorithm)\n\n                sigv.add_sigsubj(sig, self.fingerprint.keyid, subj, verified)\n\n        return sigv"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nencrypt a message using this key.", "response": "def encrypt(self, message, sessionkey=None, **prefs):\n        \"\"\"\n        Encrypt a PGPMessage using this key.\n\n        :param message: The message to encrypt.\n        :type message: :py:obj:`PGPMessage`\n        :optional param sessionkey: Provide a session key to use when encrypting something. Default is ``None``.\n                                    If ``None``, a session key of the appropriate length will be generated randomly.\n\n                                    .. warning::\n\n                                        Care should be taken when making use of this option! Session keys *absolutely need*\n                                        to be unpredictable! Use the ``gen_key()`` method on the desired\n                                        :py:obj:`~constants.SymmetricKeyAlgorithm` to generate the session key!\n        :type sessionkey: ``bytes``, ``str``\n\n        :raises: :py:exc:`~errors.PGPEncryptionError` if encryption failed for any reason.\n        :returns: A new :py:obj:`PGPMessage` with the encrypted contents of ``message``\n\n        The following optional keyword arguments can be used with :py:meth:`PGPKey.encrypt`:\n\n        :keyword cipher: Specifies the symmetric block cipher to use when encrypting the message.\n        :type cipher: :py:obj:`~constants.SymmetricKeyAlgorithm`\n        :keyword user: Specifies the User ID to use as the recipient for this encryption operation, for the purposes of\n                       preference defaults and selection validation.\n        :type user: ``str``, ``unicode``\n        \"\"\"\n        user = prefs.pop('user', None)\n        uid = None\n        if user is not None:\n            uid = self.get_uid(user)\n        else:\n            uid = next(iter(self.userids), None)\n            if uid is None and self.parent is not None:\n                uid = next(iter(self.parent.userids), None)\n        cipher_algo = prefs.pop('cipher', uid.selfsig.cipherprefs[0])\n\n        if cipher_algo not in uid.selfsig.cipherprefs:\n            warnings.warn(\"Selected symmetric algorithm not in key preferences\", stacklevel=3)\n\n        if message.is_compressed and message._compression not in uid.selfsig.compprefs:\n            warnings.warn(\"Selected compression algorithm not in key preferences\", stacklevel=3)\n\n        if sessionkey is None:\n            sessionkey = cipher_algo.gen_key()\n\n        # set up a new PKESessionKeyV3\n        pkesk = PKESessionKeyV3()\n        pkesk.encrypter = bytearray(binascii.unhexlify(self.fingerprint.keyid.encode('latin-1')))\n        pkesk.pkalg = self.key_algorithm\n        # pkesk.encrypt_sk(self.__key__, cipher_algo, sessionkey)\n        pkesk.encrypt_sk(self._key, cipher_algo, sessionkey)\n\n        if message.is_encrypted:  # pragma: no cover\n            _m = message\n\n        else:\n            _m = PGPMessage()\n            skedata = IntegrityProtectedSKEDataV1()\n            skedata.encrypt(sessionkey, cipher_algo, message.__bytes__())\n            _m |= skedata\n\n        _m |= pkesk\n\n        return _m"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decrypt(self, message):\n        if not message.is_encrypted:\n            warnings.warn(\"This message is not encrypted\", stacklevel=3)\n            return message\n\n        if self.fingerprint.keyid not in message.encrypters:\n            sks = set(self.subkeys)\n            mis = set(message.encrypters)\n            if sks & mis:\n                skid = list(sks & mis)[0]\n                warnings.warn(\"Message was encrypted with this key's subkey: {:s}. \"\n                              \"Decrypting with that...\".format(skid),\n                              stacklevel=2)\n                return self.subkeys[skid].decrypt(message)\n\n            raise PGPError(\"Cannot decrypt the provided message with this key\")\n\n        pkesk = next(pk for pk in message._sessionkeys if pk.pkalg == self.key_algorithm and pk.encrypter == self.fingerprint.keyid)\n        alg, key = pkesk.decrypt_sk(self._key)\n\n        # now that we have the symmetric cipher used and the key, we can decrypt the actual message\n        decmsg = PGPMessage()\n        decmsg.parse(message.message.decrypt(key, alg))\n\n        return decmsg", "response": "Decrypt a PGPMessage using this key."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload all keys provided into this keyring object.", "response": "def load(self, *args):\n        \"\"\"\n        Load all keys provided into this keyring object.\n\n        :param \\*args: Each arg in ``args`` can be any of the formats supported by :py:meth:`PGPKey.from_path` and\n                      :py:meth:`PGPKey.from_blob`, or a ``list`` or ``tuple`` of these.\n        :type \\*args: ``list``, ``tuple``, ``str``, ``unicode``, ``bytes``, ``bytearray``\n        :returns: a ``set`` containing the unique fingerprints of all of the keys that were loaded during this operation.\n        \"\"\"\n        def _preiter(first, iterable):\n            yield first\n            for item in iterable:\n                yield item\n\n        loaded = set()\n        for key in iter(item for ilist in iter(ilist if isinstance(ilist, (tuple, list)) else [ilist] for ilist in args)\n                        for item in ilist):\n            if os.path.isfile(key):\n                _key, keys = PGPKey.from_file(key)\n\n            else:\n                _key, keys = PGPKey.from_blob(key)\n\n            for ik in _preiter(_key, keys.values()):\n                self._add_key(ik)\n                loaded |= {ik.fingerprint} | {isk.fingerprint for isk in ik.subkeys.values()}\n\n        return list(loaded)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a set of all loaded fingerprints of the keys in the database that match the filters specified.", "response": "def fingerprints(self, keyhalf='any', keytype='any'):\n        \"\"\"\n        List loaded fingerprints with some optional filtering.\n\n        :param str keyhalf: Can be 'any', 'public', or 'private'. If 'public', or 'private', the fingerprints of keys of the\n                            the other type will not be included in the results.\n        :param str keytype: Can be 'any', 'primary', or 'sub'. If 'primary' or 'sub', the fingerprints of keys of the\n                            the other type will not be included in the results.\n        :returns: a ``set`` of fingerprints of keys matching the filters specified.\n        \"\"\"\n        return {pk.fingerprint for pk in self._keys.values()\n                if pk.is_primary in [True if keytype in ['primary', 'any'] else None,\n                                     False if keytype in ['sub', 'any'] else None]\n                if pk.is_public in [True if keyhalf in ['public', 'any'] else None,\n                                    False if keyhalf in ['private', 'any'] else None]}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unload(self, key):\n        assert isinstance(key, PGPKey)\n        pkid = id(key)\n        if pkid in self._keys:\n            # remove references\n            [ kd.remove(pkid) for kd in [self._pubkeys, self._privkeys] if pkid in kd ]\n            # remove the key\n            self._keys.pop(pkid)\n\n            # remove aliases\n            for m, a in [ (m, a) for m in self._aliases for a, p in m.items() if p == pkid ]:\n                m.pop(a)\n                # do a re-sort of this alias if it was not unique\n                if a in self:\n                    self._sort_alias(a)\n\n            # if key is a primary key, unload its subkeys as well\n            if key.is_primary:\n                [ self.unload(sk) for sk in key.subkeys.values() ]", "response": "Unloads a loaded key and its subkeys."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a single tag from a packet.", "response": "def parse(self, packet):\n        \"\"\"\n        There are two formats for headers\n\n        old style\n        ---------\n\n        Old style headers can be 1, 2, 3, or 6 octets long and are composed of a Tag and a Length.\n        If the header length is 1 octet (length_type == 3), then there is no Length field.\n\n        new style\n        ---------\n\n        New style headers can be 2, 3, or 6 octets long and are also composed of a Tag and a Length.\n\n\n        Packet Tag\n        ----------\n\n        The packet tag is the first byte, comprising the following fields:\n\n        +-------------+----------+---------------+---+---+---+---+----------+----------+\n        | byte        | 1                                                              |\n        +-------------+----------+---------------+---+---+---+---+----------+----------+\n        | bit         | 7        | 6             | 5 | 4 | 3 | 2 | 1        | 0        |\n        +-------------+----------+---------------+---+---+---+---+----------+----------+\n        | old-style   | always 1 | packet format | packet tag    | length type         |\n        | description |          | 0 = old-style |               | 0 = 1 octet         |\n        |             |          | 1 = new-style |               | 1 = 2 octets        |\n        |             |          |               |               | 2 = 5 octets        |\n        |             |          |               |               | 3 = no length field |\n        +-------------+          +               +---------------+---------------------+\n        | new-style   |          |               | packet tag                          |\n        | description |          |               |                                     |\n        +-------------+----------+---------------+-------------------------------------+\n\n        :param packet: raw packet bytes\n        \"\"\"\n        self._lenfmt = ((packet[0] & 0x40) >> 6)\n        self.tag = packet[0]\n        if self._lenfmt == 0:\n            self.llen = (packet[0] & 0x03)\n        del packet[0]\n\n        if (self._lenfmt == 0 and self.llen > 0) or self._lenfmt == 1:\n            self.length = packet\n\n        else:\n            # indeterminate packet length\n            self.length = len(packet)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting and re - initialize all private components to zero", "response": "def clear(self):\n        \"\"\"delete and re-initialize all private components to zero\"\"\"\n        for field in self.__privfields__:\n            delattr(self, field)\n            setattr(self, field, MPI(0))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef encrypt(cls, pk, *args):\n        # *args should be:\n        # - m\n        #\n        _m, = args\n\n        # m may need to be PKCS5-padded\n        padder = PKCS7(64).padder()\n        m = padder.update(_m) + padder.finalize()\n\n        km = pk.keymaterial\n\n        ct = cls()\n\n        # generate ephemeral key pair, then store it in ct\n        v = ec.generate_private_key(km.oid.curve(), default_backend())\n        ct.vX = MPI(v.public_key().public_numbers().x)\n        ct.vY = MPI(v.public_key().public_numbers().y)\n\n        # compute the shared point S\n        s = v.exchange(ec.ECDH(), km.__pubkey__())\n\n        # derive the wrapping key\n        z = km.kdf.derive_key(s, km.oid, PubKeyAlgorithm.ECDH, pk.fingerprint)\n\n        # compute C\n        ct.c = aes_key_wrap(z, m, default_backend())\n\n        return ct", "response": "This method encrypts the given message with the given key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetermining if the given text is an ASCII - armored PGP block.", "response": "def is_armor(text):\n        \"\"\"\n        Whether the ``text`` provided is an ASCII-armored PGP block.\n        :param text: A possible ASCII-armored PGP block.\n        :raises: :py:exc:`TypeError` if ``text`` is not a ``str``, ``bytes``, or ``bytearray``\n        :returns: Whether the text is ASCII-armored.\n        \"\"\"\n        if isinstance(text, (bytes, bytearray)):  # pragma: no cover\n            text = text.decode('latin-1')\n\n        return Armorable.__armor_regex.search(text) is not None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ascii_unarmor(text):\n        m = {'magic': None, 'headers': None, 'body': bytearray(), 'crc': None}\n        if not Armorable.is_ascii(text):\n            m['body'] = bytearray(text)\n            return m\n\n        if isinstance(text, (bytes, bytearray)):  # pragma: no cover\n            text = text.decode('latin-1')\n\n        m = Armorable.__armor_regex.search(text)\n\n        if m is None:  # pragma: no cover\n            raise ValueError(\"Expected: ASCII-armored PGP data\")\n\n        m = m.groupdict()\n\n        if m['hashes'] is not None:\n            m['hashes'] = m['hashes'].split(',')\n\n        if m['headers'] is not None:\n            m['headers'] = collections.OrderedDict(re.findall('^(?P<key>.+): (?P<value>.+)$\\n?', m['headers'], flags=re.MULTILINE))\n\n        if m['body'] is not None:\n            try:\n                m['body'] = bytearray(base64.b64decode(m['body'].encode()))\n\n            except (binascii.Error, TypeError) as ex:\n                six.raise_from(PGPError, ex)\n                six.raise_from(PGPError(str(ex)), ex)\n\n        if m['crc'] is not None:\n            m['crc'] = Header.bytes_to_int(base64.b64decode(m['crc'].encode()))\n            if Armorable.crc24(m['body']) != m['crc']:\n                warnings.warn('Incorrect crc24', stacklevel=3)\n\n        return m", "response": "Takes an ASCII - armored PGP block and returns the decoded byte value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bytes_to_int(b, order='big'):  # pragma: no cover\n        if six.PY2:\n            # save the original type of b without having to copy any data\n            _b = b.__class__()\n            if order != 'little':\n                b = reversed(b)\n\n            if not isinstance(_b, bytearray):\n                b = six.iterbytes(b)\n\n            return sum(c << (i * 8) for i, c in enumerate(b))\n\n        return int.from_bytes(b, order)", "response": "convert bytes to integer"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert integer to bytes", "response": "def int_to_bytes(i, minlen=1, order='big'):  # pragma: no cover\n        \"\"\"convert integer to bytes\"\"\"\n        blen = max(minlen, PGPObject.int_byte_len(i), 1)\n\n        if six.PY2:\n            r = iter(_ * 8 for _ in (range(blen) if order == 'little' else range(blen - 1, -1, -1)))\n            return bytes(bytearray((i >> c) & 0xff for c in r))\n\n        return i.to_bytes(blen, order)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check(self):  # pragma: no cover\n        for unsorted in iter(self[i] for i in range(len(self) - 2) if not operator.le(self[i], self[i + 1])):\n            self.resort(unsorted)", "response": "re - sort any items in self that are not sorted"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sdmethod(meth):\n    sd = singledispatch(meth)\n\n    def wrapper(obj, *args, **kwargs):\n        return sd.dispatch(args[0].__class__)(obj, *args, **kwargs)\n\n    wrapper.register = sd.register\n    wrapper.dispatch = sd.dispatch\n    wrapper.registry = sd.registry\n    wrapper._clear_cache = sd._clear_cache\n    functools.update_wrapper(wrapper, meth)\n    return wrapper", "response": "A decorator that returns a function that will be used to call the sdproperty method."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef initialize_key(self, key):\r\n        self.k = key\r\n        self.n = 0\r\n        if self.has_key():\r\n            self.cipher.initialize(key)", "response": "Initializes the key for the next time the key is set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encrypt_with_ad(self, ad: bytes, plaintext: bytes) -> bytes:\r\n        if self.n == MAX_NONCE:\r\n            raise NoiseMaxNonceError('Nonce has depleted!')\r\n\r\n        if not self.has_key():\r\n            return plaintext\r\n\r\n        ciphertext = self.cipher.encrypt(self.k, self.n, ad, plaintext)\r\n        self.n = self.n + 1\r\n        return ciphertext", "response": "Encrypts the given plaintext with the given key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef decrypt_with_ad(self, ad: bytes, ciphertext: bytes) -> bytes:\r\n        if self.n == MAX_NONCE:\r\n            raise NoiseMaxNonceError('Nonce has depleted!')\r\n\r\n        if not self.has_key():\r\n            return ciphertext\r\n\r\n        plaintext = self.cipher.decrypt(self.k, self.n, ad, ciphertext)\r\n        self.n = self.n + 1\r\n        return plaintext", "response": "Decrypts the ciphertext with the given key and returns the decrypted ciphertext."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef initialize_symmetric(cls, noise_protocol: 'NoiseProtocol') -> 'SymmetricState':\r\n        # Create SymmetricState\r\n        instance = cls()\r\n        instance.noise_protocol = noise_protocol\r\n\r\n        # If protocol_name is less than or equal to HASHLEN bytes in length, sets h equal to protocol_name with zero\r\n        # bytes appended to make HASHLEN bytes. Otherwise sets h = HASH(protocol_name).\r\n        if len(noise_protocol.name) <= noise_protocol.hash_fn.hashlen:\r\n            instance.h = noise_protocol.name.ljust(noise_protocol.hash_fn.hashlen, b'\\0')\r\n        else:\r\n            instance.h = noise_protocol.hash_fn.hash(noise_protocol.name)\r\n\r\n        # Sets ck = h.\r\n        instance.ck = instance.h\r\n\r\n        # Calls InitializeKey(empty).\r\n        instance.cipher_state = CipherState(noise_protocol)\r\n        instance.cipher_state.initialize_key(Empty())\r\n        noise_protocol.cipher_state_handshake = instance.cipher_state\r\n\r\n        return instance", "response": "Initializes a new SymmetricState object with the given NoiseProtocol object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmix the hash of the data into the set h.", "response": "def mix_hash(self, data: bytes):\r\n        \"\"\"\r\n        Sets h = HASH(h + data).\r\n\r\n        :param data: bytes sequence\r\n        \"\"\"\r\n        self.h = self.noise_protocol.hash_fn.hash(self.h + data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef encrypt_and_hash(self, plaintext: bytes) -> bytes:\r\n        ciphertext = self.cipher_state.encrypt_with_ad(self.h, plaintext)\r\n        self.mix_hash(ciphertext)\r\n        return ciphertext", "response": "Encrypt and hash the given plaintext."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset plaintext = DecryptWithAd(h, ciphertext), calls MixHash(ciphertext), and returns plaintext. Note that if k is empty, the DecryptWithAd() call will set plaintext equal to ciphertext. :param ciphertext: bytes sequence :return: plaintext bytes sequence", "response": "def decrypt_and_hash(self, ciphertext: bytes) -> bytes:\r\n        \"\"\"\r\n        Sets plaintext = DecryptWithAd(h, ciphertext), calls MixHash(ciphertext), and returns plaintext. Note that if\r\n        k is empty, the DecryptWithAd() call will set plaintext equal to ciphertext.\r\n\r\n        :param ciphertext: bytes sequence\r\n        :return: plaintext bytes sequence\r\n        \"\"\"\r\n        plaintext = self.cipher_state.decrypt_with_ad(self.h, ciphertext)\r\n        self.mix_hash(ciphertext)\r\n        return plaintext"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef split(self):\r\n        # Sets temp_k1, temp_k2 = HKDF(ck, b'', 2).\r\n        temp_k1, temp_k2 = self.noise_protocol.hkdf(self.ck, b'', 2)\r\n\r\n        # If HASHLEN is 64, then truncates temp_k1 and temp_k2 to 32 bytes.\r\n        if self.noise_protocol.hash_fn.hashlen == 64:\r\n            temp_k1 = temp_k1[:32]\r\n            temp_k2 = temp_k2[:32]\r\n\r\n        # Creates two new CipherState objects c1 and c2.\r\n        # Calls c1.InitializeKey(temp_k1) and c2.InitializeKey(temp_k2).\r\n        c1, c2 = CipherState(self.noise_protocol), CipherState(self.noise_protocol)\r\n        c1.initialize_key(temp_k1)\r\n        c2.initialize_key(temp_k2)\r\n        if self.noise_protocol.handshake_state.initiator:\r\n            self.noise_protocol.cipher_state_encrypt = c1\r\n            self.noise_protocol.cipher_state_decrypt = c2\r\n        else:\r\n            self.noise_protocol.cipher_state_encrypt = c2\r\n            self.noise_protocol.cipher_state_decrypt = c1\r\n\r\n        self.noise_protocol.handshake_done()\r\n\r\n        # Returns the pair (c1, c2).\r\n        return c1, c2", "response": "Returns a pair of CipherState objects for encrypting and decrypting transport messages."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef initialize(cls, noise_protocol: 'NoiseProtocol', initiator: bool, prologue: bytes=b'', s: '_KeyPair'=None,\r\n                   e: '_KeyPair'=None, rs: '_KeyPair'=None, re: '_KeyPair'=None) -> 'HandshakeState':\r\n        \"\"\"\r\n        Constructor method.\r\n        Comments below are mostly copied from specification.\r\n        Instead of taking handshake_pattern as an argument, we take full NoiseProtocol object, that way we have access\r\n        to protocol name and crypto functions\r\n\r\n        :param noise_protocol: a valid NoiseProtocol instance\r\n        :param initiator: boolean indicating the initiator or responder role\r\n        :param prologue: byte sequence which may be zero-length, or which may contain context information that both\r\n            parties want to confirm is identical\r\n        :param s: local static key pair\r\n        :param e: local ephemeral key pair\r\n        :param rs: remote party\u2019s static public key\r\n        :param re: remote party\u2019s ephemeral public key\r\n        :return: initialized HandshakeState instance\r\n        \"\"\"\r\n        # Create HandshakeState\r\n        instance = cls()\r\n        instance.noise_protocol = noise_protocol\r\n\r\n        # Originally in specification:\r\n        # \"Derives a protocol_name byte sequence by combining the names for\r\n        # the handshake pattern and crypto functions, as specified in Section 8.\"\r\n        # Instead, we supply the NoiseProtocol to the function. The protocol name should already be validated.\r\n\r\n        # Calls InitializeSymmetric(noise_protocol)\r\n        instance.symmetric_state = SymmetricState.initialize_symmetric(noise_protocol)\r\n\r\n        # Calls MixHash(prologue)\r\n        instance.symmetric_state.mix_hash(prologue)\r\n\r\n        # Sets the initiator, s, e, rs, and re variables to the corresponding arguments\r\n        instance.initiator = initiator\r\n        instance.s = s if s is not None else Empty()\r\n        instance.e = e if e is not None else Empty()\r\n        instance.rs = rs if rs is not None else Empty()\r\n        instance.re = re if re is not None else Empty()\r\n\r\n        # Calls MixHash() once for each public key listed in the pre-messages from handshake_pattern, with the specified\r\n        # public key as input (...). If both initiator and responder have pre-messages, the initiator\u2019s public keys are\r\n        # hashed first\r\n        initiator_keypair_getter = instance._get_local_keypair if initiator else instance._get_remote_keypair\r\n        responder_keypair_getter = instance._get_remote_keypair if initiator else instance._get_local_keypair\r\n        for keypair in map(initiator_keypair_getter, noise_protocol.pattern.get_initiator_pre_messages()):\r\n            instance.symmetric_state.mix_hash(keypair.public_bytes)\r\n        for keypair in map(responder_keypair_getter, noise_protocol.pattern.get_responder_pre_messages()):\r\n            instance.symmetric_state.mix_hash(keypair.public_bytes)\r\n\r\n        # Sets message_patterns to the message patterns from handshake_pattern\r\n        instance.message_patterns = noise_protocol.pattern.tokens.copy()\r\n\r\n        return instance", "response": "Constructs a new instance of the same class with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_message(self, payload: Union[bytes, bytearray], message_buffer: bytearray):\r\n        # Fetches and deletes the next message pattern from message_patterns, then sequentially processes each token\r\n        # from the message pattern\r\n        message_pattern = self.message_patterns.pop(0)\r\n        for token in message_pattern:\r\n            if token == TOKEN_E:\r\n                # Sets e = GENERATE_KEYPAIR(). Appends e.public_key to the buffer. Calls MixHash(e.public_key)\r\n                self.e = self.noise_protocol.dh_fn.generate_keypair() if isinstance(self.e, Empty) else self.e\r\n                message_buffer += self.e.public_bytes\r\n                self.symmetric_state.mix_hash(self.e.public_bytes)\r\n                if self.noise_protocol.is_psk_handshake:\r\n                    self.symmetric_state.mix_key(self.e.public_bytes)\r\n\r\n            elif token == TOKEN_S:\r\n                # Appends EncryptAndHash(s.public_key) to the buffer\r\n                message_buffer += self.symmetric_state.encrypt_and_hash(self.s.public_bytes)\r\n\r\n            elif token == TOKEN_EE:\r\n                # Calls MixKey(DH(e, re))\r\n                self.symmetric_state.mix_key(self.noise_protocol.dh_fn.dh(self.e.private, self.re.public))\r\n\r\n            elif token == TOKEN_ES:\r\n                # Calls MixKey(DH(e, rs)) if initiator, MixKey(DH(s, re)) if responder\r\n                if self.initiator:\r\n                    self.symmetric_state.mix_key(self.noise_protocol.dh_fn.dh(self.e.private, self.rs.public))\r\n                else:\r\n                    self.symmetric_state.mix_key(self.noise_protocol.dh_fn.dh(self.s.private, self.re.public))\r\n\r\n            elif token == TOKEN_SE:\r\n                # Calls MixKey(DH(s, re)) if initiator, MixKey(DH(e, rs)) if responder\r\n                if self.initiator:\r\n                    self.symmetric_state.mix_key(self.noise_protocol.dh_fn.dh(self.s.private, self.re.public))\r\n                else:\r\n                    self.symmetric_state.mix_key(self.noise_protocol.dh_fn.dh(self.e.private, self.rs.public))\r\n\r\n            elif token == TOKEN_SS:\r\n                # Calls MixKey(DH(s, rs))\r\n                self.symmetric_state.mix_key(self.noise_protocol.dh_fn.dh(self.s.private, self.rs.public))\r\n\r\n            elif token == TOKEN_PSK:\r\n                self.symmetric_state.mix_key_and_hash(self.noise_protocol.psks.pop(0))\r\n\r\n            else:\r\n                raise NotImplementedError('Pattern token: {}'.format(token))\r\n\r\n        # Appends EncryptAndHash(payload) to the buffer\r\n        message_buffer += self.symmetric_state.encrypt_and_hash(payload)\r\n\r\n        # If there are no more message patterns returns two new CipherState objects by calling Split()\r\n        if len(self.message_patterns) == 0:\r\n            return self.symmetric_state.split()", "response": "Writes a message to the buffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a message from the message_patterns and returns a tuple of SymmetricState and CipherState objects.", "response": "def read_message(self, message: Union[bytes, bytearray], payload_buffer: bytearray):\r\n        \"\"\"\r\n        Comments below are mostly copied from specification.\r\n\r\n        :param message: byte sequence containing a Noise handshake message\r\n        :param payload_buffer: buffer-like object\r\n        :return: None or result of SymmetricState.split() - tuple (CipherState, CipherState)\r\n        \"\"\"\r\n        # Fetches and deletes the next message pattern from message_patterns, then sequentially processes each token\r\n        # from the message pattern\r\n        dhlen = self.noise_protocol.dh_fn.dhlen\r\n        message_pattern = self.message_patterns.pop(0)\r\n        for token in message_pattern:\r\n            if token == TOKEN_E:\r\n                # Sets re to the next DHLEN bytes from the message. Calls MixHash(re.public_key).\r\n                self.re = self.noise_protocol.keypair_class.from_public_bytes(bytes(message[:dhlen]))\r\n                message = message[dhlen:]\r\n                self.symmetric_state.mix_hash(self.re.public_bytes)\r\n                if self.noise_protocol.is_psk_handshake:\r\n                    self.symmetric_state.mix_key(self.re.public_bytes)\r\n\r\n            elif token == TOKEN_S:\r\n                # Sets temp to the next DHLEN + 16 bytes of the message if HasKey() == True, or to the next DHLEN bytes\r\n                # otherwise. Sets rs to DecryptAndHash(temp).\r\n                if self.noise_protocol.cipher_state_handshake.has_key():\r\n                    temp = bytes(message[:dhlen + 16])\r\n                    message = message[dhlen + 16:]\r\n                else:\r\n                    temp = bytes(message[:dhlen])\r\n                    message = message[dhlen:]\r\n                self.rs = self.noise_protocol.keypair_class.from_public_bytes(\r\n                    self.symmetric_state.decrypt_and_hash(temp)\r\n                )\r\n\r\n            elif token == TOKEN_EE:\r\n                # Calls MixKey(DH(e, re)).\r\n                self.symmetric_state.mix_key(self.noise_protocol.dh_fn.dh(self.e.private, self.re.public))\r\n\r\n            elif token == TOKEN_ES:\r\n                # Calls MixKey(DH(e, rs)) if initiator, MixKey(DH(s, re)) if responder\r\n                if self.initiator:\r\n                    self.symmetric_state.mix_key(self.noise_protocol.dh_fn.dh(self.e.private, self.rs.public))\r\n                else:\r\n                    self.symmetric_state.mix_key(self.noise_protocol.dh_fn.dh(self.s.private, self.re.public))\r\n\r\n            elif token == TOKEN_SE:\r\n                # Calls MixKey(DH(s, re)) if initiator, MixKey(DH(e, rs)) if responder\r\n                if self.initiator:\r\n                    self.symmetric_state.mix_key(self.noise_protocol.dh_fn.dh(self.s.private, self.re.public))\r\n                else:\r\n                    self.symmetric_state.mix_key(self.noise_protocol.dh_fn.dh(self.e.private, self.rs.public))\r\n\r\n            elif token == TOKEN_SS:\r\n                # Calls MixKey(DH(s, rs))\r\n                self.symmetric_state.mix_key(self.noise_protocol.dh_fn.dh(self.s.private, self.rs.public))\r\n\r\n            elif token == TOKEN_PSK:\r\n                self.symmetric_state.mix_key_and_hash(self.noise_protocol.psks.pop(0))\r\n\r\n            else:\r\n                raise NotImplementedError('Pattern token: {}'.format(token))\r\n\r\n        # Calls DecryptAndHash() on the remaining bytes of the message and stores the output into payload_buffer.\r\n        payload_buffer += self.symmetric_state.decrypt_and_hash(bytes(message))\r\n\r\n        # If there are no more message patterns returns two new CipherState objects by calling Split()\r\n        if len(self.message_patterns) == 0:\r\n            return self.symmetric_state.split()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove underscores and capitalizes the neighbouring character", "response": "def mixedcase(path):\n    \"\"\"Removes underscores and capitalizes the neighbouring character\"\"\"\n    words = path.split('_')\n    return words[0] + ''.join(word.title() for word in words[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\noutput a formatted message in the console if debug is activated.", "response": "def _log(self, message, debug=None, **kwargs):\n        \"\"\"Outputs a formatted message in the console if the\n        debug mode is activated.\n\n        :param message: The message that will be printed\n        :param debug: (optional) Overwrite of `Client.debug`\n        :param kwargs: (optional) Arguments that will be passed\n            to the `str.format()` method\n        \"\"\"\n        display_log = self.debug\n        if debug is not None:\n            display_log = debug\n        if display_log:\n            print(message.format(**kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwrapping for session. request.", "response": "def send_request(self, *args, **kwargs):\n        \"\"\"Wrapper for session.request\n        Handle connection reset error even from pyopenssl\n        \"\"\"\n        try:\n            return self.session.request(*args, **kwargs)\n        except ConnectionError:\n            self.session.close()\n            return self.session.request(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrequesting a URL and returns a *Bunched* response. This method basically wraps the request method of the requests module and adds a `path` and `debug` option. A `ValueError` will be thrown if the response is not JSON encoded. :param method: The request method, e.g. 'get', 'post', etc. :param url: The URL to request :param path: (optional) Appended to the request URL. This can be either a string or a list which will be joined by forward slashes. :param extension: (optional) The extension to append to the URL. :param suffix: (optional) Append stuff like trailing slashes the URL. :param params: (optional) The URL query parameters :param headers: (optional) Extra headers to sent with the request. Existing header keys can be overwritten. :param data: (optional) Dictionary :param debug: (optional) Overwrite of `Client.debug` :param cache_lifetime: (optional) The amount of seconds that the response has to be cached for. :param silent: (optional) When ``True`, any exception resulted from HTTP status codes or parsing will be ignored. :param ignore_cache: (optional) When ``True``, a previously cached response of the same request will be ignored. :param format: (optional) The type of request data to parse. May take the following values: - 'json', 'xml', ... both request data load and response are converted to the specified format - (None, 'json') a tuple, with the request data format in pos 0 and the response format in pos 1 defaults to 'json' :param delay: (option) Ensures a minimum delay of seconds between requests. :param kwargs: (optional) Arguments that will be passed to the `requests.request` method :return: :class:`Bunch` object from JSON-parsed response", "response": "def request(self, method, url, path=(), extension=None, suffix=None,\n                params=None, headers=None, data=None, debug=None,\n                cache_lifetime=None, silent=None, ignore_cache=False,\n                format='json', delay=0.0, formatter=None, **kwargs):\n        \"\"\"Requests a URL and returns a *Bunched* response.\n\n        This method basically wraps the request method of the requests\n        module and adds a `path` and `debug` option.\n\n        A `ValueError` will be thrown if the response is not JSON encoded.\n\n        :param method: The request method, e.g. 'get', 'post', etc.\n        :param url: The URL to request\n        :param path: (optional) Appended to the request URL. This can be\n            either a string or a list which will be joined\n            by forward slashes.\n        :param extension: (optional) The extension to append to the URL.\n        :param suffix: (optional) Append stuff like trailing slashes the URL.\n        :param params: (optional) The URL query parameters\n        :param headers: (optional) Extra headers to sent with the request.\n            Existing header keys can be overwritten.\n        :param data: (optional) Dictionary\n        :param debug: (optional) Overwrite of `Client.debug`\n        :param cache_lifetime: (optional) The amount of seconds that the\n            response has to be cached for.\n        :param silent: (optional) When ``True`, any exception resulted\n            from HTTP status codes or parsing will be ignored.\n        :param ignore_cache: (optional) When ``True``, a previously\n            cached response of the same request will be ignored.\n        :param format: (optional) The type of request data to parse.\n            May take the following values:\n              - 'json', 'xml', ... both request data load and response are\n                converted to the specified format\n              - (None, 'json') a tuple, with the request data format in pos 0\n                and the response format in pos 1\n            defaults to 'json'\n        :param delay: (option) Ensures a minimum delay of seconds between\n            requests.\n        :param kwargs: (optional) Arguments that will be passed to\n            the `requests.request` method\n        :return: :class:`Bunch` object from JSON-parsed response\n        \"\"\"\n        if debug is None:\n            debug = self.debug\n\n        # build the request headers\n        request_headers = dict(self.headers.__dict__)\n        if headers is not None:\n            request_headers.update(headers)\n\n        # extract request_format and response_format from format arguments\n        if type(format) in (list, tuple) and len(format) == 2:\n            request_format, response_format = format\n        else:\n            request_format = response_format = format\n\n        # add the 'Content-Type' header and compose data, only when:\n        #   1. the content is actually sent (whatever the HTTP verb is used)\n        #   2. the format is provided ('json' by default)\n        if request_format and (data is not None):\n            request_headers.setdefault(\n                'Content-Type', formats.meta(request_format).get('content_type'))\n            data = formats.compose(request_format, data)\n\n        # form the URL\n        if not hasattr(path, \"encode\"):\n            path = '/'.join(path)\n        if extension is None:\n            extension = ''\n        elif not extension.startswith('.'):\n            extension = '.' + extension\n        if suffix is None:\n            suffix = ''\n        url = '%s%s%s%s' % (url, path, extension, suffix)\n\n        # log a debug message about the request\n        self._log(debug_messages['request'], debug, method=method.upper(),\n                  url=url, headers=request_headers, params=params, data=data)\n\n        # check if the response for this request is cached\n        cache_key = (url, str(params), str(headers))\n        if self.cache.has(cache_key) and not ignore_cache:\n            item = self.cache.get(cache_key)\n            self._log(debug_messages['cached_response'], debug, text=item)\n            return bunchify(item)\n\n        # delay the request if needed\n        if delay > 0:\n            t = time.time()\n            if self._last_request_time is None:\n                self._last_request_time = t\n\n            elapsed = t - self._last_request_time\n            if elapsed < delay:\n                time.sleep(delay - elapsed)\n\n        # use default request parameters\n        for name, value in self.defaults.items():\n            kwargs.setdefault(name, value)\n\n        # execute the request\n        r = self.send_request(method, url, params=params,\n                              headers=request_headers, data=data, **kwargs)\n        self._last_request_time = time.time()\n\n        # when not silent, raise an exception for any HTTP status code >= 400\n        if not silent:\n            r.raise_for_status()\n\n        try:\n            # parse the response into something nice\n            has_body = len(r.text) > 0\n            if not has_body:\n                # TODO: This is set 'No response' for the debug message.\n                #       Extract this into a different variable so that\n                #       `parsed_response` is not ambiguous.\n                parsed_response = 'No response'\n            else:\n                parsed_response = formats.parse(response_format, r.text)\n        except ValueError as e:\n            # we've failed, raise this stuff when not silent\n            if len(r.text) > DEBUG_MAX_TEXT_LENGTH:\n                text = r.text[:DEBUG_MAX_TEXT_LENGTH] + '...'\n            else:\n                text = r.text\n            self._log(debug_messages['incorrect_format_response'], debug,\n                      format=response_format, status_code=r.status_code,\n                      reason=r.reason, text=text)\n            if silent:\n                return None\n            raise e\n\n        # cache the response if required\n        # only GET requests are cached\n        if cache_lifetime and cache_lifetime > 0 and method.lower() == 'get':\n            self.cache.set(cache_key, parsed_response, cache_lifetime)\n\n        # print out a final debug message about the response of the request\n        debug_message = 'success_response' if r.status_code == 200 else \\\n            'failure_response'\n        self._log(debug_messages[debug_message], debug,\n                  status_code=r.status_code, reason=r.reason,\n                  text=parsed_response)\n\n        # return our findings and try to make it a bit nicer\n        if has_body:\n            return bunchify(parsed_response)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef request(self, method, *parts, **options):\n        if len(parts) != 0:\n            # the chain will be extended with the parts and finally a\n            # request will be triggered\n            return self.__call__(*parts).request(method=method, **options)\n\n        else:\n            if 'url' not in options:\n                # the last part constructs the URL\n                options['url'] = self.url()\n\n            for key, value in six.iteritems(self.config):\n                # set the defaults in the options\n                if value is not None:\n                    if isinstance(value, dict):\n                        # prevents overwriting default values in dicts\n                        copy = value.copy()\n                        if options.get(key):\n                            copy.update(options[key])\n                        options[key] = copy\n                    else:\n                        options.setdefault(key, value)\n\n            # at this point, we're ready to completely go down the chain\n            return self._parent.request(method=method, **options)", "response": "This method wraps the requests. request method of the requests module and returns a *Bunched* response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_page(self, route, target, link_name=None):\n        req = proto.Proxy(route=route, target=target, link_name=link_name)\n        self._client._call('AddProxy', req)\n        return ProxiedPage(route, target, link_name, self.address,\n                           self.proxy_prefix)", "response": "Add a new proxied page to the Web UI."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves a proxied page from the Web UI.", "response": "def remove_page(self, route):\n        \"\"\"Remove a proxied page from the Web UI.\n\n        Parameters\n        ----------\n        route : str\n            The route for the proxied page. Must be a valid path *segment* in a\n            url (e.g. ``foo`` in ``/foo/bar/baz``). Routes must be unique\n            across the application.\n        \"\"\"\n        req = proto.RemoveProxyRequest(route=route)\n        self._client._call('RemoveProxy', req)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets all registered pages.", "response": "def get_pages(self):\n        \"\"\"Get all registered pages.\n\n        Returns\n        -------\n        pages : dict\n            A ``dict`` of ``route`` to ``ProxiedPage`` for all pages.\n        \"\"\"\n        resp = self._client._call('GetProxies', proto.GetProxiesRequest())\n        return {i.route: ProxiedPage(i.route, i.target,\n                                     i.link_name if i.link_name else None,\n                                     self.address, self.proxy_prefix)\n                for i in resp.proxy}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def tcp_echo_client(message, loop, host, port):\n    print(\"Connecting to server at %s:%d\" % (host, port))\n    reader, writer = await asyncio.open_connection(host, port, loop=loop)\n\n    writer.write(message.encode())\n    print('Sent: %r' % message)\n\n    data = await reader.read(100)\n    print('Received: %r' % data.decode())\n\n    writer.close()", "response": "Generic python tcp echo client"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends and recieve a message from all running echo servers", "response": "async def echo_all(app, message):\n    \"\"\"Send and recieve a message from all running echo servers\"\"\"\n    # Loop through all registered server addresses\n    for address in app.kv.get_prefix('address.').values():\n        # Parse the host and port from the stored address\n        host, port = address.decode().split(':')\n        port = int(port)\n\n        # Send the message to the echo server\n        await tcp_echo_client(message, loop, host, port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_global_driver(self):\n        address, _ = _read_driver()\n\n        if address is None:\n            raise DriverNotRunningError(\"No driver currently running\")\n\n        security = Security.from_default()\n        return Client(address=address, security=security)", "response": "Connect to the global driver."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start_global_driver(keytab=None, principal=None, log=None,\n                            log_level=None, java_options=None):\n        \"\"\"Start the global driver.\n\n        No-op if the global driver is already running.\n\n        Parameters\n        ----------\n        keytab : str, optional\n            Path to a keytab file to use when starting the driver. If not\n            provided, the driver will login using the ticket cache instead.\n        principal : str, optional\n            The principal to use when starting the driver with a keytab.\n        log : str, bool, or None, optional\n            Sets the logging behavior for the driver. Values may be a path for\n            logs to be written to, ``None`` to log to stdout/stderr, or\n            ``False`` to turn off logging completely. Default is ``None``.\n        log_level : str or skein.model.LogLevel, optional\n            The driver log level. Sets the ``skein.log.level`` system property.\n            One of {'ALL', 'TRACE', 'DEBUG', 'INFO', 'WARN', 'ERROR', 'FATAL',\n            'OFF'} (from most to least verbose). Default is 'INFO'.\n        java_options : str or list of str, optional\n            Additional Java options to forward to the driver. Can also be\n            configured by setting the environment variable\n            ``SKEIN_DRIVER_JAVA_OPTIONS``.\n\n        Returns\n        -------\n        address : str\n            The address of the driver\n        \"\"\"\n        address, pid = _read_driver()\n\n        if address is not None:\n            try:\n                Client(address=address)\n                return address\n            except ConnectionError:\n                if pid_exists(pid):\n                    # PID exists, but we can't connect, reraise\n                    raise\n                # PID doesn't exist, warn and continue as normal\n                context.warn(\"Previous driver at %s, PID %d has died. Restarting.\"\n                             % (address, pid))\n        address, _ = _start_driver(set_global=True,\n                                   keytab=keytab,\n                                   principal=principal,\n                                   log=log,\n                                   log_level=log_level,\n                                   java_options=java_options)\n        return address", "response": "Start the global driver."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop_global_driver(force=False):\n        address, pid = _read_driver()\n        if address is None:\n            return\n\n        if not force:\n            # Attempt to connect first, errors on failure\n            try:\n                Client(address=address)\n            except ConnectionError:\n                if pid_exists(pid):\n                    # PID exists, but we can't connect, reraise\n                    raise\n                # PID doesn't exist, continue cleanup as normal\n        try:\n            os.kill(pid, signal.SIGTERM)\n        except OSError as exc:\n            # If we're forcing a kill, ignore EPERM as well, as we're not sure\n            # if the process is a driver.\n            ignore = (errno.ESRCH, errno.EPERM) if force else (errno.ESRCH,)\n            if exc.errno not in ignore:  # pragma: no cover\n                raise\n\n        try:\n            os.remove(os.path.join(properties.config_dir, 'driver'))\n        except OSError:  # pragma: no cover\n            pass", "response": "Stops the global driver if running."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef close(self):\n        if self._proc is not None:\n            self._proc.stdin.close()\n            self._proc.wait()", "response": "Closes the java driver if started by this client. No - op otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef submit(self, spec):\n        spec = ApplicationSpec._from_any(spec)\n        resp = self._call('submit', spec.to_protobuf())\n        return resp.id", "response": "Submit a new skein application."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef submit_and_connect(self, spec):\n        spec = ApplicationSpec._from_any(spec)\n        app_id = self.submit(spec)\n        try:\n            return self.connect(app_id, security=spec.master.security)\n        except BaseException:\n            self.kill_application(app_id)\n            raise", "response": "Submit a new skein application and wait to connect to it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connect(self, app_id, wait=True, security=None):\n        if wait:\n            resp = self._call('waitForStart', proto.Application(id=app_id))\n        else:\n            resp = self._call('getStatus', proto.Application(id=app_id))\n        report = ApplicationReport.from_protobuf(resp)\n        if report.state is not ApplicationState.RUNNING:\n            raise ApplicationNotRunningError(\n                \"%s is not running. Application state: \"\n                \"%s\" % (app_id, report.state))\n\n        if security is None:\n            security = self.security\n\n        return ApplicationClient('%s:%d' % (report.host, report.port),\n                                 app_id,\n                                 security=security)", "response": "Connect to a running application."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_applications(self, states=None, name=None, user=None, queue=None,\n                         started_begin=None, started_end=None,\n                         finished_begin=None, finished_end=None):\n        \"\"\"Get the status of current skein applications.\n\n        Parameters\n        ----------\n        states : sequence of ApplicationState, optional\n            If provided, applications will be filtered to these application\n            states. Default is ``['SUBMITTED', 'ACCEPTED', 'RUNNING']``.\n        name : str, optional\n            Only select applications with this name.\n        user : str, optional\n            Only select applications with this user.\n        queue : str, optional\n            Only select applications in this queue.\n        started_begin : datetime or str, optional\n            Only select applications that started after this time (inclusive).\n            Can be either a datetime or a string representation of one. String\n            representations can use any of the following formats:\n\n              - ``YYYY-M-D H:M:S`` (e.g. 2019-4-10 14:50:20)\n              - ``YYYY-M-D H:M`` (e.g. 2019-4-10 14:50)\n              - ``YYYY-M-D`` (e.g. 2019-4-10)\n              - ``H:M:S`` (e.g. 14:50:20, today is used for date)\n              - ``H:M`` (e.g. 14:50, today is used for date)\n\n        started_end : datetime or str, optional\n            Only select applications that started before this time (inclusive).\n            Can be either a datetime or a string representation of one.\n        finished_begin : datetime or str, optional\n            Only select applications that finished after this time (inclusive).\n            Can be either a datetime or a string representation of one.\n        finished_end : datetime or str, optional\n            Only select applications that finished before this time (inclusive).\n            Can be either a datetime or a string representation of one.\n\n        Returns\n        -------\n        reports : list of ApplicationReport\n\n        Examples\n        --------\n        Get all the finished and failed applications\n\n        >>> client.get_applications(states=['FINISHED', 'FAILED'])\n        [ApplicationReport<name='demo'>,\n         ApplicationReport<name='dask'>,\n         ApplicationReport<name='demo'>]\n\n        Get all applications named 'demo' started after 2019-4-10:\n\n        >>> client.get_applications(name='demo', started_begin='2019-4-10')\n        [ApplicationReport<name='demo'>,\n         ApplicationReport<name='demo'>]\n        \"\"\"\n        if states is not None:\n            states = tuple(ApplicationState(s) for s in states)\n        else:\n            states = (ApplicationState.SUBMITTED,\n                      ApplicationState.ACCEPTED,\n                      ApplicationState.RUNNING)\n\n        started_begin = self._parse_datetime(started_begin, 'started_begin')\n        started_end = self._parse_datetime(started_end, 'started_end')\n        finished_begin = self._parse_datetime(finished_begin, 'finished_begin')\n        finished_end = self._parse_datetime(finished_end, 'finished_end')\n\n        req = proto.ApplicationsRequest(\n            states=[str(s) for s in states],\n            name=name,\n            user=user,\n            queue=queue,\n            started_begin=datetime_to_millis(started_begin),\n            started_end=datetime_to_millis(started_end),\n            finished_begin=datetime_to_millis(finished_begin),\n            finished_end=datetime_to_millis(finished_end)\n        )\n        resp = self._call('getApplications', req)\n        return sorted((ApplicationReport.from_protobuf(r) for r in resp.reports),\n                      key=lambda x: x.id)", "response": "Get the status of the current skein applications."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the status of nodes in the cluster.", "response": "def get_nodes(self, states=None):\n        \"\"\"Get the status of nodes in the cluster.\n\n        Parameters\n        ----------\n        states : sequence of NodeState, optional\n            If provided, nodes will be filtered to these node states. Default\n            is all states.\n\n        Returns\n        -------\n        reports : list of NodeReport\n\n        Examples\n        --------\n        Get all the running nodes\n\n        >>> client.get_nodes(states=['RUNNING'])\n        [NodeReport<id='worker1.example.com:34721'>,\n         NodeReport<id='worker2.example.com:34721'>]\n        \"\"\"\n        if states is not None:\n            states = tuple(NodeState(s) for s in states)\n        else:\n            states = ()\n\n        req = proto.NodesRequest(states=[str(s) for s in states])\n        resp = self._call('getNodes', req)\n        return sorted((NodeReport.from_protobuf(r) for r in resp.reports),\n                      key=lambda x: x.id)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget information about a queue.", "response": "def get_queue(self, name):\n        \"\"\"Get information about a queue.\n\n        Parameters\n        ----------\n        name : str\n            The queue name.\n\n        Returns\n        -------\n        queue : Queue\n\n        Examples\n        --------\n        >>> client.get_queue('myqueue')\n        Queue<name='myqueue', percent_used=5.00>\n        \"\"\"\n        req = proto.QueueRequest(name=name)\n        resp = self._call('getQueue', req)\n        return Queue.from_protobuf(resp)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_child_queues(self, name):\n        req = proto.QueueRequest(name=name)\n        resp = self._call('getChildQueues', req)\n        return [Queue.from_protobuf(q) for q in resp.queues]", "response": "Get information about all children of a parent queue."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget information about all queues in the cluster.", "response": "def get_all_queues(self):\n        \"\"\"Get information about all queues in the cluster.\n\n        Returns\n        -------\n        queues : list of Queue\n\n        Examples\n        --------\n        >>> client.get_all_queues()\n        [Queue<name='default', percent_used=0.00>,\n         Queue<name='myqueue', percent_used=5.00>,\n         Queue<name='child1', percent_used=10.00>,\n         Queue<name='child2', percent_used=0.00>]\n        \"\"\"\n        resp = self._call('getAllQueues', proto.Empty())\n        return [Queue.from_protobuf(q) for q in resp.queues]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef application_report(self, app_id):\n        resp = self._call('getStatus', proto.Application(id=app_id))\n        return ApplicationReport.from_protobuf(resp)", "response": "Get a report on the status of a skein application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmoving an application to a different queue.", "response": "def move_application(self, app_id, queue):\n        \"\"\"Move an application to a different queue.\n\n        Parameters\n        ----------\n        app_id : str\n            The id of the application to move.\n        queue : str\n            The queue to move the application to.\n        \"\"\"\n        self._call('moveApplication', proto.MoveRequest(id=app_id, queue=queue))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nkill an application. Parameters ---------- app_id : str The id of the application to kill. user : str, optional The user to kill the application as. Requires the current user to have permissions to proxy as ``user``. Default is the current user.", "response": "def kill_application(self, app_id, user=\"\"):\n        \"\"\"Kill an application.\n\n        Parameters\n        ----------\n        app_id : str\n            The id of the application to kill.\n        user : str, optional\n            The user to kill the application as. Requires the current user to\n            have permissions to proxy as ``user``. Default is the current user.\n        \"\"\"\n        self._call('kill', proto.KillRequest(id=app_id, user=user))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef shutdown(self, status='SUCCEEDED', diagnostics=None):\n        req = proto.ShutdownRequest(final_status=str(FinalStatus(status)),\n                                    diagnostics=diagnostics)\n        self._call('shutdown', req)", "response": "Shutdown the application.\n\n        Stop all running containers and shutdown the application.\n\n        Parameters\n        ----------\n        status : FinalStatus, optional\n            The final application status. Default is 'SUCCEEDED'.\n        diagnostics : str, optional\n            The application exit message, usually used for diagnosing failures.\n            Can be seen in the YARN Web UI for completed applications under\n            \"diagnostics\", as well as the ``diagnostic`` field of\n            ``ApplicationReport`` objects. If not provided, a default will be\n            used."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_specification(self):\n        resp = self._call('getApplicationSpec', proto.Empty())\n        return ApplicationSpec.from_protobuf(resp)", "response": "Get the running application s current specification."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef scale(self, service, count=None, delta=None, **kwargs):\n        if 'instances' in kwargs:\n            count = kwargs.pop('instances')\n            warnings.warn(\"instances is deprecated, use count instead\")\n        assert not kwargs\n        if count is not None and delta is not None:\n            raise context.ValueError(\"cannot specify both `count` and `delta`\")\n        elif count is None and delta is None:\n            raise context.ValueError(\"must specify either `count` or `delta`\")\n        if count and count < 0:\n            raise context.ValueError(\"count must be >= 0\")\n\n        req = proto.ScaleRequest(service_name=service,\n                                 count=count,\n                                 delta=delta)\n        resp = self._call('scale', req)\n        return [Container.from_protobuf(c) for c in resp.containers]", "response": "Scale a service to a requested number of instances."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the progress of this application.", "response": "def set_progress(self, progress):\n        \"\"\"Update the progress for this application.\n\n        For applications processing a fixed set of work it may be useful for\n        diagnostics to set the progress as the application processes.\n\n        Progress indicates job progression, and must be a float between 0 and\n        1. By default the progress is set at 0.1 for its duration, which is a\n        good default value for applications that don't know their progress,\n        (e.g. interactive applications).\n\n        Parameters\n        ----------\n        progress : float\n            The application progress, must be a value between 0 and 1.\n        \"\"\"\n        if not (0 <= progress <= 1.0):\n            raise ValueError(\"progress must be between 0 and 1, got %.3f\"\n                             % progress)\n        self._call('SetProgress', proto.SetProgressRequest(progress=progress))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_current(cls):\n        if properties.application_id is None:\n            raise context.ValueError(\"Not running inside a container\")\n\n        return cls(properties.appmaster_address,\n                   properties.application_id,\n                   security=Security.from_default())", "response": "Create an application client from within a running container."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_containers(self, services=None, states=None):\n        if services is not None:\n            services = set(services)\n        if states is not None:\n            states = [str(ContainerState(s)) for s in states]\n\n        req = proto.ContainersRequest(services=services, states=states)\n        resp = self._call('getContainers', req)\n        return sorted((Container.from_protobuf(c) for c in resp.containers),\n                      key=lambda x: (x.service_name, x.instance))", "response": "Get information on containers in this application."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_protobuf(cls, msg):\n        if not isinstance(msg, cls._protobuf_cls):\n            raise TypeError(\"Expected message of type \"\n                            \"%r\" % cls._protobuf_cls.__name__)\n        kwargs = {k: getattr(msg, k) for k in cls._get_params()}\n        return cls(**kwargs)", "response": "Create an instance of a class from a protobuf message."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_protobuf(self):\n        self._validate()\n        kwargs = {k: _convert(getattr(self, k), 'to_protobuf')\n                  for k in self._get_params()}\n        return self._protobuf_cls(**kwargs)", "response": "Convert object to a protobuf message"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts the object to a dict", "response": "def to_dict(self, skip_nulls=True):\n        \"\"\"Convert object to a dict\"\"\"\n        self._validate()\n        out = {}\n        for k in self._get_params():\n            val = getattr(self, k)\n            if not skip_nulls or val is not None:\n                out[k] = _convert(val, 'to_dict', skip_nulls)\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert object to a json string", "response": "def to_json(self, skip_nulls=True):\n        \"\"\"Convert object to a json string\"\"\"\n        return json.dumps(self.to_dict(skip_nulls=skip_nulls))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts object to a yaml string", "response": "def to_yaml(self, skip_nulls=True):\n        \"\"\"Convert object to a yaml string\"\"\"\n        return yaml.safe_dump(self.to_dict(skip_nulls=skip_nulls),\n                              default_flow_style=False)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding the HTML for the current object.", "response": "def build_html():\n    \"\"\"Build the html, to be served by IndexHandler\"\"\"\n    source = AjaxDataSource(data_url='./data',\n                            polling_interval=INTERVAL,\n                            method='GET')\n\n    # OHLC plot\n    p = figure(plot_height=400,\n               title='OHLC',\n               sizing_mode='scale_width',\n               tools=\"xpan,xwheel_zoom,xbox_zoom,reset\",\n               x_axis_type=None,\n               y_axis_location=\"right\",\n               y_axis_label=\"Price ($)\")\n    p.x_range.follow = \"end\"\n    p.x_range.follow_interval = 100\n    p.x_range.range_padding = 0\n    p.line(x='time', y='average', alpha=0.25, line_width=3, color='black',\n           source=source)\n    p.line(x='time', y='ma', alpha=0.8, line_width=2, color='steelblue',\n           source=source)\n    p.segment(x0='time', y0='low', x1='time', y1='high', line_width=2,\n              color='black', source=source)\n    p.segment(x0='time', y0='open', x1='time', y1='close', line_width=8,\n              color='color', source=source, alpha=0.8)\n\n    # MACD plot\n    p2 = figure(plot_height=200,\n                title='MACD',\n                sizing_mode='scale_width',\n                x_range=p.x_range,\n                x_axis_label='Time (s)',\n                tools=\"xpan,xwheel_zoom,xbox_zoom,reset\",\n                y_axis_location=\"right\")\n    p2.line(x='time', y='macd', color='darkred', line_width=2, source=source)\n    p2.line(x='time', y='macd9', color='navy', line_width=2, source=source)\n    p2.segment(x0='time', y0=0, x1='time', y1='macdh', line_width=6, color='steelblue',\n               alpha=0.5, source=source)\n\n    # Combine plots together\n    plot = gridplot([[p], [p2]], toolbar_location=\"left\", plot_width=1000)\n\n    # Compose html from plots and template\n    script, div = components(plot, theme=theme)\n    html = template.render(resources=CDN.render(), script=script, div=div)\n\n    return html"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the next element in the stream and update the plot data", "response": "def update(self):\n        \"\"\"Compute the next element in the stream, and update the plot data\"\"\"\n        # Update the simulated pricing data\n        self.t += 1000 / INTERVAL\n        self.average *= np.random.lognormal(0, 0.04)\n\n        high = self.average * np.exp(np.abs(np.random.gamma(1, 0.03)))\n        low = self.average / np.exp(np.abs(np.random.gamma(1, 0.03)))\n        delta = high - low\n        open = low + delta * np.random.uniform(0.05, 0.95)\n        close = low + delta * np.random.uniform(0.05, 0.95)\n        color = \"darkgreen\" if open < close else \"darkred\"\n\n        for k, point in [('time', self.t),\n                         ('average', self.average),\n                         ('open', open),\n                         ('high', high),\n                         ('low', low),\n                         ('close', close),\n                         ('color', color)]:\n            self.data[k].append(point)\n\n        ema12 = self._ema(self.data['close'], self.kernel12)\n        ema26 = self._ema(self.data['close'], self.kernel26)\n        macd = ema12 - ema26\n\n        self.data['ma'].append(ema12)\n        self.data['macd'].append(macd)\n\n        macd9 = self._ema(self.data['macd'], self.kernel9)\n\n        self.data['macd9'].append(macd9)\n        self.data['macdh'].append(macd - macd9)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef container_instance_from_string(id):\n    try:\n        service, instance = id.rsplit('_', 1)\n        instance = int(instance)\n    except (TypeError, ValueError):\n        raise context.ValueError(\"Invalid container id %r\" % id)\n    return _proto.ContainerInstance(service_name=service, instance=instance)", "response": "Create a ContainerInstance from an id string"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_memory(s):\n    if isinstance(s, integer):\n        out = s\n    elif isinstance(s, float):\n        out = math_ceil(s)\n    elif isinstance(s, string):\n        s = s.replace(' ', '')\n\n        if not s:\n            raise context.ValueError(\"Could not interpret %r as a byte unit\" % s)\n\n        if s[0].isdigit():\n            for i, c in enumerate(reversed(s)):\n                if not c.isalpha():\n                    break\n\n            index = len(s) - i\n            prefix = s[:index]\n            suffix = s[index:]\n\n            try:\n                n = float(prefix)\n            except ValueError:\n                raise context.ValueError(\"Could not interpret %r as a number\" % prefix)\n        else:\n            n = 1\n            suffix = s\n\n        try:\n            multiplier = _byte_sizes[suffix.lower()]\n        except KeyError:\n            raise context.ValueError(\"Could not interpret %r as a byte unit\" % suffix)\n\n        out = math_ceil(n * multiplier / (2 ** 20))\n    else:\n        raise context.TypeError(\"memory must be an integer, got %r\"\n                                % type(s).__name__)\n\n    if out < 0:\n        raise context.ValueError(\"memory must be positive\")\n\n    return out", "response": "Converts bytes expression to number of mebibytes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_default(cls):\n        from .core import properties\n\n        # Are we in a container started by skein?\n        if properties.application_id is not None:\n            if properties.container_dir is not None:\n                cert_path = os.path.join(properties.container_dir, '.skein.crt')\n                key_path = os.path.join(properties.container_dir, '.skein.pem')\n                if os.path.exists(cert_path) and os.path.exists(key_path):\n                    return Security(cert_file=cert_path, key_file=key_path)\n            raise context.FileNotFoundError(\n                \"Failed to resolve .skein.{crt,pem} in 'LOCAL_DIRS'\")\n\n        # Try to load from config_dir, and fallback to minting new credentials\n        try:\n            return cls.from_directory(properties.config_dir)\n        except FileNotFoundError:\n            pass\n\n        new = cls.new_credentials()\n        try:\n            out = new.to_directory(properties.config_dir)\n            context.warn(\"Skein global security credentials not found, \"\n                         \"writing now to %r.\" % properties.config_dir)\n        except FileExistsError:\n            # Race condition between competing processes, use the credentials\n            # written by the other process.\n            out = cls.from_directory(properties.config_dir)\n        return out", "response": "Load the default security configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a security object from a directory.", "response": "def from_directory(cls, directory):\n        \"\"\"Create a security object from a directory.\n\n        Relies on standard names for each file (``skein.crt`` and\n        ``skein.pem``).\"\"\"\n        cert_path = os.path.join(directory, 'skein.crt')\n        key_path = os.path.join(directory, 'skein.pem')\n        for path, name in [(cert_path, 'cert'), (key_path, 'key')]:\n            if not os.path.exists(path):\n                raise context.FileNotFoundError(\n                    \"Security %s file not found at %r\" % (name, path)\n                )\n        return Security(cert_file=cert_path, key_file=key_path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite this security object to a directory.", "response": "def to_directory(self, directory, force=False):\n        \"\"\"Write this security object to a directory.\n\n        Parameters\n        ----------\n        directory : str\n            The directory to write the configuration to.\n        force : bool, optional\n            If security credentials already exist at this location, an error\n            will be raised by default. Set to True to overwrite existing files.\n\n        Returns\n        -------\n        security : Security\n            A new security object backed by the written files.\n        \"\"\"\n        self._validate()\n\n        # Create directory if it doesn't exist\n        makedirs(directory, exist_ok=True)\n\n        cert_path = os.path.join(directory, 'skein.crt')\n        key_path = os.path.join(directory, 'skein.pem')\n        cert_bytes = self._get_bytes('cert')\n        key_bytes = self._get_bytes('key')\n\n        lock_path = os.path.join(directory, 'skein.lock')\n        with lock_file(lock_path):\n            for path, name in [(cert_path, 'skein.crt'), (key_path, 'skein.pem')]:\n                if os.path.exists(path):\n                    if force:\n                        os.unlink(path)\n                    else:\n                        msg = (\"%r file already exists, use `%s` to overwrite\" %\n                               (name, '--force' if context.is_cli else 'force'))\n                        raise context.FileExistsError(msg)\n\n            flags = os.O_WRONLY | os.O_CREAT | os.O_EXCL\n            for path, data in [(cert_path, cert_bytes), (key_path, key_bytes)]:\n                with os.fdopen(os.open(path, flags, 0o600), 'wb') as fil:\n                    fil.write(data)\n\n        return Security(cert_file=cert_path, key_file=key_path)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new Security object with a new certificate and key pair.", "response": "def new_credentials(cls):\n        \"\"\"Create a new Security object with a new certificate/key pair.\"\"\"\n        from cryptography import x509\n        from cryptography.hazmat.backends import default_backend\n        from cryptography.hazmat.primitives import hashes\n        from cryptography.hazmat.primitives import serialization\n        from cryptography.hazmat.primitives.asymmetric import rsa\n        from cryptography.x509.oid import NameOID\n\n        key = rsa.generate_private_key(public_exponent=65537,\n                                       key_size=2048,\n                                       backend=default_backend())\n        key_bytes = key.private_bytes(\n            encoding=serialization.Encoding.PEM,\n            format=serialization.PrivateFormat.PKCS8,\n            encryption_algorithm=serialization.NoEncryption())\n\n        subject = issuer = x509.Name(\n            [x509.NameAttribute(NameOID.COMMON_NAME, u'skein-internal')])\n        now = datetime.utcnow()\n        cert = (x509.CertificateBuilder()\n                    .subject_name(subject)\n                    .issuer_name(issuer)\n                    .public_key(key.public_key())\n                    .serial_number(x509.random_serial_number())\n                    .not_valid_before(now)\n                    .not_valid_after(now + timedelta(days=365))\n                    .sign(key, hashes.SHA256(), default_backend()))\n\n        cert_bytes = cert.public_bytes(serialization.Encoding.PEM)\n\n        return cls(cert_bytes=cert_bytes, key_bytes=key_bytes)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_dict(cls, obj, **kwargs):\n        _origin = _pop_origin(kwargs)\n\n        if isinstance(obj, string):\n            obj = {'source': obj}\n\n        cls._check_keys(obj)\n        if _origin:\n            if 'source' not in obj:\n                raise context.TypeError(\"parameter 'source' is required but \"\n                                        \"wasn't provided\")\n            obj = dict(obj)\n            obj['source'] = cls._normpath(obj['source'], _origin)\n        return cls(**obj)", "response": "Create an instance of a ResourceRecordSet from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _from_any(cls, spec):\n        if isinstance(spec, str):\n            spec = cls.from_file(spec)\n        elif isinstance(spec, dict):\n            spec = cls.from_dict(spec)\n        elif not isinstance(spec, cls):\n            raise context.TypeError(\"spec must be either an ApplicationSpec, \"\n                                    \"path, or dict, got \"\n                                    \"%s\" % type(spec).__name__)\n        return spec", "response": "Generic creation method for all types accepted as spec"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_file(cls, path, format='infer'):\n        format = _infer_format(path, format=format)\n        origin = os.path.abspath(os.path.dirname(path))\n\n        with open(path) as f:\n            data = f.read()\n        if format == 'json':\n            obj = json.loads(data)\n        else:\n            obj = yaml.safe_load(data)\n        return cls.from_dict(obj, _origin=origin)", "response": "Create an instance of the class from a json or yaml file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_file(self, path, format='infer', skip_nulls=True):\n        format = _infer_format(path, format=format)\n        data = getattr(self, 'to_' + format)(skip_nulls=skip_nulls)\n        with open(path, mode='w') as f:\n            f.write(data)", "response": "Write object to a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lock_file(path):\n    with _paths_lock:\n        lock = _paths_to_locks.get(path)\n        if lock is None:\n            _paths_to_locks[path] = lock = _FileLock(path)\n    return lock", "response": "Creates a file based lock on path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef datetime_to_millis(x):\n    if x is None:\n        return None\n    if hasattr(x, 'timestamp'):\n        # Python >= 3.3\n        secs = x.timestamp()\n    elif x.tzinfo is None:\n        # Timezone naive\n        secs = (time.mktime((x.year, x.month, x.day,\n                             x.hour, x.minute, x.second,\n                             -1, -1, -1)) + x.microsecond / 1e6)\n    else:\n        # Timezone aware\n        secs = (x - _EPOCH).total_seconds()\n    return int(secs * 1000)", "response": "Convert a datetime. datetime to milliseconds since the epoch"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat an ascii table for given columns and rows.", "response": "def format_table(columns, rows):\n    \"\"\"Formats an ascii table for given columns and rows.\n\n    Parameters\n    ----------\n    columns : list\n        The column names\n    rows : list of tuples\n        The rows in the table. Each tuple must be the same length as\n        ``columns``.\n    \"\"\"\n    rows = [tuple(str(i) for i in r) for r in rows]\n    columns = tuple(str(i).upper() for i in columns)\n    if rows:\n        widths = tuple(max(max(map(len, x)), len(c))\n                       for x, c in zip(zip(*rows), columns))\n    else:\n        widths = tuple(map(len, columns))\n    row_template = ('    '.join('%%-%ds' for _ in columns)) % widths\n    header = (row_template % tuple(columns)).strip()\n    if rows:\n        data = '\\n'.join((row_template % r).strip() for r in rows)\n        return '\\n'.join([header, data])\n    else:\n        return header"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd select2 data attributes.", "response": "def build_attrs(self, *args, **kwargs):\n        \"\"\"Add select2 data attributes.\"\"\"\n        attrs = super(Select2Mixin, self).build_attrs(*args, **kwargs)\n        if self.is_required:\n            attrs.setdefault('data-allow-clear', 'false')\n        else:\n            attrs.setdefault('data-allow-clear', 'true')\n            attrs.setdefault('data-placeholder', '')\n\n        attrs.setdefault('data-minimum-input-length', 0)\n        if 'class' in attrs:\n            attrs['class'] += ' django-select2'\n        else:\n            attrs['class'] = 'django-select2'\n        return attrs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd empty option for clearable selects.", "response": "def optgroups(self, name, value, attrs=None):\n        \"\"\"Add empty option for clearable selects.\"\"\"\n        if not self.is_required and not self.allow_multiple_selected:\n            self.choices = list(chain([('', '')], self.choices))\n        return super(Select2Mixin, self).optgroups(name, value, attrs=attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_media(self):\n        lang = get_language()\n        select2_js = (settings.SELECT2_JS,) if settings.SELECT2_JS else ()\n        select2_css = (settings.SELECT2_CSS,) if settings.SELECT2_CSS else ()\n\n        i18n_name = SELECT2_TRANSLATIONS.get(lang)\n        if i18n_name not in settings.SELECT2_I18N_AVAILABLE_LANGUAGES:\n            i18n_name = None\n\n        i18n_file = ('%s/%s.js' % (settings.SELECT2_I18N_PATH, i18n_name),) if i18n_name else ()\n\n        return forms.Media(\n            js=select2_js + i18n_file + ('django_select2/django_select2.js',),\n            css={'screen': select2_css}\n        )", "response": "Construct a Media instance with the dynamic property."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds select2 s tag attributes.", "response": "def build_attrs(self, *args, **kwargs):\n        \"\"\"Add select2's tag attributes.\"\"\"\n        self.attrs.setdefault('data-minimum-input-length', 1)\n        self.attrs.setdefault('data-tags', 'true')\n        self.attrs.setdefault('data-token-separators', '[\",\", \" \"]')\n        return super(Select2TagMixin, self).build_attrs(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_attrs(self, *args, **kwargs):\n        attrs = super(HeavySelect2Mixin, self).build_attrs(*args, **kwargs)\n\n        # encrypt instance Id\n        self.widget_id = signing.dumps(id(self))\n\n        attrs['data-field_id'] = self.widget_id\n        attrs.setdefault('data-ajax--url', self.get_url())\n        attrs.setdefault('data-ajax--cache', \"true\")\n        attrs.setdefault('data-ajax--type', \"GET\")\n        attrs.setdefault('data-minimum-input-length', 2)\n        if self.dependent_fields:\n            attrs.setdefault('data-select2-dependent-fields', \" \".join(self.dependent_fields))\n\n        attrs['class'] += ' django-select2-heavy'\n        return attrs", "response": "Set select2 s AJAX attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render(self, *args, **kwargs):\n        output = super(HeavySelect2Mixin, self).render(*args, **kwargs)\n        self.set_to_cache()\n        return output", "response": "Render widget and register it in Django s cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_to_cache(self):\n        try:\n            cache.set(self._get_cache_key(), {\n                'widget': self,\n                'url': self.get_url(),\n            })\n        except (PicklingError, AttributeError):\n            msg = \"You need to overwrite \\\"set_to_cache\\\" or ensure that %s is serialisable.\"\n            raise NotImplementedError(msg % self.__class__.__name__)", "response": "Add this object to Django s cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd the widget s attributes to Django s cache.", "response": "def set_to_cache(self):\n        \"\"\"\n        Add widget's attributes to Django's cache.\n\n        Split the QuerySet, to not pickle the result set.\n        \"\"\"\n        queryset = self.get_queryset()\n        cache.set(self._get_cache_key(), {\n            'queryset':\n                [\n                    queryset.none(),\n                    queryset.query,\n                ],\n            'cls': self.__class__,\n            'search_fields': tuple(self.search_fields),\n            'max_results': int(self.max_results),\n            'url': str(self.get_url()),\n            'dependent_fields': dict(self.dependent_fields),\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter_queryset(self, request, term, queryset=None, **dependent_fields):\n        if queryset is None:\n            queryset = self.get_queryset()\n        search_fields = self.get_search_fields()\n        select = Q()\n        term = term.replace('\\t', ' ')\n        term = term.replace('\\n', ' ')\n        for t in [t for t in term.split(' ') if not t == '']:\n            select &= reduce(lambda x, y: x | Q(**{y: t}), search_fields,\n                             Q(**{search_fields[0]: t}))\n        if dependent_fields:\n            select &= Q(**dependent_fields)\n\n        return queryset.filter(select).distinct()", "response": "Filter the queryset by search_fields matching the passed term."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_search_fields(self):\n        if self.search_fields:\n            return self.search_fields\n        raise NotImplementedError('%s, must implement \"search_fields\".' % self.__class__.__name__)", "response": "Return list of lookup names."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns only selected options and set QuerySet from ModelChoicesIterator.", "response": "def optgroups(self, name, value, attrs=None):\n        \"\"\"Return only selected options and set QuerySet from `ModelChoicesIterator`.\"\"\"\n        default = (None, [], 0)\n        groups = [default]\n        has_selected = False\n        selected_choices = {str(v) for v in value}\n        if not self.is_required and not self.allow_multiple_selected:\n            default[1].append(self.create_option(name, '', '', False, 0))\n        if not isinstance(self.choices, ModelChoiceIterator):\n            return super(ModelSelect2Mixin, self).optgroups(name, value, attrs=attrs)\n        selected_choices = {\n            c for c in selected_choices\n            if c not in self.choices.field.empty_values\n        }\n        field_name = self.choices.field.to_field_name or 'pk'\n        query = Q(**{'%s__in' % field_name: selected_choices})\n        for obj in self.choices.queryset.filter(query):\n            option_value = self.choices.choice(obj)[0]\n            option_label = self.label_from_instance(obj)\n\n            selected = (\n                str(option_value) in value and\n                (has_selected is False or self.allow_multiple_selected)\n            )\n            if selected is True and has_selected is False:\n                has_selected = True\n            index = len(default[1])\n            subgroup = default[1]\n            subgroup.append(self.create_option(name, option_value, option_label, selected_choices, index))\n        return groups"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a : class :. django. http. JsonResponse.", "response": "def get(self, request, *args, **kwargs):\n        \"\"\"\n        Return a :class:`.django.http.JsonResponse`.\n\n        Example::\n\n            {\n                'results': [\n                    {\n                        'text': \"foo\",\n                        'id': 123\n                    }\n                ],\n                'more': true\n            }\n\n        \"\"\"\n        self.widget = self.get_widget_or_404()\n        self.term = kwargs.get('term', request.GET.get('term', ''))\n        self.object_list = self.get_queryset()\n        context = self.get_context_data()\n        return JsonResponse({\n            'results': [\n                {\n                    'text': self.widget.label_from_instance(obj),\n                    'id': obj.pk,\n                }\n                for obj in context['object_list']\n                ],\n            'more': context['page_obj'].has_next()\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_queryset(self):\n        kwargs = {\n            model_field_name: self.request.GET.get(form_field_name)\n            for form_field_name, model_field_name in self.widget.dependent_fields.items()\n            if form_field_name in self.request.GET and self.request.GET.get(form_field_name, '') != ''\n        }\n        return self.widget.filter_queryset(self.request, self.term, self.queryset, **kwargs)", "response": "Get QuerySet from cached widget."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_widget_or_404(self):\n        field_id = self.kwargs.get('field_id', self.request.GET.get('field_id', None))\n        if not field_id:\n            raise Http404('No \"field_id\" provided.')\n        try:\n            key = signing.loads(field_id)\n        except BadSignature:\n            raise Http404('Invalid \"field_id\".')\n        else:\n            cache_key = '%s%s' % (settings.SELECT2_CACHE_PREFIX, key)\n            widget_dict = cache.get(cache_key)\n            if widget_dict is None:\n                raise Http404('field_id not found')\n            if widget_dict.pop('url') != self.request.path:\n                raise Http404('field_id was issued for the view.')\n        qs, qs.query = widget_dict.pop('queryset')\n        self.queryset = qs.all()\n        widget_dict['queryset'] = self.queryset\n        widget_cls = widget_dict.pop('cls')\n        return widget_cls(**widget_dict)", "response": "Get and return a widget from cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading a custom widget for the form field.", "response": "def load_widget(path):\n    \"\"\" Load custom widget for the form field \"\"\"\n    i = path.rfind('.')\n    module, attr = path[:i], path[i + 1:]\n    try:\n        mod = import_module(module)\n    except (ImportError, ValueError) as e:\n        error_message = 'Error importing widget for BleachField %s: \"%s\"'\n        raise ImproperlyConfigured(error_message % (path, e))\n\n    try:\n        cls = getattr(mod, attr)\n    except AttributeError:\n        raise ImproperlyConfigured(\n            'Module \"%s\" does not define a \"%s\" widget' % (module, attr)\n        )\n\n    return cls"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the default widget or the widget defined in settings. BLEACH_DEFAULT_WIDGET", "response": "def get_default_widget():\n    \"\"\" Get the default widget or the widget defined in settings \"\"\"\n    default_widget = forms.Textarea\n    if hasattr(settings, 'BLEACH_DEFAULT_WIDGET'):\n        default_widget = load_widget(settings.BLEACH_DEFAULT_WIDGET)\n    return default_widget"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert the value to a string.", "response": "def to_python(self, value):\n        \"\"\"\n        Strips any dodgy HTML tags from the input\n        \"\"\"\n        if value in self.empty_values:\n            try:\n                return self.empty_value\n            except AttributeError:\n                # CharField.empty_value was introduced in Django 1.11; in prior\n                # versions a unicode string was returned for empty values in\n                # all cases.\n                return u''\n        return bleach.clean(value, **self.bleach_options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_config(self, organization, config, actor=None):\n        if config.get('name'):\n            client = self.get_client(actor)\n            try:\n                repo = client.get_repo(config['name'])\n            except Exception as e:\n                self.raise_error(e)\n            else:\n                config['external_id'] = six.text_type(repo['id'])\n        return config", "response": "```\n        if config['foo'] and not config['bar']:\n            raise PluginError('You cannot configure foo with bar')\n        return config\n        ```"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild a dynamic field based on JIRA s meta field information.", "response": "def build_dynamic_field(self, group, field_meta):\n        \"\"\"\n        Builds a field based on JIRA's meta field information\n        \"\"\"\n        schema = field_meta['schema']\n\n        # set up some defaults for form fields\n        fieldtype = 'text'\n        fkwargs = {\n            'label': field_meta['name'],\n            'required': field_meta['required'],\n        }\n        # override defaults based on field configuration\n        if (schema['type'] in ['securitylevel', 'priority']\n                or schema.get('custom') == JIRA_CUSTOM_FIELD_TYPES['select']):\n            fieldtype = 'select'\n            fkwargs['choices'] = self.make_choices(field_meta.get('allowedValues'))\n        elif field_meta.get('autoCompleteUrl') and \\\n                (schema.get('items') == 'user' or schema['type'] == 'user'):\n            fieldtype = 'select'\n            sentry_url = '/api/0/issues/%s/plugins/%s/autocomplete' % (group.id, self.slug)\n            fkwargs['url'] = '%s?jira_url=%s' % (\n                sentry_url, quote_plus(field_meta['autoCompleteUrl']),\n            )\n            fkwargs['has_autocomplete'] = True\n            fkwargs['placeholder'] = 'Start typing to search for a user'\n        elif schema['type'] in ['timetracking']:\n            # TODO: Implement timetracking (currently unsupported alltogether)\n            return None\n        elif schema.get('items') in ['worklog', 'attachment']:\n            # TODO: Implement worklogs and attachments someday\n            return None\n        elif schema['type'] == 'array' and schema['items'] != 'string':\n            fieldtype = 'select'\n            fkwargs.update(\n                {\n                    'multiple': True,\n                    'choices': self.make_choices(field_meta.get('allowedValues')),\n                    'default': []\n                }\n            )\n\n        # break this out, since multiple field types could additionally\n        # be configured to use a custom property instead of a default.\n        if schema.get('custom'):\n            if schema['custom'] == JIRA_CUSTOM_FIELD_TYPES['textarea']:\n                fieldtype = 'textarea'\n\n        fkwargs['type'] = fieldtype\n        return fkwargs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nvalidate the config and return the config dict.", "response": "def validate_config(self, project, config, actor=None):\n        \"\"\"\n        ```\n        if config['foo'] and not config['bar']:\n            raise PluginError('You cannot configure foo with bar')\n        return config\n        ```\n        \"\"\"\n        client = JiraClient(config['instance_url'], config['username'], config['password'])\n        try:\n            client.get_projects_list()\n        except ApiError as e:\n            self.raise_error(e)\n\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new issue on the remote service and returns an issue ID.", "response": "def create_issue(self, request, group, form_data, **kwargs):\n        \"\"\"\n        Creates the issue on the remote service and returns an issue ID.\n        \"\"\"\n        instance = self.get_option('instance', group.project)\n        project = (\n            form_data.get('project') or\n            self.get_option('default_project', group.project)\n        )\n\n        client = self.get_client(request.user)\n\n        title = form_data['title']\n        description = form_data['description']\n        link = absolute_uri(group.get_absolute_url(params={'referrer': 'vsts_plugin'}))\n        try:\n            created_item = client.create_work_item(\n                instance=instance,\n                project=project,\n                title=title,\n                comment=markdown(description),\n                link=link,\n            )\n        except Exception as e:\n            self.raise_error(e, identity=client.auth)\n\n        return {\n            'id': created_item['id'],\n            'url': created_item['_links']['html']['href'],\n            'title': title,\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_cached(self, full_url):\n        key = 'sentry-jira:' + md5(full_url, self.base_url).hexdigest()\n        cached_result = cache.get(key)\n        if not cached_result:\n            cached_result = self.get(full_url)\n            cache.set(key, cached_result, 60)\n        return cached_result", "response": "Basic Caching mechanism for requests and responses."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __apply_mask(address_packed, mask_packed, nr_bytes):\n\n    anon_packed = bytearray()\n    for i in range(0, nr_bytes):\n        anon_packed.append(ord(mask_packed[i]) & ord(address_packed[i]))\n    return six.text_type(ip_address(six.binary_type(anon_packed)))", "response": "Perform a bitwise AND operation on all corresponding bytes between the provided address and the provided mask."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsubmits a conversion to Nexmo.", "response": "def submit_sms_conversion(self, message_id, delivered=True, timestamp=None):\n        \"\"\"\n        Notify Nexmo that an SMS was successfully received.\n\n        :param message_id: The `message-id` str returned by the send_message call.\n        :param delivered: A `bool` indicating that the message was or was not successfully delivered.\n        :param timestamp: A `datetime` object containing the time the SMS arrived.\n        :return: The parsed response from the server. On success, the bytestring b'OK'\n        \"\"\"\n        params = {\n            \"message-id\": message_id,\n            \"delivered\": delivered,\n            \"timestamp\": timestamp or datetime.now(pytz.utc),\n        }\n        # Ensure timestamp is a string:\n        _format_date_param(params, \"timestamp\")\n        return self.post(self.api_host, \"/conversions/sms\", params)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fmt(self):\n      lines = [ ]\n      def write (line):\n        lines.append(line)\n      if self._defaults:\n          write(\"[%s]\\n\" % DEFAULTSECT)\n          for (key, value) in self._defaults.items():\n              write(\"%s = %s\\n\" % (key, str(value).replace('\\n', '\\n\\t')))\n          write(\"\\n\")\n      for section in self._sections:\n          write(\"[%s]\\n\" % section)\n          for (key, value) in self._sections[section].items():\n              if key == \"__name__\":\n                  continue\n              if (value is not None) or (self._optcre == self.OPTCRE):\n                  key = \" = \".join((key, str(value).replace('\\n', '\\n\\t')))\n              write(\"%s\\n\" % (key))\n          write(\"\\n\")\n      return \"\".join(lines)", "response": "Return an. ini - format representation of the configuration state."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nallows us to use method to set up the application.", "response": "def setup_application (self):\n    \"\"\" Allows us to use method, injected as dependency earlier to set\n    up argparser before autocompletion/running the app.\n    \"\"\"\n    # figure out precise method name, specific to this use\n    name = 'configure_%s_app' % self.parent.name\n    # call generic set up method\n    getattr(self.method, 'configure_app', self._no_op_setup)(self, self.parser)\n    # call specific set up method\n    getattr(self.method, name, self._no_op_setup)(self, self.parser)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef geo_distance(a, b):\n    a_y = radians(a.y)\n    b_y = radians(b.y)\n    delta_x = radians(a.x - b.x)\n    cos_x = (sin(a_y) * sin(b_y) +\n             cos(a_y) * cos(b_y) * cos(delta_x))\n    return acos(cos_x) * earth_radius_km", "response": "Distance between two geo points in km."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_stripped_file_lines(filename):\n    try:\n        lines = open(filename).readlines()\n    except FileNotFoundError:\n        fatal(\"Could not open file: {!r}\".format(filename))\n\n    return [line.strip() for line in lines]", "response": "Return lines of a file with whitespace removed"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates a resolver s nameservers.", "response": "def update_resolver_nameservers(resolver, nameservers, nameserver_filename):\n    \"\"\"\n    Update a resolver's nameservers. The following priority is taken:\n        1. Nameservers list provided as an argument\n        2. A filename containing a list of nameservers\n        3. The original nameservers associated with the resolver\n    \"\"\"\n    if nameservers:\n        resolver.nameservers = nameservers\n    elif nameserver_filename:\n        nameservers = get_stripped_file_lines(nameserver_filename)\n        resolver.nameservers = nameservers\n    else:\n        # Use original nameservers\n        pass\n\n    return resolver"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_settings(from_environment=False, locustfile=None,\n        classes=None, host=None, num_clients=None,\n        hatch_rate=None, reset_stats=False, run_time=\"3m\"):\n    '''\n    Returns a settings object to be used by a LocalLocustRunner.\n\n    Arguments\n\n        from_environment: get settings from environment variables\n        locustfile: locustfile to use for loadtest\n        classes: locust classes to use for load test\n        host: host for load testing\n        num_clients: number of clients to simulate in load test\n        hatch_rate: number of clients per second to start\n        reset_stats: Whether to reset stats after all clients are hatched\n        run_time: The length of time to run the test for. Cannot exceed the duration limit set by lambda\n\n    If from_environment is set to True then this function will attempt to set\n    the attributes from environment variables. The environment variables are\n    named LOCUST_ + attribute name in upper case.\n    '''\n\n    settings = type('', (), {})()\n\n    settings.from_environment = from_environment\n    settings.locustfile = locustfile\n    settings.classes = classes\n    settings.host = host\n    settings.num_clients = num_clients\n    settings.hatch_rate = hatch_rate\n    settings.reset_stats = reset_stats\n    settings.run_time = run_time\n\n    # Default settings that are not to be changed\n    settings.no_web = True\n    settings.master = False\n    settings.show_task_ratio_json = False\n    settings.list_commands = False\n    settings.loglevel = 'INFO'\n    settings.slave = False\n    settings.only_summary = True\n    settings.logfile = None\n    settings.show_task_ratio = False\n    settings.print_stats = False\n\n    if from_environment:\n        for attribute in ['locustfile', 'classes', 'host', 'run_time', 'num_clients', 'hatch_rate']:\n            var_name = 'LOCUST_{0}'.format(attribute.upper())\n            var_value = os.environ.get(var_name)\n            if var_value:\n                setattr(settings, attribute, var_value)\n\n    if settings.locustfile is None and settings.classes is None:\n        raise Exception('One of locustfile or classes must be specified')\n\n    if settings.locustfile and settings.classes:\n        raise Exception('Only one of locustfile or classes can be specified')\n\n    if settings.locustfile:\n        docstring, classes = load_locustfile(settings.locustfile)\n        settings.classes = [classes[n] for n in classes]\n    else:\n        if isinstance(settings.classes, str):\n            settings.classes = settings.classes.split(',')\n            for idx, val in enumerate(settings.classes):\n                # This needs fixing\n                settings.classes[idx] = eval(val)\n\n    for attribute in ['classes', 'host', 'num_clients', 'hatch_rate']:\n        val = getattr(settings, attribute, None)\n        if not val:\n            raise Exception('configuration error, attribute not set: {0}'.format(attribute))\n\n        if isinstance(val, str) and val.isdigit():\n            setattr(settings, attribute, int(val))\n    \n    return settings", "response": "Creates a new settings object that can be used by a LocalLocustRunner."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_lambda_runtime_info(context):\n    '''\n    Returns a dictionary of information about the AWS Lambda function invocation\n\n    Arguments\n\n    context: The context object from AWS Lambda.\n    '''\n\n    runtime_info = {\n        'remaining_time': context.get_remaining_time_in_millis(),\n        'function_name': context.function_name,\n        'function_version': context.function_version,\n        'invoked_function_arn': context.invoked_function_arn,\n        'memory_limit': context.memory_limit_in_mb,\n        'aws_request_id': context.aws_request_id,\n        'log_group_name': context.log_group_name,\n        'log_stream_name': context.log_stream_name\n    }\n\n    return runtime_info", "response": "Returns a dictionary of information about the AWS Lambda function invocation\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes a list of many individual results and returns a dictionary of aggregated loan results.", "response": "def results_aggregator(results):\n    '''\n    Takes a list of many individual results and returns a dictionary of aggregated\n    data.\n\n    arguments\n\n    results: A list of results from LocustLoadTest.stats()\n    '''\n\n    def _flatten_unique(list_of_lists):\n        l_flat = sum(list_of_lists, [])\n        l_unique = list(set(l_flat))\n        return l_unique\n\n    def _mean(numbers):\n        return float(sum(numbers)) / max(len(numbers), 1)\n\n    def _merge_response_times(response_times):\n        flat_list = []\n        for r_time in response_times:\n            for key, value in r_time.items():\n                flat_list.extend([int(float(key))] * value)\n        hist, bins = histogram(flat_list)\n        return {\n            'histogram': hist.tolist(),\n            'bins': bins.tolist(),\n        }\n\n    def _get_min(data, key):\n        try:\n            return min([r[key] for r in data if r[key] is not None])\n        except ValueError:\n            return 0\n\n    def _get_max(data, key):\n        try:\n            return max([r[key] for r in data if r[key] is not None])\n        except ValueError:\n            return 0\n\n    def _calculate_aws_lambda_cost(total_execution_time, memory_limit, invocation_count):\n        dollar_cost_per_128mb_100ms = 0.000000208\n        dollar_cost_per_invocation = 0.0000002\n        memory_cost_multiplier = int(memory_limit) / 128.0\n        time_in_100ms_lots = int(total_lambda_execution_time / 100.0)\n        invocation_cost = invocation_count * 0.0000002\n        execution_time_cost = time_in_100ms_lots * dollar_cost_per_128mb_100ms * memory_cost_multiplier\n        return (invocation_cost + execution_time_cost)\n\n    request_tasks = _flatten_unique([list(stat['requests'].keys()) for stat in results])\n    failed_tasks = _flatten_unique([list(stat['failures'].keys()) for stat in results])\n    total_lambda_execution_time = sum([(300000 - stat['remaining_time']) for stat in results])\n    memory_limit = _get_max(results, 'memory_limit')\n\n    agg_results = {\n        'requests': {key: {} for key in request_tasks},\n        'failures': {key: {} for key in failed_tasks},\n        'num_requests': sum([stat['num_requests'] for stat in results]),\n        'num_requests_fail': sum([stat['num_requests_fail'] for stat in results]),\n        'total_lambda_execution_time': total_lambda_execution_time,\n        'lambda_invocations': len(results),\n        'approximate_cost': _calculate_aws_lambda_cost(total_lambda_execution_time, memory_limit, len(results))\n    }\n\n    for task in request_tasks:\n        task_data_results = [stat['requests'][task] for stat in results if task in stat['requests']]\n\n        for mean_stat in ['median_response_time', 'total_rps', 'avg_response_time']:\n            agg_results['requests'][task][mean_stat] = _mean([data[mean_stat] for data in task_data_results])\n\n        agg_results['requests'][task]['max_response_time'] = _get_max(task_data_results, 'max_response_time')\n        agg_results['requests'][task]['min_response_time'] = _get_min(task_data_results, 'min_response_time')\n        agg_results['requests'][task]['response_times'] = _merge_response_times([data['response_times'] for data in task_data_results if data['response_times'] is not None])\n        agg_results['requests'][task]['total_rpm'] = agg_results['requests'][task]['total_rps'] * 60\n        agg_results['requests'][task]['num_requests'] = sum([stat['requests'][task]['num_requests'] for stat in results if task in stat['requests']])\n\n    for task in failed_tasks:\n        task_data_results = [stat['failures'][task] for stat in results if task in stat['failures']]\n        agg_results['failures'][task] = task_data_results[0]\n        agg_results['failures'][task]['occurences'] = sum([stat['occurences'] for stat in task_data_results])\n\n    return agg_results"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a byte - aligned array for efficient use by pyfftw.", "response": "def pyfftw_byte_aligned(array, dtype=None, n=None):\n    \"\"\"\n    Construct a byte-aligned array for efficient use by :mod:`pyfftw`.\n    This function is a wrapper for :func:`pyfftw.byte_align`\n\n    Parameters\n    ----------\n    array : ndarray\n      Input array\n    dtype : dtype, optional (default None)\n      Output array dtype\n    n : int, optional (default None)\n      Output array should be aligned to n-byte boundary\n\n    Returns\n    -------\n    a :  ndarray\n      Array with required byte-alignment\n    \"\"\"\n\n    return pyfftw.byte_align(array, n=n, dtype=dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an empty byte - aligned array for efficient use by pyfftw. empty_aligned", "response": "def pyfftw_empty_aligned(shape, dtype, order='C', n=None):\n    \"\"\"\n    Construct an empty byte-aligned array for efficient use by :mod:`pyfftw`.\n    This function is a wrapper for :func:`pyfftw.empty_aligned`\n\n    Parameters\n    ----------\n    shape : sequence of ints\n      Output array shape\n    dtype : dtype\n      Output array dtype\n    order : {'C', 'F'}, optional (default 'C')\n      Specify whether arrays should be stored in row-major (C-style) or\n      column-major (Fortran-style) order\n    n : int, optional (default None)\n      Output array should be aligned to n-byte boundary\n\n    Returns\n    -------\n    a :  ndarray\n      Empty array with required byte-alignment\n    \"\"\"\n\n    return pyfftw.empty_aligned(shape, dtype, order, n)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pyfftw_rfftn_empty_aligned(shape, axes, dtype, order='C', n=None):\n\n    ashp = list(shape)\n    raxis = axes[-1]\n    ashp[raxis] = ashp[raxis] // 2 + 1\n    cdtype = complex_dtype(dtype)\n    return pyfftw.empty_aligned(ashp, cdtype, order, n)", "response": "Returns an empty byte - aligned array for efficient use by pyfftw. rfftn."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the inverse of the multi - dimensional discrete Fourier transform of real input.", "response": "def irfftn(a, s, axes=None):\n    \"\"\"\n    Compute the inverse of the multi-dimensional discrete Fourier transform\n    for real input. This function is a wrapper for\n    :func:`pyfftw.interfaces.numpy_fft.irfftn`, with an interface similar to\n    that of :func:`numpy.fft.irfftn`.\n\n    Parameters\n    ----------\n    a : array_like\n      Input array\n    s : sequence of ints\n      Shape of the output along each transformed axis (input is cropped or\n      zero-padded to match). This parameter is not optional because, unlike\n      :func:`ifftn`, the output shape cannot be uniquely determined from\n      the input shape.\n    axes : sequence of ints, optional (default None)\n      Axes over which to compute the inverse DFT.\n\n    Returns\n    -------\n    af : ndarray\n      Inverse DFT of input array\n    \"\"\"\n\n    return pyfftw.interfaces.numpy_fft.irfftn(\n        a, s=s, axes=axes, overwrite_input=False,\n        planner_effort='FFTW_MEASURE', threads=pyfftw_threads)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes a multi - dimensional DCT - II over specified array axes.", "response": "def dctii(x, axes=None):\n    \"\"\"\n    Compute a multi-dimensional DCT-II over specified array axes. This\n    function is implemented by calling the one-dimensional DCT-II\n    :func:`scipy.fftpack.dct` with normalization mode 'ortho' for each\n    of the specified axes.\n\n    Parameters\n    ----------\n    a : array_like\n      Input array\n    axes : sequence of ints, optional (default None)\n      Axes over which to compute the DCT-II.\n\n    Returns\n    -------\n    y : ndarray\n      DCT-II of input array\n    \"\"\"\n\n    if axes is None:\n        axes = list(range(x.ndim))\n    for ax in axes:\n        x = fftpack.dct(x, type=2, axis=ax, norm='ortho')\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef idctii(x, axes=None):\n\n    if axes is None:\n        axes = list(range(x.ndim))\n    for ax in axes[::-1]:\n        x = fftpack.idct(x, type=2, axis=ax, norm='ortho')\n    return x", "response": "Compute a multi - dimensional inverse DCT - II over the specified array axes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute a multi - dimensional convolution via the Discrete Fourier Transform.", "response": "def fftconv(a, b, axes=(0, 1)):\n    \"\"\"\n    Compute a multi-dimensional convolution via the Discrete Fourier\n    Transform. Note that the output has a phase shift relative to the\n    output of :func:`scipy.ndimage.convolve` with the default ``origin``\n    parameter.\n\n    Parameters\n    ----------\n    a : array_like\n      Input array\n    b : array_like\n      Input array\n    axes : sequence of ints, optional (default (0, 1))\n      Axes on which to perform convolution\n\n    Returns\n    -------\n    ab : ndarray\n      Convolution of input arrays, a and b, along specified axes\n    \"\"\"\n\n    if np.isrealobj(a) and np.isrealobj(b):\n        fft = rfftn\n        ifft = irfftn\n    else:\n        fft = fftn\n        ifft = ifftn\n    dims = np.maximum([a.shape[i] for i in axes], [b.shape[i] for i in axes])\n    af = fft(a, dims, axes)\n    bf = fft(b, dims, axes)\n    return ifft(af * bf, dims, axes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the inner product of x and y on specified axis equivalent to summing x and y over the specified axis.", "response": "def inner(x, y, axis=-1):\n    \"\"\"\n    Compute inner product of x and y on specified axis, equivalent to\n    :code:`np.sum(x * y, axis=axis, keepdims=True)`.\n\n    Parameters\n    ----------\n    x : array_like\n      Input array x\n    y : array_like\n      Input array y\n    axis : int, optional (default -1)\n      Axis over which to compute the sum\n\n    Returns\n    -------\n    y : ndarray\n      Inner product array equivalent to summing x*y over the specified\n      axis\n    \"\"\"\n\n    # Convert negative axis to positive\n    if axis < 0:\n        axis = x.ndim + axis\n\n    # If sum not on axis 0, roll specified axis to 0 position\n    if axis == 0:\n        xr = x\n        yr = y\n    else:\n        xr = np.rollaxis(x, axis, 0)\n        yr = np.rollaxis(y, axis, 0)\n\n    # Efficient inner product on axis 0\n    if np.__version__ == '1.14.0':\n        # Setting of optimize flag due to\n        #    https://github.com/numpy/numpy/issues/10343\n        ip = np.einsum(xr, [0, Ellipsis], yr, [0, Ellipsis],\n                       optimize=False)[np.newaxis, ...]\n    else:\n        ip = np.einsum(xr, [0, Ellipsis], yr, [0, Ellipsis])[np.newaxis, ...]\n\n    # Roll axis back to original position if necessary\n    if axis != 0:\n        ip = np.rollaxis(ip, 0, axis + 1)\n\n    return ip"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dot(a, b, axis=-2):\n\n    # Ensure axis specification is positive\n    if axis < 0:\n        axis = b.ndim + axis\n    # Insert singleton axis into b\n    bx = np.expand_dims(b, axis)\n    # Calculate index of required singleton axis in a and insert it\n    axshp = [1] * bx.ndim\n    axshp[axis:axis + 2] = a.shape\n    ax = a.reshape(axshp)\n    # Calculate indexing expression required to remove singleton axis in\n    # product\n    idxexp = [slice(None)] * bx.ndim\n    idxexp[axis + 1] = 0\n    # Compute and return product\n    return np.sum(ax * bx, axis=axis+1, keepdims=True)[tuple(idxexp)]", "response": "Compute the matrix product of a and b over the specified axes of a and return the result as a new array containing the matrix product of a and b over the specified axes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef solvedbi_sm_c(ah, a, rho, axis=4):\n\n    return ah / (inner(ah, a, axis=axis) + rho)", "response": "r Compute cached component used by solvedbi_sm."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef solvedbd_sm_c(ah, a, d, axis=4):\n\n    return (ah / d) / (inner(ah, (a / d), axis=axis) + 1.0)", "response": "r Compute cached component used by solvedbd_sm."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef solvemdbi_cg(ah, rho, b, axisM, axisK, tol=1e-5, mit=1000, isn=None):\n\n    a = np.conj(ah)\n    if isn is not None:\n        isn = isn.ravel()\n    Aop = lambda x: inner(ah, x, axis=axisM)\n    AHop = lambda x: inner(a, x, axis=axisK)\n    AHAop = lambda x: AHop(Aop(x))\n    vAHAoprI = lambda x: AHAop(x.reshape(b.shape)).ravel() + rho * x.ravel()\n    lop = LinearOperator((b.size, b.size), matvec=vAHAoprI, dtype=b.dtype)\n    vx, cgit = _cg_wrapper(lop, b.ravel(), isn, tol, mit)\n    return vx.reshape(b.shape), cgit", "response": "r Solve a multi - diagonal block linear system with a scaled identity term using Conjugate Gradient."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lu_solve_ATAI(A, rho, b, lu, piv, check_finite=True):\n\n    N, M = A.shape\n    if N >= M:\n        x = linalg.lu_solve((lu, piv), b, check_finite=check_finite)\n    else:\n        x = (b - A.T.dot(linalg.lu_solve((lu, piv), A.dot(b), 1,\n                                         check_finite=check_finite))) / rho\n    return x", "response": "r Solve the linear system A and B using the linear system lu."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef zpad(x, pd, ax):\n\n    xpd = ((0, 0),)*ax + (pd,) + ((0, 0),)*(x.ndim-ax-1)\n    return np.pad(x, xpd, 'constant')", "response": "Zero - pad array x with pd = leading trailing zeros on axis ax."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Gax(x, ax):\n\n    slc = (slice(None),)*ax + (slice(-1, None),)\n    xg = np.roll(x, -1, axis=ax) - x\n    xg[slc] = 0.0\n    return xg", "response": "Compute gradient of x along axis ax."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute transpose of gradient of x along axis ax.", "response": "def GTax(x, ax):\n    \"\"\"\n    Compute transpose of gradient of `x` along axis `ax`.\n\n    Parameters\n    ----------\n    x : array_like\n      Input array\n    ax : int\n      Axis on which gradient transpose is to be computed\n\n    Returns\n    -------\n    xg : ndarray\n      Output array\n    \"\"\"\n\n    slc0 = (slice(None),) * ax\n    xg = np.roll(x, 1, axis=ax) - x\n    xg[slc0 + (slice(0, 1),)] = -x[slc0 + (slice(0, 1),)]\n    xg[slc0 + (slice(-1, None),)] = x[slc0 + (slice(-2, -1),)]\n    return xg"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GradientFilters(ndim, axes, axshp, dtype=None):\n\n    if dtype is None:\n        dtype = np.float32\n    g = np.zeros([2 if k in axes else 1 for k in range(ndim)] +\n                 [len(axes),], dtype)\n    for k in axes:\n        g[(0,) * k + (slice(None),) + (0,) * (g.ndim - 2 - k) + (k,)] = \\\n            np.array([1, -1])\n    Gf = rfftn(g, axshp, axes=axes)\n    GHGf = np.sum(np.conj(Gf) * Gf, axis=-1).real\n    return Gf, GHGf", "response": "r Constructs a set of filters for computing gradients in the frequency domain."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef zdivide(x, y):\n\n    # See https://stackoverflow.com/a/37977222\n    return np.divide(x, y, out=np.zeros_like(x), where=(y != 0))", "response": "Returns x / y with 0 instead of NaN where y is 0."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new array with at least n dimensions.", "response": "def atleast_nd(n, u):\n    \"\"\"\n    If the input array has fewer than n dimensions, append singleton\n    dimensions so that it is n dimensional. Note that the interface\n    differs substantially from that of :func:`numpy.atleast_3d` etc.\n\n    Parameters\n    ----------\n    n : int\n      Minimum number of required dimensions\n    u : array_like\n      Input array\n\n    Returns\n    -------\n    v : ndarray\n      Output array with at least n dimensions\n    \"\"\"\n\n    if u.ndim >= n:\n        return u\n    else:\n        return u.reshape(u.shape + (1,)*(n-u.ndim))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef split(u, axis=0):\n\n    # Convert negative axis to positive\n    if axis < 0:\n        axis = u.ndim + axis\n\n    # Construct axis selection slice\n    slct0 = (slice(None),) * axis\n    return [u[slct0 + (k,)] for k in range(u.shape[axis])]", "response": "Split an array into a list of arrays on the specified axis."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstruct a block circulant matrix from a tuple of arrays. This is a block-matrix variant of :func:`scipy.linalg.circulant`. Parameters ---------- A : tuple of array_like Tuple of arrays corresponding to the first block column of the output block matrix Returns ------- B : ndarray Output array", "response": "def blockcirculant(A):\n    \"\"\"\n    Construct a block circulant matrix from a tuple of arrays. This is a\n    block-matrix variant of :func:`scipy.linalg.circulant`.\n\n    Parameters\n    ----------\n    A : tuple of array_like\n      Tuple of arrays corresponding to the first block column of the output\n      block matrix\n\n    Returns\n    -------\n    B : ndarray\n      Output array\n    \"\"\"\n\n    r, c = A[0].shape\n    B = np.zeros((len(A) * r, len(A) * c), dtype=A[0].dtype)\n    for k in range(len(A)):\n        for l in range(len(A)):\n            kl = np.mod(k + l, len(A))\n            B[r*kl:r*(kl + 1), c*k:c*(k + 1)] = A[l]\n    return B"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fl2norm2(xf, axis=(0, 1)):\n\n    xfs = xf.shape\n    return (np.linalg.norm(xf)**2) / np.prod(np.array([xfs[k] for k in axis]))", "response": "r Compute the squared 2 norm of a multi - dimensional array."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn initialiser for working variable U.", "response": "def uinit(self, ushape):\n        \"\"\"Return initialiser for working variable U.\"\"\"\n\n        if  self.opt['Y0'] is None:\n            return np.zeros(ushape, dtype=self.dtype)\n        else:\n            # If initial Y is non-zero, initial U is chosen so that\n            # the relevant dual optimality criterion (see (3.10) in\n            # boyd-2010-distributed) is satisfied.\n            Yss = np.sqrt(np.sum(self.Y**2, axis=self.S.ndim, keepdims=True))\n            return (self.lmbda/self.rho)*sl.zdivide(self.Y, Yss)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nminimise Augmented Lagrangian with respect to .", "response": "def xstep(self):\n        r\"\"\"Minimise Augmented Lagrangian with respect to\n        :math:`\\mathbf{x}`.\n        \"\"\"\n\n        ngsit = 0\n        gsrrs = np.inf\n        while gsrrs > self.opt['GSTol'] and ngsit < self.opt['MaxGSIter']:\n            self.X = self.GaussSeidelStep(self.S, self.X,\n                                          self.cnst_AT(self.Y-self.U),\n                                          self.rho, self.lcw, self.Wdf2)\n            gsrrs = sl.rrs(\n                self.rho*self.cnst_AT(self.cnst_A(self.X)) +\n                self.Wdf2*self.X, self.Wdf2*self.S +\n                self.rho*self.cnst_AT(self.Y - self.U))\n            ngsit += 1\n\n        self.xs = (ngsit, gsrrs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nminimising Augmented Lagrangian with respect to self. Y.", "response": "def ystep(self):\n        r\"\"\"Minimise Augmented Lagrangian with respect to\n        :math:`\\mathbf{y}`.\n        \"\"\"\n\n        self.Y = np.asarray(sp.prox_l2(\n            self.AX + self.U, (self.lmbda/self.rho)*self.Wtvna,\n            axis=self.saxes), dtype=self.dtype)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef eval_objfn(self):\n\n        dfd = 0.5*(np.linalg.norm(self.Wdf * (self.X - self.S))**2)\n        reg = np.sum(self.Wtv * np.sqrt(np.sum(self.obfn_gvar()**2,\n                                               axis=self.saxes)))\n        obj = dfd + self.lmbda*reg\n        return (obj, dfd, reg)", "response": "r Compute components of objective function as well as total\n        contribution to objective function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cnst_AT(self, X):\n\n        return np.sum(np.concatenate(\n            [sl.GTax(X[..., ax], ax)[..., np.newaxis] for ax in self.axes],\n            axis=X.ndim-1), axis=X.ndim-1)", "response": "r Compute A^T \\ mathbf { x } where A^T \\ mathbf { x } is\n            a component of ADMM problem constraint."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cnst_c(self):\n\n        return np.zeros(self.S.shape + (len(self.axes),), self.dtype)", "response": "r Compute constant component of ADMM problem\n        constraint. In this case the constant component of ADMM problem\n        constraint is used."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef LaplaceCentreWeight(self):\n\n        sz = [1,] * self.S.ndim\n        for ax in self.axes:\n            sz[ax] = self.S.shape[ax]\n        lcw = 2*len(self.axes)*np.ones(sz, dtype=self.dtype)\n        for ax in self.axes:\n            lcw[(slice(None),)*ax + ([0, -1],)] -= 1.0\n        return lcw", "response": "Centre weighting matrix for TV Laplacian."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nminimise Augmented Lagrangian with respect to .", "response": "def xstep(self):\n        r\"\"\"Minimise Augmented Lagrangian with respect to\n        :math:`\\mathbf{x}`.\n        \"\"\"\n\n        b = self.AHSf + self.rho*np.sum(\n            np.conj(self.Gf)*sl.rfftn(self.Y-self.U, axes=self.axes),\n            axis=self.Y.ndim-1)\n        self.Xf = b / (self.AHAf + self.rho*self.GHGf)\n        self.X = sl.irfftn(self.Xf, self.axsz, axes=self.axes)\n\n        if self.opt['LinSolveCheck']:\n            ax = (self.AHAf + self.rho*self.GHGf)*self.Xf\n            self.xrrs = sl.rrs(ax, b)\n        else:\n            self.xrrs = None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef eval_objfn(self):\n\n        Ef = self.Af * self.Xf - self.Sf\n        dfd = sl.rfl2norm2(Ef, self.S.shape, axis=self.axes) / 2.0\n        reg = np.sum(self.Wtv * np.sqrt(np.sum(self.obfn_gvar()**2,\n                                               axis=self.saxes)))\n        obj = dfd + self.lmbda*reg\n        return (obj, dfd, reg)", "response": "r Compute components of objective function as well as total\n        contribution to objective function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef solve(self):\n\n        # Open status display\n        fmtstr, nsep = self.display_start()\n\n        # Start solve timer\n        self.timer.start(['solve', 'solve_wo_func', 'solve_wo_rsdl'])\n\n        # Main optimisation iterations\n        for self.k in range(self.k, self.k + self.opt['MaxMainIter']):\n\n            # Update record of Y from previous iteration\n            self.Yprev = self.Y.copy()\n\n            # X update\n            self.xstep()\n\n            # Implement relaxation if RelaxParam != 1.0\n            self.relax_AX()\n\n            # Y update\n            self.ystep()\n\n            # U update\n            self.ustep()\n\n            # Compute residuals and stopping thresholds\n            self.timer.stop('solve_wo_rsdl')\n            if self.opt['AutoRho', 'Enabled'] or not self.opt['FastSolve']:\n                r, s, epri, edua = self.compute_residuals()\n            self.timer.start('solve_wo_rsdl')\n\n            # Compute and record other iteration statistics and\n            # display iteration stats if Verbose option enabled\n            self.timer.stop(['solve_wo_func', 'solve_wo_rsdl'])\n            if not self.opt['FastSolve']:\n                itst = self.iteration_stats(self.k, r, s, epri, edua)\n                self.itstat.append(itst)\n                self.display_status(fmtstr, itst)\n            self.timer.start(['solve_wo_func', 'solve_wo_rsdl'])\n\n            # Automatic rho adjustment\n            self.timer.stop('solve_wo_rsdl')\n            if self.opt['AutoRho', 'Enabled'] or not self.opt['FastSolve']:\n                self.update_rho(self.k, r, s)\n            self.timer.start('solve_wo_rsdl')\n\n            # Call callback function if defined\n            if self.opt['Callback'] is not None:\n                if self.opt['Callback'](self):\n                    break\n\n            # Stop if residual-based stopping tolerances reached\n            if self.opt['AutoRho', 'Enabled'] or not self.opt['FastSolve']:\n                if r < epri and s < edua:\n                    break\n\n\n        # Increment iteration count\n        self.k += 1\n\n        # Record solve time\n        self.timer.stop(['solve', 'solve_wo_func', 'solve_wo_rsdl'])\n\n        # Print final separator string if Verbose option enabled\n        self.display_end(nsep)\n\n        return self.getmin()", "response": "Start or re - start the optimisation of the object with the specified iteration number."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef runtime(self):\n\n        warnings.warn(\"admm.ADMM.runtime attribute has been replaced by \"\n                      \"an upgraded timer class: please see the documentation \"\n                      \"for admm.ADMM.solve method and util.Timer class\",\n                      PendingDeprecationWarning)\n        return self.timer.elapsed('init') + self.timer.elapsed('solve')", "response": "Transitional property providing access to the new timer\n        mechanism. This property is deprecated in favor of upgraded timer classes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compute_residuals(self):\n\n        if self.opt['AutoRho', 'StdResiduals']:\n            r = np.linalg.norm(self.rsdl_r(self.AXnr, self.Y))\n            s = np.linalg.norm(self.rsdl_s(self.Yprev, self.Y))\n            epri = np.sqrt(self.Nc) * self.opt['AbsStopTol'] + \\\n                self.rsdl_rn(self.AXnr, self.Y) * self.opt['RelStopTol']\n            edua = np.sqrt(self.Nx) * self.opt['AbsStopTol'] + \\\n                self.rsdl_sn(self.U) * self.opt['RelStopTol']\n        else:\n            rn = self.rsdl_rn(self.AXnr, self.Y)\n            if rn == 0.0:\n                rn = 1.0\n            sn = self.rsdl_sn(self.U)\n            if sn == 0.0:\n                sn = 1.0\n            r = np.linalg.norm(self.rsdl_r(self.AXnr, self.Y)) / rn\n            s = np.linalg.norm(self.rsdl_s(self.Yprev, self.Y)) / sn\n            epri = np.sqrt(self.Nc) * self.opt['AbsStopTol'] / rn + \\\n                self.opt['RelStopTol']\n            edua = np.sqrt(self.Nx) * self.opt['AbsStopTol'] / sn + \\\n                self.opt['RelStopTol']\n\n        return r, s, epri, edua", "response": "Compute residuals and stopping thresholds."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstruct dictionary mapping display column title to iterationStats entries.", "response": "def hdrval(cls):\n        \"\"\"Construct dictionary mapping display column title to\n        IterationStats entries.\n        \"\"\"\n\n        hdrmap = {'Itn': 'Iter'}\n        hdrmap.update(cls.hdrval_objfun)\n        hdrmap.update({'r': 'PrimalRsdl', 's': 'DualRsdl', u('\u03c1'): 'Rho'})\n        return hdrmap"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iteration_stats(self, k, r, s, epri, edua):\n\n        tk = self.timer.elapsed(self.opt['IterTimer'])\n        tpl = (k,) + self.eval_objfn() + (r, s, epri, edua, self.rho) + \\\n            self.itstat_extra() + (tk,)\n        return type(self).IterationStats(*tpl)", "response": "Construct iteration stats record tuple."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset up status display if option selected.", "response": "def display_start(self):\n        \"\"\"Set up status display if option selected. NB: this method\n        assumes that the first entry is the iteration count and the last\n        is the rho value.\n        \"\"\"\n\n        if self.opt['Verbose']:\n            # If AutoRho option enabled rho is included in iteration status\n            if self.opt['AutoRho', 'Enabled']:\n                hdrtxt = type(self).hdrtxt()\n            else:\n                hdrtxt = type(self).hdrtxt()[0:-1]\n            # Call utility function to construct status display formatting\n            hdrstr, fmtstr, nsep = common.solve_status_str(\n                hdrtxt, fwdth0=type(self).fwiter, fprec=type(self).fpothr)\n            # Print header and separator strings\n            if self.opt['StatusHeader']:\n                print(hdrstr)\n                print(\"-\" * nsep)\n        else:\n            fmtstr, nsep = '', 0\n\n        return fmtstr, nsep"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndisplay current iteration status as selection of fields from iteration stats tuple.", "response": "def display_status(self, fmtstr, itst):\n        \"\"\"Display current iteration status as selection of fields from\n        iteration stats tuple.\n        \"\"\"\n\n        if self.opt['Verbose']:\n            hdrtxt = type(self).hdrtxt()\n            hdrval = type(self).hdrval()\n            itdsp = tuple([getattr(itst, hdrval[col]) for col in hdrtxt])\n            if not self.opt['AutoRho', 'Enabled']:\n                itdsp = itdsp[0:-1]\n\n            print(fmtstr % itdsp)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing primal residual vector.", "response": "def rsdl_r(self, AX, Y):\n        \"\"\"Compute primal residual vector.\n\n        Overriding this method is required if methods :meth:`cnst_A`,\n        :meth:`cnst_AT`, :meth:`cnst_B`, and :meth:`cnst_c` are not\n        overridden.\n        \"\"\"\n\n        # Avoid calling cnst_c() more than once in case it is expensive\n        # (e.g. due to allocation of a large block of memory)\n        if not hasattr(self, '_cnst_c'):\n            self._cnst_c = self.cnst_c()\n        return AX + self.cnst_B(Y) - self._cnst_c"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rsdl_rn(self, AX, Y):\n\n        # Avoid computing the norm of the value returned by cnst_c()\n        # more than once\n        if not hasattr(self, '_nrm_cnst_c'):\n            self._nrm_cnst_c = np.linalg.norm(self.cnst_c())\n        return max((np.linalg.norm(AX), np.linalg.norm(self.cnst_B(Y)),\n                    self._nrm_cnst_c))", "response": "Compute primal residual normalisation term."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rsdl_sn(self, U):\n\n        return self.rho * np.linalg.norm(self.cnst_AT(U))", "response": "Compute dual residual normalisation term."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getmin(self):\n\n        if self.opt['ReturnVar'] == 'X':\n            return self.var_x()\n        elif self.opt['ReturnVar'] == 'Y0':\n            return self.var_y0()\n        elif self.opt['ReturnVar'] == 'Y1':\n            return self.var_y1()\n        else:\n            raise ValueError(self.opt['ReturnVar'] + ' is not a valid value'\n                             'for option ReturnVar')", "response": "Get minimiser after optimisation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nseparate variable into component corresponding to y_0 in Y in : math:`\\mathbf { y}_0 in \\ mathbf { y_0 in \\ mathbf { y_0 } in \\ mathbf { y_0 } in \\ mathbf { y_0 } in \\ mathbf { y_0 } in \\ mathbf { y_0 } in \\ mathbf { y_0 } in \\ mathbf { y_0 } in \\ mathbf ;.", "response": "def block_sep0(self, Y):\n        r\"\"\"Separate variable into component corresponding to\n        :math:`\\mathbf{y}_0` in :math:`\\mathbf{y}\\;\\;`.\n        \"\"\"\n\n        return Y[(slice(None),)*self.blkaxis + (slice(0, self.blkidx),)]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef block_cat(self, Y0, Y1):\n\n        return np.concatenate((Y0, Y1), axis=self.blkaxis)", "response": "r Concatenate components corresponding to Y0 and Y1 to form \\ mathbf \\ ;."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef relax_AX(self):\n\n        self.AXnr = self.cnst_A(self.X)\n        if self.rlx == 1.0:\n            self.AX = self.AXnr\n        else:\n            if not hasattr(self, '_cnst_c0'):\n                self._cnst_c0 = self.cnst_c0()\n            if not hasattr(self, '_cnst_c1'):\n                self._cnst_c1 = self.cnst_c1()\n            alpha = self.rlx\n            self.AX = alpha*self.AXnr + (1 - alpha)*self.block_cat(\n                self.var_y0() + self._cnst_c0,\n                self.var_y1() + self._cnst_c1)", "response": "Implement relaxation if option RelaxParam!= 1. 0."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef obfn_g1var(self):\n\n        return self.var_y1() if self.opt['AuxVarObj'] else \\\n            self.cnst_A1(self.X) - self.cnst_c1()", "response": "Variable to be evaluated in computing\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef eval_objfn(self):\n\n        fval = self.obfn_f(self.obfn_fvar())\n        g0val = self.obfn_g0(self.obfn_g0var())\n        g1val = self.obfn_g1(self.obfn_g1var())\n        obj = fval + g0val + g1val\n        return (obj, fval, g0val, g1val)", "response": "Compute components of objective function as well as total\n        contribution to objective function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cnst_A(self, X):\n\n        return self.block_cat(self.cnst_A0(X), self.cnst_A1(X))", "response": "r Compute A component of ADMM problem of problem containing A."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing primal residual vector.", "response": "def rsdl_r(self, AX, Y):\n        \"\"\"Compute primal residual vector.\n\n        Overriding this method is required if methods :meth:`cnst_A`,\n        :meth:`cnst_AT`, :meth:`cnst_c0` and :meth:`cnst_c1` are not\n        overridden.\n        \"\"\"\n\n        if not hasattr(self, '_cnst_c0'):\n            self._cnst_c0 = self.cnst_c0()\n        if not hasattr(self, '_cnst_c1'):\n            self._cnst_c1 = self.cnst_c1()\n        return AX - self.block_cat(self.var_y0() + self._cnst_c0,\n                                   self.var_y1() + self._cnst_c1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing dual residual vector.", "response": "def rsdl_s(self, Yprev, Y):\n        \"\"\"Compute dual residual vector.\n\n        Overriding this method is required if methods :meth:`cnst_A`,\n        :meth:`cnst_AT`, :meth:`cnst_B`, and :meth:`cnst_c` are not\n        overridden.\n        \"\"\"\n\n        return self.rho * self.cnst_AT(Yprev - Y)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rsdl_rn(self, AX, Y):\n\n        if not hasattr(self, '_cnst_nrm_c'):\n            self._cnst_nrm_c = np.sqrt(np.linalg.norm(self.cnst_c0())**2 +\n                                       np.linalg.norm(self.cnst_c1())**2)\n        return max((np.linalg.norm(AX), np.linalg.norm(Y), self._cnst_nrm_c))", "response": "Compute primal residual normalisation term."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nminimise Augmented Lagrangian with respect to respect to \\ mathbf { y.", "response": "def ystep(self):\n        r\"\"\"Minimise Augmented Lagrangian with respect to :math:`\\mathbf{y}`.\n        \"\"\"\n\n        rho = self.Nb * self.rho\n        mAXU = np.mean(self.AX + self.U, axis=-1)\n        self.Y[:] = self.prox_g(mAXU, rho)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimplements relaxation if option RelaxParam!= 1. 0.", "response": "def relax_AX(self):\n        \"\"\"Implement relaxation if option ``RelaxParam`` != 1.0.\"\"\"\n\n        self.AXnr = self.X\n        if self.rlx == 1.0:\n            self.AX = self.X\n        else:\n            alpha = self.rlx\n            self.AX = alpha*self.X + (1 - alpha)*self.Y[..., np.newaxis]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef eval_objfn(self):\n\n        fval = self.obfn_f()\n        gval = self.obfn_g(self.obfn_gvar())\n        obj = fval + gval\n        return (obj, fval, gval)", "response": "Compute components of objective function as well as total\n        contribution to objective function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef obfn_fvar(self, i):\n\n        return self.X[..., i] if self.opt['fEvalX'] else self.Y", "response": "Variable to be evaluated in computing : math : f_i \\ cdot depending on the fEvalX option value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef obfn_gvar(self):\n\n        return self.Y if self.opt['gEvalY'] else np.mean(self.X, axis=-1)", "response": "Variable to be evaluated in computing : math : g \\ cdot"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef obfn_f(self):\n\n        obf = 0.0\n        for i in range(self.Nb):\n            obf += self.obfn_fi(self.obfn_fvar(i), i)\n        return obf", "response": "r Compute : math : f \\ sum_i f \\ mathbf_i x"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rsdl_s(self, Yprev, Y):\n\n        # Since s = rho A^T B (y^(k+1) - y^(k)) and B = -(I I I ...)^T,\n        # the correct calculation here would involve replicating (Yprev - Y)\n        # on the axis on which the blocks of X are stacked. Since this would\n        # require allocating additional memory, and since it is only the norm\n        # of s that is required, instead of replicating the vector it is\n        # scaled to have the same l2 norm as the replicated vector\n        return np.sqrt(self.Nb) * self.rho * (Yprev - Y)", "response": "Compute dual residual vector."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes primal residual normalisation term.", "response": "def rsdl_rn(self, AX, Y):\n        \"\"\"Compute primal residual normalisation term.\"\"\"\n\n        # The primal residual normalisation term is\n        # max( ||A x^(k)||_2, ||B y^(k)||_2 ) and B = -(I I I ...)^T.\n        # The scaling by sqrt(Nb) of the l2 norm of Y accounts for the\n        # block replication introduced by multiplication by B\n        return max((np.linalg.norm(AX), np.sqrt(self.Nb) * np.linalg.norm(Y)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prox_l1l2(v, alpha, beta, axis=None):\n\n    return prox_l2(prox_l1(v, alpha), beta, axis)", "response": "r Compute the proximal operator of the l1 plus the l2 norm."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a ConvBPDNMask class from a label string.", "response": "def cbpdnmsk_class_label_lookup(label):\n    \"\"\"Get a ConvBPDNMask class from a label string.\"\"\"\n\n    clsmod = {'admm': admm_cbpdn.ConvBPDNMaskDcpl,\n              'fista': fista_cbpdn.ConvBPDNMask}\n    if label in clsmod:\n        return clsmod[label]\n    else:\n        raise ValueError('Unknown ConvBPDNMask solver method %s' % label)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ConvBPDNMaskOptionsDefaults(method='admm'):\n\n    dflt = copy.deepcopy(cbpdnmsk_class_label_lookup(method).Options.defaults)\n    if method == 'admm':\n        dflt.update({'MaxMainIter': 1, 'AutoRho':\n                     {'Period': 10, 'AutoScaling': False,\n                      'RsdlRatio': 10.0, 'Scaling': 2.0,\n                      'RsdlTarget': 1.0}})\n    else:\n        dflt.update({'MaxMainIter': 1, 'BackTrack':\n                     {'gamma_u': 1.2, 'MaxIter': 50}})\n    return dflt", "response": "Get defaults dict for the ConvBPDNMask class specified by the\n    method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ConvBPDNMask(*args, **kwargs):\n\n    # Extract method selection argument or set default\n    method = kwargs.pop('method', 'admm')\n\n    # Assign base class depending on method selection argument\n    base = cbpdnmsk_class_label_lookup(method)\n\n    # Nested class with dynamically determined inheritance\n    class ConvBPDNMask(base):\n        def __init__(self, *args, **kwargs):\n            super(ConvBPDNMask, self).__init__(*args, **kwargs)\n\n    # Allow pickling of objects of type ConvBPDNMask\n    _fix_dynamic_class_lookup(ConvBPDNMask, method)\n\n    # Return object of the nested class type\n    return ConvBPDNMask(*args, **kwargs)", "response": "A wrapper function that dynamically defines a class derived from the Convolutional Constrained MOD\n    problems and returns an object instantiated with the provided parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a ConvCnstrMODMask class from a label string.", "response": "def ccmodmsk_class_label_lookup(label):\n    \"\"\"Get a ConvCnstrMODMask class from a label string.\"\"\"\n\n    clsmod = {'ism': admm_ccmod.ConvCnstrMODMaskDcpl_IterSM,\n              'cg': admm_ccmod.ConvCnstrMODMaskDcpl_CG,\n              'cns': admm_ccmod.ConvCnstrMODMaskDcpl_Consensus,\n              'fista': fista_ccmod.ConvCnstrMODMask}\n    if label in clsmod:\n        return clsmod[label]\n    else:\n        raise ValueError('Unknown ConvCnstrMODMask solver method %s' % label)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ConvCnstrMODMaskOptionsDefaults(method='fista'):\n\n    dflt = copy.deepcopy(ccmodmsk_class_label_lookup(method).Options.defaults)\n    if method == 'fista':\n        dflt.update({'MaxMainIter': 1, 'BackTrack':\n                     {'gamma_u': 1.2, 'MaxIter': 50}})\n    else:\n        dflt.update({'MaxMainIter': 1, 'AutoRho':\n                     {'Period': 10, 'AutoScaling': False,\n                      'RsdlRatio': 10.0, 'Scaling': 2.0,\n                      'RsdlTarget': 1.0}})\n    return dflt", "response": "Get defaults dict for the ConvCnstrMODMask class specified by the\n    method."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reconstruct(self, D=None, X=None):\n\n        if D is None:\n            D = self.getdict(crop=False)\n        if X is None:\n            X = self.getcoef()\n        Df = sl.rfftn(D, self.xstep.cri.Nv, self.xstep.cri.axisN)\n        Xf = sl.rfftn(X, self.xstep.cri.Nv, self.xstep.cri.axisN)\n        DXf = sl.inner(Df, Xf, axis=self.xstep.cri.axisM)\n        return sl.irfftn(DXf, self.xstep.cri.Nv, self.xstep.cri.axisN)", "response": "Reconstruct representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef evaluate(self):\n\n        if self.opt['AccurateDFid']:\n            DX = self.reconstruct()\n            S = self.xstep.S\n            dfd = (np.linalg.norm(self.xstep.W * (DX - S))**2) / 2.0\n            if self.xmethod == 'fista':\n                X = self.xstep.getcoef()\n            else:\n                X = self.xstep.var_y1()\n            rl1 = np.sum(np.abs(X))\n            return dict(DFid=dfd, RegL1=rl1,\n                        ObjFun=dfd + self.xstep.lmbda * rl1)\n        else:\n            return None", "response": "Evaluate functional value of previous iteration."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pathsplit(pth, dropext=True):\n\n    if dropext:\n        pth = os.path.splitext(pth)[0]\n    parts = os.path.split(pth)\n    if parts[0] == '':\n        return parts[1:]\n    elif len(parts[0]) == 1:\n        return parts\n    else:\n        return pathsplit(parts[0], dropext=False) + parts[1:]", "response": "Split a path into a tuple of all of its components."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_required(srcpth, dstpth):\n\n    return not os.path.exists(dstpth) or \\\n        os.stat(srcpth).st_mtime > os.stat(dstpth).st_mtime", "response": "Determines whether an update is required for the file at srcpth to be generated from the file at dstpth."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fetch_intersphinx_inventory(uri):\n\n    # See https://stackoverflow.com/a/30981554\n    class MockConfig(object):\n        intersphinx_timeout = None\n        tls_verify = False\n\n    class MockApp(object):\n        srcdir = ''\n        config = MockConfig()\n\n        def warn(self, msg):\n            warnings.warn(msg)\n\n    return intersphinx.fetch_inventory(MockApp(), '', uri)", "response": "Fetch and read an intersphinx inventory at a specified uri."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_sphinx_environment(pth):\n\n    with open(pth, 'rb') as fo:\n        env = pickle.load(fo)\n    return env", "response": "Read the sphinx environment. pickle file at path pth."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the top - level RST index file at rstpth and return a list of subdirectories in order of appearance in the index file and a dict mapping subdirectory name to description.", "response": "def parse_rst_index(rstpth):\n    \"\"\"\n    Parse the top-level RST index file, at `rstpth`, for the example\n    python scripts.  Returns a list of subdirectories in order of\n    appearance in the index file, and a dict mapping subdirectory name\n    to a description.\n    \"\"\"\n\n    pthidx = {}\n    pthlst = []\n    with open(rstpth) as fd:\n        lines = fd.readlines()\n    for i, l in enumerate(lines):\n        if i > 0:\n            if re.match(r'^  \\w+', l) is not None and \\\n               re.match(r'^\\w+', lines[i - 1]) is not None:\n                # List of subdirectories in order of appearance in index.rst\n                pthlst.append(lines[i - 1][:-1])\n                # Dict mapping subdirectory name to description\n                pthidx[lines[i - 1][:-1]] = l[2:-1]\n    return pthlst, pthidx"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef preprocess_script_string(str):\n\n    # Remove header comment\n    str = re.sub(r'^(#[^#\\n]+\\n){5}\\n*', r'', str)\n    # Insert notebook plotting configuration function\n    str = re.sub(r'from sporco import plot', r'from sporco import plot'\n                 '\\nplot.config_notebook_plotting()',\n                 str, flags=re.MULTILINE)\n    # Remove final input statement and preceding comment\n    str = re.sub(r'\\n*# Wait for enter on keyboard.*\\ninput().*\\n*',\n                 r'', str, flags=re.MULTILINE)\n\n    return str", "response": "Process python script represented as string str in preparation\n    for conversion to a notebook."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a python script represented as string str to a notebook with filename pth.", "response": "def script_string_to_notebook(str, pth):\n    \"\"\"\n    Convert a python script represented as string `str` to a notebook\n    with filename `pth`.\n    \"\"\"\n\n    nb = py2jn.py_string_to_notebook(str)\n    py2jn.write_notebook(nb, pth)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert the script at spth to a notebook at npth.", "response": "def script_to_notebook(spth, npth, cr):\n    \"\"\"\n    Convert the script at `spth` to a notebook at `npth`. Parameter `cr`\n    is a CrossReferenceLookup object.\n    \"\"\"\n\n    # Read entire text of example script\n    with open(spth) as f:\n        stxt = f.read()\n    # Process script text\n    stxt = preprocess_script_string(stxt)\n\n    # If the notebook file exists and has been executed, try to\n    # update markdown cells without deleting output cells\n    if os.path.exists(npth) and notebook_executed(npth):\n        # Read current notebook file\n        nbold = nbformat.read(npth, as_version=4)\n        # Construct updated notebook\n        nbnew = script_string_to_notebook_object(stxt)\n        if cr is not None:\n            notebook_substitute_ref_with_url(nbnew, cr)\n        # If the code cells of the two notebooks match, try to\n        # update markdown cells without deleting output cells\n        if same_notebook_code(nbnew, nbold):\n            try:\n                replace_markdown_cells(nbnew, nbold)\n            except Exception:\n                script_string_to_notebook_with_links(stxt, npth, cr)\n            else:\n                with open(npth, 'wt') as f:\n                    nbformat.write(nbold, f)\n        else:\n            # Write changed text to output notebook file\n            script_string_to_notebook_with_links(stxt, npth, cr)\n    else:\n        # Write changed text to output notebook file\n        script_string_to_notebook_with_links(stxt, npth, cr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef script_string_to_notebook_with_links(str, pth, cr=None):\n\n    if cr is None:\n        script_string_to_notebook(str, pth)\n    else:\n        ntbk = script_string_to_notebook_object(str)\n        notebook_substitute_ref_with_url(ntbk, cr)\n        with open(pth, 'wt') as f:\n            nbformat.write(ntbk, f)", "response": "Convert a python script represented as string str to a notebook with filename pth and replace sphinx cross - references with links\n            to online docs."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert an rst file to a notebook file.", "response": "def rst_to_notebook(infile, outfile):\n    \"\"\"Convert an rst file to a notebook file.\"\"\"\n\n    # Read infile into a string\n    with open(infile, 'r') as fin:\n        rststr = fin.read()\n    # Convert string from rst to markdown\n    mdfmt = 'markdown_github+tex_math_dollars+fenced_code_attributes'\n    mdstr = pypandoc.convert_text(rststr, mdfmt, format='rst',\n                                  extra_args=['--atx-headers'])\n    # In links, replace .py extensions with .ipynb\n    mdstr = re.sub(r'\\(([^\\)]+).py\\)', r'(\\1.ipynb)', mdstr)\n    # Enclose the markdown within triple quotes and convert from\n    # python to notebook\n    mdstr = '\"\"\"' + mdstr + '\"\"\"'\n    nb = py2jn.py_string_to_notebook(mdstr)\n    py2jn.tools.write_notebook(nb, outfile, nbver=4)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef markdown_to_notebook(infile, outfile):\n\n    # Read infile into a string\n    with open(infile, 'r') as fin:\n        str = fin.read()\n    # Enclose the markdown within triple quotes and convert from\n    # python to notebook\n    str = '\"\"\"' + str + '\"\"\"'\n    nb = py2jn.py_string_to_notebook(str)\n    py2jn.tools.write_notebook(nb, outfile, nbver=4)", "response": "Convert a markdown file to a notebook file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rst_to_docs_rst(infile, outfile):\n\n    # Read infile into a list of lines\n    with open(infile, 'r') as fin:\n        rst = fin.readlines()\n\n    # Inspect outfile path components to determine whether outfile\n    # is in the root of the examples directory or in a subdirectory\n    # thererof\n    ps = pathsplit(outfile)[-3:]\n    if ps[-2] == 'examples':\n        ps = ps[-2:]\n        idx = 'index'\n    else:\n        idx = ''\n\n    # Output string starts with a cross-reference anchor constructed from\n    # the file name and path\n    out = '.. _' + '_'.join(ps) + ':\\n\\n'\n\n    # Iterate over lines from infile\n    it = iter(rst)\n    for line in it:\n        if line[0:12] == '.. toc-start':  # Line has start of toc marker\n            # Initialise current toc array and iterate over lines until\n            # end of toc marker encountered\n            toc = []\n            for line in it:\n                if line == '\\n':  # Drop newline lines\n                    continue\n                elif line[0:10] == '.. toc-end':  # End of toc marker\n                    # Add toctree section to output string\n                    out += '.. toctree::\\n   :maxdepth: 1\\n\\n'\n                    for c in toc:\n                        out += '   %s <%s>\\n' % c\n                    break\n                else:  #  Still within toc section\n                    # Extract link text and target url and append to\n                    # toc array\n                    m = re.search(r'`(.*?)\\s*<(.*?)(?:.py)?>`', line)\n                    if m:\n                        if idx == '':\n                            toc.append((m.group(1), m.group(2)))\n                        else:\n                            toc.append((m.group(1),\n                                        os.path.join(m.group(2), idx)))\n        else:  # Not within toc section\n            out += line\n\n    with open(outfile, 'w') as fout:\n        fout.write(out)", "response": "Convert an rst file to a sphinx docs rst file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_notebook_index(ntbkpth):\n\n    # Convert notebook to RST text in string\n    rex = RSTExporter()\n    rsttxt = rex.from_filename(ntbkpth)[0]\n    # Clean up trailing whitespace\n    rsttxt = re.sub(r'\\n  ', r'', rsttxt, re.M | re.S)\n    pthidx = {}\n    pthlst = []\n    lines = rsttxt.split('\\n')\n    for l in lines:\n        m = re.match(r'^-\\s+`([^<]+)\\s+<([^>]+).ipynb>`__', l)\n        if m:\n            # List of subdirectories in order of appearance in index.rst\n            pthlst.append(m.group(2))\n            # Dict mapping subdirectory name to description\n            pthidx[m.group(2)] = m.group(1)\n    return pthlst, pthidx", "response": "Parse the top - level notebook index file at ntbkpth and return a list of subdirectories in order of appearance in the index file and a dict mapping subdirectory name to a description."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstruct a markdown format index for the list of paths in pthlst.", "response": "def construct_notebook_index(title, pthlst, pthidx):\n    \"\"\"\n    Construct a string containing a markdown format index for the list\n    of paths in `pthlst`.  The title for the index is in `title`, and\n    `pthidx` is a dict giving label text for each path.\n    \"\"\"\n\n    # Insert title text\n    txt = '\"\"\"\\n## %s\\n\"\"\"\\n\\n\"\"\"' % title\n    # Insert entry for each item in pthlst\n    for pth in pthlst:\n        # If pth refers to a .py file, replace .py with .ipynb, otherwise\n        # assume it's a directory name and append '/index.ipynb'\n        if pth[-3:] == '.py':\n            link = os.path.splitext(pth)[0] + '.ipynb'\n        else:\n            link = os.path.join(pth, 'index.ipynb')\n        txt += '- [%s](%s)\\n' % (pthidx[pth], link)\n    txt += '\"\"\"'\n    return txt"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine whether the notebook at pth has been executed.", "response": "def notebook_executed(pth):\n    \"\"\"Determine whether the notebook at `pth` has been executed.\"\"\"\n\n    nb = nbformat.read(pth, as_version=4)\n    for n in range(len(nb['cells'])):\n        if nb['cells'][n].cell_type == 'code' and \\\n                nb['cells'][n].execution_count is None:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True of the code cells of notebook objects nb1 and nb2 are the same.", "response": "def same_notebook_code(nb1, nb2):\n    \"\"\"\n    Return true of the code cells of notebook objects `nb1` and `nb2`\n    are the same.\n    \"\"\"\n\n    # Notebooks do not match of the number of cells differ\n    if len(nb1['cells']) != len(nb2['cells']):\n        return False\n\n    # Iterate over cells in nb1\n    for n in range(len(nb1['cells'])):\n        # Notebooks do not match if corresponding cells have different\n        # types\n        if nb1['cells'][n]['cell_type'] != nb2['cells'][n]['cell_type']:\n            return False\n        # Notebooks do not match if source of corresponding code cells\n        # differ\n        if nb1['cells'][n]['cell_type'] == 'code' and \\\n                nb1['cells'][n]['source'] != nb2['cells'][n]['source']:\n            return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes the notebook at npth using dpth as the execution directory.", "response": "def execute_notebook(npth, dpth, timeout=1200, kernel='python3'):\n    \"\"\"\n    Execute the notebook at `npth` using `dpth` as the execution\n    directory.  The execution timeout and kernel are `timeout` and\n    `kernel` respectively.\n    \"\"\"\n\n    ep = ExecutePreprocessor(timeout=timeout, kernel_name=kernel)\n    nb = nbformat.read(npth, as_version=4)\n    t0 = timer()\n    ep.preprocess(nb, {'metadata': {'path': dpth}})\n    t1 = timer()\n    with open(npth, 'wt') as f:\n        nbformat.write(nb, f)\n    return t1 - t0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace_markdown_cells(src, dst):\n\n    # It is an error to attempt markdown replacement if src and dst\n    # have different numbers of cells\n    if len(src['cells']) != len(dst['cells']):\n        raise ValueError('notebooks do not have the same number of cells')\n\n    # Iterate over cells in src\n    for n in range(len(src['cells'])):\n        # It is an error to attempt markdown replacement if any\n        # corresponding pair of cells have different type\n        if src['cells'][n]['cell_type'] != dst['cells'][n]['cell_type']:\n            raise ValueError('cell number %d of different type in src and dst')\n        # If current src cell is a markdown cell, copy the src cell to\n        # the dst cell\n        if src['cells'][n]['cell_type'] == 'markdown':\n            dst['cells'][n]['source'] = src['cells'][n]['source']", "response": "Replace markdown cells in notebook object src with corresponding\n    cells in notebook object dst."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef notebook_substitute_ref_with_url(ntbk, cr):\n\n    # Iterate over cells in notebook\n    for n in range(len(ntbk['cells'])):\n        # Only process cells of type 'markdown'\n        if ntbk['cells'][n]['cell_type'] == 'markdown':\n            # Get text of markdown cell\n            txt = ntbk['cells'][n]['source']\n            # Replace links to online docs with sphinx cross-references\n            txt = cr.substitute_ref_with_url(txt)\n            # Replace current cell text with processed text\n            ntbk['cells'][n]['source'] = txt", "response": "In markdown cells of notebook object ntbk replace sphinx\n    cross - references with links to online docs. Parameter cr is a CrossReferenceLookup object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef preprocess_notebook(ntbk, cr):\n\n    # Iterate over cells in notebook\n    for n in range(len(ntbk['cells'])):\n        # Only process cells of type 'markdown'\n        if ntbk['cells'][n]['cell_type'] == 'markdown':\n            # Get text of markdown cell\n            txt = ntbk['cells'][n]['source']\n            # Replace links to online docs with sphinx cross-references\n            txt = cr.substitute_url_with_ref(txt)\n            # Replace current cell text with processed text\n            ntbk['cells'][n]['source'] = txt", "response": "Processes a notebook object ntbk in preparation for conversion to an an\n    rst document."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting the converted notebook text txt and resources res to the specified directory pth.", "response": "def write_notebook_rst(txt, res, fnm, pth):\n    \"\"\"\n    Write the converted notebook text `txt` and resources `res` to\n    filename `fnm` in directory `pth`.\n    \"\"\"\n\n    # Extended filename used for output images\n    extfnm = fnm + '_files'\n    # Directory into which output images are written\n    extpth = os.path.join(pth, extfnm)\n    # Make output image directory if it doesn't exist\n    mkdir(extpth)\n    # Iterate over output images in resources dict\n    for r in res['outputs'].keys():\n        # New name for current output image\n        rnew = re.sub('output', fnm, r)\n        # Partial path for current output image\n        rpth = os.path.join(extfnm, rnew)\n        # In RST text, replace old output name with the new one\n        txt = re.sub('\\.\\. image:: ' + r, '.. image:: ' + rpth, txt, re.M)\n        # Full path of the current output image\n        fullrpth = os.path.join(pth, rpth)\n        # Write the current output image to disk\n        with open(fullrpth, 'wb') as fo:\n            fo.write(res['outputs'][r])\n\n    # Remove trailing whitespace in RST text\n    txt = re.sub(r'[ \\t]+$', '', txt, flags=re.M)\n\n    # Write RST text to disk\n    with open(os.path.join(pth, fnm + '.rst'), 'wt') as fo:\n        fo.write(txt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a notebook at npth to rst document at rpth in directory rdir.", "response": "def notebook_to_rst(npth, rpth, rdir, cr=None):\n    \"\"\"\n    Convert notebook at `npth` to rst document at `rpth`, in directory\n    `rdir`. Parameter `cr` is a CrossReferenceLookup object.\n    \"\"\"\n\n    # Read the notebook file\n    ntbk = nbformat.read(npth, nbformat.NO_CONVERT)\n    # Convert notebook object to rstpth\n    notebook_object_to_rst(ntbk, rpth, rdir, cr)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef notebook_object_to_rst(ntbk, rpth, cr=None):\n\n    # Parent directory of file rpth\n    rdir = os.path.dirname(rpth)\n    # File basename\n    rb = os.path.basename(os.path.splitext(rpth)[0])\n\n    # Pre-process notebook prior to conversion to rst\n    if cr is not None:\n        preprocess_notebook(ntbk, cr)\n    # Convert notebook to rst\n    rex = RSTExporter()\n    rsttxt, rstres = rex.from_notebook_node(ntbk)\n    # Replace `` with ` in sphinx cross-references\n    rsttxt = re.sub(r':([^:]+):``(.*?)``', r':\\1:`\\2`', rsttxt)\n    # Insert a cross-reference target at top of file\n    reflbl = '.. _examples_' + os.path.basename(rdir) + '_' + \\\n             rb.replace('-', '_') + ':\\n'\n    rsttxt = reflbl + rsttxt\n    # Write the converted rst to disk\n    write_notebook_rst(rsttxt, rstres, rb, rdir)", "response": "Convert a notebook object to rst document at rpth in in\n    directory rdir."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a script and the corresponding executed notebook to rst.", "response": "def script_and_notebook_to_rst(spth, npth, rpth):\n    \"\"\"\n    Convert a script and the corresponding executed notebook to rst.\n    The script is converted to notebook format *without* replacement\n    of sphinx cross-references with links to online docs, and the\n    resulting markdown cells are inserted into the executed notebook,\n    which is then converted to rst.\n    \"\"\"\n\n    # Read entire text of script at spth\n    with open(spth) as f:\n        stxt = f.read()\n    # Process script text\n    stxt = preprocess_script_string(stxt)\n    # Convert script text to notebook object\n    nbs = script_string_to_notebook_object(stxt)\n\n    # Read notebook file npth\n    nbn = nbformat.read(npth, as_version=4)\n\n    # Overwrite markdown cells in nbn with those from nbs\n    try:\n        replace_markdown_cells(nbs, nbn)\n    except ValueError:\n        raise ValueError('mismatch between source script %s and notebook %s' %\n                         (spth, npth))\n\n    # Convert notebook object to rst\n    notebook_object_to_rst(nbn, rpth)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates rst docs from example scripts.", "response": "def make_example_scripts_docs(spth, npth, rpth):\n    \"\"\"\n    Generate rst docs from example scripts.  Arguments `spth`, `npth`,\n    and `rpth` are the top-level scripts directory, the top-level\n    notebooks directory, and the top-level output directory within the\n    docs respectively.\n    \"\"\"\n\n    # Ensure that output directory exists\n    mkdir(rpth)\n\n    # Iterate over index files\n    for fp in glob(os.path.join(spth, '*.rst')) + \\\n              glob(os.path.join(spth, '*', '*.rst')):\n        # Index basename\n        b = os.path.basename(fp)\n        # Index dirname\n        dn = os.path.dirname(fp)\n        # Name of subdirectory of examples directory containing current index\n        sd = os.path.split(dn)\n        # Set d to the name of the subdirectory of the root directory\n        if dn == spth:  # fp is the root directory index file\n            d = ''\n        else:           # fp is a subdirectory index file\n            d = sd[-1]\n        # Path to corresponding subdirectory in docs directory\n        fd = os.path.join(rpth, d)\n        # Ensure notebook subdirectory exists\n        mkdir(fd)\n        # Filename of index file to be constructed\n        fn = os.path.join(fd, b)\n        # Process current index file if corresponding notebook file\n        # doesn't exist, or is older than index file\n        if update_required(fp, fn):\n            print('Converting %s                ' % os.path.join(d, b),\n                  end='\\r')\n            # Convert script index to docs index\n            rst_to_docs_rst(fp, fn)\n\n    # Iterate over example scripts\n    for fp in sorted(glob(os.path.join(spth, '*', '*.py'))):\n        # Name of subdirectory of examples directory containing current script\n        d = os.path.split(os.path.dirname(fp))[1]\n        # Script basename\n        b = os.path.splitext(os.path.basename(fp))[0]\n        # Path to corresponding notebook\n        fn = os.path.join(npth, d, b + '.ipynb')\n        # Path to corresponding sphinx doc file\n        fr = os.path.join(rpth, d, b + '.rst')\n        # Only proceed if script and notebook exist\n        if os.path.exists(fp) and os.path.exists(fn):\n            # Convert notebook to rst if notebook is newer than rst\n            # file or if rst file doesn't exist\n            if update_required(fn, fr):\n                fnb = os.path.join(d, b + '.ipynb')\n                print('Processing %s                ' % fnb, end='\\r')\n                script_and_notebook_to_rst(fp, fn, fr)\n        else:\n            print('WARNING: script %s or notebook %s not found' %\n                  (fp, fn))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the full name of an object in the system.", "response": "def get_full_name(self, role, name):\n        \"\"\"\n        If ``name`` is already the full name of an object, return\n        ``name``.  Otherwise, if ``name`` is a partial object name,\n        look up the full name and return it.\n        \"\"\"\n\n        # An initial '.' indicates a partial name\n        if name[0] == '.':\n            # Find matches for the partial name in the string\n            # containing all full names for this role\n            ptrn = r'(?<= )[^,]*' + name + r'(?=,)'\n            ml = re.findall(ptrn, self.rolnam[role])\n            # Handle cases depending on the number of returned matches,\n            # raising an error if exactly one match is not found\n            if len(ml) == 0:\n                raise KeyError('name matching %s not found' % name,\n                               'name', len(ml))\n            elif len(ml) > 1:\n                raise KeyError('multiple names matching %s found' % name,\n                               'name', len(ml))\n            else:\n                return ml[0]\n        else:\n            # The absence of an initial '.' indicates a full\n            # name. Return the name if it is present in the inventory,\n            # otherwise raise an error\n            try:\n                dom = IntersphinxInventory.roledomain[role]\n            except KeyError:\n                raise KeyError('role %s not found' % role, 'role', 0)\n            if name in self.inv[dom]:\n                return name\n            else:\n                raise KeyError('name %s not found' % name, 'name', 0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef matching_base_url(self, url):\n\n        n = len(self.baseurl)\n        return url[0:n] == self.baseurl", "response": "Return True if the initial part of url matches the base url of this object and False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_sphinx_ref(self, url, label=None):\n\n        # Raise an exception if the initial part of url does not match\n        # the base url for this object\n        n = len(self.baseurl)\n        if url[0:n] != self.baseurl:\n            raise KeyError('base of url %s does not match base url %s' %\n                           (url, self.baseurl))\n        # The reverse lookup key is either the full url or the postfix\n        # to the base url, depending on flag addbase\n        if self.addbase:\n            pstfx = url[n:]\n        else:\n            pstfx = url\n\n        # Look up the cross-reference role and referenced object\n        # name via the postfix to the base url\n        role, name = self.revinv[pstfx]\n\n        # If the label string is provided and is shorter than the name\n        # string we have lookup up, assume it is a partial name for\n        # the same object: append a '.' at the front and use it as the\n        # object name in the cross-reference\n        if label is not None and len(label) < len(name):\n            name = '.' + label\n\n        # Construct cross-reference\n        ref = ':%s:`%s`' % (role, name)\n        return ref", "response": "Get an internal sphinx cross - reference corresponding to url and label."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstruct dicts facilitating information lookup in an inventory dict.", "response": "def inventory_maps(inv):\n        \"\"\"\n        Construct dicts facilitating information lookup in an\n        inventory dict. A reversed dict allows lookup of a tuple\n        specifying the sphinx cross-reference role and the name of the\n        referenced type from the intersphinx inventory url postfix\n        string. A role-specific name lookup string allows the set of all\n        names corresponding to a specific role to be searched via regex.\n        \"\"\"\n\n        # Initialise dicts\n        revinv = {}\n        rolnam = {}\n        # Iterate over domain keys in inventory dict\n        for d in inv:\n            # Since keys seem to be duplicated, ignore those not\n            # starting with 'py:'\n            if d[0:3] == 'py:' and d in IntersphinxInventory.domainrole:\n                # Get role corresponding to current domain\n                r = IntersphinxInventory.domainrole[d]\n                # Initialise role-specific name lookup string\n                rolnam[r] = ''\n                # Iterate over all type names for current domain\n                for n in inv[d]:\n                    # Get the url postfix string for the current\n                    # domain and type name\n                    p = inv[d][n][2]\n                    # Allow lookup of role and object name tuple from\n                    # url postfix\n                    revinv[p] = (r, n)\n                    # Append object name to a string for this role,\n                    # allowing regex searching for partial names\n                    rolnam[r] += ' ' + n + ','\n        return revinv, rolnam"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_docs_url(self, role, name):\n\n        if role == 'cite':\n            # If the cross-reference is a citation, make sure that\n            # the cite key is in the sphinx environment bibtex cache.\n            # If it is, construct the url from the cite key, otherwise\n            # raise an exception\n            if name not in self.env.bibtex_cache.get_all_cited_keys():\n                raise KeyError('cite key %s not found' % name, 'cite', 0)\n            url = self.baseurl + 'zreferences.html#' + name\n        elif role == 'ref':\n            try:\n                reftpl = self.env.domaindata['std']['labels'][name]\n            except Exception:\n                raise KeyError('ref label %s not found' % name, 'ref', 0)\n            url = self.baseurl + reftpl[0] + '.html#' + reftpl[1]\n        else:\n            # If the  cross-reference is not a citation, try to look it\n            # up in each of the IntersphinxInventory objects in our list\n            url = None\n            for ii in self.invlst:\n                try:\n                    url = ii.get_docs_url(role, name)\n                except KeyError as ex:\n                    # Re-raise the exception if multiple matches found,\n                    # otherwise ignore it\n                    if ex.args[1] == 'role' or ex.args[2] > 1:\n                        raise ex\n                else:\n                    # If an exception was not raised, the lookup must\n                    # have succeeded: break from the loop to terminate\n                    # further searching\n                    break\n\n            if url is None:\n                raise KeyError('name %s not found' % name, 'name', 0)\n\n        return url", "response": "Get the online docs url for sphinx cross - reference."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_docs_label(self, role, name):\n\n        if role == 'cite':\n            # Get the string used as the citation label in the text\n            try:\n                cstr = self.env.bibtex_cache.get_label_from_key(name)\n            except Exception:\n                raise KeyError('cite key %s not found' % name, 'cite', 0)\n            # The link label is the citation label (number) enclosed\n            # in square brackets\n            return '[%s]' % cstr\n        elif role == 'ref':\n            try:\n                reftpl = self.env.domaindata['std']['labels'][name]\n            except Exception:\n                raise KeyError('ref label %s not found' % name, 'ref', 0)\n            return reftpl[2]\n        else:\n            # Use the object name as a label, omiting any initial '.'\n            if name[0] == '.':\n                return name[1:]\n            else:\n                return name", "response": "Get an appropriate label to use in a link to the online docs."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget an internal sphinx cross reference corresponding to url and label.", "response": "def get_sphinx_ref(self, url, label=None):\n        \"\"\"\n        Get an internal sphinx cross reference corresponding to `url`\n        into the online docs, associated with a link with label `label`\n        (if not None).\n        \"\"\"\n\n        # A url is assumed to correspond to a citation if it contains\n        # 'zreferences.html#'\n        if 'zreferences.html#' in url:\n            key = url.partition('zreferences.html#')[2]\n            ref = ':cite:`%s`' % key\n        else:\n            # If the url does not correspond to a citation, try to look it\n            # up in each of the IntersphinxInventory objects in our list\n            ref = None\n            # Iterate over IntersphinxInventory objects in our list\n            for ii in self.invlst:\n                # If the baseurl for the current IntersphinxInventory\n                # object matches the url, try to look up the reference\n                # from the url and terminate the loop of the look up\n                # succeeds\n                if ii.matching_base_url(url):\n                    ref = ii.get_sphinx_ref(url, label)\n                    break\n\n            if ref is None:\n                raise KeyError('no match found for url %s' % url)\n\n        return ref"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef substitute_ref_with_url(self, txt):\n\n        # Find sphinx cross-references\n        mi = re.finditer(r':([^:]+):`([^`]+)`', txt)\n        if mi:\n            # Iterate over match objects in iterator returned by re.finditer\n            for mo in mi:\n                # Initialize link label and url for substitution\n                lbl = None\n                url = None\n                # Get components of current match: full matching text, the\n                # role label in the reference, and the name of the\n                # referenced type\n                mtxt = mo.group(0)\n                role = mo.group(1)\n                name = mo.group(2)\n\n                # If role is 'ref', the name component is in the form\n                # label <name>\n                if role == 'ref':\n                    ma = re.match(r'\\s*([^\\s<]+)\\s*<([^>]+)+>', name)\n                    if ma:\n                        name = ma.group(2)\n                        lbl = ma.group(1)\n\n                # Try to look up the current cross-reference. Issue a\n                # warning if the lookup fails, and do the substitution\n                # if it succeeds.\n                try:\n                    url = self.get_docs_url(role, name)\n                    if role != 'ref':\n                        lbl = self.get_docs_label(role, name)\n                except KeyError as ex:\n                    if len(ex.args) == 1 or ex.args[1] != 'role':\n                        print('Warning: %s' % ex.args[0])\n                else:\n                    # If the cross-reference lookup was successful, replace\n                    # it with an appropriate link to the online docs\n                    rtxt = '[%s](%s)' % (lbl, url)\n                    txt = re.sub(mtxt, rtxt, txt, flags=re.M)\n\n        return txt", "response": "Substitute sphinx references with online docs with online docs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef substitute_url_with_ref(self, txt):\n\n        # Find links\n        mi = re.finditer(r'\\[([^\\]]+|\\[[^\\]]+\\])\\]\\(([^\\)]+)\\)', txt)\n        if mi:\n            # Iterate over match objects in iterator returned by\n            # re.finditer\n            for mo in mi:\n                # Get components of current match: full matching text,\n                # the link label, and the postfix to the base url in the\n                # link url\n                mtxt = mo.group(0)\n                lbl = mo.group(1)\n                url = mo.group(2)\n\n                # Try to look up the current link url. Issue a warning if\n                # the lookup fails, and do the substitution if it succeeds.\n                try:\n                    ref = self.get_sphinx_ref(url, lbl)\n                except KeyError as ex:\n                    print('Warning: %s' % ex.args[0])\n                else:\n                    txt = re.sub(re.escape(mtxt), ref, txt)\n\n        return txt", "response": "Substitute links to online docs with sphinx cross - references."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ConvCnstrMOD(*args, **kwargs):\n\n    # Extract method selection argument or set default\n    if 'method' in kwargs:\n        method = kwargs['method']\n        del kwargs['method']\n    else:\n        method = 'cns'\n\n    # Assign base class depending on method selection argument\n    if method == 'ism':\n        base = ConvCnstrMOD_IterSM\n    elif method == 'cg':\n        base = ConvCnstrMOD_CG\n    elif method == 'cns':\n        base = ConvCnstrMOD_Consensus\n    else:\n        raise ValueError('Unknown ConvCnstrMOD solver method %s' % method)\n\n    # Nested class with dynamically determined inheritance\n    class ConvCnstrMOD(base):\n        def __init__(self, *args, **kwargs):\n            super(ConvCnstrMOD, self).__init__(*args, **kwargs)\n\n    # Allow pickling of objects of type ConvCnstrMOD\n    _fix_dynamic_class_lookup(ConvCnstrMOD, method)\n\n    # Return object of the nested class type\n    return ConvCnstrMOD(*args, **kwargs)", "response": "A wrapper function that dynamically defines a class derived from the ConvCnstrMOD class and returns an object instantiated with the provided parameters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ConvCnstrMODOptions(opt=None, method='cns'):\n\n    # Assign base class depending on method selection argument\n    if method == 'ism':\n        base = ConvCnstrMOD_IterSM.Options\n    elif method == 'cg':\n        base = ConvCnstrMOD_CG.Options\n    elif method == 'cns':\n        base = ConvCnstrMOD_Consensus.Options\n    else:\n        raise ValueError('Unknown ConvCnstrMOD solver method %s' % method)\n\n    # Nested class with dynamically determined inheritance\n    class ConvCnstrMODOptions(base):\n        def __init__(self, opt):\n            super(ConvCnstrMODOptions, self).__init__(opt)\n\n    # Allow pickling of objects of type ConvCnstrMODOptions\n    _fix_dynamic_class_lookup(ConvCnstrMODOptions, method)\n\n    # Return object of the nested class type\n    return ConvCnstrMODOptions(opt)", "response": "A wrapper function that returns a class derived from the Options class associated with a Convolutional Constrained MOD problem and returns an object of type ConvCnstrMODOptions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef uinit(self, ushape):\n\n        if self.opt['Y0'] is None:\n            return np.zeros(ushape, dtype=self.dtype)\n        else:\n            # If initial Y is non-zero, initial U is chosen so that\n            # the relevant dual optimality criterion (see (3.10) in\n            # boyd-2010-distributed) is satisfied.\n            return self.Y", "response": "Return initialiser for working variable U"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget final dictionary. If ``crop`` is ``True``, apply :func:`.cnvrep.bcrop` to returned array.", "response": "def getdict(self, crop=True):\n        \"\"\"Get final dictionary. If ``crop`` is ``True``, apply\n        :func:`.cnvrep.bcrop` to returned array.\n        \"\"\"\n\n        D = self.Y\n        if crop:\n            D = cr.bcrop(D, self.cri.dsz, self.cri.dimN)\n        return D"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nminimises Augmented Lagrangian with respect to y.", "response": "def ystep(self):\n        r\"\"\"Minimise Augmented Lagrangian with respect to\n        :math:`\\mathbf{y}`.\n        \"\"\"\n\n        self.Y = self.Pcn(self.AX + self.U)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute components of objective function as well as total contribution to objective function.", "response": "def eval_objfn(self):\n        \"\"\"Compute components of objective function as well as total\n        contribution to objective function.\n        \"\"\"\n\n        dfd = self.obfn_dfd()\n        cns = self.obfn_cns()\n        return (dfd, cns)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes constraint violation measure.", "response": "def obfn_cns(self):\n        r\"\"\"Compute constraint violation measure :math:`\\| P(\\mathbf{y}) -\n        \\mathbf{y}\\|_2`.\n        \"\"\"\n\n        return np.linalg.norm((self.Pcn(self.obfn_gvar()) - self.obfn_gvar()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreconstructs representation of the object.", "response": "def reconstruct(self, D=None):\n        \"\"\"Reconstruct representation.\"\"\"\n\n        if D is None:\n            Df = self.Xf\n        else:\n            Df = sl.rfftn(D, None, self.cri.axisN)\n\n        Sf = np.sum(self.Zf * Df, axis=self.cri.axisM)\n        return sl.irfftn(Sf, self.cri.Nv, self.cri.axisN)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef xstep(self):\n\n        self.cgit = None\n        self.YU[:] = self.Y - self.U\n        b = self.ZSf + self.rho*sl.rfftn(self.YU, None, self.cri.axisN)\n        self.Xf[:], cgit = sl.solvemdbi_cg(self.Zf, self.rho, b,\n                                           self.cri.axisM, self.cri.axisK,\n                                           self.opt['CG', 'StopTol'],\n                                           self.opt['CG', 'MaxIter'], self.Xf)\n        self.cgit = cgit\n        self.X = sl.irfftn(self.Xf, self.cri.Nv, self.cri.axisN)\n        self.xstep_check(b)", "response": "Minimise Augmented Lagrangian with respect to respect to \\ mathbf { x."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning initialiser for working variable U.", "response": "def uinit(self, ushape):\n        \"\"\"Return initialiser for working variable U.\"\"\"\n\n        if self.opt['Y0'] is None:\n            return np.zeros(ushape, dtype=self.dtype)\n        else:\n            # If initial Y is non-zero, initial U is chosen so that\n            # the relevant dual optimality criterion (see (3.10) in\n            # boyd-2010-distributed) is satisfied.\n            return np.repeat(self.Y[..., np.newaxis],\n                             self.Nb, axis=-1)/self.rho"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nminimise Augmented Lagrangian with respect to block vector .", "response": "def xstep(self):\n        r\"\"\"Minimise Augmented Lagrangian with respect to block vector\n        :math:`\\mathbf{x} = \\left( \\begin{array}{ccc} \\mathbf{x}_0^T &\n        \\mathbf{x}_1^T & \\ldots \\end{array} \\right)^T\\;`.\n        \"\"\"\n\n        # This test reflects empirical evidence that two slightly\n        # different implementations are faster for single or\n        # multi-channel data. This kludge is intended to be temporary.\n        if self.cri.Cd > 1:\n            for i in range(self.Nb):\n                self.xistep(i)\n        else:\n            self.YU[:] = self.Y[..., np.newaxis] - self.U\n            b = np.swapaxes(self.ZSf[..., np.newaxis], self.cri.axisK, -1) \\\n                + self.rho*sl.rfftn(self.YU, None, self.cri.axisN)\n            for i in range(self.Nb):\n                self.Xf[..., i] = sl.solvedbi_sm(\n                    self.Zf[..., [i], :], self.rho, b[..., i],\n                    axis=self.cri.axisM)\n            self.X = sl.irfftn(self.Xf, self.cri.Nv, self.cri.axisN)\n\n\n        if self.opt['LinSolveCheck']:\n            ZSfs = np.sum(self.ZSf, axis=self.cri.axisK, keepdims=True)\n            YU = np.sum(self.Y[..., np.newaxis] - self.U, axis=-1)\n            b = ZSfs + self.rho*sl.rfftn(YU, None, self.cri.axisN)\n            Xf = self.swapaxes(self.Xf)\n            Zop = lambda x: sl.inner(self.Zf, x, axis=self.cri.axisM)\n            ZHop = lambda x: np.conj(self.Zf) * x\n            ax = np.sum(ZHop(Zop(Xf)) + self.rho*Xf, axis=self.cri.axisK,\n                        keepdims=True)\n            self.xrrs = sl.rrs(ax, b)\n        else:\n            self.xrrs = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nminimises Augmented Lagrangian with respect to respect to \\ mathbf { x } i.", "response": "def xistep(self, i):\n        r\"\"\"Minimise Augmented Lagrangian with respect to :math:`\\mathbf{x}`\n        component :math:`\\mathbf{x}_i`.\n        \"\"\"\n\n        self.YU[:] = self.Y - self.U[..., i]\n        b = np.take(self.ZSf, [i], axis=self.cri.axisK) + \\\n            self.rho*sl.rfftn(self.YU, None, self.cri.axisN)\n\n        self.Xf[..., i] = sl.solvedbi_sm(np.take(\n            self.Zf, [i], axis=self.cri.axisK),\n                                         self.rho, b, axis=self.cri.axisM)\n        self.X[..., i] = sl.irfftn(self.Xf[..., i], self.cri.Nv,\n                                   self.cri.axisN)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute constraint violation measure.", "response": "def obfn_cns(self):\n        r\"\"\"Compute constraint violation measure :math:`\\| P(\\mathbf{y})\n        - \\mathbf{y}\\|_2`.\n        \"\"\"\n\n        Y = self.obfn_gvar()\n        return np.linalg.norm((self.Pcn(Y) - Y))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the coefficient array for the entry in the dictionary.", "response": "def setcoef(self, Z):\n        \"\"\"Set coefficient array.\"\"\"\n\n        # If the dictionary has a single channel but the input (and\n        # therefore also the coefficient map array) has multiple\n        # channels, the channel index and multiple image index have\n        # the same behaviour in the dictionary update equation: the\n        # simplest way to handle this is to just reshape so that the\n        # channels also appear on the multiple image index.\n        if self.cri.Cd == 1 and self.cri.C > 1:\n            Z = Z.reshape(self.cri.Nv + (1,) + (self.cri.Cx * self.cri.K,) +\n                          (self.cri.M,))\n        self.Z = np.asarray(Z, dtype=self.dtype)\n\n        self.Zf = sl.rfftn(self.Z, self.cri.Nv, self.cri.axisN)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes gradient in Fourier domain.", "response": "def eval_grad(self):\n        \"\"\"Compute gradient in Fourier domain.\"\"\"\n\n        # Compute X D - S\n        Ryf = self.eval_Rf(self.Yf)\n\n        gradf = sl.inner(np.conj(self.Zf), Ryf, axis=self.cri.axisK)\n\n        # Multiple channel signal, single channel dictionary\n        if self.cri.C > 1 and self.cri.Cd == 1:\n            gradf = np.sum(gradf, axis=self.cri.axisC, keepdims=True)\n\n        return gradf"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute fixed point residual in Fourier domain.", "response": "def rsdl(self):\n        \"\"\"Compute fixed point residual in Fourier domain.\"\"\"\n\n        diff = self.Xf - self.Yfprv\n        return sl.rfl2norm2(diff, self.X.shape, axis=self.cri.axisN)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing data fidelity term", "response": "def obfn_dfd(self):\n        r\"\"\"Compute data fidelity term :math:`(1/2) \\| \\sum_m\n        \\mathbf{d}_m * \\mathbf{x}_m - \\mathbf{s} \\|_2^2`.\n        \"\"\"\n\n        Ef = self.eval_Rf(self.Xf)\n        return sl.rfl2norm2(Ef, self.S.shape, axis=self.cri.axisN) / 2.0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef obfn_cns(self):\n\n        return np.linalg.norm((self.Pcn(self.X) - self.X))", "response": "Compute constraint violation measure."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef obfn_f(self, Xf=None):\n        if Xf is None:\n            Xf = self.Xf\n\n        Rf = self.eval_Rf(Xf)\n        return 0.5 * np.linalg.norm(Rf.flatten(), 2)**2", "response": "r Compute data fidelity term"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef obfn_dfd(self):\n\n        Ef = self.eval_Rf(self.Xf)\n        E = sl.irfftn(Ef, self.cri.Nv, self.cri.axisN)\n\n        return (np.linalg.norm(self.W * E)**2) / 2.0", "response": "Compute data fidelity term"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cbpdn_class_label_lookup(label):\n\n    clsmod = {'admm': admm_cbpdn.ConvBPDN,\n              'fista': fista_cbpdn.ConvBPDN}\n    if label in clsmod:\n        return clsmod[label]\n    else:\n        raise ValueError('Unknown ConvBPDN solver method %s' % label)", "response": "Get a CBPDN class from a label string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget defaults dict for the ConvBPDN class specified by the method paramater.", "response": "def ConvBPDNOptionsDefaults(method='admm'):\n    \"\"\"Get defaults dict for the ConvBPDN class specified by the ``method``\n    parameter.\n    \"\"\"\n\n    dflt = copy.deepcopy(cbpdn_class_label_lookup(method).Options.defaults)\n    if method == 'admm':\n        dflt.update({'MaxMainIter': 1, 'AutoRho':\n                     {'Period': 10, 'AutoScaling': False,\n                      'RsdlRatio': 10.0, 'Scaling': 2.0,\n                      'RsdlTarget': 1.0}})\n    else:\n        dflt.update({'MaxMainIter': 1, 'BackTrack':\n                     {'gamma_u': 1.2, 'MaxIter': 50}})\n    return dflt"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ConvBPDN(*args, **kwargs):\n\n    # Extract method selection argument or set default\n    method = kwargs.pop('method', 'admm')\n\n    # Assign base class depending on method selection argument\n    base = cbpdn_class_label_lookup(method)\n\n    # Nested class with dynamically determined inheritance\n    class ConvBPDN(base):\n        def __init__(self, *args, **kwargs):\n            super(ConvBPDN, self).__init__(*args, **kwargs)\n\n    # Allow pickling of objects of type ConvBPDN\n    _fix_dynamic_class_lookup(ConvBPDN, method)\n\n    # Return object of the nested class type\n    return ConvBPDN(*args, **kwargs)", "response": "A wrapper function that dynamically defines a class derived from a Convolutional Constrained MOD\n    problem and returns an object instantiated with the provided parameters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a CCMOD class from a label string.", "response": "def ccmod_class_label_lookup(label):\n    \"\"\"Get a CCMOD class from a label string.\"\"\"\n\n    clsmod = {'ism': admm_ccmod.ConvCnstrMOD_IterSM,\n              'cg': admm_ccmod.ConvCnstrMOD_CG,\n              'cns': admm_ccmod.ConvCnstrMOD_Consensus,\n              'fista': fista_ccmod.ConvCnstrMOD}\n    if label in clsmod:\n        return clsmod[label]\n    else:\n        raise ValueError('Unknown ConvCnstrMOD solver method %s' % label)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting defaults dict for the ConvCnstrMOD class specified by the method.", "response": "def ConvCnstrMODOptionsDefaults(method='fista'):\n    \"\"\"Get defaults dict for the ConvCnstrMOD class specified by the\n    ``method`` parameter.\n    \"\"\"\n\n    dflt = copy.deepcopy(ccmod_class_label_lookup(method).Options.defaults)\n    if method == 'fista':\n        dflt.update({'MaxMainIter': 1, 'BackTrack':\n                     {'gamma_u': 1.2, 'MaxIter': 50}})\n    else:\n        dflt.update({'MaxMainIter': 1, 'AutoRho':\n                     {'Period': 10, 'AutoScaling': False,\n                      'RsdlRatio': 10.0, 'Scaling': 2.0,\n                      'RsdlTarget': 1.0}})\n    return dflt"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ConvCnstrMODOptions(opt=None, method='fista'):\n\n    # Assign base class depending on method selection argument\n    base = ccmod_class_label_lookup(method).Options\n\n    # Nested class with dynamically determined inheritance\n    class ConvCnstrMODOptions(base):\n        def __init__(self, opt):\n            super(ConvCnstrMODOptions, self).__init__(opt)\n\n    # Allow pickling of objects of type ConvCnstrMODOptions\n    _fix_dynamic_class_lookup(ConvCnstrMODOptions, method)\n\n    # Return object of the nested class type\n    return ConvCnstrMODOptions(opt)", "response": "A wrapper function that returns a class derived from the Options class associated with a Convolutional Constrained MOD problem."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef evaluate(self):\n\n        if self.opt['AccurateDFid']:\n            if self.dmethod == 'fista':\n                D = self.dstep.getdict(crop=False)\n            else:\n                D = self.dstep.var_y()\n            if self.xmethod == 'fista':\n                X = self.xstep.getcoef()\n            else:\n                X = self.xstep.var_y()\n            Df = sl.rfftn(D, self.xstep.cri.Nv, self.xstep.cri.axisN)\n            Xf = sl.rfftn(X, self.xstep.cri.Nv, self.xstep.cri.axisN)\n            Sf = self.xstep.Sf\n            Ef = sl.inner(Df, Xf, axis=self.xstep.cri.axisM) - Sf\n            dfd = sl.rfl2norm2(Ef, self.xstep.S.shape,\n                               axis=self.xstep.cri.axisN) / 2.0\n            rl1 = np.sum(np.abs(X))\n            return dict(DFid=dfd, RegL1=rl1,\n                        ObjFun=dfd + self.xstep.lmbda * rl1)\n        else:\n            return None", "response": "Evaluate functional value of previous iteration."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nevaluates functional value of previous iteration", "response": "def evaluate(self):\n        \"\"\"Evaluate functional value of previous iteration\"\"\"\n\n        if self.opt['AccurateDFid']:\n            D = self.dstep.var_y()\n            X = self.xstep.var_y()\n            S = self.xstep.S\n            dfd = 0.5*np.linalg.norm((D.dot(X) - S))**2\n            rl1 = np.sum(np.abs(X))\n            return dict(DFid=dfd, RegL1=rl1, ObjFun=dfd+self.xstep.lmbda*rl1)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns true if pth1 is newer than pth2.", "response": "def is_newer_than(pth1, pth2):\n    \"\"\"\n    Return true if either file pth1 or file pth2 don't exist, or if\n    pth1 has been modified more recently than pth2\n    \"\"\"\n\n    return not os.path.exists(pth1) or not os.path.exists(pth2) or \\\n       os.stat(pth1).st_mtime > os.stat(pth2).st_mtime"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gengraphs(pth, nopyfftw):\n\n    srcmodflt = '^sporco.admm'\n    srcqnmflt = r'^((?!<locals>|__new|_name_nested).)*$'\n    dstqnmflt = r'^((?!<locals>|__new|_name_nested).)*$'\n\n    fnmsub = ('^sporco.admm.', '')\n    grpflt = r'^[^\\.]*.[^\\.]*'\n    lnkpfx = '../../modules/'\n    lnksub = (r'^([^\\.]*).([^\\.]*)(?:(.__init__|.__call__)|(.[^\\.]*))',\n              lnkpfx + r'sporco.admm.\\1.html#sporco.admm.\\1.\\2\\4')\n\n\n    fntsz = 9\n    fntfm = 'Vera Sans, DejaVu Sans, Liberation Sans, Arial, Helvetica, sans'\n    kwargs = {'fntsz': fntsz, 'fntfm': fntfm, 'rmsz': True}\n\n\n    ct = jonga.CallTracer(srcmodflt=srcmodflt, srcqnmflt=srcqnmflt,\n                          dstqnmflt=dstqnmflt, fnmsub=fnmsub,\n                          grpflt=grpflt, lnksub=lnksub)\n\n\n    # Make destination directory if it doesn't exist\n    if not os.path.exists(pth):\n        os.makedirs(pth, exist_ok=True)\n\n\n    # Handle environment in which pyfftw is unavailable\n    if nopyfftw:\n        import numpy.fft as npfft\n        import sporco.linalg as spl\n\n        def empty(shape, dtype, order='C', n=None):\n            return np.zeros(shape, dtype=dtype)\n        empty.__doc__ = spl.pyfftw_empty_aligned.__doc__\n        spl.pyfftw_empty_aligned = empty\n\n\n        def rfftn_empty(shape, axes, dtype, order='C', n=None):\n            ashp = list(shape)\n            raxis = axes[-1]\n            ashp[raxis] = ashp[raxis] // 2 + 1\n            cdtype = spl.complex_dtype(dtype)\n            return np.zeros(ashp, dtype=cdtype)\n        rfftn_empty.__doc__ = spl.pyfftw_rfftn_empty_aligned.__doc__\n        spl.pyfftw_rfftn_empty_aligned = rfftn_empty\n\n        npfft.fftn.__doc__ = spl.fftn.__doc__\n        spl.fftn = npfft.fftn\n        npfft.ifftn.__doc__ = spl.ifftn.__doc__\n        spl.ifftn = npfft.ifftn\n        npfft.rfftn.__doc__ = spl.rfftn.__doc__\n        spl.rfftn = npfft.rfftn\n        npfft.irfftn.__doc__ = spl.irfftn.__doc__\n        spl.irfftn = npfft.irfftn\n\n\n    import numpy as np\n    np.random.seed(12345)\n\n\n    #### bpdn module\n    from sporco.admm import bpdn\n    mdnm = 'sporco.admm.bpdn'\n\n    D = np.random.randn(8, 16)\n    s = np.random.randn(8, 1)\n    lmbda = 0.1\n\n    ## BPDN class\n    opt = bpdn.BPDN.Options({'Verbose': False, 'MaxMainIter': 1})\n\n    with CallGraph(ct, mdnm, pth, 'bpdn_init.svg', **kwargs):\n        b = bpdn.BPDN(D, s, lmbda, opt)\n\n    with CallGraph(ct, mdnm, pth, 'bpdn_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## BPDNJoint class\n    opt = bpdn.BPDNJoint.Options({'Verbose': False, 'MaxMainIter': 1})\n    mu = 0.01\n\n    with CallGraph(ct, mdnm, pth, 'bpdnjnt_init.svg', **kwargs):\n        b = bpdn.BPDNJoint(D, s, lmbda, mu, opt)\n\n    with CallGraph(ct, mdnm, pth, 'bpdnjnt_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## ElasticNet class\n    opt = bpdn.ElasticNet.Options({'Verbose': False, 'MaxMainIter': 1})\n\n    with CallGraph(ct, mdnm, pth, 'elnet_init.svg', **kwargs):\n        b = bpdn.ElasticNet(D, s, lmbda, mu, opt)\n\n    with CallGraph(ct, mdnm, pth, 'elnet_solve.svg', **kwargs):\n        b.solve()\n\n\n    # BPDNProjL1 class\n    opt = bpdn.BPDNProjL1.Options({'Verbose': False, 'MaxMainIter': 1})\n    gamma = 2.0\n\n    with CallGraph(ct, mdnm, pth, 'bpdnprjl1_init.svg', **kwargs):\n        b = bpdn.BPDNProjL1(D, s, gamma, opt)\n\n    with CallGraph(ct, mdnm, pth, 'bpdnprjl1_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## MinL1InL2Ball class\n    opt = bpdn.MinL1InL2Ball.Options({'Verbose': False, 'MaxMainIter': 1})\n    epsilon = 1.0\n\n    with CallGraph(ct, mdnm, pth, 'bpdnml1l2_init.svg', **kwargs):\n        b = bpdn.MinL1InL2Ball(D, s, epsilon, opt)\n\n    with CallGraph(ct, mdnm, pth, 'bpdnml1l2_solve.svg', **kwargs):\n        b.solve()\n\n\n\n\n    #### cbpdn module\n    from sporco.admm import cbpdn\n    mdnm = 'sporco.admm.cbpdn'\n\n    D = np.random.randn(4, 4, 16)\n    s = np.random.randn(8, 8)\n    lmbda = 0.1\n\n    ## ConvBPDN class\n    opt = cbpdn.ConvBPDN.Options({'Verbose': False, 'MaxMainIter': 1})\n\n    with CallGraph(ct, mdnm, pth, 'cbpdn_init.svg', **kwargs):\n        b = cbpdn.ConvBPDN(D, s, lmbda, opt)\n\n    with CallGraph(ct, mdnm, pth, 'cbpdn_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## ConvBPDNJoint class\n    opt = cbpdn.ConvBPDNJoint.Options({'Verbose': False, 'MaxMainIter': 1})\n    mu = 0.01\n\n    with CallGraph(ct, mdnm, pth, 'cbpdnjnt_init.svg', **kwargs):\n        b = cbpdn.ConvBPDNJoint(D, s, lmbda, mu, opt)\n\n    with CallGraph(ct, mdnm, pth, 'cbpdnjnt_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## ConvElasticNet class\n    opt = cbpdn.ConvElasticNet.Options({'Verbose': False, 'MaxMainIter': 1})\n\n    with CallGraph(ct, mdnm, pth, 'celnet_init.svg', **kwargs):\n        b = cbpdn.ConvElasticNet(D, s, lmbda, mu, opt)\n\n    with CallGraph(ct, mdnm, pth, 'celnet_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## ConvBPDNGradReg class\n    opt = cbpdn.ConvBPDNGradReg.Options({'Verbose': False, 'MaxMainIter': 1})\n\n    with CallGraph(ct, mdnm, pth, 'cbpdngrd_init.svg', **kwargs):\n        b = cbpdn.ConvBPDNGradReg(D, s, lmbda, mu, opt)\n\n    with CallGraph(ct, mdnm, pth, 'cbpdngrd_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## ConvBPDNProjL1 class\n    opt = cbpdn.ConvBPDNProjL1.Options({'Verbose': False, 'MaxMainIter': 1})\n    gamma = 0.5\n\n    with CallGraph(ct, mdnm, pth, 'cbpdnprjl1_init.svg', **kwargs):\n        b = cbpdn.ConvBPDNProjL1(D, s, gamma, opt)\n\n    with CallGraph(ct, mdnm, pth, 'cbpdnprjl1_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## ConvMinL1InL2Ball class\n    opt = cbpdn.ConvMinL1InL2Ball.Options({'Verbose': False, 'MaxMainIter': 1})\n    epsilon = 0.5\n\n    with CallGraph(ct, mdnm, pth, 'cbpdnml1l2_init.svg', **kwargs):\n        b = cbpdn.ConvMinL1InL2Ball(D, s, epsilon, opt)\n\n    with CallGraph(ct, mdnm, pth, 'cbpdnml1l2_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## ConvBPDNMaskDcpl class\n    opt = cbpdn.ConvBPDNMaskDcpl.Options({'Verbose': False, 'MaxMainIter': 1})\n    W = np.ones(s.shape)\n\n    with CallGraph(ct, mdnm, pth, 'cbpdnmd_init.svg', **kwargs):\n        b = cbpdn.ConvBPDNMaskDcpl(D, s, lmbda, W, opt)\n\n    with CallGraph(ct, mdnm, pth, 'cbpdnmd_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## ConvL1L1Grd class\n    opt = cbpdn.ConvL1L1Grd.Options({'Verbose': False, 'MaxMainIter': 1})\n    mu = 1e-2\n\n    with CallGraph(ct, mdnm, pth, 'cl1l1grd_init.svg', **kwargs):\n        b = cbpdn.ConvL1L1Grd(D, s, lmbda, mu, W, opt)\n\n    with CallGraph(ct, mdnm, pth, 'cl1l1grd_solve.svg', **kwargs):\n        b.solve()\n\n\n\n\n    #### cbpdntv module\n    from sporco.admm import cbpdntv\n    mdnm = 'sporco.admm.cbpdntv'\n\n    D = np.random.randn(4, 4, 16)\n    s = np.random.randn(8, 8)\n    lmbda = 0.1\n    mu = 0.01\n\n    ## ConvBPDNScalarTV class\n    opt = cbpdntv.ConvBPDNScalarTV.Options({'Verbose': False, 'MaxMainIter': 1})\n\n    with CallGraph(ct, mdnm, pth, 'cbpdnstv_init.svg', **kwargs):\n        b = cbpdntv.ConvBPDNScalarTV(D, s, lmbda, mu, opt)\n\n    with CallGraph(ct, mdnm, pth, 'cbpdnstv_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## ConvBPDNVectorTV class\n    opt = cbpdntv.ConvBPDNVectorTV.Options({'Verbose': False, 'MaxMainIter': 1})\n\n    with CallGraph(ct, mdnm, pth, 'cbpdnvtv_init.svg', **kwargs):\n        b = cbpdntv.ConvBPDNVectorTV(D, s, lmbda, mu, opt)\n\n    with CallGraph(ct, mdnm, pth, 'cbpdnvtv_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## ConvBPDNRecTV class\n    opt = cbpdntv.ConvBPDNRecTV.Options({'Verbose': False, 'MaxMainIter': 1})\n\n    with CallGraph(ct, mdnm, pth, 'cbpdnrtv_init.svg', **kwargs):\n        b = cbpdntv.ConvBPDNRecTV(D, s, lmbda, mu, opt)\n\n    with CallGraph(ct, mdnm, pth, 'cbpdnrtv_solve.svg', **kwargs):\n        b.solve()\n\n\n\n\n    #### cmod module\n    from sporco.admm import cmod\n    mdnm = 'sporco.admm.cmod'\n\n    X = np.random.randn(8, 16)\n    S = np.random.randn(8, 16)\n\n    ## CnstrMOD class\n    opt = cmod.CnstrMOD.Options({'Verbose': False, 'MaxMainIter': 1})\n\n    with CallGraph(ct, mdnm, pth, 'cmod_init.svg', **kwargs):\n        b = cmod.CnstrMOD(X, S, opt=opt)\n\n    with CallGraph(ct, mdnm, pth, 'cmod_solve.svg', **kwargs):\n        b.solve()\n\n\n\n\n    #### ccmod module\n    from sporco.admm import ccmod\n    mdnm = 'sporco.admm.ccmod'\n\n    X = np.random.randn(8, 8, 1, 2, 1)\n    S = np.random.randn(8, 8, 2)\n    dsz = (4, 4, 1)\n\n    ## ConvCnstrMOD_IterSM class\n    opt = ccmod.ConvCnstrMOD_IterSM.Options({'Verbose': False,\n                                             'MaxMainIter': 1})\n\n    with CallGraph(ct, mdnm, pth, 'ccmodism_init.svg', **kwargs):\n        b = ccmod.ConvCnstrMOD_IterSM(X, S, dsz=dsz, opt=opt)\n\n    with CallGraph(ct, mdnm, pth, 'ccmodism_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## ConvCnstrMOD_CG class\n    opt = ccmod.ConvCnstrMOD_CG.Options({'Verbose': False,\n                                         'MaxMainIter': 1,\n                                         'CG': {'MaxIter': 1}})\n\n    with CallGraph(ct, mdnm, pth, 'ccmodcg_init.svg', **kwargs):\n        b = ccmod.ConvCnstrMOD_CG(X, S, dsz=dsz, opt=opt)\n\n    with CallGraph(ct, mdnm, pth, 'ccmodcg_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## ConvCnstrMOD_Consensus class\n    opt = ccmod.ConvCnstrMOD_Consensus.Options({'Verbose': False,\n                                                'MaxMainIter': 1})\n\n    with CallGraph(ct, mdnm, pth, 'ccmodcnsns_init.svg', **kwargs):\n        b = ccmod.ConvCnstrMOD_Consensus(X, S, dsz=dsz, opt=opt)\n\n    with CallGraph(ct, mdnm, pth, 'ccmodcnsns_solve.svg', **kwargs):\n        b.solve()\n\n\n\n\n    #### ccmodmd module\n    from sporco.admm import ccmodmd\n    mdnm = 'sporco.admm.ccmodmd'\n\n    X = np.random.randn(8, 8, 1, 2, 1)\n    S = np.random.randn(8, 8, 2)\n    W = np.array([1.0])\n    dsz = (4, 4, 1)\n\n    ## ConvCnstrMODMaskDcpl_IterSM class\n    opt = ccmodmd.ConvCnstrMODMaskDcpl_IterSM.Options({'Verbose': False,\n                                             'MaxMainIter': 1})\n\n    with CallGraph(ct, mdnm, pth, 'ccmodmdism_init.svg', **kwargs):\n        b = ccmodmd.ConvCnstrMODMaskDcpl_IterSM(X, S, W, dsz=dsz, opt=opt)\n\n    with CallGraph(ct, mdnm, pth, 'ccmodmdism_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## ConvCnstrMODMaskDcpl_CG class\n    opt = ccmodmd.ConvCnstrMODMaskDcpl_CG.Options({'Verbose': False,\n                                         'MaxMainIter': 1,\n                                         'CG': {'MaxIter': 1}})\n\n    with CallGraph(ct, mdnm, pth, 'ccmodmdcg_init.svg', **kwargs):\n        b = ccmodmd.ConvCnstrMODMaskDcpl_CG(X, S, W, dsz=dsz, opt=opt)\n\n    with CallGraph(ct, mdnm, pth, 'ccmodmdcg_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## ConvCnstrMODMaskDcpl_Consensus class\n    opt = ccmodmd.ConvCnstrMODMaskDcpl_Consensus.Options({'Verbose': False,\n                                                'MaxMainIter': 1})\n\n    with CallGraph(ct, mdnm, pth, 'ccmodmdcnsns_init.svg', **kwargs):\n        b = ccmodmd.ConvCnstrMODMaskDcpl_Consensus(X, S, W, dsz=dsz, opt=opt)\n\n    with CallGraph(ct, mdnm, pth, 'ccmodmdcnsns_solve.svg', **kwargs):\n        b.solve()\n\n\n\n\n    #### tvl1 module\n    from sporco.admm import tvl1\n    mdnm = 'sporco.admm.tvl1'\n\n    s = np.random.randn(16, 16)\n    lmbda = 0.1\n\n    ## TVL1Denoise class\n    opt = tvl1.TVL1Denoise.Options({'Verbose': False, 'MaxMainIter': 1})\n\n    with CallGraph(ct, mdnm, pth, 'tvl1den_init.svg', **kwargs):\n        b = tvl1.TVL1Denoise(s, lmbda, opt)\n\n    with CallGraph(ct, mdnm, pth, 'tvl1den_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## TVL1Deconv class\n    opt = tvl1.TVL1Deconv.Options({'Verbose': False, 'MaxMainIter': 1})\n    h = np.random.randn(3, 3)\n\n    with CallGraph(ct, mdnm, pth, 'tvl1dcn_init.svg', **kwargs):\n        b = tvl1.TVL1Deconv(h, s, lmbda, opt)\n\n    with CallGraph(ct, mdnm, pth, 'tvl1dcn_solve.svg', **kwargs):\n        b.solve()\n\n\n\n\n    #### tvl2 module\n    from sporco.admm import tvl2\n    mdnm = 'sporco.admm.tvl2'\n\n    s = np.random.randn(16, 16)\n    lmbda = 0.1\n\n    ## TVL2Denoise class\n    opt = tvl2.TVL2Denoise.Options({'Verbose': False, 'MaxMainIter': 1})\n\n    with CallGraph(ct, mdnm, pth, 'tvl2den_init.svg', **kwargs):\n        b = tvl2.TVL2Denoise(s, lmbda, opt)\n\n    with CallGraph(ct, mdnm, pth, 'tvl2den_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## TVL2Deconv class\n    opt = tvl2.TVL2Deconv.Options({'Verbose': False, 'MaxMainIter': 1})\n    h = np.random.randn(3, 3)\n\n    with CallGraph(ct, mdnm, pth, 'tvl2dcn_init.svg', **kwargs):\n        b = tvl2.TVL2Deconv(h, s, lmbda, opt)\n\n    with CallGraph(ct, mdnm, pth, 'tvl2dcn_solve.svg', **kwargs):\n        b.solve()\n\n\n\n    srcmodflt = '^sporco.fista'\n    fnmsub = ('^sporco.fista.', '')\n    lnksub = (r'^([^\\.]*).([^\\.]*)(?:(.__init__|.__call__)|(.[^\\.]*))',\n              lnkpfx + r'sporco.fista.\\1.html#sporco.fista.\\1.\\2\\4')\n    ct = jonga.CallTracer(srcmodflt=srcmodflt, srcqnmflt=srcqnmflt,\n                          dstqnmflt=dstqnmflt, fnmsub=fnmsub,\n                          grpflt=grpflt, lnksub=lnksub)\n\n\n    #### fista.cbpdn module\n    from sporco.fista import cbpdn\n    mdnm = 'sporco.fista.cbpdn'\n\n    D = np.random.randn(4, 4, 16)\n    s = np.random.randn(8, 8)\n    lmbda = 0.1\n\n    ## ConvBPDN class\n    opt = cbpdn.ConvBPDN.Options({'Verbose': False, 'MaxMainIter': 1})\n\n    with CallGraph(ct, mdnm, pth, 'fista_cbpdn_init.svg', **kwargs):\n        b = cbpdn.ConvBPDN(D, s, lmbda, opt)\n\n    with CallGraph(ct, mdnm, pth, 'fista_cbpdn_solve.svg', **kwargs):\n        b.solve()\n\n\n\n\n    #### fista.ccmod module\n    from sporco.fista import ccmod\n    mdnm = 'sporco.fista.ccmod'\n\n    X = np.random.randn(8, 8, 1, 2, 1)\n    S = np.random.randn(8, 8, 2)\n    dsz = (4, 4, 1)\n\n    ## ConvCnstrMOD class\n    opt = ccmod.ConvCnstrMOD.Options({'Verbose': False, 'MaxMainIter': 1})\n\n    with CallGraph(ct, mdnm, pth, 'ccmodfista_init.svg', **kwargs):\n        b = ccmod.ConvCnstrMOD(X, S, dsz=dsz, opt=opt)\n\n    with CallGraph(ct, mdnm, pth, 'ccmodfista_solve.svg', **kwargs):\n        b.solve()\n\n\n    ## ConvCnstrMODMask class\n    opt = ccmod.ConvCnstrMODMask.Options({'Verbose': False,\n                                          'MaxMainIter': 1})\n\n    with CallGraph(ct, mdnm, pth, 'ccmodmdfista_init.svg', **kwargs):\n        b = ccmod.ConvCnstrMODMask(X, S, W, dsz=dsz, opt=opt)\n\n    with CallGraph(ct, mdnm, pth, 'ccmodmdfista_solve.svg', **kwargs):\n        b.solve()\n\n\n\n\n    srcmodflt = '^sporco.dictlrn'\n    fnmsub = ('^sporco.dictlrn.', '')\n    lnksub = (r'^([^\\.]*).([^\\.]*)(?:(.__init__|.__call__)|(.[^\\.]*))',\n              lnkpfx + r'sporco.dictlrn.\\1.html#sporco.dictlrn.\\1.\\2\\4')\n    ct = jonga.CallTracer(srcmodflt=srcmodflt, srcqnmflt=srcqnmflt,\n                          dstqnmflt=dstqnmflt, fnmsub=fnmsub,\n                          grpflt=grpflt, lnksub=lnksub)\n\n\n\n    #### bpdndl module\n    from sporco.dictlrn import bpdndl\n    mdnm = 'sporco.dictlrn.bpdndl'\n\n    D0 = np.random.randn(8, 8)\n    S = np.random.randn(8, 16)\n    lmbda = 0.1\n\n    ## BPDNDictLearn class\n    opt = bpdndl.BPDNDictLearn.Options({'Verbose': False, 'MaxMainIter': 1,\n                                        'AccurateDFid': True})\n\n    with CallGraph(ct, mdnm, pth, 'bpdndl_init.svg', **kwargs):\n        b = bpdndl.BPDNDictLearn(D0, S, lmbda, opt)\n\n    with CallGraph(ct, mdnm, pth, 'bpdndl_solve.svg', **kwargs):\n        b.solve()\n\n\n\n\n    #### cbpdndl module\n    from sporco.dictlrn import cbpdndl\n    mdnm = 'sporco.dictlrn.cbpdndl'\n\n    D0 = np.random.randn(4, 4, 16)\n    s = np.random.randn(8, 8, 10)\n    lmbda = 0.1\n\n    ## ConvBPDNDictLearn class\n    opt = cbpdndl.ConvBPDNDictLearn.Options({'Verbose': False,\n                    'MaxMainIter': 1, 'AccurateDFid': True})\n\n    with CallGraph(ct, mdnm, pth, 'cbpdndl_init.svg', **kwargs):\n        b = cbpdndl.ConvBPDNDictLearn(D0, s, lmbda, opt)\n\n    with CallGraph(ct, mdnm, pth, 'cbpdndl_solve.svg', **kwargs):\n        b.solve()\n\n\n\n\n    #### cbpdndlmd module\n    from sporco.dictlrn import cbpdndlmd\n    mdnm = 'sporco.dictlrn.cbpdndlmd'\n\n    ## ConvBPDNMaskDcplDictLearn class\n    W = np.array([1.0])\n    opt = cbpdndlmd.ConvBPDNMaskDictLearn.Options({'Verbose': False,\n                    'MaxMainIter': 1, 'AccurateDFid': True})\n\n    with CallGraph(ct, mdnm, pth, 'cbpdnmddl_init.svg', **kwargs):\n        b = cbpdndlmd.ConvBPDNMaskDictLearn(D0, s, lmbda, W, opt)\n\n    with CallGraph(ct, mdnm, pth, 'cbpdnmddl_solve.svg', **kwargs):\n        b.solve()", "response": "Generate call graph images when necessary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mpraw_as_np(shape, dtype):\n\n    sz = int(np.product(shape))\n    csz = sz * np.dtype(dtype).itemsize\n    raw = mp.RawArray('c', csz)\n    return np.frombuffer(raw, dtype=dtype, count=sz).reshape(shape)", "response": "Construct a numpy array of the specified shape and dtype for which the multiprocessing RawArray in shared memory is a multiprocessing RawArray in shared memory."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nswaps an array x at the specified axis and return the resulting array.", "response": "def swap_axis_to_0(x, axis):\n    \"\"\"Insert a new singleton axis at position 0 and swap it with the\n    specified axis. The resulting array has an additional dimension,\n    with ``axis`` + 1 (which was ``axis`` before the insertion of the\n    new axis) of ``x`` at position 0, and a singleton axis at position\n    ``axis`` + 1.\n\n    Parameters\n    ----------\n    x : ndarray\n      Input array\n    axis : int\n      Index of axis in ``x`` to swap to axis index 0.\n\n    Returns\n    -------\n    arr : ndarray\n      Output array\n    \"\"\"\n\n    return np.ascontiguousarray(np.swapaxes(x[np.newaxis, ...], 0, axis+1))"}
